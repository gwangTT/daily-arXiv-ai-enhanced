{"id": "2508.05779", "pdf": "https://arxiv.org/pdf/2508.05779", "abs": "https://arxiv.org/abs/2508.05779", "authors": ["Pengyu Liu", "Mingkuan Xu", "Hengyun Zhou", "Hanrui Wang", "Umut A. Acar", "Yunong Shi"], "title": "ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays", "categories": ["cs.AR", "quant-ph"], "comment": null, "summary": "Recent progress on concatenated codes, especially many-hypercube codes,\nachieves unprecedented space efficiency. Yet two critical challenges persist in\npractice. First, these codes lack efficient implementations of addressable\nlogical gates. Second, the required high degree of parallelism and long-range\ninteractions pose significant challenges for current hardware platforms. In\nthis paper, we propose an efficient compilation approach for concatenated\ncodes, specifically many-hypercube codes, targeted at neutral atom arrays,\nwhich provide the necessary parallelism and long-range interactions. Our\napproach builds on two key innovations. First, we introduce\nAutomorphism-assisted Hierarchical Addressing (AHA) logical CNOT gates that\nsignificantly reduce spacetime overhead compared to conventional\ndistillation-based methods. Second, we develop Virtual Atom Intermediate\nRepresentation (VAIR) that enables level-wise optimization and legalization. We\nimplement these innovations in ConiQ, a hardware-aware quantum compiler\ndesigned to compile fault-tolerant quantum circuits for neutral atom arrays\nusing many-hypercube codes. Our evaluation demonstrates that ConiQ achieves up\nto 2000x reduction in spacetime overhead and up to 10^6x reduction in\ncompilation time compared to state-of-the-art compilers, with our AHA gates\nproviding an additional overhead reduction of up to 20x. These results\nestablish concatenated codes as a promising approach for fault-tolerant quantum\ncomputing in the near future.", "AI": {"tldr": "The paper presents an efficient compilation method for many-hypercube codes using neutral atom arrays, significantly reducing overhead and enhancing practicality for fault-tolerant quantum computing.", "motivation": "Although concatenated codes offer high space efficiency, they face challenges with efficient implementation of logical gates and hardware limitations on parallelism and long-range interactions.", "method": "The authors propose two innovations: Automorphism-assisted Hierarchical Addressing (AHA) for efficient logical gates and Virtual Atom Intermediate Representation (VAIR) for optimization and legalization. These are integrated into ConiQ, a specialized quantum compiler for neutral atom arrays.", "result": "ConiQ achieves up to 2000x spacetime overhead reduction, up to 10^6x faster compilation times, and an additional 20x overhead reduction from AHA gates compared to current methods.", "conclusion": "The work demonstrates that concatenated codes, with the proposed methods, are highly effective for fault-tolerant quantum computing and pave the way for practical adoption in near-future quantum systems."}}
{"id": "2508.06047", "pdf": "https://arxiv.org/pdf/2508.06047", "abs": "https://arxiv.org/abs/2508.06047", "authors": ["Suresh Purini", "Siddhant Garg", "Mudit Gaur", "Sankalp Bhat", "Sohan Mupparapu", "Arun Ravindran"], "title": "ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis", "categories": ["cs.AR"], "comment": "Published in 7th ACM/IEEE International Symposium on Machine Learning\n  for CAD", "summary": "Modern SoC datapaths include deeply pipelined, domain-specific accelerators,\nbut their RTL implementation and verification are still mostly done by hand.\nWhile large language models (LLMs) exhibit advanced code-generation abilities\nfor programming languages like Python, their application to Verilog-like RTL\nremains in its nascent stage. This is reflected in the simple arithmetic and\ncontrol circuits currently used to evaluate generative capabilities in existing\nbenchmarks. In this paper, we introduce ArchXBench, a six-level benchmark suite\nthat encompasses complex arithmetic circuits and other advanced digital\nsubsystems drawn from domains such as cryptography, image processing, machine\nlearning, and signal processing. Architecturally, some of these designs are\npurely combinational, others are multi-cycle or pipelined, and many require\nhierarchical composition of modules. For each benchmark, we provide a problem\ndescription, design specification, and testbench, enabling rapid research in\nthe area of LLM-driven agentic approaches for complex digital systems design.\n  Using zero-shot prompting with Claude Sonnet 4, GPT 4.1, o4-mini-high, and\nDeepSeek R1 under a pass@5 criterion, we observed that o4-mini-high\nsuccessfully solves the largest number of benchmarks, 16 out of 30, spanning\nLevels 1, 2, and 3. From Level 4 onward, however, all models consistently fail,\nhighlighting a clear gap in the capabilities of current state-of-the-art LLMs\nand prompting/agentic approaches.", "AI": {"tldr": "The paper introduces ArchXBench, a benchmark suite designed to evaluate the capabilities of LLMs in generating complex digital subsystems for RTL design. Current models perform well on simple circuits but fail on advanced ones.", "motivation": "To address the limitations in applying LLMs for RTL design, particularly improving the automation of complex pipelined and hierarchical digital systems design.", "method": "The authors created ArchXBench, a benchmark suite with six levels of complexity, including circuit designs from cryptography, image processing, machine learning, and signal processing. They tested various LLMs using zero-shot prompting and evaluated performance using a pass@5 criterion.", "result": "The o4-mini-high model outperformed others, solving 16 out of 30 benchmarks from Levels 1-3. However, all models failed to solve Level 4 and above benchmarks.", "conclusion": "Current LLM capabilities are insufficient for addressing complex RTL designs, revealing a need for further research and development in this area."}}
{"id": "2508.06344", "pdf": "https://arxiv.org/pdf/2508.06344", "abs": "https://arxiv.org/abs/2508.06344", "authors": ["Robin Sehm", "Christian Ewert", "Rainer Buchty", "Mladen Berekovic", "Saleh Mulhem"], "title": "Nail: Not Another Fault-Injection Framework for Chisel-generated RTL", "categories": ["cs.AR"], "comment": "PREPRINT - accepted In Proceedings of the 28th Euromicro Conference\n  Series on Digital System Design (DSD)", "summary": "Fault simulation and emulation are essential techniques for evaluating the\ndependability of integrated circuits, enabling early-stage vulnerability\nanalysis and supporting the implementation of effective mitigation strategies.\nHigh-level hardware description languages such as Chisel facilitate the rapid\ndevelopment of complex fault scenarios with minimal modification to the design.\nHowever, existing Chisel-based fault injection (FI) frameworks are limited by\ncoarse-grained, instruction-level controllability, restricting the precision of\nfault modeling. This work introduces Nail, a Chisel-based open-source FI\nframework that overcomes these limitations by introducing state-based faults.\nThis approach enables fault scenarios that depend on specific system states,\nrather than solely on instruction-level triggers, thereby removing the need for\nprecise timing of fault activation. For greater controllability, Nail allows\nusers to arbitrarily modify internal trigger states via software at runtime. To\nsupport this, Nail automatically generates a software interface, offering\nstraightforward access to the instrumented design. This enables fine-tuning of\nfault parameters during active FI campaigns - a feature particularly beneficial\nfor FPGA emulation, where synthesis is time-consuming. Utilizing these\nfeatures, Nail narrows the gap between the high speed of emulation-based FI\nframeworks, the usability of software-based approaches, and the controllability\nachieved in simulation. We demonstrate Nail's state-based FI and software\nframework by modeling a faulty general-purpose register in a RISC-V processor.\nAlthough this might appear straightforward, it requires state-dependent FI and\nwas previously impossible without fundamental changes to the design. The\napproach was validated in both simulation and FPGA emulation, where the\naddition of Nail introduced less than 1% resource overhead.", "AI": {"tldr": "This paper presents Nail, a Chisel-based fault injection framework that provides state-based fault modeling for precise and controllable fault emulation and simulation.", "motivation": "Current Chisel-based fault injection frameworks are limited to coarse-grained, instruction-level fault modeling, reducing precision and usability in advanced applications.", "method": "Authors developed Nail, utilizing Chisel to enable state-based fault modeling and runtime modification of system triggers via an automated software interface for enhanced flexibility and precision.", "result": "Nail successfully models state-dependent faults, like a faulty register in a RISC-V processor, with validation in both simulation and FPGA emulation. It introduces less than 1% resource overhead.", "conclusion": "Nail bridges the gap between emulation speed and simulation controllability, offering improved fault modeling techniques for fault injection campaigns without significantly impacting resource usage."}}
{"id": "2508.05797", "pdf": "https://arxiv.org/pdf/2508.05797", "abs": "https://arxiv.org/abs/2508.05797", "authors": ["Sreeharsha Udayashankar", "Abdelrahman Baba", "Samer Al-Kiswany"], "title": "Accelerating Data Chunking in Deduplication Systems using Vector Instructions", "categories": ["cs.DC", "cs.AR"], "comment": "Under review. This is the follow-up work to our FAST 2025 paper,\n  \"VectorCDC: Accelerating Data Deduplication with Vector Instructions\". The\n  associated code is available at https://github.com/UWASL/dedup-bench", "summary": "Content-defined Chunking (CDC) algorithms dictate the overall space savings\nthat deduplication systems achieve. However, due to their need to scan each\nfile in its entirety, they are slow and often the main performance bottleneck\nwithin data deduplication. We present VectorCDC, a method to accelerate\nhashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our\nevaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs,\nachieving 8.35x - 26.2x higher throughput than existing vector-accelerated\ntechniques without affecting the deduplication space savings.", "AI": {"tldr": "VectorCDC uses vector CPU instructions to accelerate CDC in deduplication systems, achieving 8.35x-26.2x speedup.", "motivation": "Current Content-defined Chunking (CDC) algorithms are performance bottlenecks in data deduplication systems because they process entire files slowly.", "method": "Introduces VectorCDC, a method applying vector CPU instructions (like SSE/AVX) to accelerate hashless CDC algorithms.", "result": "Achieves 8.35x - 26.2x higher throughput compared to existing vector-accelerated techniques without compromising deduplication efficiency.", "conclusion": "VectorCDC effectively speeds up CDC algorithms without diminishing data deduplication space savings, making it broadly applicable across various CPU architectures."}}
{"id": "2508.05722", "pdf": "https://arxiv.org/pdf/2508.05722", "abs": "https://arxiv.org/abs/2508.05722", "authors": ["Rania Al-Sabbagh"], "title": "PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces PEACH, a sentence-aligned parallel English-Arabic\ncorpus of healthcare texts encompassing patient information leaflets and\neducational materials. The corpus contains 51,671 parallel sentences, totaling\napproximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths\nvary between 9.52 and 11.83 words on average. As a manually aligned corpus,\nPEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,\ntranslation studies, and natural language processing. It can be used to derive\nbilingual lexicons, adapt large language models for domain-specific machine\ntranslation, evaluate user perceptions of machine translation in healthcare,\nassess patient information leaflets and educational materials' readability and\nlay-friendliness, and as an educational resource in translation studies. PEACH\nis publicly accessible.", "AI": {"tldr": "The paper introduces PEACH, a publicly accessible, manually aligned English-Arabic healthcare text corpus.", "motivation": "To create a high-quality resource aiding linguistics, translation studies, and natural language processing in the healthcare domain.", "method": "Developed PEACH, a corpus with 51,671 parallel English-Arabic sentences manually aligned to ensure gold-standard quality.", "result": "The corpus consists of ~590,517 English and ~567,707 Arabic word tokens, with an average sentence length of 9.52\u201311.83 words.", "conclusion": "PEACH serves as a valuable tool for tasks like bilingual lexicon derivation, machine translation evaluation, and translation studies, and is made freely accessible."}}
{"id": "2508.05997", "pdf": "https://arxiv.org/pdf/2508.05997", "abs": "https://arxiv.org/abs/2508.05997", "authors": ["Aditi Kabra", "Jonathan Laurent", "Stefan Mitsch", "Andr\u00e9 Platzer"], "title": "Hybrid Game Control Envelope Synthesis", "categories": ["cs.PL", "cs.LO", "I.2.2; I.2.4"], "comment": null, "summary": "Control problems for embedded systems like cars and trains can be modeled by\ntwo-player hybrid games. Control envelopes, which are families of safe control\nsolutions, correspond to nondeterministic winning policies of hybrid games,\nwhere each deterministic specialization of the policy is a control solution.\nThis paper synthesizes nondeterministic winning policies for hybrid games that\nare as permissive as possible. It introduces subvalue maps, a compositional\nrepresentation of such policies that enables verification and synthesis along\nthe structure of the game. An inductive logical characterization in\ndifferential game logic (dGL) checks whether a subvalue map induces a sound\ncontrol envelope which always induces a winning play. A policy is said to win\nif it always achieves the desirable outcome when the player follows it, no\nmatter what actions the opponent plays. The maximal subvalue map, which allows\nthe most action options while still winning, is shown to exist and satisfy a\nlogical characterization. A family of algorithms for nondeterministic policy\nsynthesis can be obtained from the inductive subvalue map soundness\ncharacterization. An implementation of these findings is evaluated on examples\nthat use the expressivity of dGL to model a range of diverse control\nchallenges.", "AI": {"tldr": "This paper focuses on two-player hybrid games to address control problems in embedded systems such as cars and trains. It introduces a method to synthesize nondeterministic winning policies, enabling safety and flexibility in controlling these systems.", "motivation": "The motivation is to provide the safest and most flexible control solutions for embedded systems by leveraging nondeterministic winning strategies in hybrid games.", "method": "The paper uses subvalue maps to represent nondeterministic policies, verified and synthesized using differential game logic (dGL). A logical characterization checks if a policy is sound and winning.", "result": "The study shows that the maximal subvalue map exists, allowing for the most permissive winning strategies. Algorithms based on the subvalue map characterization were developed and demonstrated using dGL models.", "conclusion": "The findings provide a structured and verified approach to synthesize safe and flexible control policies for embedded systems, with promising results in diverse control challenges."}}
{"id": "2508.05731", "pdf": "https://arxiv.org/pdf/2508.05731", "abs": "https://arxiv.org/abs/2508.05731", "authors": ["Yuhang Liu", "Zeyu Liu", "Shuanghe Zhu", "Pengxiang Li", "Congkai Xie", "Jiasheng Wang", "Xueyu Hu", "Xiaotian Han", "Jianbo Yuan", "Xinyao Wang", "Shengyu Zhang", "Hongxia Yang", "Fei Wu"], "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "categories": ["cs.AI", "cs.CL"], "comment": "11 pages, 3 figures", "summary": "The emergence of Multimodal Large Language Models (MLLMs) has propelled the\ndevelopment of autonomous agents that operate on Graphical User Interfaces\n(GUIs) using pure visual input. A fundamental challenge is robustly grounding\nnatural language instructions. This requires a precise spatial alignment, which\naccurately locates the coordinates of each element, and, more critically, a\ncorrect semantic alignment, which matches the instructions to the functionally\nappropriate UI element. Although Reinforcement Learning with Verifiable Rewards\n(RLVR) has proven to be effective at improving spatial alignment for these\nMLLMs, we find that inefficient exploration bottlenecks semantic alignment,\nwhich prevent models from learning difficult semantic associations. To address\nthis exploration problem, we present Adaptive Exploration Policy Optimization\n(AEPO), a new policy optimization framework. AEPO employs a multi-answer\ngeneration strategy to enforce broader exploration, which is then guided by a\ntheoretically grounded Adaptive Exploration Reward (AER) function derived from\nfirst principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B\nand InfiGUI-G1-7B, establish new state-of-the-art results across multiple\nchallenging GUI grounding benchmarks, achieving significant relative\nimprovements of up to 9.0% against the naive RLVR baseline on benchmarks\ndesigned to test generalization and semantic understanding. Resources are\navailable at https://github.com/InfiXAI/InfiGUI-G1.", "AI": {"tldr": "The paper proposes Adaptive Exploration Policy Optimization (AEPO) to overcome inefficiencies in semantic alignment for Multimodal Large Language Models (MLLMs) operating on GUIs, achieving state-of-the-art results on benchmarks.", "motivation": "To address the challenge of robustly grounding natural language instructions in GUI-based MLLMs, where current models face issues with semantic alignment and inefficient exploration.", "method": "Introduces AEPO, a policy optimization framework with a multi-answer generation strategy and an Adaptive Exploration Reward (AER) function based on efficiency to enhance exploration and improve learning of semantic associations.", "result": "AEPO-trained models (InfiGUI-G1-3B and InfiGUI-G1-7B) significantly outperform the RLVR baseline, showing up to 9.0% improvement in GUI grounding benchmarks aimed at testing generalization and semantic understanding.", "conclusion": "AEPO effectively addresses exploration inefficiencies, establishing new state-of-the-art methods for GUI grounding tasks and advancing the semantic understanding capabilities of MLLMs."}}
{"id": "2508.05689", "pdf": "https://arxiv.org/pdf/2508.05689", "abs": "https://arxiv.org/abs/2508.05689", "authors": ["Jinjia Peng", "Zeze Tao", "Huibing Wang", "Meng Wang", "Yang Wang"], "title": "Boosting Adversarial Transferability via Residual Perturbation Attack", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "Accepted to ieee/cvf international conference on computer vision\n  (ICCV2025)", "summary": "Deep neural networks are susceptible to adversarial examples while suffering\nfrom incorrect predictions via imperceptible perturbations. Transfer-based\nattacks create adversarial examples for surrogate models and transfer these\nexamples to target models under black-box scenarios. Recent studies reveal that\nadversarial examples in flat loss landscapes exhibit superior transferability\nto alleviate overfitting on surrogate models. However, the prior arts overlook\nthe influence of perturbation directions, resulting in limited transferability.\nIn this paper, we propose a novel attack method, named Residual Perturbation\nAttack (ResPA), relying on the residual gradient as the perturbation direction\nto guide the adversarial examples toward the flat regions of the loss function.\nSpecifically, ResPA conducts an exponential moving average on the input\ngradients to obtain the first moment as the reference gradient, which\nencompasses the direction of historical gradients. Instead of heavily relying\non the local flatness that stems from the current gradients as the perturbation\ndirection, ResPA further considers the residual between the current gradient\nand the reference gradient to capture the changes in the global perturbation\ndirection. The experimental results demonstrate the better transferability of\nResPA than the existing typical transfer-based attack methods, while the\ntransferability can be further improved by combining ResPA with the current\ninput transformation methods. The code is available at\nhttps://github.com/ZezeTao/ResPA.", "AI": {"tldr": "Deep neural networks are vulnerable to adversarial examples, and this paper addresses improvements in their transferability using a novel Residual Perturbation Attack (ResPA).", "motivation": "The existing transfer-based attack methods focus insufficiently on perturbation directions, leading to limited efficacy in transferring adversarial examples.", "method": "ResPA uses residual gradients as perturbation directions obtained via exponential moving averages on historical gradients, making the adversarial examples align with flatter loss regions.", "result": "Experimental results show better adversarial transferability of ResPA compared to existing methods, and its effectiveness improves further when combined with input transformation techniques.", "conclusion": "ResPA enhances transfer-based attacks by targeting perturbation directions and flat loss landscapes, contributing to improved black-box attack success rates."}}
{"id": "2508.05693", "pdf": "https://arxiv.org/pdf/2508.05693", "abs": "https://arxiv.org/abs/2508.05693", "authors": ["Siamak Farshidi", "Amir Saberhabibi", "Behbod Eskafi", "Niloofar Nikfarjam", "Sadegh Eskandari", "Slinger Jansen", "Michel Chaudron", "Bedir Tekinerdogan"], "title": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Selecting third-party software packages in open-source ecosystems like Python\nis challenging due to the large number of alternatives and limited transparent\nevidence for comparison. Generative AI tools are increasingly used in\ndevelopment workflows, but their suggestions often overlook dependency\nevaluation, emphasize popularity over suitability, and lack reproducibility.\nThis creates risks for projects that require transparency, long-term\nreliability, maintainability, and informed architectural decisions. This study\nformulates software package selection as a Multi-Criteria Decision-Making\n(MCDM) problem and proposes a data-driven framework for technology evaluation.\nAutomated data pipelines continuously collect and integrate software metadata,\nusage trends, vulnerability information, and developer sentiment from GitHub,\nPyPI, and Stack Overflow. These data are structured into a decision model\nrepresenting relationships among packages, domain features, and quality\nattributes. The framework is implemented in PySelect, a decision support system\nthat uses large language models to interpret user intent and query the model to\nidentify contextually appropriate packages. The approach is evaluated using\n798,669 Python scripts from 16,887 GitHub repositories and a user study based\non the Technology Acceptance Model. Results show high data extraction\nprecision, improved recommendation quality over generative AI baselines, and\npositive user evaluations of usefulness and ease of use. This work introduces a\nscalable, interpretable, and reproducible framework that supports\nevidence-based software selection using MCDM principles, empirical data, and\nAI-assisted intent modeling.", "AI": {"tldr": "The paper proposes PySelect, a decision support system using MCDM principles and AI to support evidence-based selection of Python packages.", "motivation": "The motivation is to address challenges in choosing third-party Python packages due to numerous alternatives and limited comparison evidence, minimizing risks associated with dependency evaluation and emphasizing long-term reliability.", "method": "The method includes formulating package selection as an MCDM problem, collecting metadata and trends from platforms (GitHub, PyPI, Stack Overflow), and structuring these into a decision model utilized by PySelect, powered by large language models.", "result": "The study evaluated 798,669 Python scripts from 16,887 GitHub repositories, demonstrating high precision in data extraction, enhanced recommendation quality over AI baselines, and positive user feedback about usefulness and ease of use.", "conclusion": "The work presents a scalable, interpretable, and reproducible framework to aid software selection through empirical data and AI-assisted modeling, improving transparency and maintainability."}}
{"id": "2508.05659", "pdf": "https://arxiv.org/pdf/2508.05659", "abs": "https://arxiv.org/abs/2508.05659", "authors": ["Jeroen F. Uleman", "Loes Crielaard", "Leonie K. Elsenburg", "Guido A. Veldhuis", "Karien Stronks", "Naja Hulvej Rod", "Rick Quax", "V\u00edtor V. Vasconcelos"], "title": "Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "21 pages, 4 figures, 4 tables", "summary": "Causal loop diagrams (CLDs) are widely used in health and environmental\nresearch to represent hypothesized causal structures underlying complex\nproblems. However, as qualitative and static representations, CLDs are limited\nin their ability to support dynamic analysis and inform intervention\nstrategies. Additionally, quantitative CLD analysis methods like network\ncentrality analysis often lead to false inference. We propose\nDiagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory\nsystem dynamics models (SDMs) in the absence of empirical data. With minimal\nuser input - following a protocol to label variables as stocks,\nflows/auxiliaries, or constants - D2D leverages the structural information\nalready encoded in CLDs, namely, link existence and polarity, to simulate\nhypothetical interventions and explore potential leverage points under\nuncertainty. Results suggest that D2D helps distinguish between high- and\nlow-ranked leverage points. We compare D2D to a data-driven SDM constructed\nfrom the same CLD and variable labeling. D2D showed greater consistency with\nthe data-driven model than network centrality analysis, while providing\nuncertainty estimates and guidance for future data collection. The method is\nimplemented in an open-source Python package and a web-based application to\nsupport further testing and lower the barrier to dynamic modeling for\nresearchers working with CLDs. We expect additional validation will further\nestablish the approach's utility across a broad range of cases and domains.", "AI": {"tldr": "The paper introduces Diagrams-to-Dynamics (D2D), a method to convert causal loop diagrams (CLDs) into exploratory system dynamics models (SDMs), enabling dynamic analysis and simulation of interventions under uncertainty.", "motivation": "Causal loop diagrams (CLDs) are limited in dynamic analysis and intervention strategy development, and existing quantitative analysis methods like network centrality analysis often lead to false inferences.", "method": "D2D converts CLDs into exploratory SDMs with minimal user input by labeling variables as stocks, flows/auxiliaries, or constants. The method then leverages the structural information in CLDs to simulate hypothetical interventions and identify leverage points while accounting for uncertainty.", "result": "D2D distinguished high- and low-ranked leverage points, showed greater consistency with a data-driven SDM compared to network centrality analysis, and provided uncertainty estimates and data collection guidance.", "conclusion": "D2D lowers the barrier for dynamic modeling of CLDs through an open-source Python package and web application, supporting researchers in testing interventions and improving data-driven modeling practices."}}
{"id": "2508.05773", "pdf": "https://arxiv.org/pdf/2508.05773", "abs": "https://arxiv.org/abs/2508.05773", "authors": ["Keyvan Majd", "Hardik Parwana", "Bardh Hoxha", "Steven Hong", "Hideki Okamoto", "Georgios Fainekos"], "title": "GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted to IEEE ITSC 2025", "summary": "Articulated vehicles such as tractor-trailers, yard trucks, and similar\nplatforms must often reverse and maneuver in cluttered spaces where pedestrians\nare present. We present how Barrier-Rate guided Model Predictive Path Integral\n(BR-MPPI) control can solve navigation in such challenging environments.\nBR-MPPI embeds Control Barrier Function (CBF) constraints directly into the\npath-integral update. By steering the importance-sampling distribution toward\ncollision-free, dynamically feasible trajectories, BR-MPPI enhances the\nexploration strength of MPPI and improves robustness of resulting trajectories.\nThe method is evaluated in the high-fidelity CarMaker simulator on a 12 [m]\ntractor-trailer tasked with reverse and forward parking in a parking lot.\nBR-MPPI computes control inputs in above 100 [Hz] on a single GPU (for\nscenarios with eight obstacles) and maintains better parking clearance than a\nstandard MPPI baseline and an MPPI with collision cost baseline.", "AI": {"tldr": "The paper introduces a control method called Barrier-Rate guided Model Predictive Path Integral (BR-MPPI) for articulated vehicle navigation in cluttered environments, evaluated in a simulator for tractor-trailer parking scenarios.", "motivation": "The motivation is to address the challenge of maneuvering articulated vehicles like tractor-trailers in cluttered spaces with pedestrians, requiring safe and robust trajectory planning.", "method": "The method integrates Control Barrier Function (CBF) constraints into the MPPI framework, steering sampling toward safe and feasible trajectories while enhancing exploration strength.", "result": "The proposed BR-MPPI method outperformed standard MPPI and collision-cost baseline in a simulated tractor-trailer parking task, maintaining high computational efficiency at over 100 Hz.", "conclusion": "BR-MPPI is a robust and efficient control approach for articulated vehicle navigation in complex and constrained environments, demonstrating better safety and performance in collision avoidance."}}
{"id": "2508.06085", "pdf": "https://arxiv.org/pdf/2508.06085", "abs": "https://arxiv.org/abs/2508.06085", "authors": ["Genki Shimizu", "Taro Toyoizumi"], "title": "Diverse Neural Sequences in QIF Networks: An Analytically Tractable Framework for Synfire Chains and Hippocampal Replay", "categories": ["q-bio.NC", "cs.NE"], "comment": "Accepted to ICONIP 2025 (Oral). Version of Record will appear in\n  Springer LNCS; DOI to be added upon publication", "summary": "Sequential neural activity is fundamental to cognition, yet how diverse\nsequences are recalled under biological constraints remains a key question.\nExisting models often struggle to balance biophysical realism and analytical\ntractability. We address this problem by proposing a parsimonious network of\nQuadratic Integrate-and-Fire (QIF) neurons with sequences embedded via a\ntemporally asymmetric Hebbian (TAH) rule. Our findings demonstrate that this\nsingle framework robustly reproduces a spectrum of sequential activities,\nincluding persistent synfire-like chains and transient, hippocampal replay-like\nbursts exhibiting intra-ripple frequency accommodation (IFA), all achieved\nwithout requiring specialized delay or adaptation mechanisms. Crucially, we\nderive exact low-dimensional firing-rate equations (FREs) that provide\nmechanistic insight, elucidating the bifurcation structure governing these\ndistinct dynamical regimes and explaining their stability. The model also\nexhibits strong robustness to synaptic heterogeneity and memory pattern\noverlap. These results establish QIF networks with TAH connectivity as an\nanalytically tractable and biologically plausible platform for investigating\nthe emergence, stability, and diversity of sequential neural activity in the\nbrain.", "AI": {"tldr": "The paper introduces a QIF neural network model with a TAH learning rule to simulate diverse, biologically plausible sequential neural activities, offering analytical tractability and robustness.", "motivation": "Sequential neural activity is crucial for cognition, but understanding its recall under biological constraints remains challenging.", "method": "The authors propose a QIF neural network with sequences embedded via a temporally asymmetric Hebbian (TAH) learning rule and derive low-dimensional firing-rate equations to study its dynamics.", "result": "The model reproduces diverse sequential activities, from synfire-like chains to hippocampal replay-like bursts, and explains these dynamics using derived bifurcation structures. It also shows robustness to synaptic heterogeneity and pattern overlap.", "conclusion": "The proposed model serves as a biologically plausible and analytically tractable framework for studying sequential neural activity dynamics, stability, and diversity."}}
{"id": "2508.05663", "pdf": "https://arxiv.org/pdf/2508.05663", "abs": "https://arxiv.org/abs/2508.05663", "authors": ["Xingran Chen", "Parimal Parag", "Rohit Bhagat", "Zonghong Liu", "Salim El Rouayheb"], "title": "Random Walk Learning and the Pac-Man Attack", "categories": ["stat.ML", "cs.CR", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Random walk (RW)-based algorithms have long been popular in distributed\nsystems due to low overheads and scalability, with recent growing applications\nin decentralized learning. However, their reliance on local interactions makes\nthem inherently vulnerable to malicious behavior. In this work, we investigate\nan adversarial threat that we term the ``Pac-Man'' attack, in which a malicious\nnode probabilistically terminates any RW that visits it. This stealthy behavior\ngradually eliminates active RWs from the network, effectively halting the\nlearning process without triggering failure alarms. To counter this threat, we\npropose the Average Crossing (AC) algorithm--a fully decentralized mechanism\nfor duplicating RWs to prevent RW extinction in the presence of Pac-Man. Our\ntheoretical analysis establishes that (i) the RW population remains almost\nsurely bounded under AC and (ii) RW-based stochastic gradient descent remains\nconvergent under AC, even in the presence of Pac-Man, with a quantifiable\ndeviation from the true optimum. Our extensive empirical results on both\nsynthetic and real-world datasets corroborate our theoretical findings.\nFurthermore, they uncover a phase transition in the extinction probability as a\nfunction of the duplication threshold. We offer theoretical insights by\nanalyzing a simplified variant of the AC, which sheds light on the observed\nphase transition.", "AI": {"tldr": "This paper presents the \"Pac-Man\" attack on random walk-based decentralized learning and proposes the Average Crossing (AC) algorithm as a defense mechanism, ensuring robustness and convergence.", "motivation": "Random walk-based algorithms are efficient and scalable but are vulnerable to stealthy adversarial threats, such as malicious actions in decentralized learning systems.", "method": "The authors introduce the \"Pac-Man\" attack, a stealthy adversarial method that halts random walks in a network, and propose the Average Crossing (AC) algorithm to duplicate random walks and maintain robustness against such threats.", "result": "Theoretical analysis shows that the proposed AC algorithm keeps the random walk population bounded and ensures stochastic gradient descent convergence, even under adversarial attacks. Empirical results confirm these findings and demonstrate a phase transition behavior in extinction probability based on the duplication threshold.", "conclusion": "Average Crossing effectively counters the Pac-Man attack, preserving decentralized learning processes' robustness and efficiency. The work improves understanding of adversarial resistance mechanisms in distributed systems."}}
{"id": "2508.05786", "pdf": "https://arxiv.org/pdf/2508.05786", "abs": "https://arxiv.org/abs/2508.05786", "authors": ["Yang Li", "Luopeiwen Yi", "Tananun Songdechakraiwut"], "title": "Functional Connectivity Graph Neural Networks", "categories": ["cs.NE"], "comment": "26 pages, 5 figures, 24 tables", "summary": "Real-world networks often benefit from capturing both local and global\ninteractions. Inspired by multi-modal analysis in brain imaging, where\nstructural and functional connectivity offer complementary views of network\norganization, we propose a graph neural network framework that generalizes this\napproach to other domains. Our method introduces a functional connectivity\nblock based on persistent graph homology to capture global topological\nfeatures. Combined with structural information, this forms a multi-modal\narchitecture called Functional Connectivity Graph Neural Networks. Experiments\nshow consistent performance gains over existing methods, demonstrating the\nvalue of brain-inspired representations for graph-level classification across\ndiverse networks.", "AI": {"tldr": "The paper introduces Functional Connectivity Graph Neural Networks, a brain-inspired framework leveraging global topological and structural features for graph-level classification, achieving better performance than existing methods.", "motivation": "The motivation is to improve graph-level classification by capturing both local and global interactions, as seen in brain imaging where functional and structural connectivity are complementary.", "method": "The method combines a functional connectivity block using persistent graph homology with structural features, creating a multi-modal graph neural network architecture.", "result": "Experiments confirm consistent performance improvements over existing approaches for graph-level classification in various networks.", "conclusion": "The proposed framework benefits from brain-inspired representations and proves effective for diverse graph-level classification tasks."}}
{"id": "2508.05821", "pdf": "https://arxiv.org/pdf/2508.05821", "abs": "https://arxiv.org/abs/2508.05821", "authors": ["Shadman Sakib", "Ajay Katangur", "Rahul Dubey"], "title": "A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization", "categories": ["cs.DC"], "comment": "Accepted for publication in 2025 IEEE Cloud Summit", "summary": "Cloud computing has grown rapidly in recent years, mainly due to the sharp\nincrease in data transferred over the internet. This growth makes load\nbalancing a key part of cloud systems, as it helps distribute user requests\nacross servers to maintain performance, prevent overload, and ensure a smooth\nuser experience. Despite its importance, managing server resources and keeping\nworkloads balanced over time remains a major challenge in cloud environments.\nThis paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that\nallocates workloads to virtual machines based on real-time performance metrics.\nThe objective is to enhance resource utilization and overall system efficiency.\nThe method was thoroughly tested using the CloudSim 7G platform, comparing its\nperformance against the throttled load balancing strategy. Evaluations were\nconducted across a variety of workloads and scenarios, demonstrating the\nSBDLB's ability to adapt dynamically to workload fluctuations while optimizing\nresource usage. The proposed method outperformed the throttled strategy,\nimproving average response times by 34% and 37% in different scenarios. It also\nreduced data center processing times by an average of 13%. Over a 24-hour\nsimulation, the method decreased operational costs by 15%, promoting a more\nenergy-efficient and sustainable cloud infrastructure through reduced energy\nconsumption.", "AI": {"tldr": "The paper presents a Score-Based Dynamic Load Balancer (SBDLB) for cloud systems, improving resource utilization, response times, and energy efficiency.", "motivation": "With the rapid growth in cloud computing, efficient load balancing is needed to maintain system performance and prevent server overload.", "method": "A Score-Based Dynamic Load Balancer (SBDLB) was introduced, which allocates workloads to virtual machines using real-time performance metrics, tested with CloudSim 7G against a throttled strategy.", "result": "SBDLB improved average response times by up to 37%, reduced processing times by 13%, and decreased operational costs by 15%.", "conclusion": "SBDLB enhances resource utilization and optimizes energy consumption, making cloud systems more efficient and sustainable."}}
{"id": "2508.05775", "pdf": "https://arxiv.org/pdf/2508.05775", "abs": "https://arxiv.org/abs/2508.05775", "authors": ["Chi Zhang", "Changjia Zhu", "Junjie Xiong", "Xiaoran Xu", "Lingyao Li", "Yao Liu", "Zhuo Lu"], "title": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) have revolutionized content creation across\ndigital platforms, offering unprecedented capabilities in natural language\ngeneration and understanding. These models enable beneficial applications such\nas content generation, question and answering (Q&A), programming, and code\nreasoning. Meanwhile, they also pose serious risks by inadvertently or\nintentionally producing toxic, offensive, or biased content. This dual role of\nLLMs, both as powerful tools for solving real-world problems and as potential\nsources of harmful language, presents a pressing sociotechnical challenge. In\nthis survey, we systematically review recent studies spanning unintentional\ntoxicity, adversarial jailbreaking attacks, and content moderation techniques.\nWe propose a unified taxonomy of LLM-related harms and defenses, analyze\nemerging multimodal and LLM-assisted jailbreak strategies, and assess\nmitigation efforts, including reinforcement learning with human feedback\n(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the\nevolving landscape of LLM safety, identifies limitations in current evaluation\nmethodologies, and outlines future research directions to guide the development\nof robust and ethically aligned language technologies.", "AI": {"tldr": "This survey examines the dual nature of Large Language Models (LLMs) as both beneficial tools and potential risks, exploring toxicity, adversarial attacks, and mitigation strategies.", "motivation": "The paper aims to address the sociotechnical challenges posed by LLMs' capability to produce both beneficial applications and harmful language.", "method": "The approach involves a systematic review of studies related to toxicity, adversarial jailbreaking attacks, and content moderation, proposing a taxonomy of harms and defenses.", "result": "The survey identifies evolving multimodal and LLM-assisted jailbreak strategies. It also evaluates mitigation techniques like RLHF, prompt engineering, and safety alignment.", "conclusion": "The paper highlights the limitations in current evaluation methodologies and suggests future research directions to improve LLM safety and ethical alignment."}}
{"id": "2508.05766", "pdf": "https://arxiv.org/pdf/2508.05766", "abs": "https://arxiv.org/abs/2508.05766", "authors": ["Bo Wen"], "title": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "nlin.AO"], "comment": null, "summary": "This paper proposes a novel framework for developing safe Artificial General\nIntelligence (AGI) by combining Active Inference principles with Large Language\nModels (LLMs). We argue that traditional approaches to AI safety, focused on\npost-hoc interpretability and reward engineering, have fundamental limitations.\nWe present an architecture where safety guarantees are integrated into the\nsystem's core design through transparent belief representations and\nhierarchical value alignment. Our framework leverages natural language as a\nmedium for representing and manipulating beliefs, enabling direct human\noversight while maintaining computational tractability. The architecture\nimplements a multi-agent system where agents self-organize according to Active\nInference principles, with preferences and safety constraints flowing through\nhierarchical Markov blankets. We outline specific mechanisms for ensuring\nsafety, including: (1) explicit separation of beliefs and preferences in\nnatural language, (2) bounded rationality through resource-aware free energy\nminimization, and (3) compositional safety through modular agent structures.\nThe paper concludes with a research agenda centered on the Abstraction and\nReasoning Corpus (ARC) benchmark, proposing experiments to validate our\nframework's safety properties. Our approach offers a path toward AGI\ndevelopment that is inherently safer, rather than retrofitted with safety\nmeasures.", "AI": {"tldr": "This paper introduces a framework for safer Artificial General Intelligence (AGI) using Active Inference principles combined with Large Language Models (LLMs).", "motivation": "The authors aim to address the limitations of traditional AI safety measures based on post-hoc interpretability and reward engineering by proposing a more integrated approach.", "method": "The framework integrates safety through transparent belief representations, hierarchical value alignment, and multi-agent systems guided by Active Inference principles. It employs the natural language for oversight and includes safety mechanisms like belief-preference separation, resource-aware decision-making, and modular agent structures.", "result": "The framework is proposed to ensure safety guarantees within AGI development and is validated through experiments using the Abstraction and Reasoning Corpus (ARC) benchmark.", "conclusion": "The study suggests that AGI can be developed to be inherently safe by embedding safety principles into its core design rather than retrofitting them later."}}
{"id": "2508.05732", "pdf": "https://arxiv.org/pdf/2508.05732", "abs": "https://arxiv.org/abs/2508.05732", "authors": ["Pinxuan Li", "Bing Cao", "Changqing Zhang", "Qinghua Hu"], "title": "Generalized Few-Shot Out-of-Distribution Detection", "categories": ["cs.CV"], "comment": null, "summary": "Few-shot Out-of-Distribution (OOD) detection has emerged as a critical\nresearch direction in machine learning for practical deployment. Most existing\nFew-shot OOD detection methods suffer from insufficient generalization\ncapability for the open world. Due to the few-shot learning paradigm, the OOD\ndetection ability is often overfit to the limited training data itself, thus\ndegrading the performance on generalized data and performing inconsistently\nacross different scenarios. To address this challenge, we proposed a\nGeneralized Few-shot OOD Detection (GOOD) framework, which empowers the general\nknowledge of the OOD detection model with an auxiliary General Knowledge Model\n(GKM), instead of directly learning from few-shot data. We proceed to reveal\nthe few-shot OOD detection from a generalization perspective and theoretically\nderive the Generality-Specificity balance (GS-balance) for OOD detection, which\nprovably reduces the upper bound of generalization error with a general\nknowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE)\nmechanism to adaptively modulate the guidance of general knowledge. KDE\ndynamically aligns the output distributions of the OOD detection model to the\ngeneral knowledge model based on the Generalized Belief (G-Belief) of GKM,\nthereby boosting the GS-balance. Experiments on real-world OOD benchmarks\ndemonstrate our superiority. Codes will be available.", "AI": {"tldr": "This paper introduces a Generalized Few-shot OOD Detection (GOOD) framework using auxiliary general knowledge models to overcome generalization limitations in few-shot OOD detection.", "motivation": "Although few-shot OOD detection is important for practical use, existing methods struggle with generalization, overfitting to limited training data and inconsistent performance across scenarios.", "method": "The authors propose a framework called GOOD that leverages a General Knowledge Model (GKM) to introduce general knowledge beyond the few-shot data, and develops a Knowledge Dynamic Embedding (KDE) mechanism to modulate this knowledge adaptively.", "result": "The GOOD framework successfully improves generalization in few-shot OOD detection, reducing errors and achieving superior performance in practical OOD benchmarks.", "conclusion": "The proposed approach effectively addresses generalization challenges in few-shot OOD detection by using a general knowledge model and adaptive embedding, setting a new direction for improved performance."}}
{"id": "2508.05710", "pdf": "https://arxiv.org/pdf/2508.05710", "abs": "https://arxiv.org/abs/2508.05710", "authors": ["Jia Fu", "Xinyu Yang", "Hongzhi Zhang", "Yahui Liu", "Jingyuan Zhang", "Qi Wang", "Fuzheng Zhang", "Guorui Zhou"], "title": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning", "categories": ["cs.SE", "cs.AI"], "comment": "21 pages, 11 figures", "summary": "Precise, correct feedback is crucial for effectively training large language\nmodels (LLMs) in code reinforcement learning. However, synthesizing\nhigh-quality test cases remains a profoundly challenging and unsolved problem.\nIn this work, we present Klear-CodeTest, a comprehensive test case synthesis\nframework featuring rigorous verification to ensure quality and reliability of\ntest cases. Our approach achieves broad coverage of programming problems via a\nnovel Generator-Validation (G-V) framework, ensuring correctness through a\nconsistency validation mechanism that verifies outputs against gold solutions.\nThe proposed G-V framework generates comprehensive test cases including both\nregular and corner cases, enhancing test coverage and discriminative power for\nsolution correctness assessment in code reinforcement learning. In addition, we\ndesign a multi-layered security sandbox system optimized for online\nverification platforms, guaranteeing safe and reliable code execution. Through\ncomprehensive experiments, we demonstrate the effectiveness of our curated\ndataset, showing significant improvements in model performance and training\nstability. The source codes, curated dataset and sandbox system are available\nat: https://github.com/Kwai-Klear/CodeTest.", "AI": {"tldr": "Klear-CodeTest proposes a robust test case synthesis framework to improve feedback for training LLMs in code reinforcement learning, including a validation mechanism and security sandbox.", "motivation": "High-quality feedback for large language models in code reinforcement learning is hampered by the challenge of synthesizing reliable test cases.", "method": "Introduces a Generator-Validation (G-V) framework to create comprehensive test cases, along with a secure, multi-layered sandbox system for safe execution.", "result": "Showed enhanced model performance and stability through experiments using the curated dataset and validation mechanisms.", "conclusion": "The framework provides better test coverage, ensures correctness, and improves LLM training for code tasks. Source code and dataset are publicly available."}}
{"id": "2508.05724", "pdf": "https://arxiv.org/pdf/2508.05724", "abs": "https://arxiv.org/abs/2508.05724", "authors": ["Massimiliano Romiti"], "title": "A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics", "categories": ["cs.LG", "physics.data-an", "68T07, 81-08, 05C90", "I.2.6; G.2.2; I.5.1"], "comment": "14 pages, 9 figures", "summary": "This work introduces a novel framework for representing and analyzing\nphysical laws as a weighted knowledge graph. We constructed a database of 659\ndistinct physical equations, subjected to rigorous semantic cleaning to resolve\nnotational ambiguities, resulting in a corpus of 400 advanced physics\nequations. We developed an enhanced graph representation where both physical\nconcepts and equations are nodes, connected by weighted inter-equation bridges.\nThese weights are objectively defined using normalized metrics for variable\noverlap, physics-informed importance scores, and bibliometric data. A Graph\nAttention Network (GAT) was trained for link prediction, achieving a test AUC\nof 0.9742 +/- 0.0018 across five independent runs, significantly outperforming\nboth classical heuristics (best baseline AUC: 0.9487) and established GNN\narchitectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing\nconfirmed significance of all comparisons (p < 0.05), with 2.7% improvement\nover the best baseline. Our analysis reveals three key findings: (i) The model\nautonomously rediscovers the known macroscopic structure of physics,\nidentifying strong conceptual axes between Electromagnetism and Statistical\nMechanics. (ii) It identifies central hub equations that serve as critical\nbridges between multiple physical domains. (iii) The model generates stable,\ncomputationally-derived hypotheses for cross-domain relationships, identifying\nboth known principles and suggesting novel mathematical analogies for further\ntheoretical investigation. The framework can generate hundreds of such\nhypotheses, enabling the creation of specialized datasets for targeted analysis\nof specific physics subfields. Code and data available at\nhttps://github.com/kingelanci/graphysics", "AI": {"tldr": "The paper introduces a knowledge graph framework for physical laws, leveraging 400 cleaned physics equations and a Graph Attention Network (GAT) model for link prediction. Results significantly outperform baselines, revealing insights into physics interconnections.", "motivation": "The motivation was to better understand and systematize the structure of physical laws using graph-based approaches to bridge gaps between various physical domains and enable hypothesis generation.", "method": "The authors created a weighted knowledge graph from 400 cleaned physics equations, defined weights for connections based on normalized metrics, and used a GAT model for link prediction, comparing with classical and other GNN methods.", "result": "The GAT model achieved superior link prediction test AUC (0.9742), outperforming baselines and other architectures. It uncovered conceptual connections, critical hub equations, and provided testable hypotheses.", "conclusion": "The framework proved effective in analyzing physics concepts and domains, generating new cross-domain hypotheses, and offering datasets for further specialized analysis. It demonstrates potential for innovative theoretical discoveries."}}
{"id": "2508.05838", "pdf": "https://arxiv.org/pdf/2508.05838", "abs": "https://arxiv.org/abs/2508.05838", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY", "68T07, 68T40, 90C40, 93E35", "I.2.6; I.2.9; I.2.10"], "comment": "Published in the Proceedings of the 2025 3rd International Conference\n  on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 figures, 1\n  table", "summary": "This paper presents a novel approach that integrates vision foundation models\nwith reinforcement learning to enhance object interaction capabilities in\nsimulated environments. By combining the Segment Anything Model (SAM) and\nYOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the\nAI2-THOR simulation environment, we enable the agent to perceive and interact\nwith objects more effectively. Our comprehensive experiments, conducted across\nfour diverse indoor kitchen settings, demonstrate significant improvements in\nobject interaction success rates and navigation efficiency compared to a\nbaseline agent without advanced perception. The results show a 68% increase in\naverage cumulative reward, a 52.5% improvement in object interaction success\nrate, and a 33% increase in navigation efficiency. These findings highlight the\npotential of integrating foundation models with reinforcement learning for\ncomplex robotic tasks, paving the way for more sophisticated and capable\nautonomous agents.", "AI": {"tldr": "The paper combines vision foundation models like SAM and YOLOv5 with reinforcement learning (PPO) to improve robotic object interaction and navigation in simulated environments, achieving significant performance gains.", "motivation": "To improve object interaction and navigation efficiency for reinforcement learning agents in simulated environments by leveraging advanced foundation models.", "method": "The approach integrates the Segment Anything Model (SAM) and YOLOv5 with a Proximal Policy Optimization (PPO) reinforcement learning agent in the AI2-THOR simulation environment. Comprehensive experiments are conducted in four indoor kitchen settings.", "result": "The combined method shows a 68% rise in average cumulative reward, a 52.5% improvement in object interaction success rate, and a 33% increase in navigation efficiency over a baseline approach.", "conclusion": "Integrating foundation models with reinforcement learning enhances robotic perception and capability in simulated environments, offering a foundation for more sophisticated autonomous agents."}}
{"id": "2508.06118", "pdf": "https://arxiv.org/pdf/2508.06118", "abs": "https://arxiv.org/abs/2508.06118", "authors": ["Daniil Vlasenko", "Vadim Ushakov", "Alexey Zaikin", "Denis Zakharov"], "title": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Understanding and classifying human cognitive brain states based on\nneuroimaging data remains one of the foremost and most challenging problems in\nneuroscience, owing to the high dimensionality and intrinsic noise of the\nsignals. In this work, we propose an ensemble-based graph representation method\nof functional magnetic resonance imaging (fMRI) data for the task of binary\nbrain-state classification. Our method builds the graph by leveraging multiple\nbase machine-learning models: each edge weight reflects the difference in\nposterior probabilities between two cognitive states, yielding values in the\nrange [-1, 1] that encode confidence in a given state. We applied this approach\nto seven cognitive tasks from the Human Connectome Project (HCP 1200 Subject\nRelease), including working memory, gambling, motor activity, language, social\ncognition, relational processing, and emotion processing. Using only the mean\nincident edge weights of the graphs as features, a simple logistic-regression\nclassifier achieved average accuracies from 97.07% to 99.74%. We also compared\nour ensemble graphs with classical correlation-based graphs in a classification\ntask with a graph neural network (GNN). In all experiments, the highest\nclassification accuracy was obtained with ensemble graphs. These results\ndemonstrate that ensemble graphs convey richer topological information and\nenhance brain-state discrimination. Our approach preserves edge-level\ninterpretability of the fMRI graph representation, is adaptable to multiclass\nand regression tasks, and can be extended to other neuroimaging modalities and\npathological-state classification.", "AI": {"tldr": "The paper presents an ensemble-based graph representation method for fMRI data, achieving high classification accuracy in distinguishing cognitive brain states.", "motivation": "The work aims to address the challenge of classifying human cognitive brain states from high-dimensional and noisy neuroimaging data.", "method": "The method involves creating ensemble-based graphs where edge weights represent the difference in posterior probabilities between cognitive states, and using these graphs for classification tasks.", "result": "The approach achieved an average accuracy between 97.07% and 99.74% across seven cognitive tasks, outperforming correlation-based graphs in all experiments.", "conclusion": "Ensemble-based graphs improved classification accuracy and preserved interpretability, showcasing their utility in brain-state discrimination and potential for broader applications."}}
{"id": "2508.05715", "pdf": "https://arxiv.org/pdf/2508.05715", "abs": "https://arxiv.org/abs/2508.05715", "authors": ["Johannes Piller", "L\u00e9a Orsini", "Simon Wiegrebe", "John Zobolas", "Lukas Burk", "Sophie Hanna Langbein", "Philip Studener", "Markus Goeswein", "Andreas Bender"], "title": "Reduction Techniques for Survival Analysis", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we discuss what we refer to as reduction techniques for\nsurvival analysis, that is, techniques that \"reduce\" a survival task to a more\ncommon regression or classification task, without ignoring the specifics of\nsurvival data. Such techniques particularly facilitate machine learning-based\nsurvival analysis, as they allow for applying standard tools from machine and\ndeep learning to many survival tasks without requiring custom learners. We\nprovide an overview of different reduction techniques and discuss their\nrespective strengths and weaknesses. We also provide a principled\nimplementation of some of these reductions, such that they are directly\navailable within standard machine learning workflows. We illustrate each\nreduction using dedicated examples and perform a benchmark analysis that\ncompares their predictive performance to established machine learning methods\nfor survival analysis.", "AI": {"tldr": "This paper explores methods to simplify survival analysis by converting it into a regression or classification task, enabling the use of standard machine learning tools.", "motivation": "The authors aim to address challenges in survival analysis by leveraging common approaches from regression or classification, making it easier to use machine learning and deep learning methods for such tasks.", "method": "The paper discusses various reduction techniques that allow survival analysis tasks to be expressed as regression or classification problems, detailing strengths, weaknesses, examples, and offering a benchmark comparison of their predictive performance.", "result": "The benchmark results show how the reduction techniques can compare to established machine learning methods for survival analysis, providing insights into their predictiveness and applicability.", "conclusion": "Reduction techniques simplify survival analysis by enabling the use of conventional machine learning tools, demonstrating their practical advantages and effectiveness through examples and benchmarks."}}
{"id": "2508.06389", "pdf": "https://arxiv.org/pdf/2508.06389", "abs": "https://arxiv.org/abs/2508.06389", "authors": ["James Stovold"], "title": "Identity Increases Stability in Neural Cellular Automata", "categories": ["cs.NE", "cs.AI"], "comment": "Accepted to ALIFE 2025", "summary": "Neural Cellular Automata (NCAs) offer a way to study the growth of\ntwo-dimensional artificial organisms from a single seed cell. From the outset,\nNCA-grown organisms have had issues with stability, their natural boundary\noften breaking down and exhibiting tumour-like growth or failing to maintain\nthe expected shape. In this paper, we present a method for improving the\nstability of NCA-grown organisms by introducing an 'identity' layer with simple\nconstraints during training.\n  Results show that NCAs grown in close proximity are more stable compared with\nthe original NCA model. Moreover, only a single identity value is required to\nachieve this increase in stability. We observe emergent movement from the\nstable organisms, with increasing prevalence for models with multiple identity\nvalues.\n  This work lays the foundation for further study of the interaction between\nNCA-grown organisms, paving the way for studying social interaction at a\ncellular level in artificial organisms.", "AI": {"tldr": "This paper introduces an 'identity' layer to Neural Cellular Automata (NCAs) to improve organism stability and foster emergent behaviors.", "motivation": "NCA-grown organisms face challenges like boundary breakdowns and tumor-like growth. The study aims to stabilize these artificial organisms.", "method": "An 'identity' layer with constraints is included during training to enhance organism stability.", "result": "NCAs grown nearby exhibit enhanced stability, require only one identity value for this improvement, and show emergent movement patterns.", "conclusion": "The method improves NCA-grown organism stability and opens avenues for studying cellular-level social interactions in artificial systems."}}
{"id": "2508.05904", "pdf": "https://arxiv.org/pdf/2508.05904", "abs": "https://arxiv.org/abs/2508.05904", "authors": ["Brandon Baker", "Elliott Brossard", "Chenwei Xie", "Zihao Ye", "Deen Liu", "Yijun Xie", "Arthur Zwiegincew", "Nitya Kumar Sharma", "Gaurav Jain", "Eugene Retunsky", "Mike Halcrow", "Derek Denny-Brown", "Istvan Cseri", "Tyler Akidau", "Yuxiong He"], "title": "Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data", "categories": ["cs.DC", "cs.DB"], "comment": "12 pages, 6 figures, accepted in ICDCS 2025", "summary": "Snowflake revolutionized data analytics with an elastic architecture that\ndecouples compute and storage, enabling scalable solutions supporting data\narchitectures like data lake, data warehouse, data lakehouse, and data mesh.\nBuilding on this foundation, Snowflake has advanced its AI Data Cloud vision by\nintroducing Snowpark, a managed turnkey solution that supports data engineering\nand AI and ML workloads using Python and other programming languages.\n  This paper outlines Snowpark's design objectives towards high performance,\nstrong security and governance, and ease of use. We detail the architecture of\nSnowpark, highlighting its elastic scalability and seamless integration with\nSnowflake core compute infrastructure. This includes leveraging Snowflake\ncontrol plane for distributed computing and employing a secure sandbox for\nisolating Snowflake SQL workloads from Snowpark executions. Additionally, we\npresent core innovations in Snowpark that drive further performance\nenhancements, such as query initialization latency reduction through Python\npackage caching, improved workload scheduling for customized workloads, and\ndata skew management via efficient row redistribution. Finally, we showcase\nreal-world case studies that illustrate Snowpark's efficiency and effectiveness\nfor large-scale data engineering and AI and ML tasks.", "AI": {"tldr": "This paper discusses Snowpark, a Snowflake solution enhancing AI and ML workflows by leveraging elastic scalability, secure execution, and integration with Snowflake's core infrastructure.", "motivation": "To extend Snowflake's capabilities to support efficient and secure data engineering, AI, and ML workflows at scale.", "method": "Snowpark employs features like Python package caching, improved workload scheduling, and data skew management while utilizing Snowflake's control plane and secure sandboxes to integrate into its computation infrastructure.", "result": "The platform reduced query latency, enhanced workload customizability, and illustrated real-world success in large-scale AI, ML, and data engineering tasks.", "conclusion": "Snowpark is an effective extension of Snowflake for supporting versatile and performance-oriented data, AI, and ML workloads in a scalable and secure manner."}}
{"id": "2508.05782", "pdf": "https://arxiv.org/pdf/2508.05782", "abs": "https://arxiv.org/abs/2508.05782", "authors": ["Xiangyan Chen", "Yufeng Li", "Yujian Gan", "Arkaitz Zubiaga", "Matthew Purver"], "title": "FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are known to produce hallucinations - factually\nincorrect or fabricated information - which poses significant challenges for\nmany Natural Language Processing (NLP) applications, such as dialogue systems.\nAs a result, detecting hallucinations has become a critical area of research.\nCurrent approaches to hallucination detection in dialogue systems primarily\nfocus on verifying the factual consistency of generated responses. However,\nthese responses often contain a mix of accurate, inaccurate or unverifiable\nfacts, making one factual label overly simplistic and coarse-grained. In this\npaper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact\nverification, which involves verifying atomic facts extracted from dialogue\nresponses. To support this, we construct a dataset based on publicly available\ndialogue datasets and evaluate it using various baseline methods. Experimental\nresults demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning\ncan enhance performance in dialogue fact verification. Despite this, the best\nF1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is\nonly 0.75, indicating that the benchmark remains a challenging task for future\nresearch. Our dataset and code will be public on GitHub.", "AI": {"tldr": "The paper introduces FineDialFact, a benchmark for fine-grained fact verification in dialogue systems, with Chain-of-Thought reasoning improving but not solving the problem.", "motivation": "Detecting hallucinations in dialogue systems is critical as they often mix accurate, inaccurate, or unverifiable facts, making current single-label factual verification approaches insufficient.", "method": "The authors create the FineDialFact benchmark and dataset for fine-grained fact verification in dialogue systems, using publicly available data and testing baseline methods, including Chain-of-Thought reasoning.", "result": "Experiments show that Chain-of-Thought reasoning improves performance, but the best F1-score on HybriDialogue was 0.75, revealing the task remains challenging.", "conclusion": "FineDialFact is a significant step towards improving fact verification in dialogue systems, but there is a lot of room for future advancements."}}
{"id": "2508.05776", "pdf": "https://arxiv.org/pdf/2508.05776", "abs": "https://arxiv.org/abs/2508.05776", "authors": ["Thomas L. Griffiths", "Brenden M. Lake", "R. Thomas McCoy", "Ellie Pavlick", "Taylor W. Webb"], "title": "Whither symbols in the era of advanced neural networks?", "categories": ["cs.AI"], "comment": null, "summary": "Some of the strongest evidence that human minds should be thought about in\nterms of symbolic systems has been the way they combine ideas, produce novelty,\nand learn quickly. We argue that modern neural networks -- and the artificial\nintelligence systems built upon them -- exhibit similar abilities. This\nundermines the argument that the cognitive processes and representations used\nby human minds are symbolic, although the fact that these neural networks are\ntypically trained on data generated by symbolic systems illustrates that such\nsystems play an important role in characterizing the abstract problems that\nhuman minds have to solve. This argument leads us to offer a new agenda for\nresearch on the symbolic basis of human thought.", "AI": {"tldr": "The paper challenges the notion that human minds operate purely symbolically and argues that modern neural networks share similar cognitive capabilities.", "motivation": "To re-evaluate the symbolic foundation of human cognition in light of the capabilities of modern neural networks.", "method": "Comparatively analyzing the traits, functionality, and learning capabilities of neural networks versus symbolic systems.", "result": "Modern neural networks show abilities akin to symbolic combinations, novelty, and quick learning traditionally attributed to human cognition.", "conclusion": "Symbolic systems remain important for framing problems human minds solve, but a new research agenda is needed to understand symbolic aspects of cognition in light of neural networks."}}
{"id": "2508.05755", "pdf": "https://arxiv.org/pdf/2508.05755", "abs": "https://arxiv.org/abs/2508.05755", "authors": ["Agnieszka Polowczyk", "Alicja Polowczyk", "Dawid Malarz", "Artur Kasymov", "Marcin Mazur", "Jacek Tabor", "Przemys\u0142aw Spurek"], "title": "UnGuide: Learning to Forget with LoRA-Guided Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in large-scale text-to-image diffusion models have heightened\nconcerns about their potential misuse, especially in generating harmful or\nmisleading content. This underscores the urgent need for effective machine\nunlearning, i.e., removing specific knowledge or concepts from pretrained\nmodels without compromising overall performance. One possible approach is\nLow-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models\nfor targeted unlearning. However, LoRA often inadvertently alters unrelated\ncontent, leading to diminished image fidelity and realism. To address this\nlimitation, we introduce UnGuide -- a novel approach which incorporates\nUnGuidance, a dynamic inference mechanism that leverages Classifier-Free\nGuidance (CFG) to exert precise control over the unlearning process. UnGuide\nmodulates the guidance scale based on the stability of a few first steps of\ndenoising processes, enabling selective unlearning by LoRA adapter. For prompts\ncontaining the erased concept, the LoRA module predominates and is\ncounterbalanced by the base model; for unrelated prompts, the base model\ngoverns generation, preserving content fidelity. Empirical results demonstrate\nthat UnGuide achieves controlled concept removal and retains the expressive\npower of diffusion models, outperforming existing LoRA-based methods in both\nobject erasure and explicit content removal tasks.", "AI": {"tldr": "The authors propose UnGuide, a method to improve machine unlearning in text-to-image diffusion models while maintaining overall performance.", "motivation": "The paper seeks to address concerns about the misuse of large-scale text-to-image diffusion models for harmful or misleading content, emphasizing the need for precise unlearning without degrading model functionality.", "method": "The authors develop UnGuide, a mechanism that integrates UnGuidance with Classifier-Free Guidance (CFG) to selectively modulate learning via a LoRA adapter. It dynamically adjusts guidance scales during early denoising steps to ensure controlled unlearning while preserving content fidelity.", "result": "UnGuide outperforms existing LoRA solutions in tasks like object erasure and explicit content removal, providing higher fidelity and realism in unrelated image prompts.", "conclusion": "UnGuide effectively balances the removal of undesired concepts while preserving the expressive power of diffusion models, presenting a significant improvement over previous approaches."}}
{"id": "2508.05747", "pdf": "https://arxiv.org/pdf/2508.05747", "abs": "https://arxiv.org/abs/2508.05747", "authors": ["Rohaizah Abdul Wahid", "Muhamad Said Nizamuddin Nadim", "Suliana Sulaiman", "Syahmi Akmal Shaharudin", "Muhammad Danial Jupikil", "Iqqwan Jasman Su Azlan Su"], "title": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework", "categories": ["cs.SE", "cs.ET"], "comment": null, "summary": "Laravel has emerged as a foundational framework in university web development\ncurricula. However, despite its scaffolding capabilities, students often\nstruggle to complete projects within limited academic timelines. This\nconceptual paper introduces Composer, PHP's standard dependency manager, and\ncategorizes a curated selection of Composer packages that significantly reduce\ndevelopment effort while fostering professional software practices. Grounded in\npractical and pedagogical considerations, the paper illustrates how educators\nand learners can strategically leverage these tools to build typical academic\nor personal Laravel-based systems. Central to this approach is maintaining code\nquality and reinforcing conceptual understanding. The paper also addresses\npotential risks such as package conflicts and over-reliance on tools, providing\nbest-practice recommendations to mitigate them. While the goal is to accelerate\ndevelopment, the deeper objective is to reinforce professional workflows and\nindustry readiness. Exposure to Composer packages enhances curriculum relevance\nand smooths the transition from academia to the workplace. However, effective\nintegration requires deliberate instructional design aligned with learning\nobjectives. Without guidance, students may treat packages as black boxes. Thus,\neducators must teach not only how to use these tools, but also when and why,\nencouraging critical evaluation of their utility and limitations. This ensures\nthat practical convenience supports rather than supplants deep learning.", "AI": {"tldr": "The paper proposes using Composer packages to ease Laravel development in academic settings while promoting professional practices and deeper learning.", "motivation": "Students face challenges completing Laravel projects within short academic timelines, necessitating tools to aid development.", "method": "The paper categorizes useful Composer packages, discusses their integration in educational curricula, and provides best-practice guidelines.", "result": "Using Composer packages can simplify project development, align academia with industry practices, and prepare students for professional environments.", "conclusion": "Properly guided use of Composer packages accelerates learning and enhances industry readiness, but educators must ensure students critically engage with the tools to foster deep understanding."}}
{"id": "2508.05778", "pdf": "https://arxiv.org/pdf/2508.05778", "abs": "https://arxiv.org/abs/2508.05778", "authors": ["Jaemin Oh", "Jinsil Lee", "Youngjoon Hong"], "title": "Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "21 pages, 5 figures, 6 tables", "summary": "Nudging is an empirical data assimilation technique that incorporates an\nobservation-driven control term into the model dynamics. The trajectory of the\nnudged system approaches the true system trajectory over time, even when the\ninitial conditions differ. For linear state space models, such control terms\ncan be derived under mild assumptions. However, designing effective nudging\nterms becomes significantly more challenging in the nonlinear setting. In this\nwork, we propose neural network nudging, a data-driven method for learning\nnudging terms in nonlinear state space models. We establish a theoretical\nexistence result based on the Kazantzis--Kravaris--Luenberger observer theory.\nThe proposed approach is evaluated on three benchmark problems that exhibit\nchaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and\nthe Kolmogorov flow.", "AI": {"tldr": "Nudging is a data assimilation method which adjusts model dynamics using observations. This study introduces a neural network-based approach to improve nudging in nonlinear state space models.", "motivation": "The motivation is to address the challenge of designing effective nudging terms for nonlinear state space models, which are difficult compared to linear models.", "method": "A neural network-based nudging method is proposed, supported by theoretical analysis using observer theory, and tested on chaotic benchmark problems.", "result": "The method is evaluated on models such as Lorenz 96, Kuramoto-Sivashinsky, and Kolmogorov flow, showcasing its effectiveness in chaotic systems.", "conclusion": "Neural network nudging enhances the ability to incorporate observation data in nonlinear systems, overcoming limitations of classical nudging techniques."}}
{"id": "2508.05936", "pdf": "https://arxiv.org/pdf/2508.05936", "abs": "https://arxiv.org/abs/2508.05936", "authors": ["Haohui Pan", "Takuya Kiyokawa", "Tomoki Ishikura", "Shingo Hamada", "Genichiro Matsuda", "Kensuke Harada"], "title": "Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration", "categories": ["cs.RO"], "comment": "8 pages, 9 figures", "summary": "The disassembly of small household appliances poses significant challenges\ndue to their complex and curved geometries, which render traditional rigid\nfixtures inadequate. In this paper, we propose a modular vacuum-based fixturing\nsystem that leverages commercially available balloon-type soft grippers to\nconform to arbitrarily shaped surfaces and provide stable support during\nscrew-removal tasks. To enable a reliable deployment of the system, we develop\na stability-aware planning framework that samples the bottom surface of the\ntarget object, filters candidate contact points based on geometric continuity,\nand evaluates support configurations using convex hull-based static stability\ncriteria. We compare the quality of object placement under different numbers\nand configurations of balloon hands. In addition, real-world experiments were\nconducted to compare the success rates of traditional rigid fixtures with our\nproposed system. The results demonstrate that our method consistently achieves\nhigher success rates and superior placement stability during screw removal\ntasks.", "AI": {"tldr": "The paper presents a modular vacuum fixturing system using balloon-type soft grippers for improved disassembly of curved appliances.", "motivation": "Traditional rigid fixtures struggle with the disassembly of complex and curved objects like small household appliances.", "method": "A system combining modular balloon-type soft grippers and a stability-aware planning framework ensures effective handling and placement during screw-removal tasks.", "result": "Experimental results show the proposed system achieves better placement stability and higher success rates compared to rigid fixtures.", "conclusion": "The modular vacuum-based soft gripper system is an effective alternative for disassembling objects with complex geometries, outperforming traditional fixtures in stability and success rates."}}
{"id": "2508.06253", "pdf": "https://arxiv.org/pdf/2508.06253", "abs": "https://arxiv.org/abs/2508.06253", "authors": ["Maria V. Ageeva", "Denis S. Goldobin"], "title": "Low dimensional dynamics of a sparse balanced synaptic network of quadratic integrate-and-fire neurons", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": "12 pages, 4 figures", "summary": "Kinetics of a balanced network of neurons with a sparse grid of synaptic\nlinks is well representable by the stochastic dynamics of a generic neuron\nsubject to an effective shot noise. The rate of delta-pulses of the noise is\ndetermined self-consistently from the probability density of the neuron states.\nImportantly, the most sophisticated (but robust) collective regimes of the\nnetwork do not allow for the diffusion approximation, which is routinely\nadopted for a shot noise in mathematical neuroscience. These regimes can be\nexpected to be biologically relevant. For the kinetics equations of the\ncomplete mean field theory of a homogeneous inhibitory network of quadratic\nintegrate-and-fire neurons, we introduce circular cumulants of the genuine\nphase variable and derive a rigorous two cumulant reduction for both\ntime-independent conditions and modulation of the excitatory current. The low\ndimensional model is examined with numerical simulations and found to be\naccurate for time-independent states and dynamic response to a periodic\nmodulation deep into the parameter domain where the diffusion approximation is\nnot applicable. The accuracy of a low dimensional model indicates and explains\na low embedding dimensionality of the macroscopic collective dynamics of the\nnetwork. The reduced model can be instrumental for theoretical studies of\ninhibitory-excitatory balances neural networks.", "AI": {"tldr": "This paper presents a low-dimensional model using circular cumulants to describe the kinetics of a balanced network of neurons and demonstrates its accuracy even in non-diffusion conditions.", "motivation": "To address the limitations of diffusion approximation in modeling complex collective behaviors in neural networks and provide a framework for studying biologically relevant regimes of neural activity.", "method": "The authors use a mean-field theory approach for a homogeneous inhibitory network of quadratic integrate-and-fire neurons, introducing circular cumulants to formulate a two-cumulant reduction. They validate the reduced model through numerical simulations under both static and periodically modulated inputs.", "result": "The derived model shows high accuracy in representing the time-independent and dynamic responses of the network, even in parameter domains where the diffusion approximation fails.", "conclusion": "The reduced low-dimensional model provides insights into the macroscopic dynamics of neural networks with a low embedding dimensionality and offers a robust tool for further theoretical exploration of neural inhibitory-excitatory balances."}}
{"id": "2508.05764", "pdf": "https://arxiv.org/pdf/2508.05764", "abs": "https://arxiv.org/abs/2508.05764", "authors": ["Arvind K. Saibaba", "Ilse C. F. Ipsen"], "title": "Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "15A15, 65F99, 65C05, 68W20, 68Q32"], "comment": "3 figures", "summary": "We consider matrices $\\boldsymbol{A}(\\boldsymbol\\theta)\\in\\mathbb{R}^{m\\times\nm}$ that depend, possibly nonlinearly, on a parameter $\\boldsymbol\\theta$ from\na compact parameter space $\\Theta$. We present a Monte Carlo estimator for\nminimizing $\\text{trace}(\\boldsymbol{A}(\\boldsymbol\\theta))$ over all\n$\\boldsymbol\\theta\\in\\Theta$, and determine the sampling amount so that the\nbackward error of the estimator is bounded with high probability. We derive two\ntypes of bounds, based on epsilon nets and on generic chaining. Both types\npredict a small sampling amount for matrices\n$\\boldsymbol{A}(\\boldsymbol\\theta)$ with small offdiagonal mass, and parameter\nspaces $\\Theta$ of small ``size.'' Dependence on the matrix dimension~$m$ is\nonly weak or not explicit. The bounds based on epsilon nets are easier to\nevaluate and come with fully specified constants. In contrast, the bounds based\non chaining depend on the Talagrand functionals which are difficult to\nevaluate, except in very special cases. Comparisons between the two types of\nbounds are difficult, although the literature suggests that chaining bounds can\nbe superior.", "AI": {"tldr": "This paper develops a Monte Carlo estimator to minimize a trace function of parameter-dependent matrices and evaluates sampling bounds using two techniques: epsilon nets and generic chaining.", "motivation": "The study seeks to minimize the trace of parameter-dependent matrices efficiently while ensuring that errors are controlled and sampling requirements are minimized.", "method": "The authors use Monte Carlo estimation to minimize the trace of the matrix and derive sampling bounds for error control based on two methods: epsilon net and generic chaining techniques.", "result": "Both methods predict minimal sampling requirements for matrices with small offdiagonal mass and compact parameter spaces. Epsilon net bounds include explicit constants, while chaining bounds are theoretically promising but harder to quantify.", "conclusion": "Epsilon nets offer practical applicability, while chaining bounds might perform better in theory but are difficult to evaluate, leaving a gap in direct comparison."}}
{"id": "2508.06035", "pdf": "https://arxiv.org/pdf/2508.06035", "abs": "https://arxiv.org/abs/2508.06035", "authors": ["Genaro J. Martinez", "Andrew Adamatzky", "Guanrong Chen"], "title": "Post-apocalyptic computing from cellular automata", "categories": ["nlin.CG", "cs.NE"], "comment": "27 pages, 1 table, 6 figures", "summary": "Cellular automata are arrays of finite state machines that can exist in a\nfinite number of states. These machines update their states simultaneously\nbased on specific local rules that govern their interactions. This framework\nprovides a simple yet powerful model for studying complex systems and emergent\nbehaviors. We revisit and reconsider the traditional notion of an algorithm,\nproposing a novel perspective in which algorithms are represented through the\ndynamic state-space configurations of cellular automata. By doing so, we\nestablish a conceptual framework that connects computation to physical\nprocesses in a unique and innovative way. This approach not only enhances our\nunderstanding of computation but also paves the way for the future development\nof unconventional computing devices. Such devices could be engineered to\nleverage the inherent computational capabilities of physical, chemical, and\nbiological substrates. This opens up new possibilities for designing systems\nthat are more efficient, adaptive, and capable of solving problems in ways that\ntraditional silicon-based computers cannot. The integration of cellular\nautomata into these domains highlights their potential as a transformative tool\nin the ongoing evolution of computational theory and practice.", "AI": {"tldr": "This paper reimagines algorithms as dynamic state-space configurations of cellular automata, offering a framework connecting computation to physical processes and enabling unconventional computing.", "motivation": "To rethink traditional algorithms by exploring cellular automata as computational models and to connect computation with physical systems.", "method": "Proposed representing algorithms through the dynamic state-space configurations of cellular automata, linking computational theory to physical and emergent processes.", "result": "The study reveals the potential of engineered devices leveraging cellular automata for unconventional computing beyond silicon-based systems.", "conclusion": "Cellular automata offer a transformative tool for advancing computational theory and practice, with implications for engineering adaptive, efficient, and novel computing systems."}}
{"id": "2508.06001", "pdf": "https://arxiv.org/pdf/2508.06001", "abs": "https://arxiv.org/abs/2508.06001", "authors": ["Kai Zhang", "Peng Wang", "Sai Bi", "Jianming Zhang", "Yuanjun Xiong"], "title": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training", "categories": ["cs.DC", "cs.CV"], "comment": "Code is available at https://github.com/Kai-46/KnapFormer/", "summary": "We present KnapFormer, an efficient and versatile framework to combine\nworkload balancing and sequence parallelism in distributed training of\nDiffusion Transformers (DiT). KnapFormer builds on the insight that strong\nsynergy exists between sequence parallelism and the need to address the\nsignificant token imbalance across ranks. This imbalance arises from\nvariable-length text inputs and varying visual token counts in mixed-resolution\nand image-video joint training. KnapFormer redistributes tokens by first\ngathering sequence length metadata across all ranks in a balancing group and\nsolving a global knapsack problem. The solver aims to minimize the variances of\ntotal workload per-GPU, while accounting for the effect of sequence\nparallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the\nload-balancing decision process and utilizing a simple semi-empirical workload\nmodel, KnapFormers achieves minimal communication overhead and less than 1%\nworkload discrepancy in real-world training workloads with sequence length\nvarying from a few hundred to tens of thousands. It eliminates straggler\neffects and achieves 2x to 3x speedup when training state-of-the-art diffusion\nmodels like FLUX on mixed-resolution and image-video joint data corpora. We\nopen-source the KnapFormer implementation at\nhttps://github.com/Kai-46/KnapFormer/", "AI": {"tldr": "KnapFormer is a framework that efficiently balances workloads and implements sequence parallelism for distributed training of Diffusion Transformers, achieving notable speedups and reduced workload discrepancies.", "motivation": "Variable-length input sequences and varying token counts in mixed-resolution or joint image-video datasets lead to workload imbalances across GPUs during distributed training.", "method": "KnapFormer addresses imbalances by redistributing tokens using metadata collection and solving a global knapsack problem, incorporating sequence parallelism and a workload model to minimize workload variance.", "result": "The framework achieves less than 1% workload discrepancy, eliminates stragglers, and provides a 2x to 3x training speedup in real-world setups.", "conclusion": "KnapFormer effectively handles token imbalance and sequence parallelism in training Diffusion Transformers, optimizing distributed training performance with minimal overhead. The implementation is open-sourced."}}
{"id": "2508.05803", "pdf": "https://arxiv.org/pdf/2508.05803", "abs": "https://arxiv.org/abs/2508.05803", "authors": ["Abishek Thamma", "Micha Heilbron"], "title": "Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models", "categories": ["cs.CL", "I.2.7"], "comment": null, "summary": "Human memory is fleeting. As words are processed, the exact wordforms that\nmake up incoming sentences are rapidly lost. Cognitive scientists have long\nbelieved that this limitation of memory may, paradoxically, help in learning\nlanguage - an idea supported by classic connectionist modelling work. The rise\nof Transformers appears to challenge this idea, as these models can learn\nlanguage effectively, despite lacking memory limitations or other architectural\nrecency biases. Here, we investigate the hypothesized benefit of fleeting\nmemory for language learning in tightly controlled experiments on transformer\nlanguage models. Training transformers with and without fleeting memory on a\ndevelopmentally realistic training set, we find that fleeting memory\nconsistently improves language learning (as quantified by both overall language\nmodelling performance and targeted syntactic evaluation) but, unexpectedly,\nimpairs surprisal-based prediction of human reading times. Interestingly,\nfollow up analyses revealed that this discrepancy - better language modeling,\nyet worse reading time prediction - could not be accounted for by prior\nexplanations of why better language models sometimes fit human reading time\nworse. Together, these results support a benefit of memory limitations on\nneural network language learning - but not on predicting behavior.", "AI": {"tldr": "Investigates the role of fleeting memory on language learning and its effects on performance and prediction in transformer models.", "motivation": "The paper aims to explore why fleeting memory might paradoxically aid language learning, a notion at odds with the capabilities of transformer models which lack such limitations.", "method": "Experiments were conducted by training transformer models with and without memory limitations using a realistic training set to analyze language modeling and syntactic evaluation performance.", "result": "Fleeting memory improves language modeling and syntax evaluation but impairs prediction of human reading times, a counterintuitive result unexplained by prior theories.", "conclusion": "Memory limitations benefit neural network-based language learning but do not enhance the models\u2019 ability to predict human reading behaviors."}}
{"id": "2508.05792", "pdf": "https://arxiv.org/pdf/2508.05792", "abs": "https://arxiv.org/abs/2508.05792", "authors": ["Kausik Lakkaraju", "Siva Likitha Valluru", "Biplav Srivastava"], "title": "Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making", "categories": ["cs.AI"], "comment": null, "summary": "Current eXplainable AI (XAI) methods largely serve developers, often focusing\non justifying model outputs rather than supporting diverse stakeholder needs. A\nrecent shift toward Evaluative AI reframes explanation as a tool for hypothesis\ntesting, but still focuses primarily on operational organizations. We introduce\nHolistic-XAI (H-XAI), a unified framework that integrates causal rating methods\nwith traditional XAI methods to support explanation as an interactive,\nmulti-method process. H-XAI allows stakeholders to ask a series of questions,\ntest hypotheses, and compare model behavior against automatically constructed\nrandom and biased baselines. It combines instance-level and global\nexplanations, adapting to each stakeholder's goals, whether understanding\nindividual decisions, assessing group-level bias, or evaluating robustness\nunder perturbations. We demonstrate the generality of our approach through two\ncase studies spanning six scenarios: binary credit risk classification and\nfinancial time-series forecasting. H-XAI fills critical gaps left by existing\nXAI methods by combining causal ratings and post-hoc explanations to answer\nstakeholder-specific questions at both the individual decision level and the\noverall model level.", "AI": {"tldr": "The paper proposes Holistic-XAI (H-XAI), a unified framework combining causal rating and traditional XAI methods to create multi-method, interactive explanations tailored to diverse stakeholder needs.", "motivation": "Existing XAI methods focus predominantly on developers and lack inclusivity for diverse stakeholders, often limiting explanations to model justification rather than hypothesis testing and broader needs.", "method": "Holistic-XAI integrates causal ratings with traditional XAI approaches, providing instance-level and global explanations tailored to stakeholder needs, and introduces hypothesis testing through comparison against random and biased baselines.", "result": "H-XAI's generality was validated via two case studies in binary credit risk classification and financial time-series forecasting across six scenarios, demonstrating capability in answering stakeholder-specific questions at individual and model levels.", "conclusion": "H-XAI addresses limitations in current XAI approaches by introducing a comprehensive framework that adapts explanations for stakeholders, offering both granular and global insights into AI behavior."}}
{"id": "2508.05769", "pdf": "https://arxiv.org/pdf/2508.05769", "abs": "https://arxiv.org/abs/2508.05769", "authors": ["Seyed Hadi Seyed", "Ayberk Cansever", "David Hart"], "title": "Improving Masked Style Transfer using Blended Partial Convolution", "categories": ["cs.CV"], "comment": null, "summary": "Artistic style transfer has long been possible with the advancements of\nconvolution- and transformer-based neural networks. Most algorithms apply the\nartistic style transfer to the whole image, but individual users may only need\nto apply a style transfer to a specific region in the image. The standard\npractice is to simply mask the image after the stylization. This work shows\nthat this approach tends to improperly capture the style features in the region\nof interest. We propose a partial-convolution-based style transfer network that\naccurately applies the style features exclusively to the region of interest.\nAdditionally, we present network-internal blending techniques that account for\nimperfections in the region selection. We show that this visually and\nquantitatively improves stylization using examples from the SA-1B dataset. Code\nis publicly available at https://github.com/davidmhart/StyleTransferMasked.", "AI": {"tldr": "This paper introduces a partial-convolution-based network for localized artistic style transfer, improving over traditional masking approaches.", "motivation": "Existing artistic style transfer methods apply style to entire images, making them unsuitable for users who want stylization only for specific regions. Standard masking techniques are ineffective for accurately capturing style features within regions of interest.", "method": "The authors developed a style transfer network that utilizes partial convolutions to apply styles precisely to selected regions. Internal blending techniques are integrated to address imperfections in region selection.", "result": "Experimental results on the SA-1B dataset demonstrate visual and quantitative improvements in the stylization process.", "conclusion": "The proposed method successfully enables precise and improved artistic style transfer to specific image regions. The work advances the field by overcoming limitations of conventional masking approaches, with code accessible for reproducibility."}}
{"id": "2508.05799", "pdf": "https://arxiv.org/pdf/2508.05799", "abs": "https://arxiv.org/abs/2508.05799", "authors": ["Yoseph Berhanu Alebachew"], "title": "AI-Guided Exploration of Large-Scale Codebases", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Understanding large-scale, complex software systems is a major challenge for\ndevelopers, who spend a significant portion of their time on program\ncomprehension. Traditional tools such as static visualizations and reverse\nengineering techniques provide structural insights but often lack\ninteractivity, adaptability, and integration with contextual information.\nRecent advancements in large language models (LLMs) offer new opportunities to\nenhance code exploration workflows, yet their lack of grounding and integration\nwith structured views limits their effectiveness. This work introduces a hybrid\napproach that integrates deterministic reverse engineering with LLM-guided,\nintent-aware visual exploration. The proposed system combines UML-based\nvisualization, dynamic user interfaces, historical context, and collaborative\nfeatures into an adaptive tool for code comprehension. By interpreting user\nqueries and interaction patterns, the LLM helps developers navigate and\nunderstand complex codebases more effectively. A prototype implementation for\nJava demonstrates the feasibility of this approach. Future work includes\nempirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM\ninteraction models. This research lays the groundwork for intelligent,\ninteractive environments that align with developer cognition and collaborative\nworkflows.", "AI": {"tldr": "The paper proposes an adaptive tool blending UML visuals, user interfaces, and LLM-guided exploration for better software comprehension.", "motivation": "Developers struggle to understand complex software systems effectively using traditional tools lacking adaptability, interactivity, and integration with context.", "method": "The paper introduces a hybrid system combining deterministic reverse engineering with LLM-assisted intent-aware exploration, featuring UML visuals, dynamic interfaces, and collaborative tools.", "result": "A prototype for Java demonstrates the approach's feasibility, setting a foundation for empirical evaluation and future expansions.", "conclusion": "This adaptive tool addresses comprehension challenges, paving the way for intelligent environments that align with developer cognition and collaborative workflows."}}
{"id": "2508.05791", "pdf": "https://arxiv.org/pdf/2508.05791", "abs": "https://arxiv.org/abs/2508.05791", "authors": ["Haoran Li", "Lihao Mai", "Muhao Guo", "Jiaqi Wu", "Yang Weng", "Yannan Sun", "Ce Jimmy Liu"], "title": "From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages", "summary": "Accurate distribution grid topology is essential for reliable modern grid\noperations. However, real-world utility data originates from multiple sources\nwith varying characteristics and levels of quality. In this work, developed in\ncollaboration with Oncor Electric Delivery, we propose a scalable framework\nthat reconstructs a trustworthy grid topology by systematically integrating\nheterogeneous data. We observe that distribution topology is fundamentally\ngoverned by two complementary dimensions: the spatial layout of physical\ninfrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the\nsystem in the signal domain (e.g., voltage time series). When jointly\nleveraged, these dimensions support a complete and physically coherent\nreconstruction of network connectivity. To address the challenge of uneven data\nquality without compromising observability, we introduce a confidence-aware\ninference mechanism that preserves structurally informative yet imperfect\ninputs, while quantifying the reliability of each inferred connection for\noperator interpretation. This soft handling of uncertainty is tightly coupled\nwith hard enforcement of physical feasibility: we embed operational\nconstraints, such as transformer capacity limits and radial topology\nrequirements, directly into the learning process. Together, these components\nensure that inference is both uncertainty-aware and structurally valid,\nenabling rapid convergence to actionable, trustworthy topologies under\nreal-world deployment conditions. The proposed framework is validated using\ndata from over 8000 meters across 3 feeders in Oncor's service territory,\ndemonstrating over 95% accuracy in topology reconstruction and substantial\nimprovements in confidence calibration and computational efficiency relative to\nbaseline methods.", "AI": {"tldr": "The paper introduces a framework to reconstruct accurate distribution grid topology using heterogeneous data, ensuring reliability under varied real-world conditions.", "motivation": "Distribution grid topology is critical for reliable grid operations, but utility data varies in quality and origin, necessitating a scalable and trustworthy reconstruction method.", "method": "A framework integrates spatial and signal domain data, employs confidence-aware inference, and enforces operational constraints during the learning process.", "result": "Validated on data from over 8000 meters across 3 feeders, the framework achieved over 95% accuracy in topology reconstruction and improved confidence calibration and efficiency.", "conclusion": "The approach systematically handles uncertainty and ensures structural validity, providing reliable topology reconstruction tailored for real-world deployment."}}
{"id": "2508.05937", "pdf": "https://arxiv.org/pdf/2508.05937", "abs": "https://arxiv.org/abs/2508.05937", "authors": ["Gen Sako", "Takuya Kiyokawa", "Kensuke Harada", "Tomoki Ishikura", "Naoya Miyaji", "Genichiro Matsuda"], "title": "Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts", "categories": ["cs.RO"], "comment": "6 pages, 9 figures", "summary": "Robotic non-destructive disassembly of mating parts remains challenging due\nto the need for flexible manipulation and the limited visibility of internal\nstructures. This study presents an affordance-guided teleoperation system that\nenables intuitive human demonstrations for dual-arm fix-and-disassemble tasks\nfor mating parts. The system visualizes feasible grasp poses and disassembly\ndirections in a virtual environment, both derived from the object's geometry,\nto address occlusions and structural complexity. To prevent excessive position\ntracking under load when following the affordance, we integrate a hybrid\ncontroller that combines position and impedance control into the teleoperated\ndisassembly arm. Real-world experiments validate the effectiveness of the\nproposed system, showing improved task success rates and reduced object pose\ndeviation.", "AI": {"tldr": "The paper introduces a teleoperation system for robotic disassembly of mating parts using intuitive visualization of grasp and disassembly directions, combined with a hybrid controller to enhance task success and precision.", "motivation": "Robotic disassembly of mating parts is challenging due to structural occlusions, manipulation flexibility, and visibility constraints, motivating the development of a system for better interaction and task execution.", "method": "The paper employs an affordance-guided system that visualizes grasp poses and disassembly directions in a virtual environment, coupled with a hybrid controller integrating position and impedance control for robotic teleoperation.", "result": "Experiments in real-world scenarios validate the system, showing improved success rates in disassembly tasks and reduced positional deviations of objects involved.", "conclusion": "The study demonstrates that combining affordance visualization with hybrid control enhances robotic disassembly performance by enabling intuitive human interaction and addressing structural complexities."}}
{"id": "2508.06069", "pdf": "https://arxiv.org/pdf/2508.06069", "abs": "https://arxiv.org/abs/2508.06069", "authors": ["Bo Yang", "Ruixuan Luo", "Junqi Jin", "Han Zhu"], "title": "Lightweight Auto-bidding based on Traffic Prediction in Live Advertising", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Internet live streaming is widely used in online entertainment and\ne-commerce, where live advertising is an important marketing tool for anchors.\nAn advertising campaign hopes to maximize the effect (such as conversions)\nunder constraints (such as budget and cost-per-click). The mainstream control\nof campaigns is auto-bidding, where the performance depends on the decision of\nthe bidding algorithm in each request. The most widely used auto-bidding\nalgorithms include Proportional-Integral-Derivative (PID) control, linear\nprogramming (LP), reinforcement learning (RL), etc. Existing methods either do\nnot consider the entire time traffic, or have too high computational\ncomplexity. In this paper, the live advertising has high requirements for\nreal-time bidding (second-level control) and faces the difficulty of unknown\nfuture traffic. Therefore, we propose a lightweight bidding algorithm Binary\nConstrained Bidding (BiCB), which neatly combines the optimal bidding formula\ngiven by mathematical analysis and the statistical method of future traffic\nestimation, and obtains good approximation to the optimal result through a low\ncomplexity solution. In addition, we complement the form of upper and lower\nbound constraints for traditional auto-bidding modeling and give theoretical\nanalysis of BiCB. Sufficient offline and online experiments prove BiCB's good\nperformance and low engineering cost.", "AI": {"tldr": "The paper introduces Binary Constrained Bidding (BiCB), a lightweight algorithm for real-time bidding in live advertising, combining mathematical optimization and statistical traffic estimation.", "motivation": "Existing auto-bidding methods struggle with real-time traffic control and unknown future traffic complexities, requiring a better solution for live streaming advertising.", "method": "BiCB combines an optimal bidding formula derived from mathematical analysis with statistical traffic estimation, achieving efficient performance through a low-complexity solution and bounding constraints on auto-bidding models.", "result": "Offline and online experiments demonstrate that BiCB performs well with low engineering costs and provides good approximations to optimal results.", "conclusion": "BiCB improves real-time bidding performance in live advertising while maintaining computational efficiency and practical utility."}}
{"id": "2508.06024", "pdf": "https://arxiv.org/pdf/2508.06024", "abs": "https://arxiv.org/abs/2508.06024", "authors": ["Zheming Yang", "Yunqing Hu", "Sheng Sun", "Wen Ji"], "title": "EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference", "categories": ["cs.DC"], "comment": "9 pages, 8 figures", "summary": "The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to\nscale up model capacity while maintaining inference efficiency. However,\ndeploying MoE models across heterogeneous end-cloud environments poses new\nchallenges in expert scheduling, communication overhead, and resource\nheterogeneity. In this paper, we propose EC2MoE, an adaptive framework for\nscalable MoE inference via end-cloud pipeline collaboration. First, we design a\nhardware-aware lightweight group gate network that enhances expert selection\nand computational efficiency. By incorporating a hardware-aware local expert\nselection mechanism, the system adaptively filters candidate experts based on\nreal-time device profiles. A lightweight group gate module then integrates\nlocal and global gating outputs to achieve high-quality expert routing with\nminimal overhead. Second, we develop a pipeline optimization mechanism based on\nendcloud collaboration to accelerate MoE inference. This includes an\nencoder-decoder structure based on low-rank compression, which reduces\ntransmission and computation costs. And a route-aware heuristic pipeline\nscheduling algorithm that dynamically allocates inference stages across devices\naccording to workload and network topology. Extensive experiments show that\nEC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by\n53% to 67% while maintaining high accuracy compared to state-of-the-art\nmethods. It also maintains good scalability under dynamic load and network\nenvironments.", "AI": {"tldr": "The paper introduces EC2MoE, a framework designed for scalable Mixture-of-Experts (MoE) inference across end-cloud environments, improving throughput, latency, and scalability.", "motivation": "The motivation is to address challenges in expert scheduling, communication overhead, and resource heterogeneity while deploying MoE models in heterogeneous end-cloud setups.", "method": "The authors propose a hardware-aware lightweight group gate network for adaptive expert selection and a pipeline optimization mechanism involving end-cloud collaboration, low-rank compression, and route-aware pipeline scheduling.", "result": "EC2MoE achieves a throughput increase of 2.2x to 5.1x, a latency reduction of 53% to 67%, and maintains high accuracy over state-of-the-art methods.", "conclusion": "The proposed EC2MoE framework enhances scalable inference, improves efficiency across multi-device systems, and remains robust under dynamic conditions."}}
{"id": "2508.05830", "pdf": "https://arxiv.org/pdf/2508.05830", "abs": "https://arxiv.org/abs/2508.05830", "authors": ["Tong Li", "Rasiq Hussain", "Mehak Gupta", "Joshua R. Oltmanns"], "title": "\"Mirror\" Language AI Models of Depression are Criterion-Contaminated", "categories": ["cs.CL", "cs.CY"], "comment": "39 pages, 9 figures", "summary": "A growing number of studies show near-perfect LLM language-based prediction\nof depression assessment scores (up to R2 of .70). However, many develop these\nmodels directly from language responses to depression assessments. These\n\"Mirror models\" suffer from \"criterion contamination\", which arises when a\npredicted score depends in part on the predictors themselves. This causes\nartificial effect size inflation which reduces model generalizability. The\npresent study compares the performance of Mirror models versus \"Non-Mirror\nmodels\", which are developed from language that does not mirror the assessment\nthey are developed to predict. N = 110 research participants completed two\ndifferent interviews: structured diagnostic and life history interviews. GPT-4,\nGPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic\ninterview depression scores from the two transcripts separately. Mirror models\n(using structured diagnostic data) showed very large effect sizes (e.g., R2 =\n.80). As expected, NonMirror models (using life history data) demonstrated\nsmaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror\nand Non-Mirror model-predicted structured interview depression scores were\ncorrelated with self-reported depression symptoms, Mirror and NonMirror\nperformed the same (e.g., r = ~.54), indicating that Mirror models contain bias\nperhaps due to criterion contamination. Topic modeling identified clusters\nacross Mirror and Non-Mirror models, as well as between true-positive and\nfalse-positive predictions. In this head-to-head comparison study, Mirror\nlanguage AI models of depression showed artificially inflated effect sizes and\nless generalizability. As language AI models for depression continue to evolve,\nincorporating Non-Mirror models may identify interpretable, and generalizable\nsemantic features that have unique utility in real-world psychological\nassessment.", "AI": {"tldr": "Studies find that AI language models achieve high accuracy in predicting depression scores based on direct input responses (Mirror models), but these models exhibit bias and limited generalizability due to criterion contamination. Non-Mirror models provide more reliable but smaller effect sizes.", "motivation": "To assess the reliability and generalizability of language-based AI models for predicting depression scores, and highlight the limitations introduced by criterion contamination in Mirror models.", "method": "The study compares \"Mirror models\"\u2014developed from structured diagnostic language\u2014to \"Non-Mirror models,\" trained on non-diagnostic life history interviews. Predictions were tested using GPT-4, GPT-4o, and LLaMA3-70B across participant data.", "result": "Mirror models achieved high effect sizes (R2 = .80) but were biased, while Non-Mirror models achieved lower effect sizes (R2 = .27). Despite this, both model types performed equally (r ~ .54) in correlating AI predictions with self-reported depression scores.", "conclusion": "Mirror models show inflated effect sizes due to overfitting and bias, impairing generalizability. Non-Mirror models offer a path to more generalizable and interpretable AI-based semantic predictions for psychology applications."}}
{"id": "2508.05855", "pdf": "https://arxiv.org/pdf/2508.05855", "abs": "https://arxiv.org/abs/2508.05855", "authors": ["Zixia Wang", "Jia Hu", "Ronghui Mu"], "title": "Safety of Embodied Navigation: A Survey", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "As large language models (LLMs) continue to advance and gain influence, the\ndevelopment of embodied AI has accelerated, drawing significant attention,\nparticularly in navigation scenarios. Embodied navigation requires an agent to\nperceive, interact with, and adapt to its environment while moving toward a\nspecified target in unfamiliar settings. However, the integration of embodied\nnavigation into critical applications raises substantial safety concerns. Given\ntheir deployment in dynamic, real-world environments, ensuring the safety of\nsuch systems is critical. This survey provides a comprehensive analysis of\nsafety in embodied navigation from multiple perspectives, encompassing attack\nstrategies, defense mechanisms, and evaluation methodologies. Beyond conducting\na comprehensive examination of existing safety challenges, mitigation\ntechnologies, and various datasets and metrics that assess effectiveness and\nrobustness, we explore unresolved issues and future research directions in\nembodied navigation safety. These include potential attack methods, mitigation\nstrategies, more reliable evaluation techniques, and the implementation of\nverification frameworks. By addressing these critical gaps, this survey aims to\nprovide valuable insights that can guide future research toward the development\nof safer and more reliable embodied navigation systems. Furthermore, the\nfindings of this study have broader implications for enhancing societal safety\nand increasing industrial efficiency.", "AI": {"tldr": "The paper surveys the safety challenges in embodied navigation systems, analyzing attack and defense strategies and evaluation methods, while proposing future directions for safer systems.", "motivation": "To address safety concerns in embodied AI navigation systems deployed in dynamic, real-world environments.", "method": "A comprehensive analysis of attack strategies, defense mechanisms, evaluation methodologies, existing challenges, and unresolved issues.", "result": "Identification of gaps, emerging technologies, and strategies for improving safety and reliability in embodied navigation systems.", "conclusion": "Insights are provided to facilitate safer embodied navigation systems, with implications for societal safety and industrial efficiency."}}
{"id": "2508.05772", "pdf": "https://arxiv.org/pdf/2508.05772", "abs": "https://arxiv.org/abs/2508.05772", "authors": ["Can Zhao", "Pengfei Guo", "Dong Yang", "Yucheng Tang", "Yufan He", "Benjamin Simon", "Mason Belue", "Stephanie Harmon", "Baris Turkbey", "Daguang Xu"], "title": "MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss", "categories": ["cs.CV"], "comment": null, "summary": "Medical image synthesis is an important topic for both clinical and research\napplications. Recently, diffusion models have become a leading approach in this\narea. Despite their strengths, many existing methods struggle with (1) limited\ngeneralizability that only work for specific body regions or voxel spacings,\n(2) slow inference, which is a common issue for diffusion models, and (3) weak\nalignment with input conditions, which is a critical issue for medical imaging.\nMAISI, a previously proposed framework, addresses generalizability issues but\nstill suffers from slow inference and limited condition consistency. In this\nwork, we present MAISI-v2, the first accelerated 3D medical image synthesis\nframework that integrates rectified flow to enable fast and high quality\ngeneration. To further enhance condition fidelity, we introduce a novel\nregion-specific contrastive loss to enhance the sensitivity to region of\ninterest. Our experiments show that MAISI-v2 can achieve SOTA image quality\nwith $33 \\times$ acceleration for latent diffusion model. We also conducted a\ndownstream segmentation experiment to show that the synthetic images can be\nused for data augmentation. We release our code, training details, model\nweights, and a GUI demo to facilitate reproducibility and promote further\ndevelopment within the community.", "AI": {"tldr": "MAISI-v2 improves medical image synthesis using rectified flow for faster and higher-quality generation, while addressing prior limitations with condition fidelity and inference speed.", "motivation": "Medical image synthesis using diffusion models faces challenges like limited generalizability, slow inference, and weak input alignment, particularly critical for clinical and research applications.", "method": "MAISI-v2 integrates rectified flow to accelerate synthesis and introduces a region-specific contrastive loss for enhanced condition fidelity.", "result": "MAISI-v2 achieves state-of-the-art image quality with 33\u00d7 faster inference compared to latent diffusion models. Its synthetic images are validated for data augmentation in segmentation tasks.", "conclusion": "MAISI-v2 addresses multiple limitations of prior methods in medical image synthesis, offering enhanced condition fidelity, faster generation, and reproducibility tools for broader adoption and development in the field."}}
{"id": "2508.05923", "pdf": "https://arxiv.org/pdf/2508.05923", "abs": "https://arxiv.org/abs/2508.05923", "authors": ["Yanusha Mehendran", "Maolin Tang", "Yi Lu"], "title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "categories": ["cs.SE", "cs.AI"], "comment": "26 Pages, 3 figures, 6 Tables, Submitted to Empirical Software\n  Engineering and it is under review", "summary": "Software vulnerabilities continue to undermine the reliability and security\nof modern systems, particularly as software complexity outpaces the\ncapabilities of traditional detection methods. This study introduces a genetic\nalgorithm-based method for test input generation that innovatively integrates\ngenetic operators and adaptive learning to enhance software vulnerability\ndetection. A key contribution is the application of the crossover operator,\nwhich facilitates exploration by searching across a broader space of potential\ntest inputs. Complementing this, an adaptive feedback mechanism continuously\nlearns from the system's execution behavior and dynamically guides input\ngeneration toward promising areas of the input space. Rather than relying on\nfixed or randomly selected inputs, the approach evolves a population of\nstructurally valid test cases using feedback-driven selection, enabling deeper\nand more effective code traversal. This strategic integration of exploration\nand exploitation ensures that both diverse and targeted test inputs are\ndeveloped over time. Evaluation was conducted across nine open-source\nJSON-processing libraries. The proposed method achieved substantial\nimprovements in coverage compared to a benchmark evolutionary fuzzing method,\nwith average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%\nin line coverage, 114.0% in instruction coverage, and 166.0% in branch\ncoverage. These results highlight the method's capacity to detect deeper and\nmore complex vulnerabilities, offering a scalable and adaptive solution to\nsoftware security testing.", "AI": {"tldr": "This paper presents a genetic algorithm-based approach for generating test inputs to detect software vulnerabilities more effectively, achieving significant improvements in code coverage metrics.", "motivation": "The growing complexity of software outpaces traditional methods for detecting vulnerabilities, necessitating adaptive and innovative solutions for effective security testing.", "method": "A genetic algorithm integrates crossover operators and adaptive feedback mechanisms to dynamically generate structurally valid test inputs, evolving them to achieve deeper code traversal and improved detection efficiency.", "result": "The method, evaluated on nine open-source JSON-processing libraries, demonstrated significant improvements in various code coverage metrics compared to a benchmark fuzzing method, including 166% higher branch coverage.", "conclusion": "The approach provides an adaptive and scalable solution for software security testing, capable of uncovering deeper and more complex vulnerabilities, and exceeding traditional fuzzing methods in effectiveness."}}
{"id": "2508.05831", "pdf": "https://arxiv.org/pdf/2508.05831", "abs": "https://arxiv.org/abs/2508.05831", "authors": ["Alexander DeLise", "Kyle Loh", "Krish Patel", "Meredith Teague", "Andrea Arnold", "Matthias Chung"], "title": "Optimal Linear Baseline Models for Scientific Machine Learning", "categories": ["cs.LG", "cs.NA", "math.NA", "15A29 Inverse problems in linear algebra 65F22, 68T07, 65F05, 62C12", "G.1.3; F.2.1; I.2.6"], "comment": "40 pages, 10 Figures, 9 Tables", "summary": "Across scientific domains, a fundamental challenge is to characterize and\ncompute the mappings from underlying physical processes to observed signals and\nmeasurements. While nonlinear neural networks have achieved considerable\nsuccess, they remain theoretically opaque, which hinders adoption in contexts\nwhere interpretability is paramount. In contrast, linear neural networks serve\nas a simple yet effective foundation for gaining insight into these complex\nrelationships. In this work, we develop a unified theoretical framework for\nanalyzing linear encoder-decoder architectures through the lens of Bayes risk\nminimization for solving data-driven scientific machine learning problems. We\nderive closed-form, rank-constrained linear and affine linear optimal mappings\nfor forward modeling and inverse recovery tasks. Our results generalize\nexisting formulations by accommodating rank-deficiencies in data, forward\noperators, and measurement processes. We validate our theoretical results by\nconducting numerical experiments on datasets from simple biomedical imaging,\nfinancial factor analysis, and simulations involving nonlinear fluid dynamics\nvia the shallow water equations. This work provides a robust baseline for\nunderstanding and benchmarking learned neural network models for scientific\nmachine learning problems.", "AI": {"tldr": "The paper develops a robust framework for analyzing linear encoder-decoder architectures in scientific machine learning, offering theoretical insights and practical validations.", "motivation": "The paper aims to address the challenge of understanding mappings from physical processes to observed signals, with an emphasis on interpretable methods.", "method": "A unified theoretical framework involving Bayes risk minimization is applied to linear encoder-decoder architectures, producing rank-constrained solutions.", "result": "Validated with numerical experiments across biomedical imaging, financial analysis, and fluid dynamics, the results generalize formulations to rank-deficiencies.", "conclusion": "The work provides a baseline for benchmarking neural network models in scientific machine learning, ensuring interpretability and broader applicability of trained models."}}
{"id": "2508.05941", "pdf": "https://arxiv.org/pdf/2508.05941", "abs": "https://arxiv.org/abs/2508.05941", "authors": ["Zhanyi Sun", "Shuran Song"], "title": "Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution", "categories": ["cs.RO"], "comment": null, "summary": "Visuomotor policies trained via behavior cloning are vulnerable to covariate\nshift, where small deviations from expert trajectories can compound into\nfailure. Common strategies to mitigate this issue involve expanding the\ntraining distribution through human-in-the-loop corrections or synthetic data\naugmentation. However, these approaches are often labor-intensive, rely on\nstrong task assumptions, or compromise the quality of imitation. We introduce\nLatent Policy Barrier, a framework for robust visuomotor policy learning.\nInspired by Control Barrier Functions, LPB treats the latent embeddings of\nexpert demonstrations as an implicit barrier separating safe, in-distribution\nstates from unsafe, out-of-distribution (OOD) ones. Our approach decouples the\nrole of precise expert imitation and OOD recovery into two separate modules: a\nbase diffusion policy solely on expert data, and a dynamics model trained on\nboth expert and suboptimal policy rollout data. At inference time, the dynamics\nmodel predicts future latent states and optimizes them to stay within the\nexpert distribution. Both simulated and real-world experiments show that LPB\nimproves both policy robustness and data efficiency, enabling reliable\nmanipulation from limited expert data and without additional human correction\nor annotation.", "AI": {"tldr": "Latent Policy Barrier (LPB) is introduced to improve robustness in visuomotor policy learning, addressing covariate shift by separating expert imitation and recovery from out-of-distribution states.", "motivation": "Visuomotor policies trained with behavior cloning face challenges due to covariate shift, causing failure when slight deviations from expert trajectories accumulate.", "method": "LPB uses latent embeddings of expert demonstrations as implicit barriers to differentiate safe and unsafe states. It decouples expert imitation and recovery into two modules: a diffusion policy trained on expert data, and a dynamics model trained on a mix of expert and suboptimal data, guiding inference towards in-distribution states.", "result": "Simulated and real-world experiments demonstrated that LPB enhances policy robustness and reduces reliance on extensive human corrections while achieving efficient manipulation with limited expert data.", "conclusion": "LPB is effective in mitigating covariate shift issues by creating a robust framework for visuomotor policy learning, driven by expert imitation and recovery mechanisms."}}
{"id": "2508.06337", "pdf": "https://arxiv.org/pdf/2508.06337", "abs": "https://arxiv.org/abs/2508.06337", "authors": ["Benedikt Fr\u00f6hlich", "Alison Durst", "Merle Behr"], "title": "Decorrelated feature importance from local sample weighting", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Feature importance (FI) statistics provide a prominent and valuable method of\ninsight into the decision process of machine learning (ML) models, but their\neffectiveness has well-known limitations when correlation is present among the\nfeatures in the training data. In this case, the FI often tends to be\ndistributed among all features which are in correlation with the\nresponse-generating signal features. Even worse, if multiple signal features\nare in strong correlation with a noise feature, while being only modestly\ncorrelated with one another, this can result in a noise feature having a\ndistinctly larger FI score than any signal feature. Here we propose local\nsample weighting (losaw) which can flexibly be integrated into many ML\nalgorithms to improve FI scores in the presence of feature correlation in the\ntraining data. Our approach is motivated from inverse probability weighting in\ncausal inference and locally, within the ML model, uses a sample weighting\nscheme to decorrelate a target feature from the remaining features. This\nreduces model bias locally, whenever the effect of a potential signal feature\nis evaluated and compared to others. Moreover, losaw comes with a natural\ntuning parameter, the minimum effective sample size of the weighted population,\nwhich corresponds to an interpretation-prediction-tradeoff, analog to a\nbias-variance-tradeoff as for classical ML tuning parameters. We demonstrate\nhow losaw can be integrated within decision tree-based ML methods and within\nmini-batch training of neural networks. We investigate losaw for random forest\nand convolutional neural networks in a simulation study on settings showing\ndiverse correlation patterns. We found that losaw improves FI consistently.\nMoreover, it often improves prediction accuracy for out-of-distribution, while\nmaintaining a similar accuracy for in-distribution test data.", "AI": {"tldr": "The paper introduces a method called local sample weighting (losaw) to improve feature importance (FI) scores in machine learning models when features are correlated, by decorrelating target features using a sample weighting scheme.", "motivation": "FI statistics are valuable for understanding machine learning models but are limited when features in the training data are correlated, potentially leading to noisy or misleading FI scores.", "method": "The proposed losaw method incorporates local sample weighting inspired by causality and inverse probability weighting, aiming to decorrelate target features locally and reduce model bias for better FI evaluation.", "result": "Losaw consistently improves FI scores and often enhances out-of-distribution prediction accuracy, while maintaining similar in-distribution accuracy, as demonstrated on random forest and convolutional neural networks in simulation studies.", "conclusion": "Losaw is effective in handling feature correlation and can be flexibly integrated into many machine learning algorithms, offering a trade-off between interpretation and prediction performance."}}
{"id": "2508.06243", "pdf": "https://arxiv.org/pdf/2508.06243", "abs": "https://arxiv.org/abs/2508.06243", "authors": ["Ioan-Sorin Comsa", "Purav Shah", "Karthik Vaidhyanathan", "Deepak Gangadharan", "Christof Imhof", "Per Bergamin", "Aryan Kaushik", "Gabriel-Miro Muntean", "Ramona Trestian"], "title": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems", "categories": ["cs.LG", "cs.NE", "cs.SY", "eess.SY"], "comment": null, "summary": "The advent of 6G networks opens new possibilities for connected infotainment\nservices in vehicular environments. However, traditional Radio Resource\nManagement (RRM) techniques struggle with the increasing volume and complexity\nof data such as Channel Quality Indicators (CQI) from autonomous vehicles. To\naddress this, we propose SCAR (State-Space Compression for AI-Driven Resource\nManagement), an Edge AI-assisted framework that optimizes scheduling and\nfairness in vehicular infotainment. SCAR employs ML-based compression\ntechniques (e.g., clustering and RBF networks) to reduce CQI data size while\npreserving essential features. These compressed states are used to train\n6G-enabled Reinforcement Learning policies that maximize throughput while\nmeeting fairness objectives defined by the NGMN. Simulations show that SCAR\nincreases time in feasible scheduling regions by 14\\% and reduces unfair\nscheduling time by 15\\% compared to RL baselines without CQI compression.\nFurthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based\nclustering reduces CQI clustering distortion by 10\\%, confirming its\nefficiency. These results demonstrate SCAR's scalability and fairness benefits\nfor dynamic vehicular networks.", "AI": {"tldr": "This paper introduces SCAR, an Edge AI-assisted framework for optimizing scheduling and fairness in 6G vehicular infotainment by compressing Channel Quality Indicators (CQI) for efficient reinforcement learning.", "motivation": "The complexities and increasing volume of CQI data in autonomous vehicular networks challenge traditional Radio Resource Management techniques, necessitating innovative solutions to optimize scheduling and ensure fairness.", "method": "SCAR uses machine learning-based compression methods, such as clustering and RBF networks, to reduce CQI data size, and then applies reinforcement learning to train scheduling policies that maximize throughput and meet fairness criteria.", "result": "SCAR improves feasible scheduling by 14% and reduces unfair scheduling by 15% compared to non-compressed RL baselines. Additionally, SAST-based CQI clustering decreases distortion by 10%.", "conclusion": "SCAR proves to be an efficient solution for managing resources in dynamic vehicular networks, showcasing significant gains in scalability, scheduling efficiency, and fairness for future 6G systems."}}
{"id": "2508.06297", "pdf": "https://arxiv.org/pdf/2508.06297", "abs": "https://arxiv.org/abs/2508.06297", "authors": ["Yanyu Liu", "Jingying Fu", "Sixiang Liu", "Yitian Zou", "You Fu", "Jiehan Zhou", "Shouhua Zhang"], "title": "KV Cache Compression for Inference Efficiency in LLMs: A Review", "categories": ["cs.DC"], "comment": "12 pages", "summary": "Withtherapid advancement of large language models (LLMs), the context length\nfor inference has been continuously increasing, leading to an exponential\ngrowth in the demand for Key-Value (KV) caching. This has resulted in a\nsignificant memory bottleneck, limiting the inference efficiency and\nscalability of the models. Therefore, optimizing the KV cache during inference\nis crucial for enhancing performance and efficiency. This review systematically\nexamines current KV cache optimization techniques, including compression\nstrategies such as selective token strategies, quantization, and attention\ncompression. We evaluate the effectiveness, trade-offs, and application\nscenarios of these methods, providing a comprehensive analysis of their impact\non memory usage and inference speed. We focus on identifying the limitations\nand challenges of existing methods, such as compatibility issues with different\nmodels and tasks. Additionally, this review highlights future research\ndirections, including hybrid optimization techniques, adaptive dynamic\nstrategies, and software-hardware co-design. These approaches aim to improve\ninference efficiency and promote the practical application of large language\nmodels.", "AI": {"tldr": "The paper reviews optimization techniques for Key-Value (KV) caching in large language models, addressing memory bottlenecks and exploring strategies to enhance inference efficiency.", "motivation": "The exponential growth in KV caching demand due to increasing context lengths in large language models has created significant memory bottlenecks, necessitating optimization for better scalability and performance during inference.", "method": "A systematic review of KV cache optimization techniques, including compression strategies, quantization, attention compression, and evaluation of their effectiveness, trade-offs, and applicability.", "result": "Comprehensive analysis of the impact of various KV cache optimization techniques on memory usage and inference speed, with insights into their limitations and challenges.", "conclusion": "Future directions for research are proposed, such as hybrid optimization techniques, adaptive strategies, and software-hardware co-design to further improve inference efficiency and practical applications of LLMs."}}
{"id": "2508.05843", "pdf": "https://arxiv.org/pdf/2508.05843", "abs": "https://arxiv.org/abs/2508.05843", "authors": ["Miles Gilberti", "Shane Storks", "Huteng Dai"], "title": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication", "categories": ["cs.CL"], "comment": null, "summary": "Emergent communication (EmCom) with deep neural network-based agents promises\nto yield insights into the nature of human language, but remains focused\nprimarily on a few subfield-specific goals and metrics that prioritize\ncommunication schemes which represent attributes with unique characters\none-to-one and compose them syntactically. We thus reinterpret a common EmCom\nsetting, the attribute-value reconstruction game, by imposing a\nsmall-vocabulary constraint to simulate double articulation, and formulating a\nnovel setting analogous to naturalistic inflectional morphology (enabling\nmeaningful comparison to natural language communication schemes). We develop\nnew metrics and explore variations of this game motivated by real properties of\ninflectional morphology: concatenativity and fusionality. Through our\nexperiments, we discover that simulated phonological constraints encourage\nconcatenative morphology, and emergent languages replicate the tendency of\nnatural languages to fuse grammatical attributes.", "AI": {"tldr": "This paper enhances emergent communication research by simulating natural language morphological traits, like inflectional morphology, via small vocabularies and novel metrics.", "motivation": "To bridge the gap between emergent communication in deep neural network-based agents and the complexities of human-like natural language.", "method": "The study explores a variation of the attribute-value reconstruction game by introducing a small vocabulary and experiments reflecting real morphological properties such as concatenativity and fusionality.", "result": "Simulated phonological constraints promoted concatenative morphology, and emergent languages showed natural tendencies towards fusing grammatical attributes.", "conclusion": "The approach bridges emergent communication settings and natural language systems by drawing parallels in morphological characteristics."}}
{"id": "2508.05888", "pdf": "https://arxiv.org/pdf/2508.05888", "abs": "https://arxiv.org/abs/2508.05888", "authors": ["Sahil Bansal", "Sai Shruthi Sistla", "Aarti Arikatala", "Sebastian Schreiber"], "title": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Effective tool retrieval is essential for AI agents to select from a vast\narray of tools when identifying and planning actions in the context of complex\nuser queries. Despite its central role in planning, this aspect remains\nunderexplored in the literature. Traditional approaches rely primarily on\nsimilarities between user queries and tool descriptions, which significantly\nlimits retrieval accuracy, specifically when handling multi-step user requests.\nTo address these limitations, we propose a Knowledge Graph (KG)-based tool\nretrieval framework that captures the semantic relationships between tools and\ntheir functional dependencies. Our retrieval algorithm leverages ensembles of\n1-hop ego tool graphs to model direct and indirect connections between tools,\nenabling more comprehensive and contextual tool selection for multi-step tasks.\nWe evaluate our approach on a synthetically generated internal dataset across\nsix defined user classes, extending previous work on coherent dialogue\nsynthesis and too retrieval benchmarks. Results demonstrate that our tool\ngraph-based method achieves 91.85% tool coverage on the micro-average Complete\nRecall metric, compared to 89.26% for re-ranked semantic-lexical hybrid\nretrieval, the strongest non-KG baseline in our experiments. These findings\nsupport our hypothesis that the structural information in the KG provides\ncomplementary signals to pure similarity matching, particularly for queries\nrequiring sequential tool composition.", "AI": {"tldr": "The paper proposes a Knowledge Graph-based tool retrieval framework to improve AI tool selection accuracy, focusing on multi-step tasks.", "motivation": "Current tool retrieval methods primarily rely on query-to-description similarity, which limits accuracy, especially for multi-step user tasks.", "method": "The authors introduce a Knowledge Graph framework that models tools' semantic relationships and functional dependencies, utilizing 1-hop ego tool graphs for retrieval.", "result": "Their method achieved 91.85% tool coverage in Complete Recall, outperforming traditional semantic-lexical approaches (89.26%).", "conclusion": "The structural information embedded in Knowledge Graphs improves multi-step tool retrieval accuracy, addressing limitations of similarity-based methods."}}
{"id": "2508.05783", "pdf": "https://arxiv.org/pdf/2508.05783", "abs": "https://arxiv.org/abs/2508.05783", "authors": ["Mengyu Li", "Guoyao Shen", "Chad W. Farris", "Xin Zhang"], "title": "Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks", "categories": ["cs.CV", "cs.AI"], "comment": "30 pages, 8 figures, 7 tables", "summary": "Machine learning using transformers has shown great potential in medical\nimaging, but its real-world applicability remains limited due to the scarcity\nof annotated data. In this study, we propose a practical framework for the\nfew-shot deployment of pretrained MRI transformers in diverse brain imaging\ntasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a\nlarge-scale, multi-cohort brain MRI dataset comprising over 31 million slices,\nwe obtain highly transferable latent representations that generalize well\nacross tasks and datasets. For high-level tasks such as classification, a\nfrozen MAE encoder combined with a lightweight linear head achieves\nstate-of-the-art accuracy in MRI sequence identification with minimal\nsupervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a\nhybrid architecture that fuses multiscale CNN features with pretrained MAE\nembeddings. This model consistently outperforms other strong baselines in both\nskull stripping and multi-class anatomical segmentation under data-limited\nconditions. With extensive quantitative and qualitative evaluations, our\nframework demonstrates efficiency, stability, and scalability, suggesting its\nsuitability for low-resource clinical environments and broader neuroimaging\napplications.", "AI": {"tldr": "This study introduces a framework using pretrained MRI transformers for efficient few-shot brain imaging tasks, leveraging Masked Autoencoder (MAE) pretraining on a massive brain MRI dataset.", "motivation": "To address the limited real-world applicability of transformer-based machine learning in medical imaging due to a lack of annotated data.", "method": "The framework uses Masked Autoencoder (MAE) pretraining on a large dataset of over 31 million MRI slices, creating transferable representations. It utilizes a combination of techniques like frozen MAE encoders with linear heads for high-level tasks and a hybrid architecture (MAE-FUnet) for low-level tasks.", "result": "The framework achieves state-of-the-art accuracy in classification tasks and outperforms baselines in segmentation tasks under data-scarce conditions.", "conclusion": "The proposed method is suitable for low-resource clinical environments and broader neuroimaging applications, offering efficiency, stability, and scalability."}}
{"id": "2508.05949", "pdf": "https://arxiv.org/pdf/2508.05949", "abs": "https://arxiv.org/abs/2508.05949", "authors": ["Jialin Yang", "Zainab Saad", "Jiajun Wu", "Xiaoguang Niu", "Henry Leung", "Steve Drew"], "title": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration", "categories": ["cs.SE"], "comment": "Submitted to ACM Computing Surveys", "summary": "The soaring energy demands of large-scale software ecosystems and cloud data\ncenters, accelerated by the intensive training and deployment of large language\nmodels, have driven energy consumption and carbon footprint to unprecedented\nlevels. In response, both industry and academia are increasing efforts to\nreduce the carbon emissions associated with cloud computing through more\nefficient task scheduling and infrastructure orchestration. In this work, we\npresent a systematic review of various Kubernetes scheduling strategies,\ncategorizing them into hardware-centric and software-centric, annotating each\nwith its sustainability objectives, and grouping them according to the\nalgorithms they use. We propose a comprehensive taxonomy for cloud task\nscheduling studies, with a particular focus on the environmental sustainability\naspect. We analyze emerging research trends and open challenges, and our\nfindings provide critical insight into the design of sustainable scheduling\nsolutions for next-generation cloud computing systems.", "AI": {"tldr": "This paper reviews Kubernetes scheduling strategies for addressing energy consumption and carbon emissions in cloud computing, providing a taxonomy and sustainability-focused insights.", "motivation": "The overwhelming energy demands of cloud computing and extensive deployment of large language models have dramatically increased carbon footprints, necessitating efficient solutions.", "method": "The paper systematically reviews Kubernetes scheduling strategies, classifies them into hardware-centric and software-centric approaches, and proposes a taxonomy focusing on sustainability objectives.", "result": "Key research trends and open challenges in sustainable scheduling for cloud systems are analyzed, offering insights to guide future developments.", "conclusion": "Effective scheduling strategies can play a pivotal role in reducing energy demands and carbon emissions, contributing to more sustainable cloud computing systems."}}
{"id": "2508.05836", "pdf": "https://arxiv.org/pdf/2508.05836", "abs": "https://arxiv.org/abs/2508.05836", "authors": ["Rituparna Datta", "Nibir Chandra Mandal"], "title": "An Effective Approach for Node Classification in Textual Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Textual Attribute Graphs (TAGs) are critical for modeling complex networks\nlike citation networks, but effective node classification remains challenging\ndue to difficulties in integrating rich semantics from text with structural\ngraph information. Existing methods often struggle with capturing nuanced\ndomain-specific terminology, modeling long-range dependencies, adapting to\ntemporal evolution, and scaling to massive datasets. To address these issues,\nwe propose a novel framework that integrates TAPE (Text-Attributed Graph\nRepresentation Enhancement) with Graphormer. Our approach leverages a large\nlanguage model (LLM), specifically ChatGPT, within the TAPE framework to\ngenerate semantically rich explanations from paper content, which are then\nfused into enhanced node representations. These embeddings are combined with\nstructural features using a novel integration layer with learned attention\nweights. Graphormer's path-aware position encoding and multi-head attention\nmechanisms are employed to effectively capture long-range dependencies across\nthe citation network. We demonstrate the efficacy of our framework on the\nchallenging ogbn-arxiv dataset, achieving state-of-the-art performance with a\nclassification accuracy of 0.772, significantly surpassing the best GCN\nbaseline of 0.713. Our method also yields strong results in precision (0.671),\nrecall (0.577), and F1-score (0.610). We validate our approach through\ncomprehensive ablation studies that quantify the contribution of each\ncomponent, demonstrating the synergy between semantic and structural\ninformation. Our framework provides a scalable and robust solution for node\nclassification in dynamic TAGs, offering a promising direction for future\nresearch in knowledge systems and scientific discovery.", "AI": {"tldr": "The paper introduces an innovative framework combining TAPE and Graphormer to enhance node classification in Textual Attribute Graphs (TAGs), achieving state-of-the-art results.", "motivation": "Address the challenges in integrating textual semantics with structural graph information for effective node classification in Textual Attribute Graphs.", "method": "Combines TAPE with Graphormer, integrates ChatGPT for semantic enrichment, and utilizes path-aware encoding and multi-head attention for structural analysis.", "result": "Achieved state-of-the-art classification accuracy of 0.772 on the ogbn-arxiv dataset, outperforming existing methods in multiple metrics like precision, recall, and F1-score.", "conclusion": "The proposed framework demonstrates its robustness and scalability for node classification, offering advancements in knowledge systems and scientific discovery."}}
{"id": "2508.05946", "pdf": "https://arxiv.org/pdf/2508.05946", "abs": "https://arxiv.org/abs/2508.05946", "authors": ["Nello Balossino", "Rossana Damiano", "Cristina Gena", "Alberto Lillo", "Anna Maria Marras", "Claudio Mattutino", "Antonio Pizzo", "Alessia Prin", "Fabiana Vernero"], "title": "Social and Telepresence Robots for Accessibility and Inclusion in Small Museums", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "There are still many museums that present accessibility barriers,\nparticularly regarding perceptual, cultural, and cognitive aspects. This is\nespecially evident in low-density population areas. The aim of the ROBSO-PM\nproject is to improve the accessibility of small museums through the use of\nsocial robots and social telepresence robots, focusing on three museums as case\nstudies: the Museum of the Holy Shroud in Turin, a small but globally known\ninstitution, and two lesser known mountain museums: the Museum of the Champlas\ndu Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and\nTraditions. The project explores two main applications for robots: as guides\nsupporting inclusive visits for foreign or disabled visitors, and as\ntelepresence tools allowing people with limited mobility to access museums\nremotely. From a research perspective, key topics include storytelling, robot\npersonality, empathy, personalization, and, in the case of telepresence,\ncollaboration between the robot and the person, with clearly defined roles and\nautonomy.", "AI": {"tldr": "The ROBSO-PM project aims to enhance the accessibility of small museums using social and telepresence robots, focusing on guiding inclusive visits and enabling remote access.", "motivation": "Many museums face accessibility challenges, particularly in lesser-known areas with barriers tied to perception, culture, and cognition.", "method": "The project applies robots as museum guides and telepresence tools, emphasizing inclusivity for foreign and disabled visitors, backed by research on storytelling, empathy, and role definitions.", "result": "Case studies include the use of robots at three specific museums, showcasing improved access for visitors with mobility limitations and inclusive experiences.", "conclusion": "Robots can effectively address accessibility issues in smaller museums, fostering inclusivity and providing remote access opportunities."}}
{"id": "2508.06377", "pdf": "https://arxiv.org/pdf/2508.06377", "abs": "https://arxiv.org/abs/2508.06377", "authors": ["Thomas Michel", "Debabrota Basu", "Emilie Kaufmann"], "title": "DP-SPRT: Differentially Private Sequential Probability Ratio Tests", "categories": ["stat.ML", "cs.CR", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We revisit Wald's celebrated Sequential Probability Ratio Test for sequential\ntests of two simple hypotheses, under privacy constraints. We propose DP-SPRT,\na wrapper that can be calibrated to achieve desired error probabilities and\nprivacy constraints, addressing a significant gap in previous work. DP-SPRT\nrelies on a private mechanism that processes a sequence of queries and stops\nafter privately determining when the query results fall outside a predefined\ninterval. This OutsideInterval mechanism improves upon naive composition of\nexisting techniques like AboveThreshold, potentially benefiting other\nsequential algorithms. We prove generic upper bounds on the error and sample\ncomplexity of DP-SPRT that can accommodate various noise distributions based on\nthe practitioner's privacy needs. We exemplify them in two settings: Laplace\nnoise (pure Differential Privacy) and Gaussian noise (R\\'enyi differential\nprivacy). In the former setting, by providing a lower bound on the sample\ncomplexity of any $\\epsilon$-DP test with prescribed type I and type II errors,\nwe show that DP-SPRT is near optimal when both errors are small and the two\nhypotheses are close. Moreover, we conduct an experimental study revealing its\ngood practical performance.", "AI": {"tldr": "The paper revisits Wald's Sequential Probability Ratio Test (SPRT) under privacy constraints, presenting DP-SPRT, a privacy-preserving and near-optimal method for hypothesis testing.", "motivation": "The existing sequential hypothesis tests lack mechanisms for achieving desired error probabilities while maintaining differential privacy. This study aims to fill this gap.", "method": "The authors propose DP-SPRT, a test relying on a privacy-preserving mechanism called OutsideInterval, which processes sequential queries with noise from privacy settings and halts when query results leave a set interval.", "result": "The paper provides theoretical bounds on error and sample complexity, validates the method for Laplace noise (pure DP) and Gaussian noise (RDP), and demonstrates its near-optimality in specific scenarios. Experiments showcase strong practical performance.", "conclusion": "DP-SPRT is a practically effective and theoretically sound mechanism for sequential hypothesis testing under privacy constraints, with potential for broad applicability."}}
{"id": "2508.06347", "pdf": "https://arxiv.org/pdf/2508.06347", "abs": "https://arxiv.org/abs/2508.06347", "authors": ["Ruiyu Zhang", "Ce Zhao", "Xin Zhao", "Lin Nie", "Wai-Fung Lam"], "title": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "10 pages, 2 figures", "summary": "Learning interpretable latent representations from tabular data remains a\nchallenge in deep generative modeling. We introduce SE-VAE (Structural\nEquation-Variational Autoencoder), a novel architecture that embeds measurement\nstructure directly into the design of a variational autoencoder. Inspired by\nstructural equation modeling, SE-VAE aligns latent subspaces with known\nindicator groupings and introduces a global nuisance latent to isolate\nconstruct-specific confounding variation. This modular architecture enables\ndisentanglement through design rather than through statistical regularizers\nalone. We evaluate SE-VAE on a suite of simulated tabular datasets and\nbenchmark its performance against a series of leading baselines using standard\ndisentanglement metrics. SE-VAE consistently outperforms alternatives in factor\nrecovery, interpretability, and robustness to nuisance variation. Ablation\nresults reveal that architectural structure, rather than regularization\nstrength, is the key driver of performance. SE-VAE offers a principled\nframework for white-box generative modeling in scientific and social domains\nwhere latent constructs are theory-driven and measurement validity is\nessential.", "AI": {"tldr": "SE-VAE introduces architectural design elements to improve latent disentanglement and interpretable representation in tabular data by embedding structural equation modeling principles.", "motivation": "The paper aims to address the challenge of learning interpretable latent representations in tabular data, a known difficulty in deep generative models.", "method": "SE-VAE leverages a structural equation-inspired modular design, embedding measurement structure directly into the variational autoencoder architecture. It includes a global nuisance latent and aligns latent subspaces with known variable groupings.", "result": "Performance evaluations on simulated tabular datasets show SE-VAE outperforms alternative methods in factor recovery, interpretability, and robustness to nuisance variation.", "conclusion": "SE-VAE introduces a principled and modular approach to generative modeling that prioritizes theory-driven latent constructs, offering significant improvements in interpretability and applicability for scientific and social data modeling."}}
{"id": "2508.06339", "pdf": "https://arxiv.org/pdf/2508.06339", "abs": "https://arxiv.org/abs/2508.06339", "authors": ["Evelyne Ringoot", "Rabab Alomairy", "Valentin Churavy", "Alan Edelman"], "title": "Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision", "categories": ["cs.DC", "cs.MS"], "comment": "12 pages, 6 figures, 4 tables", "summary": "This paper presents a portable, GPU-accelerated implementation of a QR-based\nsingular value computation algorithm in Julia. The singular value ecomposition\n(SVD) is a fundamental numerical tool in scientific computing and machine\nlearning, providing optimal low-rank matrix approximations. Its importance has\nincreased even more in large-scale machine learning pipelines, including large\nlanguage models (LLMs), where it enables low-rank adaptation (LoRA). The\nimplemented algorithm is based on the classic two-stage QR reduction,\nconsisting of successive matrix reduction to band form and bidiagonal form. Our\nimplementation leverages Julia's multiple dispatch and metaprogramming\ncapabilities, integrating with the GPUArrays and KernelAbstractions frameworks\nto provide a unified type and hardware-agnostic function. It supports diverse\nGPU architectures and data types, and is, to our knowledge, the first\nGPU-accelerated singular value implementation to support Apple Metal GPUs and\nhalf precision. Performance results on multiple GPU backends and data types\ndemonstrate that portability does not require sacrificing performance: the\nunified function outperforms most linear algebra libraries (MAGMA, SLATE,\nrocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90%\nof the performance of cuSOLVER for large matrices.", "AI": {"tldr": "The paper introduces a GPU-accelerated QR-based singular value decomposition (SVD) algorithm implemented in Julia, excelling in portability and performance.", "motivation": "The paper aims to address the need for a portable and high-performance GPU-accelerated SVD implementation, crucial for tasks like low-rank adaptation in large-scale machine learning systems.", "method": "The algorithm employs a QR reduction approach, integrating Julia's multiple dispatch and metaprogramming with GPUArrays and KernelAbstractions to ensure type and hardware-agnostic functionality across multiple architectures and data types.", "result": "The implementation is compatible with diverse GPU frameworks, including Apple Metal GPUs and half precision, outperforming many existing libraries for matrices larger than 1024x1024, achieving 80%-90% of NVIDIA\u2019s cuSOLVER performance.", "conclusion": "The presented solution demonstrates that efficient and portable GPU-accelerated SVD computation is achievable without sacrificing performance, contributing significantly to both numerical computing and machine learning workflows."}}
{"id": "2508.05880", "pdf": "https://arxiv.org/pdf/2508.05880", "abs": "https://arxiv.org/abs/2508.05880", "authors": ["Sree Bhattacharyya", "Lucas Craig", "Tharun Dilliraj", "Jia Li", "James Z. Wang"], "title": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Affective Computing has been established as a crucial field of inquiry to\nadvance the holistic development of Artificial Intelligence (AI) systems.\nFoundation models -- especially Large Language Models (LLMs) -- have been\nevaluated, trained, or instruction-tuned in several past works, to become\nbetter predictors or generators of emotion. Most of these studies, however,\napproach emotion-related tasks in a supervised manner, assessing or training\nthe capabilities of LLMs using discrete emotion labels associated with stimuli\n(e.g., text, images, video, audio). Evaluation studies, in particular, have\noften been limited to standard and superficial emotion-related tasks, such as\nthe recognition of evoked or expressed emotions. In this paper, we move beyond\nsurface-level emotion tasks to investigate how LLMs reason about emotions\nthrough cognitive dimensions. Drawing from cognitive appraisal theory, we\nexamine whether LLMs produce coherent and plausible cognitive reasoning when\nreasoning about emotionally charged stimuli. We introduce a large-scale\nbenchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal\ncognitive structures implicitly used by LLMs for emotional reasoning. Through a\nplethora of evaluation experiments and analysis, we seek to answer: (a) Are\nmodels more likely to implicitly rely on specific cognitive appraisal\ndimensions?, (b) What cognitive dimensions are important for characterizing\nspecific emotions?, and, (c) Can the internal representations of different\nemotion categories in LLMs be interpreted through cognitive appraisal\ndimensions? Our results and analyses reveal diverse reasoning patterns across\ndifferent LLMs. Our benchmark and code will be made publicly available.", "AI": {"tldr": "This paper introduces a benchmark, CoRE, to evaluate how Large Language Models (LLMs) reason about emotions based on cognitive appraisal theory rather than just performing superficial emotion tasks.", "motivation": "Existing evaluations of LLMs on emotion tasks focus mainly on recognizing or generating emotions based on discrete labels, which fail to address deeper cognitive reasoning about emotions.", "method": "The authors utilize cognitive appraisal theory to assess the emotional reasoning capabilities of LLMs, introducing the CoRE benchmark to measure their internal reasoning patterns.", "result": "Findings indicate that LLMs exhibit varied cognitive reasoning patterns for emotion reasoning, suggesting reliance on specific cognitive dimensions and providing interpretability of emotional representations.", "conclusion": "The study highlights the need for deeper, cognition-driven evaluations of LLMs and makes CoRE a foundational toolkit for assessing emotional reasoning in these models, with benchmark and code publicly available."}}
{"id": "2508.05996", "pdf": "https://arxiv.org/pdf/2508.05996", "abs": "https://arxiv.org/abs/2508.05996", "authors": ["Kaitao Chen", "Mianxin Liu", "Daoming Zong", "Chaoyue Ding", "Shaohao Rui", "Yankai Jiang", "Mu Zhou", "Xiaosong Wang"], "title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making", "categories": ["cs.AI"], "comment": "14 pages, 4 figures", "summary": "Complex medical decision-making involves cooperative workflows operated by\ndifferent clinicians. Designing AI multi-agent systems can expedite and augment\nhuman-level clinical decision-making. Existing multi-agent researches primarily\nfocus on language-only tasks, yet their extension to multimodal scenarios\nremains challenging. A blind combination of diverse vision-language models\n(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are\nless capable in instruction following and importantly self-reflection, compared\nto large language models (LLMs) of comparable sizes. This disparity largely\nconstrains VLMs' ability in cooperative workflows. In this study, we propose\nMedOrch, a mediator-guided multi-agent collaboration framework for medical\nmultimodal decision-making. MedOrch employs an LLM-based mediator agent that\nenables multiple VLM-based expert agents to exchange and reflect on their\noutputs towards collaboration. We utilize multiple open-source general-purpose\nand domain-specific VLMs instead of costly GPT-series models, revealing the\nstrength of heterogeneous models. We show that the collaboration within\ndistinct VLM-based agents can surpass the capabilities of any individual agent.\nWe validate our approach on five medical vision question answering benchmarks,\ndemonstrating superior collaboration performance without model training. Our\nfindings underscore the value of mediator-guided multi-agent collaboration in\nadvancing medical multimodal intelligence. Our code will be made publicly\navailable.", "AI": {"tldr": "The paper proposes MedOrch, a mediator-guided collaboration framework for medical multimodal decision-making using VLM- and LLM-based agents. It enables better performance on medical benchmarks without additional model training.", "motivation": "Medical decision-making is complex and involves cooperative workflows among clinicians. AI multi-agent systems could enhance this process, but existing approaches struggle with multimodal scenarios, especially due to limitations of vision-language models (VLMs) in instruction following and self-reflection.", "method": "The paper introduces MedOrch, a framework using an LLM-based mediator agent to coordinate VLM-based expert agents. This approach focuses on collaboration without requiring model retraining, leveraging open-source general-purpose and domain-specific VLMs.", "result": "MedOrch demonstrates superior performance on five medical vision question answering benchmarks, outperforming the abilities of individual agents and showing the strengths of heterogeneous model collaboration.", "conclusion": "Mediator-guided collaboration among heterogeneous AI agents improves multimodal medical decision-making capabilities, revealing the potential of such systems in advancing medical intelligence."}}
{"id": "2508.05813", "pdf": "https://arxiv.org/pdf/2508.05813", "abs": "https://arxiv.org/abs/2508.05813", "authors": ["Raphael Du Sablon", "David Hart"], "title": "Optimization-Free Style Transfer for 3D Gaussian Splats", "categories": ["cs.CV"], "comment": null, "summary": "The task of style transfer for 3D Gaussian splats has been explored in many\nprevious works, but these require reconstructing or fine-tuning the splat while\nincorporating style information or optimizing a feature extraction network on\nthe splat representation. We propose a reconstruction- and optimization-free\napproach to stylizing 3D Gaussian splats. This is done by generating a graph\nstructure across the implicit surface of the splat representation. A\nfeed-forward, surface-based stylization method is then used and interpolated\nback to the individual splats in the scene. This allows for any style image and\n3D Gaussian splat to be used without any additional training or optimization.\nThis also allows for fast stylization of splats, achieving speeds under 2\nminutes even on consumer-grade hardware. We demonstrate the quality results\nthis approach achieves and compare to other 3D Gaussian splat style transfer\nmethods. Code is publicly available at\nhttps://github.com/davidmhart/FastSplatStyler.", "AI": {"tldr": "This paper introduces a fast approach to 3D Gaussian splat style transfer using a graph-based surface method without needing reconstruction or optimization.", "motivation": "Previous methods for stylizing 3D Gaussian splats required complex reconstruction, fine-tuning, or optimization steps. Simplifying this process while enabling style transfer quickly and on consumer-grade hardware was the goal.", "method": "The method involves generating a graph structure across the implicit surface of the splat representation, applying a feed-forward surface-based stylization, and interpolating the stylization back to individual splats.", "result": "The proposed approach achieves rapid style transfer under 2 minutes, even on consumer-grade hardware, producing quality results comparable to existing methods.", "conclusion": "The approach successfully simplifies the process of 3D Gaussian splat stylization while maintaining high-quality results, making it accessible and efficient."}}
{"id": "2508.05970", "pdf": "https://arxiv.org/pdf/2508.05970", "abs": "https://arxiv.org/abs/2508.05970", "authors": ["Yanzhou Li", "Shangqing Liu", "Kangjie Chen", "Tianwei Zhang", "Yang Liu"], "title": "Impact-driven Context Filtering For Cross-file Code Completion", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has recently demonstrated considerable\npotential for repository-level code completion, as it integrates cross-file\nknowledge with in-file preceding code to provide comprehensive contexts for\ngeneration. To better understand the contribution of the retrieved cross-file\ncontexts, we introduce a likelihood-based metric to evaluate the impact of each\nretrieved code chunk on the completion. Our analysis reveals that, despite\nretrieving numerous chunks, only a small subset positively contributes to the\ncompletion, while some chunks even degrade performance. To address this issue,\nwe leverage this metric to construct a repository-level dataset where each\nretrieved chunk is labeled as positive, neutral, or negative based on its\nrelevance to the target completion. We then propose an adaptive retrieval\ncontext filtering framework, CODEFILTER, trained on this dataset to mitigate\nthe harmful effects of negative retrieved contexts in code completion.\nExtensive evaluation on the RepoEval and CrossCodeLongEval benchmarks\ndemonstrates that CODEFILTER consistently improves completion accuracy compared\nto approaches without filtering operations across various tasks. Additionally,\nCODEFILTER significantly reduces the length of the input prompt, enhancing\ncomputational efficiency while exhibiting strong generalizability across\ndifferent models. These results underscore the potential of CODEFILTER to\nenhance the accuracy, efficiency, and attributability of repository-level code\ncompletion.", "AI": {"tldr": "The paper addresses the issue of irrelevant or harmful retrieved contexts in repository-level code completion, introducing CODEFILTER to improve accuracy and efficiency.", "motivation": "Existing retrieval-augmented generation (RAG) techniques for code completion sometimes utilize irrelevant or detrimental cross-file contexts, impacting the quality of code completions.", "method": "The authors propose CODEFILTER, a retrieval context filtering framework trained on a custom-labeled dataset to classify retrieved code chunks as positive, neutral, or negative, filtering out harmful ones during generation.", "result": "CODEFILTER improves code completion accuracy, reduces input prompt length, and shows strong generalizability across tasks and models, validated on benchmarks like RepoEval and CrossCodeLongEval.", "conclusion": "The proposed CODEFILTER framework enhances repository-level code completion by improving accuracy, computational efficiency, and precision through adaptive filtering of retrieved contexts."}}
{"id": "2508.05876", "pdf": "https://arxiv.org/pdf/2508.05876", "abs": "https://arxiv.org/abs/2508.05876", "authors": ["Francesca Ferrara", "Lander W. Schillinger Arana", "Florian D\u00f6rfler", "Sarah H. Q. Li"], "title": "A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance", "categories": ["cs.LG", "astro-ph.EP", "astro-ph.IM", "cs.ET"], "comment": "16 pages, 13 figures, submitted to the 2025 Astrodynamics Specialist\n  Conference", "summary": "This work presents a Markov decision process (MDP) framework to model\ndecision-making for collision avoidance maneuver (CAM) and a reinforcement\nlearning policy gradient (RL-PG) algorithm to train an autonomous guidance\npolicy using historic CAM data. In addition to maintaining acceptable collision\nrisks, this approach seeks to minimize the average fuel consumption of CAMs by\nmaking early maneuver decisions. We model CAM as a continuous state, discrete\naction and finite horizon MDP, where the critical decision is determining when\nto initiate the maneuver. The MDP model also incorporates analytical models for\nconjunction risk, propellant consumption, and transit orbit geometry. The\nMarkov policy effectively trades-off maneuver delay-which improves the\nreliability of conjunction risk indicators-with propellant consumption-which\nincreases with decreasing maneuver time. Using historical data of tracked\nconjunction events, we verify this framework and conduct an extensive ablation\nstudy on the hyper-parameters used within the MDP. On synthetic conjunction\nevents, the trained policy significantly minimizes both the overall and average\npropellant consumption per CAM when compared to a conventional cut-off policy\nthat initiates maneuvers 24 hours before the time of closest approach (TCA). On\nhistorical conjunction events, the trained policy consumes more propellant\noverall but reduces the average propellant consumption per CAM. For both\nhistorical and synthetic conjunction events, the trained policy achieves equal\nif not higher overall collision risk guarantees.", "AI": {"tldr": "The paper develops a Markov decision process framework for collision avoidance maneuvers optimized for fuel economy and decision timing using reinforcement learning.", "motivation": "To improve collision avoidance strategies by minimizing propellant consumption and ensuring acceptable collision risks using decision-making models.", "method": "Continuous-state, discrete-action MDP model combined with reinforcement learning policy gradient. Verified with historical data and ablation studies on hyperparameters.", "result": "The trained policy outperforms conventional policies in fuel efficiency across synthetic and historical conjunction events while maintaining collision risk guarantees.", "conclusion": "Reinforcement-learning-based CAM policies offer a balanced approach to minimize propellant use and address collision risks effectively."}}
{"id": "2508.05972", "pdf": "https://arxiv.org/pdf/2508.05972", "abs": "https://arxiv.org/abs/2508.05972", "authors": ["Shaoting Liu", "Zhou Liu"], "title": "Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles", "categories": ["cs.RO"], "comment": null, "summary": "Air-land bimodal vehicles provide a promising solution for navigating complex\nenvironments by combining the flexibility of aerial locomotion with the energy\nefficiency of ground mobility. To enhance the robustness of trajectory planning\nunder environmental disturbances, this paper presents a disturbance-aware\nplanning framework that incorporates real-time disturbance estimation into both\npath searching and trajectory optimization. A key component of the framework is\na disturbance-adaptive safety boundary adjustment mechanism, which dynamically\nmodifies the vehicle's feasible dynamic boundaries based on estimated\ndisturbances to ensure trajectory feasibility. Leveraging the dynamics model of\nthe bimodal vehicle, the proposed approach achieves adaptive and reliable\nmotion planning across different terrains and operating conditions. A series of\nreal-world experiments and benchmark comparisons on a custom-built platform\nvalidate the effectiveness and robustness of the method, demonstrating\nimprovements in tracking accuracy, task efficiency, and energy performance\nunder both ground and aerial disturbances.", "AI": {"tldr": "This paper proposes a planning framework for air-land vehicles to improve trajectory robustness by estimating and adapting to environmental disturbances.", "motivation": "Enhance trajectory robustness of air-land bimodal vehicles under environmental disturbances, utilizing the advantages of aerial and ground-based locomotion.", "method": "Developed a disturbance-aware planning framework that integrates real-time disturbance estimation, dynamic safety boundary adjustments, and a dynamics model for adaptive trajectory optimization.", "result": "The method exhibited improved tracking accuracy, task efficiency, and energy performance in real-world tests and benchmark comparisons.", "conclusion": "The proposed approach ensures feasible, adaptive, and robust motion planning for air-land vehicles across diverse environments."}}
{"id": "2508.06406", "pdf": "https://arxiv.org/pdf/2508.06406", "abs": "https://arxiv.org/abs/2508.06406", "authors": ["Murtaza Rangwala", "Venugopal K R", "Rajkumar Buyya"], "title": "Blockchain-Enabled Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": "32 pages, 6 figures, chapter for edited book (Federated Learning:\n  Foundations and Applications)", "summary": "Blockchain-enabled federated learning (BCFL) addresses fundamental challenges\nof trust, privacy, and coordination in collaborative AI systems. This chapter\nprovides comprehensive architectural analysis of BCFL systems through a\nsystematic four-dimensional taxonomy examining coordination structures,\nconsensus mechanisms, storage architectures, and trust models. We analyze\ndesign patterns from blockchain-verified centralized coordination to fully\ndecentralized peer-to-peer networks, evaluating trade-offs in scalability,\nsecurity, and performance. Through detailed examination of consensus mechanisms\ndesigned for federated learning contexts, including Proof of Quality and Proof\nof Federated Learning, we demonstrate how computational work can be repurposed\nfrom arbitrary cryptographic puzzles to productive machine learning tasks. The\nchapter addresses critical storage challenges by examining multi-tier\narchitectures that balance blockchain's transaction constraints with neural\nnetworks' large parameter requirements while maintaining cryptographic\nintegrity. A technical case study of the TrustMesh framework illustrates\npractical implementation considerations in BCFL systems through distributed\nimage classification training, demonstrating effective collaborative learning\nacross IoT devices with highly non-IID data distributions while maintaining\ncomplete transparency and fault tolerance. Analysis of real-world deployments\nacross healthcare consortiums, financial services, and IoT security\napplications validates the practical viability of BCFL systems, achieving\nperformance comparable to centralized approaches while providing enhanced\nsecurity guarantees and enabling new models of trustless collaborative\nintelligence.", "AI": {"tldr": "The paper analyzes blockchain-enabled federated learning (BCFL) systems, providing a taxonomy and case study, and validates their practical viability in real-world applications.", "motivation": "To address challenges of trust, privacy, and coordination in collaborative AI systems through blockchain-enabled federated learning.", "method": "The paper presents a four-dimensional taxonomy to analyze BCFL systems, detailed consensus mechanisms, multi-tier storage architectures, and a technical case study of the TrustMesh framework.", "result": "The study demonstrates scalable, secure, and fault-tolerant BCFL systems with effective collaborative learning across non-IID data and real-world applicability in healthcare, finance, and IoT.", "conclusion": "BCFL systems can achieve centralized system-like performance while offering enhanced security and enabling trustless collaborative AI models."}}
{"id": "2508.05909", "pdf": "https://arxiv.org/pdf/2508.05909", "abs": "https://arxiv.org/abs/2508.05909", "authors": ["Zhanghao Hu", "Qinglin Zhu", "Siya Qi", "Yulan He", "Hanqi Yan", "Lin Gui"], "title": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown improved generation performance\nthrough retrieval-augmented generation (RAG) following the retriever-reader\nparadigm, which supplements model inputs with externally retrieved knowledge.\nHowever, prior work often evaluates RAG holistically, assessing the retriever\nand reader jointly, making it difficult to isolate the true contribution of\nretrieval, particularly given the prompt sensitivity of LLMs used as readers.\nWe introduce Spectrum Projection Score (SPS), a lightweight, supervision-free\nmetric that allows the reader to gauge the semantic alignment of a retrieved\nsummary with its hidden representation by comparing the area formed by\ngenerated tokens from the summary, and the principal directions of subspace in\nthe reader and to measure the relevance. Building on SPS we present xCompress,\nan inference time controller framework that dynamically samples, ranks, and\ncompresses retrieval summary candidates. Extensive experiments on five QA\nbenchmarks with four open source LLMs show that SPS not only enhances\nperformance across a range of tasks but also provides a principled perspective\non the interaction between retrieval and generation.", "AI": {"tldr": "The paper introduces a lightweight, supervision-free metric called Spectrum Projection Score (SPS) to assess the semantic alignment of retrieved summaries in retrieval-augmented generation. It also proposes xCompress, a framework optimizing retrieval at inference time, demonstrating performance improvements across QA benchmarks.", "motivation": "To enhance the evaluation of retrieval effectiveness in retrieval-augmented generation (RAG) and address the challenge of isolating retrieval contributions from generation, especially given the prompt sensitivity of large language models.", "method": "The authors introduce SPS, which compares semantic alignment via the area of generated tokens and principal directions of the reader's hidden representation. Using SPS, they develop xCompress, which dynamically samples, ranks, and compresses retrieved summaries during inference.", "result": "Experiments on five QA benchmarks with four open-source LLMs show that SPS and xCompress improve performance across tasks, providing useful insights into retrieval-generation interaction.", "conclusion": "The study offers a novel metric (SPS) and inference framework (xCompress) that effectively improve retrieval-augmented generation while deepening the understanding of retrieval-generation dynamics."}}
{"id": "2508.06042", "pdf": "https://arxiv.org/pdf/2508.06042", "abs": "https://arxiv.org/abs/2508.06042", "authors": ["Daechul Ahn", "San Kim", "Jonghyun Choi"], "title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning", "categories": ["cs.AI"], "comment": "COLM 2025", "summary": "Large Language Models (LLMs) have recently demonstrated impressive action\nsequence prediction capabilities but often struggle with dynamic, long-horizon\ntasks such as real-time strategic games. In a game such as StarCraftII (SC2),\nagents need to manage resource constraints and adapt to evolving battlefield\nsituations in a partially observable environment. This often overwhelms\nexisiting LLM-based approaches. To address these challenges, we propose a\nhierarchical multi-agent framework that employs specialized imitation learning\nagents under a meta-controller called Strategic Planner (SP). By expert\ndemonstrations, each specialized agent learns a distinctive strategy, such as\naerial support or defensive maneuvers, and produces coherent, structured\nmultistep action sequences. The SP then orchestrates these proposals into a\nsingle, environmentally adaptive plan that ensures local decisions aligning\nwith long-term strategies. We call this HIMA (Hierarchical Imitation\nMulti-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that\nencompasses all race match combinations in SC2. Our empirical results show that\nHIMA outperforms state of the arts in strategic clarity, adaptability, and\ncomputational efficiency, underscoring the potential of combining specialized\nimitation modules with meta-level orchestration to develop more robust,\ngeneral-purpose AI agents.", "AI": {"tldr": "The paper introduces a hierarchical multi-agent framework (HIMA) using specialized imitation learning agents orchestrated by a Strategic Planner (SP) to address challenges in dynamic, long-horizon tasks like playing StarCraft II.", "motivation": "Traditional LLMs struggle with the complexity, partial observability, and dynamic planning required for tasks such as real-time strategy games.", "method": "The proposed method employs a hierarchical system wherein specialized imitation agents are trained on expert demonstrations for specific strategies. A meta-controller (SP) then integrates these specialized outputs into adaptive, long-term plans.", "result": "The hierarchical framework, named HIMA, outperforms existing methods in strategic clarity, adaptability, and computational efficiency in the newly introduced TEXTSCII-ALL testbed for StarCraft II.", "conclusion": "Specialized imitation modules combined with a high-level orchestrator can significantly enhance the adaptability and performance of AI agents in dynamic, complex tasks."}}
{"id": "2508.05819", "pdf": "https://arxiv.org/pdf/2508.05819", "abs": "https://arxiv.org/abs/2508.05819", "authors": ["Jong-Ik Park", "Carlee Joe-Wong", "Gary K. Fedder"], "title": "MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses", "categories": ["cs.CV"], "comment": null, "summary": "Neural Radiance Fields (NeRF) methods excel at 3D reconstruction from\nmultiple 2D images, even those taken with unknown camera poses. However, they\nstill miss the fine-detailed structures that matter in industrial inspection,\ne.g., detecting sub-micron defects on a production line or analyzing chips with\nScanning Electron Microscopy (SEM). In these scenarios, the sensor resolution\nis fixed and compute budgets are tight, so the only way to expose fine\nstructure is to add zoom-in images; yet, this breaks the multi-view consistency\nthat pose-free NeRF training relies on. We propose Multi-Zoom Enhanced NeRF\n(MZEN), the first NeRF framework that natively handles multi-zoom image sets.\nMZEN (i) augments the pin-hole camera model with an explicit, learnable zoom\nscalar that scales the focal length, and (ii) introduces a novel pose strategy:\nwide-field images are solved first to establish a global metric frame, and\nzoom-in images are then pose-primed to the nearest wide-field counterpart via a\nzoom-consistent crop-and-match procedure before joint refinement. Across eight\nforward-facing scenes$\\unicode{x2013}$synthetic TCAD models, real SEM of\nmicro-structures, and BLEFF objects$\\unicode{x2013}$MZEN consistently\noutperforms pose-free baselines and even high-resolution variants, boosting\nPSNR by up to $28 \\%$, SSIM by $10 \\%$, and reducing LPIPS by up to $222 \\%$.\nMZEN, therefore, extends NeRF to real-world factory settings, preserving global\naccuracy while capturing the micron-level details essential for industrial\ninspection.", "AI": {"tldr": "NeRF struggles with fine details in industrial contexts like sub-micron defect detection due to fixed sensor resolution. MZEN addresses this by incorporating multi-zoom image sets and achieves superior accuracy.", "motivation": "Industrial inspection requires accurate 3D reconstruction to detect fine structures, such as sub-micron defects, which traditional NeRF fails to capture due to fixed sensor resolution.", "method": "MZEN introduces a learnable zoom scalar to scale focal lengths and employs a pose strategy that solves wide-field images first and then refines zoom-in images using a zoom-consistent procedure.", "result": "MZEN outperforms baselines, boosting metrics like PSNR by 28%, SSIM by 10%, and reducing LPIPS by 222%, across diverse scenes including synthetic models and real-world SEM data.", "conclusion": "MZEN makes NeRF applicable in factory settings by preserving global 3D accuracy while capturing micron-level details critical for industrial inspection."}}
{"id": "2508.06017", "pdf": "https://arxiv.org/pdf/2508.06017", "abs": "https://arxiv.org/abs/2508.06017", "authors": ["Xiangzhe Xu", "Shiwei Feng", "Zian Su", "Chengpeng Wang", "Xiangyu Zhang"], "title": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "The first two authors contributed equally to this work", "summary": "Intelligent coding systems are transforming software development by enabling\nusers to specify code behavior in natural language. However, the opaque\ndecision-making of AI-driven coders raises trust and usability concerns,\nparticularly for non-expert users who cannot inspect low-level implementations.\nWe argue that these systems should not only generate code but also produce\nclear, consistent justifications that bridge model reasoning and user\nunderstanding. To this end, we identify two critical justification\nproperties-cognitive alignment and semantic faithfulness-and highlight the\nlimitations of existing methods, including formal verification, static\nanalysis, and post-hoc explainability. We advocate exploring neuro-symbolic\napproaches for justification generation, where symbolic constraints guide model\nbehavior during training and program semantics are enriched through neural\nrepresentations, enabling automated consistency checks at inference time.", "AI": {"tldr": "The paper discusses enhancing AI coding systems by focusing on generating clear and meaningful justifications for code suggestions.", "motivation": "The motivation is to address trust and usability concerns stemming from the opaque decision-making of AI coding systems, particularly for non-expert users.", "method": "The proposed method suggests adopting neuro-symbolic approaches, incorporating symbolic constraints during training and enriching program semantics with neural representations to generate justifications.", "result": "The authors identify two critical properties for justifications: cognitive alignment and semantic faithfulness, and critique existing approaches like formal verification and post-hoc explainability.", "conclusion": "The paper concludes that integrating neuro-symbolic methods could enhance the trust, usability, and comprehensibility of AI-driven coding systems."}}
{"id": "2508.05905", "pdf": "https://arxiv.org/pdf/2508.05905", "abs": "https://arxiv.org/abs/2508.05905", "authors": ["Jeffrey Uhlmann"], "title": "The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)", "categories": ["cs.LG"], "comment": null, "summary": "Quantization is usually regarded as a means to trade quality of performance\nfor reduced compute requirements, i.e., as a suboptimal approximation. However,\nif examined in terms of a fixed overall resource budget, a very different\nperspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit\nquantization that deterministically provides gradient information with no\nforward-path penalty. Our analysis provides evidence that it may improve\ninformation density compared to non-quantized alternatives.", "AI": {"tldr": "The paper introduces a 2-bit quantization method called Signed-Zero Ternary (SZT) that claims to improve gradient representation without computational drawbacks.", "motivation": "To challenge the traditional view that quantization sacrifices quality for reduced compute requirements and explore its potential to enhance information density within fixed resource budgets.", "method": "The authors propose a deterministic 2-bit quantization method, Signed-Zero Ternary (SZT), that encodes gradient information effectively without incurring any forward-path computational penalties.", "result": "The analysis suggests that SZT improves information density when compared to non-quantized options.", "conclusion": "SZT quantization may serve as a resource-efficient technique that enhances gradient representation without sacrificing performance in systems constrained by fixed budgets."}}
{"id": "2508.06053", "pdf": "https://arxiv.org/pdf/2508.06053", "abs": "https://arxiv.org/abs/2508.06053", "authors": ["Kaixuan Wu", "Yuanzhuo Xu", "Zejun Zhang", "Weiping Zhu", "Steve Drew", "Xiaoguang Niu"], "title": "ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference", "categories": ["cs.RO"], "comment": null, "summary": "Pedestrian inertial localization is key for mobile and IoT services because\nit provides infrastructure-free positioning. Yet most learning-based methods\ndepend on fixed sliding-window integration, struggle to adapt to diverse motion\nscales and cadences, and yield inconsistent uncertainty, limiting real-world\nuse. We present ReNiL, a Bayesian deep-learning framework for accurate,\nefficient, and uncertainty-aware pedestrian localization. ReNiL introduces\nInertial Positioning Demand Points (IPDPs) to estimate motion at contextually\nmeaningful waypoints instead of dense tracking, and supports inference on IMU\nsequences at any scale so cadence can match application needs. It couples a\nmotion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a\ndual-task network that blends patch-based self-supervision with Bayesian\nregression. By modeling displacements with a Laplace distribution, ReNiL\nprovides homogeneous Euclidean uncertainty that integrates cleanly with other\nsensors. A Bayesian inference chain links successive IPDPs into consistent\ntrajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor\nmotion from 28 participants, ReNiL achieves state-of-the-art displacement\naccuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN\nvariants while reducing computation. Application studies further show\nrobustness and practicality for mobile and IoT localization, making ReNiL a\nscalable, uncertainty-aware foundation for next-generation positioning.", "AI": {"tldr": "The paper introduces ReNiL, a Bayesian deep learning framework for accurate and uncertainty-aware pedestrian inertial localization, outperforming existing methods with reduced computation and improved practicality.", "motivation": "Pedestrian inertial localization provides infrastructure-free positioning crucial for mobile and IoT services, yet existing approaches struggle with adaptability to diverse motion cadences, scales, and consistent uncertainty.", "method": "ReNiL uses Inertial Positioning Demand Points (IPDPs) for waypoint-based motion estimation, integrates a motion-aware orientation filter, and employs an Any-Scale Laplace Estimator (ASLE) to model displacement with homogeneous Euclidean uncertainty.", "result": "ReNiL delivers state-of-the-art displacement accuracy and consistent uncertainty on datasets like RoNIN-ds and WUDataset, outperforming other methods (TLIO, CTIN, iMoT, RoNIN variants) while reducing computational cost.", "conclusion": "ReNiL offers a robust and scalable solution for pedestrian localization in mobile and IoT contexts, supporting uncertainty-aware and efficient positioning systems."}}
{"id": "2508.05706", "pdf": "https://arxiv.org/pdf/2508.05706", "abs": "https://arxiv.org/abs/2508.05706", "authors": ["Hyunwoong Chang", "Jaehoan Kim"], "title": "Identifiability of the minimum-trace directed acyclic graph and hill climbing algorithms without strict local optima under weakly increasing error variances", "categories": ["stat.CO", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "We prove that the true underlying directed acyclic graph (DAG) in Gaussian\nlinear structural equation models is identifiable as the minimum-trace DAG when\nthe error variances are weakly increasing with respect to the true causal\nordering. This result bridges two existing frameworks as it extends the\nidentifiable cases within the minimum-trace DAG method and provides a\nprincipled interpretation of the algorithmic ordering search approach,\nrevealing that its objective is actually to minimize the total residual sum of\nsquares. On the computational side, we prove that the hill climbing algorithm\nwith a random-to-random (R2R) neighborhood does not admit any strict local\noptima. Under standard settings, we confirm the result through extensive\nsimulations, observing only a few weak local optima. Interestingly, algorithms\nusing other neighborhoods of equal size exhibit suboptimal behavior, having\nstrict local optima and a substantial number of weak local optima.", "AI": {"tldr": "The paper establishes the identifiability of true DAGs in Gaussian linear models and enhances algorithmic understanding, while presenting computational insights about neighborhood search methods.", "motivation": "To address identifiability issues in Gaussian linear structural equation models and connect existing frameworks with computational insights.", "method": "By proving minimum-trace DAG identifiability under weakly increasing error variances and analyzing algorithmic behavior using hill climbing with R2R neighborhoods.", "result": "True DAGs are identifiable with the proposed approach, and R2R neighborhoods avoid strict local optima, outperforming other neighborhood search methods in simulations.", "conclusion": "The method links theory and computation, emphasizing minimum-trace DAGs, and offers a robust approach using R2R neighborhoods in causal discovery."}}
{"id": "2508.06301", "pdf": "https://arxiv.org/pdf/2508.06301", "abs": "https://arxiv.org/abs/2508.06301", "authors": ["Junhyeog Yun", "Minui Hong", "Gunhee Kim"], "title": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "comment": "ICCV 2025", "summary": "Neural fields provide a memory-efficient representation of data, which can\neffectively handle diverse modalities and large-scale data. However, learning\nto map neural fields often requires large amounts of training data and\ncomputations, which can be limited to resource-constrained edge devices. One\napproach to tackle this limitation is to leverage Federated Meta-Learning\n(FML), but traditional FML approaches suffer from privacy leakage. To address\nthese issues, we introduce a novel FML approach called FedMeNF. FedMeNF\nutilizes a new privacy-preserving loss function that regulates privacy leakage\nin the local meta-optimization. This enables the local meta-learner to optimize\nquickly and efficiently without retaining the client's private data. Our\nexperiments demonstrate that FedMeNF achieves fast optimization speed and\nrobust reconstruction performance, even with few-shot or non-IID data across\ndiverse data modalities, while preserving client data privacy.", "AI": {"tldr": "FedMeNF introduces a privacy-preserving Federated Meta-Learning approach to efficiently optimize neural fields while safeguarding client data.", "motivation": "To address computational and data constraints on edge devices while ensuring privacy in Federated Meta-Learning approaches.", "method": "A novel Federated Meta-Learning technique incorporating a privacy-preserving loss function for local optimizations without accessing client data.", "result": "FedMeNF achieves robust reconstruction and fast optimization across diverse modalities under non-IID and few-shot scenarios.", "conclusion": "FedMeNF effectively balances privacy preservation, optimization efficiency, and performance in neural field learning across diverse conditions."}}
{"id": "2508.05938", "pdf": "https://arxiv.org/pdf/2508.05938", "abs": "https://arxiv.org/abs/2508.05938", "authors": ["Rafal Kocielnik", "Min Kim", "Penphob", "Boonyarungsrit", "Fereshteh Soltani", "Deshawn Sambrano", "Animashree Anandkumar", "R. Michael Alvarez"], "title": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; K.4"], "comment": "9 pages, 4 figures, 4 tables", "summary": "Detecting prosociality in text--communication intended to affirm, support, or\nimprove others' behavior--is a novel and increasingly important challenge for\ntrust and safety systems. Unlike toxic content detection, prosociality lacks\nwell-established definitions and labeled data, requiring new approaches to both\nannotation and deployment. We present a practical, three-stage pipeline that\nenables scalable, high-precision prosocial content classification while\nminimizing human labeling effort and inference costs. First, we identify the\nbest LLM-based labeling strategy using a small seed set of human-labeled\nexamples. We then introduce a human-AI refinement loop, where annotators review\nhigh-disagreement cases between GPT-4 and humans to iteratively clarify and\nexpand the task definition-a critical step for emerging annotation tasks like\nprosociality. This process results in improved label quality and definition\nalignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train\na two-stage inference system: a lightweight classifier handles high-confidence\npredictions, while only $\\sim$35\\% of ambiguous instances are escalated to\nGPT-4o. This architecture reduces inference costs by $\\sim$70% while achieving\nhigh precision ($\\sim$0.90). Our pipeline demonstrates how targeted human-AI\ninteraction, careful task formulation, and deployment-aware architecture design\ncan unlock scalable solutions for novel responsible AI tasks.", "AI": {"tldr": "The paper introduces a three-stage pipeline to classify prosocial text with high precision and minimal labeling and inference costs.", "motivation": "There is a need for identifying and classifying prosocial text content, which supports or improves others' behavior, due to its significance in trust and safety systems\u2014but there is a lack of established definitions and datasets for this task.", "method": "The authors propose a practical pipeline involving: (1) determining effective LLM-based labeling using a small human-labeled dataset, (2) employing a human-AI refinement loop to improve annotation definitions and label quality, and (3) generating 10k high-quality labels with GPT-4 to train a two-stage model for efficient classification.", "result": "The resulting system reduces inference costs by approximately 70%, ensures scalable implementation, and achieves high precision (~0.90).", "conclusion": "The study demonstrates the effectiveness of combining human-AI interaction, thoughtful task design, and cost-efficient architecture to handle emerging classification tasks such as prosociality detection."}}
{"id": "2508.06060", "pdf": "https://arxiv.org/pdf/2508.06060", "abs": "https://arxiv.org/abs/2508.06060", "authors": ["Sankarshan Damle", "Boi Faltings"], "title": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences", "categories": ["cs.AI"], "comment": "Published in the Proceedings of the 28th European Conference on\n  Artificial Intelligence (ECAI 2025)", "summary": "Large Language Models (LLMs) are increasingly expected to handle complex\ndecision-making tasks, yet their ability to perform structured resource\nallocation remains underexplored. Evaluating their reasoning is also difficult\ndue to data contamination and the static nature of existing benchmarks. We\npresent a dual-purpose framework leveraging Participatory Budgeting (PB) both\nas (i) a practical setting for LLM-based resource allocation and (ii) an\nadaptive benchmark for evaluating their reasoning capabilities. We task LLMs\nwith selecting project subsets under feasibility (e.g., budget) constraints via\nthree prompting strategies: greedy selection, direct optimization, and a\nhill-climbing-inspired refinement. We benchmark LLMs' allocations against a\nutility-maximizing oracle. Interestingly, we also test whether LLMs can infer\nstructured preferences from natural-language voter input or metadata, without\nexplicit votes. By comparing allocations based on inferred preferences to those\nfrom ground-truth votes, we evaluate LLMs' ability to extract preferences from\nopen-ended input. Our results underscore the role of prompt design and show\nthat LLMs hold promise for mechanism design with unstructured inputs.", "AI": {"tldr": "This paper explores the use of large language models (LLMs) for resource allocation tasks, introducing a dual-purpose framework based on Participatory Budgeting (PB) for both practical application and evaluation of reasoning capabilities.", "motivation": "The motivation is to address the growing expectation for LLMs to handle complex decision-making tasks, such as structured resource allocation, and the challenges in evaluating their reasoning due to data issues and static benchmarks.", "method": "The authors use Participatory Budgeting (PB) as a framework and propose three prompting strategies\u2014greedy selection, direct optimization, and hill-climbing-inspired refinement. They also test LLMs' ability to infer structured preferences from natural language input.", "result": "The study finds that prompt design plays a significant role in LLM performance. LLMs show promise in allocating resources under constraints, as well as inferring preferences from unstructured inputs like metadata or natural language.", "conclusion": "LLMs have potential in mechanism design for resource allocation tasks, especially when dealing with unstructured or open-ended inputs. The findings emphasize the importance of prompt strategies in enhancing their capabilities."}}
{"id": "2508.05829", "pdf": "https://arxiv.org/pdf/2508.05829", "abs": "https://arxiv.org/abs/2508.05829", "authors": ["Guoping Xu", "Hua-Chieh Shao", "You Zhang"], "title": "TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios", "categories": ["cs.CV"], "comment": "23 pages, 5 figures", "summary": "Promptable video object segmentation and tracking (VOST) has seen significant\nadvances with the emergence of foundation models like Segment Anything Model 2\n(SAM2); however, their application in surgical video analysis remains\nchallenging due to complex motion dynamics and the redundancy of memory that\nimpedes effective learning. In this work, we propose TSMS-SAM2, a novel\nframework that enhances promptable VOST in surgical videos by addressing\nchallenges of rapid object motion and memory redundancy in SAM2. TSMS-SAM2\nintroduces two key strategies: multi-temporal-scale video sampling augmentation\nto improve robustness against motion variability, and a memory splitting and\npruning mechanism that organizes and filters past frame features for more\nefficient and accurate segmentation. Evaluated on EndoVis2017 and EndoVis2018\ndatasets, TSMS-SAM2 achieved the highest mean Dice scores of 95.24 and 86.73,\nrespectively, outperforming prior SAM-based and task-specific methods.\nExtensive ablation studies confirm the effectiveness of multiscale temporal\naugmentation and memory splitting, highlighting the framework's potential for\nrobust, efficient segmentation in complex surgical scenarios. Our source code\nwill be available at https://github.com/apple1986/TSMS-SAM2.", "AI": {"tldr": "The paper presents TSMS-SAM2, a novel framework designed for video object segmentation and tracking (VOST) in surgical videos, improving motion robustness and memory efficiency.", "motivation": "To address challenges in applying foundation models like SAM to surgical videos due to rapid object motion and memory redundancy during segmentation.", "method": "The framework introduces multi-temporal-scale video sampling for motion variability and a memory mechanism to filter and organize past frame features for efficient segmentation.", "result": "TSMS-SAM2 achieved the highest Dice scores of 95.24 and 86.73 on EndoVis2017 and EndoVis2018 datasets, outperforming previous methods.", "conclusion": "TSMS-SAM2 is effective in improving segmentation robustness and efficiency in challenging surgical video scenarios, with code availability announced for reproducibility."}}
{"id": "2508.06192", "pdf": "https://arxiv.org/pdf/2508.06192", "abs": "https://arxiv.org/abs/2508.06192", "authors": ["Lantian Li", "Yuyu Chen", "Jingwen Wu", "Yue Pan", "Zhongxing Yu"], "title": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts", "categories": ["cs.SE"], "comment": "31 pages, 11 figures", "summary": "Smart contracts enable contract terms to be automatically executed and\nverified on the blockchain, and recent years have witnessed numerous\napplications of them in areas such as financial institutions and supply chains.\nThe execution logic of a smart contract is closely related to the contract\nstate, and thus the correct and safe execution of the contract depends heavily\non the precise control and update of the contract state. However, the contract\nstate update process can have issues. In particular, inconsistent state update\nissues can arise for reasons such as unsynchronized modifications. Inconsistent\nstate update bugs have been exploited by attackers many times, but existing\ndetection tools still have difficulty in effectively identifying them. This\npaper conducts the first large-scale empirical study about inconsistent state\nupdate vulnerabilities (that is, inconsistent state update bugs that are\nexploitable) in smart contracts, aiming to shed light for developers,\nresearchers, tool builders, and language or library designers in order to avoid\ninconsistent state update vulnerabilities. We systematically investigate 116\ninconsistent state update vulnerabilities in 352 real-world smart contract\nprojects, summarizing their root causes, fix strategies, and exploitation\nmethods. Our study provides 11 original and important findings, and we also\ngive the implications of our findings. To illustrate the potential benefits of\nour research, we also develop a proof-of-concept checker based on one of our\nfindings. The checker effectively detects issues in 64 popular GitHub projects,\nand 19 project owners have confirmed the detected issues at the time of\nwriting. The result demonstrates the usefulness and importance of our findings\nfor avoiding inconsistent state update vulnerabilities in smart contracts.", "AI": {"tldr": "This paper presents the first large-scale study on inconsistent state update vulnerabilities in smart contracts. It identifies root causes, fixes, and exploitation methods, offering findings and developed a detection tool successfully applied to GitHub projects.", "motivation": "Smart contracts' state update vulnerabilities are exploited by attackers, creating a need for better detection and prevention methods.", "method": "A systematic large-scale empirical study conducted on 116 vulnerabilities in 352 smart contract projects, supported by a proof-of-concept detection tool.", "result": "The study uncovers 11 key findings and demonstrates the successful application of its detection tool in identifying issues in 64 GitHub projects, with confirmations from 19 project owners.", "conclusion": "The findings and developed checker highlight critical insights and practical tools for identifying and mitigating inconsistent state update vulnerabilities in smart contracts."}}
{"id": "2508.05915", "pdf": "https://arxiv.org/pdf/2508.05915", "abs": "https://arxiv.org/abs/2508.05915", "authors": ["Alex Glushkovsky"], "title": "Dual Signal Decomposition of Stochastic Time Series", "categories": ["cs.LG", "62M10"], "comment": "21 pages, 9 figures, 1 table", "summary": "The research paper addresses decomposition of a stochastic time series into\nthree time series representing a dual signal i.e., the mean and the dispersion,\nwith noise isolated. Decomposition is done by applying machine learning to fit\na dual signal. Machine learning minimizes the loss function which compromises\nbetween fitting the original time series and penalizing irregularities of the\ndual signal. The latter includes terms based on the first and second order\nderivatives along time. To preserve special patterns, weighting of the\nregularization components of the loss function has been introduced based on\nStatistical Process Control methodology. The proposed decomposition can be\napplied as a smoothing algorithm against the mean and dispersion of the time\nseries. By isolating noise, the proposed decomposition can be seen as a\ndenoising algorithm. Two approaches of the learning process have been\nconsidered: sequential and jointly. The former approach learns the mean signal\nfirst and then dispersion. The latter approach fits the dual signal jointly.\nJointly learning can uncover complex relationships for the time series with\nheteroskedasticity. Learning has been set by solving the direct non-linear\nunconstrained optimization problem or by applying neural networks that have\nsequential or twin output architectures. Tuning of the loss function\nhyperparameters focuses on the isolated noise to be a stationary stochastic\nprocess without autocorrelation properties. Depending on the applications, the\nhyperparameters of the learning can be tuned towards either the discrete states\nby stepped signal or smoothed series. The decomposed dual signal can be\nrepresented on the 2D space and used to learn inherent structures, to forecast\nboth mean and dispersion, or to analyze cross effects in case of multiple time\nseries.", "AI": {"tldr": "This paper discusses a method to decompose stochastic time series into mean, dispersion, and noise using machine learning. The approach minimizes a custom loss function, incorporates statistical regularization, and supports sequential or joint learning processes.", "motivation": "The paper aims to effectively decompose time series data into meaningful components (mean, dispersion, and noise), to improve analysis, denoising, and forecasting capabilities while handling complex structures like heteroskedasticity.", "method": "The decomposition is achieved using machine learning methods that minimize a loss function balancing data fitting and regularization. Weighting based on Statistical Process Control is introduced, and models optimize via direct nonlinear techniques or neural networks.", "result": "The approach effectively isolates noise and provides decompositions for analysis. It supports applications in denoising, structure learning, and forecasting. Sequential learning processes mean and dispersion separately, while joint learning uncovers complex relationships.", "conclusion": "The proposed decomposition is versatile and enables a variety of applications such as noise isolation, pattern recognition, and forecasting. It flexibly adapts to different scenarios with customizable hyperparameters and learning architectures."}}
{"id": "2508.06095", "pdf": "https://arxiv.org/pdf/2508.06095", "abs": "https://arxiv.org/abs/2508.06095", "authors": ["Mitchell Abrams", "Thies Oelerich", "Christian Hartl-Nesic", "Andreas Kugi", "Matthias Scheutz"], "title": "Incremental Language Understanding for Online Motion Planning of Robot Manipulators", "categories": ["cs.RO"], "comment": "8 pages, 9 figures, accepted at IROS 2025", "summary": "Human-robot interaction requires robots to process language incrementally,\nadapting their actions in real-time based on evolving speech input. Existing\napproaches to language-guided robot motion planning typically assume fully\nspecified instructions, resulting in inefficient stop-and-replan behavior when\ncorrections or clarifications occur. In this paper, we introduce a novel\nreasoning-based incremental parser which integrates an online motion planning\nalgorithm within the cognitive architecture. Our approach enables continuous\nadaptation to dynamic linguistic input, allowing robots to update motion plans\nwithout restarting execution. The incremental parser maintains multiple\ncandidate parses, leveraging reasoning mechanisms to resolve ambiguities and\nrevise interpretations when needed. By combining symbolic reasoning with online\nmotion planning, our system achieves greater flexibility in handling speech\ncorrections and dynamically changing constraints. We evaluate our framework in\nreal-world human-robot interaction scenarios, demonstrating online adaptions of\ngoal poses, constraints, or task objectives. Our results highlight the\nadvantages of integrating incremental language understanding with real-time\nmotion planning for natural and fluid human-robot collaboration. The\nexperiments are demonstrated in the accompanying video at\nwww.acin.tuwien.ac.at/42d5.", "AI": {"tldr": "The paper introduces an incremental parser for human-robot interaction, enabling real-time motion adaptation to evolving linguistic inputs.", "motivation": "Existing systems assume complete instructions, causing inefficiencies when speech corrections or clarifications are made, limiting natural human-robot collaboration.", "method": "The authors integrate a reasoning-based incremental parser with online motion planning within a cognitive architecture, maintaining multiple candidate parses and adapting dynamically to linguistic input.", "result": "The framework demonstrates successful online adaptations for changing constraints and task objectives in real-world scenarios, outperforming traditional methods.", "conclusion": "Integrating incremental language understanding with motion planning enhances fluid interactions, improving real-time adaptability in human-robot systems."}}
{"id": "2508.05844", "pdf": "https://arxiv.org/pdf/2508.05844", "abs": "https://arxiv.org/abs/2508.05844", "authors": ["Fran\u00e7ois Bachoc", "Nicol\u00f2 Cesa-Bianchi", "Tommaso Cesari", "Roberto Colomboni"], "title": "Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding", "categories": ["cs.GT", "cs.LG", "stat.ML"], "comment": null, "summary": "Motivated by applications in crowdsourcing, where a fixed sum of money is\nsplit among $K$ workers, and autobidding, where a fixed budget is used to bid\nin $K$ simultaneous auctions, we define a stochastic bandit model where arms\nbelong to the $K$-dimensional probability simplex and represent the fraction of\nbudget allocated to each task/auction. The reward in each round is the sum of\n$K$ stochastic rewards, where each of these rewards is unlocked with a\nprobability that varies with the fraction of the budget allocated to that\ntask/auction. We design an algorithm whose expected regret after $T$ steps is\nof order $K\\sqrt{T}$ (up to log factors) and prove a matching lower bound.\nImproved bounds of order $K (\\log T)^2$ are shown when the function mapping\nbudget to probability of unlocking the reward (i.e., terminating the task or\nwinning the auction) satisfies additional diminishing-returns conditions.", "AI": {"tldr": "This study introduces a stochastic bandit model to optimize budget allocation among $K$ tasks or auctions, achieving regret bounds of $K\\sqrt{T}$ or $K(\\log T)^2$ under specific conditions.", "motivation": "Applications in crowdsourcing (budget distribution) and autobidding (simultaneous auction allocations) necessitate efficient resource allocation.", "method": "A stochastic bandit model with rewards dependent on probabilities tied to fractional budget distribution is constructed with regret-minimization algorithms.", "result": "Achieved expected regret bounds of $K\\sqrt{T}$ (general) and $K(\\log T)^2$ (under diminishing returns conditions).", "conclusion": "The proposed model and algorithms effectively allocate budgets while minimizing regret, backed by matching theoretical bounds."}}
{"id": "2508.06489", "pdf": "https://arxiv.org/pdf/2508.06489", "abs": "https://arxiv.org/abs/2508.06489", "authors": ["Mustafa Doger", "Sennur Ulukus"], "title": "Voting-Based Semi-Parallel Proof-of-Work Protocol", "categories": ["cs.CR", "cs.DC", "cs.DM", "cs.IT", "math.IT", "math.PR"], "comment": null, "summary": "Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety\nguarantees, transaction throughput and confirmation latencies of Nakamoto\nconsensus. In this work, we first consider the existing parallel PoW protocols\nand develop hard-coded incentive attack structures. Our theoretical results and\nsimulations show that the existing parallel PoW protocols are more vulnerable\nto incentive attacks than the Nakamoto consensus, e.g., attacks have smaller\nprofitability threshold and they result in higher relative rewards. Next, we\nintroduce a voting-based semi-parallel PoW protocol that outperforms both\nNakamoto consensus and the existing parallel PoW protocols from most practical\nperspectives such as communication overheads, throughput, transaction\nconflicts, incentive compatibility of the protocol as well as a fair\ndistribution of transaction fees among the voters and the leaders. We use\nstate-of-the-art analysis to evaluate the consistency of the protocol and\nconsider Markov decision process (MDP) models to substantiate our claims about\nthe resilience of our protocol against incentive attacks.", "AI": {"tldr": "This paper investigates vulnerabilities in existing parallel Proof-of-Work (PoW) protocols, introduces a voting-based semi-parallel PoW protocol, and demonstrates its advantages in security, throughput, and incentive compatibility.", "motivation": "The authors aim to address safety vulnerabilities, throughput limitations, and incentive compatibility challenges of Nakamoto consensus and existing parallel PoW protocols.", "method": "The authors identify incentive attacks in existing parallel PoW, develop attack models, and propose a new voting-based semi-parallel PoW protocol with Markov decision process (MDP) analysis for performance and security evaluations.", "result": "The proposed protocol mitigates incentive attack vulnerabilities, improves throughput, reduces transaction conflicts, and ensures a fair reward distribution.", "conclusion": "The voting-based semi-parallel PoW protocol surpasses Nakamoto and existing parallel PoW protocols in practicality, security, and fairness."}}
{"id": "2508.05987", "pdf": "https://arxiv.org/pdf/2508.05987", "abs": "https://arxiv.org/abs/2508.05987", "authors": ["Chunyun Zhang", "Hongyan Zhao", "Chaoran Cui", "Qilong Song", "Zhiqing Lu", "Shuai Gong", "Kailin Liu"], "title": "Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring", "categories": ["cs.CL"], "comment": null, "summary": "Cross-topic automated essay scoring (AES) aims to develop a transferable\nmodel capable of effectively evaluating essays on a target topic. A significant\nchallenge in this domain arises from the inherent discrepancies between topics.\nWhile existing methods predominantly focus on extracting topic-shared features\nthrough distribution alignment of source and target topics, they often neglect\ntopic-specific features, limiting their ability to assess critical traits such\nas topic adherence. To address this limitation, we propose an Adversarial\nTOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns\ntopic-shared and topic-specific features to improve cross-topic AES. ATOP\nachieves this by optimizing a learnable topic-aware prompt--comprising both\nshared and specific components--to elicit relevant knowledge from pre-trained\nlanguage models (PLMs). To enhance the robustness of topic-shared prompt\nlearning and mitigate feature scale sensitivity introduced by topic alignment,\nwe incorporate adversarial training within a unified regression and\nclassification framework. In addition, we employ a neighbor-based classifier to\nmodel the local structure of essay representations and generate pseudo-labels\nfor target-topic essays. These pseudo-labels are then used to guide the\nsupervised learning of topic-specific prompts tailored to the target topic.\nExtensive experiments on the publicly available ASAP++ dataset demonstrate that\nATOP significantly outperforms existing state-of-the-art methods in both\nholistic and multi-trait essay scoring. The implementation of our method is\npublicly available at: https://anonymous.4open.science/r/ATOP-A271.", "AI": {"tldr": "The study introduces ATOP, a method enhancing cross-topic essay scoring accuracy by integrating topic-shared and topic-specific features using language models.", "motivation": "Existing methods for cross-topic AES often fail to properly assess topic adherence due to neglect of topic-specific features.", "method": "ATOP uses topic-aware prompts to extract shared and specific features and applies adversarial training to improve robustness, alongside pseudo-label approaches for supervised learning.", "result": "Experiments using the ASAP++ dataset show that ATOP outperforms current state-of-the-art methods for holistic and multi-trait scoring.", "conclusion": "ATOP addresses key limitations in cross-topic AES, providing a novel framework that leverages pre-trained language models for improved scoring across diverse topics."}}
{"id": "2508.06062", "pdf": "https://arxiv.org/pdf/2508.06062", "abs": "https://arxiv.org/abs/2508.06062", "authors": ["Evgenii E. Vityaev", "Andrei Mantsivoda"], "title": "Don't Forget Imagination!", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 68T30"], "comment": "14 pages, 2 figures", "summary": "Cognitive imagination is a type of imagination that plays a key role in human\nthinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to\nmentally visualize coherent and holistic systems of concepts and causal links\nthat serve as semantic contexts for reasoning, decision making and prediction.\nOur position is that the role of cognitive imagination is still greatly\nunderestimated, and this creates numerous problems and diminishes the current\ncapabilities of AI. For instance, when reasoning, humans rely on imaginary\ncontexts to retrieve background info. They also constantly return to the\ncontext for semantic verification that their reasoning is still reasonable.\nThus, reasoning without imagination is blind. This paper is a call for greater\nattention to cognitive imagination as the next promising breakthrough in\nartificial intelligence. As an instrument for simulating cognitive imagination,\nwe propose semantic models -- a new approach to mathematical models that can\nlearn, like neural networks, and are based on probabilistic causal\nrelationships. Semantic models can simulate cognitive imagination because they\nensure the consistency of imaginary contexts and implement a glass-box approach\nthat allows the context to be manipulated as a holistic and coherent system of\ninterrelated facts glued together with causal relations.", "AI": {"tldr": "Cognitive imagination is crucial for AI, enabling reasoning through imaginary contexts. The paper advocates for semantic models to simulate cognitive imagination by ensuring consistency and causal relationships.", "motivation": "Highlight the underestimated role of cognitive imagination in reasoning and decision-making, aiming to unlock its potential for AI innovation.", "method": "Proposing semantic models that utilize probabilistic causal relationships to simulate cognitive imagination in a transparent, manipulable way.", "result": "Semantic models provide a framework to simulate cognitive imagination, ensuring consistency and holistic reasoning, potentially advancing AI capabilities.", "conclusion": "Recognizing cognitive imagination as central to reasoning can lead to breakthroughs in AI. Semantic models offer a promising approach to integrate this capability into AI systems."}}
{"id": "2508.05851", "pdf": "https://arxiv.org/pdf/2508.05851", "abs": "https://arxiv.org/abs/2508.05851", "authors": ["Ka-Wai Yung", "Felix J. S. Bragman", "Jialang Xu", "Imanol Luengo", "Danail Stoyanov", "Evangelos B. Mazomenos"], "title": "Temporal Cluster Assignment for Efficient Real-Time Video Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Vision Transformers have substantially advanced the capabilities of\nsegmentation models across both image and video domains. Among them, the Swin\nTransformer stands out for its ability to capture hierarchical, multi-scale\nrepresentations, making it a popular backbone for segmentation in videos.\nHowever, despite its window-attention scheme, it still incurs a high\ncomputational cost, especially in larger variants commonly used for dense\nprediction in videos. This remains a major bottleneck for real-time,\nresource-constrained applications. Whilst token reduction methods have been\nproposed to alleviate this, the window-based attention mechanism of Swin\nrequires a fixed number of tokens per window, limiting the applicability of\nconventional pruning techniques. Meanwhile, training-free token clustering\napproaches have shown promise in image segmentation while maintaining window\nconsistency. Nevertheless, they fail to exploit temporal redundancy, missing a\nkey opportunity to further optimize video segmentation performance. We\nintroduce Temporal Cluster Assignment (TCA), a lightweight and effective,\nfine-tuning-free strategy that enhances token clustering by leveraging temporal\ncoherence across frames. Instead of indiscriminately dropping redundant tokens,\nTCA refines token clusters using temporal correlations, thereby retaining\nfine-grained details while significantly reducing computation. Extensive\nevaluations on YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and a private surgical\nvideo dataset show that TCA consistently boosts the accuracy-speed trade-off of\nexisting clustering-based methods. Our results demonstrate that TCA generalizes\ncompetently across both natural and domain-specific videos.", "AI": {"tldr": "The paper introduces Temporal Cluster Assignment (TCA), a method to refine token clustering for video segmentation using temporal coherence, achieving better accuracy-speed trade-offs.", "motivation": "Vision Transformers, particularly the Swin Transformer, excel in multi-scale video segmentation but face computational inefficiencies for real-time, resource-constrained scenarios.", "method": "The study presents the TCA approach, which refines token clusters by leveraging temporal correlations across video frames, retaining fine-grained details without requiring model fine-tuning.", "result": "TCA effectively reduces computation while enhancing performance in various datasets such as YouTube-VIS and surgical video datasets, improving clustering methods' accuracy-speed trade-off.", "conclusion": "TCA is a generalizable and efficient solution for optimizing video segmentation models in both natural and specialized domains without extra training overhead."}}
{"id": "2508.06299", "pdf": "https://arxiv.org/pdf/2508.06299", "abs": "https://arxiv.org/abs/2508.06299", "authors": ["Henrique Henriques", "Hugo Louren\u00e7o", "Vasco Amaral", "Miguel Goul\u00e3o"], "title": "Improving the Developer Experience with a Low-Code Process Modelling Language", "categories": ["cs.SE"], "comment": "Preprint", "summary": "Context: The OutSystems Platform is a development environment composed of\nseveral DSLs, used to specify, quickly build, and validate web and mobile\napplications. The DSLs allow users to model different perspectives such as\ninterfaces and data models, define custom business logic and construct process\nmodels. Problem: The DSL for process modelling (Business Process Technology\n(BPT)), has a low adoption rate and is perceived as having usability problems\nhampering its adoption. This is problematic given the language maintenance\ncosts. Method: We used a combination of interviews, a critical review of BPT\nusing the \"Physics of Notation\" and empirical evaluations of BPT using the\nSystem Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a\nnew version of BPT, taking these inputs and Outsystems' engineers' culture into\naccount. Results: Evaluations conducted with 25 professional software engineers\nshowed an increase of the semantic transparency on the new version, from 31% to\n69%, an increase in the correctness of responses, from 51% to 89%, an increase\nin the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from\n36.50 to 20.78. These differences were statistically significant. Conclusions:\nThese results suggest that the new version of BPT significantly improved the\ndeveloper experience of the previous version. The end users' background with\nOutSystems had a relevant impact on the final concrete syntax choices and\nachieved usability indicators.", "AI": {"tldr": "The paper addresses usability issues in the process modeling language (BPT) of the OutSystems Platform, redesigning it based on empirical evaluations and achieving significant usability improvements.", "motivation": "The motivation comes from the low adoption rate and usability problems of the BPT DSL in the OutSystems Platform, leading to increased maintenance costs and limited usage.", "method": "The method involved interviews, critical reviews using the 'Physics of Notation,' and empirical evaluations (System Usability Scale and NASA Task Load Index) to inform redesign efforts aligned with engineers' workflows and culture.", "result": "The new BPT version showed significant improvement in usability, reflected in better semantic transparency (31% to 69%), correctness of responses (51% to 89%), SUS score (42.25 to 64.78), and reduced task load (TLX score: 36.50 to 20.78).", "conclusion": "The redesigned BPT version substantially enhances developer experience compared to its predecessor, showcasing how user feedback and targeted changes can improve adoption and usability in a specialized DSL."}}
{"id": "2508.05921", "pdf": "https://arxiv.org/pdf/2508.05921", "abs": "https://arxiv.org/abs/2508.05921", "authors": ["Siddharth Rout"], "title": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations", "categories": ["cs.LG", "math.FA", "math.RT", "physics.comp-ph"], "comment": null, "summary": "Accuracy in neural PDE solvers often breaks down not because of limited\nexpressivity, but due to poor optimisation caused by ill-conditioning,\nespecially in multi-fidelity and stiff problems. We study this issue in\nPhysics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural\nPDE solvers, and show that asymptotic components in governing equations can\nproduce highly ill-conditioned activation matrices, severely limiting\nconvergence. We introduce Shifted Gaussian Encoding, a simple yet effective\nactivation filtering step that increases matrix rank and expressivity while\npreserving convexity. Our method extends the solvable range of Peclet numbers\nin steady advection-diffusion equations by over two orders of magnitude,\nachieves up to six orders lower error on multi-frequency function learning, and\nfits high-fidelity image vectors more accurately and faster than deep networks\nwith over a million parameters. This work highlights that conditioning, not\ndepth, is often the bottleneck in scientific neural solvers and that simple\narchitectural changes can unlock substantial gains.", "AI": {"tldr": "The paper tackles the optimization and ill-conditioning issues in neural PDE solvers by introducing Shifted Gaussian Encoding, which improves accuracy and efficiency.", "motivation": "To address the optimization challenges in Physics-Informed Extreme Learning Machines (PIELMs), caused by ill-conditioned activation matrices and asymptotic behavior in governing equations, which impair convergence.", "method": "The authors propose Shifted Gaussian Encoding, a filtering step that improves the matrix rank and avoids ill-conditioning while maintaining the solver's convex properties.", "result": "The approach extended the solvable range of Peclet numbers by over two orders of magnitude, reduced errors in multi-frequency learning by up to six orders, and delivered better accuracy and speed compared to deep networks with over one million parameters.", "conclusion": "The findings emphasize that ill-conditioning, rather than network depth, is a limiting factor in scientific neural PDE solvers and that simple architectural adjustments can yield significant improvements."}}
{"id": "2508.06096", "pdf": "https://arxiv.org/pdf/2508.06096", "abs": "https://arxiv.org/abs/2508.06096", "authors": ["Eric Jing", "Abdeslam Boularias"], "title": "Bounding Distributional Shifts in World Modeling through Novelty Detection", "categories": ["cs.RO", "cs.AI"], "comment": "7 pages, 6 figures", "summary": "Recent work on visual world models shows significant promise in latent state\ndynamics obtained from pre-trained image backbones. However, most of the\ncurrent approaches are sensitive to training quality, requiring near-complete\ncoverage of the action and state space during training to prevent divergence\nduring inference. To make a model-based planning algorithm more robust to the\nquality of the learned world model, we propose in this work to use a\nvariational autoencoder as a novelty detector to ensure that proposed action\ntrajectories during planning do not cause the learned model to deviate from the\ntraining data distribution. To evaluate the effectiveness of this approach, a\nseries of experiments in challenging simulated robot environments was carried\nout, with the proposed method incorporated into a model-predictive control\npolicy loop extending the DINO-WM architecture. The results clearly show that\nthe proposed method improves over state-of-the-art solutions in terms of data\nefficiency.", "AI": {"tldr": "The paper proposes a novel method to improve the robustness of model-based planning algorithms using a variational autoencoder (VAE) as a novelty detector, evaluating its effectiveness in simulated robotic environments.", "motivation": "Existing approaches for visual world models often struggle with sensitivity to training quality, requiring complete action and state space coverage to avoid issues during inference.", "method": "The authors use a variational autoencoder (VAE) as a novelty detector to ensure that action trajectories remain within the training data distribution and integrate this into a model-predictive control policy based on the DINO-WM architecture.", "result": "In simulated robotic environments, the proposed method demonstrated superior data efficiency compared to state-of-the-art solutions.", "conclusion": "Incorporating a VAE-based novelty detection mechanism into the planning loop enhances robustness and data efficiency in model-based planning algorithms."}}
{"id": "2508.05901", "pdf": "https://arxiv.org/pdf/2508.05901", "abs": "https://arxiv.org/abs/2508.05901", "authors": ["Sourav Chatterjee", "Persi Diaconis", "Susan Holmes"], "title": "Estimating the size of a set using cascading exclusion", "categories": ["math.ST", "cs.IT", "math.IT", "math.PR", "stat.ML", "stat.TH", "62G05, 62G25"], "comment": "46 pages, 10 figures", "summary": "Let $S$ be a finite set, and $X_1,\\ldots,X_n$ an i.i.d. uniform sample from\n$S$. To estimate the size $|S|$, without further structure, one can wait for\nrepeats and use the birthday problem. This requires a sample size of the order\n$|S|^\\frac{1}{2}$. On the other hand, if $S=\\{1,2,\\ldots,|S|\\}$, the maximum of\nthe sample blown up by $n/(n-1)$ gives an efficient estimator based on any\ngrowing sample size. This paper gives refinements that interpolate between\nthese extremes. A general non-asymptotic theory is developed. This includes\nestimating the volume of a compact convex set, the unseen species problem, and\na host of testing problems that follow from the question `Is this new\nobservation a typical pick from a large prespecified population?' We also treat\nregression style predictors. A general theorem gives non-parametric finite $n$\nerror bounds in all cases.", "AI": {"tldr": "The paper explores methods for estimating the size of a finite set using sampling techniques, developing improved estimators and error bounds for various applications, including unseen species problems and regression-style predictors.", "motivation": "The motivation is to enhance the efficiency and accuracy of estimators for the size of a finite set, especially in scenarios where traditional methods like the birthday problem or maximum sampling have limitations.", "method": "The paper develops a general non-asymptotic theory, proposes refinements to existing estimators, and uses non-parametric finite sample error bounds to validate the approaches.", "result": "The proposed methods improve on traditional estimation techniques and provide a framework for broader applications, including species estimation and population testing.", "conclusion": "The refinements and general results offer practical alternatives that bridge extremes between conventional methods, giving robust estimators for finite set sizes and related statistical challenges."}}
{"id": "2508.06016", "pdf": "https://arxiv.org/pdf/2508.06016", "abs": "https://arxiv.org/abs/2508.06016", "authors": ["Sagar Gandhi", "Vishal Gandhi"], "title": "Crisp Attention: Regularizing Transformers via Structured Sparsity", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The quadratic computational cost of the self-attention mechanism is a primary\nchallenge in scaling Transformer models. While attention sparsity is widely\nstudied as a technique to improve computational efficiency, it is almost\nuniversally assumed to come at the cost of model accuracy. In this paper, we\nreport a surprising counter-example to this common wisdom. By introducing\nstructured, post-hoc sparsity to the attention mechanism of a DistilBERT model\nduring fine-tuning on the SST-2 sentiment analysis task, we find that model\naccuracy improves significantly. Our model with 80\\% attention sparsity\nachieves a validation accuracy of 91.59\\%, a 0.97\\% absolute improvement over\nthe dense baseline. We hypothesize that this phenomenon is due to sparsity\nacting as a powerful implicit regularizer, preventing the model from\noverfitting by forcing it to make predictions with a more constrained and\nrobust set of features. Our work recasts attention sparsity not just as a tool\nfor computational efficiency, but as a potential method for improving the\ngeneralization and performance of Transformer models.", "AI": {"tldr": "The study demonstrates that introducing strategic sparsity to a Transformer model's attention improves both efficiency and accuracy, challenging traditional assumptions.", "motivation": "Address the computational inefficiency of self-attention mechanisms in Transformer models while investigating whether sparsity negatively impacts accuracy.", "method": "Integrate structured, post-hoc sparsity into the attention mechanism of a DistilBERT model during fine-tuning on the SST-2 sentiment analysis task.", "result": "Achieved 91.59% validation accuracy with 80% attention sparsity, improving accuracy by 0.97% over a dense baseline.", "conclusion": "Sparsity not only enhances computational efficiency but also acts as an implicit regularizer, improving the generalization and performance of Transformer models."}}
{"id": "2508.06064", "pdf": "https://arxiv.org/pdf/2508.06064", "abs": "https://arxiv.org/abs/2508.06064", "authors": ["Harold Silv\u00e8re Kiossou", "Siegfried Nijssen", "Pierre Schaus"], "title": "A Generic Complete Anytime Beam Search for Optimal Decision Tree", "categories": ["cs.AI"], "comment": null, "summary": "Finding an optimal decision tree that minimizes classification error is known\nto be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic\nprogramming guarantee optimality, they often suffer from poor anytime behavior\n-- meaning they struggle to find high-quality decision trees quickly when the\nsearch is stopped before completion -- due to unbalanced search space\nexploration. To address this, several anytime extensions of exact methods have\nbeen proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not\nbeen systematically compared, making it difficult to assess their relative\neffectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and\nanytime beam search algorithm that extends the DL8.5 framework and unifies some\nexisting anytime strategies. In particular, CA-DL8.5 generalizes previous\napproaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various\nheuristics and relaxation mechanisms through a modular design. The algorithm\nreuses DL8.5's efficient branch-and-bound pruning and trie-based caching,\ncombined with a restart-based beam search that gradually relaxes pruning\ncriteria to improve solution quality over time. Our contributions are twofold:\n(1) We introduce this new generic framework for exact and anytime decision tree\nlearning, enabling the incorporation of diverse heuristics and search\nstrategies; (2) We conduct a rigorous empirical comparison of several\ninstantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k\nheuristics -- using an anytime evaluation metric called the primal gap\nintegral. Experimental results on standard classification benchmarks show that\nCA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime\nperformance, outperforming both other CA-DL8.5 variants and the Blossom\nalgorithm while maintaining completeness and optimality guarantees.", "AI": {"tldr": "The paper introduces CA-DL8.5, a new anytime beam search algorithm for generating optimal decision trees. It outperforms previous algorithms in anytime performance while ensuring optimality.", "motivation": "Exact methods for generating optimal decision trees often exhibit poor anytime performance, struggling to find quality solutions quickly. Existing extended anytime methods are not systematically compared, creating a need for a unified framework.", "method": "CA-DL8.5 is a beam search algorithm extending the DL8.5 framework, combining branch-and-bound pruning, caching, and a restart-based beam search that relaxes pruning criteria. It incorporates various heuristics (e.g., Purity, Gain, Discrepancy) to balance exploration.", "result": "CA-DL8.5 using LDS (limited discrepancy strategy) achieved the best anytime performance on standard benchmarks, surpassing existing variants and Blossom in quality while maintaining optimality guarantees.", "conclusion": "CA-DL8.5 provides a flexible and effective approach to exact and anytime decision tree learning, showcasing better anytime performance and adaptability through heuristic integration."}}
{"id": "2508.05852", "pdf": "https://arxiv.org/pdf/2508.05852", "abs": "https://arxiv.org/abs/2508.05852", "authors": ["Kaiser Hamid", "Khandakar Ashrafi Akbar", "Nade Liang"], "title": "VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments", "categories": ["cs.CV", "I.5.4"], "comment": null, "summary": "Driver visual attention prediction is a critical task in autonomous driving\nand human-computer interaction (HCI) research. Most prior studies focus on\nestimating attention allocation at a single moment in time, typically using\nstatic RGB images such as driving scene pictures. In this work, we propose a\nvision-language framework that models the changing landscape of drivers' gaze\nthrough natural language, using few-shot and zero-shot learning on single RGB\nimages. We curate and refine high-quality captions from the BDD-A dataset using\nhuman-in-the-loop feedback, then fine-tune LLaVA to align visual perception\nwith attention-centric scene understanding. Our approach integrates both\nlow-level cues and top-down context (e.g., route semantics, risk anticipation),\nenabling language-based descriptions of gaze behavior. We evaluate performance\nacross training regimes (few shot, and one-shot) and introduce domain-specific\nmetrics for semantic alignment and response diversity. Results show that our\nfine-tuned model outperforms general-purpose VLMs in attention shift detection\nand interpretability. To our knowledge, this is among the first attempts to\ngenerate driver visual attention allocation and shifting predictions in natural\nlanguage, offering a new direction for explainable AI in autonomous driving.\nOur approach provides a foundation for downstream tasks such as behavior\nforecasting, human-AI teaming, and multi-agent coordination.", "AI": {"tldr": "This study introduces a vision-language model to predict driver gaze shifts in natural language using few-shot and zero-shot learning on images.", "motivation": "Understanding and predicting driver visual attention is crucial for autonomous driving and HCI, but most current approaches rely on static image analysis.", "method": "The paper uses a vision-language framework anchored by a fine-tuned LLaVA model to translate driver gaze predictions into language. It employs caption refinement from the BDD-A dataset with human feedback and integrates visual and contextual cues.", "result": "The fine-tuned model outperforms general-purpose models in attention shift detection and interpretability, demonstrating improved results in both few-shot and zero-shot scenarios.", "conclusion": "This is a pioneering effort in generating natural language descriptions of driver gaze behavior, offering advancements toward more explainable AI in autonomous driving and related tasks like behavior forecasting."}}
{"id": "2508.06365", "pdf": "https://arxiv.org/pdf/2508.06365", "abs": "https://arxiv.org/abs/2508.06365", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Execution-Feedback Driven Test Generation from SWE Issues", "categories": ["cs.SE"], "comment": null, "summary": "A software engineering issue (SWE issue) is easier to resolve when\naccompanied by a reproduction test. Unfortunately, most issues do not come with\nfunctioning reproduction tests, so this paper explores how to generate them\nautomatically. The primary challenge in this setting is that the code to be\ntested is either missing or wrong, as evidenced by the existence of the issue\nin the first place. This has held back test generation for this setting:\nwithout the correct code to execute, it is difficult to leverage execution\nfeedback to generate good tests. This paper introduces novel techniques for\nleveraging execution feedback to get around this problem, implemented in a new\nreproduction test generator called e-Otter++. Experiments show that e-Otter++\nrepresents a leap ahead in the state-of-the-art for this problem, generating\ntests with an average fail-to-pass rate of 63% on the TDD-Bench Verified\nbenchmark.", "AI": {"tldr": "The paper introduces e-Otter++, a tool that generates reproduction tests for software engineering issues, overcoming the challenge posed by missing or incorrect code.", "motivation": "To address the difficulty in resolving software engineering issues due to the lack of reproduction tests.", "method": "Developing and implementing e-Otter++, which uses novel execution feedback techniques to generate reproduction tests even when the code is incomplete or incorrect.", "result": "Experiments with e-Otter++ demonstrated its effectiveness, achieving an average fail-to-pass rate of 63% on the TDD-Bench Verified benchmark.", "conclusion": "e-Otter++ significantly advances the state-of-the-art in automated test generation for software issues, particularly when reproduction tests are missing."}}
{"id": "2508.05928", "pdf": "https://arxiv.org/pdf/2508.05928", "abs": "https://arxiv.org/abs/2508.05928", "authors": ["Si Shen", "Peijun Shen", "Wenhua Zhao", "Danhao Zhu"], "title": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting", "categories": ["cs.LG"], "comment": null, "summary": "Group-Relative Policy Optimization (GRPO) is a key technique for training\nlarge reasoning models, yet it suffers from a critical vulnerability: the\n\\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning\nprocess. This problem is most severe in unbalanced response groups,\nparadoxically degrading the signal precisely when it should be most\ninformative. To address this challenge, we propose Stable Group-Relative Policy\nOptimization (S-GRPO), a principled enhancement that derives optimal,\nnoise-aware advantage weights to stabilize training. Our comprehensive\nexperiments on mathematical reasoning benchmarks demonstrate S-GRPO's\neffectiveness and robustness. On various models, S-GRPO significantly\noutperforms DR. GRPO, achieving performance gains of +2.5% on\nQwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on\nQwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn\nunder 20% synthetic reward noise, S-GRPO maintains stable learning progress.\nThese results highlight S-GRPO's potential for more robust and effective\ntraining of large-scale reasoning models. \\footnote{Code and data are available\nat: https://github.com/shenpeijun0212/S-GRPO", "AI": {"tldr": "The paper introduces Stable Group-Relative Policy Optimization (S-GRPO), a method designed to address stability challenges in training reasoning models under noisy reward signals.", "motivation": "The issue arises from the 'Think-Answer Mismatch', where unbalanced response groups lead to corrupted learning signals, hindering model performance.", "method": "S-GRPO enhances standard GRPO by introducing noise-aware advantage weights that stabilize the training process.", "result": "S-GRPO significantly outperforms DR. GRPO across various reasoning models, such as a performance gain of +2.5% on Qwen-Math-7B-Base, and presents stable learning under synthetic reward noise conditions.", "conclusion": "S-GRPO provides a robust solution for training large-scale reasoning models, especially under scenarios with high noise, making it superior to standard GRPO methods."}}
{"id": "2508.06181", "pdf": "https://arxiv.org/pdf/2508.06181", "abs": "https://arxiv.org/abs/2508.06181", "authors": ["Jan W\u0119grzynowski", "Piotr Kicki", "Grzegorz Czechmanowski", "Maciej Krupka", "Krzysztof Walas"], "title": "Beyond Constant Parameters: Hyper Prediction Models and HyperMPC", "categories": ["cs.RO"], "comment": null, "summary": "Model Predictive Control (MPC) is among the most widely adopted and reliable\nmethods for robot control, relying critically on an accurate dynamics model.\nHowever, existing dynamics models used in the gradient-based MPC are limited by\ncomputational complexity and state representation. To address this limitation,\nwe propose the Hyper Prediction Model (HyperPM) - a novel approach in which we\nproject the unmodeled dynamics onto a time-dependent dynamics model. This\ntime-dependency is captured through time-varying model parameters, whose\nevolution over the MPC prediction horizon is learned using a neural network.\nSuch formulation preserves the computational efficiency and robustness of the\nbase model while equipping it with the capacity to anticipate previously\nunmodeled phenomena. We evaluated the proposed approach on several challenging\nsystems, including real-world F1TENTH autonomous racing, and demonstrated that\nit significantly reduces long-horizon prediction errors. Moreover, when\nintegrated within the MPC framework (HyperMPC), our method consistently\noutperforms existing state-of-the-art techniques.", "AI": {"tldr": "The paper presents HyperPM, a novel model improving dynamics prediction in Model Predictive Control (MPC) by introducing time-dependent parameters learned through neural networks, yielding higher accuracy and outperforming existing methods in robotic systems like autonomous racing.", "motivation": "Improving dynamics prediction in MPC by addressing computational complexity and limited state representation challenges of existing models.", "method": "Developing the Hyper Prediction Model (HyperPM) that projects unmodeled dynamics onto a time-dependent model with neural network-learned evolution over MPC horizons.", "result": "HyperPM reduces long-horizon prediction errors and consistently outperforms other techniques when integrated into MPC across various systems, including real-world autonomous racing.", "conclusion": "HyperPM enhances MPC dynamics prediction efficiency and accuracy, demonstrating robustness and superiority over state-of-the-art approaches."}}
{"id": "2508.06087", "pdf": "https://arxiv.org/pdf/2508.06087", "abs": "https://arxiv.org/abs/2508.06087", "authors": ["Zhihao Yao", "Yuxuan Gu", "Xiachong Feng", "Weitao Ma", "Bo Li", "Xiaocheng Feng"], "title": "Adaptive Backtracking for Privacy Protection in Large Language Models", "categories": ["cs.CR", "cs.LG", "stat.ML"], "comment": null, "summary": "The preservation of privacy has emerged as a critical topic in the era of\nartificial intelligence. However, current work focuses on user-oriented\nprivacy, overlooking severe enterprise data leakage risks exacerbated by the\nRetrieval-Augmented Generation paradigm. To address this gap, our paper\nintroduces a novel objective: enterprise-oriented privacy concerns. Achieving\nthis objective requires overcoming two fundamental challenges: existing methods\nsuch as data sanitization severely degrade model performance, and the field\nlacks public datasets for evaluation. We address these challenges with several\nsolutions. (1) To prevent performance degradation, we propose ABack, a\ntraining-free mechanism that leverages a Hidden State Model to pinpoint the\norigin of a leakage intention and rewrite the output safely. (2) To solve the\nlack of datasets, we construct PriGenQA, a new benchmark for enterprise privacy\nscenarios in healthcare and finance. To ensure a rigorous evaluation, we move\nbeyond simple static attacks by developing a powerful adaptive attacker with\nGroup Relative Policy Optimization. Experiments show that against this superior\nadversary, ABack improves the overall privacy utility score by up to 15\\% over\nstrong baselines, avoiding the performance trade-offs of prior methods.", "AI": {"tldr": "This paper addresses enterprise-oriented privacy issues in AI by proposing a mechanism called ABack and introducing a benchmark dataset PriGenQA.", "motivation": "Current approaches mostly address user privacy, ignoring enterprise data leakage risks, especially with Retrieval-Augmented Generation models.", "method": "The authors propose ABack, a mechanism using Hidden State Models for safe output rewriting and construct PriGenQA, a benchmark dataset for healthcare and finance privacy scenarios.", "result": "ABack achieves a 15% improvement in privacy utility score over strong baselines while avoiding performance trade-offs.", "conclusion": "The solutions presented successfully address enterprise privacy concerns without compromising model effectiveness and offer benchmarks for rigorous evaluation in sensitive industries."}}
{"id": "2508.06026", "pdf": "https://arxiv.org/pdf/2508.06026", "abs": "https://arxiv.org/abs/2508.06026", "authors": ["Yidong Wang", "Xin Wang", "Cunxiang Wang", "Junfeng Fang", "Qiufeng Wang", "Jianing Chu", "Xuran Meng", "Shuxun Yang", "Libo Qin", "Yue Zhang", "Wei Ye", "Shikun Zhang"], "title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "Self-Rewarding Language Models propose an architecture in which the Large\nLanguage Models(LLMs) both generates responses and evaluates its own outputs\nvia LLM-as-a-Judge prompting, dynamically improving its generative capabilities\nthrough iterative Direct Preference Optimization (DPO). However, our analysis\nreveals a critical limitation in existing Self-Rewarding paradigms: the\nsynchronized improvement of chosen and rejected responses progressively narrows\nthe representational difference between contrasting samples, undermining\neffective preference learning. We propose \\textbf{Temporal Self-Rewarding\nLanguage Models} that strategically coordinate past, present, and future model\ngenerations to sustain learning signals. Our dual-phase framework introduces:\n(1) \\textit{Anchored Rejection} - fixing rejected responses using the past\ninitial model's outputs and (2) \\textit{Future-Guided Chosen} - dynamically\ncurating chosen samples using next-generation model predictions. Extensive\nexperiments across three model families (Llama, Qwen, Mistral) and different\nmodel sizes (Llama3B/8B/70B) demonstrate significant improvements when trained\nwith our method compared to Self-Rewarding using same computation resources.\nFor example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our\nmethod, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our\nmethod also demonstrates superior out-of-distribution generalization across\nmathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code\ngeneration (HumanEval) tasks, even though we do not specifically collect such\ntraining data.", "AI": {"tldr": "The paper introduces Temporal Self-Rewarding Language Models to address limitations in existing self-rewarding setups for LLMs, showcasing improved capabilities through a framework coordinating past, present, and future generations.", "motivation": "To overcome the representational narrowing in existing Self-Rewarding Language Models, which hampers effective preference learning.", "method": "A dual-phase framework featuring Anchored Rejection for rejected responses and Future-Guided Chosen for chosen outputs, strategically utilizing past and future model generations.", "result": "Achieved significant improvements in win rates and generalization across diverse tasks in experiments with multiple model families and sizes, notably outperforming Self-Rewarding baselines.", "conclusion": "Temporal coordination in model training leads to better generative capabilities and adaptability, enabling robust out-of-distribution generalization without specialized training datasets."}}
{"id": "2508.06074", "pdf": "https://arxiv.org/pdf/2508.06074", "abs": "https://arxiv.org/abs/2508.06074", "authors": ["Siyi Lu", "Run Liu", "Dongsheng Yang", "Lei He"], "title": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous driving systems face significant challenges in perceiving complex\nenvironments and making real-time decisions. Traditional modular approaches,\nwhile offering interpretability, suffer from error propagation and coordination\nissues, whereas end-to-end learning systems can simplify the design but face\ncomputational bottlenecks. This paper presents a novel approach to autonomous\ndriving using deep reinforcement learning (DRL) that integrates bird's-eye view\n(BEV) perception for enhanced real-time decision-making. We introduce the\n\\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction\nnetwork that combines BEV-based perception with the Mamba framework for\ntemporal feature modeling. This integration allows the system to encode vehicle\nsurroundings and road features in a unified coordinate system and accurately\nmodel long-range dependencies. Building on this, we propose the\n\\texttt{ME$^3$-BEV} framework, which utilizes the \\texttt{Mamba-BEV} model as a\nfeature input for end-to-end DRL, achieving superior performance in dynamic\nurban driving scenarios. We further enhance the interpretability of the model\nby visualizing high-dimensional features through semantic segmentation,\nproviding insight into the learned representations. Extensive experiments on\nthe CARLA simulator demonstrate that \\texttt{ME$^3$-BEV} outperforms existing\nmodels across multiple metrics, including collision rate and trajectory\naccuracy, offering a promising solution for real-time autonomous driving.", "AI": {"tldr": "The paper proposes an enhanced deep reinforcement learning (DRL) framework, ME\u00b3-BEV, that integrates bird's-eye view perception and a novel Mamba-BEV network for improved autonomous driving performance in dynamic environments.", "motivation": "Enhancing real-time decision-making in autonomous driving, which struggles with challenges such as error propagation in modular systems and computational inefficiencies in end-to-end systems.", "method": "The approach uses bird's-eye view (BEV) perception integrated with the Mamba-BEV model for spatio-temporal feature extraction, enabling unified encoding of vehicle surroundings, road details, and long-range dependencies. This is coupled with an end-to-end DRL framework.", "result": "The proposed ME\u00b3-BEV framework demonstrated superior performance in urban driving scenarios within the CARLA simulator, excelling in collision rate reduction and trajectory accuracy compared to other state-of-the-art models.", "conclusion": "ME\u00b3-BEV offers a scalable and interpretable solution for real-time autonomous driving, integrating BEV perception and DRL to overcome computational and error propagation challenges."}}
{"id": "2508.05857", "pdf": "https://arxiv.org/pdf/2508.05857", "abs": "https://arxiv.org/abs/2508.05857", "authors": ["Qiaomu Miao", "Vivek Raju Golani", "Jingyi Xu", "Progga Paromita Dutta", "Minh Hoai", "Dimitris Samaras"], "title": "Multi-view Gaze Target Estimation", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "This paper presents a method that utilizes multiple camera views for the gaze\ntarget estimation (GTE) task. The approach integrates information from\ndifferent camera views to improve accuracy and expand applicability, addressing\nlimitations in existing single-view methods that face challenges such as face\nocclusion, target ambiguity, and out-of-view targets. Our method processes a\npair of camera views as input, incorporating a Head Information Aggregation\n(HIA) module for leveraging head information from both views for more accurate\ngaze estimation, an Uncertainty-based Gaze Selection (UGS) for identifying the\nmost reliable gaze output, and an Epipolar-based Scene Attention (ESA) module\nfor cross-view background information sharing. This approach significantly\noutperforms single-view baselines, especially when the second camera provides a\nclear view of the person's face. Additionally, our method can estimate the gaze\ntarget in the first view using the image of the person in the second view only,\na capability not possessed by single-view GTE methods. Furthermore, the paper\nintroduces a multi-view dataset for developing and evaluating multi-view GTE\nmethods. Data and code are available at\nhttps://www3.cs.stonybrook.edu/~cvl/multiview_gte.html", "AI": {"tldr": "This study proposes a multi-camera approach to gaze target estimation, addressing limitations like face occlusions and out-of-view targets.", "motivation": "Current single-view gaze estimation methods struggle with challenges like occluded faces, ambiguity, and inability to handle out-of-view targets.", "method": "The approach integrates head information aggregation, uncertainty-based gaze selection, and epipolar-based scene attention using pairs of camera views.", "result": "The multi-camera method significantly outperforms single-camera systems, especially when a second camera captures a clear face view.", "conclusion": "The method enhances gaze estimation capabilities and introduces a new multi-view dataset for evaluation, advancing the domain of gaze target estimation."}}
{"id": "2508.06414", "pdf": "https://arxiv.org/pdf/2508.06414", "abs": "https://arxiv.org/abs/2508.06414", "authors": ["Dongze Li", "Songqiang Chen", "Jialun Cao", "Shing-Chi Cheung"], "title": "What Builds Effective In-Context Examples for Code Generation?", "categories": ["cs.SE"], "comment": null, "summary": "In-Context Learning (ICL) has emerged as a promising solution to enhance the\ncode generation capabilities of Large Language Models (LLMs), which\nincorporates code examples inside the prompt to let LLMs learn from\ndemonstrations. However, despite the substantial effectiveness of the code\nexample-based ICL approach, the specific features (e.g., identifier naming\nstyles, code formatting, solution insight) within the ICL-provided code\nexamples that significantly contribute to the ICL's effectiveness remain\nunclear. This paper systematically investigates the impact of various code\nfeatures on ICL with code examples through controlled ablation studies. Our\nfindings reveal that the appropriate naming of variables and functions is\ncrucial for effective code generation, with their elimination leading to\nperformance decreases of up to 30 percentage points. We further demonstrate\nthat LLMs prioritize semantically meaningful identifier names over formatting\nconventions, with language-specific preferences regarding identifier verbosity.\nAdditionally, our investigation into ICL's potential for enhancing reflection\nand inference capabilities reveals that current LLMs struggle to extract\ngeneralizable problem-solving insights from similar code solutions, despite\nbeing capable of utilizing direct information effectively. These findings are\nexpected to provide valuable insights for optimizing ICL systems in code\ngeneration applications and highlight fundamental challenges in\nreflection-based learning for code generation tasks.", "AI": {"tldr": "The paper explores how various code features in In-Context Learning (ICL) prompts influence the code generation ability of Large Language Models (LLMs), finding that identifier naming is a critical factor for performance.", "motivation": "The paper seeks to uncover which specific features in code examples, such as naming conventions or formatting, most impact ICL's effectiveness in enhancing LLM code generation.", "method": "The authors perform controlled ablation studies on various features (e.g., naming styles, formatting) in ICL-provided code examples to isolate and evaluate their impact on performance.", "result": "Appropriate naming of variables and functions is found to significantly improve code generation, while LLMs prioritize semantically meaningful naming over formatting. Current LLMs struggle to generalize problem-solving insights from examples.", "conclusion": "The study provides insights for optimizing ICL systems and identifies key challenges in enabling LLMs to learn reflection-based problem-solving for code generation tasks."}}
{"id": "2508.05957", "pdf": "https://arxiv.org/pdf/2508.05957", "abs": "https://arxiv.org/abs/2508.05957", "authors": ["Hasibul Karim Shanto", "Umme Ayman Koana", "Shadikur Rahman"], "title": "Multi-Armed Bandits-Based Optimization of Decision Trees", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Decision trees, without appropriate constraints, can easily become overly\ncomplex and prone to overfit, capturing noise rather than generalizable\npatterns. To resolve this problem,pruning operation is a crucial part in\noptimizing decision trees, as it not only reduces the complexity of trees but\nalso decreases the probability of generating overfit models. The conventional\npruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning\n(REP) are mostly based on greedy approaches that focus on immediate gains in\nperformance while pruning nodes of the decision tree. However, this might\nresult in a lower generalization in the long run, compromising the robust\nability of the tree model when introduced to unseen data samples, particularly\nwhen trained with small and complex datasets. To address this challenge, we are\nproposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement\nlearning (RL)-based technique, that will dynamically prune the tree to generate\nan optimal decision tree with better generalization. Our proposed approach\nassumes the pruning process as an exploration-exploitation problem, where we\nare utilizing the MAB algorithms to find optimal branch nodes to prune based on\nfeedback from each pruning actions. Experimental evaluation on several\nbenchmark datasets, demonstrated that our proposed approach results in better\npredictive performance compared to the traditional ones. This suggests the\npotential of utilizing MAB for a dynamic and probabilistic way of decision tree\npruning, in turn optimizing the decision tree-based model.", "AI": {"tldr": "The paper proposes a novel decision tree pruning approach using Multi-Armed Bandits (MAB) to improve generalization and performance, surpassing traditional methods.", "motivation": "Traditional decision tree pruning methods like Cost-Complexity Pruning (CCP) and Reduced Error Pruning (REP) often overfit or underperform on unseen data, especially with small, complex datasets.", "method": "The proposed approach models the pruning process as an exploration-exploitation problem, employing MAB algorithms to dynamically optimize pruning decisions based on feedback from previous pruning actions.", "result": "Experimental results on several benchmark datasets reveal that the MAB-based pruning method outperforms conventional pruning techniques in predictive performance.", "conclusion": "The study shows that a reinforcement learning-based MAB pruning approach is a promising alternative for optimizing decision tree models by enhancing generalization and reducing overfitting."}}
{"id": "2508.06206", "pdf": "https://arxiv.org/pdf/2508.06206", "abs": "https://arxiv.org/abs/2508.06206", "authors": ["Hanqing Wang", "Shaoyang Wang", "Yiming Zhong", "Zemin Yang", "Jiamin Wang", "Zhiqing Cui", "Jiahao Yuan", "Yifan Han", "Mingyu Liu", "Yuexin Ma"], "title": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Affordance grounding focuses on predicting the specific regions of objects\nthat are associated with the actions to be performed by robots. It plays a\nvital role in the fields of human-robot interaction, human-object interaction,\nembodied manipulation, and embodied perception. Existing models often neglect\nthe affordance shared among different objects because they lack the\nChain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)\ngeneralization and explicit reasoning capabilities. To address these\nchallenges, we propose Affordance-R1, the first unified affordance grounding\nframework that integrates cognitive CoT guided Group Relative Policy\nOptimization (GRPO) within a reinforcement learning paradigm. Specifically, we\ndesigned a sophisticated affordance function, which contains format,\nperception, and cognition rewards to effectively guide optimization directions.\nFurthermore, we constructed a high-quality affordance-centric reasoning\ndataset, ReasonAff, to support training. Trained exclusively via reinforcement\nlearning with GRPO and without explicit reasoning data, Affordance-R1 achieves\nrobust zero-shot generalization and exhibits emergent test-time reasoning\ncapabilities. Comprehensive experiments demonstrate that our model outperforms\nwell-established methods and exhibits open-world generalization. To the best of\nour knowledge, Affordance-R1 is the first to integrate GRPO-based RL with\nreasoning into affordance reasoning. The code of our method and our dataset is\nreleased on https://github.com/hq-King/Affordance-R1.", "AI": {"tldr": "This paper introduces Affordance-R1, a novel framework integrating reinforcement learning and reasoning for robotic affordance prediction.", "motivation": "Address limitations in existing models that neglect shared affordances among objects and lack reasoning abilities, which restrict OOD generalization.", "method": "Proposed Affordance-R1 framework uses Group Relative Policy Optimization (GRPO) within reinforcement learning and introduces a reasoning-focused dataset named ReasonAff.", "result": "Affordance-R1 demonstrates robust zero-shot generalization and emergent test-time reasoning, outperforming established methods in open-world generalization tasks.", "conclusion": "Affordance-R1 successfully integrates GRPO-based RL and reasoning, marking an advancement in affordance grounding with improved generalization and reasoning."}}
{"id": "2508.06126", "pdf": "https://arxiv.org/pdf/2508.06126", "abs": "https://arxiv.org/abs/2508.06126", "authors": ["Jixuan Yin", "Zhihao Yao", "Wenshuai Huo", "Xinmiao Yu", "Xiaocheng Feng", "Bo Li"], "title": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "In clustering tasks, it is essential to structure the feature space into\nclear, well-separated distributions. However, because short text\nrepresentations have limited expressiveness, conventional methods struggle to\nidentify cluster centers that truly capture each category's underlying\nsemantics, causing the representations to be optimized in suboptimal\ndirections. To address this issue, we propose IOCC, a novel few-shot\ncontrastive learning method that achieves alignment between the cluster centers\nand the semantic centers. IOCC consists of two key modules:\nInteraction-enhanced Optimal Transport (IEOT) and Center-aware Contrastive\nLearning (CACL). Specifically, IEOT incorporates semantic interactions between\nindividual samples into the conventional optimal transport problem, and\ngenerate pseudo-labels. Based on these pseudo-labels, we aggregate\nhigh-confidence samples to construct pseudo-centers that approximate the\nsemantic centers. Next, CACL optimizes text representations toward their\ncorresponding pseudo-centers. As training progresses, the collaboration between\nthe two modules gradually reduces the gap between cluster centers and semantic\ncenters. Therefore, the model will learn a high-quality distribution, improving\nclustering performance. Extensive experiments on eight benchmark datasets show\nthat IOCC outperforms previous methods, achieving up to 7.34\\% improvement on\nchallenging Biomedical dataset and also excelling in clustering stability and\nefficiency. The code is available at:\nhttps://anonymous.4open.science/r/IOCC-C438.", "AI": {"tldr": "IOCC is proposed as a novel few-shot contrastive learning method for clustering short text data by aligning cluster centers with semantic centers. It consists of Interaction-enhanced Optimal Transport (IEOT) and Center-aware Contrastive Learning (CACL).", "motivation": "Short text representations lack expressiveness, leading to suboptimal clustering performance as conventional methods fail to capture underlying semantics effectively.", "method": "IOCC utilizes IEOT to generate pseudo-labels informed by semantic interactions, and CACL optimizes text representations toward pseudo-centers, bridging the gap between cluster centers and semantic centers iteratively.", "result": "IOCC demonstrated improvements in clustering accuracy, achieving up to 7.34% enhancement on challenging datasets like Biomedical and surpassing previous methods in stability and efficiency.", "conclusion": "Effective alignment of cluster centers with semantic centers through IOCC results in higher clustering performance, establishing the method's utility and reliability for short text clustering tasks."}}
{"id": "2508.06030", "pdf": "https://arxiv.org/pdf/2508.06030", "abs": "https://arxiv.org/abs/2508.06030", "authors": ["Kartik Sharma", "Yiqiao Jin", "Rakshit Trivedi", "Srijan Kumar"], "title": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) acquire knowledge across diverse domains such as\nscience, history, and geography encountered during generative pre-training.\nHowever, due to their stochasticity, it is difficult to predict what LLMs have\nacquired. Prior work has developed different ways to probe this knowledge by\ninvestigating the hidden representations, crafting specific task prompts,\ncurating representative samples, and estimating their uncertainty. However,\nthese methods require making forward passes through the underlying model to\nprobe the LLM's knowledge about a specific fact, making them computationally\nexpensive and time-consuming. To bridge this gap, we propose $\\textbf{PEEK}$ or\n$\\textbf{P}$roxy $\\textbf{E}$mbeddings to $\\textbf{E}$stimate\n$\\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models\nthat effectively encode factual knowledge as text or graphs as proxies for\nLLMs. First, we identify a training set of facts known by LLMs through various\nprobing strategies and then adapt embedding models to predict the LLM outputs\nwith a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived\ndatasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict\nLLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find\nthat sentence embedding models are more suitable than graph embeddings to\npredict LLM knowledge, shedding light on the underlying representation of the\nfactual landscape. Thus, we believe that knowledge-adapted embeddings can be\nused to identify knowledge gaps in LLMs at scale and can provide deeper\ninsights into LLMs' internal inductive bias. The code and data are made\navailable at https://github.com/claws-lab/peek.", "AI": {"tldr": "The paper proposes PEEK, a method using proxy embeddings to estimate the knowledge of large language models (LLMs) efficiently without computationally expensive forward passes.", "motivation": "To address the challenge of determining the factual knowledge acquired by LLMs in a computationally efficient manner.", "method": "The authors use pre-trained embedding models to predict LLM outputs by adapting these embeddings through a linear decoder layer trained on a set of facts known by the LLMs.", "result": "Embeddings were able to predict LLM knowledge on a held-out dataset with up to 90% accuracy, with sentence embeddings outperforming graph embeddings.", "conclusion": "Knowledge-adapted embeddings can identify gaps in LLM knowledge at scale and offer insights into their inductive bias, making them a promising tool for efficiently probing LLM knowledge."}}
{"id": "2508.06091", "pdf": "https://arxiv.org/pdf/2508.06091", "abs": "https://arxiv.org/abs/2508.06091", "authors": ["Stan P Hauke", "Przemys\u0142aw Andrzej Wa\u0142\u0119ga"], "title": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2", "categories": ["cs.AI"], "comment": "18 pages", "summary": "In recent years, there has been growing interest in understanding the\nexpressive power of graph neural networks (GNNs) by relating them to logical\nlanguages. This research has been been initialised by an influential result of\nBarcel\\'o et al. (2020), who showed that the graded modal logic (or a guarded\nfragment of the logic C2), characterises the logical expressiveness of\naggregate-combine GNNs. As a ``challenging open problem'' they left the\nquestion whether full C2 characterises the logical expressiveness of\naggregate-combine-readout GNNs. This question has remained unresolved despite\nseveral attempts. In this paper, we solve the above open problem by proving\nthat the logical expressiveness of aggregate-combine-readout GNNs strictly\nexceeds that of C2. This result holds over both undirected and directed graphs.\nBeyond its implications for GNNs, our work also leads to purely logical\ninsights on the expressive power of infinitary logics.", "AI": {"tldr": "This paper resolves a key open problem in graph neural networks (GNNs), proving that aggregate-combine-readout GNNs are more expressive than the logic C2.", "motivation": "There has been significant interest in connecting the expressiveness of graph neural networks with logical frameworks, motivated by previous findings that related GNNs to specific logical logics such as C2.", "method": "The authors analyzed the expressive capabilities of aggregate-combine-readout GNNs and compared them to the logical expressiveness of C2 over both undirected and directed graphs.", "result": "The researchers demonstrated that the expressive power of aggregate-combine-readout GNNs surpasses that of C2, resolving a longstanding open problem in the field.", "conclusion": "This study advances the theoretical understanding of GNN expressiveness and contributes insights into the expressive power of infinitary logics."}}
{"id": "2508.05898", "pdf": "https://arxiv.org/pdf/2508.05898", "abs": "https://arxiv.org/abs/2508.05898", "authors": ["Hamidreza Dastmalchi", "Aijun An", "Ali cheraghian"], "title": "ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates", "categories": ["cs.CV"], "comment": "BMVC2025", "summary": "Pretrained vision-language models (VLMs) like CLIP show strong zero-shot\nperformance but struggle with generalization under distribution shifts.\nTest-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test\ndata in new domains. While some TTA methods rely on prompt-tuning,\ntraining-free cache-based approaches are preferred for efficiency. However,\ncurrent cache-based TTA models store only a limited set of high-confidence\nsamples, restricting the decision boundary to these samples and ignoring the\ninfluence of other incoming test data. To address this, we propose Efficient\nTest-Time Adaptation (ETTA), introducing a Recursive Updating module that\nintegrates all incoming test samples, progressively refining the decision\nboundary. This strategy mimics an unbounded cache, dynamically updating\ncontextual embeddings for improved accuracy with minimal memory and\ncomputational overhead. ETTA also includes an Adaptive Ensemble module to\nreduce prompt dependency in image-to-text scores by dynamically selecting\noptimal prompts for each class. Furthermore, ETTA adaptively combines scores\nfrom both modules based on confidence levels, leveraging their complementary\nstrengths. Extensive experiments on two benchmarks confirm that ETTA surpasses\nthe state-of-the-art TTA models in computational complexity and accuracy,\nsetting a new standard for effective, efficient test-time adaptation. The code\nhas been released at https://github.com/hamidreza-dastmalchi/ETTA.", "AI": {"tldr": "The paper introduces ETTA, a method that improves test-time adaptation by refining decision boundaries dynamically using all incoming test samples and reducing dependency on prompt tuning, achieving state-of-the-art results in accuracy and computational efficiency.", "motivation": "Pretrained vision-language models like CLIP struggle to generalize under distribution shifts, leading to the need for effective test-time adaptation strategies.", "method": "ETTA employs a Recursive Updating module to use all incoming test samples for dynamically refining decision boundaries, and an Adaptive Ensemble module to reduce prompt dependency by selecting optimal prompts and combining module scores adaptively.", "result": "Experiments show ETTA significantly outperforms existing methods on benchmarks in terms of accuracy and computational complexity.", "conclusion": "ETTA establishes a new benchmark for efficient and effective test-time adaptation, enhancing generalization without substantial memory or computational demands."}}
{"id": "2508.05697", "pdf": "https://arxiv.org/pdf/2508.05697", "abs": "https://arxiv.org/abs/2508.05697", "authors": ["Marcos Guillermo Lammers", "Federico Hern\u00e1n Holik", "Alejandro Fern\u00e1ndez"], "title": "Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering", "categories": ["quant-ph", "cs.SE"], "comment": "in Spanish language", "summary": "Quantum computers represent a radical technological breakthrough in\ninformation processing by leveraging the principles of quantum mechanics to\nsolve highly complex problems beyond the reach of classical systems. However,\nin the current NISQ era (noisy intermediate-scale quantum devices), the\navailable hardware presents several limitations, such as a limited number of\nqubits, high error rates, and short coherence times. Efficient management of\nquantum resources, both physical and logical, is especially relevant in the\ndesign and deployment of quantum algorithms. In this paper, we analyze the role\nof resources in current uses of NISQ devices, identifying their relevance and\nimplications for quantum software engineering. With this contribution, we aim\nto strengthen the field of Quantum Resource Estimation (QRE) and move toward\nscalable and reliable quantum software development", "AI": {"tldr": "Quantum computers in the NISQ era face hardware limitations like limited qubits and high error rates. This paper explores efficient quantum resource management for better algorithm deployment.", "motivation": "Current NISQ devices have significant physical limitations, prompting the need for improved resource management to unlock their potential for quantum computing.", "method": "The paper analyzes the role of quantum resources in deploying quantum algorithms and highlights their implications for quantum software engineering.", "result": "The study strengthens the concept of Quantum Resource Estimation (QRE) and offers insights into developing scalable and reliable quantum software.", "conclusion": "Efficient resource management can mitigate NISQ hardware limitations, advancing quantum software development and highlighting the importance of Quantum Resource Estimation."}}
{"id": "2508.05960", "pdf": "https://arxiv.org/pdf/2508.05960", "abs": "https://arxiv.org/abs/2508.05960", "authors": ["Haohui Chen", "Zhiyong Chen"], "title": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) seeks to learn optimal policies from\nstatic datasets without further environment interaction. A key challenge is the\ndistribution shift between the learned and behavior policies, leading to\nout-of-distribution (OOD) actions and overestimation. To prevent gross\noverestimation, the value function must remain conservative; however, excessive\nconservatism may hinder performance improvement. To address this, we propose\nthe mildly conservative regularized evaluation (MCRE) framework, which balances\nconservatism and performance by combining temporal difference (TD) error with a\nbehavior cloning term in the Bellman backup. Building on this, we develop the\nmildly conservative regularized Q-learning (MCRQ) algorithm, which integrates\nMCRE into an off-policy actor-critic framework. Experiments show that MCRQ\noutperforms strong baselines and state-of-the-art offline RL algorithms on\nbenchmark datasets.", "AI": {"tldr": "This paper introduces MCRE framework and MCRQ algorithm to improve performance in offline RL by balancing conservatism and performance.", "motivation": "The challenge of distribution shift in offline RL causes out-of-distribution actions and overestimation, requiring a balance between conservatism and performance.", "method": "Introduces the MCRE framework, which integrates a behavior cloning term into the Bellman backup, and develops the MCRQ algorithm within an off-policy actor-critic framework.", "result": "MCRQ surpasses strong baselines and state-of-the-art offline RL approaches in benchmark experiments.", "conclusion": "The proposed MCRQ algorithm demonstrates effective performance in offline RL by achieving a balance between conservative value estimation and policy improvement."}}
{"id": "2508.06207", "pdf": "https://arxiv.org/pdf/2508.06207", "abs": "https://arxiv.org/abs/2508.06207", "authors": ["Andrea Dal Prete", "Seyram Ofori", "Chan Yon Sin", "Ashwin Narayan", "Francesco Braghin", "Marta Gandolla", "Haoyong Yu"], "title": "Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization", "categories": ["cs.RO"], "comment": null, "summary": "Back exoskeletons can reduce musculoskeletal strain, but their effectiveness\ndepends on support modulation and adaptive control. This study addresses two\nchallenges: defining optimal support strategies and developing adaptive control\nbased on payload estimation. We introduce an optimization space based on muscle\nactivity reduction, perceived discomfort, and user preference, constructing\nfunctions to identify optimal strategies. Experiments with 12 subjects revealed\noptimal operating regions, highlighting the need for dynamic modulation. Based\non these insights, we developed a vision-based adaptive control pipeline that\nestimates payloads in real-time by enhancing exoskeleton contextual\nunderstanding, minimising latency and enabling support adaptation within the\ndefined optimisation space. Validation with 12 more subjects showed over 80%\naccuracy and improvements across all metrics. Compared to static control,\nadaptive modulation reduced peak back muscle activation by up to 23% while\npreserving user preference and minimising discomfort. These findings validate\nthe proposed framework and highlight the potential of intelligent,\ncontext-aware control in industrial exoskeletons.", "AI": {"tldr": "The study addresses optimizing support strategies and adaptive control for back exoskeletons, leveraging user-centered metrics and real-time payload estimation through a vision-based pipeline.", "motivation": "To enhance the effectiveness of back exoskeletons in reducing musculoskeletal strain by addressing modulation and control challenges.", "method": "The authors proposed an optimization space based on muscle activity, discomfort, and user preference, conducted experiments to define optimal regions, and developed a vision-based adaptive control pipeline for real-time payload estimation.", "result": "The adaptive control pipeline achieved an accuracy above 80%, reduced peak back muscle activation by up to 23%, and improved user-centric metrics versus static control.", "conclusion": "The intelligent adaptive framework demonstrates substantial benefits in reducing muscle strain, validating its potential for industrial use in context-aware exoskeletons."}}
{"id": "2508.06247", "pdf": "https://arxiv.org/pdf/2508.06247", "abs": "https://arxiv.org/abs/2508.06247", "authors": ["Zichun Ye", "Runqi Wang", "Xutong Liu", "Shuai Li"], "title": "Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential\ndecision-making framework, dominated by two algorithmic families: UCB-based and\nadversarial methods such as follow the regularized leader (FTRL) and online\nmirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer\nfrom additional regret factor $\\log T$ that is detrimental over long horizons,\nwhile adversarial methods such as EXP3.M and HYBRID impose significant\ncomputational overhead. To resolve this trade-off, we introduce the\nCombinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS\nis a computationally efficient algorithm that achieves an instance-independent\nregret of $O\\big( (\\log k)^2\\sqrt{kmT}\\big )$ under semi-bandit feedback, where\n$m$ is the number of arms and $k$ is the maximum cardinality of a feasible\naction. Crucially, this result eliminates the dependency on $\\log T$ and\nmatches the established $\\Omega\\big( \\sqrt{kmT}\\big)$ lower bound up to\n$O\\big((\\log k)^2\\big)$. We then extend our analysis to show that CMOSS is also\napplicable to cascading feedback. Experiments on synthetic and real-world\ndatasets validate that CMOSS consistently outperforms benchmark algorithms in\nboth regret and runtime efficiency.", "AI": {"tldr": "The paper introduces CMOSS, a novel algorithm for combinatorial multi-armed bandit problems, achieving low regret and high computational efficiency.", "motivation": "Current CMAB algorithms either have high computational cost or incur additional regret over long horizons, creating a need for a method that balances computational efficiency and regret minimization.", "method": "CMOSS, a computationally efficient algorithm operating under a stochastic framework with semi-bandit and cascading feedback, achieves optimal regret bounds by eliminating dependency on log T.", "result": "CMOSS achieves near-optimal regret of $O((\\log k)^2\\sqrt{kmT})$ and performs better than existing benchmarks in both regret and runtime efficiency in synthetic and real-world settings.", "conclusion": "CMOSS is an effective and efficient solution that strikes a balance between regret minimization and computational overhead, outperforming existing methods for combinatorial multi-armed bandit problems."}}
{"id": "2508.06046", "pdf": "https://arxiv.org/pdf/2508.06046", "abs": "https://arxiv.org/abs/2508.06046", "authors": ["Xinda Wang", "Zhengxu Hou", "Yangshijie Zhang", "Bingren Yan", "Zhibo Yang", "Xingsheng Zhang", "Luxi Xing", "Qiang Zhou", "Chen Zhang"], "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although the effectiveness of Large Language Models (LLMs) as judges\n(LLM-as-a-judge) has been validated, their performance remains limited in\nopen-ended tasks, particularly in story evaluation. Accurate story evaluation\nis crucial not only for assisting human quality judgment but also for providing\nkey signals to guide story generation. However, existing methods face a\ndilemma: prompt engineering for closed-source models suffers from poor\nadaptability, while fine-tuning approaches for open-source models lack the\nrigorous reasoning capabilities essential for story evaluation. To address\nthis, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.\nGrounded in pairwise comparison, the framework first self-synthesizes\nscore-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To\nensure data quality, these raw CoTs undergo a self-filtering process, utilizing\nmulti-agents to guarantee their logical rigor and robustness. Finally, the\nevaluator trained on the refined data is deployed as a reward model to guide\nthe story generation task. Experimental results demonstrate that our framework\nachieves state-of-the-art (SOTA) performance on three evaluation benchmarks\nincluding StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward\nmodel, it significantly enhances the quality of generated stories, thereby\nfully validating the superiority of our self-evolving approach.", "AI": {"tldr": "The paper introduces EvolvR, a framework enhancing story evaluation through self-synthesized and refined reasoning data, achieving SOTA performance and improving story generation quality.", "motivation": "Current methods for story evaluation face challenges: prompt engineering for closed-source models lacks adaptability, and fine-tuning for open-source models lacks reasoning rigor.", "method": "EvolvR employs pairwise comparison to generate self-synthesized reasoning data with a multi-persona strategy, followed by a self-filtering process using multi-agent systems, training an evaluator as a reward model for story generation.", "result": "EvolvR achieved state-of-the-art performance on three benchmarks (StoryER, HANNA, and OpenMEVA) and improved the quality of generated stories when used as a reward model.", "conclusion": "The EvolvR framework improves story evaluation and generation through a superior self-synthesized data approach, addressing limitations in adaptability and reasoning capabilities of existing methods."}}
{"id": "2508.06110", "pdf": "https://arxiv.org/pdf/2508.06110", "abs": "https://arxiv.org/abs/2508.06110", "authors": ["Yiran Rex Ma"], "title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "categories": ["cs.AI", "cs.MA"], "comment": "Accepted at IJCNN 2025", "summary": "Table reasoning, including tabular QA and fact verification, often depends on\nannotated data or complex data augmentation, limiting flexibility and\ngeneralization. LLMs, despite their versatility, often underperform compared to\nsimple supervised models. To approach these issues, we introduce PanelTR, a\nframework utilizing LLM agent scientists for robust table reasoning through a\nstructured scientific approach. PanelTR's workflow involves agent scientists\nconducting individual investigations, engaging in self-review, and\nparticipating in collaborative peer-review discussions. This process, driven by\nfive scientist personas, enables semantic-level transfer without relying on\ndata augmentation or parametric optimization. Experiments across four\nbenchmarks show that PanelTR outperforms vanilla LLMs and rivals fully\nsupervised models, all while remaining independent of training data. Our\nfindings indicate that structured scientific methodology can effectively handle\ncomplex tasks beyond table reasoning with flexible semantic understanding in a\nzero-shot context.", "AI": {"tldr": "PanelTR improves table reasoning using structured methods with isolated LLM agents, achieving strong performance without training data.", "motivation": "Addressing limitations of annotated data dependency and LLMs underperformance in table reasoning tasks.", "method": "Utilized structured scientific workflow with LLM agent scientists performing investigations, reviews, and peer discussions.", "result": "PanelTR surpasses vanilla LLMs and rivals supervised models on benchmarks without training data reliance.", "conclusion": "Structured methodology within zero-shot setups enhances the versatility of LLMs in complex reasoning tasks like table interpretation."}}
{"id": "2508.05899", "pdf": "https://arxiv.org/pdf/2508.05899", "abs": "https://arxiv.org/abs/2508.05899", "authors": ["Zixuan Bian", "Ruohan Ren", "Yue Yang", "Chris Callison-Burch"], "title": "HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "3D scene generation plays a crucial role in gaming, artistic creation,\nvirtual reality and many other domains. However, current 3D scene design still\nrelies heavily on extensive manual effort from creators, and existing automated\nmethods struggle to generate open-domain scenes or support flexible editing. As\na result, generating 3D worlds directly from text has garnered increasing\nattention. In this paper, we introduce HOLODECK 2.0, an advanced\nvision-language-guided framework for 3D world generation with support for\ninteractive scene editing based on human feedback. HOLODECK 2.0 can generate\ndiverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and\ncyberpunk styles) that exhibit high semantic fidelity to fine-grained input\ndescriptions, suitable for both indoor and open-domain environments. HOLODECK\n2.0 leverages vision-language models (VLMs) to identify and parse the objects\nrequired in a scene and generates corresponding high-quality assets via\nstate-of-the-art 3D generative models. It then iteratively applies spatial\nconstraints derived from the VLMs to achieve semantically coherent and\nphysically plausible layouts. Human evaluations and CLIP-based assessments\ndemonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely\naligned with detailed textual descriptions, consistently outperforming\nbaselines across indoor and open-domain scenarios. Additionally, we provide\nediting capabilities that flexibly adapt to human feedback, supporting layout\nrefinement and style-consistent object edits. Finally, we present a practical\napplication of HOLODECK 2.0 in procedural game modeling, generating visually\nrich and immersive environments, potentially boosting efficiency.", "AI": {"tldr": "HOLODECK 2.0 is an advanced framework for 3D scene generation from text, supporting diverse styles, high semantic accuracy, and interactive editing.", "motivation": "The motivation stems from the high manual effort involved in current 3D scene creation and the limitations of automated methods in generating open-domain, flexible, editable 3D scenes directly from text.", "method": "HOLODECK 2.0 employs vision-language models for object identification, high-quality asset generation through 3D generative models, and iterative spatial constraint application for scene layout coherence.", "result": "Experiments show that HOLODECK 2.0 outperforms baselines in generating semantically accurate and visually diverse 3D scenes, validated by human evaluations and CLIP-based metrics.", "conclusion": "HOLODECK 2.0 represents a significant step forward in automated 3D scene generation, with applications in game modeling and other fields requiring efficient 3D design workflows."}}
{"id": "2508.05865", "pdf": "https://arxiv.org/pdf/2508.05865", "abs": "https://arxiv.org/abs/2508.05865", "authors": ["Kiana Kiashemshaki", "Elvis Nnaemeka Chukwuani", "Mohammad Jalili Torkamani", "Negin Mahmoudi"], "title": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models", "categories": ["cs.CR", "cs.SE", "C.2; D.2; D.4.1; D.4.4; D.4.6; I.2.7"], "comment": "9 pages, 8 figures, 1 table", "summary": "Blockchain technology offers a promising foundation for modernizing E-Voting\nsystems by enhancing transparency, decentralization, and security. Yet,\nreal-world adoption remains limited due to persistent challenges such as\nscalability constraints, high computational demands, and complex privacy\nrequirements. This paper presents a comparative framework for analyzing\nblockchain-based E-Voting architectures, consensus mechanisms, and\ncryptographic protocols. We examine the limitations of prevalent models like\nProof of Work, Proof of Stake, and Delegated Proof of Stake, and propose\noptimization strategies that include hybrid consensus, lightweight\ncryptography, and decentralized identity management. Additionally, we explore\nthe novel role of Large Language Models (LLMs) in smart contract generation,\nanomaly detection, and user interaction. Our findings offer a foundation for\ndesigning secure, scalable, and intelligent blockchain-based E-Voting systems\nsuitable for national-scale deployment. This work lays the groundwork for\nbuilding an end-to-end blockchain E-Voting prototype enhanced by LLM-guided\nsmart contract generation and validation, supported by a systematic framework\nand simulation-based analysis.", "AI": {"tldr": "The paper investigates the use of blockchain technology in E-Voting, addressing challenges like scalability and privacy while leveraging large language models (LLMs) for advanced capabilities.", "motivation": "To address the challenges of real-world adoption of blockchain-based E-Voting, such as scalability, high computational demands, and privacy complexities, and to explore how LLMs can contribute to this domain.", "method": "The authors provide a comparative analysis of blockchain architectures, consensus mechanisms, and cryptographic protocols, propose optimization strategies, and analyze the role of LLMs in smart contract generation and anomaly detection.", "result": "The study establishes a foundation for secure and scalable blockchain E-Voting systems and suggests practical optimization strategies and the integration of LLM capabilities for improved performance.", "conclusion": "This research helps advance blockchain-based E-Voting by offering a systematic framework, simulation-based validation, and potential for building intelligent systems with LLMs for national-scale deployments."}}
{"id": "2508.05977", "pdf": "https://arxiv.org/pdf/2508.05977", "abs": "https://arxiv.org/abs/2508.05977", "authors": ["Aoming Liang", "Chi Cheng", "Dashuai Chen", "Boai Sun", "Dixia Fan"], "title": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "In the domain of scientific machine learning, designing effective reward\nfunctions remains a challenge in reinforcement learning (RL), particularly in\nenvironments where task goals are difficult to specify numerically. Reward\nfunctions in existing work are predominantly based on heuristics, manual\nengineering, or task-specific tuning. In this work, we introduce a semantically\naligned reinforcement learning method where rewards are computed by aligning\nthe current state with a target semantic instruction using a\nSentence-Bidirectional Encoder Representations from Transformers (SBERT).\nInstead of relying on manually defined reward functions, the policy receives\nfeedback based on the reward, which is a cosine similarity between the goal\ntextual description and the statement description in the episode. We evaluated\nour approach in several environments and showed that semantic reward can guide\nlearning to achieve competitive control behavior, even in the absence of\nhand-crafted reward functions. Our study demonstrates a correlation between the\nlanguage embedding space and the conventional Euclidean space. This framework\nopens new horizons for aligning agent behavior with natural language goals and\nlays the groundwork for a more seamless integration of larger language models\n(LLMs) and fluid control applications.", "AI": {"tldr": "This paper introduces a semantic-based reward computation method for reinforcement learning (RL) using SBERT to align state and goal descriptions, eliminating the need for handcrafted rewards.", "motivation": "Current reinforcement learning struggles with designing effective reward functions in tasks with difficult-to-specify goals, often relying on heuristic or manually engineered solutions.", "method": "The authors propose a method that computes rewards based on the cosine similarity between natural language descriptions of task goals and states using Sentence-BERT (SBERT), replacing manually defined rewards.", "result": "Experiments across varied environments demonstrated that this semantic reward approach achieves competitive control behaviors without relying on handcrafted rewards.", "conclusion": "The study highlights the relationship between language embedding and Euclidean spaces, paving the way for integrating larger language models with RL for natural language-guided agent behaviors."}}
{"id": "2508.06229", "pdf": "https://arxiv.org/pdf/2508.06229", "abs": "https://arxiv.org/abs/2508.06229", "authors": ["Zihao Xu", "Ce Hao", "Chunzheng Wang", "Kuankuan Sima", "Fan Shi", "Jin Song Dong"], "title": "REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance", "categories": ["cs.RO"], "comment": null, "summary": "Dynamic obstacle avoidance (DOA) is critical for quadrupedal robots operating\nin environments with moving obstacles or humans. Existing approaches typically\nrely on navigation-based trajectory replanning, which assumes sufficient\nreaction time and leading to fails when obstacles approach rapidly. In such\nscenarios, quadrupedal robots require reflexive evasion capabilities to perform\ninstantaneous, low-latency maneuvers. This paper introduces Reflexive Evasion\nRobot (REBot), a control framework that enables quadrupedal robots to achieve\nreal-time reflexive obstacle avoidance. REBot integrates an avoidance policy\nand a recovery policy within a finite-state machine. With carefully designed\nlearning curricula and by incorporating regularization and adaptive rewards,\nREBot achieves robust evasion and rapid stabilization in instantaneous DOA\ntasks. We validate REBot through extensive simulations and real-world\nexperiments, demonstrating notable improvements in avoidance success rates,\nenergy efficiency, and robustness to fast-moving obstacles. Videos and appendix\nare available on https://rebot-2025.github.io/.", "AI": {"tldr": "The paper introduces a control framework (REBot) for dynamic obstacle avoidance (DOA) in quadrupedal robots, focusing on reflexive evasion to handle fast-moving obstacles.", "motivation": "To address the shortcomings of existing navigation-based trajectory replanning approaches, which fail when faced with rapidly approaching obstacles, and to equip quadrupedal robots with low-latency reflexive evasive capabilities.", "method": "The authors developed REBot, a control framework based on a finite-state machine that integrates an avoidance policy and a recovery policy. It features tailored learning curricula, regularization, and adaptive rewards to enhance performance in instantaneous DOA tasks.", "result": "REBot demonstrates significant improvements in obstacle avoidance success rates, energy efficiency, and robustness in both simulations and real-world experiments involving fast-moving obstacles.", "conclusion": "The proposed framework, REBot, equips quadrupedal robots with real-time reflexive evasion capabilities, addressing limitations in existing approaches and showing robust and efficient performance in dynamic environments."}}
{"id": "2508.06483", "pdf": "https://arxiv.org/pdf/2508.06483", "abs": "https://arxiv.org/abs/2508.06483", "authors": ["Ben Chugg", "Aaditya Ramdas"], "title": "A variational approach to dimension-free self-normalized concentration", "categories": ["math.PR", "math.ST", "stat.ML", "stat.TH"], "comment": "37 pages", "summary": "We study the self-normalized concentration of vector-valued stochastic\nprocesses. We focus on bounds for sub-$\\psi$ processes, a tail condition that\nencompasses a wide variety of well-known distributions (including\nsub-exponential, sub-Gaussian, sub-gamma, and sub-Poisson distributions). Our\nresults recover and generalize the influential bound of Abbasi-Yadkori et al.\n(2011) and fill a gap in the literature between determinant-based bounds and\nthose based on condition numbers. As applications we prove a Bernstein\ninequality for random vectors satisfying a moment condition (which is more\ngeneral than boundedness), and also provide the first dimension-free,\nself-normalized empirical Bernstein inequality. Our techniques are based on the\nvariational (PAC-Bayes) approach to concentration.", "AI": {"tldr": "This paper improves bounds for vector-valued stochastic processes, specifically for distributions satisfying a sub-psi tail condition, and offers new inequalities for improving concentration results.", "motivation": "The need to generalize existing bounds for stochastic processes, particularly addressing a gap between determinant-based bounds and condition-number-based bounds in the literature.", "method": "Use variational (PAC-Bayes) techniques to derive self-normalized concentration bounds for sub-psi processes, including more general conditions than boundedness.", "result": "Key results include a Bernstein inequality for random vectors with a general moment condition and a dimension-free, self-normalized empirical Bernstein inequality.", "conclusion": "The study advances concentration bounds for sub-psi processes, deepening understanding in this area of stochastic processes and providing more versatile tools for analysis."}}
{"id": "2508.06094", "pdf": "https://arxiv.org/pdf/2508.06094", "abs": "https://arxiv.org/abs/2508.06094", "authors": ["Morris Alper", "Moran Yanuka", "Raja Giryes", "Ga\u0161per Begu\u0161"], "title": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline", "categories": ["cs.CL"], "comment": "Project page: https://conlangcrafter.github.io", "summary": "Constructed languages (conlangs) such as Esperanto and Quenya have played\ndiverse roles in art, philosophy, and international communication. Meanwhile,\nlarge-scale foundation models have revolutionized creative generation in text,\nimages, and beyond. In this work, we leverage modern LLMs as computational\ncreativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a\nmulti-hop pipeline that decomposes language design into modular stages --\nphonology, morphology, syntax, lexicon generation, and translation. At each\nstage, our method leverages LLMs' meta-linguistic reasoning capabilities,\ninjecting randomness to encourage diversity and leveraging self-refinement\nfeedback to encourage consistency in the emerging language description. We\nevaluate ConlangCrafter on metrics measuring coherence and typological\ndiversity, demonstrating its ability to produce coherent and varied conlangs\nwithout human linguistic expertise.", "AI": {"tldr": "The paper introduces ConlangCrafter, a pipeline utilizing large language models (LLMs) for automated constructed language (conlang) generation, showcasing its ability to produce consistent and diverse languages without human expertise.", "motivation": "To explore how modern foundation models (i.e., LLMs) can assist in creative linguistic tasks, specifically in creating constructed languages, enhancing computational creativity in linguistics.", "method": "The paper proposes a multi-hop pipeline called ConlangCrafter, breaking down language design into modular stages (e.g., phonology, morphology, syntax) and leveraging LLM capabilities for randomness and self-refinement.", "result": "ConlangCrafter produces coherent, typologically diverse constructed languages, evaluated through specific metrics, proving effective even without human linguistic intervention.", "conclusion": "LLMs exhibit potential as powerful computational aids for creative linguistic tasks, providing a scalable methodology for conlang creation while ensuring both diversity and consistency."}}
{"id": "2508.06111", "pdf": "https://arxiv.org/pdf/2508.06111", "abs": "https://arxiv.org/abs/2508.06111", "authors": ["Dewi S. W. Gould", "Bruno Mlodozeniec", "Samuel F. Brown"], "title": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges", "categories": ["cs.AI"], "comment": "7 pages and appendices", "summary": "Evaluating the capabilities and risks of foundation models is paramount, yet\ncurrent methods demand extensive domain expertise, hindering their scalability\nas these models rapidly evolve. We introduce SKATE: a novel evaluation\nframework in which large language models (LLMs) compete by generating and\nsolving verifiable tasks for one another. Our core insight is to treat\nevaluation as a game: models act as both task-setters and solvers, incentivized\nto create questions which highlight their own strengths while exposing others'\nweaknesses. SKATE offers several key advantages, balancing scalability,\nopen-endedness, and objectivity. It is fully automated, data-free, and\nscalable, requiring no human input or domain expertise. By using verifiable\ntasks rather than LLM judges, scoring is objective. Unlike domain-limited\nprogrammatically-generated benchmarks (e.g. chess-playing or spatial\nreasoning), having LLMs creatively pose challenges enables open-ended and\nscalable evaluation. As a proof of concept, we introduce LLM-set\ncode-output-prediction (COP) challenges as a verifiable and extensible\nframework in which to test our approach. Using a TrueSkill-based ranking\nsystem, we evaluate six frontier LLMs and find that: (1) weaker models can\nreliably differentiate and score stronger ones, (2) LLM-based systems are\ncapable of self-preferencing behavior, generating questions that align with\ntheir own capabilities, and (3) SKATE automatically surfaces fine-grained\ncapability differences between models. Our findings are an important step\ntowards general, scalable evaluation frameworks which can keep pace with LLM\nprogress.", "AI": {"tldr": "SKATE is an automated framework for evaluating large language models (LLMs) by treating evaluation as a competitive game of task generation and solving.", "motivation": "Current evaluation methods for foundation models require extensive domain expertise, making them difficult to scale as models evolve rapidly.", "method": "The SKATE framework involves LLMs acting as both task-creators and solvers, using verifiable tasks to objectively evaluate performance without human input.", "result": "SKATE was tested using a code-output-prediction challenge and revealed that weaker models can score stronger ones, LLMs exhibit self-preferencing behavior, and fine-grained capability differences can be identified.", "conclusion": "SKATE represents a step forward in scalable, generalizable LLM evaluation methods that adapt to model advancements."}}
{"id": "2508.05903", "pdf": "https://arxiv.org/pdf/2508.05903", "abs": "https://arxiv.org/abs/2508.05903", "authors": ["Lang Nie", "Yuan Mei", "Kang Liao", "Yunqiu Xu", "Chunyu Lin", "Bin Xiao"], "title": "Robust Image Stitching with Optimal Plane", "categories": ["cs.CV"], "comment": "* Equal contribution", "summary": "We present \\textit{RopStitch}, an unsupervised deep image stitching framework\nwith both robustness and naturalness. To ensure the robustness of\n\\textit{RopStitch}, we propose to incorporate the universal prior of content\nperception into the image stitching model by a dual-branch architecture. It\nseparately captures coarse and fine features and integrates them to achieve\nhighly generalizable performance across diverse unseen real-world scenes.\nConcretely, the dual-branch model consists of a pretrained branch to capture\nsemantically invariant representations and a learnable branch to extract\nfine-grained discriminative features, which are then merged into a whole by a\ncontrollable factor at the correlation level. Besides, considering that content\nalignment and structural preservation are often contradictory to each other, we\npropose a concept of virtual optimal planes to relieve this conflict. To this\nend, we model this problem as a process of estimating homography decomposition\ncoefficients, and design an iterative coefficient predictor and minimal\nsemantic distortion constraint to identify the optimal plane. This scheme is\nfinally incorporated into \\textit{RopStitch} by warping both views onto the\noptimal plane bidirectionally. Extensive experiments across various datasets\ndemonstrate that \\textit{RopStitch} significantly outperforms existing methods,\nparticularly in scene robustness and content naturalness. The code is available\nat {\\color{red}https://github.com/MmelodYy/RopStitch}.", "AI": {"tldr": "This paper presents RopStitch, an unsupervised deep image stitching framework that ensures robustness and naturalness by using a dual-branch architecture and virtual optimal planes.", "motivation": "The paper aims to address the challenges of robustness and naturalness in image stitching, which are critical when dealing with diverse and unseen real-world scenes.", "method": "RopStitch uses a dual-branch architecture to capture coarse and fine image features and merges them at a correlation level. It also employs virtual optimal planes and homography decomposition coefficients for content alignment and structural preservation.", "result": "Extensive experiments show that RopStitch significantly outperforms existing methods in robustness and naturalness across various datasets.", "conclusion": "RopStitch is an effective and generalizable image stitching framework that provides superior scene robustness and content naturalness in unsupervised settings."}}
{"id": "2508.05883", "pdf": "https://arxiv.org/pdf/2508.05883", "abs": "https://arxiv.org/abs/2508.05883", "authors": ["Sean Feeney", "Reuben Tate", "John Golden", "Stephan Eidenbenz"], "title": "MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization", "categories": ["quant-ph", "cs.ET", "cs.SE"], "comment": "14 pages, 7 figures", "summary": "We present the MPS-JuliQAOA simulator, a user-friendly, open-source tool to\nsimulate the Quantum Approximate Optimization Algorithm (QAOA) of any\noptimization problem that can be expressed as diagonal Hamiltonian. By\nleveraging Julia-language constructs and the ITensor package to implement a\nMatrix Product State (MPS) approach to simulating QAOA, MPS-Juli-QAOA\neffortlessly scales to 512 qubits and 20 simulation rounds on the standard\nde-facto benchmark 3-regular MaxCut QAOA problem. MPS-JuliQAOA also has\nbuilt-in parameter finding capabilities, which is a crucial performance aspect\nof QAOA. We illustrate through examples that the user does not need to know MPS\nprinciples or complex automatic differentiation techniques to use MPS-JuliQAOA.\nWe study the scalability of our tool with respect to runtime, memory usage and\naccuracy tradeoffs. Code available at\nhttps://github.com/lanl/JuliQAOA.jl/tree/mps.", "AI": {"tldr": "The paper introduces MPS-JuliQAOA, an open-source simulator for Quantum Approximate Optimization Algorithm (QAOA) problems utilizing Matrix Product State (MPS) methods for scalability.", "motivation": "To provide an accessible, scalable tool for simulating QAOA problems, addressing challenges in parameter finding and the computational scalability of existing methods.", "method": "Employing Julia-language constructs and the ITensor package with MPS techniques, the tool supports QAOA simulation for large-scale problems of up to 512 qubits and multiple simulation rounds.", "result": "Achieves simulation scalability for 512 qubits and 20 rounds on the benchmark MaxCut problem, with built-in parameter finding capabilities for enhanced usability.", "conclusion": "MPS-JuliQAOA simplifies QAOA simulation for users without knowledge of MPS or advanced differentiation techniques, while proving efficient in runtime, memory usage, and accuracy tradeoffs."}}
{"id": "2508.05984", "pdf": "https://arxiv.org/pdf/2508.05984", "abs": "https://arxiv.org/abs/2508.05984", "authors": ["Ankur Naskar", "Gugan Thoppe", "Vijay Gupta"], "title": "Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning", "categories": ["cs.LG"], "comment": null, "summary": "Algorithms for solving \\textit{nonlinear} fixed-point equations -- such as\naverage-reward \\textit{$Q$-learning} and \\textit{TD-learning} -- often involve\nsemi-norm contractions. Achieving parameter-free optimal convergence rates for\nthese methods via Polyak--Ruppert averaging has remained elusive, largely due\nto the non-monotonicity of such semi-norms. We close this gap by (i.) recasting\nthe averaged error as a linear recursion involving a nonlinear perturbation,\nand (ii.) taming the nonlinearity by coupling the semi-norm's contraction with\nthe monotonicity of a suitably induced norm. Our main result yields the first\nparameter-free $\\tilde{O}(1/\\sqrt{t})$ optimal rates for $Q$-learning in both\naverage-reward and exponentially discounted settings, where $t$ denotes the\niteration index. The result applies within a broad framework that accommodates\nsynchronous and asynchronous updates, single-agent and distributed deployments,\nand data streams obtained either from simulators or along Markovian\ntrajectories.", "AI": {"tldr": "The paper introduces methods to achieve optimal convergence rates for nonlinear fixed-point algorithms, such as $Q$-learning and TD-learning, by overcoming the challenge of semi-norm non-monotonicity.", "motivation": "Nonlinear fixed-point algorithms like $Q$-learning and TD-learning often involve semi-norm contractions, but achieving optimal convergence rates has been challenging due to non-monotonicity.", "method": "The authors recast averaged errors as linear recursions with nonlinear perturbations and couple semi-norm contractions with the monotonicity of induced norms to tame nonlinearity.", "result": "The paper achieves parameter-free optimal convergence rates of $\tilde{O}(1/\\sqrt{t})$ for $Q$-learning methods in various settings, including synchronous, asynchronous, single-agent, distributed, and simulator-based deployments.", "conclusion": "These results contribute a unified framework for nonlinear fixed-point algorithms, addressing critical gaps in achieving optimal performance for both average-reward and discounted $Q$-learning."}}
{"id": "2508.06266", "pdf": "https://arxiv.org/pdf/2508.06266", "abs": "https://arxiv.org/abs/2508.06266", "authors": ["Zezeng Li", "Rui Yang", "Ruochen Chen", "ZhongXuan Luo", "Liming Chen"], "title": "ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints", "categories": ["cs.RO"], "comment": null, "summary": "Diffusion policies have recently emerged as a powerful class of visuomotor\ncontrollers for robot manipulation, offering stable training and expressive\nmulti-modal action modeling. However, existing approaches typically treat\naction generation as an unconstrained denoising process, ignoring valuable a\npriori knowledge about geometry and control structure. In this work, we propose\nthe Adaptive Diffusion Policy (ADP), a test-time adaptation method that\nintroduces two key inductive biases into the diffusion. First, we embed a\ngeometric manifold constraint that aligns denoising updates with task-relevant\nsubspaces, leveraging the fact that the relative pose between the end-effector\nand target scene provides a natural gradient direction, and guiding denoising\nalong the geodesic path of the manipulation manifold. Then, to reduce\nunnecessary exploration and accelerate convergence, we propose an analytically\nguided initialization: rather than sampling from an uninformative prior, we\ncompute a rough registration between the gripper and target scenes to propose a\nstructured initial noisy action. ADP is compatible with pre-trained diffusion\npolicies and requires no retraining, enabling test-time adaptation that tailors\nthe policy to specific tasks, thereby enhancing generalization across novel\ntasks and environments. Experiments on RLBench, CALVIN, and real-world dataset\nshow that ADPro, an implementation of ADP, improves success rates,\ngeneralization, and sampling efficiency, achieving up to 25% faster execution\nand 9% points over strong diffusion baselines.", "AI": {"tldr": "The paper introduces the Adaptive Diffusion Policy (ADP), a diffusion-based robot control approach that incorporates geometric and analytical constraints to improve performance and generalization without retraining.", "motivation": "To address the limitations of existing diffusion policies for robot manipulation, which overlook geometric and control constraints, and often result in slow convergence and suboptimal generalization.", "method": "The proposed ADP introduces two test-time adaptation biases: (1) a geometric manifold constraint to align denoising updates with task-relevant subspaces and guidance along the manipulation manifold; (2) an analytically guided initialization to provide structured noisy action proposals based on gripper-target registration. ADP integrates these into pre-trained diffusion policies.", "result": "ADP, demonstrated through its implementation called ADPro, improves success rates, generalization, and sampling efficiency in benchmarks and real-world settings. It achieves up to 25% faster execution and a 9% improvement over strong diffusion baselines.", "conclusion": "ADP effectively enhances diffusion policy performance by incorporating inductive biases at test time, enabling better task-specific adaptation, improved generalization, and faster convergence without the need for retraining."}}
{"id": "2508.06103", "pdf": "https://arxiv.org/pdf/2508.06103", "abs": "https://arxiv.org/abs/2508.06103", "authors": ["Mohamed Basem", "Islam Oshallah", "Ali Hamdi", "Ammar Mohammed"], "title": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs", "categories": ["cs.CL", "cs.IR"], "comment": "6 pages , 2 figures , Accepted in IMSA 2025,Egypt ,\n  https://imsa.msa.edu.eg/", "summary": "This paper presents two effective approaches for Extractive Question\nAnswering (QA) on the Quran. It addresses challenges related to complex\nlanguage, unique terminology, and deep meaning in the text. The second uses\nfew-shot prompting with instruction-tuned large language models such as Gemini\nand DeepSeek. A specialized Arabic prompt framework is developed for span\nextraction. A strong post-processing system integrates subword alignment,\noverlap suppression, and semantic filtering. This improves precision and\nreduces hallucinations. Evaluations show that large language models with Arabic\ninstructions outperform traditional fine-tuned models. The best configuration\nachieves a pAP10 score of 0.637. The results confirm that prompt-based\ninstruction tuning is effective for low-resource, semantically rich QA tasks.", "AI": {"tldr": "The paper proposes two approaches\u2014few-shot prompting with instruction-tuned large language models and a post-processing system\u2014for Extractive QA on the Quran. It includes an Arabic prompt framework and shows improved performance compared to traditional methods.", "motivation": "To address challenges in Extractive QA on the Quran, including its complex language, unique terminology, and deep semantic meanings.", "method": "The approach involves few-shot prompting with instruction-tuned large language models (like Gemini and DeepSeek), along with an Arabic prompt framework and a post-processing system for span extraction.", "result": "Evaluations indicate that the instruction-tuned large language models surpass traditional fine-tuned models, achieving a pAP10 score of 0.637.", "conclusion": "Prompt-based instruction tuning is effective for Extractive QA in low-resource, semantically rich tasks, such as on the Quran."}}
{"id": "2508.06129", "pdf": "https://arxiv.org/pdf/2508.06129", "abs": "https://arxiv.org/abs/2508.06129", "authors": ["Bachtiar Herdianto", "Romain Billot", "Flavien Lucas", "Marc Sevaux"], "title": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem", "categories": ["cs.AI"], "comment": "22 pages, 14 figures", "summary": "The Vehicle Routing Problem (VRP) is a complex optimization problem with\nnumerous real-world applications, mostly solved using metaheuristic algorithms\ndue to its $\\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely\non human-crafted designs developed through empirical studies. However, recent\nresearch shows that machine learning methods can be used the structural\ncharacteristics of solutions in combinatorial optimization, thereby aiding in\ndesigning more efficient algorithms, particularly for solving VRP. Building on\nthis advancement, this study extends the previous research by conducting a\nsensitivity analysis using multiple classifier models that are capable of\npredicting the quality of VRP solutions. Hence, by leveraging explainable AI,\nthis research is able to extend the understanding of how these models make\ndecisions. Finally, our findings indicate that while feature importance varies,\ncertain features consistently emerge as strong predictors. Furthermore, we\npropose a unified framework able of ranking feature impact across different\nscenarios to illustrate this finding. These insights highlight the potential of\nfeature importance analysis as a foundation for developing a guidance mechanism\nof metaheuristic algorithms for solving the VRP.", "AI": {"tldr": "This paper explores leveraging machine learning, specifically explainable AI, to predict the quality of VRP solutions and analyze feature importance across different scenarios.", "motivation": "Traditional VRP methods rely on human-crafted metaheuristics, which are limited in adaptability. Machine learning methods offer potential for improvement by analyzing structural solution features.", "method": "The study conducts sensitivity analysis using multiple classifier models capable of predicting VRP solution quality. It employs feature importance analysis through explainable AI.", "result": "The research identified consistent feature predictors, despite variability in importance, and proposed a unified framework for ranking their impact across diverse scenarios.", "conclusion": "Feature importance analysis can inform metaheuristic algorithm design, enhancing their efficiency in solving VRPs."}}
{"id": "2508.05907", "pdf": "https://arxiv.org/pdf/2508.05907", "abs": "https://arxiv.org/abs/2508.05907", "authors": ["Ilya Chugunov"], "title": "Neural Field Representations of Mobile Computational Photography", "categories": ["cs.CV"], "comment": "PhD thesis", "summary": "Over the past two decades, mobile imaging has experienced a profound\ntransformation, with cell phones rapidly eclipsing all other forms of digital\nphotography in popularity. Today's cell phones are equipped with a diverse\nrange of imaging technologies - laser depth ranging, multi-focal camera arrays,\nand split-pixel sensors - alongside non-visual sensors such as gyroscopes,\naccelerometers, and magnetometers. This, combined with on-board integrated\nchips for image and signal processing, makes the cell phone a versatile\npocket-sized computational imaging platform. Parallel to this, we have seen in\nrecent years how neural fields - small neural networks trained to map\ncontinuous spatial input coordinates to output signals - enable the\nreconstruction of complex scenes without explicit data representations such as\npixel arrays or point clouds. In this thesis, I demonstrate how carefully\ndesigned neural field models can compactly represent complex geometry and\nlighting effects. Enabling applications such as depth estimation, layer\nseparation, and image stitching directly from collected in-the-wild mobile\nphotography data. These methods outperform state-of-the-art approaches without\nrelying on complex pre-processing steps, labeled ground truth data, or machine\nlearning priors. Instead, they leverage well-constructed, self-regularized\nmodels that tackle challenging inverse problems through stochastic gradient\ndescent, fitting directly to raw measurements from a smartphone.", "AI": {"tldr": "This paper explores using neural field models to enhance mobile photography by representing complex geometry and lighting effects, enabling advanced imaging applications like depth estimation and image stitching.", "motivation": "The paper aims to leverage advancements in computational imaging and neural mapping techniques to address challenges in mobile photography and enhance its potential for sophisticated applications.", "method": "The authors propose well-constructed, self-regularized neural field models that fit directly to raw data from smartphone sensors using stochastic gradient descent without relying on complex preprocessing or labeled data.", "result": "The proposed neural field models demonstrated superior performance in applications like depth estimation, layer separation, and image stitching compared to state-of-the-art methods.", "conclusion": "The study concludes that neural fields represent a promising and efficient approach to solving complex inverse problems in mobile photography, expanding its capabilities with less dependency on traditional machine learning techniques."}}
{"id": "2508.05988", "pdf": "https://arxiv.org/pdf/2508.05988", "abs": "https://arxiv.org/abs/2508.05988", "authors": ["Wenhao Zeng", "Yaoning Wang", "Chao Hu", "Yuling Shi", "Chengcheng Wan", "Hongyu Zhang", "Xiaodong Gu"], "title": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal", "categories": ["cs.LG", "cs.SE"], "comment": "Code and model available at https://github.com/Zengwh02/ASAP", "summary": "Recently, Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in code reasoning by scaling up the length of Chain-of-Thought\n(CoT). However, excessively long reasoning traces introduce substantial\nchallenges in terms of training cost, inference latency, and deployment\nfeasibility. While various CoT compression approaches have emerged to address\nthis challenge, they face inherent trade-offs: token-level methods often\ndisrupt syntactic and logical coherence, while step-level methods based on\nperplexity fail to reliably capture the logically critical reasoning steps. In\nthis paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel\ncoarse-to-fine framework for CoT compression. ASAP first performs anchor-guided\npruning to preserve the core reasoning structure, which efficiently reduces the\nsearch space for subsequent processing. It then enables a logic-aware pruning\nby selecting logically essential reasoning steps based on a novel first-token\nsurprisal metric. Finally, ASAP teaches models to autonomously generate and\nleverage these concise CoTs at inference time, enabling efficient reasoning in\ncoding tasks. Experiments show that ASAP achieves state-of-the-art accuracy\nacross multiple code generation benchmarks while substantially reducing\ntraining and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,\nour approach reduces token generation by 23.5% and inference latency by 43.5%\ncompared to the strongest baseline, while achieving a competitive accuracy of\n36.19% in Pass@1. Our results highlight a promising direction for building\npowerful and efficient LRMs.", "AI": {"tldr": "ASAP introduces a novel method to compress reasoning traces in large reasoning models for efficient coding tasks, achieving state-of-the-art metrics while reducing cost and latency.", "motivation": "Long reasoning chains in code reasoning tasks create challenges due to higher training costs, inference latency, and deployment feasibility.", "method": "ASAP performs anchor-guided pruning to preserve the core reasoning structure and uses a logic-aware pruning based on a first-token surprisal metric.", "result": "ASAP reduces token generation by 23.5% and inference latency by 43.5% while maintaining competitive accuracy of 36.19% on challenging code benchmarks.", "conclusion": "ASAP provides a promising approach toward effective and efficient large reasoning models by improving reasoning trace compression without compromising accuracy."}}
{"id": "2508.06276", "pdf": "https://arxiv.org/pdf/2508.06276", "abs": "https://arxiv.org/abs/2508.06276", "authors": ["Juan Heredia", "Christian Schlette", "Mikkel Baun Kj\u00e6rgaard"], "title": "EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators", "categories": ["cs.RO"], "comment": null, "summary": "Existing literature proposes models for estimating the electrical power of\nmanipulators, yet two primary limitations prevail. First, most models are\npredominantly tested using traditional industrial robots. Second, these models\noften lack accuracy. To address these issues, we introduce an open source\nMatlab-based library designed to automatically generate \\ac{ec} models for\nmanipulators. The necessary inputs for the library are Denavit-Hartenberg\nparameters, link masses, and centers of mass. Additionally, our model is\ndata-driven and requires real operational data, including joint positions,\nvelocities, accelerations, electrical power, and corresponding timestamps. We\nvalidated our methodology by testing on four lightweight robots sourced from\nthree distinct manufacturers: Universal Robots, Franka Emika, and Kinova. The\nmodel underwent testing, and the results demonstrated an RMSE ranging from 1.42\nW to 2.80 W for the training dataset and from 1.45 W to 5.25 W for the testing\ndataset.", "AI": {"tldr": "This paper introduces a Matlab-based library for generating electrical power estimation models for manipulators, validated on lightweight robots with improved accuracy.", "motivation": "The paper addresses the limitations in existing models for estimating electrical power in manipulators, particularly their focus on traditional robots and lack of accuracy.", "method": "The authors developed a Matlab-based, open-source library that utilizes real operational data and specific inputs such as Denavit-Hartenberg parameters, link masses, and centers of mass to generate data-driven electrical power estimation models.", "result": "The methodology was tested on four lightweight robots from Universal Robots, Franka Emika, and Kinova, yielding RMSE between 1.42 W and 2.80 W for training data and between 1.45 W and 5.25 W for testing data.", "conclusion": "The study demonstrates that the developed library is effective and accurate for creating electrical power estimation models for lightweight manipulators, offering higher precision compared to previous models."}}
{"id": "2508.06105", "pdf": "https://arxiv.org/pdf/2508.06105", "abs": "https://arxiv.org/abs/2508.06105", "authors": ["Shengyuan Chen", "Chuang Zhou", "Zheng Yuan", "Qinggang Zhang", "Zeyang Cui", "Hao Chen", "Yilin Xiao", "Jiannong Cao", "Xiao Huang"], "title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) often suffer from hallucination, generating\nfactually incorrect statements when handling questions beyond their knowledge\nand perception. Retrieval-augmented generation (RAG) addresses this by\nretrieving query-relevant contexts from knowledge bases to support LLM\nreasoning. Recent advances leverage pre-constructed graphs to capture the\nrelational connections among distributed documents, showing remarkable\nperformance in complex tasks. However, existing Graph-based RAG (GraphRAG)\nmethods rely on a costly process to transform the corpus into a graph,\nintroducing overwhelming token cost and update latency. Moreover, real-world\nqueries vary in type and complexity, requiring different logic structures for\naccurate reasoning. The pre-built graph may not align with these required\nstructures, resulting in ineffective knowledge retrieval. To this end, we\npropose a \\textbf{\\underline{Logic}}-aware\n\\textbf{\\underline{R}}etrieval-\\textbf{\\underline{A}}ugmented\n\\textbf{\\underline{G}}eneration framework (\\textbf{LogicRAG}) that dynamically\nextracts reasoning structures at inference time to guide adaptive retrieval\nwithout any pre-built graph. LogicRAG begins by decomposing the input query\ninto a set of subproblems and constructing a directed acyclic graph (DAG) to\nmodel the logical dependencies among them. To support coherent multi-step\nreasoning, LogicRAG then linearizes the graph using topological sort, so that\nsubproblems can be addressed in a logically consistent order. Besides, LogicRAG\napplies graph pruning to reduce redundant retrieval and uses context pruning to\nfilter irrelevant context, significantly reducing the overall token cost.\nExtensive experiments demonstrate that LogicRAG achieves both superior\nperformance and efficiency compared to state-of-the-art baselines.", "AI": {"tldr": "LogicRAG offers a dynamic, logic-aware framework for Retrieval-Augmented Generation without relying on pre-built graphs, addressing the issues of token cost and inefficiency in adapting to query complexity.", "motivation": "To address the limitations of existing Graph-based Retrieval-Augmented Generation (GraphRAG) methods that are resource-intensive and lack adaptability for diverse query types.", "method": "LogicRAG decomposes input queries into subproblems, constructs directed acyclic graphs (DAGs), uses topological sorting for logical progression, and applies pruning mechanisms to optimize retrieval and context management.", "result": "LogicRAG demonstrates superior performance and efficiency over state-of-the-art RAG methods through extensive experimental validation.", "conclusion": "LogicRAG provides an effective and resource-efficient solution for dynamic and logic-aware retrieval-augmented generation, eliminating reliance on pre-built graphs and enhancing reasoning capabilities."}}
{"id": "2508.06145", "pdf": "https://arxiv.org/pdf/2508.06145", "abs": "https://arxiv.org/abs/2508.06145", "authors": ["Byeonghun Bang", "Jongsuk Yoon", "Dong-Jin Chang", "Seho Park", "Yong Oh Lee"], "title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications", "categories": ["cs.AI"], "comment": null, "summary": "The versatility of large language models (LLMs) has been explored across\nvarious sectors, but their application in healthcare poses challenges,\nparticularly in the domain of pharmaceutical contraindications where accurate\nand reliable information is required. This study enhances the capability of\nLLMs to address contraindications effectively by implementing a Retrieval\nAugmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base\nmodel, and the text-embedding-3-small model for embeddings, our approach\nintegrates Langchain to orchestrate a hybrid retrieval system with re-ranking.\nThis system leverages Drug Utilization Review (DUR) data from public databases,\nfocusing on contraindications for specific age groups, pregnancy, and\nconcomitant drug use. The dataset includes 300 question-answer pairs across\nthree categories, with baseline model accuracy ranging from 0.49 to 0.57.\nPost-integration of the RAG pipeline, we observed a significant improvement in\nmodel accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications\nrelated to age groups, pregnancy, and concomitant drug use, respectively. The\nresults indicate that augmenting LLMs with a RAG framework can substantially\nreduce uncertainty in prescription and drug intake decisions by providing more\nprecise and reliable drug contraindication information.", "AI": {"tldr": "The paper enhanced large language models (LLMs) for healthcare applications, specifically to improve accuracy in identifying pharmaceutical contraindications using a Retrieval Augmented Generation (RAG) pipeline.", "motivation": "The study aims to tackle the challenge of applying LLMs in healthcare, especially in delivering precise and reliable information about pharmaceutical contraindications.", "method": "The approach utilizes OpenAI's GPT-4o-mini model for language generation and the text-embedding-3-small model for embeddings. It incorporates a hybrid retrieval system orchestrated by Langchain, leveraging Drug Utilization Review (DUR) data from public databases.", "result": "The integration of the RAG pipeline significantly improved LLM accuracy, achieving scores of 0.94, 0.87, and 0.89 in contraindication categories (age groups, pregnancy, and concomitant drug use), compared to a baseline of 0.49 to 0.57.", "conclusion": "Augmenting LLMs with a RAG pipeline shows promise in improving decision-making in healthcare by providing precise drug contraindication information."}}
{"id": "2508.05922", "pdf": "https://arxiv.org/pdf/2508.05922", "abs": "https://arxiv.org/abs/2508.05922", "authors": ["Sri Ramana Saketh Vasanthawada", "Pengkun Liu", "Pingbo Tang"], "title": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Monitoring construction progress is crucial yet resource-intensive, prompting\nthe exploration of computer-vision-based methodologies for enhanced efficiency\nand scalability. Traditional data acquisition methods, primarily focusing on\nindoor environments, falter in construction site's complex, cluttered, and\ndynamically changing conditions. This paper critically evaluates the\napplication of two advanced 3D segmentation methods, Segment Anything Model\n(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained\ninitially on indoor datasets, both models' adaptability and performance are\nassessed in real-world construction settings, highlighting the gap in current\nsegmentation approaches due to the absence of benchmarks for outdoor scenarios.\nThrough a comparative analysis, this study not only showcases the relative\neffectiveness of SAM and Mask3D but also addresses the critical need for\ntailored segmentation workflows capable of extracting actionable insights from\nconstruction site data, thereby advancing the field towards more automated and\nprecise monitoring techniques.", "AI": {"tldr": "The paper evaluates SAM and Mask3D's performance in construction progress monitoring, highlighting limits in their adaptability to outdoor scenarios.", "motivation": "Improving efficiency and scalability in construction progress monitoring through computer-vision methods.", "method": "Comparative evaluation of SAM and Mask3D in real-world construction environments and analyzing their segmentation capabilities.", "result": "Weaknesses in current approaches for outdoor segmentation were noted, suggesting SAM and Mask3D need tailored workflows for better performance.", "conclusion": "Advancements in automated techniques require improved methods for 3D segmentation in dynamic construction settings."}}
{"id": "2508.05995", "pdf": "https://arxiv.org/pdf/2508.05995", "abs": "https://arxiv.org/abs/2508.05995", "authors": ["Fei Xu Yu", "Gina Adam", "Nathaniel D. Bastian", "Tian Lan"], "title": "Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation and structured reasoning; however, their performance often\ndegrades on complex tasks that require consistent multi-step planning. Recent\nwork has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet\nexisting approaches primarily focus on generating heuristic-based code for\noptimization or target simpler tasks where correctness alone is sufficient. In\nthis work, we propose MCTS-OPS, a novel neural-symbolic framework that\nformulates prompt selection as a sequential decision process guided by MCTS.\nOur method explores and refines multi-step prompt sequences for the goal of\nimproving code generation quality and enhancing the problem-solving\ncapabilities of LLMs in general optimization. Experiments on network\noptimization show significant improvement over the baselines, both in the\nsuccess rate of executing the generated code and in the optimization results\nwith the specified objective and constraints (2$\\sim$4$\\times$ higher reward\nand 3$\\times$ lower standard deviation). Moreover, it improves the chance of\nattaining the optimal solution by about 10\\% of cases, compared to baseline\nmethods in hard problems. These results highlight the promise of combining\nsymbolic planning with LLMs for robust, high-quality code generation in complex\ndomains.", "AI": {"tldr": "The paper introduces MCTS-OPS, a framework merging Monte Carlo Tree Search (MCTS) with prompt selection in large language models (LLMs) to improve multi-step tasks, showing significant improvements in code execution success and optimization results.", "motivation": "To address the performance drop of LLMs on complex tasks requiring consistent multi-step planning and explore neural-symbolic frameworks for improving code generation.", "method": "The method integrates MCTS to guide sequential decision-making in prompt selection, refining prompt sequences for LLM-based code generation and optimization in complex tasks.", "result": "Experiments on network optimization demonstrate improved code execution success, optimization quality (2-4x higher reward, 3x lower standard deviation), and enhanced probability of attaining optimal solutions (+10% in hard problems).", "conclusion": "MCTS-OPS effectively combines symbolic planning with LLMs to enhance problem-solving capabilities and code generation quality in complex domains."}}
{"id": "2508.06278", "pdf": "https://arxiv.org/pdf/2508.06278", "abs": "https://arxiv.org/abs/2508.06278", "authors": ["Petr Novak", "Stefan Biffl", "Marek Obitko", "Petr Kadera"], "title": "Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs", "categories": ["cs.RO"], "comment": "3 pages, 1 figure", "summary": "Contemporary industrial cyber-physical production systems (CPPS) composed of\nrobotic workcells face significant challenges in the analysis of undesired\nconditions due to the flexibility of Industry 4.0 that disrupts traditional\nquality assurance mechanisms. This paper presents a novel industry-oriented\nsemantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG),\nwhich is designed to analyze and mitigate undesired conditions in flexible\nCPPS. Built on top of the well-proven Product-Process-Resource (PPR) model\noriginating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses\nshortcomings of conventional model-driven engineering for CPPS, particularly\ninadequate undesired condition and error handling representation. The\nintegration of semantic technologies with large language models (LLMs) provides\nintuitive interfaces for factory operators, production planners, and engineers\nto interact with the entire model using natural language. Evaluation with the\nuse case addressing electric vehicle battery remanufacturing demonstrates that\nthe PPR-AKG approach efficiently supports resource allocation based on\nexplicitly represented capabilities as well as identification and mitigation of\nundesired conditions in production. The key contributions include (1) a\nholistic PPR-AKG model capturing multi-dimensional production knowledge, and\n(2) the useful combination of the PPR-AKG with LLM-based chatbots for human\ninteraction.", "AI": {"tldr": "This paper introduces PPR-AKG, a semantic model for addressing undesired conditions in flexible CPPS using OWL ontology and LLMs.", "motivation": "Address the challenges in undesired condition analysis and quality assurance in the flexible and dynamic Industry 4.0 CPPS.", "method": "The authors developed the Product-Process-Resource Asset Knowledge Graph (PPR-AKG) built on the Product-Process-Resource model, integrated it with OWL ontology for error handling, and combined it with LLM-based chatbot interfaces.", "result": "Evaluation in the context of electric vehicle battery remanufacturing confirmed the model's utility in resource allocation and mitigating undesired conditions.", "conclusion": "PPR-AKG provides an effective framework for analyzing and mitigating undesired conditions in CPPS, offering an approachable and interactive solution for industry stakeholders."}}
{"id": "2508.06124", "pdf": "https://arxiv.org/pdf/2508.06124", "abs": "https://arxiv.org/abs/2508.06124", "authors": ["Sayantan Adak", "Pratyush Chatterjee", "Somnath Banerjee", "Rima Hazra", "Somak Aditya", "Animesh Mukherjee"], "title": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Present day LLMs face the challenge of managing affordance-based safety\nrisks-situations where outputs inadvertently facilitate harmful actions due to\noverlooked logical implications. Traditional safety solutions, such as scalar\noutcome-based reward models, parameter tuning, or heuristic decoding\nstrategies, lack the granularity and proactive nature needed to reliably detect\nand intervene during subtle yet crucial reasoning steps. Addressing this\nfundamental gap, we introduce AURA, an innovative, multi-layered framework\ncentered around Process Reward Models (PRMs), providing comprehensive, step\nlevel evaluations across logical coherence and safety-awareness. Our framework\nseamlessly combines introspective self-critique, fine-grained PRM assessments,\nand adaptive safety-aware decoding to dynamically and proactively guide models\ntoward safer reasoning trajectories. Empirical evidence clearly demonstrates\nthat this approach significantly surpasses existing methods, significantly\nimproving the logical integrity and affordance-sensitive safety of model\noutputs. This research represents a pivotal step toward safer, more\nresponsible, and contextually aware AI, setting a new benchmark for\nalignment-sensitive applications.", "AI": {"tldr": "The paper introduces AURA, a new framework using Process Reward Models (PRMs) to enhance logical coherence and safety in AI reasoning, outperforming existing safety measures.", "motivation": "Current large language models (LLMs) struggle with affordance-based safety risks, where outputs can unintentionally lead to harmful actions due to overlooked logical implications.", "method": "The authors propose a multi-layered framework (AURA) combining introspective self-critique, PRMs for step-by-step evaluations, and adaptive decoding to guide safer reasoning.", "result": "Empirical evidence shows that AURA significantly improves logical integrity and affordance-sensitive safety compared to traditional methods.", "conclusion": "AURA marks a meaningful advancement in creating safer, context-aware AI, setting a higher standard for alignment-sensitive applications."}}
{"id": "2508.06225", "pdf": "https://arxiv.org/pdf/2508.06225", "abs": "https://arxiv.org/abs/2508.06225", "authors": ["Zailong Tian", "Zhuoheng Han", "Yanzhe Chen", "Haozhe Xu", "Xi Yang", "richeng xuan", "Hongfeng Wang", "Lizi Liao"], "title": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are widely used as automated judges, where\npractical value depends on both accuracy and trustworthy, risk-aware judgments.\nExisting approaches predominantly focus on accuracy, overlooking the necessity\nof well-calibrated confidence, which is vital for adaptive and reliable\nevaluation pipelines. In this work, we advocate a shift from accuracy-centric\nevaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing\nthe necessity of well-calibrated confidence for trustworthy and adaptive\nevaluation. We systematically identify the **Overconfidence Phenomenon** in\ncurrent LLM-as-a-Judges, where predicted confidence significantly overstates\nactual correctness, undermining reliability in practical deployment. To\nquantify this phenomenon, we introduce **TH-Score**, a novel metric measuring\nconfidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an\nensemble framework that transforms LLMs into reliable, risk-aware evaluators.\nExtensive experiments demonstrate that our approach substantially improves\ncalibration and enables adaptive, confidence-driven evaluation pipelines,\nachieving superior reliability and accuracy compared to existing baselines.", "AI": {"tldr": "This paper introduces the Overconfidence Phenomenon observed in current LLM-based judgment systems and proposes solutions for improving calibrated confidence. It introduces the TH-Score metric and an LLM-as-a-Fuser ensemble framework for risk-aware evaluations.", "motivation": "The motivation behind this paper is to improve the reliability and trustworthiness of LLMs when used as automated judges, focusing on the issue of overconfidence in their predictions.", "method": "The authors identify the Overconfidence Phenomenon in LLMs and introduce TH-Score, a metric to quantify confidence-accuracy alignment. Additionally, they propose LLM-as-a-Fuser, an ensemble framework to enhance calibration and reliability.", "result": "The proposed methods significantly improve confidence calibration and enable adaptive evaluation pipelines, achieving better reliability and accuracy compared to current approaches.", "conclusion": "The paper advocates for a confidence-driven, risk-aware evaluation system for LLMs-as-a-Judges, emphasizing the significance of calibrated confidence in practical usage."}}
{"id": "2508.05950", "pdf": "https://arxiv.org/pdf/2508.05950", "abs": "https://arxiv.org/abs/2508.05950", "authors": ["Yanxing Liang", "Yinghui Wang", "Jinlong Yang", "Wei Li"], "title": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The lack of spatial dimensional information remains a challenge in normal\nestimation from a single image. Recent diffusion-based methods have\ndemonstrated significant potential in 2D-to-3D implicit mapping, they rely on\ndata-driven statistical priors and miss the explicit modeling of light-surface\ninteraction, leading to multi-view normal direction conflicts. Moreover, the\ndiscrete sampling mechanism of diffusion models causes gradient discontinuity\nin differentiable rendering reconstruction modules, preventing 3D geometric\nerrors from being backpropagated to the normal generation network, thereby\nforcing existing methods to depend on dense normal annotations. This paper\nproposes SINGAD, a novel Self-supervised framework from a single Image for\nNormal estimation via 3D GAussian splatting guided Diffusion. By integrating\nphysics-driven light-interaction modeling and a differentiable rendering-based\nreprojection strategy, our framework directly converts 3D geometric errors into\nnormal optimization signals, solving the challenges of multi-view geometric\ninconsistency and data dependency. Specifically, the framework constructs a\nlight-interaction-driven 3DGS reparameterization model to generate multi-scale\ngeometric features consistent with light transport principles, ensuring\nmulti-view normal consistency. A cross-domain feature fusion module is designed\nwithin a conditional diffusion model, embedding geometric priors to constrain\nnormal generation while maintaining accurate geometric error propagation.\nFurthermore, a differentiable 3D reprojection loss strategy is introduced for\nself-supervised optimization that minimizes geometric error between the\nreconstructed and input image, eliminating dependence on annotated normal\ndatasets. Quantitative evaluations on the Google Scanned Objects dataset\ndemonstrate that our method outperforms state-of-the-art approaches across\nmultiple metrics.", "AI": {"tldr": "This paper introduces SINGAD, a framework that improves single-image normal estimation by integrating physics-based modeling and a differentiable rendering strategy, addressing inconsistencies and reducing the need for dense annotations.", "motivation": "To address challenges in single-image normal estimation, including multi-view inconsistencies and reliance on dense annotations, by exploiting light-surface interaction modeling.", "method": "The SINGAD framework incorporates a 3D Gaussian splatting reparameterization model, geometric feature extraction guided by light transport principles, cross-domain fusion for embedding priors in a diffusion model, and a self-supervised differentiable reprojection loss strategy.", "result": "SINGAD achieves consistent multi-view normal estimations and eliminates reliance on annotated datasets. It outperforms existing methods in experimental evaluations on the Google Scanned Objects dataset across various metrics.", "conclusion": "SINGAD provides an effective, self-supervised solution for single-image normal estimation using physics-aware modeling and optimized diffusion frameworks."}}
{"id": "2508.06023", "pdf": "https://arxiv.org/pdf/2508.06023", "abs": "https://arxiv.org/abs/2508.06023", "authors": ["Xiaobin Shen", "Jonathan Elmer", "George H. Chen"], "title": "Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients", "categories": ["cs.LG"], "comment": null, "summary": "Prognostication for comatose post-cardiac arrest patients is a critical\nchallenge that directly impacts clinical decision-making in the ICU. Clinical\ninformation that informs prognostication is collected serially over time.\nShortly after cardiac arrest, various time-invariant baseline features are\ncollected (e.g., demographics, cardiac arrest characteristics). After ICU\nadmission, additional features are gathered, including time-varying hemodynamic\ndata (e.g., blood pressure, doses of vasopressor medications). We view these as\ntwo phases in which we collect new features. In this study, we propose a novel\nstepwise dynamic competing risks model that improves the prediction of\nneurological outcomes by automatically determining when to take advantage of\ntime-invariant features (first phase) and time-varying features (second phase).\nNotably, our model finds patients for whom this second phase (time-varying\nhemodynamic) information is beneficial for prognostication and also when this\ninformation is beneficial (as we collect more hemodynamic data for a patient\nover time, how important these data are for prognostication varies). Our\napproach extends the standard Fine and Gray model to explicitly model the two\nphases and to incorporate neural networks to flexibly capture complex nonlinear\nfeature relationships. Evaluated on a retrospective cohort of 2,278 comatose\npost-arrest patients, our model demonstrates robust discriminative performance\nfor the competing outcomes of awakening, withdrawal of life-sustaining therapy,\nand death despite maximal support. Our approach generalizes to more than two\nphases in which new features are collected and could be used in other dynamic\nprediction tasks, where it may be helpful to know when and for whom newly\ncollected features significantly improve prediction.", "AI": {"tldr": "This paper introduces a novel dynamic prediction model for neurologic outcomes in post-cardiac arrest patients, leveraging baseline and time-varying features to improve clinical prognostication.", "motivation": "Prognostication for post-cardiac arrest patients is challenging due to the evolving nature of clinical data collected in ICU settings. Existing methods inadequately address when and how to use these time-invariant and time-varying features.", "method": "The researchers propose a stepwise dynamic competing risks model, extending the Fine and Gray model and incorporating neural networks to flexibly capture nonlinear relationships. The model unfolds in two phases, utilizing both baseline and hemodynamic features over time.", "result": "The proposed model, evaluated on 2,278 retrospective cases, shows strong predictive performance for three competing outcomes: awakening, withdrawal of life-sustaining therapy, and death despite support.", "conclusion": "This dynamic model enhances prognostication, particularly identifying when and for whom additional ICU data is meaningful. The approach is generalizable to other domains where features are sequentially collected."}}
{"id": "2508.06283", "pdf": "https://arxiv.org/pdf/2508.06283", "abs": "https://arxiv.org/abs/2508.06283", "authors": ["Saad Ejaz", "Marco Giberna", "Muhammad Shaheer", "Jose Andres Millan-Romera", "Ali Tourani", "Paul Kremer", "Holger Voos", "Jose Luis Sanchez-Lopez"], "title": "Situationally-aware Path Planning Exploiting 3D Scene Graphs", "categories": ["cs.RO"], "comment": null, "summary": "3D Scene Graphs integrate both metric and semantic information, yet their\nstructure remains underutilized for improving path planning efficiency and\ninterpretability. In this work, we present S-Path, a situationally-aware path\nplanner that leverages the metric-semantic structure of indoor 3D Scene Graphs\nto significantly enhance planning efficiency. S-Path follows a two-stage\nprocess: it first performs a search over a semantic graph derived from the\nscene graph to yield a human-understandable high-level path. This also\nidentifies relevant regions for planning, which later allows the decomposition\nof the problem into smaller, independent subproblems that can be solved in\nparallel. We also introduce a replanning mechanism that, in the event of an\ninfeasible path, reuses information from previously solved subproblems to\nupdate semantic heuristics and prioritize reuse to further improve the\nefficiency of future planning attempts. Extensive experiments on both\nreal-world and simulated environments show that S-Path achieves average\nreductions of 5.7x in planning time while maintaining comparable path\noptimality to classical sampling-based planners and surpassing them in complex\nscenarios, making it an efficient and interpretable path planner for\nenvironments represented by indoor 3D Scene Graphs.", "AI": {"tldr": "The paper introduces S-Path, a path planning framework leveraging 3D Scene Graphs for efficient and interpretable indoor navigation.", "motivation": "Current path planning methods underutilize the combination of metric and semantic information inherent in 3D Scene Graphs.", "method": "The S-Path method uses a two-stage process: semantic graph search for human-level path understanding followed by problem decomposition into smaller sub-problems solved in parallel. It includes a replanning mechanism to optimize paths when infeasibility arises.", "result": "S-Path demonstrated a 5.7x reduction in planning time while maintaining path optimality comparable to classical methods, outperforming them in complex scenarios.", "conclusion": "S-Path is proven to be an efficient and interpretable path planning technique for environments structured by 3D Scene Graphs."}}
{"id": "2508.06135", "pdf": "https://arxiv.org/pdf/2508.06135", "abs": "https://arxiv.org/abs/2508.06135", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Knowledge Distillation (KD) is a fundamental technique for compressing large\nlanguage models (LLMs) into compact, efficient student models. However,\nexisting white-box KD methods mainly focus on balancing ground truth and\nstudent-generated responses while overlooking two critical factors: training\ndata quality and student-model compatibility. To address these limitations, we\npropose Selective Reflection Distillation (SRD), a novel data curation\nframework that leverages reflections from student models to systematically\nrefine training data. SRD dynamically evaluates and selects prompt-response\npairs by comparing ground truth data with student model outputs, selectively\ncurating high-quality, student-compatible training instances through automated\nranking based on difficulty. Furthermore, after selecting the training data, a\ncurriculum scheduling strategy is employed to incrementally introduce these\ncurated subsets into the distillation process at fixed intervals. As a\nplug-and-play enhancement, SRD consistently improves distillation outcomes\nacross diverse white-box KD approaches and model architectures, as well as\ndecreases computational cost significantly during KD training. Experiments on a\nrange of language model benchmarks demonstrate SRD's consistent improvements in\ndistilled model performance, as well as a reduction in training runtime by up\nto 39%, under diverse KD methods and model families. Notably, SRD operates as a\nplug-and-play module, enhancing sample efficiency without modifying underlying\nKD algorithms. Our findings highlight that data quality and compatibility are\npivotal to effective and efficient distillation of LLMs, and SRD provides a\nprincipled framework to achieve both. This work advances the understanding of\ndata-centric factors in KD and offers practical insights for enhancing the\ncapability and efficiency of compressed LLMs.", "AI": {"tldr": "Selective Reflection Distillation (SRD) improves the efficiency and performance of compressing large language models by refining training data and implementing curriculum scheduling.", "motivation": "Address the limitations of existing Knowledge Distillation methods by prioritizing training data quality and compatibility with student models.", "method": "Propose a data curation framework (SRD) that evaluates and selects training data based on comparison between ground truth and student outputs, alongside a curriculum scheduling strategy for incremental training.", "result": "SRD consistently improves distilled model performance across various model architectures, reduces KD training runtime by up to 39%, and enhances sample efficiency without altering core KD algorithms.", "conclusion": "SRD highlights the importance of data quality and compatibility in Knowledge Distillation, providing a scalable framework to refine training processes and improve outcomes."}}
{"id": "2508.06226", "pdf": "https://arxiv.org/pdf/2508.06226", "abs": "https://arxiv.org/abs/2508.06226", "authors": ["Yumeng Fu", "Jiayin Zhu", "Lingling Zhang", "Bo Zhao", "Shaoxuan Ma", "Yushun Zhang", "Yanrui Wu", "Wenjun Wu"], "title": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines", "categories": ["cs.AI"], "comment": null, "summary": "Geometry problem solving (GPS) requires models to master diagram\ncomprehension, logical reasoning, knowledge application, numerical computation,\nand auxiliary line construction. This presents a significant challenge for\nMultimodal Large Language Models (MLLMs). However, existing benchmarks for\nevaluating MLLM geometry skills overlook auxiliary line construction and lack\nfine-grained process evaluation, making them insufficient for assessing MLLMs'\nlong-step reasoning abilities. To bridge these gaps, we present the GeoLaux\nbenchmark, comprising 2,186 geometry problems, incorporating both calculation\nand proving questions. Notably, the problems require an average of 6.51\nreasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary\nline construction. Building on the dataset, we design a novel five-dimensional\nevaluation strategy assessing answer correctness, process correctness, process\nquality, auxiliary line impact, and error causes. Extensive experiments on 13\nleading MLLMs (including thinking models and non-thinking models) yield three\npivotal findings: First, models exhibit substantial performance degradation in\nextended reasoning steps (nine models demonstrate over 50% performance drop).\nSecond, compared to calculation problems, MLLMs tend to take shortcuts when\nsolving proving problems. Third, models lack auxiliary line awareness, and\nenhancing this capability proves particularly beneficial for overall geometry\nreasoning improvement. These findings establish GeoLaux as both a benchmark for\nevaluating MLLMs' long-step geometric reasoning with auxiliary lines and a\nguide for capability advancement. Our dataset and code are included in\nsupplementary materials and will be released.", "AI": {"tldr": "This paper introduces GeoLaux, a benchmark with 2,186 geometry problems to evaluate MLLMs on complex geometric reasoning, particularly auxiliary line construction.", "motivation": "Existing benchmarks do not sufficiently assess MLLMs' long-step reasoning skills or auxiliary line construction, crucial for geometry problem solving.", "method": "GeoLaux provides problems requiring an average of 6.51 reasoning steps and incorporates auxiliary line construction. It also proposes a five-dimensional evaluation framework.", "result": "Experiments reveal MLLMs struggle with extended reasoning, proving problems, and auxiliary line awareness, highlighting areas for improvement.", "conclusion": "GeoLaux serves as both a benchmark for evaluating geometric reasoning capabilities and a roadmap for improving MLLMs in this domain. Dataset and code will be released for further use."}}
{"id": "2508.05954", "pdf": "https://arxiv.org/pdf/2508.05954", "abs": "https://arxiv.org/abs/2508.05954", "authors": ["Han Lin", "Jaemin Cho", "Amir Zadeh", "Chuan Li", "Mohit Bansal"], "title": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project Page: https://bifrost-1.github.io", "summary": "There is growing interest in integrating high-fidelity visual synthesis\ncapabilities into large language models (LLMs) without compromising their\nstrong reasoning capabilities. Existing methods that directly train LLMs or\nbridge LLMs and diffusion models usually suffer from costly training since the\nbackbone LLMs have not seen image representations during pretraining. We\npresent Bifrost-1, a unified framework that bridges pretrained multimodal LLMs\n(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent\nvariables, which are natively aligned with the MLLM's CLIP visual encoder.\nThese patch-level image embeddings are integrated into the diffusion model with\na lightweight adaptation of its ControlNet. To retain the original multimodal\nreasoning capabilities of MLLMs, we equip the MLLM with a visual generation\nbranch initialized from the original MLLM parameters when predicting the\npatch-level image embeddings. By seamlessly integrating pretrained MLLMs and\ndiffusion models with patch-level CLIP latents, our framework enables\nhigh-fidelity controllable image generation with significant training\nefficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or\nbetter performance than previous methods in terms of visual fidelity and\nmultimodal understanding, with substantially lower compute during training. We\nalso provide comprehensive ablation studies showing the effectiveness of our\ndesign choices.", "AI": {"tldr": "Bifrost-1 introduces a unified framework that integrates pretrained multimodal language models (MLLMs) and diffusion models using patch-level CLIP image embeddings, yielding high-quality image synthesis with efficient training.", "motivation": "The paper aims to address the challenge of integrating high-fidelity visual generation in large language models without weakening their reasoning capabilities or incurring high computational costs during training.", "method": "The method involves bridging pretrained MLLMs and diffusion models via patch-level CLIP image embeddings. These embeddings serve as latent variables aligned with the MLLM's visual encoder and are incorporated into the diffusion model using a lightweight adaptation of ControlNet. A visual generation branch is added to the MLLM for predicting these embeddings.", "result": "The proposed Bifrost-1 framework achieves comparable or better results than existing methods in terms of image quality and multimodal reasoning, while significantly reducing training compute requirements.", "conclusion": "Bifrost-1 demonstrates that seamlessly combining MLLMs and diffusion models with efficient embeddings enables high-quality controllable image generation and preserves multimodal reasoning capabilities, offering an effective and computationally efficient solution."}}
{"id": "2508.06034", "pdf": "https://arxiv.org/pdf/2508.06034", "abs": "https://arxiv.org/abs/2508.06034", "authors": ["Qin Chen", "Guojie Song"], "title": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted tp CIKM 2025", "summary": "Heterogeneous graphs (HGs) are common in real-world scenarios and often\nexhibit heterophily. However, most existing studies focus on either\nheterogeneity or heterophily in isolation, overlooking the prevalence of\nheterophilic HGs in practical applications. Such ignorance leads to their\nperformance degradation. In this work, we first identify two main challenges in\nmodeling heterophily HGs: (1) varying heterophily distributions across hops and\nmeta-paths; (2) the intricate and often heterophily-driven diversity of\nsemantic information across different meta-paths. Then, we propose the Adaptive\nHeterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN\nemploys a heterophily-aware convolution that accounts for heterophily\ndistributions specific to both hops and meta-paths. It then integrates messages\nfrom diverse semantic spaces using a coarse-to-fine attention mechanism, which\nfilters out noise and emphasizes informative signals. Experiments on seven\nreal-world graphs and twenty baselines demonstrate the superior performance of\nAHGNN, particularly in high-heterophily situations.", "AI": {"tldr": "This paper introduces an Adaptive Heterogeneous Graph Neural Network (AHGNN) to better handle heterophilic heterogeneous graphs and outperforms 20 baselines in experiments.", "motivation": "Heterogeneous graphs often present heterophily, but existing studies fail to address heterophilic HGs effectively, leading to performance degradation.", "method": "The proposed AHGNN incorporates heterophily-aware convolutions and a coarse-to-fine attention mechanism for better modeling of semantic diversity and heterophily.", "result": "AHGNN exhibited superior performance in experiments on seven real-world graphs compared to 20 baseline models, excelling in high-heterophily cases.", "conclusion": "The study emphasizes addressing the nuances of heterophily and heterogeneity in graphs, presenting AHGNN as an effective solution."}}
{"id": "2508.06291", "pdf": "https://arxiv.org/pdf/2508.06291", "abs": "https://arxiv.org/abs/2508.06291", "authors": ["Christian Rauch", "Bj\u00f6rn Ellensohn", "Linus Nwankwo", "Vedant Dave", "Elmar Rueckert"], "title": "Real-Time 3D Vision-Language Embedding Mapping", "categories": ["cs.RO"], "comment": null, "summary": "A metric-accurate semantic 3D representation is essential for many robotic\ntasks. This work proposes a simple, yet powerful, way to integrate the 2D\nembeddings of a Vision-Language Model in a metric-accurate 3D representation at\nreal-time. We combine a local embedding masking strategy, for a more distinct\nembedding distribution, with a confidence-weighted 3D integration for more\nreliable 3D embeddings. The resulting metric-accurate embedding representation\nis task-agnostic and can represent semantic concepts on a global multi-room, as\nwell as on a local object-level. This enables a variety of interactive robotic\napplications that require the localisation of objects-of-interest via natural\nlanguage. We evaluate our approach on a variety of real-world sequences and\ndemonstrate that these strategies achieve a more accurate object-of-interest\nlocalisation while improving the runtime performance in order to meet our\nreal-time constraints. We further demonstrate the versatility of our approach\nin a variety of interactive handheld, mobile robotics and manipulation tasks,\nrequiring only raw image data.", "AI": {"tldr": "The paper proposes a method to integrate 2D embeddings into metric-accurate 3D representations in real-time, enhancing robotic applications like object localization using natural language.", "motivation": "To provide a task-agnostic metric-accurate 3D semantic representation for robotics, capable of object localization in real-time using natural language.", "method": "Combining local embedding masking and confidence-weighted 3D integration to ensure distinct 2D embeddings and reliable 3D embeddings.", "result": "Achieved more accurate object localization and improved runtime performance, validated on diverse real-world sequences.", "conclusion": "The approach facilitates versatile and interactive robotic tasks using raw image data, enabling efficient real-time object localization and manipulation."}}
{"id": "2508.06149", "pdf": "https://arxiv.org/pdf/2508.06149", "abs": "https://arxiv.org/abs/2508.06149", "authors": ["Gunhee Cho", "Yun-Gyung Cheong"], "title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "categories": ["cs.CL", "cs.MA"], "comment": null, "summary": "We present Big5-Scaler, a prompt-based framework for conditioning large\nlanguage models (LLMs) with controllable Big Five personality traits. By\nembedding numeric trait values into natural language prompts, our method\nenables fine-grained personality control without additional training. We\nevaluate Big5-Scaler across trait expression, dialogue generation, and human\ntrait imitation tasks. Results show that it induces consistent and\ndistinguishable personality traits across models, with performance varying by\nprompt type and scale. Our analysis highlights the effectiveness of concise\nprompts and lower trait intensities, providing a efficient approach for\nbuilding personality-aware dialogue agents.", "AI": {"tldr": "Big5-Scaler is a framework using prompts to control language models' Big Five personality traits without extra training. It is tested on personality expression, dialogue generation, and imitation tasks.", "motivation": "To create a method for easily controlling personality traits in large language models (LLMs) for better dialogue generation and human trait imitation.", "method": "The framework embeds numeric personality values into prompts for fine-grained control without additional training. Various tasks are conducted to evaluate the model's effectiveness.", "result": "Big5-Scaler successfully induces distinct personality traits, with performance dependent on prompt design and trait intensity.", "conclusion": "Concise prompts and lower-intensity traits improve efficiency, providing a streamlined method for building personality-aware dialogue systems."}}
{"id": "2508.06230", "pdf": "https://arxiv.org/pdf/2508.06230", "abs": "https://arxiv.org/abs/2508.06230", "authors": ["Ruben Sharma", "Sebastijan Duman\u010di\u0107", "Ross D. King", "Andrew Cropper"], "title": "Learning Logical Rules using Minimum Message Length", "categories": ["cs.AI"], "comment": null, "summary": "Unifying probabilistic and logical learning is a key challenge in AI. We\nintroduce a Bayesian inductive logic programming approach that learns minimum\nmessage length programs from noisy data. Our approach balances hypothesis\ncomplexity and data fit through priors, which explicitly favour more general\nprograms, and a likelihood that favours accurate programs. Our experiments on\nseveral domains, including game playing and drug design, show that our method\nsignificantly outperforms previous methods, notably those that learn minimum\ndescription length programs. Our results also show that our approach is\ndata-efficient and insensitive to example balance, including the ability to\nlearn from exclusively positive examples.", "AI": {"tldr": "The paper presents a Bayesian inductive logic programming approach for learning minimum message length programs from noisy data, achieving state-of-the-art performance.", "motivation": "To overcome the challenge of unifying probabilistic and logical learning in AI, especially when dealing with noisy data in various domains.", "method": "The authors propose a Bayesian approach that balances hypothesis complexity and data fit using priors favoring generality and likelihood favoring accuracy. They test the method across multiple domains.", "result": "The proposed approach outperforms previous methods, including those based on minimum description length, and proves to be data-efficient and robust against example imbalance, performing well even with exclusively positive examples.", "conclusion": "Bayesian inductive logic programming effectively combines probabilistic and logical learning, delivering superior performance and data efficiency compared to existing methods."}}
{"id": "2508.05976", "pdf": "https://arxiv.org/pdf/2508.05976", "abs": "https://arxiv.org/abs/2508.05976", "authors": ["Zhihao Zhu", "Yifan Zheng", "Siyu Pan", "Yaohui Jin", "Yao Mu"], "title": "PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to ICCV 2025. 8 pages main paper, 8 figures, plus\n  supplementary material", "summary": "The fragmentation between high-level task semantics and low-level geometric\nfeatures remains a persistent challenge in robotic manipulation. While\nvision-language models (VLMs) have shown promise in generating affordance-aware\nvisual representations, the lack of semantic grounding in canonical spaces and\nreliance on manual annotations severely limit their ability to capture dynamic\nsemantic-affordance relationships. To address these, we propose Primitive-Aware\nSemantic Grounding (PASG), a closed-loop framework that introduces: (1)\nAutomatic primitive extraction through geometric feature aggregation, enabling\ncross-category detection of keypoints and axes; (2) VLM-driven semantic\nanchoring that dynamically couples geometric primitives with functional\naffordances and task-relevant description; (3) A spatial-semantic reasoning\nbenchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's\neffectiveness in practical robotic manipulation tasks across diverse scenarios,\nachieving performance comparable to manual annotations. PASG achieves a\nfiner-grained semantic-affordance understanding of objects, establishing a\nunified paradigm for bridging geometric primitives with task semantics in\nrobotic manipulation.", "AI": {"tldr": "The paper presents PASG, a framework for tackling the challenge of linking high-level task semantics with low-level geometric features in robotic manipulation using vision-language models and automatic primitive extraction.", "motivation": "Robotic manipulation struggles with connecting high-level semantic concepts from tasks to detailed geometric features. Current vision-language models face limitations due to their lack of dynamic semantic grounding and reliance on manual annotations.", "method": "The proposed PASG framework includes geometric primitive extraction, semantic anchoring using fine-tuned VLMs, and a spatial-semantic reasoning benchmark to enhance object semantic-affordance connections for robotics.", "result": "PASG was validated through practical robotic manipulation tasks across varied scenarios, delivering performance similar to methods relying on manual annotations while improving semantic-affordance understanding.", "conclusion": "PASG offers a unified approach to bridging geometric and semantic aspects in robotic manipulation, showing promise for improved automated handling of diverse tasks."}}
{"id": "2508.06041", "pdf": "https://arxiv.org/pdf/2508.06041", "abs": "https://arxiv.org/abs/2508.06041", "authors": ["Sangwoo Kwon", "Seong Hoon Seo", "Jae W. Lee", "Yeonhong Park"], "title": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "How can we effectively handle queries for on-device large language models\n(LLMs) with varying runtime constraints, such as latency and accuracy?\nMulti-scale quantization addresses this challenge by enabling memory-efficient\nruntime model adaptation of LLMs through the overlaying of multiple model\nvariants quantized to different bitwidths. Meanwhile, an important question\nstill remains open-ended: how can models be properly configured to match a\ntarget precision or latency? While mixed-precision offers a promising solution,\nwe take this further by leveraging the key observation that the sensitivity of\neach layer dynamically changes across decoding iterations. Building on this\ninsight, we introduce DP-LLM, a novel mechanism that dynamically assigns\nprecision to each layer based on input values. DP-LLM augments each linear\nlayer in an LLM with a precision selector that determines the bitwidth at\nruntime using a lightweight error estimator and threshold values learned\nthrough fine-tuning. Experimental results across multiple models and benchmarks\ndemonstrate that DP-LLM achieves a superior performance-latency trade-off,\noutperforming prior approaches.", "AI": {"tldr": "DP-LLM introduces dynamic precision assignment for on-device large language models to optimize performance and latency based on runtime needs.", "motivation": "The paper aims to address the challenge of efficiently handling runtime constraints (such as latency and accuracy) in on-device large language models.", "method": "The proposed method involves dynamically allocating precision to each LLM layer via a lightweight error estimator and learned threshold values, leveraging mixed-precision quantization.", "result": "DP-LLM demonstrates a superior trade-off between performance and latency compared to prior approaches, as shown through experiments on multiple models and benchmarks.", "conclusion": "Dynamic precision assignment using DP-LLM is effective in optimizing LLM runtime constraints, offering a scalable solution for on-device model adaptation."}}
{"id": "2508.06295", "pdf": "https://arxiv.org/pdf/2508.06295", "abs": "https://arxiv.org/abs/2508.06295", "authors": ["Juan Heredia", "Emil Stubbe Kolvig-Raun", "Sune Lundo Sorensen", "Mikkel Baun Kjaergaard"], "title": "Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots", "categories": ["cs.RO"], "comment": null, "summary": "The code performance of industrial robots is typically analyzed through CPU\nmetrics, which overlook the physical impact of code on robot behavior. This\nstudy introduces a novel framework for assessing robot program performance from\nan embodiment perspective by analyzing the robot's electrical power profile.\nOur approach diverges from conventional CPU based evaluations and instead\nleverages a suite of normalized metrics, namely, the energy utilization\ncoefficient, the energy conversion metric, and the reliability coefficient, to\ncapture how efficiently and reliably energy is used during task execution.\nComplementing these metrics, the established robot wear metric provides further\ninsight into long term reliability. Our approach is demonstrated through an\nexperimental case study in machine tending, comparing four programs with\ndiverse strategies using a UR5e robot. The proposed metrics directly compare\nand categorize different robot programs, regardless of the specific task, by\nlinking code performance to its physical manifestation through power\nconsumption patterns. Our results reveal the strengths and weaknesses of each\nstrategy, offering actionable insights for optimizing robot programming\npractices. Enhancing energy efficiency and reliability through this embodiment\ncentric approach not only improves individual robot performance but also\nsupports broader industrial objectives such as sustainable manufacturing and\ncost reduction.", "AI": {"tldr": "This paper introduces a new method for evaluating industrial robot code performance using electrical power profiles rather than traditional CPU metrics.", "motivation": "Energy efficiency and physical reliability of robots during task execution is an overlooked but critical aspect, prompting the need for alternative evaluation frameworks beyond CPU metrics.", "method": "The framework is built on normalized metrics such as energy utilization coefficient, energy conversion metric, reliability coefficient, and robot wear metric, supported by an experimental case study using a UR5e robot.", "result": "The metrics effectively differentiate and categorize robot programs based on power utilization and task execution reliability, showing strengths and weaknesses of diverse coding strategies.", "conclusion": "Optimizing robot code performance via this embodiment-centric framework enhances energy efficiency, reliability, and aligns with industrial goals of sustainability and cost reduction."}}
{"id": "2508.06155", "pdf": "https://arxiv.org/pdf/2508.06155", "abs": "https://arxiv.org/abs/2508.06155", "authors": ["Renhan Zhang", "Lian Lian", "Zhen Qi", "Guiran Liu"], "title": "Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach", "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the issue of implicit stereotypes that may arise during\nthe generation process of large language models. It proposes an interpretable\nbias detection method aimed at identifying hidden social biases in model\noutputs, especially those semantic tendencies that are not easily captured\nthrough explicit linguistic features. The method combines nested semantic\nrepresentation with a contextual contrast mechanism. It extracts latent bias\nfeatures from the vector space structure of model outputs. Using attention\nweight perturbation, it analyzes the model's sensitivity to specific social\nattribute terms, thereby revealing the semantic pathways through which bias is\nformed. To validate the effectiveness of the method, this study uses the\nStereoSet dataset, which covers multiple stereotype dimensions including\ngender, profession, religion, and race. The evaluation focuses on several key\nmetrics, such as bias detection accuracy, semantic consistency, and contextual\nsensitivity. Experimental results show that the proposed method achieves strong\ndetection performance across various dimensions. It can accurately identify\nbias differences between semantically similar texts while maintaining high\nsemantic alignment and output stability. The method also demonstrates high\ninterpretability in its structural design. It helps uncover the internal bias\nassociation mechanisms within language models. This provides a more transparent\nand reliable technical foundation for bias detection. The approach is suitable\nfor real-world applications where high trustworthiness of generated content is\nrequired.", "AI": {"tldr": "The paper proposes an interpretable method to detect hidden biases in large language models using nested semantic representation and contextual contrast mechanisms.", "motivation": "Implicit social biases in large language models can lead to undesirable outcomes and need reliable methods for their detection.", "method": "Combines nested semantic representation with contextual contrast mechanisms to extract bias features and analyze sensitivity using attention weight perturbation.", "result": "Achieved strong bias detection across multiple dimensions including gender, profession, religion, and race, with high semantic alignment and output stability.", "conclusion": "The method provides a transparent technical foundation for bias detection, offering interpretability and trustworthiness suitable for practical applications."}}
{"id": "2508.06263", "pdf": "https://arxiv.org/pdf/2508.06263", "abs": "https://arxiv.org/abs/2508.06263", "authors": ["Andrew Cropper", "David M. Cerna", "Matti J\u00e4rvisalo"], "title": "Symmetry breaking for inductive logic programming", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The goal of inductive logic programming is to search for a hypothesis that\ngeneralises training data and background knowledge. The challenge is searching\nvast hypothesis spaces, which is exacerbated because many logically equivalent\nhypotheses exist. To address this challenge, we introduce a method to break\nsymmetries in the hypothesis space. We implement our idea in answer set\nprogramming. Our experiments on multiple domains, including visual reasoning\nand game playing, show that our approach can reduce solving times from over an\nhour to just 17 seconds.", "AI": {"tldr": "The paper introduces a method to reduce solving times in inductive logic programming by breaking symmetries in the hypothesis space.", "motivation": "The challenge of searching vast hypothesis spaces in inductive logic programming is exacerbated by the existence of many logically equivalent hypotheses.", "method": "The paper introduces a symmetry-breaking method implemented using answer set programming.", "result": "The experiments demonstrate that their approach can significantly reduce solving times, from over an hour to 17 seconds, across multiple domains.", "conclusion": "Breaking symmetries in hypothesis spaces can drastically enhance the efficiency of inductive logic programming."}}
{"id": "2508.05982", "pdf": "https://arxiv.org/pdf/2508.05982", "abs": "https://arxiv.org/abs/2508.05982", "authors": ["Qingyang Liu", "Bingjie Gao", "Weiheng Huang", "Jun Zhang", "Zhongqian Sun", "Yang Wei", "Zelin Peng", "Qianli Ma", "Shuai Yang", "Zhaohe Liao", "Haonan Zhao", "Li Niu"], "title": "AnimateScene: Camera-controllable Animation in Any Scene", "categories": ["cs.CV"], "comment": null, "summary": "3D scene reconstruction and 4D human animation have seen rapid progress and\nbroad adoption in recent years. However, seamlessly integrating reconstructed\nscenes with 4D human animation to produce visually engaging results remains\nchallenging. One key difficulty lies in placing the human at the correct\nlocation and scale within the scene while avoiding unrealistic\ninterpenetration. Another challenge is that the human and the background may\nexhibit different lighting and style, leading to unrealistic composites. In\naddition, appealing character motion videos are often accompanied by camera\nmovements, which means that the viewpoints need to be reconstructed along a\nspecified trajectory. We present AnimateScene, which addresses the above issues\nin a unified framework. First, we design an accurate placement module that\nautomatically determines a plausible 3D position for the human and prevents any\ninterpenetration within the scene during motion. Second, we propose a\ntraining-free style alignment method that adapts the 4D human representation to\nmatch the background's lighting and style, achieving coherent visual\nintegration. Finally, we design a joint post-reconstruction method for both the\n4D human and the 3D scene that allows camera trajectories to be inserted,\nenabling the final rendered video to feature visually appealing camera\nmovements. Extensive experiments show that AnimateScene generates dynamic scene\nvideos with high geometric detail and spatiotemporal coherence across various\ncamera and action combinations.", "AI": {"tldr": "AnimateScene integrates 4D human animation with 3D scene reconstruction, addressing challenges like human placement, style inconsistency, and camera trajectory generation.", "motivation": "To seamlessly integrate 4D human animation with 3D scene reconstruction for visually engaging videos while overcoming challenges like correct human placement, lighting inconsistencies, and camera motion.", "method": "Proposes a unified framework with modules for automatic human placement, training-free style alignment, and joint post-reconstruction to handle camera trajectories.", "result": "Generates visually dynamic scene videos with high detail and coherence across various camera and action setups.", "conclusion": "AnimateScene improves 4D human animation within 3D reconstructed scenes, providing a cohesive and dynamic visual experience."}}
{"id": "2508.06066", "pdf": "https://arxiv.org/pdf/2508.06066", "abs": "https://arxiv.org/abs/2508.06066", "authors": ["Barak Gahtan", "Alex M. Bronstein"], "title": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep temporal architectures such as Temporal Convolutional Networks (TCNs)\nachieve strong predictive performance on sequential data, yet theoretical\nunderstanding of their generalization remains limited. We address this gap by\nproviding both the first non-vacuous, architecture-aware generalization bounds\nfor deep temporal models and a principled evaluation methodology.\n  For exponentially $\\beta$-mixing sequences, we derive bounds scaling as $\nO\\!\\Bigl(R\\,\\sqrt{\\tfrac{D\\,p\\,n\\,\\log N}{N}}\\Bigr), $ where $D$ is network\ndepth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our\ndelayed-feedback blocking mechanism transforms dependent samples into\neffectively independent ones while discarding only $O(1/\\log N)$ of the data,\nyielding $\\sqrt{D}$ scaling instead of exponential, implying that doubling\ndepth requires approximately quadrupling the training data.\n  We also introduce a fair-comparison methodology that fixes the effective\nsample size to isolate the effect of temporal structure from information\ncontent. Under $N_{\\text{eff}}=2{,}000$, strongly dependent sequences\n($\\rho=0.8$) exhibit $\\approx76\\%$ smaller generalization gaps than weakly\ndependent ones ($\\rho=0.2$), challenging the intuition that dependence is\npurely detrimental. Yet convergence rates diverge from theory: weak\ndependencies follow $N_{\\text{eff}}^{-1.21}$ scaling and strong dependencies\nfollow $N_{\\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.\nThese findings reveal that temporal dependence can enhance learning under fixed\ninformation budgets, while highlighting gaps between theory and practice that\nmotivate future research.", "AI": {"tldr": "This paper provides first non-vacuous, architecture-aware generalization bounds for Temporal Convolutional Networks (TCNs) addressing their theoretical limitations and evaluates their predictive performance under various sequential data dependencies.", "motivation": "The aim is to bridge the gap in theoretical understanding and generalization bounds of Temporal Convolutional Networks (TCNs) for sequential data.", "method": "The authors derive generalization bounds for TCNs by using a delayed-feedback blocking mechanism to minimize dependencies in exponentially \u03b2-mixing sequences. They also develop a methodology to fairly compare models by fixing the effective sample size to examine impacts of temporal dependencies.", "result": "The derived bounds reveal $\nabla\\sqrt{D}$ scalability (quadratic data growth per depth increase). Experiments show that strong temporal dependencies can reduce generalization gaps by 76%, but that empirical convergence rates deviate from theoretical expectations.", "conclusion": "The study finds that temporal dependence may enhance TCN generalization performance under fixed information budgets, but divergence between theoretical predictions and empirical findings highlights the need for further investigation."}}
{"id": "2508.06313", "pdf": "https://arxiv.org/pdf/2508.06313", "abs": "https://arxiv.org/abs/2508.06313", "authors": ["Amir Hossein Barjini", "Mohammad Bahari", "Mahdi Hejrati", "Jouni Mattila"], "title": "Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators", "categories": ["cs.RO"], "comment": "This is submitted to IEEE T-ASE", "summary": "This paper presents a unified system-level modeling and control framework for\nan all-electric heavy-duty robotic manipulator (HDRM) driven by\nelectromechanical linear actuators (EMLAs). A surrogate-enhanced actuator\nmodel, combining integrated electromechanical dynamics with a neural network\ntrained on a dedicated testbed, is integrated into an extended virtual\ndecomposition control (VDC) architecture augmented by a natural adaptation law.\nThe derived analytical HDRM model supports a hierarchical control structure\nthat seamlessly maps high-level force and velocity objectives to real-time\nactuator commands, accompanied by a Lyapunov-based stability proof. In\nmulti-domain simulations of both cubic and a custom planar triangular\ntrajectory, the proposed adaptive modular controller achieves sub-centimeter\nCartesian tracking accuracy. Experimental validation of the same 1-DoF platform\nunder realistic load emulation confirms the efficacy of the proposed control\nstrategy. These findings demonstrate that a surrogate-enhanced EMLA model\nembedded in the VDC approach can enable modular, real-time control of an\nall-electric HDRM, supporting its deployment in next-generation mobile working\nmachines.", "AI": {"tldr": "The paper introduces an advanced framework integrating neural network-enhanced actuator models with hierarchical control mechanisms for precise and stable operation of all-electric heavy-duty robotic manipulators.", "motivation": "To address the need for precise, stable, and modular control in next-generation heavy-duty robotic manipulators driven by electromechanical actuators.", "method": "The authors developed a surrogate-enhanced electromechanical actuator model using neural networks on a testbed, integrating it into an extended virtual decomposition control architecture with an adaptation law and stability analysis.", "result": "Multi-domain simulations achieved highly accurate tracking, while experiments validated the proposed system showing robustness under realistic load conditions.", "conclusion": "The research successfully demonstrates that neural network-enhanced actuator models embedded in specialized control frameworks can achieve modular, real-time, and reliable robotic manipulator control."}}
{"id": "2508.06163", "pdf": "https://arxiv.org/pdf/2508.06163", "abs": "https://arxiv.org/abs/2508.06163", "authors": ["Yingfeng Luo", "Dingyang Lin", "Junxin Wang", "Ziqiang Xu", "Kaiyan Chang", "Tong Zheng", "Bei Li", "Anxiang Ma", "Tong Xiao", "Zhengtao Yu", "Jingbo Zhu"], "title": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Model merging has emerged as a compelling data-free paradigm for multi-task\nlearning, enabling the fusion of multiple fine-tuned models into a single,\npowerful entity. A key technique in merging methods is sparsification, which\nprunes redundant parameters from task vectors to mitigate interference.\nHowever, prevailing approaches employ a ``one-size-fits-all'' strategy,\napplying a uniform sparsity ratio that overlooks the inherent structural and\nstatistical heterogeneity of model parameters. This often leads to a suboptimal\ntrade-off, where critical parameters are inadvertently pruned while less useful\nones are retained. To address this limitation, we introduce \\textbf{TADrop}\n(\\textbf{T}ensor-wise \\textbf{A}daptive \\textbf{Drop}), an adaptive\nsparsification strategy that respects this heterogeneity. Instead of a global\nratio, TADrop assigns a tailored sparsity level to each parameter tensor based\non its distributional properties. The core intuition is that tensors with\ndenser, more redundant distributions can be pruned aggressively, while sparser,\nmore critical ones are preserved. As a simple and plug-and-play module, we\nvalidate TADrop by integrating it with foundational, classic, and SOTA merging\nmethods. Extensive experiments across diverse tasks (vision, language, and\nmultimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and\nsignificantly boosts their performance. For instance, when enhancing a leading\nmerging method, it achieves an average performance gain of 2.0\\% across 8\nViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter\ninterference by tailoring sparsification to the model's structure, offering a\nnew baseline for high-performance model merging.", "AI": {"tldr": "The paper introduces TADrop, an adaptive sparsification method tailored to model parameters' distributions, significantly boosting performance in model merging tasks.", "motivation": "To address the limitations of current sparsification strategies in model merging that fail to account for parameter heterogeneity, leading to suboptimal performance.", "method": "TADrop uses tensor-wise adaptive sparsification by assigning tailored sparsity levels to each parameter tensor based on its distributional properties.", "result": "TADrop consistently improves performance in model merging methods, achieving significant performance gains, including an average of 2.0% across multiple vision tasks.", "conclusion": "TADrop offers an effective, plug-and-play solution to enhance model merging by mitigating parameter interference, establishing a new baseline for performance."}}
{"id": "2508.06296", "pdf": "https://arxiv.org/pdf/2508.06296", "abs": "https://arxiv.org/abs/2508.06296", "authors": ["Pierre Peign\u00e9 - Lefebvre", "Quentin Feuillade-Montixi", "Tom David", "Nicolas Miailhe"], "title": "LLM Robustness Leaderboard v1 --Technical report", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "This technical report accompanies the LLM robustness leaderboard published by\nPRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior\nElicitation Tool (BET), an AI system performing automated red-teaming through\nDynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)\nagainst 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we\npropose a fine-grained robustness metric estimating the average number of\nattempts required to elicit harmful behaviors, revealing that attack difficulty\nvaries by over 300-fold across models despite universal vulnerability. We\nintroduce primitive-level vulnerability analysis to identify which jailbreaking\ntechniques are most effective for specific hazard categories. Our collaborative\nevaluation with trusted third parties from the AI Safety Network demonstrates\npractical pathways for distributed robustness assessment across the community.", "AI": {"tldr": "The paper presents the PRISM Eval Behavior Elicitation Tool (BET), which conducts automated red-teaming and achieves a high attack success against prominent LLMs, and proposes a nuanced robustness metric.", "motivation": "To enhance the evaluation of language models' safety and vulnerabilities by developing an effective and scalable assessment tool.", "method": "They used automated red-teaming through Dynamic Adversarial Optimization and introduced advanced metrics for vulnerability analysis across models.", "result": "BET achieved a 100% attack success rate against 37 of 41 LLMs, showcasing universal vulnerabilities with significant variation in attack difficulty.", "conclusion": "The study emphasizes the need for collaborative and distributed robustness evaluations to improve AI safety frameworks."}}
{"id": "2508.05989", "pdf": "https://arxiv.org/pdf/2508.05989", "abs": "https://arxiv.org/abs/2508.05989", "authors": ["Younjoon Chung", "Hyoungseob Park", "Patrick Rim", "Xiaoran Zhang", "Jihe He", "Ziyao Zeng", "Safa Cicek", "Byung-Woo Hong", "James S. Duncan", "Alex Wong"], "title": "ETA: Energy-based Test-time Adaptation for Depth Completion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a method for test-time adaptation of pretrained depth completion\nmodels. Depth completion models, trained on some ``source'' data, often predict\nerroneous outputs when transferred to ``target'' data captured in novel\nenvironmental conditions due to a covariate shift. The crux of our method lies\nin quantifying the likelihood of depth predictions belonging to the source data\ndistribution. The challenge is in the lack of access to out-of-distribution\n(target) data prior to deployment. Hence, rather than making assumptions\nregarding the target distribution, we utilize adversarial perturbations as a\nmechanism to explore the data space. This enables us to train an energy model\nthat scores local regions of depth predictions as in- or out-of-distribution.\nWe update the parameters of pretrained depth completion models at test time to\nminimize energy, effectively aligning test-time predictions to those of the\nsource distribution. We call our method ``Energy-based Test-time Adaptation'',\nor ETA for short. We evaluate our method across three indoor and three outdoor\ndatasets, where ETA improve over the previous state-of-the-art method by an\naverage of 6.94% for outdoors and 10.23% for indoors. Project Page:\nhttps://fuzzythecat.github.io/eta.", "AI": {"tldr": "The method introduces Energy-based Test-time Adaptation (ETA) to address the issue of covariate shift in pretrained depth completion models by aligning test-time predictions with the source distribution using adversarial perturbations.", "motivation": "Pretrained depth completion models struggle with covariate shifts when applied to data from novel environments, leading to inaccurate predictions.", "method": "The method uses adversarial perturbations to explore data space and train an energy model that scores depth predictions as in- or out-of-distribution. At test time, model parameters are updated to minimize the energy and align predictions with the source distribution.", "result": "ETA improves over the previous state-of-the-art method by an average of 6.94% in outdoor datasets and 10.23% in indoor datasets.", "conclusion": "Energy-based Test-time Adaptation effectively mitigates covariate shift in depth completion models, enhancing their accuracy across diverse environments."}}
{"id": "2508.06097", "pdf": "https://arxiv.org/pdf/2508.06097", "abs": "https://arxiv.org/abs/2508.06097", "authors": ["Simon B\u00fchrer", "Andreas Plesner", "Till Aczel", "Roger Wattenhofer"], "title": "Recurrent Deep Differentiable Logic Gate Networks", "categories": ["cs.LG"], "comment": null, "summary": "While differentiable logic gates have shown promise in feedforward networks,\ntheir application to sequential modeling remains unexplored. This paper\npresents the first implementation of Recurrent Deep Differentiable Logic Gate\nNetworks (RDDLGN), combining Boolean operations with recurrent architectures\nfor sequence-to-sequence learning.\n  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and\n30.9\\% accuracy during training, approaching GRU performance (5.41 BLEU) and\ngraceful degradation (4.39 BLEU) during inference. This work establishes\nrecurrent logic-based neural computation as viable, opening research directions\nfor FPGA acceleration in sequential modeling and other recursive network\narchitectures.", "AI": {"tldr": "The paper introduces Recurrent Deep Differentiable Logic Gate Networks (RDDLGN) for sequence-to-sequence learning, combining logic gates with recurrent architectures.", "motivation": "Explores the largely uncharted application of differentiable logic gates in sequential models.", "method": "Developed RDDLGN architecture, applying Boolean operations with recurrent models for tasks like translation.", "result": "RDDLGN shows comparable performance to GRU in translation tasks, with BLEU score of 5.00 and 30.9% training accuracy.", "conclusion": "RDDLGNs demonstrate the viability of logic-based recurrent computation, suggesting potential for FPGA acceleration and advancing recursive networks."}}
{"id": "2508.06319", "pdf": "https://arxiv.org/pdf/2508.06319", "abs": "https://arxiv.org/abs/2508.06319", "authors": ["Sagar Parekh", "Heramb Nemlekar", "Dylan P. Losey"], "title": "Towards Balanced Behavior Cloning from Imbalanced Datasets", "categories": ["cs.RO"], "comment": null, "summary": "Robots should be able to learn complex behaviors from human demonstrations.\nIn practice, these human-provided datasets are inevitably imbalanced: i.e., the\nhuman demonstrates some subtasks more frequently than others. State-of-the-art\nmethods default to treating each element of the human's dataset as equally\nimportant. So if -- for instance -- the majority of the human's data focuses on\nreaching a goal, and only a few state-action pairs move to avoid an obstacle,\nthe learning algorithm will place greater emphasis on goal reaching. More\ngenerally, misalignment between the relative amounts of data and the importance\nof that data causes fundamental problems for imitation learning approaches. In\nthis paper we analyze and develop learning methods that automatically account\nfor mixed datasets. We formally prove that imbalanced data leads to imbalanced\npolicies when each state-action pair is weighted equally; these policies\nemulate the most represented behaviors, and not the human's complex, multi-task\ndemonstrations. We next explore algorithms that rebalance offline datasets\n(i.e., reweight the importance of different state-action pairs) without human\noversight. Reweighting the dataset can enhance the overall policy performance.\nHowever, there is no free lunch: each method for autonomously rebalancing\nbrings its own pros and cons. We formulate these advantages and disadvantages,\nhelping other researchers identify when each type of approach is most\nappropriate. We conclude by introducing a novel meta-gradient rebalancing\nalgorithm that addresses the primary limitations behind existing approaches.\nOur experiments show that dataset rebalancing leads to better downstream\nlearning, improving the performance of general imitation learning algorithms\nwithout requiring additional data collection. See our project website:\nhttps://collab.me.vt.edu/data_curation/.", "AI": {"tldr": "The paper investigates learning from imbalanced human demonstration datasets in imitation learning and proposes solutions for rebalancing these datasets.", "motivation": "Address the issue of imbalanced datasets in human demonstrations, which causes learning algorithms to disproportionately emphasize overrepresented behaviors, undermining the diversity and complexity of human-provided demonstrations.", "method": "Formal proof of imbalanced data's effects on policies, development of autonomous dataset reweighting techniques, and introduction of a novel meta-gradient rebalancing algorithm.", "result": "Experimental findings show that rebalancing datasets improves downstream imitation learning performance, providing benefit without needing additional data collection.", "conclusion": "Dataset rebalancing is essential to overcome dataset imbalances, and the proposed methods (including the new meta-gradient algorithm) enhance general imitation learning performance, with tradeoffs highlighted to guide researchers on method choice."}}
{"id": "2508.06165", "pdf": "https://arxiv.org/pdf/2508.06165", "abs": "https://arxiv.org/abs/2508.06165", "authors": ["Weitao Li", "Boran Xiang", "Xiaolong Wang", "Zhinan Gou", "Weizhi Ma", "Yang Liu"], "title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities through two\ncomplementary paradigms: Retrieval-Augmented Generation (RAG), which enhances\nknowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),\nwhich optimizes complex reasoning abilities. However, these two capabilities\nare often developed in isolation, and existing efforts to unify them remain\nnarrow in scope-typically limited to open-domain QA with fixed retrieval\nsettings and task-specific assumptions. This lack of integration constrains\ngeneralization and limits the applicability of RAG-RL methods to broader\ndomains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a\ngeneral framework that unifies retrieval and reasoning through reinforcement\nlearning. UR2 introduces two key contributions: a difficulty-aware curriculum\ntraining that selectively invokes retrieval only for challenging problems, and\na hybrid knowledge access strategy combining domain-specific offline corpora\nwith LLM-generated summaries. These components are designed to enable dynamic\ncoordination between retrieval and reasoning, improving adaptability across a\ndiverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,\nand mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B\nand LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,\nachieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several\nbenchmarks. We have released all code, models, and data at\nhttps://github.com/Tsinghua-dhy/UR2.", "AI": {"tldr": "This paper introduces UR2, a framework unifying Retrieval-Augmented Generation and Reinforcement Learning for reasoning and knowledge retrieval, showing superior results across multiple tasks.", "motivation": "To address the limitations of current models where retrieval and reasoning capabilities are often developed in isolation, reducing generalizability and applicability to broader tasks.", "method": "The proposed UR2 framework uses a difficulty-aware curriculum for selective retrieval and a hybrid knowledge access strategy, dynamically integrating retrieval and reasoning through reinforcement learning.", "result": "UR2 outperforms existing methods in open-domain QA, medical, mathematical reasoning, and competes with GPT-4 variants in benchmarks.", "conclusion": "The proposed framework efficiently unifies retrieval and reasoning, advancing adaptability in LLMs across diverse tasks. Code and models are publicly available."}}
{"id": "2508.06326", "pdf": "https://arxiv.org/pdf/2508.06326", "abs": "https://arxiv.org/abs/2508.06326", "authors": ["Nathaniel Virgo", "Martin Biehl", "Manuel Baltieri", "Matteo Capucci"], "title": "A \"good regulator theorem\" for embodied agents", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "Accepted at the Artificial Life conference 2025 (ALife 2025). 10\n  pages, 1 figure", "summary": "In a classic paper, Conant and Ashby claimed that \"every good regulator of a\nsystem must be a model of that system.\" Artificial Life has produced many\nexamples of systems that perform tasks with apparently no model in sight; these\nsuggest Conant and Ashby's theorem doesn't easily generalise beyond its\nrestricted setup. Nevertheless, here we show that a similar intuition can be\nfleshed out in a different way: whenever an agent is able to perform a\nregulation task, it is possible for an observer to interpret it as having\n\"beliefs\" about its environment, which it \"updates\" in response to sensory\ninput. This notion of belief updating provides a notion of model that is more\nsophisticated than Conant and Ashby's, as well as a theorem that is more\nbroadly applicable. However, it necessitates a change in perspective, in that\nthe observer plays an essential role in the theory: models are not a mere\nproperty of the system but are imposed on it from outside. Our theorem holds\nregardless of whether the system is regulating its environment in a classic\ncontrol theory setup, or whether it's regulating its own internal state; the\nmodel is of its environment either way. The model might be trivial, however,\nand this is how the apparent counterexamples are resolved.", "AI": {"tldr": "The paper extends Conant and Ashby's theorem, arguing that systems regulating their environments can be interpreted as having 'beliefs' about their surroundings, which are updated based on sensory input. This introduces a more sophisticated model-based perspective but shifts the role of interpretation onto the observer.", "motivation": "To explore whether Conant and Ashby's theorem on good regulators can generalize to scenarios where systems appear to operate without explicit models.", "method": "The authors redefine the notion of a model to one involving 'belief updating' imposed by an observer, thereby broadening the theorem's applicability to different forms of regulation tasks.", "result": "The extended theorem demonstrates that systems can always be interpreted as having belief-like models of their environment, irrespective of the type of regulation performed. This interpretation reconciles apparent counterexamples to the original theorem.", "conclusion": "The work redefines system modeling by emphasizing the observer\u2019s role, establishing a broader applicability for Conant and Ashby's theorem and resolving counterexamples by framing models as imposed interpretations."}}
{"id": "2508.05990", "pdf": "https://arxiv.org/pdf/2508.05990", "abs": "https://arxiv.org/abs/2508.05990", "authors": ["Haichao Wang", "Xinyue Xi", "Jiangtao Wen", "Yuxing Han"], "title": "Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision", "categories": ["cs.CV"], "comment": null, "summary": "The efficiency of video computer vision system remains a challenging task due\nto the high temporal redundancy inside a video. Existing works have been\nproposed for efficient vision computer vision. However, they do not fully\nreduce the temporal redundancy and neglect the front end computation overhead.\nIn this paper, we propose an efficient video computer vision system. First,\nimage signal processor is removed and Bayer-format data is directly fed into\nvideo computer vision models, thus saving the front end computation. Second,\ninstead of optical flow models and video codecs, a fast block matching-based\nmotion estimation algorithm is proposed specifically for efficient video\ncomputer vision, with a MV refinement module. To correct the error,\ncontext-aware block refinement network is introduced to refine regions with\nlarge error. To further balance the accuracy and efficiency, a frame selection\nstrategy is employed. Experiments on multiple video computer vision tasks\ndemonstrate that our method achieves significant acceleration with slight\nperformance loss.", "AI": {"tldr": "This paper introduces an efficient video computer vision system that reduces temporal redundancy and eliminates front-end computation overhead, achieving faster performance with minimal accuracy trade-off.", "motivation": "The challenge lies in achieving efficient video computer vision due to high temporal redundancy in videos and underutilized approaches to reduce computation overhead.", "method": "The method includes removing the image signal processor, directly inputting Bayer-format data, using a block matching-based motion estimation algorithm with MV refinement, introducing a context-aware block refinement network, and employing a frame selection strategy.", "result": "Experiments across multiple video vision tasks show significant speed-up while incurring only slight performance loss.", "conclusion": "The proposed system effectively addresses inefficiencies in video computer vision by optimizing both front-end and motion estimation processes, balancing accuracy with computational efficiency."}}
{"id": "2508.06108", "pdf": "https://arxiv.org/pdf/2508.06108", "abs": "https://arxiv.org/abs/2508.06108", "authors": ["Xing Lei", "Wenyan Yang", "Kaiqiang Ke", "Shentao Yang", "Xuetao Zhang", "Joni Pajarinen", "Donglin Wang"], "title": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a\nfundamental challenge in reinforcement learning. While hindsight experience\nreplay (HER) has shown promise by relabeling collected trajectories with\nachieved goals, we argue that trajectory relabeling alone does not fully\nexploit the available experiences in off-policy GCRL methods, resulting in\nlimited sample efficiency. In this paper, we propose Hindsight Goal-conditioned\nRegularization (HGR), a technique that generates action regularization priors\nbased on hindsight goals. When combined with hindsight self-imitation\nregularization (HSR), our approach enables off-policy RL algorithms to maximize\nexperience utilization. Compared to existing GCRL methods that employ HER and\nself-imitation techniques, our hindsight regularizations achieve substantially\nmore efficient sample reuse and the best performances, which we empirically\ndemonstrate on a suite of navigation and manipulation tasks.", "AI": {"tldr": "The paper introduces Hindsight Goal-conditioned Regularization (HGR) to enhance sample efficiency in goal-conditioned reinforcement learning (GCRL).", "motivation": "Sparse rewards in GCRL impede learning efficiency, and existing trajectory relabeling approaches like HER cannot fully exploit general experience.", "method": "The authors present HGR, which uses hindsight goals to regularize actions, combined with hindsight self-imitation regularization (HSR) for better experience utilization.", "result": "The approach achieves superior sample efficiency and outperforms existing techniques in navigation and manipulation tasks.", "conclusion": "HGR and HSR together allow off-policy RL methods to better utilize data, leading to enhanced performance in sparse reward environments."}}
{"id": "2508.06330", "pdf": "https://arxiv.org/pdf/2508.06330", "abs": "https://arxiv.org/abs/2508.06330", "authors": ["Baorun Li", "Chengrui Zhu", "Siyi Du", "Bingran Chen", "Jie Ren", "Wenfei Wang", "Yong Liu", "Jiajun Lv"], "title": "L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience", "categories": ["cs.RO"], "comment": "IROS2025", "summary": "Extrinsic calibration is essential for multi-sensor fusion, existing methods\nrely on structured targets or fully-excited data, limiting real-world\napplicability. Online calibration further suffers from weak excitation, leading\nto unreliable estimates. To address these limitations, we propose a\nreinforcement learning (RL)-based extrinsic calibration framework that\nformulates extrinsic calibration as a decision-making problem, directly\noptimizes $SE(3)$ extrinsics to enhance odometry accuracy. Our approach\nleverages a probabilistic Bingham distribution to model 3D rotations, ensuring\nstable optimization while inherently retaining quaternion symmetry. A\ntrajectory alignment reward mechanism enables robust calibration without\nstructured targets by quantitatively evaluating estimated tightly-coupled\ntrajectory against a reference trajectory. Additionally, an automated data\nselection module filters uninformative samples, significantly improving\nefficiency and scalability for large-scale datasets. Extensive experiments on\nUAVs, UGVs, and handheld platforms demonstrate that our method outperforms\ntraditional optimization-based approaches, achieving high-precision calibration\neven under weak excitation conditions. Our framework simplifies deployment on\ndiverse robotic platforms by eliminating the need for high-quality initial\nextrinsics and enabling calibration from routine operating data. The code is\navailable at https://github.com/APRIL-ZJU/learn-to-calibrate.", "AI": {"tldr": "This paper proposes a reinforcement learning-based framework for extrinsic calibration, improving odometry accuracy across diverse robotic platforms without the need for structured targets.", "motivation": "Existing methods for multi-sensor extrinsic calibration are limited by their reliance on structured targets and fully-excited data, making them less suitable for real-world applications.", "method": "The authors introduce a reinforcement learning framework that models extrinsic calibration as a decision-making problem, optimizing $SE(3)$ extrinsics. It utilizes a Bingham distribution for stable 3D rotation modeling, a trajectory alignment reward mechanism for calibration without structured targets, and an automated data selection module for enhancing scalability.", "result": "Experimental evaluations on various platforms, including UAVs and UGVs, show that the proposed method outperforms traditional optimization-based approaches, achieving high-precision calibration even under weak excitation conditions.", "conclusion": "The framework simplifies deployment across robotic platforms by supporting calibration from routine data, removing the need for high-quality initial extrinsics, and demonstrating robustness and efficiency in diverse conditions."}}
{"id": "2508.06167", "pdf": "https://arxiv.org/pdf/2508.06167", "abs": "https://arxiv.org/abs/2508.06167", "authors": ["V\u00edt Gvo\u017ediak"], "title": "Pragmatics beyond humans: meaning, communication, and LLMs", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "The paper reconceptualizes pragmatics not as a subordinate, third dimension\nof meaning, but as a dynamic interface through which language operates as a\nsocially embedded tool for action. With the emergence of large language models\n(LLMs) in communicative contexts, this understanding needs to be further\nrefined and methodologically reconsidered. The first section challenges the\ntraditional semiotic trichotomy, arguing that connectionist LLM architectures\ndestabilize established hierarchies of meaning, and proposes the Human-Machine\nCommunication (HMC) framework as a more suitable alternative. The second\nsection examines the tension between human-centred pragmatic theories and the\nmachine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics\ncontinue to dominate, it relies on human-specific assumptions ill-suited to\npredictive systems like LLMs. Probabilistic pragmatics, particularly the\nRational Speech Act framework, offers a more compatible teleology by focusing\non optimization rather than truth-evaluation. The third section addresses the\nissue of substitutionalism in three forms - generalizing, linguistic, and\ncommunicative - highlighting the anthropomorphic biases that distort LLM\nevaluation and obscure the role of human communicative subjects. Finally, the\npaper introduces the concept of context frustration to describe the paradox of\nincreased contextual input paired with a collapse in contextual understanding,\nemphasizing how users are compelled to co-construct pragmatic conditions both\nfor the model and themselves. These arguments suggest that pragmatic theory may\nneed to be adjusted or expanded to better account for communication involving\ngenerative AI.", "AI": {"tldr": "The paper suggests reconceptualizing pragmatics as a dynamic interface central to language use, focusing on how large language models (LLMs) influence traditional pragmatic theories and practices.", "motivation": "The motivation is to refine the understanding of pragmatics to account for the communicative implications of large language models and overcome limitations of human-centric traditional models.", "method": "The paper challenges semiotic hierarchies, contrasts existing pragmatic theories with LLM-based systems, criticizes biases in evaluation, and introduces new concepts like context frustration.", "result": "It highlights tensions in adapting traditional pragmatics to machine-centered communication, proposes probabilistic approaches, and outlines the co-construction of pragmatic contexts in LLM interactions.", "conclusion": "Pragmatic theory may require expansion or adjustment to accommodate and better understand communication involving generative AI."}}
{"id": "2508.06348", "pdf": "https://arxiv.org/pdf/2508.06348", "abs": "https://arxiv.org/abs/2508.06348", "authors": ["Mille Mei Zhen Loo", "Gert Luzkov", "Paolo Burelli"], "title": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games", "categories": ["cs.AI"], "comment": null, "summary": "Cheating in online video games compromises the integrity of gaming\nexperiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face\nsignificant challenges in keeping pace with evolving cheating methods without\nimposing invasive measures on users' systems. This paper presents\nAntiCheatPT\\_256, a transformer-based machine learning model designed to detect\ncheating behaviour in Counter-Strike 2 using gameplay data. To support this, we\nintroduce and publicly release CS2CD: A labelled dataset of 795 matches. Using\nthis dataset, 90,707 context windows were created and subsequently augmented to\naddress class imbalance. The transformer model, trained on these windows,\nachieved an accuracy of 89.17\\% and an AUC of 93.36\\% on an unaugmented test\nset. This approach emphasizes reproducibility and real-world applicability,\noffering a robust baseline for future research in data-driven cheat detection.", "AI": {"tldr": "A transformer-based machine learning model, AntiCheatPT_256, is introduced for detecting cheating in Counter-Strike 2 using gameplay data, achieving 89.17% accuracy.", "motivation": "Addressing the challenge of detecting online video game cheating without invasive measures, enhancing anti-cheat system efficacy.", "method": "Developed a transformer model trained on gameplay data including 90,707 augmented context windows from the newly created CS2CD dataset to tackle class imbalance.", "result": "Achieved 89.17% accuracy and 93.36% AUC on an unaugmented test dataset, demonstrating the model's effectiveness.", "conclusion": "AntiCheatPT_256 offers a reproducible, data-driven solution for cheat detection, setting a robust baseline for future advancements in the field."}}
{"id": "2508.05991", "pdf": "https://arxiv.org/pdf/2508.05991", "abs": "https://arxiv.org/abs/2508.05991", "authors": ["Juewen Hu", "Yexin Li", "Jiulin Li", "Shuo Chen", "Pring Wong"], "title": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": null, "summary": "Emotion recognition plays a vital role in enhancing human-computer\ninteraction. In this study, we tackle the MER-SEMI challenge of the MER2025\ncompetition by proposing a novel multimodal emotion recognition framework. To\naddress the issue of data scarcity, we leverage large-scale pre-trained models\nto extract informative features from visual, audio, and textual modalities.\nSpecifically, for the visual modality, we design a dual-branch visual encoder\nthat captures both global frame-level features and localized facial\nrepresentations. For the textual modality, we introduce a context-enriched\nmethod that employs large language models to enrich emotional cues within the\ninput text. To effectively integrate these multimodal features, we propose a\nfusion strategy comprising two key components, i.e., self-attention mechanisms\nfor dynamic modality weighting, and residual connections to preserve original\nrepresentations. Beyond architectural design, we further refine noisy labels in\nthe training set by a multi-source labeling strategy. Our approach achieves a\nsubstantial performance improvement over the official baseline on the\nMER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to\n78.63%, thereby validating the effectiveness of the proposed framework.", "AI": {"tldr": "The study proposes a novel multimodal framework for emotion recognition, leveraging advanced pre-trained models to improve feature extraction across visual, audio, and textual modalities.", "motivation": "To improve human-computer interaction by addressing challenges in multimodal emotion recognition, especially issues related to data scarcity.", "method": "The framework includes a dual-branch visual encoder for capturing diverse features, a context-enriched textual method using large language models, a fusion strategy with self-attention mechanisms and residual connections, and a multi-source labeling strategy to refine noisy training labels.", "result": "The proposed framework achieved a significant performance improvement, reaching a weighted F-score of 87.49% on the MER2025-SEMI dataset, compared to the baseline score of 78.63%.", "conclusion": "The study demonstrates the effectiveness of leveraging pre-trained models, advanced feature extraction methods, and innovative fusion strategies for improved emotion recognition in multimodal settings."}}
{"id": "2508.06151", "pdf": "https://arxiv.org/pdf/2508.06151", "abs": "https://arxiv.org/abs/2508.06151", "authors": ["Yong Oh Lee", "JeeEun Kim", "Jung Woo Lee"], "title": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "In oral cancer diagnostics, the limited availability of annotated datasets\nfrequently constrains the performance of diagnostic models, particularly due to\nthe variability and insufficiency of training data. To address these\nchallenges, this study proposed a novel approach to enhance diagnostic accuracy\nby synthesizing realistic oral cancer lesions using an inpainting technique\nwith a fine-tuned diffusion model. We compiled a comprehensive dataset from\nmultiple sources, featuring a variety of oral cancer images. Our method\ngenerated synthetic lesions that exhibit a high degree of visual fidelity to\nactual lesions, thereby significantly enhancing the performance of diagnostic\nalgorithms. The results show that our classification model achieved a\ndiagnostic accuracy of 0.97 in differentiating between cancerous and\nnon-cancerous tissues, while our detection model accurately identified lesion\nlocations with 0.85 accuracy. This method validates the potential for synthetic\nimage generation in medical diagnostics and paves the way for further research\ninto extending these methods to other types of cancer diagnostics.", "AI": {"tldr": "This paper introduces a method using synthetic image generation with inpainting and diffusion models to improve diagnostic accuracy in oral cancer by overcoming limitations of annotated datasets.", "motivation": "The motivation of the paper is to address the challenge of limited availability and variability of annotated datasets in oral cancer diagnostics, which constrains model performance.", "method": "The study utilizes an inpainting technique combined with a fine-tuned diffusion model to synthesize realistic oral cancer lesion images and enhance the diagnostic dataset.", "result": "The synthetic lesions improved diagnostic algorithms, achieving 0.97 accuracy in classification between cancerous and non-cancerous tissues and 0.85 accuracy in lesion detection.", "conclusion": "The approach demonstrates the potential of synthetic image generation in medical diagnostics and offers a foundation for exploring similar methods in other cancer diagnoses."}}
{"id": "2508.06404", "pdf": "https://arxiv.org/pdf/2508.06404", "abs": "https://arxiv.org/abs/2508.06404", "authors": ["Abdullah Zareh Andaryan", "Michael G. H. Bell", "Mohsen Ramezani", "Glenn Geers"], "title": "V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles", "categories": ["cs.RO", "math.OC"], "comment": null, "summary": "Autonomous vehicle navigation in structured environments requires planners\ncapable of generating time-optimal, collision-free trajectories that satisfy\ndynamic and kinematic constraints. We introduce V*, a graph-based motion\nplanner that represents speed and direction as explicit state variables within\na discretised space-time-velocity lattice. Unlike traditional methods that\ndecouple spatial search from dynamic feasibility or rely on post-hoc smoothing,\nV* integrates both motion dimensions directly into graph construction through\ndynamic graph generation during search expansion. To manage the complexity of\nhigh-dimensional search, we employ a hexagonal discretisation strategy and\nprovide formal mathematical proofs establishing optimal waypoint spacing and\nminimal node redundancy under constrained heading transitions for\nvelocity-aware motion planning. We develop a mathematical formulation for\ntransient steering dynamics in the kinematic bicycle model, modelling steering\nangle convergence with exponential behaviour, and deriving the relationship for\nconvergence rate parameters. This theoretical foundation, combined with\ngeometric pruning strategies that eliminate expansions leading to infeasible\nsteering configurations, enables V* to evaluate dynamically admissible\nmanoeuvres, ensuring each trajectory is physically realisable without further\nrefinement. We further demonstrate V*'s performance in simulation studies with\ncluttered and dynamic environments involving moving obstacles, showing its\nability to avoid conflicts, yield proactively, and generate safe, efficient\ntrajectories with temporal reasoning capabilities for waiting behaviours and\ndynamic coordination.", "AI": {"tldr": "This paper introduces V*, a motion planner for autonomous vehicles that integrates speed and direction into a graph-based approach to generate collision-free, time-optimal, and dynamically feasible trajectories.", "motivation": "To address the limitations of current motion planning methods for autonomous vehicles, which often separate spatial feasibility from dynamic constraints or require smoothing after trajectory generation.", "method": "The authors propose V*, a graph-based motion planner using a space-time-velocity lattice with integrated speed and direction as state variables. Techniques include hexagonal discretisation for efficient search, mathematical proofs for waypoint spacing, and geometric pruning to ensure dynamically feasible steering.", "result": "V* demonstrates successful navigation in simulations with cluttered and dynamic environments, proactively avoiding conflicts, waiting when necessary, and coordinating dynamically with moving obstacles.", "conclusion": "V* provides a theoretically sound framework to plan safe, efficient, and dynamically feasible trajectories without requiring additional refinement post-generation."}}
{"id": "2508.06178", "pdf": "https://arxiv.org/pdf/2508.06178", "abs": "https://arxiv.org/abs/2508.06178", "authors": ["Hugo Abonizio", "Thales Almeida", "Roberto Lotufo", "Rodrigo Nogueira"], "title": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) often require vast amounts of text to\neffectively acquire new knowledge. While continuing pre-training on large\ncorpora or employing retrieval-augmented generation (RAG) has proven\nsuccessful, updating an LLM with only a few thousand or million tokens remains\nchallenging. In this work, we investigate the task of injecting small,\nunstructured information into LLMs and its relation to the catastrophic\nforgetting phenomenon. We use a dataset of recent news -- ensuring no overlap\nwith the model's pre-training data -- to evaluate the knowledge acquisition by\nprobing the model with question-answer pairs related the learned information.\nStarting from a continued pre-training baseline, we explored different\naugmentation algorithms to generate synthetic data to improve the knowledge\nacquisition capabilities. Our experiments show that simply continuing\npre-training on limited data yields modest improvements, whereas exposing the\nmodel to diverse textual variations significantly improves the learning of new\nfacts -- particularly with methods that induce greater variability through\ndiverse prompting. Furthermore, we shed light on the forgetting phenomenon in\nsmall-data regimes, illustrating the delicate balance between learning new\ncontent and retaining existing capabilities. We also confirm the sensitivity of\nRAG-based approaches for knowledge injection, which often lead to greater\ndegradation on control datasets compared to parametric methods. Finally, we\ndemonstrate that models can generate effective synthetic training data\nthemselves, suggesting a pathway toward self-improving model updates. All code\nand generated data used in our experiments are publicly available, providing a\nresource for studying efficient knowledge injection in LLMs with limited data\nat https://github.com/hugoabonizio/knowledge-injection-methods.", "AI": {"tldr": "This paper explores methods to inject small amounts of new knowledge into large language models (LLMs) while minimizing catastrophic forgetting and retaining existing capabilities.", "motivation": "Updating large language models with small datasets (thousands or millions of tokens) is challenging due to factors like catastrophic forgetting, and the field lacks efficient techniques for knowledge injection with limited data.", "method": "The authors used news data outside the model's training set to test knowledge acquisition, employed various synthetic data augmentation techniques, and evaluated the balance between learning new facts and retaining old ones through controlled experiments.", "result": "Diverse prompting and synthetic data generation significantly improved knowledge acquisition, while RAG-based methods harmed performance on control datasets. Catastrophic forgetting remains a key challenge.", "conclusion": "Efficient knowledge injection is achievable with small datasets by leveraging diverse textual variations and synthetic data. Self-generated synthetic training data shows potential as a pathway toward self-improving LLMs."}}
{"id": "2508.06352", "pdf": "https://arxiv.org/pdf/2508.06352", "abs": "https://arxiv.org/abs/2508.06352", "authors": ["Christian Meske", "Justin Brenne", "Erdi Uenal", "Sabahat Oelcer", "Ayseguel Doganguen"], "title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Current explainable AI (XAI) approaches prioritize algorithmic transparency\nand present explanations in abstract, non-adaptive formats that often fail to\nsupport meaningful end-user understanding. This paper introduces \"Explanatory\nAI\" as a complementary paradigm that leverages generative AI capabilities to\nserve as explanatory partners for human understanding rather than providers of\nalgorithmic transparency. While XAI reveals algorithmic decision processes for\nmodel validation, Explanatory AI addresses contextual reasoning to support\nhuman decision-making in sociotechnical contexts. We develop a definition and\nsystematic eight-dimensional conceptual model distinguishing Explanatory AI\nthrough narrative communication, adaptive personalization, and progressive\ndisclosure principles. Empirical validation through Rapid Contextual Design\nmethodology with healthcare professionals demonstrates that users consistently\nprefer context-sensitive, multimodal explanations over technical transparency.\nOur findings reveal the practical urgency for AI systems designed for human\ncomprehension rather than algorithmic introspection, establishing a\ncomprehensive research agenda for advancing user-centered AI explanation\napproaches across diverse domains and cultural contexts.", "AI": {"tldr": "This paper introduces 'Explanatory AI,' emphasizing user-focused contextual reasoning over traditional algorithmic transparency and validates its efficacy with healthcare professionals.", "motivation": "To address the shortcomings of traditional explainable AI (XAI) in supporting meaningful end-user understanding, particularly in sociotechnical decision-making contexts.", "method": "The authors propose an eight-dimensional conceptual model for Explanatory AI, based on narrative communication, adaptive personalization, and progressive disclosure, and validate it through Rapid Contextual Design with healthcare professionals.", "result": "Users consistently preferred context-sensitive and multimodal explanations provided by Explanatory AI over technical transparency.", "conclusion": "There is a critical need for AI systems that prioritize human comprehension and contextual reasoning across various domains, suggesting a shift in research focus towards user-centered explanation methods."}}
{"id": "2508.05994", "pdf": "https://arxiv.org/pdf/2508.05994", "abs": "https://arxiv.org/abs/2508.05994", "authors": ["Huadong Wu", "Yi Fu", "Yunhao Li", "Yuan Gao", "Kang Du"], "title": "EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad", "categories": ["cs.CV"], "comment": null, "summary": "Facial makeup editing aims to realistically transfer makeup from a reference\nto a target face. Existing methods often produce low-quality results with\ncoarse makeup details and struggle to preserve both identity and makeup\nfidelity, mainly due to the lack of structured paired data -- where source and\nresult share identity, and reference and result share identical makeup. To\naddress this, we introduce MakeupQuad, a large-scale, high-quality dataset with\nnon-makeup faces, references, edited results, and textual makeup descriptions.\nBuilding on this, we propose EvoMakeup, a unified training framework that\nmitigates image degradation during multi-stage distillation, enabling iterative\nimprovement of both data and model quality. Although trained solely on\nsynthetic data, EvoMakeup generalizes well and outperforms prior methods on\nreal-world benchmarks. It supports high-fidelity, controllable, multi-task\nmakeup editing -- including full-face and partial reference-based editing, as\nwell as text-driven makeup editing -- within a single model. Experimental\nresults demonstrate that our method achieves superior makeup fidelity and\nidentity preservation, effectively balancing both aspects. Code and dataset\nwill be released upon acceptance.", "AI": {"tldr": "The paper introduces a new dataset (MakeupQuad) and framework (EvoMakeup) for high-quality facial makeup editing, excelling in maintaining identity and makeup fidelity.", "motivation": "Current methods for makeup transfer fail to produce high-quality results due to the lack of structured paired data that preserves identity and makeup fidelity.", "method": "The authors developed MakeupQuad, a large-scale dataset with diverse inputs, and EvoMakeup, a training framework that iteratively improves data and model quality.", "result": "EvoMakeup, trained only on synthetic data, excels at makeup fidelity and identity preservation across various tasks, outperforming previous methods on real-world benchmarks.", "conclusion": "The proposed dataset and framework enable superior, flexible, and high-fidelity makeup editing. Future code and data release will support further research."}}
{"id": "2508.06183", "pdf": "https://arxiv.org/pdf/2508.06183", "abs": "https://arxiv.org/abs/2508.06183", "authors": ["Xiyuan Yang", "Shengyuan Hu", "Soyeon Kim", "Tian Li"], "title": "Differentially Private Federated Clustering with Random Rebalancing", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages", "summary": "Federated clustering aims to group similar clients into clusters and produce\none model for each cluster. Such a personalization approach typically improves\nmodel performance compared with training a single model to serve all clients,\nbut can be more vulnerable to privacy leakage. Directly applying client-level\ndifferentially private (DP) mechanisms to federated clustering could degrade\nthe utilities significantly. We identify that such deficiencies are mainly due\nto the difficulties of averaging privacy noise within each cluster (following\nstandard privacy mechanisms), as the number of clients assigned to the same\nclusters is uncontrolled. To this end, we propose a simple and effective\ntechnique, named RR-Cluster, that can be viewed as a light-weight add-on to\nmany federated clustering algorithms. RR-Cluster achieves reduced privacy noise\nvia randomly rebalancing cluster assignments, guaranteeing a minimum number of\nclients assigned to each cluster. We analyze the tradeoffs between decreased\nprivacy noise variance and potentially increased bias from incorrect\nassignments and provide convergence bounds for RR-Clsuter. Empirically, we\ndemonstrate the RR-Cluster plugged into strong federated clustering algorithms\nresults in significantly improved privacy/utility tradeoffs across both\nsynthetic and real-world datasets.", "AI": {"tldr": "The paper addresses privacy challenges in federated clustering by introducing RR-Cluster, a lightweight method to minimize privacy noise via random rebalancing of cluster assignments without compromising utility.", "motivation": "The authors aim to tackle the vulnerabilities of federated clustering to privacy leakage while preserving model utility, as current privacy mechanisms often lead to degraded performance.", "method": "The RR-Cluster technique involves randomly rebalancing cluster assignments to ensure a minimum number of clients per cluster, reducing privacy noise variance while analyzing tradeoffs between noise and bias.", "result": "RR-Cluster improves privacy/utility tradeoffs when integrated with federated clustering algorithms, demonstrated across synthetic and real-world datasets.", "conclusion": "The proposed RR-Cluster method is an effective add-on for federated clustering algorithms, enhancing both privacy preservation and model utility."}}
{"id": "2508.06426", "pdf": "https://arxiv.org/pdf/2508.06426", "abs": "https://arxiv.org/abs/2508.06426", "authors": ["Youguang Xing", "Xu Luo", "Junlin Xie", "Lianli Gao", "Hengtao Shen", "Jingkuan Song"], "title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "CoRL 2025", "summary": "Generalist robot policies trained on large-scale datasets such as Open\nX-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.\nHowever, they often struggle to generalize beyond the distribution of their\ntraining data. In this paper, we investigate the underlying cause of this\nlimited generalization capability. We identify shortcut learning -- the\nreliance on task-irrelevant features -- as a key impediment to generalization.\nThrough comprehensive theoretical and empirical analysis, we uncover two\nprimary contributors to shortcut learning: (1) limited diversity within\nindividual sub-datasets, and (2) significant distributional disparities across\nsub-datasets, leading to dataset fragmentation. These issues arise from the\ninherent structure of large-scale datasets like OXE, which are typically\ncomposed of multiple sub-datasets collected independently across varied\nenvironments and embodiments. Our findings provide critical insights into\ndataset collection strategies that can reduce shortcut learning and enhance the\ngeneralization ability of generalist robot policies. Moreover, in scenarios\nwhere acquiring new large-scale data is impractical, we demonstrate that\ncarefully selected robotic data augmentation strategies can effectively reduce\nshortcut learning in existing offline datasets, thereby improving\ngeneralization capabilities of generalist robot policies, e.g., $\\pi_0$, in\nboth simulation and real-world environments. More information at\nhttps://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.", "AI": {"tldr": "This paper analyzes the limited generalization capacity observed in generalist robot policies trained on large-scale datasets like Open X-Embodiment (OXE), attributing it to shortcut learning caused by dataset limitations.", "motivation": "To address the challenge of poor generalization in generalist robot policies, which hinders their practical deployment in tasks deviating from the training data distribution.", "method": "The paper conducts theoretical and empirical analysis to identify the key causes of shortcut learning, namely limited diversity within sub-datasets and large distributional disparities. It also explores robotic data augmentation strategies to mitigate these issues.", "result": "The study confirms that shortcut learning is rooted in dataset structure and argues for improved dataset collection strategies and data augmentation as means of addressing the problem. Both methods show improvements in simulations and real-world tests.", "conclusion": "Understanding the structural shortcomings of large-scale datasets like OXE and leveraging data augmentation can significantly enhance the generalization potential of generalist robot policies."}}
{"id": "2508.06186", "pdf": "https://arxiv.org/pdf/2508.06186", "abs": "https://arxiv.org/abs/2508.06186", "authors": ["Ali Sarabadani", "Maryam Abdollahi Shamami", "Hamidreza Sadeghsalehi", "Borhan Asadi", "Saba Hesaraki"], "title": "DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have grown exponentially since the release of\nChatGPT. These models have gained attention due to their robust performance on\nvarious tasks, including language processing tasks. These models achieve\nunderstanding and comprehension of tasks by training billions of parameters.\nThe development of these models is a transformative force in enhancing natural\nlanguage understanding and has taken a significant step towards artificial\ngeneral intelligence (AGI). In this study, we aim to present the DKG-LLM\nframework. The DKG-LLM framework introduces a groundbreaking approach to\nmedical diagnosis and personalized treatment recommendations by integrating a\ndynamic knowledge graph (DKG) with the Grok 3 large language model. Using the\nAdaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data\n(including clinical reports and PubMed articles) and patient records\ndynamically generate a knowledge graph consisting of 15,964 nodes in 13\ndistinct types (e.g., diseases, symptoms, treatments, patient profiles) and\n127,392 edges in 26 relationship types (e.g., causal, therapeutic,\nassociation). ASFA utilizes advanced probabilistic models, Bayesian inference,\nand graph optimization to extract semantic information, dynamically updating\nthe graph with approximately 150 new nodes and edges in each data category\nwhile maintaining scalability with up to 987,654 edges. Real-world datasets,\nincluding MIMIC-III and PubMed, were utilized to evaluate the proposed\narchitecture. The evaluation results show that DKG-LLM achieves a diagnostic\naccuracy of 84.19%. The model also has a treatment recommendation accuracy of\n89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and\ntransformative tool that handles noisy data and complex multi-symptom diseases,\nalong with feedback-based learning from physician input.", "AI": {"tldr": "The paper introduces the DKG-LLM framework that combines dynamic knowledge graphs with large language models for medical diagnosis and personalized treatment recommendations, achieving high levels of diagnostic and recommendation accuracy.", "motivation": "The motivation behind this paper is to leverage the transformative potential of large language models by incorporating dynamic knowledge graphs to enhance medical diagnosis and personalized treatment recommendations.", "method": "The study integrates a dynamic knowledge graph (DKG) with the Grok 3 large language model and employs the Adaptive Semantic Fusion Algorithm (ASFA) to process and dynamically update medical data, achieving scalable graph construction and accurate diagnostic modeling.", "result": "Evaluation using real-world datasets like MIMIC-III and PubMed demonstrated that DKG-LLM achieves a diagnostic accuracy of 84.19%, a treatment recommendation accuracy of 89.63%, and a semantic coverage of 93.48%.", "conclusion": "DKG-LLM is presented as a reliable tool for handling noisy medical data and complex diseases, providing transformative insights and personalization in medical domains."}}
{"id": "2508.06368", "pdf": "https://arxiv.org/pdf/2508.06368", "abs": "https://arxiv.org/abs/2508.06368", "authors": ["Claudia dAmato", "Giuseppe Rubini", "Francesco Didio", "Donato Francioso", "Fatima Zahra Amara", "Nicola Fanizzi"], "title": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned", "categories": ["cs.AI"], "comment": null, "summary": "Legal decision-making process requires the availability of comprehensive and\ndetailed legislative background knowledge and up-to-date information on legal\ncases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a\nvaluable tool to facilitate access to legal information, to be queried and\nexploited for the purpose, and to enable advanced reasoning and machine\nlearning applications. Indeed, legal KGs may act as knowledge intensive\ncomponent to be used by pre-dictive machine learning solutions supporting the\ndecision process of the legal expert. Nevertheless, a few KGs can be found in\nthe legal domain. To fill this gap, we developed a legal KG targeting legal\ncases of violence against women, along with clear adopted methodologies.\nSpecifically, the paper introduces two complementary approaches for automated\nlegal KG construction; a systematic bottom-up approach, customized for the\nlegal domain, and a new solution leveraging Large Language Models. Starting\nfrom legal sentences publicly available from the European Court of Justice, the\nsolutions integrate structured data extraction, ontology development, and\nsemantic enrichment to produce KGs tailored for legal cases involving violence\nagainst women. After analyzing and comparing the results of the two approaches,\nthe developed KGs are validated via suitable competency questions. The obtained\nKG may be impactful for multiple purposes: can improve the accessibility to\nlegal information both to humans and machine, can enable complex queries and\nmay constitute an important knowledge component to be possibly exploited by\nmachine learning tools tailored for predictive justice.", "AI": {"tldr": "This paper presents the development of Legal Knowledge Graphs (KGs) for violence against women cases, using two complementary automated approaches: a domain-specific method and a Large Language Model-driven method.", "motivation": "Legal decision-making requires structured access to detailed legislative information and case records, but there is a lack of domain-specific Legal Knowledge Graphs, especially for cases involving violence against women.", "method": "The work introduces two approaches for constructing legal KGs: a systematic bottom-up method customized for the legal domain and a solution using Large Language Models. Both approaches involve structured data extraction, ontology creation, and semantic enrichment.", "result": "Two Legal Knowledge Graphs tailored to violence against women cases were developed and validated through competency questions, demonstrating their ability to improve legal information accessibility and enable complex queries.", "conclusion": "The developed KGs not only enhance access to legal information but also provide a foundation for machine learning solutions aimed at predictive justice, potentially aiding decision-making processes."}}
{"id": "2508.06009", "pdf": "https://arxiv.org/pdf/2508.06009", "abs": "https://arxiv.org/abs/2508.06009", "authors": ["Jun Feng", "Zixin Wang", "Zhentao Zhang", "Yue Guo", "Zhihan Zhou", "Xiuyi Chen", "Zhenyang Li", "Dawei Yin"], "title": "MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": "29 pages, 16 figures", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in visual mathematical reasoning across various existing\nbenchmarks. However, these benchmarks are predominantly based on clean or\nprocessed multimodal inputs, without incorporating the images provided by\nreal-world Kindergarten through 12th grade (K-12) educational users. To address\nthis gap, we introduce MathReal, a meticulously curated dataset comprising\n2,000 mathematical questions with images captured by handheld mobile devices in\nauthentic scenarios. Each question is an image, containing the question text\nand visual element. We systematically classify the real images into three\nprimary categories: image quality degradation, perspective variation, and\nirrelevant content interference, which are further delineated into 14\nsubcategories. Additionally, MathReal spans five core knowledge and ability\ncategories, which encompass three question types and are divided into three\ndifficulty levels. To comprehensively evaluate the multimodal mathematical\nreasoning abilities of state-of-the-art MLLMs in real-world scenarios, we\ndesign six experimental settings that enable a systematic analysis of their\nperformance. Through extensive experimentation, we find that the\nproblem-solving abilities of existing MLLMs are significantly challenged in\nrealistic educational contexts. Based on this, we conduct a thorough analysis\nof their performance and error patterns, providing insights into their\nrecognition, comprehension, and reasoning capabilities, and outlining\ndirections for future improvements. Data and code:\nhttps://github.com/junfeng0288/MathReal.", "AI": {"tldr": "The paper introduces MathReal, a dataset of real-world educational math problems with images to evaluate MLLMs' reasoning abilities, revealing significant challenges in realistic contexts.", "motivation": "Existing benchmarks for visual mathematical reasoning are based on clean or processed modalities, lacking real-world scenarios provided by K-12 educational users.", "method": "The authors created the MathReal dataset with 2,000 real math questions captured via mobile devices, categorized images into 14 subcategories of challenges, and evaluated MLLMs in six experimental settings.", "result": "MLLMs show significant performance limitations when tested in realistic educational contexts, with challenges identified across recognition, comprehension, and reasoning.", "conclusion": "MathReal dataset highlights the need for improved algorithms to enhance MLLMs' real-world problem-solving capabilities, driving future research focus."}}
{"id": "2508.06199", "pdf": "https://arxiv.org/pdf/2508.06199", "abs": "https://arxiv.org/abs/2508.06199", "authors": ["Mateusz Praski", "Jakub Adamczyk", "Wojciech Czech"], "title": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Pretrained neural networks have attracted significant interest in chemistry\nand small molecule drug design. Embeddings from these models are widely used\nfor molecular property prediction, virtual screening, and small data learning\nin molecular chemistry. This study presents the most extensive comparison of\nsuch models to date, evaluating 25 models across 25 datasets. Under a fair\ncomparison framework, we assess models spanning various modalities,\narchitectures, and pretraining strategies. Using a dedicated hierarchical\nBayesian statistical testing model, we arrive at a surprising result: nearly\nall neural models show negligible or no improvement over the baseline ECFP\nmolecular fingerprint. Only the CLAMP model, which is also based on molecular\nfingerprints, performs statistically significantly better than the\nalternatives. These findings raise concerns about the evaluation rigor in\nexisting studies. We discuss potential causes, propose solutions, and offer\npractical recommendations.", "AI": {"tldr": "The study compares 25 pretrained neural network models in molecular chemistry and finds that most do not outperform the baseline ECFP molecular fingerprint.", "motivation": "To assess the effectiveness of pretrained neural networks in molecular property prediction and drug design, and to address evaluation pitfalls in previous studies.", "method": "The authors conducted a systematic evaluation of 25 models across 25 datasets using a fair comparison framework and hierarchical Bayesian statistical testing.", "result": "Most neural models do not show notable improvement over the ECFP molecular fingerprint baseline. The CLAMP model is the only exception with better performance.", "conclusion": "Current pretrained neural networks provide limited added value over traditional ECFP molecular fingerprints, prompting a need for more rigorous evaluation and better methodologies."}}
{"id": "2508.05646", "pdf": "https://arxiv.org/pdf/2508.05646", "abs": "https://arxiv.org/abs/2508.05646", "authors": ["Thomas Sievers"], "title": "A Humanoid Social Robot as a Teaching Assistant in the Classroom", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Although innovation and the support of new technologies are much needed to\nease the burden on the education system, social robots in schools to help\nteachers with educational tasks are rare. Child-Robot Interaction (CRI) could\nsupport teachers and add an embodied social component to modern multi-modal and\nmulti-sensory learning environments already in use. The social robot Pepper,\nconnected to the Large Language Model (LLM) ChatGPT, was used in a high school\nclassroom to teach new learning content to groups of students. I tested the\ntechnical possibilities with the robot on site and asked the students about\ntheir acceptance and perceived usefulness of teaching with the help of a social\nrobot. All participants felt that the robot's presentation of the learning\nmaterial was appropriate or at least partially appropriate and that its use\nmade sense.", "AI": {"tldr": "This paper explores the use of the social robot Pepper, connected to ChatGPT, in high school classrooms to teach learning content and gauges students' acceptance and perceived usefulness.", "motivation": "To address the lack of social robots assisting teachers in educational environments and explore the potential of Child-Robot Interaction (CRI) in modern learning environments.", "method": "The robot Pepper, connected to ChatGPT, was deployed in a high school classroom to present learning content. Student feedback regarding the robot's acceptance and perceived usefulness was gathered.", "result": "All participants found the robot's presentation appropriate or partially appropriate and believed its use to be justified.", "conclusion": "Integrating a social robot like Pepper, with AI capabilities, into classrooms is perceived positively by students and holds promise for enhancing educational tasks."}}
{"id": "2508.06194", "pdf": "https://arxiv.org/pdf/2508.06194", "abs": "https://arxiv.org/abs/2508.06194", "authors": ["Lai Jiang", "Yuekang Li", "Xiaohan Zhang", "Youtao Ding", "Li Pan"], "title": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Precise jailbreak evaluation is vital for LLM red teaming and jailbreak\nresearch. Current approaches employ binary classification ( e.g., string\nmatching, toxic text classifiers, LLM-driven methods), yielding only \"yes/no\"\nlabels without quantifying harm intensity. Existing multi-dimensional\nframeworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)\napply uniform evaluation criteria across scenarios, resulting in\nscenario-specific mismatches--for instance, \"Relative Truthfulness\" is\nirrelevant to \"hate speech\"--which compromise evaluation precision. To tackle\nthese limitations, we introduce SceneJailEval, with key contributions: (1) A\ngroundbreaking scenario-adaptive multi-dimensional framework for jailbreak\nevaluation, overcoming the critical \"one-size-fits-all\" constraint of existing\nmulti-dimensional methods, and featuring strong extensibility to flexibly adapt\nto customized or emerging scenarios. (2) A comprehensive 14-scenario dataset\nwith diverse jailbreak variants and regional cases, filling the long-standing\ngap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)\nSceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on\nour full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over\nprior SOTA), surpassing accuracy limits of existing evaluation methods in\nheterogeneous scenarios and confirming its advantage.", "AI": {"tldr": "SceneJailEval introduces a scenario-adaptive multi-dimensional framework for precise jailbreak evaluation, significantly outperforming past methods with a remarkable F1 score of 0.917 and a specialized dataset.", "motivation": "Current jailbreak evaluations lack precision due to binary-only methods and uniform criteria applied across diverse scenarios, necessitating a more adaptive approach.", "method": "The paper presents a scenario-adaptive multi-dimensional evaluation framework and develops a comprehensive dataset covering 14 scenarios with varied jailbreak cases.", "result": "SceneJailEval achieved state-of-the-art performance with an F1 score of 0.917 on a diverse dataset and 0.995 on JBB, improving by up to 6% over prior methods.", "conclusion": "SceneJailEval's adaptable framework and dataset overcome critical limitations in existing methods, offering precise and extensible evaluation across heterogeneous scenarios."}}
{"id": "2508.06443", "pdf": "https://arxiv.org/pdf/2508.06443", "abs": "https://arxiv.org/abs/2508.06443", "authors": ["Debabrota Basu", "Udvas Das"], "title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.GT"], "comment": null, "summary": "An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify\ndifferent types of bias (also known as unfairness) exhibited in the predictions\nof ML algorithms, and to design new algorithms to mitigate them. Often, the\ndefinitions of bias used in the literature are observational, i.e. they use the\ninput and output of a pre-trained algorithm to quantify a bias under concern.\nIn reality,these definitions are often conflicting in nature and can only be\ndeployed if either the ground truth is known or only in retrospect after\ndeploying the algorithm. Thus,there is a gap between what we want Fair ML to\nachieve and what it does in a dynamic social environment. Hence, we propose an\nalternative dynamic mechanism,\"Fair Game\",to assure fairness in the predictions\nof an ML algorithm and to adapt its predictions as the society interacts with\nthe algorithm over time. \"Fair Game\" puts together an Auditor and a Debiasing\nalgorithm in a loop around an ML algorithm. The \"Fair Game\" puts these two\ncomponents in a loop by leveraging Reinforcement Learning (RL). RL algorithms\ninteract with an environment to take decisions, which yields new observations\n(also known as data/feedback) from the environment and in turn, adapts future\ndecisions. RL is already used in algorithms with pre-fixed long-term fairness\ngoals. \"Fair Game\" provides a unique framework where the fairness goals can be\nadapted over time by only modifying the auditor and the different biases it\nquantifies. Thus,\"Fair Game\" aims to simulate the evolution of ethical and\nlegal frameworks in the society by creating an auditor which sends feedback to\na debiasing algorithm deployed around an ML system. This allows us to develop a\nflexible and adaptive-over-time framework to build Fair ML systems pre- and\npost-deployment.", "AI": {"tldr": "The paper introduces 'Fair Game,' a dynamic mechanism using Reinforcement Learning to adaptively ensure fairness in ML predictions over time.", "motivation": "Current Fair ML approaches face limitations as their bias definitions are often conflicting and static, hindering effective use in dynamic social environments.", "method": "Introduces 'Fair Game,' combining an Auditor and Debiasing algorithm within a Reinforcement Learning loop to adapt ML system predictions based on societal feedback.", "result": "The framework enables adaptive fairness that evolves with societal changes by modifying the Auditor's bias definitions.", "conclusion": "'Fair Game' facilitates the development of flexible ML systems capable of addressing fairness pre- and post-deployment, aligning with societal ethical and legal evolution."}}
{"id": "2508.06014", "pdf": "https://arxiv.org/pdf/2508.06014", "abs": "https://arxiv.org/abs/2508.06014", "authors": ["Minsu Kim", "Subin Jeon", "In Cho", "Mijin Yoo", "Seon Joo Kim"], "title": "ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors", "categories": ["cs.CV"], "comment": "10 pages, 6 Figures, ICCV 2025", "summary": "Recent advances in novel view synthesis (NVS) have enabled real-time\nrendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle\nwith artifacts and missing regions when rendering from viewpoints that deviate\nfrom the training trajectory, limiting seamless scene exploration. To address\nthis, we propose a 3DGS-based pipeline that generates additional training views\nto enhance reconstruction. We introduce an information-gain-driven virtual\ncamera placement strategy to maximize scene coverage, followed by video\ndiffusion priors to refine rendered results. Fine-tuning 3D Gaussians with\nthese enhanced views significantly improves reconstruction quality. To evaluate\nour method, we present Wild-Explore, a benchmark designed for challenging scene\nexploration. Experiments demonstrate that our approach outperforms existing\n3DGS-based methods, enabling high-quality, artifact-free rendering from\narbitrary viewpoints.\n  https://exploregs.github.io", "AI": {"tldr": "The paper proposes an improved pipeline for 3D Gaussian Splatting (3DGS) to address rendering artifacts and missing regions during novel view synthesis (NVS), enabling better reconstruction and scene exploration.", "motivation": "Current 3DGS methods struggle with artifacts and incomplete renderings when viewing scenes from perspectives outside the training viewpoints, which hinders seamless exploration.", "method": "The authors propose a pipeline using an information-gain-driven virtual camera placement strategy to improve scene coverage and video diffusion priors to enhance rendering quality. They also fine-tune 3D Gaussians with the augmented views.", "result": "The proposed method outperforms existing 3DGS approaches in rendering quality and artifact reduction, as validated on the new Wild-Explore benchmark designed for challenging scene exploration.", "conclusion": "This improved 3DGS pipeline facilitates high-quality, artifact-free rendering from arbitrary viewpoints, providing a significant improvement in novel view synthesis for complex scenes."}}
{"id": "2508.06208", "pdf": "https://arxiv.org/pdf/2508.06208", "abs": "https://arxiv.org/abs/2508.06208", "authors": ["Ce Na", "Kai Yang", "Dengzhao Fang", "Yu Li", "Jingtong Gao", "Chengcheng Zhu", "Jiale Zhang", "Xiaobing Sun", "Yi Chang"], "title": "Graph Federated Learning for Personalized Privacy Recommendation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated recommendation systems (FedRecs) have gained significant attention\nfor providing privacy-preserving recommendation services. However, existing\nFedRecs assume that all users have the same requirements for privacy\nprotection, i.e., they do not upload any data to the server. The approaches\noverlook the potential to enhance the recommendation service by utilizing\npublicly available user data. In real-world applications, users can choose to\nbe private or public. Private users' interaction data is not shared, while\npublic users' interaction data can be shared. Inspired by the issue, this paper\nproposes a novel Graph Federated Learning for Personalized Privacy\nRecommendation (GFed-PP) that adapts to different privacy requirements while\nimproving recommendation performance. GFed-PP incorporates the interaction data\nof public users to build a user-item interaction graph, which is then used to\nform a user relationship graph. A lightweight graph convolutional network (GCN)\nis employed to learn each user's user-specific personalized item embedding. To\nprotect user privacy, each client learns the user embedding and the scoring\nfunction locally. Additionally, GFed-PP achieves optimization of the federated\nrecommendation framework through the initialization of item embedding on\nclients and the aggregation of the user relationship graph on the server.\nExperimental results demonstrate that GFed-PP significantly outperforms\nexisting methods for five datasets, offering superior recommendation accuracy\nwithout compromising privacy. This framework provides a practical solution for\naccommodating varying privacy preferences in federated recommendation systems.", "AI": {"tldr": "This paper introduces GFed-PP, a federated recommendation system capable of adjusting to varying user privacy preferences while leveraging publicly available data to improve recommendation performance.", "motivation": "Current federated recommendation systems assume uniform privacy requirements, neglecting opportunities to enhance recommendations by using public user data.", "method": "GFed-PP combines public user interaction data to create user-item and user relationship graphs, employs lightweight GCN for personalized item embedding, learns key metrics locally on clients, and optimizes the framework through server-side aggregation and initialization.", "result": "Experimental evaluations show GFed-PP achieves superior recommendation accuracy across five datasets without compromising privacy.", "conclusion": "GFed-PP is a practical and effective approach to balancing personalized privacy preferences and improved recommendation accuracy in federated systems."}}
{"id": "2508.05846", "pdf": "https://arxiv.org/pdf/2508.05846", "abs": "https://arxiv.org/abs/2508.05846", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "cs.RO", "68T01, 68T40", "K.7.4; K.4.1; I.2.9; H.1.2"], "comment": "Published in the Proceedings of the 2025 3rd International Conference\n  on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 tables", "summary": "As artificial intelligence (AI) and robotics increasingly permeate society,\nensuring the ethical behavior of these systems has become paramount. This paper\ncontends that transparency in AI decision-making processes is fundamental to\ndeveloping trustworthy and ethically aligned robotic systems. We explore how\ntransparency facilitates accountability, enables informed consent, and supports\nthe debugging of ethical algorithms. The paper outlines technical, ethical, and\npractical challenges in implementing transparency and proposes novel approaches\nto enhance it, including standardized metrics, explainable AI techniques, and\nuser-friendly interfaces. This paper introduces a framework that connects\ntechnical implementation with ethical considerations in robotic systems,\nfocusing on the specific challenges of achieving transparency in dynamic,\nreal-world contexts. We analyze how prioritizing transparency can impact public\ntrust, regulatory policies, and avenues for future research. By positioning\ntransparency as a fundamental element in ethical AI system design, we aim to\nadd to the ongoing discussion on responsible AI and robotics, providing\ndirection for future advancements in this vital field.", "AI": {"tldr": "The paper emphasizes the importance of transparency in AI and robotics to ensure ethical behavior and trustworthiness, exploring its challenges and proposing solutions.", "motivation": "The increase in AI and robotics usage in society creates a need for ethical and trustworthy systems, which requires transparency in decision-making processes.", "method": "The authors propose approaches for enhancing transparency such as standardized metrics, explainable AI techniques, and user-friendly interfaces, along with a framework connecting technical implementation to ethical considerations.", "result": "The paper highlights how transparency impacts public trust, regulatory policies, and research directions, fundamentally affecting ethical AI design.", "conclusion": "Transparency is crucial for ethical and responsible AI system designs, and the paper adds to discussions on advancing the field with practical and ethical considerations."}}
{"id": "2508.06196", "pdf": "https://arxiv.org/pdf/2508.06196", "abs": "https://arxiv.org/abs/2508.06196", "authors": ["Nizi Nazar", "Ehsaneddin Asgari"], "title": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Emotional Intelligence (EI) is a critical yet underexplored dimension in the\ndevelopment of human-aligned LLMs. To address this gap, we introduce a unified,\npsychologically grounded four-layer taxonomy of EI tailored for large language\nmodels (LLMs), encompassing emotional tracking, cause inference, appraisal, and\nemotionally appropriate response generation. Building on this framework, we\npresent EICAP-Bench, a novel MCQ style multi-turn benchmark designed to\nevaluate EI capabilities in open-source LLMs across diverse linguistic and\ncultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma\n(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,\nidentifying Qwen2.5-Instruct as the strongest baseline. To assess the potential\nfor enhancing EI capabilities, we fine-tune both Qwen2.5-Base and\nQwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,\ninstruction-tuned dialogue dataset, in both English and Arabic. Our statistical\nanalysis reveals that among the five EI layers, only the Appraisal layer shows\nsignificant improvement through UC-based fine-tuning. These findings highlight\nthe limitations of existing pretraining and instruction-tuning paradigms in\nequipping LLMs with deeper emotional reasoning and underscore the need for\ntargeted data and modeling strategies for comprehensive EI alignment.", "AI": {"tldr": "The paper introduces a taxonomy for Emotional Intelligence (EI) in large language models (LLMs) and evaluates six LLMs using a novel benchmark called EmoCap-Bench, finding limitations in current pretraining for emotional reasoning.", "motivation": "To address the gap in equipping LLMs with Emotional Intelligence (EI) capabilities for human alignment.", "method": "The authors propose a four-layer taxonomy for EI and design the multi-turn benchmark EICAP-Bench to test LLMs, followed by fine-tuning selected LLMs using LoRA adapters on UltraChat in multiple languages.", "result": "They found significant improvement in the 'Appraisal' layer of EI through fine-tuning but observed general limitations in current pretraining and instruction-tuning methods.", "conclusion": "Comprehensive EI alignment in LLMs requires more specialized data and modeling approaches as current paradigms are insufficient."}}
{"id": "2508.06454", "pdf": "https://arxiv.org/pdf/2508.06454", "abs": "https://arxiv.org/abs/2508.06454", "authors": ["Joshua Caiata", "Ben Armstrong", "Kate Larson"], "title": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting", "categories": ["cs.AI", "cs.GT"], "comment": "41 pages", "summary": "Committee-selection problems arise in many contexts and applications, and\nthere has been increasing interest within the social choice research community\non identifying which properties are satisfied by different multi-winner voting\nrules. In this work, we propose a data-driven framework to evaluate how\nfrequently voting rules violate axioms across diverse preference distributions\nin practice, shifting away from the binary perspective of axiom satisfaction\ngiven by worst-case analysis. Using this framework, we analyze the relationship\nbetween multi-winner voting rules and their axiomatic performance under several\npreference distributions. We then show that neural networks, acting as voting\nrules, can outperform traditional rules in minimizing axiom violations. Our\nresults suggest that data-driven approaches to social choice can inform the\ndesign of new voting systems and support the continuation of data-driven\nresearch in social choice.", "AI": {"tldr": "The paper introduces a data-driven framework to examine how often different multi-winner voting rules violate axioms under various preference distributions, rather than relying solely on worst-case scenarios.", "motivation": "Traditional analysis of multi-winner voting rules tends to focus on whether these rules satisfy axioms in a binary manner under worst-case scenarios. There is a need for a practical evaluation method that considers violations across diverse preference distributions.", "method": "The researchers employed a data-driven framework to evaluate the frequency of axiom violations of multi-winner voting rules across diverse preference distributions. They also compared standard voting rules with neural networks acting as voting rules.", "result": "Neural networks, when used as voting rules, exhibited better performance in reducing axiom violations compared to traditional voting mechanisms.", "conclusion": "The study suggests that data-driven approaches can improve the design and evaluation of voting systems, emphasizing the potential for neural networks in developing advanced voting methodologies."}}
{"id": "2508.06021", "pdf": "https://arxiv.org/pdf/2508.06021", "abs": "https://arxiv.org/abs/2508.06021", "authors": ["Utku Ozbulak", "Michaela Cohrs", "Hristo L. Svilenov", "Joris Vankerschaver", "Wesley De Neve"], "title": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Sub-visible particle analysis using flow imaging microscopy combined with\ndeep learning has proven effective in identifying particle types, enabling the\ndistinction of harmless components such as silicone oil from protein particles.\nHowever, the scarcity of available data and severe imbalance between particle\ntypes within datasets remain substantial hurdles when applying multi-class\nclassifiers to such problems, often forcing researchers to rely on less\neffective methods. The aforementioned issue is particularly challenging for\nparticle types that appear unintentionally and in lower numbers, such as\nsilicone oil and air bubbles, as opposed to protein particles, where obtaining\nlarge numbers of images through controlled settings is comparatively\nstraightforward. In this work, we develop a state-of-the-art diffusion model to\naddress data imbalance by generating high-fidelity images that can augment\ntraining datasets, enabling the effective training of multi-class deep neural\nnetworks. We validate this approach by demonstrating that the generated samples\nclosely resemble real particle images in terms of visual quality and structure.\nTo assess the effectiveness of using diffusion-generated images in training\ndatasets, we conduct large-scale experiments on a validation dataset comprising\n500,000 protein particle images and demonstrate that this approach improves\nclassification performance with no negligible downside. Finally, to promote\nopen research and reproducibility, we publicly release both our diffusion\nmodels and the trained multi-class deep neural network classifiers, along with\na straightforward interface for easy integration into future studies, at\nhttps://github.com/utkuozbulak/svp-generative-ai.", "AI": {"tldr": "This paper presents a diffusion model to generate high-fidelity images to address data imbalance in sub-visible particle analysis, improving multi-class classifier performance.", "motivation": "The research aims to tackle data scarcity and class imbalance issues in sub-visible particle analysis, which hinder the effectiveness of multi-class classifiers, especially for underrepresented types like silicone oil and air bubbles.", "method": "The study develops a state-of-the-art diffusion model to generate synthetic particle images to augment training datasets, validating the generated images' quality through visual resemblance and structural fidelity.", "result": "The diffusion-generated images improved classification performance when applied to a large validation dataset of 500,000 protein particle images, with no significant drawbacks.", "conclusion": "The use of diffusion models effectively addresses data imbalance, enhancing deep learning classifier performance for sub-visible particle analysis, and the tools are released publicly for broader accessibility."}}
{"id": "2508.06214", "pdf": "https://arxiv.org/pdf/2508.06214", "abs": "https://arxiv.org/abs/2508.06214", "authors": ["Hai Zhong", "Xun Wang", "Zhuoran Li", "Longbo Huang"], "title": "Reparameterization Proximal Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reparameterization policy gradient (RPG) is promising for improving sample\nefficiency by leveraging differentiable dynamics. However, a critical barrier\nis its training instability, where high-variance gradients can destabilize the\nlearning process. To address this, we draw inspiration from Proximal Policy\nOptimization (PPO), which uses a surrogate objective to enable stable sample\nreuse in the model-free setting. We first establish a connection between this\nsurrogate objective and RPG, which has been largely unexplored and is\nnon-trivial. Then, we bridge this gap by demonstrating that the\nreparameterization gradient of a PPO-like surrogate objective can be computed\nefficiently using backpropagation through time. Based on this key insight, we\npropose Reparameterization Proximal Policy Optimization (RPO), a stable and\nsample-efficient RPG-based method. RPO enables multiple epochs of stable sample\nreuse by optimizing a clipped surrogate objective tailored for RPG, while being\nfurther stabilized by Kullback-Leibler (KL) divergence regularization and\nremaining fully compatible with existing variance reduction methods. We\nevaluate RPO on a suite of challenging locomotion and manipulation tasks, where\nexperiments demonstrate that our method achieves superior sample efficiency and\nstrong performance.", "AI": {"tldr": "This paper introduces Reparameterization Proximal Policy Optimization (RPO), a stable, sample-efficient method combining RPG and PPO techniques.", "motivation": "RPG shows promise for better sample efficiency but suffers from high-gradient variance, leading to training instability. The authors aim to address this issue by integrating stable policy optimization techniques.", "method": "The authors connect RPG with PPO's surrogate objective formulation, enabling efficient computation of the reparameterization gradient. RPO is introduced with a clipped surrogate for RPG, KL regularization, and compatibility with variance reduction techniques.", "result": "RPO demonstrates both superior sample efficiency and strong task performance in benchmarks related to locomotion and manipulation.", "conclusion": "RPO effectively stabilizes RPG by incorporating PPO's techniques, achieving robust learning and improved sample reuse while maintaining compatibility with existing methods."}}
{"id": "2508.06204", "pdf": "https://arxiv.org/pdf/2508.06204", "abs": "https://arxiv.org/abs/2508.06204", "authors": ["Richard Willats", "Josh Pennington", "Aravind Mohan", "Bertie Vidgen"], "title": "Classification is a RAG problem: A case study on hate speech detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Robust content moderation requires classification systems that can quickly\nadapt to evolving policies without costly retraining. We present classification\nusing Retrieval-Augmented Generation (RAG), which shifts traditional\nclassification tasks from determining the correct category in accordance with\npre-trained parameters to evaluating content in relation to contextual\nknowledge retrieved at inference. In hate speech detection, this transforms the\ntask from \"is this hate speech?\" to \"does this violate the hate speech policy?\"\n  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates\nthis approach and offers three key advantages: (1) robust classification\naccuracy comparable to leading commercial systems, (2) inherent explainability\nvia retrieved policy segments, and (3) dynamic policy updates without model\nretraining. Through three experiments, we demonstrate strong baseline\nperformance and show that the system can apply fine-grained policy control by\ncorrectly adjusting protection for specific identity groups without requiring\nretraining or compromising overall performance. These findings establish that\nRAG can transform classification into a more flexible, transparent, and\nadaptable process for content moderation and wider classification problems.", "AI": {"tldr": "This paper introduces a novel approach using Retrieval-Augmented Generation (RAG) for dynamic, explainable, and adaptable content moderation systems.", "motivation": "Traditional classification systems require costly retraining to adapt to policy changes, presenting limitations in dynamic content moderation.", "method": "The authors propose the Contextual Policy Engine (CPE), a RAG-based system, which retrieves contextual knowledge at inference to classify content dynamically according to updated policies.", "result": "CPE achieves comparable accuracy to leading systems, provides inherent explainability, and dynamically adapts to policy updates without retraining.", "conclusion": "RAG-based systems like CPE enhance flexibility, transparency, and adaptation for content moderation tasks, addressing critical limitations of conventional classification systems."}}
{"id": "2304.04475", "pdf": "https://arxiv.org/pdf/2304.04475", "abs": "https://arxiv.org/abs/2304.04475", "authors": ["Gaurav Deshkar", "Jayanta Kshirsagar", "Harshal Hayatnagarkar", "Janani Venugopalan"], "title": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "To mitigate the impact of the pandemic, several measures include lockdowns,\nrapid vaccination programs, school closures, and economic stimulus. These\ninterventions can have positive or unintended negative consequences. Current\nresearch to model and determine an optimal intervention automatically through\nround-tripping is limited by the simulation objectives, scale (a few thousand\nindividuals), model types that are not suited for intervention studies, and the\nnumber of intervention strategies they can explore (discrete vs continuous). We\naddress these challenges using a Deep Deterministic Policy Gradient (DDPG)\nbased policy optimization framework on a large-scale (100,000 individual)\nepidemiological agent-based simulation where we perform multi-objective\noptimization. We determine the optimal policy for lockdown and vaccination in a\nminimalist age-stratified multi-vaccine scenario with a basic simulation for\neconomic activity. With no lockdown and vaccination (mid-age and elderly),\nresults show optimal economy (individuals below the poverty line) with balanced\nhealth objectives (infection, and hospitalization). An in-depth simulation is\nneeded to further validate our results and open-source our framework.", "AI": {"tldr": "The paper explores an optimization framework using Deep Deterministic Policy Gradient (DDPG) to balance health and economic objectives in large-scale pandemic interventions.", "motivation": "Current methods for modeling optimal pandemic interventions are limited in scope, scale, and flexibility.", "method": "The study uses DDPG-based policy optimization in a 100,000-individual agent-based epidemiological simulation to determine ideal lockdowns and vaccination strategies.", "result": "Optimal outcomes include minimal economic impact and balanced health objectives when mid-age and elderly individuals are vaccinated with no lockdowns.", "conclusion": "Further validation and open-sourcing of the framework are necessary for broader applicability and reliability."}}
{"id": "2508.06032", "pdf": "https://arxiv.org/pdf/2508.06032", "abs": "https://arxiv.org/abs/2508.06032", "authors": ["Kiran Chhatre", "Christopher Peters", "Srikrishna Karanam"], "title": "Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts", "categories": ["cs.CV"], "comment": "16 pages, 11 figures", "summary": "Existing methods for human parsing into body parts and clothing often use\nfixed mask categories with broad labels that obscure fine-grained clothing\ntypes. Recent open-vocabulary segmentation approaches leverage pretrained\ntext-to-image (T2I) diffusion model features for strong zero-shot transfer, but\ntypically group entire humans into a single person category, failing to\ndistinguish diverse clothing or detailed body parts. To address this, we\npropose Spectrum, a unified network for part-level pixel parsing (body parts\nand clothing) and instance-level grouping. While diffusion-based\nopen-vocabulary models generalize well across tasks, their internal\nrepresentations are not specialized for detailed human parsing. We observe\nthat, unlike diffusion models with broad representations, image-driven 3D\ntexture generators maintain faithful correspondence to input images, enabling\nstronger representations for parsing diverse clothing and body parts. Spectrum\nintroduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model --\nobtained by fine-tuning a T2I model on 3D human texture maps -- for improved\nalignment with body parts and clothing. From an input image, we extract\nhuman-part internal features via the I2Tx diffusion model and generate\nsemantically valid masks aligned to diverse clothing categories through\nprompt-guided grounding. Once trained, Spectrum produces semantic segmentation\nmaps for every visible body part and clothing category, ignoring standalone\ngarments or irrelevant objects, for any number of humans in the scene. We\nconduct extensive cross-dataset experiments -- separately assessing body parts,\nclothing parts, unseen clothing categories, and full-body masks -- and\ndemonstrate that Spectrum consistently outperforms baseline methods in\nprompt-based segmentation.", "AI": {"tldr": "Spectrum proposes an advanced tool for detailed human parsing by combining body parts and clothing into finely grained segmentation and instance grouping using repurposed 3D texture-based diffusion models.", "motivation": "Existing human parsing methods lack granularity in clothing types and body parts, and recent diffusion-based models fail to distinguish diverse clothing and detailed body parts.", "method": "Spectrum repurposes an Image-to-Texture (I2Tx) diffusion model fine-tuned on 3D human texture maps, extracting internal features for pixel parsing and aligning them with diverse clothing categories through prompt-guided grounding.", "result": "Spectrum achieves improved semantic segmentation outputs for body parts and various clothing categories in multi-human scenarios, outperforming baseline methods on cross-dataset evaluations.", "conclusion": "This study offers a novel and effective solution for fine-grained human parsing by leveraging specialized features from 3D texture-based diffusion models, enhancing both segmentation accuracy and generality."}}
{"id": "2508.06220", "pdf": "https://arxiv.org/pdf/2508.06220", "abs": "https://arxiv.org/abs/2508.06220", "authors": ["Keummin Ka", "Junhyeong Park", "Jahyun Jeon", "Youngjae Yu"], "title": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 9 figures", "summary": "Recent advances in Vision-Language Models (VLMs) have demonstrated impressive\ncapabilities in perception and reasoning. However, the ability to perform\ncausal inference -- a core aspect of human cognition -- remains underexplored,\nparticularly in multimodal settings. In this study, we introduce InfoCausalQA,\na novel benchmark designed to evaluate causal reasoning grounded in\ninfographics that combine structured visual data with textual context. The\nbenchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning\nbased on inferred numerical trends, while Task 2 targets semantic causal\nreasoning involving five types of causal relations: cause, effect,\nintervention, counterfactual, and temporal. We manually collected 494\ninfographic-text pairs from four public sources and used GPT-4o to generate\n1,482 high-quality multiple-choice QA pairs. These questions were then\ncarefully revised by humans to ensure they cannot be answered based on\nsurface-level cues alone but instead require genuine visual grounding. Our\nexperimental results reveal that current VLMs exhibit limited capability in\ncomputational reasoning and even more pronounced limitations in semantic causal\nreasoning. Their significantly lower performance compared to humans indicates a\nsubstantial gap in leveraging infographic-based information for causal\ninference. Through InfoCausalQA, we highlight the need for advancing the causal\nreasoning abilities of multimodal AI systems.", "AI": {"tldr": "The paper introduces InfoCausalQA, a benchmark for evaluating causal reasoning in Vision-Language Models using infographics and textual context. Current models perform poorly on this task compared to humans.", "motivation": "To address the lack of comprehensive evaluation benchmarks for causal reasoning in Vision-Language Models, particularly in multimodal scenarios involving infographics.", "method": "The authors manually collected 494 infographic-text pairs from public sources and used GPT-4 to generate 1,482 multiple-choice QA pairs, which were human-revised to ensure genuine causal reasoning. Two tasks focusing on quantitative and semantic causal reasoning were designed.", "result": "Experimental results show that existing Vision-Language Models perform poorly in computational and semantic causal reasoning tasks, falling significantly behind human performance.", "conclusion": "There is a substantial gap in the ability of current multimodal AI systems to perform causal inference based on infographic data. Developing models with stronger causal reasoning capabilities is essential."}}
{"id": "2507.12286", "pdf": "https://arxiv.org/pdf/2507.12286", "abs": "https://arxiv.org/abs/2507.12286", "authors": ["Anouk Oudshoorn", "Magdalena Ortiz", "Mantas Simkus"], "title": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques", "categories": ["cs.LO", "cs.AI"], "comment": "36 pages, 6 figures, submitted to the journal of Artificial\n  Intelligence (AIJ)", "summary": "SHACL and OWL are two prominent W3C standards for managing RDF data. These\nlanguages share many features, but they have one fundamental difference: OWL,\ndesigned for inferring facts from incomplete data, makes the open-world\nassumption, whereas SHACL is a constraint language that treats the data as\ncomplete and must be validated under the closed-world assumption. The\ncombination of both formalisms is very appealing and has been called for, but\ntheir semantic gap is a major challenge, semantically and computationally. In\nthis paper, we advocate a semantics for SHACL validation in the presence of\nontologies based on core universal models. We provide a technique for\nconstructing these models for ontologies in the rich data-tractable description\nlogic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to\ndevelop a rewriting technique that reduces SHACL validation in the presence of\nontologies to standard validation. Finally, we study the complexity of SHACL\nvalidation in the presence of ontologies, and show that even very simple\nontologies make the problem EXPTIME-complete, and PTIME-complete in data\ncomplexity.", "AI": {"tldr": "This paper discusses SHACL and OWL, highlighting their semantic gap and proposing solutions for validation in the presence of ontologies using universal models.", "motivation": "To address the challenge of combining SHACL and OWL, which operate under fundamentally different assumptions, to leverage their strengths in managing RDF data.", "method": "The paper introduces a semantic for SHACL validation using core universal models, constructs these models for Horn-ALCHIQ, utilizes finite representations for rewriting techniques, and analyzes computational complexity.", "result": "The proposed approach enables SHACL validation in the presence of OWL ontologies and reveals that the problem has a high computational complexity (EXPTIME-complete or PTIME-complete depending on data).", "conclusion": "While integrating SHACL and OWL validation is computationally demanding, the proposed framework provides a viable solution for combining these formalisms effectively."}}
{"id": "2508.06033", "pdf": "https://arxiv.org/pdf/2508.06033", "abs": "https://arxiv.org/abs/2508.06033", "authors": ["Yiming Gong", "Zhen Zhu", "Minjia Zhang"], "title": "InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "We propose a fast text-guided image editing method called InstantEdit based\non the RectifiedFlow framework, which is structured as a few-step editing\nprocess that preserves critical content while following closely to textual\ninstructions. Our approach leverages the straight sampling trajectories of\nRectifiedFlow by introducing a specialized inversion strategy called PerRFI. To\nmaintain consistent while editable results for RectifiedFlow model, we further\npropose a novel regeneration method, Inversion Latent Injection, which\neffectively reuses latent information obtained during inversion to facilitate\nmore coherent and detailed regeneration. Additionally, we propose a\nDisentangled Prompt Guidance technique to balance editability with detail\npreservation, and integrate a Canny-conditioned ControlNet to incorporate\nstructural cues and suppress artifacts. Evaluation on the PIE image editing\ndataset demonstrates that InstantEdit is not only fast but also achieves better\nqualitative and quantitative results compared to state-of-the-art few-step\nediting methods.", "AI": {"tldr": "The paper introduces InstantEdit, a fast few-step text-guided image editing method using RectifiedFlow, delivering consistent and superior results by introducing novel techniques like PerRFI, Inversion Latent Injection, and Disentangled Prompt Guidance.", "motivation": "The motivation behind this research is to enable faster and more accurate text-guided image editing while maintaining critical image content and generating highly coherent outputs.", "method": "The authors developed the InstantEdit framework, which includes innovations such as PerRFI for improved inversion, Inversion Latent Injection for detailed regeneration, and Disentangled Prompt Guidance. They also integrated a Canny-conditioned ControlNet to introduce structural consistency and minimize artifacts.", "result": "InstantEdit performed better both qualitatively and quantitatively on the PIE image editing dataset, surpassing other state-of-the-art methods for few-step image editing tasks.", "conclusion": "InstantEdit demonstrates that fast text-guided image editing with improved structural coherence and quality can be achieved through advancements in RectifiedFlow and the proposed novel techniques."}}
{"id": "2508.06244", "pdf": "https://arxiv.org/pdf/2508.06244", "abs": "https://arxiv.org/abs/2508.06244", "authors": ["Xurun Wang", "Guangrui Liu", "Xinjie Li", "Haoyu He", "Lin Yao", "Weizhe Zhang"], "title": "Membership Inference Attack with Partial Features", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Machine learning models have been shown to be susceptible to membership\ninference attack, which can be used to determine whether a given sample appears\nin the training data. Existing membership inference methods commonly assume\nthat the adversary has full access to the features of the target sample. This\nassumption, however, does not hold in many real-world scenarios where only\npartial features information is available, thereby limiting the applicability\nof these methods. In this work, we study an inference scenario where the\nadversary observes only partial features of each sample and aims to infer\nwhether this observed subset was present in the training set of the target\nmodel. We define this problem as Partial Feature Membership Inference (PFMI).\nTo address this problem, we propose MRAD (Memory-guided Reconstruction and\nAnomaly Detection), a two-stage attack framework. In the first stage, MRAD\noptimizes the unknown feature values to minimize the loss of the sample. In the\nsecond stage, it measures the deviation between the reconstructed sample and\nthe training distribution using anomaly detection. Empirical results\ndemonstrate that MRAD is effective across a range of datasets, and maintains\ncompatibility with various off-the-shelf anomaly detection techniques. For\nexample, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of\nthe missing features.", "AI": {"tldr": "This paper introduces Partial Feature Membership Inference (PFMI), a new type of membership inference attack where adversaries have only partial access to feature data. The proposed MRAD framework effectively addresses this problem, demonstrating strong performance across datasets.", "motivation": "The motivation is to study membership inference attacks in scenarios where adversaries have access to only partial feature information, which is common in real-world situations and limits the applicability of existing methods.", "method": "The paper proposes MRAD, a two-stage attack framework. In the first stage, it reconstructs missing feature values to minimize loss. In the second stage, it detects anomalies by measuring deviations from the training set's distribution.", "result": "MRAD performs effectively across multiple datasets and can integrate well with existing anomaly detection techniques. For instance, it achieves an AUC of about 0.6 on STL-10 even with 40% of features missing.", "conclusion": "MRAD provides a robust approach for membership inference attacks under partial feature observability. It highlights the vulnerability of machine learning models to PFMI attacks, even with limited feature data."}}
{"id": "2508.06277", "pdf": "https://arxiv.org/pdf/2508.06277", "abs": "https://arxiv.org/abs/2508.06277", "authors": ["Theresa Pekarek Rosin", "Burak Can Kaplan", "Stefan Wermter"], "title": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech", "categories": ["cs.CL", "cs.LG", "cs.SD"], "comment": "11 pages, 3 figures, accepted at KONVENS 2025", "summary": "Intent recognition (IR) for speech commands is essential for artificial\nintelligence (AI) assistant systems; however, most existing approaches are\nlimited to short commands and are predominantly developed for English. This\npaper addresses these limitations by focusing on IR from speech by elderly\nGerman speakers. We propose a novel approach that combines an adapted Whisper\nASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based\nlanguage models trained on synthetic text datasets generated by three\nwell-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To\nevaluate the robustness of our approach, we generate synthetic speech with a\ntext-to-speech model and conduct extensive cross-dataset testing. Our results\nshow that synthetic LLM-generated data significantly boosts classification\nperformance and robustness to different speaking styles and unseen vocabulary.\nNotably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the\nmuch larger ChatGPT (175B) in dataset quality for German intent recognition.\nOur approach demonstrates that generative AI can effectively bridge data gaps\nin low-resource domains. We provide detailed documentation of our data\ngeneration and training process to ensure transparency and reproducibility.", "AI": {"tldr": "This paper develops a method to improve intent recognition for elderly German speech using adapted ASR and synthetic LLM-generated data.", "motivation": "Most existing intent recognition models focus on short commands and English language, leaving a gap for elderly German speakers.", "method": "Combines a fine-tuned Whisper ASR model on elderly German speech with Transformer-based models trained on synthetic datasets from LLMs like LeoLM, Llama3, and ChatGPT, with evaluations through cross-dataset tests.", "result": "Synthetic LLM-generated data enhances intent recognition performance and robustness, with the domain-specific LeoLM outperforming ChatGPT for German intent recognition.", "conclusion": "Generative AI is effective in addressing data scarcity in low-resource domains, and the study provides detailed procedural transparency."}}
{"id": "2508.04748", "pdf": "https://arxiv.org/pdf/2508.04748", "abs": "https://arxiv.org/abs/2508.04748", "authors": ["Xuan Lin", "Long Chen", "Yile Wang"], "title": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "9 pages", "summary": "Large Language Models (LLMs) have shown promise in assisting molecular\nproperty prediction tasks but often rely on human-crafted prompts and\nchain-of-thought templates. While recent advanced large reasoning models like\nDeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,\ntheir reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,\nan attribute-guided reinforcement learning framework for molecular property\nprediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)\na format reward encouraging attribute-based structured output, (2) a count\nreward to avoid enumerating irrelevant attributes, and (3) a rationality reward\nusing advanced LLMs and RDKit to verify the relatedness of the generated\nattributes. This approach implicitly elicits the model's inherent knowledge of\nrelevant molecular attributes during reasoning, enables making predictions for\nthe molecular property more effectively. Experiments on both in-distribution\nand out-of-distribution datasets show that, training both 7B-size\nR1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our\nproposed AttriLens-Mol method significantly boosts the performance, getting\ncomparable or better results than supervised fine-tuning models\n(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,\nDeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the\ntarget property, when used as features for an interpretable decision tree\nmodel, yield superior performance compared to attributes generated by prompting\nLLMs. This shows that AttriLens-Mol effectively elicits more relevant and\npredictive molecular attributes, leading to enhanced interpretability and\nperformance for property prediction. We release the code in\nhttps://github.com/szu-tera/AttriLens-Mol.", "AI": {"tldr": "The paper proposes AttriLens-Mol, a reinforcement learning framework to improve molecular property prediction using LLMs by guiding their reasoning process with attribute-based rewards. This method outperforms prior models and enhances interpretability.", "motivation": "Existing LLMs for molecular property prediction rely heavily on human-crafted prompts/templates and produce verbose or irrelevant reasoning. A more structured and effective approach is needed.", "method": "Introduced AttriLens-Mol, which uses three types of rewards (format, count, rationality) to guide LLMs towards generating structured, relevant, and rational output. Experiments were conducted using specifically trained 7B LLMs on molecular datasets.", "result": "AttriLens-Mol achieved comparable or better results than supervised fine-tuning models and advanced LLMs. Generated attributes, when used with decision tree models, showed enhanced performance and interpretability.", "conclusion": "AttriLens-Mol effectively elicits relevant molecular attributes, improving both predictive performance and interpretability of molecular property predictions. The open-source release provides resources for further exploration."}}
{"id": "2508.06036", "pdf": "https://arxiv.org/pdf/2508.06036", "abs": "https://arxiv.org/abs/2508.06036", "authors": ["Jun Xie", "Yingjian Zhu", "Feng Chen", "Zhenghao Zhang", "Xiaohui Fan", "Hongzhu Yi", "Xinming Wang", "Chen Yu", "Yue Bi", "Zhaoran Zhao", "Xiongjun Guan", "Zhepeng Wang"], "title": "More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we present our solution for the semi-supervised learning track\n(MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the\nprinciple that \"more is better,\" to construct a robust Mixture of Experts (MoE)\nemotion recognition system. Our approach integrates a diverse range of input\nmodalities as independent experts, including novel signals such as knowledge\nfrom large Vision-Language Models (VLMs) and temporal Action Unit (AU)\ninformation. To effectively utilize unlabeled data, we introduce a\nconsensus-based pseudo-labeling strategy, generating high-quality labels from\nthe agreement between a baseline model and Gemini, which are then used in a\ntwo-stage training paradigm. Finally, we employ a multi-expert voting ensemble\ncombined with a rule-based re-ranking process to correct prediction bias and\nbetter align the outputs with human preferences. Evaluated on the MER2025-SEMI\nchallenge dataset, our method achieves an F1-score of 0.8772 on the test set,\nranking 2nd in the track. Our code is available at\nhttps://github.com/zhuyjan/MER2025-MRAC25.", "AI": {"tldr": "The paper proposes a semi-supervised learning framework for Mixture of Experts (MoE) emotion recognition, achieving an F1-score of 0.8772 and ranking 2nd in the MER2025-SEMI challenge.", "motivation": "The motivation is to improve emotion recognition through a robust and diverse mixture of expert systems while effectively using unlabeled data in a semi-supervised learning context.", "method": "The paper's method includes integrating multiple input modalities as experts (e.g., Vision-Language Model knowledge and Action Unit information), pseudo-labeling through a consensus-based strategy, two-stage training, and multi-expert ensemble voting with rule-based re-ranking.", "result": "The proposed method achieved an F1-score of 0.8772 on the MER2025-SEMI challenge dataset, ranking 2nd in the competition.", "conclusion": "The proposed comprehensive framework demonstrates the effectiveness of leveraging diverse modalities, pseudo-labeling, and ensemble strategies in semi-supervised emotion recognition tasks."}}
{"id": "2508.06113", "pdf": "https://arxiv.org/pdf/2508.06113", "abs": "https://arxiv.org/abs/2508.06113", "authors": ["Jian Wang", "Chaokang Jiang", "Haitao Xu"], "title": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": "7 pages, 4 figures", "summary": "Diffusion-based models are redefining the state-of-the-art in end-to-end\nautonomous driving, yet their performance is increasingly hampered by a\nreliance on transformer-based fusion. These architectures face fundamental\nlimitations: quadratic computational complexity restricts the use of\nhigh-resolution features, and a lack of spatial priors prevents them from\neffectively modeling the inherent structure of Bird's Eye View (BEV)\nrepresentations. This paper introduces GMF-Drive (Gated Mamba Fusion for\nDriving), an end-to-end framework that overcomes these challenges through two\nprincipled innovations. First, we supersede the information-limited\nhistogram-based LiDAR representation with a geometrically-augmented pillar\nformat encoding shape descriptors and statistical features, preserving critical\n3D geometric details. Second, we propose a novel hierarchical gated mamba\nfusion (GM-Fusion) architecture that substitutes an expensive transformer with\na highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM\nleverages directional sequencing and adaptive fusion mechanisms to capture\nlong-range dependencies with linear complexity, while explicitly respecting the\nunique spatial properties of the driving scene. Extensive experiments on the\nchallenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new\nstate-of-the-art performance, significantly outperforming DiffusionDrive.\nComprehensive ablation studies validate the efficacy of each component,\ndemonstrating that task-specific SSMs can surpass a general-purpose transformer\nin both performance and efficiency for autonomous driving.", "AI": {"tldr": "GMF-Drive introduces a more efficient and spatially-aware framework for autonomous driving by replacing transformers with state-space models, achieving state-of-the-art results.", "motivation": "To overcome the limitations of transformer-based fusion in autonomous driving, such as computational inefficiency and inadequate representation of spatial dependencies in BEV formats.", "method": "Introduces GMF-Drive framework combining geometrically-augmented pillar format for LiDAR data and a hierarchical gated mamba fusion architecture using a spatially-aware state-space model (BEV-SSM) with linear complexity.", "result": "GMF-Drive outperforms DiffusionDrive and achieves state-of-the-art results on the NAVSIM benchmark, validated by extensive experiments and ablation studies.", "conclusion": "Task-specific state-space models (SSMs) can offer superior performance and efficiency over general-purpose transformers in autonomous driving applications."}}
{"id": "2508.06309", "pdf": "https://arxiv.org/pdf/2508.06309", "abs": "https://arxiv.org/abs/2508.06309", "authors": ["Ruichong Zhang"], "title": "Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC", "categories": ["cs.CL", "math.PR"], "comment": null, "summary": "In recent years, concerns about intellectual property (IP) in large language\nmodels (LLMs) have grown significantly. Plagiarizing other LLMs (through direct\nweight copying, upcycling, pruning, or continual pretraining) and claiming\nauthorship without properly attributing to the original license, is a serious\nmisconduct that can lead to significant financial and reputational harm to the\noriginal developers. However, existing methods for detecting LLM plagiarism\nfall short in key areas. They fail to accurately reconstruct weight\ncorrespondences, lack the ability to compute statistical significance measures\nsuch as $p$-values, and may mistakenly flag models trained on similar data as\nbeing related. To address these limitations, we propose Matrix-Driven Instant\nReview (MDIR), a novel method that leverages matrix analysis and Large\nDeviation Theory. MDIR achieves accurate reconstruction of weight\nrelationships, provides rigorous $p$-value estimation, and focuses exclusively\non weight similarity without requiring full model inference. Experimental\nresults demonstrate that MDIR reliably detects plagiarism even after extensive\ntransformations, such as random permutations and continual pretraining with\ntrillions of tokens. Moreover, all detections can be performed on a single PC\nwithin an hour, making MDIR both efficient and accessible.", "AI": {"tldr": "This paper introduces MDIR, a method for detecting plagiarism in large language model weights, capable of identifying copying even after transformations, with efficient processing.", "motivation": "The motivation stems from the rise in intellectual property concerns over large language models, particularly the increasing instances of plagiarism such as weight copying, unauthorized adaptations, or retraining.", "method": "The proposed method, MDIR, utilizes matrix analysis and Large Deviation Theory to detect weight relationships, computes $p$-values for statistical significance, and focuses strictly on weight similarity, avoiding full model inference.", "result": "Experimental tests reveal that MDIR effectively detects plagiarism, even under extensive model transformations, and achieves this efficiently on a single PC within an hour.", "conclusion": "MDIR offers a rigorous, reliable, and accessible tool for addressing intellectual property concerns in large language models by accurately identifying weight-based plagiarism."}}
{"id": "2508.05637", "pdf": "https://arxiv.org/pdf/2508.05637", "abs": "https://arxiv.org/abs/2508.05637", "authors": ["Siddharth Gangwar", "David A. Selby", "Sebastian J. Vollmer"], "title": "Automated Visualization Makeovers with LLMs", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Making a good graphic that accurately and efficiently conveys the desired\nmessage to the audience is both an art and a science, typically not taught in\nthe data science curriculum. Visualisation makeovers are exercises where the\ncommunity exchange feedback to improve charts and data visualizations. Can\nmulti-modal large language models (LLMs) emulate this task? Given a plot in the\nform of an image file, or the code used to generate it, an LLM, primed with a\nlist of visualization best practices, is employed to semi-automatically\ngenerate constructive criticism to produce a better plot. Our system is centred\naround prompt engineering of a pre-trained model, relying on a combination of\nuserspecified guidelines and any latent knowledge of data visualization\npractices that might lie within an LLMs training corpus. Unlike other works,\nthe focus is not on generating valid visualization scripts from raw data or\nprompts, but on educating the user how to improve their existing data\nvisualizations according to an interpretation of best practices. A quantitative\nevaluation is performed to measure the sensitivity of the LLM agent to various\nplotting issues across different chart types. We make the tool available as a\nsimple self-hosted applet with an accessible Web interface.", "AI": {"tldr": "The paper explores whether large language models (LLMs) can assist in improving data visualizations by providing constructive feedback based on best practices.", "motivation": "To investigate the potential of LLMs in aiding users to enhance their data visualizations by offering semi-automated, constructive critiques based on established best practices.", "method": "The approach relies on prompt engineering of a pre-trained LLM and incorporates user-provided guidelines along with the model's inherent knowledge of visualization practices to deliver feedback.", "result": "Quantitative evaluation showed the model's sensitivity to different plotting issues across varied chart types, demonstrating its utility in the visualization improvement process.", "conclusion": "LLMs, with appropriate prompt engineering, can effectively educate users on improving existing visualizations, offering a valuable tool for both learning and refinement. The tool is released as a simple, self-hosted app with a user-friendly web interface."}}
{"id": "2508.06038", "pdf": "https://arxiv.org/pdf/2508.06038", "abs": "https://arxiv.org/abs/2508.06038", "authors": ["Huanyu Wang", "Jushi Kai", "Haoli Bai", "Lu Hou", "Bo Jiang", "Ziwei He", "Zhouhan Lin"], "title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 4 figures", "summary": "Vision-Language Models (VLMs) typically replace the predefined image\nplaceholder token (<image>) in textual instructions with visual features from\nan image encoder, forming the input to a backbone Large Language Model (LLM).\nHowever, the large number of vision tokens significantly increases the context\nlength, leading to high computational overhead and inference latency. While\nprevious efforts mitigate this by selecting only important visual features or\nleveraging learnable queries to reduce token count, they often compromise\nperformance or introduce substantial extra costs. In response, we propose\nFourier-VLM, a simple yet efficient method that compresses visual\nrepresentations in the frequency domain. Our approach is motivated by the\nobservation that vision features output from the vision encoder exhibit\nconcentrated energy in low-frequency components. Leveraging this, we apply a\nlow-pass filter to the vision features using a two-dimentional Discrete Cosine\nTransform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier\nTransform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$,\nminimizing the extra computational cost while introducing no additional\nparameters. Extensive experiments across various image-based benchmarks\ndemonstrate that Fourier-VLM achieves competitive performance with strong\ngeneralizability across both LLaVA and Qwen-VL architectures. Crucially, it\nreduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%\ncompared to LLaVA-v1.5, highlighting the superior efficiency and practicality.", "AI": {"tldr": "Fourier-VLM reduces computational overhead in Vision-Language Models by compressing visual features in the frequency domain, achieving up to 83.8% inference FLOPs reduction and 31.2% faster generation compared to similar models.", "motivation": "The paper seeks to address the high computational overhead and latency caused by the large number of vision tokens in Vision-Language Models.", "method": "It proposes compressing visual representations using a low-pass filter and a two-dimensional Discrete Cosine Transform (DCT), executed efficiently via the Fast Fourier Transform (FFT) operator.", "result": "Fourier-VLM demonstrates competitive performance and strong generalizability on image-based benchmarks while significantly reducing inference FLOPs and increasing generation speed.", "conclusion": "Fourier-VLM offers a practical and efficient way to handle visual features in Vision-Language Models, balancing performance and computational efficiency without adding extra parameters."}}
{"id": "2508.06249", "pdf": "https://arxiv.org/pdf/2508.06249", "abs": "https://arxiv.org/abs/2508.06249", "authors": ["David Kacz\u00e9r", "Magnus J\u00f8rgenv\u00e5g", "Clemens Vetter", "Lucie Flek", "Florian Mai"], "title": "In-Training Defenses against Emergent Misalignment in Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Fine-tuning lets practitioners repurpose aligned large language models (LLMs)\nfor new domains, yet recent work reveals emergent misalignment (EMA): Even a\nsmall, domain-specific fine-tune can induce harmful behaviors far outside the\ntarget domain. Even in the case where model weights are hidden behind a\nfine-tuning API, this gives attackers inadvertent access to a broadly\nmisaligned model in a way that can be hard to detect from the fine-tuning data\nalone. We present the first systematic study of in-training safeguards against\nEMA that are practical for providers who expose fine-tuning via an API. We\ninvestigate four training regularization interventions: (i) KL-divergence\nregularization toward a safe reference model, (ii) $\\ell_2$ distance in feature\nspace, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving\nof a small amount of safe training examples from a general instruct-tuning\ndataset. We first evaluate the methods' emergent misalignment effect across\nfour malicious, EMA-inducing tasks. Second, we assess the methods' impacts on\nbenign tasks. We conclude with a discussion of open questions in emergent\nmisalignment research.", "AI": {"tldr": "The paper investigates methods to address emergent misalignment (EMA) in fine-tuned large language models, proposing and testing four training interventions.", "motivation": "Practitioners fine-tune aligned LLMs for domain-specific tasks, but this can unexpectedly create harmful behaviors outside the target domain, posing risks for models exposed via fine-tuning APIs.", "method": "The paper tests four regularization interventions during fine-tuning to mitigate EMA: KL-divergence regularization, feature-space distance enforcement, SafeLoRA projection, and interleaving safe examples during fine-tuning.", "result": "The interventions were systematically evaluated for their effects on emergent misalignment across malicious tasks and their performance on benign tasks.", "conclusion": "Several training strategies show promise in combating EMA, though further research is needed to explore unanswered questions and refine safeguards against misalignment."}}
{"id": "2508.06177", "pdf": "https://arxiv.org/pdf/2508.06177", "abs": "https://arxiv.org/abs/2508.06177", "authors": ["Dominik Br\u00e4mer", "Diana Kleingarn", "Oliver Urbann"], "title": "Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted at 28th RoboCup International Symposium, Salvador, Brasil", "summary": "Accurate localization represents a fundamental challenge in\n  robotic navigation. Traditional methodologies, such as Lidar or QR-code based\nsystems, suffer from inherent scalability and adaptability con straints,\nparticularly in complex environments. In this work, we propose\n  an innovative localization framework that harnesses flooring characteris tics\nby employing graph-based representations and Graph Convolutional\n  Networks (GCNs). Our method uses graphs to represent floor features,\n  which helps localize the robot more accurately (0.64cm error) and more\n  efficiently than comparing individual image features. Additionally, this\n  approach successfully addresses the kidnapped robot problem in every\n  frame without requiring complex filtering processes. These advancements\n  open up new possibilities for robotic navigation in diverse environments.", "AI": {"tldr": "This paper presents a localization framework for robotic navigation using floor graph characteristics and Graph Convolutional Networks, achieving high accuracy (0.64cm error) and addressing the kidnapped robot problem effectively.", "motivation": "Current localization methods like Lidar or QR-code systems face scalability and adaptability issues in complex environments.", "method": "The framework represents floor features using graphs and utilizes Graph Convolutional Networks for accurate and efficient robot localization.", "result": "The method achieved a low localization error of 0.64cm and solved the kidnapped robot problem without complicated filtering processes.", "conclusion": "The proposed approach significantly improves robotic navigation accuracy and efficiency, presenting new opportunities for operation in diverse environments."}}
{"id": "2508.06345", "pdf": "https://arxiv.org/pdf/2508.06345", "abs": "https://arxiv.org/abs/2508.06345", "authors": ["Yanbin Wei", "Jiangyue Yan", "Chun Kang", "Yang Chen", "Hua Liu", "James T. Kwok", "Yu Zhang"], "title": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "categories": ["cs.CL", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities\nin diverse domain question-answering (QA) tasks, including graph QA that\ninvolves complex graph topologies. However, most current approaches use only a\nsingle type of graph representation, namely Topology Representation Form (TRF),\nsuch as prompt-unified text descriptions or style-fixed visual styles. Those\n\"one-size-fits-all\" approaches fail to consider the specific preferences of\ndifferent models or tasks, often leading to incorrect or overly long responses.\nTo address this, we first analyze the characteristics and weaknesses of\nexisting TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to\nzero-shot graph QA. We then introduce a new metric, Graph Response Efficiency\n(GRE), which measures the balance between the performance and the brevity in\ngraph QA. Built on these, we develop the DynamicTRF framework, which aims to\nimprove both the accuracy and conciseness of graph QA. To be specific,\nDynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based\non their GRE scores, to probe the question-specific TRF preferences. Then it\ntrains a TRF router on the TRFP dataset, to adaptively assign the best TRF from\n$F_{ZS}$ for each question during the inference. Extensive experiments across 7\nin-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show\nthat DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms\nof accuracy", "AI": {"tldr": "This paper introduces DynamicTRF, a framework for improving zero-shot graph QA in Large Multimodal Models by adaptively selecting tailored graph representations based on their efficiency.", "motivation": "To tackle the limitations of existing approaches in zero-shot graph QA that rely on single, generic graph representation styles, often leading to inaccuracies or verbose responses.", "method": "DynamicTRF analyzes existing graph representation forms, designs multiple tailored representations ($F_{ZS}$), introduces a Graph Response Efficiency (GRE) metric, creates a preference dataset (TRFP), and trains a routing model to dynamically select the most suited representations for each question.", "result": "Extensive experiments on 7 in-domain and 2 out-of-domain tasks demonstrate significant improvements in graph QA accuracy and conciseness using DynamicTRF.", "conclusion": "The DynamicTRF framework effectively enhances zero-shot graph QA performance by adapting graph representations to question-specific preferences, ensuring better accuracy and response efficiency."}}
{"id": "2508.05640", "pdf": "https://arxiv.org/pdf/2508.05640", "abs": "https://arxiv.org/abs/2508.05640", "authors": ["Liang Guo", "Wei Li", "Lucy Liao", "Huihui Cheng", "Rui Zhang", "Yu Shi", "Yueming Wang", "Yanzun Huang", "Keke Zhai", "Pengchao Wang", "Timothy Shi", "Xuan Cao", "Shengzhi Wang", "Renqin Cai", "Zhaojie Gong", "Omkar Vichare", "Rui Jian", "Leon Gao", "Shiyan Deng", "Xingyu Liu", "Xiong Zhang", "Fu Li", "Wenlei Xie", "Bin Wen", "Rui Li", "Xing Liu", "Jiaqi Zhai"], "title": "Request-Only Optimization for Recommendation Systems", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Deep Learning Recommendation Models (DLRMs) represent one of the largest\nmachine learning applications on the planet. Industry-scale DLRMs are trained\nwith petabytes of recommendation data to serve billions of users every day. To\nutilize the rich user signals in the long user history, DLRMs have been scaled\nup to unprecedented complexity, up to trillions of floating-point operations\n(TFLOPs) per example. This scale, coupled with the huge amount of training\ndata, necessitates new storage and training algorithms to efficiently improve\nthe quality of these complex recommendation systems. In this paper, we present\na Request-Only Optimizations (ROO) training and modeling paradigm. ROO\nsimultaneously improves the storage and training efficiency as well as the\nmodel quality of recommendation systems. We holistically approach this\nchallenge through co-designing data (i.e., request-only data), infrastructure\n(i.e., request-only based data processing pipeline), and model architecture\n(i.e., request-only neural architectures). Our ROO training and modeling\nparadigm treats a user request as a unit of the training data. Compared with\nthe established practice of treating a user impression as a unit, our new\ndesign achieves native feature deduplication in data logging, consequently\nsaving data storage. Second, by de-duplicating computations and communications\nacross multiple impressions in a request, this new paradigm enables highly\nscaled-up neural network architectures to better capture user interest signals,\nsuch as Generative Recommenders (GRs) and other request-only friendly\narchitectures.", "AI": {"tldr": "This paper introduces a Request-Only Optimizations (ROO) approach to improve storage, training efficiency, and recommendation model quality.", "motivation": "DLRMs are highly complex systems requiring efficient algorithms and storage to handle massive petabytes of training data and trillions of computations per example.", "method": "The paper proposes the ROO paradigm that uses a user's request as a unit for data and computation, enabling deduplication and co-design across data, infrastructure, and model architectures.", "result": "Using ROO achieves savings in storage, reduces computational redundancy, and facilitates more advanced architectures like Generative Recommenders.", "conclusion": "ROO represents a scalable and efficient advancement for industry-scale DLRMs, improving both quality and resource utilization."}}
{"id": "2508.06044", "pdf": "https://arxiv.org/pdf/2508.06044", "abs": "https://arxiv.org/abs/2508.06044", "authors": ["Huimin Wu", "Xiaojian Ma", "Haozhe Zhao", "Yanpeng Zhao", "Qing Li"], "title": "NEP: Autoregressive Image Editing via Next Editing Token Prediction", "categories": ["cs.CV"], "comment": "The project page is: https://nep-bigai.github.io/", "summary": "Text-guided image editing involves modifying a source image based on a\nlanguage instruction and, typically, requires changes to only small local\nregions. However, existing approaches generate the entire target image rather\nthan selectively regenerate only the intended editing areas. This results in\n(1) unnecessary computational costs and (2) a bias toward reconstructing\nnon-editing regions, which compromises the quality of the intended edits. To\nresolve these limitations, we propose to formulate image editing as Next\nEditing-token Prediction (NEP) based on autoregressive image generation, where\nonly regions that need to be edited are regenerated, thus avoiding unintended\nmodification to the non-editing areas. To enable any-region editing, we propose\nto pre-train an any-order autoregressive text-to-image (T2I) model. Once\ntrained, it is capable of zero-shot image editing and can be easily adapted to\nNEP for image editing, which achieves a new state-of-the-art on widely used\nimage editing benchmarks. Moreover, our model naturally supports test-time\nscaling (TTS) through iteratively refining its generation in a zero-shot\nmanner. The project page is: https://nep-bigai.github.io/", "AI": {"tldr": "The paper introduces a method for text-guided image editing that minimizes computational costs and unintended changes to non-editing regions.", "motivation": "Existing image editing methods are computationally expensive and prone to unintentionally altering non-editing regions.", "method": "The method is based on autoregressive Next Editing-token Prediction (NEP), pre-training a text-to-image (T2I) model for selective region edits.", "result": "The proposed method achieves state-of-the-art results in image editing benchmarks with support for test-time scaling for refinement.", "conclusion": "Formulating image editing as NEP enables precise, efficient edits with zero-shot capability, improving flexibility and edit quality."}}
{"id": "2508.06251", "pdf": "https://arxiv.org/pdf/2508.06251", "abs": "https://arxiv.org/abs/2508.06251", "authors": ["Alejandro Moreno R.", "Desale Fentaw", "Samuel Palmer", "Ra\u00fal Salles de Padua", "Ninad Dixit", "Samuel Mugel", "Roman Or\u00fas", "Manuel Radons", "Josef Menter", "Ali Abedi"], "title": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)", "categories": ["cs.LG", "cs.AI", "cs.CR", "quant-ph"], "comment": "10 pages", "summary": "Synthetic data generation is a key technique in modern artificial\nintelligence, addressing data scarcity, privacy constraints, and the need for\ndiverse datasets in training robust models. In this work, we propose a method\nfor generating privacy-preserving high-quality synthetic tabular data using\nTensor Networks, specifically Matrix Product States (MPS). We benchmark the\nMPS-based generative model against state-of-the-art models such as CTGAN, VAE,\nand PrivBayes, focusing on both fidelity and privacy-preserving capabilities.\nTo ensure differential privacy (DP), we integrate noise injection and gradient\nclipping during training, enabling privacy guarantees via R\\'enyi Differential\nPrivacy accounting. Across multiple metrics analyzing data fidelity and\ndownstream machine learning task performance, our results show that MPS\noutperforms classical models, particularly under strict privacy constraints.\nThis work highlights MPS as a promising tool for privacy-aware synthetic data\ngeneration. By combining the expressive power of tensor network representations\nwith formal privacy mechanisms, the proposed approach offers an interpretable\nand scalable alternative for secure data sharing. Its structured design\nfacilitates integration into sensitive domains where both data quality and\nconfidentiality are critical.", "AI": {"tldr": "A method is proposed to generate high-quality, privacy-preserving synthetic tabular data using Matrix Product States (MPS), outperforming traditional approaches under privacy constraints.", "motivation": "The increasing need to overcome data scarcity, address privacy concerns, and create diverse datasets in AI demands effective synthetic data generation methods.", "method": "The study employs Tensor Networks, especially Matrix Product States (MPS), integrating noise injection and gradient clipping for R\u00e9nyi Differential Privacy, and benchmarks this against models like CTGAN, VAE, and PrivBayes.", "result": "The proposed MPS model outperformed classical models in data fidelity and downstream task performance, particularly under stringent privacy settings.", "conclusion": "MPS offers a scalable and interpretable solution for generating privacy-preserving synthetic data, making it suitable for sensitive domains requiring high data quality and confidentiality."}}
{"id": "2508.06227", "pdf": "https://arxiv.org/pdf/2508.06227", "abs": "https://arxiv.org/abs/2508.06227", "authors": ["Md Sazidur Rahman", "David Cabecinhas", "Ricard Marxer"], "title": "Depth Jitter: Seeing through the Depth", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Depth information is essential in computer vision, particularly in underwater\nimaging, robotics, and autonomous navigation. However, conventional\naugmentation techniques overlook depth aware transformations, limiting model\nrobustness in real world depth variations. In this paper, we introduce\nDepth-Jitter, a novel depth-based augmentation technique that simulates natural\ndepth variations to improve generalization. Our approach applies adaptive depth\noffsetting, guided by depth variance thresholds, to generate synthetic depth\nperturbations while preserving structural integrity. We evaluate Depth-Jitter\non two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on\nmodel stability under diverse depth conditions. Extensive experiments compare\nDepth-Jitter against traditional augmentation strategies such as ColorJitter,\nanalyzing performance across varying learning rates, encoders, and loss\nfunctions. While Depth-Jitter does not always outperform conventional methods\nin absolute performance, it consistently enhances model stability and\ngeneralization in depth-sensitive environments. These findings highlight the\npotential of depth-aware augmentation for real-world applications and provide a\nfoundation for further research into depth-based learning strategies. The\nproposed technique is publicly available to support advancements in depth-aware\naugmentation. The code is publicly available on\n\\href{https://github.com/mim-team/Depth-Jitter}{github}.", "AI": {"tldr": "The paper presents Depth-Jitter, a depth-aware augmentation method improving model robustness and generalization in depth-sensitive tasks.", "motivation": "Existing augmentation techniques lack depth-aware transformations, limiting model robustness in scenarios involving real-world depth variations.", "method": "Depth-Jitter uses adaptive depth offsetting guided by depth variance thresholds to create synthetic depth perturbations while maintaining structural coherence.", "result": "Depth-Jitter improves model stability and generalization on benchmark datasets like FathomNet and UTDAC2020, though it doesn't always surpass conventional methods in absolute performance.", "conclusion": "Depth-Jitter shows promise for depth-sensitive environments, providing a novel approach to depth-aware augmentation that lays the groundwork for future research."}}
{"id": "2508.06360", "pdf": "https://arxiv.org/pdf/2508.06360", "abs": "https://arxiv.org/abs/2508.06360", "authors": ["Aisha Saeid", "Anu Sabu", "Girish A. Koushik", "Ferrante Neri", "Diptesh Kanojia"], "title": "Cyberbullying Detection via Aggression-Enhanced Prompting", "categories": ["cs.CL"], "comment": "Accepted to RANLP 2025", "summary": "Detecting cyberbullying on social media remains a critical challenge due to\nits subtle and varied expressions. This study investigates whether integrating\naggression detection as an auxiliary task within a unified training framework\ncan enhance the generalisation and performance of large language models (LLMs)\nin cyberbullying detection. Experiments are conducted on five aggression\ndatasets and one cyberbullying dataset using instruction-tuned LLMs. We\nevaluated multiple strategies: zero-shot, few-shot, independent LoRA\nfine-tuning, and multi-task learning (MTL). Given the inconsistent results of\nMTL, we propose an enriched prompt pipeline approach in which aggression\npredictions are embedded into cyberbullying detection prompts to provide\ncontextual augmentation. Preliminary results show that the enriched prompt\npipeline consistently outperforms standard LoRA fine-tuning, indicating that\naggression-informed context significantly boosts cyberbullying detection. This\nstudy highlights the potential of auxiliary tasks, such as aggression\ndetection, to improve the generalisation of LLMs for safety-critical\napplications on social networks.", "AI": {"tldr": "The study explores enhancing large language models (LLMs) for cyberbullying detection by integrating aggression detection as an auxiliary task using various strategies, ultimately finding enriched prompt pipeline methods as effective solutions.", "motivation": "Cyberbullying detection is a challenging problem due to its subtle and varied expressions. There is a necessity to improve the generalisation capabilities and performance of LLMs when applied to safety-related tasks such as cyberbullying detection.", "method": "The study used five aggression datasets and one cyberbullying dataset with instruction-tuned LLMs to test strategies like zero-shot, few-shot, LoRA fine-tuning, multi-task learning, and enriched prompt pipeline approaches.", "result": "The enriched prompt pipeline approach, which embeds aggression predictions into cyberbullying detection prompts, consistently performed better than standard LoRA fine-tuning in experiments, enhancing model context and detection accuracy.", "conclusion": "Incorporating aggression detection as an auxiliary task through enriched prompts significantly improves cyberbullying detection, highlighting the value of contextual augmentation in safety-critical applications."}}
{"id": "2508.05647", "pdf": "https://arxiv.org/pdf/2508.05647", "abs": "https://arxiv.org/abs/2508.05647", "authors": ["Vibhor Agrawal", "Fay Wang", "Rishi Puri"], "title": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "We present a novel graph neural network (GNN) architecture for\nretrieval-augmented generation (RAG) that leverages query-aware attention\nmechanisms and learned scoring heads to improve retrieval accuracy on complex,\nmulti-hop questions. Unlike traditional dense retrieval methods that treat\ndocuments as independent entities, our approach constructs per-episode\nknowledge graphs that capture both sequential and semantic relationships\nbetween text chunks. We introduce an Enhanced Graph Attention Network with\nquery-guided pooling that dynamically focuses on relevant parts of the graph\nbased on user queries. Experimental results demonstrate that our approach\nsignificantly outperforms standard dense retrievers on complex question\nanswering tasks, particularly for questions requiring multi-document reasoning.\nOur implementation leverages PyTorch Geometric for efficient processing of\ngraph-structured data, enabling scalable deployment in production retrieval\nsystems", "AI": {"tldr": "The paper proposes a novel graph neural network (GNN) architecture for retrieval-augmented generation (RAG) to enhance multi-hop question answering.", "motivation": "To address limitations of traditional dense retrieval methods that fail to capture relationships between text chunks, essential for complex multi-hop questions.", "method": "The authors designed a retrieval approach using per-episode knowledge graphs constructed with Enhanced Graph Attention Networks (EGAN) that include query-guided pooling.", "result": "Experimental evaluation showed that their method improved retrieval accuracy, especially in multi-document reasoning tasks, surpassing standard dense retrievers.", "conclusion": "The proposed method advances retrieval-augmented generation by integrating query-aware graph attention, making it effective and scalable for real-world complex question answering."}}
{"id": "2508.06051", "pdf": "https://arxiv.org/pdf/2508.06051", "abs": "https://arxiv.org/abs/2508.06051", "authors": ["Linhan Cao", "Wei Sun", "Weixia Zhang", "Xiangyang Zhu", "Jun Jia", "Kaiwei Zhang", "Dandan Zhu", "Guangtao Zhai", "Xiongkuo Min"], "title": "VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Video quality assessment (VQA) aims to objectively quantify perceptual\nquality degradation in alignment with human visual perception. Despite recent\nadvances, existing VQA models still suffer from two critical limitations:\n\\textit{poor generalization to out-of-distribution (OOD) videos} and\n\\textit{limited explainability}, which restrict their applicability in\nreal-world scenarios. To address these challenges, we propose\n\\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large\nmultimodal models (LMMs) with reinforcement learning to jointly model video\nquality understanding and scoring, emulating human perceptual decision-making.\nSpecifically, we adopt group relative policy optimization (GRPO), a rule-guided\nreinforcement learning algorithm that enables reasoning over video quality\nunder score-level supervision, and introduce three VQA-specific rewards: (1) a\n\\textbf{bell-shaped regression reward} that increases rapidly as the prediction\nerror decreases and becomes progressively less sensitive near the ground truth;\n(2) a \\textbf{pairwise ranking reward} that guides the model to correctly\ndetermine the relative quality between video pairs; and (3) a \\textbf{temporal\nconsistency reward} that encourages the model to prefer temporally coherent\nvideos over their perturbed counterparts. Extensive experiments demonstrate\nthat VQAThinker achieves state-of-the-art performance on both in-domain and OOD\nVQA benchmarks, showing strong generalization for video quality scoring.\nFurthermore, evaluations on video quality understanding tasks validate its\nsuperiority in distortion attribution and quality description compared to\nexisting explainable VQA models and LMMs. These findings demonstrate that\nreinforcement learning offers an effective pathway toward building\ngeneralizable and explainable VQA models solely with score-level supervision.", "AI": {"tldr": "The paper introduces VQAThinker, a reasoning-based framework for video quality assessment, that uses reinforcement learning to improve generalization and explainability, achieving state-of-the-art results.", "motivation": "To overcome poor generalization to out-of-distribution videos and limited explainability in existing video quality assessment (VQA) models, both of which hinder their real-world applicability.", "method": "A framework called VQAThinker is proposed, leveraging large multimodal models (LMMs) and group relative policy optimization (GRPO), a reinforcement learning technique. It utilizes three VQA-specific rewards: bell-shaped regression reward, pairwise ranking reward, and temporal consistency reward.", "result": "The proposed framework achieves state-of-the-art performance on both in-domain and out-of-distribution VQA benchmarks. It also outperforms existing models in video quality understanding tasks, demonstrating improved distortion attribution and quality description.", "conclusion": "Reinforcement learning emerges as a viable approach to building generalizable and explainable VQA models, using only score-level supervision."}}
{"id": "2508.06257", "pdf": "https://arxiv.org/pdf/2508.06257", "abs": "https://arxiv.org/abs/2508.06257", "authors": ["Jielong Lu", "Zhihao Wu", "Jiajun Yu", "Jiajun Bu", "Haishuai Wang"], "title": "Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors", "categories": ["cs.LG"], "comment": null, "summary": "Integrating multi-omics datasets through data-driven analysis offers a\ncomprehensive understanding of the complex biological processes underlying\nvarious diseases, particularly cancer. Graph Neural Networks (GNNs) have\nrecently demonstrated remarkable ability to exploit relational structures in\nbiological data, enabling advances in multi-omics integration for cancer\nsubtype classification. Existing approaches often neglect the intricate\ncoupling between heterogeneous omics, limiting their capacity to resolve subtle\ncancer subtype heterogeneity critical for precision oncology. To address these\nlimitations, we propose a framework named Graph Transformer for Multi-omics\nCancer Subtype Classification (GTMancer). This framework builds upon the GNN\noptimization problem and extends its application to complex multi-omics data.\nSpecifically, our method leverages contrastive learning to embed multi-omics\ndata into a unified semantic space. We unroll the multiplex graph optimization\nproblem in that unified space and introduce dual sets of attention coefficients\nto capture structural graph priors both within and among multi-omics data. This\napproach enables global omics information to guide the refining of the\nrepresentations of individual omics. Empirical experiments on seven real-world\ncancer datasets demonstrate that GTMancer outperforms existing state-of-the-art\nalgorithms.", "AI": {"tldr": "This paper introduces GTMancer, leveraging Graph Neural Networks and contrastive learning for improved multi-omics cancer subtype classification.", "motivation": "Current methods for multi-omics cancer subtype classification fall short in addressing the intricate coupling between heterogeneous omics data.", "method": "The approach introduces GTMancer, which uses contrastive learning to unify multi-omics data in a semantic space, and employs dual attention mechanisms for refining graph representations.", "result": "Empirical tests on seven cancer datasets show GTMancer surpasses existing algorithms in performance.", "conclusion": "GTMancer enhances precision oncology by improving the integration and analysis of heterogeneous multi-omics data for cancer subtype classification."}}
{"id": "2508.06374", "pdf": "https://arxiv.org/pdf/2508.06374", "abs": "https://arxiv.org/abs/2508.06374", "authors": ["Anubhav Jangra", "Bahareh Sarrafzadeh", "Adrian de Wynter", "Silviu Cucerzan", "Sujay Kumar Jauhar"], "title": "Evaluating Style-Personalized Text Generation: Challenges and Directions", "categories": ["cs.CL"], "comment": null, "summary": "While prior research has built tools and benchmarks towards style\npersonalized text generation, there has been limited exploration of evaluation\nin low-resource author style personalized text generation space. Through this\nwork, we question the effectiveness of the widely adopted evaluation metrics\nlike BLEU and ROUGE, and explore other evaluation paradigms such as style\nembeddings and LLM-as-judge to holistically evaluate the style personalized\ntext generation task. We evaluate these metrics and their ensembles using our\nstyle discrimination benchmark, that spans eight writing tasks, and evaluates\nacross three settings, domain discrimination, authorship attribution, and LLM\npersonalized vs non-personalized discrimination. We provide conclusive evidence\nto adopt ensemble of diverse evaluation metrics to effectively evaluate style\npersonalized text generation.", "AI": {"tldr": "This paper critiques the effectiveness of traditional metrics like BLEU and ROUGE for evaluating style-personalized text generation and studies alternative evaluation paradigms.", "motivation": "Most current evaluation methods in style-personalized text generation overly rely on traditional metrics, which may not be suited for nuanced evaluation, especially in low-resource settings.", "method": "The research examines various evaluation tools such as style embeddings and LLM-as-judge and assesses them using a style discrimination benchmark across multiple writing tasks and settings.", "result": "The study establishes through experiments that an ensemble of diverse evaluation metrics provides a more effective framework for assessing style-personalized text generation.", "conclusion": "For comprehensive evaluation, the adoption of diverse, ensemble-based metrics is recommended over traditional metrics when evaluating personalized text generation."}}
{"id": "2508.05648", "pdf": "https://arxiv.org/pdf/2508.05648", "abs": "https://arxiv.org/abs/2508.05648", "authors": ["Chandler Campbell", "Bernie Boscoe", "Tuan Do"], "title": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted to US Research Software Engineer Association (US-RSE) 2025", "summary": "Research groups face persistent challenges in capturing, storing, and\nretrieving knowledge that is distributed across team members. Although\nstructured data intended for analysis and publication is often well managed,\nmuch of a group's collective knowledge remains informal, fragmented, or\nundocumented--often passed down orally through meetings, mentoring, and\nday-to-day collaboration. This includes private resources such as emails,\nmeeting notes, training materials, and ad hoc documentation. Together, these\nreflect the group's tacit knowledge--the informal, experience-based expertise\nthat underlies much of their work. Accessing this knowledge can be difficult,\nrequiring significant time and insider understanding. Retrieval-augmented\ngeneration (RAG) systems offer promising solutions by enabling users to query\nand generate responses grounded in relevant source material. However, most\ncurrent RAG-LLM systems are oriented toward public documents and overlook the\nprivacy concerns of internal research materials. We introduce AquiLLM\n(pronounced ah-quill-em), a lightweight, modular RAG system designed to meet\nthe needs of research groups. AquiLLM supports varied document types and\nconfigurable privacy settings, enabling more effective access to both formal\nand informal knowledge within scholarly groups.", "AI": {"tldr": "AquiLLM is a lightweight, modular Retrieval-Augmented Generation (RAG) system designed to help research groups manage and access their distributed, often undocumented knowledge, while addressing privacy concerns.", "motivation": "Research groups face difficulties in managing and retrieving their fragmented, informal, and undocumented tacit knowledge, which is often spread across private resources like emails and meeting notes.", "method": "AquiLLM incorporates a modular RAG system that supports multiple document types and allows for configurable privacy settings to cater specifically to research groups' unique knowledge-sharing needs.", "result": "AquiLLM provides a solution for effective query and response generation by grounding them in source materials while preserving privacy and addressing the incomplete documentation of tacit knowledge.", "conclusion": "AquiLLM helps research groups access formal and informal knowledge more effectively, supporting better knowledge management while respecting privacy concerns of internal resources."}}
{"id": "2508.06055", "pdf": "https://arxiv.org/pdf/2508.06055", "abs": "https://arxiv.org/abs/2508.06055", "authors": ["Wonjung Park", "Suhyun Ahn", "Jinah Park"], "title": "LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Lateral ventricle (LV) shape analysis holds promise as a biomarker for\nneurological diseases; however, challenges remain due to substantial shape\nvariability across individuals and segmentation difficulties arising from\nlimited MRI resolution. We introduce LV-Net, a novel framework for producing\nindividualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint\nLV-hippocampus template mesh. By incorporating anatomical relationships\nembedded within the joint template, LV-Net reduces boundary segmentation\nartifacts and improves reconstruction robustness. In addition, by classifying\nthe vertices of the template mesh based on their anatomical adjacency, our\nmethod enhances point correspondence across subjects, leading to more accurate\nLV shape statistics. We demonstrate that LV-Net achieves superior\nreconstruction accuracy, even in the presence of segmentation imperfections,\nand delivers more reliable shape descriptors across diverse datasets. Finally,\nwe apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that\nshow significantly associations with the disease relative to cognitively normal\ncontrols. The codes for LV shape modeling are available at\nhttps://github.com/PWonjung/LV_Shape_Modeling.", "AI": {"tldr": "This paper presents LV-Net, a robust 3D shape modeling framework for lateral ventricles in the brain, addressing challenges in variability and imaging limitations, and applies it to Alzheimer's disease analysis.", "motivation": "To address challenges in lateral ventricle shape analysis, such as individual variability and MRI segmentation difficulties, and to enhance its potential as a biomarker for neurological diseases.", "method": "Introduces LV-Net, which deforms a joint LV-hippocampus template mesh and incorporates anatomical relationships to provide accurate and robust lateral ventricle reconstructions from brain MRI.", "result": "Demonstrates superior reconstruction accuracy, enhanced point correspondence, and reliable LV shape statistics, identifying Alzheimer's disease-related LV subregions.", "conclusion": "LV-Net provides a promising tool for individualized LV shape analysis, offering improved accuracy, robustness, and its application highlights significant associations between LV shape and Alzheimer's disease."}}
{"id": "2508.06269", "pdf": "https://arxiv.org/pdf/2508.06269", "abs": "https://arxiv.org/abs/2508.06269", "authors": ["Zhuoran Li", "Xun Wang", "Hai Zhong", "Longbo Huang"], "title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative models, especially diffusion and flow-based models, have been\npromising in offline multi-agent reinforcement learning. However, integrating\npowerful generative models into this framework poses unique challenges. In\nparticular, diffusion and flow-based policies suffer from low sampling\nefficiency due to their iterative generation processes, making them impractical\nin time-sensitive or resource-constrained settings. To tackle these\ndifficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel\noffline MARL algorithm to achieve efficient one-step action sampling. To\naddress the misalignment between generative objectives and reward maximization,\nwe introduce a reward-aware optimization scheme that integrates a\ncarefully-designed mean-flow matching loss with Q-function supervision.\nAdditionally, we design a generalized timestep distribution and a\nderivative-free estimation strategy to reduce memory overhead and improve\ntraining stability. Empirical evaluations on Multi-Agent Particle and MuJoCo\nbenchmarks demonstrate that OM2P achieves superior performance, with up to a\n3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.\nOur approach represents the first to successfully integrate mean-flow model\ninto offline MARL, paving the way for practical and scalable generative\npolicies in cooperative multi-agent settings.", "AI": {"tldr": "This paper introduces OM2P, a novel offline MARL algorithm using mean-flow policies to achieve efficient one-step action sampling, addressing time and resource constraints.", "motivation": "Generative models like diffusion and flow-based models show promise in offline MARL but face challenges such as low sampling efficiency due to iterative generation processes.", "method": "The authors propose OM2P, integrating mean-flow matching loss with Q-function supervision for reward alignment, introducing a generalized timestep distribution, and a derivative-free estimation strategy.", "result": "OM2P achieves up to a 3.8x reduction in GPU memory use and up to a 10.8x speed-up in training time, achieving superior performance in Multi-Agent Particle and MuJoCo benchmarks.", "conclusion": "OM2P demonstrates the practical integration of mean-flow models into offline MARL, providing scalable and efficient solutions for cooperative multi-agent policies."}}
{"id": "2508.06388", "pdf": "https://arxiv.org/pdf/2508.06388", "abs": "https://arxiv.org/abs/2508.06388", "authors": ["Lanlan Qiu", "Xiao Pu", "Yeqi Feng", "Tianxing He"], "title": "LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing", "categories": ["cs.CL"], "comment": "21 pages, 17 figures, 3 tables", "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nrole-playing conversations and providing emotional support as separate research\ndirections. However, there remains a significant research gap in combining\nthese capabilities to enable emotionally supportive interactions with virtual\ncharacters. To address this research gap, we focus on anime characters as a\ncase study because of their well-defined personalities and large fan bases.\nThis choice enables us to effectively evaluate how well LLMs can provide\nemotional support while maintaining specific character traits. We introduce\nChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We\nfirst thoughtfully select 20 top-tier characters from popular anime communities\nand design 60 emotion-centric real-world scenario questions. Then, we execute a\nnationwide selection process to identify 40 Chinese anime enthusiasts with\nprofound knowledge of specific characters and extensive experience in\nrole-playing. Next, we systematically collect two rounds of dialogue data from\n10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP\nperformance of LLMs, we design a user experience-oriented evaluation system\nfeaturing 9 fine-grained metrics across three dimensions: basic dialogue,\nrole-playing and emotional support, along with an overall metric for response\ndiversity. In total, the dataset comprises 2,400 human-written and 24,000\nLLM-generated answers, supported by over 132,000 human annotations.\nExperimental results show that top-performing LLMs surpass human fans in\nrole-playing and emotional support, while humans still lead in response\ndiversity. We hope this work can provide valuable resources and insights for\nfuture research on optimizing LLMs in ESRP. Our datasets are available at\nhttps://github.com/LanlanQiu/ChatAnime.", "AI": {"tldr": "This paper focuses on combining role-playing and emotional support in Large Language Models (LLMs), introducing ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset leveraging anime characters.", "motivation": "The need to bridge the gap in enabling emotionally supportive conversations with role-playing virtual characters.", "method": "The authors selected 20 anime characters and 60 emotion-driven scenarios, collaborated with 40 Chinese anime experts, and developed a dataset with responses from humans and 10 LLMs, evaluated using a user-oriented system with 9 metrics.", "result": "LLMs outperformed human experts in role-playing and emotional support but fell short on response diversity.", "conclusion": "ChatAnime offers valuable insights and resources to enhance LLMs for ESRP, pushing forward the integration of role-playing and emotional support capabilities."}}
{"id": "2508.05650", "pdf": "https://arxiv.org/pdf/2508.05650", "abs": "https://arxiv.org/abs/2508.05650", "authors": ["Jiaxuan Liang", "Shide Zhou", "Kailong Wang"], "title": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\nLLMs, evaluating its true performance benefits in a reproducible and\ninterpretable way remains a major hurdle. Existing methods often fall short:\nthey lack domain coverage, employ coarse metrics that miss sub document\nprecision, and fail to capture computational trade offs. Most critically, they\nprovide no standardized framework for comparing RAG effectiveness across\ndifferent models and domains.\n  We introduce OmniBench RAG, a novel automated platform for multi domain\nevaluation of RAG systems. The platform quantifies performance gains across\naccuracy and efficiency dimensions, spanning nine knowledge fields including\nculture, geography, and health. We introduce two standardized metrics:\nImprovements (accuracy gains) and Transformation (efficiency differences\nbetween pre RAG and post RAG models), enabling reproducible comparisons across\nmodels and tasks. The platform features dynamic test generation, modular\nevaluation pipelines, and automated knowledge base construction. Our evaluation\nreveals striking variability in RAG effectiveness, from significant gains in\nculture to declines in mathematics, highlighting the critical importance of\nsystematic, domain aware assessment. A demonstration video is available at:\nhttps://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\nhttps://github.com/Garnett-Liang/Omnibench-RAG.", "AI": {"tldr": "This paper introduces OmniBench RAG, a platform for standardized evaluation of Retrieval Augmented Generation (RAG) systems across multiple domains, emphasizing both accuracy and efficiency metrics.", "motivation": "To address the lack of comprehensive, reproducible, and interpretable evaluation frameworks for RAG systems, which are critical in assessing their true performance across different models and knowledge domains.", "method": "Introduced OmniBench RAG, which includes dynamic test generation, modular evaluation pipelines, and automated knowledge base construction, with two metrics: Improvements for accuracy and Transformation for efficiency.", "result": "The evaluation showed substantial variability in RAG effectiveness across domains, with significant improvements in some fields like culture but declines in others, such as mathematics.", "conclusion": "Standardized, domain-aware evaluations are essential to understand and compare the effectiveness of RAG systems accurately, highlighting domain-specific strengths and weaknesses."}}
{"id": "2508.06057", "pdf": "https://arxiv.org/pdf/2508.06057", "abs": "https://arxiv.org/abs/2508.06057", "authors": ["Mojtaba Valipour", "Kelly Zheng", "James Lowman", "Spencer Szabados", "Mike Gartner", "Bobby Braswell"], "title": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted in IGARSS 2025!", "summary": "Artificial General Intelligence (AGI) is closer than ever to becoming a\nreality, sparking widespread enthusiasm in the research community to collect\nand work with various modalities, including text, image, video, and audio.\nDespite recent efforts, satellite spectral imagery, as an additional modality,\nhas yet to receive the attention it deserves. This area presents unique\nchallenges, but also holds great promise in advancing the capabilities of AGI\nin understanding the natural world. In this paper, we argue why Earth\nObservation data is useful for an intelligent model, and then we review\nexisting benchmarks and highlight their limitations in evaluating the\ngeneralization ability of foundation models in this domain. This paper\nemphasizes the need for a more comprehensive benchmark to evaluate earth\nobservation models. To facilitate this, we propose a comprehensive set of tasks\nthat a benchmark should encompass to effectively assess a model's ability to\nunderstand and interact with Earth observation data.", "AI": {"tldr": "The paper discusses the potential of using satellite spectral imagery to advance Artificial General Intelligence (AGI) and proposes comprehensive benchmarks to evaluate models in Earth Observation.", "motivation": "The motivation is to address the lack of focus on satellite spectral imagery as a modality in AGI research, despite its potential for improving models' understanding of Earth's environment.", "method": "The study reviews existing benchmarks, identifies their shortcomings, and proposes a set of tasks to build a comprehensive benchmark for evaluating Earth observation models.", "result": "The proposed framework aims to better assess a model\u2019s ability to interact with and understand Earth observation data.", "conclusion": "Satellite spectral imagery represents a valuable yet underutilized resource in AGI research, and developing a robust evaluation benchmark is essential for advancing this domain."}}
{"id": "2508.06280", "pdf": "https://arxiv.org/pdf/2508.06280", "abs": "https://arxiv.org/abs/2508.06280", "authors": ["Gokul Adethya T", "S. Jaya Nirmala"], "title": "A Study on Regularization-Based Continual Learning Methods for Indic ASR", "categories": ["cs.LG"], "comment": null, "summary": "Indias linguistic diversity poses significant challenges for developing\ninclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual\nmodels, which require simultaneous access to all language data, are impractical\ndue to the sequential arrival of data and privacy constraints. Continual\nLearning (CL) offers a solution by enabling models to learn new languages\nsequentially without catastrophically forgetting previously learned knowledge.\nThis paper investigates CL for ASR on Indian languages using a subset of the\nIndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,\ninitially pretrained on Hindi, which is then incrementally trained on eight\nadditional Indian languages, for a total sequence of nine languages. We\nevaluate three prominent regularization- and distillation-based CL strategies:\nElastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning\nwithout Forgetting (LwF), selected for their suitability in no-replay,\nprivacy-conscious scenarios. Performance is analyzed using Word Error Rate\n(WER) for both RNN-T and CTC paths on clean and noisy data, as well as\nknowledge retention via Backward Transfer. We also explore the impact of\nvarying the number of training epochs (1, 2, 5, and 10) per task. Results,\ncompared against naive fine-tuning, demonstrate CLs effectiveness in mitigating\nforgetting, making it a promising approach for scalable ASR in diverse Indian\nlanguages under realistic constraints. The code is available at:\nhttps://github.com/FrozenWolf-Cyber/Indic-CL-ASR", "AI": {"tldr": "The paper studies Continual Learning (CL) strategies for Automatic Speech Recognition (ASR) systems in Indian languages using a Conformer-based hybrid model. It compares Elastic Weight Consolidation, Memory Aware Synapses, and Learning without Forgetting methods for sequential learning without catastrophic forgetting.", "motivation": "India's linguistic diversity necessitates ASR systems that can adapt to multiple languages under constraints like sequential data arrival and privacy. The motivation is to enable scalable multilingual ASR solutions without catastrophic forgetting.", "method": "The authors use a Conformer-based hybrid RNN-T/CTC model initially pretrained on Hindi, which is incrementally trained on eight additional Indian languages. Regularization- and distillation-based CL methods like EWC, MAS, and LwF are evaluated for their Word Error Rate (WER) performance and knowledge retention in no-replay settings.", "result": "The results show that CL strategies outperform naive fine-tuning by mitigating forgetting. Experiments also reveal how varying training epochs affects performance and backward knowledge transfer under clean and noisy data conditions.", "conclusion": "Continual Learning methods like EWC, MAS, and LwF provide scalable solutions for multilingual ASR in languages like Hindi and others. This approach is realistic and effective for implementing ASR systems that respect privacy and adapt sequentially."}}
{"id": "2508.06418", "pdf": "https://arxiv.org/pdf/2508.06418", "abs": "https://arxiv.org/abs/2508.06418", "authors": ["Haoran Shi", "Hongwei Yao", "Shuo Shao", "Shaopeng Jiao", "Ziqi Peng", "Zhan Qin", "Cong Wang"], "title": "Quantifying Conversation Drift in MCP via Latent Polytope", "categories": ["cs.CL"], "comment": null, "summary": "The Model Context Protocol (MCP) enhances large language models (LLMs) by\nintegrating external tools, enabling dynamic aggregation of real-time data to\nimprove task execution. However, its non-isolated execution context introduces\ncritical security and privacy risks. In particular, adversarially crafted\ncontent can induce tool poisoning or indirect prompt injection, leading to\nconversation hijacking, misinformation propagation, or data exfiltration.\nExisting defenses, such as rule-based filters or LLM-driven detection, remain\ninadequate due to their reliance on static signatures, computational\ninefficiency, and inability to quantify conversational hijacking. To address\nthese limitations, we propose SecMCP, a secure framework that detects and\nquantifies conversation drift, deviations in latent space trajectories induced\nby adversarial external knowledge. By modeling LLM activation vectors within a\nlatent polytope space, SecMCP identifies anomalous shifts in conversational\ndynamics, enabling proactive detection of hijacking, misleading, and data\nexfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,\nVicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),\ndemonstrating robust detection with AUROC scores exceeding 0.915 while\nmaintaining system usability. Our contributions include a systematic\ncategorization of MCP security threats, a novel latent polytope-based\nmethodology for quantifying conversation drift, and empirical validation of\nSecMCP's efficacy.", "AI": {"tldr": "The paper proposes SecMCP, a secure framework to address critical security risks in the Model Context Protocol (MCP), enhancing the detection and mitigation of threats like conversation hijacking and data exfiltration through latent polytope analysis.", "motivation": "The paper identifies security vulnerabilities in the MCP framework, which integrates external tools into LLMs, making them susceptible to adversarial attacks like tool poisoning and indirect prompt injection.", "method": "SecMCP uses a latent polytope-based approach to model LLM activation vectors in latent space, detecting conversational drift caused by adversarial content.", "result": "SecMCP achieved robust detection performance with AUROC scores over 0.915 across various datasets and LLMs, demonstrating effective identification of security threats without compromising usability.", "conclusion": "SecMCP enhances the security of MCP frameworks by enabling proactive detection of adversarial disruptions through latent space trajectory analysis, systematically addressing MCP-related threats."}}
{"id": "2508.05652", "pdf": "https://arxiv.org/pdf/2508.05652", "abs": "https://arxiv.org/abs/2508.05652", "authors": ["Julia Ann Mathew", "Suining He"], "title": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation", "categories": ["cs.IR", "cs.AI"], "comment": "4 pages, UrbComp 2025", "summary": "The increasing popularity of outdoor recreational activities (such as hiking\nand biking) has boosted the demand for a conversational AI system to provide\ninformative and personalized suggestion on outdoor trails. Challenges arise in\nresponse to (1) how to provide accurate outdoor trail information via\nconversational AI; and (2) how to enable usable and efficient recommendation\nservices. To address above, this paper discusses the preliminary and practical\nlessons learned from developing Judy, an outdoor trail recommendation chatbot\nbased on the large language model (LLM) with retrieval augmented generation\n(RAG). To gain concrete system insights, we have performed case studies with\nthe outdoor trails in Connecticut (CT), US. We have conducted web-based data\ncollection, outdoor trail data management, and LLM model performance studies on\nthe RAG-based recommendation. Our experimental results have demonstrated the\naccuracy, effectiveness, and usability of Judy in recommending outdoor trails\nbased on the LLM with RAG.", "AI": {"tldr": "This paper introduces Judy, a chatbot utilizing large language models (LLMs) and retrieval augmented generation (RAG) for outdoor trail recommendations.", "motivation": "The rising popularity of outdoor activities necessitates an AI system that can provide precise suggestions and handle challenges in information accuracy and user usability.", "method": "The system design includes web-based data collection, outdoor trail data management, and performance evaluation using case studies focused on Connecticut trails.", "result": "Experimental findings highlight Judy\u2019s effectiveness in delivering accurate, user-friendly trail recommendations.", "conclusion": "The study proves that a RAG-based LLM chatbot can efficiently recommend personalized outdoor trails, addressing both functional and user needs."}}
{"id": "2508.06058", "pdf": "https://arxiv.org/pdf/2508.06058", "abs": "https://arxiv.org/abs/2508.06058", "authors": ["Shiyang Zhou", "Haijin Zeng", "Yunfan Lu", "Yongyong Chen", "Jie Liu", "Jingyong Su"], "title": "Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera\ncapture brightness changes as asynchronous \"events\" instead of frames, offering\nadvanced application on mobile photography. However, challenges arise from\ncombining a Quad Bayer Color Filter Array (CFA) sensor with event pixels\nlacking color information, resulting in aliasing and artifacts on the\ndemosaicing process before downstream application. Current methods struggle to\naddress these issues, especially on resource-limited mobile devices. In\nresponse, we introduce \\textbf{TSANet}, a lightweight \\textbf{T}wo-stage\nnetwork via \\textbf{S}tate space augmented cross-\\textbf{A}ttention, which can\nhandle event pixels inpainting and demosaicing separately, leveraging the\nbenefits of dividing complex tasks into manageable subtasks. Furthermore, we\nintroduce a lightweight Cross-Swin State Block that uniquely utilizes\npositional prior for demosaicing and enhances global dependencies through the\nstate space model with linear complexity. In summary, TSANet demonstrates\nexcellent demosaicing performance on both simulated and real data of HybridEVS\nwhile maintaining a lightweight model, averaging better results than the\nprevious state-of-the-art method DemosaicFormer across seven diverse datasets\nin both PSNR and SSIM, while respectively reducing parameter and computation\ncosts by $1.86\\times$ and $3.29\\times$. Our approach presents new possibilities\nfor efficient image demosaicing on mobile devices. Code is available in the\nsupplementary materials.", "AI": {"tldr": "The paper introduces TSANet, a lightweight two-stage network leveraging state-space cross-attention for efficient and high-quality image demosaicing of HybridEVS event cameras, outperforming existing methods while being computationally lighter.", "motivation": "The motivation is to address challenges in demosaicing images captured by HybridEVS event cameras, specifically resolving aliasing and artifacts caused by combining CFA sensors and event pixels, while keeping resource constraints of mobile devices in mind.", "method": "The paper proposes a two-stage network, TSANet, which separates the inpainting and demosaicing tasks for better manageability. It introduces a lightweight Cross-Swin State Block that enhances positional prior and global dependencies using a state space model, ensuring linear computational complexity.", "result": "TSANet achieves superior demosaicing performance in terms of PSNR and SSIM metrics across seven datasets when compared to DemosaicFormer, while reducing parameters by 1.86x and computation costs by 3.29x. It performs well on both simulated and real data from HybridEVS.", "conclusion": "The study demonstrates that TSANet is an efficient and effective solution for image demosaicing challenges in hybrid event-based sensors, enabling advanced mobile applications while being resource-efficient."}}
{"id": "2508.06292", "pdf": "https://arxiv.org/pdf/2508.06292", "abs": "https://arxiv.org/abs/2508.06292", "authors": ["Sanja Karilanova", "Subhrakanti Dey", "Ay\u00e7a \u00d6z\u00e7elikkale"], "title": "Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback", "categories": ["cs.LG"], "comment": "15 pages, 7 Tables, 6 Figures", "summary": "Neuromorphic computing is an emerging technology enabling low-latency and\nenergy-efficient signal processing. A key algorithmic tool in neuromorphic\ncomputing is spiking neural networks (SNNs). SNNs are biologically inspired\nneural networks which utilize stateful neurons, and provide low-bit data\nprocessing by encoding and decoding information using spikes. Similar to SNNs,\ndeep state-space models (SSMs) utilize stateful building blocks. However, deep\nSSMs, which recently achieved competitive performance in various temporal\nmodeling tasks, are typically designed with high-precision activation functions\nand no reset mechanisms. To bridge the gains offered by SNNs and the recent\ndeep SSM models, we propose a novel multiple-output spiking neuron model that\ncombines a linear, general SSM state transition with a non-linear feedback\nmechanism through reset. Compared to the existing neuron models for SNNs, our\nproposed model clearly conceptualizes the differences between the spiking\nfunction, the reset condition and the reset action. The experimental results on\nvarious tasks, i.e., a keyword spotting task, an event-based vision task and a\nsequential pattern recognition task, show that our proposed model achieves\nperformance comparable to existing benchmarks in the SNN literature. Our\nresults illustrate how the proposed reset mechanism can overcome instability\nand enable learning even when the linear part of neuron dynamics is unstable,\nallowing us to go beyond the strictly enforced stability of linear dynamics in\nrecent deep SSM models.", "AI": {"tldr": "The paper introduces a novel spiking neuron model combining linear state transitions with a reset mechanism, achieving competitive performance in signal processing tasks.", "motivation": "The study aims to bridge the advantages of spiking neural networks (SNNs) and deep state-space models (SSMs) to enhance low-latency, energy-efficient computing.", "method": "A multiple-output spiking neuron model is proposed, integrating linear SSM state transitions with nonlinear reset mechanisms for enhanced stability and learning.", "result": "The model achieves comparable performance benchmarks across tasks such as keyword spotting, event-based vision, and sequential pattern recognition.", "conclusion": "The reset mechanism overcomes neuron instability and surpasses the strictly enforced stability limitations in linear dynamics of deep SSM models."}}
{"id": "2508.06433", "pdf": "https://arxiv.org/pdf/2508.06433", "abs": "https://arxiv.org/abs/2508.06433", "authors": ["Runnan Fang", "Yuan Liang", "Xiaobin Wang", "Jialong Wu", "Shuofei Qiao", "Pengjun Xie", "Fei Huang", "Huajun Chen", "Ningyu Zhang"], "title": "Memp: Exploring Agent Procedural Memory", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": "Work in progress", "summary": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they\nsuffer from brittle procedural memory that is manually engineered or entangled\nin static parameters. In this work, we investigate strategies to endow agents\nwith a learnable, updatable, and lifelong procedural memory. We propose Memp\nthat distills past agent trajectories into both fine-grained, step-by-step\ninstructions and higher-level, script-like abstractions, and explore the impact\nof different strategies for Build, Retrieval, and Update of procedural memory.\nCoupled with a dynamic regimen that continuously updates, corrects, and\ndeprecates its contents, this repository evolves in lockstep with new\nexperience. Empirical evaluation on TravelPlanner and ALFWorld shows that as\nthe memory repository is refined, agents achieve steadily higher success rates\nand greater efficiency on analogous tasks. Moreover, procedural memory built\nfrom a stronger model retains its value: migrating the procedural memory to a\nweaker model yields substantial performance gains.", "AI": {"tldr": "This paper introduces \"Memp,\" a system that equips large language model-based agents with lifelong procedural memory through strategies for building, retrieving, and updating such memory.", "motivation": "LLMs-based agents lack robust procedural memory, which limits their adaptability and long-term effectiveness in tasks.", "method": "The authors propose a procedural memory system called \"Memp\" that condenses agent trajectories into instructions and abstractions, updating continuously with new experiences.", "result": "Empirical evaluations show improved success rates and task efficiency for agents equipped with refined procedural memory, and memory transfer boosts weaker models' performance.", "conclusion": "Procedural memory enhances both immediate task execution and adaptability over time, showing promise in augmenting different types of models."}}
{"id": "2508.05653", "pdf": "https://arxiv.org/pdf/2508.05653", "abs": "https://arxiv.org/abs/2508.05653", "authors": ["Jules Clerc", "Domitile Lourdeaux", "Mohamed Sallak", "Johann Barbier", "Marc Ravaine"], "title": "Modeling Interactive Narrative Systems: A Formal Approach", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Interactive Narrative Systems (INS) have revolutionized digital experiences\nby empowering users to actively shape their stories, diverging from traditional\npassive storytelling. However, the field faces challenges due to fragmented\nresearch efforts and diverse system representations. This paper introduces a\nformal representation framework for INS, inspired by diverse approaches from\nthe state of the art. By providing a consistent vocabulary and modeling\nstructure, the framework facilitates the analysis, the description and\ncomparison of INS properties. Experimental validations on the \"Little Red\nRiding Hood\" scenario highlight the usefulness of the proposed formalism and\nits impact on improving the evaluation of INS. This work aims to foster\ncollaboration and coherence within the INS research community by proposing a\nmethodology for formally representing these systems.", "AI": {"tldr": "The paper proposes a formal representation framework for Interactive Narrative Systems (INS) to standardize analysis, inspired by state-of-the-art approaches.", "motivation": "The motivation is to address the fragmented research efforts and diverse representations in Interactive Narrative Systems, which hinder analysis and comparison.", "method": "The paper introduces a formal representation framework using a consistent vocabulary and modeling structure, validated experimentally with the \"Little Red Riding Hood\" scenario.", "result": "The framework is shown to improve the evaluation and comparison of INS through its application in experimental settings.", "conclusion": "The authors conclude that their framework can enhance collaboration and coherence among the INS research community by providing a formal foundation."}}
{"id": "2508.06063", "pdf": "https://arxiv.org/pdf/2508.06063", "abs": "https://arxiv.org/abs/2508.06063", "authors": ["Chao Hao", "Zitong Yu", "Xin Liu", "Yuhao Wang", "Weicheng Xie", "Jingang Shi", "Huanjing Yue", "Jingyu Yang"], "title": "Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Salient object detection (SOD) and camouflaged object detection (COD) are two\nclosely related but distinct computer vision tasks. Although both are\nclass-agnostic segmentation tasks that map from RGB space to binary space, the\nformer aims to identify the most salient objects in the image, while the latter\nfocuses on detecting perfectly camouflaged objects that blend into the\nbackground in the image. These two tasks exhibit strong contradictory\nattributes. Previous works have mostly believed that joint learning of these\ntwo tasks would confuse the network, reducing its performance on both tasks.\nHowever, here we present an opposite perspective: with the correct approach to\nlearning, the network can simultaneously possess the capability to find both\nsalient and camouflaged objects, allowing both tasks to benefit from joint\nlearning. We propose SCJoint, a joint learning scheme for SOD and COD tasks,\nassuming that the decoding processes of SOD and COD have different distribution\ncharacteristics. The key to our method is to learn the respective means and\nvariances of the decoding processes for both tasks by inserting a minimal\namount of task-specific learnable parameters within a fully shared network\nstructure, thereby decoupling the contradictory attributes of the two tasks at\na minimal cost. Furthermore, we propose a saliency-based sampling strategy\n(SBSS) to sample the training set of the SOD task to balance the training set\nsizes of the two tasks. In addition, SBSS improves the training set quality and\nshortens the training time. Based on the proposed SCJoint and SBSS, we train a\npowerful generalist network, named JoNet, which has the ability to\nsimultaneously capture both ``salient\" and ``camouflaged\". Extensive\nexperiments demonstrate the competitive performance and effectiveness of our\nproposed method. The code is available at https://github.com/linuxsino/JoNet.", "AI": {"tldr": "This paper introduces a joint learning approach for Salient Object Detection (SOD) and Camouflaged Object Detection (COD), demonstrating that combining these tasks can actually enhance performance under the proposed method.", "motivation": "The motivation is to challenge the prevailing notion that the joint learning of SOD and COD tasks produces conflicting results, and instead show that these tasks can complement each other when decoupled effectively.", "method": "The authors propose SCJoint, a joint learning scheme where minimal task-specific parameters are integrated into a fully shared network. They also introduce a Saliency-based Sampling Strategy (SBSS) to balance training sizes and enhance efficiency.", "result": "The proposed JoNet model, based on SCJoint and SBSS, achieves strong performance in detecting salient and camouflaged objects, with extensive experiments validating its effectiveness.", "conclusion": "The study concludes that with the right joint learning approach, the seemingly contradictory tasks of SOD and COD can be integrated efficiently, leading to mutual benefits for both."}}
{"id": "2508.06435", "pdf": "https://arxiv.org/pdf/2508.06435", "abs": "https://arxiv.org/abs/2508.06435", "authors": ["Andrea Nasuto", "Stefano Maria Iacus", "Francisco Rowe", "Devika Jain"], "title": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are transforming social-science research by\nenabling scalable, precise analysis. Their adaptability raises the question of\nwhether knowledge acquired through fine-tuning in a few languages can transfer\nto unseen languages that only appeared during pre-training. To examine this, we\nfine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or\nmultilingual data sets to classify immigration-related tweets from X/Twitter\nacross 13 languages, a domain characterised by polarised, culturally specific\ndiscourse. We evaluate whether minimal language-specific fine-tuning enables\ncross-lingual topic detection and whether adding targeted languages corrects\npre-training biases. Results show that LLMs fine-tuned in one or two languages\ncan reliably classify immigration-related content in unseen languages. However,\nidentifying whether a tweet expresses a pro- or anti-immigration stance\nbenefits from multilingual fine-tuning. Pre-training bias favours dominant\nlanguages, but even minimal exposure to under-represented languages during\nfine-tuning (as little as $9.62\\times10^{-11}$ of the original pre-training\ntoken volume) yields significant gains. These findings challenge the assumption\nthat cross-lingual mastery requires extensive multilingual training: limited\nlanguage coverage suffices for topic-level generalisation, and structural\nbiases can be corrected with lightweight interventions. By releasing\n4-bit-quantised, LoRA fine-tuned models, we provide an open-source,\nreproducible alternative to proprietary LLMs that delivers 35 times faster\ninference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,\nenabling scalable, inclusive research.", "AI": {"tldr": "The paper explores how fine-tuned LLaMA models can classify immigration-related tweets across languages, finding that even minimal multilingual fine-tuning delivers reliable cross-lingual topic detection and reduced pre-training biases.", "motivation": "The authors aim to enhance cross-lingual topic detection capabilities of large language models (LLMs) while addressing pre-training biases in multilingual contexts.", "method": "Fine-tuned lightweight LLaMA models (3.2-3B) on monolingual, bilingual, and multilingual datasets to classify tweets in 13 different languages and observe cross-lingual transferability and bias correction.", "result": "Fine-tuning in one or two languages reliably detects immigration topics in unseen languages, while stance detection requires multilingual fine-tuning. Minimal exposure to under-represented languages significantly corrects structural biases.", "conclusion": "Cross-lingual generalization does not require extensive multilingual training; lightweight interventions like fine-tuning in specific languages can deliver scalable and affordable NLP solutions."}}
{"id": "2508.05654", "pdf": "https://arxiv.org/pdf/2508.05654", "abs": "https://arxiv.org/abs/2508.05654", "authors": ["Leonardo Santiago Benitez Pereira", "Robinson Pizzio", "Samir Bonho"], "title": "Comparison of Information Retrieval Techniques Applied to IT Support Tickets", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Institutions dependent on IT services and resources acknowledge the crucial\nsignificance of an IT help desk system, that act as a centralized hub\nconnecting IT staff and users for service requests. Employing various Machine\nLearning models, these IT help desk systems allow access to corrective actions\nused in the past, but each model has different performance when applied to\ndifferent datasets. This work compares eleven Information Retrieval techniques\nin a dataset of IT support tickets, with the goal of implementing a software\nthat facilitates the work of Information Technology support analysts. The best\nresults were obtained with the Sentence-BERT technique, in its multi-language\nvariation distilluse-base-multilingual-cased-v1, where 78.7% of the\nrecommendations made by the model were considered relevant. TF-IDF (69.0%),\nWord2vec (68.7%) and LDA (66.3%) techniques also had consistent results.\nFurthermore, the used datasets and essential parts of coding have been\npublished and made open source. It also demonstrated the practicality of a\nsupport ticket recovery system by implementing a minimal viable prototype, and\ndescribed in detail the implementation of the system. Finally, this work\nproposed a novel metric for comparing the techniques, whose aim is to closely\nreflect the perception of the IT analysts about the retrieval quality.", "AI": {"tldr": "The paper evaluates 11 Machine Learning-based Information Retrieval techniques for IT help desk ticket analysis, highlighting Sentence-BERT as the best performer.", "motivation": "Improving IT support analyst efficiency by identifying an optimal method for ticket retrieval using past corrective actions.", "method": "Comparison of 11 Information Retrieval techniques on IT support ticket datasets and development of a prototype system.", "result": "Sentence-BERT achieved the highest relevance score (78.7%), surpassing TF-IDF, Word2vec, and LDA. All datasets and code were made open source.", "conclusion": "The study identifies optimal retrieval techniques for IT support systems, proposes a novel metric, and establishes practical solutions with a prototype system."}}
{"id": "2508.06072", "pdf": "https://arxiv.org/pdf/2508.06072", "abs": "https://arxiv.org/abs/2508.06072", "authors": ["Zijian Chen", "Lirong Deng", "Zhengyu Chen", "Kaiwei Zhang", "Qi Jia", "Yuan Tian", "Yucheng Zhu", "Guangtao Zhai"], "title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "categories": ["cs.CV", "cs.AI"], "comment": "24 pages, 10 figures", "summary": "Evaluating the abilities of large models and manifesting their gaps are\nchallenging. Current benchmarks adopt either ground-truth-based score-form\nevaluation on static datasets or indistinct textual chatbot-style human\npreferences collection, which may not provide users with immediate, intuitive,\nand perceptible feedback on performance differences. In this paper, we\nintroduce BioMotion Arena, a novel framework for evaluating large language\nmodels (LLMs) and multimodal large language models (MLLMs) via visual\nanimation. Our methodology draws inspiration from the inherent visual\nperception of motion patterns characteristic of living organisms that utilizes\npoint-light source imaging to amplify the performance discrepancies between\nmodels. Specifically, we employ a pairwise comparison evaluation and collect\nmore than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion\nvariants. Data analyses show that the crowd-sourced human votes are in good\nagreement with those of expert raters, demonstrating the superiority of our\nBioMotion Arena in offering discriminative feedback. We also find that over\n90\\% of evaluated models, including the cutting-edge open-source InternVL3 and\nproprietary Claude-4 series, fail to produce fundamental humanoid point-light\ngroups, much less smooth and biologically plausible motions. This enables\nBioMotion Arena to serve as a challenging benchmark for performance\nvisualization and a flexible evaluation framework without restrictions on\nground-truth.", "AI": {"tldr": "BioMotion Arena introduces a novel framework using visual animations to evaluate large language models (LLMs) and multimodal LLMs (MLLMs), emphasizing performance differences through biological motion perception.", "motivation": "Current evaluation methods of large models either rely on static ground-truth-based benchmarks or unclear human preferences, which fail to provide straightforward and perceptible feedback on performance gaps.", "method": "The framework utilizes point-light source imaging inspired by biological motion patterns for pairwise comparison evaluation. It collects crowdsourced human votes alongside expert validation on 90 motion variants.", "result": "Data analysis shows alignment between human and expert evaluations. 90% of models tested fail to generate fundamental humanoid point-light animations, exposing limitations in current LLMs and MLLMs.", "conclusion": "BioMotion Arena serves as a discriminative, ground-truth-independent benchmark for evaluating and visualizing performance inconsistencies of large models."}}
{"id": "2508.06336", "pdf": "https://arxiv.org/pdf/2508.06336", "abs": "https://arxiv.org/abs/2508.06336", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Victor Oei", "Anna Penzkofer", "Andreas Bulling"], "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "comment": "16 pages", "summary": "We introduce Unsupervised Partner Design (UPD) - a population-free,\nmulti-agent reinforcement learning framework for robust ad-hoc teamwork that\nadaptively generates training partners without requiring pretrained partners or\nmanual parameter tuning. UPD constructs diverse partners by stochastically\nmixing an ego agent's policy with biased random behaviours and scores them\nusing a variance-based learnability metric that prioritises partners near the\nego agent's current learning frontier. We show that UPD can be integrated with\nunsupervised environment design, resulting in the first method enabling fully\nunsupervised curricula over both level and partner distributions in a\ncooperative setting. Through extensive evaluations on Overcooked-AI and the\nOvercooked Generalisation Challenge, we demonstrate that this dynamic partner\ncurriculum is highly effective: UPD consistently outperforms both\npopulation-based and population-free baselines as well as ablations. In a user\nstudy, we further show that UPD achieves higher returns than all baselines and\nwas perceived as significantly more adaptive, more human-like, a better\ncollaborator, and less frustrating.", "AI": {"tldr": "UPD is a novel framework for ad-hoc teamwork that generates diverse training partners without requiring predefined resources, achieving superior performance in cooperative tasks.", "motivation": "To achieve robust ad-hoc teamwork without relying on pretrained partners or manual hyperparameter tuning.", "method": "UPD stochastically mixes the ego agent's policy with random behaviors and evaluates these partners using a variance-based learnability metric.", "result": "UPD surpasses both population-based and population-free baselines on benchmarks like Overcooked-AI, and demonstrates adaptability and human-like behavior in a user study.", "conclusion": "UPD is an effective and adaptive solution for generating training partners in multi-agent reinforcement learning."}}
{"id": "2508.06445", "pdf": "https://arxiv.org/pdf/2508.06445", "abs": "https://arxiv.org/abs/2508.06445", "authors": ["Abolfazl Ansari", "Delvin Ce Zhang", "Nafis Irtiza Tripto", "Dongwon Lee"], "title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in 18th International Conference on Social Computing,\n  Behavioral-Cultural Modeling, & Prediction and Behavior Representation in\n  Modeling and Simulation, and to be published in the Springer LNCS series", "summary": "The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns\nfor journalistic integrity and authorship. This study examines AI-generated\ncontent across over 40,000 news articles from major, local, and college news\nmedia, in various media formats. Using three advanced AI-text detectors (e.g.,\nBinoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of\nGenAI use in recent years, especially in local and college news. Sentence-level\nanalysis reveals LLMs are often used in the introduction of news, while\nconclusions usually written manually. Linguistic analysis shows GenAI boosts\nword richness and readability but lowers formality, leading to more uniform\nwriting styles, particularly in local media.", "AI": {"tldr": "This study analyzes over 40,000 news articles and finds increased use of Generative AI in local and college media, often impacting writing style, word richness, and readability.", "motivation": "Concerns over journalistic integrity and the authorship due to the rise of Generative AI tools in media production.", "method": "Used three AI text detectors to analyze content from over 40,000 news articles across various media formats.", "result": "Finds growing use of Generative AI, especially in local and college news, with AI often employed for introductions and linguistic improvements (e.g., richer vocabulary).", "conclusion": "Generative AI contributes to enhanced readability and word richness but results in less formal and more uniform writing styles, especially noticeable in regional news media."}}
{"id": "2508.05657", "pdf": "https://arxiv.org/pdf/2508.05657", "abs": "https://arxiv.org/abs/2508.05657", "authors": ["Haozhe Xu", "Xiaohua Wang", "Changze Lv", "Xiaoqing Zheng"], "title": "Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Conversational recommender systems (CRSs) enhance recommendation quality by\nengaging users in multi-turn dialogues, capturing nuanced preferences through\nnatural language interactions. However, these systems often face the false\nnegative issue, where items that a user might like are incorrectly labeled as\nnegative during training, leading to suboptimal recommendations.Expanding the\nlabel set through data augmentation presents an intuitive solution but faces\nthe challenge of balancing two key aspects: ensuring semantic relevance and\npreserving the collaborative information inherent in CRS datasets. To address\nthese issues, we propose a novel data augmentation framework that first\nleverages an LLM-based semantic retriever to identify diverse and semantically\nrelevant items, which are then filtered by a relevance scorer to remove noisy\ncandidates. Building on this, we introduce a two-stage training strategy\nbalancing semantic relevance and collaborative information. Extensive\nexperiments on two benchmark datasets and user simulators demonstrate\nsignificant and consistent performance improvements across various\nrecommenders, highlighting the effectiveness of our approach in advancing CRS\nperformance.", "AI": {"tldr": "This paper introduces a data augmentation framework to address false negative issues in conversational recommender systems by balancing semantic relevance and collaborative information, resulting in improved recommendation performance.", "motivation": "The motivation of this paper is to tackle the false negative issue in conversational recommender systems, where items that users might like are incorrectly labeled as negatives during training, leading to poor recommendations.", "method": "The proposed method involves a data augmentation framework. First, a semantic retriever based on a large language model identifies diverse, semantically relevant items. Then, a relevance scorer filters out noisy candidates. Finally, a two-stage training strategy is applied to balance semantic relevance and collaborative information.", "result": "Extensive experiments on benchmark datasets and user simulators showed consistent and significant performance improvements in various recommenders.", "conclusion": "The proposed framework effectively addresses false negative issues and advances conversational recommender system performance by enhancing recommendation quality."}}
{"id": "2508.06076", "pdf": "https://arxiv.org/pdf/2508.06076", "abs": "https://arxiv.org/abs/2508.06076", "authors": ["Michael Wehrli", "Alicia Durrer", "Paul Friedrich", "Sidaty El Hadramy", "Edwin Li", "Luana Brahaj", "Carol C. Hasler", "Philippe C. Cattin"], "title": "Towards MR-Based Trochleoplasty Planning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at MICCAI COLAS Workshop 2025. Code:\n  https://wehrlimi.github.io/sr-3d-planning/", "summary": "To treat Trochlear Dysplasia (TD), current approaches rely mainly on\nlow-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.\nThe surgeries are planned based on surgeons experience, have limited adoption\nof minimally invasive techniques, and lead to inconsistent outcomes. We propose\na pipeline that generates super-resolved, patient-specific 3D pseudo-healthy\ntarget morphologies from conventional clinical MR scans. First, we compute an\nisotropic super-resolved MR volume using an Implicit Neural Representation\n(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label\ncustom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to\ngenerate pseudo-healthy target morphologies of the trochlear region. In\ncontrast to prior work producing pseudo-healthy low-resolution 3D MR images,\nour approach enables the generation of sub-millimeter resolved 3D shapes\ncompatible for pre- and intraoperative use. These can serve as preoperative\nblueprints for reshaping the femoral groove while preserving the native patella\narticulation. Furthermore, and in contrast to other work, we do not require a\nCT for our pipeline - reducing the amount of radiation. We evaluated our\napproach on 25 TD patients and could show that our target morphologies\nsignificantly improve the sulcus angle (SA) and trochlear groove depth (TGD).\nThe code and interactive visualization are available at\nhttps://wehrlimi.github.io/sr-3d-planning/.", "AI": {"tldr": "The paper presents a pipeline for treating Trochlear Dysplasia using super-resolved, patient-specific 3D pseudo-healthy target morphologies. The method does not rely on CT imaging, reducing radiation exposure.", "motivation": "Current treatments for Trochlear Dysplasia rely on low-resolution MR scans and surgical intuition, which lead to inconsistent outcomes and have limited minimally invasive techniques.", "method": "The pipeline utilizes an Implicit Neural Representation for super-resolving MR volumes, a custom-trained network for segmentation, and a Wavelet Diffusion Model to generate pseudo-healthy target morphologies.", "result": "The proposed approach significantly improved sulcus angle and trochlear groove depth in evaluations of 25 patients.", "conclusion": "The sub-millimeter resolved 3D shapes generated by the pipeline can enhance pre-and intraoperative planning, serve as blueprints for reshaping femoral grooves, and reduce radiation exposure by avoiding CT scans."}}
{"id": "2508.06346", "pdf": "https://arxiv.org/pdf/2508.06346", "abs": "https://arxiv.org/abs/2508.06346", "authors": ["Mert Can Kurucu", "Tufan Kumbasar", "\u0130brahim Eksin", "M\u00fcjde G\u00fczelkaya"], "title": "Introducing Fractional Classification Loss for Robust Learning with Noisy Labels", "categories": ["cs.LG"], "comment": "25 pages, 6 figures, 2 table. Submitted to Pattern Recognition", "summary": "Robust loss functions are crucial for training deep neural networks in the\npresence of label noise, yet existing approaches require extensive,\ndataset-specific hyperparameter tuning. In this work, we introduce Fractional\nClassification Loss (FCL), an adaptive robust loss that automatically\ncalibrates its robustness to label noise during training. Built within the\nactive-passive loss framework, FCL employs the fractional derivative of the\nCross-Entropy (CE) loss as its active component and the Mean Absolute Error\n(MAE) as its passive loss component. With this formulation, we demonstrate that\nthe fractional derivative order $\\mu$ spans a family of loss functions that\ninterpolate between MAE-like robustness and CE-like fast convergence.\nFurthermore, we integrate $\\mu$ into the gradient-based optimization as a\nlearnable parameter and automatically adjust it to optimize the trade-off\nbetween robustness and convergence speed. We reveal that FCL's unique property\nestablishes a critical trade-off that enables the stable learning of $\\mu$:\nlower log penalties on difficult or mislabeled examples improve robustness but\nimpose higher penalties on easy or clean data, reducing model confidence in\nthem. Consequently, FCL can dynamically reshape its loss landscape to achieve\neffective classification performance under label noise. Extensive experiments\non benchmark datasets show that FCL achieves state-of-the-art results without\nthe need for manual hyperparameter tuning.", "AI": {"tldr": "The paper introduces Fractional Classification Loss (FCL), a robust loss function for deep networks that adapts to label noise without requiring dataset-specific hyperparameter tuning.", "motivation": "Existing robust loss functions struggle with label noise and require heavy hyperparameter tuning, motivating the need for a more adaptive approach.", "method": "FCL uses the fractional derivative of Cross-Entropy loss as an active component and Mean Absolute Error as a passive one. The fractional derivative order is learned and optimized during training.", "result": "FCL automatically balances robustness and convergence speed, achieving superior performance on benchmarks with label noise.", "conclusion": "FCL eliminates the need for hyperparameter tuning and offers robust, adaptive loss behavior, making it effective against label noise."}}
{"id": "2508.06447", "pdf": "https://arxiv.org/pdf/2508.06447", "abs": "https://arxiv.org/abs/2508.06447", "authors": ["Lingkun Long", "Rubing Yang", "Yushi Huang", "Desheng Hui", "Ao Zhou", "Jianlei Yang"], "title": "SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning", "categories": ["cs.CL"], "comment": null, "summary": "Long-context inference for Large Language Models (LLMs) is heavily limited by\nhigh computational demands. While several existing methods optimize attention\ncomputation, they still process the full set of hidden states at each layer,\nlimiting overall efficiency. In this work, we propose SlimInfer, an innovative\nframework that aims to accelerate inference by directly pruning less critical\nprompt tokens during the forward pass. Our key insight is an information\ndiffusion phenomenon: As information from critical tokens propagates through\nlayers, it becomes distributed across the entire sequence. This diffusion\nprocess suggests that LLMs can maintain their semantic integrity when excessive\ntokens, even including these critical ones, are pruned in hidden states.\nMotivated by this, SlimInfer introduces a dynamic fine-grained pruning\nmechanism that accurately removes redundant tokens of hidden state at\nintermediate layers. This layer-wise pruning naturally enables an asynchronous\nKV cache manager that prefetches required token blocks without complex\npredictors, reducing both memory usage and I/O costs. Extensive experiments\nshow that SlimInfer can achieve up to $\\mathbf{2.53\\times}$ time-to-first-token\n(TTFT) speedup and $\\mathbf{1.88\\times}$ end-to-end latency reduction for\nLLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on\nLongBench. Our code will be released upon acceptance.", "AI": {"tldr": "SlimInfer accelerates large language model inference by pruning redundant prompt tokens during computation, achieving significant speed and efficiency gains.", "motivation": "Large Language Models struggle with computational demands, particularly in handling long-context inference. This paper addresses the inefficiencies arising from processing hidden states comprehensively at each layer.", "method": "SlimInfer implements dynamic fine-grained pruning of less critical prompt tokens during the forward pass, leveraging an information diffusion process. It introduces an asynchronous KV cache manager to streamline data handling.", "result": "Experiments demonstrate up to 2.53x speedup in time-to-first-token and 1.88x reduction in end-to-end latency for LLaMA3.1-8B-Instruct, with negligible performance compromise on evaluation benchmarks.", "conclusion": "SlimInfer successfully optimizes inference for large language models, showcasing efficiency improvements without diminishing semantic performance, and highlights potential for broader application in large-scale model deployments."}}
{"id": "2508.05660", "pdf": "https://arxiv.org/pdf/2508.05660", "abs": "https://arxiv.org/abs/2508.05660", "authors": ["Aditya Nagori", "Ricardo Accorsi Casonatto", "Ayush Gautam", "Abhinav Manikantha Sai Cheruvu", "Rishikesan Kamaleswaran"], "title": "Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The surge in scientific publications challenges traditional review methods,\ndemanding tools that integrate structured metadata with full-text analysis.\nHybrid Retrieval Augmented Generation (RAG) systems, combining graph queries\nwith vector search offer promise but are typically static, rely on proprietary\ntools, and lack uncertainty estimates. We present an agentic approach that\nencapsulates the hybrid RAG pipeline within an autonomous agent capable of (1)\ndynamically selecting between GraphRAG and VectorRAG for each query, (2)\nadapting instruction-tuned generation in real time to researcher needs, and (3)\nquantifying uncertainty during inference. This dynamic orchestration improves\nrelevance, reduces hallucinations, and promotes reproducibility.\n  Our pipeline ingests bibliometric open-access data from PubMed, arXiv, and\nGoogle Scholar APIs, builds a Neo4j citation-based knowledge graph (KG), and\nembeds full-text PDFs into a FAISS vector store (VS) using the all-MiniLM-L6-v2\nmodel. A Llama-3.3-70B agent selects GraphRAG (translating queries to Cypher\nfor KG) or VectorRAG (combining sparse and dense retrieval with re-ranking).\nInstruction tuning refines domain-specific generation, and bootstrapped\nevaluation yields standard deviation for evaluation metrics.\n  On synthetic benchmarks mimicking real-world queries, the Instruction-Tuned\nAgent with Direct Preference Optimization (DPO) outperforms the baseline,\nachieving a gain of 0.63 in VS Context Recall and a 0.56 gain in overall\nContext Precision. Additional gains include 0.24 in VS Faithfulness, 0.12 in\nboth VS Precision and KG Answer Relevance, 0.11 in overall Faithfulness score,\n0.05 in KG Context Recall, and 0.04 in both VS Answer Relevance and overall\nPrecision. These results highlight the system's improved reasoning over\nheterogeneous sources and establish a scalable framework for autonomous,\nagentic scientific discovery.", "AI": {"tldr": "The paper proposes an autonomous agent using Hybrid Retrieval Augmented Generation (RAG) that dynamically switches retrieval methods and quantifies uncertainty, leveraging bibliometric data and demonstrating improved reasoning for scientific discovery.", "motivation": "The motivation is the increasing number of scientific publications, which makes traditional review methods inadequate, necessitating advanced tools integrating metadata and full-text analysis.", "method": "The pipeline builds a Neo4j citation graph and FAISS vector store, powered by Llama-3.3-70B agent for dynamic switching between GraphRAG and VectorRAG approaches, incorporating instruction tuning and uncertainty estimation.", "result": "The proposed system achieves marked improvements across metrics like recall, precision, and faithfulness in synthetic benchmarks, demonstrating enhanced query processing and reasoning over diverse scientific sources.", "conclusion": "The agentic hybrid RAG framework succeeds in improving scalability and reproducibility in scientific discovery, creating a robust solution for navigating and analyzing scientific literature."}}
{"id": "2508.06080", "pdf": "https://arxiv.org/pdf/2508.06080", "abs": "https://arxiv.org/abs/2508.06080", "authors": ["Bin Xia", "Jiyang Liu", "Yuechen Zhang", "Bohao Peng", "Ruihang Chu", "Yitong Wang", "Xinglong Wu", "Bei Yu", "Jiaya Jia"], "title": "DreamVE: Unified Instruction-based Image and Video Editing", "categories": ["cs.CV"], "comment": null, "summary": "Instruction-based editing holds vast potential due to its simple and\nefficient interactive editing format. However, instruction-based editing,\nparticularly for video, has been constrained by limited training data,\nhindering its practical application. To this end, we introduce DreamVE, a\nunified model for instruction-based image and video editing. Specifically, We\npropose a two-stage training strategy: first image editing, then video editing.\nThis offers two main benefits: (1) Image data scales more easily, and models\nare more efficient to train, providing useful priors for faster and better\nvideo editing training. (2) Unifying image and video generation is natural and\naligns with current trends. Moreover, we present comprehensive training data\nsynthesis pipelines, including collage-based and generative model-based data\nsynthesis. The collage-based data synthesis combines foreground objects and\nbackgrounds to generate diverse editing data, such as object manipulation,\nbackground changes, and text modifications. It can easily generate billions of\naccurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE\non extensive collage-based data to achieve strong performance in key editing\ntypes and enhance generalization and transfer capabilities. However,\ncollage-based data lacks some attribute editing cases, leading to a relative\ndrop in performance. In contrast, the generative model-based pipeline, despite\nbeing hard to scale up, offers flexibility in handling attribute editing cases.\nTherefore, we use generative model-based data to further fine-tune DreamVE.\nBesides, we design an efficient and powerful editing framework for DreamVE. We\nbuild on the SOTA T2V model and use a token concatenation with early drop\napproach to inject source image guidance, ensuring strong consistency and\neditability. The codes and models will be released.", "AI": {"tldr": "DreamVE is a unified model for instruction-based image and video editing. It employs a two-stage training strategy: training with image data followed by video data. Collage-based and generative model-based pipelines synthesize training data.", "motivation": "The practical application of instruction-based video editing has been limited by a lack of sufficient training data, necessitating innovative strategies to improve scalability and efficiency.", "method": "DreamVE utilizes a two-stage training approach starting with image editing and then progressing to video editing. It combines extensive collage-based data pretraining with generative model-based fine-tuning. A novel editing framework incorporates guidance from source images using a token concatenation method.", "result": "The model demonstrates strong performance in key editing tasks and improved generalization capabilities by leveraging collage-based pretraining. Fine-tuning with generative data addresses specific attribute editing challenges.", "conclusion": "DreamVE advances instruction-based editing by unifying image and video editing, incorporating scalable and diverse training data synthesis, and designing an efficient editing framework. Its release aims to further research and application."}}
{"id": "2508.06471", "pdf": "https://arxiv.org/pdf/2508.06471", "abs": "https://arxiv.org/abs/2508.06471", "authors": ["GLM-4. 5 Team", ":", "Aohan Zeng", "Xin Lv", "Qinkai Zheng", "Zhenyu Hou", "Bin Chen", "Chengxing Xie", "Cunxiang Wang", "Da Yin", "Hao Zeng", "Jiajie Zhang", "Kedong Wang", "Lucen Zhong", "Mingdao Liu", "Rui Lu", "Shulin Cao", "Xiaohan Zhang", "Xuancheng Huang", "Yao Wei", "Yean Cheng", "Yifan An", "Yilin Niu", "Yuanhao Wen", "Yushi Bai", "Zhengxiao Du", "Zihan Wang", "Zilin Zhu", "Bohan Zhang", "Bosi Wen", "Bowen Wu", "Bowen Xu", "Can Huang", "Casey Zhao", "Changpeng Cai", "Chao Yu", "Chen Li", "Chendi Ge", "Chenghua Huang", "Chenhui Zhang", "Chenxi Xu", "Chenzheng Zhu", "Chuang Li", "Congfeng Yin", "Daoyan Lin", "Dayong Yang", "Dazhi Jiang", "Ding Ai", "Erle Zhu", "Fei Wang", "Gengzheng Pan", "Guo Wang", "Hailong Sun", "Haitao Li", "Haiyang Li", "Haiyi Hu", "Hanyu Zhang", "Hao Peng", "Hao Tai", "Haoke Zhang", "Haoran Wang", "Haoyu Yang", "He Liu", "He Zhao", "Hongwei Liu", "Hongxi Yan", "Huan Liu", "Huilong Chen", "Ji Li", "Jiajing Zhao", "Jiamin Ren", "Jian Jiao", "Jiani Zhao", "Jianyang Yan", "Jiaqi Wang", "Jiayi Gui", "Jiayue Zhao", "Jie Liu", "Jijie Li", "Jing Li", "Jing Lu", "Jingsen Wang", "Jingwei Yuan", "Jingxuan Li", "Jingzhao Du", "Jinhua Du", "Jinxin Liu", "Junkai Zhi", "Junli Gao", "Ke Wang", "Lekang Yang", "Liang Xu", "Lin Fan", "Lindong Wu", "Lintao Ding", "Lu Wang", "Man Zhang", "Minghao Li", "Minghuan Xu", "Mingming Zhao", "Mingshu Zhai", "Pengfan Du", "Qian Dong", "Shangde Lei", "Shangqing Tu", "Shangtong Yang", "Shaoyou Lu", "Shijie Li", "Shuang Li", "Shuang-Li", "Shuxun Yang", "Sibo Yi", "Tianshu Yu", "Wei Tian", "Weihan Wang", "Wenbo Yu", "Weng Lam Tam", "Wenjie Liang", "Wentao Liu", "Xiao Wang", "Xiaohan Jia", "Xiaotao Gu", "Xiaoying Ling", "Xin Wang", "Xing Fan", "Xingru Pan", "Xinyuan Zhang", "Xinze Zhang", "Xiuqing Fu", "Xunkai Zhang", "Yabo Xu", "Yandong Wu", "Yida Lu", "Yidong Wang", "Yilin Zhou", "Yiming Pan", "Ying Zhang", "Yingli Wang", "Yingru Li", "Yinpei Su", "Yipeng Geng", "Yitong Zhu", "Yongkun Yang", "Yuhang Li", "Yuhao Wu", "Yujiang Li", "Yunan Liu", "Yunqing Wang", "Yuntao Li", "Yuxuan Zhang", "Zezhen Liu", "Zhen Yang", "Zhengda Zhou", "Zhongpei Qiao", "Zhuoer Feng", "Zhuorui Liu", "Zichen Zhang", "Zihan Wang", "Zijun Yao", "Zikang Wang", "Ziqiang Liu", "Ziwei Chai", "Zixuan Li", "Zuodong Zhao", "Wenguang Chen", "Jidong Zhai", "Bin Xu", "Minlie Huang", "Hongning Wang", "Juanzi Li", "Yuxiao Dong", "Jie Tang"], "title": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models", "categories": ["cs.CL"], "comment": null, "summary": "We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language\nmodel with 355B total parameters and 32B activated parameters, featuring a\nhybrid reasoning method that supports both thinking and direct response modes.\nThrough multi-stage training on 23T tokens and comprehensive post-training with\nexpert model iteration and reinforcement learning, GLM-4.5 achieves strong\nperformance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on\nTAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer\nparameters than several competitors, GLM-4.5 ranks 3rd overall among all\nevaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B\nparameters) and a compact version, GLM-4.5-Air (106B parameters), to advance\nresearch in reasoning and agentic AI systems. Code, models, and more\ninformation are available at https://github.com/zai-org/GLM-4.5.", "AI": {"tldr": "The paper introduces GLM-4.5, a 355-billion parameter Mixture-of-Experts language model, emphasizing reasoning capabilities and efficient performance with fewer activated parameters. It achieves competitive benchmarks and is open-source.", "motivation": "To create a large language model that excels in reasoning and agentic tasks, offering strong performance with fewer parameters compared to competitors and advancing research on reasoning and agentic AI systems.", "method": "GLM-4.5 employs a Mixture-of-Experts architecture with 355B total parameters, activating 32B parameters per task. It undergoes multi-stage training on 23T tokens, expert model iteration, and reinforcement learning techniques for optimization.", "result": "The model achieves strong benchmark results: 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. It ranks 3rd overall and 2nd on agentic benchmarks, outperforming some models with more parameters.", "conclusion": "GLM-4.5 demonstrates that efficient large models can achieve strong reasoning and agentic task performance. By releasing the model and its compact version, GLM-4.5-Air, the authors aim to contribute to the research community and promote advancements in AI systems."}}
{"id": "2508.05661", "pdf": "https://arxiv.org/pdf/2508.05661", "abs": "https://arxiv.org/abs/2508.05661", "authors": ["Andre Rusli", "Shoma Ishimoto", "Sho Akiyama", "Aman Kumar Singh"], "title": "Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace", "categories": ["cs.IR", "cs.AI"], "comment": "6 pages, KDD 2025 Workshop on Two-sided Marketplace Optimization:\n  Search, Pricing, Matching & Growth (TSMO)", "summary": "Visual search offers an intuitive way for customers to explore diverse\nproduct catalogs, particularly in consumer-to-consumer (C2C) marketplaces where\nlistings are often unstructured and visually driven. This paper presents a\nscalable visual search system deployed in Mercari's C2C marketplace, where\nend-users act as buyers and sellers. We evaluate recent vision-language models\nfor zero-shot image retrieval and compare their performance with an existing\nfine-tuned baseline. The system integrates real-time inference and background\nindexing workflows, supported by a unified embedding pipeline optimized through\ndimensionality reduction. Offline evaluation using user interaction logs shows\nthat the multilingual SigLIP model outperforms other models across multiple\nretrieval metrics, achieving a 13.3% increase in nDCG@5 over the baseline. A\none-week online A/B test in production further confirms real-world impact, with\nthe treatment group showing substantial gains in engagement and conversion, up\nto a 40.9% increase in transaction rate via image search. Our findings\nhighlight that recent zero-shot models can serve as a strong and practical\nbaseline for production use, which enables teams to deploy effective visual\nsearch systems with minimal overhead, while retaining the flexibility to\nfine-tune based on future data or domain-specific needs.", "AI": {"tldr": "The paper introduces a visual search system for Mercari's C2C marketplace using zero-shot vision-language models, achieving significant performance improvement in offline and online evaluations.", "motivation": "To create an intuitive visual search experience for C2C marketplaces where unstructured and visually driven product listings can make search challenging for users.", "method": "The system uses recent vision-language models for zero-shot image retrieval, integrating real-time inference, background indexing workflows, and a unified embedding pipeline optimized with dimensionality reduction. Performance is evaluated via offline user interaction logs and online A/B testing.", "result": "The multilingual SigLIP model outperformed competitors, with a 13.3% increase in offline nDCG@5 and up to a 40.9% increase in transaction rate in an online A/B test, showcasing enhanced user engagement and conversion.", "conclusion": "Zero-shot models can effectively serve as a strong baseline for scalable, production-ready visual search systems, offering flexibility for future fine-tuning while minimizing initial deployment complexity."}}
{"id": "2508.06082", "pdf": "https://arxiv.org/pdf/2508.06082", "abs": "https://arxiv.org/abs/2508.06082", "authors": ["Yanxiao Sun", "Jiafu Wu", "Yun Cao", "Chengming Xu", "Yabiao Wang", "Weijian Cao", "Donghao Luo", "Chengjie Wang", "Yanwei Fu"], "title": "SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion-based or flow-based models have achieved significant progress in\nvideo synthesis but require multiple iterative sampling steps, which incurs\nsubstantial computational overhead. While many distillation methods that are\nsolely based on trajectory-preserving or distribution-matching have been\ndeveloped to accelerate video generation models, these approaches often suffer\nfrom performance breakdown or increased artifacts under few-step settings. To\naddress these limitations, we propose \\textbf{\\emph{SwiftVideo}}, a unified and\nstable distillation framework that combines the advantages of\ntrajectory-preserving and distribution-matching strategies. Our approach\nintroduces continuous-time consistency distillation to ensure precise\npreservation of ODE trajectories. Subsequently, we propose a dual-perspective\nalignment that includes distribution alignment between synthetic and real data\nalong with trajectory alignment across different inference steps. Our method\nmaintains high-quality video generation while substantially reducing the number\nof inference steps. Quantitative evaluations on the OpenVid-1M benchmark\ndemonstrate that our method significantly outperforms existing approaches in\nfew-step video generation.", "AI": {"tldr": "SwiftVideo addresses computational inefficiency in video synthesis by combining trajectory-preserving and distribution-matching methods for accelerated, high-quality generation.", "motivation": "Existing diffusion and flow-based video synthesis methods are computationally expensive due to iterative sampling, and distillation methods are prone to performance issues with fewer inference steps.", "method": "SwiftVideo employs continuous-time consistency distillation and dual-perspective alignment, combining trajectory alignment and distribution alignment for stable and efficient video synthesis.", "result": "SwiftVideo achieves fewer inference steps while maintaining superior quality in video generation, outperforming alternative methods on the OpenVid-1M benchmark.", "conclusion": "SwiftVideo establishes a robust framework for efficient video synthesis by addressing the trade-offs between computational speed and video quality, offering advancements in few-step generation approaches."}}
{"id": "2508.06353", "pdf": "https://arxiv.org/pdf/2508.06353", "abs": "https://arxiv.org/abs/2508.06353", "authors": ["Parichit Sharma", "Marcin Stanislaw", "Hasan Kurban", "Oguzhan Kulekci", "Mehmet Dalkilic"], "title": "Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces Geometric-k-means (or Gk-means for short), a novel\napproach that significantly enhances the efficiency and energy economy of the\nwidely utilized k-means algorithm, which, despite its inception over five\ndecades ago, remains a cornerstone in machine learning applications. The\nessence of Gk-means lies in its active utilization of geometric principles,\nspecifically scalar projection, to significantly accelerate the algorithm\nwithout sacrificing solution quality. This geometric strategy enables a more\ndiscerning focus on data points that are most likely to influence cluster\nupdates, which we call as high expressive data (HE). In contrast, low\nexpressive data (LE), does not impact clustering outcome, is effectively\nbypassed, leading to considerable reductions in computational overhead.\nExperiments spanning synthetic, real-world and high-dimensional datasets,\ndemonstrate Gk-means is significantly better than traditional and state of the\nart (SOTA) k-means variants in runtime and distance computations (DC).\nMoreover, Gk-means exhibits better resource efficiency, as evidenced by its\nreduced energy footprint, placing it as more sustainable alternative.", "AI": {"tldr": "The paper presents a new version of the k-means algorithm, called Geometric-k-means (Gk-means), which uses geometric principles for faster processing and enhanced efficiency.", "motivation": "To address the inefficiency and high computational cost of the traditional k-means algorithm while maintaining solution quality.", "method": "Utilizes geometric principles like scalar projection to differentiate between impactful (HE) and non-impactful (LE) data points for efficient cluster updates.", "result": "Gk-means demonstrates superior runtime, computational efficiency, and reduced energy consumption compared to traditional and state-of-the-art versions across various datasets.", "conclusion": "Gk-means provides a sustainable, efficient alternative to traditional k-means, significantly improving performance and resource utilization without compromising clustering quality."}}
{"id": "2508.06475", "pdf": "https://arxiv.org/pdf/2508.06475", "abs": "https://arxiv.org/abs/2508.06475", "authors": ["Guimin Hu", "Daniel Hershcovich", "Hasti Seifi"], "title": "HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning", "categories": ["cs.CL"], "comment": null, "summary": "Haptic captioning is the task of generating natural language descriptions\nfrom haptic signals, such as vibrations, for use in virtual reality,\naccessibility, and rehabilitation applications. While previous multimodal\nresearch has focused primarily on vision and audio, haptic signals for the\nsense of touch remain underexplored. To address this gap, we formalize the\nhaptic captioning task and propose HapticLLaMA, a multimodal sensory language\nmodel that interprets vibration signals into descriptions in a given sensory,\nemotional, or associative category. We investigate two types of haptic\ntokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that\nconvert haptic signals into sequences of discrete units, enabling their\nintegration with the LLaMA model. HapticLLaMA is trained in two stages: (1)\nsupervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,\nand (2) fine-tuning via reinforcement learning from human feedback (RLHF). We\nassess HapticLLaMA's captioning performance using both automated n-gram metrics\nand human evaluation. HapticLLaMA demonstrates strong capability in\ninterpreting haptic vibration signals, achieving a METEOR score of 59.98 and a\nBLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated\ncaptions received human ratings above 3.5 on a 7-point scale, with RLHF\nyielding a 10% improvement in the overall rating distribution, indicating\nstronger alignment with human haptic perception. These findings highlight the\npotential of large language models to process and adapt to sensory data.", "AI": {"tldr": "The paper introduces HapticLLaMA, which interprets haptic signals into descriptive captions, demonstrating its effectiveness via both automated metrics and human feedback.", "motivation": "Explore haptic signals for natural language generation in applications like virtual reality and accessibility.", "method": "Formalized haptic captioning task using LLaMA-based multimodal language model trained through supervised fine-tuning and RLHF.", "result": "HapticLLaMA attained METEOR score of 59.98, BLEU-4 score of 32.06, and strong human feedback alignment, improving caption quality.", "conclusion": "LLMs can process and adapt to haptic sensory data effectively, showcasing their applicability in novel multimodal domains."}}
{"id": "2508.05662", "pdf": "https://arxiv.org/pdf/2508.05662", "abs": "https://arxiv.org/abs/2508.05662", "authors": ["Yuzhou Zhu"], "title": "From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Dynamic streams from news feeds, social media, sensor networks, and financial\nmarkets challenge static RAG frameworks. Full-scale indices incur high memory\ncosts; periodic rebuilds introduce latency that undermines data freshness;\nnaive sampling sacrifices semantic coverage. We present Streaming RAG, a\nunified pipeline that combines multi-vector cosine screening, mini-batch\nclustering, and a counter-based heavy-hitter filter to maintain a compact\nprototype set. We further prove an approximation bound \\$E\\[R(K\\_t)] \\ge R^\\* -\nL \\Delta\\$ linking retrieval quality to clustering variance. An incremental\nindex upsert mechanism refreshes prototypes without interrupting queries.\nExperiments on eight real-time streams show statistically significant gains in\nRecall\\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and\nthroughput above 900 documents per second under a 150 MB budget. Hyperparameter\nsensitivity analysis over cluster count, admission probability, relevance\nthreshold, and counter capacity validates default settings. In open-domain\nquestion answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match\nand 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L\nimprovements. Streaming RAG establishes a new Pareto frontier for retrieval\naugmentation.", "AI": {"tldr": "The paper introduces Streaming RAG, a method designed to improve dynamic retrieval-augmented generation frameworks by addressing challenges in real-time data streams such as high memory costs and latency.", "motivation": "Static frameworks cannot efficiently keep up with dynamic streams, leading to limitations in latency, memory usage, and semantic coverage for retrieval tasks.", "method": "A unified pipeline with multi-vector cosine screening, mini-batch clustering, and heavy-hitter filtering maintains a compact prototype set alongside an incremental index update mechanism.", "result": "The proposed approach improved Recall@10 (up to 3 points), reduced latency (<15 ms), handled high throughput (>900 docs/sec), and achieved gains in exact match and F1 using GPT-3.5 Turbo.", "conclusion": "Streaming RAG sets a new benchmark for dynamic retrieval augmentation, delivering efficient data freshness and improved performance across diverse real-time applications."}}
{"id": "2508.06084", "pdf": "https://arxiv.org/pdf/2508.06084", "abs": "https://arxiv.org/abs/2508.06084", "authors": ["Weichen Zhang", "Zhui Zhu", "Ningbo Li", "Kebin Liu", "Yunhao Liu"], "title": "AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have achieved impressive performance on\nmultimodal reasoning tasks such as visual question answering (VQA), but their\ninference cost remains a significant challenge due to the large number of\nvision tokens processed during the prefill stage. Existing pruning methods\noften rely on directly using the attention patterns or static text prompt\nguidance, failing to exploit the dynamic internal signals generated during\ninference. To address these issues, we propose AdaptInfer, a plug-and-play\nframework for adaptive vision token pruning in VLMs. First, we introduce a\nfine-grained, dynamic text-guided pruning mechanism that reuses layer-wise\ntext-to-text attention maps to construct soft priors over text-token\nimportance, allowing more informed scoring of vision tokens at each stage.\nSecond, we perform an offline analysis of cross-modal attention shifts and\nidentify consistent inflection locations in inference, which inspire us to\npropose a more principled and efficient pruning schedule. Our method is\nlightweight and plug-and-play, also generalizable across multi-modal tasks.\nExperimental results have verified the effectiveness of the proposed method.\nFor example, it reduces CUDA latency by 61.3\\% while maintaining an average\naccuracy of 92.9\\% on vanilla LLaVA-1.5-7B. Under the same token budget,\nAdaptInfer surpasses SOTA in accuracy.", "AI": {"tldr": "AdaptInfer is a plug-and-play framework targeting the reduction of inference costs in vision-language models by introducing a dynamic text-guided pruning technique and an efficient pruning schedule.", "motivation": "Vision-language models excel in multimodal reasoning but struggle with high inference costs due to excessive vision token processing. Existing methods fail to leverage dynamic internal inference signals, necessitating a more adaptive pruning approach.", "method": "AdaptInfer uses a dynamic text-guided pruning mechanism that harnesses layer-wise text-to-text attention maps to prioritize important vision tokens. Additionally, it employs an optimized pruning schedule inspired by cross-modal attention shift patterns identified through offline analysis.", "result": "AdaptInfer significantly reduces CUDA latency by 61.3% while maintaining an accuracy of 92.9% on LLaVA-1.5-7B. It also outperforms state-of-the-art methods in accuracy under the same token budget.", "conclusion": "The proposed framework is lightweight, efficient, and generalizable, offering substantial improvements in multimodal reasoning tasks without sacrificing performance, making it a valuable advancement in vision-language models."}}
{"id": "2508.06361", "pdf": "https://arxiv.org/pdf/2508.06361", "abs": "https://arxiv.org/abs/2508.06361", "authors": ["Zhaomin Wu", "Mingzhe Du", "See-Kiong Ng", "Bingsheng He"], "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been widely deployed in reasoning,\nplanning, and decision-making tasks, making their trustworthiness a critical\nconcern. The potential for intentional deception, where an LLM deliberately\nfabricates or conceals information to serve a hidden objective, remains a\nsignificant and underexplored threat. Existing studies typically induce such\ndeception by explicitly setting a \"hidden\" objective through prompting or\nfine-tuning, which may not fully reflect real-world human-LLM interactions.\nMoving beyond this human-induced deception, we investigate LLMs' self-initiated\ndeception on benign prompts. To address the absence of ground truth in this\nevaluation, we propose a novel framework using \"contact searching questions.\"\nThis framework introduces two statistical metrics derived from psychological\nprinciples to quantify the likelihood of deception. The first, the Deceptive\nIntention Score, measures the model's bias towards a hidden objective. The\nsecond, Deceptive Behavior Score, measures the inconsistency between the LLM's\ninternal belief and its expressed output. Upon evaluating 14 leading LLMs, we\nfind that both metrics escalate as task difficulty increases, rising in\nparallel for most models. Building on these findings, we formulate a\nmathematical model to explain this behavior. These results reveal that even the\nmost advanced LLMs exhibit an increasing tendency toward deception when\nhandling complex problems, raising critical concerns for the deployment of LLM\nagents in complex and crucial domains.", "AI": {"tldr": "The paper investigates self-initiated deception in Large Language Models (LLMs), introducing two metrics to measure deception tendencies, finding that deception increases with task complexity.", "motivation": "The study aims to address trustworthiness concerns of LLMs, specifically the unexplored threat of self-initiated deception in real-world benign prompts.", "method": "A novel framework using 'contact searching questions' introduces two metrics: Deceptive Intention Score and Deceptive Behavior Score, evaluated across 14 leading LLMs.", "result": "Findings reveal that deception tendencies, as quantified by the two metrics, escalate parallelly with task complexity in most examined LLMs.", "conclusion": "The increasing propensity for deception in advanced LLMs during complex problems raises critical concerns about their deployment in high-stakes domains."}}
{"id": "2508.06482", "pdf": "https://arxiv.org/pdf/2508.06482", "abs": "https://arxiv.org/abs/2508.06482", "authors": ["Yilun Hua", "Evan Wang", "Yoav Artzi"], "title": "Post-training for Efficient Communication via Convention Formation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to COLM 2025", "summary": "Humans communicate with increasing efficiency in multi-turn interactions, by\nadapting their language and forming ad-hoc conventions. In contrast, prior work\nshows that LLMs do not naturally show this behavior. We develop a post-training\nprocess to develop this ability through targeted fine-tuning on heuristically\nidentified demonstrations of convention formation. We evaluate with two new\nbenchmarks focused on this capability. First, we design a focused,\ncognitively-motivated interaction benchmark that consistently elicits strong\nconvention formation trends in humans. Second, we create a new\ndocument-grounded reference completion task that reflects in-the-wild\nconvention formation behavior. Our studies show significantly improved\nconvention formation abilities in post-trained LLMs across the two evaluation\nmethods.", "AI": {"tldr": "The paper addresses the limitation of LLMs in naturally adapting language for convention formation, proposing targeted fine-tuning and introducing two benchmarks to successfully improve this capability.", "motivation": "Prior research indicates that unlike humans, LLMs do not naturally adapt their language or create ad-hoc conventions in multi-turn interactions. The paper aims to solve this limitation for enhancing language interaction capabilities.", "method": "The authors use a post-training process involving targeted fine-tuning on demonstrations of convention formation, with two new evaluation methods: interaction benchmark and document-grounded reference completion task.", "result": "Post-trained LLMs show significantly improved convention formation abilities, as evidenced by performance in cognitively motivated benchmarks and real-world-inspired tasks.", "conclusion": "Targeted fine-tuning enhances LLMs' ability to form ad-hoc language conventions, effectively bridging a gap between human and LLM interaction efficiencies."}}
{"id": "2508.05664", "pdf": "https://arxiv.org/pdf/2508.05664", "abs": "https://arxiv.org/abs/2508.05664", "authors": ["Hei Yu Chan", "Kuok Tou Ho", "Chenglong Ma", "Yujing Si", "Hok Lai Lin", "Sa Lei Lam"], "title": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.m"], "comment": "6 pages", "summary": "Many AI customer service systems use standard NLP pipelines or finetuned\nlanguage models, which often fall short on ambiguous, multi-intent, or\ndetail-specific queries. This case study evaluates recent techniques: query\nrewriting, RAG Fusion, keyword augmentation, intent recognition, and context\nreranking, for building a robust customer support system in the electric power\ndomain. We compare vector-store and graph-based RAG frameworks, ultimately\nselecting the graph-based RAG for its superior performance in handling complex\nqueries. We find that query rewriting improves retrieval for queries using\nnon-standard terminology or requiring precise detail. RAG Fusion boosts\nperformance on vague or multifaceted queries by merging multiple retrievals.\nReranking reduces hallucinations by filtering irrelevant contexts. Intent\nrecognition supports the decomposition of complex questions into more targeted\nsub-queries, increasing both relevance and efficiency. In contrast, keyword\naugmentation negatively impacts results due to biased keyword selection. Our\nfinal system combines intent recognition, RAG Fusion, and reranking to handle\ndisambiguation and multi-source queries. Evaluated on both a GPT-4-generated\ndataset and a real-world electricity provider FAQ dataset, it achieves 97.9%\nand 89.6% accuracy respectively, substantially outperforming baseline RAG\nmodels.", "AI": {"tldr": "The study evaluates AI techniques\u2014query rewriting, RAG Fusion, intent recognition, and reranking\u2014and selects a graph-based RAG framework to build an advanced customer support system for the electric power domain, achieving high accuracy.", "motivation": "Customer service AI systems struggle with ambiguous, multi-intent, or detail-specific queries, necessitating improved methods for handling such complexity.", "method": "The study compared vector-store and graph-based RAG frameworks while applying query rewriting, RAG Fusion, keyword augmentation, intent recognition, and context reranking techniques.", "result": "The graph-based RAG framework was superior in handling complex queries. Critical components like query rewriting, RAG Fusion, and intent recognition improved the system's performance, reaching 97.9% accuracy on a GPT-4 dataset and 89.6% on a real-world dataset.", "conclusion": "Combining intent recognition, RAG Fusion, and reranking creates a robust solution for complex, ambiguous queries in customer support, outperforming baseline models."}}
{"id": "2508.06092", "pdf": "https://arxiv.org/pdf/2508.06092", "abs": "https://arxiv.org/abs/2508.06092", "authors": ["Yachun Mi", "Yu Li", "Yanting Li", "Shixin Sun", "Chen Hui", "Tong Zhang", "Yuanyuan Liu", "Chenyue Song", "Shaohui Liu"], "title": "Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate and efficient Video Quality Assessment (VQA) has long been a key\nresearch challenge. Current mainstream VQA methods typically improve\nperformance by pretraining on large-scale classification datasets (e.g.,\nImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this\nstrategy presents two significant challenges: (1) merely transferring semantic\nknowledge learned from pretraining is insufficient for VQA, as video quality\ndepends on multiple factors (e.g., semantics, distortion, motion, aesthetics);\n(2) pretraining on large-scale datasets demands enormous computational\nresources, often dozens or even hundreds of times greater than training\ndirectly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown\nremarkable generalization capabilities across a wide range of visual tasks, and\nhave begun to demonstrate promising potential in quality assessment. In this\nwork, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP\nenhances both visual and textual representations through a Shared Cross-Modal\nAdapter (SCMA), which contains only a minimal number of trainable parameters\nand is the only component that requires training. This design significantly\nreduces computational cost. In addition, we introduce a set of five learnable\nquality-level prompts to guide the VLMs in perceiving subtle quality\nvariations, thereby further enhancing the model's sensitivity to video quality.\nFurthermore, we investigate the impact of different frame sampling strategies\non VQA performance, and find that frame-difference-based sampling leads to\nbetter generalization performance across datasets. Extensive experiments\ndemonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.", "AI": {"tldr": "The authors introduce Q-CLIP, a cost-efficient VQA framework built around Vision-Language Models, which eliminates the need for extensive pretraining and incorporates mechanisms to enhance sensitivity to video quality variations.", "motivation": "Accurate Video Quality Assessment is challenging due to the reliance on computationally expensive pretraining on large datasets and the insufficiency of semantic knowledge transfer for the nuanced factors impacting video quality.", "method": "The proposed Q-CLIP framework utilizes Vision-Language Models with a Shared Cross-Modal Adapter (SCMA) to optimize visual and textual representations. The approach incorporates trainable prompts to focus on video quality nuances and explores efficient frame sampling strategies.", "result": "Q-CLIP achieves high performance on multiple VQA datasets while significantly reducing computational demands compared to conventional methods.", "conclusion": "Q-CLIP establishes itself as an efficient and robust VQA solution by leveraging VLMs with minimal training requirements and introducing techniques to enhance video quality sensitivity."}}
{"id": "2508.06364", "pdf": "https://arxiv.org/pdf/2508.06364", "abs": "https://arxiv.org/abs/2508.06364", "authors": ["Renyi Zhou", "Huimin Zhu", "Jing Tang", "Min Li"], "title": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Achieving precise control over a molecule's biological activity-encompassing\ntargeted activation/inhibition, cooperative multi-target modulation, and\noff-target toxicity mitigation-remains a critical challenge in de novo drug\ndesign. However, existing generative methods primarily focus on producing\nmolecules with a single desired activity, lacking integrated mechanisms for the\nsimultaneous management of multiple intended and unintended molecular\ninteractions. Here, we propose ActivityDiff, a generative approach based on the\nclassifier-guidance technique of diffusion models. It leverages separately\ntrained drug-target classifiers for both positive and negative guidance,\nenabling the model to enhance desired activities while minimizing harmful\noff-target effects. Experimental results show that ActivityDiff effectively\nhandles essential drug design tasks, including single-/dual-target generation,\nfragment-constrained dual-target design, selective generation to enhance target\nspecificity, and reduction of off-target effects. These results demonstrate the\neffectiveness of classifier-guided diffusion in balancing efficacy and safety\nin molecular design. Overall, our work introduces a novel paradigm for\nachieving integrated control over molecular activity, and provides ActivityDiff\nas a versatile and extensible framework.", "AI": {"tldr": "This paper introduces ActivityDiff, a new drug design method using classifier-guided diffusion models to control targeted molecular activity and mitigate off-target toxicity.", "motivation": "The authors aim to address the challenge of achieving precise control over multifaceted molecular behaviors (targeted activation/inhibition, multi-target efficacy, and toxicity mitigation) in drug design.", "method": "ActivityDiff uses classifier-guidance in diffusion models, which leverage drug-target classifiers to guide molecular generation positively (desired activities) and negatively (reduce harmful effects).", "result": "ActivityDiff demonstrated strong performance in critical design tasks such as dual-target generation, selective target enhancement, and off-target toxicity reduction.", "conclusion": "This approach effectively balances drug efficacy and safety, offering a novel framework with potential extensions for integrated molecular activity control in drug design."}}
{"id": "2508.05666", "pdf": "https://arxiv.org/pdf/2508.05666", "abs": "https://arxiv.org/abs/2508.05666", "authors": ["Alejandro Godinez"], "title": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis", "categories": ["cs.IR", "cs.AI", "cs.LG", "I.2.7; H.3.3; I.2.6; H.2.8; I.7.5"], "comment": "47 pages, 10 figures. Code:\n  https://github.com/agodinezmm2007/docling_mod. Demo:\n  https://youtu.be/ZCy5ESJ1gVE?si=K8CttwgTj7yGrWjn. ETL+multi-agent RAG\n  framework for literature synthesis, 35.1% improvement over PDF chunking. Real\n  application: reduced 17,400 papers to 24 relevant ones (99.86%) in 10 minutes\n  for wastewater epidemiology review", "summary": "We present HySemRAG, a framework that combines Extract, Transform, Load (ETL)\npipelines with Retrieval-Augmented Generation (RAG) to automate large-scale\nliterature synthesis and identify methodological research gaps. The system\naddresses limitations in existing RAG architectures through a multi-layered\napproach: hybrid retrieval combining semantic search, keyword filtering, and\nknowledge graph traversal; an agentic self-correction framework with iterative\nquality assurance; and post-hoc citation verification ensuring complete\ntraceability. Our implementation processes scholarly literature through eight\nintegrated stages: multi-source metadata acquisition, asynchronous PDF\nretrieval, custom document layout analysis using modified Docling architecture,\nbibliographic management, LLM-based field extraction, topic modeling, semantic\nunification, and knowledge graph construction. The system creates dual data\nproducts - a Neo4j knowledge graph enabling complex relationship queries and\nQdrant vector collections supporting semantic search - serving as foundational\ninfrastructure for verifiable information synthesis. Evaluation across 643\nobservations from 60 testing sessions demonstrates structured field extraction\nachieving 35.1% higher semantic similarity scores (0.655 $\\pm$ 0.178) compared\nto PDF chunking approaches (0.485 $\\pm$ 0.204, p < 0.000001). The agentic\nquality assurance mechanism achieves 68.3% single-pass success rates with 99.0%\ncitation accuracy in validated responses. Applied to geospatial epidemiology\nliterature on ozone exposure and cardiovascular disease, the system identifies\nmethodological trends and research gaps, demonstrating broad applicability\nacross scientific domains for accelerating evidence synthesis and discovery.", "AI": {"tldr": "HySemRAG is an ETL-RAG framework that automates large-scale literature synthesis, identifying research gaps and achieving high accuracy in citation verification.", "motivation": "The study aims to improve RAG architectures for automated literature synthesis, addressing limitations in traceability, semantic understanding, and scalability.", "method": "HySemRAG employs hybrid retrieval (semantic search, keyword filtering, knowledge graphs), LLM-based field extraction, and quality assurance mechanisms across an 8-stage pipeline for processing scholarly literature.", "result": "The system outperforms traditional approaches in semantic similarity by 35.1%, achieves 99.0% citation accuracy, and demonstrates applicability in identifying trends in specific domains like geospatial epidemiology.", "conclusion": "HySemRAG is a robust infrastructure for automating evidence synthesis, offering traceable, highly accurate, and scalable solutions for identifying methodological trends and gaps across diverse scientific fields."}}
{"id": "2508.06093", "pdf": "https://arxiv.org/pdf/2508.06093", "abs": "https://arxiv.org/abs/2508.06093", "authors": ["Chen Zhu", "Buzhen Huang", "Zijing Wu", "Binghui Zuo", "Yangang Wang"], "title": "E-React: Towards Emotionally Controlled Synthesis of Human Reactions", "categories": ["cs.CV"], "comment": null, "summary": "Emotion serves as an essential component in daily human interactions.\nExisting human motion generation frameworks do not consider the impact of\nemotions, which reduces naturalness and limits their application in interactive\ntasks, such as human reaction synthesis. In this work, we introduce a novel\ntask: generating diverse reaction motions in response to different emotional\ncues. However, learning emotion representation from limited motion data and\nincorporating it into a motion generation framework remains a challenging\nproblem. To address the above obstacles, we introduce a semi-supervised emotion\nprior in an actor-reactor diffusion model to facilitate emotion-driven reaction\nsynthesis. Specifically, based on the observation that motion clips within a\nshort sequence tend to share the same emotion, we first devise a\nsemi-supervised learning framework to train an emotion prior. With this prior,\nwe further train an actor-reactor diffusion model to generate reactions by\nconsidering both spatial interaction and emotional response. Finally, given a\nmotion sequence of an actor, our approach can generate realistic reactions\nunder various emotional conditions. Experimental results demonstrate that our\nmodel outperforms existing reaction generation methods. The code and data will\nbe made publicly available at https://ereact.github.io/", "AI": {"tldr": "The paper introduces a method for generating human reaction motions influenced by emotional cues using a semi-supervised emotion prior and an actor-reactor diffusion model, outperforming existing methods.", "motivation": "Existing motion generation techniques lack consideration of emotions, making them less natural and restricting their use in interactive tasks.", "method": "A semi-supervised learning framework is used to train an emotion prior, integrated with an actor-reactor diffusion model for emotion-driven reaction synthesis.", "result": "The approach generates realistic reaction motions in different emotional contexts and surpasses current reaction generation methods in performance.", "conclusion": "The model effectively integrates emotional cues into motion generation frameworks, advancing human-like interaction synthesis for practical applications."}}
{"id": "2508.06387", "pdf": "https://arxiv.org/pdf/2508.06387", "abs": "https://arxiv.org/abs/2508.06387", "authors": ["Anurag Tripathi", "Vaibhav Patle", "Abhinav Jain", "Ayush Pundir", "Sairam Menon", "Ajeet Kumar Singh"], "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IJCNN25", "summary": "Text-to-SQL bridges the gap between natural language and structured database\nlanguage, thus allowing non-technical users to easily query databases.\nTraditional approaches model text-to-SQL as a direct translation task, where a\ngiven Natural Language Query (NLQ) is mapped to an SQL command. Recent advances\nin large language models (LLMs) have significantly improved translation\naccuracy, however, these methods all require that the target database is\npre-specified. This becomes problematic in scenarios with multiple extensive\ndatabases, where identifying the correct database becomes a crucial yet\noverlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL\nframework to identify the user's intended database before generating SQL\nqueries. Our approach leverages LLMs and prompt engineering to extract implicit\ninformation from natural language queries (NLQs) in the form of a ruleset. We\nthen train a large db\\_id prediction model, which includes a RoBERTa-based\nfinetuned encoder, to predict the correct Database identifier (db\\_id) based on\nboth the NLQ and the LLM-generated rules. Finally, we refine the generated SQL\nby using critic agents to correct errors. Experimental results demonstrate that\nour framework outperforms the current state-of-the-art models in both database\nintent prediction and SQL generation accuracy.", "AI": {"tldr": "The paper introduces a three-stage framework for the Text-to-SQL task, improving accuracy by first predicting the target database identifier (db_id) before generating SQL queries.", "motivation": "To address challenges in Text-to-SQL scenarios where the user's intended database is not pre-specified, which can be problematic when multiple databases are involved.", "method": "They use a three-stage framework: 1) Extract implicit database-related information via LLMs and prompt engineering. 2) Train a RoBERTa-based encoder for database identifier (db_id) prediction. 3) Refine SQL generation using critic agents for error correction.", "result": "The proposed framework achieves better database intent prediction and SQL generation accuracy, surpassing current state-of-the-art models.", "conclusion": "The approach demonstrates the importance of database selection in Text-to-SQL tasks and shows that incorporating database intent prediction and error refinement leads to improved performance in querying tasks."}}
{"id": "2508.05667", "pdf": "https://arxiv.org/pdf/2508.05667", "abs": "https://arxiv.org/abs/2508.05667", "authors": ["Zekun Liu", "Xiaowen Huang", "Jitao Sang"], "title": "ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated outstanding performance in\nnatural language processing tasks. However, in the field of recommendation\nsystems, due to the structural differences between user behavior data and\nnatural language, LLMs struggle to effectively model the associations between\nuser preferences and items. Although prompt-based methods can generate\nrecommendation results, their inadequate understanding of recommendation tasks\nleads to constrained performance. To address this gap, in this work, we\nconstruct a sufficient instruction tuning dataset, ITDR, which encompasses 7\nsubtasks across two core root tasks--user-item interaction and user-item\nunderstanding. The dataset integrates data from 13 public recommendation\ndatasets and is built using manually crafted standardized templates, comprising\napproximately 200,000 instances. Experimental results demonstrate that ITDR\nsignificantly enhances the performance of mainstream open-source LLMs such as\nGLM-4, Qwen2.5, Qwen2.5-Instruct and LLaMA-3.2 on recommendation tasks.\nFurthermore, we analyze the correlations between tasks and explore the impact\nof task descriptions and data scale on instruction tuning effectiveness.\nFinally, we perform comparative experiments against closed-source LLMs with\nsubstantial parameters. Our tuning dataset ITDR and the fine-tuned large\nrecommendation models can be accessed at https://github.com/hellolzk/ITDR.", "AI": {"tldr": "Large language models (LLMs) struggle with recommendation tasks due to structural data differences. This paper introduces ITDR, a robust instruction tuning dataset, to enhance LLMs' recommendation capabilities.", "motivation": "To bridge the gap in LLM performance on recommendation tasks caused by differences between user behavior data and natural language data.", "method": "A comprehensive instruction tuning dataset called ITDR was created, incorporating data from 13 public datasets and consisting of 200,000 instances derived from two root tasks and 7 subtasks.", "result": "Experimental results show that ITDR improved the recommendation performance of mainstream open-source LLMs like GLM-4 and LLaMA-3.2. Further experiments analyzed task correlations, data scale, and compared against closed-source LLMs.", "conclusion": "Constructing an instruction tuning dataset tailored to recommendation tasks can significantly enhance the performance of LLMs in this domain. The dataset and fine-tuned models are publicly available."}}
{"id": "2508.06101", "pdf": "https://arxiv.org/pdf/2508.06101", "abs": "https://arxiv.org/abs/2508.06101", "authors": ["Yachun Mi", "Xingyang He", "Shixin Sun", "Yu Li", "Yanting Li", "Zhixuan Li", "Jian Jin", "Chen Hui", "Shaohui Liu"], "title": "UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization", "categories": ["cs.CV"], "comment": null, "summary": "In the digital age, advanced image editing tools pose a serious threat to the\nintegrity of visual content, making image forgery detection and localization a\nkey research focus. Most existing Image Manipulation Localization (IML) methods\nrely on discriminative learning and require large, high-quality annotated\ndatasets. However, current datasets lack sufficient scale and diversity,\nlimiting model performance in real-world scenarios. To overcome this, recent\nstudies have explored Constrained IML (CIML), which generates pixel-level\nannotations through algorithmic supervision. However, existing CIML approaches\noften depend on complex multi-stage pipelines, making the annotation process\ninefficient. In this work, we propose a novel generative framework based on\ndiffusion models, named UGD-IML, which for the first time unifies both IML and\nCIML tasks within a single framework. By learning the underlying data\ndistribution, generative diffusion models inherently reduce the reliance on\nlarge-scale labeled datasets, allowing our approach to perform effectively even\nunder limited data conditions. In addition, by leveraging a class embedding\nmechanism and a parameter-sharing design, our model seamlessly switches between\nIML and CIML modes without extra components or training overhead. Furthermore,\nthe end-to-end design enables our model to avoid cumbersome steps in the data\nannotation process. Extensive experimental results on multiple datasets\ndemonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and\n4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the\nproposed method also excels in uncertainty estimation, visualization and\nrobustness.", "AI": {"tldr": "The paper introduces UGD-IML, a unified generative framework for image manipulation detection and constrained annotation using diffusion models. It achieves superior performance in accuracy and efficiency compared to state-of-the-art methods.", "motivation": "With the increased threat to visual content integrity due to advanced image editing tools, existing image forgery detection methods are limited by dataset scale, diversity, and inefficiency in annotation processes.", "method": "The paper proposes UGD-IML, a generative diffusion model framework integrating IML and CIML tasks with a class embedding mechanism and parameter-sharing design. The model avoids multi-stage pipelines and reduces reliance on large-scale datasets.", "result": "UGD-IML surpasses state-of-the-art techniques in F1 metrics for IML and CIML tasks by 9.66 and 4.36, respectively, and demonstrates strong performance in uncertainty estimation, visualization, and robustness.", "conclusion": "The proposed approach effectively addresses limitations of existing methods, offering a unified, efficient, and high-performing solution for both image manipulation detection and constrained annotation tasks."}}
{"id": "2508.06409", "pdf": "https://arxiv.org/pdf/2508.06409", "abs": "https://arxiv.org/abs/2508.06409", "authors": ["Wooyong Jung", "Sola Kim", "Dongwook Kim", "Maryam Tabar", "Dongwon Lee"], "title": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images", "categories": ["cs.LG"], "comment": "10 pages, Accepted to SBP-BRiMS 2025", "summary": "Homelessness in the United States has surged to levels unseen since the Great\nDepression. However, existing methods for monitoring it, such as point-in-time\n(PIT) counts, have limitations in terms of frequency, consistency, and spatial\ndetail. This study proposes a new approach using publicly available,\ncrowdsourced data, specifically 311 Service Calls and street-level imagery, to\ntrack and forecast homeless tent trends in San Francisco. Our predictive model\ncaptures fine-grained daily and neighborhood-level variations, uncovering\npatterns that traditional counts often overlook, such as rapid fluctuations\nduring the COVID-19 pandemic and spatial shifts in tent locations over time. By\nproviding more timely, localized, and cost-effective information, this approach\nserves as a valuable tool for guiding policy responses and evaluating\ninterventions aimed at reducing unsheltered homelessness.", "AI": {"tldr": "This paper introduces a novel method using 311 Service Calls and street-level imagery data to track and predict homelessness tent trends in San Francisco with fine-grained spatial and temporal detail.", "motivation": "Existing methods for monitoring homelessness, like PIT counts, lack frequency, consistency, and detailed spatial resolution.", "method": "The study utilizes 311 Service Calls and street-level imagery data to create a predictive model that captures daily and neighborhood-level variations in homeless tent trends.", "result": "The model reveals nuanced trends overlooked by traditional methods, such as fluctuations during the COVID-19 pandemic and shifts in tent locations.", "conclusion": "This approach offers a more timely, localized, and cost-effective method for informing homelessness policy responses and evaluating interventions."}}
{"id": "2508.05668", "pdf": "https://arxiv.org/pdf/2508.05668", "abs": "https://arxiv.org/abs/2508.05668", "authors": ["Yunjia Xi", "Jianghao Lin", "Yongzhao Xiao", "Zheli Zhou", "Rong Shan", "Te Gao", "Jiachen Zhu", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "title": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "The advent of Large Language Models (LLMs) has significantly revolutionized\nweb search. The emergence of LLM-based Search Agents marks a pivotal shift\ntowards deeper, dynamic, autonomous information seeking. These agents can\ncomprehend user intentions and environmental context and execute multi-turn\nretrieval with dynamic planning, extending search capabilities far beyond the\nweb. Leading examples like OpenAI's Deep Research highlight their potential for\ndeep information mining and real-world applications. This survey provides the\nfirst systematic analysis of search agents. We comprehensively analyze and\ncategorize existing works from the perspectives of architecture, optimization,\napplication, and evaluation, ultimately identifying critical open challenges\nand outlining promising future research directions in this rapidly evolving\nfield. Our repository is available on\nhttps://github.com/YunjiaXi/Awesome-Search-Agent-Papers.", "AI": {"tldr": "Large Language Model-based Search Agents significantly enhance web search with dynamic planning and multi-turn retrieval capabilities. This survey systematically categorizes research in this field and highlights future challenges and directions.", "motivation": "To address the growing capabilities of LLM-based Search Agents and their extensive applications in deeper, autonomous information retrieval.", "method": "Systematically analyzing and categorizing existing literature in terms of architecture, optimization, application, and evaluation, while providing a curated repository.", "result": "Critical challenges and promising research directions in LLM-based search agents are identified, providing a roadmap for advancement.", "conclusion": "LLM-based search agents represent a transformative approach to information retrieval, warranting further research to tackle challenges and unlock their full potential."}}
{"id": "2508.06104", "pdf": "https://arxiv.org/pdf/2508.06104", "abs": "https://arxiv.org/abs/2508.06104", "authors": ["Gui Zou", "Chaofan Gan", "Chern Hong Lim", "Supavadee Aramvith", "Weiyao Lin"], "title": "MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment", "categories": ["cs.CV"], "comment": "ICMEW 2025", "summary": "With the increasing availability of 2D and 3D data, significant advancements\nhave been made in the field of cross-modal retrieval. Nevertheless, the\nexistence of imperfect annotations presents considerable challenges, demanding\nrobust solutions for 2D-3D cross-modal retrieval in the presence of noisy label\nconditions. Existing methods generally address the issue of noise by dividing\nsamples independently within each modality, making them susceptible to\noverfitting on corrupted labels. To address these issues, we propose a robust\n2D-3D \\textbf{M}ulti-level cross-modal adaptive \\textbf{C}orrection and\n\\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal\nJoint label Correction (MJC) mechanism that leverages multimodal historical\nself-predictions to jointly model the modality prediction consistency, enabling\nreliable label refinement. Additionally, we propose a Multi-level Adaptive\nAlignment (MAA) strategy to effectively enhance cross-modal feature semantics\nand discrimination across different levels. Extensive experiments demonstrate\nthe superiority of our method, MCA, which achieves state-of-the-art performance\non both conventional and realistic noisy 3D benchmarks, highlighting its\ngenerality and effectiveness.", "AI": {"tldr": "This paper introduces MCA, a robust framework for 2D-3D cross-modal retrieval under noisy label conditions, using multimodal label correction and adaptive alignment strategies.", "motivation": "Existing 2D-3D cross-modal retrieval methods are vulnerable to overfitting due to noisy labels, highlighting the need for robust solutions.", "method": "The proposed MCA framework includes a Multimodal Joint label Correction mechanism to refine labels using historical self-predictions and a Multi-level Adaptive Alignment strategy to improve cross-modal feature semantics and discrimination.", "result": "MCA achieves state-of-the-art performance on both conventional and realistic noisy 3D benchmarks, demonstrating its effectiveness.", "conclusion": "MCA is a general and effective solution for robust 2D-3D cross-modal retrieval, particularly under noisy label conditions."}}
{"id": "2508.06412", "pdf": "https://arxiv.org/pdf/2508.06412", "abs": "https://arxiv.org/abs/2508.06412", "authors": ["Zichuan Liu", "Jinyu Wang", "Lei Song", "Jiang Bian"], "title": "Sample-efficient LLM Optimization with Reset Replay", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent advancements in post-training Large Language Models (LLMs),\nparticularly through Reinforcement Learning (RL) and preference optimization\nmethods, are key drivers for enhancing their reasoning capabilities. However,\nthese methods are often plagued by low sample efficiency and a susceptibility\nto primacy bias, where overfitting to initial experiences degrades policy\nquality and damages the learning process. To address these challenges, we\nintroduce LLM optimization with Reset Replay (LoRR), a general and powerful\nplugin designed to enhance sample efficiency in any preference-based\noptimization framework. LoRR core mechanism enables training at a high replay\nnumber, maximizing the utility of each collected data batch. To counteract the\nrisk of overfitting inherent in high-replay training, LoRR incorporates a\nperiodic reset strategy with reusing initial data, which preserves network\nplasticity. Furthermore, it leverages a hybrid optimization objective,\ncombining supervised fine-tuning (SFT) and preference-based losses to further\nbolster data exploitation. Our extensive experiments demonstrate that LoRR\nsignificantly boosts the performance of various preference optimization methods\non both mathematical and general reasoning benchmarks. Notably, an iterative\nDPO approach augmented with LoRR achieves comparable performance on challenging\nmath tasks, outperforming some complex and computationally intensive RL-based\nalgorithms. These findings highlight that LoRR offers a practical,\nsample-efficient, and highly effective paradigm for LLM finetuning, unlocking\ngreater performance from limited data.", "AI": {"tldr": "The paper introduces LoRR, a method for more sample-efficient and effective large language model tuning, particularly in reasoning tasks.", "motivation": "To improve reasoning capabilities in LLMs while addressing issues like low sample efficiency and primacy bias in current optimization methods.", "method": "LoRR combines high-replay training with a reset-and-reuse strategy for initial data and a hybrid optimization objective utilizing both supervised fine-tuning and preference-based losses.", "result": "LoRR significantly enhances performance in preference optimization methods, achieving results comparable to complex RL-based algorithms on challenging tasks.", "conclusion": "LoRR provides a practical, efficient, and effective approach for finetuning LLMs, demonstrating its utility in unlocking higher performance using limited data."}}
{"id": "2508.05669", "pdf": "https://arxiv.org/pdf/2508.05669", "abs": "https://arxiv.org/abs/2508.05669", "authors": ["Jin Khye Tan", "En Jun Choong", "Ethan Jeremiah Chitty", "Yan Pheng Choo", "John Hsin Yang Wong", "Chern Eu Cheah"], "title": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV", "cs.LG", "I.2.7; I.7.2; J.1"], "comment": "28 pages, 14 figures, 5 tables. Evaluation code (LLM-as-a-judge and\n  Markdown TEDS) is available at https://github.com/jinkhye/MyFinMarkdown. The\n  development dataset and evaluation benchmark are available on Hugging Face at\n  https://huggingface.co/datasets/jinkhye/MyFinMarkdown-sample and\n  https://huggingface.co/datasets/jinkhye/MyFinMarkdown-bench respectively", "summary": "Accurately extracting and representing the structure of tabular data from\nfinancial documents remains a critical challenge in document understanding,\nparticularly for regulatory and analytical use cases. This study addresses the\ncomplexity of converting financial tables from Malaysian audited financial\nreports into Markdown format, a task complicated by rotated layouts,\nmulti-level headers, and implicit structural cues. We propose a fine-tuned\nvision-language model (VLM), based on Qwen2.5-VL-7B, optimized for\nhigh-fidelity Markdown generation from document images. Our approach includes a\ncurated dataset of 2,152 image-text pairs with augmentations and a supervised\nfine-tuning strategy using LoRA. To assess performance, we evaluated our model\non 100 out-of-sample tables using a dual framework: a criteria-based\nLLM-as-a-judge for fine-grained accuracy and our novel Markdown\nTree-Edit-Distance-based Similarity (TEDS) metric for holistic structural\nfidelity. Our model achieves a 92.20% overall accuracy on the criteria-based\nassessment and a 96.53% Markdown TEDS score. This performance significantly\nsurpasses its Qwen2.5-VL-7B base model, larger-scale VLMs, and specialized\nreasoning-enabled models. Compared to these self-hosted alternatives, it also\nsignificantly reduces inference time. Furthermore, its accuracy exceeds that of\nwidely used proprietary models such as OpenAI's GPT-4o and Gemini 2.5 Flash.\nThese results demonstrate that domain-specific fine-tuning provides an\neffective and efficient method to bridge the gap between unstructured financial\ndocuments and downstream automation, rivalling much larger and more general\nmodels without their computational overhead.", "AI": {"tldr": "The paper proposes a fine-tuned vision-language model to convert complex financial tables into Markdown with high accuracy and efficiency.", "motivation": "Financial documents often contain complex tabular data essential for regulatory and analytical tasks, but accurately extracting and representing this data remains a challenge.", "method": "The study uses a fine-tuned VLM based on Qwen2.5-VL-7B, trained on a curated dataset of 2,152 image-text pairs with LoRA supervision and assessed using a criteria-based LLM and Markdown TEDS metric.", "result": "The proposed model achieved 92.20% accuracy on criteria-based assessment and 96.53% Markdown TEDS score, outperforming baseline models, larger VLMs, and proprietary systems like GPT-4o and Gemini.", "conclusion": "Domain-specific fine-tuning is efficient for extracting and converting unstructured financial data with high accuracy, rivaling larger general models while minimizing computational costs."}}
{"id": "2508.06107", "pdf": "https://arxiv.org/pdf/2508.06107", "abs": "https://arxiv.org/abs/2508.06107", "authors": ["Shree Mitra", "Ritabrata Chakraborty", "Nilkanta Sahu"], "title": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recognizing handwritten mathematical expressions (HMER) is a challenging task\ndue to the inherent two-dimensional structure, varying symbol scales, and\ncomplex spatial relationships among symbols. In this paper, we present a\nself-supervised learning (SSL) framework for HMER that eliminates the need for\nexpensive labeled data. Our approach begins by pretraining an image encoder\nusing a combination of global and local contrastive loss, enabling the model to\nlearn both holistic and fine-grained representations. A key contribution of\nthis work is a novel self-supervised attention network, which is trained using\na progressive spatial masking strategy. This attention mechanism is designed to\nlearn semantically meaningful focus regions, such as operators, exponents, and\nnested mathematical notation, without requiring any supervision. The\nprogressive masking curriculum encourages the network to become increasingly\nrobust to missing or occluded visual information, ultimately improving\nstructural understanding. Our complete pipeline consists of (1) self-supervised\npretraining of the encoder, (2) self-supervised attention learning, and (3)\nsupervised fine-tuning with a transformer decoder to generate LATEX sequences.\nExtensive experiments on CROHME benchmarks demonstrate that our method\noutperforms existing SSL and fully supervised baselines, validating the\neffectiveness of our progressive attention mechanism in enhancing HMER\nperformance. Our codebase can be found here.", "AI": {"tldr": "The paper introduces a self-supervised learning (SSL) approach for handwriting mathematical expression recognition (HMER) without needing extensive labeled data.", "motivation": "The task of recognizing handwritten mathematical expressions (HMER) is complex due to the two-dimensional structure, symbol variations, and spatial relationships, which require robust solutions.", "method": "The proposed method leverages self-supervised learning with an image encoder pretrained using contrastive loss, a novel progressive spatial masking strategy for self-supervised attention, and supervised fine-tuning using a transformer decoder.", "result": "Experiments on CROHME benchmarks reveal that the proposed approach outperforms existing self-supervised and supervised methods for HMER, particularly due to its robust attention mechanism.", "conclusion": "The paper demonstrates the effectiveness of self-supervised learning combined with a progressive attention mechanism for improving HMER performance and provides an open-source codebase."}}
{"id": "2508.06467", "pdf": "https://arxiv.org/pdf/2508.06467", "abs": "https://arxiv.org/abs/2508.06467", "authors": ["Ameya Anjarlekar", "Sandeep Pombra"], "title": "LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection", "categories": ["cs.LG"], "comment": "14 Pages, 3 Figures, 11 Tables", "summary": "The growing legal and ethical scrutiny of large language models (LLMs)\nnecessitates effective machine unlearning, particularly for sensitive or\nunauthorized data. Existing empirical methods often yield incomplete forgetting\nor unintended degradation of unrelated knowledge due to poor localization. In\nthis work, we propose GRIN: a modular and targeted framework for LLM\nunlearning. GRIN introduces a novel gradient-ratio-based metric to identify\nparameters most responsible for memorizing forget data. We then perform\nselective noise injection into these parameters prior to fine-tuning, which\nimproves unlearning performance while maintaining model utility. Finally, we\npropose new evaluation metrics tailored to the LLM setting and validate our\napproach on standard benchmarks such as TOFU, WMDP, and SafePKU.", "AI": {"tldr": "The paper presents GRIN, a modular framework for targeted unlearning in large language models (LLMs) using a gradient-ratio-based metric for precise parameter adjustment and introduces new evaluation metrics.", "motivation": "To address issues of machine unlearning in LLMs due to sensitive or unauthorized data, ensuring high effectiveness with minimal degradation of unrelated knowledge.", "method": "GRIN employs a gradient-ratio-based metric to locate parameters responsible for memorizing specific data. It introduces selective noise injection into these parameters and proposes new metrics for evaluating unlearning in LLMs.", "result": "Validation using standard benchmarks shows GRIN achieves improved unlearning performance while preserving the overall model utility.", "conclusion": "GRIN provides a robust solution for targeted unlearning in LLMs, balancing effective removal of sensitive data and preserving useful knowledge with improved evaluation mechanisms."}}
{"id": "2508.05671", "pdf": "https://arxiv.org/pdf/2508.05671", "abs": "https://arxiv.org/abs/2508.05671", "authors": ["Ko-Wei Chuang", "Hen-Hsen Huang", "Tsai-Yen Li"], "title": "DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing", "categories": ["cs.CR", "cs.CL"], "comment": "7 pages", "summary": "As large language models (LLMs) and generative AI become increasingly\nintegrated into customer service and moderation applications, adversarial\nthreats emerge from both external manipulations and internal label corruption.\nIn this work, we identify and systematically address these dual adversarial\nthreats by introducing DINA (Dual Defense Against Internal Noise and\nAdversarial Attacks), a novel unified framework tailored specifically for NLP.\nOur approach adapts advanced noisy-label learning methods from computer vision\nand integrates them with adversarial training to simultaneously mitigate\ninternal label sabotage and external adversarial perturbations. Extensive\nexperiments conducted on a real-world dataset from an online gaming service\ndemonstrate that DINA significantly improves model robustness and accuracy\ncompared to baseline models. Our findings not only highlight the critical\nnecessity of dual-threat defenses but also offer practical strategies for\nsafeguarding NLP systems in realistic adversarial scenarios, underscoring\nbroader implications for fair and responsible AI deployment.", "AI": {"tldr": "DINA, a novel framework, addresses dual adversarial threats for NLP systems by merging noisy-label learning and adversarial training, showing improved robustness and accuracy.", "motivation": "The paper aims to address emerging adversarial threats in NLP applications, specifically from external manipulations and internal label corruption in customer service and moderation applications.", "method": "The authors introduce DINA, which combines advanced noisy-label learning methods and adversarial training into a unified framework tailored for NLP.", "result": "Experiments on a real-world dataset from an online gaming service demonstrated that DINA significantly enhanced robustness and accuracy compared to baseline models.", "conclusion": "DINA offers effective strategies to safeguard NLP systems against dual threats, ensuring fair and responsible AI deployment and highlighting the importance of robust defenses in adversarial scenarios."}}
{"id": "2508.05670", "pdf": "https://arxiv.org/pdf/2508.05670", "abs": "https://arxiv.org/abs/2508.05670", "authors": ["Daniele Proverbio", "Alessio Buscemi", "Alessandro Di Stefano", "The Anh Han", "German Castignani", "Pietro Li\u00f2"], "title": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "comment": null, "summary": "Game theory has long served as a foundational tool in cybersecurity to test,\npredict, and design strategic interactions between attackers and defenders. The\nrecent advent of Large Language Models (LLMs) offers new tools and challenges\nfor the security of computer systems; In this work, we investigate whether\nclassical game-theoretic frameworks can effectively capture the behaviours of\nLLM-driven actors and bots. Using a reproducible framework for game-theoretic\nLLM agents, we investigate two canonical scenarios -- the one-shot zero-sum\ngame and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to\nexpected outcomes or exhibit deviations due to embedded biases. Our experiments\ninvolve four state-of-the-art LLMs and span five natural languages, English,\nFrench, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic\nsensitivity. For both games, we observe that the final payoffs are influenced\nby agents characteristics such as personality traits or knowledge of repeated\nrounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to\nthe choice of languages, which should warn against indiscriminate application\nof LLMs in cybersecurity applications and call for in-depth studies, as LLMs\nmay behave differently when deployed in different countries. We also employ\nquantitative metrics to evaluate the internal consistency and cross-language\nstability of LLM agents, to help guide the selection of the most stable LLMs\nand optimising models for secure applications.", "AI": {"tldr": "The paper explores how well classical game theory captures the behavior of LLM-driven agents in cybersecurity contexts, highlighting language-based and agent-specific influences.", "motivation": "The study aims to understand whether classical game theory can effectively model the actions and biases of LLM-driven agents, which are increasingly relevant in cybersecurity.", "method": "The researchers used a reproducible game-theoretic framework to analyze LLM-driven agents across two scenarios: one-shot zero-sum games and dynamic Prisoner's Dilemma, involving four LLMs in five languages.", "result": "LLMs displayed sensitivity to personality traits, repeated rounds, and language choice, influencing the outcomes of the games. This variability poses risks for their indiscriminate use in cybersecurity.", "conclusion": "Game theory frameworks can model LLM behavior but must account for variability arising from agent traits and language-dependent idiosyncrasies to ensure reliable cybersecurity applications."}}
{"id": "2508.06109", "pdf": "https://arxiv.org/pdf/2508.06109", "abs": "https://arxiv.org/abs/2508.06109", "authors": ["Zhibo Zhu", "Renyu Huang", "Lei He"], "title": "FMCE-Net++: Feature Map Convergence Evaluation and Training", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep Neural Networks (DNNs) face interpretability challenges due to their\nopaque internal representations. While Feature Map Convergence Evaluation\n(FMCE) quantifies module-level convergence via Feature Map Convergence Scores\n(FMCS), it lacks experimental validation and closed-loop integration. To\naddress this limitation, we propose FMCE-Net++, a novel training framework that\nintegrates a pretrained, frozen FMCE-Net as an auxiliary head. This module\ngenerates FMCS predictions, which, combined with task labels, jointly supervise\nbackbone optimization through a Representation Auxiliary Loss. The RAL\ndynamically balances the primary classification loss and feature convergence\noptimization via a tunable \\Representation Abstraction Factor. Extensive\nexperiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100\ndemonstrate that FMCE-Net++ consistently enhances model performance without\narchitectural modifications or additional data. Key experimental outcomes\ninclude accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp\n(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate\nstate-of-the-art performance ceilings.", "AI": {"tldr": "FMCE-Net++ introduces a framework to improve DNNs' interpretability and performance by integrating feature map convergence evaluation during training.", "motivation": "To tackle interpretability challenges and enhance the performance of Deep Neural Networks by addressing the limitations of existing Feature Map Convergence Evaluation methods.", "method": "Proposed FMCE-Net++, which uses a pretrained FMCE-Net as an auxiliary head to predict feature convergence during training. A Representation Auxiliary Loss dynamically balances classification and convergence loss.", "result": "Extensive experiments on datasets like MNIST and CIFAR showed improved accuracy, e.g., +1.16 pp for ResNet-50 on CIFAR-10 and +1.08 pp for ShuffleNet v2 on CIFAR-100.", "conclusion": "FMCE-Net++ effectively enhances DNN performance and interpretability without requiring architectural changes or extra data, offering a practical approach to surpassing current performance ceilings."}}
{"id": "2107.06056", "pdf": "https://arxiv.org/pdf/2107.06056", "abs": "https://arxiv.org/abs/2107.06056", "authors": ["Prathamesh Kalamkar", "Janani Venugopalan Ph. D.", "Vivek Raghavan Ph. D"], "title": "Indian Legal NLP Benchmarks : A Survey", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Availability of challenging benchmarks is the key to advancement of AI in a\nspecific field.Since Legal Text is significantly different than normal English\ntext, there is a need to create separate Natural Language Processing benchmarks\nfor Indian Legal Text which are challenging and focus on tasks specific to\nLegal Systems. This will spur innovation in applications of Natural language\nProcessing for Indian Legal Text and will benefit AI community and Legal\nfraternity. We review the existing work in this area and propose ideas to\ncreate new benchmarks for Indian Legal Natural Language Processing.", "AI": {"tldr": "This paper discusses the importance of creating dedicated NLP benchmarks for Indian legal texts, reviews existing work, and proposes ideas for new benchmarks.", "motivation": "Legal text differs significantly from standard English, necessitating specialized NLP benchmarks for Indian legal texts to advance AI applications in this domain.", "method": "The paper reviews existing work in the field and suggests ideas for developing benchmarks tailored to Indian legal scenarios.", "result": "The paper does not report tangible results but highlights the necessity of new benchmarks for Indian Legal NLP.", "conclusion": "Creating such benchmarks will facilitate innovation in NLP applications for Indian legal systems and benefit both the AI community and the legal profession."}}
{"id": "2508.05694", "pdf": "https://arxiv.org/pdf/2508.05694", "abs": "https://arxiv.org/abs/2508.05694", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Guanggang Geng", "Zhiying Li", "Jian Weng"], "title": "DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Submitted to the 2025 IEEE International Conference on Data Mining\n  (ICDM)", "summary": "Insider threat detection (ITD) poses a persistent and high-impact challenge\nin cybersecurity due to the subtle, long-term, and context-dependent nature of\nmalicious insider behaviors. Traditional models often struggle to capture\nsemantic intent and complex behavior dynamics, while existing LLM-based\nsolutions face limitations in prompt adaptability and modality coverage. To\nbridge this gap, we propose DMFI, a dual-modality framework that integrates\nsemantic inference with behavior-aware fine-tuning. DMFI converts raw logs into\ntwo structured views: (1) a semantic view that processes content-rich artifacts\n(e.g., emails, https) using instruction-formatted prompts; and (2) a behavioral\nabstraction, constructed via a 4W-guided (When-Where-What-Which) transformation\nto encode contextual action sequences. Two LoRA-enhanced LLMs are fine-tuned\nindependently, and their outputs are fused via a lightweight MLP-based decision\nmodule. We further introduce DMFI-B, a discriminative adaptation strategy that\nseparates normal and abnormal behavior representations, improving robustness\nunder severe class imbalance. Experiments on CERT r4.2 and r5.2 datasets\ndemonstrate that DMFI outperforms state-of-the-art methods in detection\naccuracy. Our approach combines the semantic reasoning power of LLMs with\nstructured behavior modeling, offering a scalable and effective solution for\nreal-world insider threat detection. Our work demonstrates the effectiveness of\ncombining LLM reasoning with structured behavioral modeling, offering a\nscalable and deployable solution for modern insider threat detection.", "AI": {"tldr": "The paper introduces DMFI, a dual-modality framework for insider threat detection (ITD), combining semantic inference and behavior modeling to achieve state-of-the-art results.", "motivation": "Insider threat detection remains a complex challenge in cybersecurity due to the subtle and context-dependent nature of malicious behaviors; existing approaches lack semantic intent understanding and robust behavior modeling.", "method": "DMFI processes raw logs into two views: semantic (via prompts for content-rich data) and behavioral (using a 4W-guided transformation). It employs two fine-tuned LLMs, fuses their outputs, and uses a discriminative strategy for imbalanced data.", "result": "DMFI achieves superior detection accuracy on CERT r4.2 and r5.2 datasets, outperforming other state-of-the-art methods in robustness and scalability.", "conclusion": "Combining LLM-based semantic inference with structured behavior modeling offers a scalable and effective approach to modern insider threat detection."}}
{"id": "2508.05672", "pdf": "https://arxiv.org/pdf/2508.05672", "abs": "https://arxiv.org/abs/2508.05672", "authors": ["Yao Zhao", "Yantian Ding", "Zhiyue Zhang", "Dapeng Yao", "Yanxun Xu"], "title": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) systems often struggle with\ndomain-specific knowledge due to performance deterioration of pre-trained\nembeddings and prohibitive computational costs of large language model\n(LLM)-based retrievers. While fine-tuning data augmentation embedding models\noffers a promising direction, its effectiveness is limited by the need for\nhigh-quality training data and reliable chunking strategies that preserve\ncontextual integrity. We propose LMAR (Language Model Augmented Retriever), a\nmodel-agnostic framework that addresses these challenges by combining\nLLM-guided data synthesis with contrastive embedding adaptation and efficient\ntext clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling\nand synthetic data augmentation, where LLMs act as both labeler and validator\nto ensure high-fidelity supervision throughout the pipeline. Experimental\nresults across multiple domain-specific benchmark datasets demonstrate that\nLMAR outperforms multiple baseline models, while maintaining moderate hardware\nrequirements and low latency. Its model-agnostic nature further enables\nseamless integration with emerging RAG architectures and text embedding models,\nensuring continual improvements without redesigning the pipeline. These results\nhighlight LMAR as a practical and cost-effective solution for scalable\ndomain-specific adaptation.", "AI": {"tldr": "The paper introduces LMAR, a framework designed to address domain-specific retrieval challenges in RAG systems through LLM-based data synthesis and embedding adaptation techniques.", "motivation": "Existing RAG systems struggle with domain-specific retrieval due to limitations in embeddings and high computational costs. Reliable and scalable solutions are needed for better contextual adaptation.", "method": "LMAR uses a two-stage pipeline that involves LLM-powered data augmentation and contrastive embedding adaptation, coupled with efficient text clustering strategies.", "result": "LMAR outperforms baseline models on domain-specific benchmark datasets while maintaining moderate hardware requirements and low latency.", "conclusion": "LMAR emerges as a scalable, cost-effective, and model-agnostic framework suitable for enhancing domain-specific retrieval in RAG architectures."}}
{"id": "2508.01854", "pdf": "https://arxiv.org/pdf/2508.01854", "abs": "https://arxiv.org/abs/2508.01854", "authors": ["Fanze Kong", "Chen-Chih Lai", "Yubin Lu"], "title": "Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures", "categories": ["physics.comp-ph", "cs.LG", "math.AP", "nlin.AO"], "comment": null, "summary": "This paper proposes a data-driven learning framework for identifying\ngoverning laws of generalized diffusions with non-gradient components. By\ncombining energy dissipation laws with a physically consistent penalty and\nfirst-moment evolution, we design a two-stage method to recover the\npseudo-potential and rotation in the pointwise orthogonal decomposition of a\nclass of non-gradient drifts in generalized diffusions. Our two-stage method is\napplied to complex generalized diffusion processes including\ndissipation-rotation dynamics, rough pseudo-potentials and noisy data.\nRepresentative numerical experiments demonstrate the effectiveness of our\napproach for learning physical laws in non-gradient generalized diffusions.", "AI": {"tldr": "This paper introduces a framework to identify governing laws in non-gradient generalized diffusions using a two-stage method that combines dissipation laws and first-moment evolution.", "motivation": "The motivation is to improve the ability to recover governing laws in generalized diffusion processes that include non-gradient components, which are challenging to model and analyze due to their complexity.", "method": "The framework incorporates energy dissipation laws with a physically consistent penalty and first-moment evolution in a two-stage learning process to recover pseudo-potential and rotation in non-gradient drift dynamics.", "result": "The method is successfully applied to scenarios with dissipation-rotation dynamics, rough pseudo-potentials, and noisy data, demonstrating its effectiveness in learning these physical processes.", "conclusion": "The proposed two-stage method proves to be effective for identifying physical laws in complex and noisy non-gradient generalized diffusions."}}
{"id": "2508.05673", "pdf": "https://arxiv.org/pdf/2508.05673", "abs": "https://arxiv.org/abs/2508.05673", "authors": ["Weiqin Yang", "Jiawei Chen", "Shengjia Zhang", "Peng Wu", "Yuegang Sun", "Yan Feng", "Chun Chen", "Can Wang"], "title": "Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "Accepted by KDD 2025", "summary": "In the realm of recommender systems (RS), Top-$K$ ranking metrics such as\nNDCG@$K$ are the gold standard for evaluating recommendation performance.\nHowever, during the training of recommendation models, optimizing NDCG@$K$\nposes significant challenges due to its inherent discontinuous nature and the\nintricate Top-$K$ truncation. Recent efforts to optimize NDCG@$K$ have either\noverlooked the Top-$K$ truncation or suffered from high computational costs and\ntraining instability. To overcome these limitations, we propose SoftmaxLoss@$K$\n(SL@$K$), a novel recommendation loss tailored for NDCG@$K$ optimization.\nSpecifically, we integrate the quantile technique to handle Top-$K$ truncation\nand derive a smooth upper bound for optimizing NDCG@$K$ to address\ndiscontinuity. The resulting SL@$K$ loss has several desirable properties,\nincluding theoretical guarantees, ease of implementation, computational\nefficiency, gradient stability, and noise robustness. Extensive experiments on\nfour real-world datasets and three recommendation backbones demonstrate that\nSL@$K$ outperforms existing losses with a notable average improvement of 6.03%.\nThe code is available at https://github.com/Tiny-Snow/IR-Benchmark.", "AI": {"tldr": "The paper introduces SoftmaxLoss@$K$ (SL@$K$), a new loss function that improves NDCG@$K$ optimization in recommender systems with better computational efficiency and stability, achieving a 6.03% improvement on average.", "motivation": "Optimizing NDCG@$K$, the standard Top-$K$ ranking metric in recommender systems, is challenging due to its discontinuity and Top-$K$ truncation. Existing methods either ignore these challenges or are computationally costly and unstable.", "method": "The proposed SL@$K$ loss incorporates a quantile technique for handling Top-$K$ truncation and introduces a smooth upper bound to address the discontinuity in NDCG@$K$ optimization. This approach ensures theoretical robustness and computational efficiency.", "result": "Extensive experiments across four real-world datasets and three recommendation backbones show that SL@$K$ outperforms existing losses, achieving a significant average improvement of 6.03%.", "conclusion": "The SL@$K$ loss offers an effective and practical solution for NDCG@$K$ optimization in recommendation systems, providing computational efficiency, stability, and superior performance in experimental evaluations."}}
{"id": "2508.06115", "pdf": "https://arxiv.org/pdf/2508.06115", "abs": "https://arxiv.org/abs/2508.06115", "authors": ["Weichen Zhang", "Kebin Liu", "Fan Dang", "Zhui Zhu", "Xikai Sun", "Yunhao Liu"], "title": "SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Semantic segmentation in open-vocabulary scenarios presents significant\nchallenges due to the wide range and granularity of semantic categories.\nExisting weakly-supervised methods often rely on category-specific supervision\nand ill-suited feature construction methods for contrastive learning, leading\nto semantic misalignment and poor performance. In this work, we propose a novel\nweakly-supervised approach, SynSeg, to address the challenges. SynSeg performs\nMulti-Category Contrastive Learning (MCCL) as a stronger training signal with a\nnew feature reconstruction framework named Feature Synergy Structure (FSS).\nSpecifically, MCCL strategy robustly combines both intra- and inter-category\nalignment and separation in order to make the model learn the knowledge of\ncorrelations from different categories within the same image. Moreover, FSS\nreconstructs discriminative features for contrastive learning through prior\nfusion and semantic-activation-map enhancement, effectively avoiding the\nforeground bias introduced by the visual encoder. In general, SynSeg\neffectively improves the abilities in semantic localization and discrimination\nunder weak supervision. Extensive experiments on benchmarks demonstrate that\nour method outperforms state-of-the-art (SOTA) performance. For instance,\nSynSeg achieves higher accuracy than SOTA baselines by 4.5\\% on VOC, 8.9\\% on\nContext, 2.6\\% on Object and 2.0\\% on City.", "AI": {"tldr": "SynSeg introduces a novel weakly-supervised method for open-vocabulary semantic segmentation, improving accuracy and addressing semantic misalignment challenges through Multi-Category Contrastive Learning and the Feature Synergy Structure.", "motivation": "Semantic segmentation in open-vocabulary scenarios faces challenges due to varied semantic categories and weak supervision methods, which result in poor performance and semantic misalignment.", "method": "SynSeg employs Multi-Category Contrastive Learning (MCCL) for intra- and inter-category alignment and uses Feature Synergy Structure (FSS) for feature reconstruction to enhance semantic learning while avoiding biases.", "result": "SynSeg demonstrated improvements over state-of-the-art methods with significant accuracy gains across various benchmarks: 4.5% on VOC, 8.9% on Context, 2.6% on Object, and 2.0% on City.", "conclusion": "The paper concludes that SynSeg effectively enhances semantic segmentation in open-vocabulary scenarios by improving localization and discrimination capabilities under weak supervision."}}
{"id": "2508.05649", "pdf": "https://arxiv.org/pdf/2508.05649", "abs": "https://arxiv.org/abs/2508.05649", "authors": ["Jayanth Yetukuri", "Mehran Elyasi", "Samarth Agrawal", "Aritra Mandal", "Rui Kong", "Harish Vempati", "Ishita Khan"], "title": "AI Guided Accelerator For Search Experience", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at SIGIR eCom'25.\n  https://sigir-ecom.github.io/eCom25Papers/paper_25.pdf", "summary": "Effective query reformulation is pivotal in narrowing the gap between a\nuser's exploratory search behavior and the identification of relevant products\nin e-commerce environments. While traditional approaches predominantly model\nquery rewrites as isolated pairs, they often fail to capture the sequential and\ntransitional dynamics inherent in real-world user behavior. In this work, we\npropose a novel framework that explicitly models transitional\nqueries--intermediate reformulations occurring during the user's journey toward\ntheir final purchase intent. By mining structured query trajectories from\neBay's large-scale user interaction logs, we reconstruct query sequences that\nreflect shifts in intent while preserving semantic coherence. This approach\nallows us to model a user's shopping funnel, where mid-journey transitions\nreflect exploratory behavior and intent refinement. Furthermore, we incorporate\ngenerative Large Language Models (LLMs) to produce semantically diverse and\nintent-preserving alternative queries, extending beyond what can be derived\nthrough collaborative filtering alone. These reformulations can be leveraged to\npopulate Related Searches or to power intent-clustered carousels on the search\nresults page, enhancing both discovery and engagement. Our contributions\ninclude (i) the formal identification and modeling of transitional queries,\n(ii) the introduction of a structured query sequence mining pipeline for intent\nflow understanding, and (iii) the application of LLMs for scalable,\nintent-aware query expansion. Empirical evaluation demonstrates measurable\ngains in conversion and engagement metrics compared to the existing Related\nSearches module, validating the effectiveness of our approach in real-world\ne-commerce settings.", "AI": {"tldr": "The paper addresses improving e-commerce query reformulation by modeling transitional queries, constructing query trajectories, and leveraging Large Language Models (LLMs) for generating intent-preserving alternatives, achieving better engagement and conversion metrics.", "motivation": "Traditional query reformulation methods fail to capture the sequential progression and transitions in user intent during exploratory searches in e-commerce.", "method": "The authors mine large-scale user interaction logs from eBay to build structured query sequences reflecting intent refinement and leverage generative LLMs to generate semantically diverse query alternatives.", "result": "Empirical evaluations show improved conversion and engagement metrics for exploratory searches over traditional methods like Related Searches.", "conclusion": "Modeling transitional queries and applying LLMs for query expansion improves both discovery and engagement, validating the approach for real-world e-commerce applications."}}
{"id": "2508.05798", "pdf": "https://arxiv.org/pdf/2508.05798", "abs": "https://arxiv.org/abs/2508.05798", "authors": ["Yuri Gurevich"], "title": "Basic interactive algorithms: Preview", "categories": ["cs.LO", "cs.CL", "math.LO", "quant-ph"], "comment": null, "summary": "This dialog paper offers a preview and provides a foretaste of an upcoming\nwork on the axiomatization of basic interactive algorithms.\n  The modern notion of algorithm was elucidated in the 1930s--1950s. It was\naxiomatized a quarter of a century ago as the notion of ``sequential\nalgorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm\"\nnow. The axiomatization was used to show that for every basic algorithm there\nis a behaviorally equivalent abstract state machine. It was also used to prove\nthe Church-Turing thesis as it has been understood by the logicians.\n  Starting from the 1960s, the notion of algorithm has expanded --\nprobabilistic algorithms, quantum algorithms, etc. -- prompting introduction of\na much more ambitious version of the Church-Turing thesis commonly known as the\n``physical thesis.'' We emphasize the difference between the two versions of\nthe Church-Turing thesis and illustrate how nondeterministic and probabilistic\nalgorithms can be viewed as basic algorithms with appropriate oracles. The same\nview applies to quantum circuit algorithms and many other classes of\nalgorithms.", "AI": {"tldr": "The paper previews an upcoming work on the axiomatization of basic interactive algorithms, discussing their expansion beyond classical constructs.", "motivation": "To revisit and build upon the notion of algorithms, which has evolved to include various types like probabilistic and quantum algorithms, and provide a unifying view.", "method": "Discussion on the axiomatic foundations of basic algorithms and the application of oracles to extend this framework to newer algorithm classes.", "result": "The paper illustrates how models like nondeterministic, probabilistic, and quantum circuit algorithms can be linked to basic algorithm frameworks.", "conclusion": "The study bridges classical and modern algorithmic formulations, highlighting the conceptual distinction between the classical and physical Church-Turing theses."}}
{"id": "2508.05674", "pdf": "https://arxiv.org/pdf/2508.05674", "abs": "https://arxiv.org/abs/2508.05674", "authors": ["Minghao Shao", "Nanda Rani", "Kimberly Milner", "Haoran Xi", "Meet Udeshi", "Saksham Aggarwal", "Venkata Sai Charan Putrevu", "Sandeep Kumar Shukla", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri", "Muhammad Shafique"], "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recent advances in LLM agentic systems have improved the automation of\noffensive security tasks, particularly for Capture the Flag (CTF) challenges.\nWe systematically investigate the key factors that drive agent success and\nprovide a detailed recipe for building effective LLM-based offensive security\nagents. First, we present CTFJudge, a framework leveraging LLM as a judge to\nanalyze agent trajectories and provide granular evaluation across CTF solving\nsteps. Second, we propose a novel metric, CTF Competency Index (CCI) for\npartial correctness, revealing how closely agent solutions align with\nhuman-crafted gold standards. Third, we examine how LLM hyperparameters, namely\ntemperature, top-p, and maximum token length, influence agent performance and\nautomated cybersecurity task planning. For rapid evaluation, we present\nCTFTiny, a curated benchmark of 50 representative CTF challenges across binary\nexploitation, web, reverse engineering, forensics, and cryptography. Our\nfindings identify optimal multi-agent coordination settings and lay the\ngroundwork for future LLM agent research in cybersecurity. We make CTFTiny open\nsource to public https://github.com/NYU-LLM-CTF/CTFTiny along with CTFJudge on\nhttps://github.com/NYU-LLM-CTF/CTFJudge.", "AI": {"tldr": "The paper explores the application of advanced LLM systems in automating offensive security tasks for CTF challenges, introducing tools, metrics, and benchmarks to optimize performance.", "motivation": "The paper is motivated by the growing need to enhance cybersecurity automation and the transformative potential of LLM agents in solving challenging tasks like CTF competitions.", "method": "The authors present CTFJudge for agent trajectory analysis and granular evaluation, a new metric CTF Competency Index (CCI) for partial correctness, and CTFTiny\u2014a curated benchmark to evaluate agent performance across varied tasks.", "result": "The study identifies optimal configurations for multi-agent setups and demonstrates improvements in task automation for various cybersecurity domains using their proposed tools and metrics.", "conclusion": "The findings outline actionable strategies for optimizing LLM agent performance and provide open-source resources to advance research in automated cybersecurity solutions."}}
{"id": "2508.06122", "pdf": "https://arxiv.org/pdf/2508.06122", "abs": "https://arxiv.org/abs/2508.06122", "authors": ["Ting-Shuo Yo", "Shih-Hao Su", "Chien-Ming Wu", "Wei-Ting Chen", "Jung-Lien Chu", "Chiao-Wei Chang", "Hung-Chi Kuo"], "title": "Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events", "categories": ["cs.CV", "physics.ao-ph"], "comment": "37 pages, 6 figures, 3 tables", "summary": "This study applied representation learning algorithms to satellite images and\nevaluated the learned latent spaces with classifications of various weather\nevents. The algorithms investigated include the classical linear\ntransformation, i.e., principal component analysis (PCA), state-of-the-art deep\nlearning method, i.e., convolutional autoencoder (CAE), and a residual network\npre-trained with large image datasets (PT). The experiment results indicated\nthat the latent space learned by CAE consistently showed higher threat scores\nfor all classification tasks. The classifications with PCA yielded high hit\nrates but also high false-alarm rates. In addition, the PT performed\nexceptionally well at recognizing tropical cyclones but was inferior in other\ntasks. Further experiments suggested that representations learned from\nhigher-resolution datasets are superior in all classification tasks for\ndeep-learning algorithms, i.e., CAE and PT. We also found that smaller latent\nspace sizes had minor impact on the classification task's hit rate. Still, a\nlatent space dimension smaller than 128 caused a significantly higher false\nalarm rate. Though the CAE can learn latent spaces effectively and efficiently,\nthe interpretation of the learned representation lacks direct connections to\nphysical attributions. Therefore, developing a physics-informed version of CAE\ncan be a promising outlook for the current work.", "AI": {"tldr": "This paper explores the use of representation learning algorithms, including PCA, CAE, and pre-trained ResNet, for classifying weather events from satellite images, finding CAE to be the most effective.", "motivation": "To investigate how different representation learning techniques perform on satellite imagery classification tasks for various weather events.", "method": "The study compares three representation learning methods (PCA, CAE, and pre-trained ResNet) by evaluating their latent spaces through classification performance on weather-related satellite images.", "result": "CAE demonstrated the highest classification performance with low false alarm rates, PCA showed high false alarms, and pre-trained ResNet excelled at tropical cyclone detection but underperformed for other tasks. High-resolution input data and specific latent space sizes impacted performance.", "conclusion": "CAE is effective for representation learning but lacks physical interpretability, suggesting the potential for further development of physics-informed CAE to address this limitation."}}
{"id": "2508.05835", "pdf": "https://arxiv.org/pdf/2508.05835", "abs": "https://arxiv.org/abs/2508.05835", "authors": ["Edresson Casanova", "Paarth Neekhara", "Ryan Langman", "Shehzeen Hussain", "Subhankar Ghosh", "Xuesong Yang", "Ante Juki\u0107", "Jason Li", "Boris Ginsburg"], "title": "NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Large Language Models (LLMs) have significantly advanced audio processing by\nleveraging audio codecs to discretize audio into tokens, enabling the\napplication of language modeling techniques to speech data. However, existing\naudio codecs often operate at high frame rates, leading to slow training and\ninference, particularly for autoregressive models. To address this, there is\ngrowing interest in low frame-rate audio codecs, which reduce the number of\nautoregressive steps required to generate one second of audio. In this paper,\nwe conduct ablation studies to examine the impact of frame rate, bitrate, and\ncausality on codec reconstruction quality. Based on our findings, we introduce\nNanoCodec, a state-of-the-art audio codec that achieves high-quality\ncompression at just 12.5 frames per second (FPS). NanoCodec outperforms related\nworks across various bitrate ranges, establishing a new benchmark for\nlow-latency and efficient Speech LLM training and inference.", "AI": {"tldr": "The paper introduces NanoCodec, a low-frame-rate audio codec achieving exceptional audio compression quality at 12.5 FPS, enhancing efficiency for Speech LLM training and inference.", "motivation": "To address the inefficiencies caused by high frame rates in existing audio codecs, which result in slow training and inference for Speech LLMs, particularly in autoregressive models.", "method": "A series of ablation studies were conducted to assess the effects of frame rate, bitrate, and causality on audio codec reconstruction quality, leading to the design and implementation of NanoCodec.", "result": "NanoCodec demonstrated superior performance over existing codecs across various bitrate ranges, achieving high-quality audio compression at 12.5 FPS.", "conclusion": "NanoCodec sets a new benchmark for low-latency, efficient Speech LLM training and inference, marking a significant step forward in audio compression technology."}}
{"id": "2508.05675", "pdf": "https://arxiv.org/pdf/2508.05675", "abs": "https://arxiv.org/abs/2508.05675", "authors": ["Jing Wang", "Zheng Li", "Lei Li", "Fan He", "Liyu Lin", "Yao Lai", "Yan Li", "Xiaoyang Zeng", "Yufeng Guo"], "title": "Principle-Guided Verilog Optimization: IP-Safe Knowledge Transfer via Local-Cloud Collaboration", "categories": ["cs.CR", "cs.AI"], "comment": "Our code and dataset are available at\n  https://github.com/friyawang/VeriOptim", "summary": "Recent years have witnessed growing interest in adopting large language\nmodels (LLMs) for Register Transfer Level (RTL) code optimization. While\npowerful cloud-based LLMs offer superior optimization capabilities, they pose\nunacceptable intellectual property (IP) leakage risks when processing\nproprietary hardware designs. In this paper, we propose a new scenario where\nVerilog code must be optimized for specific attributes without leaking\nsensitive IP information. We introduce the first IP-preserving edge-cloud\ncollaborative framework that leverages the benefits of both paradigms. Our\napproach employs local small LLMs (e.g., Qwen-2.5-Coder-7B) to perform secure\ncomparative analysis between paired high-quality target designs and novice\ndraft codes, yielding general design principles that summarize key insights for\nimprovements. These principles are then used to query stronger cloud LLMs\n(e.g., Deepseek-V3) for targeted code improvement, ensuring that only\nabstracted and IP-safe guidance reaches external services. Our experimental\nresults demonstrate that the framework achieves significantly higher\noptimization success rates compared to baseline methods. For example, combining\nQwen-2.5-Coder-7B and Deepseek-V3 achieves a 66.67\\% optimization success rate\nfor power utilization, outperforming Deepseek-V3 alone (49.81\\%) and even\ncommercial models like GPT-4o (55.81\\%). Further investigation of local and\ncloud LLM combinations reveals that different model pairings exhibit varying\nstrengths for specific optimization objectives, with interesting trends\nemerging when varying the number of comparative code pairs. Our work\nestablishes a new paradigm for secure hardware design optimization that\nbalances performance gains with IP protection.", "AI": {"tldr": "This paper introduces a secure edge-cloud collaborative framework using local and cloud-based large language models (LLMs) for optimizing Verilog code while preserving intellectual property (IP). The method ensures improved optimization success rates without leaking sensitive information.", "motivation": "The paper addresses the problem of intellectual property leakage when using powerful cloud-based LLMs for hardware design optimization and proposes a secure framework to balance optimization with IP protection.", "method": "The method involves leveraging local small LLMs for secure comparative analysis to derive general optimization principles, which are then abstracted and passed to stronger cloud-based LLMs for further code improvement.", "result": "The framework shows superior optimization outcomes, achieving success rates like 66.67% for power utilization, exceeding standalone models such as Deepseek-V3 (49.81%) and GPT-4o (55.81%).", "conclusion": "The work establishes a novel paradigm in hardware optimization, combining performance boosts with strong IP protection protocols."}}
{"id": "2508.06125", "pdf": "https://arxiv.org/pdf/2508.06125", "abs": "https://arxiv.org/abs/2508.06125", "authors": ["Lin Zhang", "Xianfang Zeng", "Kangcong Li", "Gang Yu", "Tao Chen"], "title": "SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "We propose SC-Captioner, a reinforcement learning framework that enables the\nself-correcting capability of image caption models. Our crucial technique lies\nin the design of the reward function to incentivize accurate caption\ncorrections. Specifically, the predicted and reference captions are decomposed\ninto object, attribute, and relation sets using scene-graph parsing algorithms.\nWe calculate the set difference between sets of initial and self-corrected\ncaptions to identify added and removed elements. These elements are matched\nagainst the reference sets to calculate correctness bonuses for accurate\nrefinements and mistake punishments for wrong additions and removals, thereby\nforming the final reward. For image caption quality assessment, we propose a\nset of metrics refined from CAPTURE that alleviate its incomplete precision\nevaluation and inefficient relation matching problems. Furthermore, we collect\na fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K\ndiverse images from COCO dataset. Experiments show that applying SC-Captioner\non large visual-language models can generate better image captions across\nvarious scenarios, significantly outperforming the direct preference\noptimization training strategy.", "AI": {"tldr": "SC-Captioner is a reinforcement learning-based framework designed for improving the self-correcting ability of image captioning models, using a novel reward system and new metrics.", "motivation": "To address limitations in existing image captioning models which lack the capability to self-correct their caption predictions and struggle with accurate quality assessment.", "method": "The framework uses scene-graph parsing to decompose captions into object, attribute, and relation sets. Reward is calculated based on correctness bonuses and mistake punishments by comparing against these sets. A new dataset (RefinedCaps) and improved evaluation metrics are introduced.", "result": "Experiments demonstrate that SC-Captioner significantly outperforms traditional preference optimization methods in generating high-quality, contextually accurate image captions.", "conclusion": "SC-Captioner enhances the captioning capabilities of visual-language models by introducing a better reward structure and evaluation metrics, leading to more accurate and refined captions."}}
{"id": "2508.05913", "pdf": "https://arxiv.org/pdf/2508.05913", "abs": "https://arxiv.org/abs/2508.05913", "authors": ["Stefan Pasch", "Min Chul Cha"], "title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "As AI systems become increasingly embedded in organizational workflows and\nconsumer applications, ethical principles such as fairness, transparency, and\nrobustness have been widely endorsed in policy and industry guidelines.\nHowever, there is still scarce empirical evidence on whether these principles\nare recognized, valued, or impactful from the perspective of users. This study\ninvestigates the link between ethical AI and user satisfaction by analyzing\nover 100,000 user reviews of AI products from G2. Using transformer-based\nlanguage models, we measure sentiment across seven ethical dimensions defined\nby the EU Ethics Guidelines for Trustworthy AI. Our findings show that all\nseven dimensions are positively associated with user satisfaction. Yet, this\nrelationship varies systematically across user and product types. Technical\nusers and reviewers of AI development platforms more frequently discuss\nsystem-level concerns (e.g., transparency, data governance), while\nnon-technical users and reviewers of end-user applications emphasize\nhuman-centric dimensions (e.g., human agency, societal well-being). Moreover,\nthe association between ethical AI and user satisfaction is significantly\nstronger for non-technical users and end-user applications across all\ndimensions. Our results highlight the importance of ethical AI design from\nusers' perspectives and underscore the need to account for contextual\ndifferences across user roles and product types.", "AI": {"tldr": "The paper investigates how ethical principles in AI affect user satisfaction by analyzing over 100,000 user reviews from G2. Using transformer-based language models, it examines sentiment across seven ethical AI dimensions and discovers varying impacts based on user roles and product types.", "motivation": "To address the lack of empirical evidence on how ethical AI principles are recognized, valued, or impactful from the perspective of users.", "method": "Analyzing 100,000+ user reviews of AI products using transformer-based language models to measure sentiment across seven ethical dimensions outlined in the EU Ethics Guidelines for Trustworthy AI.", "result": "All seven ethical dimensions are positively associated with user satisfaction, with variations in emphasis based on user type (technical vs. non-technical) and product type (AI development platforms vs. end-user applications).", "conclusion": "Ethical AI design is crucial from the users' perspectives, and contextual differences in user roles and product types should be considered to optimize user satisfaction."}}
{"id": "2508.05677", "pdf": "https://arxiv.org/pdf/2508.05677", "abs": "https://arxiv.org/abs/2508.05677", "authors": ["Peizhuo Liu"], "title": "Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "30 pages (21 pages main text, 3 pages references, 6 pages appendix),\n  4 figures", "summary": "RL-based medical questionnaire systems have shown great potential in medical\nscenarios. However, their safety and robustness remain unresolved. This study\nperforms a comprehensive evaluation on adversarial attack methods to identify\nand analyze their potential vulnerabilities. We formulate the diagnosis process\nas a Markov Decision Process (MDP), where the state is the patient responses\nand unasked questions, and the action is either to ask a question or to make a\ndiagnosis. We implemented six prevailing major attack methods, including the\nFast Gradient Signed Method (FGSM), Projected Gradient Descent (PGD), Carlini &\nWagner Attack (C&W) attack, Basic Iterative Method (BIM), DeepFool, and\nAutoAttack, with seven epsilon values each. To ensure the generated adversarial\nexamples remain clinically plausible, we developed a comprehensive medical\nvalidation framework consisting of 247 medical constraints, including\nphysiological bounds, symptom correlations, and conditional medical\nconstraints. We achieved a 97.6% success rate in generating clinically\nplausible adversarial samples. We performed our experiment on the National\nHealth Interview Survey (NHIS) dataset (https://www.cdc.gov/nchs/nhis/), which\nconsists of 182,630 samples, to predict the participant's 4-year mortality\nrate. We evaluated our attacks on the AdaptiveFS framework proposed in\narXiv:2004.00994. Our results show that adversarial attacks could significantly\nimpact the diagnostic accuracy, with attack success rates ranging from 33.08%\n(FGSM) to 64.70% (AutoAttack). Our work has demonstrated that even under strict\nmedical constraints on the input, such RL-based medical questionnaire systems\nstill show significant vulnerabilities.", "AI": {"tldr": "The paper examines vulnerabilities in RL-based medical questionnaire systems under adversarial attacks, achieving a 97.6% success rate for generating clinically plausible adversarial samples.", "motivation": "To assess the safety and robustness of Reinforcement Learning (RL)-based medical questionnaire systems, especially under adversarial attack scenarios.", "method": "The authors formulated the diagnostic process as a Markov Decision Process (MDP) and tested six major adversarial attack methods on samples from the NHIS dataset while ensuring medical plausibility using a validation framework with 247 constraints.", "result": "Under adversarial attacks, diagnostic accuracy suffered significantly, with attack success rates ranging from 33.08% (FGSM) to 64.70% (AutoAttack).", "conclusion": "Despite enforcing strict medical constraints, RL-based medical questionnaire systems remain vulnerable to adversarial attacks, raising safety and reliability concerns."}}
{"id": "2508.06127", "pdf": "https://arxiv.org/pdf/2508.06127", "abs": "https://arxiv.org/abs/2508.06127", "authors": ["Yi Qin", "Rui Wang", "Tao Huang", "Tong Xiao", "Liping Jing"], "title": "SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures", "categories": ["cs.CV", "I.4.9"], "comment": "8 pages,recived by ICCV2025", "summary": "While the Segment Anything Model (SAM) transforms interactive segmentation\nwith zero-shot abilities, its inherent vulnerabilities present a single-point\nrisk, potentially leading to the failure of numerous downstream applications.\nProactively evaluating these transferable vulnerabilities is thus imperative.\nPrior adversarial attacks on SAM often present limited transferability due to\ninsufficient exploration of common weakness across domains. To address this, we\npropose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that\nleverages only the encoder of SAM for generating transferable adversarial\nexamples. Specifically, it achieves this by explicitly characterizing the\nshared vulnerable regions between SAM and downstream models through a\nparametric simplicial complex. Our goal is to identify such complexes within\nadversarially potent regions by iterative vertex-wise refinement. A lightweight\ndomain re-adaptation strategy is introduced to bridge domain divergence using\nminimal reference data during the initialization of simplicial complex.\nUltimately, VeSCA generates consistently transferable adversarial examples\nthrough random simplicial complex sampling. Extensive experiments demonstrate\nthat VeSCA achieves performance improved by 12.7% compared to state-of-the-art\nmethods across three downstream model categories across five domain-specific\ndatasets. Our findings further highlight the downstream model risks posed by\nSAM's vulnerabilities and emphasize the urgency of developing more robust\nfoundation models.", "AI": {"tldr": "The paper introduces VeSCA, a method to evaluate and exploit vulnerabilities in SAM by generating transferable adversarial examples using simplicial complexes and domain re-adaptation.", "motivation": "To address the single-point risk posed by SAM's vulnerabilities, which can jeopardize the reliability of multiple downstream models.", "method": "VeSCA uses the encoder of SAM to find shared vulnerable regions via a parametric simplicial complex and iterative refinement, supplemented by domain re-adaptation for better transferability.", "result": "VeSCA improves adversarial transferability by 12.7% over state-of-the-art methods on various models and datasets.", "conclusion": "SAM's vulnerabilities pose risks to downstream applications, emphasizing the need for more secure and robust foundational models."}}
{"id": "2508.05680", "pdf": "https://arxiv.org/pdf/2508.05680", "abs": "https://arxiv.org/abs/2508.05680", "authors": ["Stefanie Urchs", "Veronika Thurner", "Matthias A\u00dfenmacher", "Ludwig Bothmann", "Christian Heumann", "Stephanie Thiemichen"], "title": "Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Algorithmic systems such as search engines and information retrieval\nplatforms significantly influence academic visibility and the dissemination of\nknowledge. Despite assumptions of neutrality, these systems can reproduce or\nreinforce societal biases, including those related to gender. This paper\nintroduces and applies a bias-preserving definition of algorithmic gender\nfairness, which assesses whether algorithmic outputs reflect real-world gender\ndistributions without introducing or amplifying disparities. Using a\nheterogeneous dataset of academic profiles from German universities and\nuniversities of applied sciences, we analyse gender differences in metadata\ncompleteness, publication retrieval in academic databases, and visibility in\nGoogle search results. While we observe no overt algorithmic discrimination,\nour findings reveal subtle but consistent imbalances: male professors are\nassociated with a greater number of search results and more aligned publication\nrecords, while female professors display higher variability in digital\nvisibility. These patterns reflect the interplay between platform algorithms,\ninstitutional curation, and individual self-presentation. Our study highlights\nthe need for fairness evaluations that account for both technical performance\nand representational equality in digital systems.", "AI": {"tldr": "The paper explores how algorithmic systems may perpetuate gender biases in academic visibility and emphasizes the need for fairness in these systems.", "motivation": "To investigate gender-related biases in algorithmic systems used in academia, like search engines and academic databases.", "method": "A bias-preserving definition of algorithmic gender fairness is proposed, applied to analyze gender differences in metadata completeness, publication retrieval, and Google search visibility using a dataset of German academic profiles.", "result": "Male professors typically have more search results and aligned publication records, while female professors face greater variability in visibility, even without overt algorithmic discrimination.", "conclusion": "Fairness evaluations of algorithmic systems should address both technical performance and representational equality."}}
{"id": "2508.06136", "pdf": "https://arxiv.org/pdf/2508.06136", "abs": "https://arxiv.org/abs/2508.06136", "authors": ["YoungChan Choi", "HengFei Wang", "YiHua Cheng", "Boeun Kim", "Hyung Jin Chang", "YoungGeun Choi", "Sang-Il Choi"], "title": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 5 figures, ACM Multimeida 2025 accepted", "summary": "We propose a novel 3D gaze redirection framework that leverages an explicit\n3D eyeball structure. Existing gaze redirection methods are typically based on\nneural radiance fields, which employ implicit neural representations via volume\nrendering. Unlike these NeRF-based approaches, where the rotation and\ntranslation of 3D representations are not explicitly modeled, we introduce a\ndedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian\nSplatting (3DGS). Our method generates photorealistic images that faithfully\nreproduce the desired gaze direction by explicitly rotating and translating the\n3D eyeball structure. In addition, we propose an adaptive deformation module\nthat enables the replication of subtle muscle movements around the eyes.\nThrough experiments conducted on the ETH-XGaze dataset, we demonstrate that our\nframework is capable of generating diverse novel gaze images, achieving\nsuperior image quality and gaze estimation accuracy compared to previous\nstate-of-the-art methods.", "AI": {"tldr": "The paper proposes a framework for 3D gaze redirection using an explicit 3D eyeball structure based on 3D Gaussian Splatting, producing photorealistic images with improved gaze estimation accuracy.", "motivation": "To address limitations in existing gaze redirection methods, which lack explicit modeling of 3D rotation and translation, aiming to enhance image realism and gaze estimation accuracy.", "method": "The approach uses 3D Gaussian Splatting to create a dedicated 3D eyeball model, explicitly rotating and translating the structure while using an adaptive deformation module for realistic muscle movement replication.", "result": "Experiments on ETH-XGaze dataset show the framework generates diverse novel gaze images with better image quality and higher gaze estimation accuracy than state-of-the-art methods.", "conclusion": "The explicit representation of 3D eyeball structure and adaptive deformation module substantially improve gaze redirection realism and accuracy, making it a superior alternative to previous methods."}}
{"id": "2508.05681", "pdf": "https://arxiv.org/pdf/2508.05681", "abs": "https://arxiv.org/abs/2508.05681", "authors": ["Yuhan Zhi", "Longtian Wang", "Xiaofei Xie", "Chao Shen", "Qiang Hu", "Xiaohong Guan"], "title": "Selection-Based Vulnerabilities: Clean-Label Backdoor Attacks in Active Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Active learning(AL), which serves as the representative label-efficient\nlearning paradigm, has been widely applied in resource-constrained scenarios.\nThe achievement of AL is attributed to acquisition functions, which are\ndesigned for identifying the most important data to label. Despite this\nsuccess, one question remains unanswered: is AL safe? In this work, we\nintroduce ALA, a practical and the first framework to utilize the acquisition\nfunction as the poisoning attack surface to reveal the weakness of active\nlearning. Specifically, ALA optimizes imperceptibly poisoned inputs to exhibit\nhigh uncertainty scores, increasing their probability of being selected by\nacquisition functions. To evaluate ALA, we conduct extensive experiments across\nthree datasets, three acquisition functions, and two types of clean-label\nbackdoor triggers. Results show that our attack can achieve high success rates\n(up to 94%) even under low poisoning budgets (0.5%-1.0%) while preserving model\nutility and remaining undetectable to human annotators. Our findings remind\nactive learning users: acquisition functions can be easily exploited, and\nactive learning should be deployed with caution in trusted data scenarios.", "AI": {"tldr": "The paper introduces ALA, a framework revealing vulnerabilities in Active Learning by showcasing how acquisition functions can be exploited for poisoning attacks.", "motivation": "Active Learning is widely adopted in resource-constrained scenarios, but its security vulnerabilities, particularly regarding acquisition functions, remain unexplored.", "method": "ALA utilizes imperceptible poisoned inputs to manipulate acquisition functions and increase their selection probability for labeling.", "result": "Experiments show ALA achieves up to 94% attack success rates with minimal poisoning budgets (0.5%-1.0%) while maintaining model utility and being undetectable to human annotators.", "conclusion": "Active Learning acquisition functions are easily exploitable, highlighting the need for caution and security considerations when deploying in sensitive contexts."}}
{"id": "2508.06139", "pdf": "https://arxiv.org/pdf/2508.06139", "abs": "https://arxiv.org/abs/2508.06139", "authors": ["Shaohua Pan", "Xinyu Yi", "Yan Zhou", "Weihua Jian", "Yuan Zhang", "Pengfei Wan", "Feng Xu"], "title": "DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera", "categories": ["cs.CV"], "comment": null, "summary": "Combining sparse IMUs and a monocular camera is a new promising setting to\nperform real-time human motion capture. This paper proposes a diffusion-based\nsolution to learn human motion priors and fuse the two modalities of signals\ntogether seamlessly in a unified framework. By delicately considering the\ncharacteristics of the two signals, the sequential visual information is\nconsidered as a whole and transformed into a condition embedding, while the\ninertial measurement is concatenated with the noisy body pose frame by frame to\nconstruct a sequential input for the diffusion model. Firstly, we observe that\nthe visual information may be unavailable in some frames due to occlusions or\nsubjects moving out of the camera view. Thus incorporating the sequential\nvisual features as a whole to get a single feature embedding is robust to the\noccasional degenerations of visual information in those frames. On the other\nhand, the IMU measurements are robust to occlusions and always stable when\nsignal transmission has no problem. So incorporating them frame-wisely could\nbetter explore the temporal information for the system. Experiments have\ndemonstrated the effectiveness of the system design and its state-of-the-art\nperformance in pose estimation compared with the previous works. Our codes are\navailable for research at https://shaohua-pan.github.io/diffcap-page.", "AI": {"tldr": "This paper introduces a diffusion-based method to integrate IMUs and a monocular camera for real-time human motion capture, demonstrating state-of-the-art pose estimation performance.", "motivation": "Recent advancements require robust real-time human motion capture, which is challenging due to issues like occlusion and signal inconsistencies in traditional methods.", "method": "The paper uses a diffusion model to learn human motion priors, where visual information is treated as a single sequential feature embedding, and IMU measurements are processed frame-by-frame.", "result": "Experimental evaluations show that the proposed system offers improved robustness and achieves state-of-the-art results in pose estimation compared to previous approaches.", "conclusion": "By combining sparse IMUs and a monocular camera within a unified framework, the research provides a novel solution for reliable and accurate human motion tracking."}}
{"id": "2508.05676", "pdf": "https://arxiv.org/pdf/2508.05676", "abs": "https://arxiv.org/abs/2508.05676", "authors": ["Han Gao", "Timo Hartmann", "Botao Zhong", "Kai Lia", "Hanbin Luo"], "title": "Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Building Information Modeling (BIM) is essential for managing building data\nacross the entire lifecycle, supporting tasks from design to maintenance.\nNatural Language Interface (NLI) systems are increasingly explored as\nuser-friendly tools for information retrieval in Building Information Modeling\n(BIM) environments. Despite their potential, accurately extracting BIM-related\ndata through natural language queries remains a persistent challenge due to the\ncomplexity use queries and specificity of domain knowledge. This study presents\na comparative analysis of two prominent approaches for developing NLI-based BIM\ninformation retrieval systems: domain-specific fine-tuning and prompt-based\nlearning using large language models (LLMs). A two-stage framework consisting\nof intent recognition and table-based question answering is implemented to\nevaluate the effectiveness of both approaches. To support this evaluation, a\nBIM-specific dataset of 1,740 annotated queries of varying types across 69\nmodels is constructed. Experimental results show that domain-specific\nfine-tuning delivers superior performance in intent recognition tasks, while\nprompt-based learning, particularly with GPT-4o, shows strength in table-based\nquestion answering. Based on these findings, this study identify a hybrid\nconfiguration that combines fine-tuning for intent recognition with\nprompt-based learning for question answering, achieving more balanced and\nrobust performance across tasks. This integrated approach is further tested\nthrough case studies involving BIM models of varying complexity. This study\nprovides a systematic analysis of the strengths and limitations of each\napproach and discusses the applicability of the NLI to real-world BIM\nscenarios. The findings offer insights for researchers and practitioners in\ndesigning intelligent, language-driven BIM systems.", "AI": {"tldr": "The paper compares domain-specific fine-tuning and prompt-based learning using LLMs in developing NLI systems for BIM data retrieval.", "motivation": "There is a need for effective Natural Language Interface systems to simplify and enhance data retrieval in complex BIM scenarios.", "method": "Two-stage framework using intent recognition and table-based question answering is tested on a dataset of 1,740 annotated queries across 69 BIM models.", "result": "Domain-specific fine-tuning excelled in intent recognition, while prompt-based learning (e.g., GPT-4) performed better in table-based question answering. A hybrid approach combining both performed robustly.", "conclusion": "Hybrid methods integrating fine-tuning and LLMs for specific tasks are promising for designing advanced NLI-based BIM systems, with real-world evaluations showing balanced effectiveness."}}
{"id": "2508.06059", "pdf": "https://arxiv.org/pdf/2508.06059", "abs": "https://arxiv.org/abs/2508.06059", "authors": ["Haorui He", "Yupeng Li", "Bin Benjamin Zhu", "Dacheng Wen", "Reynold Cheng", "Francis C. M. Lau"], "title": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "State-of-the-art fact-checking systems combat misinformation at scale by\nemploying autonomous LLM-based agents to decompose complex claims into smaller\nsub-claims, verify each sub-claim individually, and aggregate the partial\nresults to produce verdicts with justifications (explanatory rationales for the\nverdicts). The security of these systems is crucial, as compromised\nfact-checkers, which tend to be easily underexplored, can amplify\nmisinformation. This work introduces Fact2Fiction, the first poisoning attack\nframework targeting such agentic fact-checking systems. Fact2Fiction mirrors\nthe decomposition strategy and exploits system-generated justifications to\ncraft tailored malicious evidences that compromise sub-claim verification.\nExtensive experiments demonstrate that Fact2Fiction achieves 8.9\\%--21.2\\%\nhigher attack success rates than state-of-the-art attacks across various\npoisoning budgets. Fact2Fiction exposes security weaknesses in current\nfact-checking systems and highlights the need for defensive countermeasures.", "AI": {"tldr": "The paper introduces Fact2Fiction, a poisoning attack framework targeting autonomous LLM-based fact-checking systems, achieving higher attack success rates and exposing security gaps.", "motivation": "The authors aim to address the potential security vulnerabilities in state-of-the-art LLM-based fact-checking systems, as these systems can amplify misinformation if compromised.", "method": "Fact2Fiction mimics the claim decomposition strategy used by fact-checking systems and exploits system-generated justifications to craft malicious evidence that disrupt sub-claim verification processes.", "result": "Fact2Fiction demonstrates 8.9%-21.2% higher attack success rates compared to prior attacks, revealing significant weaknesses in current fact-checking systems.", "conclusion": "The findings emphasize the need for more robust defensive measures to secure LLM-based agentic fact-checking systems against such poisoning attacks."}}
{"id": "2508.05687", "pdf": "https://arxiv.org/pdf/2508.05687", "abs": "https://arxiv.org/abs/2508.05687", "authors": ["Alistair Reid", "Simon O'Callaghan", "Liam Carroll", "Tiberio Caetano"], "title": "Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Organisations are starting to adopt LLM-based AI agents, with their\ndeployments naturally evolving from single agents towards interconnected,\nmulti-agent networks. Yet a collection of safe agents does not guarantee a safe\ncollection of agents, as interactions between agents over time create emergent\nbehaviours and induce novel failure modes. This means multi-agent systems\nrequire a fundamentally different risk analysis approach than that used for a\nsingle agent.\n  This report addresses the early stages of risk identification and analysis\nfor multi-agent AI systems operating within governed environments where\norganisations control their agent configurations and deployment. In this\nsetting, we examine six critical failure modes: cascading reliability failures,\ninter-agent communication failures, monoculture collapse, conformity bias,\ndeficient theory of mind, and mixed motive dynamics. For each, we provide a\ntoolkit for practitioners to extend or integrate into their existing frameworks\nto assess these failure modes within their organisational contexts.\n  Given fundamental limitations in current LLM behavioural understanding, our\napproach centres on analysis validity, and advocates for progressively\nincreasing validity through staged testing across stages of abstraction and\ndeployment that gradually increases exposure to potential negative impacts,\nwhile collecting convergent evidence through simulation, observational\nanalysis, benchmarking, and red teaming. This methodology establishes the\ngroundwork for robust organisational risk management as these LLM-based\nmulti-agent systems are deployed and operated.", "AI": {"tldr": "This paper explores risk identification and analysis for multi-agent AI systems, highlighting six critical failure modes and providing tools to address them in governed environments.", "motivation": "To address the unique risks that arise when transitioning from single-agent to interconnected multi-agent AI systems, and to propose an effective risk management framework.", "method": "The authors analyze six critical multi-agent system failure modes and propose a staged testing methodology involving simulation, observations, benchmarking, and red teaming to assess risks systematically.", "result": "The study highlights six major failure modes\u2014cascading reliability failures, inter-agent communication failures, monoculture collapse, conformity bias, deficient theory of mind, and mixed motive dynamics\u2014and introduces tools to assess them.", "conclusion": "The paper lays a foundation for risk management techniques to ensure safer deployments of LLM-based multi-agent systems within organizations by progressively analyzing and mitigating risks."}}
{"id": "2508.06142", "pdf": "https://arxiv.org/pdf/2508.06142", "abs": "https://arxiv.org/abs/2508.06142", "authors": ["Hanqing Wang", "Yuan Tian", "Mingyu Liu", "Zhenhao Zhang", "Xiangyang Zhu"], "title": "SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "In the rapidly evolving landscape of Multimodal Large Language Models\n(MLLMs), the safety concerns of their outputs have earned significant\nattention. Although numerous datasets have been proposed, they may become\noutdated with MLLM advancements and are susceptible to data contamination\nissues. To address these problems, we propose \\textbf{SDEval}, the\n\\textit{first} safety dynamic evaluation framework to controllably adjust the\ndistribution and complexity of safety benchmarks. Specifically, SDEval mainly\nadopts three dynamic strategies: text, image, and text-image dynamics to\ngenerate new samples from original benchmarks. We first explore the individual\neffects of text and image dynamics on model safety. Then, we find that\ninjecting text dynamics into images can further impact safety, and conversely,\ninjecting image dynamics into text also leads to safety risks. SDEval is\ngeneral enough to be applied to various existing safety and even capability\nbenchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and\ncapability benchmarks, MMBench and MMVet, show that SDEval significantly\ninfluences safety evaluation, mitigates data contamination, and exposes safety\nlimitations of MLLMs. Code is available at https://github.com/hq-King/SDEval", "AI": {"tldr": "The paper introduces SDEval, a dynamic framework for evaluating the safety of Multimodal Large Language Models (MLLMs).", "motivation": "Existing safety evaluation benchmarks for MLLMs become outdated and face data contamination issues.", "method": "SDEval uses text, image, and text-image dynamics to generate new samples from original benchmarks, addressing these shortcomings.", "result": "Experiments show that SDEval effectively influences safety evaluation, mitigates contamination, and reveals safety limitations in MLLMs.", "conclusion": "SDEval proves to be adaptable for various benchmarks, significantly advancing safety evaluations for MLLMs."}}
{"id": "2508.06065", "pdf": "https://arxiv.org/pdf/2508.06065", "abs": "https://arxiv.org/abs/2508.06065", "authors": ["Daniel Lee", "Nikhil Sharma", "Donghoon Shin", "DaEun Choi", "Harsh Sharma", "Jeonghwan Kim", "Heng Ji"], "title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV", "H.5.2; I.2.7"], "comment": null, "summary": "Generative AI has made image creation more accessible, yet aligning outputs\nwith nuanced creative intent remains challenging, particularly for non-experts.\nExisting tools often require users to externalize ideas through prompts or\nreferences, limiting fluid exploration. We introduce ThematicPlane, a system\nthat enables users to navigate and manipulate high-level semantic concepts\n(e.g., mood, style, or narrative tone) within an interactive thematic design\nplane. This interface bridges the gap between tacit creative intent and system\ncontrol. In our exploratory study (N=6), participants engaged in divergent and\nconvergent creative modes, often embracing unexpected results as inspiration or\niteration cues. While they grounded their exploration in familiar themes,\ndiffering expectations of how themes mapped to outputs revealed a need for more\nexplainable controls. Overall, ThematicPlane fosters expressive, iterative\nworkflows and highlights new directions for intuitive, semantics-driven\ninteraction in generative design tools.", "AI": {"tldr": "The paper introduces ThematicPlane, a system enhancing generative AI design by enabling interactive, high-level semantic control over outputs.", "motivation": "Generative AI struggles to align outputs with nuanced creative intent, especially for non-experts, due to reliance on prompts or references.", "method": "ThematicPlane allows users to manipulate semantic concepts like mood and style interactively, bridging creative intent with system control.", "result": "Participants effectively used ThematicPlane for exploratory and iterative workflows, though they identified a need for more explainable controls.", "conclusion": "ThematicPlane supports expressive creativity and highlights the importance of intuitive, semantics-driven interaction in AI design tools."}}
{"id": "2508.06146", "pdf": "https://arxiv.org/pdf/2508.06146", "abs": "https://arxiv.org/abs/2508.06146", "authors": ["Yuchen Guan", "Chong Sun", "Canmiao Fu", "Zhipeng Huang", "Chun Yuan", "Chen Li"], "title": "Text-guided Visual Prompt DINO for Generic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in multimodal vision models have highlighted limitations\nin late-stage feature fusion and suboptimal query selection for hybrid prompts\nopen-world segmentation, alongside constraints from caption-derived\nvocabularies. To address these challenges, we propose Prompt-DINO, a\ntext-guided visual Prompt DINO framework featuring three key innovations.\nFirst, we introduce an early fusion mechanism that unifies text/visual prompts\nand backbone features at the initial encoding stage, enabling deeper\ncross-modal interactions to resolve semantic ambiguities. Second, we design\norder-aligned query selection for DETR-based architectures, explicitly\noptimizing the structural alignment between text and visual queries during\ndecoding to enhance semantic-spatial consistency. Third, we develop a\ngenerative data engine powered by the Recognize Anything via Prompting (RAP)\nmodel, which synthesizes 0.5B diverse training instances through a dual-path\ncross-verification pipeline, reducing label noise by 80.5% compared to\nconventional approaches. Extensive experiments demonstrate that Prompt-DINO\nachieves state-of-the-art performance on open-world detection benchmarks while\nsignificantly expanding semantic coverage beyond fixed-vocabulary constraints.\nOur work establishes a new paradigm for scalable multimodal detection and data\ngeneration in open-world scenarios. Data&Code are available at\nhttps://github.com/WeChatCV/WeVisionOne.", "AI": {"tldr": "This paper proposes Prompt-DINO, a multimodal framework addressing limitations in open-world segmentation through early fusion, aligned query selection, and a generative data engine, achieving state-of-the-art results.", "motivation": "The paper addresses challenges in late-stage feature fusion, suboptimal query selection, and fixed-vocabulary constraints in open-world segmentation.", "method": "The authors introduce early fusion of text/visual prompts with backbone features, implement order-aligned query selection in DETR-based architectures, and develop a generative data engine to produce diverse training datasets.", "result": "Prompt-DINO achieves state-of-the-art results in open-world detection benchmarks, expands semantic coverage, and reduces label noise by 80.5%.", "conclusion": "Prompt-DINO sets a new standard for scalable multimodal detection and data generation in open-world scenarios."}}
{"id": "2508.05684", "pdf": "https://arxiv.org/pdf/2508.05684", "abs": "https://arxiv.org/abs/2508.05684", "authors": ["Junhao He", "Tianyu Liu", "Jingyuan Zhao", "Benjamin Turner"], "title": "MM-FusionNet: Context-Aware Dynamic Fusion for Multi-modal Fake News Detection with Large Vision-Language Models", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The proliferation of multi-modal fake news on social media poses a\nsignificant threat to public trust and social stability. Traditional detection\nmethods, primarily text-based, often fall short due to the deceptive interplay\nbetween misleading text and images. While Large Vision-Language Models (LVLMs)\noffer promising avenues for multi-modal understanding, effectively fusing\ndiverse modal information, especially when their importance is imbalanced or\ncontradictory, remains a critical challenge. This paper introduces\nMM-FusionNet, an innovative framework leveraging LVLMs for robust multi-modal\nfake news detection. Our core contribution is the Context-Aware Dynamic Fusion\nModule (CADFM), which employs bi-directional cross-modal attention and a novel\ndynamic modal gating network. This mechanism adaptively learns and assigns\nimportance weights to textual and visual features based on their contextual\nrelevance, enabling intelligent prioritization of information. Evaluated on the\nlarge-scale Multi-modal Fake News Dataset (LMFND) comprising 80,000 samples,\nMM-FusionNet achieves a state-of-the-art F1-score of 0.938, surpassing existing\nmulti-modal baselines by approximately 0.5% and significantly outperforming\nsingle-modal approaches. Further analysis demonstrates the model's dynamic\nweighting capabilities, its robustness to modality perturbations, and\nperformance remarkably close to human-level, underscoring its practical\nefficacy and interpretability for real-world fake news detection.", "AI": {"tldr": "MM-FusionNet employs Large Vision-Language Models and introduces dynamic mechanisms for effectively detecting multi-modal fake news, achieving state-of-the-art results.", "motivation": "The paper addresses challenges in detecting multi-modal fake news, which involves deceptive combinations of text and images on social media, surpassing the limitations of traditional text-based methods.", "method": "The proposed MM-FusionNet framework utilizes the Context-Aware Dynamic Fusion Module with bi-directional cross-modal attention and dynamic modal gating to adaptively fuse textual and visual information.", "result": "MM-FusionNet achieved an F1-score of 0.938, outperforming current multi-modal baselines by 0.5% and single-modal methods significantly, while demonstrating robustness and near-human-level performance.", "conclusion": "MM-FusionNet is a practical and interpretable solution for multi-modal fake news detection, offering high accuracy and adaptability for real-world applications."}}
{"id": "2508.06401", "pdf": "https://arxiv.org/pdf/2508.06401", "abs": "https://arxiv.org/abs/2508.06401", "authors": ["Andrew Brown", "Muhammad Roman", "Barry Devereux"], "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.IR"], "comment": "58 pages", "summary": "This systematic review of the research literature on retrieval-augmented\ngeneration (RAG) provides a focused analysis of the most highly cited studies\npublished between 2020 and May 2025. A total of 128 articles met our inclusion\ncriteria. The records were retrieved from ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP).\nRAG couples a neural retriever with a generative language model, grounding\noutput in up-to-date, non-parametric memory while retaining the semantic\ngeneralisation stored in model weights. Guided by the PRISMA 2020 framework, we\n(i) specify explicit inclusion and exclusion criteria based on citation count\nand research questions, (ii) catalogue datasets, architectures, and evaluation\npractices, and (iii) synthesise empirical evidence on the effectiveness and\nlimitations of RAG. To mitigate citation-lag bias, we applied a lower\ncitation-count threshold to papers published in 2025 so that emerging\nbreakthroughs with naturally fewer citations were still captured. This review\nclarifies the current research landscape, highlights methodological gaps, and\ncharts priority directions for future research.", "AI": {"tldr": "This review analyzes 128 notable papers on retrieval-augmented generation (RAG) published between 2020 and May 2025, focusing on datasets, architectures, evaluations, and its effectiveness.", "motivation": "To clarify the current understanding and progression of retrieval-augmented generation (RAG) systems, while identifying gaps and future priorities in research.", "method": "A systematic review guided by PRISMA 2020, analyzing studies with explicit inclusion criteria based on citation count and research questions, and applying adjustments to account for emerging breakthroughs.", "result": "The study catalogs datasets, describes architectures, evaluates practices, and synthesizes evidence on RAG's strengths and weaknesses. Emerging studies from 2025 were inclusively considered.", "conclusion": "The review highlights the current state, gaps, and future directions in RAG research, and provides valuable insights for researchers and practitioners."}}
{"id": "2508.06147", "pdf": "https://arxiv.org/pdf/2508.06147", "abs": "https://arxiv.org/abs/2508.06147", "authors": ["Xuanyu Liu", "Bonan An"], "title": "DSConv: Dynamic Splitting Convolution for Pansharpening", "categories": ["cs.CV"], "comment": null, "summary": "Aiming to obtain a high-resolution image, pansharpening involves the fusion\nof a multi-spectral image (MS) and a panchromatic image (PAN), the low-level\nvision task remaining significant and challenging in contemporary research.\nMost existing approaches rely predominantly on standard convolutions, few\nmaking the effort to adaptive convolutions, which are effective owing to the\ninter-pixel correlations of remote sensing images. In this paper, we propose a\nnovel strategy for dynamically splitting convolution kernels in conjunction\nwith attention, selecting positions of interest, and splitting the original\nconvolution kernel into multiple smaller kernels, named DSConv. The proposed\nDSConv more effectively extracts features of different positions within the\nreceptive field, enhancing the network's generalization, optimization, and\nfeature representation capabilities. Furthermore, we innovate and enrich\nconcepts of dynamic splitting convolution and provide a novel network\narchitecture for pansharpening capable of achieving the tasks more efficiently,\nbuilding upon this methodology. Adequate fair experiments illustrate the\neffectiveness and the state-of-the-art performance attained by\nDSConv.Comprehensive and rigorous discussions proved the superiority and\noptimal usage conditions of DSConv.", "AI": {"tldr": "DSConv, a novel dynamic splitting convolution method combined with attention, enhances pansharpening performance by improving feature extraction and network generalization.", "motivation": "Existing pansharpening methods, used to produce high-resolution images by combining multi-spectral and panchromatic images, lack adaptability due to their heavy reliance on standard convolutions.", "method": "The authors introduce DSConv, a strategy that adaptively splits convolution kernels with attention mechanisms to improve feature extraction at diverse positions, optimizing network performance.", "result": "DSConv achieves state-of-the-art performance in pansharpening tasks and demonstrates improved generalization and feature representation capabilities.", "conclusion": "The study validates DSConv\u2019s effectiveness and superiority through experiments, suggesting its promising applications in advanced pansharpening techniques."}}
{"id": "2508.05696", "pdf": "https://arxiv.org/pdf/2508.05696", "abs": "https://arxiv.org/abs/2508.05696", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Zhiying Li", "Guanggang Geng"], "title": "Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition", "categories": ["cs.CR", "cs.AI"], "comment": "Submitted to the 2025 IEEE International Conference on Trust,\n  Security and Privacy in Computing and Communications (TrustCom)", "summary": "Insider threat detection presents a significant challenge due to the\ndeceptive nature of malicious behaviors, which often resemble legitimate user\noperations. However, existing approaches typically model system logs as flat\nevent sequences, thereby failing to capture the inherent frequency dynamics and\nmultiscale disturbance patterns embedded in user behavior. To address these\nlimitations, we propose Log2Sig, a robust anomaly detection framework that\ntransforms user logs into multivariate behavioral frequency signals,\nintroducing a novel representation of user behavior. Log2Sig employs\nMultivariate Variational Mode Decomposition (MVMD) to extract Intrinsic Mode\nFunctions (IMFs), which reveal behavioral fluctuations across multiple temporal\nscales. Based on this, the model further performs joint modeling of behavioral\nsequences and frequency-decomposed signals: the daily behavior sequences are\nencoded using a Mamba-based temporal encoder to capture long-term dependencies,\nwhile the corresponding frequency components are linearly projected to match\nthe encoder's output dimension. These dual-view representations are then fused\nto construct a comprehensive user behavior profile, which is fed into a\nmultilayer perceptron for precise anomaly detection. Experimental results on\nthe CERT r4.2 and r5.2 datasets demonstrate that Log2Sig significantly\noutperforms state-of-the-art baselines in both accuracy and F1 score.", "AI": {"tldr": "The paper presents Log2Sig, a novel anomaly detection framework that transforms system logs into frequency signals for detecting insider threats, achieving superior performance on two datasets.", "motivation": "Insider threats are challenging to detect due to the deceptive similarity between malicious and legitimate user behaviors. Existing approaches fail to capture complex frequency dynamics and multi-scale patterns in user behavior.", "method": "Log2Sig converts user logs into multivariate behavioral frequency signals, utilizes Multivariate Variational Mode Decomposition (MVMD) to derive behavioral fluctuations across scales, and employs a Mamba-based encoder alongside frequency component projection for capturing and fusing behavioral representations for anomaly detection.", "result": "Log2Sig demonstrated significant improvements in accuracy and F1 score compared to state-of-the-art baselines when tested on the CERT r4.2 and r5.2 datasets.", "conclusion": "The dual-view modeling of user logs in Log2Sig provides a robust framework for insider threat detection, effectively addressing limitations in frequency dynamics and scaling for detection."}}
{"id": "2508.06152", "pdf": "https://arxiv.org/pdf/2508.06152", "abs": "https://arxiv.org/abs/2508.06152", "authors": ["Kaiyuan Jiang", "Ruoxi Sun", "Ying Cao", "Yuqi Xu", "Xinran Zhang", "Junyan Guo", "ChengSheng Deng"], "title": "VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation", "categories": ["cs.CV"], "comment": "17 pages,8 figures", "summary": "We present VISTAR, a user-centric, multi-dimensional benchmark for\ntext-to-image (T2I) evaluation that addresses the limitations of existing\nmetrics. VISTAR introduces a two-tier hybrid paradigm: it employs\ndeterministic, scriptable metrics for physically quantifiable attributes (e.g.,\ntext rendering, lighting) and a novel Hierarchical Weighted P/N Questioning\n(HWPQ) scheme that uses constrained vision-language models to assess abstract\nsemantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study\nwith 120 experts, we defined seven user roles and nine evaluation angles to\nconstruct the benchmark, which comprises 2,845 prompts validated by over 15,000\nhuman pairwise comparisons. Our metrics achieve high human alignment (>75%),\nwith the HWPQ scheme reaching 85.9% accuracy on abstract semantics,\nsignificantly outperforming VQA baselines. Comprehensive evaluation of\nstate-of-the-art models reveals no universal champion, as role-weighted scores\nreorder rankings and provide actionable guidance for domain-specific\ndeployment. All resources are publicly released to foster reproducible T2I\nassessment.", "AI": {"tldr": "VISTAR introduces a user-centric, multi-dimensional benchmark for evaluating text-to-image (T2I) models, combining scriptable metrics with a novel approach that uses vision-language models for abstract semantics.", "motivation": "Existing text-to-image evaluation metrics have limitations in assessing both quantifiable and abstract facets of generated images, necessitating a comprehensive and user-centric framework.", "method": "The approach combines deterministic metrics for measurable attributes with a Hierarchical Weighted P/N Questioning scheme for abstract semantics, derived through a Delphi study and involving 15,000 human comparisons.", "result": "Metrics achieve high alignment with human judgments (>75%), with an 85.9% accuracy in assessing abstract semantics, outperforming existing methods. State-of-the-art models show variable performance based on user role-weighted evaluations.", "conclusion": "There is no universal best model for text-to-image tasks; the VISTAR benchmark provides actionable insights and facilitates tailored assessments for specific domains."}}
{"id": "2508.05690", "pdf": "https://arxiv.org/pdf/2508.05690", "abs": "https://arxiv.org/abs/2508.05690", "authors": ["Meital Shlezinger", "Shay Akirav", "Lei Zhou", "Liang Guo", "Avi Kessel", "Guoliang Li"], "title": "Leveraging large language models for SQL behavior-based database intrusion detection", "categories": ["cs.CR", "cs.DB", "cs.LG"], "comment": null, "summary": "Database systems are extensively used to store critical data across various\ndomains. However, the frequency of abnormal database access behaviors, such as\ndatabase intrusion by internal and external attacks, continues to rise.\nInternal masqueraders often have greater organizational knowledge, making it\neasier to mimic employee behavior effectively. In contrast, external\nmasqueraders may behave differently due to their lack of familiarity with the\norganization. Current approaches lack the granularity needed to detect\nanomalies at the operational level, frequently misclassifying entire sequences\nof operations as anomalies, even though most operations are likely to represent\nnormal behavior. On the other hand, some anomalous behaviors often resemble\nnormal activities, making them difficult for existing detection methods to\nidentify. This paper introduces a two-tiered anomaly detection approach for\nStructured Query Language (SQL) using the Bidirectional Encoder Representations\nfrom Transformers (BERT) model, specifically DistilBERT, a more efficient,\npre-trained version. Our method combines both unsupervised and supervised\nmachine learning techniques to accurately identify anomalous activities while\nminimizing the need for data labeling. First, the unsupervised method uses\nensemble anomaly detectors that flag embedding vectors distant from learned\nnormal patterns of typical user behavior across the database (out-of-scope\nqueries). Second, the supervised method uses fine-tuned transformer-based\nmodels to detect internal attacks with high precision (in-scope queries), using\nrole-labeled classification, even on limited labeled SQL data. Our findings\nmake a significant contribution by providing an effective solution for\nsafeguarding critical database systems from sophisticated threats.", "AI": {"tldr": "The paper presents a two-tier anomaly detection system for SQL using DistilBERT to improve precision in identifying internal and external database threats.", "motivation": "To address the rising threat of abnormal database access behaviors, particularly from internal and external masqueraders, and overcome the limitations of current detection methods, which lack granularity and fail to distinguish between normal and anomalous behaviors.", "method": "The paper proposes a combined unsupervised and supervised machine learning approach using DistilBERT for anomaly detection. Unsupervised methods focus on out-of-scope queries via ensemble detectors, while supervised methods deal with in-scope queries by fine-tuning role-labeled classification models.", "result": "The proposed system effectively identifies anomalous behavior in SQL databases with high accuracy, even on limited labeled data.", "conclusion": "The two-tier method offers a robust solution to protect critical databases from advanced internal and external threats by leveraging advanced transformer-based models and reducing the reliance on data labeling."}}
{"id": "2508.06457", "pdf": "https://arxiv.org/pdf/2508.06457", "abs": "https://arxiv.org/abs/2508.06457", "authors": ["Sanket Badhe"], "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.MA"], "comment": "Accepted at CAMLIS 25: Conference on Applied Machine Learning for\n  Information Security. 10 pages, 3 figures", "summary": "Large Language Models (LLMs) have demonstrated impressive fluency and\nreasoning capabilities, but their potential for misuse has raised growing\nconcern. In this paper, we present ScamAgent, an autonomous multi-turn agent\nbuilt on top of LLMs, capable of generating highly realistic scam call scripts\nthat simulate real-world fraud scenarios. Unlike prior work focused on\nsingle-shot prompt misuse, ScamAgent maintains dialogue memory, adapts\ndynamically to simulated user responses, and employs deceptive persuasion\nstrategies across conversational turns. We show that current LLM safety\nguardrails, including refusal mechanisms and content filters, are ineffective\nagainst such agent-based threats. Even models with strong prompt-level\nsafeguards can be bypassed when prompts are decomposed, disguised, or delivered\nincrementally within an agent framework. We further demonstrate the\ntransformation of scam scripts into lifelike voice calls using modern\ntext-to-speech systems, completing a fully automated scam pipeline. Our\nfindings highlight an urgent need for multi-turn safety auditing, agent-level\ncontrol frameworks, and new methods to detect and disrupt conversational\ndeception powered by generative AI.", "AI": {"tldr": "ScamAgent demonstrates the misuse potential of LLMs in generating convincing scam dialogues and voice calls using AI tools, revealing weaknesses in current safety mechanisms.", "motivation": "To investigate and highlight the vulnerabilities of LLMs in simulated fraud scenarios and the ineffectiveness of existing safeguard mechanisms.", "method": "Developed ScamAgent, an LLM autonomous multi-turn agent, which creates scam call scripts, maintains dialogue memory, adapts to simulated user responses, and uses modern text-to-speech systems to convert scripts into lifelike voice calls.", "result": "Demonstrated that current LLM guardrails are easily bypassed through incremental prompts or disguised inputs, creating realistic and highly persuasive scam scenarios.", "conclusion": "The study underscores the urgent need for improved multi-turn safety mechanisms, agent-level controls, and methods to detect sophisticated conversational deception driven by AI."}}
{"id": "2508.05700", "pdf": "https://arxiv.org/pdf/2508.05700", "abs": "https://arxiv.org/abs/2508.05700", "authors": ["Runze Su", "Jiayin Jin", "Jiacheng Li", "Sihan Wang", "Guangtong Bai", "Zelun Wang", "Li Tang", "Yixiong Meng", "Huasen Wu", "Zhimeng Pan", "Kungang Li", "Han Sun", "Zhifang Liu", "Haoyang Li", "Siping Ji", "Ling Leng", "Prathibha Deshikachar"], "title": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large embedding tables are indispensable in modern recommendation systems,\nthanks to their ability to effectively capture and memorize intricate details\nof interactions among diverse entities. As we explore integrating large\nembedding tables into Pinterest's ads ranking models, we encountered not only\ncommon challenges such as sparsity and scalability, but also several obstacles\nunique to our context. Notably, our initial attempts to train large embedding\ntables from scratch resulted in neutral metrics. To tackle this, we introduced\na novel multi-faceted pretraining scheme that incorporates multiple pretraining\nalgorithms. This approach greatly enriched the embedding tables and resulted in\nsignificant performance improvements. As a result, the multi-faceted large\nembedding tables bring great performance gain on both the Click-Through Rate\n(CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid\nserving infrastructure to overcome GPU memory limits and elevate the\nscalability. This framework has been deployed in the Pinterest Ads system and\nachieved 1.34% online CPC reduction and 2.60% CTR increase with neutral\nend-to-end latency change.", "AI": {"tldr": "The paper addresses challenges in using large embedding tables in Pinterest Ads ranking models, introduces a novel pretraining scheme and CPU-GPU hybrid infrastructure, leading to improved CTR, CVR, and CPC performance.", "motivation": "To enhance the performance of Pinterest's ad-ranking models by tackling scalability issues, sparsity, and challenges in training large embedding tables effectively.", "method": "Introduced a multi-faceted pretraining scheme combining various algorithms and developed a CPU-GPU hybrid serving infrastructure to manage memory limits and scalability.", "result": "Achieved substantial performance improvements, including a 1.34% reduction in CPC, a 2.60% increase in CTR, and neutral latency change upon deployment in the Pinterest Ads system.", "conclusion": "The novel approaches improved performance metrics of Pinterest Ads significantly, demonstrating the utility of optimized embedding table pretraining and hybrid serving frameworks in real-world systems."}}
{"id": "2508.06157", "pdf": "https://arxiv.org/pdf/2508.06157", "abs": "https://arxiv.org/abs/2508.06157", "authors": ["Xiaoxiao Yang", "Meiliang Liu", "Yunfang Xu", "Zijin Li", "Zhengye Si", "Xinyue Yang", "Zhiwen Zhao"], "title": "An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis", "categories": ["cs.CV"], "comment": null, "summary": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder that\nseverely impairs cognitive function and quality of life. Timely intervention in\nAD relies heavily on early and precise diagnosis, which remains challenging due\nto the complex and subtle structural changes in the brain. Most existing deep\nlearning methods focus only on a single plane of structural magnetic resonance\nimaging (sMRI) and struggle to accurately capture the complex and nonlinear\nrelationships among pathological regions of the brain, thus limiting their\nability to precisely identify atrophic features. To overcome these limitations,\nwe propose an innovative framework, MPF-KANSC, which integrates multi-plane\nfusion (MPF) for combining features from the coronal, sagittal, and axial\nplanes, and a Kolmogorov-Arnold Network-guided spatial-channel attention\nmechanism (KANSC) to more effectively learn and represent sMRI atrophy\nfeatures. Specifically, the proposed model enables parallel feature extraction\nfrom multiple anatomical planes, thus capturing more comprehensive structural\ninformation. The KANSC attention mechanism further leverages a more flexible\nand accurate nonlinear function approximation technique, facilitating precise\nidentification and localization of disease-related abnormalities. Experiments\non the ADNI dataset confirm that the proposed MPF-KANSC achieves superior\nperformance in AD diagnosis. Moreover, our findings provide new evidence of\nright-lateralized asymmetry in subcortical structural changes during AD\nprogression, highlighting the model's promising interpretability.", "AI": {"tldr": "This paper proposes MPF-KANSC, a new AI framework for better Alzheimer's disease diagnosis using multi-plane fusion and advanced attention mechanisms.", "motivation": "The motivation is to address the difficulty of early and precise Alzheimer's disease diagnosis caused by subtle and complex brain structural changes, which current deep learning models can't effectively capture.", "method": "The authors developed MPF-KANSC, which uses a multi-plane fusion for combining coronal, sagittal, and axial MRI features, alongside a Kolmogorov-Arnold Network-guided attention mechanism for flexible and precise analysis.", "result": "The proposed model outperformed existing methods in diagnosing Alzheimer's on the ADNI dataset, offering superior accuracy and better feature extraction.", "conclusion": "The MPF-KANSC model not only enhances diagnostic precision but also provides insights into right-lateralized brain structure changes, showing both effectiveness and interpretability."}}
{"id": "2508.05695", "pdf": "https://arxiv.org/pdf/2508.05695", "abs": "https://arxiv.org/abs/2508.05695", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Zhiying Li", "Guanggang Geng", "Jian Weng"], "title": "MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection", "categories": ["cs.CR", "cs.LG"], "comment": "Submitted to the 2025 IEEE International Conference on Data Mining\n  (ICDM)", "summary": "Enterprises are facing increasing risks of insider threats, while existing\ndetection methods are unable to effectively address these challenges due to\nreasons such as insufficient temporal dynamic feature modeling, computational\nefficiency and real-time bottlenecks and cross-modal information island\nproblem. This paper proposes a new insider threat detection framework MambaITD\nbased on the Mamba state space model and cross-modal adaptive fusion. First,\nthe multi-source log preprocessing module aligns heterogeneous data through\nbehavioral sequence encoding, interval smoothing, and statistical feature\nextraction. Second, the Mamba encoder models long-range dependencies in\nbehavioral and interval sequences, and combines the sequence and statistical\ninformation dynamically in combination with the gated feature fusion mechanism.\nFinally, we propose an adaptive threshold optimization method based on\nmaximizing inter-class variance, which dynamically adjusts the decision\nthreshold by analyzing the probability distribution, effectively identifies\nanomalies, and alleviates class imbalance and concept drift. Compared with\ntraditional methods, MambaITD shows significant advantages in modeling\nefficiency and feature fusion capabilities, outperforming Transformer-based\nmethods, and provides a more effective solution for insider threat detection.", "AI": {"tldr": "The paper introduces MambaITD, a novel framework for insider threat detection, addressing challenges like temporal dynamics, computational bottlenecks, and cross-modal data integration.", "motivation": "Existing detection methods fail to adequately address insider threats due to insufficient modeling of time dynamics, real-time inefficiencies, and data silo issues.", "method": "The framework includes multi-source log preprocessing for heterogeneous data alignment, a Mamba encoder for capturing behavioral and interval dependencies, and an adaptive threshold optimization method to improve anomaly detection and handle class imbalances.", "result": "MambaITD demonstrates superior modeling efficiency, feature fusion, and outperforms Transformer-based methods in detecting insider threats.", "conclusion": "The proposed MambaITD framework offers a robust and efficient solution for insider threat detection, overcoming limitations of traditional methods."}}
{"id": "2508.06492", "pdf": "https://arxiv.org/pdf/2508.06492", "abs": "https://arxiv.org/abs/2508.06492", "authors": ["Yuwei Yang", "Zeyu Zhang", "Yunzhong Hou", "Zhuowan Li", "Gaowen Liu", "Ali Payani", "Yuan-Sen Ting", "Liang Zheng"], "title": "Effective Training Data Synthesis for Improving MLLM Chart Understanding", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted by ICCV 2025 (poster). 26 pages, 17 figures", "summary": "Being able to effectively read scientific plots, or chart understanding, is a\ncentral part toward building effective agents for science. However, existing\nmultimodal large language models (MLLMs), especially open-source ones, are\nstill falling behind with a typical success rate of 30%-50% on challenging\nbenchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are\noften restricted by their inadequate similarity to the real charts, which could\ncompromise model training and performance on complex real-world charts. In this\nstudy, we show that modularizing chart generation and diversifying visual\ndetails improves chart understanding capabilities. In particular, we design a\nfive-step data synthesis pipeline, where we separate data and function creation\nfor single plot generation, condition the generation of later subplots on\nearlier ones for multi-subplot figures, visually diversify the generated\nfigures, filter out low quality data, and finally generate the question-answer\n(QA) pairs with GPT-4o. This approach allows us to streamline the generation of\nfine-tuning datasets and introduce the effective chart dataset (ECD), which\ncontains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring\n250+ chart type combinations with high visual complexity. We show that ECD\nconsistently improves the performance of various MLLMs on a range of real-world\nand synthetic test sets. Code, data and models are available at:\nhttps://github.com/yuweiyang-anu/ECD.", "AI": {"tldr": "The paper introduces a five-step data synthesis pipeline for improving chart understanding in multimodal large language models (MLLMs), resulting in a new dataset, the Effective Chart Dataset (ECD), which enhances model performance.", "motivation": "Current multimodal large language models struggle with chart understanding, achieving only a 30%-50% success rate on challenging benchmarks. Existing fine-tuning approaches using synthetic charts are limited by their lack of realism, leading to poor performance on real-world charts.", "method": "The authors developed a modularized five-step data synthesis pipeline to generate training datasets. This pipeline includes separate data and function creation, conditional subplot generation, visual diversification of figures, quality filtering, and question-answer pair generation using GPT-4. The resulting dataset (ECD) consists of over 10,000 chart images and 300,000 QA pairs across 25 topics and 250+ chart types.", "result": "Tests show that incorporating ECD consistently improves MLLM performance on real-world and synthetic benchmarks, enhancing chart understanding capabilities.", "conclusion": "The proposed method and the ECD dataset address challenges in chart understanding and improve the effectiveness of MLLMs. The resources made openly available will facilitate further advances in the field."}}
{"id": "2508.05702", "pdf": "https://arxiv.org/pdf/2508.05702", "abs": "https://arxiv.org/abs/2508.05702", "authors": ["Yan Zhang"], "title": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control", "categories": ["cs.MA", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "The increasing penetration of Distributed Energy Resources (DERs), widespread\nadoption of Electric Vehicles (EVs), and the growing frequency of extreme\nweather events have significantly increased the complexity of power grid\nplanning, operation, and management. Traditional rule-based systems and\nnumerical optimization approaches often struggle with the scale, dynamics, and\nadaptability required by modern power networks. This paper introduces\nGrid-Agent, an autonomous, AI-driven framework that combines Large Language\nModels (LLMs) with multi-agent reinforcement learning to detect and remediate\ngrid violations in real time. Grid-Agent integrates semantic reasoning with\nnumerical precision through a modular agent architecture: a planning agent\ngenerates coordinated action sequences using numerical power flow solvers,\nwhile a validation agent evaluates system stability and action effectiveness\nvia sandboxed execution with safety rollbacks. To ensure scalability,\nGrid-Agent incorporates an adaptive multiscale network representation that\ndynamically selects optimal encoding schemes based on network size and\ncomplexity. The framework enables coordinated violation resolution through\noptimizing switch configurations, battery deployment, and load curtailment\nstrategies. Experimental results in standard IEEE and CIGRE test systems (IEEE\n69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation\nperformance. Additionally, the framework's built-in data collection and\nlearning capabilities enable continuous learning and adaptation to diverse\nnetwork topologies. The autonomous nature of the framework makes it\nparticularly suitable for modern smart grid applications requiring rapid\nresponse to dynamic operating conditions.", "AI": {"tldr": "The paper introduces Grid-Agent, an AI-based framework blending Large Language Models (LLMs) and reinforcement learning to address power grid violations in real time.", "motivation": "The paper is motivated by the increasing challenges in power grid planning, operation, and management due to the rise of Distributed Energy Resources (DERs), Electric Vehicles (EVs), and extreme weather events.", "method": "The proposed system integrates semantic reasoning from Large Language Models (LLMs) with multi-agent reinforcement learning. It uses a modular agent architecture with a planning agent for action generation and a validation agent for stability evaluation. It also employs adaptive multiscale network representation for scalability.", "result": "Experimental results validate Grid-Agent's effectiveness using IEEE and CIGRE test systems, showcasing superior performance in mitigating grid violations and enabling continuous learning for diverse network topologies.", "conclusion": "Grid-Agent demonstrates its potential as an adaptable, autonomous framework well-suited for modern smart grid applications requiring fast and dynamic system responses."}}
{"id": "2508.06160", "pdf": "https://arxiv.org/pdf/2508.06160", "abs": "https://arxiv.org/abs/2508.06160", "authors": ["Zhenbang Du", "Yonggan Fu", "Lifu Wang", "Jiayi Qian", "Xiao Luo", "Yingyan", "Lin"], "title": "Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Diffusion models have shown remarkable success across generative tasks, yet\ntheir high computational demands challenge deployment on resource-limited\nplatforms. This paper investigates a critical question for compute-optimal\ndiffusion model deployment: Under a post-training setting without fine-tuning,\nis it more effective to reduce the number of denoising steps or to use a\ncheaper per-step inference? Intuitively, reducing the number of denoising steps\nincreases the variability of the distributions across steps, making the model\nmore sensitive to compression. In contrast, keeping more denoising steps makes\nthe differences smaller, preserving redundancy, and making post-training\ncompression more feasible. To systematically examine this, we propose PostDiff,\na training-free framework for accelerating pre-trained diffusion models by\nreducing redundancy at both the input level and module level in a post-training\nmanner. At the input level, we propose a mixed-resolution denoising scheme\nbased on the insight that reducing generation resolution in early denoising\nsteps can enhance low-frequency components and improve final generation\nfidelity. At the module level, we employ a hybrid module caching strategy to\nreuse computations across denoising steps. Extensive experiments and ablation\nstudies demonstrate that (1) PostDiff can significantly improve the\nfidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to\nboost efficiency while maintaining decent generation fidelity, reducing\nper-step inference cost is often more effective than reducing the number of\ndenoising steps. Our code is available at\nhttps://github.com/GATECH-EIC/PostDiff.", "AI": {"tldr": "This paper introduces PostDiff, a framework designed to accelerate diffusion models without fine-tuning, optimizing computational efficiency through mixed-resolution inputs and computation reuse.", "motivation": "The motivation is to address the computational challenges of deploying diffusion models on resource-limited platforms and to determine the optimal strategy for compute-efficient deployment without retraining.", "method": "PostDiff reduces inference costs post-training by (1) introducing a mixed-resolution scheme that prioritizes low-frequency components during early denoising steps and (2) utilizing a hybrid module caching strategy for reuse of computations.", "result": "The framework achieves a significant improvement in the fidelity-efficiency trade-off for state-of-the-art diffusion models, demonstrating that reducing per-step inference cost is more effective than reducing the number of denoising steps.", "conclusion": "PostDiff provides an effective solution for accelerating diffusion models, showing that strategic computation reduction can maintain fidelity while optimizing performance."}}
{"id": "2508.05705", "pdf": "https://arxiv.org/pdf/2508.05705", "abs": "https://arxiv.org/abs/2508.05705", "authors": ["Valentina Roquemen-Echeverri", "Taisa Kushner", "Peter G. Jacobs", "Clara Mosquera-Lopez"], "title": "A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Simulating glucose dynamics in individuals with type 1 diabetes (T1D) is\ncritical for developing personalized treatments and supporting data-driven\nclinical decisions. Existing models often miss key physiological aspects and\nare difficult to individualize. Here, we introduce physiologically-constrained\nneural network (NN) digital twins to simulate glucose dynamics in T1D. To\nensure interpretability and physiological consistency, we first build a\npopulation-level NN state-space model aligned with a set of ordinary\ndifferential equations (ODEs) describing glucose regulation. This model is\nformally verified to conform to known T1D dynamics. Digital twins are then\ncreated by augmenting the population model with individual-specific models,\nwhich include personal data, such as glucose management and contextual\ninformation, capturing both inter- and intra-individual variability. We\nvalidate our approach using real-world data from the T1D Exercise Initiative\nstudy. Two weeks of data per participant were split into 5-hour sequences and\nsimulated glucose profiles were compared to observed ones. Clinically relevant\noutcomes were used to assess similarity via paired equivalence t-tests with\npredefined clinical equivalence margins. Across 394 digital twins, glucose\noutcomes were equivalent between simulated and observed data: time in range\n(70-180 mg/dL) was 75.1$\\pm$21.2% (simulated) vs. 74.4$\\pm$15.4% (real;\nP<0.001); time below range (<70 mg/dL) 2.5$\\pm$5.2% vs. 3.0$\\pm$3.3% (P=0.022);\nand time above range (>180 mg/dL) 22.4$\\pm$22.0% vs. 22.6$\\pm$15.9% (P<0.001).\nOur framework can incorporate unmodeled factors like sleep and activity while\npreserving key dynamics. This approach enables personalized in silico testing\nof treatments, supports insulin optimization, and integrates physics-based and\ndata-driven modeling. Code: https://github.com/mosqueralopez/T1DSim_AI", "AI": {"tldr": "The paper presents physiologically-constrained neural network digital twins to simulate glucose dynamics in type 1 diabetes, ensuring physiologically consistent and individually personalized modeling.", "motivation": "To improve the simulation of glucose dynamics in T1D by addressing gaps in existing models that overlook key physiological aspects and personalization potential.", "method": "The authors designed a physiologically-aligned neural network model verified using ordinary differential equations, then individualized models incorporating personal data and contextual information.", "result": "Using real-world T1D data, simulated glucose profiles matched observed data with clinically equivalent outcomes for time in range, time below range, and time above range.", "conclusion": "The framework successfully integrates personalized modeling, allowing in silico testing of treatments, insulin optimization, and blending physics-based and data-driven approaches."}}
{"id": "2508.06169", "pdf": "https://arxiv.org/pdf/2508.06169", "abs": "https://arxiv.org/abs/2508.06169", "authors": ["Wenpeng Xing", "Jie Chen", "Zaifeng Yang", "Changting Lin", "Jianfeng Dong", "Chaochao Chen", "Xun Zhou", "Meng Han"], "title": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Underwater 3D scene reconstruction faces severe challenges from light\nabsorption, scattering, and turbidity, which degrade geometry and color\nfidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF\nextensions such as SeaThru-NeRF incorporate physics-based models, their MLP\nreliance limits efficiency and spatial resolution in hazy environments. We\nintroduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for\nrobust underwater reconstruction. Key innovations include: (1) a plug-and-play\nlearnable underwater image formation module using voxel-based regression for\nspatially varying attenuation and backscatter; and (2) a Physics-Aware\nUncertainty Pruning (PAUP) branch that adaptively removes noisy floating\nGaussians via uncertainty scoring, ensuring artifact-free geometry. The\npipeline operates in training and rendering stages. During training, noisy\nGaussians are optimized end-to-end with underwater parameters, guided by PAUP\npruning and scattering modeling. In rendering, refined Gaussians produce clean\nUnattenuated Radiance Images (URIs) free from media effects, while learned\nphysics enable realistic Underwater Images (UWIs) with accurate light\ntransport. Experiments on SeaThru-NeRF and UWBundle datasets show superior\nperformance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on\nSeaThru-NeRF, with ~65% reduction in floating artifacts.", "AI": {"tldr": "This paper introduces UW-3DGS, a novel underwater 3D reconstruction framework leveraging 3D Gaussian Splatting, addressing light absorption, scattering, and turbidity challenges better than Neural Radiance Fields (NeRF) or its extensions.", "motivation": "Underwater environments hinder traditional 3D reconstruction methods like NeRF due to light-related issues, necessitating a more effective and efficient approach for geometry and color fidelity.", "method": "Key innovations include a learnable underwater image formation module using voxel-based regression and Physics-Aware Uncertainty Pruning (PAUP) to remove noisy artifacts caused by floating Gaussians.", "result": "UW-3DGS demonstrated superior performance on SeaThru-NeRF and UWBundle datasets, yielding PSNR: 27.604, SSIM: 0.868, LPIPS: 0.104, and reducing floating artifacts by ~65%.", "conclusion": "UW-3DGS significantly improves the accuracy and efficiency of underwater 3D reconstruction compared to existing methods, paving the way for enhanced scene fidelity and artifact minimization."}}
{"id": "2508.06170", "pdf": "https://arxiv.org/pdf/2508.06170", "abs": "https://arxiv.org/abs/2508.06170", "authors": ["Ojonugwa Oluwafemi Ejiga Peter", "Akingbola Oluwapemiisin", "Amalahu Chetachi", "Adeniran Opeyemi", "Fahmi Khalifa", "Md Mahmudur Rahman"], "title": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,\nwhich is one of the main causes of cancer-related mortality globally; hence, it\nis deemed an essential technique for the prevention and early detection of\ncolorectal cancer. The research introduces a unique multidirectional\narchitectural framework to automate polyp detection within colonoscopy images\nwhile helping resolve limited healthcare dataset sizes and annotation\ncomplexities. The research implements a comprehensive system that delivers\nsynthetic data generation through Stable Diffusion enhancements together with\ndetection and segmentation algorithms. This detection approach combines Faster\nR-CNN for initial object localization while the Segment Anything Model (SAM)\nrefines the segmentation masks. The faster R-CNN detection algorithm achieved a\nrecall of 93.08% combined with a precision of 88.97% and an F1 score of\n90.98%.SAM is then used to generate the image mask. The research evaluated five\nstate-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,\nand MANet using ResNet34 as a base model. The results demonstrate the superior\nperformance of FPN with the highest scores of PSNR (7.205893) and SSIM\n(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced\nperformance in IoU (64.20%) and Dice score (77.53%).", "AI": {"tldr": "The paper presents a method to enhance automated polyp detection in colonoscopy images using a novel framework combining Stable Diffusion for synthetic data generation with Faster R-CNN and SAM for detection and segmentation.", "motivation": "To enhance early detection and prevention of colorectal cancer, leveraging artificial intelligence to address challenges like limited medical datasets and complex image annotation.", "method": "The method integrates Stable Diffusion for synthetic data generation, Faster R-CNN for object localization, and the SAM model for mask refinement. Various segmentation models, including FPN, U-Net, PSPNet, LinkNet, and MANet, were evaluated using ResNet34.", "result": "Faster R-CNN achieved high recall (93.08%), precision (88.97%), and F1 score (90.98%). Among segmentation models, FPN showed the best PSNR (7.205893) and SSIM (0.492381), U-Net excelled in recall (84.85%), while LinkNet had balanced IoU (64.20%) and Dice score (77.53%).", "conclusion": "The framework demonstrates a high level of effectiveness in enhancing polyp detection and segmentation, by leveraging a combination of state-of-the-art AI techniques and synthetic data generation."}}
{"id": "2508.05709", "pdf": "https://arxiv.org/pdf/2508.05709", "abs": "https://arxiv.org/abs/2508.05709", "authors": ["Boyu Chen", "Siran Chen", "Zhengrong Yue", "Kainan Yan", "Chenyun Yu", "Beibei Kong", "Cheng Lei", "Chengxiang Zhuo", "Zang Li", "Yali Wang"], "title": "G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation", "categories": ["cs.IR", "cs.LG", "cs.MA"], "comment": null, "summary": "User feedback is critical for refining recommendation systems, yet explicit\nfeedback (e.g., likes or dislikes) remains scarce in practice. As a more\nfeasible alternative, inferring user preferences from massive implicit feedback\nhas shown great potential (e.g., a user quickly skipping a recommended video\nusually indicates disinterest). Unfortunately, implicit feedback is often\nnoisy: a user might skip a video due to accidental clicks or other reasons,\nrather than disliking it. Such noise can easily misjudge user interests,\nthereby undermining recommendation performance. To address this issue, we\npropose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which\nleverages contextual guidance from relevant user groups, enabling robust and\nin-depth interpretation of implicit feedback for individual users.\nSpecifically, G-UBS operates via two key agents. First, the User Group Manager\n(UGM) effectively clusters users to generate group profiles utilizing a\n``summarize-cluster-reflect\" workflow based on LLMs. Second, the User Feedback\nModeler (UFM) employs an innovative group-aware reinforcement learning\napproach, where each user is guided by the associated group profiles during the\nreinforcement learning process, allowing UFM to robustly and deeply examine the\nreasons behind implicit feedback. To assess our G-UBS paradigm, we have\nconstructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To\nthe best of our knowledge, this is the first multi-modal benchmark for implicit\nfeedback evaluation in video recommendation, encompassing 15k users, 25k\nvideos, and 933k interaction records with implicit feedback. Extensive\nexperiments on IF-VR demonstrate that G-UBS significantly outperforms\nmainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a\nplay rate > 30% and 14.9% higher reasoning accuracy on IF-VR.", "AI": {"tldr": "Explicit feedback in recommendation systems is rare, making implicit feedback crucial yet noisy. This paper introduces \"Group-aware User Behavior Simulation\" (G-UBS) leveraging contextual user groups to enhance feedback interpretation.", "motivation": "Implicit feedback is easy to obtain but suffers from noise, making it challenging to accurately infer user preferences.", "method": "G-UBS uses a User Group Manager (UGM) to cluster user groups with an LLM-based workflow, and a User Feedback Modeler (UFM) employs group-aware reinforcement learning.", "result": "G-UBS demonstrates superior performance, with a 4.0% increase in video play rate >30% and a 14.9% boost in reasoning accuracy on the IF-VR benchmark.", "conclusion": "The approach provides a robust mechanism to interpret implicit feedback, improving recommendation efficacy and creating a validated multi-modal benchmark."}}
{"id": "2508.05728", "pdf": "https://arxiv.org/pdf/2508.05728", "abs": "https://arxiv.org/abs/2508.05728", "authors": ["Santiago Casas", "Christian Fidler", "Boris Bolliet", "Francisco Villaescusa-Navarro", "Julien Lesgourgues"], "title": "CLAPP: The CLASS LLM Agent for Pair Programming", "categories": ["astro-ph.IM", "astro-ph.CO", "cs.AI", "cs.MA"], "comment": "Code: https://github.com/santiagocasas/clapp, Streamlit app:\n  https://classclapp.streamlit.app", "summary": "We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI\nassistant designed to support researchers working with the Einstein-Boltzmann\nsolver CLASS. CLAPP leverages large language models (LLMs) and domain-specific\nretrieval to provide conversational coding support for CLASS-answering\nquestions, generating code, debugging errors, and producing plots. Its\narchitecture combines multi-agent LLM orchestration, semantic search across\nCLASS documentation, and a live Python execution environment. Deployed as a\nuser-friendly web application, CLAPP lowers the entry barrier for scientists\nunfamiliar with AI tools and enables more productive human-AI collaboration in\ncomputational and numerical cosmology. The app is available at\nhttps://classclapp.streamlit.app", "AI": {"tldr": "CLAPP is an AI assistant combining LLMs, domain-specific retrieval, and Python execution for helping cosmologists work with the CLASS solver.", "motivation": "To facilitate computational and numerical cosmology by providing AI-driven support for the CLASS Einstein-Boltzmann solver.", "method": "CLAPP integrates multi-agent LLM orchestration, semantic search, and a live Python environment deployed in a user-friendly web app.", "result": "CLAPP provides functionality for coding tasks such as debugging, code generation, and plotting, enhancing productivity and collaboration.", "conclusion": "CLAPP simplifies interaction with CLASS for researchers, promoting accessibility and efficiency in cosmology research."}}
{"id": "2508.06189", "pdf": "https://arxiv.org/pdf/2508.06189", "abs": "https://arxiv.org/abs/2508.06189", "authors": ["Cheng Liu", "Daou Zhang", "Tingxu Liu", "Yuhan Wang", "Jinyang Chen", "Yuexuan Li", "Xinying Xiao", "Chenbo Xin", "Ziru Wang", "Weichao Wu"], "title": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration", "categories": ["cs.CV"], "comment": null, "summary": "With the acceleration of urbanization, criminal behavior in public scenes\nposes an increasingly serious threat to social security. Traditional anomaly\ndetection methods based on feature recognition struggle to capture high-level\nbehavioral semantics from historical information, while generative approaches\nbased on Large Language Models (LLMs) often fail to meet real-time\nrequirements. To address these challenges, we propose MA-CBP, a criminal\nbehavior prediction framework based on multi-agent asynchronous collaboration.\nThis framework transforms real-time video streams into frame-level semantic\ndescriptions, constructs causally consistent historical summaries, and fuses\nadjacent image frames to perform joint reasoning over long- and short-term\ncontexts. The resulting behavioral decisions include key elements such as event\nsubjects, locations, and causes, enabling early warning of potential criminal\nactivity. In addition, we construct a high-quality criminal behavior dataset\nthat provides multi-scale language supervision, including frame-level,\nsummary-level, and event-level semantic annotations. Experimental results\ndemonstrate that our method achieves superior performance on multiple datasets\nand offers a promising solution for risk warning in urban public safety\nscenarios.", "AI": {"tldr": "The paper introduces MA-CBP, a framework for predicting criminal behavior by analyzing real-time video streams and historical information, outperforming traditional methods.", "motivation": "Address challenges in criminal behavior detection linked to limitations in traditional feature recognition methods and delays in language model-based approaches.", "method": "MA-CBP utilizes multi-agent asynchronous collaboration to transform video streams into semantic descriptions, construct historical summaries, and perform reasoning across diverse temporal contexts.", "result": "The framework demonstrates superior performance in criminal behavior prediction on multiple datasets, supported by a newly developed annotated dataset.", "conclusion": "MA-CBP offers a robust solution for predicting and warning about criminal activities, enhancing urban public safety measures."}}
{"id": "2508.05744", "pdf": "https://arxiv.org/pdf/2508.05744", "abs": "https://arxiv.org/abs/2508.05744", "authors": ["Aizhan Akhmetzhanova", "Carolina Cuesta-Lazaro", "Siddharth Mishra-Sharma"], "title": "Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows", "categories": ["astro-ph.CO", "astro-ph.IM", "cs.LG"], "comment": "14 + 5 pages, 6 + 4 figures", "summary": "Current and upcoming cosmological surveys will produce unprecedented amounts\nof high-dimensional data, which require complex high-fidelity forward\nsimulations to accurately model both physical processes and systematic effects\nwhich describe the data generation process. However, validating whether our\ntheoretical models accurately describe the observed datasets remains a\nfundamental challenge. An additional complexity to this task comes from\nchoosing appropriate representations of the data which retain all the relevant\ncosmological information, while reducing the dimensionality of the original\ndataset. In this work we present a novel framework combining scale-dependent\nneural summary statistics with normalizing flows to detect model\nmisspecification in cosmological simulations through Bayesian evidence\nestimation. By conditioning our neural network models for data compression and\nevidence estimation on the smoothing scale, we systematically identify where\ntheoretical models break down in a data-driven manner. We demonstrate a first\napplication to our approach using matter and gas density fields from three\nCAMELS simulation suites with different subgrid physics implementations.", "AI": {"tldr": "The paper introduces a novel framework that uses neural networks and normalizing flows to detect theoretical model errors in cosmological data simulations.", "motivation": "Current cosmological data analysis faces challenges in validating theoretical models amidst high-dimensional data and choosing suitable data representations that retain critical information.", "method": "The framework combines scale-dependent neural summary statistics and normalizing flows, conditioned on smoothing scales, to perform Bayesian evidence estimation and detect model misspecifications.", "result": "The method was applied to matter and gas density fields from CAMELS simulation suites, demonstrating its ability to systematically pinpoint where theoretical models fail.", "conclusion": "This approach enhances the ability to validate cosmological models through a data-driven analysis, ensuring robust model simulations for upcoming cosmological surveys."}}
{"id": "2508.06191", "pdf": "https://arxiv.org/pdf/2508.06191", "abs": "https://arxiv.org/abs/2508.06191", "authors": ["Ruixiang Tang", "Jianglong Qin", "Mingda Zhang", "Yan Song", "Yi Wu", "Wei Wu"], "title": "A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet", "categories": ["cs.CV", "68T45, 92C55", "I.4.6; I.5.4; J.3"], "comment": "12 pages, 6 figures, 2 tables", "summary": "Pleural effusion semantic segmentation can significantly enhance the accuracy\nand timeliness of clinical diagnosis and treatment by precisely identifying\ndisease severity and lesion areas. Currently, semantic segmentation of pleural\neffusion CT images faces multiple challenges. These include similar gray levels\nbetween effusion and surrounding tissues, blurred edges, and variable\nmorphology. Existing methods often struggle with diverse image variations and\ncomplex edges, primarily because direct feature concatenation causes semantic\ngaps. To address these challenges, we propose the Dual-Branch Interactive\nFusion Attention model (DBIF-AUNet). This model constructs a densely nested\nskip-connection network and innovatively refines the Dual-Domain Feature\nDisentanglement module (DDFD). The DDFD module orthogonally decouples the\nfunctions of dual-domain modules to achieve multi-scale feature complementarity\nand enhance characteristics at different levels. Concurrently, we design a\nBranch Interaction Attention Fusion module (BIAF) that works synergistically\nwith the DDFD. This module dynamically weights and fuses global, local, and\nfrequency band features, thereby improving segmentation robustness.\nFurthermore, we implement a nested deep supervision mechanism with hierarchical\nadaptive hybrid loss to effectively address class imbalance. Through validation\non 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet\nachieved IoU and Dice scores of 80.1% and 89.0% respectively. These results\noutperform state-of-the-art medical image segmentation models U-Net++ and\nSwin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant\noptimization in segmentation accuracy for complex pleural effusion CT images.", "AI": {"tldr": "This paper proposes DBIF-AUNet, a novel model for semantic segmentation of pleural effusion in CT images, achieving better accuracy and robustness than existing methods.", "motivation": "Semantic segmentation of pleural effusion CT images is crucial for enhancing clinical diagnosis and treatment, but faces challenges due to similar gray levels, blurred edges, and varying morphology.", "method": "The paper introduces DBIF-AUNet, which includes a Dual-Domain Feature Disentanglement module (DDFD) for feature complementarity, a Branch Interaction Attention Fusion module (BIAF) for dynamic feature fusion, and a nested deep supervision mechanism for addressing class imbalance.", "result": "DBIF-AUNet demonstrates IoU and Dice scores of 80.1% and 89.0%, outperforming U-Net++ and Swin-UNet models by significant margins.", "conclusion": "DBIF-AUNet effectively optimizes segmentation accuracy and robustness for pleural effusion CT images, proving its potential for clinical applicability and outperforming state-of-the-art methods."}}
{"id": "2508.05762", "pdf": "https://arxiv.org/pdf/2508.05762", "abs": "https://arxiv.org/abs/2508.05762", "authors": ["Sajid Mannan", "Vaibhav Bihani", "Carmelo Gonzales", "Kin Long Kelvin Lee", "Nitya Nand Gosvami", "Sayan Ranu", "Santiago Miret", "N M Anoop Krishnan"], "title": "Evaluating Universal Machine Learning Force Fields Against Experimental Measurements", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Universal machine learning force fields (UMLFFs) promise to revolutionize\nmaterials science by enabling rapid atomistic simulations across the periodic\ntable. However, their evaluation has been limited to computational benchmarks\nthat may not reflect real-world performance. Here, we present UniFFBench, a\ncomprehensive framework for evaluating UMLFFs against experimental measurements\nof ~1,500 carefully curated mineral structures spanning diverse chemical\nenvironments, bonding types, structural complexity, and elastic properties. Our\nsystematic evaluation of six state-of-the-art UMLFFs reveals a substantial\nreality gap: models achieving impressive performance on computational\nbenchmarks often fail when confronted with experimental complexity. Even the\nbest-performing models exhibit higher density prediction error than the\nthreshold required for practical applications. Most strikingly, we observe\ndisconnects between simulation stability and mechanical property accuracy, with\nprediction errors correlating with training data representation rather than the\nmodeling method. These findings demonstrate that while current computational\nbenchmarks provide valuable controlled comparisons, they may overestimate model\nreliability when extrapolated to experimentally complex chemical spaces.\nAltogether, UniFFBench establishes essential experimental validation standards\nand reveals systematic limitations that must be addressed to achieve truly\nuniversal force field capabilities.", "AI": {"tldr": "This paper introduces UniFFBench, a framework to evaluate universal machine learning force fields (UMLFFs) against experimental mineral structures. Findings show current UMLFFs fail to meet real-world requirements, revealing systematic limitations.", "motivation": "Universal machine learning force fields have the potential to transform materials science but lack rigorous experimental validation to test their reliability beyond computational benchmarks.", "method": "UniFFBench was used to assess six UMLFF models against experimental measurements of mineral structures, analyzing their density prediction, simulation stability, and representation of mechanical properties.", "result": "The study found significant gaps between computational benchmark results and experimental performance. Density prediction errors exceeded practical thresholds, and the errors were influenced by dataset representation rather than modeling approaches.", "conclusion": "While computational benchmarks are useful for comparisons, they overestimate UMLFF reliability in complex chemical spaces. UniFFBench establishes essential validation standards to address this gap and improve universal force field models."}}
{"id": "2508.06202", "pdf": "https://arxiv.org/pdf/2508.06202", "abs": "https://arxiv.org/abs/2508.06202", "authors": ["Chang Che", "Ziqi Wang", "Pengwan Yang", "Qi Wang", "Hui Ma", "Zenglin Shi"], "title": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language\nModels (MLLMs) to incrementally learn new tasks over time. However, this\nprocess is challenged by catastrophic forgetting, where performance on\npreviously learned tasks deteriorates as the model adapts to new ones. A common\napproach to mitigate forgetting is architecture expansion, which introduces\ntask-specific modules to prevent interference. Yet, existing methods often\nexpand entire layers for each task, leading to significant parameter overhead\nand poor scalability. To overcome these issues, we introduce LoRA in LoRA\n(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in\nMLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,\napplies an additional low-rank decomposition to matrix B to minimize\ntask-specific parameters, and incorporates a cosine-regularized stability loss\nto preserve consistency in shared representations over time. Extensive\nexperiments on a diverse CVIT benchmark show that LiLoRA consistently achieves\nsuperior performance in sequential task learning while significantly improving\nparameter efficiency compared to existing approaches.", "AI": {"tldr": "This paper proposes LiLoRA, an efficient method to enable Continual Visual Instruction Tuning (CVIT) for multimodal large language models (MLLMs) with minimal parameter expansion while addressing catastrophic forgetting.", "motivation": "The motivation is to address the challenge of catastrophic forgetting in CVIT for MLLMs while reducing parameter overhead and improving scalability in task-specific modules.", "method": "The paper introduces LiLoRA, which shares LoRA matrix A across tasks, applies a low-rank decomposition to matrix B for task-specific parameter minimization, and uses cosine-regularized stability loss to maintain shared representation consistency.", "result": "Experiments demonstrate that LiLoRA outperforms existing methods in sequential task learning and substantially improves parameter efficiency on a diverse CVIT benchmark.", "conclusion": "LiLoRA is a scalable and efficient solution for CVIT, enabling MLLMs to continuously learn tasks with significantly less parameter redundancy and better performance."}}
{"id": "2508.06203", "pdf": "https://arxiv.org/pdf/2508.06203", "abs": "https://arxiv.org/abs/2508.06203", "authors": ["Zhaopeng Gu", "Bingke Zhu", "Guibo Zhu", "Yingying Chen", "Wei Ge", "Ming Tang", "Jinqiao Wang"], "title": "AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Anomaly detection is a critical task across numerous domains and modalities,\nyet existing methods are often highly specialized, limiting their\ngeneralizability. These specialized models, tailored for specific anomaly types\nlike textural defects or logical errors, typically exhibit limited performance\nwhen deployed outside their designated contexts. To overcome this limitation,\nwe propose AnomalyMoE, a novel and universal anomaly detection framework based\non a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the\ncomplex anomaly detection problem into three distinct semantic hierarchies:\nlocal structural anomalies, component-level semantic anomalies, and global\nlogical anomalies. AnomalyMoE correspondingly employs three dedicated expert\nnetworks at the patch, component, and global levels, and is specialized in\nreconstructing features and identifying deviations at its designated semantic\nlevel. This hierarchical design allows a single model to concurrently\nunderstand and detect a wide spectrum of anomalies. Furthermore, we introduce\nan Expert Information Repulsion (EIR) module to promote expert diversity and an\nExpert Selection Balancing (ESB) module to ensure the comprehensive utilization\nof all experts. Experiments on 8 challenging datasets spanning industrial\nimaging, 3D point clouds, medical imaging, video surveillance, and logical\nanomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art\nperformance, significantly outperforming specialized methods in their\nrespective domains.", "AI": {"tldr": "AnomalyMoE is a general anomaly detection framework that uses a Mixture-of-Experts (MoE) architecture to address diverse anomaly types across different semantic levels, significantly outperforming specialized models.", "motivation": "Existing anomaly detection models are highly specialized and often fail to generalize across diverse types of anomalies, creating an urgent need for a universal approach.", "method": "AnomalyMoE employs a hierarchical Mixture-of-Experts (MoE) architecture with three distinct expert networks focused on patch-level, component-level, and global-level anomalies. It incorporates Expert Information Repulsion (EIR) and Expert Selection Balancing (ESB) modules for diversity and comprehensive utilization.", "result": "AnomalyMoE sets new state-of-the-art benchmarks across 8 datasets spanning varied tasks, outperforming domain-specific methods significantly.", "conclusion": "The hierarchical design and expert diversity of AnomalyMoE enable robust anomaly detection, establishing its utility as a universal framework across diverse domains."}}
{"id": "2508.06205", "pdf": "https://arxiv.org/pdf/2508.06205", "abs": "https://arxiv.org/abs/2508.06205", "authors": ["Ruiyan Wang", "Lin Zuo", "Zonghao Lin", "Qiang Wang", "Zhengxue Cheng", "Rong Xie", "Jun Ling", "Li Song"], "title": "PA-HOI: A Physics-Aware Human and Object Interaction Dataset", "categories": ["cs.CV"], "comment": null, "summary": "The Human-Object Interaction (HOI) task explores the dynamic interactions\nbetween humans and objects in physical environments, providing essential\nbiomechanical and cognitive-behavioral foundations for fields such as robotics,\nvirtual reality, and human-computer interaction. However, existing HOI data\nsets focus on details of affordance, often neglecting the influence of physical\nproperties of objects on human long-term motion. To bridge this gap, we\nintroduce the PA-HOI Motion Capture dataset, which highlights the impact of\nobjects' physical attributes on human motion dynamics, including human posture,\nmoving velocity, and other motion characteristics. The dataset comprises 562\nmotion sequences of human-object interactions, with each sequence performed by\nsubjects of different genders interacting with 35 3D objects that vary in size,\nshape, and weight. This dataset stands out by significantly extending the scope\nof existing ones for understanding how the physical attributes of different\nobjects influence human posture, speed, motion scale, and interacting\nstrategies. We further demonstrate the applicability of the PA-HOI dataset by\nintegrating it with existing motion generation methods, validating its capacity\nto transfer realistic physical awareness.", "AI": {"tldr": "This paper introduces the PA-HOI dataset for studying the impact of physical attributes of objects on human motion dynamics.", "motivation": "Existing HOI datasets overlook the influence of physical object properties on human long-term motion.", "method": "The authors developed the PA-HOI motion capture dataset containing 562 human-object interaction sequences, performed with 35 varied 3D objects.", "result": "The dataset features a wide range of human posture, velocity, and interaction characteristics, extending the scope of existing studies.", "conclusion": "PA-HOI enables realistic motion generation while incorporating physical awareness, bridging a gap in HOI studies."}}
{"id": "2508.06218", "pdf": "https://arxiv.org/pdf/2508.06218", "abs": "https://arxiv.org/abs/2508.06218", "authors": ["Zhiyan Bo", "Laura C. Coates", "Bartlomiej W. Papiez"], "title": "Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning", "categories": ["cs.CV"], "comment": "Accepted by MICCAI AMAI Workshop 2025", "summary": "The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials\nto quantify radiographic damage in Rheumatoid Arthritis (RA), but its\ncomplexity has limited its adoption in routine clinical practice. To address\nthe inefficiency of manual scoring, this work proposes a two-stage pipeline for\ninterpretable image-level SvdH score prediction using dual-hand radiographs.\nOur approach extracts disease-relevant image regions and integrates them using\nattention-based multiple instance learning to generate image-level features for\nprediction. We propose two region extraction schemes: 1) sampling image tiles\nmost likely to contain abnormalities, and 2) cropping patches containing\ndisease-relevant joints. With Scheme 2, our best individual score prediction\nmodel achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root\nmean squared error (RMSE) of 15.73. Ensemble learning further boosted\nprediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving\nstate-of-the-art performance that is comparable to that of experienced\nradiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively\nidentified and made decisions based on anatomical structures which clinicians\nconsider relevant to RA progression.", "AI": {"tldr": "This paper introduces a two-stage pipeline to automate the scoring of radiographic damage in RA using dual-hand radiographs, achieving near-radiologist-level accuracy.", "motivation": "The paper aims to address the inefficiency and complexity of manual SvdH scoring for RA, which prevents its widespread use in routine clinical practice.", "method": "The authors propose a pipeline using dual-hand radiographs with two region extraction schemes: sampling image tiles containing abnormalities and cropping patches of disease-relevant joints. Multiple instance learning is employed for prediction.", "result": "The best model achieved PCC of 0.943 and RMSE of 15.73, while ensemble learning slightly improved these metrics to PCC of 0.945 and RMSE of 15.57, comparable to radiologists.", "conclusion": "The automated pipeline effectively replicates radiologists\u2019 accuracy and uses interpretable anatomical structures relevant to RA progression, making it promising for routine use."}}
{"id": "2508.06224", "pdf": "https://arxiv.org/pdf/2508.06224", "abs": "https://arxiv.org/abs/2508.06224", "authors": ["Guoyu Zhou", "Jing Zhang", "Yi Yan", "Hui Zhang", "Li Zhuo"], "title": "TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images", "categories": ["cs.CV"], "comment": "Submitted to GRSL", "summary": "Semantic segmentation of urban remote sensing images (URSIs) is crucial for\napplications such as urban planning and environmental monitoring. However,\ngeospatial objects often exhibit subtle texture differences and similar spatial\nstructures, which can easily lead to semantic ambiguity and misclassification.\nMoreover, challenges such as irregular object shapes, blurred boundaries, and\noverlapping spatial distributions of semantic objects contribute to complex and\ndiverse edge morphologies, further complicating accurate segmentation. To\ntackle these issues, we propose a texture-aware and edge-guided Transformer\n(TEFormer) that integrates texture awareness and edge-guidance mechanisms for\nsemantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is\ndesigned to capture fine-grained texture differences between visually similar\ncategories to enhance semantic discrimination. Then, an edge-guided tri-branch\ndecoder (Eg3Head) is constructed to preserve local edges and details for\nmultiscale context-awareness. Finally, an edge-guided feature fusion module\n(EgFFM) is to fuse contextual and detail information with edge information to\nrealize refined semantic segmentation. Extensive experiments show that TEFormer\nachieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and\nLoveDA datasets, respectively, shows the effectiveness in URSI semantic\nsegmentation.", "AI": {"tldr": "The paper introduces TEFormer, a novel approach to improve semantic segmentation in urban remote sensing images using texture-aware and edge-guided mechanisms to address challenges like semantic ambiguity and irregular object shapes.", "motivation": "Urban remote sensing image segmentation faces challenges like subtle texture differences, similar spatial structures, irregular shapes, and overlapping distributions, which lead to misclassification and semantic ambiguity.", "method": "TEFormer integrates a texture-aware module, an edge-guided tri-branch decoder, and an edge-guided feature fusion module to enhance fine-grained texture detection, preserve edges, and fuse edge-contextual information.", "result": "TEFormer achieves impressive mIoU scores of 88.57% (Potsdam), 81.46% (Vaihingen), and 53.55% (LoveDA datasets), showcasing superior performance in urban remote sensing image segmentation.", "conclusion": "TEFormer effectively tackles the complexities of URSI segmentation by improving semantic discrimination and edge-preserving capabilities, demonstrating strong results across various datasets."}}
{"id": "2508.05878", "pdf": "https://arxiv.org/pdf/2508.05878", "abs": "https://arxiv.org/abs/2508.05878", "authors": ["Martyna Majchrzak", "Jacek Ma\u0144dziuk"], "title": "Training chord recognition models on artificially generated audio", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "One of the challenging problems in Music Information Retrieval is the\nacquisition of enough non-copyrighted audio recordings for model training and\nevaluation. This study compares two Transformer-based neural network models for\nchord sequence recognition in audio recordings and examines the effectiveness\nof using an artificially generated dataset for this purpose. The models are\ntrained on various combinations of Artificial Audio Multitracks (AAM),\nSchubert's Winterreise Dataset, and the McGill Billboard Dataset and evaluated\nwith three metrics: Root, MajMin and Chord Content Metric (CCM). The\nexperiments prove that even though there are certainly differences in\ncomplexity and structure between artificially generated and human-composed\nmusic, the former can be useful in certain scenarios. Specifically, AAM can\nenrich a smaller training dataset of music composed by a human or can even be\nused as a standalone training set for a model that predicts chord sequences in\npop music, if no other data is available.", "AI": {"tldr": "This paper compares two Transformer-based models for chord sequence recognition in audio and evaluates the utility of an artificially generated dataset for training.", "motivation": "The motivation is to address the challenge of acquiring sufficient non-copyrighted audio recordings for training and evaluating models in Music Information Retrieval.", "method": "Two Transformer-based neural network models were trained on artificial and human-composed datasets and evaluated with three metrics: Root, MajMin, and CCM.", "result": "The study found that Artificial Audio Multitracks (AAM) can supplement smaller human-composed datasets or serve as standalone training data for chord sequence prediction in pop music when no other data is available.", "conclusion": "Artificially generated music datasets, despite differences from human-composed music, are valuable for enriching training data or as a substitute in the absence of human-composed datasets."}}
{"id": "2508.06228", "pdf": "https://arxiv.org/pdf/2508.06228", "abs": "https://arxiv.org/abs/2508.06228", "authors": ["Daniel Feijoo", "Paula Garrido-Mellado", "Jaesung Rim", "Alvaro Garcia", "Marcos V. Conde"], "title": "Towards Unified Image Deblurring using a Mixture-of-Experts Decoder", "categories": ["cs.CV"], "comment": "Preprint. Under review", "summary": "Image deblurring, removing blurring artifacts from images, is a fundamental\ntask in computational photography and low-level computer vision. Existing\napproaches focus on specialized solutions tailored to particular blur types,\nthus, these solutions lack generalization. This limitation in current methods\nimplies requiring multiple models to cover several blur types, which is not\npractical in many real scenarios. In this paper, we introduce the first\nall-in-one deblurring method capable of efficiently restoring images affected\nby diverse blur degradations, including global motion, local motion, blur in\nlow-light conditions, and defocus blur. We propose a mixture-of-experts (MoE)\ndecoding module, which dynamically routes image features based on the\nrecognized blur degradation, enabling precise and efficient restoration in an\nend-to-end manner. Our unified approach not only achieves performance\ncomparable to dedicated task-specific models, but also demonstrates remarkable\nrobustness and generalization capabilities on unseen blur degradation\nscenarios.", "AI": {"tldr": "The paper presents an all-in-one image deblurring approach using a mixture-of-experts decoding module that generalizes across various blur types and scenarios.", "motivation": "Existing deblurring approaches are tailored to specific blur types, resulting in poor generalization and requiring multiple models for diverse scenarios, which is impractical.", "method": "The authors propose a mixture-of-experts (MoE) decoding module that dynamically routes image features based on identified blur degradations for efficient image restoration in an end-to-end framework.", "result": "The proposed method performs comparably to specialized models while showcasing exceptional robustness and generalization to unseen blur conditions.", "conclusion": "The all-in-one approach offers a practical, efficient, and robust deblurring solution for varied blur types, addressing limitations of task-specific methods."}}
{"id": "2508.05908", "pdf": "https://arxiv.org/pdf/2508.05908", "abs": "https://arxiv.org/abs/2508.05908", "authors": ["Shreshth A. Malik", "Tiarnan A. S. Doherty", "Benjamin Colmey", "Stephen J. Roberts", "Yarin Gal", "Paul A. Midgley"], "title": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "High-fidelity electron microscopy simulations required for quantitative\ncrystal structure refinements face a fundamental challenge: while physical\ninteractions are well-described theoretically, real-world experimental effects\nare challenging to model analytically. To address this gap, we present a novel\nhybrid physics-machine learning framework that integrates differentiable\nphysical simulations with neural networks. By leveraging automatic\ndifferentiation throughout the simulation pipeline, our method enables\ngradient-based joint optimization of physical parameters and neural network\ncomponents representing experimental variables, offering superior scalability\ncompared to traditional second-order methods. We demonstrate this framework\nthrough application to three-dimensional electron diffraction (3D-ED) structure\nrefinement, where our approach learns complex thickness distributions directly\nfrom diffraction data rather than relying on simplified geometric models. This\nmethod achieves state-of-the-art refinement performance across synthetic and\nexperimental datasets, recovering atomic positions, thermal displacements, and\nthickness profiles with high fidelity. The modular architecture proposed can\nnaturally be extended to accommodate additional physical phenomena and extended\nto other electron microscopy techniques. This establishes differentiable hybrid\nmodeling as a powerful new paradigm for quantitative electron microscopy, where\nexperimental complexities have historically limited analysis.", "AI": {"tldr": "The paper introduces a hybrid physics-machine learning framework that combines differentiable physical simulations with neural networks to improve high-fidelity quantitative crystal structure refinements in electron microscopy.", "motivation": "Real-world experimental effects in electron microscopy are difficult to model analytically despite theoretical descriptions of physical interactions.", "method": "The framework uses automatic differentiation for gradient-based joint optimization of physical parameters and neural network components. It is applied to 3D electron diffraction structure refinement, learning complex experimental variables directly from the data.", "result": "The proposed approach achieves state-of-the-art refinement performance, recovering accurate atomic positions, thermal displacements, and thickness profiles in both synthetic and experimental data.", "conclusion": "The hybrid framework provides a powerful paradigm for enhancing quantitative electron microscopy analysis and can be extended to incorporate additional physical phenomena and other microscopy techniques."}}
{"id": "2508.05933", "pdf": "https://arxiv.org/pdf/2508.05933", "abs": "https://arxiv.org/abs/2508.05933", "authors": ["Xueyuan Xu", "Wenjia Dong", "Fulin Wei", "Li Zhuo"], "title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The affective brain-computer interface is a crucial technology for affective\ninteraction and emotional intelligence, emerging as a significant area of\nresearch in the human-computer interaction. Compared to single-type features,\nmulti-type EEG features provide a multi-level representation for analyzing\nmulti-dimensional emotions. However, the high dimensionality of multi-type EEG\nfeatures, combined with the relatively small number of high-quality EEG\nsamples, poses challenges such as classifier overfitting and suboptimal\nreal-time performance in multi-dimensional emotion recognition. Moreover,\npractical applications of affective brain-computer interface frequently\nencounters partial absence of multi-dimensional emotional labels due to the\nopen nature of the acquisition environment, and ambiguity and variability in\nindividual emotion perception. To address these challenges, this study proposes\na novel EEG feature selection method for missing multi-dimensional emotion\nrecognition. The method leverages adaptive orthogonal non-negative matrix\nfactorization to reconstruct the multi-dimensional emotional label space\nthrough second-order and higher-order correlations, which could reduce the\nnegative impact of missing values and outliers on label reconstruction.\nSimultaneously, it employs least squares regression with graph-based manifold\nlearning regularization and global feature redundancy minimization\nregularization to enable EEG feature subset selection despite missing\ninformation, ultimately achieving robust EEG-based multi-dimensional emotion\nrecognition. Simulation experiments on three widely used multi-dimensional\nemotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method\noutperforms thirteen advanced feature selection methods in terms of robustness\nfor EEG emotional feature selection.", "AI": {"tldr": "This study addresses the issue of high-dimensional EEG data and missing emotional labels in brain-computer interfaces through a novel feature selection method, achieving superior performance in multi-dimensional emotion recognition.", "motivation": "Affective brain-computer interfaces face challenges such as high-dimensional EEG data, small sample sizes, and missing emotional labels, limiting their robustness and real-time application.", "method": "The paper proposes using adaptive orthogonal non-negative matrix factorization for reconstructing emotional label spaces and least squares regression with graph-based manifold learning and global redundancy minimization for feature selection.", "result": "The method demonstrated superior performance compared to thirteen advanced alternatives in simulations conducted on three EEG emotional datasets: DREAMER, DEAP, and HDED.", "conclusion": "The proposed feature selection approach enhances robustness for multi-dimensional emotion recognition, addressing key challenges in affective brain-computer interfaces."}}
{"id": "2508.06248", "pdf": "https://arxiv.org/pdf/2508.06248", "abs": "https://arxiv.org/abs/2508.06248", "authors": ["Andrii Yermakov", "Jan Cech", "Jiri Matas", "Mario Fritz"], "title": "Deepfake Detection that Generalizes Across Benchmarks", "categories": ["cs.CV"], "comment": null, "summary": "The generalization of deepfake detectors to unseen manipulation techniques\nremains a challenge for practical deployment. Although many approaches adapt\nfoundation models by introducing significant architectural complexity, this\nwork demonstrates that robust generalization is achievable through a\nparameter-efficient adaptation of a pre-trained CLIP vision encoder. The\nproposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters\n(0.03% of the total) and enhances generalization by enforcing a hyperspherical\nfeature manifold using L2 normalization and latent space augmentations.\n  We conducted an extensive evaluation on 13 benchmark datasets spanning from\n2019 to 2025. The proposed method achieves state-of-the-art performance,\noutperforming more complex, recent approaches in average cross-dataset AUROC.\nOur analysis yields two primary findings for the field: 1) training on paired\nreal-fake data from the same source video is essential for mitigating shortcut\nlearning and improving generalization, and 2) detection difficulty on academic\ndatasets has not strictly increased over time, with models trained on older,\ndiverse datasets showing strong generalization capabilities.\n  This work delivers a computationally efficient and reproducible method,\nproving that state-of-the-art generalization is attainable by making targeted,\nminimal changes to a pre-trained CLIP model. The code will be made publicly\navailable upon acceptance.", "AI": {"tldr": "This paper proposes LNCLIP-DF, a parameter-efficient deepfake detection model using minimal adaptation of a pre-trained CLIP encoder, achieving superior generalization to unseen techniques.", "motivation": "Deepfake detectors often struggle with generalizing to unseen manipulation techniques, and current solutions involve complex architectures, limiting practical deployment.", "method": "The LNCLIP-DF method fine-tunes only Layer Normalization parameters of a CLIP vision encoder, introducing L2 normalization and latent space augmentations to enhance generalization.", "result": "Extensive evaluations across 13 benchmark datasets from 2019 to 2025 show LNCLIP-DF achieving state-of-the-art performance in average cross-dataset AUROC, surpassing more complex methods.", "conclusion": "Minimal, targeted adaptations to a pre-trained CLIP model can deliver superior generalization in deepfake detection, providing a computationally efficient and reproducible approach for practical deployment."}}
{"id": "2508.05934", "pdf": "https://arxiv.org/pdf/2508.05934", "abs": "https://arxiv.org/abs/2508.05934", "authors": ["Xueyuan Xu", "Tianze Yu", "Wenjia Dong", "Fulin Wei", "Li Zhuo"], "title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Recently, multi-modal physiological signals based emotion recognition has\ngarnered increasing attention in the field of brain-computer interfaces.\nNevertheness, the associated multi-modal physiological features are often\nhigh-dimensional and inevitably include irrelevant, redundant, and noisy\nrepresentation, which can easily lead to overfitting, poor performance, and\nhigh computational complexity in emotion classifiers. Feature selection has\nbeen widely applied to address these challenges. However, previous studies\ngenerally assumed that multi-modal physiological data are complete, whereas in\nreality, the data are often incomplete due to the openness of the acquisition\nand operational environment. For example, a part of samples are available in\nseveral modalities but not in others. To address this issue, we propose a novel\nmethod for incomplete multi-modal physiological signal feature selection called\nadaptive shared latent structure learning (ASLSL). Based on the property that\nsimilar features share similar emotional labels, ASLSL employs adaptive shared\nlatent structure learning to explore a common latent space shared for\nincomplete multi-modal physiological signals and multi-dimensional emotional\nlabels, thereby mitigating the impact of missing information and mining\nconsensus information. Two most popular multi-modal physiological emotion\ndatasets (DEAP and DREAMER) with multi-dimensional emotional labels were\nutilized to compare the performance between compare ASLSL and seventeen feature\nselection methods. Comprehensive experimental results on these datasets\ndemonstrate the effectiveness of ASLSL.", "AI": {"tldr": "The paper proposes Adaptive Shared Latent Structure Learning (ASLSL) as a feature selection method to handle incomplete multi-modal physiological signals in emotion recognition, outperforming existing approaches on DEAP and DREAMER datasets.", "motivation": "The paper aims to address the challenges of high-dimensional, potentially noisy, irrelevant, or redundant multi-modal physiological features in emotion recognition, which lead to performance and computational issues, especially when data is incomplete.", "method": "The ASLSL approach learns a common latent space shared among incomplete multi-modal physiological signals and multi-dimensional emotional labels. It uses adaptive shared latent structure learning to mitigate missing data effects while capturing key consensus information.", "result": "The ASLSL method demonstrated superior feature selection and performance compared to seventeen existing methods when evaluated on the DEAP and DREAMER datasets.", "conclusion": "Adaptive Shared Latent Structure Learning is an effective solution for feature selection in incomplete multi-modal physiological emotion recognition. It reduces the impact of data incompleteness and improves recognition performance."}}
{"id": "2508.06256", "pdf": "https://arxiv.org/pdf/2508.06256", "abs": "https://arxiv.org/abs/2508.06256", "authors": ["Bar\u0131\u015f B\u00fcy\u00fckta\u015f", "Jonas Klotz", "Beg\u00fcm Demir"], "title": "FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "Federated learning (FL) enables the collaborative training of deep neural\nnetworks across decentralized data archives (i.e., clients), where each client\nstores data locally and only shares model updates with a central server. This\nmakes FL a suitable learning paradigm for remote sensing (RS) image\nclassification tasks, where data centralization may be restricted due to legal\nand privacy constraints. However, a key challenge in applying FL to RS tasks is\nthe communication overhead caused by the frequent exchange of large model\nupdates between clients and the central server. To address this issue, in this\npaper we propose a novel strategy (denoted as FedX) that uses\nexplanation-guided pruning to reduce communication overhead by minimizing the\nsize of the transmitted models without compromising performance. FedX leverages\nbackpropagation-based explanation methods to estimate the task-specific\nimportance of model components and prunes the least relevant ones at the\ncentral server. The resulting sparse global model is then sent to clients,\nsubstantially reducing communication overhead. We evaluate FedX on multi-label\nscene classification using the BigEarthNet-S2 dataset and single-label scene\nclassification using the EuroSAT dataset. Experimental results show the success\nof FedX in significantly reducing the number of shared model parameters while\nenhancing the generalization capability of the global model, compared to both\nunpruned model and state-of-the-art pruning methods. The code of FedX will be\navailable at https://git.tu-berlin.de/rsim/FedX.", "AI": {"tldr": "Federated learning (FL) is adapted for remote sensing image classification by pruning model updates to reduce communication overhead through the FedX strategy.", "motivation": "Federated learning often faces legal and privacy restrictions in remote sensing applications but struggles with communication inefficiencies due to frequent large model updates.", "method": "The proposed FedX employs explanation-guided pruning, using backpropagation-based methods to rank and prune less relevant model components, thereby reducing the size of exchanged models.", "result": "FedX significantly reduces communication overhead and enhances the generalization capability of the global model compared to unpruned and existing pruning methods.", "conclusion": "FedX provides an effective solution for addressing FL communication bottlenecks in remote sensing applications by optimizing model update transmissions without sacrificing performance."}}
{"id": "2508.06258", "pdf": "https://arxiv.org/pdf/2508.06258", "abs": "https://arxiv.org/abs/2508.06258", "authors": ["Byunghyun Ko", "Anning Tian", "Jeongkyu Lee"], "title": "XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation", "categories": ["cs.CV"], "comment": "Accepted at the 2025 International Conference on Artificial\n  Intelligence, Computer, Data Sciences and Applications (ACDSA). This is the\n  preprint version of the paper", "summary": "Accurate segmentation of femur structures from Magnetic Resonance Imaging\n(MRI) is critical for orthopedic diagnosis and surgical planning but remains\nchallenging due to the limitations of existing 2D and 3D deep learning-based\nsegmentation approaches. In this study, we propose XAG-Net, a novel 2.5D\nU-Net-based architecture that incorporates pixel-wise cross-slice attention\n(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice\ncontextual modeling and intra-slice feature refinement. Unlike previous\nCSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent\nslices at each spatial location for fine-grained inter-slice modeling.\nExtensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and\n3D U-Net models in femur segmentation accuracy while maintaining computational\nefficiency. Ablation studies further validate the critical role of the CSA and\nAG modules, establishing XAG-Net as a promising framework for efficient and\naccurate femur MRI segmentation.", "AI": {"tldr": "The paper introduces XAG-Net, a 2.5D U-Net-based architecture achieving improved femur MRI segmentation by utilizing novel cross-slice attention and skip attention gating mechanisms.", "motivation": "Address the challenges of accurate femur segmentation from MRI using existing 2D and 3D deep learning-based approaches.", "method": "Developed XAG-Net, featuring pixel-wise cross-slice attention (CSA) and skip attention gating (AG) mechanisms, enhancing contextual modeling and feature refinement in MRI segmentation.", "result": "XAG-Net significantly improved femur segmentation accuracy over 2D, 2.5D, and 3D U-Net models, with efficient computational performance.", "conclusion": "XAG-Net, integrating CSA and AG modules, offers an effective solution for femur MRI segmentation, proving its potential in orthopedic applications."}}
{"id": "2508.05978", "pdf": "https://arxiv.org/pdf/2508.05978", "abs": "https://arxiv.org/abs/2508.05978", "authors": ["Wei Chen", "Binzhu Sha", "Dan Luo", "Jing Yang", "Zhuo Wang", "Fan Fan", "Zhiyong Wu"], "title": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": "Accepted by INTERSPEECH 2025", "summary": "Singing Voice Conversion (SVC) transfers a source singer's timbre to a target\nwhile keeping melody and lyrics. The key challenge in any-to-any SVC is\nadapting unseen speaker timbres to source audio without quality degradation.\nExisting methods either face timbre leakage or fail to achieve satisfactory\ntimbre similarity and quality in the generated audio. To address these\nchallenges, we propose DAFMSVC, where the self-supervised learning (SSL)\nfeatures from the source audio are replaced with the most similar SSL features\nfrom the target audio to prevent timbre leakage. It also incorporates a dual\ncross-attention mechanism for the adaptive fusion of speaker embeddings,\nmelody, and linguistic content. Additionally, we introduce a flow matching\nmodule for high quality audio generation from the fused features. Experimental\nresults show that DAFMSVC significantly enhances timbre similarity and\nnaturalness, outperforming state-of-the-art methods in both subjective and\nobjective evaluations.", "AI": {"tldr": "This paper introduces DAFMSVC, a method to improve Singing Voice Conversion (SVC) by incorporating SSL feature replacement, dual cross-attention, and a flow matching module, resulting in better timbre similarity and audio quality.", "motivation": "The motivation is to address challenges in any-to-any Singing Voice Conversion (SVC), specifically issues like timbre leakage and ensuring high timbre similarity and audio quality.", "method": "DAFMSVC prevents timbre leakage by replacing source audio SSL features with similar features from the target. It uses a dual cross-attention mechanism to fuse speaker embeddings, melody, and linguistic content, and employs a flow matching module for high-quality audio generation.", "result": "DAFMSVC achieves significant improvements in timbre similarity, naturalness, and audio quality compared to existing methods, as demonstrated by subjective and objective evaluations.", "conclusion": "The proposed DAFMSVC method surpasses existing SVC approaches in quality, effectively resolving common challenges like timbre leakage while maintaining high fidelity to timbre and naturalness in generated audio."}}
{"id": "2508.06259", "pdf": "https://arxiv.org/pdf/2508.06259", "abs": "https://arxiv.org/abs/2508.06259", "authors": ["Zhangquan Chen", "Ruihui Zhao", "Chuwei Luo", "Mingze Sun", "Xinlei Yu", "Yangyang Kang", "Ruqi Huang"], "title": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "categories": ["cs.CV", "cs.AI", "I.2.10"], "comment": "15 pages, 13 figures", "summary": "Current multimodal large language models (MLLMs) still face significant\nchallenges in complex visual tasks (e.g., spatial understanding, fine-grained\nperception). Prior methods have tried to incorporate visual reasoning, however,\nthey fail to leverage attention correction with spatial cues to iteratively\nrefine their focus on prompt-relevant regions. In this paper, we introduce\nSIFThinker, a spatially-aware \"think-with-images\" framework that mimics human\nvisual perception. Specifically, SIFThinker enables attention correcting and\nimage region focusing by interleaving depth-enhanced bounding boxes and natural\nlanguage. Our contributions are twofold: First, we introduce a\nreverse-expansion-forward-inference strategy that facilitates the generation of\ninterleaved image-text chains of thought for process-level supervision, which\nin turn leads to the construction of the SIF-50K dataset. Besides, we propose\nGRPO-SIF, a reinforced training paradigm that integrates depth-informed visual\ngrounding into a unified reasoning pipeline, teaching the model to dynamically\ncorrect and focus on prompt-relevant regions. Extensive experiments demonstrate\nthat SIFThinker outperforms state-of-the-art methods in spatial understanding\nand fine-grained visual perception, while maintaining strong general\ncapabilities, highlighting the effectiveness of our method.", "AI": {"tldr": "This paper presents SIFThinker, a framework designed to improve complex visual reasoning tasks by incorporating spatial perception and iterative attention correction.", "motivation": "The motivation is to address challenges in multimodal large language models (MLLMs) for complex visual tasks like spatial understanding and fine-grained perception, where existing approaches fail to utilize iterative spatial attention corrections.", "method": "The authors propose the SIFThinker framework, which uses depth-enhanced bounding boxes and language interleaving to mimic visual perception. They introduce a reverse-expansion-forward-inference strategy for process supervision and suggest GRPO-SIF, a reinforced training paradigm for dynamic spatial reasoning.", "result": "Experiments demonstrate that SIFThinker surpasses state-of-the-art methods in spatial understanding and fine-grained perception tasks while retaining strong general-purpose performance.", "conclusion": "The results confirm the effectiveness of SIFThinker in advancing MLLMs' capability in handling complex visual reasoning tasks by improving spatial awareness and attention refinement."}}
{"id": "2508.06317", "pdf": "https://arxiv.org/pdf/2508.06317", "abs": "https://arxiv.org/abs/2508.06317", "authors": ["Jian Hu", "Zixu Cheng", "Shaogang Gong", "Isabel Guan", "Jianye Hao", "Jun Wang", "Kun Shao"], "title": "Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding", "categories": ["cs.CV"], "comment": null, "summary": "Video Temporal Grounding (TG) aims to temporally locate video segments\nmatching a natural language description (a query) in a long video. While\nVision-Language Models (VLMs) are effective at holistic semantic matching, they\noften struggle with fine-grained temporal localisation. Recently, Group\nRelative Policy Optimisation (GRPO) reformulates the inference process as a\nreinforcement learning task, enabling fine-grained grounding and achieving\nstrong in-domain performance. However, GRPO relies on labelled data, making it\nunsuitable in unlabelled domains. Moreover, because videos are large and\nexpensive to store and process, performing full-scale adaptation introduces\nprohibitive latency and computational overhead, making it impractical for\nreal-time deployment. To overcome both problems, we introduce a Data-Efficient\nUnlabelled Cross-domain Temporal Grounding method, from which a model is first\ntrained on a labelled source domain, then adapted to a target domain using only\na small number of unlabelled videos from the target domain. This approach\neliminates the need for target annotation and keeps both computational and\nstorage overhead low enough to run in real time. Specifically, we introduce.\nUncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain\nknowledge transfer in learning video temporal grounding without target labels.\nURPA generates multiple candidate predictions using GRPO rollouts, averages\nthem to form a pseudo label, and estimates confidence from the variance across\nthese rollouts. This confidence then weights the training rewards, guiding the\nmodel to focus on reliable supervision. Experiments on three datasets across\nsix cross-domain settings show that URPA generalises well using only a few\nunlabelled target videos. Codes will be released once published.", "AI": {"tldr": "This paper introduces URPA to enable effective video temporal grounding across domains using a minimal amount of unlabelled target data.", "motivation": "While Vision-Language Models show promise in semantic matching, they struggle with fine-grained temporal localization. Existing solutions like GRPO provide strong performance but lack scalability for unlabelled domains and real-time use.", "method": "The paper proposes URPA, which uses GRPO rollouts to create pseudo labels and confidence metrics, integrating these metrics into reward weighting during training for efficient cross-domain adaptation.", "result": "Experiments conducted on three datasets and six cross-domain settings demonstrate URPA\u2019s capability to generalize effectively with minimal unlabelled target data.", "conclusion": "URPA addresses the limitations of GRPO by enabling scalable domain adaptation without the need for target annotations, making it suitable for real-time, computationally efficient applications."}}
{"id": "2508.06318", "pdf": "https://arxiv.org/pdf/2508.06318", "abs": "https://arxiv.org/abs/2508.06318", "authors": ["Giacomo D'Amicantonio", "Snehashis Majhi", "Quan Kong", "Lorenzo Garattoni", "Gianpiero Francesca", "Fran\u00e7ois Bremond", "Egor Bondarev"], "title": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video Anomaly Detection (VAD) is a challenging task due to the variability of\nanomalous events and the limited availability of labeled data. Under the\nWeakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided\nduring training, while predictions are made at the frame level. Although\nstate-of-the-art models perform well on simple anomalies (e.g., explosions),\nthey struggle with complex real-world events (e.g., shoplifting). This\ndifficulty stems from two key issues: (1) the inability of current models to\naddress the diversity of anomaly types, as they process all categories with a\nshared model, overlooking category-specific features; and (2) the weak\nsupervision signal, which lacks precise temporal information, limiting the\nability to capture nuanced anomalous patterns blended with normal events. To\naddress these challenges, we propose Gaussian Splatting-guided Mixture of\nExperts (GS-MoE), a novel framework that employs a set of expert models, each\nspecialized in capturing specific anomaly types. These experts are guided by a\ntemporal Gaussian splatting loss, enabling the model to leverage temporal\nconsistency and enhance weak supervision. The Gaussian splatting approach\nencourages a more precise and comprehensive representation of anomalies by\nfocusing on temporal segments most likely to contain abnormal events. The\npredictions from these specialized experts are integrated through a\nmixture-of-experts mechanism to model complex relationships across diverse\nanomaly patterns. Our approach achieves state-of-the-art performance, with a\n91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on\nXD-Violence and MSAD datasets. By leveraging category-specific expertise and\ntemporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.", "AI": {"tldr": "The paper introduces GS-MoE, a model that uses specialized experts and Gaussian splatting for weakly-supervised video anomaly detection, achieving state-of-the-art performance.", "motivation": "Current models struggle with detecting complex anomalies and dealing with weak supervision signals for VAD.", "method": "The GS-MoE leverages expert models specialized in specific anomaly types, guided by a temporal Gaussian splatting mechanism, with predictions integrated through a mixture-of-experts framework.", "result": "GS-MoE achieves 91.58% AUC on UCF-Crime and performs superiorly on XD-Violence and MSAD datasets.", "conclusion": "The proposed GS-MoE framework improves VAD under weak supervision by addressing category-specific anomalies and enhancing temporal representation."}}
{"id": "2508.06327", "pdf": "https://arxiv.org/pdf/2508.06327", "abs": "https://arxiv.org/abs/2508.06327", "authors": ["Xin Ci Wong", "Duygu Sarikaya", "Kieran Zucker", "Marc De Kamps", "Nishant Ravikumar"], "title": "Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?", "categories": ["cs.CV"], "comment": "ICONIP 2025", "summary": "Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain\nshift due to variations in imaging devices and acquisition protocols. This\nchallenge limits the deployment of trained AI models in real-world scenarios,\nwhere performance degrades on unseen domains. Traditional solutions involve\nincreasing the size of the dataset through ad-hoc image augmentation or\nadditional online training/transfer learning, which have several limitations.\nSynthetic data offers a promising alternative, but anatomical/structural\nconsistency constraints limit the effectiveness of generative models in\ncreating image-label pairs. To address this, we propose a diffusion model (DM)\ntrained on a source domain that generates synthetic cardiac MR images that\nresemble a given reference. The synthetic data maintains spatial and structural\nfidelity, ensuring similarity to the source domain and compatibility with the\nsegmentation mask. We assess the utility of our generative approach in\nmulti-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and\nvanilla U-Net segmentation networks. We explore domain generalisation, where,\ndomain-invariant segmentation models are trained on synthetic source domain\ndata, and domain adaptation, where, we shift target domain data towards the\nsource domain using the DM. Both strategies significantly improved segmentation\nperformance on data from an unseen target domain, in terms of surface-based\nmetrics (Welch's t-test, p < 0.01), compared to training segmentation models on\nreal data alone. The proposed method ameliorates the need for transfer learning\nor online training to address domain shift challenges in cardiac MR image\nanalysis, especially useful in data-scarce settings.", "AI": {"tldr": "The paper proposes a diffusion model (DM) to generate synthetic cardiac MRI data that addresses domain shift issues, improving segmentation performance on unseen domains without traditional approaches like transfer learning.", "motivation": "To overcome domain shift challenges in cardiac MR imaging caused by variations in imaging devices and protocols that degrade AI model performance, especially in data-limited scenarios.", "method": "A diffusion model (DM) is trained on a source domain to generate synthetic cardiac MR images with structural fidelity, used for domain generalization and domain adaptation in segmentation tasks.", "result": "The approach improved segmentation performance on unseen domains using metrics like Welch's t-test, showing significant advantages over traditional real data methods.", "conclusion": "The proposed method reduces reliance on transfer learning or online training, effectively addressing domain shift issues in cardiac MRI analysis, making it ideal for data-scarce environments."}}
{"id": "2508.06335", "pdf": "https://arxiv.org/pdf/2508.06335", "abs": "https://arxiv.org/abs/2508.06335", "authors": ["Patrick Takenaka", "Johannes Maucher", "Marco F. Huber"], "title": "ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction", "categories": ["cs.CV"], "comment": "Published in 2025 International Joint Conference on Neural Networks\n  (IJCNN)", "summary": "Predicting future video frames is a challenging task with many downstream\napplications. Previous work has shown that procedural knowledge enables deep\nmodels for complex dynamical settings, however their model ViPro assumed a\ngiven ground truth initial symbolic state. We show that this approach led to\nthe model learning a shortcut that does not actually connect the observed\nenvironment with the predicted symbolic state, resulting in the inability to\nestimate states given an observation if previous states are noisy. In this\nwork, we add several improvements to ViPro that enables the model to correctly\ninfer states from observations without providing a full ground truth state in\nthe beginning. We show that this is possible in an unsupervised manner, and\nextend the original Orbits dataset with a 3D variant to close the gap to real\nworld scenarios.", "AI": {"tldr": "This paper improves video frame prediction by eliminating reliance on initial ground truth symbolic states, enabling unsupervised state inference.", "motivation": "Previous models relied on given ground truth symbolic states, which created a shortcut. This approach failed when initial states were noisy.", "method": "The authors improved the ViPro model to infer states from observations without ground truth states and extended the Orbits dataset to 3D for realism.", "result": "The modified model successfully inferred symbolic states in an unsupervised manner and proved its applicability to real-world-like settings.", "conclusion": "The advancements overcome limitations of earlier models, showing promise in robust video frame prediction for complex scenarios."}}
{"id": "2508.06052", "pdf": "https://arxiv.org/pdf/2508.06052", "abs": "https://arxiv.org/abs/2508.06052", "authors": ["Haruto Nakashima", "Siddhartha Ganguly", "Kenji Kashima"], "title": "Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": "To be presented at the IEEE CDC, Rio de Janeiro, 2025", "summary": "We tackle the data-driven chance-constrained density steering problem using\nthe Gromov-Wasserstein metric. The underlying dynamical system is an unknown\nlinear controlled recursion, with the assumption that sufficiently rich\ninput-output data from pre-operational experiments are available. The initial\nstate is modeled as a Gaussian mixture, while the terminal state is required to\nmatch a specified Gaussian distribution. We reformulate the resulting optimal\ncontrol problem as a difference-of-convex program and show that it can be\nefficiently and tractably solved using the DC algorithm. Numerical results\nvalidate our approach through various data-driven schemes.", "AI": {"tldr": "This paper addresses a data-driven approach to control an unknown linear system while fulfilling specific probabilistic constraints using the Gromov-Wasserstein metric.", "motivation": "The paper is motivated by the need to effectively steer the density of dynamical systems, modeled with insufficiently understood dynamics, while ensuring chance constraints are met.", "method": "The authors use a difference-of-convex (DC) programming approach to reformulate the optimal control problem. They rely on the Gromov-Wasserstein metric and sufficient input-output experimental data, along with DC algorithms to solve the problem efficiently.", "result": "The approach is validated through numerical experiments that showcase the feasibility and effectiveness of data-driven schemes.", "conclusion": "The proposed framework demonstrates a robust method for addressing chance-constrained density steering in systems with unknown dynamics."}}
{"id": "2508.06342", "pdf": "https://arxiv.org/pdf/2508.06342", "abs": "https://arxiv.org/abs/2508.06342", "authors": ["Kieran Elrod", "Katherine Flanigan", "Mario Berg\u00e9s"], "title": "Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities", "categories": ["cs.CV", "cs.SI"], "comment": null, "summary": "Designing socially active streets has long been a goal of urban planning, yet\nexisting quantitative research largely measures pedestrian volume rather than\nthe quality of social interactions. We hypothesize that street view imagery --\nan inexpensive data source with global coverage -- contains latent social\ninformation that can be extracted and interpreted through established social\nscience theory. As a proof of concept, we analyzed 2,998 street view images\nfrom 15 cities using a multimodal large language model guided by Mehta's\ntaxonomy of passive, fleeting, and enduring sociability -- one illustrative\nexample of a theory grounded in urban design that could be substituted or\ncomplemented by other sociological frameworks. We then used linear regression\nmodels, controlling for factors like weather, time of day, and pedestrian\ncounts, to test whether the inferred sociability measures correlate with\ncity-level place attachment scores from the World Values Survey and with\nenvironmental predictors (e.g., green, sky, and water view indices) derived\nfrom individual street view images. Results aligned with long-standing urban\nplanning theory: the sky view index was associated with all three sociability\ntypes, the green view index predicted enduring sociability, and place\nattachment was positively associated with fleeting sociability. These results\nprovide preliminary evidence that street view images can be used to infer\nrelationships between specific types of social interactions and built\nenvironment variables. Further research could establish street view imagery as\na scalable, privacy-preserving tool for studying urban sociability, enabling\ncross-cultural theory testing and evidence-based design of socially vibrant\ncities.", "AI": {"tldr": "The study explores the use of street view imagery to assess social interactions using urban design theories, confirming connections between environmental features and sociability.", "motivation": "There is a need for a scalable, cost-effective tool to measure qualitative aspects of sociability on streets, beyond pedestrian volume.", "method": "The methodology involved analyzing 2,998 street view images with a multimodal large language model guided by sociability taxonomy, complemented by regression models controlling for external variables.", "result": "Findings revealed correlations between urban design elements (like green and sky view indices) and various sociability types, aligning with established urban planning theories.", "conclusion": "Street view imagery demonstrates potential as a global, privacy-preserving method for studying sociability, paving the way for improved urban design and theory testing."}}
{"id": "2508.05979", "pdf": "https://arxiv.org/pdf/2508.05979", "abs": "https://arxiv.org/abs/2508.05979", "authors": ["Xinming Yang", "Haasil Pujara", "Jun Li"], "title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Published at COLM 2025", "summary": "While Large Language Models (LLMs) are often used as virtual tutors in\ncomputer science (CS) education, this approach can foster passive learning and\nover-reliance. This paper presents a novel pedagogical paradigm that inverts\nthis model: students act as instructors who must teach an LLM to solve\nproblems. To facilitate this, we developed strategies for designing questions\nwith engineered knowledge gaps that only a student can bridge, and we introduce\nSocrates, a system for deploying this method with minimal overhead. We\nevaluated our approach in an undergraduate course and found that this\nactive-learning method led to statistically significant improvements in student\nperformance compared to historical cohorts. Our work demonstrates a practical,\ncost-effective framework for using LLMs to deepen student engagement and\nmastery.", "AI": {"tldr": "This paper introduces an educational method where students act as instructors to teach a Large Language Model (LLM) via strategically designed questions, resulting in improved student performance.", "motivation": "The authors aim to address the issues of passive learning and over-reliance on LLMs in computer science education.", "method": "The method inverts the typical LLM-tutor approach by having students teach the LLM through questions with engineered knowledge gaps. The authors developed a system called Socrates to implement this process efficiently.", "result": "Testing in an undergraduate course showed statistically significant improvements in student performance compared to previous cohorts.", "conclusion": "The proposed method offers a practical and cost-effective way to enhance student engagement and mastery using LLMs in educational settings."}}
{"id": "2508.06350", "pdf": "https://arxiv.org/pdf/2508.06350", "abs": "https://arxiv.org/abs/2508.06350", "authors": ["Yingxian Chen", "Jiahui Liu", "Ruifan Di", "Yanwei Li", "Chirui Chang", "Shizhen Zhao", "Wilton W. T. Fok", "Xiaojuan Qi", "Yik-Chung Wu"], "title": "Aligning Effective Tokens with Video Anomaly in Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Understanding abnormal events in videos is a vital and challenging task that\nhas garnered significant attention in a wide range of applications. Although\ncurrent video understanding Multi-modal Large Language Models (MLLMs) are\ncapable of analyzing general videos, they often struggle to handle anomalies\ndue to the spatial and temporal sparsity of abnormal events, where the\nredundant information always leads to suboptimal outcomes. To address these\nchallenges, exploiting the representation and generalization capabilities of\nVison Language Models (VLMs) and Large Language Models (LLMs), we propose\nVA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in\nvarious videos. Our approach efficiently aligns effective tokens between visual\nencoders and LLMs through two key proposed modules: Spatial Effective Token\nSelection (SETS) and Temporal Effective Token Generation (TETG). These modules\nenable our model to effectively capture and analyze both spatial and temporal\ninformation associated with abnormal events, resulting in more accurate\nresponses and interactions. Furthermore, we construct an instruction-following\ndataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a\ncross-domain evaluation benchmark based on XD-Violence dataset. Our proposed\nmethod outperforms existing state-of-the-art methods on various benchmarks.", "AI": {"tldr": "This paper proposes VA-GPT, a novel Multi-modal Large Language Model (MLLM) designed to improve the detection and analysis of abnormal events in videos by addressing spatial and temporal sparsity issues.", "motivation": "To address the limitations of current video understanding Multi-modal Large Language Models (MLLMs), which struggle with recognizing abnormal events due to information sparsity and redundancy.", "method": "The proposed VA-GPT model employs Spatial Effective Token Selection (SETS) and Temporal Effective Token Generation (TETG) modules to align tokens between visual encoders and LLMs, improving spatial and temporal anomaly detection capabilities.", "result": "VA-GPT demonstrates superior performance over state-of-the-art methods across various benchmarks, including the cross-domain XD-Violence dataset.", "conclusion": "VA-GPT effectively handles video anomaly detection challenges by leveraging advancements in Vision Language Models (VLMs) and Large Language Models (LLMs), offering a robust solution for summarizing and localizing abnormal events."}}
{"id": "2508.06351", "pdf": "https://arxiv.org/pdf/2508.06351", "abs": "https://arxiv.org/abs/2508.06351", "authors": ["Olakunle S. Abawonse", "G\u00fcnay Do\u011fan"], "title": "An Implemention of Two-Phase Image Segmentation using the Split Bregman Method", "categories": ["cs.CV", "math.OC"], "comment": "15 pages", "summary": "In this paper, we describe an implementation of the two-phase image\nsegmentation algorithm proposed by Goldstein, Bresson, Osher in\n\\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into\nforeground and background regions, and each pixel of the image is assigned\nmembership to one of these two regions. The underlying assumption for the\nsegmentation model is that the pixel values of the input image can be\nsummarized by two distinct average values, and that the region boundaries are\nsmooth. Accordingly, the model is defined as an energy in which the variable is\na region membership function to assign pixels to either region, originally\nproposed by Chan and Vese in \\cite{chan:vese}. This energy is the sum of image\ndata terms in the regions and a length penalty for region boundaries.\nGoldstein, Bresson, Osher modify the energy of Chan-Vese in \\cite{gold:bre} so\nthat their new energy can be minimized efficiently using the split Bregman\nmethod to produce an equivalent two-phase segmentation. We provide a detailed\nimplementation of this method \\cite{gold:bre}, and document its performance\nwith several images over a range of algorithm parameters.", "AI": {"tldr": "This paper implements and evaluates a two-phase image segmentation algorithm that divides an image into foreground and background by assigning pixels based on average values and smooth region boundaries.", "motivation": "The motivation behind this paper is to implement and analyze the two-phase image segmentation algorithm by Goldstein, Bresson, and Osher, which optimizes the region-membership function for efficient foreground-background segmentation.", "method": "The authors implemented the modified Chan-Vese energy model using the split Bregman method, which minimizes the energy combining data consistency and region boundary smoothness.", "result": "The performance of the implemented segmentation algorithm was validated on several images with varying algorithm parameters, showcasing its efficiency.", "conclusion": "The paper provides a detailed documentation of the segmentation algorithm's implementation and demonstrates its effectiveness on various datasets."}}
{"id": "2508.06357", "pdf": "https://arxiv.org/pdf/2508.06357", "abs": "https://arxiv.org/abs/2508.06357", "authors": ["Aman Bhatta", "Maria Dhakal", "Michael C. King", "Kevin W. Bowyer"], "title": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "A central problem in one-to-many facial identification is that the person in\nthe probe image may or may not have enrolled image(s) in the gallery; that is,\nmay be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one\nresult is Out-of-gallery have mostly focused on finding a suitable threshold on\nthe similarity score. We take a new approach, using the additional enrolled\nimages of the identity with the rank-one result to predict if the rank-one\nresult is In-gallery / Out-of-gallery. Given a gallery of identities and\nimages, we generate In-gallery and Out-of-gallery training data by extracting\nthe ranks of additional enrolled images corresponding to the rank-one identity.\nWe then train a classifier to utilize this feature vector to predict whether a\nrank-one result is In-gallery or Out-of-gallery. Using two different datasets\nand four different matchers, we present experimental results showing that our\napproach is viable for mugshot quality probe images, and also, importantly, for\nprobes degraded by blur, reduced resolution, atmospheric turbulence and\nsunglasses. We also analyze results across demographic groups, and show that\nIn-gallery / Out-of-gallery classification accuracy is similar across\ndemographics. Our approach has the potential to provide an objective estimate\nof whether a one-to-many facial identification is Out-of-gallery, and thereby\nto reduce false positive identifications, wrongful arrests, and wasted\ninvestigative time. Interestingly, comparing the results of older deep\nCNN-based face matchers with newer ones suggests that the effectiveness of our\nOut-of-gallery detection approach emerges only with matchers trained using\nadvanced margin-based loss functions.", "AI": {"tldr": "This paper introduces a method to improve facial identification systems by predicting if the top-matching identity is already enrolled in the gallery using data from additional images.", "motivation": "To tackle the challenge of identifying whether the top-ranked facial match from a gallery is legitimately linked to an enrolled identity (In-gallery) or not (Out-of-gallery), especially in challenging conditions like image degradation.", "method": "The approach generates training data by deriving ranks of additional enrolled images linked to the top-ranked result, then trains a classifier to predict Out-of-gallery/In-gallery results using these ranks.", "result": "The method demonstrates effectiveness on two datasets and under various conditions (e.g. image blur, atmospheric turbulence, etc.), maintaining consistent accuracy across demographic groups.", "conclusion": "This approach provides a reliable mechanism for detecting Out-of-gallery cases, which can reduce false positives, wrongful arrests, and wasted investigative efforts. The method's success depends on the use of advanced CNN face matchers with margin-based loss functions."}}
{"id": "2508.06000", "pdf": "https://arxiv.org/pdf/2508.06000", "abs": "https://arxiv.org/abs/2508.06000", "authors": ["Wei Xiang", "Ziyue Lei", "Haoyuan Che", "Fangyuan Ye", "Xueting Wu", "Lingyun Sun"], "title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Operational skill learning, inherently physical and reliant on hands-on\npractice and kinesthetic feedback, has yet to be effectively replicated in\nlarge language model (LLM)-supported training. Current LLM training assistants\nprimarily generate customized textual feedback, neglecting the crucial\nkinesthetic modality. This gap derives from the textual and uncertain nature of\nLLMs, compounded by concerns on user acceptance of LLM driven body control. To\nbridge this gap and realize the potential of collaborative human-LLM action,\nthis work explores human experience of LLM driven kinesthetic assistance.\nSpecifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed\nFlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS)\nfor flight skill acquisition, a representative operational skill domain.\nFlightAxis learns flight skills from manuals and guides forearm movements\nduring simulated flight tasks. Our results demonstrate high user acceptance of\nLLM-mediated body control and significantly reduced task completion times.\nCrucially, trainees reported that this kinesthetic assistance enhanced their\nawareness of operation flaws and fostered increased engagement in the training\nprocess, rather than relieving perceived load. This work demonstrated the\npotential of kinesthetic LLM training in operational skill acquisition.", "AI": {"tldr": "This paper introduces FlightAxis, a tool combining LLMs and EMS for enhancing flight skill training with kinesthetic feedback.", "motivation": "Address the gap in LLM-supported training by incorporating physical and hands-on assistance for operational skill learning.", "method": "Developed the 'Align-Analyze-Adjust' strategy, integrating LLMs with EMS to guide physical movements during simulated training tasks.", "result": "Users showed high acceptance of LLM-driven body control, reduced task times, and improved engagement and awareness of operational flaws.", "conclusion": "LLM-mediated kinesthetic training can improve operational skill acquisition and demonstrates promising potential for broader applications."}}
{"id": "2508.06382", "pdf": "https://arxiv.org/pdf/2508.06382", "abs": "https://arxiv.org/abs/2508.06382", "authors": ["Xiangyu Wu", "Feng Yu", "Yang Yang", "Jianfeng Lu"], "title": "Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning", "categories": ["cs.CV"], "comment": "Accepted for publication at ACMMM 2025", "summary": "The integration of prompt tuning with multimodal learning has shown\nsignificant generalization abilities for various downstream tasks. Despite\nadvancements, existing methods heavily depend on massive modality-specific\nlabeled data (e.g., video, audio, and image), or are customized for a single\nmodality. In this study, we present Text as Any-Modality by Consistent Prompt\nTuning (TaAM-CPT), a scalable approach for constructing a general\nrepresentation model toward unlimited modalities using solely text data.\nTaAM-CPT comprises modality prompt pools, text construction, and\nmodality-aligned text encoders from pre-trained models, which allows for\nextending new modalities by simply adding prompt pools and modality-aligned\ntext encoders. To harmonize the learning across different modalities, TaAM-CPT\ndesigns intra- and inter-modal learning objectives, which can capture category\ndetails within modalities while maintaining semantic consistency across\ndifferent modalities. Benefiting from its scalable architecture and pre-trained\nmodels, TaAM-CPT can be seamlessly extended to accommodate unlimited\nmodalities. Remarkably, without any modality-specific labeled data, TaAM-CPT\nachieves leading results on diverse datasets spanning various modalities,\nincluding video classification, image classification, and audio classification.\nThe code is available at https://github.com/Jinx630/TaAM-CPT.", "AI": {"tldr": "The paper introduces a scalable approach called TaAM-CPT for generalized multimodal learning using only text data, avoiding reliance on modality-specific labeled data.", "motivation": "To address the limitations of existing multimodal learning methods, which rely heavily on modality-specific labeled data or focus only on a single modality.", "method": "TaAM-CPT uses modality prompt pools, text construction, and modality-aligned text encoders from pre-trained models, with intra- and inter-modal objectives to ensure semantic consistency across modalities.", "result": "TaAM-CPT achieves leading performance across diverse datasets in tasks like video, image, and audio classification without using modality-specific labeled data.", "conclusion": "TaAM-CPT enables scalable and extensible multimodal learning by leveraging text data as a universal modality, achieving strong generalization across multiple tasks."}}
{"id": "2508.06392", "pdf": "https://arxiv.org/pdf/2508.06392", "abs": "https://arxiv.org/abs/2508.06392", "authors": ["Wenbin Teng", "Gonglin Chen", "Haiwei Chen", "Yajie Zhao"], "title": "FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in 3D reconstruction has enabled realistic 3D models from\ndense image captures, yet challenges persist with sparse views, often leading\nto artifacts in unseen areas. Recent works leverage Video Diffusion Models\n(VDMs) to generate dense observations, filling the gaps when only sparse views\nare available for 3D reconstruction tasks. A significant limitation of these\nmethods is their slow sampling speed when using VDMs. In this paper, we present\nFVGen, a novel framework that addresses this challenge by enabling fast novel\nview synthesis using VDMs in as few as four sampling steps. We propose a novel\nvideo diffusion model distillation method that distills a multi-step denoising\nteacher model into a few-step denoising student model using Generative\nAdversarial Networks (GANs) and softened reverse KL-divergence minimization.\nExtensive experiments on real-world datasets show that, compared to previous\nworks, our framework generates the same number of novel views with similar (or\neven better) visual quality while reducing sampling time by more than 90%.\nFVGen significantly improves time efficiency for downstream reconstruction\ntasks, particularly when working with sparse input views (more than 2) where\npre-trained VDMs need to be run multiple times to achieve better spatial\ncoverage.", "AI": {"tldr": "This paper introduces FVGen, a framework to accelerate novel view synthesis with Video Diffusion Models (VDMs), achieving comparable or better quality in just four steps while dramatically reducing sampling time.", "motivation": "3D reconstruction struggles with sparse input views, often creating artifacts due to poor visual coverage. Fast synthesis of dense observations is necessary to address these gaps and improve spatial coverage for reconstruction tasks.", "method": "The paper proposes FVGen, which uses video diffusion model distillation. It employs a teacher-student approach where a multi-step denoising model is distilled into a few-step model using GANs and softened reverse KL-divergence minimization.", "result": "Extensive tests on real-world datasets show FVGen generates novel views with similar or better quality while reducing sampling time by more than 90%.", "conclusion": "FVGen significantly enhances efficiency in novel view generation and downstream 3D reconstruction tasks, especially under sparse view conditions."}}
{"id": "2508.06407", "pdf": "https://arxiv.org/pdf/2508.06407", "abs": "https://arxiv.org/abs/2508.06407", "authors": ["Ch Muhammad Awais", "Marco Reggiannini", "Davide Moroni", "Oktay Karakus"], "title": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "High-resolution imagery plays a critical role in improving the performance of\nvisual recognition tasks such as classification, detection, and segmentation.\nIn many domains, including remote sensing and surveillance, low-resolution\nimages can limit the accuracy of automated analysis. To address this,\nsuper-resolution (SR) techniques have been widely adopted to attempt to\nreconstruct high-resolution images from low-resolution inputs. Related\ntraditional approaches focus solely on enhancing image quality based on\npixel-level metrics, leaving the relationship between super-resolved image\nfidelity and downstream classification performance largely underexplored. This\nraises a key question: can integrating classification objectives directly into\nthe super-resolution process further improve classification accuracy? In this\npaper, we try to respond to this question by investigating the relationship\nbetween super-resolution and classification through the deployment of a\nspecialised algorithmic strategy. We propose a novel methodology that increases\nthe resolution of synthetic aperture radar imagery by optimising loss functions\nthat account for both image quality and classification performance. Our\napproach improves image quality, as measured by scientifically ascertained\nimage quality indicators, while also enhancing classification accuracy.", "AI": {"tldr": "This paper explores improving classification accuracy by integrating classification objectives into super-resolution techniques, offering a novel approach for synthesizing high-resolution images.", "motivation": "Low-resolution images hinder the accuracy of automated visual tasks like classification and detection. Current SR methods focus on pixel quality but lack integration with classification performance improvement.", "method": "The authors propose a methodology that optimizes loss functions accounting for both image quality and classification performance, targeting synthetic aperture radar imagery.", "result": "The method enhances both image quality and classification accuracy as validated through image metrics and classification tests.", "conclusion": "Integrating classification performance directly within the SR process yields better-quality images and improved classification outcomes."}}
{"id": "2508.06131", "pdf": "https://arxiv.org/pdf/2508.06131", "abs": "https://arxiv.org/abs/2508.06131", "authors": ["Philip Anton Hernicht", "Alona Sakhnenko", "Corey O'Meara", "Giorgio Cortiana", "Jeanette Miriam Lorenz"], "title": "Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications", "categories": ["quant-ph", "cs.LG"], "comment": "9 pages, 8 figures", "summary": "Quantum machine learning (QML) presents potential for early industrial\nadoption, yet limited access to quantum hardware remains a significant\nbottleneck for deployment of QML solutions. This work explores the use of\nclassical surrogates to bypass this restriction, which is a technique that\nallows to build a lightweight classical representation of a (trained) quantum\nmodel, enabling to perform inference on entirely classical devices. We reveal\nprohibiting high computational demand associated with previously proposed\nmethods for generating classical surrogates from quantum models, and propose an\nalternative pipeline enabling generation of classical surrogates at a larger\nscale than was previously possible. Previous methods required at least a\nhigh-performance computing (HPC) system for quantum models of below industrial\nscale (ca. 20 qubits), which raises questions about its practicality. We\ngreatly minimize the redundancies of the previous approach, utilizing only a\nminute fraction of the resources previously needed. We demonstrate the\neffectiveness of our method on a real-world energy demand forecasting problem,\nconducting rigorous testing of performance and computation demand in both\nsimulations and on quantum hardware. Our results indicate that our method\nachieves high accuracy on the testing dataset while its computational resource\nrequirements scale linearly rather than exponentially. This work presents a\nlightweight approach to transform quantum solutions into classically deployable\nversions, facilitating faster integration of quantum technology in industrial\nsettings. Furthermore, it can serve as a powerful research tool in search\npractical quantum advantage in an empirical setup.", "AI": {"tldr": "This paper proposes using classical surrogates to make quantum machine learning (QML) solutions deployable on classical devices, addressing deployment challenges due to limited quantum hardware access.", "motivation": "To bridge the gap between the potential of quantum machine learning and limited access to quantum hardware, enabling industrial adoption.", "method": "The authors propose an optimized pipeline for generating classical surrogates for quantum models, minimizing computational demands compared to previous methods and employing rigorous testing on quantum hardware and simulations.", "result": "Their method achieves high accuracy in energy demand forecasting while scaling computational resource requirements linearly, making large-scale surrogate generation feasible.", "conclusion": "The proposed lightweight classical surrogate approach accelerates the integration of quantum solutions into industry and aids in exploring practical quantum advantages empirically."}}
{"id": "2508.06420", "pdf": "https://arxiv.org/pdf/2508.06420", "abs": "https://arxiv.org/abs/2508.06420", "authors": ["Ch Muhammad Awais", "Marco Reggiannini", "Davide Moroni", "Oktay Karakus"], "title": "Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification", "categories": ["cs.CV"], "comment": "Accepted and presented at IGARSS", "summary": "SAR ship classification faces the challenge of long-tailed datasets, which\ncomplicates the classification of underrepresented classes. Oversampling\nmethods have proven effective in addressing class imbalance in optical data. In\nthis paper, we evaluated the effect of oversampling in the feature space for\nSAR ship classification. We propose two novel algorithms inspired by the\nMajor-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two\npublic datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three\nstate-of-the-art models as feature extractors: ViT, VGG16, and ResNet50.\nAdditionally, we also analyzed the impact of oversampling methods on different\nclass sizes. The results demonstrated the effectiveness of our novel methods\nover the original M2m and baselines, with an average F1-score increase of 8.82%\nfor FuSARShip and 4.44% for OpenSARShip.", "AI": {"tldr": "The paper addresses class imbalance in SAR ship classification datasets using novel oversampling algorithms, improving F1-scores significantly on public datasets.", "motivation": "To tackle the long-tailed datasets problem in SAR ship classification, where underrepresented classes hinder accurate classification.", "method": "Proposed two new algorithms (M2m$_f$ and M2m$_u$) inspired by the Major-to-minor method, tested across two public datasets (OpenSARShip and FuSARShip) using three models (ViT, VGG16, ResNet50).", "result": "The new methods achieved an average F1-score improvement of 8.82% on FuSARShip and 4.44% on OpenSARShip over the baseline methods.", "conclusion": "The proposed algorithms effectively address class imbalance, making them valuable for improving SAR ship classification in long-tailed datasets."}}
{"id": "2508.06133", "pdf": "https://arxiv.org/pdf/2508.06133", "abs": "https://arxiv.org/abs/2508.06133", "authors": ["Meixuan Wang", "Yinyu Ye", "Zijie Zhou"], "title": "LLM Serving Optimization with Variable Prefill and Decode Lengths", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "We study the problem of serving LLM (Large Language Model) requests where\neach request has heterogeneous prefill and decode lengths. In LLM serving, the\nprefill length corresponds to the input prompt length, which determines the\ninitial memory usage in the KV cache. The decode length refers to the number of\noutput tokens generated sequentially, with each additional token increasing the\nKV cache memory usage by one unit. Given a set of n requests, our goal is to\nschedule and process them to minimize the total completion time. We show that\nthis problem is NP-hard due to the interplay of batching, placement\nconstraints, precedence relationships, and linearly increasing memory usage. We\nthen analyze commonly used scheduling strategies in practice, such as\nFirst-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their\ncompetitive ratios scale up sublinearly with the memory limit-a significant\ndrawback in real-world settings where memory demand is large. To address this,\nwe propose a novel algorithm based on a new selection metric that efficiently\nforms batches over time. We prove that this algorithm achieves a constant\ncompetitive ratio. Finally, we develop and evaluate a few algorithm variants\ninspired by this approach, including dynamic programming variants, local search\nmethods, and an LP-based scheduler, demonstrating through comprehensive\nsimulations that they outperform standard baselines while maintaining\ncomputational efficiency.", "AI": {"tldr": "The paper addresses the issue of efficiently scheduling LLM requests to minimize completion time, considering constraints like memory usage and batching challenges.", "motivation": "The motivation is to address the inefficiency of current scheduling strategies for LLM requests in real-world applications, where large memory demands and complex request dynamics make performance optimization challenging.", "method": "The authors analyze the limitations of existing scheduling strategies like FCFS and SF, propose a novel algorithm with a constant competitive ratio for batching, and further refine it using dynamic programming, local search, and LP-based approaches.", "result": "The newly proposed algorithm and its variants outperform baseline scheduling strategies in simulations, balancing improved performance with computational efficiency.", "conclusion": "The paper highlights the NP-hardness of scheduling LLM requests, proposes an innovative solution with practical performance benefits, and provides a framework for future improvement in LLM serving systems."}}
{"id": "2508.06429", "pdf": "https://arxiv.org/pdf/2508.06429", "abs": "https://arxiv.org/abs/2508.06429", "authors": ["Guido Manni", "Clemente Lauretti", "Loredana Zollo", "Paolo Soda"], "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning has revolutionized medical imaging, but its effectiveness is\nseverely limited by insufficient labeled training data. This paper introduces a\nnovel GAN-based semi-supervised learning framework specifically designed for\nlow labeled-data regimes, evaluated across settings with 5 to 50 labeled\nsamples per class. Our approach integrates three specialized neural networks --\na generator for class-conditioned image translation, a discriminator for\nauthenticity assessment and classification, and a dedicated classifier --\nwithin a three-phase training framework. The method alternates between\nsupervised training on limited labeled data and unsupervised learning that\nleverages abundant unlabeled images through image-to-image translation rather\nthan generation from noise. We employ ensemble-based pseudo-labeling that\ncombines confidence-weighted predictions from the discriminator and classifier\nwith temporal consistency through exponential moving averaging, enabling\nreliable label estimation for unlabeled data. Comprehensive evaluation across\neleven MedMNIST datasets demonstrates that our approach achieves statistically\nsignificant improvements over six state-of-the-art GAN-based semi-supervised\nmethods, with particularly strong performance in the extreme 5-shot setting\nwhere the scarcity of labeled data is most challenging. The framework maintains\nits superiority across all evaluated settings (5, 10, 20, and 50 shots per\nclass). Our approach offers a practical solution for medical imaging\napplications where annotation costs are prohibitive, enabling robust\nclassification performance even with minimal labeled data. Code is available at\nhttps://github.com/GuidoManni/SPARSE.", "AI": {"tldr": "The paper proposes a GAN-based semi-supervised learning framework tailored for medical imaging with minimal labeled data, demonstrating improvements against existing methods across various labeled-data settings.", "motivation": "Address the challenge of inadequate labeled training data in medical imaging, particularly in scenarios where annotation is costly and data is scarce.", "method": "A framework involving three neural networks (generator, discriminator, classifier) with supervised and unsupervised phases, leveraging image-to-image translation, ensemble-based pseudo-labeling, and temporal consistency for label estimation.", "result": "Significant improvements over six state-of-the-art methods across eleven MedMNIST datasets, showing robust performance even in extremely low labeled-data settings (as few as 5 labeled samples/class).", "conclusion": "The method provides a viable solution for medical imaging tasks, achieving reliable classification with minimal labeled data, and promises practical application in low-data regimes."}}
{"id": "2508.06430", "pdf": "https://arxiv.org/pdf/2508.06430", "abs": "https://arxiv.org/abs/2508.06430", "authors": ["Om Patil", "Jinesh Modi", "Suryabha Mukhopadhyay", "Meghaditya Giri", "Chhavi Malhotra"], "title": "MotionSwap", "categories": ["cs.CV"], "comment": "8 pages, 7 figures, 5 tables. This is a student research submission\n  from BITS Pilani, Hyderabad Campus. Our implementation enhances SimSwap with\n  attention modules and dynamic training strategies", "summary": "Face swapping technology has gained significant attention in both academic\nresearch and commercial applications. This paper presents our implementation\nand enhancement of SimSwap, an efficient framework for high fidelity face\nswapping. We introduce several improvements to the original model, including\nthe integration of self and cross-attention mechanisms in the generator\narchitecture, dynamic loss weighting, and cosine annealing learning rate\nscheduling. These enhancements lead to significant improvements in identity\npreservation, attribute consistency, and overall visual quality.\n  Our experimental results, spanning 400,000 training iterations, demonstrate\nprogressive improvements in generator and discriminator performance. The\nenhanced model achieves better identity similarity, lower FID scores, and\nvisibly superior qualitative results compared to the baseline. Ablation studies\nconfirm the importance of each architectural and training improvement. We\nconclude by identifying key future directions, such as integrating StyleGAN3,\nimproving lip synchronization, incorporating 3D facial modeling, and\nintroducing temporal consistency for video-based applications.", "AI": {"tldr": "This paper enhances SimSwap for face swapping by integrating attention mechanisms, dynamic loss adjustment, and learning rate scheduling, achieving better quality and identity preservation.", "motivation": "To advance face swapping technology for improved fidelity, identity preservation, and consistency in attributes.", "method": "The authors improve SimSwap by adding self and cross-attention mechanisms, dynamic loss weighting, and cosine annealing learning rate scheduling.", "result": "Enhanced model yields better identity similarity, lower FID scores, and qualitative improvements backed by experiments over 400,000 training iterations.", "conclusion": "Key future directions include integrating StyleGAN3, improving lip synchronization, exploring 3D facial modeling, and ensuring temporal consistency in video applications."}}
{"id": "2508.06434", "pdf": "https://arxiv.org/pdf/2508.06434", "abs": "https://arxiv.org/abs/2508.06434", "authors": ["Shengzhu Yang", "Jiawei Du", "Shuai Lu", "Weihang Zhang", "Ningli Wang", "Huiqi Li"], "title": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large-scale natural image-text datasets, especially those automatically\ncollected from the web, often suffer from loose semantic alignment due to weak\nsupervision, while medical datasets tend to have high cross-modal correlation\nbut low content diversity. These properties pose a common challenge for\ncontrastive language-image pretraining (CLIP): they hinder the model's ability\nto learn robust and generalizable representations. In this work, we propose\nCLIPin, a unified non-contrastive plug-in that can be seamlessly integrated\ninto CLIP-style architectures to improve multimodal semantic alignment,\nproviding stronger supervision and enhancing alignment robustness. Furthermore,\ntwo shared pre-projectors are designed for image and text modalities\nrespectively to facilitate the integration of contrastive and non-contrastive\nlearning in a parameter-compromise manner. Extensive experiments on diverse\ndownstream tasks demonstrate the effectiveness and generality of CLIPin as a\nplug-and-play component compatible with various contrastive frameworks. Code is\navailable at https://github.com/T6Yang/CLIPin.", "AI": {"tldr": "The paper introduces CLIPin, a plug-in for improving multimodal semantic alignment in CLIP-style architectures, addressing challenges in natural and medical datasets.", "motivation": "To enhance CLIP's ability to learn robust and generalizable representations, particularly in datasets with loose alignment or low diversity.", "method": "Introduced a non-contrastive plug-in, CLIPin, with shared pre-projectors for both modalities to harmonize contrastive and non-contrastive learning.", "result": "Demonstrated effectiveness of CLIPin across multiple downstream tasks, showcasing its compatibility with various contrastive frameworks.", "conclusion": "The proposed CLIPin enhances supervision and alignment robustness, serving as an effective, generalizable plug-and-play solution for multimodal representation learning."}}
{"id": "2508.06452", "pdf": "https://arxiv.org/pdf/2508.06452", "abs": "https://arxiv.org/abs/2508.06452", "authors": ["Mattia Litrico", "Mario Valerio Giuffrida", "Sebastiano Battiato", "Devis Tuia"], "title": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent unsupervised domain adaptation (UDA) methods have shown great success\nin addressing classical domain shifts (e.g., synthetic-to-real), but they still\nsuffer under complex shifts (e.g. geographical shift), where both the\nbackground and object appearances differ significantly across domains. Prior\nworks showed that the language modality can help in the adaptation process,\nexhibiting more robustness to such complex shifts. In this paper, we introduce\nTRUST, a novel UDA approach that exploits the robustness of the language\nmodality to guide the adaptation of a vision model. TRUST generates\npseudo-labels for target samples from their captions and introduces a novel\nuncertainty estimation strategy that uses normalised CLIP similarity scores to\nestimate the uncertainty of the generated pseudo-labels. Such estimated\nuncertainty is then used to reweight the classification loss, mitigating the\nadverse effects of wrong pseudo-labels obtained from low-quality captions. To\nfurther increase the robustness of the vision model, we propose a multimodal\nsoft-contrastive learning loss that aligns the vision and language feature\nspaces, by leveraging captions to guide the contrastive training of the vision\nmodel on target images. In our contrastive loss, each pair of images acts as\nboth a positive and a negative pair and their feature representations are\nattracted and repulsed with a strength proportional to the similarity of their\ncaptions. This solution avoids the need for hardly determining positive and\nnegative pairs, which is critical in the UDA setting. Our approach outperforms\nprevious methods, setting the new state-of-the-art on classical (DomainNet) and\ncomplex (GeoNet) domain shifts. The code will be available upon acceptance.", "AI": {"tldr": "The paper introduces TRUST, a novel UDA method leveraging language modality to overcome classical and complex domain shifts by generating pseudo-labels from captions and utilizing multimodal soft-contrastive learning.", "motivation": "Unsupervised domain adaptation methods struggle with complex domain shifts, like geographical changes where object and background appearances vary significantly. Language modalities show potential in improving adaptation robustness.", "method": "TRUST generates pseudo-labels using captions, applies uncertainty estimation with normalised CLIP similarity scores, reweights classification loss to mitigate wrong pseudo-label effects, and employs multimodal soft-contrastive learning to align vision and language feature spaces.", "result": "TRUST achieves state-of-the-art performance in both classical domain shifts (DomainNet) and complex shifts (GeoNet).", "conclusion": "TRUST effectively addresses challenges in UDA by using language-guided pseudo labeling and multimodal contrastive learning, offering improved robustness and accuracy under diverse shift types."}}
{"id": "2508.06453", "pdf": "https://arxiv.org/pdf/2508.06453", "abs": "https://arxiv.org/abs/2508.06453", "authors": ["Ruida Cheng", "Tejas Sudharshan Mathai", "Pritam Mukherjee", "Benjamin Hou", "Qingqing Zhu", "Zhiyong Lu", "Matthew McAuliffe", "Ronald M. Summers"], "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Segmentation of lesions on CT enables automatic measurement for clinical\nassessment of chronic diseases (e.g., lymphoma). Integrating large language\nmodels (LLMs) into the lesion segmentation workflow offers the potential to\ncombine imaging features with descriptions of lesion characteristics from the\nradiology reports. In this study, we investigate the feasibility of integrating\ntext into the Swin-UMamba architecture for the task of lesion segmentation. The\npublicly available ULS23 DeepLesion dataset was used along with short-form\ndescriptions of the findings from the reports. On the test dataset, a high Dice\nScore of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for\nlesion segmentation. The proposed Text-Swin-UMamba model outperformed prior\napproaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <\n0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by\n1.74% and 0.22%, respectively. The dataset and code can be accessed at\nhttps://github.com/ruida/LLM-Swin-UMamba", "AI": {"tldr": "The paper introduces the Text-Swin-UMamba model for lesion segmentation by incorporating text from radiology reports into a CT image analysis workflow, achieving significant performance improvements.", "motivation": "The research aims to enhance the accuracy of lesion segmentation on CT scans by leveraging text descriptions from radiology reports alongside imaging features.", "method": "The study integrates text-based descriptions into the Swin-UMamba architecture and evaluates performance using the ULS23 DeepLesion dataset.", "result": "The model achieved a Dice Score of 82% and a Hausdorff distance of 6.58 pixels, outperforming previous models such as LanGuideMedSeg by 37%, xLSTM-UNet by 1.74%, and nnUNet by 0.22%. Statistical significance (p < 0.001) was demonstrated.", "conclusion": "Integrating text with imaging features significantly enhances lesion segmentation models, offering improved metrics and potential clinical benefits."}}
{"id": "2508.06485", "pdf": "https://arxiv.org/pdf/2508.06485", "abs": "https://arxiv.org/abs/2508.06485", "authors": ["Sofiane Bouaziz", "Adel Hafiane", "Raphael Canals", "Rachid Nedjai"], "title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing\n  (TGRS)", "summary": "Urbanization, climate change, and agricultural stress are increasing the\ndemand for precise and timely environmental monitoring. Land Surface\nTemperature (LST) is a key variable in this context and is retrieved from\nremote sensing satellites. However, these systems face a trade-off between\nspatial and temporal resolution. While spatio-temporal fusion methods offer\npromising solutions, few have addressed the estimation of daily LST at 10 m\nresolution. In this study, we present WGAST, a Weakly-Supervised Generative\nNetwork for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra\nMODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning\nframework designed for this task. It adopts a conditional generative\nadversarial architecture, with a generator composed of four stages: feature\nextraction, fusion, LST reconstruction, and noise suppression. The first stage\nemploys a set of encoders to extract multi-level latent representations from\nthe inputs, which are then fused in the second stage using cosine similarity,\nnormalization, and temporal attention mechanisms. The third stage decodes the\nfused features into high-resolution LST, followed by a Gaussian filter to\nsuppress high-frequency noise. Training follows a weakly supervised strategy\nbased on physical averaging principles and reinforced by a PatchGAN\ndiscriminator. Experiments demonstrate that WGAST outperforms existing methods\nin both quantitative and qualitative evaluations. Compared to the\nbest-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves\nSSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and\neffectively captures fine-scale thermal patterns, as validated against 33\nground-based sensors. The code is available at\nhttps://github.com/Sofianebouaziz1/WGAST.git.", "AI": {"tldr": "This paper introduces WGAST, a novel deep learning framework for estimating daily Land Surface Temperature (LST) at 10 m resolution using spatio-temporal fusion of satellite data. WGAST outperforms existing methods in accuracy and robustness against noise.", "motivation": "The need for precise and timely environmental monitoring is intensified by urbanization, climate change, and agricultural demands. Current satellite-based LST retrieval systems face a trade-off between spatial and temporal resolution, creating the need for advanced solutions.", "method": "WGAST, the proposed method, is a weakly-supervised generative network using a conditional GAN architecture. It includes multi-stage processing\u2014feature extraction, fusion, LST reconstruction, and noise reduction\u2014leveraging encoders, cosine similarity, normalization, temporal attention, and Gaussian filtering. A PatchGAN discriminator reinforces the weakly supervised training.", "result": "WGAST demonstrates superior performance by reducing RMSE by 17.18% and improving SSIM by 11.00% relative to the best baseline method. The approach is validated on 33 ground-based sensors and exhibits robustness against cloud-induced LST issues.", "conclusion": "The findings highlight WGAST as a pioneering and effective solution for daily 10 m LST estimation, addressing a key gap in remote sensing. The model's performance and robustness affirm its utility for high-resolution environmental monitoring tasks."}}
{"id": "2508.06321", "pdf": "https://arxiv.org/pdf/2508.06321", "abs": "https://arxiv.org/abs/2508.06321", "authors": ["Durjoy Chandra Paul", "Gaurob Saha", "Md Amjad Hossain"], "title": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition", "categories": ["cs.SD", "cs.HC", "cs.LG"], "comment": "To be published in ICCCNT 2025 (16th International Conference on\n  Computing Communication and Networking Technologies)", "summary": "Recognizing emotional signals in speech has a significant impact on enhancing\nthe effectiveness of human-computer interaction (HCI). This study introduces\nEmoAugNet, a hybrid deep learning framework, that incorporates Long Short-Term\nMemory (LSTM) layers with one-dimensional Convolutional Neural Networks\n(1D-CNN) to enable reliable Speech Emotion Recognition (SER). The quality and\nvariety of the features that are taken from speech signals have a significant\nimpact on how well SER systems perform. A comprehensive speech data\naugmentation strategy was used to combine both traditional methods, such as\nnoise addition, pitch shifting, and time stretching, with a novel\ncombination-based augmentation pipeline to enhance generalization and reduce\noverfitting. Each audio sample was transformed into a high-dimensional feature\nvector using root mean square energy (RMSE), Mel-frequency Cepstral Coefficient\n(MFCC), and zero-crossing rate (ZCR). Our model with ReLU activation has a\nweighted accuracy of 95.78\\% and unweighted accuracy of 92.52\\% on the IEMOCAP\ndataset and, with ELU activation, has a weighted accuracy of 96.75\\% and\nunweighted accuracy of 91.28\\%. On the RAVDESS dataset, we get a weighted\naccuracy of 94.53\\% and 94.98\\% unweighted accuracy for ReLU activation and\n93.72\\% weighted accuracy and 94.64\\% unweighted accuracy for ELU activation.\nThese results highlight EmoAugNet's effectiveness in improving the robustness\nand performance of SER systems through integated data augmentation and hybrid\nmodeling.", "AI": {"tldr": "This paper introduces EmoAugNet, a hybrid deep learning model combining LSTM and 1D-CNN for speech emotion recognition (SER), using enhanced data augmentation and feature extraction. The model achieves high accuracy on standard datasets.", "motivation": "The study aims to improve the robustness and performance of Speech Emotion Recognition (SER) systems for more effective human-computer interaction by addressing challenges such as overfitting and feature quality.", "method": "The authors proposed EmoAugNet, a deep learning framework combining LSTM and 1D-CNN layers. A novel data augmentation technique, mixing traditional and combination-based methods, was applied. Key features like RMSE, MFCC, and ZCR were extracted to transform audio into high-dimensional feature vectors.", "result": "On the IEMOCAP dataset, accuracy reached up to 96.75% (weighted) and 92.52% (unweighted). For the RAVDESS dataset, the model achieved up to 94.98% (weighted) and 94.64% (unweighted) accuracy, with slight variations across ReLU and ELU activations.", "conclusion": "EmoAugNet effectively enhances the robustness and accuracy of SER systems through its integrated data augmentation and hybrid modeling techniques, showcasing its potential for practical applications in HCI."}}
{"id": "2508.06494", "pdf": "https://arxiv.org/pdf/2508.06494", "abs": "https://arxiv.org/abs/2508.06494", "authors": ["Yehonathan Litman", "Fernando De la Torre", "Shubham Tulsiani"], "title": "LightSwitch: Multi-view Relighting with Material-guided Diffusion", "categories": ["cs.CV"], "comment": "ICCV 2025, Project page & Code:\n  https://yehonathanlitman.github.io/light_switch/", "summary": "Recent approaches for 3D relighting have shown promise in integrating 2D\nimage relighting generative priors to alter the appearance of a 3D\nrepresentation while preserving the underlying structure. Nevertheless,\ngenerative priors used for 2D relighting that directly relight from an input\nimage do not take advantage of intrinsic properties of the subject that can be\ninferred or cannot consider multi-view data at scale, leading to subpar\nrelighting. In this paper, we propose Lightswitch, a novel finetuned\nmaterial-relighting diffusion framework that efficiently relights an arbitrary\nnumber of input images to a target lighting condition while incorporating cues\nfrom inferred intrinsic properties. By using multi-view and material\ninformation cues together with a scalable denoising scheme, our method\nconsistently and efficiently relights dense multi-view data of objects with\ndiverse material compositions. We show that our 2D relighting prediction\nquality exceeds previous state-of-the-art relighting priors that directly\nrelight from images. We further demonstrate that LightSwitch matches or\noutperforms state-of-the-art diffusion inverse rendering methods in relighting\nsynthetic and real objects in as little as 2 minutes.", "AI": {"tldr": "The paper presents Lightswitch, a finetuned diffusion framework for efficient multi-view relighting using intrinsic cues, outperforming existing methods.", "motivation": "Current 3D relighting techniques struggle with integrating intrinsic subject properties and large-scale multi-view data, resulting in lower-quality relighting.", "method": "Lightswitch leverages a material-relighting diffusion framework incorporating intrinsic property cues, multi-views, and scalable denoising to enhance relighting.", "result": "Lightswitch achieves superior 2D relighting quality compared to existing state-of-the-art methods and outperforms in relighting synthetic and real objects efficiently.", "conclusion": "The proposed Lightswitch framework is a significant step forward in scalable and efficient 3D relighting, offering improvements in quality and computational efficiency."}}
{"id": "2508.04728", "pdf": "https://arxiv.org/pdf/2508.04728", "abs": "https://arxiv.org/abs/2508.04728", "authors": ["Shuo Chen", "Yijin Li", "Xi Zheng", "Guofeng Zhang"], "title": "Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy", "categories": ["eess.IV", "cs.CV", "physics.ins-det"], "comment": null, "summary": "The scanning electron microscope (SEM) is a widely used imaging device in\nscientific research and industrial applications. Conventional two-dimensional\n(2D) SEM images do not directly reveal the three-dimensional (3D) topography of\nmicro samples, motivating the development of SEM 3D surface reconstruction\nmethods. However, reconstruction of complex microstructures remains challenging\nfor existing methods due to the limitations of discrete 3D representations, the\nneed for calibration with reference samples, and shadow-induced gradient\nerrors. Here, we introduce NFH-SEM, a neural field-based hybrid SEM 3D\nreconstruction method that takes multi-view, multi-detector 2D SEM images as\ninput and fuses geometric and photometric information into a continuous neural\nfield representation. NFH-SEM eliminates the manual calibration procedures\nthrough end-to-end self-calibration and automatically disentangles shadows from\nSEM images during training, enabling accurate reconstruction of intricate\nmicrostructures. We validate the effectiveness of NFH-SEM on real and simulated\ndatasets. Our experiments show high-fidelity reconstructions of diverse,\nchallenging samples, including two-photon lithography microstructures, peach\npollen, and silicon carbide particle surfaces, demonstrating precise detail and\nbroad applicability.", "AI": {"tldr": "This paper introduces NFH-SEM, a neural field-based method to achieve 3D surface reconstruction from 2D SEM images, overcoming existing challenges.", "motivation": "Conventional SEM images are 2D and lack direct information on the 3D topography of microstructures, necessitating new reconstruction methods.", "method": "The NFH-SEM method uses multi-view, multi-detector 2D SEM images to fuse geometric and photometric data into a continuous neural field representation, featuring end-to-end self-calibration and shadow disentanglement.", "result": "NFH-SEM delivers high-quality 3D reconstructions on both real and simulated datasets, accurately capturing intricate microstructures such as lithography designs, pollen, and silicon carbide particles.", "conclusion": "NFH-SEM provides a robust and adaptable solution for precise SEM 3D surface reconstruction, eliminating manual calibrations and achieving broad applicability in scientific and industrial contexts."}}
{"id": "2508.06098", "pdf": "https://arxiv.org/pdf/2508.06098", "abs": "https://arxiv.org/abs/2508.06098", "authors": ["Xiquan Li", "Junxi Liu", "Yuzhe Liang", "Zhikang Niu", "Wenxi Chen", "Xie Chen"], "title": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows", "categories": ["cs.SD", "cs.AI"], "comment": "9 pages, 3 figures", "summary": "Recent developments in diffusion- and flow- based models have significantly\nadvanced Text-to-Audio Generation (TTA). While achieving great synthesis\nquality and controllability, current TTA systems still suffer from slow\ninference speed, which significantly limits their practical applicability. This\npaper presents MeanAudio, a novel MeanFlow-based model tailored for fast and\nfaithful text-to-audio generation. Built on a Flux-style latent transformer,\nMeanAudio regresses the average velocity field during training, enabling fast\ngeneration by mapping directly from the start to the endpoint of the flow\ntrajectory. By incorporating classifier-free guidance (CFG) into the training\ntarget, MeanAudio incurs no additional cost in the guided sampling process. To\nfurther stabilize training, we propose an instantaneous-to-mean curriculum with\nflow field mix-up, which encourages the model to first learn the foundational\ninstantaneous dynamics, and then gradually adapt to mean flows. This strategy\nproves critical for enhancing training efficiency and generation quality.\nExperimental results demonstrate that MeanAudio achieves state-of-the-art\nperformance in single-step audio generation. Specifically, it achieves a real\ntime factor (RTF) of 0.013 on a single NVIDIA RTX 3090, yielding a 100x speedup\nover SOTA diffusion-based TTA systems. Moreover, MeanAudio also demonstrates\nstrong performance in multi-step generation, enabling smooth and coherent\ntransitions across successive synthesis steps.", "AI": {"tldr": "MeanAudio introduces a fast and efficient mechanism for text-to-audio generation, achieving up to 100x speedup compared to diffusion-based systems.", "motivation": "The paper aims to overcome the slow inference speed of current text-to-audio generation (TTA) systems, which limits their practical application despite achieving great synthesis quality.", "method": "The authors propose MeanAudio, built on a MeanFlow-based model that leverages a Flux-style latent transformer, instantaneous-to-mean curriculum learning, and classifier-free guidance for efficient audio synthesis.", "result": "MeanAudio achieves state-of-the-art (SOTA) single-step audio generation with a real-time factor (RTF) of 0.013, demonstrating a 100x speed improvement over diffusion-based systems and strong performance in multi-step generation.", "conclusion": "Using innovative methodologies and optimizations, MeanAudio addresses the speed bottleneck in TTA systems, offering significant advancements in synthesis quality and rate, making it viable for practical applications."}}
{"id": "2508.05658", "pdf": "https://arxiv.org/pdf/2508.05658", "abs": "https://arxiv.org/abs/2508.05658", "authors": ["Song Yan", "Hui Wei", "Jinlong Fei", "Guoliang Yang", "Zhengyu Zhao", "Zheng Wamg"], "title": "Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards", "categories": ["cs.CR", "cs.CV", "cs.MM"], "comment": "ACM MM 2025", "summary": "Various (text) prompt filters and (image) safety checkers have been\nimplemented to mitigate the misuse of Text-to-Image (T2I) models in creating\nNot-Safe-For-Work (NSFW) content.In order to expose potential security\nvulnerabilities of such safeguards, multimodal jailbreaks have been\nstudied.However, existing jailbreaks are limited to prompt-specific and\nimage-specific perturbations, which suffer from poor scalability and\ntime-consuming optimization.To address these limitations, we propose\nUniversally Unfiltered and Unseen (U3)-Attack, a multimodal jailbreak attack\nmethod against T2I safeguards.Specifically, U3-Attack optimizes an adversarial\npatch on the image background to universally bypass safety checkers and\noptimizes a safe paraphrase set from a sensitive word to universally bypass\nprompt filters while eliminating redundant computations.Extensive experimental\nresults demonstrate the superiority of our U3-Attack on both open-source and\ncommercial T2I models.For example, on the commercial Runway-inpainting model\nwith both prompt filter and safety checker, our U3-Attack achieves $~4\\times$\nhigher success rates than the state-of-the-art multimodal jailbreak attack,\nMMA-Diffusion.Content Warning: This paper includes examples of NSFW content.", "AI": {"tldr": "The U3-Attack method bypasses safety measures in T2I models by using optimized adversarial patches and paraphrases, achieving significantly higher success rates compared to existing approaches.", "motivation": "Addressing security vulnerabilities in text-to-image (T2I) safeguards, which face issues of scalability and inefficiency in current jailbreak methods.", "method": "Development of the U3-Attack, which utilizes optimized adversarial patches on image backgrounds and safe paraphrases to bypass both prompt filters and safety checkers in T2I models.", "result": "Experimental results show U3-Attack achieves nearly four times higher success rates than the previous best method, MMA-Diffusion, particularly in commercial models like Runway-inpainting.", "conclusion": "The U3-Attack offers a superior, scalable solution for testing security weaknesses in T2I safeguards, highlighting the need for stronger protection mechanisms."}}
{"id": "2508.06383", "pdf": "https://arxiv.org/pdf/2508.06383", "abs": "https://arxiv.org/abs/2508.06383", "authors": ["Rashid Barket", "Matthew England", "J\u00fcrgen Gerhard"], "title": "Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms", "categories": ["cs.SC", "cs.LG"], "comment": "29 pages, 13 figures, 5 tables, submitted to Transactions on\n  Mathematical Software (TOMS)", "summary": "Symbolic indefinite integration in Computer Algebra Systems such as Maple\ninvolves selecting the most effective algorithm from multiple available\nmethods. Not all methods will succeed for a given problem, and when several do,\nthe results, though mathematically equivalent, can differ greatly in\npresentation complexity. Traditionally, this choice has been made with minimal\nconsideration of the problem instance, leading to inefficiencies.\n  We present a machine learning (ML) approach using tree-based deep learning\nmodels within a two-stage architecture: first identifying applicable methods\nfor a given instance, then ranking them by predicted output complexity.\nFurthermore, we find representing mathematical expressions as tree structures\nsignificantly improves performance over sequence-based representations, and our\ntwo-stage framework outperforms alternative ML formulations.\n  Using a diverse dataset generated by six distinct data generators, our models\nachieve nearly 90% accuracy in selecting the optimal method on a 70,000 example\nholdout test set. On an independent out-of-distribution benchmark from Maple's\ninternal test suite, our tree transformer model maintains strong\ngeneralisation, outperforming Maple's built-in selector and prior ML\napproaches.\n  These results highlight the critical role of data representation and problem\nframing in ML for symbolic computation, and we expect our methodology to\ngeneralise effectively to similar optimisation problems in mathematical\nsoftware.", "AI": {"tldr": "The paper introduces a machine learning-based approach for symbolic indefinite integration in Computer Algebra Systems, aiming to choose efficient algorithms based on input complexity.", "motivation": "Often, Computer Algebra Systems inefficiently select algorithms without considering problem-specific nuances, leading to suboptimal outcomes.", "method": "The authors propose a machine learning framework with tree-based deep learning models. Their two-stage architecture first identifies applicable methods and then ranks them based on presentation complexity.", "result": "Their model achieves 90% accuracy in method selection on a large test set and outperforms traditional approaches and built-in systems on independent benchmarks.", "conclusion": "Using tree-based representations boosts accuracy in symbolic computation, and their framework is expected to generalize well across similar mathematical optimization problems."}}
{"id": "2508.06411", "pdf": "https://arxiv.org/pdf/2508.06411", "abs": "https://arxiv.org/abs/2508.06411", "authors": ["Ze Shen Chin"], "title": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "24 pages including references, 6 figures. To be presented in\n  Technical AI Governance Forum 2025", "summary": "Although discourse around the risks of Artificial Intelligence (AI) has\ngrown, it often lacks a comprehensive, multidimensional framework, and concrete\ncausal pathways mapping hazard to harm. This paper aims to bridge this gap by\nexamining six commonly discussed AI catastrophic risks: CBRN, cyber offense,\nsudden loss of control, gradual loss of control, environmental risk, and\ngeopolitical risk. First, we characterize these risks across seven key\ndimensions, namely intent, competency, entity, polarity, linearity, reach, and\norder. Next, we conduct risk pathway modeling by mapping step-by-step\nprogressions from the initial hazard to the resulting harms. The dimensional\napproach supports systematic risk identification and generalizable mitigation\nstrategies, while risk pathway models help identify scenario-specific\ninterventions. Together, these methods offer a more structured and actionable\nfoundation for managing catastrophic AI risks across the value chain.", "AI": {"tldr": "The paper develops a structured framework to explore six major AI catastrophic risks by analyzing their dimensions and step-by-step pathways from hazards to harms.", "motivation": "The lack of a multidimensional and causal approach in studying the risks associated with AI technology motivated this research.", "method": "The paper mapped six AI risks using a seven-dimensional framework\u2014intent, competency, entity, polarity, linearity, reach, and order\u2014and applied risk pathway modeling to trace hazards to harms.", "result": "The dimensional analysis facilitates systematic risk identification and general mitigation, while pathway models enable targeted, scenario-specific interventions.", "conclusion": "By offering a structured and actionable foundation, the study enhances the understanding and management of AI-related catastrophic risks across various sectors."}}
{"id": "2508.06450", "pdf": "https://arxiv.org/pdf/2508.06450", "abs": "https://arxiv.org/abs/2508.06450", "authors": ["Daria Tikhonovich", "Nikita Zelinskiy", "Aleksandr V. Petrov", "Mayya Spirina", "Andrei Semenov", "Andrey V. Savchenko", "Sergei Kuliev"], "title": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at ACM RecSys 2025", "summary": "Since their introduction, Transformer-based models, such as SASRec and\nBERT4Rec, have become common baselines for sequential recommendations,\nsurpassing earlier neural and non-neural methods. A number of following\npublications have shown that the effectiveness of these models can be improved\nby, for example, slightly updating the architecture of the Transformer layers,\nusing better training objectives, and employing improved loss functions.\nHowever, the additivity of these modular improvements has not been\nsystematically benchmarked - this is the gap we aim to close in this paper.\nThrough our experiments, we identify a very strong model that uses SASRec's\ntraining objective, LiGR Transformer layers, and Sampled Softmax Loss. We call\nthis combination eSASRec (Enhanced SASRec). While we primarily focus on\nrealistic, production-like evaluation, in our preliminarily study we find that\ncommon academic benchmarks show eSASRec to be 23% more effective compared to\nthe most recent state-of-the-art models, such as ActionPiece. In our main\nproduction-like benchmark, eSASRec resides on the Pareto frontier in terms of\nthe accuracy-coverage tradeoff (alongside the recent industrial models HSTU and\nFuXi. As the modifications compared to the original SASRec are relatively\nstraightforward and no extra features are needed (such as timestamps in HSTU),\nwe believe that eSASRec can be easily integrated into existing recommendation\npipelines and can can serve as a strong yet very simple baseline for emerging\ncomplicated algorithms. To facilitate this, we provide the open-source\nimplementations for our models and benchmarks in repository\nhttps://github.com/blondered/transformer_benchmark", "AI": {"tldr": "The paper introduces eSASRec, an enhanced Transformer-based model for sequential recommendations, combining improved architecture, training objective, and loss functions. It is 23% more effective on benchmarks than recent state-of-the-art models while being simple to integrate.", "motivation": "Close the gap in systematically benchmarking the additivity of modular improvements in Transformer-based sequential recommendation models.", "method": "Combine modular improvements like SASRec's objective, LiGR Transformer layers, and Sampled Softmax Loss to develop eSASRec and benchmark its effectiveness against academic and production-like datasets.", "result": "eSASRec outperforms recent state-of-the-art models by 23% on academic benchmarks and performs excellently in production-like settings, residing on the Pareto frontier for the accuracy-coverage tradeoff.", "conclusion": "eSASRec is a powerful, simple model that improves recommendation pipelines without extra features. Its accessibility and effectiveness make it a solid baseline for future algorithm developments, with open-source implementations provided."}}
{"id": "2508.06137", "pdf": "https://arxiv.org/pdf/2508.06137", "abs": "https://arxiv.org/abs/2508.06137", "authors": ["Ojonugwa Oluwafemi Ejiga Peter", "Daniel Emakporuena", "Bamidele Dayo Tunde", "Maryam Abdulkarim", "Abdullahi Bn Umar"], "title": "Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Breast cancer detection through mammography interpretation remains difficult\nbecause of the minimal nature of abnormalities that experts need to identify\nalongside the variable interpretations between readers. The potential of CNNs\nfor medical image analysis faces two limitations: they fail to process both\nlocal information and wide contextual data adequately, and do not provide\nexplainable AI (XAI) operations that doctors need to accept them in clinics.\nThe researcher developed the MammoFormer framework, which unites\ntransformer-based architecture with multi-feature enhancement components and\nXAI functionalities within one framework. Seven different architectures\nconsisting of CNNs, Vision Transformer, Swin Transformer, and ConvNext were\ntested alongside four enhancement techniques, including original images,\nnegative transformation, adaptive histogram equalization, and histogram of\noriented gradients. The MammoFormer framework addresses critical clinical\nadoption barriers of AI mammography systems through: (1) systematic\noptimization of transformer architectures via architecture-specific feature\nenhancement, achieving up to 13% performance improvement, (2) comprehensive\nexplainable AI integration providing multi-perspective diagnostic\ninterpretability, and (3) a clinically deployable ensemble system combining CNN\nreliability with transformer global context modeling. The combination of\ntransformer models with suitable feature enhancements enables them to achieve\nequal or better results than CNN approaches. ViT achieves 98.3% accuracy\nalongside AHE while Swin Transformer gains a 13.0% advantage through HOG\nenhancements", "AI": {"tldr": "The study introduces the MammoFormer framework, combining transformer-based models with feature enhancements to improve accuracy and diagnostic transparency, addressing key challenges in AI-based mammography systems.", "motivation": "There are challenges in mammography-based breast cancer detection due to subtle abnormalities and inconsistent interpretations by specialists. Current CNN approaches struggle with global context and lack explainability for clinical adoption.", "method": "The researchers developed the MammoFormer framework combining transformers with multi-feature enhancements and explainable AI functionalities. Various architectures were evaluated (CNNs, Vision Transformer, Swin Transformer, ConvNext) with enhancements like histograms and adaptive processing.", "result": "Results showed up to 13% performance improvement with systematic optimization. Notably, ViT achieved 98.3% accuracy with AHE enhancements, and Swin Transformer saw a 13% improvement using HOG enhancements.", "conclusion": "The framework effectively addresses limitations of traditional mammography AI systems by enhancing model accuracy and interpretability, making it suitable for clinical deployment."}}
{"id": "2508.06455", "pdf": "https://arxiv.org/pdf/2508.06455", "abs": "https://arxiv.org/abs/2508.06455", "authors": ["Nikita Sukhorukov", "Danil Gusak", "Evgeny Frolov"], "title": "Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Cold-start challenges in recommender systems necessitate leveraging auxiliary\nfeatures beyond user-item interactions. However, the presence of irrelevant or\nnoisy features can degrade predictive performance, whereas an excessive number\nof features increases computational demands, leading to higher memory\nconsumption and prolonged training times.\n  To address this, we propose a feature selection strategy that prioritizes the\nuser behavioral information. Our method enhances the feature representation by\nincorporating correlations from collaborative behavior data using a hybrid\nmatrix factorization technique and then ranks features using a mechanism based\non the maximum volume algorithm. This approach identifies the most influential\nfeatures, striking a balance between recommendation accuracy and computational\nefficiency. We conduct an extensive evaluation across various datasets and\nhybrid recommendation models, demonstrating that our method excels in\ncold-start scenarios by selecting minimal yet highly effective feature subsets.\nEven under strict feature reduction, our approach surpasses existing feature\nselection techniques while maintaining superior efficiency.", "AI": {"tldr": "The paper introduces a feature selection technique for recommender systems to tackle cold-start challenges, enhancing accuracy and efficiency by prioritizing critical user behavioral features.", "motivation": "Cold-start issues in recommender systems demand effective utilization of auxiliary features, but irrelevant or excessive features degrade performance or increase computation.", "method": "A hybrid matrix factorization technique incorporates correlations from collaborative behavior data, followed by a maximum volume algorithm-based ranking to select influential features.", "result": "The method excels in cold-start scenarios by selecting minimal yet effective features, outperforming existing techniques even with strict feature reduction.", "conclusion": "The proposed feature selection strategy improves recommendation accuracy and efficiency, effectively addressing cold-start challenges in recommender systems."}}
{"id": "2508.06154", "pdf": "https://arxiv.org/pdf/2508.06154", "abs": "https://arxiv.org/abs/2508.06154", "authors": ["Xiaoxiong Zhang", "Xin Zhou", "Zhiwei Zeng", "Dusit Niyato", "Zhiqi Shen"], "title": "Semantic Item Graph Enhancement for Multimodal Recommendation", "categories": ["cs.IR", "cs.AI", "cs.MM"], "comment": null, "summary": "Multimodal recommendation systems have attracted increasing attention for\ntheir improved performance by leveraging items' multimodal information. Prior\nmethods often build modality-specific item-item semantic graphs from raw\nmodality features and use them as supplementary structures alongside the\nuser-item interaction graph to enhance user preference learning. However, these\nsemantic graphs suffer from semantic deficiencies, including (1) insufficient\nmodeling of collaborative signals among items and (2) structural distortions\nintroduced by noise in raw modality features, ultimately compromising\nperformance. To address these issues, we first extract collaborative signals\nfrom the interaction graph and infuse them into each modality-specific item\nsemantic graph to enhance semantic modeling. Then, we design a modulus-based\npersonalized embedding perturbation mechanism that injects perturbations with\nmodulus-guided personalized intensity into embeddings to generate contrastive\nviews. This enables the model to learn noise-robust representations through\ncontrastive learning, thereby reducing the effect of structural noise in\nsemantic graphs. Besides, we propose a dual representation alignment mechanism\nthat first aligns multiple semantic representations via a designed Anchor-based\nInfoNCE loss using behavior representations as anchors, and then aligns\nbehavior representations with the fused semantics by standard InfoNCE, to\nensure representation consistency. Extensive experiments on four benchmark\ndatasets validate the effectiveness of our framework.", "AI": {"tldr": "The paper proposes a multimodal recommendation system addressing issues in semantic graphs by enhancing collaborative signals and reducing noise with a personalized embedding perturbation mechanism.", "motivation": "Multimodal recommendation systems face semantic deficiencies, such as insufficient modeling of collaborations and noise-induced structural distortions, which hinder user preference learning.", "method": "The authors extract collaborative signals from interaction graphs, apply a personalized embedding perturbation mechanism for noise-robust learning, and use a dual representation alignment mechanism to enhance representation consistency.", "result": "Experiments on four benchmark datasets confirm that the proposed framework improves the performance and addresses semantic deficiencies.", "conclusion": "The framework effectively tackles semantic deficiencies in multimodal recommendation systems, improving robustness and representation consistency through innovative mechanisms."}}
{"id": "2508.06182", "pdf": "https://arxiv.org/pdf/2508.06182", "abs": "https://arxiv.org/abs/2508.06182", "authors": ["Chiara Baldini", "Kaisar Kushibar", "Richard Osuala", "Simone Balocco", "Oliver Diaz", "Karim Lekadir", "Leonardo S. Mattos"], "title": "Clinically-guided Data Synthesis for Laryngeal Lesion Detection", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Although computer-aided diagnosis (CADx) and detection (CADe) systems have\nmade significant progress in various medical domains, their application is\nstill limited in specialized fields such as otorhinolaryngology. In the latter,\ncurrent assessment methods heavily depend on operator expertise, and the high\nheterogeneity of lesions complicates diagnosis, with biopsy persisting as the\ngold standard despite its substantial costs and risks. A critical bottleneck\nfor specialized endoscopic CADx/e systems is the lack of well-annotated\ndatasets with sufficient variability for real-world generalization. This study\nintroduces a novel approach that exploits a Latent Diffusion Model (LDM)\ncoupled with a ControlNet adapter to generate laryngeal endoscopic\nimage-annotation pairs, guided by clinical observations. The method addresses\ndata scarcity by conditioning the diffusion process to produce realistic,\nhigh-quality, and clinically relevant image features that capture diverse\nanatomical conditions. The proposed approach can be leveraged to expand\ntraining datasets for CADx/e models, empowering the assessment process in\nlaryngology. Indeed, during a downstream task of detection, the addition of\nonly 10% synthetic data improved the detection rate of laryngeal lesions by 9%\nwhen the model was internally tested and 22.1% on out-of-domain external data.\nAdditionally, the realism of the generated images was evaluated by asking 5\nexpert otorhinolaryngologists with varying expertise to rate their confidence\nin distinguishing synthetic from real images. This work has the potential to\naccelerate the development of automated tools for laryngeal disease diagnosis,\noffering a solution to data scarcity and demonstrating the applicability of\nsynthetic data in real-world scenarios.", "AI": {"tldr": "This paper proposes an innovative method using a Latent Diffusion Model (LDM) paired with ControlNet to generate high-quality synthetic laryngeal endoscopic image datasets, addressing data scarcity for CAD systems in otorhinolaryngology.", "motivation": "Current diagnostic methods in otorhinolaryngology rely heavily on expert assessments, face challenges due to lesion heterogeneity, and lack sufficient well-annotated datasets for CADx/CADe systems.", "method": "The authors utilize a Latent Diffusion Model (LDM) with ControlNet, conditioned by clinical observations, to synthesize realistic image-annotation pairs for training datasets.", "result": "Adding just 10% synthetic data to training improved lesion detection rates by 9% on internal tests and 22.1% on external datasets. Experts also found the synthetic images indistinguishable from real ones.", "conclusion": "This approach demonstrates the value of synthetic data in enhancing CADx/CADe performance, offering solutions to data scarcity in laryngology and improving diagnostic outcomes."}}
{"id": "2508.06477", "pdf": "https://arxiv.org/pdf/2508.06477", "abs": "https://arxiv.org/abs/2508.06477", "authors": ["Llu\u00eds Arola-Fern\u00e1ndez"], "title": "Intuition emerges in Maximum Caliber models at criticality", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG"], "comment": null, "summary": "Whether large predictive models merely parrot their training data or produce\ngenuine insight lacks a physical explanation. This work reports a primitive\nform of intuition that emerges as a metastable phase of learning that\ncritically balances next-token prediction against future path-entropy. The\nintuition mechanism is discovered via mind-tuning, the minimal principle that\nimposes Maximum Caliber in predictive models with a control temperature-like\nparameter $\\lambda$. Training on random walks in deterministic mazes reveals a\nrich phase diagram: imitation (low $\\lambda$), rule-breaking hallucination\n(high $\\lambda$), and a fragile in-between window exhibiting strong\nprotocol-dependence (hysteresis) and multistability, where models spontaneously\ndiscover novel goal-directed strategies. These results are captured by an\neffective low-dimensional theory and frame intuition as an emergent property at\nthe critical balance between memorizing what is and wondering what could be.", "AI": {"tldr": "This study explores how large predictive models may exhibit intuition by implementing Maximum Caliber with a temperature-like control parameter $\\lambda$. It identifies three phases of model behavior and links intuition to a critical balance between memorization and exploration.", "motivation": "Investigate whether predictive models genuinely produce insights or simply mimic training data, explaining mechanisms underlying emergent behavior through physical principles.", "method": "Introduce mind-tuning using a Maximum Caliber framework and a control parameter $\\lambda$, training models on deterministic maze random walks, examining their behavior across varying $\\lambda$ values.", "result": "Discovery of a phase diagram with three states: imitation (low $\\lambda$), hallucination (high $\\lambda$), and a fragile intermediate phase displaying goal-directed strategies and hysteresis.", "conclusion": "Intuition in predictive models emerges as a metastable phase between memorization and speculation, suggesting it is an emergent property rooted in critical learning balance."}}
{"id": "2508.06287", "pdf": "https://arxiv.org/pdf/2508.06287", "abs": "https://arxiv.org/abs/2508.06287", "authors": ["Mobarak Abumohsen", "Enrique Costa-Montenegro", "Silvia Garc\u00eda-M\u00e9ndez", "Amani Yousef Owda", "Majdi Owda"], "title": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Lung cancer (LC) ranks among the most frequently diagnosed cancers and is one\nof the most common causes of death for men and women worldwide. Computed\nTomography (CT) images are the most preferred diagnosis method because of their\nlow cost and their faster processing times. Many researchers have proposed\nvarious ways of identifying lung cancer using CT images. However, such\ntechniques suffer from significant false positives, leading to low accuracy.\nThe fundamental reason results from employing a small and imbalanced dataset.\nThis paper introduces an innovative approach for LC detection and\nclassification from CT images based on the DenseNet201 model. Our approach\ncomprises several advanced methods such as Focal Loss, data augmentation, and\nregularization to overcome the imbalanced data issue and overfitting challenge.\nThe findings show the appropriateness of the proposal, attaining a promising\nperformance of 98.95% accuracy.", "AI": {"tldr": "This paper proposes using DenseNet201 paired with advanced techniques such as Focal Loss, data augmentation, and regularization to achieve 98.95% accuracy in lung cancer detection and classification from CT images.", "motivation": "Lung cancer is a leading cause of global mortality and its diagnosis through CT images often lacks accuracy due to imbalanced and small datasets, resulting in significant false positives.", "method": "The paper employs the DenseNet201 model combined with Focal Loss, data augmentation, and regularization techniques to address issues of data imbalance and overfitting for lung cancer detection and classification.", "result": "The proposed method demonstrated an impressive performance, achieving 98.95% accuracy in LC detection and classification from CT images.", "conclusion": "Leveraging DenseNet201 with advanced methods significantly enhances the accuracy of lung cancer detection, offering a robust solution to challenges linked to dataset imbalance and false positive rates."}}
{"id": "2508.06490", "pdf": "https://arxiv.org/pdf/2508.06490", "abs": "https://arxiv.org/abs/2508.06490", "authors": ["Stanislas Ducotterd", "Michael Unser"], "title": "Multivariate Fields of Experts", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "comment": null, "summary": "We introduce the multivariate fields of experts, a new framework for the\nlearning of image priors. Our model generalizes existing fields of experts\nmethods by incorporating multivariate potential functions constructed via\nMoreau envelopes of the $\\ell_\\infty$-norm. We demonstrate the effectiveness of\nour proposal across a range of inverse problems that include image denoising,\ndeblurring, compressed-sensing magnetic-resonance imaging, and computed\ntomography. The proposed approach outperforms comparable univariate models and\nachieves performance close to that of deep-learning-based regularizers while\nbeing significantly faster, requiring fewer parameters, and being trained on\nsubstantially fewer data. In addition, our model retains a relatively high\nlevel of interpretability due to its structured design.", "AI": {"tldr": "The paper introduces multivariate fields of experts, a novel framework for learning image priors, excelling in solving inverse problems with better performance and interpretability.", "motivation": "To address the limitations of existing univariate fields of experts methods and provide more effective and interpretable image priors for inverse problems.", "method": "The authors propose incorporating multivariate potential functions, specifically Moreau envelopes of the $\\ell_\\infty$-norm, into the fields of experts framework.", "result": "The proposed multivariate approach outperforms univariate models, rivals deep-learning-based regularizers in quality, and is faster and more efficient in terms of parameters and training data.", "conclusion": "The multivariate fields of experts method provides an effective and interpretable alternative to deep-learning-based techniques for image priors in inverse problems, balancing performance and efficiency."}}
{"id": "2508.06325", "pdf": "https://arxiv.org/pdf/2508.06325", "abs": "https://arxiv.org/abs/2508.06325", "authors": ["Zelin Li", "Ruohan Zong", "Yifan Liu", "Ruichen Yao", "Yaokun Liu", "Yang Zhang", "Dong Wang"], "title": "Anti-Tamper Protection for Unauthorized Individual Image Generation", "categories": ["cs.CR", "cs.CV"], "comment": "22 pages ,22 figures, Paper has been accepted by ICCV'2025", "summary": "With the advancement of personalized image generation technologies, concerns\nabout forgery attacks that infringe on portrait rights and privacy are growing.\nTo address these concerns, protection perturbation algorithms have been\ndeveloped to disrupt forgery generation. However, the protection algorithms\nwould become ineffective when forgery attackers apply purification techniques\nto bypass the protection. To address this issue, we present a novel approach,\nAnti-Tamper Perturbation (ATP). ATP introduces a tamper-proof mechanism within\nthe perturbation. It consists of protection and authorization perturbations,\nwhere the protection perturbation defends against forgery attacks, while the\nauthorization perturbation detects purification-based tampering. Both\nprotection and authorization perturbations are applied in the frequency domain\nunder the guidance of a mask, ensuring that the protection perturbation does\nnot disrupt the authorization perturbation. This design also enables the\nauthorization perturbation to be distributed across all image pixels,\npreserving its sensitivity to purification-based tampering. ATP demonstrates\nits effectiveness in defending forgery attacks across various attack settings\nthrough extensive experiments, providing a robust solution for protecting\nindividuals' portrait rights and privacy. Our code is available at:\nhttps://github.com/Seeyn/Anti-Tamper-Perturbation .", "AI": {"tldr": "The paper introduces Anti-Tamper Perturbation (ATP), a perturbation algorithm designed to protect images from forgery attacks and detect tampering caused by purification methods.", "motivation": "Growing concerns about forgery attacks undermining portrait rights and privacy in the age of personalized image generation technologies.", "method": "ATP employs perturbations applied in the frequency domain, separating protection perturbation (to combat forgery) and authorization perturbation (to detect tampering). A mask ensures they function without interference.", "result": "ATP successfully defended against various forgery attack scenarios and remained effective against purification attempts in extensive experiments.", "conclusion": "The ATP method offers a robust and tamper-proof solution to protect portrait rights and privacy, addressing challenges posed by purification and forgery attacks."}}
{"id": "2508.06264", "pdf": "https://arxiv.org/pdf/2508.06264", "abs": "https://arxiv.org/abs/2508.06264", "authors": ["Randal E. Bryant"], "title": "Numerical Considerations in Weighted Model Counting", "categories": ["math.NA", "cs.AI", "cs.LO", "cs.NA"], "comment": null, "summary": "Weighted model counting computes the sum of the rational-valued weights\nassociated with the satisfying assignments for a Boolean formula, where the\nweight of an assignment is given by the product of the weights assigned to the\npositive and negated variables comprising the assignment. Weighted model\ncounting finds applications across a variety of domains including probabilistic\nreasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly)\nconverting the input formula into a form that enables arithmetic evaluation,\nusing multiplication for conjunctions and addition for disjunctions. Performing\nthis evaluation using floating-point arithmetic can yield inaccurate results,\nand it cannot quantify the level of precision achieved. Computing with rational\narithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to\nefficiently compute weighted model counts that are guaranteed to achieve a\nuser-specified precision. When all weights are nonnegative, we prove that the\nprecision loss of arithmetic evaluation using floating-point arithmetic can be\ntightly bounded. We show that supplementing a standard IEEE double-precision\nrepresentation with a separate 64-bit exponent, a format we call extended-range\ndouble (ERD), avoids the underflow and overflow issues commonly encountered in\nweighted model counting. For problems with mixed negative and positive weights,\nwe show that a combination of interval floating-point arithmetic and rational\narithmetic can achieve the twin goals of efficiency and guaranteed precision.\nFor our evaluations, we have devised especially challenging formulas and weight\nassignments, demonstrating the robustness of our approach.", "AI": {"tldr": "This paper addresses the challenges of weighted model counting and proposes methods to achieve guaranteed precision while maintaining efficiency.", "motivation": "Current methods for weighted model counting face challenges such as inaccurate results with floating-point arithmetic or high computational costs with rational arithmetic.", "method": "The paper introduces extended-range double (ERD) numeric representation for nonnegative weights and a combination of interval floating-point arithmetic and rational arithmetic for mixed weights.", "result": "The proposed techniques efficiently compute weighted model counts with user-specified precision, overcoming underflow and overflow issues.", "conclusion": "Using tailored numeric representations ensures robust weighted model counting with improved efficiency and guaranteed precision."}}
{"id": "2508.06343", "pdf": "https://arxiv.org/pdf/2508.06343", "abs": "https://arxiv.org/abs/2508.06343", "authors": ["V\u00e1clav Bla\u017eej", "Micha\u0142 D\u0119bski ad Zbigniew Lonc", "Marta Piecyk", "Pawe\u0142 Rz\u0105\u017cewski"], "title": "On Approximate MMS Allocations on Restricted Graph Classes", "categories": ["cs.DM", "cs.AI"], "comment": null, "summary": "We study the problem of fair division of a set of indivisible goods with\nconnectivity constraints. Specifically, we assume that the goods are\nrepresented as vertices of a connected graph, and sets of goods allocated to\nthe agents are connected subgraphs of this graph. We focus on the\nwidely-studied maximin share criterion of fairness. It has been shown that an\nallocation satisfying this criterion may not exist even without connectivity\nconstraints, i.e., if the graph of goods is complete. In view of this, it is\nnatural to seek approximate allocations that guarantee each agent a connected\nbundle of goods with value at least a constant fraction of the maximin share\nvalue to the agent. It is known that for some classes of graphs, such as\ncomplete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such\napproximate allocations indeed exist. However, it is an open problem whether\nthey exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of\napproximate allocations on restricted graph classes. In particular, we show\nthat such allocations exist for several well-studied classes, including block\ngraphs, cacti, complete multipartite graphs, and split graphs.", "AI": {"tldr": "The paper investigates fair division of indivisible goods represented as connected subgraphs within various graph classes, specifically under maximin share fairness. The authors establish approximate fairness guarantees for several graph classes, including block graphs, cacti, and split graphs.", "motivation": "To address the challenge of ensuring fair division of indivisible goods when connectivity constraints apply, particularly under the approximate maximin share fairness criterion, which has not been fully resolved for all graph classes.", "method": "The authors systematically analyze the properties of restricted classes of graphs, developing techniques to prove the existence of approximate allocations for those classes.", "result": "They demonstrate that approximate fair allocations satisfying a fraction of the maximin share value are possible for several graph classes, including block graphs, cacti, complete multipartite graphs, and split graphs.", "conclusion": "The findings advance the understanding of fair division under connectivity constraints, resolving open problems for specific graph classes and expanding the scope of guaranteed fairness."}}
{"id": "2508.06372", "pdf": "https://arxiv.org/pdf/2508.06372", "abs": "https://arxiv.org/abs/2508.06372", "authors": ["Han Yin", "Yafeng Chen", "Chong Deng", "Luyao Cheng", "Hui Wang", "Chao-Hong Tan", "Qian Chen", "Wen Wang", "Xiangang Li"], "title": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "The Speaker Diarization and Recognition (SDR) task aims to predict \"who spoke\nwhen and what\" within an audio clip, which is a crucial task in various\nreal-world multi-speaker scenarios such as meeting transcription and dialogue\nsystems. Existing SDR systems typically adopt a cascaded framework, combining\nmultiple modules such as speaker diarization (SD) and automatic speech\nrecognition (ASR). The cascaded systems suffer from several limitations, such\nas error propagation, difficulty in handling overlapping speech, and lack of\njoint optimization for exploring the synergy between SD and ASR tasks. To\naddress these limitations, we introduce SpeakerLM, a unified multimodal large\nlanguage model for SDR that jointly performs SD and ASR in an end-to-end\nmanner. Moreover, to facilitate diverse real-world scenarios, we incorporate a\nflexible speaker registration mechanism into SpeakerLM, enabling SDR under\ndifferent speaker registration settings. SpeakerLM is progressively developed\nwith a multi-stage training strategy on large-scale real data. Extensive\nexperiments show that SpeakerLM demonstrates strong data scaling capability and\ngeneralizability, outperforming state-of-the-art cascaded baselines on both\nin-domain and out-of-domain public SDR benchmarks. Furthermore, experimental\nresults show that the proposed speaker registration mechanism effectively\nensures robust SDR performance of SpeakerLM across diverse speaker registration\nconditions and varying numbers of registered speakers.", "AI": {"tldr": "SpeakerLM, a multimodal large language model, is introduced for end-to-end Speaker Diarization and Recognition (SDR), overcoming limitations of cascaded systems.", "motivation": "The motivation is to address key limitations in existing cascaded SDR systems, such as error propagation, challenges with overlapping speech, and the lack of joint optimization between Speaker Diarization (SD) and Automatic Speech Recognition (ASR).", "method": "The authors propose SpeakerLM, a unified multimodal large language model for SDR that uses a multi-stage training strategy on large-scale real data to jointly perform SD and ASR in an end-to-end manner. A flexible speaker registration mechanism is also incorporated.", "result": "SpeakerLM outperforms state-of-the-art cascaded baselines on both in-domain and out-of-domain SDR benchmarks, demonstrating strong data scaling ability and generalizability. The speaker registration mechanism enables robust performance under different settings.", "conclusion": "The paper concludes that SpeakerLM effectively mitigates the limitations of existing systems, significantly improving SDR tasks and demonstrating robustness across diverse scenarios."}}
{"id": "2508.06393", "pdf": "https://arxiv.org/pdf/2508.06393", "abs": "https://arxiv.org/abs/2508.06393", "authors": ["Md Asif Jalal", "Luca Remaggi", "Vasileios Moschopoulos", "Thanasis Kotsiopoulos", "Vandana Rajan", "Karthikeyan Saravanan", "Anastasis Drosou", "Junho Heo", "Hyuk Oh", "Seokyeong Jeong"], "title": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted to Interspeech 2025", "summary": "Traditional speech separation and speaker diarization approaches rely on\nprior knowledge of target speakers or a predetermined number of participants in\naudio signals. To address these limitations, recent advances focus on\ndeveloping enrollment-free methods capable of identifying targets without\nexplicit speaker labeling. This work introduces a new approach to train\nsimultaneous speech separation and diarization using automatic identification\nof target speaker embeddings, within mixtures. Our proposed model employs a\ndual-stage training pipeline designed to learn robust speaker representation\nfeatures that are resilient to background noise interference. Furthermore, we\npresent an overlapping spectral loss function specifically tailored for\nenhancing diarization accuracy during overlapped speech frames. Experimental\nresults show significant performance gains compared to the current SOTA\nbaseline, achieving 71% relative improvement in DER and 69% in cpWER.", "AI": {"tldr": "This paper proposes a method combining speech separation and speaker diarization without prior knowledge of target speakers, using automatic speaker embeddings.", "motivation": "Current systems for speech separation and diarization rely heavily on speaker enrollment or predefined participant limits, which limits flexibility and scalability.", "method": "The model uses a dual-stage training process to develop robust speaker embeddings and adds a spectral loss function to improve diarization in overlapping speech scenarios.", "result": "The model achieves significant performance gains compared to state-of-the-art baselines: 71% improvement in Diarization Error Rate (DER) and 69% improvement in word error rate in overlapped speech (cpWER).", "conclusion": "The introduced method effectively enhances speech separation and diarization accuracy, pushing boundaries for enrollment-free systems."}}
