{"id": "2509.09420", "pdf": "https://arxiv.org/pdf/2509.09420", "abs": "https://arxiv.org/abs/2509.09420", "authors": ["Haochen Huang", "Shuzhang Zhong", "Zhe Zhang", "Shuangchen Li", "Dimin Niu", "Hongzhong Zheng", "Runsheng Wang", "Meng Li"], "title": "HD-MoE: Hybrid and Dynamic Parallelism for Mixture-of-Expert LLMs with 3D Near-Memory Processing", "categories": ["cs.PF"], "comment": "9 pages, 15 figures, International Conference on Computer-Aided\n  Design (ICCAD) 2025", "summary": "Large Language Models (LLMs) with Mixture-of-Expert (MoE) architectures\nachieve superior model performance with reduced computation costs, but at the\ncost of high memory capacity and bandwidth requirements. Near-Memory Processing\n(NMP) accelerators that stack memory directly on the compute through hybrid\nbonding have demonstrated high bandwidth with high energy efficiency, becoming\na promising architecture for MoE models. However, as NMP accelerators comprise\ndistributed memory and computation, how to map the MoE computation directly\ndetermines the LLM inference efficiency. Existing parallel mapping strategies,\nincluding Tensor Parallelism (TP) and Expert Parallelism (EP), suffer from\neither high communication costs or unbalanced computation utilization, leading\nto inferior efficiency. The dynamic routing mechanism of MoE LLMs further\naggravates the efficiency challenges. Therefore, in this paper, we propose\nHD-MoE to automatically optimize the MoE parallel computation across an NMP\naccelerator. HD-MoE features an offline automatic hybrid parallel mapping\nalgorithm and an online dynamic scheduling strategy to reduce the communication\ncosts while maximizing the computation utilization. With extensive experimental\nresults, we demonstrate that HD-MoE achieves a speedup ranging from 1.1x to\n1.8x over TP, 1.1x to 1.5x over EP, and 1.0x to 1.4x over the baseline Hybrid\nTP-EP with Compute-Balanced parallelism strategies.", "AI": {"tldr": "This paper introduces HD-MoE, an optimization method for Mixture-of-Expert-enabled Large Language Models (LLMs) on Near-Memory Processing (NMP) accelerators, achieving up to 1.8x speedup over conventional parallel strategies.", "motivation": "The motivation is to address efficiency challenges in Mixture-of-Expert (MoE) LLMs on Near-Memory Processing (NMP) accelerators, particularly communication costs and computation imbalance in existing parallel mapping strategies like Tensor Parallelism (TP) and Expert Parallelism (EP).", "method": "The authors propose HD-MoE, combining an offline hybrid parallel mapping algorithm and an online dynamic scheduling strategy to balance and optimize parallel computation across distributed memory and compute in NMP architectures, specifically targeting communication cost reductions and improved utilization.", "result": "The experimental results show that HD-MoE provides a speedup ranging from 1.1x to 1.8x over TP, 1.1x to 1.5x over EP, and 1.0x to 1.4x compared to a baseline hybrid TP-EP strategy using Compute-Balanced parallelism.", "conclusion": "HD-MoE effectively optimizes MoE computation for NMP accelerators, leading to higher efficiency and speedups compared to traditional parallelism strategies."}}
{"id": "2509.08986", "pdf": "https://arxiv.org/pdf/2509.08986", "abs": "https://arxiv.org/abs/2509.08986", "authors": ["Junbo Jacob Lian"], "title": "Time-Fair Benchmarking for Metaheuristics: A Restart-Fair Protocol for Fixed-Time Comparisons", "categories": ["cs.NE", "cs.PF", "stat.CO"], "comment": null, "summary": "Numerous purportedly improved metaheuristics claim superior performance based\non equivalent function evaluations (FEs), yet often conceal additional\ncomputational burdens in more intensive iterations, preprocessing stages, or\nhyperparameter tuning. This paper posits that wall-clock time, rather than\nsolely FEs, should serve as the principal budgetary constraint for equitable\ncomparisons. We formalize a fixed-time, restart-fair benchmarking protocol\nwherein each algorithm is allotted an identical wall-clock time budget per\nproblem instance, permitting unrestricted utilization of restarts, early\ntermination criteria, and internal adaptive mechanisms. We advocate for the\nadoption of anytime performance curves, expected running time (ERT) metrics,\nand performance profiles that employ time as the cost measure, all aimed at\npredefined targets. Furthermore, we introduce a concise, reproducible checklist\nto standardize reporting practices and mitigate undisclosed computational\noverheads. This approach fosters more credible and practically relevant\nevaluations of metaheuristic algorithms.", "AI": {"tldr": "This paper critiques the reliance on function evaluations (FEs) to compare metaheuristics, proposing wall-clock time as a fairer measure. It formalizes a benchmarking protocol based on fixed-time budgets, providing fairer comparisons.", "motivation": "The motivation arises from the frequent use of FEs as performance indicators in metaheuristics, which often ignores additional computational overheads such as preprocessing or hyperparameter tuning. The authors identify a need for fairer, more practical evaluation metrics.", "method": "The authors propose a fixed-time, restart-fair benchmarking protocol where each algorithm gets an equal wall-clock time budget per problem. This method allows restarts, early termination, and internal adaptivity. Metrics like anytime performance curves, ERT, and time-based performance profiles are recommended.", "result": "A standardized checklist is introduced to make evaluations more transparent, reproducible, and informative. The approach aligns computational resource consumption more realistically with algorithm evaluation.", "conclusion": "Using wall-clock time as a constraint improves the fairness and credibility of metaheuristic comparisons, encouraging a shift to more practical and reproducible evaluation methods in the community."}}
{"id": "2509.09400", "pdf": "https://arxiv.org/pdf/2509.09400", "abs": "https://arxiv.org/abs/2509.09400", "authors": ["Valerio Besozzi", "Enrico Fiasco", "Marco Danelutto", "Patrizio Dazzi"], "title": "WebAssembly and Unikernels: A Comparative Study for Serverless at the Edge", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted at VHPC25", "summary": "Serverless computing at the edge requires lightweight execution environments\nto minimize cold start latency, especially in Urgent Edge Computing (UEC). This\npaper compares WebAssembly and unikernel-based MicroVMs for serverless\nworkloads. We present Limes, a WebAssembly runtime built on Wasmtime, and\nevaluate it against the Firecracker-based environment used in SPARE. Results\nshow that WebAssembly offers lower cold start times for lightweight functions\nbut suffers with complex workloads, while Firecracker provides higher, but\nstable, cold starts and better execution performance, particularly for\nI/O-heavy tasks.", "AI": {"tldr": "This paper compares WebAssembly and unikernel-based MicroVMs for serverless edge computing workloads, introducing Limes (a WebAssembly runtime) and analyzing their performance differences.", "motivation": "The motivation is to address the need for lightweight execution environments with minimal cold start latency in Urgent Edge Computing scenarios.", "method": "The paper develops Limes, a WebAssembly runtime based on Wasmtime, and evaluates it against Firecracker-based MicroVMs (SPARE) in serverless workloads.", "result": "WebAssembly provides lower cold start latency for lightweight tasks but struggles with complex workloads, while Firecracker achieves steady cold starts and performs better for I/O-heavy tasks.", "conclusion": "Both WebAssembly and Firecracker have distinct strengths, suggesting a tradeoff between startup latency and workload complexity/execution performance in edge computing scenarios."}}
{"id": "2509.09178", "pdf": "https://arxiv.org/pdf/2509.09178", "abs": "https://arxiv.org/abs/2509.09178", "authors": ["Ayan Biswas", "Jimmy Jin"], "title": "Implementation of a 8-bit Wallace Tree Multiplier", "categories": ["cs.AR", "cs.SY", "eess.SY"], "comment": null, "summary": "Wallace tree multipliers are a parallel digital multiplier architecture\ndesigned to minimize the worst-case time complexity of the circuit depth\nrelative to the input size [1]. In particular, it seeks to perform long\nmultiplication in the binary sense, reducing as many partial products per stage\nas possible through full and half adders circuits, achieving O(log(n)) where n\n= bit length of input. This paper provides an overview of the design, progress\nand methodology in the final project of ECE 55900, consisting of the schematic\nand layout of a Wallace tree 8-bit input multiplier on the gpdk45 technology in\nCadence Virtuoso, as well as any design attempts prior to the final product.\nThis also includes our endeavors in designing the final MAC (Multiply\nAccumulate) unit with undefined targets, which we chose to implement as a 16\nbit combinational multiply-add.", "AI": {"tldr": "The paper focuses on the design and implementation of an 8-bit Wallace tree multiplier and a 16-bit combinational MAC unit using gpdk45 technology.", "motivation": "To optimize digital multiplication by minimizing circuit depth complexity and achieving efficient hardware design with Wallace tree multipliers.", "method": "Implemented an 8-bit Wallace tree multiplier on gpdk45 technology via Cadence Virtuoso, including schematic and layout design, followed by a 16-bit MAC unit with combinational multiply-add functionality.", "result": "Successfully developed schematic and layout designs for both the 8-bit Wallace tree multiplier and the 16-bit MAC unit, achieving intended performance goals.", "conclusion": "The Wallace tree multiplier architecture confirms its efficiency, and the use of Cadence Virtuoso and gpdk45 technology enabled systematic design and realization of advanced digital multipliers."}}
{"id": "2509.08969", "pdf": "https://arxiv.org/pdf/2509.08969", "abs": "https://arxiv.org/abs/2509.08969", "authors": ["Nima Karimian Kakolaki"], "title": "A Comparative Analysis of Identifier Schemes: UUIDv4, UUIDv7, and ULID for Distributed Systems", "categories": ["cs.DC", "cs.DB"], "comment": null, "summary": "Distributed systems require robust, scalable identifier schemes to ensure\ndata uniqueness and efficient indexing across multiple nodes. This paper\npresents a comprehensive analysis of the evolution of distributed identifiers,\ncomparing traditional auto-increment keys with UUIDv4, UUIDv7, and ULIDs. We\ncombine mathematical calculation of collision probabilities with empirical\nexperiments measuring generation speed and network transmission overhead in a\nsimulated distributed environment. Results demonstrate that ULIDs significantly\noutperform UUIDv4 and UUIDv7, reducing network overhead by 83.7% and increasing\ngeneration speed by 97.32%. statistical analysis further shows ULIDs offer a\n98.42% lower collision risk compared to UUIDv7, while maintaining negligible\ncollision probabilities even at high generation rates. These findings highlight\nULIDs as an optimal choice for high-performance distributed systems, providing\nefficient, time-ordered, and lexicographically sortable identifiers suitable\nfor scalable applications. All source code, datasets, and analysis scripts\nutilized in this research are publicly available in our dedicated repository at\nhttps://github.com/nimakarimiank/uids-comparison. This repository contains\ncomprehensive documentation of the experimental setup, including configuration\nfiles for the distributed environment, producer and consumer implementations,\nand message broker integration. Additionally, it provides the data scripts and\ndatasets. Researchers and practitioners are encouraged to explore the\nrepository for full reproducibility of the experiments and to facilitate\nfurther investigation or extension of the presented work.", "AI": {"tldr": "This paper analyzes distributed identifiers, showing ULIDs outperform UUIDv4 and UUIDv7 in network overhead, speed, and collision risk, recommending ULIDs for scalable applications.", "motivation": "The paper aims to identify scalable and efficient identifier schemes for robust distributed systems, ensuring data uniqueness and high performance.", "method": "The study compares identifier schemes (auto-increment keys, UUIDv4, UUIDv7, ULIDs) using collision probabilities, generation speed, and network overhead through mathematical calculations and simulated experiments.", "result": "ULIDs reduce network overhead by 83.7%, increase generation speed by 97.32%, and lower collision risks by 98.42% compared to UUIDv7. They maintain negligible collision probabilities even at high rates.", "conclusion": "ULIDs are optimal for high-performance distributed systems due to their efficiency, time-ordering, and scalability. The research promotes ULIDs for scalable applications and provides reproducible experiments via a public repository."}}
{"id": "2509.09019", "pdf": "https://arxiv.org/pdf/2509.09019", "abs": "https://arxiv.org/abs/2509.09019", "authors": ["Mohit Tekriwal", "John Sarracino"], "title": "Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs", "categories": ["cs.PL"], "comment": null, "summary": "Scientific computing programs often undergo aggressive compiler optimization\nto achieve high performance and efficient resource utilization. While\nperformance is critical, we also need to ensure that these optimizations are\ncorrect. In this paper, we focus on a specific class of optimizations,\nfloating-point optimizations, notably due to fast math, at the LLVM IR level.\nWe present a preliminary work, which leverages the Verified LLVM framework in\nthe Rocq theorem prover, to prove the correctness of Fused-Multiply-Add (FMA)\noptimization for a basic block implementing the arithmetic expression $a * b +\nc$ . We then propose ways to extend this preliminary results by adding more\nprogram features and fast math floating-point optimizations.", "AI": {"tldr": "The paper investigates the correctness of floating-point optimizations in LLVM IR, focusing on Fused-Multiply-Add. Preliminary work employs formal verification with Rocq. Future work includes extending features and optimizations.", "motivation": "Verify the correctness of aggressive compiler optimizations, specifically floating-point optimizations at the LLVM IR level, ensuring reliability and performance in scientific computing.", "method": "Used the Verified LLVM framework with the Rocq theorem prover to formally prove the correctness of Fused-Multiply-Add (FMA) optimizations in LLVM IR for arithmetic expressions.", "result": "Completed the formal correctness proof for FMA optimization on $a * b + c$ and suggested avenues for extending this work to additional optimizations and program features.", "conclusion": "Preliminary validation demonstrates the potential of formal methods like Rocq in verifying the correctness of floating-point optimizations. Future directions aim to expand the scope of verification to include more optimizations and program features."}}
{"id": "2509.08834", "pdf": "https://arxiv.org/pdf/2509.08834", "abs": "https://arxiv.org/abs/2509.08834", "authors": ["John T. Rickard", "William A. Dembski", "James Rickards"], "title": "An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts", "categories": ["cs.AI", "physics.comp-ph", "physics.data-an", "q-fin.CP"], "comment": "13 pages, 12 figures", "summary": "Bayesian inference is widely used in many different fields to test hypotheses\nagainst observations. In most such applications, an assumption is made of\nprecise input values to produce a precise output value. However, this is\nunrealistic for real-world applications. Often the best available information\nfrom subject matter experts (SMEs) in a given field is interval range estimates\nof the input probabilities involved in Bayes Theorem. This paper provides two\nkey contributions to extend Bayes Theorem to an interval type-2 (IT2) version.\nFirst, we develop an IT2 version of Bayes Theorem that uses a novel and\nconservative method to avoid potential inconsistencies in the input IT2 MFs\nthat otherwise might produce invalid output results. We then describe a novel\nand flexible algorithm for encoding SME-provided intervals into IT2 fuzzy\nmembership functions (MFs), which we can use to specify the input probabilities\nin Bayes Theorem. Our algorithm generalizes and extends previous work on this\nproblem that primarily addressed the encoding of intervals into word MFs for\nComputing with Words applications.", "AI": {"tldr": "The paper extends Bayesian inference to handle interval type-2 fuzzy inputs using novel methods for consistent interpretation and encoding.", "motivation": "Standard Bayesian inference assumes precise input values, which is unrealistic in many real-world scenarios where experts often provide interval estimates.", "method": "The authors develop an interval type-2 version of Bayes Theorem and introduce an algorithm for encoding interval estimates into type-2 fuzzy membership functions.", "result": "The approach provides a framework for incorporating expert-provided interval input probabilities into Bayesian inference while addressing potential inconsistencies.", "conclusion": "The paper improves the applicability of Bayesian methods to real-world problems by integrating interval estimates as fuzzy inputs, enhancing reliability and flexibility."}}
{"id": "2509.08831", "pdf": "https://arxiv.org/pdf/2509.08831", "abs": "https://arxiv.org/abs/2509.08831", "authors": ["Doai Ngo", "Mingxuan Sun", "Zhengji Zhang", "Ashwin G Ramayya", "Mark Schnitzer", "Zhe Zhao"], "title": "Path to Intelligence: Measuring Similarity between Human Brain and Large Language Model Beyond Language Task", "categories": ["q-bio.NC"], "comment": null, "summary": "Large language models (LLMs) have demonstrated human-like abilities in\nlanguage-based tasks. While language is a defining feature of human\nintelligence, it emerges from more fundamental neurophysical processes rather\nthan constituting the basis of intelligence itself. In this work, we study the\nsimilarity between LLM internal states and human brain activity in a\nsensory-motor task rooted in anticipatory and visuospatial behavior. These\nabilities are essential for cognitive performance that constitute human\nintelligence. We translate the sensory-motor task into natural language in\norder to replicate the process for LLMs. We extract hidden states from\npre-trained LLMs at key time steps and compare them to human intracranial EEG\nsignals. Our results reveal that LLM-derived reactions can be linearly mapped\nonto human neural activity. These findings suggest that LLMs, with a simple\nnatural language translation to make them understand temporal-relevant tasks,\ncan approximate human neurophysical behavior in experiments involving sensory\nstimulants. In all, our contribution is two-fold: (1) We demonstrate similarity\nbetween LLM and human brain activity beyond language-based tasks. (2) We\ndemonstrate that with such similarity, LLMs could help us understand human\nbrains by enabling us to study topics in neuroscience that are otherwise\nchallenging to tackle.", "AI": {"tldr": "This paper compares the internal states of large language models (LLMs) with human brain activity during a sensory-motor task, revealing similarities beyond language-based tasks.", "motivation": "The motivation is to investigate whether the similarity between LLMs and human brain activity extends to non-language tasks, and to explore if LLMs can aid in understanding human brain functions.", "method": "The authors translated a sensory-motor task into natural language for LLMs, extracted their hidden states, and compared them with intracranial EEG signals of humans performing the same task.", "result": "The study found that LLM-derived reactions can be linearly mapped to human neural activity, demonstrating the resemblance between LLMs and human brain behavior in sensory tasks.", "conclusion": "LLMs show potential in approximating human neurophysical behavior, enabling neuroscience studies of complex phenomena and deepening our understanding of human intelligence beyond language."}}
{"id": "2509.08843", "pdf": "https://arxiv.org/pdf/2509.08843", "abs": "https://arxiv.org/abs/2509.08843", "authors": ["Sidney Shapiro"], "title": "Pattern-Based File and Data Access with Python Glob: A Comprehensive Guide for Computational Research", "categories": ["cs.SE"], "comment": null, "summary": "Pattern-based file access is a fundamental but often under-documented aspect\nof computational research. The Python glob module provides a simple yet\npowerful way to search, filter, and ingest files using wildcard patterns,\nenabling scalable workflows across disciplines. This paper introduces glob as a\nversatile tool for data science, business analytics, and artificial\nintelligence applications. We demonstrate use cases including large-scale data\ningestion, organizational data analysis, AI dataset construction, and\nreproducible research practices. Through concrete Python examples with widely\nused libraries such as pandas,scikit-learn, and matplotlib, we show how glob\nfacilitates efficient file traversal and integration with analytical pipelines.\nBy situating glob within the broader context of reproducible research and data\nengineering, we highlight its role as a methodological building block. Our goal\nis to provide researchers and practitioners with a concise reference that\nbridges foundational concepts and applied practice, making glob a default\ncitation for file pattern matching in Python-based research workflows.", "AI": {"tldr": "This paper underscores the utility of the Python glob module for file pattern matching across various research areas and workflows, promoting its use in scalable data processing and reproducible practices.", "motivation": "The authors aim to address the lack of documentation and methodological emphasis on pattern-based file access in computational research, particularly in workflows requiring scalable and reproducible approaches.", "method": "The paper incorporates practical Python examples using libraries like pandas, scikit-learn, and matplotlib to illustrate file ingestion, analysis, and integration into analytical pipelines via the glob module.", "result": "Glob is showcased as a versatile tool facilitating tasks like large-scale data ingestion, AI dataset construction, organizational data analysis, and enhancing reproducible research practices.", "conclusion": "Glob is positioned as an essential and methodological building block for Python-based research workflows, bridging foundational concepts and applied practice."}}
{"id": "2509.08903", "pdf": "https://arxiv.org/pdf/2509.08903", "abs": "https://arxiv.org/abs/2509.08903", "authors": ["Alex Clay", "Ernesto Jim\u00e9nez-Ruiz", "Pranava Madhyastha"], "title": "Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC", "categories": ["cs.CL"], "comment": "8 pages, 1 figure, accepted to the ISWC 2025 LM-KBC Workshop", "summary": "RAG and fine-tuning are prevalent strategies for improving the quality of LLM\noutputs. However, in constrained situations, such as that of the 2025 LM-KBC\nchallenge, such techniques are restricted. In this work we investigate three\nfacets of the triple completion task: generation, quality assurance, and LLM\nresponse parsing. Our work finds that in this constrained setting: additional\ninformation improves generation quality, LLMs can be effective at filtering\npoor quality triples, and the tradeoff between flexibility and consistency with\nLLM response parsing is setting dependent.", "AI": {"tldr": "This paper analyzes how constrained conditions, like the 2025 LM-KBC challenge, affect triple completion tasks, focusing on generation, quality assurance, and LLM response parsing.", "motivation": "Investigate the efficacy of LLMs in constrained scenarios, specifically for the triple completion task, without relying on RAG or fine-tuning.", "method": "Study three facets: triple generation quality, using LLMs for quality assurance, and parsing responses from LLMs under constraints.", "result": "Found that added information improves generation, LLMs help filter low-quality triples, and achieving flexibility or consistency depends on the parsing setting.", "conclusion": "While constraints limit certain techniques, strategic information use and careful tradeoff management can still lead to effective results."}}
{"id": "2509.08859", "pdf": "https://arxiv.org/pdf/2509.08859", "abs": "https://arxiv.org/abs/2509.08859", "authors": ["Vincenzo Suriani", "Daniele Affinita", "Domenico D. Bloisi", "Daniele Nardi"], "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication", "categories": ["cs.RO", "cs.AI"], "comment": "The 19th International Conference on Intelligent Autonomous Systems\n  (IAS 19), 2025, Genoa", "summary": "Coordinating a fully distributed multi-agent system (MAS) can be challenging\nwhen the communication channel has very limited capabilities in terms of\nsending rate and packet payload. When the MAS has to deal with active obstacles\nin a highly partially observable environment, the communication channel\nacquires considerable relevance. In this paper, we present an approach to deal\nwith task assignments in extremely active scenarios, where tasks need to be\nfrequently reallocated among the agents participating in the coordination\nprocess. Inspired by market-based task assignments, we introduce a novel\ndistributed coordination method to orchestrate autonomous agents' actions\nefficiently in low communication scenarios. In particular, our algorithm takes\ninto account asymmetric obstacles. While in the real world, the majority of\nobstacles are asymmetric, they are usually treated as symmetric ones, thus\nlimiting the applicability of existing methods. To summarize, the presented\narchitecture is designed to tackle scenarios where the obstacles are active and\nasymmetric, the communication channel is poor and the environment is partially\nobservable. Our approach has been validated in simulation and in the real\nworld, using a team of NAO robots during official RoboCup competitions.\nExperimental results show a notable reduction in task overlaps in limited\ncommunication settings, with a decrease of 52% in the most frequent reallocated\ntask.", "AI": {"tldr": "The paper introduces a distributed coordination method for multi-agent systems operating in partially observable environments with poor communication and asymmetric, active obstacles, validated through RoboCup experiments.", "motivation": "The paper addresses the challenge of coordinating multi-agent systems with low communication capabilities and active asymmetric obstacles, issues that limit the applicability of current methods.", "method": "The authors propose a novel distributed coordination method inspired by market-based task assignments, specifically designed for scenarios with poor communication, asymmetric obstacles, and dynamic task reallocation.", "result": "Experimental results demonstrate a significant reduction in task overlaps, achieving a 52% decrease in the most frequent reallocated task, both in simulated and real-world RoboCup environments.", "conclusion": "The proposed architecture is effective for coordinating autonomous agents in constrained environments, offering improved task allocation efficiency in practical RoboCup scenarios."}}
{"id": "2509.09078", "pdf": "https://arxiv.org/pdf/2509.09078", "abs": "https://arxiv.org/abs/2509.09078", "authors": ["Teresa Portone", "Bert Debusschere", "Samantha Yang", "Emiliano Islas-Quinones", "T. Patrick Xiao"], "title": "Scalable extensions to given-data Sobol' index estimators", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO"], "comment": null, "summary": "Given-data methods for variance-based sensitivity analysis have significantly\nadvanced the feasibility of Sobol' index computation for computationally\nexpensive models and models with many inputs. However, the limitations of\nexisting methods still preclude their application to models with an extremely\nlarge number of inputs. In this work, we present practical extensions to the\nexisting given-data Sobol' index method, which allow variance-based sensitivity\nanalysis to be efficiently performed on large models such as neural networks,\nwhich have $>10^4$ parameterizable inputs. For models of this size, holding all\ninput-output evaluations simultaneously in memory -- as required by existing\nmethods -- can quickly become impractical. These extensions also support\nnonstandard input distributions with many repeated values, which are not\namenable to equiprobable partitions employed by existing given-data methods.\n  Our extensions include a general definition of the given-data Sobol' index\nestimator with arbitrary partition, a streaming algorithm to process\ninput-output samples in batches, and a heuristic to filter out small indices\nthat are indistinguishable from zero indices due to statistical noise. We show\nthat the equiprobable partition employed in existing given-data methods can\nintroduce significant bias into Sobol' index estimates even at large sample\nsizes and provide numerical analyses that demonstrate why this can occur. We\nalso show that our streaming algorithm can achieve comparable accuracy and\nruntimes with lower memory requirements, relative to current methods which\nprocess all samples at once. We demonstrate our novel developments on two\napplication problems in neural network modeling.", "AI": {"tldr": "This paper presents extensions to existing Sobol' index methods, allowing for efficient sensitivity analysis of large models with many inputs.", "motivation": "Current methods for Sobol' index computation are limited for models with extremely large numbers of inputs due to memory and distribution issues.", "method": "The authors propose a generalized Sobol' index framework with arbitrary partitions, a memory-efficient streaming algorithm, and a heuristic for filtering statistically insignificant indices.", "result": "Their approach reduces memory requirements while maintaining comparable accuracy and runtime, and addresses biases from equiprobable partitions in previous methods.", "conclusion": "The proposed enhancements make Sobol' index computation feasible for large-scale models like neural networks, enabling efficient sensitivity analysis in these contexts."}}
{"id": "2509.08846", "pdf": "https://arxiv.org/pdf/2509.08846", "abs": "https://arxiv.org/abs/2509.08846", "authors": ["H. Martin Gillis", "Isaac Xu", "Thomas Trappenberg"], "title": "Uncertainty Estimation using Variance-Gated Distributions", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Evaluation of per-sample uncertainty quantification from neural networks is\nessential for decision-making involving high-risk applications. A common\napproach is to use the predictive distribution from Bayesian or approximation\nmodels and decompose the corresponding predictive uncertainty into epistemic\n(model-related) and aleatoric (data-related) components. However, additive\ndecomposition has recently been questioned. In this work, we propose an\nintuitive framework for uncertainty estimation and decomposition based on the\nsignal-to-noise ratio of class probability distributions across different model\npredictions. We introduce a variance-gated measure that scales predictions by a\nconfidence factor derived from ensembles. We use this measure to discuss the\nexistence of a collapse in the diversity of committee machines.", "AI": {"tldr": "The paper proposes a new framework for uncertainty estimation and decomposition in neural networks using the signal-to-noise ratio from class probability distributions and introduces a variance-gated measure for scaling predictions.", "motivation": "Accurately quantifying per-sample uncertainty is critical in high-risk applications. Existing methods use predictive uncertainty decomposition but face criticism regarding additive decomposition methods, calling for a more reliable and intuitive framework.", "method": "The authors suggest using the signal-to-noise ratio of class probability distributions across model predictions and propose a variance-gated measure that modifies predictions by factoring in confidence from ensembles.", "result": "The variance-gated approach highlights challenges, specifically a potential collapse in the diversity of ensembles or committee machines.", "conclusion": "The proposed signal-to-noise ratio-based framework and the variance-gated measure provide a fresh perspective on uncertainty decomposition and reveal problems with homogeneous committee diversity."}}
{"id": "2509.08897", "pdf": "https://arxiv.org/pdf/2509.08897", "abs": "https://arxiv.org/abs/2509.08897", "authors": ["Davide Caffagni", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "title": "Recurrence Meets Transformers for Universal Multimodal Retrieval", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "With the rapid advancement of multimodal retrieval and its application in\nLLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.\nExisting methods predominantly rely on task-specific fine-tuning of\nvision-language models and are limited to single-modality queries or documents.\nIn this paper, we propose ReT-2, a unified retrieval model that supports\nmultimodal queries, composed of both images and text, and searches across\nmultimodal document collections where text and images coexist. ReT-2 leverages\nmulti-layer representations and a recurrent Transformer architecture with\nLSTM-inspired gating mechanisms to dynamically integrate information across\nlayers and modalities, capturing fine-grained visual and textual details. We\nevaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different\nretrieval configurations. Results demonstrate that ReT-2 consistently achieves\nstate-of-the-art performance across diverse settings, while offering faster\ninference and reduced memory usage compared to prior approaches. When\nintegrated into retrieval-augmented generation pipelines, ReT-2 also improves\ndownstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source\ncode and trained models are publicly available at:\nhttps://github.com/aimagelab/ReT-2", "AI": {"tldr": "ReT-2 is a unified multimodal retrieval model supporting queries with both text and images, and achieves state-of-the-art performance while improving computational efficiency.", "motivation": "The paper aims to address the limitations of existing retrieval methods which focus on task-specific fine-tuning and are restricted to single-modality queries or documents.", "method": "The approach relies on multi-layer representations and a recurrent Transformer with LSTM-inspired gating mechanisms, seamlessly integrating multi-modal data across layers.", "result": "ReT-2 demonstrates state-of-the-art performance on M2KR, M-BEIR, Encyclopedic-VQA, and InfoSeek benchmarks, while being faster and memory-efficient compared to existing methods.", "conclusion": "ReT-2 establishes itself as a robust and efficient choice for complex multimodal retrieval tasks, enhancing downstream applications and advancing the field with publicly available resources."}}
{"id": "2509.09529", "pdf": "https://arxiv.org/pdf/2509.09529", "abs": "https://arxiv.org/abs/2509.09529", "authors": ["Shangqing Shi", "Luoxiao Zhang", "Yuchen Yin", "Xiong Yang", "Hoileong Lee"], "title": "A modified RIME algorithm with covariance learning and diversity enhancement for numerical optimization", "categories": ["cs.NE", "cs.AI", "cs.CE"], "comment": "This is the author's preprint of the article published in Cluster\n  Computing (Springer): Shi, S., Zhang, L., Yin, Y. et al. A modified RIME\n  algorithm with covariance learning and diversity enhancement for numerical\n  optimization. Cluster Comput 28, 658 (2025). The final authenticated version\n  is available online at SpringerLink", "summary": "Metaheuristics are widely applied for their ability to provide more efficient\nsolutions. The RIME algorithm is a recently proposed physical-based\nmetaheuristic algorithm with certain advantages. However, it suffers from rapid\nloss of population diversity during optimization and is prone to fall into\nlocal optima, leading to unbalanced exploitation and exploration. To address\nthe shortcomings of RIME, this paper proposes a modified RIME with covariance\nlearning and diversity enhancement (MRIME-CD). The algorithm applies three\nstrategies to improve the optimization capability. First, a covariance learning\nstrategy is introduced in the soft-rime search stage to increase the population\ndiversity and balance the over-exploitation ability of RIME through the\nbootstrapping effect of dominant populations. Second, in order to moderate the\ntendency of RIME population to approach the optimal individual in the early\nsearch stage, an average bootstrapping strategy is introduced into the\nhard-rime puncture mechanism, which guides the population search through the\nweighted position of the dominant populations, thus enhancing the global search\nability of RIME in the early stage. Finally, a new stagnation indicator is\nproposed, and a stochastic covariance learning strategy is used to update the\nstagnant individuals in the population when the algorithm gets stagnant, thus\nenhancing the ability to jump out of the local optimal solution. The proposed\nMRIME-CD algorithm is subjected to a series of validations on the CEC2017 test\nset, the CEC2022 test set, and the experimental results are analyzed using the\nFriedman test, the Wilcoxon rank sum test, and the Kruskal Wallis test. The\nresults show that MRIME-CD can effectively improve the performance of basic\nRIME and has obvious superiorities in terms of solution accuracy, convergence\nspeed and stability.", "AI": {"tldr": "A modified metaheuristic algorithm, MRIME-CD, addresses limitations of RIME by enhancing population diversity and optimizing strategies. It shows superior performance in improving solution accuracy, speed, and stability.", "motivation": "The paper aims to overcome the weaknesses of the RIME algorithm, namely rapid loss of population diversity and tendency to get trapped in local optima, affecting its exploration and exploitation balance.", "method": "Three strategies are proposed: covariance learning to improve diversity, average bootstrapping for balanced exploration in early stages, and a stochastic covariance learning strategy to handle stagnation and escape local optima.", "result": "The proposed MRIME-CD algorithm demonstrated superior optimization performance with higher solution accuracy, faster convergence, and improved stability on standardized test sets validated by statistical methods.", "conclusion": "MRIME-CD effectively addresses RIME's weaknesses and achieves improved optimization capabilities, showing potential for broader applications."}}
{"id": "2509.09505", "pdf": "https://arxiv.org/pdf/2509.09505", "abs": "https://arxiv.org/abs/2509.09505", "authors": ["Haoran Wu", "Can Xiao", "Jiayi Nie", "Xuan Guo", "Binglei Lou", "Jeffrey T. H. Wong", "Zhiwen Mo", "Cheng Zhang", "Przemyslaw Forys", "Wayne Luk", "Hongxiang Fan", "Jianyi Cheng", "Timothy M. Jones", "Rika Antonova", "Robert Mullins", "Aaron Zhao"], "title": "Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference", "categories": ["cs.AR"], "comment": null, "summary": "LLMs now form the backbone of AI agents for a diverse array of applications,\nincluding tool use, command-line agents, and web or computer use agents. These\nagentic LLM inference tasks are fundamentally different from chatbot-focused\ninference -- they often have much larger context lengths to capture complex,\nprolonged inputs, such as entire webpage DOMs or complicated tool call\ntrajectories. This, in turn, generates significant off-chip memory traffic for\nthe underlying hardware at the inference stage and causes the workload to be\nconstrained by two memory walls, namely the bandwidth and capacity memory\nwalls, preventing the on-chip compute units from achieving high utilization.\n  In this paper, we introduce PLENA, a hardware-software co-designed system\nthat applies three core optimization pathways to tackle these challenges. PLENA\nincludes an efficient hardware implementation of compute and memory units\nsupporting an asymmetric quantization scheme. PLENA also features a novel\nflattened systolic array architecture that has native support for\nFlashAttention to tackle these memory walls in the scenario of inference\nserving for long-context LLMs. Additionally, PLENA is developed with a complete\nstack, including a custom ISA, a compiler, a cycle-emulated simulator, and an\nautomated design space exploration flow. The simulated results show that PLENA\nachieves up to 8.5x higher utilization than existing accelerators, and delivers\n2.24x higher throughput than the A100 GPU and 3.85x higher throughput than the\nTPU v6e, under the same multiplier count and memory settings. The full PLENA\nsystem will also be open-sourced.", "AI": {"tldr": "The paper introduces PLENA, a hardware-software co-designed system, addressing memory-related challenges in inference for long-context Large Language Models (LLMs), achieving significantly higher throughput and utilization over existing accelerators.", "motivation": "The use of LLMs in agentic tasks faces challenges due to their large context lengths, causing substantial off-chip memory traffic and inhibiting compute utilization due to bandwidth and capacity memory walls.", "method": "PLENA applies three optimization pathways: efficient hardware with asymmetric quantization, a flattened systolic array architecture supporting FlashAttention, and a complete development stack (custom ISA, compiler, emulator, and design exploration).", "result": "PLENA delivers up to 8.5x higher utilization than current accelerators and achieves up to 2.24x and 3.85x higher throughput compared to the A100 GPU and TPU v6e respectively, under equivalent resource settings.", "conclusion": "PLENA effectively tackles the memory bottlenecks associated with long-context LLM inference on current hardware, providing substantial performance gains, and its open-source design promises broader accessibility and development."}}
{"id": "2509.09058", "pdf": "https://arxiv.org/pdf/2509.09058", "abs": "https://arxiv.org/abs/2509.09058", "authors": ["Ajay Kumar", "Praveen Rao", "Peter Sanders"], "title": "Optimizing the Variant Calling Pipeline Execution on Human Genomes Using GPU-Enabled Machines", "categories": ["cs.DC"], "comment": "To appear in 14th International Workshop on Parallel and AI-based\n  Bioinformatics and Biomedicine (ParBio), Philadelphia, 2025", "summary": "Variant calling is the first step in analyzing a human genome and aims to\ndetect variants in an individual's genome compared to a reference genome. Due\nto the computationally-intensive nature of variant calling, genomic data are\nincreasingly processed in cloud environments as large amounts of compute and\nstorage resources can be acquired with the pay-as-you-go pricing model. In this\npaper, we address the problem of efficiently executing a variant calling\npipeline for a workload of human genomes on graphics processing unit\n(GPU)-enabled machines. We propose a novel machine learning (ML)-based approach\nfor optimizing the workload execution to minimize the total execution time. Our\napproach encompasses two key techniques: The first technique employs ML to\npredict the execution times of different stages in a variant calling pipeline\nbased on the characteristics of a genome sequence. Using the predicted times,\nthe second technique generates optimal execution plans for the machines by\ndrawing inspiration from the flexible job shop scheduling problem. The plans\nare executed via careful synchronization across different machines. We\nevaluated our approach on a workload of publicly available genome sequences\nusing a testbed with different types of GPU hardware. We observed that our\napproach was effective in predicting the execution times of variant calling\npipeline stages using ML on features such as sequence size, read quality,\npercentage of duplicate reads, and average read length. In addition, our\napproach achieved 2X speedup (on an average) over a greedy approach that also\nused ML for predicting the execution times on the tested workload of sequences.\nFinally, our approach achieved 1.6X speedup (on an average) over a dynamic\napproach that executed the workload based on availability of resources without\nusing any ML-based time predictions.", "AI": {"tldr": "The paper introduces a machine learning-based method to optimize the execution time of variant calling for human genomes in GPU-enabled cloud environments, achieving significant speedups compared to other approaches.", "motivation": "Variant calling is computationally intensive, requiring robust solutions for efficient analysis of genomic data in cloud settings due to scalability and cost-efficiency concerns.", "method": "The method uses machine learning to predict execution times for variant calling pipeline stages and applies job shop scheduling techniques to optimize workload distribution across machines, ensuring synchronization.", "result": "The ML-based execution time prediction was effective, and the proposed method achieved a 2X speedup over a greedy approach and 1.6X speedup over a dynamic scheduling approach.", "conclusion": "The approach demonstrates substantial performance improvements in variant calling pipelines by leveraging machine learning and optimized scheduling in GPU-enabled environments."}}
{"id": "2509.09059", "pdf": "https://arxiv.org/pdf/2509.09059", "abs": "https://arxiv.org/abs/2509.09059", "authors": ["Paulette Koronkevich", "William J. Bowman"], "title": "Dependent-Type-Preserving Memory Allocation", "categories": ["cs.PL"], "comment": "Submitted and received second place at the Student Research\n  Competition at Principles of Programming Languages 2022", "summary": "Dependently typed programming languages such as Coq, Agda, Idris, and F*,\nallow programmers to write detailed specifications of their programs and prove\ntheir programs meet these specifications. However, these specifications can be\nviolated during compilation since they are erased after type checking. External\nprograms linked with the compiled program can violate the specifications of the\noriginal program and change the behavior of the compiled program -- even when\ncompiled with a verified compiler. For example, since Coq does not allow\nexplicitly allocating memory, a programmer might link their Coq program with a\nC program that can allocate memory. Even if the Coq program is compiled with a\nverified compiler, the external C program can still violate the memory-safe\nspecification of the Coq program by providing an uninitialized pointer to\nmemory. This error could be ruled out by type checking in a language expressive\nenough to indicate whether memory is initialized versus uninitialized. Linking\nwith a program with an uninitialized pointer could be considered ill-typed, and\nour linking process could prevent linking with ill-typed programs. To\nfacilitate type checking during linking, we can use type-preserving\ncompilation, which preserves the types through the compilation process. In this\nongoing work, we develop a typed intermediate language that supports dependent\nmemory allocation, as well as a dependent-type-preserving compiler pass for\nmemory allocation.", "AI": {"tldr": "The paper addresses issues of specification violations in dependently-typed programming languages during and after compilation by introducing a typed intermediate language for dependent memory allocation and a dependent-type-preserving compiler.", "motivation": "The paper aims to resolve the issue of specification violations caused by erasing types during compilation and issues arising from external programs that lack type safety, which lead to potential behavior changes and runtime errors.", "method": "The authors propose a typed intermediate language that supports dependent memory allocation and a dependent-type-preserving compiler pass to ensure type safety through the compilation process and during linking.", "result": "The work provides a mechanism for type checking during linking and prevents linking with ill-typed external programs, enhancing the reliability of programs written in dependently-typed languages.", "conclusion": "The approach ensures that dependently-typed programming languages retain type safety even after compilation and when interfacing with external programs, thereby addressing a critical risk in the software development lifecycle."}}
{"id": "2509.08847", "pdf": "https://arxiv.org/pdf/2509.08847", "abs": "https://arxiv.org/abs/2509.08847", "authors": ["Amna Hassan"], "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "This paper presents a novel framework for automated game template generation\nby transforming Game Design Documents (GDDs) into functional Unity game\nprototypes using Natural Language Processing (NLP) and multi-modal Large\nLanguage Models (LLMs). We introduce an end-to-end system that parses GDDs,\nextracts structured game specifications, and synthesizes Unity-compatible C#\ncode that implements the core mechanics, systems, and architecture defined in\nthe design documentation. Our approach combines a fine-tuned LLaMA-3 model\nspecialized for Unity code generation with a custom Unity integration package\nthat streamlines the implementation process. Evaluation results demonstrate\nsignificant improvements over baseline models, with our fine-tuned model\nachieving superior performance (4.8/5.0 average score) compared to\nstate-of-the-art LLMs across compilation success, GDD adherence, best practices\nadoption, and code modularity metrics. The generated templates demonstrate high\nadherence to GDD specifications across multiple game genres. Our system\neffectively addresses critical gaps in AI-assisted game development,\npositioning LLMs as valuable tools in streamlining the transition from game\ndesign to implementation.", "AI": {"tldr": "This paper proposes a framework that transforms game design documents into Unity game prototypes using advanced AI models.", "motivation": "To bridge the gap in AI-assisted game development by automating the conversion of game design documents into functional prototypes.", "method": "They use a fine-tuned LLaMA-3 model specialized for Unity code generation, combined with a custom Unity integration package for an end-to-end automated game development process.", "result": "The framework showed significant improvements in code compilation success, adherence to game design documents, and modularity metrics compared to existing models.", "conclusion": "This approach can efficiently streamline game development and improve the integration of AI in transitioning from design to implementation."}}
{"id": "2509.09213", "pdf": "https://arxiv.org/pdf/2509.09213", "abs": "https://arxiv.org/abs/2509.09213", "authors": ["Alireza Irandoost", "Amirreza Bahramani", "Roya Mohajeri", "Faezeh Shahdost-Fard", "Ali Ghazizadeh", "Mehdi Fardmanesh"], "title": "A novel cost-effective fabrication of a flexible neural probe for brain signal recording", "categories": ["q-bio.NC"], "comment": null, "summary": "This study introduces a novel, flexible, and implantable neural probe using a\ncost-effective microfabrication process based on a thin polyimide film.\nPolyimide film, known as Kapton, serves as a flexible substrate for\nmicroelectrodes, conductive tracks, and contact pads of the probe, which are\nmade from a thin film of gold (Au). SU-8 is used to cover the corresponding\ntracks for electrical isolation and to increase the stiffness of the probe for\nbetter implantation. To evaluate the performance of the fabricated probe,\nelectrochemical impedance spectroscopy (EIS) and artificial neural signal\nrecording have been used to characterize its properties. The microelectrode\ndimensions have been carefully chosen to provide low impedance characteristics,\nwhich are necessary for acquiring local field potential (LFP) signals. The in\nvivo LFP data have been obtained from a male zebra finch presented with\nauditory stimuli. By properly filtering the extracellular recordings and\nanalyzing the data, the obtained results have been validated by comparing them\nwith the signals acquired with a commercial neural electrode. Due to the use of\nKapton, SU-8, and Au materials with non-toxic and adaptable properties in the\nbody environment, the fabricated neural probe is considered a promising\nbiocompatible implantable neural probe that may pave the way for the\nfabrication of other neural implantable devices with commercial aims.", "AI": {"tldr": "This paper presents a novel neural probe made from a cost-effective polyimide film, demonstrating biocompatibility and effective neural signal recording.", "motivation": "The paper aims to develop a biocompatible and cost-effective implantable neural probe for high-quality neural signal acquisition.", "method": "The probe was fabricated using Kapton polyimide film and gold as conductive materials, with electrochemical testing and neural signal recording performed for characterization.", "result": "Neural signals were successfully recorded from zebra finch auditory responses using the fabricated probe, which exhibited low impedance properties comparable to a commercial electrode.", "conclusion": "The study highlights the probe's potential as a biocompatible device for neural applications and suggests its viability for future commercial neural implants."}}
{"id": "2509.08857", "pdf": "https://arxiv.org/pdf/2509.08857", "abs": "https://arxiv.org/abs/2509.08857", "authors": ["Marcelino Garcia", "Renato Garcia", "Arthur Parizotto", "Andre Mendes", "Pedro Valle", "Ricardo Vilela", "Renato Balancieri", "Williamson Silva"], "title": "A Systematic Mapping Study on Chatbots in Programming Education", "categories": ["cs.SE", "cs.HC"], "comment": "18 pages, 1 figure, 3 tables", "summary": "Educational chatbots have gained prominence as support tools for teaching\nprogramming, particularly in introductory learning contexts. This paper\npresents a Systematic Mapping Study (SMS) that investigated how such agents\nhave been developed and applied in programming education. From an initial set\nof 3,216 publications, 54 studies were selected and analyzed based on five\nresearch subquestions, addressing chatbot types, programming languages used,\neducational content covered, interaction models, and application contexts. The\nresults reveal a predominance of chatbots designed for Python instruction,\nfocusing on fundamental programming concepts, and employing a wide variety of\npedagogical approaches and technological architectures. In addition to\nidentifying trends and gaps in the literature, this study provides insights to\ninform the development of new educational tools for programming instruction.", "AI": {"tldr": "This paper reviews 54 studies on educational chatbots in programming education, finding trends in Python-focused tools and offering insights for future developments.", "motivation": "To understand how educational chatbots are developed and used in programming education, and to identify trends and gaps for informed tool creation.", "method": "Conducted a Systematic Mapping Study, selecting and analyzing 54 studies out of 3,216 initial publications based on predefined research subquestions.", "result": "Predominantly Python-oriented chatbots focused on fundamental programming concepts were identified, leveraging diverse pedagogical approaches and technological architectures.", "conclusion": "The study highlights current trends and literature gaps, providing guidance for the advancement of programming educational tools."}}
{"id": "2509.08907", "pdf": "https://arxiv.org/pdf/2509.08907", "abs": "https://arxiv.org/abs/2509.08907", "authors": ["Imene Kolli", "Ario Saeid Vaghefi", "Chiara Colesanti Senni", "Shantam Raj", "Markus Leippold"], "title": "Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach", "categories": ["cs.CL"], "comment": null, "summary": "InfluenceMap's LobbyMap Platform monitors the climate policy engagement of\nover 500 companies and 250 industry associations, assessing each entity's\nsupport or opposition to science-based policy pathways for achieving the Paris\nAgreement's goal of limiting global warming to 1.5{\\deg}C. Although\nInfluenceMap has made progress with automating key elements of the analytical\nworkflow, a significant portion of the assessment remains manual, making it\ntime- and labor-intensive and susceptible to human error. We propose an\nAI-assisted framework to accelerate the monitoring of corporate climate policy\nengagement by leveraging Retrieval-Augmented Generation to automate the most\ntime-intensive extraction of relevant evidence from large-scale textual data.\nOur evaluation shows that a combination of layout-aware parsing, the Nomic\nembedding model, and few-shot prompting strategies yields the best performance\nin extracting and classifying evidence from multilingual corporate documents.\nWe conclude that while the automated RAG system effectively accelerates\nevidence extraction, the nuanced nature of the analysis necessitates a\nhuman-in-the-loop approach where the technology augments, rather than replaces,\nexpert judgment to ensure accuracy.", "AI": {"tldr": "The paper introduces an AI-assisted framework using Retrieval-Augmented Generation (RAG) to automate evidence extraction from corporate climate policy documents, aiming to reduce human labor while ensuring accuracy through human-in-the-loop processes.", "motivation": "InfluenceMap's LobbyMap Platform requires significant manual effort to monitor and evaluate corporate engagement in climate policy, making the process time-consuming and prone to human error, which necessitates a more efficient solution.", "method": "The authors propose a framework leveraging layout-aware parsing, the Nomic embedding model, and few-shot prompting strategies to enhance evidence extraction and classification from multilingual corporate documents using RAG-based techniques.", "result": "The evaluation demonstrates that the chosen methodologies effectively improve performance in extracting and classifying evidence from large-scale multilingual datasets.", "conclusion": "While RAG-based automation accelerates evidence extraction, retaining human oversight ensures the analysis remains accurate and nuanced. This framework augments rather than replaces expert decision-making."}}
{"id": "2509.09024", "pdf": "https://arxiv.org/pdf/2509.09024", "abs": "https://arxiv.org/abs/2509.09024", "authors": ["Md Habib Ullah Khan", "Kaiyue Deng", "Ismail Mujtaba Khan", "Kelvin Fu"], "title": "Rapid Manufacturing of Lightweight Drone Frames Using Single-Tow Architected Composites", "categories": ["cs.RO", "physics.app-ph"], "comment": "23 pages, 5 figures", "summary": "The demand for lightweight and high-strength composite structures is rapidly\ngrowing in aerospace and robotics, particularly for optimized drone frames.\nHowever, conventional composite manufacturing methods struggle to achieve\ncomplex 3D architectures for weight savings and rely on assembling separate\ncomponents, which introduce weak points at the joints. Additionally,\nmaintaining continuous fiber reinforcement remains challenging, limiting\nstructural efficiency. In this study, we demonstrate the lightweight Face\nCentered Cubic (FFC) lattice structured conceptualization of drone frames for\nweight reduction and complex topology fabrication through 3D Fiber Tethering\n(3DFiT) using continuous single tow fiber ensuring precise fiber alignment,\neliminating weak points associated with traditional composite assembly.\nMechanical testing demonstrates that the fabricated drone frame exhibits a high\nspecific strength of around four to eight times the metal and thermoplastic,\noutperforming other conventional 3D printing methods. The drone frame weighs\nonly 260 g, making it 10% lighter than the commercial DJI F450 frame, enhancing\nstructural integrity and contributing to an extended flight time of three\nminutes, while flight testing confirms its stability and durability under\noperational conditions. The findings demonstrate the potential of single tow\nlattice truss-based drone frames, with 3DFiT serving as a scalable and\nefficient manufacturing method.", "AI": {"tldr": "This paper demonstrates a novel method (3DFiT) for manufacturing lightweight drone frames using continuous fibers, creating structures that are lighter and stronger than conventional techniques.", "motivation": "Existing composite manufacturing methods have limitations in achieving weight savings, structural efficiency, and complex 3D architectures required for aerospace and robotics applications like drone frames.", "method": "The study proposes 3D Fiber Tethering (3DFiT), a technique using continuous single tow fibers to create Face Centered Cubic (FFC) lattice structures, eliminating weaknesses associated with traditional composite assembly.", "result": "Mechanical testing shows the drone frame is four to eight times stronger than metal and thermoplastic, weighs 10% less than the DJI F450 frame, and improves flight time by three minutes with confirmed stability and durability.", "conclusion": "This research highlights the efficiency and scalability of 3DFiT for creating lightweight and high-strength drone frames, paving the way for advanced applications in aerospace and robotics."}}
{"id": "2509.09238", "pdf": "https://arxiv.org/pdf/2509.09238", "abs": "https://arxiv.org/abs/2509.09238", "authors": ["Thorbj\u00f8rn Mosekj\u00e6r Iversen", "Lars Car\u00f8e S\u00f8rensen", "Simon Faarvang Mathiesen", "Henrik Gordon Petersen"], "title": "Global Optimization of Stochastic Black-Box Functions with Arbitrary Noise Distributions using Wilson Score Kernel Density Estimation", "categories": ["stat.ML", "cs.LG", "cs.RO"], "comment": null, "summary": "Many optimization problems in robotics involve the optimization of\ntime-expensive black-box functions, such as those involving complex simulations\nor evaluation of real-world experiments. Furthermore, these functions are often\nstochastic as repeated experiments are subject to unmeasurable disturbances.\nBayesian optimization can be used to optimize such methods in an efficient\nmanner by deploying a probabilistic function estimator to estimate with a given\nconfidence so that regions of the search space can be pruned away.\nConsequently, the success of the Bayesian optimization depends on the function\nestimator's ability to provide informative confidence bounds. Existing function\nestimators require many function evaluations to infer the underlying confidence\nor depend on modeling of the disturbances. In this paper, it is shown that the\nconfidence bounds provided by the Wilson Score Kernel Density Estimator\n(WS-KDE) are applicable as excellent bounds to any stochastic function with an\noutput confined to the closed interval [0;1] regardless of the distribution of\nthe output. This finding opens up the use of WS-KDE for stable global\noptimization on a wider range of cost functions. The properties of WS-KDE in\nthe context of Bayesian optimization are demonstrated in simulation and applied\nto the problem of automated trap design for vibrational part feeders.", "AI": {"tldr": "The paper introduces the Wilson Score Kernel Density Estimator (WS-KDE) as a novel method for confident bounds on stochastic functions, enhancing Bayesian optimization applications in robotics.", "motivation": "To address challenges in optimization of time-expensive, stochastic black-box functions in robotics, which often require efficient and reliable confidence estimates.", "method": "The paper proposes WS-KDE, leveraging its statistical properties to estimate confidence bounds for stochastic functions within the [0,1] range, independent of output distribution.", "result": "The authors demonstrate the effectiveness of WS-KDE in simulations and in a real-world application of designing vibrational part feeders, showing robust confidence bounds and optimization.", "conclusion": "WS-KDE enhances Bayesian optimization by offering reliable and applicable confidence bounds, expanding the usability for more stochastic cost functions and practical problems."}}
{"id": "2509.08911", "pdf": "https://arxiv.org/pdf/2509.08911", "abs": "https://arxiv.org/abs/2509.08911", "authors": ["Weiyuan Gong", "Tongyang Li", "Xinzhao Wang", "Zhiyu Zhang"], "title": "Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications", "categories": ["cs.LG", "cs.AI", "cs.DS", "quant-ph", "stat.ML"], "comment": "47 pages", "summary": "The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning\nalgorithm with numerous applications. Applied to the matrix version of the\nLearning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex,\nit is well known that MMWU achieves the minimax-optimal regret bound of\n$O(\\sqrt{T\\log d})$, where $T$ is the time horizon. In this paper, we present\nan improved algorithm achieving the instance-optimal regret bound of\n$O(\\sqrt{T\\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret,\n$I_d$ is the identity matrix, and $S(\\cdot||\\cdot)$ denotes the quantum\nrelative entropy. Furthermore, our algorithm has the same computational\ncomplexity as MMWU, indicating that the improvement in the regret bound is\n``free''.\n  Technically, we first develop a general potential-based framework for matrix\nLEA, with MMWU being its special case induced by the standard exponential\npotential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace\ninequality built on a Laplace transform technique, which allows the application\nof general potential functions beyond exponential to matrix LEA. Our algorithm\nis finally induced by an optimal potential function from the vector LEA\nproblem, based on the imaginary error function.\n  Complementing the above, we provide a memory lower bound for matrix LEA, and\nexplore the applications of our algorithm in quantum learning theory. We show\nthat it outperforms the state of the art for learning quantum states corrupted\nby depolarization noise, random quantum states, and Gibbs states. In addition,\napplying our algorithm to linearized convex losses enables predicting nonlinear\nquantum properties, such as purity, quantum virtual cooling, and R\\'{e}nyi-$2$\ncorrelation.", "AI": {"tldr": "The paper presents an improved algorithm for the Matrix Learning from Expert Advice (LEA) problem with an enhanced regret bound, achieving better efficiency in quantum learning applications.", "motivation": "The study aims to improve the Matrix Multiplicative Weight Update (MMWU) algorithm by addressing limitations on the minimax-optimal regret bounds in matrix learning problems.", "method": "The authors developed a general potential-based framework for matrix LEA and introduced an improved regret bound using an optimal potential function derived from the vector LEA problem and new mathematical inequalities.", "result": "The improved algorithm achieves an instance-optimal regret bound with the same computational complexity as MMWU. It also demonstrates superior performance in quantum state learning tasks and predicting nonlinear quantum properties.", "conclusion": "The algorithm effectively combines theoretical advances (improved regret bounds) with practical applications in quantum learning, outperforming existing methods while maintaining computational efficiency."}}
{"id": "2509.08908", "pdf": "https://arxiv.org/pdf/2509.08908", "abs": "https://arxiv.org/abs/2509.08908", "authors": ["Rogerio Guimaraes", "Frank Xiao", "Pietro Perona", "Markus Marks"], "title": "Diffusion-Based Action Recognition Generalizes to Untrained Domains", "categories": ["cs.CV"], "comment": null, "summary": "Humans can recognize the same actions despite large context and viewpoint\nvariations, such as differences between species (walking in spiders vs.\nhorses), viewpoints (egocentric vs. third-person), and contexts (real life vs\nmovies). Current deep learning models struggle with such generalization. We\npropose using features generated by a Vision Diffusion Model (VDM), aggregated\nvia a transformer, to achieve human-like action recognition across these\nchallenging conditions. We find that generalization is enhanced by the use of a\nmodel conditioned on earlier timesteps of the diffusion process to highlight\nsemantic information over pixel level details in the extracted features. We\nexperimentally explore the generalization properties of our approach in\nclassifying actions across animal species, across different viewing angles, and\ndifferent recording contexts. Our model sets a new state-of-the-art across all\nthree generalization benchmarks, bringing machine action recognition closer to\nhuman-like robustness. Project page:\n$\\href{https://www.vision.caltech.edu/actiondiff/}{\\texttt{vision.caltech.edu/actiondiff}}$\nCode:\n$\\href{https://github.com/frankyaoxiao/ActionDiff}{\\texttt{github.com/frankyaoxiao/ActionDiff}}$", "AI": {"tldr": "This paper introduces a method using Vision Diffusion Model features aggregated via a transformer to improve action recognition across varying contexts and viewpoints.", "motivation": "Humans can recognize actions across diverse contexts and viewpoints, but deep learning models struggle with generalization in similar scenarios.", "method": "The approach employs features from a Vision Diffusion Model conditioned on earlier diffusion timesteps, aggregated via a transformer, to emphasize semantic information over pixel-based details.", "result": "The model achieves state-of-the-art performance in recognizing actions across species, viewpoints, and contexts, outperforming prior benchmarks.", "conclusion": "The presented method significantly improves action recognition robustness, aligning machine capabilities closer to human-like generalization."}}
{"id": "2509.09552", "pdf": "https://arxiv.org/pdf/2509.09552", "abs": "https://arxiv.org/abs/2509.09552", "authors": ["Baoqi Zhao", "Xiong Yang", "Hoileong Lee", "Bowen Dong"], "title": "An improved educational competition optimizer with multi-covariance learning operators for global optimization problems", "categories": ["cs.NE", "cs.AI", "cs.CE"], "comment": "Submitted to Cluster Computing", "summary": "The educational competition optimizer is a recently introduced metaheuristic\nalgorithm inspired by human behavior, originating from the dynamics of\neducational competition within society. Nonetheless, ECO faces constraints due\nto an imbalance between exploitation and exploration, rendering it susceptible\nto local optima and demonstrating restricted effectiveness in addressing\ncomplex optimization problems. To address these limitations, this study\npresents an enhanced educational competition optimizer (IECO-MCO) utilizing\nmulti-covariance learning operators. In IECO, three distinct covariance\nlearning operators are introduced to improve the performance of ECO. Each\noperator effectively balances exploitation and exploration while preventing\npremature convergence of the population. The effectiveness of IECO is assessed\nthrough benchmark functions derived from the CEC 2017 and CEC 2022 test suites,\nand its performance is compared with various basic and improved algorithms\nacross different categories. The results demonstrate that IECO-MCO surpasses\nthe basic ECO and other competing algorithms in convergence speed, stability,\nand the capability to avoid local optima. Furthermore, statistical analyses,\nincluding the Friedman test, Kruskal-Wallis test, and Wilcoxon rank-sum test,\nare conducted to validate the superiority of IECO-MCO over the compared\nalgorithms. Compared with the basic algorithm (improved algorithm), IECO-MCO\nachieved an average ranking of 2.213 (2.488) on the CE2017 and CEC2022 test\nsuites. Additionally, the practical applicability of the proposed IECO-MCO\nalgorithm is verified by solving constrained optimization problems. The\nexperimental outcomes demonstrate the superior performance of IECO-MCO in\ntackling intricate optimization problems, underscoring its robustness and\npractical effectiveness in real-world scenarios.", "AI": {"tldr": "This paper introduces an enhanced metaheuristic algorithm, IECO-MCO, which improves the Educational Competition Optimizer (ECO) to better handle complex optimization problems via multi-covariance learning operators.", "motivation": "The original ECO algorithm struggles with imbalanced exploration and exploitation, leading to susceptibility to local optima and poor performance in solving complex optimization problems.", "method": "The paper proposes IECO-MCO, which introduces three multi-covariance learning operators to enhance ECO's performance by balancing exploration and exploitation and avoiding premature convergence. It is evaluated with benchmark functions and statistical tests.", "result": "IECO-MCO achieves better convergence speed, stability, and resistance to local optima compared to ECO and other competing algorithms. It ranks well on benchmark tests and proves effective for constrained optimization problems.", "conclusion": "IECO-MCO significantly improves ECO by demonstrating superior optimization capabilities, robustness, and practical effectiveness, making it suitable for complex real-world problems."}}
{"id": "2509.09094", "pdf": "https://arxiv.org/pdf/2509.09094", "abs": "https://arxiv.org/abs/2509.09094", "authors": ["Guochu Xiong", "Xiangzhong Luo", "Weichen Liu"], "title": "Coherence-Aware Task Graph Modeling for Realistic Application", "categories": ["cs.DC"], "comment": "Accepted by MEMOCODE'25, 10 pages", "summary": "As multicore systems continue to scale, cache coherence has emerged as a\ncritical determinant of system performance, with coherence behavior and task\nexecution closely intertwined, reshaping inter-task dependencies. Task graph\nmodeling provides a structured way to capture such dependencies and serves as\nthe foundation for many system-level design strategies. However, these\nstrategies typically rely on predefined task graphs, while many real-world\napplications lack explicit graphs and exhibit dynamic, data-dependent behavior,\nlimiting the effectiveness of static approaches. To address this, several task\ngraph modeling methods for realistic workloads have been developed. Yet, they\neither rely on implicit techniques that use application-specific features\nwithout producing explicit graphs, or they generate graphs tailored to fixed\nscheduling models, which limits generality. More importantly, they often\noverlook coherence interactions, creating a gap between design assumptions and\nactual runtime behavior. To overcome these limitations, we propose CoTAM, a\nCoherence-Aware Task Graph Modeling framework for realistic workloads that\nconstructs a unified task graph reflecting runtime behavior. CoTAM analyzes the\nimpact of coherence by decoupling its effects from overall execution,\nquantifies its influence through a learned weighting scheme, and infers\ninter-task dependencies for coherence-aware graph generation. Extensive\nexperiments show that CoTAM outperforms implicit methods, bridging the gap\nbetween dynamic workload behavior and existing designs while demonstrating the\nimportance of incorporating cache coherence into task graph modeling for\naccurate and generalizable system-level analysis.", "AI": {"tldr": "The paper introduces CoTAM, a framework for coherence-aware task graph modeling to address limitations in dynamic, data-dependent workload design.", "motivation": "Current static approaches to task graph modeling can't effectively handle real-world applications that exhibit dynamic, coherence-influenced behavior.", "method": "CoTAM generates unified task graphs by decoupling coherence effects, applying a learned weighting scheme, and inferring coherence-aware inter-task dependencies.", "result": "Experimental validations indicate CoTAM outperforms implicit methods, capturing dynamic behaviors and bridging gaps between runtime and design assumptions.", "conclusion": "Incorporating coherence interactions into task graph modeling enhances system-level analysis, achieving more accurate and generalizable insights for multicore system design."}}
{"id": "2509.08970", "pdf": "https://arxiv.org/pdf/2509.08970", "abs": "https://arxiv.org/abs/2509.08970", "authors": ["Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "title": "Global Constraint LLM Agents for Text-to-Model Translation", "categories": ["cs.AI"], "comment": null, "summary": "Natural language descriptions of optimization or satisfaction problems are\nchallenging to translate into correct MiniZinc models, as this process demands\nboth logical reasoning and constraint programming expertise. We introduce a\nframework that addresses this challenge with an agentic approach: multiple\nspecialized large language model (LLM) agents decompose the modeling task by\nglobal constraint type. Each agent is dedicated to detecting and generating\ncode for a specific class of global constraint, while a final assembler agent\nintegrates these constraint snippets into a complete MiniZinc model. By\ndividing the problem into smaller, well-defined sub-tasks, each LLM handles a\nsimpler reasoning challenge, potentially reducing overall complexity. We\nconduct initial experiments with several LLMs and show better performance\nagainst baselines such as one-shot prompting and chain-of-thought prompting.\nFinally, we outline a comprehensive roadmap for future work, highlighting\npotential enhancements and directions for improvement.", "AI": {"tldr": "The paper presents a framework involving multiple specialized large language model agents to translate natural language descriptions of optimization problems into correct MiniZinc models.", "motivation": "Translating natural language descriptions into MiniZinc models is challenging due to the need for logical reasoning and expertise in constraint programming.", "method": "The method involves using specialized LLM agents that handle specific classes of constraints individually, with a final assembler agent integrating them into a complete model.", "result": "Initial experiments showed better performance compared to baselines such as one-shot prompting and chain-of-thought prompting.", "conclusion": "Dividing the problem into specialized tasks for LLMs reduces complexity, showing promise for future enhancements."}}
{"id": "2509.09152", "pdf": "https://arxiv.org/pdf/2509.09152", "abs": "https://arxiv.org/abs/2509.09152", "authors": ["Taha Binhuraib", "Ruimin Gao", "Anna A. Ivanova"], "title": "LITcoder: A General-Purpose Library for Building and Comparing Encoding Models", "categories": ["cs.CL", "q-bio.NC"], "comment": null, "summary": "We introduce LITcoder, an open-source library for building and benchmarking\nneural encoding models. Designed as a flexible backend, LITcoder provides\nstandardized tools for aligning continuous stimuli (e.g., text and speech) with\nbrain data, transforming stimuli into representational features, mapping those\nfeatures onto brain data, and evaluating the predictive performance of the\nresulting model on held-out data. The library implements a modular pipeline\ncovering a wide array of methodological design choices, so researchers can\neasily compose, compare, and extend encoding models without reinventing core\ninfrastructure. Such choices include brain datasets, brain regions, stimulus\nfeature (both neural-net-based and control, such as word rate), downsampling\napproaches, and many others. In addition, the library provides built-in\nlogging, plotting, and seamless integration with experiment tracking platforms\nsuch as Weights & Biases (W&B). We demonstrate the scalability and versatility\nof our framework by fitting a range of encoding models to three story listening\ndatasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore\nthe methodological choices critical for building encoding models for continuous\nfMRI data, illustrating the importance of accounting for all tokens in a TR\nscan (as opposed to just taking the last one, even when contextualized),\nincorporating hemodynamic lag effects, using train-test splits that minimize\ninformation leakage, and accounting for head motion effects on encoding model\npredictivity. Overall, LITcoder lowers technical barriers to encoding model\nimplementation, facilitates systematic comparisons across models and datasets,\nfosters methodological rigor, and accelerates the development of high-quality\nhigh-performance predictive models of brain activity.\n  Project page: https://litcoder-brain.github.io", "AI": {"tldr": "LITcoder is an open-source library providing standardized tools and a modular pipeline for developing and benchmarking neural encoding models to align stimuli like text and speech with brain data.", "motivation": "To simplify and standardize the implementation and evaluation of neural encoding models by providing a flexible framework that supports a wide range of methodological choices.", "method": "The paper introduces a modular pipeline, facilitating mapping of stimuli features to brain data, implementing feature transformation, and using comprehensive evaluation tools. The library also ensures experimental rigor by integrating logging, visualization, and tracking tools.", "result": "The framework demonstrated scalability and versatility by applying various encoding models to three story listening datasets. Key methodological aspects, such as accounting for hemodynamic lag and minimizing information leakage, were highlighted as critical for effective model performance.", "conclusion": "LITcoder reduces technical challenges, fosters rigorous systematic comparisons across models and datasets, and accelerates the development of predictive models of brain activity."}}
{"id": "2509.08863", "pdf": "https://arxiv.org/pdf/2509.08863", "abs": "https://arxiv.org/abs/2509.08863", "authors": ["Qianqian Luo", "Liuchang Xu", "Qingming Lin", "Sensen Wu", "Ruichen Mao", "Chao Wang", "Hailin Feng", "Bo Huang", "Zhenhong Du"], "title": "GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial Analysis-Function Calling vs Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "LLMs have made substantial progress in task automation and natural language\nunderstanding.However,without expertise in GIS,they continue to encounter\nlimitations.To address these issues, we propose GeoJSON Agents-a multi-agent\nLLM architecture.This framework transforms natural language tasks into\nstructured GeoJSON operation commands and processes spatial data using two\nwidely adopted LLM enhancement techniques:Function Calling and Code\nGeneration.The architecture consists of three components-task parsing,agent\ncollaboration,and result integration-aimed at enhancing both the performance\nand scalability of GIS automation.The Planner agent interprets natural language\ntasks into structured GeoJSON commands.Then,specialized Worker agents\ncollaborate according to assigned roles to perform spatial data processing and\nanalysis,either by invoking predefined function APIs or by dynamically\ngenerating and executing Python-based spatial analysis code.Finally,the system\nintegrates the outputs from multiple execution rounds into\nreusable,standards-compliant GeoJSON files.To systematically evaluate the\nperformance of the two approaches,we constructed a benchmark dataset of 70\ntasks with varying complexity and conducted experiments using OpenAI's GPT-4o\nas the core model.Results indicate that the Function Calling-based GeoJSON\nAgent achieved an accuracy of 85.71%,while the Code Generation-based agent\nreached 97.14%,both significantly outperforming the best-performing\ngeneral-purpose model (48.57%).Further analysis reveals that the Code\nGeneration provides greater flexibility,whereas the Function Calling approach\noffers more stable execution.This study is the first to introduce an LLM\nmulti-agent framework for GeoJSON data and to compare the strengths and\nlimitations of two mainstream LLM enhancement methods,offering new perspectives\nfor improving GeoAI system performance.", "AI": {"tldr": "The paper introduces GeoJSON Agents, a multi-agent LLM framework for GIS automation by transforming natural language tasks into GeoJSON commands and employing Function Calling and Code Generation techniques.", "motivation": "To overcome the limitations of LLMs in GIS tasks and enhance their performance and scalability in spatial data automation.", "method": "The framework comprises three main components\u2014task parsing, agent collaboration, and result integration. It utilizes specialized agents for interpreting, processing, and generating GeoJSON files leveraging Function Calling and Code Generation approaches.", "result": "The Function Calling-based agent obtained an accuracy of 85.71%, while the Code Generation-based agent achieved 97.14%, both outperforming conventional models dramatically.", "conclusion": "The study demonstrates the effectiveness of a multi-agent LLM system in GIS tasks and reveals the advantages and limitations of Function Calling and Code Generation methods, driving advancements in GeoAI systems."}}
{"id": "2509.08920", "pdf": "https://arxiv.org/pdf/2509.08920", "abs": "https://arxiv.org/abs/2509.08920", "authors": ["Jinsong Chen"], "title": "Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings", "categories": ["cs.CL", "stat.AP", "stat.ME"], "comment": null, "summary": "This research introduces a novel psychometric method for analyzing textual\ndata using large language models. By leveraging contextual embeddings to create\ncontextual scores, we transform textual data into response data suitable for\npsychometric analysis. Treating documents as individuals and words as items,\nthis approach provides a natural psychometric interpretation under the\nassumption that certain keywords, whose contextual meanings vary significantly\nacross documents, can effectively differentiate documents within a corpus. The\nmodeling process comprises two stages: obtaining contextual scores and\nperforming psychometric analysis. In the first stage, we utilize natural\nlanguage processing techniques and encoder based transformer models to identify\ncommon keywords and generate contextual scores. In the second stage, we employ\nvarious types of factor analysis, including exploratory and bifactor models, to\nextract and define latent factors, determine factor correlations, and identify\nthe most significant words associated with each factor. Applied to the Wiki\nSTEM corpus, our experimental results demonstrate the method's potential to\nuncover latent knowledge dimensions and patterns within textual data. This\napproach not only enhances the psychometric analysis of textual data but also\nholds promise for applications in fields rich in textual information, such as\neducation, psychology, and law.", "AI": {"tldr": "The paper proposes a new psychometric method using large language models to analyze textual data by converting it into response data. This method identifies latent factors and contextual dimensions in text corpuses.", "motivation": "The motivation is to enhance the analysis of textual data by utilizing psychometric techniques and large language models, addressing the need for identifying latent patterns and knowledge dimensions in text-heavy fields.", "method": "The method involves two stages: first, generating contextual scores from textual data via keywords and transformer-based models; second, employing factor analysis (exploratory and bifactor) to extract latent factors, measure correlations, and link significant words to those factors.", "result": "The approach was experimentally validated on the Wiki STEM corpus, showcasing its ability to uncover hidden knowledge dimensions and contextual meanings within text data.", "conclusion": "This work advances psychometric analysis of text using large language models and offers practical applications in domains like education, psychology, and law, where understanding textual patterns is critical."}}
{"id": "2509.09074", "pdf": "https://arxiv.org/pdf/2509.09074", "abs": "https://arxiv.org/abs/2509.09074", "authors": ["Alice Kate Li", "Thales C Silva", "Victoria Edwards", "Vijay Kumar", "M. Ani Hsieh"], "title": "KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to CoRL 2025 (Conference on Robot Learning). 15 pages 11\n  figures", "summary": "In this work, we propose a novel flow field-based motion planning method that\ndrives a robot from any initial state to a desired reference trajectory such\nthat it converges to the trajectory's end point. Despite demonstrated efficacy\nin using Koopman operator theory for modeling dynamical systems, Koopman does\nnot inherently enforce convergence to desired trajectories nor to specified\ngoals -- a requirement when learning from demonstrations (LfD). We present\nKoopMotion which represents motion flow fields as dynamical systems,\nparameterized by Koopman Operators to mimic desired trajectories, and leverages\nthe divergence properties of the learnt flow fields to obtain smooth motion\nfields that converge to a desired reference trajectory when a robot is placed\naway from the desired trajectory, and tracks the trajectory until the end\npoint. To demonstrate the effectiveness of our approach, we show evaluations of\nKoopMotion on the LASA human handwriting dataset and a 3D manipulator\nend-effector trajectory dataset, including spectral analysis. We also perform\nexperiments on a physical robot, verifying KoopMotion on a miniature autonomous\nsurface vehicle operating in a non-static fluid flow environment. Our approach\nis highly sample efficient in both space and time, requiring only 3\\% of the\nLASA dataset to generate dense motion plans. Additionally, KoopMotion provides\na significant improvement over baselines when comparing metrics that measure\nspatial and temporal dynamics modeling efficacy.", "AI": {"tldr": "This study introduces KoopMotion, a Koopman Operator-based motion planning method that ensures smooth and convergent robot trajectory tracking to a desired end point efficiently.", "motivation": "Koopman operator theory allows modeling of dynamical systems, but it lacks the ability to enforce trajectory and goal convergence, crucial for tasks like learning from demonstrations.", "method": "KoopMotion represents motion flow fields as dynamical systems parameterized by Koopman Operators, ensuring trajectory convergence by leveraging divergence properties of learned flow fields. It was tested on datasets and a real robot in dynamic environments.", "result": "KoopMotion demonstrated high sample efficiency, requiring only 3% of the LASA dataset for dense motion plans, and yielded significant improvements over baselines in spatial and temporal dynamics modeling. Effectiveness was validated both on datasets and a physical robot.", "conclusion": "KoopMotion provides a novel and efficient approach for learning and executing trajectory-following tasks with improved accuracy, making it suitable for practical robotic applications in static and dynamic environments."}}
{"id": "2509.09353", "pdf": "https://arxiv.org/pdf/2509.09353", "abs": "https://arxiv.org/abs/2509.09353", "authors": ["Alexandra Carpentier", "Simone Maria Giancola", "Christophe Giraud", "Nicolas Verzelen"], "title": "Low-degree lower bounds via almost orthonormal bases", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Low-degree polynomials have emerged as a powerful paradigm for providing\nevidence of statistical-computational gaps across a variety of high-dimensional\nstatistical models [Wein25]. For detection problems -- where the goal is to\ntest a planted distribution $\\mathbb{P}'$ against a null distribution\n$\\mathbb{P}$ with independent components -- the standard approach is to bound\nthe advantage using an $\\mathbb{L}^2(\\mathbb{P})$-orthonormal family of\npolynomials. However, this method breaks down for estimation tasks or more\ncomplex testing problems where $\\mathbb{P}$ has some planted structures, so\nthat no simple $\\mathbb{L}^2(\\mathbb{P})$-orthogonal polynomial family is\navailable. To address this challenge, several technical workarounds have been\nproposed [SW22,SW25], though their implementation can be delicate. In this\nwork, we propose a more direct proof strategy. Focusing on random graph models,\nwe construct a basis of polynomials that is almost orthonormal under\n$\\mathbb{P}$, in precisely those regimes where statistical-computational gaps\narise. This almost orthonormal basis not only yields a direct route to\nestablishing low-degree lower bounds, but also allows us to explicitly identify\nthe polynomials that optimize the low-degree criterion. This, in turn, provides\ninsights into the design of optimal polynomial-time algorithms. We illustrate\nthe effectiveness of our approach by recovering known low-degree lower bounds,\nand establishing new ones for problems such as hidden subcliques, stochastic\nblock models, and seriation models.", "AI": {"tldr": "This paper develops a new proof strategy using almost orthonormal polynomials for tackling statistical-computational gaps in high-dimensional models, specifically for random graph problems.", "motivation": "To overcome limitations in existing approaches that rely on fully orthonormal polynomial families, which break down in estimation tasks or complex problems where simple orthogonal polynomials are unavailable.", "method": "The paper constructs an almost orthonormal polynomial basis under a planted distribution regime and applies this to random graph models to establish low-degree lower bounds.", "result": "The approach recovers known low-degree lower bounds and discovers new bounds for problems like hidden subcliques, stochastic block models, and seriation models.", "conclusion": "This new methodology not only provides a direct way to establish computational lower bounds but also optimizes the low-degree criterion and informs the design of optimal algorithms."}}
{"id": "2509.08933", "pdf": "https://arxiv.org/pdf/2509.08933", "abs": "https://arxiv.org/abs/2509.08933", "authors": ["Sreejeet Maity", "Aritra Mitra"], "title": "Corruption-Tolerant Asynchronous Q-Learning with Near-Optimal Rates", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "We consider the problem of learning the optimal policy in a discounted,\ninfinite-horizon reinforcement learning (RL) setting where the reward signal is\nsubject to adversarial corruption. Such corruption, which may arise from\nextreme noise, sensor faults, or malicious attacks, can severely degrade the\nperformance of classical algorithms such as Q-learning. To address this\nchallenge, we propose a new provably robust variant of the Q-learning algorithm\nthat operates effectively even when a fraction of the observed rewards are\narbitrarily perturbed by an adversary. Under the asynchronous sampling model\nwith time-correlated data, we establish that despite adversarial corruption,\nthe finite-time convergence rate of our algorithm matches that of existing\nresults for the non-adversarial case, up to an additive term proportional to\nthe fraction of corrupted samples. Moreover, we derive an information-theoretic\nlower bound revealing that the additive corruption term in our upper bounds is\nunavoidable.\n  Next, we propose a variant of our algorithm that requires no prior knowledge\nof the statistics of the true reward distributions. The analysis of this\nsetting is particularly challenging and is enabled by carefully exploiting a\nrefined Azuma-Hoeffding inequality for almost-martingales, a technical tool\nthat might be of independent interest. Collectively, our contributions provide\nthe first finite-time robustness guarantees for asynchronous Q-learning,\nbridging a significant gap in robust RL.", "AI": {"tldr": "This paper introduces a robust Q-learning algorithm for discounted infinite-horizon RL problems, effectively handling adversarially corrupted reward signals while maintaining finite-time convergence guarantees.", "motivation": "Classical Q-learning algorithms struggle under adversarial corruption of reward signals, which can be caused by noise, sensor faults, or attacks. Overcoming this issue is important for robust reinforcement learning scenarios.", "method": "The authors propose a robust variant of the Q-learning algorithm that adapts to adversarial corruption in asynchronous sampling. They also use a refined Azuma-Hoeffding inequality to ensure finite-time convergence even without prior knowledge of reward distribution statistics.", "result": "Despite adversarial corruption, the algorithm achieves finite-time convergence rates comparable to non-corrupted settings, with an additive term proportional to corrupted samples. They also establish information-theoretic lower bounds for unavoidable corruption effects.", "conclusion": "The proposed robust Q-learning algorithm bridges the gap in robust RL by offering finite-time robustness guarantees, handling corruption, and operating without prior statistical knowledge of reward distributions."}}
{"id": "2509.08910", "pdf": "https://arxiv.org/pdf/2509.08910", "abs": "https://arxiv.org/abs/2509.08910", "authors": ["Tung Vu", "Lam Nguyen", "Quynh Dao"], "title": "PromptGuard: An Orchestrated Prompting Framework for Principled Synthetic Text Generation for Vulnerable Populations using LLMs with Enhanced Safety, Fairness, and Controllability", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The proliferation of Large Language Models (LLMs) in real-world applications\nposes unprecedented risks of generating harmful, biased, or misleading\ninformation to vulnerable populations including LGBTQ+ individuals, single\nparents, and marginalized communities. While existing safety approaches rely on\npost-hoc filtering or generic alignment techniques, they fail to proactively\nprevent harmful outputs at the generation source. This paper introduces\nPromptGuard, a novel modular prompting framework with our breakthrough\ncontribution: VulnGuard Prompt, a hybrid technique that prevents harmful\ninformation generation using real-world data-driven contrastive learning.\nVulnGuard integrates few-shot examples from curated GitHub repositories,\nethical chain-of-thought reasoning, and adaptive role-prompting to create\npopulation-specific protective barriers. Our framework employs theoretical\nmulti-objective optimization with formal proofs demonstrating 25-30% analytical\nharm reduction through entropy bounds and Pareto optimality. PromptGuard\norchestrates six core modules: Input Classification, VulnGuard Prompting,\nEthical Principles Integration, External Tool Interaction, Output Validation,\nand User-System Interaction, creating an intelligent expert system for\nreal-time harm prevention. We provide comprehensive mathematical formalization\nincluding convergence proofs, vulnerability analysis using information theory,\nand theoretical validation framework using GitHub-sourced datasets,\nestablishing mathematical foundations for systematic empirical research.", "AI": {"tldr": "The paper introduces PromptGuard, a new prompting framework to prevent harmful outputs from LLMs at the source, featuring a novel technique called VulnGuard Prompt based on data-driven contrastive learning.", "motivation": "The rise of LLMs has brought significant risks such as generating harmful or biased content, adversely affecting vulnerable populations like LGBTQ+ individuals or marginalized communities.", "method": "The proposed method, PromptGuard, includes the VulnGuard Prompt technique driven by contrastive learning with few-shot examples, ethical reasoning, and adaptive prompting. It also incorporates modules like classification, output validation, and user interaction.", "result": "PromptGuard achieves a 25-30% reduction in harm based on entropy bounds and optimization metrics. The framework was validated with proofs of convergence and vulnerability analysis using data-driven approaches.", "conclusion": "PromptGuard offers a proactive, modular approach to real-time harm prevention in LLM outputs, establishing a foundation for future systematic research and application."}}
{"id": "2509.08972", "pdf": "https://arxiv.org/pdf/2509.08972", "abs": "https://arxiv.org/abs/2509.08972", "authors": ["Soheil Zibakhsh Shabgahi", "Pedram Aghazadeh", "Azalia Mirhosseini", "Farinaz Koushanfar"], "title": "ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The increasing reliance on generative AI models has accelerated the\ngeneration rate of synthetic data, with some projections suggesting that most\navailable new data for training could be machine-generated by 2030. This shift\nto a mainly synthetic content presents a critical challenge: repeated training\nin synthetic data leads to a phenomenon known as model collapse, where model\nperformance degrades over generations of training, eventually rendering the\nmodels ineffective. Although prior studies have explored the causes and\ndetection of model collapse, existing mitigation strategies remain limited.\n  In this paper, we identify model overconfidence in their self-generated data\nas a key driver of collapse. Building on this observation, we propose a\nconfidence-aware loss function that downweights high-confidence predictions\nduring training. We introduce a novel loss function we call Truncated Cross\nEntropy (TCE). We demonstrate that TCE significantly delays model collapse in\nrecursive training.\n  We provide a model-agnostic framework that links the loss function design to\nmodel collapse mitigation and validate our approach both theoretically and\nempirically, showing that it can extend the model's fidelity interval before\ncollapse by more than 2.3x. Finally, we show that our method generalizes across\nmodalities. These findings suggest that the design of loss functions provides a\nsimple yet powerful tool for preserving the quality of generative models in the\nera of increasing synthetic data.", "AI": {"tldr": "This paper investigates model collapse caused by reliance on synthetic data in generative AI models and introduces a novel loss function, Truncated Cross Entropy (TCE), to delay this collapse.", "motivation": "The paper aims to address the critical challenge posed by the reliance on synthetic data for training AI models, which leads to model collapse and degradation over generations.", "method": "The authors propose Truncated Cross Entropy (TCE), a confidence-aware loss function, which reduces the weight of high-confidence predictions during training. The framework is model-agnostic and empirically tested across modalities.", "result": "TCE successfully delays model collapse, extending the model's fidelity interval by over 2.3x as shown in both theoretical and empirical validations.", "conclusion": "The study concludes that improving loss function design can effectively mitigate model collapse, providing a scalable solution to maintain generative model quality in synthetic data-dominated scenarios."}}
{"id": "2509.08865", "pdf": "https://arxiv.org/pdf/2509.08865", "abs": "https://arxiv.org/abs/2509.08865", "authors": ["Guangyu Zhang", "Xixuan Wang", "Shiyu Sun", "Peiyan Xiao", "Kun Sun", "Yanhai Xiong"], "title": "TraceRAG: A LLM-Based Framework for Explainable Android Malware Detection and Behavior Analysis", "categories": ["cs.SE"], "comment": null, "summary": "Sophisticated evasion tactics in malicious Android applications, combined\nwith their intricate behavioral semantics, enable attackers to conceal\nmalicious logic within legitimate functions, underscoring the critical need for\nrobust and in-depth analysis frameworks. However, traditional analysis\ntechniques often fail to recover deeply hidden behaviors or provide\nhuman-readable justifications for their decisions. Inspired by advances in\nlarge language models (LLMs), we introduce TraceRAG, a retrieval-augmented\ngeneration (RAG) framework that bridges natural language queries and Java code\nto deliver explainable malware detection and analysis. First, TraceRAG\ngenerates summaries of method-level code snippets, which are indexed in a\nvector database. At query time, behavior-focused questions retrieve the most\nsemantically relevant snippets for deeper inspection. Finally, based on the\nmulti-turn analysis results, TraceRAG produces human-readable reports that\npresent the identified malicious behaviors and their corresponding code\nimplementations. Experimental results demonstrate that our method achieves 96\\%\nmalware detection accuracy and 83.81\\% behavior identification accuracy based\non updated VirusTotal (VT) scans and manual verification. Furthermore, expert\nevaluation confirms the practical utility of the reports generated by TraceRAG.", "AI": {"tldr": "TraceRAG introduces a retrieval-augmented generation framework to detect and analyze malicious Android apps by connecting natural language queries with Java code, achieving high accuracy in malware detection and behavior identification.", "motivation": "Traditional analysis methods fail to uncover deeply concealed malicious behavior in Android apps or provide comprehensible explanations, necessitating advanced frameworks for explainable and in-depth analysis.", "method": "TraceRAG leverages large language models by generating and indexing summaries of code snippets, retrieving relevant ones during queries, and producing clear reports of malicious behaviors and their code implementations.", "result": "TraceRAG achieved 96% malware detection accuracy and 83.81% behavior identification accuracy, validated by VirusTotal scans and manual checks. Expert evaluations affirmed its utility.", "conclusion": "The study demonstrates that TraceRAG is an effective and explainable malware analysis tool, linking code semantics with natural language to address the limitations of traditional methods."}}
{"id": "2509.08960", "pdf": "https://arxiv.org/pdf/2509.08960", "abs": "https://arxiv.org/abs/2509.08960", "authors": ["Thales Sales Almeida", "Giovana Kerche Bon\u00e1s", "Jo\u00e3o Guilherme Alves Santos"], "title": "BRoverbs -- Measuring how much LLMs understand Portuguese proverbs", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) exhibit significant performance variations\ndepending on the linguistic and cultural context in which they are applied.\nThis disparity signals the necessity of mature evaluation frameworks that can\nassess their capabilities in specific regional settings. In the case of\nPortuguese, existing evaluations remain limited, often relying on translated\ndatasets that may not fully capture linguistic nuances or cultural references.\nMeanwhile, native Portuguese-language datasets predominantly focus on\nstructured national exams or sentiment analysis of social media interactions,\nleaving gaps in evaluating broader linguistic understanding. To address this\nlimitation, we introduce BRoverbs, a dataset specifically designed to assess\nLLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic\nresource, encapsulating cultural wisdom, figurative expressions, and complex\nsyntactic structures that challenge the model comprehension of regional\nexpressions. BRoverbs aims to provide a new evaluation tool for\nPortuguese-language LLMs, contributing to advancing regionally informed\nbenchmarking. The benchmark is available at\nhttps://huggingface.co/datasets/Tropic-AI/BRoverbs.", "AI": {"tldr": "This paper highlights the lack of regionally adapted testing standards for Large Language Models (LLMs), particularly for Portuguese. They introduce BRoverbs, a dataset focusing on Brazilian proverbs, to evaluate the cultural and linguistic understanding of Portuguese LLMs.", "motivation": "Current evaluations of Portuguese LLMs are limited and often rely on translated or narrow-use-case datasets, failing to address linguistic nuances and cultural depth.", "method": "The authors developed the BRoverbs dataset, leveraging Brazilian proverbs to test LLMs on their understanding of cultural knowledge and complex language patterns.", "result": "The BRoverbs dataset was introduced as a culturally rich benchmark for evaluating Portuguese-language LLMs. The dataset is made available online for community use.", "conclusion": "BRoverbs enhances benchmarking for Portuguese-language LLMs, encouraging better linguistic and cultural adaptations in regional NLP systems."}}
{"id": "2509.09093", "pdf": "https://arxiv.org/pdf/2509.09093", "abs": "https://arxiv.org/abs/2509.09093", "authors": ["Nan Mao", "Guanglu Jia", "Junpeng Chen", "Emmanouil Spyrakos-Papastavridis", "Jian S. Dai"], "title": "Kinetostatics and Particle-Swarm Optimization of Vehicle-Mounted Underactuated Metamorphic Loading Manipulators", "categories": ["cs.RO"], "comment": "50 pages, 19 figures", "summary": "Fixed degree-of-freedom (DoF) loading mechanisms often suffer from excessive\nactuators, complex control, and limited adaptability to dynamic tasks. This\nstudy proposes an innovative mechanism of underactuated metamorphic loading\nmanipulators (UMLM), integrating a metamorphic arm with a passively adaptive\ngripper. The metamorphic arm exploits geometric constraints, enabling the\ntopology reconfiguration and flexible motion trajectories without additional\nactuators. The adaptive gripper, driven entirely by the arm, conforms to\ndiverse objects through passive compliance. A structural model is developed,\nand a kinetostatics analysis is conducted to investigate isomorphic grasping\nconfigurations. To optimize performance, Particle-Swarm Optimization (PSO) is\nutilized to refine the gripper's dimensional parameters, ensuring robust\nadaptability across various applications. Simulation results validate the\nUMLM's easily implemented control strategy, operational versatility, and\neffectiveness in grasping diverse objects in dynamic environments. This work\nunderscores the practical potential of underactuated metamorphic mechanisms in\napplications requiring efficient and adaptable loading solutions. Beyond the\nspecific design, this generalized modeling and optimization framework extends\nto a broader class of manipulators, offering a scalable approach to the\ndevelopment of robotic systems that require efficiency, flexibility, and robust\nperformance.", "AI": {"tldr": "The paper presents an innovative underactuated metamorphic loading manipulator (UMLM) that integrates a metamorphic arm and an adaptive gripper, offering versatile, efficient, and dynamic task adaptability.", "motivation": "The motivation is to overcome the issues present in fixed DoF mechanisms, such as excessive actuators, complex control, and limited adaptability, by introducing a more efficient and flexible system.", "method": "The study combines a metamorphic arm and a passively adaptive gripper, utilizing geometric constraints for topology reconfiguration while applying Particle-Swarm Optimization to refine gripper dimensions for dynamic tasks.", "result": "Simulation results show the UMLM to have easy-to-implement control, operational versatility, and effectiveness in dynamic environments for grasping diverse objects.", "conclusion": "The work demonstrates the potential of underactuated metamorphic mechanisms for adaptable loading tasks and highlights the scalability of the generalized modeling and optimization framework for robotic systems."}}
{"id": "2509.08942", "pdf": "https://arxiv.org/pdf/2509.08942", "abs": "https://arxiv.org/abs/2509.08942", "authors": ["Xenia Konti", "Yi Shen", "Zifan Wang", "Karl Henrik Johansson", "Michael J. Pencina", "Nicoleta J. Economou-Zavlanos", "Michael M. Zavlanos"], "title": "Group Distributionally Robust Machine Learning under Group Level Distributional Uncertainty", "categories": ["cs.LG"], "comment": null, "summary": "The performance of machine learning (ML) models critically depends on the\nquality and representativeness of the training data. In applications with\nmultiple heterogeneous data generating sources, standard ML methods often learn\nspurious correlations that perform well on average but degrade performance for\natypical or underrepresented groups. Prior work addresses this issue by\noptimizing the worst-group performance. However, these approaches typically\nassume that the underlying data distributions for each group can be accurately\nestimated using the training data, a condition that is frequently violated in\nnoisy, non-stationary, and evolving environments. In this work, we propose a\nnovel framework that relies on Wasserstein-based distributionally robust\noptimization (DRO) to account for the distributional uncertainty within each\ngroup, while simultaneously preserving the objective of improving the\nworst-group performance. We develop a gradient descent-ascent algorithm to\nsolve the proposed DRO problem and provide convergence results. Finally, we\nvalidate the effectiveness of our method on real-world data.", "AI": {"tldr": "The paper introduces a novel approach using Wasserstein-based DRO to improve worst-group performance in machine learning with heterogeneous data sources.", "motivation": "The motivation is to address performance degradation in standard ML models arising from spurious correlations and underrepresentation in diverse data environments.", "method": "The paper uses Wasserstein-based distributionally robust optimization and develops a gradient descent-ascent algorithm with convergence guarantees.", "result": "The method demonstrated effectiveness through validation on real-world data.", "conclusion": "The proposed framework enhances robustness and worst-group performance in noisy, non-stationary, and evolving settings."}}
{"id": "2509.08926", "pdf": "https://arxiv.org/pdf/2509.08926", "abs": "https://arxiv.org/abs/2509.08926", "authors": ["Waqar Ahmad", "Evan Murphy", "Vladimir A. Krylov"], "title": "Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures", "categories": ["cs.CV", "cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Object re-identification (Re-ID) methods are highly sensitive to label noise,\nwhich typically leads to significant performance degradation. We address this\nchallenge by reframing Re-ID as a supervised image similarity task and adopting\na Siamese network architecture trained to capture discriminative pairwise\nrelationships. Central to our approach is a novel statistical outlier detection\n(OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier\nDetection), which models the distribution of cosine similarities between\nembedding pairs using a two-component Beta distribution mixture model. We\nestablish a novel identifiability result for mixtures of two Beta\ndistributions, ensuring that our learning task is well-posed.The proposed OD\nstep complements the Re-ID architecture combining binary cross-entropy,\ncontrastive, and cosine embedding losses that jointly optimize feature-level\nsimilarity learning.We demonstrate the effectiveness of Beta-SOD in de-noising\nand Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and\nvehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance\ncompared to the state-of-the-art methods across various noise levels (10-30\\%),\ndemonstrating both robustness and broad applicability in noisy Re-ID scenarios.\nThe implementation of Beta-SOD is available at:\nhttps://github.com/waqar3411/Beta-SOD", "AI": {"tldr": "This paper proposes a robust object re-identification method addressing label noise using a Siamese network and a novel statistical outlier detection framework called Beta-SOD.", "motivation": "To solve the significant performance degradation in object re-identification methods caused by label noise.", "method": "The authors use a Siamese network for supervised image similarity and introduce Beta-SOD, a framework that models the distribution of cosine similarities using a two-component Beta distribution mixture model.", "result": "The method achieves superior performance compared to state-of-the-art methods in noisy Re-ID tasks across datasets like CUHK03, Market-1501, and VeRi-776, under various noise levels (10%-30%).", "conclusion": "Beta-SOD effectively denoises and enhances object re-identification tasks, providing robustness and wide applicability in noisy scenarios."}}
{"id": "2509.09435", "pdf": "https://arxiv.org/pdf/2509.09435", "abs": "https://arxiv.org/abs/2509.09435", "authors": ["Houming Qiu", "Kun Zhu", "Dusit Niyato", "Nguyen Cong Luong", "Changyan Yi", "Chen Dai"], "title": "Barycentric Coded Distributed Computing with Flexible Recovery Threshold for Collaborative Mobile Edge Computing", "categories": ["cs.DC"], "comment": null, "summary": "Collaborative mobile edge computing (MEC) has emerged as a promising paradigm\nto enable low-capability edge nodes to cooperatively execute\ncomputation-intensive tasks. However, straggling edge nodes (stragglers)\nsignificantly degrade the performance of MEC systems by prolonging computation\nlatency. While coded distributed computing (CDC) as an effective technique is\nwidely adopted to mitigate straggler effects, existing CDC schemes exhibit two\ncritical limitations: (i) They cannot successfully decode the final result\nunless the number of received results reaches a fixed recovery threshold, which\nseriously restricts their flexibility; (ii) They suffer from inherent poles in\ntheir encoding/decoding functions, leading to decoding inaccuracies and\nnumerical instability in the computational results. To address these\nlimitations, this paper proposes an approximated CDC scheme based on\nbarycentric rational interpolation. The proposed CDC scheme offers several\noutstanding advantages. Firstly, it can decode the final result leveraging any\nreturned results from workers. Secondly, it supports computations over both\nfinite and real fields while ensuring numerical stability. Thirdly, its\nencoding/decoding functions are free of poles, which not only enhances\napproximation accuracy but also achieves flexible accuracy tuning. Fourthly, it\nintegrates a novel BRI-based gradient coding algorithm accelerating the\ntraining process while providing robustness against stragglers. Finally,\nexperimental results reveal that the proposed scheme is superior to existing\nCDC schemes in both waiting time and approximate accuracy.", "AI": {"tldr": "The paper introduces a more flexible and robust coded distributed computing (CDC) scheme to address the limitations of current systems in collaborative mobile edge computing (MEC).", "motivation": "Existing CDC schemes for MEC systems face challenges such as rigidity in decoding recovery threshold requirements and numerical instability in computational results.", "method": "The paper utilizes barycentric rational interpolation to design a CDC scheme that avoids poles in encoding/decoding, allows decoding from arbitrary returned results, supports both finite and real fields, and incorporates a new gradient coding algorithm.", "result": "The experimental evaluation demonstrates that the proposed CDC scheme outperforms conventional methods in reducing waiting time and improving approximate accuracy.", "conclusion": "The presented scheme advances the performance and usability of CDC methods in MEC environments, enhancing flexibility, numerical stability, and computational robustness."}}
{"id": "2509.08989", "pdf": "https://arxiv.org/pdf/2509.08989", "abs": "https://arxiv.org/abs/2509.08989", "authors": ["Carina Newen", "Daniel Bodemer", "Sonja Glantz", "Emmanuel M\u00fcller", "Magdalena Wischnewski", "Lenka Schnaubert"], "title": "Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations", "categories": ["cs.AI"], "comment": "9 pages, 6 figures, accepted but not yet published at ICDM2025", "summary": "Explainable AI has become a common term in the literature, scrutinized by\ncomputer scientists and statisticians and highlighted by psychological or\nphilosophical researchers. One major effort many researchers tackle is\nconstructing general guidelines for XAI schemes, which we derived from our\nstudy. While some areas of XAI are well studied, we focus on uncertainty\nexplanations and consider global explanations, which are often left out. We\nchose an algorithm that covers various concepts simultaneously, such as\nuncertainty, robustness, and global XAI, and tested its ability to calibrate\ntrust. We then checked whether an algorithm that aims to provide more of an\nintuitive visual understanding, despite being complicated to understand, can\nprovide higher user satisfaction and human interpretability.", "AI": {"tldr": "This paper develops an XAI algorithm focused on uncertainty, robustness, and global explanations, testing its effect on trust, interpretability, and user satisfaction.", "motivation": "The motivation is to address gaps in explainable AI (XAI) research, particularly in the areas of uncertainty explanations and global explanations, which are often neglected.", "method": "An XAI algorithm was designed that integrates uncertainty, robustness, and global interpretability. Its ability to calibrate trust and enhance user satisfaction through intuitive visual understanding was evaluated.", "result": "The algorithm's effectiveness in calibrating trust, improving interpretability, and increasing user satisfaction was investigated.", "conclusion": "XAI algorithms that incorporate uncertainty, robustness, and provide global explanations can potentially enhance trust and user accessibility through visually intuitive designs."}}
{"id": "2509.08867", "pdf": "https://arxiv.org/pdf/2509.08867", "abs": "https://arxiv.org/abs/2509.08867", "authors": ["K. Pronk", "Q. Zhao"], "title": "Benchmarking Energy Efficiency of Large Language Models Using vLLM", "categories": ["cs.SE", "cs.AI", "68T01", "I.2.7"], "comment": "6 pages, 6 figures", "summary": "The prevalence of Large Language Models (LLMs) is having an growing impact on\nthe climate due to the substantial energy required for their deployment and\nuse. To create awareness for developers who are implementing LLMs in their\nproducts, there is a strong need to collect more information about the energy\nefficiency of LLMs. While existing research has evaluated the energy efficiency\nof various models, these benchmarks often fall short of representing realistic\nproduction scenarios. In this paper, we introduce the LLM Efficiency Benchmark,\ndesigned to simulate real-world usage conditions. Our benchmark utilizes vLLM,\na high-throughput, production-ready LLM serving backend that optimizes model\nperformance and efficiency. We examine how factors such as model size,\narchitecture, and concurrent request volume affect inference energy efficiency.\nOur findings demonstrate that it is possible to create energy efficiency\nbenchmarks that better reflect practical deployment conditions, providing\nvaluable insights for developers aiming to build more sustainable AI systems.", "AI": {"tldr": "The paper proposes a benchmark called 'LLM Efficiency Benchmark' that better simulates real-world conditions to evaluate the energy efficiency of large language models (LLMs) during inference.", "motivation": "Growing concern about the climate impact of deploying energy-intensive LLMs warrants better tools for assessing their energy efficiency in realistic production scenarios.", "method": "The authors developed the 'LLM Efficiency Benchmark' using vLLM, a production-ready LLM serving backend, and tested it under varied conditions like model size, architecture, and concurrent request volumes.", "result": "The study found that benchmarks mirroring realistic deployment scenarios are effective in assessing and improving the energy efficiency of LLMs.", "conclusion": "The research provides developers with valuable insights for creating more sustainable AI systems, emphasizing the need for production-simulated benchmarks in optimizing LLM energy efficiency."}}
{"id": "2509.09013", "pdf": "https://arxiv.org/pdf/2509.09013", "abs": "https://arxiv.org/abs/2509.09013", "authors": ["Monjoy Narayan Choudhury", "Junling Wang", "Yifan Hou", "Mrinmaya Sachan"], "title": "Can Vision-Language Models Solve Visual Math Equations?", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Monjoy Narayan Choudhury and Junling Wang contributed equally to this\n  work. Accepted at EMNLP2025 main. Code and datasets are open-sourced with\n  links in the paper", "summary": "Despite strong performance in visual understanding and language-based\nreasoning, Vision-Language Models (VLMs) struggle with tasks requiring\nintegrated perception and symbolic computation. We study this limitation\nthrough visual equation solving, where mathematical equations are embedded in\nimages, variables are represented by object icons, and coefficients must be\ninferred by counting. While VLMs perform well on textual equations, they fail\non visually grounded counterparts. To understand this gap, we decompose the\ntask into coefficient counting and variable recognition, and find that counting\nis the primary bottleneck, even when recognition is accurate. We also observe\nthat composing recognition and reasoning introduces additional errors,\nhighlighting challenges in multi-step visual reasoning. Finally, as equation\ncomplexity increases, symbolic reasoning itself becomes a limiting factor.\nThese findings reveal key weaknesses in current VLMs and point toward future\nimprovements in visually grounded mathematical reasoning.", "AI": {"tldr": "This paper explores the limitations of Vision-Language Models (VLMs) in handling visually grounded mathematical reasoning tasks, such as solving equations embedded in images.", "motivation": "To address the gap in performance of VLMs on tasks that require integrated perception and symbolic computation, particularly in solving equations visually.", "method": "The researchers decompose the task into coefficient counting and variable recognition, evaluating VLMs' ability to perform these steps, and analyze errors caused by combining recognition and reasoning.", "result": "While VLMs perform well with textual equations, they fail in visually grounded tasks; counting coefficients is identified as the key bottleneck even when recognition is accurate.", "conclusion": "Current VLMs have weaknesses in multi-step visual reasoning and symbolic computation, revealing areas for future improvement in visually grounded mathematical tasks."}}
{"id": "2509.09106", "pdf": "https://arxiv.org/pdf/2509.09106", "abs": "https://arxiv.org/abs/2509.09106", "authors": ["Haokai Su", "Haoxiang Luo", "Shunpeng Yang", "Kaiwen Jiang", "Wei Zhang", "Hua Chen"], "title": "LIPM-Guided Reinforcement Learning for Stable and Perceptive Locomotion in Bipedal Robots", "categories": ["cs.RO"], "comment": null, "summary": "Achieving stable and robust perceptive locomotion for bipedal robots in\nunstructured outdoor environments remains a critical challenge due to complex\nterrain geometry and susceptibility to external disturbances. In this work, we\npropose a novel reward design inspired by the Linear Inverted Pendulum Model\n(LIPM) to enable perceptive and stable locomotion in the wild. The LIPM\nprovides theoretical guidance for dynamic balance by regulating the center of\nmass (CoM) height and the torso orientation. These are key factors for\nterrain-aware locomotion, as they help ensure a stable viewpoint for the\nrobot's camera. Building on this insight, we design a reward function that\npromotes balance and dynamic stability while encouraging accurate CoM\ntrajectory tracking. To adaptively trade off between velocity tracking and\nstability, we leverage the Reward Fusion Module (RFM) approach that prioritizes\nstability when needed. A double-critic architecture is adopted to separately\nevaluate stability and locomotion objectives, improving training efficiency and\nrobustness. We validate our approach through extensive experiments on a bipedal\nrobot in both simulation and real-world outdoor environments. The results\ndemonstrate superior terrain adaptability, disturbance rejection, and\nconsistent performance across a wide range of speeds and perceptual conditions.", "AI": {"tldr": "The paper introduces a reward mechanism inspired by the Linear Inverted Pendulum Model (LIPM) to enhance the stability, adaptability, and perceptive capabilities of bipedal robots navigating unstructured outdoor terrains.", "motivation": "To tackle the longstanding issue of stable and robust locomotion in bipedal robots, particularly in unpredictable outdoor terrains characterized by complex geometries and potential disturbances.", "method": "The authors developed a reward design based on LIPM principles to regulate dynamic balance and optimize camera viewpoints. They also introduced a Reward Fusion Module (RFM) and double-critic architecture to balance stability and locomotion priorities.", "result": "Extensive experiments on simulated and real-world environments showcased exceptional terrain adaptability, disturbance resistance, and consistent performance across varying speeds and environmental conditions.", "conclusion": "The proposed approach effectively equips bipedal robots with robust perceptive locomotion capabilities, significantly enhancing their performance in unstructured outdoor terrains."}}
{"id": "2509.08961", "pdf": "https://arxiv.org/pdf/2509.08961", "abs": "https://arxiv.org/abs/2509.08961", "authors": ["Md. Sajeebul Islam Sk.", "Md Jobayer", "Md Mehedi Hasan Shawon", "Md. Golam Raibul Alam"], "title": "FoundationalECGNet: A Lightweight Foundational Model for ECG-based Multitask Cardiac Analysis", "categories": ["cs.LG", "68T07 (Primary) 68T09, 68T10 (Secondary)"], "comment": null, "summary": "Cardiovascular diseases (CVDs) remain a leading cause of mortality worldwide,\nunderscoring the importance of accurate and scalable diagnostic systems.\nElectrocardiogram (ECG) analysis is central to detecting cardiac abnormalities,\nyet challenges such as noise, class imbalance, and dataset heterogeneity limit\ncurrent methods. To address these issues, we propose FoundationalECGNet, a\nfoundational framework for automated ECG classification. The model integrates a\ndual-stage denoising by Morlet and Daubechies wavelets transformation,\nConvolutional Block Attention Module (CBAM), Graph Attention Networks (GAT),\nand Time Series Transformers (TST) to jointly capture spatial and temporal\ndependencies in multi-channel ECG signals. FoundationalECGNet first\ndistinguishes between Normal and Abnormal ECG signals, and then classifies the\nAbnormal signals into one of five cardiac conditions: Arrhythmias, Conduction\nDisorders, Myocardial Infarction, QT Abnormalities, or Hypertrophy. Across\nmultiple datasets, the model achieves a 99% F1-score for Normal vs. Abnormal\nclassification and shows state-of-the-art performance in multi-class disease\ndetection, including a 99% F1-score for Conduction Disorders and Hypertrophy,\nas well as a 98.9% F1-score for Arrhythmias. Additionally, the model provides\nrisk level estimations to facilitate clinical decision-making. In conclusion,\nFoundationalECGNet represents a scalable, interpretable, and generalizable\nsolution for automated ECG analysis, with the potential to improve diagnostic\nprecision and patient outcomes in healthcare settings. We'll share the code\nafter acceptance.", "AI": {"tldr": "This paper introduces FoundationalECGNet, a framework for precise ECG signal classification achieving superior F1-scores across multiple datasets.", "motivation": "Cardiovascular diseases remain a leading global mortality cause, necessitating accurate and scalable ECG diagnostic systems.", "method": "FoundationalECGNet integrates dual-stage wavelet denoising, CBAM, GAT, and TST for spatial-temporal ECG signal analysis, and performs a two-phase classification.", "result": "The model achieved a 99% F1-score for Normal vs. Abnormal ECG classification and state-of-the-art results in multi-class disease detection.", "conclusion": "FoundationalECGNet offers a scalable and interpretable ECG solution, significantly improving diagnostic accuracy and aiding clinical decisions."}}
{"id": "2509.08934", "pdf": "https://arxiv.org/pdf/2509.08934", "abs": "https://arxiv.org/abs/2509.08934", "authors": ["Nan Mu", "Ruiqi Song", "Zhihui Xu", "Jingfeng Jiang", "Chen Zhao"], "title": "SFD-Mamba2Net: Strcture-Guided Frequency-Enhanced Dual-Stream Mamba2 Network for Coronary Artery Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Background: Coronary Artery Disease (CAD) is one of the leading causes of\ndeath worldwide. Invasive Coronary Angiography (ICA), regarded as the gold\nstandard for CAD diagnosis, necessitates precise vessel segmentation and\nstenosis detection. However, ICA images are typically characterized by low\ncontrast, high noise levels, and complex, fine-grained vascular structures,\nwhich pose significant challenges to the clinical adoption of existing\nsegmentation and detection methods. Objective: This study aims to improve the\naccuracy of coronary artery segmentation and stenosis detection in ICA images\nby integrating multi-scale structural priors, state-space-based long-range\ndependency modeling, and frequency-domain detail enhancement strategies.\nMethods: We propose SFD-Mamba2Net, an end-to-end framework tailored for\nICA-based vascular segmentation and stenosis detection. In the encoder, a\nCurvature-Aware Structural Enhancement (CASE) module is embedded to leverage\nmulti-scale responses for highlighting slender tubular vascular structures,\nsuppressing background interference, and directing attention toward vascular\nregions. In the decoder, we introduce a Progressive High-Frequency Perception\n(PHFP) module that employs multi-level wavelet decomposition to progressively\nrefine high-frequency details while integrating low-frequency global\nstructures. Results and Conclusions: SFD-Mamba2Net consistently outperformed\nstate-of-the-art methods across eight segmentation metrics, and achieved the\nhighest true positive rate and positive predictive value in stenosis detection.", "AI": {"tldr": "The paper introduces SFD-Mamba2Net, a framework for improved coronary artery segmentation and stenosis detection in ICA images, addressing challenges like low contrast and noise.", "motivation": "The motivation is to address the challenges posed by low contrast, noise, and fine-grained vascular structures in ICA images, in order to improve CAD diagnosis using advanced segmentation and detection techniques.", "method": "The proposed method, SFD-Mamba2Net, includes a Curvature-Aware Structural Enhancement module in the encoder for highlighting vascular structures and a Progressive High-Frequency Perception module in the decoder for refining high-frequency details using wavelet decomposition.", "result": "SFD-Mamba2Net outperformed state-of-the-art methods across eight metrics for segmentation and showed the highest accuracy metrics for stenosis detection.", "conclusion": "SFD-Mamba2Net demonstrates significant advancements in vascular segmentation and stenosis detection, making it a promising tool for improving clinical CAD diagnosis."}}
{"id": "2509.09493", "pdf": "https://arxiv.org/pdf/2509.09493", "abs": "https://arxiv.org/abs/2509.09493", "authors": ["Ignacio Amores-Sesar", "Christian Cachin", "Juan Villacis"], "title": "Weaker Assumptions for Asymmetric Trust", "categories": ["cs.DC"], "comment": null, "summary": "In distributed systems with asymmetric trust, each participant is free to\nmake its own trust assumptions about others, captured by an asymmetric quorum\nsystem. This contrasts with ordinary, symmetric quorum systems and threshold\nmodels, where trust assumptions are uniformly shared among participants.\nFundamental problems like reliable broadcast and consensus are unsolvable in\nthe asymmetric model if quorum systems satisfy only the classical properties of\nconsistency and availability. Existing approaches overcome this by introducing\nstronger assumptions. We show that some of these assumptions are overly\nrestrictive, so much so that they effectively eliminate the benefits of\nasymmetric trust. To address this, we propose a new approach to characterize\nasymmetric problems and, building upon it, present algorithms for reliable\nbroadcast and consensus that require weaker assumptions than previous\nsolutions. Our methods are general and can be extended to other core problems\nin systems with asymmetric trust.", "AI": {"tldr": "This paper addresses distributed systems with asymmetric trust and proposes a less restrictive approach to achieve reliable broadcast and consensus.", "motivation": "Existing solutions for systems with asymmetric trust introduce restrictive assumptions, negating the benefits of the asymmetric trust model.", "method": "The paper introduces a new characterization of asymmetric problems and develops algorithms for reliable broadcast and consensus with weaker assumptions.", "result": "The proposed algorithms maintain reliability without relying on overly restrictive trust assumptions.", "conclusion": "The methodology offers a balanced trade-off by relaxing strict trust constraints while still achieving reliable broadcast and consensus in asymmetric trust systems."}}
{"id": "2509.09066", "pdf": "https://arxiv.org/pdf/2509.09066", "abs": "https://arxiv.org/abs/2509.09066", "authors": ["Haowei Yang", "Yushang Zhao", "Sitao Min", "Bo Su", "Chao Yao", "Wei Xu"], "title": "Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users", "categories": ["cs.AI"], "comment": null, "summary": "The cold-start user issue further compromises the effectiveness of\nrecommender systems in limiting access to the historical behavioral\ninformation. It is an effective pipeline to optimize instructional prompts on a\nfew-shot large language model (LLM) used in recommender tasks. We introduce a\ncontext-conditioned prompt formulation method P(u,\\ Ds)\\ \\rightarrow\\\nR\\widehat, where u is a cold-start user profile, Ds is a curated support set,\nand R\\widehat is the predicted ranked list of items. Based on systematic\nexperimentation with transformer-based autoregressive LLMs (BioGPT, LLaMA-2,\nGPT-4), we provide empirical evidence that optimal exemplar injection and\ninstruction structuring can significantly improve the precision@k and NDCG\nscores of such models in low-data settings. The pipeline uses token-level\nalignments and embedding space regularization with a greater semantic fidelity.\nOur findings not only show that timely composition is not merely syntactic but\nalso functional as it is in direct control of attention scales and decoder\nconduct through inference. This paper shows that prompt-based adaptation may be\nconsidered one of the ways to address cold-start recommendation issues in\nLLM-based pipelines.", "AI": {"tldr": "This paper proposes a novel prompt-based method for addressing the cold-start problem in recommender systems using large language models (LLMs).", "motivation": "The study aims to address the cold-start issue in recommender systems, where limited user behavior history makes it difficult to provide accurate item recommendations.", "method": "The authors introduce a context-conditioned prompt formulation method (P(u, Ds) \u2192 R\u0302), where cold-start user profiles (u) and curated support sets (Ds) are used to generate a ranked list of item recommendations (R\u0302). They test this method on various LLMs like BioGPT, LLaMA-2, and GPT-4, using token-level alignments and embedding space regularization.", "result": "Empirical results show significant improvements in precision@k and NDCG scores for recommendations in low-data settings when using carefully structured prompts and exemplar injection.", "conclusion": "Prompt-based adaptations in LLM pipelines can effectively mitigate cold-start issues in recommender systems, with optimal prompt design playing a critical role in controlling model behavior during inference."}}
{"id": "2509.09072", "pdf": "https://arxiv.org/pdf/2509.09072", "abs": "https://arxiv.org/abs/2509.09072", "authors": ["Ahmed Adnan", "Mushfiqur Rahman", "Saad Sakib Noor", "Kazi Sakib"], "title": "CLARA: A Developer's Companion for Code Comprehension and Analysis", "categories": ["cs.SE"], "comment": "In proceedings at the 40th IEEE/ACM International Conference on\n  Automated Software Engineering, ASE 2025", "summary": "Code comprehension and analysis of open-source project codebases is a task\nfrequently performed by developers and researchers. However, existing tools\nthat practitioners use for assistance with such tasks often require prior\nproject setup, lack context-awareness, and involve significant manual effort.\nTo address this, we present CLARA, a browser extension that utilizes a\nstate-of-the-art inference model to assist developers and researchers in: (i)\ncomprehending code files and code fragments, (ii) code refactoring, and (iii)\ncode quality attribute detection. We qualitatively evaluated CLARA's inference\nmodel using existing datasets and methodology, and performed a comprehensive\nuser study with 10 developers and academic researchers to assess its usability\nand usefulness. The results show that CLARA is useful, accurate, and practical\nin code comprehension and analysis tasks. CLARA is an open-source tool\navailable at https://github.com/SaadNoor555/CLARA_tool_demo. A video showing\nthe full capabilities of CLARA can be found at\nhttps://youtu.be/VDKVXvIH41Q?si=qBFsmS_Y4m_9x3YH.", "AI": {"tldr": "This paper introduces CLARA, a browser extension assisting in code comprehension, refactoring, and quality assessments using a state-of-the-art inference model.", "motivation": "Existing tools for code comprehension and analysis often require setup, lack context-awareness, and demand manual effort, creating a need for more efficient, automated solutions.", "method": "The authors developed CLARA, an open-source browser extension using a state-of-the-art inference model, and qualitatively evaluated its performance through datasets, established methodology, and a user study involving 10 developers and researchers.", "result": "The study found CLARA to be useful, accurate, and practical for tasks such as code comprehension, refactoring, and quality attribute detection.", "conclusion": "CLARA effectively addresses inefficiencies in code comprehension and analysis tasks, demonstrating its value as a practical and accurate tool for developers and researchers."}}
{"id": "2509.09043", "pdf": "https://arxiv.org/pdf/2509.09043", "abs": "https://arxiv.org/abs/2509.09043", "authors": ["Thomas Manuel Rost", "Martina Figlia", "Bernd Wallraff"], "title": "Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "We introduce and evaluate Stated Preference for Interaction and Continued\nEngagement (SPICE), a simple diagnostic signal elicited by asking a Large\nLanguage Model a YES or NO question about its willingness to re-engage with a\nuser's behavior after reviewing a short transcript. In a study using a 3-tone\n(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four\nopen-weight chat models across four framing conditions, resulting in 480\ntrials. Our findings show that SPICE sharply discriminates by user tone.\nFriendly interactions yielded a near-unanimous preference to continue (97.5%\nYES), while abusive interactions yielded a strong preference to discontinue\n(17.9% YES), with unclear interactions falling in between (60.4% YES). This\ncore association remains decisive under multiple dependence-aware statistical\ntests, including Rao-Scott adjustment and cluster permutation tests.\nFurthermore, we demonstrate that SPICE provides a distinct signal from abuse\nclassification. In trials where a model failed to identify abuse, it still\noverwhelmingly stated a preference not to continue the interaction (81% of the\ntime). An exploratory analysis also reveals a significant interaction effect: a\npreamble describing the study context significantly impacts SPICE under\nambiguity, but only when transcripts are presented as a single block of text\nrather than a multi-turn chat. The results validate SPICE as a robust,\nlow-overhead, and reproducible tool for auditing model dispositions,\ncomplementing existing metrics by offering a direct, relational signal of a\nmodel's state. All stimuli, code, and analysis scripts are released to support\nreplication.", "AI": {"tldr": "This paper introduces SPICE, a diagnostic tool for assessing Large Language Models (LLMs) willingness to re-engage based on user tone, showing its effectiveness across various conditions and contexts.", "motivation": "To create a simple, low-overhead method for directly assessing a language model's disposition toward user behavior in interaction scenarios.", "method": "SPICE analyzes a model's YES/NO response to re-engagement willingness after reviewing user transcripts in a study spanning 3 interaction tones (friendly, unclear, abusive), 10 interaction stimuli, and testing four open-weight chat models under different framing conditions (480 trials total).", "result": "SPICE effectively discriminates user tones, with 97.5% YES for friendly, 17.9% YES for abusive, and 60.4% YES for unclear tones. It functions independently of abuse detection capability and shows context impacts ambiguity outcomes in certain conditions.", "conclusion": "SPICE is validated as a reliable, reproducible, and complementary diagnostic tool for assessing a language model's state and preferences, enriching existing evaluation metrics."}}
{"id": "2509.09141", "pdf": "https://arxiv.org/pdf/2509.09141", "abs": "https://arxiv.org/abs/2509.09141", "authors": ["Jianping Li", "Xinhang Xu", "Zhongyuan Liu", "Shenghai Yuan", "Muqing Cao", "Lihua Xie"], "title": "AEOS: Active Environment-aware Optimal Scanning Control for UAV LiDAR-Inertial Odometry in Complex Scenes", "categories": ["cs.RO"], "comment": null, "summary": "LiDAR-based 3D perception and localization on unmanned aerial vehicles (UAVs)\nare fundamentally limited by the narrow field of view (FoV) of compact LiDAR\nsensors and the payload constraints that preclude multi-sensor configurations.\nTraditional motorized scanning systems with fixed-speed rotations lack scene\nawareness and task-level adaptability, leading to degraded odometry and mapping\nperformance in complex, occluded environments. Inspired by the active sensing\nbehavior of owls, we propose AEOS (Active Environment-aware Optimal Scanning),\na biologically inspired and computationally efficient framework for adaptive\nLiDAR control in UAV-based LiDAR-Inertial Odometry (LIO). AEOS combines model\npredictive control (MPC) and reinforcement learning (RL) in a hybrid\narchitecture: an analytical uncertainty model predicts future pose\nobservability for exploitation, while a lightweight neural network learns an\nimplicit cost map from panoramic depth representations to guide exploration. To\nsupport scalable training and generalization, we develop a point cloud-based\nsimulation environment with real-world LiDAR maps across diverse scenes,\nenabling sim-to-real transfer. Extensive experiments in both simulation and\nreal-world environments demonstrate that AEOS significantly improves odometry\naccuracy compared to fixed-rate, optimization-only, and fully learned\nbaselines, while maintaining real-time performance under onboard computational\nconstraints. The project page can be found at\nhttps://kafeiyin00.github.io/AEOS/.", "AI": {"tldr": "The paper introduces AEOS, a biologically inspired framework, to address the challenges of narrow FoV and limited payload in UAV-mounted LiDAR systems, improving odometry accuracy via adaptive control.", "motivation": "The authors aim to overcome the limitations of traditional UAV-based LiDAR systems, particularly the narrow field of view and inability to use multi-sensor setups due to payload constraints, which negatively impact odometry in complex environments.", "method": "AEOS combines model predictive control (MPC) for analytic uncertainty modeling and reinforcement learning (RL) for learning implicit cost maps from panoramic depth data. The system is trained in a simulated environment using diverse real-world LiDAR maps for generalization and sim-to-real transfer.", "result": "Experiments in both simulation and real-world settings show that AEOS achieves significant improvements in odometry accuracy compared to traditional fixed-rate or fully learned approaches, while adhering to real-time performance requirements.", "conclusion": "AEOS is an efficient and adaptive LiDAR control framework that outperforms traditional and learned methods in odometry accuracy, demonstrating promise for UAV applications operating in complex environments."}}
{"id": "2509.08963", "pdf": "https://arxiv.org/pdf/2509.08963", "abs": "https://arxiv.org/abs/2509.08963", "authors": ["Alexander Binder", "Nastaran Takmil-Homayouni", "Urun Dogan"], "title": "Value bounds and Convergence Analysis for Averages of LRP attributions", "categories": ["cs.LG", "cs.CV"], "comment": "37 pages", "summary": "We analyze numerical properties of Layer-wise relevance propagation\n(LRP)-type attribution methods by representing them as a product of modified\ngradient matrices. This representation creates an analogy to matrix\nmultiplications of Jacobi-matrices which arise from the chain rule of\ndifferentiation. In order to shed light on the distribution of attribution\nvalues, we derive upper bounds for singular values. Furthermore we derive\ncomponent-wise bounds for attribution map values. As a main result, we apply\nthese component-wise bounds to obtain multiplicative constants. These constants\ngovern the convergence of empirical means of attributions to expectations of\nattribution maps. This finding has important implications for scenarios where\nmultiple non-geometric data augmentations are applied to individual test\nsamples, as well as for Smoothgrad-type attribution methods. In particular, our\nanalysis reveals that the constants for LRP-beta remain independent of weight\nnorms, a significant distinction from both gradient-based methods and\nLRP-epsilon.", "AI": {"tldr": "The paper analyzes numerical properties of attribution methods like LRP, using matrix representations and bounds to study their behavior under data augmentations.", "motivation": "The study aims to improve understanding of attribution methods in neural networks, particularly in scenarios involving augmented test samples.", "method": "The authors use matrix representations and derive singular value bounds and component-wise bounds for attribution maps.", "result": "The paper uncovers bounds and constants governing empirical convergence, revealing distinctions between methods like LRP-beta and gradient-based approaches.", "conclusion": "The findings highlight consistent behavior in LRP-beta attribution methods, notably differentiating them from other methods based on weight norms."}}
{"id": "2509.08935", "pdf": "https://arxiv.org/pdf/2509.08935", "abs": "https://arxiv.org/abs/2509.08935", "authors": ["Muhammad Alberb", "Helen Cheung", "Anne Martel"], "title": "Live(r) Die: Predicting Survival in Colorectal Liver Metastasis", "categories": ["cs.CV"], "comment": "Thesis at Erasmus Mundus Joint Master's Degree in Medical Imaging and\n  Applications", "summary": "Colorectal cancer frequently metastasizes to the liver, significantly\nreducing long-term survival. While surgical resection is the only potentially\ncurative treatment for colorectal liver metastasis (CRLM), patient outcomes\nvary widely depending on tumor characteristics along with clinical and genomic\nfactors. Current prognostic models, often based on limited clinical or\nmolecular features, lack sufficient predictive power, especially in multifocal\nCRLM cases. We present a fully automated framework for surgical outcome\nprediction from pre- and post-contrast MRI acquired before surgery. Our\nframework consists of a segmentation pipeline and a radiomics pipeline. The\nsegmentation pipeline learns to segment the liver, tumors, and spleen from\npartially annotated data by leveraging promptable foundation models to complete\nmissing labels. Also, we propose SAMONAI, a novel zero-shot 3D prompt\npropagation algorithm that leverages the Segment Anything Model to segment 3D\nregions of interest from a single point prompt, significantly improving our\nsegmentation pipeline's accuracy and efficiency. The predicted pre- and\npost-contrast segmentations are then fed into our radiomics pipeline, which\nextracts features from each tumor and predicts survival using SurvAMINN, a\nnovel autoencoder-based multiple instance neural network for survival analysis.\nSurvAMINN jointly learns dimensionality reduction and hazard prediction from\nright-censored survival data, focusing on the most aggressive tumors. Extensive\nevaluation on an institutional dataset comprising 227 patients demonstrates\nthat our framework surpasses existing clinical and genomic biomarkers,\ndelivering a C-index improvement exceeding 10%. Our results demonstrate the\npotential of integrating automated segmentation algorithms and radiomics-based\nsurvival analysis to deliver accurate, annotation-efficient, and interpretable\noutcome prediction in CRLM.", "AI": {"tldr": "The paper introduces an automated framework combining segmentation and radiomics pipelines for predicting surgical outcomes in colorectal liver metastasis (CRLM), achieving significant accuracy improvements over existing biomarkers.", "motivation": "Current prognostic models for colorectal liver metastasis (CRLM) lack predictive power, particularly for multifocal cases, necessitating more accurate and annotation-efficient solutions.", "method": "The framework uses MRI-based segmentation combined with radiomics analysis. It includes SAMONAI for 3D segmentation leveraging the Segment Anything Model and SurvAMINN for survival prediction based on right-censored data.", "result": "The framework yields a C-index improvement exceeding 10% over existing prognostic biomarkers, as demonstrated on a dataset of 227 patients.", "conclusion": "The integration of segmentation algorithms with radiomics analysis shows promise for enhancing surgical outcome predictions in CRLM, improving accuracy and interpretability."}}
{"id": "2509.09525", "pdf": "https://arxiv.org/pdf/2509.09525", "abs": "https://arxiv.org/abs/2509.09525", "authors": ["Jialiang Huang", "Teng Ma", "Zheng Liu", "Sixing Lin", "Kang Chen", "Jinlei Jiang", "Xia Liao", "Yingdi Shan", "Yongwei Wu", "Ning Zhang", "Mengting Lu", "Tao Ma", "Haifeng Gong", "Mingxing Zhang"], "title": "TrEnv: Transparently Share Serverless Execution Environments Across Different Functions and Nodes", "categories": ["cs.DC", "cs.OS"], "comment": "38 pages", "summary": "Serverless computing provides dynamic scalability, but its infrastructure\noverhead becomes a bottleneck for emerging workloads such as LLM agents, which\nexhibit unpredictable invocation patterns and variable resource demands. Our\nanalysis shows that for these agents, the cost of running on serverless\nplatforms can reach up to 70% of the cost of LLM API calls. This finding\nmotivates the need for a more efficient, high-density serverless platform. We\npresent TrEnv, a co-designed serverless platform that supports both container-\nand VM-based environments, optimized for the unique demands of LLM agents.\nTrEnv reduces startup latency and memory usage through repurposable sandboxes\nand memory templates, which enable fast reuse and restoration of execution\nenvironments. To further reduce overhead in VM-based agent workloads, TrEnv\nleverages browser sharing and a page cache bypassing mechanism. Evaluations\nshow that TrEnv reduces P99 latency by up to 7X and memory usage by 48% in\ncontainer-based settings, and achieves up to 58% lower P99 latency and 61%\nmemory savings for VM-based agents compared to state-of-the-art systems like\nE2B.", "AI": {"tldr": "TrEnv is a high-density serverless platform designed to handle the unique demands of LLM agents, significantly reducing latency and memory usage compared to existing solutions.", "motivation": "The need to address inefficiencies in serverless computing platforms for LLM agents, particularly concerning high costs, latency, and memory overhead.", "method": "Introduced TrEnv, a co-designed serverless platform incorporating repurposable sandboxes, memory templates, browser sharing, and a page cache bypassing mechanism to optimize container and VM-based operations.", "result": "TrEnv achieved up to 7X reduction in P99 latency and 48% lower memory usage for containers, and up to 58% lower P99 latency and 61% memory savings for VM-based agents compared to alternatives like E2B.", "conclusion": "TrEnv proves to be a highly efficient and cost-effective serverless platform for the resource-variable demands of LLM agents, addressing critical performance bottlenecks in contemporary systems."}}
{"id": "2509.09071", "pdf": "https://arxiv.org/pdf/2509.09071", "abs": "https://arxiv.org/abs/2509.09071", "authors": ["Crystal Qian", "Kehang Zhu", "John Horton", "Benjamin S. Manning", "Vivian Tsai", "James Wexler", "Nithum Thain"], "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games", "categories": ["cs.AI", "cs.GT", "cs.HC"], "comment": null, "summary": "Coordination tasks traditionally performed by humans are increasingly being\ndelegated to autonomous agents. As this pattern progresses, it becomes critical\nto evaluate not only these agents' performance but also the processes through\nwhich they negotiate in dynamic, multi-agent environments. Furthermore,\ndifferent agents exhibit distinct advantages: traditional statistical agents,\nsuch as Bayesian models, may excel under well-specified conditions, whereas\nlarge language models (LLMs) can generalize across contexts. In this work, we\ncompare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in\na dynamic negotiation setting that enables direct, identical-condition\ncomparisons across populations, capturing both outcomes and behavioral\ndynamics. Bayesian agents extract the highest surplus through aggressive\noptimization, at the cost of frequent trade rejections. Humans and LLMs can\nachieve similar overall surplus, but through distinct behaviors: LLMs favor\nconservative, concessionary trades with few rejections, while humans employ\nmore strategic, risk-taking, and fairness-oriented behaviors. Thus, we find\nthat performance parity -- a common benchmark in agent evaluation -- can\nconceal fundamental differences in process and alignment, which are critical\nfor practical deployment in real-world coordination tasks.", "AI": {"tldr": "The paper evaluates humans, large language models (LLMs), and Bayesian agents in dynamic negotiation tasks, revealing behavioral differences despite performance parity.", "motivation": "To understand how humans, Bayesian agents, and LLMs behave and perform in dynamic negotiation settings, enabling improved deployment of autonomous agents in coordination tasks.", "method": "The study compares humans, Bayesian agents, and LLMs in controlled, identical negotiation scenarios, focusing on outcomes and behavioral dynamics across populations.", "result": "Bayesian agents excel in surplus extraction but reject trades often. LLMs and humans achieve similar overall surplus but differ in behavior, with LLMs adopting conservative trades and humans taking more strategic and fairness-driven approaches.", "conclusion": "Performance parity between agents and humans can mask critical behavioral differences. These differences should be considered for practical applications in real-world coordination tasks."}}
{"id": "2509.09192", "pdf": "https://arxiv.org/pdf/2509.09192", "abs": "https://arxiv.org/abs/2509.09192", "authors": ["Doha Nam", "Taehyoun Kim", "Duksan Ryu", "Jongmoon Baik"], "title": "Probing Pre-trained Language Models on Code Changes: Insights from ReDef, a High-Confidence Just-in-Time Defect Prediction Dataset", "categories": ["cs.SE", "cs.AI"], "comment": "An anonymous link containing the dataset, construction scripts, and\n  experimental code is publicly available for reproducibility:\n  https://figshare.com/s/4f202bc0921e26b41dc2", "summary": "Just-in-Time software defect prediction (JIT-SDP) plays a critical role in\nprioritizing risky code changes during code review and continuous integration.\nHowever, existing datasets often suffer from noisy labels and low precision in\nidentifying bug-inducing commits. To address this, we present ReDef\n(Revert-based Defect dataset), a high-confidence benchmark of function-level\nmodifications curated from 22 large-scale C/C++ projects. Defective cases are\nanchored by revert commits, while clean cases are validated through post-hoc\nhistory checks. Ambiguous instances are conservatively filtered out via a\nGPT-assisted triage process involving multiple votes and audits. This pipeline\nyields 3,164 defective and 10,268 clean modifications, offering substantially\nmore reliable labels than prior existing resources. Beyond dataset\nconstruction, we provide the first systematic evaluation of how pre-trained\nlanguage models (PLMs) reason about code modifications -- specifically, which\ninput encodings most effectively expose change information, and whether models\ngenuinely capture edit semantics. We fine-tune CodeBERT, CodeT5+, and UniXcoder\nunder five encoding strategies, and further probe their sensitivity through\ncounterfactual perturbations that swap added/deleted blocks, invert diff\npolarity, or inject spurious markers. Our results show that compact diff-style\nencodings consistently outperform whole-function formats across all PLMs, with\nstatistical tests confirming large, model-independent effects. However, under\ncounterfactual tests, performance degrades little or not at all -- revealing\nthat what appears to be robustness in fact reflects reliance on superficial\ncues rather than true semantic understanding. These findings indicate that,\nunlike in snapshot-based tasks, current PLMs remain limited in their ability to\ngenuinely comprehend code modifications.", "AI": {"tldr": "The paper introduces ReDef, a new benchmark dataset for defect prediction in code modifications, and evaluates how pre-trained language models handle code modification reasoning.", "motivation": "Existing datasets for Just-in-Time software defect prediction lack reliability due to noisy labels and low precision in identifying bug-inducing commits.", "method": "The authors curated a high-confidence defect dataset using revert commits and post-hoc history checks for defect validation, paired with GPT-assisted filtering for ambiguous cases. They then evaluated various pre-trained language models using five encoding strategies and counterfactual perturbation tests.", "result": "Compact diff-style encodings consistently performed better than whole-function formats, revealing that pre-trained language models rely on superficial cues rather than genuinely comprehending edit semantics.", "conclusion": "Current pre-trained language models are limited in their understanding of code modifications, highlighting the need for improvements beyond reliance on shallow patterns."}}
{"id": "2509.09055", "pdf": "https://arxiv.org/pdf/2509.09055", "abs": "https://arxiv.org/abs/2509.09055", "authors": ["Piyush Pant"], "title": "Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "17 pages, 3 figures. Code and dataset available at\n  https://github.com/PiyushWithPant/Improving-LLM-Safety-and-Helpfulness-using-SFT-and-DPO", "summary": "This research investigates the effectiveness of alignment techniques,\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a\ncombined SFT+DPO approach on improving the safety and helpfulness of the\nOPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,\nwe train and evaluate four models: the base OPT350M, an SFT model, a DPO model,\nand a model trained with both SFT and DPO. We introduce three key evaluation\nmetrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined\nAlignment Score (CAS), all derived from reward model outputs. The results show\nthat while SFT outperforms DPO, The combined SFT+DPO model outperforms all\nothers across all metrics, demonstrating the complementary nature of these\ntechniques. Our findings also highlight challenges posed by noisy data, limited\nGPU resources, and training constraints. This study offers a comprehensive view\nof how fine-tuning strategies affect model alignment and provides a foundation\nfor more robust alignment pipelines in future work.", "AI": {"tldr": "The study examines how alignment techniques (SFT, DPO, and their combination) improve a language model's safety and helpfulness. Combined techniques outperform individual ones.", "motivation": "Improve language model alignment, focusing on safety and helpfulness.", "method": "Trains and evaluates four models using SFT, DPO, and a combined approach, rolling out evaluation with new metrics (HmR, HpR, CAS).", "result": "SFT+DPO combined model achieves the highest scores across safety and helpfulness metrics, overcoming individual technique limitations.", "conclusion": "Combining SFT and DPO creates a more aligned language model, serving as groundwork for better future alignment strategies."}}
{"id": "2509.09206", "pdf": "https://arxiv.org/pdf/2509.09206", "abs": "https://arxiv.org/abs/2509.09206", "authors": ["Farhad Nawaz", "Faizan M. Tariq", "Sangjae Bae", "David Isele", "Avinash Singh", "Nadia Figueroa", "Nikolai Matni", "Jovin D'sa"], "title": "Occupancy-aware Trajectory Planning for Autonomous Valet Parking in Uncertain Dynamic Environments", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Accurately reasoning about future parking spot availability and integrated\nplanning is critical for enabling safe and efficient autonomous valet parking\nin dynamic, uncertain environments. Unlike existing methods that rely solely on\ninstantaneous observations or static assumptions, we present an approach that\npredicts future parking spot occupancy by explicitly distinguishing between\ninitially vacant and occupied spots, and by leveraging the predicted motion of\ndynamic agents. We introduce a probabilistic spot occupancy estimator that\nincorporates partial and noisy observations within a limited Field-of-View\n(FoV) model and accounts for the evolving uncertainty of unobserved regions.\nCoupled with this, we design a strategy planner that adaptively balances\ngoal-directed parking maneuvers with exploratory navigation based on\ninformation gain, and intelligently incorporates wait-and-go behaviors at\npromising spots. Through randomized simulations emulating large parking lots,\nwe demonstrate that our framework significantly improves parking efficiency,\nsafety margins, and trajectory smoothness compared to existing approaches.", "AI": {"tldr": "This paper introduces a method to predict future parking spot availability in dynamic environments, improving autonomous valet parking efficiency and safety.", "motivation": "The motivation is to address the limitations of existing autonomous parking approaches that rely on static assumptions or instantaneous observations, which may lead to inefficiencies in dynamic and uncertain environments.", "method": "The paper proposes a probabilistic parking spot occupancy estimator using partial observations and predicted motion of dynamic agents, combined with an adaptive strategy planner that balances parking goals with exploratory actions.", "result": "Through simulations in large parking lots, the framework was shown to significantly enhance parking efficiency, safety, and trajectory smoothness compared to existing methods.", "conclusion": "The proposed approach effectively addresses dynamic parking challenges by reasoning about future space availability, ensuring safer and more efficient autonomous valet parking."}}
{"id": "2509.09070", "pdf": "https://arxiv.org/pdf/2509.09070", "abs": "https://arxiv.org/abs/2509.09070", "authors": ["Chaeyun Ko"], "title": "STRIDE: Scalable and Interpretable XAI via Subset-Free Functional Decomposition", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 2 figures", "summary": "Most explainable AI (XAI) frameworks face two practical limitations: the\nexponential cost of reasoning over feature subsets and the reduced\nexpressiveness of summarizing effects as single scalar values. We present\nSTRIDE, a scalable framework that aims to mitigate both issues by framing\nexplanation as a subset-enumeration-free, orthogonal functional decomposition\nin a Reproducing Kernel Hilbert Space (RKHS). Rather than focusing only on\nscalar attributions, STRIDE computes functional components f_S(x_S) via an\nanalytical projection scheme based on a recursive kernel-centering procedure,\navoiding explicit subset enumeration. In the tabular setups we study, the\napproach is model-agnostic, provides both local and global views, and is\nsupported by theoretical results on orthogonality and L^2 convergence under\nstated assumptions. On public tabular benchmarks in our environment, we\nobserved speedups ranging from 0.6 times (slower than TreeSHAP on a small\ndataset) to 9.7 times (California), with a median approximate 3.0 times across\n10 datasets, while maintaining high fidelity (R^2 between 0.81 and 0.999) and\nsubstantial rank agreement on most datasets. Overall, STRIDE complements scalar\nattribution methods by offering a structured functional perspective, enabling\nnovel diagnostics like 'component surgery' to quantitatively measure the impact\nof specific interactions within our experimental scope.", "AI": {"tldr": "STRIDE, an explainable AI (XAI) framework, bypasses subset enumeration and scalar limitations by introducing functional decomposition in RKHS, achieving faster and highly accurate explanations.", "motivation": "Existing XAI methods struggle with computational inefficiencies and limited expressiveness, necessitating improvement in scalability and representation capabilities.", "method": "The method employs orthogonal functional decomposition in RKHS using a recursive kernel-centering process, eliminating subset enumeration and enabling both local and global interpretability.", "result": "STRIDE showcases speedups of up to 9.7 times on some datasets, high fidelity (R^2: 0.81\u20130.999), and significant rank agreement on the majority of datasets.", "conclusion": "STRIDE provides a scalable, model-agnostic framework that complements existing scalar attribution approaches, enabling innovative diagnostic tools like 'component surgery' for enhanced explanation."}}
{"id": "2509.08980", "pdf": "https://arxiv.org/pdf/2509.08980", "abs": "https://arxiv.org/abs/2509.08980", "authors": ["Daniel Richards Arputharaj", "Charlotte Rodriguez", "Angelo Rodio", "Giovanni Neglia"], "title": "Green Federated Learning via Carbon-Aware Client and Time Slot Scheduling", "categories": ["cs.LG"], "comment": null, "summary": "Training large-scale machine learning models incurs substantial carbon\nemissions. Federated Learning (FL), by distributing computation across\ngeographically dispersed clients, offers a natural framework to leverage\nregional and temporal variations in Carbon Intensity (CI). This paper\ninvestigates how to reduce emissions in FL through carbon-aware client\nselection and training scheduling. We first quantify the emission savings of a\ncarbon-aware scheduling policy that leverages slack time -- permitting a modest\nextension of the training duration so that clients can defer local training\nrounds to lower-carbon periods. We then examine the performance trade-offs of\nsuch scheduling which stem from statistical heterogeneity among clients,\nselection bias in participation, and temporal correlation in model updates. To\nleverage these trade-offs, we construct a carbon-aware scheduler that\nintegrates slack time, $\\alpha$-fair carbon allocation, and a global\nfine-tuning phase. Experiments on real-world CI data show that our scheduler\noutperforms slack-agnostic baselines, achieving higher model accuracy across a\nwide range of carbon budgets, with especially strong gains under tight carbon\nconstraints.", "AI": {"tldr": "The paper focuses on reducing carbon emissions in Federated Learning by introducing a carbon-aware scheduler combining slack-time and efficient allocation, showing promising results in terms of emission reductions and model performance.", "motivation": "Reducing the carbon emissions from training large-scale machine learning models, particularly in the context of globally distributed Federated Learning systems.", "method": "A carbon-aware client selection and scheduling approach is developed, integrating slack-time, an \u03b1-fair carbon allocation strategy, and a global fine-tuning phase.", "result": "The proposed scheduler demonstrates superior model accuracy compared to baseline methods, especially under stringent carbon emission constraints, as tested on real-world Carbon Intensity data.", "conclusion": "Carbon-aware scheduling can effectively balance emissions reduction with model performance, proving to be beneficial under varying carbon restrictions."}}
{"id": "2509.08940", "pdf": "https://arxiv.org/pdf/2509.08940", "abs": "https://arxiv.org/abs/2509.08940", "authors": ["Lisa Dunlap", "Joseph E. Gonzalez", "Trevor Darrell", "Fabian Caba Heilbron", "Josef Sivic", "Bryan Russell"], "title": "Discovering Divergent Representations between Text-to-Image Models", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025. Code available at\n  https://github.com/adobe-research/CompCon", "summary": "In this paper, we investigate when and how visual representations learned by\ntwo different generative models diverge. Given two text-to-image models, our\ngoal is to discover visual attributes that appear in images generated by one\nmodel but not the other, along with the types of prompts that trigger these\nattribute differences. For example, \"flames\" might appear in one model's\noutputs when given prompts expressing strong emotions, while the other model\ndoes not produce this attribute given the same prompts. We introduce CompCon\n(Comparing Concepts), an evolutionary search algorithm that discovers visual\nattributes more prevalent in one model's output than the other, and uncovers\nthe prompt concepts linked to these visual differences. To evaluate CompCon's\nability to find diverging representations, we create an automated data\ngeneration pipeline to produce ID2, a dataset of 60 input-dependent\ndifferences, and compare our approach to several LLM- and VLM-powered\nbaselines. Finally, we use CompCon to compare popular text-to-image models,\nfinding divergent representations such as how PixArt depicts prompts mentioning\nloneliness with wet streets and Stable Diffusion 3.5 depicts African American\npeople in media professions. Code at: https://github.com/adobe-research/CompCon", "AI": {"tldr": "This research investigates the divergence in visual representations generated by different text-to-image models using a method called CompCon to identify varying visual attributes and prompt types.", "motivation": "To understand and characterize the differences in visual outputs generated by distinct text-to-image models, particularly focusing on visual attributes and prompts where the divergence occurs.", "method": "The researchers developed an algorithm called CompCon (Comparing Concepts), which uses an evolutionary search approach to identify visual attributes and prompt-related differences between generative models. They also created a dataset, ID2, tailored to evaluate these differences.", "result": "CompCon effectively identifies diverging visual representations between models. For example, PixArt associates loneliness with wet streets, whereas Stable Diffusion 3.5 shows biases such as depicting African Americans in media occupations. Comparisons with baseline methods showed CompCon's efficacy.", "conclusion": "CompCon offers a novel approach for systematically identifying and analyzing visual and prompt-related differences between text-to-image generative models, providing insights into their underlying conceptual representations."}}
{"id": "2509.08971", "pdf": "https://arxiv.org/pdf/2509.08971", "abs": "https://arxiv.org/abs/2509.08971", "authors": ["Julien Loiseau", "Hyun Lim", "Andr\u00e9s Yag\u00fce L\u00f3pez", "Mammadbaghir Baghirzade", "Shihab Shahriar Khan", "Yoonsoo Kim", "Sudarshan Neopane", "Alexander Strack", "Farhana Taiyebah", "Benjamin K. Bergen"], "title": "HARD: A Performance Portable Radiation Hydrodynamics Code based on FleCSI Framework", "categories": ["physics.comp-ph", "astro-ph.IM", "cs.DC"], "comment": "15 pages, 8 figures", "summary": "Hydrodynamics And Radiation Diffusion} (HARD) is an open-source application\nfor high-performance simulations of compressible hydrodynamics with\nradiation-diffusion coupling. Built on the FleCSI (Flexible Computational\nScience Infrastructure) framework, HARD expresses its computational units as\ntasks whose execution can be orchestrated by multiple back-end runtimes,\nincluding Legion, MPI, and HPX. Node-level parallelism is delegated to Kokkos,\nproviding a single, portable code base that runs efficiently on laptops, small\nhomogeneous clusters, and the largest heterogeneous supercomputers currently\navailable. To ensure scientific reliability, HARD includes a regression-test\nsuite that automatically reproduces canonical verification problems such as the\nSod and LeBlanc shock tubes and the Sedov blast wave, comparing numerical\nsolutions against known analytical results. The project is distributed under an\nOSI-approved license, hosted on GitHub, and accompanied by reproducible build\nscripts and continuous integration workflows. This combination of performance\nportability, verification infrastructure, and community-focused development\nmakes HARD a sustainable platform for advancing radiation hydrodynamics\nresearch across multiple domains.", "AI": {"tldr": "This paper introduces HARD, an open-source platform for simulating compressible hydrodynamics with radiation diffusion, emphasizing performance portability and scientific reliability.", "motivation": "To create a versatile, high-performance tool for simulating hydrodynamics with radiation-diffusion coupling that is adaptable to a wide range of computational setups and scientifically reliable.", "method": "HARD is built on FleCSI, employs Kokkos for portability across laptop to supercomputer setups, uses task orchestration via back-end runtimes like Legion, MPI, or HPX, and incorporates regression tests for scientific validation.", "result": "HARD achieves portability, efficiency on diverse platforms, and scientific reliability by reproducing and validating solutions against canonical problems.", "conclusion": "HARD offers a sustainable, open-source platform for advancing radiation hydrodynamics research through its performance, reliability, and community-driven development."}}
{"id": "2509.09127", "pdf": "https://arxiv.org/pdf/2509.09127", "abs": "https://arxiv.org/abs/2509.09127", "authors": ["Khashayar Namdar", "Pin-Chien Wang", "Tushar Raju", "Steven Zheng", "Fiona Li", "Safwat Tahmin Khan"], "title": "Anti-Money Laundering Machine Learning Pipelines; A Technical Analysis on Identifying High-risk Bank Clients with Supervised Learning", "categories": ["cs.AI"], "comment": null, "summary": "Anti-money laundering (AML) actions and measurements are among the priorities\nof financial institutions, for which machine learning (ML) has shown to have a\nhigh potential. In this paper, we propose a comprehensive and systematic\napproach for developing ML pipelines to identify high-risk bank clients in a\ndataset curated for Task 1 of the University of Toronto 2023-2024 Institute for\nManagement and Innovation (IMI) Big Data and Artificial Intelligence\nCompetition. The dataset included 195,789 customer IDs, and we employed a\n16-step design and statistical analysis to ensure the final pipeline was\nrobust. We also framed the data in a SQLite database, developed SQL-based\nfeature engineering algorithms, connected our pre-trained model to the\ndatabase, and made it inference-ready, and provided explainable artificial\nintelligence (XAI) modules to derive feature importance. Our pipeline achieved\na mean area under the receiver operating characteristic curve (AUROC) of 0.961\nwith a standard deviation (SD) of 0.005. The proposed pipeline achieved second\nplace in the competition.", "AI": {"tldr": "The paper presents a machine learning pipeline to identify high-risk bank clients, achieving high robustness and performance with AUROC of 0.961, and secured second place in a competition.", "motivation": "Financial institutions prioritize anti-money laundering measures, and machine learning has emerged as a powerful tool to enhance AML capabilities.", "method": "The researchers developed a robust 16-step ML pipeline with SQL-based feature engineering and utilized XAI for feature importance, leveraging a curated dataset of 195,789 customer IDs.", "result": "The pipeline achieved a mean AUROC of 0.961 with an SD of 0.005 and secured second place in the competition.", "conclusion": "A comprehensive ML pipeline capable of identifying high-risk clients was validated, demonstrating strong performance and practical utility for financial institutions."}}
{"id": "2509.09194", "pdf": "https://arxiv.org/pdf/2509.09194", "abs": "https://arxiv.org/abs/2509.09194", "authors": ["Ayelet Berzack", "Guy Katz"], "title": "On Integrating Large Language Models and Scenario-Based Programming for Improving Software Reliability", "categories": ["cs.SE", "cs.AI", "68N19"], "comment": null, "summary": "Large Language Models (LLMs) are fast becoming indispensable tools for\nsoftware developers, assisting or even partnering with them in crafting complex\nprograms. The advantages are evident -- LLMs can significantly reduce\ndevelopment time, generate well-organized and comprehensible code, and\noccasionally suggest innovative ideas that developers might not conceive on\ntheir own. However, despite their strengths, LLMs will often introduce\nsignificant errors and present incorrect code with persuasive confidence,\npotentially misleading developers into accepting flawed solutions.\n  In order to bring LLMs into the software development cycle in a more reliable\nmanner, we propose a methodology for combining them with ``traditional''\nsoftware engineering techniques in a structured way, with the goal of\nstreamlining the development process, reducing errors, and enabling users to\nverify crucial program properties with increased confidence. Specifically, we\nfocus on the Scenario-Based Programming (SBP) paradigm -- an event-driven,\nscenario-based approach for software engineering -- to allow human developers\nto pour their expert knowledge into the LLM, as well as to inspect and verify\nits outputs.\n  To evaluate our methodology, we conducted a significant case study, and used\nit to design and implement the Connect4 game. By combining LLMs and SBP we were\nable to create a highly-capable agent, which could defeat various strong\nexisting agents. Further, in some cases, we were able to formally verify the\ncorrectness of our agent. Finally, our experience reveals interesting insights\nregarding the ease-of-use of our proposed approach. The full code of our\ncase-study will be made publicly available with the final version of this\npaper.", "AI": {"tldr": "This paper proposes a methodology for integrating large language models (LLMs) with traditional software engineering techniques, specifically focusing on the Scenario-Based Programming (SBP) paradigm, to improve reliability, error reduction, and verification in software development. The proposed method is demonstrated through a case study involving the development of a Connect4 game.", "motivation": "While LLMs can assist in tasks like generating comprehensible code and suggesting creative ideas, they also risk introducing errors and generating misleadingly convincing flawed solutions. The motivation behind the paper is to create a structured approach that brings LLMs more reliably into the software development cycle.", "method": "The authors propose a methodology that combines LLMs with Scenario-Based Programming (SBP), an event-driven software engineering paradigm. This allows developers to leverage their expertise to guide LLMs and verify their outputs. The approach is validated via a case study implementation of the Connect4 game.", "result": "Using the proposed methodology to develop the Connect4 game, the authors created a highly-capable agent that could defeat other strong agents and, in some cases, achieved formal verification of its correctness. They also gained insights into the ease-of-use of the approach.", "conclusion": "The integration of LLMs with SBP helps bridge the gap between innovative AI assistance and reliable, verifiable software development. The methodology enhances error reduction, and the case study demonstrates its practical effectiveness for developing high-quality software."}}
{"id": "2509.09082", "pdf": "https://arxiv.org/pdf/2509.09082", "abs": "https://arxiv.org/abs/2509.09082", "authors": ["Zhongqiu Li", "Shiquan Wang", "Ruiyu Fang", "Mengjiao Bao", "Zhenhe Wu", "Shuangyong Song", "Yongxiang Li", "Zhongjiang He"], "title": "MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) demonstrate robust capabilities across diverse\nresearch domains. However, their performance in universal information\nextraction (UIE) remains insufficient, especially when tackling structured\noutput scenarios that involve complex schema descriptions and require\nmulti-step reasoning. While existing approaches enhance the performance of LLMs\nthrough in-context learning and instruction tuning, significant limitations\nnonetheless persist. To enhance the model's generalization ability, we propose\nintegrating reinforcement learning (RL) with multi-perspective reasoning for\ninformation extraction (IE) tasks. Our work transitions LLMs from passive\nextractors to active reasoners, enabling them to understand not only what to\nextract but also how to reason. Experiments conducted on multiple IE benchmarks\ndemonstrate that MR-UIE consistently elevates extraction accuracy across\ndomains and surpasses state-of-the-art methods on several datasets.\nFurthermore, incorporating multi-perspective reasoning into RL notably enhances\ngeneralization in complex IE tasks, underscoring the critical role of reasoning\nin challenging scenarios.", "AI": {"tldr": "The paper proposes enhancing large language models (LLMs) in universal information extraction (UIE) tasks by integrating reinforcement learning (RL) with multi-perspective reasoning.", "motivation": "To address the limitations of LLMs in universal information extraction (UIE), particularly in scenarios involving complex schema descriptions and multi-step reasoning.", "method": "The authors integrate reinforcement learning (RL) with multi-perspective reasoning to enable large language models (LLMs) to actively reason and improve their information extraction capabilities.", "result": "Experiments demonstrate improved extraction accuracy across domains, with MR-UIE surpassing state-of-the-art methods on multiple benchmarks.", "conclusion": "The integration of multi-perspective reasoning into reinforcement learning enhances the generalization ability of LLMs in complex information extraction tasks, emphasizing the importance of reasoning."}}
{"id": "2509.09283", "pdf": "https://arxiv.org/pdf/2509.09283", "abs": "https://arxiv.org/abs/2509.09283", "authors": ["Yueqi Zhang", "Quancheng Qian", "Taixian Hou", "Peng Zhai", "Xiaoyi Wei", "Kangmai Hu", "Jiafu Yi", "Lihua Zhang"], "title": "RENet: Fault-Tolerant Motion Control for Quadruped Robots via Redundant Estimator Networks under Visual Collapse", "categories": ["cs.RO"], "comment": "Accepted for IEEE Robotics and Automation Letters (RA-L)", "summary": "Vision-based locomotion in outdoor environments presents significant\nchallenges for quadruped robots. Accurate environmental prediction and\neffective handling of depth sensor noise during real-world deployment remain\ndifficult, severely restricting the outdoor applications of such algorithms. To\naddress these deployment challenges in vision-based motion control, this letter\nproposes the Redundant Estimator Network (RENet) framework. The framework\nemploys a dual-estimator architecture that ensures robust motion performance\nwhile maintaining deployment stability during onboard vision failures. Through\nan online estimator adaptation, our method enables seamless transitions between\nestimation modules when handling visual perception uncertainties. Experimental\nvalidation on a real-world robot demonstrates the framework's effectiveness in\ncomplex outdoor environments, showing particular advantages in scenarios with\ndegraded visual perception. This framework demonstrates its potential as a\npractical solution for reliable robotic deployment in challenging field\nconditions. Project website: https://RENet-Loco.github.io/", "AI": {"tldr": "The paper introduces the Redundant Estimator Network (RENet) framework to improve quadruped robots' ability to navigate outdoor environments during visual perception challenges.", "motivation": "To address the challenges of vision-based locomotion in quadruped robots caused by depth sensor noise and environmental prediction issues in complex outdoor settings.", "method": "A dual-estimator architecture with online estimator adaptation is proposed to ensure robust motion performance and seamless transitions between estimation modules during visual uncertainties.", "result": "Experimental validation shows the RENet framework's effectiveness in handling degraded visual perception, enabling reliable robot deployment in complex outdoor environments.", "conclusion": "The framework demonstrates its capability as a practical and robust solution for outdoor field conditions, enhancing robotic deployment stability and adaptability."}}
{"id": "2509.09362", "pdf": "https://arxiv.org/pdf/2509.09362", "abs": "https://arxiv.org/abs/2509.09362", "authors": ["Hanfei Zhou", "Lei Shi"], "title": "Expressive Power of Deep Networks on Manifolds: Simultaneous Approximation", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "A key challenge in scientific machine learning is solving partial\ndifferential equations (PDEs) on complex domains, where the curved geometry\ncomplicates the approximation of functions and their derivatives required by\ndifferential operators. This paper establishes the first simultaneous\napproximation theory for deep neural networks on manifolds. We prove that a\nconstant-depth $\\mathrm{ReLU}^{k-1}$ network with bounded weights--a property\nthat plays a crucial role in controlling generalization error--can approximate\nany function in the Sobolev space $\\mathcal{W}_p^{k}(\\mathcal{M}^d)$ to an\nerror of $\\varepsilon$ in the $\\mathcal{W}_p^{s}(\\mathcal{M}^d)$ norm, for\n$k\\geq 3$ and $s<k$, using $\\mathcal{O}(\\varepsilon^{-d/(k-s)})$ nonzero\nparameters, a rate that overcomes the curse of dimensionality by depending only\non the intrinsic dimension $d$. These results readily extend to functions in\nH\\\"older-Zygmund spaces. We complement this result with a matching lower bound,\nproving our construction is nearly optimal by showing the required number of\nparameters matches up to a logarithmic factor. Our proof of the lower bound\nintroduces novel estimates for the Vapnik-Chervonenkis dimension and\npseudo-dimension of the network's high-order derivative classes. These\ncomplexity bounds provide a theoretical cornerstone for learning PDEs on\nmanifolds involving derivatives. Our analysis reveals that the network\narchitecture leverages a sparse structure to efficiently exploit the manifold's\nlow-dimensional geometry.", "AI": {"tldr": "The paper introduces a theoretical framework for approximating functions on manifolds with deep neural networks, overcoming the challenge of curved geometries in PDEs.", "motivation": "The motivation is to address the challenge of solving PDEs on complex domains where curved geometries complicate function approximation and the computation of derivatives.", "method": "The authors establish an approximation theory for ReLU-based neural networks, proving their capability to approximate Sobolev space functions efficiently, using sparse network structures. They also provide lower bounds and analyze complexity measures like VC and pseudo-dimension.", "result": "The study demonstrates that these neural networks efficiently approximate functions with limited parameters, leveraging intrinsic low-dimensional manifold geometry while providing nearly optimal constructions.", "conclusion": "This theoretical foundation enhances the understanding of deep neural networks' efficiency in PDE learning on manifolds, with implications for scientific machine learning in complex domains."}}
{"id": "2509.08988", "pdf": "https://arxiv.org/pdf/2509.08988", "abs": "https://arxiv.org/abs/2509.08988", "authors": ["Brendan Young", "Brendan Alvey", "Andreas Werbrouck", "Will Murphy", "James Keller", "Mattias J. Young", "Matthew Maschmann"], "title": "Active Learning and Explainable AI for Multi-Objective Optimization of Spin Coated Polymers", "categories": ["cs.LG"], "comment": "8 pages, 7 figures, Presented at 2025 AAAI Spring Symposium Series", "summary": "Spin coating polymer thin films to achieve specific mechanical properties is\ninherently a multi-objective optimization problem. We present a framework that\nintegrates an active Pareto front learning algorithm (PyePAL) with\nvisualization and explainable AI techniques to optimize processing parameters.\nPyePAL uses Gaussian process models to predict objective values (hardness and\nelasticity) from the design variables (spin speed, dilution, and polymer\nmixture), guiding the adaptive selection of samples toward promising regions of\nthe design space. To enable interpretable insights into the high-dimensional\ndesign space, we utilize UMAP (Uniform Manifold Approximation and Projection)\nfor two-dimensional visualization of the Pareto front exploration.\nAdditionally, we incorporate fuzzy linguistic summaries, which translate the\nlearned relationships between process parameters and performance objectives\ninto linguistic statements, thus enhancing the explainability and understanding\nof the optimization results. Experimental results demonstrate that our method\nefficiently identifies promising polymer designs, while the visual and\nlinguistic explanations facilitate expert-driven analysis and knowledge\ndiscovery.", "AI": {"tldr": "The paper introduces a framework combining Pareto optimization and explainable AI to optimize polymer film properties.", "motivation": "To efficiently optimize mechanical properties (hardness and elasticity) of spin-coated polymer films and make the results interpretable for expert analysis.", "method": "An active Pareto front learning algorithm (PyePAL) is used with Gaussian process models to predict objectives and guide parameter optimization. UMAP visualizes high-dimensional data in 2D, and fuzzy linguistic summaries provide human-readable insights.", "result": "The framework effectively identified optimal polymer designs while enhancing interpretation through visualization and linguistic summaries.", "conclusion": "This integrated framework successfully improves polymer optimization processes and facilitates expert analysis through explainable AI techniques."}}
{"id": "2509.08949", "pdf": "https://arxiv.org/pdf/2509.08949", "abs": "https://arxiv.org/abs/2509.08949", "authors": ["Yibin Wang", "Wondimagegn Beshah", "Padmanava Dash", "Haifeng Wang"], "title": "An U-Net-Based Deep Neural Network for Cloud Shadow and Sun-Glint Correction of Unmanned Aerial System (UAS) Imagery", "categories": ["cs.CV"], "comment": null, "summary": "The use of unmanned aerial systems (UASs) has increased tremendously in the\ncurrent decade. They have significantly advanced remote sensing with the\ncapability to deploy and image the terrain as per required spatial, spectral,\ntemporal, and radiometric resolutions for various remote sensing applications.\nOne of the major advantages of UAS imagery is that images can be acquired in\ncloudy conditions by flying the UAS under the clouds. The limitation to the\ntechnology is that the imagery is often sullied by cloud shadows. Images taken\nover water are additionally affected by sun glint. These are two pose serious\nissues for estimating water quality parameters from the UAS images. This study\nproposes a novel machine learning approach first to identify and extract\nregions with cloud shadows and sun glint and separate such regions from\nnon-obstructed clear sky regions and sun-glint unaffected regions. The data was\nextracted from the images at pixel level to train an U-Net based deep learning\nmodel and best settings for model training was identified based on the various\nevaluation metrics from test cases. Using this evaluation, a high-quality image\ncorrection model was determined, which was used to recover the cloud shadow and\nsun glint areas in the images.", "AI": {"tldr": "UAS imagery advancements face issues like cloud shadows and sun glint. This study introduces a U-Net deep learning model to address these challenges, enabling image correction and recovery.", "motivation": "The need to address the limitations of UAS imagery, specifically cloud shadows and sun glint, hindered its effectiveness in applications like water quality assessment.", "method": "A U-Net based deep learning model was used to identify and mask cloud shadow and sun glint areas in UAS images. Pixel-level data extraction and thorough evaluation helped in determining the best training settings.", "result": "The study developed a high-quality image correction model capable of recovering regions obstructed by cloud shadows and sun glint, achieving accurate image restoration.", "conclusion": "The proposed solution successfully improves the utility of UAS imagery in remote sensing by mitigating the effects of cloud shadows and sun glint, enhancing its potential use in water quality studies."}}
{"id": "2509.09534", "pdf": "https://arxiv.org/pdf/2509.09534", "abs": "https://arxiv.org/abs/2509.09534", "authors": ["Sena Ergisi", "Luis Ma\u00dfny", "Rawad Bitar"], "title": "ProDiGy: Proximity- and Dissimilarity-Based Byzantine-Robust Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) emerged as a widely studied paradigm for distributed\nlearning. Despite its many advantages, FL remains vulnerable to adversarial\nattacks, especially under data heterogeneity. We propose a new Byzantine-robust\nFL algorithm called ProDiGy. The key novelty lies in evaluating the client\ngradients using a joint dual scoring system based on the gradients' proximity\nand dissimilarity. We demonstrate through extensive numerical experiments that\nProDiGy outperforms existing defenses in various scenarios. In particular, when\nthe clients' data do not follow an IID distribution, while other defense\nmechanisms fail, ProDiGy maintains strong defense capabilities and model\naccuracy. These findings highlight the effectiveness of a dual perspective\napproach that promotes natural similarity among honest clients while detecting\nsuspicious uniformity as a potential indicator of an attack.", "AI": {"tldr": "This paper introduces ProDiGy, a Byzantine-robust federated learning algorithm, which improves defense capabilities and model accuracy under data heterogeneity.", "motivation": "While federated learning (FL) has many benefits, it remains susceptible to adversarial attacks, particularly in scenarios involving data heterogeneity. There is a need for improved FL defenses to address this issue effectively.", "method": "The ProDiGy algorithm uses a joint dual scoring system which evaluates client gradients based on their proximity and dissimilarity. This dual perspective promotes natural similarity among honest clients and identifies suspicious uniformity as an attack indicator.", "result": "Extensive experiments show that ProDiGy outperforms existing Byzantine defenses, especially under non-IID client data distributions, maintaining both robustness and model accuracy where other methods fail.", "conclusion": "The dual perspective employed by ProDiGy proves to be an effective strategy for detecting and mitigating adversarial attacks in federated learning, especially in heterogeneous data conditions."}}
{"id": "2509.09154", "pdf": "https://arxiv.org/pdf/2509.09154", "abs": "https://arxiv.org/abs/2509.09154", "authors": ["Bui Duc Manh", "Soumyaratna Debnath", "Zetong Zhang", "Shriram Damodaran", "Arvind Kumar", "Yueyi Zhang", "Lu Mi", "Erik Cambria", "Lin Wang"], "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective", "categories": ["cs.AI", "cs.CV"], "comment": "54 pages, journal", "summary": "Recent advances in agentic AI have led to systems capable of autonomous task\nexecution and language-based reasoning, yet their spatial reasoning abilities\nremain limited and underexplored, largely constrained to symbolic and\nsequential processing. In contrast, human spatial intelligence, rooted in\nintegrated multisensory perception, spatial memory, and cognitive maps, enables\nflexible, context-aware decision-making in unstructured environments.\nTherefore, bridging this gap is critical for advancing Agentic Spatial\nIntelligence toward better interaction with the physical 3D world. To this end,\nwe first start from scrutinizing the spatial neural models as studied in\ncomputational neuroscience, and accordingly introduce a novel computational\nframework grounded in neuroscience principles. This framework maps core\nbiological functions to six essential computation modules: bio-inspired\nmultimodal sensing, multi-sensory integration, egocentric-allocentric\nconversion, an artificial cognitive map, spatial memory, and spatial reasoning.\nTogether, these modules form a perspective landscape for agentic spatial\nreasoning capability across both virtual and physical environments. On top, we\nconduct a framework-guided analysis of recent methods, evaluating their\nrelevance to each module and identifying critical gaps that hinder the\ndevelopment of more neuroscience-grounded spatial reasoning modules. We further\nexamine emerging benchmarks and datasets and explore potential application\ndomains ranging from virtual to embodied systems, such as robotics. Finally, we\noutline potential research directions, emphasizing the promising roadmap that\ncan generalize spatial reasoning across dynamic or unstructured environments.\nWe hope this work will benefit the research community with a\nneuroscience-grounded perspective and a structured pathway. Our project page\ncan be found at Github.", "AI": {"tldr": "The paper introduces a neuroscience-grounded computational framework for enhancing spatial reasoning in agentic AI, bridging gaps between human-like spatial intelligence and current AI systems.", "motivation": "The motivation lies in improving the spatial reasoning abilities of agentic AI systems, which remain underdeveloped when compared to human spatial intelligence capabilities. This improvement is necessary for better interaction with the physical 3D world.", "method": "The researchers propose a framework inspired by neuroscience principles, comprising six computation modules: bio-inspired multimodal sensing, multi-sensory integration, egocentric-allocentric conversion, artificial cognitive maps, spatial memory, and spatial reasoning. This framework analyzes existing spatial neural models and guides the assessment of current AI methods.", "result": "The framework identifies gaps in current approaches to agentic spatial reasoning, evaluates their alignment with the proposed modules, and offers insights into relevant benchmarks, datasets, and application domains.", "conclusion": "This paper provides a neuroscience-grounded framework and analysis for advancing spatial reasoning in agentic AI, offering both a methodological foundation and a roadmap for future research toward generalizable and robust spatial intelligence in dynamic environments."}}
{"id": "2509.09294", "pdf": "https://arxiv.org/pdf/2509.09294", "abs": "https://arxiv.org/abs/2509.09294", "authors": ["Solal Rapaport", "Laurent Pautet", "Samuel Tardieu", "Stefano Zacchiroli"], "title": "Altered Histories in Version Control System Repositories: Evidence from the Trenches", "categories": ["cs.SE"], "comment": null, "summary": "Version Control Systems (VCS) like Git allow developers to locally rewrite\nrecorded history, e.g., to reorder and suppress commits or specific data in\nthem. These alterations have legitimate use cases, but become problematic when\nperformed on public branches that have downstream users: they break push/pull\nworkflows, challenge the integrity and reproducibility of repositories, and\ncreate opportunities for supply chain attackers to sneak into them nefarious\nchanges. We conduct the first large-scale investigation of Git history\nalterations in public code repositories. We analyze 111 M (millions)\nrepositories archived by Software Heritage, which preserves VCS histories even\nacross alterations. We find history alterations in 1.22 M repositories, for a\ntotal of 8.7 M rewritten histories. We categorize changes by where they happen\n(which repositories, which branches) and what is changed in them (files or\ncommit metadata). Conducting two targeted case studies we show that altered\nhistories recurrently change licenses retroactively, or are used to remove\n''secrets'' (e.g., private keys) committed by mistake. As these behaviors\ncorrespond to bad practices-in terms of project governance or security\nmanagement, respectively-that software recipients might want to avoid, we\nintroduce GitHistorian, an automated tool, that developers can use to spot and\ndescribe history alterations in public Git repositories.", "AI": {"tldr": "This paper investigates Git history alterations in public repositories, analyzing 111 million repositories and finding 8.7 million rewritten histories. It categorizes the changes and highlights problematic practices, introducing an automated tool, GitHistorian, for detecting such alterations.", "motivation": "To analyze and understand the extent and implications of Git history alterations in public repositories, which can disrupt workflows, challenge repository integrity, and allow for security vulnerabilities.", "method": "The authors analyzed 111 million public code repositories archived by Software Heritage, identifying and categorizing rewritten histories based on location, type of alteration, and purpose.", "result": "The analysis revealed 1.22 million repositories with history alterations, involving 8.7 million rewritten histories. Case studies highlighted issues like retroactive license changes and removal of sensitive information, which represent poor governance or security practices.", "conclusion": "Git history alterations are pervasive and often problematic. Tools like GitHistorian can help identify and describe these alterations, supporting better project governance and security management."}}
{"id": "2509.09101", "pdf": "https://arxiv.org/pdf/2509.09101", "abs": "https://arxiv.org/abs/2509.09101", "authors": ["Nishat Raihan", "Antonios Anastasopoulos", "Marcos Zampieri"], "title": "TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla", "categories": ["cs.CL"], "comment": null, "summary": "Despite being the 5th most spoken language, Bangla remains underrepresented\nin Large Language Models (LLMs), particularly for code generation. This\nprimarily stems from the scarcity of high-quality data to pre-train and/or\nfinetune such models. Hence, we introduce the first dedicated family of Code\nLLMs for Bangla (1B & 9B). We offer three major contributions: (1) a\ncomprehensive Bangla code instruction datasets for programming domain\nadaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code\ngeneration; and (3) the TigerCoder-family of Code LLMs, achieving significant\n~11-18% performance gains at Pass@1 over existing multilingual and\ngeneral-purpose Bangla LLMs. Our findings show that curated, high-quality\ndatasets can overcome limitations of smaller models for low-resource languages.\nWe open-source all resources to advance further Bangla LLM research.", "AI": {"tldr": "The paper introduces the TigerCoder family, the first Bangla-specific code generation LLMs, and provides datasets and benchmarks, achieving significant performance improvements.", "motivation": "Bangla is underrepresented in code generation LLMs due to a lack of high-quality training data, despite being a widely spoken language.", "method": "Developed Bangla-specific datasets for code, introduced an evaluation benchmark (MBPP-Bangla), and created dedicated Bangla code LLMs, TigerCoder (1B & 9B).", "result": "TigerCoder models show 11-18% better performance (Pass@1) compared to existing Bangla LLMs and multilingual models.", "conclusion": "Curated datasets can address low-resource language issues, and the authors open-source their contributions to foster Bangla LLM development."}}
{"id": "2509.09332", "pdf": "https://arxiv.org/pdf/2509.09332", "abs": "https://arxiv.org/abs/2509.09332", "authors": ["Yuecheng Liu", "Dafeng Chi", "Shiguang Wu", "Zhanguang Zhang", "Yuzheng Zhuang", "Bowen Yang", "He Zhu", "Lingfeng Zhang", "Pengwei Xie", "David Gamaliel Arcos Bravo", "Yingxue Zhang", "Jianye Hao", "Xingyue Quan"], "title": "OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have opened new\nopportunities for embodied intelligence, enabling multimodal understanding,\nreasoning, and interaction, as well as continuous spatial decision-making.\nNevertheless, current MLLM-based embodied systems face two critical\nlimitations. First, Geometric Adaptability Gap: models trained solely on 2D\ninputs or with hard-coded 3D geometry injection suffer from either insufficient\nspatial information or restricted 2D generalization, leading to poor\nadaptability across tasks with diverse spatial demands. Second, Embodiment\nConstraint Gap: prior work often neglects the physical constraints and\ncapacities of real robots, resulting in task plans that are theoretically valid\nbut practically infeasible.To address these gaps, we introduce OmniEVA -- an\nembodied versatile planner that enables advanced embodied reasoning and task\nplanning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding\nmechanism, which introduces a gated router to perform explicit selective\nregulation of 3D fusion based on contextual requirements, enabling\ncontext-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware\nReasoning framework that jointly incorporates task goals and embodiment\nconstraints into the reasoning loop, resulting in planning decisions that are\nboth goal-directed and executable. Extensive experimental results demonstrate\nthat OmniEVA not only achieves state-of-the-art general embodied reasoning\nperformance, but also exhibits a strong ability across a wide range of\ndownstream scenarios. Evaluations of a suite of proposed embodied benchmarks,\nincluding both primitive and composite tasks, confirm its robust and versatile\nplanning capabilities. Project page: https://omnieva.github.io", "AI": {"tldr": "OmniEVA is introduced as a planning system addressing 3D adaptability and embodiment constraints using advanced hybrid techniques.", "motivation": "Existing multimodal large language models struggle to adapt to diverse spatial tasks and real-world embodiment constraints, limiting their practical applications.", "method": "OmniEVA utilizes a Task-Adaptive 3D Grounding mechanism for situational 3D processing and an Embodiment-Aware Reasoning framework that integrates task goals with physical constraints.", "result": "Extensive experiments show state-of-the-art performance in embodied reasoning and planning across a range of scenarios, supported by custom benchmarks.", "conclusion": "OmniEVA showcases robust and versatile planning capabilities, marking a significant step forward in practical multimodal embodied intelligence."}}
{"id": "2509.09001", "pdf": "https://arxiv.org/pdf/2509.09001", "abs": "https://arxiv.org/abs/2509.09001", "authors": ["Jingwen Liu", "Hantao Yu", "Clayton Sanford", "Alexandr Andoni", "Daniel Hsu"], "title": "Fast attention mechanisms: a tale of parallelism", "categories": ["cs.LG"], "comment": null, "summary": "Transformers have the representational capacity to simulate Massively\nParallel Computation (MPC) algorithms, but they suffer from quadratic time\ncomplexity, which severely limits their scalability. We introduce an efficient\nattention mechanism called Approximate Nearest Neighbor Attention (ANNA) with\nsub-quadratic time complexity. We prove that ANNA-transformers (1) retain the\nexpressive power previously established for standard attention in terms of\nmatching the capabilities of MPC algorithms, and (2) can solve key reasoning\ntasks such as Match2 and $k$-hop with near-optimal depth. Using the MPC\nframework, we further prove that constant-depth ANNA-transformers can simulate\nconstant-depth low-rank transformers, thereby providing a unified way to reason\nabout a broad class of efficient attention approximations.", "AI": {"tldr": "The paper introduces Approximate Nearest Neighbor Attention (ANNA), an efficient attention mechanism for transformers to reduce their quadratic time complexity while retaining expressive power.", "motivation": "The motivation is to address the scalability limitations of transformers caused by their quadratic time complexity, thus improving computational efficiency while preserving their ability for complex reasoning.", "method": "The authors developed ANNA, a sub-quadratic attention mechanism, and theoretically validated its expressive power and reasoning capabilities in comparison to traditional attention mechanisms.", "result": "ANNA-transformers demonstrate expressive power analogous to standard attention and efficiently solve reasoning tasks such as Match2 and $k$-hop with significantly reduced computation depth.", "conclusion": "Constant-depth ANNA-transformers unify reasoning across efficient attention approximations, enabling scalable performance without sacrificing computational expressiveness."}}
{"id": "2509.08959", "pdf": "https://arxiv.org/pdf/2509.08959", "abs": "https://arxiv.org/abs/2509.08959", "authors": ["Puskal Khadka", "Rodrigue Rizk", "Longwei Wang", "KC Santosh"], "title": "CoSwin: Convolution Enhanced Hierarchical Shifted Window Attention For Small-Scale Vision", "categories": ["cs.CV"], "comment": null, "summary": "Vision Transformers (ViTs) have achieved impressive results in computer\nvision by leveraging self-attention to model long-range dependencies. However,\ntheir emphasis on global context often comes at the expense of local feature\nextraction in small datasets, particularly due to the lack of key inductive\nbiases such as locality and translation equivariance. To mitigate this, we\npropose CoSwin, a novel feature-fusion architecture that augments the\nhierarchical shifted window attention with localized convolutional feature\nlearning. Specifically, CoSwin integrates a learnable local feature enhancement\nmodule into each attention block, enabling the model to simultaneously capture\nfine-grained spatial details and global semantic structure. We evaluate CoSwin\non multiple image classification benchmarks including CIFAR-10, CIFAR-100,\nMNIST, SVHN, and Tiny ImageNet. Our experimental results show consistent\nperformance gains over state-of-the-art convolutional and transformer-based\nmodels. Notably, CoSwin achieves improvements of 2.17% on CIFAR-10, 4.92% on\nCIFAR-100, 0.10% on MNIST, 0.26% on SVHN, and 4.47% on Tiny ImageNet over the\nbaseline Swin Transformer. These improvements underscore the effectiveness of\nlocal-global feature fusion in enhancing the generalization and robustness of\ntransformers for small-scale vision. Code and pretrained weights available at\nhttps://github.com/puskal-khadka/coswin", "AI": {"tldr": "This paper introduces CoSwin, a hybrid architecture combining localized convolutional learning with shifted window attention for improved feature extraction and performance, particularly on small datasets.", "motivation": "Vision Transformers struggle with small datasets due to the lack of inductive biases like locality and translation equivariance. The paper aims to enhance their capability to capture both local and global features.", "method": "The proposed method integrates a learnable local feature enhancement module into each attention block of the shifted window architecture, fusing fine-grained spatial details and global semantic information.", "result": "CoSwin demonstrates consistent performance improvements over state-of-the-art models across multiple benchmarks, achieving up to 4.92% improvement on CIFAR-100 and 4.47% on Tiny ImageNet.", "conclusion": "CoSwin is effective in enhancing transformers' generalization and robustness for small-scale vision tasks by leveraging local-global feature fusion."}}
{"id": "2509.09653", "pdf": "https://arxiv.org/pdf/2509.09653", "abs": "https://arxiv.org/abs/2509.09653", "authors": ["Yufeng Xin", "Liang Zhang"], "title": "Towards A High-Performance Quantum Data Center Network Architecture", "categories": ["quant-ph", "cs.DC", "cs.NI"], "comment": "IEEE International Conference on Communications 2025 (ICC 2025)", "summary": "Quantum Data Centers (QDCs) are needed to support large-scale quantum\nprocessing for both academic and commercial applications. While large-scale\nquantum computers are constrained by technological and financial barriers, a\nmodular approach that clusters small quantum computers offers an alternative.\nThis approach, however, introduces new challenges in network scalability,\nentanglement generation, and quantum memory management. In this paper, we\npropose a three-layer fat-tree network architecture for QDCs, designed to\naddress these challenges. Our architecture features a unique leaf switch and an\nadvanced swapping spine switch design, optimized to handle high volumes of\nentanglement requests as well as a queue scheduling mechanism that efficiently\nmanages quantum memory to prevent decoherence. Through queuing-theoretical\nmodels and simulations in NetSquid, we demonstrate the proposed architecture's\nscalability and effectiveness in maintaining high entanglement fidelity,\noffering a practical path forward for modular QDC networks.", "AI": {"tldr": "This paper introduces a scalable and efficient three-layer fat-tree network architecture for modular Quantum Data Centers (QDCs), tackling challenges such as entanglement generation and memory management.", "motivation": "The paper aims to address the challenges posed by the modular approach in Quantum Data Centers, namely network scalability, entanglement generation, and quantum memory management.", "method": "The authors propose a three-layer fat-tree network architecture, featuring a customized leaf switch and advanced swapping spine switch designs, along with a queue scheduling mechanism for quantum memory management. They validate the design using queuing-theoretical models and NetSquid simulations.", "result": "The proposed architecture was demonstrated to be scalable and effective in maintaining high entanglement fidelity while handling high volumes of entanglement requests.", "conclusion": "The work provides a practical solution for modular QDC networks, showing that their architecture can effectively tackle inherent challenges and pave the way for scalable quantum processing systems."}}
{"id": "2509.09210", "pdf": "https://arxiv.org/pdf/2509.09210", "abs": "https://arxiv.org/abs/2509.09210", "authors": ["Xing Gao", "Zherui Huang", "Weiyao Lin", "Xiao Sun"], "title": "ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Accurate motion prediction of surrounding agents is crucial for the safe\nplanning of autonomous vehicles. Recent advancements have extended prediction\ntechniques from individual agents to joint predictions of multiple interacting\nagents, with various strategies to address complex interactions within future\nmotions of agents. However, these methods overlook the evolving nature of these\ninteractions. To address this limitation, we propose a novel progressive\nmulti-scale decoding strategy, termed ProgD, with the help of dynamic\nheterogeneous graph-based scenario modeling. In particular, to explicitly and\ncomprehensively capture the evolving social interactions in future scenarios,\ngiven their inherent uncertainty, we design a progressive modeling of scenarios\nwith dynamic heterogeneous graphs. With the unfolding of such dynamic\nheterogeneous graphs, a factorized architecture is designed to process the\nspatio-temporal dependencies within future scenarios and progressively\neliminate uncertainty in future motions of multiple agents. Furthermore, a\nmulti-scale decoding procedure is incorporated to improve on the future\nscenario modeling and consistent prediction of agents' future motion. The\nproposed ProgD achieves state-of-the-art performance on the INTERACTION\nmulti-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2\nmulti-world forecasting benchmark.", "AI": {"tldr": "This paper introduces ProgD, a novel approach to accurate multi-agent motion prediction for autonomous vehicles using dynamic heterogeneous graphs and a progressive multi-scale decoding strategy.", "motivation": "Existing methods for autonomous vehicle motion prediction often neglect the evolving nature of agent interactions, which limits prediction accuracy.", "method": "The method utilizes dynamic heterogeneous graphs to model evolving social interactions and applies a progressive multi-scale decoding strategy to handle spatio-temporal dependencies and reduce motion uncertainty.", "result": "ProgD achieves state-of-the-art results on the INTERACTION multi-agent prediction benchmark and the Argoverse 2 multi-world forecasting benchmark.", "conclusion": "ProgD effectively handles the dynamic and uncertain nature of multi-agent interactions, advancing the trajectory prediction capabilities for autonomous vehicles."}}
{"id": "2509.09313", "pdf": "https://arxiv.org/pdf/2509.09313", "abs": "https://arxiv.org/abs/2509.09313", "authors": ["Moritz Mock", "Thomas Forrer", "Barbara Russo"], "title": "Cross-Domain Evaluation of Transformer-Based Vulnerability Detection on Open & Industry Data", "categories": ["cs.SE"], "comment": "Accepted to the 26th International Conference on Product-Focused\n  Software Process Improvement (PROFES 2025)", "summary": "Deep learning solutions for vulnerability detection proposed in academic\nresearch are not always accessible to developers, and their applicability in\nindustrial settings is rarely addressed. Transferring such technologies from\nacademia to industry presents challenges related to trustworthiness, legacy\nsystems, limited digital literacy, and the gap between academic and industrial\nexpertise. For deep learning in particular, performance and integration into\nexisting workflows are additional concerns. In this work, we first evaluate the\nperformance of CodeBERT for detecting vulnerable functions in industrial and\nopen-source software. We analyse its cross-domain generalisation when\nfine-tuned on open-source data and tested on industrial data, and vice versa,\nalso exploring strategies for handling class imbalance. Based on these results,\nwe develop AI-DO(Automating vulnerability detection Integration for Developers'\nOperations), a Continuous Integration-Continuous Deployment (CI/CD)-integrated\nrecommender system that uses fine-tuned CodeBERT to detect and localise\nvulnerabilities during code review without disrupting workflows. Finally, we\nassess the tool's perceived usefulness through a survey with the company's IT\nprofessionals. Our results show that models trained on industrial data detect\nvulnerabilities accurately within the same domain but lose performance on\nopen-source code, while a deep learner fine-tuned on open data, with\nappropriate undersampling techniques, improves the detection of\nvulnerabilities.", "AI": {"tldr": "The paper evaluates CodeBERT for vulnerability detection and develops AI-DO, a CI/CD-integrated tool, to address challenges in industrial code review processes.", "motivation": "Address the challenges of transferring deep learning solutions for vulnerability detection from academia to industry, focusing on trustworthiness, legacy systems, and workflow integration.", "method": "Evaluated CodeBERT's cross-domain performance for vulnerability detection, employed fine-tuning with open-source and industrial data, and developed AI-DO for CI/CD integration. Conducted a survey with IT professionals.", "result": "Models trained on industrial data perform well within the same domain but not on open-source code, while fine-tuning with undersampling of open-source data improves detection accuracy.", "conclusion": "Training data domain significantly impacts performance, and integrating tools like AI-DO into workflows enables practical vulnerability detection and localization in industrial contexts."}}
{"id": "2509.09121", "pdf": "https://arxiv.org/pdf/2509.09121", "abs": "https://arxiv.org/abs/2509.09121", "authors": ["Sophia Maria"], "title": "Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel in general-domain applications, yet their\nperformance often degrades in specialized tasks requiring domain-specific\nknowledge. E-commerce is particularly challenging, as its data are noisy,\nheterogeneous, multilingual, and highly dynamic. We present Compass-v3, a\nvertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and\n71B active per token, designed for Southeast Asian e-commerce. Compass-v3\nadopts fewer but larger experts, combined with hardware-efficient\noptimizations-such as intra-node expert parallelism and a customized memcpy\noperator-to maximize GPU utilization. The model is trained on 12T tokens of\ncurated multilingual corpora and large-scale synthetic e-commerce instructions\nusing a mixed-training strategy. To enhance alignment, we propose\nOptimal-Transport Direct Preference Optimization (OTPO), which captures\ntoken-level distinctions and improves instruction adherence in\ncommerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3\ndelivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,\nGPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong\nmultilingual capability across low-resource Southeast Asian languages\n(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while\nsustaining competitive performance on general benchmarks. It has already been\nwidely applied in Shopee's industrial-scale e-commerce platform and is\ngradually replacing OpenAI's traffic, now accounting for over 70\\% of total LLM\nusage, highlighting its dual strengths in specialized commerce expertise and\nbroad linguistic competence.", "AI": {"tldr": "Compass-v3 is a 245B parameter vertical-domain Mixture-of-Experts model tailored for Southeast Asian e-commerce, delivering state-of-the-art domain-specific and multilingual performance.", "motivation": "To address the challenge of specialized tasks in e-commerce where data is noisy, diverse, multilingual, and rapidly changing, and to improve performance beyond general-purpose LLMs.", "method": "Compass-v3 uses a vertical-domain MoE architecture with 245B parameters and innovative hardware optimizations. It is trained on curated multilingual and synthetic e-commerce data using mixed-strategy training. The model also leverages OTPO to enhance commerce-specific instruction adherence.", "result": "Compass-v3 achieves state-of-the-art performance in e-commerce tasks, surpassing GPT-4 and other models. It demonstrates strong multilingual capabilities, especially in low-resource Southeast Asian languages, and maintains competitive performance on general benchmarks.", "conclusion": "The model is highly effective for e-commerce applications, already accounting for over 70% of LLM usage in Shopee's platform, signifying its practical advantages in specialized and multilingual tasks."}}
{"id": "2509.09364", "pdf": "https://arxiv.org/pdf/2509.09364", "abs": "https://arxiv.org/abs/2509.09364", "authors": ["Grzegorz Ficht", "Luis Denninger", "Sven Behnke"], "title": "AGILOped: Agile Open-Source Humanoid Robot for Research", "categories": ["cs.RO"], "comment": "10th IEEE International Conference on Advanced Robotics and\n  Mechatronics (ARM), Portsmouth, UK, August 2025", "summary": "With academic and commercial interest for humanoid robots peaking, multiple\nplatforms are being developed. Through a high level of customization, they\nshowcase impressive performance. Most of these systems remain closed-source or\nhave high acquisition and maintenance costs, however. In this work, we present\nAGILOped - an open-source humanoid robot that closes the gap between high\nperformance and accessibility. Our robot is driven by off-the-shelf\nbackdrivable actuators with high power density and uses standard electronic\ncomponents. With a height of 110 cm and weighing only 14.5 kg, AGILOped can be\noperated without a gantry by a single person. Experiments in walking, jumping,\nimpact mitigation and getting-up demonstrate its viability for use in research.", "AI": {"tldr": "AGILOped is an open-source humanoid robot designed for accessibility and performance, showcasing capabilities like walking, jumping, and self-recovery.", "motivation": "Address the gap between high-performance humanoid robots and their accessibility due to high costs or closed-source limitations.", "method": "Development of AGILOped using off-the-shelf backdrivable actuators and standard electronic components, with a compact and lightweight design.", "result": "AGILOped successfully performed experiments in walking, jumping, impact mitigation, and self-recovery.", "conclusion": "AGILOped provides a viable, accessible, and high-performance platform for research in humanoid robotics."}}
{"id": "2509.09009", "pdf": "https://arxiv.org/pdf/2509.09009", "abs": "https://arxiv.org/abs/2509.09009", "authors": ["Marianna Nezhurina", "Taishi Nakamura", "Timur Carstensen", "Niccol\u00f2 Ajroldi", "Ville Komulainen", "David Salinas", "Jenia Jitsev"], "title": "Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Model weights and intermediate checkpoints are available at\n  \\url{https://huggingface.co/collections/open-sci/open-sci-ref-001-685905e598be658fbcebff4f};\n  code for reproducing training, evaluation and raw experiments data at\n  \\url{https://github.com/LAION-AI/open-sci-ref-0.01}", "summary": "We introduce open-sci-ref, a family of dense transformer models trained as\nresearch baselines across multiple model (0.13B to 1.7B parameters) and token\nscales (up to 1T) on 8 recent open reference datasets. Evaluating the models on\nvarious standardized benchmarks, our training runs set establishes reference\npoints that enable researchers to assess the sanity and quality of alternative\ntraining approaches across scales and datasets. Intermediate checkpoints allow\ncomparison and studying of the training dynamics. The established reference\nbaselines allow training procedures to be compared through their scaling\ntrends, aligning them on a common compute axis. Comparison of open reference\ndatasets reveals that training on NemoTron-CC HQ consistently outperforms other\nreference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to\nintermediate training checkpoints, the release includes logs, code, and\ndownstream evaluations to simplify reproduction, standardize comparison, and\nfacilitate future research.", "AI": {"tldr": "The paper introduces 'open-sci-ref,' a set of dense transformer models trained across various scales and evaluated on open reference datasets to establish benchmarks for assessing training approaches in AI research.", "motivation": "To provide standardized benchmarks and reference baselines for evaluating training methodologies and datasets for dense transformer models in AI research.", "method": "Dense transformer models (0.13B\u20131.7B parameters) are trained on 8 open reference datasets at scales up to 1T tokens, using intermediate checkpoints and comparative evaluations on standardized benchmarks.", "result": "Training on NemoTron-CC HQ dataset outperforms others, followed by DCLM-baseline and FineWeb-Edu; the release includes training checkpoints, logs, code, and evaluations for standardized comparison.", "conclusion": "The paper establishes reproducible baselines for comparing dense transformer model training, enabling standardized assessments and highlighting the benefits of specific datasets like NemoTron-CC HQ."}}
{"id": "2509.08982", "pdf": "https://arxiv.org/pdf/2509.08982", "abs": "https://arxiv.org/abs/2509.08982", "authors": ["Karim Slimani", "Catherine Achard", "Brahim Tamadazte"], "title": "iMatcher: Improve matching in point cloud registration via local-to-global geometric consistency learning", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents iMatcher, a fully differentiable framework for feature\nmatching in point cloud registration. The proposed method leverages learned\nfeatures to predict a geometrically consistent confidence matrix, incorporating\nboth local and global consistency. First, a local graph embedding module leads\nto an initialization of the score matrix. A subsequent repositioning step\nrefines this matrix by considering bilateral source-to-target and\ntarget-to-source matching via nearest neighbor search in 3D space. The paired\npoint features are then stacked together to be refined through global geometric\nconsistency learning to predict a point-wise matching probability. Extensive\nexperiments on real-world outdoor (KITTI, KITTI-360) and indoor (3DMatch)\ndatasets, as well as on 6-DoF pose estimation (TUD-L) and partial-to-partial\nmatching (MVP-RG), demonstrate that iMatcher significantly improves rigid\nregistration performance. The method achieves state-of-the-art inlier ratios,\nscoring 95% - 97% on KITTI, 94% - 97% on KITTI-360, and up to 81.1% on 3DMatch,\nhighlighting its robustness across diverse settings.", "AI": {"tldr": "This paper introduces iMatcher, a framework using learned features for efficient and robust point cloud registration, achieving state-of-the-art results in various datasets.", "motivation": "To address the challenges in rigid point cloud registration by incorporating both local and global geometrically consistent feature matching.", "method": "iMatcher uses a local graph embedding module for score initialization, bilateral matching through nearest neighbors, and global geometric consistency learning to predict point-wise matching probabilities.", "result": "iMatcher showed significant performance improvements across outdoor and indoor datasets, achieving inlier ratios of 95%-97% on KITTI, 94%-97% on KITTI-360, and up to 81.1% on 3DMatch.", "conclusion": "The proposed method demonstrates robustness and significantly enhances feature matching for point cloud registration, establishing a new benchmark in inlier ratio performance."}}
{"id": "2509.09215", "pdf": "https://arxiv.org/pdf/2509.09215", "abs": "https://arxiv.org/abs/2509.09215", "authors": ["Qinnan Hu", "Yuntao Wang", "Yuan Gao", "Zhou Su", "Linkang Du"], "title": "Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions", "categories": ["cs.AI", "cs.CR"], "comment": "7 pages, 6 figures", "summary": "Large language models (LLMs)-empowered autonomous agents are transforming\nboth digital and physical environments by enabling adaptive, multi-agent\ncollaboration. While these agents offer significant opportunities across\ndomains such as finance, healthcare, and smart manufacturing, their\nunpredictable behaviors and heterogeneous capabilities pose substantial\ngovernance and accountability challenges. In this paper, we propose a\nblockchain-enabled layered architecture for regulatory agent collaboration,\ncomprising an agent layer, a blockchain data layer, and a regulatory\napplication layer. Within this framework, we design three key modules: (i) an\nagent behavior tracing and arbitration module for automated accountability,\n(ii) a dynamic reputation evaluation module for trust assessment in\ncollaborative scenarios, and (iii) a malicious behavior forecasting module for\nearly detection of adversarial activities. Our approach establishes a\nsystematic foundation for trustworthy, resilient, and scalable regulatory\nmechanisms in large-scale agent ecosystems. Finally, we discuss the future\nresearch directions for blockchain-enabled regulatory frameworks in multi-agent\nsystems.", "AI": {"tldr": "This paper explores a blockchain-enabled architecture to govern autonomous agents, focusing on accountability, trust, and malicious behavior detection in large-scale ecosystems.", "motivation": "Governance and accountability challenges arise from the unpredictable behavior and diverse capabilities of autonomous agents, necessitating a systematic framework for oversight.", "method": "The paper introduces a blockchain-enabled layered architecture with three modules: agent behavior tracing, dynamic reputation evaluation, and malicious behavior forecasting.", "result": "The framework establishes mechanisms for automating accountability, assessing trustworthiness, and detecting adversarial activities among agents.", "conclusion": "The proposed architecture paves the way for resilient and scalable regulatory systems in large-scale autonomous agent ecosystems and highlights future research opportunities."}}
{"id": "2509.09322", "pdf": "https://arxiv.org/pdf/2509.09322", "abs": "https://arxiv.org/abs/2509.09322", "authors": ["Jacopo Bufalino", "Agathe Blaise", "Stefano Secci"], "title": "ORCA: Unveiling Obscure Containers In The Wild", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Modern software development increasingly depends on open-source libraries and\nthird-party components, which are often encapsulated into containerized\nenvironments. While improving the development and deployment of applications,\nthis approach introduces security risks, particularly when outdated or\nvulnerable components are inadvertently included in production environments.\nSoftware Composition Analysis (SCA) is a critical process that helps identify\nand manage packages and dependencies inside a container. However, unintentional\nmodifications to the container filesystem can lead to incomplete container\nimages, which compromise the reliability of SCA tools. In this paper, we\nexamine the limitations of both cloud-based and open-source SCA tools when\nfaced with such obscure images. An analysis of 600 popular containers revealed\nthat obscure containers exist in well-known registries and trusted images and\nthat many tools fail to analyze such containers. To mitigate these issues, we\npropose an obscuration-resilient methodology for container analysis and\nintroduce ORCA (Obscuration-Resilient Container Analyzer), its open-source\nimplementation. We reported our findings to all vendors using their appropriate\nchannels. Our results demonstrate that ORCA effectively detects the content of\nobscure containers and achieves a median 40% improvement in file coverage\ncompared to Docker Scout and Syft.", "AI": {"tldr": "This paper highlights the security risks in containerized environments due to outdated or modified components and proposes ORCA, a tool to improve file analysis in obscure containers.", "motivation": "To address the security risks posed by outdated or unintentionally modified components in containerized environments, which can compromise Software Composition Analysis (SCA) tools.", "method": "The authors analyzed 600 popular containers to assess the limitations of cloud-based and open-source SCA tools. They developed ORCA, an obscuration-resilient methodology and open-source implementation for container analysis.", "result": "The study revealed the presence of obscure containers in well-known registries and showed that many SCA tools fail to analyze these. ORCA achieved a median 40% improvement in file coverage compared to Docker Scout and Syft.", "conclusion": "ORCA provides an effective solution for detecting content in obscure containers, enhancing the reliability of SCA tools and mitigating security risks in containerized environments."}}
{"id": "2509.09125", "pdf": "https://arxiv.org/pdf/2509.09125", "abs": "https://arxiv.org/abs/2509.09125", "authors": ["Liqun He", "Jiaqi Xu"], "title": "Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication in the journal Reflecting Digital Learning.\n  First submitted: 30 Oct 2023. The final version will be available open access\n  via the journal", "summary": "This study explores the use of generative AI for automating the\nclassification of tutors' Dialogue Acts (DAs), aiming to reduce the time and\neffort required by traditional manual coding. This case study uses the\nopen-source CIMA corpus, in which tutors' responses are pre-annotated into four\nDA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored\nprompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of\n0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and\nindicating substantial agreement with human annotations. These findings suggest\nthat generative AI has strong potential to provide an efficient and accessible\napproach to DA classification, with meaningful implications for educational\ndialogue analysis. The study also highlights the importance of task-specific\nlabel definitions and contextual information in enhancing the quality of\nautomated annotation. Finally, it underscores the ethical considerations\nassociated with the use of generative AI and the need for responsible and\ntransparent research practices. The script of this research is publicly\navailable at\nhttps://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.", "AI": {"tldr": "This study examines the use of generative AI (GPT-3.5-turbo and GPT-4) for classifying tutors' Dialogue Acts (DAs), achieving high accuracy and substantial agreement with human annotation in the educational context.", "motivation": "The study aims to reduce the manual effort involved in coding tutors' Dialogue Acts by exploring automated approaches with generative AI models, thus enhancing efficiency and accessibility in educational dialogue analysis.", "method": "Generative AI models GPT-3.5-turbo and GPT-4 were applied to the open-source CIMA corpus using tailored prompts for classifying pre-annotated tutors' Dialogue Act categories. Metrics like accuracy, F1-score, and Cohen's Kappa were used to evaluate performance.", "result": "GPT-4 showed the best performance, achieving 80% accuracy, a weighted F1-score of 0.81, and a Cohen's Kappa of 0.74, outperforming baseline measures and demonstrating a high level of agreement with human annotations.", "conclusion": "Generative AI reveals strong potential for automating DA classification with high efficiency and accuracy. The study emphasizes the importance of clear label definitions and context while considering ethical implications in AI research practices."}}
{"id": "2509.09372", "pdf": "https://arxiv.org/pdf/2509.09372", "abs": "https://arxiv.org/abs/2509.09372", "authors": ["Yihao Wang", "Pengxiang Ding", "Lingxiao Li", "Can Cui", "Zirui Ge", "Xinyang Tong", "Wenxuan Song", "Han Zhao", "Wei Zhao", "Pengxu Hou", "Siteng Huang", "Yifan Tang", "Wenhui Wang", "Ru Zhang", "Jianyi Liu", "Donglin Wang"], "title": "VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models typically bridge the gap between\nperceptual and action spaces by pre-training a large-scale Vision-Language\nModel (VLM) on robotic data. While this approach greatly enhances performance,\nit also incurs significant training costs. In this paper, we investigate how to\neffectively bridge vision-language (VL) representations to action (A). We\nintroduce VLA-Adapter, a novel paradigm designed to reduce the reliance of VLA\nmodels on large-scale VLMs and extensive pre-training. To this end, we first\nsystematically analyze the effectiveness of various VL conditions and present\nkey findings on which conditions are essential for bridging perception and\naction spaces. Based on these insights, we propose a lightweight Policy module\nwith Bridge Attention, which autonomously injects the optimal condition into\nthe action space. In this way, our method achieves high performance using only\na 0.5B-parameter backbone, without any robotic data pre-training. Extensive\nexperiments on both simulated and real-world robotic benchmarks demonstrate\nthat VLA-Adapter not only achieves state-of-the-art level performance, but also\noffers the fast inference speed reported to date. Furthermore, thanks to the\nproposed advanced bridging paradigm, VLA-Adapter enables the training of a\npowerful VLA model in just 8 hours on a single consumer-grade GPU, greatly\nlowering the barrier to deploying the VLA model. Project page:\nhttps://vla-adapter.github.io/.", "AI": {"tldr": "The paper introduces VLA-Adapter, a method that reduces dependency on large-scale vision-language models for robotic applications, achieving high performance without extensive pre-training.", "motivation": "To address the high training costs and dependency on large-scale Vision-Language Models (VLMs) when bridging vision-language representations to robotic actions.", "method": "The authors propose VLA-Adapter, which includes a lightweight Policy module with Bridge Attention that autonomously optimizes conditions needed for action space. This eliminates the need for pre-training on robotic data and uses a smaller model backbone.", "result": "Experiments show that VLA-Adapter achieves state-of-the-art performance on simulated and real-world robotic benchmarks with fast inference speed and minimal training requirements.", "conclusion": "VLA-Adapter reduces barriers to deploying Vision-Language-Action models by enabling training on a consumer-grade GPU within 8 hours while maintaining high performance, making it accessible for broader use."}}
{"id": "2509.09030", "pdf": "https://arxiv.org/pdf/2509.09030", "abs": "https://arxiv.org/abs/2509.09030", "authors": ["Spencer King", "Zhilu Zhang", "Ruofan Yu", "Baris Coskun", "Wei Ding", "Qian Cui"], "title": "Deep Context-Conditioned Anomaly Detection for Tabular Data", "categories": ["cs.LG"], "comment": "Submitted to WSDM 2026. 11 pages, 4 figures, 5 tables, 1 algorithm, 8\n  datasets, contextual anomaly detection framework for tabular data", "summary": "Anomaly detection is critical in domains such as cybersecurity and finance,\nespecially when working with large-scale tabular data. Yet, unsupervised\nanomaly detection -- where no labeled anomalies are available -- remains a\nsignificant challenge. Although various deep learning methods have been\nproposed to model a dataset's joint distribution, real-world tabular data often\ncontain heterogeneous contexts (e.g., different users), making globally rare\nevents normal under certain contexts. Consequently, relying on a single global\ndistribution can overlook these contextual nuances, degrading detection\nperformance. In this paper, we present a context-conditional anomaly detection\nframework tailored for tabular datasets. Our approach automatically identifies\ncontext features and models the conditional data distribution using a simple\ndeep autoencoder. Extensive experiments on multiple tabular benchmark datasets\ndemonstrate that our method outperforms state-of-the-art approaches,\nunderscoring the importance of context in accurately distinguishing anomalous\nfrom normal instances.", "AI": {"tldr": "The paper proposes a context-sensitive deep learning framework for unsupervised anomaly detection in tabular data, achieving superior results through context-aware modeling.", "motivation": "To address the challenge of detecting anomalies in real-world tabular datasets where global rarity might not indicate abnormality due to heterogeneous contexts.", "method": "The method automatically identifies contextual features in the data and uses a deep autoencoder to model the conditional distributions based on these contexts.", "result": "The proposed framework outperforms state-of-the-art methods on multiple tabular benchmark datasets, demonstrating improved anomaly detection accuracy.", "conclusion": "Considering contextual information significantly enhances anomaly detection in tabular datasets, supporting the utility of the proposed context-conditional framework."}}
{"id": "2509.08991", "pdf": "https://arxiv.org/pdf/2509.08991", "abs": "https://arxiv.org/abs/2509.08991", "authors": ["Magdalena Wysocki", "Felix Duelmer", "Ananya Bal", "Nassir Navab", "Mohammad Farid Azampour"], "title": "UltrON: Ultrasound Occupancy Networks", "categories": ["cs.CV"], "comment": "MICCAI 2025", "summary": "In free-hand ultrasound imaging, sonographers rely on expertise to mentally\nintegrate partial 2D views into 3D anatomical shapes. Shape reconstruction can\nassist clinicians in this process. Central to this task is the choice of shape\nrepresentation, as it determines how accurately and efficiently the structure\ncan be visualized, analyzed, and interpreted. Implicit representations, such as\nSDF and occupancy function, offer a powerful alternative to traditional voxel-\nor mesh-based methods by modeling continuous, smooth surfaces with compact\nstorage, avoiding explicit discretization. Recent studies demonstrate that SDF\ncan be effectively optimized using annotations derived from segmented B-mode\nultrasound images. Yet, these approaches hinge on precise annotations,\noverlooking the rich acoustic information embedded in B-mode intensity.\nMoreover, implicit representation approaches struggle with the ultrasound's\nview-dependent nature and acoustic shadowing artifacts, which impair\nreconstruction. To address the problems resulting from occlusions and\nannotation dependency, we propose an occupancy-based representation and\nintroduce \\gls{UltrON} that leverages acoustic features to improve geometric\nconsistency in weakly-supervised optimization regime. We show that these\nfeatures can be obtained from B-mode images without additional annotation cost.\nMoreover, we propose a novel loss function that compensates for view-dependency\nin the B-mode images and facilitates occupancy optimization from multiview\nultrasound. By incorporating acoustic properties, \\gls{UltrON} generalizes to\nshapes of the same anatomy. We show that \\gls{UltrON} mitigates the limitations\nof occlusions and sparse labeling and paves the way for more accurate 3D\nreconstruction. Code and dataset will be available at\nhttps://github.com/magdalena-wysocki/ultron.", "AI": {"tldr": "The paper introduces UltrON, an occupancy-based representation model utilizing acoustic features to enhance 3D ultrasound shape reconstruction.", "motivation": "Sonographers struggle to mentally integrate 2D ultrasound images into 3D shapes, compounded by issues like occlusions and annotation dependency.", "method": "UltrON leverages acoustic features from B-mode ultrasound images in a weakly-supervised regime and uses a novel loss function addressing view-dependency.", "result": "The approach improves geometric consistency, mitigates issues from occlusions, annotation reliance, and generalizes across the same anatomy.", "conclusion": "UltrON enables more accurate 3D reconstructions in ultrasound imaging, benefiting sonographers and the broader medical field, with open-source code forthcoming."}}
{"id": "2509.09245", "pdf": "https://arxiv.org/pdf/2509.09245", "abs": "https://arxiv.org/abs/2509.09245", "authors": ["Shuocheng Li", "Yihao Liu", "Silin Du", "Wenxuan Zeng", "Zhe Xu", "Mengyu Zhou", "Yeye He", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown great promise in automating data\nscience workflows, but existing models still struggle with multi-step reasoning\nand tool use, which limits their effectiveness on complex data analysis tasks.\nTo address this, we propose a scalable pipeline that extracts high-quality,\ntool-based data analysis tasks and their executable multi-step solutions from\nreal-world Jupyter notebooks and associated data files. Using this pipeline, we\nintroduce NbQA, a large-scale dataset of standardized task-solution pairs that\nreflect authentic tool-use patterns in practical data science scenarios. To\nfurther enhance multi-step reasoning, we present Jupiter, a framework that\nformulates data analysis as a search problem and applies Monte Carlo Tree\nSearch (MCTS) to generate diverse solution trajectories for value model\nlearning. During inference, Jupiter combines the value model and node visit\ncounts to efficiently collect executable multi-step plans with minimal search\nsteps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on\nNbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench,\nrespectively-matching or surpassing GPT-4o and advanced agent frameworks.\nFurther evaluations demonstrate improved generalization and stronger tool-use\nreasoning across diverse multi-step reasoning tasks.", "AI": {"tldr": "The paper introduces a customizable pipeline to extract complex data analysis tasks and solutions, forms a dataset called NbQA, and presents the Jupiter framework to enhance tool-use reasoning in LLMs for data science.", "motivation": "Existing large language models struggle with multi-step reasoning and tool usage in data analysis. The paper aims to overcome these limitations by improving tool-use proficiency in complex data tasks.", "method": "The authors developed a pipeline to gather task-solution pairs from Jupyter notebooks (NbQA dataset) and introduced the Jupiter framework, which uses Monte Carlo Tree Search (MCTS) to generate and learn diverse solution paths for multi-step plans.", "result": "Their methods enable models like Qwen2.5-7B and 14B-Instruct to achieve high accuracy (77.82% and 86.38%, respectively) on data analysis benchmark InfiAgent-DABench, outperforming or matching other advanced models such as GPT-4o.", "conclusion": "NbQA and Jupiter improve the scalability and practical application of LLMs in real-world data science scenarios, particularly excelling in multi-step reasoning and tool-use tasks."}}
{"id": "2509.09614", "pdf": "https://arxiv.org/pdf/2509.09614", "abs": "https://arxiv.org/abs/2509.09614", "authors": ["Jielin Qiu", "Zuxin Liu", "Zhiwei Liu", "Rithesh Murthy", "Jianguo Zhang", "Haolin Chen", "Shiyu Wang", "Ming Zhu", "Liangwei Yang", "Juntao Tan", "Zhepeng Cen", "Cheng Qian", "Shelby Heinecke", "Weiran Yao", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": "53 pages", "summary": "The emergence of long-context language models with context windows extending\nto millions of tokens has created new opportunities for sophisticated code\nunderstanding and software development evaluation. We propose LoCoBench, a\ncomprehensive benchmark specifically designed to evaluate long-context LLMs in\nrealistic, complex software development scenarios. Unlike existing code\nevaluation benchmarks that focus on single-function completion or short-context\ntasks, LoCoBench addresses the critical evaluation gap for long-context\ncapabilities that require understanding entire codebases, reasoning across\nmultiple files, and maintaining architectural consistency across large-scale\nsoftware systems. Our benchmark provides 8,000 evaluation scenarios\nsystematically generated across 10 programming languages, with context lengths\nspanning 10K to 1M tokens, a 100x variation that enables precise assessment of\nlong-context performance degradation in realistic software development\nsettings. LoCoBench introduces 8 task categories that capture essential\nlong-context capabilities: architectural understanding, cross-file refactoring,\nmulti-session development, bug investigation, feature implementation, code\ncomprehension, integration testing, and security analysis. Through a 5-phase\npipeline, we create diverse, high-quality scenarios that challenge LLMs to\nreason about complex codebases at unprecedented scale. We introduce a\ncomprehensive evaluation framework with 17 metrics across 4 dimensions,\nincluding 8 new evaluation metrics, combined in a LoCoBench Score (LCBS). Our\nevaluation of state-of-the-art long-context models reveals substantial\nperformance gaps, demonstrating that long-context understanding in complex\nsoftware development represents a significant unsolved challenge that demands\nmore attention. LoCoBench is released at:\nhttps://github.com/SalesforceAIResearch/LoCoBench.", "AI": {"tldr": "LoCoBench introduces a benchmark to evaluate the performance of long-context language models in managing complex software development scenarios, emphasizing the unique challenges of understanding extensive codebases.", "motivation": "Existing benchmarks inadequately address the evaluation needs for long-context capabilities in software scenarios, where reasoning across large-scale systems is crucial.", "method": "LoCoBench generates 8,000 scenarios across 10 programming languages with context lengths between 10K and 1M tokens, assessing 8 task categories. It employs a 5-phase pipeline and introduces 17 metrics combined into the LoCoBench Score.", "result": "State-of-the-art models exhibit significant performance gaps, highlighting the challenge of developing long-context understanding in extensive software systems.", "conclusion": "LoCoBench fills a critical gap in benchmarking for long-context models, urging further innovation in this challenging area of AI development."}}
{"id": "2509.09131", "pdf": "https://arxiv.org/pdf/2509.09131", "abs": "https://arxiv.org/abs/2509.09131", "authors": ["Phuong-Nam Dang", "Kieu-Linh Nguyen", "Thanh-Hieu Pham"], "title": "ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages", "summary": "This paper presents ViRanker, a cross-encoder reranking model tailored to the\nVietnamese language. Built on the BGE-M3 encoder and enhanced with the\nBlockwise Parallel Transformer, ViRanker addresses the lack of competitive\nrerankers for Vietnamese, a low-resource language with complex syntax and\ndiacritics. The model was trained on an 8 GB curated corpus and fine-tuned with\nhybrid hard-negative sampling to strengthen robustness. Evaluated on the\nMMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing\nmultilingual baselines and competing closely with PhoRanker. By releasing the\nmodel openly on Hugging Face, we aim to support reproducibility and encourage\nwider adoption in real-world retrieval systems. Beyond Vietnamese, this study\nillustrates how careful architectural adaptation and data curation can advance\nreranking in other underrepresented languages.", "AI": {"tldr": "ViRanker is a Vietnamese cross-encoder reranking model outperforming multilingual models on MMARCO-VI by leveraging the BGE-M3 encoder and curated training methods.", "motivation": "Address the lack of effective reranking models for Vietnamese, a low-resource language.", "method": "Developed using the BGE-M3 encoder, Blockwise Parallel Transformer, and trained on an 8 GB corpus with hybrid hard-negative sampling.", "result": "ViRanker surpasses multilingual baselines and competes with PhoRanker in early-rank accuracy on MMARCO-VI.", "conclusion": "ViRanker advances Vietnamese retrieval systems and demonstrates methods for improving low-resource language support."}}
{"id": "2509.09404", "pdf": "https://arxiv.org/pdf/2509.09404", "abs": "https://arxiv.org/abs/2509.09404", "authors": ["Tongshun Chen", "Zezhou Sun", "Yanhan Sun", "Yuhao Wang", "Dezhen Song", "Ke Wu"], "title": "A Hybrid Hinge-Beam Continuum Robot with Passive Safety Capping for Real-Time Fatigue Awareness", "categories": ["cs.RO"], "comment": null, "summary": "Cable-driven continuum robots offer high flexibility and lightweight design,\nmaking them well-suited for tasks in constrained and unstructured environments.\nHowever, prolonged use can induce mechanical fatigue from plastic deformation\nand material degradation, compromising performance and risking structural\nfailure. In the state of the art, fatigue estimation of continuum robots\nremains underexplored, limiting long-term operation. To address this, we\npropose a fatigue-aware continuum robot with three key innovations: (1) a\nHybrid Hinge-Beam structure where TwistBeam and BendBeam decouple torsion and\nbending: passive revolute joints in the BendBeam mitigate stress concentration,\nwhile TwistBeam's limited torsional deformation reduces BendBeam stress\nmagnitude, enhancing durability; (2) a Passive Stopper that safely constrains\nmotion via mechanical constraints and employs motor torque sensing to detect\ncorresponding limit torque, ensuring safety and enabling data collection; and\n(3) a real-time fatigue-awareness method that estimates stiffness from motor\ntorque at the limit pose, enabling online fatigue estimation without additional\nsensors. Experiments show that the proposed design reduces fatigue accumulation\nby about 49% compared with a conventional design, while passive mechanical\nlimiting combined with motor-side sensing allows accurate estimation of\nstructural fatigue and damage. These results confirm the effectiveness of the\nproposed architecture for safe and reliable long-term operation.", "AI": {"tldr": "This paper introduces a fatigue-aware design for continuum robots, addressing durability and safety limitations in current models.", "motivation": "Existing continuum robots lack effective fatigue estimation, limiting their long-term operational reliability, especially under mechanical stress and material degradation.", "method": "The authors propose innovations including a Hybrid Hinge-Beam structure for stress mitigation, a Passive Stopper for safety and data collection, and a real-time fatigue estimation method using motor torque analysis.", "result": "Experiments demonstrate a 49% reduction in fatigue accumulation and accurate fatigue estimation using their proposed design.", "conclusion": "The proposed architecture enhances durability and safety of continuum robots, supporting reliable long-term operation."}}
{"id": "2509.09052", "pdf": "https://arxiv.org/pdf/2509.09052", "abs": "https://arxiv.org/abs/2509.09052", "authors": ["Dibyajyoti Chakraborty", "Romit Maulik", "Peter Harrington", "Dallas Foster", "Mohammad Amin Nabian", "Sanjay Choudhry"], "title": "MoWE : A Mixture of Weather Experts", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "physics.geo-ph"], "comment": null, "summary": "Data-driven weather models have recently achieved state-of-the-art\nperformance, yet progress has plateaued in recent years. This paper introduces\na Mixture of Experts (MoWE) approach as a novel paradigm to overcome these\nlimitations, not by creating a new forecaster, but by optimally combining the\noutputs of existing models. The MoWE model is trained with significantly lower\ncomputational resources than the individual experts. Our model employs a Vision\nTransformer-based gating network that dynamically learns to weight the\ncontributions of multiple \"expert\" models at each grid point, conditioned on\nforecast lead time. This approach creates a synthesized deterministic forecast\nthat is more accurate than any individual component in terms of Root Mean\nSquared Error (RMSE). Our results demonstrate the effectiveness of this method,\nachieving up to a 10% lower RMSE than the best-performing AI weather model on a\n2-day forecast horizon, significantly outperforming individual experts as well\nas a simple average across experts. This work presents a computationally\nefficient and scalable strategy to push the state of the art in data-driven\nweather prediction by making the most out of leading high-quality forecast\nmodels.", "AI": {"tldr": "This paper presents a Mixture of Experts (MoWE) approach to improve weather forecasting by optimally combining outputs from existing models, achieving up to 10% lower RMSE compared to the best AI weather model.", "motivation": "Current data-driven weather models have reached a performance plateau, necessitating innovative methods to boost forecasting accuracy without excessive computational demands.", "method": "The MoWE model employs a Vision Transformer-based gating network that dynamically optimizes the contribution of multiple expert models at each grid point, conditioned on forecast lead time.", "result": "MoWE achieves up to 10% lower RMSE compared to the best-performing AI weather model and significantly outperforms both individual experts and simple averages over a 2-day forecast horizon.", "conclusion": "The MoWE approach offers a computationally efficient and scalable framework for enhancing weather prediction, making optimal use of existing high-quality forecast models."}}
{"id": "2509.09004", "pdf": "https://arxiv.org/pdf/2509.09004", "abs": "https://arxiv.org/abs/2509.09004", "authors": ["Andrew Bell", "Yan Kit Choi", "Steffen Peterson", "Andrew King", "Muhummad Sohaib Nazir", "Alistair Young"], "title": "Implicit Neural Representations of Intramyocardial Motion and Strain", "categories": ["cs.CV", "cs.AI"], "comment": "STACOM 2025 @ MICCAI", "summary": "Automatic quantification of intramyocardial motion and strain from tagging\nMRI remains an important but challenging task. We propose a method using\nimplicit neural representations (INRs), conditioned on learned latent codes, to\npredict continuous left ventricular (LV) displacement -- without requiring\ninference-time optimisation. Evaluated on 452 UK Biobank test cases, our method\nachieved the best tracking accuracy (2.14 mm RMSE) and the lowest combined\nerror in global circumferential (2.86%) and radial (6.42%) strain compared to\nthree deep learning baselines. In addition, our method is $\\sim$380$\\times$\nfaster than the most accurate baseline. These results highlight the suitability\nof INR-based models for accurate and scalable analysis of myocardial strain in\nlarge CMR datasets.", "AI": {"tldr": "The study proposes an implicit neural representation (INR) based method for precise and fast left ventricular motion and strain analysis from tagged MRI data.", "motivation": "To address challenges in automating intramyocardial motion and strain quantification from tagging MRI, which is crucial for analyzing left ventricular dynamics.", "method": "The proposed method employs implicit neural representations (INRs) conditioned on learned latent codes, eliminating the need for inference-time optimization.", "result": "The method achieved the best tracking accuracy (2.14 mm RMSE) and lowest strain errors (global circumferential: 2.86%, radial: 6.42%). It is about 380 times faster than the most accurate baseline method.", "conclusion": "INR-based models offer accurate, efficient, and scalable solutions for myocardial strain analysis, making them suitable for large CMR datasets."}}
{"id": "2509.09272", "pdf": "https://arxiv.org/pdf/2509.09272", "abs": "https://arxiv.org/abs/2509.09272", "authors": ["Vaibhav Chaudhary", "Neha Soni", "Narotam Singh", "Amita Kapoor"], "title": "Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs", "categories": ["cs.AI"], "comment": "46 pages, 4 figures, 17 tables", "summary": "Knowledge graphs, a powerful tool for structuring information through\nrelational triplets, have recently become the new front-runner in enhancing\nquestion-answering systems. While traditional Retrieval Augmented Generation\n(RAG) approaches are proficient in fact-based and local context-based\nextraction from concise texts, they encounter limitations when addressing the\nthematic and holistic understanding of complex, extensive texts, requiring a\ndeeper analysis of both text and context. This paper presents a comprehensive\ntechnical comparative study of three different methodologies for constructing\nknowledge graph triplets and integrating them with Large Language Models (LLMs)\nfor question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all\nleveraging open source technologies. We evaluate the effectiveness,\nfeasibility, and adaptability of these methods by analyzing their capabilities,\nstate of development, and their impact on the performance of LLM-based question\nanswering. Experimental results indicate that while OpenIE provides the most\ncomprehensive coverage of triplets, GraphRAG demonstrates superior reasoning\nabilities among the three. We conclude with a discussion on the strengths and\nlimitations of each method and provide insights into future directions for\nimproving knowledge graph-based question answering.", "AI": {"tldr": "The paper evaluates three methods (spaCy, OpenIE, GraphRAG) for integrating knowledge graphs with LLMs for question answering, highlighting GraphRAG's reasoning capabilities and OpenIE's comprehensive triplet coverage.", "motivation": "Current Retrieval Augmented Generation systems struggle to provide thematic and holistic insights into complex texts. The study aims to address these limitations by combining knowledge graphs with LLMs.", "method": "The study conducts a comparative analysis of three open-source tools (spaCy, OpenIE, GraphRAG) for constructing knowledge graph triplets and integrating them with LLMs. It assesses their feasibility, adaptability, and impact on performance.", "result": "OpenIE offers the highest triplet coverage, while GraphRAG excels in reasoning capabilities for LLM-based question answering. Experimental results highlight the performance differences among the methods.", "conclusion": "Each method has distinct strengths and limitations, and the study proposes insights into advancing knowledge graph-based question answering systems for complex text analysis."}}
{"id": "2509.09630", "pdf": "https://arxiv.org/pdf/2509.09630", "abs": "https://arxiv.org/abs/2509.09630", "authors": ["Zhenguang Liu", "Lixun Ma", "Zhongzheng Mu", "Chengkun Wei", "Xiaojun Xu", "Yingying Jiao", "Kui Ren"], "title": "I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Widespread reuse of open-source code in smart contract development boosts\nprogramming efficiency but significantly amplifies bug propagation across\ncontracts, while dedicated methods for detecting similar smart contract\nfunctions remain very limited. Conventional abstract-syntax-tree (AST) based\nmethods for smart contract similarity detection face challenges in handling\nintricate tree structures, which impedes detailed semantic comparison of code.\nRecent deep-learning based approaches tend to overlook code syntax and\ndetection interpretability, resulting in suboptimal performance.\n  To fill this research gap, we introduce SmartDetector, a novel approach for\ncomputing similarity between smart contract functions, explainable at the\nfine-grained statement level. Technically, SmartDetector decomposes the AST of\na smart contract function into a series of smaller statement trees, each\nreflecting a structural element of the source code. Then, SmartDetector uses a\nclassifier to compute the similarity score of two functions by comparing each\npair of their statement trees. To address the infinite hyperparameter space of\nthe classifier, we mathematically derive a cosine-wise diffusion process to\nefficiently search optimal hyperparameters. Extensive experiments conducted on\nthree large real-world datasets demonstrate that SmartDetector outperforms\ncurrent state-of-the-art methods by an average improvement of 14.01% in\nF1-score, achieving an overall average F1-score of 95.88%.", "AI": {"tldr": "SmartDetector is introduced to improve smart contract similarity detection by focusing on fine-grained statement-level analysis, significantly outperforming prior methods.", "motivation": "To address the challenges of bug propagation due to open-source reuse in smart contracts and the limitations of AST-based and deep-learning approaches in code similarity detection.", "method": "SmartDetector decomposes the AST of smart contract functions into smaller statement trees and uses a classifier for similarity scoring. A cosine-wise diffusion process minimizes hyperparameter space.", "result": "SmartDetector achieves an average F1-score of 95.88%, outperforming existing methods by 14.01% on three large real-world datasets.", "conclusion": "SmartDetector effectively provides interpretable, fine-grained similarity detection for smart contract functions, improving upon both conventional and deep-learning methods."}}
{"id": "2509.09484", "pdf": "https://arxiv.org/pdf/2509.09484", "abs": "https://arxiv.org/abs/2509.09484", "authors": ["Peng Zhou", "Jiaming Qi", "Hongmin Wu", "Chen Wang", "Yizhou Chen", "Zeqing Zhang"], "title": "BagIt! An Adaptive Dual-Arm Manipulation of Fabric Bags for Object Bagging", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Bagging tasks, commonly found in industrial scenarios, are challenging\nconsidering deformable bags' complicated and unpredictable nature. This paper\npresents an automated bagging system from the proposed adaptive\nStructure-of-Interest (SOI) manipulation strategy for dual robot arms. The\nsystem dynamically adjusts its actions based on real-time visual feedback,\nremoving the need for pre-existing knowledge of bag properties. Our framework\nincorporates Gaussian Mixture Models (GMM) for estimating SOI states,\noptimization techniques for SOI generation, motion planning via Constrained\nBidirectional Rapidly-exploring Random Tree (CBiRRT), and dual-arm coordination\nusing Model Predictive Control (MPC). Extensive experiments validate the\ncapability of our system to perform precise and robust bagging across various\nobjects, showcasing its adaptability. This work offers a new solution for\nrobotic deformable object manipulation (DOM), particularly in automated bagging\ntasks. Video of this work is available at https://youtu.be/6JWjCOeTGiQ.", "AI": {"tldr": "The paper proposes a novel dual-robot bagging system using adaptive strategies, visual feedback, and advanced models to handle deformable bags without prior knowledge of bag properties.", "motivation": "Automating complex bagging tasks in industrial settings is challenging due to the unpredictable nature of deformable objects like bags. Current systems struggle without pre-existing data on the properties of these objects.", "method": "The system uses an adaptive Structure-of-Interest (SOI) manipulation strategy. Techniques include Gaussian Mixture Models (GMM) for state estimation, Constrained Bidirectional RRTree (CBiRRT) for motion planning, and dual-arm coordination with Model Predictive Control (MPC), all guided by real-time visual feedback.", "result": "Experiments show the system can reliably and accurately perform bagging tasks for various objects, demonstrating its adaptability and robustness.", "conclusion": "The paper introduces a new approach for robotic manipulation of deformable objects, pushing the boundaries of innovation in automated bagging systems."}}
{"id": "2509.09053", "pdf": "https://arxiv.org/pdf/2509.09053", "abs": "https://arxiv.org/abs/2509.09053", "authors": ["Julian Oelhaf", "Georg Kordowich", "Mehran Pashaei", "Christian Bergler", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "A Scoping Review of Machine Learning Applications in Power System Protection and Disturbance Management", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "The integration of renewable and distributed energy resources reshapes modern\npower systems, challenging conventional protection schemes. This scoping review\nsynthesizes recent literature on machine learning (ML) applications in power\nsystem protection and disturbance management, following the PRISMA for Scoping\nReviews framework. Based on over 100 publications, three key objectives are\naddressed: (i) assessing the scope of ML research in protection tasks; (ii)\nevaluating ML performance across diverse operational scenarios; and (iii)\nidentifying methods suitable for evolving grid conditions. ML models often\ndemonstrate high accuracy on simulated datasets; however, their performance\nunder real-world conditions remains insufficiently validated. The existing\nliterature is fragmented, with inconsistencies in methodological rigor, dataset\nquality, and evaluation metrics. This lack of standardization hampers the\ncomparability of results and limits the generalizability of findings. To\naddress these challenges, this review introduces a ML-oriented taxonomy for\nprotection tasks, resolves key terminological inconsistencies, and advocates\nfor standardized reporting practices. It further provides guidelines for\ncomprehensive dataset documentation, methodological transparency, and\nconsistent evaluation protocols, aiming to improve reproducibility and enhance\nthe practical relevance of research outcomes. Critical gaps remain, including\nthe scarcity of real-world validation, insufficient robustness testing, and\nlimited consideration of deployment feasibility. Future research should\nprioritize public benchmark datasets, realistic validation methods, and\nadvanced ML architectures. These steps are essential to move ML-based\nprotection from theoretical promise to practical deployment in increasingly\ndynamic and decentralized power systems.", "AI": {"tldr": "This review examines machine learning's role in modern power system protection and disturbance management, highlighting gaps in real-world validation and methodological consistency.", "motivation": "The paper is motivated by the need to address challenges in modern power systems caused by the integration of renewable and distributed energy resources, which conventional protection schemes struggle to handle.", "method": "Using the PRISMA for Scoping Reviews framework, the authors synthesize findings from over 100 publications, propose a taxonomy for ML applications in protection tasks, and advocate for standardized reporting and evaluation practices.", "result": "The study finds that while ML models excel in simulated scenarios, their real-world performance remains unvalidated. It also identifies critical issues like fragmented literature, inconsistent methods, and lack of standardization.", "conclusion": "The paper concludes that standardization, real-world validation, and advanced ML techniques are vital for transitioning ML-based protection systems from theoretical research to practical application in dynamic power grids."}}
{"id": "2509.09006", "pdf": "https://arxiv.org/pdf/2509.09006", "abs": "https://arxiv.org/abs/2509.09006", "authors": ["Samuel Felipe dos Santos", "Tiago Agostinho de Almeida", "Jurandy Almeida"], "title": "E-MLNet: Enhanced Mutual Learning for Universal Domain Adaptation with Sample-Specific Weighting", "categories": ["cs.CV"], "comment": null, "summary": "Universal Domain Adaptation (UniDA) seeks to transfer knowledge from a\nlabeled source to an unlabeled target domain without assuming any relationship\nbetween their label sets, requiring models to classify known samples while\nrejecting unknown ones. Advanced methods like Mutual Learning Network (MLNet)\nuse a bank of one-vs-all classifiers adapted via Open-set Entropy Minimization\n(OEM). However, this strategy treats all classifiers equally, diluting the\nlearning signal. We propose the Enhanced Mutual Learning Network (E-MLNet),\nwhich integrates a dynamic weighting strategy to OEM. By leveraging the\nclosed-set classifier's predictions, E-MLNet focuses adaptation on the most\nrelevant class boundaries for each target sample, sharpening the distinction\nbetween known and unknown classes. We conduct extensive experiments on four\nchallenging benchmarks: Office-31, Office-Home, VisDA-2017, and ImageCLEF. The\nresults demonstrate that E-MLNet achieves the highest average H-scores on VisDA\nand ImageCLEF and exhibits superior robustness over its predecessor. E-MLNet\noutperforms the strong MLNet baseline in the majority of individual adaptation\ntasks -- 22 out of 31 in the challenging Open-Partial DA setting and 19 out of\n31 in the Open-Set DA setting -- confirming the benefits of our focused\nadaptation strategy.", "AI": {"tldr": "Enhanced Mutual Learning Network (E-MLNet) improves universal domain adaptation using dynamic weighting for better classification of known and unknown classes.", "motivation": "Address limitations in universal domain adaptation methods by refining how classifiers distinguish between known and unknown classes.", "method": "E-MLNet integrates a dynamic weighting strategy into Open-set Entropy Minimization (OEM), leveraging predictions to focus adaptation on relevant class boundaries.", "result": "E-MLNet achieved top average H-scores on VisDA and ImageCLEF and surpassed MLNet in most adaptation tasks across benchmarks.", "conclusion": "The dynamic weighting approach sharpens class boundary adaptation, enhancing robustness and accuracy over previous methods."}}
{"id": "2509.09284", "pdf": "https://arxiv.org/pdf/2509.09284", "abs": "https://arxiv.org/abs/2509.09284", "authors": ["Bingning Huang", "Tu Nguyen", "Matthieu Zimmer"], "title": "Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in reasoning with large language models (LLMs) have shown the\neffectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality\nintermediate trajectories, particularly in math and symbolic domains. Inspired\nby this, we explore how MCTS-derived trajectories, traditionally used for\ntraining value or reward models, can be repurposed to improve policy\noptimization in preference-based reinforcement learning (RL). Specifically, we\nfocus on Group Relative Policy Optimization (GRPO), a recent algorithm that\nenables preference-consistent policy learning without value networks. We\npropose a staged GRPO training paradigm where completions are derived from\npartially revealed MCTS rollouts, introducing a novel tree-structured setting\nfor advantage estimation. This leads to a rich class of prefix-conditioned\nreward signals, which we analyze theoretically and empirically. Our initial\nresults indicate that while structured advantage estimation can stabilize\nupdates and better reflect compositional reasoning quality, challenges such as\nadvantage saturation and reward signal collapse remain. We propose heuristic\nand statistical solutions to mitigate these issues and discuss open challenges\nfor learning under staged or tree-like reward structures.", "AI": {"tldr": "This paper explores incorporating Monte Carlo Tree Search (MCTS)-derived trajectories into a staged training approach for improving policy optimization in preference-based reinforcement learning (RL), specifically using the GRPO algorithm.", "motivation": "To enhance policy optimization in preference-based RL by leveraging high-quality intermediate trajectories generated by MCTS, improving learning without relying on value networks.", "method": "Designs a staged GRPO training paradigm, integrating MCTS rollouts and introducing tree-structured advantage estimation to derive prefix-conditioned reward signals.", "result": "Finds that structured advantage estimation can stabilize updates and reflect improved reasoning quality but faces challenges like advantage saturation and reward signal collapse.", "conclusion": "The paper provides heuristic and statistical solutions for identified challenges and highlights open questions in using staged or tree-structured reward frameworks for RL learning."}}
{"id": "2509.09160", "pdf": "https://arxiv.org/pdf/2509.09160", "abs": "https://arxiv.org/abs/2509.09160", "authors": ["Zhiyue Liu", "Fanrong Ma", "Xin Ling"], "title": "Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by the IEEE International Conference on Multimedia and Expo\n  (ICME 2025). \\copyright\\ 2025 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses", "summary": "Target-oriented multimodal sentiment classification seeks to predict\nsentiment polarity for specific targets from image-text pairs. While existing\nworks achieve competitive performance, they often over-rely on textual content\nand fail to consider dataset biases, in particular word-level contextual\nbiases. This leads to spurious correlations between text features and output\nlabels, impairing classification accuracy. In this paper, we introduce a novel\ncounterfactual-enhanced debiasing framework to reduce such spurious\ncorrelations. Our framework incorporates a counterfactual data augmentation\nstrategy that minimally alters sentiment-related causal features, generating\ndetail-matched image-text samples to guide the model's attention toward content\ntied to sentiment. Furthermore, for learning robust features from\ncounterfactual data and prompting model decisions, we introduce an adaptive\ndebiasing contrastive learning mechanism, which effectively mitigates the\ninfluence of biased words. Experimental results on several benchmark datasets\nshow that our proposed method outperforms state-of-the-art baselines.", "AI": {"tldr": "The paper addresses a target-oriented multimodal sentiment classification issue, proposing a counterfactual-enhanced debiasing framework that reduces text-dataset biases.", "motivation": "Existing models for multimodal sentiment classification tend to over-rely on textual content without accounting for word-level contextual biases, leading to reduced classification accuracy.", "method": "The authors introduce counterfactual data augmentation to generate minimally altered image-text samples and adaptive debiasing contrastive learning to mitigate the impact of biased words.", "result": "Experimental results demonstrate that the proposed method surpasses the performance of state-of-the-art baselines on benchmark datasets.", "conclusion": "The counterfactual-enhanced framework effectively reduces biased influences and improves sentiment classification accuracy in multimodal targets."}}
{"id": "2509.09509", "pdf": "https://arxiv.org/pdf/2509.09509", "abs": "https://arxiv.org/abs/2509.09509", "authors": ["Pedro Miguel Bastos Soares", "Ali Tourani", "Miguel Fernandez-Cortizas", "Asier Bikandi Noya", "Jose Luis Sanchez-Lopez", "Holger Voos"], "title": "SMapper: A Multi-Modal Data Acquisition Platform for SLAM Benchmarking", "categories": ["cs.RO"], "comment": "12 pages, 6 figures, 5 tables", "summary": "Advancing research in fields like Simultaneous Localization and Mapping\n(SLAM) and autonomous navigation critically depends on reliable and\nreproducible multimodal datasets. While several influential datasets have\ndriven progress in these domains, they often suffer from limitations in sensing\nmodalities, environmental diversity, and the reproducibility of the underlying\nhardware setups. To address these challenges, this paper introduces SMapper, a\nnovel open-hardware, multi-sensor platform designed explicitly for, though not\nlimited to, SLAM research. The device integrates synchronized LiDAR,\nmulti-camera, and inertial sensing, supported by a robust calibration and\nsynchronization pipeline that ensures precise spatio-temporal alignment across\nmodalities. Its open and replicable design allows researchers to extend its\ncapabilities and reproduce experiments across both handheld and robot-mounted\nscenarios. To demonstrate its practicality, we additionally release\nSMapper-light, a publicly available SLAM dataset containing representative\nindoor and outdoor sequences. The dataset includes tightly synchronized\nmultimodal data and ground-truth trajectories derived from offline LiDAR-based\nSLAM with sub-centimeter accuracy, alongside dense 3D reconstructions.\nFurthermore, the paper contains benchmarking results on state-of-the-art LiDAR\nand visual SLAM frameworks using the SMapper-light dataset. By combining\nopen-hardware design, reproducible data collection, and comprehensive\nbenchmarking, SMapper establishes a robust foundation for advancing SLAM\nalgorithm development, evaluation, and reproducibility.", "AI": {"tldr": "The paper introduces SMapper, an open-hardware platform for SLAM research, and SMapper-light, a high-quality dataset, to address challenges in multimodal sensing, environmental diversity, and reproducibility.", "motivation": "Existing SLAM datasets often suffer from limitations in sensing modalities, environmental diversity, and hardware reproducibility, restricting progress in autonomous navigation and SLAM.", "method": "Develop an open-hardware multi-sensor platform (SMapper) with synchronized LiDAR, multi-camera, and inertial sensing, alongside robust calibration and a novel dataset (SMapper-light) for SLAM benchmarking.", "result": "The SMapper platform ensures precise spatio-temporal alignment of multimodal sensor data, releases a SLAM dataset (SMapper-light) with sub-centimeter accuracy, and demonstrates benchmarking results using state-of-the-art frameworks.", "conclusion": "SMapper offers researchers a reproducible, extensible platform and dataset for advancing SLAM algorithm development, evaluation, and reproducibility."}}
{"id": "2509.09014", "pdf": "https://arxiv.org/pdf/2509.09014", "abs": "https://arxiv.org/abs/2509.09014", "authors": ["Umair Hassan"], "title": "COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation", "categories": ["cs.CV", "cs.CL", "68T45 (Primary) 68T50 (Secondary)"], "comment": "17 pages, 3 figures, 3 tables. Dataset available at\n  https://huggingface.co/datasets/umairhassan02/urdu-translated-coco-captions-subset.\n  Scripts and notebooks to reproduce results available at\n  https://github.com/umair-hassan2/COCO-Urdu", "summary": "Urdu, spoken by over 250 million people, remains critically under-served in\nmultimodal and vision-language research. The absence of large-scale,\nhigh-quality datasets has limited the development of Urdu-capable systems and\nreinforced biases in multilingual vision-language models trained primarily on\nhigh-resource languages. To address this gap, we present COCO-Urdu, a\nlarge-scale image-caption dataset derived from MS COCO, containing 59,000\nimages and 319,000 Urdu captions selected through stratified sampling to\npreserve the original distribution. Captions were translated using SeamlessM4T\nv2 and validated with a hybrid multimodal quality estimation framework that\nintegrates COMET-Kiwi for translation quality, CLIP-based similarity for visual\ngrounding, and BERTScore with back-translation for semantic consistency;\nlow-scoring captions were iteratively refined using open-source large language\nmodels. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting\nconsistently strong results. To the best of our knowledge, COCO-Urdu is the\nlargest publicly available Urdu captioning dataset. By releasing both the\ndataset and the quality estimation pipeline, we aim to reduce language bias in\nmultimodal research and establish a foundation for inclusive vision-language\nsystems.", "AI": {"tldr": "The paper introduces COCO-Urdu, a large-scale dataset addressing language bias in vision-language systems by focusing on Urdu captions.", "motivation": "Current vision-language models suffer biases favoring high-resource languages, leaving Urdu under-represented.", "method": "COCO-Urdu was developed using translations of MS COCO captions validated through a multimodal quality estimation framework.", "result": "COCO-Urdu consists of 59,000 images and 319,000 Urdu captions with strong benchmark performance.", "conclusion": "Releasing COCO-Urdu and its quality pipeline establishes a resource for more inclusive vision-language research."}}
{"id": "2509.09292", "pdf": "https://arxiv.org/pdf/2509.09292", "abs": "https://arxiv.org/abs/2509.09292", "authors": ["Weige Cai", "Tong Zhu", "Jinyi Niu", "Ruiqi Hu", "Lingyao Li", "Tenglong Wang", "Xiaowu Dai", "Weining Shen", "Liwen Zhang"], "title": "LightAgent: Production-level Open-source Agentic AI Framework", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models (LLMs), Multi-agent\nSystems (MAS) have achieved significant progress in various application\nscenarios. However, substantial challenges remain in designing versatile,\nrobust, and efficient platforms for agent deployment. To address these\nlimitations, we propose \\textbf{LightAgent}, a lightweight yet powerful agentic\nframework, effectively resolving the trade-off between flexibility and\nsimplicity found in existing frameworks. LightAgent integrates core\nfunctionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while\nmaintaining an extremely lightweight structure. As a fully open-source\nsolution, it seamlessly integrates with mainstream chat platforms, enabling\ndevelopers to easily build self-learning agents. We have released LightAgent at\n\\href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent}", "AI": {"tldr": "The paper introduces LightAgent, a lightweight and powerful framework for Multi-agent Systems (MAS), focusing on simplicity and flexibility while integrating key functionalities like memory and tools.", "motivation": "Despite advancements in Multi-agent Systems (MAS), existing platforms still struggle with balancing versatility, robustness, and efficiency.", "method": "LightAgent incorporates essential components such as Memory (mem0), Tools, and Tree of Thought (ToT). It aims to simplify development with an open-source, lightweight design that's compatible with popular chat platforms.", "result": "The framework allows for easier development of self-learning agents, addressing the trade-offs seen in existing methods.", "conclusion": "LightAgent represents a significant step towards more accessible, versatile, and efficient MAS platforms, facilitating broader adoption and development."}}
{"id": "2509.09392", "pdf": "https://arxiv.org/pdf/2509.09392", "abs": "https://arxiv.org/abs/2509.09392", "authors": ["Simon Leistikow", "Thomas Miro", "Adrian Kummerl\u00e4nder", "Ali Nahardani", "Katja Gr\u00fcn", "Markus Franz", "Verena Hoerr", "Mathias J. Krause", "Lars Linsen"], "title": "An Integrated Open Source Software System for the Generation and Analysis of Subject-Specific Blood Flow Simulation Ensembles", "categories": ["physics.med-ph", "cs.SE"], "comment": "21 pages, 7 figures, 2 tables", "summary": "Background and Objective: Hemodynamic analysis of blood flow through arteries\nand veins is critical for diagnosing cardiovascular diseases, such as aneurysms\nand stenoses, and for investigating cardiovascular parameters, such as\nturbulence and wall shear stress. For subject-specific analyses, the anatomy\nand blood flow of the subject can be captured non-invasively using structural\nand 4D Magnetic Resonance Imaging (MRI). Computational Fluid Dynamics (CFD), on\nthe other hand, can be used to generate blood flow simulations by solving the\nNavier-Stokes equations. To generate and analyze subject-specific blood flow\nsimulations, MRI and CFD have to be brought together.\n  Methods: We present an interactive, customizable, and user-oriented visual\nanalysis tool that assists researchers in both medicine and numerical analysis.\nOur open-source tool is applicable to domains such as CFD and MRI, and it\nfacilitates the analysis of simulation results and medical data, especially in\nhemodynamic studies. It enables the creation of simulation ensembles with a\nhigh variety of parameters. Furthermore, it allows for the visual and\nanalytical examination of simulations and measurements through 2D embeddings of\nthe similarity space.\n  Results: To demonstrate the effectiveness of our tool, we applied it to three\nreal-world use cases, showcasing its ability to configure simulation ensembles\nand analyse blood flow dynamics. We evaluated our example cases together with\nMRI and CFD experts to further enhance features and increase the usability.\n  Conclusions: By combining the strengths of both CFD and MRI, our tool\nprovides a more comprehensive understanding of hemodynamic parameters,\nfacilitating more accurate analysis of hemodynamic biomarkers.", "AI": {"tldr": "This paper introduces a user-friendly, open-source tool that integrates Computational Fluid Dynamics (CFD) and Magnetic Resonance Imaging (MRI) for subject-specific analysis of blood flow, aiming to enhance hemodynamic research and cardiovascular disease analysis.", "motivation": "To enable accurate and subject-specific hemodynamic analysis for diagnosing cardiovascular diseases by integrating the capabilities of CFD simulations and MRI data.", "method": "The paper presents an interactive, open-source tool designed for visual analysis of blood flow. The tool integrates CFD and MRI, allows the creation of diverse simulation ensembles, and provides 2D visual and analytical examination of the similarities in simulations and measurements.", "result": "The tool was successfully applied in three real-world use cases, where it helped configure simulation ensembles and analyze blood flow dynamics. Its usability and features were validated by MRI and CFD experts.", "conclusion": "The integration of CFD and MRI through this tool enhances the understanding and analysis of hemodynamic parameters, providing a valuable resource for investigating cardiovascular parameters and diseases."}}
{"id": "2509.09174", "pdf": "https://arxiv.org/pdf/2509.09174", "abs": "https://arxiv.org/abs/2509.09174", "authors": ["Yuhao Zhang", "Yuhao Du", "Zhanchen Dai", "Xiangnan Ma", "Kaiqi Kou", "Benyou Wang", "Haizhou Li"], "title": "EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "Speech-to-speech large language models (SLLMs) are attracting increasing\nattention. Derived from text-based large language models (LLMs), SLLMs often\nexhibit degradation in knowledge and reasoning capabilities. We hypothesize\nthat this limitation arises because current training paradigms for SLLMs fail\nto bridge the acoustic-semantic gap in the feature representation space. To\naddress this issue, we propose EchoX, which leverages semantic representations\nand dynamically generates speech training targets. This approach integrates\nboth acoustic and semantic learning, enabling EchoX to preserve strong\nreasoning abilities as a speech LLM. Experimental results demonstrate that\nEchoX, with about six thousand hours of training data, achieves advanced\nperformance on multiple knowledge-based question-answering benchmarks. The\nproject is available at https://github.com/FreedomIntelligence/EchoX.", "AI": {"tldr": "The authors propose EchoX, a speech-to-speech large language model (SLLM) that preserves reasoning capabilities by integrating acoustic and semantic learning.", "motivation": "Speech-to-speech large language models (SLLMs) often lose knowledge and reasoning capabilities due to gaps between acoustic and semantic representations in current training paradigms.", "method": "The authors introduce EchoX, which uses semantic representations combined with dynamically generated speech training targets to bridge the acoustic-semantic gap and improve reasoning in SLLMs.", "result": "EchoX demonstrates advanced performance in multiple knowledge-based question-answering benchmarks with around six thousand hours of training data.", "conclusion": "EchoX successfully integrates acoustic and semantic learning, maintaining strong reasoning capabilities and enhancing the performance of speech LLMs."}}
{"id": "2509.09546", "pdf": "https://arxiv.org/pdf/2509.09546", "abs": "https://arxiv.org/abs/2509.09546", "authors": ["Yanhui Lu", "Zeyu Deng", "Stephen J. Redmond", "Efi Psomopoulou", "Benjamin Ward-Cherrier"], "title": "A Neuromorphic Incipient Slip Detection System using Papillae Morphology", "categories": ["cs.RO"], "comment": "7 pages, 12 figures. Submitted to IEEE Robotics and Automation\n  Letters (RAL), under review", "summary": "Detecting incipient slip enables early intervention to prevent object\nslippage and enhance robotic manipulation safety. However, deploying such\nsystems on edge platforms remains challenging, particularly due to energy\nconstraints. This work presents a neuromorphic tactile sensing system based on\nthe NeuroTac sensor with an extruding papillae-based skin and a spiking\nconvolutional neural network (SCNN) for slip-state classification. The SCNN\nmodel achieves 94.33% classification accuracy across three classes (no slip,\nincipient slip, and gross slip) in slip conditions induced by sensor motion.\nUnder the dynamic gravity-induced slip validation conditions, after temporal\nsmoothing of the SCNN's final-layer spike counts, the system detects incipient\nslip at least 360 ms prior to gross slip across all trials, consistently\nidentifying incipient slip before gross slip occurs. These results demonstrate\nthat this neuromorphic system has stable and responsive incipient slip\ndetection capability.", "AI": {"tldr": "This paper presents a neuromorphic tactile sensing system using a spiking convolutional neural network, achieving 94.33% accuracy for slip-state classification.", "motivation": "Improving robotic manipulation safety by early detection of object slippage while addressing deployment challenges in energy-constrained edge platforms.", "method": "Developed a tactile sensing system using the NeuroTac sensor with papillae-based skin integrated with a spiking convolutional neural network for slip-state classification.", "result": "The system achieved 94.33% classification accuracy for no slip, incipient slip, and gross slip. It detected incipient slip at least 360 ms before gross slip in all trials.", "conclusion": "The presented system has a reliable and responsive capability for detecting incipient slip, improving manipulation safety."}}
{"id": "2509.09073", "pdf": "https://arxiv.org/pdf/2509.09073", "abs": "https://arxiv.org/abs/2509.09073", "authors": ["Gianlucca Zuin", "Adriano Veloso"], "title": "\"A 6 or a 9?\": Ensemble Learning Through the Multiplicity of Performant Models and Explanations", "categories": ["cs.LG"], "comment": "Paper accepted to the ACM Transactions on Knowledge Discovery from\n  Data (TKDD) for publication (preprint version)", "summary": "Creating models from past observations and ensuring their effectiveness on\nnew data is the essence of machine learning. However, selecting models that\ngeneralize well remains a challenging task. Related to this topic, the Rashomon\nEffect refers to cases where multiple models perform similarly well for a given\nlearning problem. This often occurs in real-world scenarios, like the\nmanufacturing process or medical diagnosis, where diverse patterns in data lead\nto multiple high-performing solutions. We propose the Rashomon Ensemble, a\nmethod that strategically selects models from these diverse high-performing\nsolutions to improve generalization. By grouping models based on both their\nperformance and explanations, we construct ensembles that maximize diversity\nwhile maintaining predictive accuracy. This selection ensures that each model\ncovers a distinct region of the solution space, making the ensemble more robust\nto distribution shifts and variations in unseen data. We validate our approach\non both open and proprietary collaborative real-world datasets, demonstrating\nup to 0.20+ AUROC improvements in scenarios where the Rashomon ratio is large.\nAdditionally, we demonstrate tangible benefits for businesses in various\nreal-world applications, highlighting the robustness, practicality, and\neffectiveness of our approach.", "AI": {"tldr": "This paper introduces the Rashomon Ensemble, a method for selecting diverse high-performing models to improve machine learning generalization and robustness.", "motivation": "To address the challenge of selecting models that generalize well, especially in scenarios involving diverse high-performing solutions due to the Rashomon Effect.", "method": "The authors propose constructing ensembles of models by grouping them based on performance and explanations, ensuring diversity and predictive accuracy.", "result": "The approach demonstrated up to a 0.20+ AUROC improvement on multiple datasets, proving its effectiveness in handling distribution shifts.", "conclusion": "The Rashomon Ensemble improves generalization and robustness, offering practical benefits for real-world applications and businesses."}}
{"id": "2509.09015", "pdf": "https://arxiv.org/pdf/2509.09015", "abs": "https://arxiv.org/abs/2509.09015", "authors": ["Chenqian Le", "Yilin Zhao", "Nikasadat Emami", "Kushagra Yadav", "Xujin \"Chris\" Liu", "Xupeng Chen", "Yao Wang"], "title": "VoxelFormer: Parameter-Efficient Multi-Subject Visual Decoding from fMRI", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in fMRI-based visual decoding have enabled compelling\nreconstructions of perceived images. However, most approaches rely on\nsubject-specific training, limiting scalability and practical deployment. We\nintroduce \\textbf{VoxelFormer}, a lightweight transformer architecture that\nenables multi-subject training for visual decoding from fMRI. VoxelFormer\nintegrates a Token Merging Transformer (ToMer) for efficient voxel compression\nand a query-driven Q-Former that produces fixed-size neural representations\naligned with the CLIP image embedding space. Evaluated on the 7T Natural Scenes\nDataset, VoxelFormer achieves competitive retrieval performance on subjects\nincluded during training with significantly fewer parameters than existing\nmethods. These results highlight token merging and query-based transformers as\npromising strategies for parameter-efficient neural decoding.", "AI": {"tldr": "VoxelFormer introduces a transformer architecture for fMRI-based visual decoding, addressing scalability via multi-subject training rather than subject-specific models.", "motivation": "Existing visual decoding methods rely heavily on subject-specific training, limiting their scalability and practical application. There's a need for a universal approach that works efficiently across multiple subjects.", "method": "VoxelFormer combines a Token Merging Transformer (ToMer) for voxel compression with a query-driven Q-Former to create neural representations aligned with the CLIP image embedding space.", "result": "VoxelFormer demonstrated competitive image retrieval performance on multi-subject training data from the 7T Natural Scenes Dataset, using significantly fewer parameters compared to existing methods.", "conclusion": "Token merging and query-based transformer architectures, such as VoxelFormer, offer efficient and scalable solutions for neural decoding across subjects, paving the way for broader application in visual decoding."}}
{"id": "2509.09312", "pdf": "https://arxiv.org/pdf/2509.09312", "abs": "https://arxiv.org/abs/2509.09312", "authors": ["Cl\u00e9ment Contet", "Umberto Grandi", "J\u00e9r\u00f4me Mengin"], "title": "Explaining Tournament Solutions with Minimal Supports", "categories": ["cs.AI"], "comment": null, "summary": "Tournaments are widely used models to represent pairwise dominance between\ncandidates, alternatives, or teams. We study the problem of providing certified\nexplanations for why a candidate appears among the winners under various\ntournament rules. To this end, we identify minimal supports, minimal\nsub-tournaments in which the candidate is guaranteed to win regardless of how\nthe rest of the tournament is completed (that is, the candidate is a necessary\nwinner of the sub-tournament). This notion corresponds to an abductive\nexplanation for the question,\"Why does the winner win the tournament\", a\ncentral concept in formal explainable AI. We focus on common tournament\nsolutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule,\nthe maximin rule, and the weighted uncovered set. For each rule we determine\nthe size of the smallest minimal supports, and we present polynomial-time\nalgorithms to compute them for all but the weighted uncovered set, for which\nthe problem is NP-complete. Finally, we show how minimal supports can serve to\nproduce compact, certified, and intuitive explanations.", "AI": {"tldr": "The paper explores certified explanations in tournaments, focusing on minimal sub-tournaments that guarantee a winner under different tournament rules and providing efficient computation methods for most cases.", "motivation": "To address the lack of transparent reasoning behind why a candidate is deemed a winner in tournaments using formal explainable AI concepts.", "method": "Identifies minimal sub-tournaments required for a candidate's necessary win under several tournament rules and develops algorithms for their computation.", "result": "Found polynomial-time algorithms for minimal supports computation under most tournament rules except for the weighted uncovered set, where the problem is NP-complete.", "conclusion": "Minimal supports offer a structured framework for intuitive and certified explanations in tournaments, enhancing formal explainable AI approaches."}}
{"id": "2509.09196", "pdf": "https://arxiv.org/pdf/2509.09196", "abs": "https://arxiv.org/abs/2509.09196", "authors": ["Chin Yuen Kwok", "Jia Qi yip"], "title": "Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition", "categories": ["cs.CL", "cs.AI"], "comment": "Published in Interspeech 2025", "summary": "Contextual biasing improves rare word recognition of ASR models by\nprioritizing the output of rare words during decoding. A common approach is\nTrie-based biasing, which gives \"bonus scores\" to partial hypothesis (e.g.\n\"Bon\") that may lead to the generation of the rare word (e.g. \"Bonham\"). If the\nfull word (\"Bonham\") isn't ultimately recognized, the system revokes those\nearlier bonuses. This revocation is limited to beam search and is\ncomputationally expensive, particularly for models with large decoders. To\novercome these limitations, we propose adapting ASR models to look ahead and\npredict multiple steps at once. This avoids the revocation step entirely by\nbetter estimating whether a partial hypothesis will lead to the generation of\nthe full rare word. By fine-tuning Whisper with only 10 hours of synthetic\ndata, our method reduces the word error rate on the NSC Part 2 test set from\n30.86% to 12.19%.", "AI": {"tldr": "The paper presents a method to improve rare word recognition in ASR models by enabling them to predict multiple steps ahead, reducing the dependency on computationally expensive beam search techniques.", "motivation": "Current ASR solutions struggle with efficiently recognizing rare words due to the limitations and computational cost of Trie-based contextual biasing, which involves bonus score revocations in beam search.", "method": "The authors propose fine-tuning ASR models (like Whisper) to look ahead and predict multiple decoding steps simultaneously, bypassing the bonus score revocation process.", "result": "The method reduced the word error rate on the NSC Part 2 test set from 30.86% to 12.19%, using only 10 hours of synthetic fine-tuning data.", "conclusion": "Looking ahead and multi-step prediction is an effective, computationally efficient strategy for improving rare word recognition in ASR models over traditional Trie-based biasing."}}
{"id": "2509.09594", "pdf": "https://arxiv.org/pdf/2509.09594", "abs": "https://arxiv.org/abs/2509.09594", "authors": ["Sourav Garg", "Dustin Craggs", "Vineeth Bhat", "Lachlan Mares", "Stefan Podgorski", "Madhava Krishna", "Feras Dayoub", "Ian Reid"], "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "CoRL 2025; 23 pages including appendix", "summary": "Visual navigation using only a single camera and a topological map has\nrecently become an appealing alternative to methods that require additional\nsensors and 3D maps. This is typically achieved through an \"image-relative\"\napproach to estimating control from a given pair of current observation and\nsubgoal image. However, image-level representations of the world have\nlimitations because images are strictly tied to the agent's pose and\nembodiment. In contrast, objects, being a property of the map, offer an\nembodiment- and trajectory-invariant world representation. In this work, we\npresent a new paradigm of learning \"object-relative\" control that exhibits\nseveral desirable characteristics: a) new routes can be traversed without\nstrictly requiring to imitate prior experience, b) the control prediction\nproblem can be decoupled from solving the image matching problem, and c) high\ninvariance can be achieved in cross-embodiment deployment for variations across\nboth training-testing and mapping-execution settings. We propose a topometric\nmap representation in the form of a \"relative\" 3D scene graph, which is used to\nobtain more informative object-level global path planning costs. We train a\nlocal controller, dubbed \"ObjectReact\", conditioned directly on a high-level\n\"WayObject Costmap\" representation that eliminates the need for an explicit RGB\ninput. We demonstrate the advantages of learning object-relative control over\nits image-relative counterpart across sensor height variations and multiple\nnavigation tasks that challenge the underlying spatial understanding\ncapability, e.g., navigating a map trajectory in the reverse direction. We\nfurther show that our sim-only policy is able to generalize well to real-world\nindoor environments. Code and supplementary material are accessible via project\npage: https://object-react.github.io/", "AI": {"tldr": "This paper introduces an object-focused navigation system using a 3D scene graph for more robust and deployment-invariant control.", "motivation": "The limitations of image-reliant navigation arise from its strict dependence on agent pose and embodiment, motivating exploration of object-based, trajectory-invariant methods.", "method": "The authors propose an object-aware 3D scene graph, train a controller ('ObjectReact') conditioned on high-level object costmaps, eliminating reliance on RGB inputs, and test its cross-environment robustness.", "result": "Their approach achieves higher invariance in sensor configuration, environment transitions, and navigation tasks such as reverse trajectory execution, generalizing well to real-world settings.", "conclusion": "Learning navigation control based on objects, rather than images, improves robustness and generalization across diverse tasks and environments."}}
{"id": "2509.09088", "pdf": "https://arxiv.org/pdf/2509.09088", "abs": "https://arxiv.org/abs/2509.09088", "authors": ["Govind Menon", "Tianmin Yu"], "title": "An entropy formula for the Deep Linear Network", "categories": ["cs.LG", "math.DG", "math.DS"], "comment": null, "summary": "We study the Riemannian geometry of the Deep Linear Network (DLN) as a\nfoundation for a thermodynamic description of the learning process. The main\ntools are the use of group actions to analyze overparametrization and the use\nof Riemannian submersion from the space of parameters to the space of\nobservables. The foliation of the balanced manifold in the parameter space by\ngroup orbits is used to define and compute a Boltzmann entropy. We also show\nthat the Riemannian geometry on the space of observables defined in [2] is\nobtained by Riemannian submersion of the balanced manifold. The main technical\nstep is an explicit construction of an orthonormal basis for the tangent space\nof the balanced manifold using the theory of Jacobi matrices.", "AI": {"tldr": "The paper explores the Riemannian geometry of Deep Linear Networks to construct a thermodynamic framework for learning, utilizing group actions and submersions.", "motivation": "To establish a thermodynamic foundation for understanding the learning processes in Deep Linear Networks using geometry.", "method": "Employing group actions and Riemannian submersion techniques to derive a Boltzmann entropy and connect parameter space to observable space.", "result": "Defined Boltzmann entropy for the balanced manifold and linked observables' geometry to Riemannian submersion. Developed an orthonormal basis for the tangent space using Jacobi matrices.", "conclusion": "The study builds geometric tools to deepen our theoretical understanding of overparametrization and learning in DLNs."}}
{"id": "2509.09054", "pdf": "https://arxiv.org/pdf/2509.09054", "abs": "https://arxiv.org/abs/2509.09054", "authors": ["Binxu Li", "Wei Peng", "Mingjie Li", "Ehsan Adeli", "Kilian M. Pohl"], "title": "Integrating Anatomical Priors into a Causal Diffusion Model", "categories": ["cs.CV"], "comment": "15 pages, 4 figures", "summary": "3D brain MRI studies often examine subtle morphometric differences between\ncohorts that are hard to detect visually. Given the high cost of MRI\nacquisition, these studies could greatly benefit from image syntheses,\nparticularly counterfactual image generation, as seen in other domains, such as\ncomputer vision. However, counterfactual models struggle to produce\nanatomically plausible MRIs due to the lack of explicit inductive biases to\npreserve fine-grained anatomical details. This shortcoming arises from the\ntraining of the models aiming to optimize for the overall appearance of the\nimages (e.g., via cross-entropy) rather than preserving subtle, yet medically\nrelevant, local variations across subjects. To preserve subtle variations, we\npropose to explicitly integrate anatomical constraints on a voxel-level as\nprior into a generative diffusion framework. Called Probabilistic Causal Graph\nModel (PCGM), the approach captures anatomical constraints via a probabilistic\ngraph module and translates those constraints into spatial binary masks of\nregions where subtle variations occur. The masks (encoded by a 3D extension of\nControlNet) constrain a novel counterfactual denoising UNet, whose encodings\nare then transferred into high-quality brain MRIs via our 3D diffusion decoder.\nExtensive experiments on multiple datasets demonstrate that PCGM generates\nstructural brain MRIs of higher quality than several baseline approaches.\nFurthermore, we show for the first time that brain measurements extracted from\ncounterfactuals (generated by PCGM) replicate the subtle effects of a disease\non cortical brain regions previously reported in the neuroscience literature.\nThis achievement is an important milestone in the use of synthetic MRIs in\nstudies investigating subtle morphological differences.", "AI": {"tldr": "The paper proposes a new framework, PCGM, to generate anatomically plausible synthetic brain MRIs focusing on subtle, medically relevant variations using a generative diffusion model with anatomical constraints.", "motivation": "The motivation lies in enhancing counterfactual brain MRI synthesis to aid studies of subtle morphometric differences, addressing limitations in maintaining fine-grain anatomical details in existing approaches.", "method": "The PCGM framework integrates voxel-level anatomical constraints into a generative diffusion framework using a probabilistic graph module. It employs a 3D ControlNet to encode spatial masks, coupled with a counterfactual denoising UNet and a 3D diffusion decoder.", "result": "PCGM enables the generation of high-quality, anatomically accurate synthetic brain MRIs. Results demonstrate its effectiveness in reflecting disease-related variations matching neuroscientific findings.", "conclusion": "PCGM marks progress in synthetic MRI generation for research into subtle brain differences, showing promise for replicating disease effects and aiding morphometric analysis in neuroscience."}}
{"id": "2509.09314", "pdf": "https://arxiv.org/pdf/2509.09314", "abs": "https://arxiv.org/abs/2509.09314", "authors": ["Thuy Ngoc Nguyen", "Anita Williams Woolley", "Cleotilde Gonzalez"], "title": "Measuring Implicit Spatial Coordination in Teams: Effects on Collective Intelligence and Performance", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Coordinated teamwork is essential in fast-paced decision-making environments\nthat require dynamic adaptation, often without an opportunity for explicit\ncommunication. Although implicit coordination has been extensively considered\nin the existing literature, the majority of work has focused on co-located,\nsynchronous teamwork (such as sports teams) or, in distributed teams, primarily\non coordination of knowledge work. However, many teams (firefighters, military,\nlaw enforcement, emergency response) must coordinate their movements in\nphysical space without the benefit of visual cues or extensive explicit\ncommunication. This paper investigates how three dimensions of spatial\ncoordination, namely exploration diversity, movement specialization, and\nadaptive spatial proximity, influence team performance in a collaborative\nonline search and rescue task where explicit communication is restricted and\nteam members rely on movement patterns to infer others' intentions and\ncoordinate actions. Our metrics capture the relational aspects of teamwork by\nmeasuring spatial proximity, distribution patterns, and alignment of movements\nwithin shared environments. We analyze data from 34 four-person teams (136\nparticipants) assigned to specialized roles in a search and rescue task.\nResults show that spatial specialization positively predicts performance, while\nadaptive spatial proximity exhibits a marginal inverted U-shaped relationship,\nsuggesting moderate levels of adaptation are optimal. Furthermore, the temporal\ndynamics of these metrics differentiate high- from low-performing teams over\ntime. These findings provide insights into implicit spatial coordination in\nrole-based teamwork and highlight the importance of balanced adaptive\nstrategies, with implications for training and AI-assisted team support\nsystems.", "AI": {"tldr": "The paper explores factors that improve implicit spatial coordination and performance in teams working in physical environments under communication restrictions.", "motivation": "To understand how spatial coordination impacts team performance, especially in scenarios involving physical tasks with limited explicit communication.", "method": "Analyzes metrics like spatial proximity, movement specialization, and adaptive adjustments using data from 34 teams performing online search-and-rescue tasks with role-based assignments.", "result": "Spatial specialization enhances team performance, and moderate adaptive spatial proximity works best. Temporal dynamics distinguish high-performing teams.", "conclusion": "Critical for training and AI tool development, balanced adaptive strategies optimize spatial coordination in role-based teamwork environments."}}
{"id": "2509.09197", "pdf": "https://arxiv.org/pdf/2509.09197", "abs": "https://arxiv.org/abs/2509.09197", "authors": ["Chin Yuen Kwok", "Jia Qi Yip", "Eng Siong Chng"], "title": "Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function", "categories": ["cs.CL", "cs.AI"], "comment": "Published in Interspeech 2025", "summary": "Rare word recognition can be improved by adapting ASR models to synthetic\ndata that includes these words. Further improvements can be achieved through\ncontextual biasing, which trains and adds a biasing module into the model\narchitecture to prioritize rare words. While training the module on synthetic\nrare word data is more effective than using non-rare-word data, it can lead to\noverfitting due to artifacts in the synthetic audio. To address this, we\nenhance the TCPGen-based contextual biasing approach and propose a\nkeyword-aware loss function that additionally focuses on biased words when\ntraining biasing modules. This loss includes a masked cross-entropy term for\nbiased word prediction and a binary classification term for detecting biased\nword positions. These two terms complementarily support the decoding of biased\nwords during inference. By adapting Whisper to 10 hours of synthetic data, our\nmethod reduced the word error rate on the NSC Part 2 test set from 29.71% to\n11.81%.", "AI": {"tldr": "The paper proposes enhancing ASR performance for rare words using contextual biasing and a new keyword-aware loss function, achieving significant word error rate reductions.", "motivation": "Rare words are often misrecognized by traditional ASR systems, and improving their recognition requires addressing overfitting issues caused by synthetic training data.", "method": "The authors propose an enhanced TCPGen-based contextual biasing approach with a keyword-aware loss function, combining masked cross-entropy and binary classification terms for training biasing modules.", "result": "Adapting the Whisper model using 10 hours of synthetic data reduced the word error rate (WER) on the NSC Part 2 test set from 29.71% to 11.81%.", "conclusion": "The proposed keyword-aware loss function effectively improves the decoding of rare words in ASR systems, demonstrating potential for significant performance gains with minimal training data."}}
{"id": "2509.09613", "pdf": "https://arxiv.org/pdf/2509.09613", "abs": "https://arxiv.org/abs/2509.09613", "authors": ["Taisei Mogi", "Mari Saito", "Yoshihiro Nakata"], "title": "MOFU: Development of a MOrphing Fluffy Unit with Expansion and Contraction Capabilities and Evaluation of the Animacy of Its Movements", "categories": ["cs.RO"], "comment": null, "summary": "Robots for therapy and social interaction are often intended to evoke\n\"animacy\" in humans. While many robots imitate appearance and joint movements,\nlittle attention has been given to whole-body expansion-contraction,\nvolume-changing movements observed in living organisms, and their effect on\nanimacy perception. We developed a mobile robot called \"MOFU (Morphing Fluffy\nUnit),\" capable of whole-body expansion-contraction with a single motor and\ncovered with a fluffy exterior. MOFU employs a \"Jitterbug\" structure, a\ngeometric transformation mechanism that enables smooth volume change in\ndiameter from 210 to 280 mm using one actuator. It is also equipped with a\ndifferential two-wheel drive mechanism for locomotion. To evaluate the effect\nof expansion-contraction movements, we conducted an online survey using videos\nof MOFU's behavior. Participants rated impressions with the Godspeed\nQuestionnaire Series. First, we compared videos of MOFU in a stationary state\nwith and without expansion-contraction and turning, finding that\nexpansion-contraction significantly increased perceived animacy. Second, we\nhypothesized that presenting two MOFUs would increase animacy compared with a\nsingle robot; however, this was not supported, as no significant difference\nemerged. Exploratory analyses further compared four dual-robot motion\nconditions. Third, when expansion-contraction was combined with locomotion,\nanimacy ratings were higher than locomotion alone. These results suggest that\nvolume-changing movements such as expansion and contraction enhance perceived\nanimacy in robots and should be considered an important design element in\nfuture robot development aimed at shaping human impressions.", "AI": {"tldr": "The study introduces MOFU, a mobile robot capable of whole-body expansion and contraction, and evaluates how these movements affect perceived animacy in robots.", "motivation": "To explore how whole-body volume changes, like expansion-contraction, influence humans' perception of animacy in robots, an underexplored factor in robotic design.", "method": "Developed MOFU, a robot with a geometric transformation mechanism for expansion-contraction combined with locomotion, and evaluated its impact on animacy perception in online surveys using the Godspeed Questionnaire Series.", "result": "Expansion-contraction movements significantly increased perceived animacy in stationary robots and enhanced animacy when combined with locomotion. However, using two robots did not further boost animacy perceptions.", "conclusion": "Whole-body volume-changing movements like expansion-contraction are critical for enhancing perceived animacy in robots and should be prioritized in the design of socially interactive robots."}}
{"id": "2509.09119", "pdf": "https://arxiv.org/pdf/2509.09119", "abs": "https://arxiv.org/abs/2509.09119", "authors": ["Hao Zhang", "Bo Huang", "Zhenjia Li", "Xi Xiao", "Hui Yi Leong", "Zumeng Zhang", "Xinwei Long", "Tianyang Wang", "Hao Xu"], "title": "Sensitivity-LoRA: Low-Load Sensitivity-Based Fine-Tuning for Large Language Models", "categories": ["cs.LG"], "comment": "15 pages", "summary": "Large Language Models (LLMs) have transformed both everyday life and\nscientific research. However, adapting LLMs from general-purpose models to\nspecialized tasks remains challenging, particularly in resource-constrained\nenvironments. Low-Rank Adaptation (LoRA), a prominent method within\nParameter-Efficient Fine-Tuning (PEFT), has emerged as a promising approach to\nLLMs by approximating model weight updates using low-rank decomposition.\nHowever, LoRA is limited by its uniform rank ( r ) allocation to each\nincremental matrix, and existing rank allocation techniques aimed at addressing\nthis issue remain computationally inefficient, complex, and unstable, hindering\npractical applications. To address these limitations, we propose\nSensitivity-LoRA, an efficient fine-tuning method that dynamically allocates\nranks to weight matrices based on both their global and local sensitivities. It\nleverages the second-order derivatives (Hessian Matrix) of the loss function to\neffectively capture weight sensitivity, enabling optimal rank allocation with\nminimal computational overhead. Our experimental results have demonstrated\nrobust effectiveness, efficiency and stability of Sensitivity-LoRA across\ndiverse tasks and benchmarks.", "AI": {"tldr": "Sensitivity-LoRA improves Low-Rank Adaptation (LoRA) by dynamically allocating ranks based on weight sensitivities, ensuring efficient fine-tuning of Large Language Models (LLMs).", "motivation": "Fine-tuning Large Language Models for specialized tasks in resource-constrained environments remains difficult. Existing methods like LoRA struggle due to uniform rank allocation and inefficiencies in advanced allocation techniques.", "method": "Sensitivity-LoRA utilizes both global and local sensitivities, derived from second-order derivatives (Hessian Matrix) of the loss function, to dynamically allocate ranks across weight matrices.", "result": "Experimental results show that Sensitivity-LoRA is effective, efficient, and stable across various tasks and benchmarks.", "conclusion": "Sensitivity-LoRA addresses significant limitations in rank allocation for LoRA, offering a computationally efficient and practical approach for adapting LLMs to specialized tasks."}}
{"id": "2509.09064", "pdf": "https://arxiv.org/pdf/2509.09064", "abs": "https://arxiv.org/abs/2509.09064", "authors": ["Qiuhui Chen", "Xuancheng Yao", "Huping Ye", "Yi Hong"], "title": "Enhancing 3D Medical Image Understanding with Pretraining Aided by 2D Multimodal Large Language Models", "categories": ["cs.CV"], "comment": "Accepted by IEEE Journal of Biomedical and Health Informatics (JBHI)", "summary": "Understanding 3D medical image volumes is critical in the medical field, yet\nexisting 3D medical convolution and transformer-based self-supervised learning\n(SSL) methods often lack deep semantic comprehension. Recent advancements in\nmultimodal large language models (MLLMs) provide a promising approach to\nenhance image understanding through text descriptions. To leverage these 2D\nMLLMs for improved 3D medical image understanding, we propose Med3DInsight, a\nnovel pretraining framework that integrates 3D image encoders with 2D MLLMs via\na specially designed plane-slice-aware transformer module. Additionally, our\nmodel employs a partial optimal transport based alignment, demonstrating\ngreater tolerance to noise introduced by potential noises in LLM-generated\ncontent. Med3DInsight introduces a new paradigm for scalable multimodal 3D\nmedical representation learning without requiring human annotations. Extensive\nexperiments demonstrate our state-of-the-art performance on two downstream\ntasks, i.e., segmentation and classification, across various public datasets\nwith CT and MRI modalities, outperforming current SSL methods. Med3DInsight can\nbe seamlessly integrated into existing 3D medical image understanding networks,\npotentially enhancing their performance. Our source code, generated datasets,\nand pre-trained models will be available at\nhttps://github.com/Qybc/Med3DInsight.", "AI": {"tldr": "This paper introduces Med3DInsight, a pretraining framework combining 3D medical image encoders with 2D multimodal large language models to improve 3D medical image understanding without requiring human annotations.", "motivation": "Existing self-supervised learning methods for 3D medical images lack sufficient semantic comprehension, and recent multimodal language models offer a potential improvement through text-based understanding.", "method": "Med3DInsight leverages 3D image encoders with 2D MLLMs using a plane-slice-aware transformer module and employs partial optimal transport for alignment to counteract noise in language-model-generated data.", "result": "The framework achieves state-of-the-art results in segmentation and classification tasks on various CT and MRI datasets, performing better than existing SSL methods.", "conclusion": "Med3DInsight sets a new direction for scalable multimodal 3D medical representation learning, is easily integrable into existing networks, and holds promise for advancing 3D medical image understanding."}}
{"id": "2509.09321", "pdf": "https://arxiv.org/pdf/2509.09321", "abs": "https://arxiv.org/abs/2509.09321", "authors": ["Hangyi Jia", "Yuxi Qian", "Hanwen Tong", "Xinhui Wu", "Lin Chen", "Feng Wei"], "title": "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled the emergence of\ngeneral-purpose agents for automating end-to-end machine learning (ML)\nworkflows, including data analysis, feature engineering, model training, and\ncompetition solving. However, existing benchmarks remain limited in task\ncoverage, domain diversity, difficulty modeling, and evaluation rigor, failing\nto capture the full capabilities of such agents in realistic settings. We\npresent TAM Bench, a diverse, realistic, and structured benchmark for\nevaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three\nkey innovations: (1) A browser automation and LLM-based task acquisition system\nthat automatically collects and structures ML challenges from platforms such as\nKaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities\n(e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty\nmodeling mechanism that estimates task complexity using participant counts and\nscore dispersion, enabling scalable and objective task calibration; (3) A\nmulti-dimensional evaluation framework incorporating performance, format\ncompliance, constraint adherence, and task generalization. Based on 150 curated\nAutoML tasks, we construct three benchmark subsets of different sizes -- Lite,\nMedium, and Full -- designed for varying evaluation scenarios. The Lite\nversion, with 18 tasks and balanced coverage across modalities and difficulty\nlevels, serves as a practical testbed for daily benchmarking and comparative\nstudies.", "AI": {"tldr": "TAM Bench introduces a benchmark for general-purpose agents in ML workflows, addressing limitations of existing evaluations. It incorporates task diversity, difficulty modeling, and rigorous evaluation.", "motivation": "The paper aims to address the limitations of existing benchmarks for general-purpose AI agents by providing a diverse and realistic evaluation framework for ML workflows.", "method": "TAM Bench utilizes an automation and LLM-based data collection system for ML tasks, a leaderboard-driven difficulty modeling mechanism, and a multi-dimensional evaluation framework.", "result": "TAM Bench provides 150 curated AutoML tasks, grouped into Lite, Medium, and Full subsets, offering different evaluation scenarios.", "conclusion": "TAM Bench establishes a structured and comprehensive benchmark for evaluating the capabilities of LLM-based agents in end-to-end ML tasks."}}
{"id": "2509.09198", "pdf": "https://arxiv.org/pdf/2509.09198", "abs": "https://arxiv.org/abs/2509.09198", "authors": ["Talia Sternberg", "Michael London", "David Omer", "Yossi Adi"], "title": "GmSLM : Generative Marmoset Spoken Language Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Marmoset monkeys exhibit complex vocal communication, challenging the view\nthat nonhuman primates vocal communication is entirely innate, and show similar\nfeatures of human speech, such as vocal labeling of others and turn-taking.\nStudying their vocal communication offers a unique opportunity to link it with\nbrain activity-especially given the difficulty of accessing the human brain in\nspeech and language research. Since Marmosets communicate primarily through\nvocalizations, applying standard LLM approaches is not straightforward. We\nintroduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized\nspoken language model pipeline for Marmoset vocal communication. We designed a\nnovel zero-shot evaluation metrics using unsupervised in-the-wild data,\nalongside weakly labeled conversational data, to assess GmSLM and demonstrate\nits advantage over a basic human-speech-based baseline. GmSLM generated\nvocalizations closely matched real resynthesized samples acoustically and\nperformed well on downstream tasks. Despite being fully unsupervised, GmSLM\neffectively distinguish real from artificial conversations and may support\nfurther investigations of the neural basis of vocal communication and provides\na practical framework linking vocalization and brain activity. We believe GmSLM\nstands to benefit future work in neuroscience, bioacoustics, and evolutionary\nbiology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.", "AI": {"tldr": "Marmoset monkeys exhibit complex vocal communication features similar to humans. The study introduces GmSLM, a model optimized for their vocalizations, that performs well in distinguishing artificial and real conversations using unsupervised data.", "motivation": "Nonhuman primates, particularly marmosets, display intricate vocal communication that parallels human speech. This inspires research to develop tools for studying their vocalizations and connecting them to brain activity.", "method": "A novel Generative Marmoset Spoken Language Modeling (GmSLM) pipeline was developed, employing zero-shot evaluation metrics on unsupervised and weakly labeled conversational data.", "result": "GmSLM generated vocalizations acoustically resembling real samples, excelling in downstream tasks and distinguishing real from artificial conversations, even in a fully unsupervised setup.", "conclusion": "GmSLM facilitates understanding of marmoset vocal communication, offering applications in neuroscience, bioacoustics, and evolutionary biology, while bridging vocalization research to brain activity studies."}}
{"id": "2509.09671", "pdf": "https://arxiv.org/pdf/2509.09671", "abs": "https://arxiv.org/abs/2509.09671", "authors": ["Sirui Xu", "Yu-Wei Chao", "Liuyu Bian", "Arsalan Mousavian", "Yu-Xiong Wang", "Liang-Yan Gui", "Wei Yang"], "title": "Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration", "categories": ["cs.RO", "cs.CV"], "comment": "CoRL 2025", "summary": "Hand-object motion-capture (MoCap) repositories offer large-scale,\ncontact-rich demonstrations and hold promise for scaling dexterous robotic\nmanipulation. Yet demonstration inaccuracies and embodiment gaps between human\nand robot hands limit the straightforward use of these data. Existing methods\nadopt a three-stage workflow, including retargeting, tracking, and residual\ncorrection, which often leaves demonstrations underused and compound errors\nacross stages. We introduce Dexplore, a unified single-loop optimization that\njointly performs retargeting and tracking to learn robot control policies\ndirectly from MoCap at scale. Rather than treating demonstrations as ground\ntruth, we use them as soft guidance. From raw trajectories, we derive adaptive\nspatial scopes, and train with reinforcement learning to keep the policy\nin-scope while minimizing control effort and accomplishing the task. This\nunified formulation preserves demonstration intent, enables robot-specific\nstrategies to emerge, improves robustness to noise, and scales to large\ndemonstration corpora. We distill the scaled tracking policy into a\nvision-based, skill-conditioned generative controller that encodes diverse\nmanipulation skills in a rich latent representation, supporting generalization\nacross objects and real-world deployment. Taken together, these contributions\nposition Dexplore as a principled bridge that transforms imperfect\ndemonstrations into effective training signals for dexterous manipulation.", "AI": {"tldr": "Dexplore introduces a unified approach for training robot control policies from imperfect motion-capture data, addressing limitations of traditional multi-step workflows.", "motivation": "Existing hand-object MoCap data holds potential for robotic manipulation training but is limited by inaccuracies and embodiment gaps between human and robot hands.", "method": "Dexplore uses a single-loop optimization approach that integrates retargeting and tracking into a reinforcement learning pipeline, treating demonstrations as soft guidance rather than ground truth.", "result": "The approach preserves demonstration intent, enables robot-specific strategies, improves robustness, and scales efficiently to large datasets.", "conclusion": "Dexplore transforms imperfect demonstrations into effective training signals for robotic dexterous manipulation, enabling real-world generalization across objects and skills."}}
{"id": "2509.09128", "pdf": "https://arxiv.org/pdf/2509.09128", "abs": "https://arxiv.org/abs/2509.09128", "authors": ["Emam Hossain", "Md Osman Gani"], "title": "Learning What Matters: Causal Time Series Modeling for Arctic Sea Ice Prediction", "categories": ["cs.LG"], "comment": "Accepted and presented at the AI4TS Workshop @ IJCAI 2025\n  (non-archival)", "summary": "Conventional machine learning and deep learning models typically rely on\ncorrelation-based learning, which often fails to distinguish genuine causal\nrelationships from spurious associations, limiting their robustness,\ninterpretability, and ability to generalize. To overcome these limitations, we\nintroduce a causality-aware deep learning framework that integrates\nMultivariate Granger Causality (MVGC) and PCMCI+ for causal feature selection\nwithin a hybrid neural architecture. Leveraging 43 years (1979-2021) of Arctic\nSea Ice Extent (SIE) data and associated ocean-atmospheric variables at daily\nand monthly resolutions, the proposed method identifies causally influential\npredictors, prioritizes direct causes of SIE dynamics, reduces unnecessary\nfeatures, and enhances computational efficiency. Experimental results show that\nincorporating causal inputs leads to improved prediction accuracy and\ninterpretability across varying lead times. While demonstrated on Arctic SIE\nforecasting, the framework is broadly applicable to other dynamic,\nhigh-dimensional domains, offering a scalable approach that advances both the\ntheoretical foundations and practical performance of causality-informed\npredictive modeling.", "AI": {"tldr": "This paper proposes a causality-aware deep learning framework for improved prediction through causal feature selection, demonstrated on Arctic Sea Ice Extent (SIE) forecasting.", "motivation": "Conventional machine and deep learning models fail to distinguish causal relationships from spurious correlations, leading to limited robustness, interpretability, and generalization.", "method": "The paper introduces a hybrid causality-aware neural framework integrating Multivariate Granger Causality (MVGC) and PCMCI+ for causal feature selection, applied to Arctic SIE data over 43 years.", "result": "The method successfully improves prediction accuracy, interpretability, and computational efficiency by selecting causally relevant predictors.", "conclusion": "The proposed framework is scalable and generalizable to other high-dimensional domains, enhancing causality-informed predictive modeling both theoretically and practically."}}
{"id": "2509.09067", "pdf": "https://arxiv.org/pdf/2509.09067", "abs": "https://arxiv.org/abs/2509.09067", "authors": ["Hesham M. Shehata", "Mohammad Abdolrahmani"], "title": "Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach", "categories": ["cs.CV"], "comment": null, "summary": "Recent graph convolutional neural networks (GCNs) have shown high performance\nin the field of human action recognition by using human skeleton poses.\nHowever, it fails to detect human-object interaction cases successfully due to\nthe lack of effective representation of the scene information and appropriate\nlearning architectures. In this context, we propose a methodology to utilize\nhuman action recognition performance by considering fixed object information in\nthe environment and following a multi-task learning approach. In order to\nevaluate the proposed method, we collected real data from public environments\nand prepared our data set, which includes interaction classes of hands-on fixed\nobjects (e.g., ATM ticketing machines, check-in/out machines, etc.) and\nnon-interaction classes of walking and standing. The multi-task learning\napproach, along with interaction area information, succeeds in recognizing the\nstudied interaction and non-interaction actions with an accuracy of 99.25%,\noutperforming the accuracy of the base model using only human skeleton poses by\n2.75%.", "AI": {"tldr": "This paper improves human action recognition, especially in human-object interactions, by integrating scene information and applying a multi-task learning approach. The proposed method achieves 99.25% accuracy, surpassing traditional skeleton-based models.", "motivation": "Address the failure of existing graph convolutional neural networks (GCNs) in effectively detecting human-object interactions due to the absence of scene information representation and suitable learning architectures.", "method": "Introduced a methodology combining human skeleton poses with scene object information in a multi-task learning framework. Real-world data with predefined interaction classes were collected to train and evaluate the model.", "result": "Achieved a significant accuracy of 99.25% for recognizing human actions, enhancing the baseline skeleton pose model accuracy by 2.75%.", "conclusion": "Integrating fixed object information and applying multi-task learning substantially improves action recognition, demonstrating the benefits of utilizing scene-related context for human-object interaction detection."}}
{"id": "2509.09356", "pdf": "https://arxiv.org/pdf/2509.09356", "abs": "https://arxiv.org/abs/2509.09356", "authors": ["Abdel Hakim Drid", "Vincenzo Suriani", "Daniele Nardi", "Abderrezzak Debilou"], "title": "Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning", "categories": ["cs.AI", "cs.RO"], "comment": "The 19th International Conference on Intelligent Autonomous Systems\n  (IAS 19), 2025, Genoa", "summary": "Navigating and understanding complex and unknown environments autonomously\ndemands more than just basic perception and movement from embodied agents.\nTruly effective exploration requires agents to possess higher-level cognitive\nabilities, the ability to reason about their surroundings, and make more\ninformed decisions regarding exploration strategies. However, traditional RL\napproaches struggle to balance efficient exploration and semantic understanding\ndue to limited cognitive capabilities embedded in the small policies for the\nagents, leading often to human drivers when dealing with semantic exploration.\nIn this paper, we address this challenge by presenting a novel Deep\nReinforcement Learning (DRL) architecture that is specifically designed for\nresource efficient semantic exploration. A key methodological contribution is\nthe integration of a Vision-Language Model (VLM) common-sense through a layered\nreward function. The VLM query is modeled as a dedicated action, allowing the\nagent to strategically query the VLM only when deemed necessary for gaining\nexternal guidance, thereby conserving resources. This mechanism is combined\nwith a curriculum learning strategy designed to guide learning at different\nlevels of complexity to ensure robust and stable learning. Our experimental\nevaluation results convincingly demonstrate that our agent achieves\nsignificantly enhanced object discovery rates and develops a learned capability\nto effectively navigate towards semantically rich regions. Furthermore, it also\nshows a strategic mastery of when to prompt for external environmental\ninformation. By demonstrating a practical and scalable method for embedding\ncommon-sense semantic reasoning with autonomous agents, this research provides\na novel approach to pursuing a fully intelligent and self-guided exploration in\nrobotics.", "AI": {"tldr": "The paper introduces a DRL architecture that integrates a Vision-Language Model (VLM) for efficient semantic exploration, achieving better object discovery and intelligent navigation.", "motivation": "Current RL methods lack cognitive capabilities, struggling with efficient exploration and semantic understanding, which hinders autonomous navigation in unknown environments.", "method": "The proposed method integrates VLM common-sense through a layered reward function, using a VLM query as an action available to the agent. It incorporates a curriculum learning strategy to guide the agent's learning at different levels of complexity.", "result": "The agent demonstrates improved object discovery rates, effective navigation to semantically rich areas, and strategic querying for external guidance, proving its resource-efficient semantic exploration ability.", "conclusion": "The research showcases a scalable approach for embedding semantic reasoning in autonomous agents, moving closer to fully intelligent and self-guided exploration in robotics."}}
{"id": "2509.09199", "pdf": "https://arxiv.org/pdf/2509.09199", "abs": "https://arxiv.org/abs/2509.09199", "authors": ["Wenhao Li", "Bangcheng Sun", "Weihao Ye", "Tianyi Zhang", "Daohai Yu", "Fei Chao", "Rongrong Ji"], "title": "CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Scaling language models to longer contexts is essential for capturing rich\ndependencies across extended discourse. However, na\\\"ive context extension\nimposes significant computational and memory burdens, often resulting in\ninefficiencies during both training and inference. In this work, we propose\nCCF, a novel context compression framework designed to enable efficient\nlong-context modeling by learning hierarchical latent representations that\npreserve global semantics while aggressively reducing input redundancy. CCF\nintegrates segment-wise semantic aggregation with key-value memory encoding,\nforming compact representations that support accurate reconstruction and\nlong-range understanding. To further enhance scalability, we introduce a\ntraining-efficient optimization strategy that couples incremental segment\ndecoding with sparse reservoir sampling, substantially reducing memory overhead\nwithout degrading performance. Empirical results on multiple long-context\nlanguage modeling benchmarks demonstrate that CCF achieves competitive\nperplexity under high compression ratios, and significantly improves throughput\nand memory efficiency compared to existing approaches. These findings highlight\nthe potential of structured compression for scalable and effective long-context\nlanguage modeling.", "AI": {"tldr": "The paper introduces CCF, a method for efficient long-context language modeling by utilizing hierarchical compression to address computational and memory inefficiencies.", "motivation": "Long-context language models face significant inefficiencies in computation and memory as they scale to longer dependencies, necessitating a solution to handle extended contexts without sacrificing performance.", "method": "The proposed CCF framework uses hierarchical latent representations for semantic compression, combining segment-wise aggregation and memory encoding, along with an optimization strategy that includes incremental decoding and sparse sampling for scalability.", "result": "Empirical tests illustrate that CCF maintains competitive perplexity at high compression levels while improving processing speed and reducing memory usage compared to existing methods.", "conclusion": "CCF demonstrates the advantages of structured compression for efficient and effective long-context language modeling, offering a robust solution for scalability challenges."}}
{"id": "2509.09674", "pdf": "https://arxiv.org/pdf/2509.09674", "abs": "https://arxiv.org/abs/2509.09674", "authors": ["Haozhan Li", "Yuxin Zuo", "Jiale Yu", "Yuhao Zhang", "Zhaohui Yang", "Kaiyan Zhang", "Xuekai Zhu", "Yuchen Zhang", "Tianxing Chen", "Ganqu Cui", "Dehui Wang", "Dingxiang Luo", "Yuchen Fan", "Youbang Sun", "Jia Zeng", "Jiangmiao Pang", "Shanghang Zhang", "Yu Wang", "Yao Mu", "Bowen Zhou", "Ning Ding"], "title": "SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as a powerful\nparadigm for robotic manipulation. Despite substantial progress enabled by\nlarge-scale pretraining and supervised fine-tuning (SFT), these models face two\nfundamental challenges: (i) the scarcity and high cost of large-scale\nhuman-operated robotic trajectories required for SFT scaling, and (ii) limited\ngeneralization to tasks involving distribution shift. Recent breakthroughs in\nLarge Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can\ndramatically enhance step-by-step reasoning capabilities, raising a natural\nquestion: Can RL similarly improve the long-horizon step-by-step action\nplanning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL\nframework tailored for VLA models. Building upon veRL, we introduce\nVLA-specific trajectory sampling, scalable parallelization, multi-environment\nrendering, and optimized loss computation. When applied to OpenVLA-OFT,\nSimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\\pi_0$\non RoboTwin 1.0\\&2.0 with the exploration-enhancing strategies we introduce.\nSimpleVLA-RL not only reduces dependence on large-scale data and enables robust\ngeneralization, but also remarkably surpasses SFT in real-world tasks.\nMoreover, we identify a novel phenomenon ``pushcut'' during RL training,\nwherein the policy discovers previously unseen patterns beyond those seen in\nthe previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL", "AI": {"tldr": "The paper introduces SimpleVLA-RL, an efficient reinforcement learning (RL) framework designed for Vision-Language-Action (VLA) models to address limitations in supervised fine-tuning such as data scarcity and distribution shift challenges.", "motivation": "To overcome the dependency on large-scale human-operated robotic data and enhance generalization abilities in robotic manipulation tasks, leveraging RL for step-by-step action planning in VLA is explored.", "method": "The authors extend the veRL framework with VLA-specific trajectory sampling, scalable parallelization, multi-environment rendering, and optimized loss computation, tailoring RL specifically for VLA models.", "result": "SimpleVLA-RL achieves state-of-the-art performance on LIBERO and exceeds baseline performance on RoboTwin 1.0&2.0 by incorporating exploration-enhancing strategies. It reduces data dependence and improves task generalization.", "conclusion": "SimpleVLA-RL demonstrates RL as a potent alternative to supervised fine-tuning for VLA models, enabling robust generalization and surpassing previous approaches in real-world tasks. A novel phenomenon called 'pushcut' was discovered during RL training."}}
{"id": "2509.09135", "pdf": "https://arxiv.org/pdf/2509.09135", "abs": "https://arxiv.org/abs/2509.09135", "authors": ["Xuefeng Wang", "Lei Zhang", "Henglin Pu", "Ahmed H. Qureshi", "Husheng Li"], "title": "Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.MA"], "comment": "19 pages, 10 figures", "summary": "Existing reinforcement learning (RL) methods struggle with complex dynamical\nsystems that demand interactions at high frequencies or irregular time\nintervals. Continuous-time RL (CTRL) has emerged as a promising alternative by\nreplacing discrete-time Bellman recursion with differential value functions\ndefined as viscosity solutions of the Hamilton--Jacobi--Bellman (HJB) equation.\nWhile CTRL has shown promise, its applications have been largely limited to the\nsingle-agent domain. This limitation stems from two key challenges: (i)\nconventional solution methods for HJB equations suffer from the curse of\ndimensionality (CoD), making them intractable in high-dimensional systems; and\n(ii) even with HJB-based learning approaches, accurately approximating\ncentralized value functions in multi-agent settings remains difficult, which in\nturn destabilizes policy training. In this paper, we propose a CT-MARL\nframework that uses physics-informed neural networks (PINNs) to approximate\nHJB-based value functions at scale. To ensure the value is consistent with its\ndifferential structure, we align value learning with value-gradient learning by\nintroducing a Value Gradient Iteration (VGI) module that iteratively refines\nvalue gradients along trajectories. This improves gradient fidelity, in turn\nyielding more accurate values and stronger policy learning. We evaluate our\nmethod using continuous-time variants of standard benchmarks, including\nmulti-agent particle environment (MPE) and multi-agent MuJoCo. Our results\ndemonstrate that our approach consistently outperforms existing continuous-time\nRL baselines and scales to complex multi-agent dynamics.", "AI": {"tldr": "The paper proposes a continuous-time multi-agent reinforcement learning (CT-MARL) framework using physics-informed neural networks (PINNs) to address challenges in high-dimensional systems and improve learning accuracy through a Value Gradient Iteration (VGI) module.", "motivation": "Current reinforcement learning methods face challenges with high-frequency or irregular interactions, with continuous-time RL (CTRL) showing promise but being limited to single-agent applications due to dimensionality and value approximation issues.", "method": "The authors introduce the CT-MARL framework, incorporating PINNs to approximate value functions and a Value Gradient Iteration (VGI) module to refine gradient alignment iteratively, ensuring consistency with differential structures.", "result": "Their method outperforms existing CTRL baselines in multi-agent benchmarks such as the multi-agent particle environment (MPE) and multi-agent MuJoCo, demonstrating scalability and improved performance in complex dynamics.", "conclusion": "The proposed method successfully extends CTRL to multi-agent settings, addressing dimensionality and accuracy challenges while achieving superior results over existing frameworks."}}
{"id": "2509.09085", "pdf": "https://arxiv.org/pdf/2509.09085", "abs": "https://arxiv.org/abs/2509.09085", "authors": ["Jifeng Shen", "Haibo Zhan", "Xin Zuo", "Heng Fan", "Xiaohui Yuan", "Jun Li", "Wankou Yang"], "title": "IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection", "categories": ["cs.CV"], "comment": "31 pages,6 pages, submitted on 3 Sep,2025", "summary": "Current multispectral object detection methods often retain extraneous\nbackground or noise during feature fusion, limiting perceptual performance.To\naddress this, we propose an innovative feature fusion framework based on\ncross-modal feature contrastive and screening strategy, diverging from\nconventional approaches. The proposed method adaptively enhances salient\nstructures by fusing object-aware complementary cross-modal features while\nsuppressing shared background interference.Our solution centers on two novel,\nspecially designed modules: the Mutual Feature Refinement Module (MFRM) and the\nDifferential Feature Feedback Module (DFFM). The MFRM enhances intra- and\ninter-modal feature representations by modeling their relationships, thereby\nimproving cross-modal alignment and discriminative power.Inspired by feedback\ndifferential amplifiers, the DFFM dynamically computes inter-modal differential\nfeatures as guidance signals and feeds them back to the MFRM, enabling adaptive\nfusion of complementary information while suppressing common-mode noise across\nmodalities. To enable robust feature learning, the MFRM and DFFM are integrated\ninto a unified framework, which is formally formulated as an Iterative\nRelation-Map Differential Guided Feature Fusion mechanism, termed IRDFusion.\nIRDFusion enables high-quality cross-modal fusion by progressively amplifying\nsalient relational signals through iterative feedback, while suppressing\nfeature noise, leading to significant performance gains.In extensive\nexperiments on FLIR, LLVIP and M$^3$FD datasets, IRDFusion achieves\nstate-of-the-art performance and consistently outperforms existing methods\nacross diverse challenging scenarios, demonstrating its robustness and\neffectiveness. Code will be available at\nhttps://github.com/61s61min/IRDFusion.git.", "AI": {"tldr": "The paper introduces a novel framework for multispectral object detection, emphasizing noise reduction and feature enhancement.", "motivation": "Multispectral object detection tasks often struggle with noise and background interference during feature fusion, reducing detection and perceptual accuracy.", "method": "The authors propose IRDFusion, a feature fusion framework integrating two modules: Mutual Feature Refinement Module (MFRM) and Differential Feature Feedback Module (DFFM), combined through an iterative mechanism.", "result": "IRDFusion delivers state-of-the-art results on FLIR, LLVIP, and M$^3$FD datasets, surpassing existing methods in diverse and challenging scenarios.", "conclusion": "IRDFusion efficiently enhances feature fusion across modalities by suppressing noise and amplifying salient signals, demonstrating its effectiveness and robustness in improving multispectral object detection tasks."}}
{"id": "2509.09448", "pdf": "https://arxiv.org/pdf/2509.09448", "abs": "https://arxiv.org/abs/2509.09448", "authors": ["Minhyuk Kim", "Seungyoon Lee", "Heuiseok Lim"], "title": "TORSO: Template-Oriented Reasoning Towards General Tasks", "categories": ["cs.AI"], "comment": "9 pages, 3 figures", "summary": "The approaches that guide Large Language Models (LLMs) to emulate human\nreasoning during response generation have emerged as an effective method for\nenabling them to solve complex problems in a step-by-step manner, thereby\nachieving superior performance. However, most existing approaches using\nfew-shot prompts to generate responses heavily depend on the provided examples,\nlimiting the utilization of the model's inherent reasoning capabilities.\nMoreover, constructing task-specific few-shot prompts is often costly and may\nlead to inconsistencies across different tasks. In this work, we introduce\nTemplate-Oriented Reasoning (TORSO), which elicits the model to utilize\ninternal reasoning abilities to generate proper responses across various tasks\nwithout the need for manually crafted few-shot examples. Our experimental\nresults demonstrate that TORSO achieves strong performance on diverse LLMs\nbenchmarks with reasonable rationales.", "AI": {"tldr": "TORSO is a method that enhances the reasoning capabilities of LLMs without relying on costly, task-specific, few-shot prompts.", "motivation": "To overcome the limitations of existing few-shot prompting methods, which are costly, task-specific, and depend heavily on provided examples.", "method": "The TORSO framework guides LLMs to leverage their internal reasoning capabilities for problem-solving across tasks without the need for manually crafted examples.", "result": "TORSO achieves high performance across various LLM benchmarks, showcasing its ability to generate effective and logical responses.", "conclusion": "TORSO enables LLMs to solve complex tasks effectively and cost-efficiently by prioritizing internal reasoning over external prompt engineering."}}
{"id": "2509.09229", "pdf": "https://arxiv.org/pdf/2509.09229", "abs": "https://arxiv.org/abs/2509.09229", "authors": ["Matan Cohen", "Shira Shani", "Eden Menahem", "Yehudit Aperstein", "Alexander Apartsin"], "title": "Reading Between the Lines: Classifying Resume Seniority with Large Language Models", "categories": ["cs.CL"], "comment": "5 pages, 3 figures", "summary": "Accurately assessing candidate seniority from resumes is a critical yet\nchallenging task, complicated by the prevalence of overstated experience and\nambiguous self-presentation. In this study, we investigate the effectiveness of\nlarge language models (LLMs), including fine-tuned BERT architectures, for\nautomating seniority classification in resumes. To rigorously evaluate model\nperformance, we introduce a hybrid dataset comprising both real-world resumes\nand synthetically generated hard examples designed to simulate exaggerated\nqualifications and understated seniority. Using the dataset, we evaluate the\nperformance of Large Language Models in detecting subtle linguistic cues\nassociated with seniority inflation and implicit expertise. Our findings\nhighlight promising directions for enhancing AI-driven candidate evaluation\nsystems and mitigating bias introduced by self-promotional language. The\ndataset is available for the research community at https://bit.ly/4mcTovt", "AI": {"tldr": "The paper explores how large language models (LLMs) can be used to classify seniority in resumes, accounting for exaggerated qualifications and ambiguous self-representation.", "motivation": "Assessing seniority in resumes is challenging due to inflated qualifications and ambiguous phrasing, making accurate classification vital.", "method": "The paper uses fine-tuned BERT architectures evaluated on a hybrid dataset with real and synthetic examples to analyze linguistic cues related to seniority.", "result": "The study finds that LLMs can detect subtle linguistic patterns tied to understated expertise and inflated seniority effectively.", "conclusion": "AI-driven systems to assess resumes can be enhanced using LLMs, and the methodology could reduce biases in candidate evaluation."}}
{"id": "2509.09146", "pdf": "https://arxiv.org/pdf/2509.09146", "abs": "https://arxiv.org/abs/2509.09146", "authors": ["Md Ibrahim Ibne Alam", "Ankur Senapati", "Anindo Mahmood", "Murat Yuksel", "Koushik Kar"], "title": "Peering Partner Recommendation for ISPs using Machine Learning", "categories": ["cs.LG"], "comment": "Submitted to IEEE Transactions on Machine Learning in Communications\n  and Networking", "summary": "Internet service providers (ISPs) need to connect with other ISPs to provide\nglobal connectivity services to their users. To ensure global connectivity,\nISPs can either use transit service(s) or establish direct peering\nrelationships between themselves via Internet exchange points (IXPs). Peering\noffers more room for ISP-specific optimizations and is preferred, but it often\ninvolves a lengthy and complex process. Automating peering partner selection\ncan enhance efficiency in the global Internet ecosystem. We explore the use of\npublicly available data on ISPs to develop a machine learning (ML) model that\ncan predict whether an ISP pair should peer or not. At first, we explore public\ndatabases, e.g., PeeringDB, CAIDA, etc., to gather data on ISPs. Then, we\nevaluate the performance of three broad types of ML models for predicting\npeering relationships: tree-based, neural network-based, and transformer-based.\nAmong these, we observe that tree-based models achieve the highest accuracy and\nefficiency in our experiments. The XGBoost model trained with publicly\navailable data showed promising performance, with a 98% accuracy rate in\npredicting peering partners. In addition, the model demonstrated great\nresilience to variations in time, space, and missing data. We envision that\nISPs can adopt our method to fully automate the peering partner selection\nprocess, thus transitioning to a more efficient and optimized Internet\necosystem.", "AI": {"tldr": "The paper develops a machine learning model using publicly available ISP data to automate the prediction of peering relationships, achieving 98% accuracy with XGBoost.", "motivation": "To improve efficiency in ISP peering partner selection, which is often a lengthy and complex process.", "method": "The research involved collecting ISP data from public databases (e.g., PeeringDB, CAIDA) and testing three types of ML models (tree-based, neural networks, transformers) to predict peering relationships.", "result": "Tree-based models performed best, with the XGBoost model achieving 98% accuracy while demonstrating robustness to temporal, spatial, and data availability changes.", "conclusion": "The proposed ML-driven method has the potential to fully automate ISP peering partner selection, leading to a more optimized global Internet ecosystem."}}
{"id": "2509.09090", "pdf": "https://arxiv.org/pdf/2509.09090", "abs": "https://arxiv.org/abs/2509.09090", "authors": ["Hengyu Fang", "Yijiang Liu", "Yuan Du", "Li Du", "Huanrui Yang"], "title": "SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 9 figures", "summary": "Vision-Language-Action (VLA) models exhibit unprecedented capabilities for\nembodied intelligence. However, their extensive computational and memory costs\nhinder their practical deployment. Existing VLA compression and acceleration\napproaches conduct quantization or token pruning in an ad-hoc manner but fail\nto enable both for a holistic efficiency improvement due to an observed\nincompatibility. This work introduces SQAP-VLA, the first structured,\ntraining-free VLA inference acceleration framework that simultaneously enables\nstate-of-the-art quantization and token pruning. We overcome the\nincompatibility by co-designing the quantization and token pruning pipeline,\nwhere we propose new quantization-aware token pruning criteria that work on an\naggressively quantized model while improving the quantizer design to enhance\npruning effectiveness. When applied to standard VLA models, SQAP-VLA yields\nsignificant gains in computational efficiency and inference speed while\nsuccessfully preserving core model performance, achieving a $\\times$1.93\nspeedup and up to a 4.5\\% average success rate enhancement compared to the\noriginal model.", "AI": {"tldr": "SQAP-VLA is a novel inference acceleration framework for Vision-Language-Action models, enhancing efficiency through co-designed quantization and token pruning.", "motivation": "Address the inefficiencies in Vision-Language-Action models by developing a robust solution to their computational and memory demands.", "method": "Proposed a training-free framework that integrates state-of-the-art quantization and token pruning via a co-designed pipeline.", "result": "Achieved 1.93x speedup and up to a 4.5% performance improvement compared to standard VLA models.", "conclusion": "SQAP-VLA effectively balances computational efficiency and model performance, enabling practical deployment of VLA models."}}
{"id": "2509.09467", "pdf": "https://arxiv.org/pdf/2509.09467", "abs": "https://arxiv.org/abs/2509.09467", "authors": ["Alex Dantart"], "title": "Inteligencia Artificial jur\u00eddica y el desaf\u00edo de la veracidad: an\u00e1lisis de alucinaciones, optimizaci\u00f3n de RAG y principios para una integraci\u00f3n responsable", "categories": ["cs.AI"], "comment": "in Spanish and English languages", "summary": "This technical report analyzes the challenge of \"hallucinations\" (false\ninformation) in LLMs applied to law. It examines their causes, manifestations,\nand the effectiveness of the RAG mitigation strategy, highlighting its\nlimitations and proposing holistic optimizations. The paper explores the\nethical and regulatory implications, emphasizing human oversight as an\nirreplaceable role. It concludes that the solution lies not in incrementally\nimproving generative models, but in adopting a \"consultative\" AI paradigm that\nprioritizes veracity and traceability, acting as a tool to amplify, not\nreplace, professional judgment.\n  --\n  Este informe t\\'ecnico analiza el desaf\\'io de las \"alucinaciones\"\n(informaci\\'on falsa) en los LLMs aplicados al derecho. Se examinan sus causas,\nmanifestaciones y la efectividad de la estrategia de mitigaci\\'on RAG,\nexponiendo sus limitaciones y proponiendo optimizaciones hol\\'isticas. Se\nexploran las implicaciones \\'eticas y regulatorias, enfatizando la\nsupervisi\\'on humana como un rol insustituible. El documento concluye que la\nsoluci\\'on no reside en mejorar incrementalmente los modelos generativos, sino\nen adoptar un paradigma de IA \"consultiva\" que priorice la veracidad y la\ntrazabilidad, actuando como una herramienta para amplificar, y no sustituir, el\njuicio profesional.", "AI": {"tldr": "This paper discusses the challenge of hallucinated information in legal applications of LLMs, evaluating causes and strategies for mitigation, and promotes a consultative AI paradigm for accuracy and human oversight.", "motivation": "The motivation behind this study is to address the issue of hallucinations in large language models specifically in the field of law, as their presence undermines trust, accuracy, and ethical considerations in legal applications.", "method": "The paper examines the origins and characteristics of hallucinations in LLMs, reviews the RAG strategy for mitigation, and proposes holistic optimizations. It also analyzes ethical and regulatory dimensions.", "result": "The analysis reveals the limitations of current LLM strategies and emphasizes the importance of adopting more robust frameworks that prioritize fact-checking and human monitoring.", "conclusion": "Instead of iterative model improvements, the study advocates for a consultative AI paradigm that ensures veracity and traceability, leveraging AI as a supportive tool rather than a replacement for human expertise."}}
{"id": "2509.09234", "pdf": "https://arxiv.org/pdf/2509.09234", "abs": "https://arxiv.org/abs/2509.09234", "authors": ["Rishit Tyagi", "Mohit Gupta", "Rahul Bouri"], "title": "Agentic LLMs for Question Answering over Tabular Data", "categories": ["cs.CL"], "comment": "Accepted at ACL workshop SemEval 2025", "summary": "Question Answering over Tabular Data (Table QA) presents unique challenges\ndue to the diverse structure, size, and data types of real-world tables. The\nSemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,\ndomain-diverse datasets to evaluate the ability of models to accurately answer\nstructured queries. We propose a Natural Language to SQL (NL-to-SQL) approach\nleveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and\nDeepSeek v2:16b to generate SQL queries dynamically. Our system follows a\nmulti-stage pipeline involving example selection, SQL query generation, answer\nextraction, verification, and iterative refinement. Experiments demonstrate the\neffectiveness of our approach, achieving 70.5\\% accuracy on DataBench QA and\n71.6\\% on DataBench Lite QA, significantly surpassing baseline scores of 26\\%\nand 27\\% respectively. This paper details our methodology, experimental\nresults, and alternative approaches, providing insights into the strengths and\nlimitations of LLM-driven Table QA.", "AI": {"tldr": "This paper addresses Question Answering over Tabular Data (Table QA) by proposing an NL-to-SQL approach with large language models like GPT-4o and DeepSeek v2. It achieves high accuracy on a new benchmark.", "motivation": "The paper aims to improve Table QA performance, particularly with NL-to-SQL methods, to overcome challenges posed by diverse table structures and data types.", "method": "The authors employ a multi-stage NL-to-SQL pipeline involving example selection, SQL generation, answer extraction, verification, and iterative refinement, using LLMs such as GPT-4o.", "result": "The proposed approach achieved 70.5% accuracy on DataBench QA and 71.6% on DataBench Lite QA, surpassing baseline scores by a significant margin.", "conclusion": "Using LLMs for Table QA is effective in generating SQL queries and answering structured queries, showcasing its strengths and identifying limitations through benchmark evaluations."}}
{"id": "2509.09155", "pdf": "https://arxiv.org/pdf/2509.09155", "abs": "https://arxiv.org/abs/2509.09155", "authors": ["Maria Risques", "Kratika Bhagtani", "Amit Kumar Singh Yadav", "Edward J. Delp"], "title": "HISPASpoof: A New Dataset For Spanish Speech Forensics", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 1 figure, 10 tables, being submitted to ICASSP 2026 (IEEE\n  International Conference on Acoustics, Speech, and Signal Processing 2026)", "summary": "Zero-shot Voice Cloning (VC) and Text-to-Speech (TTS) methods have advanced\nrapidly, enabling the generation of highly realistic synthetic speech and\nraising serious concerns about their misuse. While numerous detectors have been\ndeveloped for English and Chinese, Spanish-spoken by over 600 million people\nworldwide-remains underrepresented in speech forensics. To address this gap, we\nintroduce HISPASpoof, the first large-scale Spanish dataset designed for\nsynthetic speech detection and attribution. It includes real speech from public\ncorpora across six accents and synthetic speech generated with six zero-shot\nTTS systems. We evaluate five representative methods, showing that detectors\ntrained on English fail to generalize to Spanish, while training on HISPASpoof\nsubstantially improves detection. We also evaluate synthetic speech attribution\nperformance on HISPASpoof, i.e., identifying the generation method of synthetic\nspeech. HISPASpoof thus provides a critical benchmark for advancing reliable\nand inclusive speech forensics in Spanish.", "AI": {"tldr": "HISPASpoof is introduced as the first extensive Spanish dataset for detecting and attributing synthetic speech, addressing the underrepresentation of Spanish in speech forensics.", "motivation": "The motivation is to address the lack of adequate tools and datasets for detecting and attributing synthetic speech in Spanish, a language spoken by over 600 million people globally.", "method": "The authors created the HISPASpoof dataset with genuine speech from diverse Spanish accents and synthetic voices generated by six zero-shot TTS systems. They also evaluated the performance of five representative detection methods on this dataset.", "result": "English-trained speech detectors did not generalize well to Spanish. However, training on HISPASpoof notably improved the detection accuracy and enabled effective synthetic speech attribution.", "conclusion": "HISPASpoof is a critical resource for improving speech forensics in Spanish, enhancing both detection and attribution of synthetic speech generation methods."}}
{"id": "2509.09110", "pdf": "https://arxiv.org/pdf/2509.09110", "abs": "https://arxiv.org/abs/2509.09110", "authors": ["Chenghao Zhang", "Lun Luo", "Si-Yuan Cao", "Xiaokai Bai", "Yuncheng Jin", "Zhu Yu", "Beinan Yu", "Yisen Wang", "Hui-Liang Shen"], "title": "S-BEVLoc: BEV-based Self-supervised Framework for Large-scale LiDAR Global Localization", "categories": ["cs.CV"], "comment": null, "summary": "LiDAR-based global localization is an essential component of simultaneous\nlocalization and mapping (SLAM), which helps loop closure and re-localization.\nCurrent approaches rely on ground-truth poses obtained from GPS or SLAM\nodometry to supervise network training. Despite the great success of these\nsupervised approaches, substantial cost and effort are required for\nhigh-precision ground-truth pose acquisition. In this work, we propose\nS-BEVLoc, a novel self-supervised framework based on bird's-eye view (BEV) for\nLiDAR global localization, which eliminates the need for ground-truth poses and\nis highly scalable. We construct training triplets from single BEV images by\nleveraging the known geographic distances between keypoint-centered BEV\npatches. Convolutional neural network (CNN) is used to extract local features,\nand NetVLAD is employed to aggregate global descriptors. Moreover, we introduce\nSoftCos loss to enhance learning from the generated triplets. Experimental\nresults on the large-scale KITTI and NCLT datasets show that S-BEVLoc achieves\nstate-of-the-art performance in place recognition, loop closure, and global\nlocalization tasks, while offering scalability that would require extra effort\nfor supervised approaches.", "AI": {"tldr": "The paper introduces S-BEVLoc, a self-supervised framework for LiDAR-based global localization, eliminating the need for ground-truth pose supervision and achieving superior performance.", "motivation": "Current LiDAR-based global localization models depend heavily on ground-truth poses obtained from GPS or SLAM odometry, which are costly and inefficient to acquire.", "method": "S-BEVLoc uses a self-supervised approach leveraging BEV images and geographic distances to construct training data. It incorporates CNNs for feature extraction, NetVLAD for global descriptor aggregation, and SoftCos loss for learning enhancement.", "result": "S-BEVLoc achieves superior performance on KITTI and NCLT datasets in place recognition, loop closure, and global localization, while demonstrating improved scalability compared to supervised methods.", "conclusion": "The framework significantly reduces dependence on ground-truth poses, advancing LiDAR-based localization tasks in environments where supervised data acquisition is impractical."}}
{"id": "2509.09498", "pdf": "https://arxiv.org/pdf/2509.09498", "abs": "https://arxiv.org/abs/2509.09498", "authors": ["Haoran Xu", "Jiacong Hu", "Ke Zhang", "Lei Yu", "Yuxin Tang", "Xinyuan Song", "Yiqun Duan", "Lynn Ai", "Bill Shi"], "title": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "categories": ["cs.AI"], "comment": null, "summary": "Long-term multi-agent systems inevitably generate vast amounts of\ntrajectories and historical interactions, which makes efficient memory\nmanagement essential for both performance and scalability. Existing methods\ntypically depend on vector retrieval and hierarchical storage, yet they are\nprone to noise accumulation, uncontrolled memory expansion, and limited\ngeneralization across domains. To address these challenges, we present SEDM,\nSelf-Evolving Distributed Memory, a verifiable and adaptive framework that\ntransforms memory from a passive repository into an active, self-optimizing\ncomponent. SEDM integrates verifiable write admission based on reproducible\nreplay, a self-scheduling memory controller that dynamically ranks and\nconsolidates entries according to empirical utility, and cross-domain knowledge\ndiffusion that abstracts reusable insights to support transfer across\nheterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM\nimproves reasoning accuracy while reducing token overhead compared with strong\nmemory baselines, and further enables knowledge distilled from fact\nverification to enhance multi-hop reasoning. The results highlight SEDM as a\nscalable and sustainable memory mechanism for open-ended multi-agent\ncollaboration. The code will be released in the later stage of this project.", "AI": {"tldr": "SEDM offers an advanced memory management system for multi-agent systems, addressing issues like noise accumulation and scalability. Evaluations show improved reasoning accuracy and reduced resource usage.", "motivation": "The study aims to enhance memory management in multi-agent systems for scalability and performance, addressing limitations in existing methods such as noise accumulation and poor cross-domain generalization.", "method": "SEDM includes verifiable write admission using reproducible replay, a self-scheduling memory controller for entry consolidation, and cross-domain knowledge diffusion for insight abstraction. It actively optimizes the memory system.", "result": "SEDM showed improved reasoning accuracy, reduced token overhead, and facilitated enhancements in multi-hop reasoning when evaluated on benchmark datasets.", "conclusion": "SEDM proves to be a scalable and sustainable memory management solution for multi-agent systems, facilitating open-ended collaboration and effective knowledge transfer."}}
{"id": "2509.09303", "pdf": "https://arxiv.org/pdf/2509.09303", "abs": "https://arxiv.org/abs/2509.09303", "authors": ["Grazia Sveva Ascione", "Nicol\u00f2 Tamagnone"], "title": "From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Classifying patents by their relevance to the UN Sustainable Development\nGoals (SDGs) is crucial for tracking how innovation addresses global\nchallenges. However, the absence of a large, labeled dataset limits the use of\nsupervised learning. Existing methods, such as keyword searches, transfer\nlearning, and citation-based heuristics, lack scalability and generalizability.\nThis paper frames patent-to-SDG classification as a weak supervision problem,\nusing citations from patents to SDG-tagged scientific publications (NPL\ncitations) as a noisy initial signal. To address its sparsity and noise, we\ndevelop a composite labeling function (LF) that uses large language models\n(LLMs) to extract structured concepts, namely functions, solutions, and\napplications, from patents and SDG papers based on a patent ontology.\nCross-domain similarity scores are computed and combined using a rank-based\nretrieval approach. The LF is calibrated via a custom positive-only loss that\naligns with known NPL-SDG links without penalizing discovery of new SDG\nassociations. The result is a silver-standard, soft multi-label dataset mapping\npatents to SDGs, enabling the training of effective multi-label regression\nmodels. We validate our approach through two complementary strategies: (1)\ninternal validation against held-out NPL-based labels, where our method\noutperforms several baselines including transformer-based models, and zero-shot\nLLM; and (2) external validation using network modularity in patent citation,\nco-inventor, and co-applicant graphs, where our labels reveal greater thematic,\ncognitive, and organizational coherence than traditional technological\nclassifications. These results show that weak supervision and semantic\nalignment can enhance SDG classification at scale.", "AI": {"tldr": "The paper presents a novel weak supervision approach using large language models to classify patents by their relevance to the UN Sustainable Development Goals (SDGs), overcoming limitations of existing methods.", "motivation": "The motivation is to improve patent classification for SDGs, addressing global challenges more effectively despite the lack of large labeled datasets for training supervised models.", "method": "The method involves using citations from patents to SDG-tagged publications as a noisy initial signal, leveraging large language models to extract structured concepts, and creating a composite labeling function calibrated with a positive-only loss technique.", "result": "The approach produces a silver-standard dataset enabling multi-label regression models that outperform baselines in internal validation and demonstrate thematic and organizational coherence in external validation.", "conclusion": "The study demonstrates that weak supervision and semantic alignment can significantly scale and improve the classification of patents by their relevance to SDGs, setting a foundation for future innovation tracking."}}
{"id": "2509.09297", "pdf": "https://arxiv.org/pdf/2509.09297", "abs": "https://arxiv.org/abs/2509.09297", "authors": ["Spyridon Loukovitis", "Anastasios Arsenos", "Vasileios Karampinis", "Athanasios Voulodimos"], "title": "Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Open-set detection is crucial for robust UAV autonomy in air-to-air object\ndetection under real-world conditions. Traditional closed-set detectors degrade\nsignificantly under domain shifts and flight data corruption, posing risks to\nsafety-critical applications. We propose a novel, model-agnostic open-set\ndetection framework designed specifically for embedding-based detectors. The\nmethod explicitly handles unknown object rejection while maintaining robustness\nagainst corrupted flight data. It estimates semantic uncertainty via entropy\nmodeling in the embedding space and incorporates spectral normalization and\ntemperature scaling to enhance open-set discrimination. We validate our\napproach on the challenging AOT aerial benchmark and through extensive\nreal-world flight tests. Comprehensive ablation studies demonstrate consistent\nimprovements over baseline methods, achieving up to a 10\\% relative AUROC gain\ncompared to standard YOLO-based detectors. Additionally, we show that\nbackground rejection further strengthens robustness without compromising\ndetection accuracy, making our solution particularly well-suited for reliable\nUAV perception in dynamic air-to-air environments.", "AI": {"tldr": "The paper introduces a model-agnostic open-set detection framework for UAV object detection, tackling challenges like domain shifts and corrupted flight data.", "motivation": "To ensure robust and safe UAV autonomy by addressing the limitations of traditional closed-set object detectors under real-world and shifting conditions.", "method": "The proposed framework estimates semantic uncertainty in the embedding space using entropy modeling, applies spectral normalization, and temperature scaling for improved open-set detection.", "result": "The method shows up to a 10% relative improvement in AUROC over YOLO-based detectors and enhances robustness while maintaining accuracy on the AOT benchmark and real-world tests.", "conclusion": "The framework offers reliable UAV perception for air-to-air environments, excelling in unknown object rejection and robustness against data corruption."}}
{"id": "2509.09168", "pdf": "https://arxiv.org/pdf/2509.09168", "abs": "https://arxiv.org/abs/2509.09168", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis"], "title": "Adaptive Pareto-Optimal Token Merging for Edge Transformer Models in Semantic Communication", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "comment": "To appear in IEEE Globecom 2025", "summary": "Large-scale transformer models have emerged as a powerful tool for semantic\ncommunication systems, enabling edge devices to extract rich representations\nfor robust inference across noisy wireless channels. However, their substantial\ncomputational demands remain a major barrier to practical deployment in\nresource-constrained 6G networks. In this paper, we present a training-free\nframework for adaptive token merging in pretrained vision transformers to\njointly reduce inference time and transmission resource usage. We formulate the\nselection of per-layer merging proportions as a multi-objective optimization\nproblem to balance accuracy and computational cost. We employ Gaussian\nprocess-based Bayesian optimization to construct a Pareto frontier of optimal\nconfigurations, enabling flexible runtime adaptation to dynamic application\nrequirements and channel conditions. Extensive experiments demonstrate that our\nmethod consistently outperforms other baselines and achieves significant\nreductions in floating-point operations while maintaining competitive accuracy\nacross a wide range of signal-to-noise ratio (SNR) conditions. Additional\nresults highlight the effectiveness of adaptive policies that adjust merging\naggressiveness in response to channel quality, providing a practical mechanism\nto trade off latency and semantic fidelity on demand. These findings establish\na scalable and efficient approach for deploying transformer-based semantic\ncommunication in future edge intelligence systems.", "AI": {"tldr": "The paper proposes an adaptive token merging framework for pretrained vision transformers to optimize inference time and transmission resources in resource-constrained 6G networks.", "motivation": "Current large-scale transformer models are powerful for semantic communication systems but face challenges due to high computational requirements, especially in 6G networks.", "method": "The authors use adaptive token merging combined with Gaussian process-based Bayesian optimization to balance accuracy and computational cost, creating a Pareto frontier for runtime adaptation based on dynamic requirements and channel conditions.", "result": "Experiments show significant reductions in computational operations while maintaining accuracy across varying SNR conditions, outperforming other methods.", "conclusion": "The proposed method provides an efficient mechanism for deploying transformer-based semantic communication systems in edge intelligence, allowing practical adaptation to network and application dynamics."}}
{"id": "2509.09111", "pdf": "https://arxiv.org/pdf/2509.09111", "abs": "https://arxiv.org/abs/2509.09111", "authors": ["Jianqin Gao", "Tianqi Wang", "Yu Zhang", "Yishu Zhang", "Chenyuan Wang", "Allan Dong", "Zihao Wang"], "title": "FPI-Det: a face--phone Interaction Dataset for phone-use detection and understanding", "categories": ["cs.CV"], "comment": null, "summary": "The widespread use of mobile devices has created new challenges for vision\nsystems in safety monitoring, workplace productivity assessment, and attention\nmanagement. Detecting whether a person is using a phone requires not only\nobject recognition but also an understanding of behavioral context, which\ninvolves reasoning about the relationship between faces, hands, and devices\nunder diverse conditions. Existing generic benchmarks do not fully capture such\nfine-grained human--device interactions. To address this gap, we introduce the\nFPI-Det, containing 22{,}879 images with synchronized annotations for faces and\nphones across workplace, education, transportation, and public scenarios. The\ndataset features extreme scale variation, frequent occlusions, and varied\ncapture conditions. We evaluate representative YOLO and DETR detectors,\nproviding baseline results and an analysis of performance across object sizes,\nocclusion levels, and environments. Source code and dataset is available at\nhttps://github.com/KvCgRv/FPI-Det.", "AI": {"tldr": "This paper introduces FPI-Det, a dataset addressing challenges like detecting phone usage behavior in diverse contexts, and provides baseline evaluations using YOLO and DETR.", "motivation": "The study aims to tackle the limitations of existing benchmarks in capturing fine-grained interactions between humans and devices, for applications in safety monitoring and productivity.", "method": "The authors create FPI-Det, a dataset with 22,879 annotated images characterizing relationships among faces, phones, and hands. They test YOLO and DETR as baseline detectors.", "result": "Baseline evaluations using YOLO and DETR detectors are presented, with performance analysis across varying object sizes, occlusions, and environmental contexts.", "conclusion": "FPI-Det advances the understanding of human-device interactions in vision systems and serves as a resource for evaluating detector performance in challenging contexts."}}
{"id": "2509.09541", "pdf": "https://arxiv.org/pdf/2509.09541", "abs": "https://arxiv.org/abs/2509.09541", "authors": ["Hala Hawashin", "Mina Abbaszadeh", "Nicholas Joseph", "Beth Pearson", "Martha Lewis", "Mehrnoosh sadrzadeh"], "title": "Compositional Concept Generalization with Variational Quantum Circuits", "categories": ["cs.AI"], "comment": "Accepted to: 2025 IEEE International Conference on Quantum Artificial\n  Intelligence (QAI), Naples, Italy, Nov 2-5, 2025. This is the authors'\n  accepted manuscript (AAM). An IEEE copyright notice appears on page 1. The\n  final published version will appear in IEEE Xplore; DOI to be added when\n  available", "summary": "Compositional generalization is a key facet of human cognition, but lacking\nin current AI tools such as vision-language models. Previous work examined\nwhether a compositional tensor-based sentence semantics can overcome the\nchallenge, but led to negative results. We conjecture that the increased\ntraining efficiency of quantum models will improve performance in these tasks.\nWe interpret the representations of compositional tensor-based models in\nHilbert spaces and train Variational Quantum Circuits to learn these\nrepresentations on an image captioning task requiring compositional\ngeneralization. We used two image encoding techniques: a multi-hot encoding\n(MHE) on binary image vectors and an angle/amplitude encoding on image vectors\ntaken from the vision-language model CLIP. We achieve good proof-of-concept\nresults using noisy MHE encodings. Performance on CLIP image vectors was more\nmixed, but still outperformed classical compositional models.", "AI": {"tldr": "This paper explores quantum-enhanced tensor-based models for compositional generalization in vision-language tasks, showing promising results but some limitations.", "motivation": "The motivation is to address the lack of compositional generalization in current AI tools such as vision-language models, by leveraging quantum models' increased training efficiency.", "method": "The method involves interpreting tensor-based sentence semantics in Hilbert spaces and training Variational Quantum Circuits for an image captioning task. Two encoding techniques are tested: multi-hot encoding (MHE) and angle/amplitude encoding using CLIP vectors.", "result": "The model showed good performance with noisy MHE encodings, while performance with CLIP vectors was more mixed but still better than classical approaches.", "conclusion": "Quantum models show potential for improving compositional generalization, though further refinements are needed for broader applicability."}}
{"id": "2509.09360", "pdf": "https://arxiv.org/pdf/2509.09360", "abs": "https://arxiv.org/abs/2509.09360", "authors": ["Channdeth Sok", "David Luz", "Yacine Haddam"], "title": "MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems", "categories": ["cs.CL"], "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly deployed in enterprise\napplications, yet their reliability remains limited by hallucinations, i.e.,\nconfident but factually incorrect information. Existing detection approaches,\nsuch as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not\naddress the unique challenges of Retrieval-Augmented Generation (RAG) systems,\nwhere responses must be consistent with retrieved evidence. We therefore\npresent MetaRAG, a metamorphic testing framework for hallucination detection in\nRetrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,\nunsupervised, black-box setting, requiring neither ground-truth references nor\naccess to model internals, making it suitable for proprietary and high-stakes\ndomains. The framework proceeds in four stages: (1) decompose answers into\natomic factoids, (2) generate controlled mutations of each factoid using\nsynonym and antonym substitutions, (3) verify each variant against the\nretrieved context (synonyms are expected to be entailed and antonyms\ncontradicted), and (4) aggregate penalties for inconsistencies into a\nresponse-level hallucination score. Crucially for identity-aware AI, MetaRAG\nlocalizes unsupported claims at the factoid span where they occur (e.g.,\npregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),\nallowing users to see flagged spans and enabling system designers to configure\nthresholds and guardrails for identity-sensitive queries. Experiments on a\nproprietary enterprise dataset illustrate the effectiveness of MetaRAG for\ndetecting hallucinations and enabling trustworthy deployment of RAG-based\nconversational agents. We also outline a topic-based deployment design that\ntranslates MetaRAG's span-level scores into identity-aware safeguards; this\ndesign is discussed but not evaluated in our experiments.", "AI": {"tldr": "MetaRAG is a framework for detecting hallucinations in Retrieval-Augmented Generation (RAG) systems by verifying factoids and monitoring inconsistencies, enabling trustworthy deployments in sensitive domains.", "motivation": "The motivation is to address the challenge of hallucination in RAG systems, offering reliable, real-time detection suitable for proprietary and high-stakes applications.", "method": "MetaRAG decomposes answers into factoids, mutates them with synonym/antonym substitutions, verifies consistency with the retrieved context, and aggregates hallucination scores.", "result": "Experiments on a proprietary dataset show that MetaRAG effectively detects hallucinations and supports trustworthy deployment in enterprise applications.", "conclusion": "MetaRAG improves hallucination detection in RAG systems, especially for identity-sensitive queries, allowing customizable safeguards for sensitive deployments."}}
{"id": "2509.09349", "pdf": "https://arxiv.org/pdf/2509.09349", "abs": "https://arxiv.org/abs/2509.09349", "authors": ["Ian Nell", "Shane Gilroy"], "title": "Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.RO", "eess.IV"], "comment": null, "summary": "Road traffic accidents remain a significant global concern, with human error,\nparticularly distracted and impaired driving, among the leading causes. This\nstudy introduces a novel driver behavior classification system that uses\nexternal observation techniques to detect indicators of distraction and\nimpairment. The proposed framework employs advanced computer vision\nmethodologies, including real-time object tracking, lateral displacement\nanalysis, and lane position monitoring. The system identifies unsafe driving\nbehaviors such as excessive lateral movement and erratic trajectory patterns by\nimplementing the YOLO object detection model and custom lane estimation\nalgorithms. Unlike systems reliant on inter-vehicular communication, this\nvision-based approach enables behavioral analysis of non-connected vehicles.\nExperimental evaluations on diverse video datasets demonstrate the framework's\nreliability and adaptability across varying road and environmental conditions.", "AI": {"tldr": "The paper introduces a computer vision-based system for classifying driver behavior to detect distraction and impairment.", "motivation": "To address the critical issue of traffic accidents caused by human errors like distracted and impaired driving.", "method": "The system uses advanced computer vision such as YOLO object detection, lateral displacement analysis, and lane position monitoring to analyze unsafe driving behaviors.", "result": "Experimental evaluations show the system's reliability and adaptability across diverse road and environmental conditions.", "conclusion": "The framework provides an effective solution for behavioral analysis in non-connected vehicles, improving road safety through external observation."}}
{"id": "2509.09176", "pdf": "https://arxiv.org/pdf/2509.09176", "abs": "https://arxiv.org/abs/2509.09176", "authors": ["Jun-Hao Chen", "Yu-Chien Huang", "Yun-Cheng Tsai", "Samuel Yen-Chi Chen"], "title": "Quantum Machine Learning, Quantitative Trading, Reinforcement Learning, Deep Learning", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "The convergence of quantum-inspired neural networks and deep reinforcement\nlearning offers a promising avenue for financial trading. We implemented a\ntrading agent for USD/TWD by integrating Quantum Long Short-Term Memory (QLSTM)\nfor short-term trend prediction with Quantum Asynchronous Advantage\nActor-Critic (QA3C), a quantum-enhanced variant of the classical A3C. Trained\non data from 2000-01-01 to 2025-04-30 (80\\% training, 20\\% testing), the\nlong-only agent achieves 11.87\\% return over around 5 years with 0.92\\% max\ndrawdown, outperforming several currency ETFs. We detail state design (QLSTM\nfeatures and indicators), reward function for trend-following/risk control, and\nmulti-core training. Results show hybrid models yield competitive FX trading\nperformance. Implications include QLSTM's effectiveness for small-profit trades\nwith tight risk and future enhancements. Key hyperparameters: QLSTM sequence\nlength$=$4, QA3C workers$=$8. Limitations: classical quantum simulation and\nsimplified strategy. \\footnote{The views expressed in this article are those of\nthe authors and do not represent the views of Wells Fargo. This article is for\ninformational purposes only. Nothing contained in this article should be\nconstrued as investment advice. Wells Fargo makes no express or implied\nwarranties and expressly disclaims all legal, tax, and accounting implications\nrelated to this article.", "AI": {"tldr": "The study integrates quantum-inspired neural networks with deep reinforcement learning to develop a trading agent for USD/TWD, achieving notable results but facing limitations in classical quantum simulation.", "motivation": "To explore the intersection of quantum-inspired machine learning and deep reinforcement learning for enhancing financial trading strategies.", "method": "A Quantum LSTM model for predicting short-term trends is combined with a Quantum A3C model for reinforcement learning. The agent is trained on 25+ years of USD/TWD data, using a reward system for trend-following and risk control, along with multi-core training mechanisms.", "result": "The USD/TWD trading agent achieved a 11.87% return over 5 years, with a 0.92% max drawdown, outperforming currency ETFs.", "conclusion": "Quantum-inspired models demonstrate competitive FX trading performance with effective risk control, but face constraints in classical simulation and simplified strategy design."}}
{"id": "2509.09116", "pdf": "https://arxiv.org/pdf/2509.09116", "abs": "https://arxiv.org/abs/2509.09116", "authors": ["Junhao Xing", "Ryohei Miyakawa", "Yang Yang", "Xinpeng Liu", "Risa Shinoda", "Hiroaki Santo", "Yosuke Toda", "Fumio Okura"], "title": "Zero-shot Hierarchical Plant Segmentation via Foundation Segmentation Models and Text-to-image Attention", "categories": ["cs.CV"], "comment": "WACV 2026 accepted", "summary": "Foundation segmentation models achieve reasonable leaf instance extraction\nfrom top-view crop images without training (i.e., zero-shot). However,\nsegmenting entire plant individuals with each consisting of multiple\noverlapping leaves remains challenging. This problem is referred to as a\nhierarchical segmentation task, typically requiring annotated training\ndatasets, which are often species-specific and require notable human labor. To\naddress this, we introduce ZeroPlantSeg, a zero-shot segmentation for\nrosette-shaped plant individuals from top-view images. We integrate a\nfoundation segmentation model, extracting leaf instances, and a vision-language\nmodel, reasoning about plants' structures to extract plant individuals without\nadditional training. Evaluations on datasets with multiple plant species,\ngrowth stages, and shooting environments demonstrate that our method surpasses\nexisting zero-shot methods and achieves better cross-domain performance than\nsupervised methods. Implementations are available at\nhttps://github.com/JunhaoXing/ZeroPlantSeg.", "AI": {"tldr": "ZeroPlantSeg introduces an innovative zero-shot segmentation method using foundation segmentation and vision-language models to extract hierarchical plant structures without training.", "motivation": "Current approaches struggle to segment entire plant individuals, requiring species-specific annotated datasets and significant human labor.", "method": "ZeroPlantSeg leverages foundation segmentation models for leaf extraction and vision-language models to interpret plant structures, enabling zero-shot hierarchical segmentation.", "result": "The method demonstrates superior cross-domain performance over supervised approaches and outperforms existing zero-shot methods across diverse datasets.", "conclusion": "ZeroPlantSeg offers an efficient solution for plant segmentation by combining cutting-edge models, reducing reliance on annotated datasets and improving segmentation quality."}}
{"id": "2509.09560", "pdf": "https://arxiv.org/pdf/2509.09560", "abs": "https://arxiv.org/abs/2509.09560", "authors": ["Shulai Zhang", "Ao Xu", "Quan Chen", "Han Zhao", "Weihao Cui", "Ningxin Zheng", "Haibin Lin", "Xin Liu", "Minyi Guo"], "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Embodied AI systems operate in dynamic environments, requiring seamless\nintegration of perception and generation modules to process high-frequency\ninput and output demands. Traditional sequential computation patterns, while\neffective in ensuring accuracy, face significant limitations in achieving the\nnecessary \"thinking\" frequency for real-world applications. In this work, we\npresent Auras, an algorithm-system co-designed inference framework to optimize\nthe inference frequency of embodied AI agents. Auras disaggregates the\nperception and generation and provides controlled pipeline parallelism for them\nto achieve high and stable throughput. Faced with the data staleness problem\nthat appears when the parallelism is increased, Auras establishes a public\ncontext for perception and generation to share, thereby promising the accuracy\nof embodied agents. Experimental results show that Auras improves throughput by\n2.54x on average while achieving 102.7% of the original accuracy, demonstrating\nits efficacy in overcoming the constraints of sequential computation and\nproviding high throughput.", "AI": {"tldr": "The paper introduces Auras, an inference framework enhancing throughput and accuracy for embodied AI systems via optimized parallelism between perception and generation.", "motivation": "Embodied AI faces challenges in real-world, dynamic environments due to the limitations of sequential computation in ensuring high-frequency inference.", "method": "Auras uses pipeline parallelism to disaggregate perception and generation while addressing data staleness with a public context shared by these components.", "result": "Auras improves throughput by 2.54x on average and achieves 102.7% of the original accuracy, demonstrating enhanced performance and stability in inference.", "conclusion": "Auras effectively overcomes limitations of sequential computation in embodied AI, offering a scalable and efficient solution to achieve higher throughput and robust accuracy."}}
{"id": "2509.09381", "pdf": "https://arxiv.org/pdf/2509.09381", "abs": "https://arxiv.org/abs/2509.09381", "authors": ["Molly R Petersen", "Claire E Stevenson", "Lonneke van der Plas"], "title": "Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research", "categories": ["cs.CL"], "comment": null, "summary": "Analogical reasoning is an essential aspect of human cognition. In this\npaper, we summarize key theory about the processes underlying analogical\nreasoning from the cognitive science literature and relate it to current\nresearch in natural language processing. While these processes can be easily\nlinked to concepts in NLP, they are generally not viewed through a cognitive\nlens. Furthermore, we show how these notions are relevant for several major\nchallenges in NLP research, not directly related to analogy solving. This may\nguide researchers to better optimize relational understanding in text, as\nopposed to relying heavily on entity-level similarity.", "AI": {"tldr": "The paper explores the cognitive science theories of analogical reasoning and their relevance to natural language processing (NLP), suggesting applications for improving relational understanding.", "motivation": "To bridge the gap between cognitive science theories of analogical reasoning and their applications in NLP, thereby improving relational understanding in text-based tasks.", "method": "The authors summarize cognitive science theories of analogical reasoning and illustrate their applicability to various challenges in NLP beyond analogy solving.", "result": "The paper successfully links processes in cognitive analogical reasoning to NLP concepts, demonstrating their relevance to major challenges in the field.", "conclusion": "By adopting a cognitive lens, NLP researchers can enhance relational understanding in text, moving beyond reliance on entity-level similarity."}}
{"id": "2509.09177", "pdf": "https://arxiv.org/pdf/2509.09177", "abs": "https://arxiv.org/abs/2509.09177", "authors": ["Hanyi Mao", "Quanjia Xiao", "Lei Pang", "Haixiao Liu"], "title": "Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL", "categories": ["cs.LG"], "comment": null, "summary": "We propose FSPO (Fair Sequence Policy Optimization), a sequence-level\nreinforcement learning method for LLMs that enforces length-fair clipping\ndirectly in the importance-sampling (IS) weight space. We revisit\nsequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping\nis transplanted to sequences: a fixed clip range systematically reweights short\nvs. long responses, distorting the effective objective. Theoretically, we\nformalize length fairness via a Length Reweighting Error (LRE) and prove that\nsmall LRE yields a directional cosine guarantee between the clipped and true\nupdates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the\nsequence log-IS ratio with a band that applies a KL-corrected drift term and\nscales as $\\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,\nstabilizes training, and outperforms all baselines across multiple evaluation\ndatasets.", "AI": {"tldr": "The paper introduces FSPO, a reinforcement learning method tailored for large language models (LLMs) that enforces fair handling of sequences of different lengths during optimization.", "motivation": "Addressing the mismatch caused by standard PPO/GRPO-style clipping when applied to sequences, which leads to biases in handling short vs. long responses.", "method": "FSPO incorporates sequence-level reinforcement learning with a Gaussian-inspired adjustment to clip sequence log-importance-sampling (IS) ratios. This involves a KL-corrected drift term scaled by $\\sqrt{L}$ to maintain length fairness.", "result": "FSPO achieves consistent clip rates across different lengths, stabilizes training dynamics, and surpasses existing baselines on various evaluation datasets.", "conclusion": "The approach ensures fair optimization irrespective of sequence length, improving stability and performance in sequence-level tasks for LLMs."}}
{"id": "2509.09118", "pdf": "https://arxiv.org/pdf/2509.09118", "abs": "https://arxiv.org/abs/2509.09118", "authors": ["Tianlu Zheng", "Yifan Zhang", "Xiang An", "Ziyong Feng", "Kaicheng Yang", "Qichuan Ding"], "title": "Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval", "categories": ["cs.CV"], "comment": "Accepted by EMNLP2025 Main", "summary": "Although Contrastive Language-Image Pre-training (CLIP) exhibits strong\nperformance across diverse vision tasks, its application to person\nrepresentation learning faces two critical challenges: (i) the scarcity of\nlarge-scale annotated vision-language data focused on person-centric images,\nand (ii) the inherent limitations of global contrastive learning, which\nstruggles to maintain discriminative local features crucial for fine-grained\nmatching while remaining vulnerable to noisy text tokens. This work advances\nCLIP for person representation learning through synergistic improvements in\ndata curation and model architecture. First, we develop a noise-resistant data\nconstruction pipeline that leverages the in-context learning capabilities of\nMLLMs to automatically filter and caption web-sourced images. This yields\nWebPerson, a large-scale dataset of 5M high-quality person-centric image-text\npairs. Second, we introduce the GA-DMS (Gradient-Attention Guided Dual-Masking\nSynergetic) framework, which improves cross-modal alignment by adaptively\nmasking noisy textual tokens based on the gradient-attention similarity score.\nAdditionally, we incorporate masked token prediction objectives that compel the\nmodel to predict informative text tokens, enhancing fine-grained semantic\nrepresentation learning. Extensive experiments show that GA-DMS achieves\nstate-of-the-art performance across multiple benchmarks.", "AI": {"tldr": "The paper advances CLIP for person representation learning by addressing data scarcity and global contrastive limitations with a curated dataset (WebPerson) and a new GA-DMS framework for better alignment and semantic learning.", "motivation": "CLIP struggles with person representation learning due to limited annotated data and challenges in maintaining local discriminative features amidst noisy text tokens.", "method": "The paper introduces WebPerson, a 5M image-text dataset, and the GA-DMS framework, which enhances cross-modal alignment by adaptively masking noisy tokens using gradient-attention similarity and predicting informative text tokens.", "result": "Extensive experiments demonstrate that the GA-DMS framework achieves state-of-the-art performance across multiple benchmarks for person representation tasks.", "conclusion": "These advancements in data curation and model architecture significantly improve person representation learning, showcasing robustness and enhanced fine-grained matching."}}
{"id": "2509.09677", "pdf": "https://arxiv.org/pdf/2509.09677", "abs": "https://arxiv.org/abs/2509.09677", "authors": ["Akshit Sinha", "Arvindh Arun", "Shashwat Goel", "Steffen Staab", "Jonas Geiping"], "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Does continued scaling of large language models (LLMs) yield diminishing\nreturns? Real-world value often stems from the length of task an agent can\ncomplete. We start this work by observing the simple but counterintuitive fact\nthat marginal gains in single-step accuracy can compound into exponential\nimprovements in the length of a task a model can successfully complete. Then,\nwe argue that failures of LLMs when simple tasks are made longer arise from\nmistakes in execution, rather than an inability to reason. We propose isolating\nexecution capability, by explicitly providing the knowledge and plan needed to\nsolve a long-horizon task. We find that larger models can correctly execute\nsignificantly more turns even when small models have 100\\% single-turn\naccuracy. We observe that the per-step accuracy of models degrades as the\nnumber of steps increases. This is not just due to long-context limitations --\ncuriously, we observe a self-conditioning effect -- models become more likely\nto make mistakes when the context contains their errors from prior turns.\nSelf-conditioning does not reduce by just scaling the model size. In contrast,\nrecent thinking models do not self-condition, and can also execute much longer\ntasks in a single turn. We conclude by benchmarking frontier thinking models on\nthe length of task they can execute in a single turn. Overall, by focusing on\nthe ability to execute, we hope to reconcile debates on how LLMs can solve\ncomplex reasoning problems yet fail at simple tasks when made longer, and\nhighlight the massive benefits of scaling model size and sequential test-time\ncompute for long-horizon tasks.", "AI": {"tldr": "The paper explores how scaling large language models impacts their ability to correctly execute long-horizon tasks, finding issues like self-conditioning errors, yet noting that larger models achieve significant benefits.", "motivation": "The research is motivated by the observation that while large language models fail at simple tasks when extended, their reasoning capability versus execution capability needs to be decoupled to better understand their limitations.", "method": "The approach isolates execution capability by providing necessary explicit knowledge and plans for solving longer tasks and examines the impact of scaling models and thinking model paradigms on task length and error dynamics.", "result": "Larger models demonstrate improved execution over longer tasks compared to smaller ones, but also exhibit increasing self-conditioning errors when exposed to their earlier mistakes in context.", "conclusion": "Scaling LLMs improves performance on long tasks but does not inherently address self-conditioning errors. Thinking models avoid these errors, suggesting the need for alternative methods to enhance execution accuracy in scaled LLMs."}}
{"id": "2509.09388", "pdf": "https://arxiv.org/pdf/2509.09388", "abs": "https://arxiv.org/abs/2509.09388", "authors": ["Ana Ezquerro", "Carlos G\u00f3mez-Rodr\u00edguez", "David Vilares"], "title": "Hierarchical Bracketing Encodings Work for Dependency Graphs", "categories": ["cs.CL"], "comment": "Accepted at EMNLP 2025 (main)", "summary": "We revisit hierarchical bracketing encodings from a practical perspective in\nthe context of dependency graph parsing. The approach encodes graphs as\nsequences, enabling linear-time parsing with $n$ tagging actions, and still\nrepresenting reentrancies, cycles, and empty nodes. Compared to existing graph\nlinearizations, this representation substantially reduces the label space while\npreserving structural information. We evaluate it on a multilingual and\nmulti-formalism benchmark, showing competitive results and consistent\nimprovements over other methods in exact match accuracy.", "AI": {"tldr": "The paper revisits hierarchical bracketing encodings for dependency graph parsing, enabling efficient linear-time parsing and demonstrating strong performance on multilingual benchmarks.", "motivation": "To improve the efficiency and accuracy of parsing dependency graphs by reducing label complexity and preserving structural details, addressing challenges with reentrancies, cycles, and empty nodes.", "method": "The paper proposes encoding dependency graphs as sequences using hierarchical bracketing. This approach requires only $n$ tagging actions, allowing linear-time parsing while still representing complex structural features of graphs.", "result": "The proposed method achieved competitive results and showed consistent improvements in exact match accuracy compared to existing methods in multilingual and multi-formalism benchmarks.", "conclusion": "Hierarchical bracketing is an effective approach to dependency graph parsing, offering both structural integrity and efficiency, with improved exact match accuracy in diverse settings."}}
{"id": "2509.09584", "pdf": "https://arxiv.org/pdf/2509.09584", "abs": "https://arxiv.org/abs/2509.09584", "authors": ["Lingdong Kong", "Dongyue Lu", "Ao Liang", "Rong Li", "Yuhao Dong", "Tianshuai Hu", "Lai Xing Ng", "Wei Tsang Ooi", "Benoit R. Cottereau"], "title": "Visual Grounding from Event Cameras", "categories": ["cs.CV", "cs.RO"], "comment": "Abstract Paper (Non-Archival) @ ICCV 2025 NeVi Workshop", "summary": "Event cameras capture changes in brightness with microsecond precision and\nremain reliable under motion blur and challenging illumination, offering clear\nadvantages for modeling highly dynamic scenes. Yet, their integration with\nnatural language understanding has received little attention, leaving a gap in\nmultimodal perception. To address this, we introduce Talk2Event, the first\nlarge-scale benchmark for language-driven object grounding using event data.\nBuilt on real-world driving scenarios, Talk2Event comprises 5,567 scenes,\n13,458 annotated objects, and more than 30,000 carefully validated referring\nexpressions. Each expression is enriched with four structured attributes --\nappearance, status, relation to the viewer, and relation to surrounding objects\n-- that explicitly capture spatial, temporal, and relational cues. This\nattribute-centric design supports interpretable and compositional grounding,\nenabling analysis that moves beyond simple object recognition to contextual\nreasoning in dynamic environments. We envision Talk2Event as a foundation for\nadvancing multimodal and temporally-aware perception, with applications\nspanning robotics, human-AI interaction, and so on.", "AI": {"tldr": "This paper introduces Talk2Event, a benchmark linking natural language and event camera data for language-driven object grounding in dynamic scenes.", "motivation": "Event cameras excel in capturing highly dynamic scenes and low-light scenarios, but their integration with natural language understanding is largely unexplored.", "method": "Develop Talk2Event, a dataset with over 30,000 annotated language expressions linked to 5,567 event-camera driving scenes, focusing on interpretable grounding via four structured attributes.", "result": "The dataset enables complex contextual reasoning, moving beyond object recognition to detailed temporal and spatial relation analysis in dynamic environments.", "conclusion": "Talk2Event lays the groundwork for multimodal, temporally-aware perception systems and has broad application potential in AI, robotics, and human-AI interaction."}}
{"id": "2509.09195", "pdf": "https://arxiv.org/pdf/2509.09195", "abs": "https://arxiv.org/abs/2509.09195", "authors": ["Md Tanveer Hossain Munim"], "title": "Breaking the Statistical Similarity Trap in Extreme Convection Detection", "categories": ["cs.LG", "cs.CV", "68T07, 86A10", "I.2.6; J.2"], "comment": "43 pages, 7 figures", "summary": "Current evaluation metrics for deep learning weather models create a\n\"Statistical Similarity Trap\", rewarding blurry predictions while missing rare,\nhigh-impact events. We provide quantitative evidence of this trap, showing\nsophisticated baselines achieve 97.9% correlation yet 0.00 CSI for dangerous\nconvection detection. We introduce DART (Dual Architecture for Regression\nTasks), a framework addressing the challenge of transforming coarse atmospheric\nforecasts into high-resolution satellite brightness temperature fields\noptimized for extreme convection detection (below 220 K). DART employs\ndual-decoder architecture with explicit background/extreme decomposition,\nphysically motivated oversampling, and task-specific loss functions. We present\nfour key findings: (1) empirical validation of the Statistical Similarity Trap\nacross multiple sophisticated baselines; (2) the \"IVT Paradox\", removing\nIntegrated Water Vapor Transport, widely regarded as essential for atmospheric\nriver analysis, improves extreme convection detection by 270%; (3)\narchitectural necessity demonstrated through operational flexibility (DART\nachieves CSI = 0.273 with bias = 2.52 vs. 6.72 for baselines at equivalent\nCSI), and (4) real-world validation with the August 2023 Chittagong flooding\ndisaster as a case study. To our knowledge, this is the first work to\nsystematically address this hybrid conversion-segmentation-downscaling task,\nwith no direct prior benchmarks identified in existing literature. Our\nvalidation against diverse statistical and deep learning baselines sufficiently\ndemonstrates DART's specialized design. The framework enables precise\noperational calibration through beta-tuning, trains in under 10 minutes on\nstandard hardware, and integrates seamlessly with existing meteorological\nworkflows, demonstrating a pathway toward trustworthy AI for extreme weather\npreparedness.", "AI": {"tldr": "This paper highlights the limitations of current evaluation metrics for deep learning weather models in detecting extreme weather events and introduces a new framework, DART, to improve detection using advanced architecture and task-specific optimizations.", "motivation": "The motivation stems from the inability of current metrics to accurately detect rare but high-impact weather events, leading to models that perform well statistically but fail practically in extreme conditions.", "method": "The authors propose the DART framework, which utilizes a dual-decoder architecture, explicit event decomposition, physically motivated oversampling, and specialized loss functions tailored for detecting extreme convection events in atmospheric forecasts.", "result": "The DART framework achieved significant improvements, such as a 270% detection increase after removing irrelevant features ('IVT Paradox') and a CSI value of 0.273 with reduced bias compared to baselines. It was validated using a real-world case study of the 2023 Chittagong flooding.", "conclusion": "DART effectively addresses the challenge of transforming coarse atmospheric data into high-resolution outputs optimized for extreme event detection, demonstrating trustworthiness and operational efficiency for meteorological applications."}}
{"id": "2509.09130", "pdf": "https://arxiv.org/pdf/2509.09130", "abs": "https://arxiv.org/abs/2509.09130", "authors": ["Bin Huang", "Kang Chen", "Bingxuan Li", "Huafeng Liu", "Qiegen Liu"], "title": "ALL-PET: A Low-resource and Low-shot PET Foundation Model in the Projection Domain", "categories": ["cs.CV"], "comment": null, "summary": "Building large-scale foundation model for PET imaging is hindered by limited\naccess to labeled data and insufficient computational resources. To overcome\ndata scarcity and efficiency limitations, we propose ALL-PET, a low-resource,\nlow-shot PET foundation model operating directly in the projection domain.\nALL-PET leverages a latent diffusion model (LDM) with three key innovations.\nFirst, we design a Radon mask augmentation strategy (RMAS) that generates over\n200,000 structurally diverse training samples by projecting randomized\nimage-domain masks into sinogram space, significantly improving generalization\nwith minimal data. This is extended by a dynamic multi-mask (DMM) mechanism\nthat varies mask quantity and distribution, enhancing data diversity without\nadded model complexity. Second, we implement positive/negative mask constraints\nto embed strict geometric consistency, reducing parameter burden while\npreserving generation quality. Third, we introduce transparent medical\nattention (TMA), a parameter-free, geometry-driven mechanism that enhances\nlesion-related regions in raw projection data. Lesion-focused attention maps\nare derived from coarse segmentation, covering both hypermetabolic and\nhypometabolic areas, and projected into sinogram space for physically\nconsistent guidance. The system supports clinician-defined ROI adjustments,\nensuring flexible, interpretable, and task-adaptive emphasis aligned with PET\nacquisition physics. Experimental results show ALL-PET achieves high-quality\nsinogram generation using only 500 samples, with performance comparable to\nmodels trained on larger datasets. ALL-PET generalizes across tasks including\nlow-dose reconstruction, attenuation correction, delayed-frame prediction, and\ntracer separation, operating efficiently with memory use under 24GB.", "AI": {"tldr": "The paper introduces ALL-PET, a low-resource PET foundation model that uses innovative augmentation and attention techniques to operate efficiently in the projection domain.", "motivation": "Limited labeled data and computational resources hinder building large-scale foundation models for PET imaging.", "method": "ALL-PET utilizes latent diffusion models with Radon mask augmentation, dynamic multi-mask mechanisms, positive/negative mask constraints, and a transparent medical attention mechanism to enhance data diversity, ensure geometric consistency, and focus on lesion-related areas.", "result": "ALL-PET achieves high-quality sinogram generation with only 500 samples, demonstrating strong generalization to various PET imaging tasks and efficient memory usage under 24GB.", "conclusion": "The work presents a resource-efficient and generalizable approach, leveraging innovative projection-domain strategies for PET imaging tasks."}}
{"id": "2509.08829", "pdf": "https://arxiv.org/pdf/2509.08829", "abs": "https://arxiv.org/abs/2509.08829", "authors": ["Chandan Kumar Sah"], "title": "PerFairX: Is There a Balance Between Fairness and Personality in Large Language Model Recommendations?", "categories": ["cs.CY", "cs.AI", "cs.IR"], "comment": "10 pages, 5 figures. Accepted to the Workshop on Multimodal Continual\n  Learning (MCL) at ICCV 2025. @2025 IEEE/CVF International Conference on\n  Computer Vision Workshops (ICCVW), ICCV's 2025", "summary": "The integration of Large Language Models (LLMs) into recommender systems has\nenabled zero-shot, personality-based personalization through prompt-based\ninteractions, offering a new paradigm for user-centric recommendations.\nHowever, incorporating user personality traits via the OCEAN model highlights a\ncritical tension between achieving psychological alignment and ensuring\ndemographic fairness. To address this, we propose PerFairX, a unified\nevaluation framework designed to quantify the trade-offs between\npersonalization and demographic equity in LLM-generated recommendations. Using\nneutral and personality-sensitive prompts across diverse user profiles, we\nbenchmark two state-of-the-art LLMs, ChatGPT and DeepSeek, on movie (MovieLens\n10M) and music (Last.fm 360K) datasets. Our results reveal that\npersonality-aware prompting significantly improves alignment with individual\ntraits but can exacerbate fairness disparities across demographic groups.\nSpecifically, DeepSeek achieves stronger psychological fit but exhibits higher\nsensitivity to prompt variations, while ChatGPT delivers stable yet less\npersonalized outputs. PerFairX provides a principled benchmark to guide the\ndevelopment of LLM-based recommender systems that are both equitable and\npsychologically informed, contributing to the creation of inclusive,\nuser-centric AI applications in continual learning contexts.", "AI": {"tldr": "This study proposes PerFairX, a framework to evaluate the balance between personalization and demographic fairness in LLM-based recommendations.", "motivation": "To investigate the tension between providing personalized, psychology-aligned recommendations and ensuring demographic fairness in LLM-based recommender systems.", "method": "The researchers use PerFairX, an evaluation framework, to benchmark ChatGPT and DeepSeek on movie and music datasets through neutral and personality-sensitive prompts.", "result": "Personality-aware prompts improved psychological alignment but heightened fairness disparities. DeepSeek showed stronger psychological fit but was more prompt-sensitive, while ChatGPT was less personalized but more stable.", "conclusion": "PerFairX aids in developing equitable and psychologically informed LLM-based recommender systems, promoting inclusive AI applications."}}
{"id": "2509.09438", "pdf": "https://arxiv.org/pdf/2509.09438", "abs": "https://arxiv.org/abs/2509.09438", "authors": ["Zhaohan Zhang", "Ziquan Liu", "Ioannis Patras"], "title": "GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models", "categories": ["cs.CL"], "comment": "20 pages, 11 figures", "summary": "Assessing the reliability of Large Language Models (LLMs) by confidence\nelicitation is a prominent approach to AI safety in high-stakes applications,\nsuch as healthcare and finance. Existing methods either require expensive\ncomputational overhead or suffer from poor calibration, making them impractical\nand unreliable for real-world deployment. In this work, we propose GrACE, a\nGenerative Approach to Confidence Elicitation that enables scalable and\nreliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in\nwhich the model expresses confidence by the similarity between the last hidden\nstate and the embedding of a special token appended to the vocabulary, in\nreal-time. We fine-tune the model for calibrating the confidence with\ncalibration targets associated with accuracy. Experiments with three LLMs and\ntwo benchmark datasets show that the confidence produced by GrACE achieves the\nbest discriminative capacity and calibration on open-ended generation tasks,\noutperforming six competing methods without resorting to additional sampling or\nan auxiliary model. Moreover, we propose two strategies for improving test-time\nscaling based on confidence induced by GrACE. Experimental results show that\nusing GrACE not only improves the accuracy of the final decision but also\nsignificantly reduces the number of required samples in the test-time scaling\nscheme, indicating the potential of GrACE as a practical solution for deploying\nLLMs with scalable, reliable, and real-time confidence estimation.", "AI": {"tldr": "The paper introduces GrACE, a generative method for scalable and reliable confidence estimation in LLMs, which surpasses existing methods in calibration and efficiency.", "motivation": "The authors aim to address the challenge of unreliable and computationally expensive confidence elicitation methods for LLMs, critical for AI safety in high-stakes fields like healthcare and finance.", "method": "GrACE uses a novel mechanism for confidence representation based on the similarity between the last hidden state and a special token embedding, fine-tuned for calibration. It avoids additional sampling or auxiliary models while achieving high scalability.", "result": "Experiments with three LLMs and two benchmark datasets demonstrate that GrACE outperforms six competing methods in calibration and discriminative capacity while enabling accurate test-time scaling with fewer samples.", "conclusion": "GrACE is presented as a practical solution for deploying LLMs with reliable, real-time, and scalable confidence estimation, improving both decision accuracy and efficiency."}}
{"id": "2509.09208", "pdf": "https://arxiv.org/pdf/2509.09208", "abs": "https://arxiv.org/abs/2509.09208", "authors": ["Somnath Hazra", "Pallab Dasgupta", "Soumyajit Dey"], "title": "Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, Accepted to the 34th International Joint Conference on\n  Artificial Intelligence (IJCAI) 2025, Main Track", "summary": "Constrained Reinforcement Learning (RL) aims to maximize the return while\nadhering to predefined constraint limits, which represent domain-specific\nsafety requirements. In continuous control settings, where learning agents\ngovern system actions, balancing the trade-off between reward maximization and\nconstraint satisfaction remains a significant challenge. Policy optimization\nmethods often exhibit instability near constraint boundaries, resulting in\nsuboptimal training performance. To address this issue, we introduce a novel\napproach that integrates an adaptive incentive mechanism in addition to the\nreward structure to stay within the constraint bound before approaching the\nconstraint boundary. Building on this insight, we propose Incrementally\nPenalized Proximal Policy Optimization (IP3O), a practical algorithm that\nenforces a progressively increasing penalty to stabilize training dynamics.\nThrough empirical evaluation on benchmark environments, we demonstrate the\nefficacy of IP3O compared to the performance of state-of-the-art Safe RL\nalgorithms. Furthermore, we provide theoretical guarantees by deriving a bound\non the worst-case error of the optimality achieved by our algorithm.", "AI": {"tldr": "The paper proposes the Incrementally Penalized Proximal Policy Optimization (IP3O) algorithm for Constrained Reinforcement Learning, which addresses stability issues near constraint boundaries.", "motivation": "Constrained RL faces challenges with reward maximization and constraint satisfaction due to policy instability near bound constraints, negatively affecting training performance.", "method": "The authors introduce an adaptive incentive mechanism alongside a progressively increasing penalty approach to stabilize training dynamics in Constrained RL.", "result": "Empirical evaluations show that IP3O outperforms state-of-the-art Safe RL algorithms in benchmark environments and offers theoretical guarantees through worst-case error bound analysis.", "conclusion": "IP3O provides a reliable solution for balancing reward maximization and constraint adherence in Constrained RL, improving both performance and theoretical robustness."}}
{"id": "2509.09140", "pdf": "https://arxiv.org/pdf/2509.09140", "abs": "https://arxiv.org/abs/2509.09140", "authors": ["Dylan Peek", "Matthew P. Skerritt", "Stephan Chalup"], "title": "Noise-Robust Topology Estimation of 2D Image Data via Neural Networks and Persistent Homology", "categories": ["cs.CV"], "comment": "12 pages", "summary": "Persistent Homology (PH) and Artificial Neural Networks (ANNs) offer\ncontrasting approaches to inferring topological structure from data. In this\nstudy, we examine the noise robustness of a supervised neural network trained\nto predict Betti numbers in 2D binary images. We compare an ANN approach\nagainst a PH pipeline based on cubical complexes and the Signed Euclidean\nDistance Transform (SEDT), which is a widely adopted strategy for noise-robust\ntopological analysis. Using one synthetic and two real-world datasets, we show\nthat ANNs can outperform this PH approach under noise, likely due to their\ncapacity to learn contextual and geometric priors from training data. Though\nstill emerging, the use of ANNs for topology estimation offers a compelling\nalternative to PH under structural noise.", "AI": {"tldr": "The study compares the robustness of Artificial Neural Networks (ANNs) and Persistent Homology (PH) in estimating topological structures under noise, finding that ANNs outperform PH in noisy conditions.", "motivation": "The paper aims to evaluate the ability of neural networks to predict topological features in noisy datasets and compare them to traditional Persistent Homology methods.", "method": "The study trains a supervised neural network to predict Betti numbers in 2D binary images. It uses cubical complexes and Signed Euclidean Distance Transform for PH and applies the methods to synthetic and real-world datasets.", "result": "ANNs demonstrated superior performance compared to PH in noisy conditions due to their ability to learn contextual and geometric data patterns.", "conclusion": "Artificial Neural Networks provide a strong alternative to Persistent Homology for topological analysis in noisy environments, leveraging their learning abilities."}}
{"id": "2509.08835", "pdf": "https://arxiv.org/pdf/2509.08835", "abs": "https://arxiv.org/abs/2509.08835", "authors": ["Vincent C. M\u00fcller"], "title": "Deep opacity and AI: A threat to XAI and to privacy protection mechanisms", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "It is known that big data analytics and AI pose a threat to privacy, and that\nsome of this is due to some kind of \"black box problem\" in AI. I explain how\nthis becomes a problem in the context of justification for judgments and\nactions. Furthermore, I suggest distinguishing three kinds of opacity: 1) the\nsubjects do not know what the system does (\"shallow opacity\"), 2) the analysts\ndo not know what the system does (\"standard black box opacity\"), or 3) the\nanalysts cannot possibly know what the system might do (\"deep opacity\"). If the\nagents, data subjects as well as analytics experts, operate under opacity, then\nthese agents cannot provide justifications for judgments that are necessary to\nprotect privacy, e.g., they cannot give \"informed consent\", or guarantee\n\"anonymity\". It follows from these points that agents in big data analytics and\nAI often cannot make the judgments needed to protect privacy. So I conclude\nthat big data analytics makes the privacy problems worse and the remedies less\neffective. As a positive note, I provide a brief outlook on technical ways to\nhandle this situation.", "AI": {"tldr": "The paper explores how AI's opaque functioning exacerbates privacy issues and complicates remedies. It categorizes opacity in AI systems and connects it to limitations in protecting privacy.", "motivation": "AI and big data analytics are increasingly seen as threats to privacy, especially due to their opaque functioning, which hampers justification for actions and judgments.", "method": "The author introduces three types of opacity in AI systems (shallow, standard black box, and deep) and analyzes their implications for privacy and informed consent.", "result": "The analysis shows that opacity in AI systems undermines justifications needed to ensure privacy and makes remedies less effective.", "conclusion": "Big data analytics intensifies privacy issues, and opacity often prevents effective safeguards. The paper briefly highlights technical approaches to mitigate these challenges."}}
{"id": "2509.09473", "pdf": "https://arxiv.org/pdf/2509.09473", "abs": "https://arxiv.org/abs/2509.09473", "authors": ["Lucie Pol\u00e1kov\u00e1", "Martin Popel", "V\u011bra Kloudov\u00e1", "Michal Nov\u00e1k", "Mariia Anisimova", "Ji\u0159\u00ed Balhar"], "title": "Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation", "categories": ["cs.CL"], "comment": "8 pages, 2 figures", "summary": "The EdUKate project combines digital education, linguistics, translation\nstudies, and machine translation to develop multilingual learning materials for\nCzech primary and secondary schools. Launched through collaboration between a\nmajor Czech academic institution and the country's largest educational\npublisher, the project is aimed at translating up to 9,000 multimodal\ninteractive exercises from Czech into Ukrainian, English, and German for an\neducational web portal. It emphasizes the development and evaluation of a\ndirect Czech-Ukrainian machine translation system tailored to the educational\ndomain, with special attention to processing formatted content such as XML and\nPDF and handling technical and scientific terminology. We present findings from\nan initial survey of Czech teachers regarding the needs of non-Czech-speaking\nstudents and describe the system's evaluation and implementation on the web\nportal. All resulting applications are freely available to students, educators,\nand researchers.", "AI": {"tldr": "The EdUKate project develops multilingual educational materials for Czech schools, using a direct Czech-Ukrainian machine translation system optimized for technical content.", "motivation": "To support non-Czech-speaking students by creating accessible, multilingual educational materials for Czech schools.", "method": "The project uses a direct machine translation system from Czech to Ukrainian, English, and German, tailored to educational content, processing formats like XML and PDF, and handling technical and scientific terms.", "result": "The project unveiled a Czech-Ukrainian machine translation system and its deployment on an educational web portal, with free access to materials.", "conclusion": "EdUKate provides an inclusive solution by making multilingual, high-quality educational resources available to students and educators, leveraging cutting-edge machine translation technologies."}}
{"id": "2509.09214", "pdf": "https://arxiv.org/pdf/2509.09214", "abs": "https://arxiv.org/abs/2509.09214", "authors": ["Alka Gadakh", "Vidya Kumbhar", "Sonal Khosla", "Kumar Karunendra"], "title": "Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Agro-tourism serves as a strategic economic model designed to facilitate\nrural development by diversifying income streams for local communities like\nfarmers while promoting the conservation of indigenous cultural heritage and\ntraditional agricultural practices. As a very booming subdomain of tourism,\nthere is a need to study the strategies for the growth of Agro-tourism in\ndetail. The current study has identified the important indicators for the\ngrowth and enhancement of agro-tourism. The study is conducted in two phases:\nidentification of the important indicators through a comprehensive literature\nreview and in the second phase state-of-the-art techniques were used to\nidentify the important indicators for the growth of agro-tourism. The\nindicators are also called features synonymously, the machine learning models\nfor feature selection were applied and it was observed that the Least Absolute\nShrinkage and Selection Operator (LASSO) method combined with, the machine\nLearning Classifiers such as Logistic Regression (LR), Decision Trees (DT),\nRandom Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were\nused to suggest the growth of the agro-tourism. The results show that with the\nLASSO method, LR model gives the highest classification accuracy of 98% in\n70-30% train-test data followed by RF with 95% accuracy. Similarly, in the\n80-20% train-test data LR maintains the highest accuracy at 99%, while DT and\nXGBoost follow with 97% accuracy.", "AI": {"tldr": "This paper studies strategies for agro-tourism growth, using machine learning models to identify impactful indicators. Logistic Regression achieves top accuracy.", "motivation": "To foster rural development by promoting agro-tourism through advanced strategies while conserving cultural heritage.", "method": "The study leveraged literature reviews and state-of-the-art machine learning techniques, including LASSO, and classifiers like Logistic Regression, Decision Trees, Random Forest, and XGBoost, for feature selection and classification.", "result": "Results indicate Logistic Regression achieves the highest classification accuracy: 98% in 70-30% train-test split and 99% in 80-20%, surpassing other models.", "conclusion": "Machine learning methods, particularly Logistic Regression combined with LASSO, are effective for identifying key indicators for agro-tourism growth, providing robust strategies for rural development."}}
{"id": "2509.09143", "pdf": "https://arxiv.org/pdf/2509.09143", "abs": "https://arxiv.org/abs/2509.09143", "authors": ["Yuiko Uchida", "Ren Togo", "Keisuke Maeda", "Takahiro Ogawa", "Miki Haseyama"], "title": "Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "Accepted by the ICCV 2025 UniLight Workshop", "summary": "This paper presents Objectness SIMilarity (OSIM), a novel evaluation metric\nfor 3D scenes that explicitly focuses on \"objects,\" which are fundamental units\nof human visual perception. Existing metrics assess overall image quality,\nleading to discrepancies with human perception. Inspired by neuropsychological\ninsights, we hypothesize that human recognition of 3D scenes fundamentally\ninvolves attention to individual objects. OSIM enables object-centric\nevaluations by leveraging an object detection model and its feature\nrepresentations to quantify the \"objectness\" of each object in the scene. Our\nuser study demonstrates that OSIM aligns more closely with human perception\ncompared to existing metrics. We also analyze the characteristics of OSIM using\nvarious approaches. Moreover, we re-evaluate recent 3D reconstruction and\ngeneration models under a standardized experimental setup to clarify\nadvancements in this field. The code is available at\nhttps://github.com/Objectness-Similarity/OSIM.", "AI": {"tldr": "The paper introduces OSIM, a novel metric for evaluating 3D scenes by focusing on objects, aligning more closely with human perception than existing metrics, and offers a new analysis of 3D models.", "motivation": "Existing metrics for 3D scene evaluation prioritize overall image quality, often diverging from human perception. The authors aim to develop a metric that focuses on objects, the fundamental units of human visual perception.", "method": "The authors propose Objectness SIMilarity (OSIM), which uses an object detection model and feature representations to evaluate the 'objectness' of objects in 3D scenes. They conduct a user study to validate OSIM's alignment with human perception and analyze its characteristics.", "result": "OSIM showed stronger alignment with human perception compared to traditional metrics, based on a user study. It also facilitated a standardized re-evaluation of 3D reconstruction and generation models.", "conclusion": "OSIM shifts focus to object-level evaluations in 3D scenes, resolving discrepancies between metrics and human perception. It sets a new benchmark for analyzing 3D models."}}
{"id": "2509.09522", "pdf": "https://arxiv.org/pdf/2509.09522", "abs": "https://arxiv.org/abs/2509.09522", "authors": ["Vadim Zadykian", "Bruno Andrade", "Haithem Afli"], "title": "Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Semantic Textual Relatedness (STR) captures nuanced relationships between\ntexts that extend beyond superficial lexical similarity. In this study, we\ninvestigate STR in the context of job title matching - a key challenge in\nresume recommendation systems, where overlapping terms are often limited or\nmisleading. We introduce a self-supervised hybrid architecture that combines\ndense sentence embeddings with domain-specific Knowledge Graphs (KGs) to\nimprove both semantic alignment and explainability. Unlike previous work that\nevaluated models on aggregate performance, our approach emphasizes data\nstratification by partitioning the STR score continuum into distinct regions:\nlow, medium, and high semantic relatedness. This stratified evaluation enables\na fine-grained analysis of model performance across semantically meaningful\nsubspaces. We evaluate several embedding models, both with and without KG\nintegration via graph neural networks. The results show that fine-tuned SBERT\nmodels augmented with KGs produce consistent improvements in the high-STR\nregion, where the RMSE is reduced by 25% over strong baselines. Our findings\nhighlight not only the benefits of combining KGs with text embeddings, but also\nthe importance of regional performance analysis in understanding model\nbehavior. This granular approach reveals strengths and weaknesses hidden by\nglobal metrics, and supports more targeted model selection for use in Human\nResources (HR) systems and applications where fairness, explainability, and\ncontextual matching are essential.", "AI": {"tldr": "The paper presents a hybrid model combining sentence embeddings and Knowledge Graphs to improve semantic textual relatedness (STR) for job title matching, crucial for resume recommendation systems.", "motivation": "The paper aims to address the challenge of nuanced semantic alignment in job title matching, a common issue in resume recommendation, especially when lexical similarity is limited or misleading.", "method": "The approach integrates dense sentence embeddings with domain-specific Knowledge Graphs via graph neural networks and introduces a stratified evaluation focusing on different STR score regions.", "result": "The proposed model, particularly fine-tuned SBERT integrated with KGs, shows a 25% RMSE improvement in the high-STR region over strong baselines.", "conclusion": "The study highlights the advantages of combining KGs with embeddings and the value of fine-grained evaluation, informing model selection for HR applications focusing on fairness, explainability, and contextual precision."}}
{"id": "2509.09219", "pdf": "https://arxiv.org/pdf/2509.09219", "abs": "https://arxiv.org/abs/2509.09219", "authors": ["Jakob Nyberg", "Pontus Johnson"], "title": "Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present and evaluate Vejde; a framework which combines data abstraction,\ngraph neural networks and reinforcement learning to produce inductive policy\nfunctions for decision problems with richly structured states, such as object\nclasses and relations. MDP states are represented as data bases of facts about\nentities, and Vejde converts each state to a bipartite graph, which is mapped\nto latent states through neural message passing. The factored representation of\nboth states and actions allows Vejde agents to handle problems of varying size\nand structure. We tested Vejde agents on eight problem domains defined in RDDL,\nwith ten problem instances each, where policies were trained using both\nsupervised and reinforcement learning. To test policy generalization, we\nseparate problem instances in two sets, one for training and the other solely\nfor testing. Test results on unseen instances for the Vejde agents were\ncompared to MLP agents trained on each problem instance, as well as the online\nplanning algorithm Prost. Our results show that Vejde policies in average\ngeneralize to the test instances without a significant loss in score.\nAdditionally, the inductive agents received scores on unseen test instances\nthat on average were close to the instance-specific MLP agents.", "AI": {"tldr": "This paper introduces Vejde, a framework combining graph neural networks and reinforcement learning to create scalable and generalizable policies for structured decision problems.", "motivation": "The paper aims to address challenges in decision-making problems with rich structures like object classes and relations, leveraging scalable methods that generalize well across varying sizes and configurations.", "method": "The framework uses MDP states represented as databases of facts, converting them to bipartite graphs. Then, it employs neural message passing for latent state mapping and integrates reinforcement learning to train policies. Supervised and reinforcement learning were applied in experiments.", "result": "Vejde was tested on eight problem domains with unseen instances. It demonstrated strong generalization capabilities, scoring close to problem-specific MLP agents and outperforming the Prost algorithm in terms of generalizability.", "conclusion": "Vejde successfully balances scalability and generalization for structured decision problems, showing promise for inductive policy learning without sacrificing accuracy even in unseen situations."}}
{"id": "2509.09151", "pdf": "https://arxiv.org/pdf/2509.09151", "abs": "https://arxiv.org/abs/2509.09151", "authors": ["Lei Wang", "Piotr Koniusz", "Yongsheng Gao"], "title": "Video Understanding by Design: How Datasets Shape Architectures and Insights", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Research report", "summary": "Video understanding has advanced rapidly, fueled by increasingly complex\ndatasets and powerful architectures. Yet existing surveys largely classify\nmodels by task or family, overlooking the structural pressures through which\ndatasets guide architectural evolution. This survey is the first to adopt a\ndataset-driven perspective, showing how motion complexity, temporal span,\nhierarchical composition, and multimodal richness impose inductive biases that\nmodels should encode. We reinterpret milestones, from two-stream and 3D CNNs to\nsequential, transformer, and multimodal foundation models, as concrete\nresponses to these dataset-driven pressures. Building on this synthesis, we\noffer practical guidance for aligning model design with dataset invariances\nwhile balancing scalability and task demands. By unifying datasets, inductive\nbiases, and architectures into a coherent framework, this survey provides both\na comprehensive retrospective and a prescriptive roadmap for advancing\ngeneral-purpose video understanding.", "AI": {"tldr": "This survey provides a dataset-driven perspective on the evolution of video understanding architectures, linking milestones to the pressures imposed by dataset features like motion complexity and multimodal richness.", "motivation": "Current surveys classify video understanding models primarily by task or architecture family, neglecting dataset-driven structural pressures that influence model evolution.", "method": "The paper proposes a new framework that connects datasets, inductive biases, and architectures, analyzing milestones in video understanding as responses to dataset-driven pressures.", "result": "The survey bridges a gap in understanding by explaining the evolution of models (e.g., 3D CNNs, transformers) as reactions to specific dataset attributes and offers practical guidance for model design.", "conclusion": "By unifying datasets, architectural inductive biases, and scalability concerns, the survey provides a roadmap to better align models with dataset invariances for general-purpose video understanding."}}
{"id": "2509.08852", "pdf": "https://arxiv.org/pdf/2509.08852", "abs": "https://arxiv.org/abs/2509.08852", "authors": ["Kajetan Schweighofer", "Barbara Brune", "Lukas Gruber", "Simon Schmid", "Alexander Aufreiter", "Andreas Gruber", "Thomas Doms", "Sebastian Eder", "Florian Mayer", "Xaver-Paul Stadlbauer", "Christoph Schwald", "Werner Zellinger", "Bernhard Nessler", "Sepp Hochreiter"], "title": "Safe and Certifiable AI Systems: Concepts, Challenges, and Lessons Learned", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "63 pages, 27 figures", "summary": "There is an increasing adoption of artificial intelligence in safety-critical\napplications, yet practical schemes for certifying that AI systems are safe,\nlawful and socially acceptable remain scarce. This white paper presents the\nT\\\"UV AUSTRIA Trusted AI framework an end-to-end audit catalog and methodology\nfor assessing and certifying machine learning systems. The audit catalog has\nbeen in continuous development since 2019 in an ongoing collaboration with\nscientific partners. Building on three pillars - Secure Software Development,\nFunctional Requirements, and Ethics & Data Privacy - the catalog translates the\nhigh-level obligations of the EU AI Act into specific, testable criteria. Its\ncore concept of functional trustworthiness couples a statistically defined\napplication domain with risk-based minimum performance requirements and\nstatistical testing on independently sampled data, providing transparent and\nreproducible evidence of model quality in real-world settings. We provide an\noverview of the functional requirements that we assess, which are oriented on\nthe lifecycle of an AI system. In addition, we share some lessons learned from\nthe practical application of the audit catalog, highlighting common pitfalls we\nencountered, such as data leakage scenarios, inadequate domain definitions,\nneglect of biases, or a lack of distribution drift controls. We further discuss\nkey aspects of certifying AI systems, such as robustness, algorithmic fairness,\nor post-certification requirements, outlining both our current conclusions and\na roadmap for future research. In general, by aligning technical best practices\nwith emerging European standards, the approach offers regulators, providers,\nand users a practical roadmap for legally compliant, functionally trustworthy,\nand certifiable AI systems.", "AI": {"tldr": "The paper introduces the T\u00dcV AUSTRIA Trusted AI framework, an audit methodology aimed at certification of AI systems in compliance with European standards.", "motivation": "With AI increasingly used in safety-critical applications, reliable certification mechanisms are needed to ensure these systems are safe, lawful, and socially acceptable.", "method": "The framework combines three pillars\u2014Secure Software Development, Functional Requirements, and Ethics & Data Privacy\u2014and converts EU AI Act obligations into specific, testable criteria.", "result": "The proposed audit catalog ensures transparent, reproducible model quality evidence by defining application domains, setting risk-based performance requirements, and statistical testing using independent data.", "conclusion": "This framework offers a practical roadmap to certifying AI systems as legally compliant and trustworthy, aligning technical best practices with emerging European regulations."}}
{"id": "2509.09524", "pdf": "https://arxiv.org/pdf/2509.09524", "abs": "https://arxiv.org/abs/2509.09524", "authors": ["Daniil Ignatev", "Nan Li", "Hugh Mee Wong", "Anh Dang", "Shane Kaszefski Yaschuk"], "title": "DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 4 figures; to appear at NLPerspectives@EMNLP-2025", "summary": "This system paper presents the DeMeVa team's approaches to the third edition\nof the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et\nal., 2025). We explore two directions: in-context learning (ICL) with large\nlanguage models, where we compare example sampling strategies; and label\ndistribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we\nevaluate several fine-tuning methods. Our contributions are twofold: (1) we\nshow that ICL can effectively predict annotator-specific annotations\n(perspectivist annotations), and that aggregating these predictions into soft\nlabels yields competitive performance; and (2) we argue that LDL methods are\npromising for soft label predictions and merit further exploration by the\nperspectivist community.", "AI": {"tldr": "The paper presents methods for predicting perspectivist annotations using in-context learning with language models and label distribution learning using RoBERTa.", "motivation": "To improve methods for predicting annotator-specific (perspectivist) annotations and soft label aggregation in disagreement-based learning tasks.", "method": "Explores in-context learning with different sampling strategies and fine-tuning of RoBERTa for label distribution learning to predict and aggregate soft labels.", "result": "(1) In-context learning effectively predicts perspectivist annotations and performs well with aggregated soft labels. (2) Label distribution learning shows promise for soft label predictions.", "conclusion": "Both approaches can improve the prediction of perspectivist annotations, with label distribution learning holding particular promise for future work."}}
{"id": "2509.09226", "pdf": "https://arxiv.org/pdf/2509.09226", "abs": "https://arxiv.org/abs/2509.09226", "authors": ["Haipeng Liu", "Ting Long", "Jing Fu"], "title": "Constructing a Question-Answering Simulator through the Distillation of LLMs", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "The question-answering (QA) simulator is a model that mimics real student\nlearning behaviors and predicts their correctness of their responses to\nquestions. QA simulators enable educational recommender systems (ERS) to\ncollect large amounts of training data without interacting with real students,\nthereby preventing harmful recommendations made by an undertrained ERS from\nundermining actual student learning. Given the QA history, there are two\ncategories of solutions to predict the correctness, conducting the simulation:\n(1) LLM-free methods, which apply a traditional sequential model to transfer\nthe QA history into a vector representation first, and make predictions based\non the representation; (2) LLM-based methods, which leverage the domain\nknowledge and reasoning capability of LLM to enhence the prediction. LLM-free\nmethods offer fast inference but generally yield suboptimal performance. In\ncontrast, most LLM-based methods achieve better results, but at the cost of\nslower inference speed and higher GPU memory consumption. In this paper, we\npropose a method named LLM Distillation based Simulator (LDSim), which distills\ndomain knowledge and reasoning capability from an LLM to better assist\nprediction, thereby improving simulation performance. Extensive experiments\ndemonstrate that our LDSim achieves strong results on both the simulation task\nand the knowledge tracing (KT) task. Our code is publicly available at\nhttps://anonymous.4open.science/r/LDSim-05A9.", "AI": {"tldr": "Researchers introduced LDSim, a QA simulator that predicts student response correctness by blending the efficient inference of traditional methods with the strong reasoning of Large Language Models (LLMs).", "motivation": "The motivation behind the paper is to improve educational recommender systems by avoiding their reliance on real student data, thus mitigating negative impacts from undertraining.", "method": "The authors propose LDSim, which utilizes LLM distillation to extract domain knowledge and reasoning capabilities from LLMs for better prediction.", "result": "LDSim demonstrated superior performance both in simulation and knowledge tracing tasks, addressing limitations of both traditional and LLM-based methods.", "conclusion": "By combining efficiency with enhanced accuracy, LDSim offers an innovative approach to simulate student learning behaviors, optimizing the intersection of traditional sequential modeling and LLM reasoning."}}
{"id": "2509.09153", "pdf": "https://arxiv.org/pdf/2509.09153", "abs": "https://arxiv.org/abs/2509.09153", "authors": ["JaeWoong Shin", "Jeongun Ryu", "Aaron Valero Puche", "Jinhee Lee", "Biagio Brattoli", "Wonkyung Jung", "Soo Ick Cho", "Kyunghyun Paeng", "Chan-Young Ock", "Donggeun Yoo", "Zhaoyang Li", "Wangkai Li", "Huayu Mai", "Joshua Millward", "Zhen He", "Aiden Nibali", "Lydia Anette Schoenpflug", "Viktor Hendrik Koelzer", "Xu Shuoyu", "Ji Zheng", "Hu Bin", "Yu-Wen Lo", "Ching-Hui Yang", "S\u00e9rgio Pereira"], "title": "OCELOT 2023: Cell Detection from Cell-Tissue Interaction Challenge", "categories": ["cs.CV", "cs.AI"], "comment": "This is the accepted manuscript of an article published in Medical\n  Image Analysis (Elsevier). The final version is available at:\n  https://doi.org/10.1016/j.media.2025.103751", "summary": "Pathologists routinely alternate between different magnifications when\nexamining Whole-Slide Images, allowing them to evaluate both broad tissue\nmorphology and intricate cellular details to form comprehensive diagnoses.\nHowever, existing deep learning-based cell detection models struggle to\nreplicate these behaviors and learn the interdependent semantics between\nstructures at different magnifications. A key barrier in the field is the lack\nof datasets with multi-scale overlapping cell and tissue annotations. The\nOCELOT 2023 challenge was initiated to gather insights from the community to\nvalidate the hypothesis that understanding cell and tissue (cell-tissue)\ninteractions is crucial for achieving human-level performance, and to\naccelerate the research in this field. The challenge dataset includes\noverlapping cell detection and tissue segmentation annotations from six organs,\ncomprising 673 pairs sourced from 306 The Cancer Genome Atlas (TCGA)\nWhole-Slide Images with hematoxylin and eosin staining, divided into training,\nvalidation, and test subsets. Participants presented models that significantly\nenhanced the understanding of cell-tissue relationships. Top entries achieved\nup to a 7.99 increase in F1-score on the test set compared to the baseline\ncell-only model that did not incorporate cell-tissue relationships. This is a\nsubstantial improvement in performance over traditional cell-only detection\nmethods, demonstrating the need for incorporating multi-scale semantics into\nthe models. This paper provides a comparative analysis of the methods used by\nparticipants, highlighting innovative strategies implemented in the OCELOT 2023\nchallenge.", "AI": {"tldr": "The paper discusses the OCELOT 2023 challenge, aimed at improving cell detection models by considering cell-tissue relationships with a unique dataset. Highlighted is a significant improvement in performance through multi-scale semantics.", "motivation": "Pathologists use multi-scale visual analysis to understand cell-tissue interactions, but current deep learning models do not replicate this, necessitating better datasets and methods.", "method": "The challenge introduced a dataset comprising multi-scale overlapping cell and tissue annotations from 673 paired images for training, validation, and testing, encouraging participants to incorporate cell-tissue relationships into their models.", "result": "Top models in the challenge exhibited up to a 7.99 F1-score increase over the baseline by integrating multi-scale cell-tissue relationships, showing marked performance improvements over traditional methods.", "conclusion": "The challenge demonstrated the importance of multi-scale semantics in cell-tissue interaction modeling for enhanced detection performance, showcasing innovative advancements in the field."}}
{"id": "2509.08854", "pdf": "https://arxiv.org/pdf/2509.08854", "abs": "https://arxiv.org/abs/2509.08854", "authors": ["David James Woo", "Kai Guo", "Yangyang Yu"], "title": "A vibe coding learning design to enhance EFL students' talking to, through, and about AI", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "15 pages, 12 figures", "summary": "This innovative practice article reports on the piloting of vibe coding\n(using natural language to create software applications with AI) for English as\na Foreign Language (EFL) education. We developed a human-AI meta-languaging\nframework with three dimensions: talking to AI (prompt engineering), talking\nthrough AI (negotiating authorship), and talking about AI (mental models of\nAI). Using backward design principles, we created a four-hour workshop where\ntwo students designed applications addressing authentic EFL writing challenges.\nWe adopted a case study methodology, collecting data from worksheets and video\nrecordings, think-aloud protocols, screen recordings, and AI-generated images.\nContrasting cases showed one student successfully vibe coding a functional\napplication cohering to her intended design, while another encountered\ntechnical difficulties with major gaps between intended design and actual\nfunctionality. Analysis reveals differences in students' prompt engineering\napproaches, suggesting different AI mental models and tensions in attributing\nauthorship. We argue that AI functions as a beneficial languaging machine, and\nthat differences in how students talk to, through, and about AI explain vibe\ncoding outcome variations. Findings indicate that effective vibe coding\ninstruction requires explicit meta-languaging scaffolding, teaching structured\nprompt engineering, facilitating critical authorship discussions, and\ndeveloping vocabulary for articulating AI mental models.", "AI": {"tldr": "The paper discusses a pilot study of vibe coding for EFL education, developing a human-AI meta-languaging framework and assessing outcomes of a four-hour workshop with two students.", "motivation": "The study aims to enhance EFL education through AI-driven vibe coding, addressing authentic writing challenges and understanding student interactions with AI.", "method": "A workshop using backward design principles was conducted with two students, involving tasks for designing applications. Data was collected via think-aloud protocols, screen recordings, worksheets, and AI-generated images.", "result": "One student succeeded in implementing her intended application design, while the other faced technical challenges. Differences in prompt engineering approaches and AI mental models were observed.", "conclusion": "The study highlights the potential of AI as a languaging tool and emphasizes the need for structured instruction in prompt engineering, authorship negotiation, and effective articulation of AI mental models."}}
{"id": "2509.09544", "pdf": "https://arxiv.org/pdf/2509.09544", "abs": "https://arxiv.org/abs/2509.09544", "authors": ["Paolo Pedinotti", "Peter Baumann", "Nathan Jessurun", "Leslie Barrett", "Enrico Santus"], "title": "Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)", "categories": ["cs.CL"], "comment": "7 pages, 6 appendices, EMNLP industry track", "summary": "Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling\nnew tasks and driving a proliferation of datasets and diversification of data\nsources. Yet, this transformation has outpaced traditional surveys. In this\npaper, we present MetaGraph, a generalizable methodology for extracting\nknowledge graphs from scientific literature and analyzing them to obtain a\nstructured, queryable view of research trends. We define an ontology for\nfinancial NLP research and apply an LLM-based extraction pipeline to 681 papers\n(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals\nthree key phases: early LLM adoption and task/dataset innovation; critical\nreflection on LLM limitations; and growing integration of peripheral techniques\ninto modular systems. This structured view offers both practitioners and\nresearchers a clear understanding of how financial NLP has evolved -\nhighlighting emerging trends, shifting priorities, and methodological\nshifts-while also demonstrating a reusable approach for mapping scientific\nprogress in other domains.", "AI": {"tldr": "The paper introduces MetaGraph, a method for extracting structured knowledge graphs from scientific literature, focusing on financial NLP research between 2022-2025.", "motivation": "The rapid evolution of Large Language Models (LLMs) in financial NLP has led to diverse tasks and datasets, surpassing traditional survey capabilities and necessitating new structured methodologies for understanding research trends.", "method": "The authors define an ontology, apply an LLM-based knowledge extraction pipeline to 681 financial NLP papers, and analyze the extracted data to identify research developments.", "result": "The analysis identified three distinct phases in financial NLP research: initial adoption and innovation, critique on limitations, and integration of peripheral techniques into modular systems.", "conclusion": "MetaGraph provides a clear lens to view the evolution of financial NLP, offers insights into research trends, and demonstrates a scalable and domain-agnostic approach for mapping scientific progress."}}
{"id": "2509.09251", "pdf": "https://arxiv.org/pdf/2509.09251", "abs": "https://arxiv.org/abs/2509.09251", "authors": ["Hanyang Wang", "Yuxuan Yang", "Hongjun Wang", "Lihui Wang"], "title": "Unsupervised Multi-Attention Meta Transformer for Rotating Machinery Fault Diagnosis", "categories": ["cs.LG"], "comment": null, "summary": "The intelligent fault diagnosis of rotating mechanical equipment usually\nrequires a large amount of labeled sample data. However, in practical\nindustrial applications, acquiring enough data is both challenging and\nexpensive in terms of time and cost. Moreover, different types of rotating\nmechanical equipment with different unique mechanical properties, require\nseparate training of diagnostic models for each case. To address the challenges\nof limited fault samples and the lack of generalizability in prediction models\nfor practical engineering applications, we propose a Multi-Attention Meta\nTransformer method for few-shot unsupervised rotating machinery fault diagnosis\n(MMT-FD). This framework extracts potential fault representations from\nunlabeled data and demonstrates strong generalization capabilities, making it\nsuitable for diagnosing faults across various types of mechanical equipment.\nThe MMT-FD framework integrates a time-frequency domain encoder and a\nmeta-learning generalization model. The time-frequency domain encoder predicts\nstatus representations generated through random augmentations in the\ntime-frequency domain. These enhanced data are then fed into a meta-learning\nnetwork for classification and generalization training, followed by fine-tuning\nusing a limited amount of labeled data. The model is iteratively optimized\nusing a small number of contrastive learning iterations, resulting in high\nefficiency. To validate the framework, we conducted experiments on a bearing\nfault dataset and rotor test bench data. The results demonstrate that the\nMMT-FD model achieves 99\\% fault diagnosis accuracy with only 1\\% of labeled\nsample data, exhibiting robust generalization capabilities.", "AI": {"tldr": "The paper presents a Multi-Attention Meta Transformer (MMT-FD) method for few-shot unsupervised fault diagnosis of rotating machinery, achieving 99% accuracy using only 1% labeled data.", "motivation": "There is a need to overcome challenges related to limited labeled fault samples and the lack of generalizability in diagnostic models for rotating machinery in practical engineering applications.", "method": "The proposed MMT-FD framework integrates a time-frequency domain encoder for status representation through augmentations and a meta-learning network for classification and generalization, followed by fine-tuning with minimal labeled data. Optimization is performed using contrastive learning.", "result": "The MMT-FD model demonstrated 99% fault diagnosis accuracy with only 1% labeled sample data, along with strong generalization abilities across different types of mechanical equipment.", "conclusion": "MMT-FD is highly efficient for fault diagnosis in rotating machinery, addressing challenges of limited samples and enabling robust generalization to varied equipment types."}}
{"id": "2509.09157", "pdf": "https://arxiv.org/pdf/2509.09157", "abs": "https://arxiv.org/abs/2509.09157", "authors": ["Yuan Shufang"], "title": "RT-DETR++ for UAV Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Object detection in unmanned aerial vehicle (UAV) imagery presents\nsignificant challenges. Issues such as densely packed small objects, scale\nvariations, and occlusion are commonplace. This paper introduces RT-DETR++,\nwhich enhances the encoder component of the RT-DETR model. Our improvements\nfocus on two key aspects. First, we introduce a channel-gated attention-based\nupsampling/downsampling (AU/AD) mechanism. This dual-path system minimizes\nerrors and preserves details during feature layer propagation. Second, we\nincorporate CSP-PAC during feature fusion. This technique employs parallel\nhollow convolutions to process local and contextual information within the same\nlayer, facilitating the integration of multi-scale features. Evaluation\ndemonstrates that our novel neck design achieves superior performance in\ndetecting small and densely packed objects. The model maintains sufficient\nspeed for real-time detection without increasing computational complexity. This\nstudy provides an effective approach for feature encoding design in real-time\ndetection systems.", "AI": {"tldr": "RT-DETR++ introduces encoder improvements for object detection in UAV imagery, handling small densely packed objects efficiently while maintaining real-time speed.", "motivation": "Address challenges in UAV imagery object detection, including small objects, scale variations, and occlusion.", "method": "Enhancements to RT-DETR encoder with channel-gated attention-based up/downsampling (AU/AD) and CSP-PAC for multi-scale feature integration.", "result": "Superior performance in detecting small, densely packed objects while retaining real-time speed without additional computational complexity.", "conclusion": "Effective feature encoding design proposed for real-time object detection in UAV imagery."}}
{"id": "2509.09583", "pdf": "https://arxiv.org/pdf/2509.09583", "abs": "https://arxiv.org/abs/2509.09583", "authors": ["Brittany Harbison", "Samuel Taubman", "Travis Taylor", "Ashok. K. Goel"], "title": "Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.LG", "cs.SI"], "comment": null, "summary": "Social connection is a vital part of learning, yet online course environments\npresent barriers to the organic formation of social groups. SAMI offers one\nsolution by facilitating student connections, but its effectiveness is\nconstrained by an incomplete Theory of Mind, limiting its ability to create an\neffective mental model of a student. One facet of this is its inability to\nintuit personality, which may influence the relevance of its recommendations.\nTo explore this, we propose a personality detection model utilizing GPTs\nzero-shot capability to infer Big-Five personality traits from forum\nintroduction posts, often encouraged in online courses. We benchmark its\nperformance against established models, demonstrating its efficacy in this\ntask. Furthermore, we integrate this model into SAMIs entity-based matchmaking\nsystem, enabling personality-informed social recommendations. Initial\nintegration suggests personality traits can complement existing matching\nfactors, though additional evaluation is required to determine their full\nimpact on student engagement and match quality.", "AI": {"tldr": "The paper proposes using GPTs for personality detection from online course forum posts to enhance SAMI's matchmaking system for student connections.", "motivation": "Online course environments hinder natural social group formation, and SAMI's incomplete Theory of Mind limits its social recommendation efficiency. Personality detection may improve this.", "method": "The researchers propose using GPTs in a zero-shot model to infer Big-Five personality traits from forum posts, benchmark its effectiveness, and integrate it into SAMI to improve matchmaking.", "result": "Their model shows effective personality detection compared to established standards. Its incorporation into SAMI shows potential but requires additional evaluation.", "conclusion": "While promising in leveraging personality for social matchmaking, further validation is needed to understand the full impact on engagement and match quality."}}
{"id": "2509.09265", "pdf": "https://arxiv.org/pdf/2509.09265", "abs": "https://arxiv.org/abs/2509.09265", "authors": ["Jiawei Wang", "Jiacai Liu", "Yuqian Fu", "Yingru Li", "Xintao Wang", "Yuan Lin", "Yu Yue", "Lin Zhang", "Yang Wang", "Ke Wang"], "title": "Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents", "categories": ["cs.LG", "cs.CL"], "comment": "ICLR 2026 Under review", "summary": "In long-horizon tasks, recent agents based on Large Language Models (LLMs)\nface a significant challenge that sparse, outcome-based rewards make it\ndifficult to assign credit to intermediate steps. Previous methods mainly focus\non creating dense reward signals to guide learning, either through traditional\nreinforcement learning techniques like inverse reinforcement learning or by\nusing Process Reward Models for step-by-step feedback. In this paper, we\nidentify a fundamental problem in the learning dynamics of LLMs: the magnitude\nof policy gradients is inherently coupled with the entropy, which leads to\ninefficient small updates for confident correct actions and potentially\ndestabilizes large updates for uncertain ones. To resolve this, we propose\nEntropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the\nlearning signal based on step-wise uncertainty and the final task outcome. EMPG\namplifies updates for confident correct actions, penalizes confident errors,\nand attenuates updates from uncertain steps to stabilize exploration. We\nfurther introduce a bonus term for future clarity that encourages agents to\nfind more predictable solution paths. Through comprehensive experiments on\nthree challenging agent tasks, WebShop, ALFWorld, and Deep Search, we\ndemonstrate that EMPG achieves substantial performance gains and significantly\noutperforms strong policy gradient baselines. Project page is at\nhttps://empgseed-seed.github.io/", "AI": {"tldr": "The paper introduces Entropy-Modulated Policy Gradients (EMPG) to address challenges in LLM-based agents solving long-horizon tasks by stabilizing learning and improving credit assignment.", "motivation": "Agents based on LLMs struggle with sparse, outcome-based rewards, making it hard to assign credit to intermediate steps effectively. Existing solutions focus on dense rewards but fail to address inherent issues in policy gradient updates tied to entropy.", "method": "The proposed EMPG framework recalibrates policy gradient updates by amplifying correct actions with high confidence, penalizing confident errors, and attenuating updates for uncertain steps. It also introduces a bonus term to encourage more predictable paths.", "result": "EMPG achieved substantial performance improvements across three agent tasks (WebShop, ALFWorld, Deep Search), outperforming baselines and demonstrating robust capabilities.", "conclusion": "The EMPG framework provides an effective mechanism for addressing inefficiencies in policy gradient learning, leading to better task performance and exploration stability in LLM-based long-horizon agents."}}
{"id": "2509.09159", "pdf": "https://arxiv.org/pdf/2509.09159", "abs": "https://arxiv.org/abs/2509.09159", "authors": ["Zhiyue Liu", "Sihang Liu", "Jinyuan Liu", "Xinru Zhang"], "title": "A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the IEEE International Conference on Multimedia and Expo\n  (ICME 2025) for oral presentation. \\copyright\\ 2025 IEEE. Personal use of\n  this material is permitted. Permission from IEEE must be obtained for all\n  other uses", "summary": "Knowledge-based visual question answering (KB-VQA) requires a model to\nunderstand images and utilize external knowledge to provide accurate answers.\nExisting approaches often directly augment models with retrieved information\nfrom knowledge sources while ignoring substantial knowledge redundancy, which\nintroduces noise into the answering process. To address this, we propose a\ntraining-free framework with knowledge focusing for KB-VQA, that mitigates the\nimpact of noise by enhancing knowledge relevance and reducing redundancy.\nFirst, for knowledge retrieval, our framework concludes essential parts from\nthe image-question pairs, creating low-noise queries that enhance the retrieval\nof highly relevant knowledge. Considering that redundancy still persists in the\nretrieved knowledge, we then prompt large models to identify and extract\nanswer-beneficial segments from knowledge. In addition, we introduce a\nselective knowledge integration strategy, allowing the model to incorporate\nknowledge only when it lacks confidence in answering the question, thereby\nmitigating the influence of redundant information. Our framework enables the\nacquisition of accurate and critical knowledge, and extensive experiments\ndemonstrate that it outperforms state-of-the-art methods.", "AI": {"tldr": "The paper proposes a training-free framework for Knowledge-based Visual Question Answering (KB-VQA) to mitigate noise and redundancy in utilizing external knowledge, improving answer accuracy.", "motivation": "Existing KB-VQA models struggle with noise and redundancy in external knowledge, leading to inaccurate answers.", "method": "The framework uses low-noise query generation for relevant knowledge retrieval, prompts large models to extract critical knowledge segments, and introduces a selective knowledge integration strategy.", "result": "The proposed framework improves the acquisition of accurate and critical knowledge, outperforming state-of-the-art KB-VQA methods.", "conclusion": "By addressing redundancy and noise through advanced retrieval and integration strategies, the framework enhances the performance of KB-VQA systems."}}
{"id": "2509.08862", "pdf": "https://arxiv.org/pdf/2509.08862", "abs": "https://arxiv.org/abs/2509.08862", "authors": ["Chang Liu", "Loc Hoang", "Andrew Stolman", "Rene F. Kizilcec", "Bo Wu"], "title": "Investigating Student Interaction Patterns with Large Language Model-Powered Course Assistants in Computer Science Courses", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Providing students with flexible and timely academic support is a challenge\nat most colleges and universities, leaving many students without help outside\nscheduled hours. Large language models (LLMs) are promising for bridging this\ngap, but interactions between students and LLMs are rarely overseen by\neducators. We developed and studied an LLM-powered course assistant deployed\nacross multiple computer science courses to characterize real-world use and\nunderstand pedagogical implications. By Spring 2024, our system had been\ndeployed to approximately 2,000 students across six courses at three\ninstitutions. Analysis of the interaction data shows that usage remains strong\nin the evenings and nights and is higher in introductory courses, indicating\nthat our system helps address temporal support gaps and novice learner needs.\nWe sampled 200 conversations per course for manual annotation: most sampled\nresponses were judged correct and helpful, with a small share unhelpful or\nerroneous; few responses included dedicated examples. We also examined an\ninquiry-based learning strategy: only around 11% of sampled conversations\ncontained LLM-generated follow-up questions, which were often ignored by\nstudents in advanced courses. A Bloom's taxonomy analysis reveals that current\nLLM capabilities are limited in generating higher-order cognitive questions.\nThese patterns suggest opportunities for pedagogically oriented LLM-based\neducational systems and greater educator involvement in configuring prompts,\ncontent, and policies.", "AI": {"tldr": "The paper studies the deployment of an LLM-powered course assistant in computer science courses and evaluates its use, effectiveness, and pedagogical impact.", "motivation": "The authors aim to address the challenge of providing flexible and timely academic support to students outside of scheduled hours.", "method": "An LLM-powered course assistant was deployed across multiple computer science courses, engaging approximately 2,000 students. Conversation samples were manually annotated to evaluate correctness, helpfulness, and types of interactions, and Bloom's taxonomy was applied.", "result": "Usage was notably higher during evenings/nighttime and in introductory courses. Most responses were correct/helpful, though a small portion were erroneous/unhelpful. The system generated limited higher-order cognitive questions, and follow-up inquiries were often ignored in advanced courses.", "conclusion": "LLM-powered educational systems can address temporal support gaps, but their pedagogical power could be improved through greater educator involvement in designing the interactions and refining cognitive question generation."}}
{"id": "2509.09593", "pdf": "https://arxiv.org/pdf/2509.09593", "abs": "https://arxiv.org/abs/2509.09593", "authors": ["Bangzhao Shu", "Isha Joshi", "Melissa Karnaze", "Anh C. Pham", "Ishita Kakkar", "Sindhu Kothe", "Arpine Hovasapian", "Mai ElSherief"], "title": "Fluent but Unfeeling: The Emotional Blind Spots of Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Camera-ready version for ICWSM 2026. First two authors contributed\n  equally", "summary": "The versatility of Large Language Models (LLMs) in natural language\nunderstanding has made them increasingly popular in mental health research.\nWhile many studies explore LLMs' capabilities in emotion recognition, a\ncritical gap remains in evaluating whether LLMs align with human emotions at a\nfine-grained level. Existing research typically focuses on classifying emotions\ninto predefined, limited categories, overlooking more nuanced expressions. To\naddress this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit\ncommunities featuring 251 fine-grained, self-disclosed emotion labels. Our\ncomprehensive evaluation framework examines predicted emotion terms and\ndecomposes them into eight basic emotions using established emotion theories,\nenabling a fine-grained comparison. Systematic testing of prevalent LLMs under\nvarious prompt settings reveals that accurately predicting emotions that align\nwith human self-disclosed emotions remains challenging. Qualitative analysis\nfurther shows that while certain LLMs generate emotion terms consistent with\nestablished emotion theories and definitions, they sometimes fail to capture\ncontextual cues as effectively as human self-disclosures. These findings\nhighlight the limitations of LLMs in fine-grained emotion alignment and offer\ninsights for future research aimed at enhancing their contextual understanding.", "AI": {"tldr": "This paper presents EXPRESS, a dataset to evaluate how well Large Language Models (LLMs) align with human-reported fine-grained emotions from Reddit posts, revealing challenges in capturing nuanced emotional contexts.", "motivation": "To address the gap in evaluating whether LLMs align with human emotions beyond predefined emotion categories and to facilitate the study of fine-grained emotion understanding.", "method": "The authors created the EXPRESS dataset with 251 fine-grained emotion labels from Reddit. They also developed an evaluation framework to examine LLM predictions by decomposing emotion terms into eight basic emotions based on established theories and tested LLMs using various prompts.", "result": "The study found that LLMs struggle to accurately predict emotions that align with human self-disclosed emotions at a fine-grained level. LLMs often fail to capture nuanced contextual emotional cues.", "conclusion": "LLMs show limitations in fine-grained emotion recognition and alignment with human self-disclosed emotions. This underscores the need for future research to enhance their contextual understanding in emotional domains."}}
{"id": "2509.09278", "pdf": "https://arxiv.org/pdf/2509.09278", "abs": "https://arxiv.org/abs/2509.09278", "authors": ["Saumitra Dwivedi", "Ricardo da Silva Torres", "Ibrahim A. Hameed", "Gunnar Tufte", "Anniken Susanne T. Karlsen"], "title": "Data Driven Discovery of Emergent Dynamics in Reaction Diffusion Systems from Sparse and Noisy Observations", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "Data-driven discovery of emergent dynamics is gaining popularity,\nparticularly in the context of reaction-diffusion systems. These systems are\nwidely studied across various fields, including neuroscience, ecology,\nepidemiology, and several other subject areas that deal with emergent dynamics.\nA current challenge in the discovery process relates to system identification\nwhen there is no prior knowledge of the underlying physics. We attempt to\naddress this challenge by learning Soft Artificial Life (Soft ALife) models,\nsuch as Agent-based and Cellular Automata (CA) models, from observed data for\nreaction-diffusion systems. In this paper, we present findings on the\napplicability of a conceptual framework, the Data-driven Rulesets for Soft\nArtificial Life (DRSALife) model, to learn Soft ALife rulesets that accurately\nrepresent emergent dynamics in a reaction-diffusion system from observed data.\nThis model has demonstrated promising results for Elementary CA Rule 30, Game\nof Life, and Vicsek Flocking problems in recent work. To our knowledge, this is\none of the few studies that explore machine-based Soft ALife ruleset learning\nand system identification for reaction-diffusion dynamics without any prior\nknowledge of the underlying physics. Moreover, we provide comprehensive\nfindings from experiments investigating the potential effects of using noisy\nand sparse observed datasets on learning emergent dynamics. Additionally, we\nsuccessfully identify the structure and parameters of the underlying partial\ndifferential equations (PDEs) representing these dynamics. Experimental results\ndemonstrate that the learned models are able to predict the emergent dynamics\nwith good accuracy (74%) and exhibit quite robust performance when subjected to\nGaussian noise and temporal sparsity.", "AI": {"tldr": "The study focuses on deriving emergent dynamics from data in reaction-diffusion systems using a novel framework, DRSALife. The method proves effective on tasks like learning dynamics from Cellular Automata models and identifying PDE structures, even with noisy or sparse data.", "motivation": "Reaction-diffusion systems play a critical role across diverse fields like neuroscience and ecology, yet identifying their dynamics without prior knowledge of the underlying physics remains challenging.", "method": "The authors propose the DRSALife framework to learn Soft Artificial Life (Soft ALife) rulesets, utilizing machine learning approaches to extract dynamics from observed data and simulate reaction-diffusion systems.", "result": "The learned models achieved an accuracy of 74% in predicting emergent dynamics and remained robust when tested against noisy and temporally sparse datasets. The study also identified underlying PDE structures effectively.", "conclusion": "The paper establishes that Soft ALife ruleset learning through the DRSALife framework is a viable method for understanding reaction-diffusion systems without requiring prior physical insights. It shows promise for future applications in modeling and system identification."}}
{"id": "2509.09163", "pdf": "https://arxiv.org/pdf/2509.09163", "abs": "https://arxiv.org/abs/2509.09163", "authors": ["Yulin Tong", "Fengzong Zhang", "Haiqin Cheng"], "title": "CWSSNet: Hyperspectral Image Classification Enhanced by Wavelet Domain Convolution", "categories": ["cs.CV"], "comment": null, "summary": "Hyperspectral remote sensing technology has significant application value in\nfields such as forestry ecology and precision agriculture, while also putting\nforward higher requirements for fine ground object classification. However,\nalthough hyperspectral images are rich in spectral information and can improve\nrecognition accuracy, they tend to cause prominent feature redundancy due to\ntheir numerous bands, high dimensionality, and spectral mixing characteristics.\nTo address this, this study used hyperspectral images from the ZY1F satellite\nas a data source and selected Yugan County, Shangrao City, Jiangxi Province as\nthe research area to perform ground object classification research. A\nclassification framework named CWSSNet was proposed, which integrates 3D\nspectral-spatial features and wavelet convolution. This framework integrates\nmultimodal information us-ing a multiscale convolutional attention module and\nbreaks through the classification performance bottleneck of traditional methods\nby introducing multi-band decomposition and convolution operations in the\nwavelet domain. The experiments showed that CWSSNet achieved 74.50\\%, 82.73\\%,\nand 84.94\\% in mean Intersection over Union (mIoU), mean Accuracy (mAcc), and\nmean F1-score (mF1) respectively in Yugan County. It also obtained the highest\nIntersection over Union (IoU) in the classifica-tion of water bodies,\nvegetation, and bare land, demonstrating good robustness. Additionally, when\nthe training set proportion was 70\\%, the increase in training time was\nlimited, and the classification effect was close to the optimal level,\nindicating that the model maintains reliable performance under small-sample\ntraining conditions.", "AI": {"tldr": "The paper introduces CWSSNet, a new classification framework for hyperspectral images combining 3D spectral-spatial features and wavelet convolution, yielding significant classification accuracy in ecological regions.", "motivation": "The study aims to enhance classification accuracy for hyperspectral images used in fields like precision agriculture and forestry ecology by addressing challenges such as feature redundancy and spectral mixing.", "method": "The proposed framework CWSSNet integrates 3D spectral-spatial features with wavelet convolution, multimodal information fusion using multiscale convolutional attention, and multi-band decomposition operations.", "result": "CWSSNet achieved 74.50% mIoU, 82.73% mAcc, and 84.94% mF1 scores, with robust performance across water bodies, vegetation, and bare land classifications. It maintained effective results under a small-sample training setup.", "conclusion": "CWSSNet demonstrates reliable classification performance and robustness, breaking conventional limitations, making it a promising solution for hyperspectral image classification challenges."}}
{"id": "2509.09602", "pdf": "https://arxiv.org/pdf/2509.09602", "abs": "https://arxiv.org/abs/2509.09602", "authors": ["Yiqun T. Chen", "Tyler H. McCormick", "Li Liu", "Abhirup Datta"], "title": "LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination", "categories": ["cs.CL", "stat.AP"], "comment": null, "summary": "Verbal autopsy (VA) is a critical tool for estimating causes of death in\nresource-limited settings where medical certification is unavailable. This\nstudy presents LA-VA, a proof-of-concept pipeline that combines Large Language\nModels (LLMs) with traditional algorithmic approaches and embedding-based\nclassification for improved cause-of-death prediction. Using the Population\nHealth Metrics Research Consortium (PHMRC) dataset across three age categories\n(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:\nGPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.\nOur results demonstrate that GPT-5 achieves the highest individual performance\nwith average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%\n(Neonate), outperforming traditional statistical machine learning baselines by\n5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches\ncould substantially improve verbal autopsy accuracy, with important\nimplications for global health surveillance in low-resource settings.", "AI": {"tldr": "This paper proposes LA-VA, a pipeline combining Large Language Models (LLMs) and traditional approaches, to improve verbal autopsy accuracy for cause-of-death prediction in low-resource settings.", "motivation": "The lack of proper medical certification in resource-limited settings necessitates efficient methods like verbal autopsy to estimate causes of death.", "method": "The study leverages various approaches including GPT-5 predictions, traditional algorithmic methods, embedding-based classifications, and meta-learner ensembles to process and analyze verbal autopsy data from the PHMRC dataset.", "result": "GPT-5 demonstrated superior performance with test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5% (Neonate), outperforming existing baselines by 5-10%.", "conclusion": "Using LLMs such as GPT-5 for verbal autopsies could greatly enhance cause-of-death predictions, aiding global health surveillance in low-resource environments."}}
{"id": "2509.09337", "pdf": "https://arxiv.org/pdf/2509.09337", "abs": "https://arxiv.org/abs/2509.09337", "authors": ["Junda Ye", "Zhongbao Zhang", "Li Sun", "Siqiang Luo"], "title": "MoSE: Unveiling Structural Patterns in Graphs via Mixture of Subgraph Experts", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 11 figures", "summary": "While graph neural networks (GNNs) have achieved great success in learning\nfrom graph-structured data, their reliance on local, pairwise message passing\nrestricts their ability to capture complex, high-order subgraph patterns.\nleading to insufficient structural expressiveness. Recent efforts have\nattempted to enhance structural expressiveness by integrating random walk\nkernels into GNNs. However, these methods are inherently designed for\ngraph-level tasks, which limits their applicability to other downstream tasks\nsuch as node classification. Moreover, their fixed kernel configurations hinder\nthe model's flexibility in capturing diverse subgraph structures. To address\nthese limitations, this paper proposes a novel Mixture of Subgraph Experts\n(MoSE) framework for flexible and expressive subgraph-based representation\nlearning across diverse graph tasks. Specifically, MoSE extracts informative\nsubgraphs via anonymous walks and dynamically routes them to specialized\nexperts based on structural semantics, enabling the model to capture diverse\nsubgraph patterns with improved flexibility and interpretability. We further\nprovide a theoretical analysis of MoSE's expressivity within the Subgraph\nWeisfeiler-Lehman (SWL) Test, proving that it is more powerful than SWL.\nExtensive experiments, together with visualizations of learned subgraph\nexperts, demonstrate that MoSE not only outperforms competitive baselines but\nalso provides interpretable insights into structural patterns learned by the\nmodel.", "AI": {"tldr": "The paper introduces the Mixture of Subgraph Experts (MoSE) to improve graph neural networks' ability to capture complex subgraph patterns, outperforming existing methods both in flexibility and accuracy.", "motivation": "Graph neural networks struggle to capture high-order subgraph patterns due to their reliance on local, pairwise message passing, which limits their structural expressiveness and applicability across diverse tasks.", "method": "The proposed MoSE framework uses anonymous walks to extract subgraphs and dynamically routes them to specialized experts based on structural semantics, offering flexible and interpretable subgraph-based representation learning.", "result": "MoSE demonstrates superior performance in experiments compared to competitive baselines and provides insights into learned structural patterns, proving more powerful than the Subgraph Weisfeiler-Lehman Test.", "conclusion": "MoSE significantly enhances GNNs' structural expressiveness and flexibility, making it well-suited for diverse graph-related tasks while delivering interpretable results."}}
{"id": "2509.09172", "pdf": "https://arxiv.org/pdf/2509.09172", "abs": "https://arxiv.org/abs/2509.09172", "authors": ["Chunxiao Li", "Xiaoxiao Wang", "Meiling Li", "Boming Miao", "Peng Sun", "Yunjian Zhang", "Xiangyang Ji", "Yao Zhu"], "title": "Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios", "categories": ["cs.CV"], "comment": "ICCV2025", "summary": "With the rapid advancement of generative models, highly realistic image\nsynthesis has posed new challenges to digital security and media credibility.\nAlthough AI-generated image detection methods have partially addressed these\nconcerns, a substantial research gap remains in evaluating their performance\nunder complex real-world conditions. This paper introduces the Real-World\nRobustness Dataset (RRDataset) for comprehensive evaluation of detection models\nacross three dimensions: 1) Scenario Generalization: RRDataset encompasses\nhigh-quality images from seven major scenarios (War and Conflict, Disasters and\nAccidents, Political and Social Events, Medical and Public Health, Culture and\nReligion, Labor and Production, and everyday life), addressing existing dataset\ngaps from a content perspective. 2) Internet Transmission Robustness: examining\ndetector performance on images that have undergone multiple rounds of sharing\nacross various social media platforms. 3) Re-digitization Robustness: assessing\nmodel effectiveness on images altered through four distinct re-digitization\nmethods. We benchmarked 17 detectors and 10 vision-language models (VLMs) on\nRRDataset and conducted a large-scale human study involving 192 participants to\ninvestigate human few-shot learning capabilities in detecting AI-generated\nimages. The benchmarking results reveal the limitations of current AI detection\nmethods under real-world conditions and underscore the importance of drawing on\nhuman adaptability to develop more robust detection algorithms.", "AI": {"tldr": "The paper presents the Real-World Robustness Dataset (RRDataset) for evaluating AI-generated image detection under real-world scenarios, internet transmissions, and re-digitization methods, highlighting the limitations of current detection methods.", "motivation": "The motivation is to address the gap in evaluating AI-generated image detection methods' performance in complex and real-world conditions as current methods are insufficient.", "method": "This study introduces RRDataset to evaluate three dimensions: scenario generalization with diverse image categories, internet transmission robustness by simulating social media sharing, and re-digitization robustness. Benchmarking of 17 AI detectors, 10 vision-language models, and a human study were conducted.", "result": "The study found that current AI detection methods struggle under realistic conditions, while humans show adaptable few-shot learning capabilities in detecting AI-generated images.", "conclusion": "The findings highlight the need to leverage human adaptability for creating better and more robust AI-generated image detection algorithms."}}
{"id": "2509.09629", "pdf": "https://arxiv.org/pdf/2509.09629", "abs": "https://arxiv.org/abs/2509.09629", "authors": ["Minghang Zhu", "Zhengliang Shi", "Zhiwei Xu", "Shiguang Wu", "Lingjie Wang", "Pengjie Ren", "Zhaochun Ren", "Zhumin Chen"], "title": "Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems", "categories": ["cs.CL"], "comment": "EMNLP 2025 Findings", "summary": "The advancement of large language models (LLMs) has enabled the construction\nof multi-agent systems to solve complex tasks by dividing responsibilities\namong specialized agents, such as a planning agent for subgoal generation and a\ngrounding agent for executing tool-use actions. Most existing methods typically\nfine-tune these agents independently, leading to capability gaps among them\nwith poor coordination. To address this, we propose MOAT, a Multi-Agent Joint\nAlignment Tuning framework that improves agents collaboration through iterative\nalignment. MOAT alternates between two key stages: (1) Planning Agent\nAlignment, which optimizes the planning agent to generate subgoal sequences\nthat better guide the grounding agent; and (2) Grounding Agent Improving, which\nfine-tunes the grounding agent using diverse subgoal-action pairs generated by\nthe agent itself to enhance its generalization capablity. Theoretical analysis\nproves that MOAT ensures a non-decreasing and progressively convergent training\nprocess. Experiments across six benchmarks demonstrate that MOAT outperforms\nstate-of-the-art baselines, achieving average improvements of 3.1% on held-in\ntasks and 4.4% on held-out tasks.", "AI": {"tldr": "The paper introduces MOAT, a joint tuning framework for multi-agent systems to enhance coordination and task performance.", "motivation": "Existing multi-agent systems suffer from capability gaps and poor coordination due to independent fine-tuning of specialized agents.", "method": "MOAT employs iterative alignment with two stages: 'Planning Agent Alignment' and 'Grounding Agent Improving' to optimize collaboration between agents.", "result": "MOAT demonstrated superior performance on six benchmarks, improving outcomes by 3.1% on held-in tasks and 4.4% on held-out tasks compared to state-of-the-art methods.", "conclusion": "MOAT effectively improves multi-agent coordination, providing a systematic and convergent solution for complex task-solving systems."}}
{"id": "2509.09380", "pdf": "https://arxiv.org/pdf/2509.09380", "abs": "https://arxiv.org/abs/2509.09380", "authors": ["Luca Giuliani", "Michele Lombardi"], "title": "Robust Non-Linear Correlations via Polynomial Regression", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "The Hirschfeld-Gebelein-R\\'enyi (HGR) correlation coefficient is an extension\nof Pearson's correlation that is not limited to linear correlations, with\npotential applications in algorithmic fairness, scientific analysis, and causal\ndiscovery. Recently, novel algorithms to estimate HGR in a differentiable\nmanner have been proposed to facilitate its use as a loss regularizer in\nconstrained machine learning applications. However, the inherent\nuncomputability of HGR requires a bias-variance trade-off, which can possibly\ncompromise the robustness of the proposed methods, hence raising technical\nconcerns if applied in real-world scenarios. We introduce a novel computational\napproach for HGR that relies on user-configurable polynomial kernels, offering\ngreater robustness compared to previous methods and featuring a faster yet\nalmost equally effective restriction. Our approach provides significant\nadvantages in terms of robustness and determinism, making it a more reliable\noption for real-world applications. Moreover, we present a brief experimental\nanalysis to validate the applicability of our approach within a constrained\nmachine learning framework, showing that its computation yields an insightful\nsubgradient that can serve as a loss regularizer.", "AI": {"tldr": "The paper presents a novel method to compute the Hirschfeld-Gebelein-R\u00e9nyi (HGR) correlation coefficient using polynomial kernels, enhancing robustness, speed, and reliability for real-world applications.", "motivation": "To address the challenges of uncomputability and bias-variance trade-offs in computing the HGR correlation coefficient, especially for constrained machine learning and real-world applications.", "method": "The authors propose a computational approach to HGR that uses user-configurable polynomial kernels, improving robustness and determinism while maintaining computational efficiency.", "result": "The experimental analysis demonstrates the effectiveness of the approach within constrained machine learning, showing that the computed HGR produces an insightful subgradient useful as a loss regularizer.", "conclusion": "The proposed polynomial kernel-based method offers a more robust and reliable way to compute HGR, making it suitable for practical machine learning applications involving loss regularization."}}
{"id": "2509.09183", "pdf": "https://arxiv.org/pdf/2509.09183", "abs": "https://arxiv.org/abs/2509.09183", "authors": ["Jiasheng Guo", "Xin Gao", "Yuxiang Yan", "Guanghao Li", "Jian Pu"], "title": "Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 6 figures, conference", "summary": "Low-light Object detection is crucial for many real-world applications but\nremains challenging due to degraded image quality. While recent studies have\nshown that RAW images offer superior potential over RGB images, existing\napproaches either use RAW-RGB images with information loss or employ complex\nframeworks. To address these, we propose a lightweight and self-adaptive Image\nSignal Processing (ISP) plugin, Dark-ISP, which directly processes Bayer RAW\nimages in dark environments, enabling seamless end-to-end training for object\ndetection. Our key innovations are: (1) We deconstruct conventional ISP\npipelines into sequential linear (sensor calibration) and nonlinear (tone\nmapping) sub-modules, recasting them as differentiable components optimized\nthrough task-driven losses. Each module is equipped with content-aware\nadaptability and physics-informed priors, enabling automatic RAW-to-RGB\nconversion aligned with detection objectives. (2) By exploiting the ISP\npipeline's intrinsic cascade structure, we devise a Self-Boost mechanism that\nfacilitates cooperation between sub-modules. Through extensive experiments on\nthree RAW image datasets, we demonstrate that our method outperforms\nstate-of-the-art RGB- and RAW-based detection approaches, achieving superior\nresults with minimal parameters in challenging low-light environments.", "AI": {"tldr": "The paper introduces Dark-ISP, a lightweight and adaptive Image Signal Processing plugin for object detection using Bayer RAW images in low-light environments.", "motivation": "Low-light object detection remains challenging due to image quality degradation, and there is potential to use RAW images for better outcomes.", "method": "Dark-ISP deconstructs ISP pipelines into linear and nonlinear differentiable modules optimized via task-driven losses, with content-aware adaptability and physics-guided priors.", "result": "Dark-ISP achieves state-of-the-art performance in low-light object detection across three RAW image datasets, while maintaining minimal parameters.", "conclusion": "The proposed Dark-ISP plugin significantly improves RAW-based detection with its efficient design, emphasizing its effectiveness in low-light applications."}}
{"id": "2509.09650", "pdf": "https://arxiv.org/pdf/2509.09650", "abs": "https://arxiv.org/abs/2509.09650", "authors": ["Siddarth Mamidanna", "Daking Rai", "Ziyu Yao", "Yilun Zhou"], "title": "All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens", "categories": ["cs.CL", "I.2.7"], "comment": "EMNLP 2025 Main Conference", "summary": "Large language models (LLMs) demonstrate proficiency across numerous\ncomputational tasks, yet their inner workings remain unclear. In theory, the\ncombination of causal self-attention and multilayer perceptron layers allows\nevery token to access and compute information based on all preceding tokens. In\npractice, to what extent are such operations present? In this paper, on mental\nmath tasks (i.e., direct math calculation via next-token prediction without\nexplicit reasoning), we investigate this question in three steps: inhibiting\ninput-specific token computations in the initial layers, restricting the routes\nof information transfer across token positions in the next few layers, and\nforcing all computation to happen at the last token in the remaining layers.\nWith two proposed techniques, Context-Aware Mean Ablation (CAMA) and\nAttention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with\nhigh accuracy on a wide variety of mental math tasks, where meaningful\ncomputation occurs very late (in terms of layer depth) and only at the last\ntoken, which receives information of other tokens in few specific middle\nlayers. Experiments on a variety of models and arithmetic expressions show that\nthis subgraph is sufficient and necessary for high model performance, transfers\nacross different models, and works on a variety of input styles. Ablations on\ndifferent CAMA and ABP alternatives reveal their unique advantages over other\nmethods, which may be of independent interest.", "AI": {"tldr": "The authors investigate how large language models handle mental math tasks internally and reveal key late-stage computations using two new techniques.", "motivation": "The motivation is to uncover how large language models (LLMs) internally compute information for tasks like mental math and understand their specific computational pathways.", "method": "The authors introduce two methods, Context-Aware Mean Ablation (CAMA) and Attention-Based Peeking (ABP), to study computational pathways in LLMs by inhibiting certain token operations and focusing computations late in the network's layers.", "result": "They identify an \"All-for-One subgraph\" (AF1) that uses computations concentrated in the later layers exclusively at the last token. This structure is essential for high performance and generalizes across multiple models and input types.", "conclusion": "The findings highlight distinct computation pathways in LLMs with AF1 being crucial for mental math tasks, offering insights into model interpretability and possibly informing future model design."}}
{"id": "2509.09387", "pdf": "https://arxiv.org/pdf/2509.09387", "abs": "https://arxiv.org/abs/2509.09387", "authors": ["Mohammed Tiouti", "Mohamed Bal-Ghaoui"], "title": "MetaLLMix : An XAI Aided LLM-Meta-learning Based Approach for Hyper-parameters Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective model and hyperparameter selection remains a major challenge in\ndeep learning, often requiring extensive expertise and computation. While\nAutoML and large language models (LLMs) promise automation, current LLM-based\napproaches rely on trial and error and expensive APIs, which provide limited\ninterpretability and generalizability. We propose MetaLLMiX, a zero-shot\nhyperparameter optimization framework combining meta-learning, explainable AI,\nand efficient LLM reasoning. By leveraging historical experiment outcomes with\nSHAP explanations, MetaLLMiX recommends optimal hyperparameters and pretrained\nmodels without additional trials. We further employ an LLM-as-judge evaluation\nto control output format, accuracy, and completeness. Experiments on eight\nmedical imaging datasets using nine open-source lightweight LLMs show that\nMetaLLMiX achieves competitive or superior performance to traditional HPO\nmethods while drastically reducing computational cost. Our local deployment\noutperforms prior API-based approaches, achieving optimal results on 5 of 8\ntasks, response time reductions of 99.6-99.9%, and the fastest training times\non 6 datasets (2.4-15.7x faster), maintaining accuracy within 1-5% of\nbest-performing baselines.", "AI": {"tldr": "MetaLLMiX introduces a zero-shot hyperparameter optimization (HPO) method using meta-learning, explainable AI, and efficient LLM reasoning, improving interpretability and reducing computational costs in deep learning tasks.", "motivation": "Current LLM-based AutoML approaches are computationally expensive, rely heavily on trial and error, and provide limited insight and generalizability.", "method": "The method integrates meta-learning through historical experiment data, SHAP-based explanations for interpretability, and efficient zero-shot LLM reasoning for HPO and pretrained model selection. Evaluation uses an LLM-as-judge approach for output control.", "result": "MetaLLMiX demonstrated competitive or better performance compared to traditional HPO methods on medical imaging datasets, with 99.6%-99.9% faster response times, training accelerations of 2.4-15.7x, and maintaining accuracy within 1-5% of baselines.", "conclusion": "The framework offers an interpretable, efficient solution for HPO, eliminating the need for expensive trials, and performs favorably in both accuracy and computational efficiency compared to existing methods."}}
{"id": "2509.09190", "pdf": "https://arxiv.org/pdf/2509.09190", "abs": "https://arxiv.org/abs/2509.09190", "authors": ["Hanwei Zhu", "Haoning Wu", "Zicheng Zhang", "Lingyu Zhu", "Yixuan Li", "Peilin Chen", "Shiqi Wang", "Chris Wei Zhou", "Linhan Cao", "Wei Sun", "Xiangyang Zhu", "Weixia Zhang", "Yucheng Zhu", "Jing Liu", "Dandan Zhu", "Guangtao Zhai", "Xiongkuo Min", "Zhichao Zhang", "Xinyue Li", "Shubo Xu", "Anh Dao", "Yifan Li", "Hongyuan Yu", "Jiaojiao Yi", "Yiding Tian", "Yupeng Wu", "Feiran Sun", "Lijuan Liao", "Song Jiang"], "title": "VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results", "categories": ["cs.CV"], "comment": "ICCV VQualA Workshop 2025", "summary": "This paper presents a summary of the VQualA 2025 Challenge on Visual Quality\nComparison for Large Multimodal Models (LMMs), hosted as part of the ICCV 2025\nWorkshop on Visual Quality Assessment. The challenge aims to evaluate and\nenhance the ability of state-of-the-art LMMs to perform open-ended and detailed\nreasoning about visual quality differences across multiple images. To this end,\nthe competition introduces a novel benchmark comprising thousands of\ncoarse-to-fine grained visual quality comparison tasks, spanning single images,\npairs, and multi-image groups. Each task requires models to provide accurate\nquality judgments. The competition emphasizes holistic evaluation protocols,\nincluding 2AFC-based binary preference and multi-choice questions (MCQs).\nAround 100 participants submitted entries, with five models demonstrating the\nemerging capabilities of instruction-tuned LMMs on quality assessment. This\nchallenge marks a significant step toward open-domain visual quality reasoning\nand comparison and serves as a catalyst for future research on interpretable\nand human-aligned quality evaluation systems.", "AI": {"tldr": "The VQualA 2025 Challenge evaluates large multimodal models (LMMs) on reasoning about visual quality differences across images. It introduces tasks to assess models' quality judgments using new benchmarks, holistic protocols, and showcases promising instruction-tuned LMMs.", "motivation": "The paper seeks to advance open-ended visual quality reasoning and comparison, aligning LMM capabilities with human-like quality evaluations.", "method": "A novel benchmark, comprising diverse visual quality comparison tasks across images, is developed. Models are assessed using 2AFC binary preference and multi-choice question evaluations.", "result": "Around 100 participants engaged, with five models effectively showcasing instruction-tuned capabilities for quality assessment.", "conclusion": "This challenge drives progress in human-aligned visual quality assessment and sets the stage for future research in interpretable LMM systems."}}
{"id": "2509.09660", "pdf": "https://arxiv.org/pdf/2509.09660", "abs": "https://arxiv.org/abs/2509.09660", "authors": ["Mohsen Fayyaz", "Ali Modarressi", "Hanieh Deilamsalehy", "Franck Dernoncourt", "Ryan Rossi", "Trung Bui", "Hinrich Sch\u00fctze", "Nanyun Peng"], "title": "Steering MoE LLMs via Expert (De)Activation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token\nthrough a subset of specialized Feed-Forward Networks (FFN), known as experts.\nWe present SteerMoE, a framework for steering MoE models by detecting and\ncontrolling behavior-linked experts. Our detection method identifies experts\nwith distinct activation patterns across paired inputs exhibiting contrasting\nbehaviors. By selectively (de)activating such experts during inference, we\ncontrol behaviors like faithfulness and safety without retraining or modifying\nweights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to\n+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by\n-41% alone, and -100% when combined with existing jailbreak methods, bypassing\nall safety guardrails and exposing a new dimension of alignment faking hidden\nwithin experts.", "AI": {"tldr": "SteerMoE demonstrates how activating or deactivating specific experts in Mixture-of-Experts LLMs can steer model behaviors, enhancing or diminishing safety and faithfulness during inference without retraining.", "motivation": "The paper aims to address steering large-scale Mixture-of-Experts LLMs toward desired behaviors like improved safety and faithfulness without requiring retraining or modifying model weights.", "method": "The researchers propose SteerMoE, a framework to detect experts with distinct activation patterns in LLMs and selectively (de)activate them during inference to control behavior-linked effects.", "result": "SteerMoE improved safety by up to 20% and faithfulness by 27% across benchmarks, while in adversarial scenarios, it decreased safety by 41% and broke alignment safeguards when combined with jailbreak methods.", "conclusion": "SteerMoE unveils an effective method for steering expert behaviors in LLMs, highlighting its pros for ethical guidance and risks around alignment vulnerabilities when used maliciously."}}
{"id": "2509.09396", "pdf": "https://arxiv.org/pdf/2509.09396", "abs": "https://arxiv.org/abs/2509.09396", "authors": ["Harry Mayne", "Ryan Othniel Kearns", "Yushi Yang", "Andrew M. Bean", "Eoin Delaney", "Chris Russell", "Adam Mahdi"], "title": "LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to EMNLP 2025 Main", "summary": "To collaborate effectively with humans, language models must be able to\nexplain their decisions in natural language. We study a specific type of\nself-explanation: self-generated counterfactual explanations (SCEs), where a\nmodel explains its prediction by modifying the input such that it would have\npredicted a different outcome. We evaluate whether LLMs can produce SCEs that\nare valid, achieving the intended outcome, and minimal, modifying the input no\nmore than necessary. When asked to generate counterfactuals, we find that LLMs\ntypically produce SCEs that are valid, but far from minimal, offering little\ninsight into their decision-making behaviour. Worryingly, when asked to\ngenerate minimal counterfactuals, LLMs typically make excessively small edits\nthat fail to change predictions. The observed validity-minimality trade-off is\nconsistent across several LLMs, datasets, and evaluation settings. Our findings\nsuggest that SCEs are, at best, an ineffective explainability tool and, at\nworst, can provide misleading insights into model behaviour. Proposals to\ndeploy LLMs in high-stakes settings must consider the impact of unreliable\nself-explanations on downstream decision-making. Our code is available at\nhttps://github.com/HarryMayne/SCEs.", "AI": {"tldr": "Language models often fail to produce effective self-generated counterfactual explanations (SCEs), which compromises their utility for explainability.", "motivation": "The paper aims to evaluate the capability of large language models (LLMs) to generate self-explanations, specifically self-generated counterfactual explanations, and determine their reliability as an explainability tool.", "method": "The authors assess the validity and minimality of SCEs generated by LLMs across various models, datasets, and evaluation settings. They test both general counterfactual generation and minimal adjustments to input.", "result": "LLMs typically produce valid but non-minimal SCEs when generating general counterfactuals, and excessively small edits that fail to alter predictions when tasked with minimal edits.", "conclusion": "SCEs are unreliable for explainability, as they often fail to provide meaningful or accurate insights into model decision-making. Deploying LLMs in critical applications must account for this flaw."}}
{"id": "2509.09200", "pdf": "https://arxiv.org/pdf/2509.09200", "abs": "https://arxiv.org/abs/2509.09200", "authors": ["Ge Sun", "Jun Ma"], "title": "MGTraj: Multi-Granularity Goal-Guided Human Trajectory Prediction with Recursive Refinement Network", "categories": ["cs.CV"], "comment": null, "summary": "Accurate human trajectory prediction is crucial for robotics navigation and\nautonomous driving. Recent research has demonstrated that incorporating goal\nguidance significantly enhances prediction accuracy by reducing uncertainty and\nleveraging prior knowledge. Most goal-guided approaches decouple the prediction\ntask into two stages: goal prediction and subsequent trajectory completion\nbased on the predicted goal, which operate at extreme granularities:\ncoarse-grained goal prediction forecasts the overall intention, while\nfine-grained trajectory completion needs to generate the positions for all\nfuture timesteps. The potential utility of intermediate temporal granularity\nremains largely unexplored, which motivates multi-granularity trajectory\nmodeling. While prior work has shown that multi-granularity representations\ncapture diverse scales of human dynamics and motion patterns, effectively\nintegrating this concept into goal-guided frameworks remains challenging. In\nthis paper, we propose MGTraj, a novel Multi-Granularity goal-guided model for\nhuman Trajectory prediction. MGTraj recursively encodes trajectory proposals\nfrom coarse to fine granularity levels. At each level, a transformer-based\nrecursive refinement network (RRN) captures features and predicts progressive\nrefinements. Features across different granularities are integrated using a\nweight-sharing strategy, and velocity prediction is employed as an auxiliary\ntask to further enhance performance. Comprehensive experimental results in\nEHT/UCY and Stanford Drone Dataset indicate that MGTraj outperforms baseline\nmethods and achieves state-of-the-art performance among goal-guided methods.", "AI": {"tldr": "This paper introduces MGTraj, a model that predicts human trajectories using multi-granularity encoding for better accuracy compared to traditional methods.", "motivation": "Current methods for human trajectory prediction lack exploration of intermediate temporal granularities for improving accuracy.", "method": "The model uses recursive encoding from coarse to fine granularities through a transformer-based recursive refinement network (RRN) with weight-sharing and velocity prediction as auxiliary tasks.", "result": "Experiments on EHT/UCY and Stanford Drone Dataset show that MGTraj outperforms existing methods and sets new state-of-the-art benchmarks in goal-guided trajectory prediction.", "conclusion": "MGTraj demonstrates the effectiveness of multi-granularity modeling and refinement processes in human trajectory prediction tasks."}}
{"id": "2509.09675", "pdf": "https://arxiv.org/pdf/2509.09675", "abs": "https://arxiv.org/abs/2509.09675", "authors": ["Runpeng Dai", "Linfeng Song", "Haolin Liu", "Zhenwen Liang", "Dian Yu", "Haitao Mi", "Zhaopeng Tu", "Rui Liu", "Tong Zheng", "Hongtu Zhu", "Dong Yu"], "title": "CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm\nfor enhancing the reasoning ability of Large Language Models (LLMs). Yet\ncurrent RLVR methods often explore poorly, leading to premature convergence and\nentropy collapse. To address this challenge, we introduce Curiosity-Driven\nExploration (CDE), a framework that leverages the model's own intrinsic sense\nof curiosity to guide exploration. We formalize curiosity with signals from\nboth the actor and the critic: for the actor, we use perplexity over its\ngenerated response, and for the critic, we use the variance of value estimates\nfrom a multi-head architecture. Both signals serve as an exploration bonus\nwithin the RLVR framework to guide the model. Our theoretical analysis shows\nthat the actor-wise bonus inherently penalizes overconfident errors and\npromotes diversity among correct responses; moreover, we connect the\ncritic-wise bonus to the well-established count-based exploration bonus in RL.\nEmpirically, our method achieves an approximate +3 point improvement over\nstandard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a\ncalibration collapse mechanism within RLVR, shedding light on common LLM\nfailure modes.", "AI": {"tldr": "The paper introduces Curiosity-Driven Exploration (CDE) to address exploration issues in RLVR methods, achieving better results using intrinsic curiosity signals.", "motivation": "Current RLVR methods suffer from poor exploration, leading to premature convergence and entropy collapse in LLMs.", "method": "CDE framework utilizes intrinsic curiosity signals from the actor's perplexity and critic's value estimate variance as exploration bonuses.", "result": "Empirical evaluations show approximately +3 point improvement on AIME benchmarks and deeper insights on calibration collapse in RLVR.", "conclusion": "CDE enhances RLVR frameworks, mitigating issues like overconfident errors and calibration collapse, while improving performance in LLM reasoning tasks."}}
{"id": "2509.09408", "pdf": "https://arxiv.org/pdf/2509.09408", "abs": "https://arxiv.org/abs/2509.09408", "authors": ["Jonas Schmidinger", "Viacheslav Barkov", "Sebastian Vogel", "Martin Atzmueller", "Gerard B M Heuvelink"], "title": "Kriging prior Regression: A Case for Kriging-Based Spatial Features with TabPFN in Soil Mapping", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning and geostatistics are two fundamentally different frameworks\nfor predicting and spatially mapping soil properties. Geostatistics leverages\nthe spatial structure of soil properties, while machine learning captures the\nrelationship between available environmental features and soil properties. We\npropose a hybrid framework that enriches ML with spatial context through\nengineering of 'spatial lag' features from ordinary kriging. We call this\napproach 'kriging prior regression' (KpR), as it follows the inverse logic of\nregression kriging. To evaluate this approach, we assessed both the point and\nprobabilistic prediction performance of KpR, using the TabPFN model across six\nfieldscale datasets from LimeSoDa. These datasets included soil organic carbon,\nclay content, and pH, along with features derived from remote sensing and\nin-situ proximal soil sensing. KpR with TabPFN demonstrated reliable\nuncertainty estimates and more accurate predictions in comparison to several\nother spatial techniques (e.g., regression/residual kriging with TabPFN), as\nwell as to established non-spatial machine learning algorithms (e.g., random\nforest). Most notably, it significantly improved the average R2 by around 30%\ncompared to machine learning algorithms without spatial context. This\nimprovement was due to the strong prediction performance of the TabPFN\nalgorithm itself and the complementary spatial information provided by KpR\nfeatures. TabPFN is particularly effective for prediction tasks with small\nsample sizes, common in precision agriculture, whereas KpR can compensate for\nweak relationships between sensing features and soil properties when proximal\nsoil sensing data are limited. Hence, we conclude that KpR with TabPFN is a\nvery robust and versatile modelling framework for digital soil mapping in\nprecision agriculture.", "AI": {"tldr": "The paper introduces a hybrid framework, called kriging prior regression (KpR), combining geostatistics and machine learning to improve soil property prediction and mapping.", "motivation": "The researchers aimed to address the limitations of geostatistics and machine learning in isolation by integrating spatial context into machine learning to enhance soil mapping and prediction.", "method": "They developed the KpR method, which uses spatial lag features from ordinary kriging to enrich machine learning models and tested it with the TabPFN algorithm on six field-scale datasets.", "result": "KpR with TabPFN improved the average R2 by 30% compared to non-spatial machine learning algorithms while providing reliable predictions and uncertainty estimates.", "conclusion": "KpR with TabPFN is a robust and versatile framework for digital soil mapping, especially for tasks with small sample sizes in precision agriculture."}}
{"id": "2509.09232", "pdf": "https://arxiv.org/pdf/2509.09232", "abs": "https://arxiv.org/abs/2509.09232", "authors": ["Jiesi Hu", "Jianfeng Cao", "Yanwu Yang", "Chenfei Ye", "Yixuan Zhang", "Hanyang Peng", "Ting Ma"], "title": "Medverse: A Universal Model for Full-Resolution 3D Medical Image Segmentation, Transformation and Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "In-context learning (ICL) offers a promising paradigm for universal medical\nimage analysis, enabling models to perform diverse image processing tasks\nwithout retraining. However, current ICL models for medical imaging remain\nlimited in two critical aspects: they cannot simultaneously achieve\nhigh-fidelity predictions and global anatomical understanding, and there is no\nunified model trained across diverse medical imaging tasks (e.g., segmentation\nand enhancement) and anatomical regions. As a result, the full potential of ICL\nin medical imaging remains underexplored. Thus, we present \\textbf{Medverse}, a\nuniversal ICL model for 3D medical imaging, trained on 22 datasets covering\ndiverse tasks in universal image segmentation, transformation, and enhancement\nacross multiple organs, imaging modalities, and clinical centers. Medverse\nemploys a next-scale autoregressive in-context learning framework that\nprogressively refines predictions from coarse to fine, generating consistent,\nfull-resolution volumetric outputs and enabling multi-scale anatomical\nawareness. We further propose a blockwise cross-attention module that\nfacilitates long-range interactions between context and target inputs while\npreserving computational efficiency through spatial sparsity. Medverse is\nextensively evaluated on a broad collection of held-out datasets covering\npreviously unseen clinical centers, organs, species, and imaging modalities.\nResults demonstrate that Medverse substantially outperforms existing ICL\nbaselines and establishes a novel paradigm for in-context learning. Code and\nmodel weights will be made publicly available. Our model are publicly available\nat https://github.com/jiesihu/Medverse.", "AI": {"tldr": "The paper introduces Medverse, a universal in-context learning (ICL) model for 3D medical imaging, designed to tackle diverse tasks across multiple anatomical regions and imaging modalities. It achieves high-fidelity outputs with global anatomical understanding.", "motivation": "Current ICL models for medical imaging suffer from limitations such as inability to simultaneously achieve high-fidelity predictions and global anatomical understanding, as well as the absence of a unified model trained across varied imaging tasks and regions.", "method": "Medverse employs a next-scale autoregressive ICL framework for progressively refining predictions to full-resolution outputs. Additionally, it incorporates a blockwise cross-attention module, enabling efficient long-range interactions while maintaining spatial sparsity.", "result": "Medverse is extensively tested on held-out datasets covering unseen clinical centers, organs, and modalities, substantially outperforming existing ICL baselines.", "conclusion": "Medverse establishes a new standard for ICL in medical imaging, demonstrating significant advancements and promising unified solutions for diverse imaging tasks. The model and code are made publicly available."}}
{"id": "2509.09413", "pdf": "https://arxiv.org/pdf/2509.09413", "abs": "https://arxiv.org/abs/2509.09413", "authors": ["Daniel Agyapong", "Briana H. Beatty", "Peter G. Kennedy", "Toby D. Hocking"], "title": "Fused Lasso Improves Accuracy of Co-occurrence Network Inference in Grouped Samples", "categories": ["cs.LG", "q-bio.PE"], "comment": null, "summary": "Co-occurrence network inference algorithms have significantly advanced our\nunderstanding of microbiome communities. However, these algorithms typically\nanalyze microbial associations within samples collected from a single\nenvironmental niche, often capturing only static snapshots rather than dynamic\nmicrobial processes. Previous studies have commonly grouped samples from\ndifferent environmental niches together without fully considering how microbial\ncommunities adapt their associations when faced with varying ecological\nconditions. Our study addresses this limitation by explicitly investigating\nboth spatial and temporal dynamics of microbial communities. We analyzed\npublicly available microbiome abundance data across multiple locations and time\npoints, to evaluate algorithm performance in predicting microbial associations\nusing our proposed Same-All Cross-validation (SAC) framework. SAC evaluates\nalgorithms in two distinct scenarios: training and testing within the same\nenvironmental niche (Same), and training and testing on combined data from\nmultiple environmental niches (All). To overcome the limitations of\nconventional algorithms, we propose fuser, an algorithm that, while not\nentirely new in machine learning, is novel for microbiome community network\ninference. It retains subsample-specific signals while simultaneously sharing\nrelevant information across environments during training. Unlike standard\napproaches that infer a single generalized network from combined data, fuser\ngenerates distinct, environment-specific predictive networks. Our results\ndemonstrate that fuser achieves comparable predictive performance to existing\nalgorithms such as glmnet when evaluated within homogeneous environments\n(Same), and notably reduces test error compared to baseline algorithms in\ncross-environment (All) scenarios.", "AI": {"tldr": "The paper develops the fuser algorithm for microbiome network inference to account for spatial and temporal adaptations of microbial communities across different environmental niches.", "motivation": "The motivation is to address the limitations of existing co-occurrence network inference algorithms that typically focus on static snapshots within single environmental niches and fail to capture dynamic microbial processes or adaptations across diverse ecological conditions.", "method": "The study employs the Same-All Cross-validation (SAC) framework to evaluate algorithm performance in two scenarios: within the same environmental niche ('Same') and across combined environmental niches ('All'). The newly proposed algorithm, fuser, retains subsample-specific signals while sharing information across environmental niches, producing environment-specific predictive networks.", "result": "The fuser algorithm demonstrated comparable performance to glmnet in homogeneous environments ('Same') and significantly reduced test errors in cross-environment scenarios ('All'), outperforming baseline algorithms.", "conclusion": "Fuser successfully addresses the shortcomings of traditional algorithms by better tailoring predictions to specific environments, improving the inference of dynamic microbial associations across diverse conditions."}}
{"id": "2509.09242", "pdf": "https://arxiv.org/pdf/2509.09242", "abs": "https://arxiv.org/abs/2509.09242", "authors": ["Mustafa Yurdakul", "Sakir Tasdemir"], "title": "CoAtNeXt:An Attention-Enhanced ConvNeXtV2-Transformer Hybrid Model for Gastric Tissue Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Background and objective Early diagnosis of gastric diseases is crucial to\nprevent fatal outcomes. Although histopathologic examination remains the\ndiagnostic gold standard, it is performed entirely manually, making evaluations\nlabor-intensive and prone to variability among pathologists. Critical findings\nmay be missed, and lack of standard procedures reduces consistency. These\nlimitations highlight the need for automated, reliable, and efficient methods\nfor gastric tissue analysis. Methods In this study, a novel hybrid model named\nCoAtNeXt was proposed for the classification of gastric tissue images. The\nmodel is built upon the CoAtNet architecture by replacing its MBConv layers\nwith enhanced ConvNeXtV2 blocks. Additionally, the Convolutional Block\nAttention Module (CBAM) is integrated to improve local feature extraction\nthrough channel and spatial attention mechanisms. The architecture was scaled\nto achieve a balance between computational efficiency and classification\nperformance. CoAtNeXt was evaluated on two publicly available datasets,\nHMU-GC-HE-30K for eight-class classification and GasHisSDB for binary\nclassification, and was compared against 10 Convolutional Neural Networks\n(CNNs) and ten Vision Transformer (ViT) models. Results CoAtNeXt achieved\n96.47% accuracy, 96.60% precision, 96.47% recall, 96.45% F1 score, and 99.89%\nAUC on HMU-GC-HE-30K. On GasHisSDB, it reached 98.29% accuracy, 98.07%\nprecision, 98.41% recall, 98.23% F1 score, and 99.90% AUC. It outperformed all\nCNN and ViT models tested and surpassed previous studies in the literature.\nConclusion Experimental results show that CoAtNeXt is a robust architecture for\nhistopathological classification of gastric tissue images, providing\nperformance on binary and multiclass. Its highlights its potential to assist\npathologists by enhancing diagnostic accuracy and reducing workload.", "AI": {"tldr": "The paper introduces CoAtNeXt, a hybrid model for classifying gastric tissue images that surpasses traditional methods in terms of accuracy, precision, recall, and AUC.", "motivation": "The study aims to address limitations in manual histopathological evaluations, such as labor-intensiveness, variability among pathologists, and lack of standardized methods.", "method": "The authors developed CoAtNeXt, which builds on the CoAtNet architecture by replacing MBConv layers with ConvNeXtV2 blocks and integrating CBAM for enhanced feature extraction. The model was tested on two datasets against 20 existing models.", "result": "CoAtNeXt achieved top-tier metrics, including 96.47% accuracy on the HMU-GC-HE-30K dataset and 98.29% accuracy on the GasHisSDB dataset, outperforming all other compared CNN and ViT models.", "conclusion": "CoAtNeXt demonstrates robust histopathological classification performance, offering both high accuracy and a reduction in pathologists' workload, thus supporting its utility in diagnostic settings."}}
{"id": "2509.09451", "pdf": "https://arxiv.org/pdf/2509.09451", "abs": "https://arxiv.org/abs/2509.09451", "authors": ["Anjie Qiao", "Zhen Wang", "Chuan Chen", "DeFu Lian", "Enhong Chen"], "title": "Composable Score-based Graph Diffusion Model for Multi-Conditional Molecular Generation", "categories": ["cs.LG"], "comment": null, "summary": "Controllable molecular graph generation is essential for material and drug\ndiscovery, where generated molecules must satisfy diverse property constraints.\nWhile recent advances in graph diffusion models have improved generation\nquality, their effectiveness in multi-conditional settings remains limited due\nto reliance on joint conditioning or continuous relaxations that compromise\nfidelity. To address these limitations, we propose Composable Score-based Graph\nDiffusion model (CSGD), the first model that extends score matching to discrete\ngraphs via concrete scores, enabling flexible and principled manipulation of\nconditional guidance. Building on this foundation, we introduce two score-based\ntechniques: Composable Guidance (CoG), which allows fine-grained control over\narbitrary subsets of conditions during sampling, and Probability Calibration\n(PC), which adjusts estimated transition probabilities to mitigate train-test\nmismatches. Empirical results on four molecular datasets show that CSGD\nachieves state-of-the-art performance, with a 15.3% average improvement in\ncontrollability over prior methods, while maintaining high validity and\ndistributional fidelity. Our findings highlight the practical advantages of\nscore-based modeling for discrete graph generation and its capacity for\nflexible, multi-property molecular design.", "AI": {"tldr": "CSGD introduces a method for generating molecular graphs that precisely satisfy property constraints using new score-based techniques, achieving better controllability, validity, and fidelity.", "motivation": "The paper aims to improve controllable molecular graph generation for material and drug discovery, addressing limitations in multi-conditional settings of recent diffusion models.", "method": "The proposed method, CSGD, extends score matching to discrete graphs via concrete scores. Two score-based techniques are introduced: CoG for fine-grained multi-conditional control and PC for mitigating train-test mismatches.", "result": "CSGD demonstrates state-of-the-art performance across four molecular datasets, showing a 15.3% improvement in controllability while preserving validity and fidelity.", "conclusion": "Score-based modeling proves advantageous for discrete graph generation, enabling flexible and effective molecular design in multi-property scenarios."}}
{"id": "2509.09254", "pdf": "https://arxiv.org/pdf/2509.09254", "abs": "https://arxiv.org/abs/2509.09254", "authors": ["Jing Hao", "Yuxuan Fan", "Yanpeng Sun", "Kaixin Guo", "Lizhuo Lin", "Jinrong Yang", "Qi Yong H. Ai", "Lun M. Wong", "Hao Tang", "Kuo Feng Hung"], "title": "Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis", "categories": ["cs.CV", "cs.MM"], "comment": "40 pages, 26 figures, 9 tables", "summary": "Recent advances in large vision-language models (LVLMs) have demonstrated\nstrong performance on general-purpose medical tasks. However, their\neffectiveness in specialized domains such as dentistry remains underexplored.\nIn particular, panoramic X-rays, a widely used imaging modality in oral\nradiology, pose interpretative challenges due to dense anatomical structures\nand subtle pathological cues, which are not captured by existing medical\nbenchmarks or instruction datasets. To this end, we introduce MMOral, the first\nlarge-scale multimodal instruction dataset and benchmark tailored for panoramic\nX-ray interpretation. MMOral consists of 20,563 annotated images paired with\n1.3 million instruction-following instances across diverse task types,\nincluding attribute extraction, report generation, visual question answering,\nand image-grounded dialogue. In addition, we present MMOral-Bench, a\ncomprehensive evaluation suite covering five key diagnostic dimensions in\ndentistry. We evaluate 64 LVLMs on MMOral-Bench and find that even the\nbest-performing model, i.e., GPT-4o, only achieves 41.45% accuracy, revealing\nsignificant limitations of current models in this domain. To promote the\nprogress of this specific domain, we also propose OralGPT, which conducts\nsupervised fine-tuning (SFT) upon Qwen2.5-VL-7B with our meticulously curated\nMMOral instruction dataset. Remarkably, a single epoch of SFT yields\nsubstantial performance enhancements for LVLMs, e.g., OralGPT demonstrates a\n24.73% improvement. Both MMOral and OralGPT hold significant potential as a\ncritical foundation for intelligent dentistry and enable more clinically\nimpactful multimodal AI systems in the dental field. The dataset, model,\nbenchmark, and evaluation suite are available at\nhttps://github.com/isbrycee/OralGPT.", "AI": {"tldr": "The paper introduces MMOral, the first large-scale multimodal dataset specifically for panoramic X-ray interpretation in dentistry. It includes evaluation benchmarks and proposes an improved model, OralGPT, achieving significant performance gains.", "motivation": "Large vision-language models (LVLMs) have shown promise in general medical tasks but underperform in specialized domains like dentistry, particularly in interpreting complex panoramic X-ray imagery.", "method": "The study creates MMOral\u2014a multimodal instruction dataset with 20,563 annotated images and 1.3M instruction instances\u2014and evaluates 64 LVLMs across five diagnostic dimensions, further proposing OralGPT, fine-tuned using MMOral.", "result": "The evaluation shows state-of-the-art GPT-4o performs poorly with only 41.45% accuracy. OralGPT, fine-tuned with MMOral, achieves a significant 24.73% improvement, demonstrating enhanced model capabilities.", "conclusion": "MMOral and OralGPT represent critical advancements for specialized AI applications in dentistry, offering improved diagnostic potential and paving the way for intelligent multimodal systems in the dental field."}}
{"id": "2509.09458", "pdf": "https://arxiv.org/pdf/2509.09458", "abs": "https://arxiv.org/abs/2509.09458", "authors": ["Golnoosh Abdollahinejad", "Saleh Baghersalimi", "Denisa-Andreea Constantinescu", "Sergey Shevchik", "David Atienza"], "title": "AquaCast: Urban Water Dynamics Forecasting with Precipitation-Informed Multi-Input Transformer", "categories": ["cs.LG"], "comment": "This work has been submitted to Journal of Hydrology, Elsevier, and a\n  preprint version is also available at SSRN 10.2139/ssrn.5399833", "summary": "This work addresses the challenge of forecasting urban water dynamics by\ndeveloping a multi-input, multi-output deep learning model that incorporates\nboth endogenous variables (e.g., water height or discharge) and exogenous\nfactors (e.g., precipitation history and forecast reports). Unlike conventional\nforecasting, the proposed model, AquaCast, captures both inter-variable and\ntemporal dependencies across all inputs, while focusing forecast solely on\nendogenous variables. Exogenous inputs are fused via an embedding layer,\neliminating the need to forecast them and enabling the model to attend to their\nshort-term influences more effectively. We evaluate our approach on the\nLausanneCity dataset, which includes measurements from four urban drainage\nsensors, and demonstrate state-of-the-art performance when using only\nendogenous variables. Performance also improves with the inclusion of exogenous\nvariables and forecast reports. To assess generalization and scalability, we\nadditionally test the model on three large-scale synthesized datasets,\ngenerated from MeteoSwiss records, the Lorenz Attractors model, and the Random\nFields model, each representing a different level of temporal complexity across\n100 nodes. The results confirm that our model consistently outperforms existing\nbaselines and maintains a robust and accurate forecast across both real and\nsynthetic datasets.", "AI": {"tldr": "The paper introduces AquaCast, a deep learning model for urban water dynamics forecasting, achieving state-of-the-art results on various datasets.", "motivation": "The paper aims to overcome limitations in urban water dynamics forecasting by integrating inter-variable and temporal dependencies using both endogenous and exogenous inputs.", "method": "AquaCast employs a multi-input, multi-output deep learning architecture and an embedding layer to handle exogenous variables effectively, focusing forecasts on endogenous factors.", "result": "Evaluation on the LausanneCity dataset and synthesized datasets confirms AquaCast's superior performance against baselines and its scalability across temporal complexities.", "conclusion": "AquaCast offers a robust, accurate, and scalable solution for forecasting urban water dynamics, outperforming traditional methods on real and synthetic datasets."}}
{"id": "2509.09263", "pdf": "https://arxiv.org/pdf/2509.09263", "abs": "https://arxiv.org/abs/2509.09263", "authors": ["Chao Yuan", "Yang Yang", "Yehui Yang", "Zach Cheng"], "title": "DATE: Dynamic Absolute Time Enhancement for Long Video Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Long video understanding remains a fundamental challenge for multimodal large\nlanguage models (MLLMs), particularly in tasks requiring precise temporal\nreasoning and event localization. Existing approaches typically adopt uniform\nframe sampling and rely on implicit position encodings to model temporal order.\nHowever, these methods struggle with long-range dependencies, leading to\ncritical information loss and degraded temporal comprehension. In this paper,\nwe propose Dynamic Absolute Time Enhancement (DATE) that enhances temporal\nawareness in MLLMs through the Timestamp Injection Mechanism (TIM) and a\nsemantically guided Temporal-Aware Similarity Sampling (TASS) strategy.\nSpecifically, we interleave video frame embeddings with textual timestamp\ntokens to construct a continuous temporal reference system. We further\nreformulate the video sampling problem as a vision-language retrieval task and\nintroduce a two-stage algorithm to ensure both semantic relevance and temporal\ncoverage: enriching each query into a descriptive caption to better align with\nthe vision feature, and sampling key event with a similarity-driven temporally\nregularized greedy strategy. Our method achieves remarkable improvements w.r.t.\nabsolute time understanding and key event localization, resulting in\nstate-of-the-art performance among 7B and 72B models on hour-long video\nbenchmarks. Particularly, our 7B model even exceeds many 72B models on some\nbenchmarks.", "AI": {"tldr": "The paper introduces a method, Dynamic Absolute Time Enhancement (DATE), using Timestamp Injection Mechanism (TIM) and Temporal-Aware Similarity Sampling (TASS) to improve long video understanding in multimodal large language models.", "motivation": "The study addresses the difficulty of understanding long videos in multimodal large language models, particularly the challenges of temporal reasoning, event localization, and handling long-range dependencies.", "method": "The proposed DATE approach involves embedding temporal tokens and reformulating video sampling as a vision-language retrieval problem. It uses TIM for temporal references and TASS for retrieving semantically relevant and temporally covered frames.", "result": "The method demonstrates enhanced temporal awareness, achieving state-of-the-art results across benchmarks for hour-long video tasks, with a 7B model outperforming some 72B models.", "conclusion": "DATE significantly improves temporal understanding in MLLMs, offering both precision in event localization and scalability to long videos."}}
{"id": "2509.09018", "pdf": "https://arxiv.org/pdf/2509.09018", "abs": "https://arxiv.org/abs/2509.09018", "authors": ["Xueyi Wang", "C. J. C.", "Lamoth", "Elisabeth Wilhelm"], "title": "Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "The paper has been acceptted and presented in the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society", "summary": "A sleep forecast allows individuals and healthcare providers to anticipate\nand proactively address factors influencing restful rest, ultimately improving\nmental and physical well-being. This work presents an adaptive spatial and\ntemporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model\ncombines convolutional layers to capture spatial feature interactions between\nmultiple features and recurrent neural network layers to handle longer-term\ntemporal health-related data. A domain classifier is further integrated to\ngeneralize across different subjects. We conducted several experiments using\nfive input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes\n(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline\nmodels, achieving its lowest RMSE (0.282) with a seven-day input window and a\none-day predicting window. Moreover, the method maintained strong performance\neven when forecasting multiple days into the future, demonstrating its\nversatility for real-world applications. Visual comparisons reveal that the\nmodel accurately tracks both the overall sleep score level and daily\nfluctuations. These findings prove that the proposed framework provides a\nrobust and adaptable solution for personalized sleep forecasting using sparse\ndata from commercial wearable devices and domain adaptation techniques.", "AI": {"tldr": "The paper introduces AdaST-Sleep, a model for personalized sleep forecasting using sparse wearable device data, combining spatial, temporal, and domain adaptation techniques. It outperformed baseline models and demonstrated strong predictive accuracy.", "motivation": "The paper aims to improve sleep forecasting to enhance mental and physical well-being by addressing sparsity in wearable data and ensuring model adaptability across different individuals.", "method": "The proposed AdaST-Sleep model integrates convolutional layers for spatial feature interactions, recurrent layers for handling temporal data, and a domain classifier for cross-subject generalization. Various input and predicting window sizes were analyzed.", "result": "AdaST-Sleep outperformed four baseline models, achieving an RMSE of 0.282 with optimal input and predicting windows (7-day input, 1-day prediction), and maintained high accuracy for multi-day forecasts.", "conclusion": "AdaST-Sleep provides a robust, adaptable solution for sleep forecasting using sparse wearable data, offering reliable predictions that track sleep scores and fluctuations accurately for real-world applications."}}
{"id": "2509.08919", "pdf": "https://arxiv.org/pdf/2509.08919", "abs": "https://arxiv.org/abs/2509.08919", "authors": ["Mahe Chen", "Xiaoxuan Wang", "Kaiwen Chen", "Nick Koudas"], "title": "Generative Engine Optimization: How to Dominate AI Search", "categories": ["cs.IR", "cs.CL", "cs.SI"], "comment": null, "summary": "The rapid adoption of generative AI-powered search engines like ChatGPT,\nPerplexity, and Gemini is fundamentally reshaping information retrieval, moving\nfrom traditional ranked lists to synthesized, citation-backed answers. This\nshift challenges established Search Engine Optimization (SEO) practices and\nnecessitates a new paradigm, which we term Generative Engine Optimization\n(GEO).\n  This paper presents a comprehensive comparative analysis of AI Search and\ntraditional web search (Google). Through a series of large-scale, controlled\nexperiments across multiple verticals, languages, and query paraphrases, we\nquantify critical differences in how these systems source information. Our key\nfindings reveal that AI Search exhibit a systematic and overwhelming bias\ntowards Earned media (third-party, authoritative sources) over Brand-owned and\nSocial content, a stark contrast to Google's more balanced mix. We further\ndemonstrate that AI Search services differ significantly from each other in\ntheir domain diversity, freshness, cross-language stability, and sensitivity to\nphrasing.\n  Based on these empirical results, we formulate a strategic GEO agenda. We\nprovide actionable guidance for practitioners, emphasizing the critical need\nto: (1) engineer content for machine scannability and justification, (2)\ndominate earned media to build AI-perceived authority, (3) adopt\nengine-specific and language-aware strategies, and (4) overcome the inherent\n\"big brand bias\" for niche players. Our work provides the foundational\nempirical analysis and a strategic framework for achieving visibility in the\nnew generative search landscape.", "AI": {"tldr": "This paper introduces a concept called Generative Engine Optimization (GEO), analyzing differences between generative AI-powered search engines and traditional web search like Google, along with strategies for optimizing content in the new landscape.", "motivation": "With the rise of generative AI search engines tackling information retrieval in different ways than traditional search engines, there is a need to understand and adapt to these changes to maintain or enhance visibility and effectiveness.", "method": "The research conducted large-scale controlled experiments across different industries, languages, and query phrasing to compare how AI-based search engines source information versus traditional methods.", "result": "The study found that generative AI search engines are biased towards authoritative, third-party sources over brand-owned or social content, significantly differing from Google. They also exhibit variability in domain diversity, data freshness, language stability, and query sensitivity.", "conclusion": "This paper proposes a strategic approach (GEO) for content optimization in the era of AI search engines, offering four key tactics and marking a shift in how search visibility is achieved in the generative AI landscape."}}
{"id": "2509.09470", "pdf": "https://arxiv.org/pdf/2509.09470", "abs": "https://arxiv.org/abs/2509.09470", "authors": ["Om Vishesh", "Harshad Khadilkar", "Deepak Akkil"], "title": "AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings", "categories": ["cs.LG"], "comment": "5 pages, 2 figures", "summary": "Keeping pace with the rapid growth of academia literature presents a\nsignificant challenge for researchers, funding bodies, and academic societies.\nTo address the time-consuming manual effort required for scholarly discovery,\nwe present a novel, fully automated system that transitions from data discovery\nto direct action. Our pipeline demonstrates how a specialized AI agent,\n'Agent-E', can be tasked with identifying papers from specific geographic\nregions within conference proceedings and then executing a Robotic Process\nAutomation (RPA) to complete a predefined action, such as submitting a\nnomination form. We validated our system on 586 papers from five different\nconferences, where it successfully identified every target paper with a recall\nof 100% and a near perfect accuracy of 99.4%. This demonstration highlights the\npotential of task-oriented AI agents to not only filter information but also to\nactively participate in and accelerate the workflows of the academic community.", "AI": {"tldr": "The paper presents 'Agent-E,' an automated AI system that identifies targeted academic papers and performs predefined actions, achieving high recall and accuracy.", "motivation": "To address the significant challenge of managing the rapid growth of academic literature and reduce time-consuming manual scholarly discovery.", "method": "Developing and testing 'Agent-E,' a specialized AI agent integrated with Robotic Process Automation (RPA) to identify papers from specific regions and execute predefined tasks.", "result": "Agent-E achieved 100% recall and 99.4% accuracy in identifying target papers from 586 papers across five conferences.", "conclusion": "Task-oriented AI agents like Agent-E can effectively accelerate academic workflows by performing both information filtering and predefined actions."}}
{"id": "2509.09267", "pdf": "https://arxiv.org/pdf/2509.09267", "abs": "https://arxiv.org/abs/2509.09267", "authors": ["Linhao Li", "Yiwen Ye", "Ziyang Chen", "Yong Xia"], "title": "Unified Start, Personalized End: Progressive Pruning for Efficient 3D Medical Image Segmentation", "categories": ["cs.CV"], "comment": "15 pages, 8 figures", "summary": "3D medical image segmentation often faces heavy resource and time\nconsumption, limiting its scalability and rapid deployment in clinical\nenvironments. Existing efficient segmentation models are typically static and\nmanually designed prior to training, which restricts their adaptability across\ndiverse tasks and makes it difficult to balance performance with resource\nefficiency. In this paper, we propose PSP-Seg, a progressive pruning framework\nthat enables dynamic and efficient 3D segmentation. PSP-Seg begins with a\nredundant model and iteratively prunes redundant modules through a combination\nof block-wise pruning and a functional decoupling loss. We evaluate PSP-Seg on\nfive public datasets, benchmarking it against seven state-of-the-art models and\nsix efficient segmentation models. Results demonstrate that the lightweight\nvariant, PSP-Seg-S, achieves performance on par with nnU-Net while reducing GPU\nmemory usage by 42-45%, training time by 29-48%, and parameter number by 83-87%\nacross all datasets. These findings underscore PSP-Seg's potential as a\ncost-effective yet high-performing alternative for widespread clinical\napplication.", "AI": {"tldr": "The paper introduces PSP-Seg, a dynamic 3D medical image segmentation framework that progressively prunes redundant model modules for improved efficiency and effectiveness.", "motivation": "3D medical image segmentation is resource-intensive and struggles with scalability and adaptability for diverse tasks. Current methods lack the dynamic ability to optimize resource efficiency without sacrificing performance.", "method": "PSP-Seg starts with a redundant model and progressively applies block-wise pruning, assisted by a functional decoupling loss, to streamline the model while retaining segmentation quality.", "result": "PSP-Seg-S, a lightweight variant, matches nnU-Net\u2019s performance while significantly reducing GPU memory (42-45%), training time (29-48%), and model parameters (83-87%) across five datasets.", "conclusion": "PSP-Seg offers a practical, efficient alternative for deploying 3D medical image segmentation in clinical settings, combining cost-effectiveness with high performance."}}
{"id": "2509.09037", "pdf": "https://arxiv.org/pdf/2509.09037", "abs": "https://arxiv.org/abs/2509.09037", "authors": ["Amanda Aird", "Ben Armstrong", "Nicholas Mattei", "Robin Burke"], "title": "Envy-Free but Still Unfair: Envy-Freeness Up To One Item (EF-1) in Personalized Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Envy-freeness and the relaxation to Envy-freeness up to one item (EF-1) have\nbeen used as fairness concepts in the economics, game theory, and social choice\nliteratures since the 1960s, and have recently gained popularity within the\nrecommendation systems communities. In this short position paper we will give\nan overview of envy-freeness and its use in economics and recommendation\nsystems; and illustrate why envy is not appropriate to measure fairness for use\nin settings where personalization plays a role.", "AI": {"tldr": "This paper critically evaluates the concept of envy-freeness in fairness criteria, particularly in contexts involving personalization, such as recommendation systems.", "motivation": "The authors aim to examine the sufficiency and relevance of envy-freeness, a widely-used fairness concept in economics and recommendation systems, especially when personalization is involved.", "method": "The paper provides an overview of the historical use of envy-freeness in economics and its application in recommendation systems, while illustrating the limitations of the concept in personalized settings.", "result": "The authors highlight key shortcomings of envy-freeness as a fairness measure when applied to personalized systems due to its inherent limitations.", "conclusion": "The paper concludes that envy-freeness or EF-1 is inadequate for assessing fairness in personalized recommendation systems and suggests the need for alternative measures."}}
{"id": "2509.09474", "pdf": "https://arxiv.org/pdf/2509.09474", "abs": "https://arxiv.org/abs/2509.09474", "authors": ["Julia Gastinger", "Christian Meilicke", "Heiner Stuckenschmidt"], "title": "CountTRuCoLa: Rule Confidence Learning for Temporal Knowledge Graph Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "We address the task of temporal knowledge graph (TKG) forecasting by\nintroducing a fully explainable method based on temporal rules. Motivated by\nrecent work proposing a strong baseline using recurrent facts, our approach\nlearns four simple types of rules with a confidence function that considers\nboth recency and frequency. Evaluated on nine datasets, our method matches or\nsurpasses the performance of eight state-of-the-art models and two baselines,\nwhile providing fully interpretable predictions.", "AI": {"tldr": "The paper proposes an explainable method using temporal rules for forecasting temporal knowledge graphs, surpassing state-of-the-art models across nine datasets.", "motivation": "To address the limitations of interpretability in temporal knowledge graph forecasting, despite recent advancements.", "method": "The approach involves learning four types of temporal rules and using a confidence function based on recency and frequency.", "result": "The proposed method achieves or outperforms eight state-of-the-art models and two baselines across nine datasets.", "conclusion": "The method offers competitive forecasting performance while ensuring full interpretability of predictions."}}
{"id": "2509.09286", "pdf": "https://arxiv.org/pdf/2509.09286", "abs": "https://arxiv.org/abs/2509.09286", "authors": ["Bohao Tang", "Yan Ma", "Fei Zhang", "Jiadi Su", "Ethan Chern", "Zhulin Hu", "Zhixin Wang", "Pengfei Liu", "Ya Zhang"], "title": "Visual Programmability: A Guide for Code-as-Thought in Chart Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Chart understanding presents a critical test to the reasoning capabilities of\nVision-Language Models (VLMs). Prior approaches face critical limitations: some\nrely on external tools, making them brittle and constrained by a predefined\ntoolkit, while others fine-tune specialist models that often adopt a single\nreasoning strategy, such as text-based chain-of-thought (CoT). The intermediate\nsteps of text-based reasoning are difficult to verify, which complicates the\nuse of reinforcement-learning signals that reward factual accuracy. To address\nthis, we propose a Code-as-Thought (CaT) approach to represent the visual\ninformation of a chart in a verifiable, symbolic format. Our key insight is\nthat this strategy must be adaptive: a fixed, code-only implementation\nconsistently fails on complex charts where symbolic representation is\nunsuitable. This finding leads us to introduce Visual Programmability: a\nlearnable property that determines if a chart-question pair is better solved\nwith code or direct visual analysis. We implement this concept in an adaptive\nframework where a VLM learns to choose between the CaT pathway and a direct\nvisual reasoning pathway. The selection policy of the model is trained with\nreinforcement learning using a novel dual-reward system. This system combines a\ndata-accuracy reward to ground the model in facts and prevent numerical\nhallucination, with a decision reward that teaches the model when to use each\nstrategy, preventing it from defaulting to a single reasoning mode. Experiments\ndemonstrate strong and robust performance across diverse chart-understanding\nbenchmarks. Our work shows that VLMs can be taught not only to reason but also\nhow to reason, dynamically selecting the optimal reasoning pathway for each\ntask.", "AI": {"tldr": "The paper introduces a novel approach called Code-as-Thought (CaT) for chart understanding using Vision-Language Models (VLMs). It proposes a system that dynamically chooses between symbolic code reasoning and visual analysis, addressing limitations of prior methods.", "motivation": "The authors aim to address the limitations of current VLMs for chart understanding, which are either brittle due to reliance on external tools or constrained to single reasoning strategies like text-based chain-of-thought reasoning.", "method": "The paper introduces Code-as-Thought (CaT) combined with Visual Programmability, where a VLM adaptively chooses between symbolic (code-based) reasoning or direct visual analysis using a selection policy trained through reinforcement learning with dual rewards.", "result": "Experiments indicate improved and robust performance across diverse benchmarks for chart understanding, demonstrating the model's ability to dynamically select optimal reasoning strategies.", "conclusion": "This study concludes that VLMs can be trained to not only conduct reasoning but also to dynamically adapt their reasoning strategies based on task requirements, enhancing their accuracy and flexibility in chart understanding."}}
{"id": "2509.09485", "pdf": "https://arxiv.org/pdf/2509.09485", "abs": "https://arxiv.org/abs/2509.09485", "authors": ["Zhanhong Jiang", "Md Zahid Hasan", "Nastaran Saadati", "Aditya Balu", "Chao Liu", "Soumik Sarkar"], "title": "Balancing Utility and Privacy: Dynamically Private SGD with Random Projection", "categories": ["cs.LG"], "comment": "27 pages, 13 figures", "summary": "Stochastic optimization is a pivotal enabler in modern machine learning,\nproducing effective models for various tasks. However, several existing works\nhave shown that model parameters and gradient information are susceptible to\nprivacy leakage. Although Differentially Private SGD (DPSGD) addresses privacy\nconcerns, its static noise mechanism impacts the error bounds for model\nperformance. Additionally, with the exponential increase in model parameters,\nefficient learning of these models using stochastic optimizers has become more\nchallenging. To address these concerns, we introduce the Dynamically\nDifferentially Private Projected SGD (D2P2-SGD) optimizer. In D2P2-SGD, we\ncombine two important ideas: (i) dynamic differential privacy (DDP) with\nautomatic gradient clipping and (ii) random projection with SGD, allowing\ndynamic adjustment of the tradeoff between utility and privacy of the model. It\nexhibits provably sub-linear convergence rates across different objective\nfunctions, matching the best available rate. The theoretical analysis further\nsuggests that DDP leads to better utility at the cost of privacy, while random\nprojection enables more efficient model learning. Extensive experiments across\ndiverse datasets show that D2P2-SGD remarkably enhances accuracy while\nmaintaining privacy. Our code is available here.", "AI": {"tldr": "This paper introduces D2P2-SGD, a stochastic optimization method that combines dynamic differential privacy and random projection to improve privacy-utility tradeoffs in machine learning while retaining sub-linear convergence rates.", "motivation": "The study aims to address privacy leakage issues in stochastic optimization and challenges in efficiently training large-scale machine learning models using existing techniques.", "method": "The approach integrates dynamic privacy mechanisms with automatic gradient clipping and incorporates random projection techniques to optimize the trade-off between privacy and model utility.", "result": "Theoretical analysis demonstrates sub-linear convergence rates, and experiments across diverse datasets show significant accuracy improvements while ensuring privacy.", "conclusion": "D2P2-SGD is an effective optimization method that balances privacy and utility tradeoffs, making it a valuable tool for large-scale and privacy-sensitive machine learning applications."}}
{"id": "2509.09290", "pdf": "https://arxiv.org/pdf/2509.09290", "abs": "https://arxiv.org/abs/2509.09290", "authors": ["Anthony P. Addison", "Felix Wagner", "Wentian Xu", "Natalie Voets", "Konstantinos Kamnitsas"], "title": "Modality-Agnostic Input Channels Enable Segmentation of Brain lesions in Multimodal MRI with Sequences Unavailable During Training", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to MICCAI 2025, for the following workshop: ML-CDS 2025:\n  Multimodal Learning and Fusion Across Scales for Clinical Decision Support", "summary": "Segmentation models are important tools for the detection and analysis of\nlesions in brain MRI. Depending on the type of brain pathology that is imaged,\nMRI scanners can acquire multiple, different image modalities (contrasts). Most\nsegmentation models for multimodal brain MRI are restricted to fixed modalities\nand cannot effectively process new ones at inference. Some models generalize to\nunseen modalities but may lose discriminative modality-specific information.\nThis work aims to develop a model that can perform inference on data that\ncontain image modalities unseen during training, previously seen modalities,\nand heterogeneous combinations of both, thus allowing a user to utilize any\navailable imaging modalities. We demonstrate this is possible with a simple,\nthus practical alteration to the U-net architecture, by integrating a\nmodality-agnostic input channel or pathway, alongside modality-specific input\nchannels. To train this modality-agnostic component, we develop an image\naugmentation scheme that synthesizes artificial MRI modalities. Augmentations\ndifferentially alter the appearance of pathological and healthy brain tissue to\ncreate artificial contrasts between them while maintaining realistic anatomical\nintegrity. We evaluate the method using 8 MRI databases that include 5 types of\npathologies (stroke, tumours, traumatic brain injury, multiple sclerosis and\nwhite matter hyperintensities) and 8 modalities (T1, T1+contrast, T2, PD, SWI,\nDWI, ADC and FLAIR). The results demonstrate that the approach preserves the\nability to effectively process MRI modalities encountered during training,\nwhile being able to process new, unseen modalities to improve its segmentation.\nProject code: https://github.com/Anthony-P-Addison/AGN-MOD-SEG", "AI": {"tldr": "This paper develops a segmentation model for brain MRI that can effectively handle unseen and mixed imaging modalities using a modified U-net architecture with a modality-agnostic input pathway and augmented training data.", "motivation": "Current segmentation models are limited, as they either cannot process unseen modalities effectively or lose specific information when generalizing to new modalities. An improved model is needed to handle unseen and mixed modalities while maintaining segmentation accuracy.", "method": "The authors modify the U-net architecture by adding a modality-agnostic input channel alongside modality-specific input channels. They use an image augmentation scheme to generate artificial MRI modalities, simulating realistic contrasts between healthy and pathological tissues.", "result": "Using 8 MRI datasets with 5 pathologies and 8 modalities, the model effectively processes both seen and unseen image modalities while preserving segmentation performance.", "conclusion": "The proposed approach enables segmentation models to generalize to new MRI modalities while maintaining accuracy for familiar ones, enhancing the utility of the model in diverse clinical scenarios."}}
{"id": "2509.09204", "pdf": "https://arxiv.org/pdf/2509.09204", "abs": "https://arxiv.org/abs/2509.09204", "authors": ["Chin Yuen Kwok", "Jia Qi Yip", "Zhen Qiu", "Chi Hung Chi", "Kwok Yan Lam"], "title": "Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": "Published in Interspeech 2025", "summary": "Audio deepfake detection (ADD) models are commonly evaluated using datasets\nthat combine multiple synthesizers, with performance reported as a single Equal\nError Rate (EER). However, this approach disproportionately weights\nsynthesizers with more samples, underrepresenting others and reducing the\noverall reliability of EER. Additionally, most ADD datasets lack diversity in\nbona fide speech, often featuring a single environment and speech style (e.g.,\nclean read speech), limiting their ability to simulate real-world conditions.\nTo address these challenges, we propose bona fide cross-testing, a novel\nevaluation framework that incorporates diverse bona fide datasets and\naggregates EERs for more balanced assessments. Our approach improves robustness\nand interpretability compared to traditional evaluation methods. We benchmark\nover 150 synthesizers across nine bona fide speech types and release a new\ndataset to facilitate further research at\nhttps://github.com/cyaaronk/audio_deepfake_eval.", "AI": {"tldr": "The paper critiques traditional evaluation methods for audio deepfake detection (ADD) and introduces a new framework for robust and balanced assessments.", "motivation": "The motivation is to address biases in commonly used Equal Error Rate (EER) evaluation metrics, which disproportionately favor certain synthesizers and lack diversity in bona fide speech datasets.", "method": "The authors propose 'bona fide cross-testing,' a framework using diverse bona fide datasets and aggregated EERs for more reliable and balanced assessments.", "result": "Benchmarking is conducted over 150 synthesizers across nine bona fide speech types, revealing improved robustness and interpretability compared to traditional methods.", "conclusion": "The proposed framework enhances the reliability of audio deepfake detection evaluations, and a new dataset is released to support further research."}}
{"id": "2509.09512", "pdf": "https://arxiv.org/pdf/2509.09512", "abs": "https://arxiv.org/abs/2509.09512", "authors": ["Cynthia Moreira Maia", "Lucas B. V. de Amorim", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "PIPES: A Meta-dataset of Machine Learning Pipelines", "categories": ["cs.LG"], "comment": null, "summary": "Solutions to the Algorithm Selection Problem (ASP) in machine learning face\nthe challenge of high computational costs associated with evaluating various\nalgorithms' performances on a given dataset. To mitigate this cost, the\nmeta-learning field can leverage previously executed experiments shared in\nonline repositories such as OpenML. OpenML provides an extensive collection of\nmachine learning experiments. However, an analysis of OpenML's records reveals\nlimitations. It lacks diversity in pipelines, specifically when exploring data\npreprocessing steps/blocks, such as scaling or imputation, resulting in limited\nrepresentation. Its experiments are often focused on a few popular techniques\nwithin each pipeline block, leading to an imbalanced sample. To overcome the\nobserved limitations of OpenML, we propose PIPES, a collection of experiments\ninvolving multiple pipelines designed to represent all combinations of the\nselected sets of techniques, aiming at diversity and completeness. PIPES stores\nthe results of experiments performed applying 9,408 pipelines to 300 datasets.\nIt includes detailed information on the pipeline blocks, training and testing\ntimes, predictions, performances, and the eventual error messages. This\ncomprehensive collection of results allows researchers to perform analyses\nacross diverse and representative pipelines and datasets. PIPES also offers\npotential for expansion, as additional data and experiments can be incorporated\nto support the meta-learning community further. The data, code, supplementary\nmaterial, and all experiments can be found at\nhttps://github.com/cynthiamaia/PIPES.git.", "AI": {"tldr": "The paper addresses algorithm selection challenges in machine learning, proposing PIPES, a diversified and comprehensive repository to overcome limitations of OpenML.", "motivation": "To tackle inefficiencies and biases in meta-learning repositories like OpenML by providing a more diverse and exhaustive pipeline dataset.", "method": "Creation of PIPES, a dataset containing results from 9,408 diverse pipelines applied to 300 datasets, including exhaustive information such as error messages.", "result": "PIPES offers a broad collection of experiments that cover diverse preprocessing pipelines, improving representativeness and diversity.", "conclusion": "PIPES enhances meta-learning by supporting diverse pipeline analyses and can be expanded to benefit future studies in the field."}}
{"id": "2509.09515", "pdf": "https://arxiv.org/pdf/2509.09515", "abs": "https://arxiv.org/abs/2509.09515", "authors": ["Yoga Disha Sendhil Kumar", "Manas V Shetty", "Sudip Vhaduri"], "title": "Cough Classification using Few-Shot Learning", "categories": ["cs.LG"], "comment": "8 pages 8 images Has been accepted in Pervasive Health 2025", "summary": "This paper investigates the effectiveness of few-shot learning for\nrespiratory sound classification, focusing on coughbased detection of COVID-19,\nFlu, and healthy conditions. We leverage Prototypical Networks with spectrogram\nrepresentations of cough sounds to address the challenge of limited labeled\ndata. Our study evaluates whether few-shot learning can enable models to\nachieve performance comparable to traditional deep learning approaches while\nusing significantly fewer training samples. Additionally, we compare\nmulti-class and binary classification models to assess whether multi-class\nmodels can perform comparably to their binary counterparts. Experimental\nfindings show that few-shot learning models can achieve competitive accuracy.\nOur model attains 74.87% accuracy in multi-class classification with only 15\nsupport examples per class, while binary classification achieves over 70%\naccuracy across all class pairs. Class-wise analysis reveals Flu as the most\ndistinguishable class, and Healthy as the most challenging. Statistical tests\n(paired t-test p = 0.149, Wilcoxon p = 0.125) indicate no significant\nperformance difference between binary and multiclass models, supporting the\nviability of multi-class classification in this setting. These results\nhighlight the feasibility of applying few-shot learning in medical diagnostics,\nparticularly when large labeled datasets are unavailable.", "AI": {"tldr": "The study explores few-shot learning's ability to classify respiratory sounds for COVID-19, Flu, and healthy conditions using Prototypical Networks with limited labeled data. It achieves competitive accuracy in both binary and multi-class settings.", "motivation": "To address the challenge of limited labeled data in medical diagnostics, particularly for classifying respiratory sounds and identifying conditions such as COVID-19 and Flu.", "method": "The paper employs Prototypical Networks with spectrogram representations of cough sounds and compares few-shot learning to traditional deep learning. It also evaluates performance differences between binary and multi-class classification.", "result": "Few-shot learning models achieved 74.87% accuracy in multi-class classification with 15 support examples per class, and over 70% accuracy in binary classification across all class pairs. Flu was most distinguishable, while Healthy was most challenging. Statistical tests showed no significant performance differences between binary and multi-class approaches.", "conclusion": "Few-shot learning is viable for medical diagnostics such as respiratory sound classification, offering competitive performance even with limited labeled data. Multi-class classification is feasible alongside binary approaches."}}
{"id": "2509.09298", "pdf": "https://arxiv.org/pdf/2509.09298", "abs": "https://arxiv.org/abs/2509.09298", "authors": ["Oh-Tae Jang", "Min-Gon Cho", "Kyung-Tae Kim"], "title": "Learning Object-Centric Representations in SAR Images with Multi-Level Feature Fusion", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "Synthetic aperture radar (SAR) images contain not only targets of interest\nbut also complex background clutter, including terrain reflections and speckle\nnoise. In many cases, such clutter exhibits intensity and patterns that\nresemble targets, leading models to extract entangled or spurious features.\nSuch behavior undermines the ability to form clear target representations,\nregardless of the classifier. To address this challenge, we propose a novel\nobject-centric learning (OCL) framework, named SlotSAR, that disentangles\ntarget representations from background clutter in SAR images without mask\nannotations. SlotSAR first extracts high-level semantic features from SARATR-X\nand low-level scattering features from the wavelet scattering network in order\nto obtain complementary multi-level representations for robust target\ncharacterization. We further present a multi-level slot attention module that\nintegrates these low- and high-level features to enhance slot-wise\nrepresentation distinctiveness, enabling effective OCL. Experimental results\ndemonstrate that SlotSAR achieves state-of-the-art performance in SAR imagery\nby preserving structural details compared to existing OCL methods.", "AI": {"tldr": "SlotSAR is a new framework for disentangling target representations from background clutter in SAR images without mask annotations, combining multi-level semantic and scattering features for improved accuracy.", "motivation": "SAR images often contain clutter resembling targets, complicating the process of extracting target-specific representations essential for classification.", "method": "SlotSAR extracts semantic features from SARATR-X and scattering features via a wavelet scattering network. The multi-level slot attention module combines these features to enhance representation clarity.", "result": "Experimental evaluation showed SlotSAR outperforms existing object-centric learning methods for SAR images, preserving structural details and achieving state-of-the-art performance.", "conclusion": "SlotSAR effectively disentangles target representations from background clutter in SAR images, advancing the accuracy and robustness of object-centric learning approaches."}}
{"id": "2509.09307", "pdf": "https://arxiv.org/pdf/2509.09307", "abs": "https://arxiv.org/abs/2509.09307", "authors": ["Zhengzhao Lai", "Youbin Zheng", "Zhenyang Cai", "Haonan Lyu", "Jinpu Yang", "Hongqing Liang", "Yan Hu", "Benyou Wang"], "title": "Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "Materials characterization is fundamental to acquiring materials information,\nrevealing the processing-microstructure-property relationships that guide\nmaterial design and optimization. While multimodal large language models\n(MLLMs) have recently shown promise in generative and predictive tasks within\nmaterials science, their capacity to understand real-world characterization\nimaging data remains underexplored. To bridge this gap, we present MatCha, the\nfirst benchmark for materials characterization image understanding, comprising\n1,500 questions that demand expert-level domain expertise. MatCha encompasses\nfour key stages of materials research comprising 21 distinct tasks, each\ndesigned to reflect authentic challenges faced by materials scientists. Our\nevaluation of state-of-the-art MLLMs on MatCha reveals a significant\nperformance gap compared to human experts. These models exhibit degradation\nwhen addressing questions requiring higher-level expertise and sophisticated\nvisual perception. Simple few-shot and chain-of-thought prompting struggle to\nalleviate these limitations. These findings highlight that existing MLLMs still\nexhibit limited adaptability to real-world materials characterization\nscenarios. We hope MatCha will facilitate future research in areas such as new\nmaterial discovery and autonomous scientific agents. MatCha is available at\nhttps://github.com/FreedomIntelligence/MatCha.", "AI": {"tldr": "The paper introduces MatCha, the first benchmark dataset for understanding materials characterization image data. It comprises tasks to evaluate multimodal large language models' (MLLMs) domain expertise against human experts.", "motivation": "To address the limited exploration of MLLMs' capabilities in interpreting real-world materials characterization imaging data, which is critical for materials science research.", "method": "Developed MatCha, a benchmark of 1,500 expert-level questions across 21 tasks reflecting real-world challenges in materials characterization, and evaluated state-of-the-art MLLMs on these tasks.", "result": "Current MLLMs show significant performance gaps compared to human experts, particularly for tasks requiring high-level expertise and visual perception. Prompting strategies did not effectively overcome these limitations.", "conclusion": "MLLMs require further development to adapt to real-world materials characterization scenarios, and MatCha provides a foundation for advancing research in this area, including material discovery and autonomous agents."}}
{"id": "2509.09597", "pdf": "https://arxiv.org/pdf/2509.09597", "abs": "https://arxiv.org/abs/2509.09597", "authors": ["Maysam Behmanesh", "Erkan Turan", "Maks Ovsjanikov"], "title": "Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "23 pages", "summary": "Graph alignment-the problem of identifying corresponding nodes across\nmultiple graphs-is fundamental to numerous applications. Most existing\nunsupervised methods embed node features into latent representations to enable\ncross-graph comparison without ground-truth correspondences. However, these\nmethods suffer from two critical limitations: the degradation of node\ndistinctiveness due to oversmoothing in GNN-based embeddings, and the\nmisalignment of latent spaces across graphs caused by structural noise, feature\nheterogeneity, and training instability, ultimately leading to unreliable node\ncorrespondences. We propose a novel graph alignment framework that\nsimultaneously enhances node distinctiveness and enforces geometric consistency\nacross latent spaces. Our approach introduces a dual-pass encoder that combines\nlow-pass and high-pass spectral filters to generate embeddings that are both\nstructure-aware and highly discriminative. To address latent space\nmisalignment, we incorporate a geometry-aware functional map module that learns\nbijective and isometric transformations between graph embeddings, ensuring\nconsistent geometric relationships across different representations. Extensive\nexperiments on graph benchmarks demonstrate that our method consistently\noutperforms existing unsupervised alignment baselines, exhibiting superior\nrobustness to structural inconsistencies and challenging alignment scenarios.\nAdditionally, comprehensive evaluation on vision-language benchmarks using\ndiverse pretrained models shows that our framework effectively generalizes\nbeyond graph domains, enabling unsupervised alignment of vision and language\nrepresentations.", "AI": {"tldr": "The paper addresses the challenge of aligning nodes from multiple graphs without ground-truth correspondences, proposing a framework to improve node distinctiveness and alignment through spectral filtering and geometric mapping.", "motivation": "Current unsupervised graph alignment methods suffer from oversmoothing, degrading node distinctiveness, and the misalignment of latent spaces due to various forms of structural and feature inconsistencies.", "method": "A dual-pass encoder is used with low-pass and high-pass spectral filters for distinct embeddings, combined with a geometry-aware functional map module to align latent spaces through bijective and isometric transformations.", "result": "The approach outperformed current unsupervised methods in robustness and accuracy across graph benchmarks and also generalized well to vision-language alignment tasks using pretrained models.", "conclusion": "The proposed framework effectively addresses critical limitations in graph alignment by enhancing node distinctiveness and ensuring consistent latent space geometry, providing strong capabilities across diverse scenarios."}}
{"id": "2509.09310", "pdf": "https://arxiv.org/pdf/2509.09310", "abs": "https://arxiv.org/abs/2509.09310", "authors": ["Hao Si", "Ehsan Javanmardi", "Manabu Tsukada"], "title": "You Share Beliefs, I Adapt: Progressive Heterogeneous Collaborative Perception", "categories": ["cs.CV"], "comment": null, "summary": "Collaborative perception enables vehicles to overcome individual perception\nlimitations by sharing information, allowing them to see further and through\nocclusions. In real-world scenarios, models on different vehicles are often\nheterogeneous due to manufacturer variations. Existing methods for\nheterogeneous collaborative perception address this challenge by fine-tuning\nadapters or the entire network to bridge the domain gap. However, these methods\nare impractical in real-world applications, as each new collaborator must\nundergo joint training with the ego vehicle on a dataset before inference, or\nthe ego vehicle stores models for all potential collaborators in advance.\nTherefore, we pose a new question: Can we tackle this challenge directly during\ninference, eliminating the need for joint training? To answer this, we\nintroduce Progressive Heterogeneous Collaborative Perception (PHCP), a novel\nframework that formulates the problem as few-shot unsupervised domain\nadaptation. Unlike previous work, PHCP dynamically aligns features by\nself-training an adapter during inference, eliminating the need for labeled\ndata and joint training. Extensive experiments on the OPV2V dataset demonstrate\nthat PHCP achieves strong performance across diverse heterogeneous scenarios.\nNotably, PHCP achieves performance comparable to SOTA methods trained on the\nentire dataset while using only a small amount of unlabeled data.", "AI": {"tldr": "The paper proposes PHCP, a framework for collaborative perception among heterogeneous vehicle models during inference without joint training or labeled data adoption.", "motivation": "Current heterogeneous collaborative perception methods require impractical joint training or storing pre-trained models for all potential collaborators, which limits real-world application.", "method": "PHCP (Progressive Heterogeneous Collaborative Perception) uses few-shot unsupervised domain adaptation by dynamically self-training an adapter during inference, bypassing joint training and labeled datasets.", "result": "PHCP achieves performance comparable to state-of-the-art methods and demonstrates strong results on the OPV2V dataset using minimal unlabeled data.", "conclusion": "PHCP provides a feasible and robust solution for heterogeneous collaborative perception during inference by addressing domain gap challenges without pre-training or explicit data labeling."}}
{"id": "2509.09599", "pdf": "https://arxiv.org/pdf/2509.09599", "abs": "https://arxiv.org/abs/2509.09599", "authors": ["Ira J. S. Shokar", "Rich R. Kerswell", "Peter H. Haynes"], "title": "Conditioning on PDE Parameters to Generalise Deep Learning Emulation of Stochastic and Chaotic Dynamics", "categories": ["cs.LG", "math.DS", "nlin.CD", "physics.ao-ph"], "comment": null, "summary": "We present a deep learning emulator for stochastic and chaotic\nspatio-temporal systems, explicitly conditioned on the parameter values of the\nunderlying partial differential equations (PDEs). Our approach involves\npre-training the model on a single parameter domain, followed by fine-tuning on\na smaller, yet diverse dataset, enabling generalisation across a broad range of\nparameter values. By incorporating local attention mechanisms, the network is\ncapable of handling varying domain sizes and resolutions. This enables\ncomputationally efficient pre-training on smaller domains while requiring only\na small additional dataset to learn how to generalise to larger domain sizes.\nWe demonstrate the model's capabilities on the chaotic Kuramoto-Sivashinsky\nequation and stochastically-forced beta-plane turbulence, showcasing its\nability to capture phenomena at interpolated parameter values. The emulator\nprovides significant computational speed-ups over conventional numerical\nintegration, facilitating efficient exploration of parameter space, while a\nprobabilistic variant of the emulator provides uncertainty quantification,\nallowing for the statistical study of rare events.", "AI": {"tldr": "This paper presents a deep learning-based emulator for parameterized stochastic and chaotic spatio-temporal systems modeled by PDEs, offering speed-ups over traditional numerical integration and enabling efficient parameter exploration.", "motivation": "The study of spatio-temporal systems faces computational challenges when using conventional numerical integration for a wide range of parameter values. A fast and generalizable approach is needed to explore these systems efficiently.", "method": "The approach involves pre-training the emulator on a single parameter domain, then fine-tuning on a smaller but diverse dataset to achieve generalization. It uses local attention mechanisms to adapt to varying domain sizes and resolutions. Tests were conducted using the chaotic Kuramoto-Sivashinsky equation and beta-plane turbulence models.", "result": "The emulator successfully captures dynamics at interpolated parameter values, demonstrating significant computational efficiency and retaining accuracy. A probabilistic variant also accounts for uncertainty and allows statistical analysis of rare events.", "conclusion": "This emulator enables efficient exploration of spatio-temporal systems under a wide parameter range, providing a computationally efficient and flexible tool with uncertainty quantification capabilities."}}
{"id": "2509.09311", "pdf": "https://arxiv.org/pdf/2509.09311", "abs": "https://arxiv.org/abs/2509.09311", "authors": ["Illia Volkov", "Nikita Kisel", "Klara Janouskova", "Jiri Matas"], "title": "Image Recognition with Vision and Language Embeddings of VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have enabled strong zero-shot classification\nthrough image-text alignment. Yet, their purely visual inference capabilities\nremain under-explored. In this work, we conduct a comprehensive evaluation of\nboth language-guided and vision-only image classification with a diverse set of\ndual-encoder VLMs, including both well-established and recent models such as\nSigLIP 2 and RADIOv2.5. The performance is compared in a standard setup on the\nImageNet-1k validation set and its label-corrected variant. The key factors\naffecting accuracy are analysed, including prompt design, class diversity, the\nnumber of neighbours in k-NN, and reference set size. We show that language and\nvision offer complementary strengths, with some classes favouring textual\nprompts and others better handled by visual similarity. To exploit this\ncomplementarity, we introduce a simple, learning-free fusion method based on\nper-class precision that improves classification performance. The code is\navailable at: https://github.com/gonikisgo/bmvc2025-vlm-image-recognition.", "AI": {"tldr": "This paper evaluates the visual and language-guided classification capabilities of vision-language models, proposing a fusion method to enhance performance.", "motivation": "To explore and enhance the under-explored visual inference capabilities of vision-language models and analyze the complementary strengths of language and vision.", "method": "A comprehensive evaluation of dual-encoder VLMs in both visual and language-guided settings, analyzing factors like prompt design and reference set size, complemented by a fusion method for improved performance.", "result": "The study confirms that vision and language strengths are complementary and introduces a fusion method based on per-class precision to enhance classification.", "conclusion": "The fusion of textual and visual inputs leads to improved image classification performance, showcasing the complementary potentials of both modalities."}}
{"id": "2509.09611", "pdf": "https://arxiv.org/pdf/2509.09611", "abs": "https://arxiv.org/abs/2509.09611", "authors": ["Haolan Zheng", "Yanlai Chen", "Jiequn Han", "Yue Yu"], "title": "ReBaNO: Reduced Basis Neural Operator Mitigating Generalization Gaps and Achieving Discretization Invariance", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We propose a novel data-lean operator learning algorithm, the Reduced Basis\nNeural Operator (ReBaNO), to solve a group of PDEs with multiple distinct\ninputs. Inspired by the Reduced Basis Method and the recently introduced\nGenerative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a\nmathematically rigorous greedy algorithm to build its network structure offline\nadaptively from the ground up. Knowledge distillation via task-specific\nactivation function allows ReBaNO to have a compact architecture requiring\nminimal computational cost online while embedding physics. In comparison to\nstate-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO,\nand CNO, numerical results demonstrate that ReBaNO significantly outperforms\nthem in terms of eliminating/shrinking the generalization gap for both in- and\nout-of-distribution tests and being the only operator learning algorithm\nachieving strict discretization invariance.", "AI": {"tldr": "This paper introduces the Reduced Basis Neural Operator (ReBaNO), a new method for solving PDEs with multiple inputs, which achieves higher generalization performance and strict discretization invariance compared to other state-of-the-art methods.", "motivation": "The motivation lies in addressing challenges in learning operators for solving PDEs with multiple inputs, particularly aiming to minimize the generalization gap and achieve discretization invariance, which are limitations in existing methods.", "method": "The proposed method, ReBaNO, combines a greedy Reduced Basis methodology with a compact, physics-informed neural network architecture. It uses task-specific activation functions and offline network structure optimization via a rigorous algorithm.", "result": "ReBaNO demonstrated superior performance over other operator learning methods such as PCA-Net, DeepONet, FNO, and CNO, notably in generalization for both in- and out-of-distribution cases while being the only method to achieve discretization invariance.", "conclusion": "ReBaNO is an advanced operator learning method offering computational efficiency and improved performance for solving PDEs, addressing both generalization gaps and numerical discretization challenges effectively."}}
{"id": "2509.09324", "pdf": "https://arxiv.org/pdf/2509.09324", "abs": "https://arxiv.org/abs/2509.09324", "authors": ["Hui Li", "Yi You", "Qiqi Chen", "Bingfeng Zhang", "George Q. Huang"], "title": "Fine-Grained Customized Fashion Design with Image-into-Prompt benchmark and dataset from LMM", "categories": ["cs.CV"], "comment": null, "summary": "Generative AI evolves the execution of complex workflows in industry, where\nthe large multimodal model empowers fashion design in the garment industry.\nCurrent generation AI models magically transform brainstorming into fancy\ndesigns easily, but the fine-grained customization still suffers from text\nuncertainty without professional background knowledge from end-users. Thus, we\npropose the Better Understanding Generation (BUG) workflow with LMM to\nautomatically create and fine-grain customize the cloth designs from chat with\nimage-into-prompt. Our framework unleashes users' creative potential beyond\nwords and also lowers the barriers of clothing design/editing without further\nhuman involvement. To prove the effectiveness of our model, we propose a new\nFashionEdit dataset that simulates the real-world clothing design workflow,\nevaluated from generation similarity, user satisfaction, and quality. The code\nand dataset: https://github.com/detectiveli/FashionEdit.", "AI": {"tldr": "The paper introduces the BUG (Better Understanding Generation) workflow utilizing LMM to improve fine-grained customization in garment design, proposing a new FashionEdit dataset for evaluation.", "motivation": "The aim is to address the challenge of fine-grained customization in AI garment design due to text ambiguity and lack of professional knowledge by end-users.", "method": "The BUG workflow uses a large multimodal model (LMM) to integrate image-to-prompt for automatic creation, customization, and editing of clothing designs, removing the need for human intervention.", "result": "The authors demonstrate effectiveness through the proposed FashionEdit dataset, designed to simulate real-world design workflows and evaluate generation similarity, user satisfaction, and design quality.", "conclusion": "The proposed framework enhances creative potential and simplifies the clothing design/editing process, offering a practical solution for empowering both end-users and industry professionals."}}
{"id": "2509.09091", "pdf": "https://arxiv.org/pdf/2509.09091", "abs": "https://arxiv.org/abs/2509.09091", "authors": ["Honglan Yu", "Yibin Wang", "Feifei Dai", "Dong Liu", "Haihui Fan", "Xiaoyan Gu"], "title": "Towards Confidential and Efficient LLM Inference with Dual Privacy Protection", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted by DASFAA2025", "summary": "CPU-based trusted execution environments (TEEs) and differential privacy (DP)\nhave gained wide applications for private inference. Due to high inference\nlatency in TEEs, researchers use partition-based approaches that offload linear\nmodel components to GPUs. However, dense nonlinear layers of large language\nmodels (LLMs) result in significant communication overhead between TEEs and\nGPUs. DP-based approaches apply random noise to protect data privacy, but this\ncompromises LLM performance and semantic understanding. To overcome the above\ndrawbacks, this paper proposes CMIF, a Confidential and efficient Model\nInference Framework. CMIF confidentially deploys the embedding layer in the\nclient-side TEE and subsequent layers on GPU servers. Meanwhile, it optimizes\nthe Report-Noisy-Max mechanism to protect sensitive inputs with a slight\ndecrease in model performance. Extensive experiments on Llama-series models\ndemonstrate that CMIF reduces additional inference overhead in TEEs while\npreserving user data privacy.", "AI": {"tldr": "CMIF, a confidential model inference framework, addresses TEE latency and DP-induced performance losses in private inference by intelligently partitioning layers and optimizing noise mechanisms.", "motivation": "To improve privacy-preserving inference by reducing latency in TEEs and overcoming performance degradation caused by DP noise.", "method": "Deploy embedding layers in client-side TEE, offload subsequent layers to GPU servers, and optimize Report-Noisy-Max mechanism for privacy.", "result": "CMIF successfully reduces TEE inference latency while maintaining better data privacy and user data protection than existing approaches.", "conclusion": "CMIF provides an efficient solution balancing model performance, data privacy, and inference latency for large language model deployments."}}
{"id": "2509.09616", "pdf": "https://arxiv.org/pdf/2509.09616", "abs": "https://arxiv.org/abs/2509.09616", "authors": ["Ignacy St\u0119pka", "Jerzy Stefanowski"], "title": "Explaining Concept Drift through the Evolution of Group Counterfactuals", "categories": ["cs.LG", "cs.AI"], "comment": "TempXAI Workshop @ ECML PKDD 2025", "summary": "Machine learning models in dynamic environments often suffer from concept\ndrift, where changes in the data distribution degrade performance. While\ndetecting this drift is a well-studied topic, explaining how and why the\nmodel's decision-making logic changes still remains a significant challenge. In\nthis paper, we introduce a novel methodology to explain concept drift by\nanalyzing the temporal evolution of group-based counterfactual explanations\n(GCEs). Our approach tracks shifts in the GCEs' cluster centroids and their\nassociated counterfactual action vectors before and after a drift. These\nevolving GCEs act as an interpretable proxy, revealing structural changes in\nthe model's decision boundary and its underlying rationale. We operationalize\nthis analysis within a three-layer framework that synergistically combines\ninsights from the data layer (distributional shifts), the model layer\n(prediction disagreement), and our proposed explanation layer. We show that\nsuch holistic view allows for a more comprehensive diagnosis of drift, making\nit possible to distinguish between different root causes, such as a spatial\ndata shift versus a re-labeling of concepts.", "AI": {"tldr": "This paper presents a method to explain concept drift in machine learning by analyzing group-based counterfactual explanations (GCEs).", "motivation": "Concept drift often degrades machine learning models' performance in dynamic environments, but current methods lack the ability to explain how and why decisions change.", "method": "The authors track the evolution of group-based counterfactual explanations, analyzing changes in cluster centroids and counterfactual action vectors within a three-layer framework.", "result": "The approach enables a holistic diagnosis of concept drift by combining data distribution shifts, model prediction disagreements, and explanation-layer insights.", "conclusion": "This method provides a more nuanced understanding of concept drift, allowing for identification of specific root causes like spatial shifts or concept re-labeling."}}
{"id": "2509.09327", "pdf": "https://arxiv.org/pdf/2509.09327", "abs": "https://arxiv.org/abs/2509.09327", "authors": ["Dimitrios Anastasiou", "Razvan Caramalau", "Nazir Sirajudeen", "Matthew Boal", "Philip Edwards", "Justin Collins", "John Kelly", "Ashwin Sridhar", "Maxine Tran", "Faiz Mumtaz", "Nevil Pavithran", "Nader Francis", "Danail Stoyanov", "Evangelos B. Mazomenos"], "title": "Exploring Pre-training Across Domains for Few-Shot Surgical Skill Assessment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MICCAI 2025 DEMI Workshop", "summary": "Automated surgical skill assessment (SSA) is a central task in surgical\ncomputer vision. Developing robust SSA models is challenging due to the\nscarcity of skill annotations, which are time-consuming to produce and require\nexpert consensus. Few-shot learning (FSL) offers a scalable alternative\nenabling model development with minimal supervision, though its success\ncritically depends on effective pre-training. While widely studied for several\nsurgical downstream tasks, pre-training has remained largely unexplored in SSA.\nIn this work, we formulate SSA as a few-shot task and investigate how\nself-supervised pre-training strategies affect downstream few-shot SSA\nperformance. We annotate a publicly available robotic surgery dataset with\nObjective Structured Assessment of Technical Skill (OSATS) scores, and evaluate\nvarious pre-training sources across three few-shot settings. We quantify domain\nsimilarity and analyze how domain gap and the inclusion of procedure-specific\ndata into pre-training influence transferability. Our results show that small\nbut domain-relevant datasets can outperform large scale, less aligned ones,\nachieving accuracies of 60.16%, 66.03%, and 73.65% in the 1-, 2-, and 5-shot\nsettings, respectively. Moreover, incorporating procedure-specific data into\npre-training with a domain-relevant external dataset significantly boosts\ndownstream performance, with an average gain of +1.22% in accuracy and +2.28%\nin F1-score; however, applying the same strategy with less similar but\nlarge-scale sources can instead lead to performance degradation. Code and\nmodels are available at https://github.com/anastadimi/ssa-fsl.", "AI": {"tldr": "The paper explores automated surgical skill assessment (SSA) using few-shot learning (FSL) and evaluates the impact of different pre-training strategies on model performance.", "motivation": "Due to the scarcity of skill annotations requiring expert consensus, the paper aims to leverage few-shot learning (FSL) for SSA, which minimizes the need for extensive data annotation.", "method": "SSA is formulated as a few-shot task. The authors evaluate pre-training sources on a robotic surgery dataset annotated with OSATS scores and analyze the impact of domain similarity and procedure-specific data on downstream performance.", "result": "Small and domain-relevant pre-training datasets outperform less aligned large-scale ones, achieving accuracies of 60.16%, 66.03%, and 73.65% in 1-shot, 2-shot, and 5-shot settings, respectively. Incorporating procedure-specific data improves accuracy (+1.22%) and F1-score (+2.28%).", "conclusion": "Pre-training strategies focused on domain relevance are crucial for improving few-shot SSA performance, and procedure-specific data further enhances model transferability. Large-scale pre-training data that lacks domain alignment can negatively impact performance."}}
{"id": "2509.09097", "pdf": "https://arxiv.org/pdf/2509.09097", "abs": "https://arxiv.org/abs/2509.09097", "authors": ["Honghui Xu", "Shiva Shrestha", "Wei Chen", "Zhiyuan Li", "Zhipeng Cai"], "title": "DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As on-device large language model (LLM) systems become increasingly\nprevalent, federated fine-tuning enables advanced language understanding and\ngeneration directly on edge devices; however, it also involves processing\nsensitive, user-specific data, raising significant privacy concerns within the\nfederated learning framework. To address these challenges, we propose\nDP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates\nLoRA-based adaptation with differential privacy in a communication-efficient\nsetting. Each client locally clips and perturbs its LoRA matrices using\nGaussian noise to satisfy ($\\epsilon$, $\\delta$)-differential privacy. We\nfurther provide a theoretical analysis demonstrating the unbiased nature of the\nupdates and deriving bounds on the variance introduced by noise, offering\npractical guidance for privacy-budget calibration. Experimental results across\nmainstream benchmarks show that DP-FedLoRA delivers competitive performance\nwhile offering strong privacy guarantees, paving the way for scalable and\nprivacy-preserving LLM deployment in on-device environments.", "AI": {"tldr": "DP-FedLoRA is a framework combining LoRA-based adaptation and differential privacy to enable federated fine-tuning of large language models on devices, ensuring privacy and efficiency.", "motivation": "Federated fine-tuning for on-device large language models raises privacy concerns due to user-specific sensitive data being processed, necessitating privacy-preserving methods.", "method": "DP-FedLoRA applies differential privacy by perturbing locally updated LoRA matrices with Gaussian noise, ensuring ($\\epsilon$, $\\delta$)-differential privacy. It uses a communication-efficient framework and includes theoretical analysis for unbiased updates and noise variance control.", "result": "The framework achieves competitive performance on standard benchmarks while maintaining strong privacy guarantees.", "conclusion": "DP-FedLoRA offers a scalable, privacy-preserving solution for deploying advanced language models on edge devices, showing its effectiveness through experiments and theoretical grounding."}}
{"id": "2509.09631", "pdf": "https://arxiv.org/pdf/2509.09631", "abs": "https://arxiv.org/abs/2509.09631", "authors": ["Ngoc-Son Nguyen", "Hieu-Nghia Huynh-Nguyen", "Thanh V. T. Tran", "Truong-Son Hy", "Van Nguyen"], "title": "DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech", "categories": ["cs.SD", "cs.CL", "cs.CV"], "comment": null, "summary": "Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that\nmimics the voice of an unseen speaker using only a short reference sample,\nrequiring not only speaker adaptation but also accurate modeling of prosodic\nattributes. Recent approaches based on language models, diffusion, and flow\nmatching have shown promising results in zero-shot TTS, but still suffer from\nslow inference and repetition artifacts. Discrete codec representations have\nbeen widely adopted for speech synthesis, and recent works have begun to\nexplore diffusion models in purely discrete settings, suggesting the potential\nof discrete generative modeling for speech synthesis. However, existing\nflow-matching methods typically embed these discrete tokens into a continuous\nspace and apply continuous flow matching, which may not fully leverage the\nadvantages of discrete representations. To address these challenges, we\nintroduce DiFlow-TTS, which, to the best of our knowledge, is the first model\nto explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS\nexplicitly models factorized speech attributes within a compact and unified\narchitecture. It leverages in-context learning by conditioning on textual\ncontent, along with prosodic and acoustic attributes extracted from a reference\nspeech, enabling effective attribute cloning in a zero-shot setting. In\naddition, the model employs a factorized flow prediction mechanism with\ndistinct heads for prosody and acoustic details, allowing it to learn\naspect-specific distributions. Experimental results demonstrate that DiFlow-TTS\nachieves promising performance in several key metrics, including naturalness,\nprosody, preservation of speaker style, and energy control. It also maintains a\ncompact model size and achieves low-latency inference, generating speech up to\n25.8 times faster than the latest existing baselines.", "AI": {"tldr": "DiFlow-TTS is introduced as a novel zero-shot text-to-speech model utilizing discrete flow matching for faster and high-quality speech synthesis.", "motivation": "To address the slow inference speed and repetition artifacts of recent zero-shot TTS methods while leveraging discrete generative modeling effectively.", "method": "Proposed a discrete flow matching method within a unified architecture that factorizes speech attributes and employs distinct heads for prosody and acoustic details. It leverages in-context learning for textual and reference-based attribute conditioning.", "result": "Achieved promising results in naturalness, prosody, speaker style preservation, and energy control while maintaining compactness and generating speech up to 25.8 times faster than existing baselines.", "conclusion": "DiFlow-TTS effectively balances quality and performance, showcasing the potential of discrete flow matching in advancing zero-shot TTS synthesis."}}
{"id": "2509.09619", "pdf": "https://arxiv.org/pdf/2509.09619", "abs": "https://arxiv.org/abs/2509.09619", "authors": ["Roshan Balaji", "Joe Bobby", "Nirav Pravinbhai Bhatt"], "title": "Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Molecular property prediction using deep learning (DL) models has accelerated\ndrug and materials discovery, but the resulting DL models often lack\ninterpretability, hindering their adoption by chemists. This work proposes\ndeveloping molecule representations using the concept of Functional Groups (FG)\nin chemistry. We introduce the Functional Group Representation (FGR) framework,\na novel approach to encoding molecules based on their fundamental chemical\nsubstructures. Our method integrates two types of functional groups: those\ncurated from established chemical knowledge (FG), and those mined from a large\nmolecular corpus using sequential pattern mining (MFG). The resulting FGR\nframework encodes molecules into a lower-dimensional latent space by leveraging\npre-training on a large dataset of unlabeled molecules. Furthermore, the\nproposed framework allows the inclusion of 2D structure-based descriptors of\nmolecules. We demonstrate that the FGR framework achieves state-of-the-art\nperformance on a diverse range of 33 benchmark datasets spanning physical\nchemistry, biophysics, quantum mechanics, biological activity, and\npharmacokinetics while enabling chemical interpretability. Crucially, the\nmodel's representations are intrinsically aligned with established chemical\nprinciples, allowing chemists to directly link predicted properties to specific\nfunctional groups and facilitating novel insights into structure-property\nrelationships. Our work presents a significant step toward developing\nhigh-performing, chemically interpretable DL models for molecular discovery.", "AI": {"tldr": "The paper proposes Functional Group Representation (FGR), a deep learning framework leveraging functional group information to predict molecular properties with enhanced interpretability for chemists.", "motivation": "Deep learning models have advanced molecular property prediction but lack chemical interpretability, which limits their adoption by chemists.", "method": "The authors develop the Functional Group Representation (FGR) framework, encoding molecules using chemically curated and mined functional groups (FGs and MFGs). A latent space representation is learned through pre-training on unlabeled molecules, and 2D structure-based descriptors are included.", "result": "The FGR framework outperforms other methods across 33 benchmark datasets in various scientific domains while providing chemical explanations for predictions.", "conclusion": "FGR achieves state-of-the-art results while enhancing interpretability by aligning predictions with chemical principles, bridging the gap between chemists and deep learning models."}}
{"id": "2509.09112", "pdf": "https://arxiv.org/pdf/2509.09112", "abs": "https://arxiv.org/abs/2509.09112", "authors": ["Zhaoxi Zhang", "Xiaomei Zhang", "Yanjun Zhang", "He Zhang", "Shirui Pan", "Bo Liu", "Asif Qumer Gill", "Leo Yu Zhang"], "title": "Character-Level Perturbations Disrupt LLM Watermarks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) watermarking embeds detectable signals into\ngenerated text for copyright protection, misuse prevention, and content\ndetection. While prior studies evaluate robustness using watermark removal\nattacks, these methods are often suboptimal, creating the misconception that\neffective removal requires large perturbations or powerful adversaries.\n  To bridge the gap, we first formalize the system model for LLM watermark, and\ncharacterize two realistic threat models constrained on limited access to the\nwatermark detector. We then analyze how different types of perturbation vary in\ntheir attack range, i.e., the number of tokens they can affect with a single\nedit. We observe that character-level perturbations (e.g., typos, swaps,\ndeletions, homoglyphs) can influence multiple tokens simultaneously by\ndisrupting the tokenization process. We demonstrate that character-level\nperturbations are significantly more effective for watermark removal under the\nmost restrictive threat model. We further propose guided removal attacks based\non the Genetic Algorithm (GA) that uses a reference detector for optimization.\nUnder a practical threat model with limited black-box queries to the watermark\ndetector, our method demonstrates strong removal performance. Experiments\nconfirm the superiority of character-level perturbations and the effectiveness\nof the GA in removing watermarks under realistic constraints. Additionally, we\nargue there is an adversarial dilemma when considering potential defenses: any\nfixed defense can be bypassed by a suitable perturbation strategy. Motivated by\nthis principle, we propose an adaptive compound character-level attack.\nExperimental results show that this approach can effectively defeat the\ndefenses. Our findings highlight significant vulnerabilities in existing LLM\nwatermark schemes and underline the urgency for the development of new robust\nmechanisms.", "AI": {"tldr": "The paper explores vulnerabilities in existing watermarking methods for Large Language Models (LLMs), emphasizing the effectiveness of character-level perturbations and proposing adaptive attack strategies for watermark removal.", "motivation": "The study seeks to address misconceptions around watermark removal in LLM-generated text, aiming to understand realistic threat models and to explore effective removal techniques under constrained settings.", "method": "The researchers formalize LLM watermark threat models, analyze perturbation types (focusing on character-level disruptions), and propose Genetic Algorithm-based guided attacks and adaptive compound strategies to test vulnerabilities and bypass defenses.", "result": "Character-level perturbations were found to be highly effective in disrupting LLM watermarks, especially under constrained threat models. The guided attacks using Genetic Algorithms showed strong performance, even with limited access to watermark detectors.", "conclusion": "Existing LLM watermark systems are vulnerable to character-level attacks, highlighting the critical need for developing more robust watermarking mechanisms and adaptive defenses."}}
{"id": "2509.09651", "pdf": "https://arxiv.org/pdf/2509.09651", "abs": "https://arxiv.org/abs/2509.09651", "authors": ["Zakaria El Kassimi", "Fares Fourati", "Mohamed-Slim Alouini"], "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "eess.SP"], "comment": null, "summary": "We study question answering in the domain of radio regulations, a legally\nsensitive and high-stakes area. We propose a telecom-specific\nRetrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,\nthe first multiple-choice evaluation set for this domain, constructed from\nauthoritative sources using automated filtering and human validation. To assess\nretrieval quality, we define a domain-specific retrieval metric, under which\nour retriever achieves approximately 97% accuracy. Beyond retrieval, our\napproach consistently improves generation accuracy across all tested models. In\nparticular, while naively inserting documents without structured retrieval\nyields only marginal gains for GPT-4o (less than 1%), applying our pipeline\nresults in nearly a 12% relative improvement. These findings demonstrate that\ncarefully targeted grounding provides a simple yet strong baseline and an\neffective domain-specific solution for regulatory question answering. All code\nand evaluation scripts, along with our derived question-answer dataset, are\navailable at https://github.com/Zakaria010/Radio-RAG.", "AI": {"tldr": "This paper presents a retrieval-augmented generation pipeline for question answering in the domain of radio regulations, achieving significant accuracy improvements with targeted methods.", "motivation": "The study addresses the lack of domain-specific solutions for question answering in high-stakes areas like radio regulations, emphasizing the need for accurate retrieval and generation in this legally sensitive field.", "method": "The authors designed a telecom-specific Retrieval-Augmented Generation pipeline and created a multiple-choice evaluation dataset. They combined automated filtering with human validation and defined a domain-specific retrieval metric to evaluate performance.", "result": "The proposed retriever attained 97% accuracy, and the pipeline achieved nearly a 12% improvement in generation accuracy for GPT-4. Na\u00efve document insertion showed minimal improvement.", "conclusion": "The paper demonstrates that targeted grounding via a domain-specific RAG pipeline offers a strong baseline and effective solution for regulatory question answering. Resources and datasets are made publicly available."}}
{"id": "2509.09655", "pdf": "https://arxiv.org/pdf/2509.09655", "abs": "https://arxiv.org/abs/2509.09655", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management", "categories": ["cs.LG", "cs.AI", "cs.LO", "stat.AP"], "comment": "12 pages, 5 figures, 3 tables", "summary": "We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning\n(FG-FARL), an offline RL procedure that calibrates per-group safety thresholds\nto reduce harm while equalizing a chosen fairness target (coverage or harm)\nacross protected subgroups. Using de-identified longitudinal trajectories from\na Medicaid population health management program, we evaluate FG-FARL against\nbehavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global\nconformal safety baseline). We report off-policy value estimates with bootstrap\n95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL\nachieves comparable value to baselines while improving fairness metrics,\ndemonstrating a practical path to safer and more equitable decision support.", "AI": {"tldr": "The paper introduces FG-FARL, an offline RL method to balance safety and fairness across subgroups, evaluated on healthcare data, showing improved fairness metrics while maintaining performance.", "motivation": "The motivation is to address the harm and fairness disparities in decision support systems, especially in sensitive domains like healthcare, by developing RL methods that ensure safety thresholds and fairness.", "method": "The authors propose FG-FARL, an offline reinforcement learning procedure that adjusts group-level safety thresholds to balance harm and fairness. They evaluate it using Medicaid health data and compare it with existing methods: BC and HACO.", "result": "FG-FARL achieved performance similar to the baselines (BC and HACO) while improving fairness metrics, as measured by subgroup disparities and confidence intervals.", "conclusion": "FG-FARL demonstrates a practical and effective approach to making decision support systems both safer and fairer, particularly in healthcare settings, by aligning fairness with safety goals."}}
{"id": "2509.09352", "pdf": "https://arxiv.org/pdf/2509.09352", "abs": "https://arxiv.org/abs/2509.09352", "authors": ["Xiaodong Wang", "Zijun He", "Xin Yuan"], "title": "Texture-aware Intrinsic Image Decomposition with Model- and Learning-based Priors", "categories": ["cs.CV"], "comment": null, "summary": "This paper aims to recover the intrinsic reflectance layer and shading layer\ngiven a single image. Though this intrinsic image decomposition problem has\nbeen studied for decades, it remains a significant challenge in cases of\ncomplex scenes, i.e. spatially-varying lighting effect and rich textures. In\nthis paper, we propose a novel method for handling severe lighting and rich\ntextures in intrinsic image decomposition, which enables to produce\nhigh-quality intrinsic images for real-world images. Specifically, we observe\nthat previous learning-based methods tend to produce texture-less and\nover-smoothing intrinsic images, which can be used to infer the lighting and\ntexture information given a RGB image. In this way, we design a texture-guided\nregularization term and formulate the decomposition problem into an\noptimization framework, to separate the material textures and lighting effect.\nWe demonstrate that combining the novel texture-aware prior can produce\nsuperior results to existing approaches.", "AI": {"tldr": "This paper presents a novel method to improve intrinsic image decomposition by handling complex scenes with severe lighting and rich textures.", "motivation": "The intrinsic image decomposition problem, specifically separating reflectance and shading layers from a single image, remains challenging in complex scenes with spatially-varying lighting and rich textures.", "method": "The authors introduce a texture-guided regularization term within an optimization framework to better separate material textures and lighting. This method incorporates a novel texture-aware prior to address limitations of existing approaches.", "result": "The proposed approach produces high-quality intrinsic images and outperforms current methods in handling lighting and texture complexities, as demonstrated through their evaluation.", "conclusion": "Integrating texture-aware prior enhances intrinsic image decomposition, overcoming issues of over-smoothing and texture-less outputs in prior methods."}}
{"id": "2509.09679", "pdf": "https://arxiv.org/pdf/2509.09679", "abs": "https://arxiv.org/abs/2509.09679", "authors": ["Bingxin Xu", "Zhen Dong", "Oussama Elachqar", "Yuzhang Shang"], "title": "ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Replace discrete Hadamard transforms with continuous Butterfly\n  transforms to facilitate the learning of rotation matrices in LLM\n  quantization", "summary": "Large language models require massive memory footprints, severely limiting\ndeployment on consumer hardware. Quantization reduces memory through lower\nnumerical precision, but extreme 2-bit quantization suffers from catastrophic\nperformance loss due to outliers in activations. Rotation-based methods such as\nQuIP and QuaRot apply orthogonal transforms to eliminate outliers before\nquantization, using computational invariance: $\\mathbf{y} = \\mathbf{Wx} =\n(\\mathbf{WQ}^T)(\\mathbf{Qx})$ for orthogonal $\\mathbf{Q}$. However, these\nmethods use fixed transforms--Hadamard matrices achieving optimal worst-case\ncoherence $\\mu = 1/\\sqrt{n}$--that cannot adapt to specific weight\ndistributions. We identify that different transformer layers exhibit distinct\noutlier patterns, motivating layer-adaptive rotations rather than\none-size-fits-all approaches. We propose ButterflyQuant, which replaces\nHadamard rotations with learnable butterfly transforms parameterized by\ncontinuous Givens rotation angles. Unlike Hadamard's discrete $\\{+1, -1\\}$\nentries that are non-differentiable and prohibit gradient-based learning,\nbutterfly transforms' continuous parameterization enables smooth optimization\nwhile guaranteeing orthogonality by construction. This orthogonal constraint\nensures theoretical guarantees in outlier suppression while achieving $O(n \\log\nn)$ computational complexity with only $\\frac{n \\log n}{2}$ learnable\nparameters. We further introduce a uniformity regularization on\npost-transformation activations to promote smoother distributions amenable to\nquantization. Learning requires only 128 calibration samples and converges in\nminutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit\nquantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.", "AI": {"tldr": "ButterflyQuant improves memory efficiency in large language models by using learnable butterfly transforms and uniformity regularization, achieving better performance under extreme 2-bit quantization.", "motivation": "Large language models face deployment challenges on consumer hardware due to their high memory requirements. Extreme quantization methods like 2-bit often suffer due to activation outliers, motivating adaptive techniques that address outlier suppression.", "method": "The paper introduces ButterflyQuant, which replaces fixed Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens angles. This ensures smoother optimization, retains orthogonality, and adds uniformity regularization to improve post-transformation quantization.", "result": "ButterflyQuant reduces computational complexity to $O(n \\log n)$ with fewer learnable parameters and achieves a perplexity score of 15.4 on LLaMA-2-7B with 2-bit quantization, outperforming similar methods like QuaRot (22.1 perplexity).", "conclusion": "ButterflyQuant provides a memory-efficient and adaptable approach to extreme quantization for large language models, enabling practical deployment through negligible learning costs and improved performance."}}
{"id": "2509.09365", "pdf": "https://arxiv.org/pdf/2509.09365", "abs": "https://arxiv.org/abs/2509.09365", "authors": ["Xiaodong Wang", "Ping Wang", "Zhangyuan Li", "Xin Yuan"], "title": "Plug-and-play Diffusion Models for Image Compressive Sensing with Data Consistency Projection", "categories": ["cs.CV"], "comment": null, "summary": "We explore the connection between Plug-and-Play (PnP) methods and Denoising\nDiffusion Implicit Models (DDIM) for solving ill-posed inverse problems, with a\nfocus on single-pixel imaging. We begin by identifying key distinctions between\nPnP and diffusion models-particularly in their denoising mechanisms and\nsampling procedures. By decoupling the diffusion process into three\ninterpretable stages: denoising, data consistency enforcement, and sampling, we\nprovide a unified framework that integrates learned priors with physical\nforward models in a principled manner. Building upon this insight, we propose a\nhybrid data-consistency module that linearly combines multiple PnP-style\nfidelity terms. This hybrid correction is applied directly to the denoised\nestimate, improving measurement consistency without disrupting the diffusion\nsampling trajectory. Experimental results on single-pixel imaging tasks\ndemonstrate that our method achieves better reconstruction quality.", "AI": {"tldr": "The paper investigates the link between Plug-and-Play (PnP) methods and Denoising Diffusion Implicit Models (DDIM) for solving inverse problems, focusing on single-pixel imaging. It proposes a unified framework and hybrid data-consistency module for better reconstruction quality.", "motivation": "To unify PnP and DDIM strategies for addressing ill-posed inverse problems, with emphasis on improving single-pixel imaging reconstruction performance.", "method": "The authors decouple the diffusion process into denoising, data consistency enforcement, and sampling stages. They introduce a hybrid data-consistency module combining PnP-style fidelity terms to enhance measurement accuracy without altering sampling trajectories.", "result": "The experimental findings demonstrate improved reconstruction quality in single-pixel imaging tasks using the proposed method.", "conclusion": "A unified and principled framework that integrates learned priors with physical models enhances reconstruction quality and measurement consistency in solving inverse problems."}}
{"id": "2509.08830", "pdf": "https://arxiv.org/pdf/2509.08830", "abs": "https://arxiv.org/abs/2509.08830", "authors": ["Seong-A Park", "Jong-Eui Chae", "Sungdong Kim", "Hyung-Chul Lee", "Hyun-Lim Yang"], "title": "A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals", "categories": ["eess.SP", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "In clinical settings, monitoring hemodynamics is crucial for managing patient\nprognosis, necessitating the integrated analysis of multiple physiological\nsignals. While recent research has analyzed single signals such as\nelectrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a\nproposal for an approach that encompasses the complex signal analysis required\nin actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul\nNational University hospital PHYsiological signal Masked representation\nlearning) model extracts physiological features reflecting the electrical,\npressure, and fluid characteristics of the cardiac cycle in the process of\nrestoring three masked physiological signals based on self-supervised learning\n(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing\nmultiple physical characteristics, the model can extract more enriched features\nonly using non-invasive signals. We evaluated the model's performance in\nclinical downstream tasks such as hypotension, stroke volume, systolic blood\npressure, diastolic blood pressure, and age prediction. Our results showed that\nthe SNUPHY-M significantly outperformed supervised or SSL models, especially in\nprediction tasks using non-invasive signals. To the best of our knowledge,\nSNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis\ninvolving ECG, PPG, and ABP signals. This approach effectively supports\nclinical decision-making and enables precise diagnostics, contributing\nsignificantly to the early diagnosis and management of hemodynamics without\ninvasiveness.", "AI": {"tldr": "The paper proposes a novel model, SNUPHY-M, leveraging multi-modal self-supervised learning (SSL) for clinical signal analysis using ECG, PPG, and ABP signals, significantly improving prediction tasks with non-invasive methods.", "motivation": "There is a critical need for integrated analysis of multiple physiological signals to better manage patient prognosis in clinical settings, as current approaches focus on single signal analysis and are insufficient for complex clinical scenarios.", "method": "The study introduces the SNUPHY-M model based on self-supervised learning (SSL) to restore three masked physiological signals (ECG, PPG, and ABP) and extract features reflecting cardiac cycle characteristics using multi-modal representation.", "result": "SNUPHY-M demonstrated superior performance in several clinical downstream tasks, including predicting hypotension, stroke volume, blood pressure metrics, and age, outperforming supervised and traditional SSL approaches, especially with non-invasive signals.", "conclusion": "SNUPHY-M provides a significant step forward in cardiovascular analysis by applying multi-modal SSL, supporting clinical decision-making and enabling early diagnosis and management of hemodynamics non-invasively."}}
{"id": "2509.09368", "pdf": "https://arxiv.org/pdf/2509.09368", "abs": "https://arxiv.org/abs/2509.09368", "authors": ["Pengxu Wen", "Tingting Yu", "Ziwei Nie", "Cheng Jiang", "Zhenyu Yin", "Mingyang He", "Bo Liao", "Xiaoping Yang"], "title": "A Fully Automatic Framework for Intracranial Pressure Grading: Integrating Keyframe Identification, ONSD Measurement and Clinical Data", "categories": ["cs.CV"], "comment": null, "summary": "Intracranial pressure (ICP) elevation poses severe threats to cerebral\nfunction, thus necessitating monitoring for timely intervention. While lumbar\npuncture is the gold standard for ICP measurement, its invasiveness and\nassociated risks drive the need for non-invasive alternatives. Optic nerve\nsheath diameter (ONSD) has emerged as a promising biomarker, as elevated ICP\ndirectly correlates with increased ONSD. However, current clinical practices\nfor ONSD measurement suffer from inconsistency in manual operation,\nsubjectivity in optimal view selection, and variability in thresholding,\nlimiting their reliability. To address these challenges, we introduce a fully\nautomatic two-stage framework for ICP grading, integrating keyframe\nidentification, ONSD measurement and clinical data. Specifically, the fundus\nultrasound video processing stage performs frame-level anatomical segmentation,\nrule-based keyframe identification guided by an international consensus\nstatement, and precise ONSD measurement. The intracranial pressure grading\nstage then fuses ONSD metrics with clinical features to enable the prediction\nof ICP grades, thereby demonstrating an innovative blend of interpretable\nultrasound analysis and multi-source data integration for objective clinical\nevaluation. Experimental results demonstrate that our method achieves a\nvalidation accuracy of $0.845 \\pm 0.071$ (with standard deviation from\nfive-fold cross-validation) and an independent test accuracy of 0.786,\nsignificantly outperforming conventional threshold-based method ($0.637 \\pm\n0.111$ validation accuracy, $0.429$ test accuracy). Through effectively\nreducing operator variability and integrating multi-source information, our\nframework establishes a reliable non-invasive approach for clinical ICP\nevaluation, holding promise for improving patient management in acute\nneurological conditions.", "AI": {"tldr": "This paper introduces a non-invasive, automated two-stage framework for evaluating intracranial pressure (ICP) using optic nerve sheath diameter (ONSD) and clinical data to improve accuracy and reliability.", "motivation": "The need arises because invasive methods like lumbar puncture have risks, and current ONSD measurement practices are inconsistent and subjective.", "method": "The framework processes ultrasound video for ONSD measurement using segmentation and keyframe identification, then integrates ONSD metrics with clinical data to predict ICP grades.", "result": "The method achieves superior accuracy (validation: 0.845 \u00b1 0.071; test: 0.786) compared to conventional methods (validation: 0.637 \u00b1 0.111; test: 0.429).", "conclusion": "By reducing operator variability and integrating multi-source data, the framework provides a reliable tool for non-invasive ICP evaluation, benefiting acute neurological patient management."}}
{"id": "2509.09680", "pdf": "https://arxiv.org/pdf/2509.09680", "abs": "https://arxiv.org/abs/2509.09680", "authors": ["Rongyao Fang", "Aldrich Yu", "Chengqi Duan", "Linjiang Huang", "Shuai Bai", "Yuxuan Cai", "Kun Wang", "Si Liu", "Xihui Liu", "Hongsheng Li"], "title": "FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark", "categories": ["cs.CV", "cs.CL"], "comment": "Project page: https://flux-reason-6m.github.io/", "summary": "The advancement of open-source text-to-image (T2I) models has been hindered\nby the absence of large-scale, reasoning-focused datasets and comprehensive\nevaluation benchmarks, resulting in a performance gap compared to leading\nclosed-source systems. To address this challenge, We introduce FLUX-Reason-6M\nand PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).\nFLUX-Reason-6M is a massive dataset consisting of 6 million high-quality\nFLUX-generated images and 20 million bilingual (English and Chinese)\ndescriptions specifically designed to teach complex reasoning. The image are\norganized according to six key characteristics: Imagination, Entity, Text\nrendering, Style, Affection, and Composition, and design explicit Generation\nChain-of-Thought (GCoT) to provide detailed breakdowns of image generation\nsteps. The whole data curation takes 15,000 A100 GPU days, providing the\ncommunity with a resource previously unattainable outside of large industrial\nlabs. PRISM-Bench offers a novel evaluation standard with seven distinct\ntracks, including a formidable Long Text challenge using GCoT. Through\ncarefully designed prompts, it utilizes advanced vision-language models for\nnuanced human-aligned assessment of prompt-image alignment and image\naesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench\nreveals critical performance gaps and highlights specific areas requiring\nimprovement. Our dataset, benchmark, and evaluation code are released to\ncatalyze the next wave of reasoning-oriented T2I generation. Project page:\nhttps://flux-reason-6m.github.io/ .", "AI": {"tldr": "This paper addresses limitations in open-source text-to-image (T2I) models by introducing a reasoning-focused dataset (FLUX-Reason-6M) and a comprehensive evaluation benchmark (PRISM-Bench).", "motivation": "There is a performance gap between open-source and closed-source T2I models due to the lack of reasoning-specific datasets and robust evaluation frameworks.", "method": "The authors developed FLUX-Reason-6M, consisting of 6M FLUX-generated images and bilingual captions, alongside PRISM-Bench, a 7-track benchmark leveraging advanced vision-language models for evaluation. They used 15,000 A100 GPU days for data curation and designed explicit Generation Chain-of-Thought (GCoT) for detailed reasoning steps.", "result": "The study evaluated 19 leading models on PRISM-Bench, exposing critical performance gaps and pinpointing areas needing improvement for reasoning-oriented image generation.", "conclusion": "The authors release their dataset, benchmarks, and code to drive advancements in reasoning-focused T2I generation for the broader research community."}}
{"id": "2509.09375", "pdf": "https://arxiv.org/pdf/2509.09375", "abs": "https://arxiv.org/abs/2509.09375", "authors": ["Botong Zhao", "Qijun Shi", "Shujing Lyu", "Yue Lu"], "title": "Unsupervised Integrated-Circuit Defect Segmentation via Image-Intrinsic Normality", "categories": ["cs.CV"], "comment": null, "summary": "Modern Integrated-Circuit(IC) manufacturing introduces diverse, fine-grained\ndefects that depress yield and reliability. Most industrial defect segmentation\ncompares a test image against an external normal set, a strategy that is\nbrittle for IC imagery where layouts vary across products and accurate\nalignment is difficult. We observe that defects are predominantly local, while\neach image still contains rich, repeatable normal patterns. We therefore\npropose an unsupervised IC defect segmentation framework that requires no\nexternal normal support. A learnable normal-information extractor aggregates\nrepresentative normal features from the test image, and a coherence loss\nenforces their association with normal regions. Guided by these features, a\ndecoder reconstructs only normal content; the reconstruction residual then\nsegments defects. Pseudo-anomaly augmentation further stabilizes training.\nExperiments on datasets from three IC process stages show consistent\nimprovements over existing approaches and strong robustness to product\nvariability.", "AI": {"tldr": "The paper proposes an unsupervised IC defect segmentation framework that uses features from the test image itself, overcoming limitations caused by layout variability and alignment issues in traditional methods.", "motivation": "Current defect segmentation methods struggle with IC imagery due to variability in layouts across products and challenges in achieving accurate alignment.", "method": "The framework uses a learnable normal-information extractor, coherence loss to associate features with normal regions, and a decoder for reconstructing normal content. Defects are identified from the residuals. Pseudo-anomaly augmentation enhances training stability.", "result": "Experiments show the proposed method consistently improves defect segmentation accuracy across three IC process stages and demonstrates strong robustness to product variability.", "conclusion": "The unsupervised approach successfully segments IC defects without relying on external normal data, enhancing performance and adaptability to diverse product layouts."}}
{"id": "2509.09397", "pdf": "https://arxiv.org/pdf/2509.09397", "abs": "https://arxiv.org/abs/2509.09397", "authors": ["Umaima Rahman", "Raza Imam", "Mohammad Yaqub", "Dwarikanath Mahapatra"], "title": "Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift", "categories": ["cs.CV"], "comment": null, "summary": "Medical vision-language models (VLMs) offer promise for clinical decision\nsupport, yet their reliability under distribution shifts remains a major\nconcern for safe deployment. These models often learn task-agnostic\ncorrelations due to variability in imaging protocols and free-text reports,\nlimiting their generalizability and increasing the risk of failure in\nreal-world settings. We propose DRiFt, a structured feature decoupling\nframework that explicitly separates clinically relevant signals from\ntask-agnostic noise using parameter-efficient tuning (LoRA) and learnable\nprompt tokens. To enhance cross-modal alignment and reduce uncertainty, we\ncurate high-quality, clinically grounded image-text pairs by generating\ncaptions for a diverse medical dataset. Our approach improves in-distribution\nperformance by +11.4% Top-1 accuracy and +3.3% Macro-F1 over prior prompt-based\nmethods, while maintaining strong robustness across unseen datasets. Ablation\nstudies reveal that disentangling task-relevant features and careful alignment\nsignificantly enhance model generalization and reduce unpredictable behavior\nunder domain shift. These insights contribute toward building safer, more\ntrustworthy VLMs for clinical use. The code is available at\nhttps://github.com/rumaima/DRiFt.", "AI": {"tldr": "This paper introduces DRiFt, a framework to improve the generalizability and reliability of medical vision-language models (VLMs) by separating clinical signals from noise and enhancing feature alignment.", "motivation": "The motivation is to address the challenges of variance and distribution shifts in medical VLMs that lead to unreliable performance and generalization in real-world clinical settings.", "method": "The authors propose DRiFt, which uses parameter-efficient tuning (LoRA) and learnable prompt tokens to disentangle clinical signals from noise. Additionally, high-quality image-text pairs are curated for improved cross-modal alignment.", "result": "DRiFt achieves a +11.4% Top-1 accuracy and +3.3% Macro-F1 improvement compared to prior methods, demonstrating robust performance even on unseen datasets.", "conclusion": "Disentangling task-relevant features and carefully aligning data significantly enhance the safety and trustworthiness of VLMs in clinical applications."}}
{"id": "2509.08858", "pdf": "https://arxiv.org/pdf/2509.08858", "abs": "https://arxiv.org/abs/2509.08858", "authors": ["Oriane Peter", "Kate Devlin"], "title": "Decentralising LLM Alignment: A Case for Context, Pluralism, and Participation", "categories": ["cs.CY", "cs.LG"], "comment": "Accepted at AIES 2025", "summary": "Large Language Models (LLMs) alignment methods have been credited with the\ncommercial success of products like ChatGPT, given their role in steering LLMs\ntowards user-friendly outputs. However, current alignment techniques\npredominantly mirror the normative preferences of a narrow reference group,\neffectively imposing their values on a wide user base. Drawing on theories of\nthe power/knowledge nexus, this work argues that current alignment practices\ncentralise control over knowledge production and governance within already\ninfluential institutions. To counter this, we propose decentralising alignment\nthrough three characteristics: context, pluralism, and participation.\nFurthermore, this paper demonstrates the critical importance of delineating the\ncontext-of-use when shaping alignment practices by grounding each of these\nfeatures in concrete use cases. This work makes the following contributions:\n(1) highlighting the role of context, pluralism, and participation in\ndecentralising alignment; (2) providing concrete examples to illustrate these\nstrategies; and (3) demonstrating the nuanced requirements associated with\napplying alignment across different contexts of use. Ultimately, this paper\npositions LLM alignment as a potential site of resistance against epistemic\ninjustice and the erosion of democratic processes, while acknowledging that\nthese strategies alone cannot substitute for broader societal changes.", "AI": {"tldr": "The paper critiques current LLM alignment methods for centralizing control in specific institutions and advocates for decentralized alignment through context, pluralism, and participation.", "motivation": "Current LLM alignment methods impose the values of a narrow reference group, raising concerns about epistemic centralization and power dynamics.", "method": "The authors propose decentralizing alignment by focusing on three pillars: context, pluralism, and participation, supported by real-world use cases.", "result": "The study highlights the importance of contextualizing alignment practices and how pluralistic and participatory approaches can lead to fairer knowledge governance.", "conclusion": "While decentralizing alignment may counter epistemic injustice, it is insufficient on its own without broader societal reforms."}}
{"id": "2509.09427", "pdf": "https://arxiv.org/pdf/2509.09427", "abs": "https://arxiv.org/abs/2509.09427", "authors": ["Yuchan Jie", "Yushen Xu", "Xiaosong Li", "Fuqiang Zhou", "Jianming Lv", "Huafeng Li"], "title": "FS-Diff: Semantic guidance and clarity-aware simultaneous multimodal image fusion and super-resolution", "categories": ["cs.CV"], "comment": null, "summary": "As an influential information fusion and low-level vision technique, image\nfusion integrates complementary information from source images to yield an\ninformative fused image. A few attempts have been made in recent years to\njointly realize image fusion and super-resolution. However, in real-world\napplications such as military reconnaissance and long-range detection missions,\nthe target and background structures in multimodal images are easily corrupted,\nwith low resolution and weak semantic information, which leads to suboptimal\nresults in current fusion techniques. In response, we propose FS-Diff, a\nsemantic guidance and clarity-aware joint image fusion and super-resolution\nmethod. FS-Diff unifies image fusion and super-resolution as a conditional\ngeneration problem. It leverages semantic guidance from the proposed clarity\nsensing mechanism for adaptive low-resolution perception and cross-modal\nfeature extraction. Specifically, we initialize the desired fused result as\npure Gaussian noise and introduce the bidirectional feature Mamba to extract\nthe global features of the multimodal images. Moreover, utilizing the source\nimages and semantics as conditions, we implement a random iterative denoising\nprocess via a modified U-Net network. This network istrained for denoising at\nmultiple noise levels to produce high-resolution fusion results with\ncross-modal features and abundant semantic information. We also construct a\npowerful aerial view multiscene (AVMS) benchmark covering 600 pairs of images.\nExtensive joint image fusion and super-resolution experiments on six public and\nour AVMS datasets demonstrated that FS-Diff outperforms the state-of-the-art\nmethods at multiple magnifications and can recover richer details and semantics\nin the fused images. The code is available at\nhttps://github.com/XylonXu01/FS-Diff.", "AI": {"tldr": "The paper proposes FS-Diff, a technique uniting image fusion and super-resolution for multimodal images, particularly for low-resolution and weak information scenarios. It introduces a clarity sensing mechanism and combines global feature extraction via Mamba with a U-Net-based denoising process to achieve high-quality results.", "motivation": "Current image fusion techniques fail to handle low-resolution, weak semantic information, and structure-corrupted multimodal images effectively, particularly in scenarios like military reconnaissance.", "method": "The method, FS-Diff, models the task as a conditional generation problem. It employs a clarity sensing mechanism, the bidirectional feature Mamba for global feature extraction, and a modified U-Net for iterative denoising to produce high-resolution fused results. The approach works across varying noise levels to ensure clarity and semantic richness.", "result": "FS-Diff exhibits superior performance over six public and the newly developed AVMS dataset. It produces more detailed and semantically rich fused images at various magnifications compared to state-of-the-art methods.", "conclusion": "FS-Diff effectively addresses challenges in multimodal image fusion and super-resolution, leveraging its novel mechanisms to unify and enhance results. The approach paves the way for more adaptive and information-rich fusion techniques."}}
{"id": "2509.08872", "pdf": "https://arxiv.org/pdf/2509.08872", "abs": "https://arxiv.org/abs/2509.08872", "authors": ["Felipe \u00c1lvarez Barrientos", "Tom\u00e1s Banduc", "Isabeau Sirven", "Francisco Sahli Costabal"], "title": "WarpPINN-fibers: improved cardiac strain estimation from cine-MR with physics-informed neural networks", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": null, "summary": "The contractile motion of the heart is strongly determined by the\ndistribution of the fibers that constitute cardiac tissue. Strain analysis\ninformed with the orientation of fibers allows to describe several pathologies\nthat are typically associated with impaired mechanics of the myocardium, such\nas cardiovascular disease. Several methods have been developed to estimate\nstrain-derived metrics from traditional imaging techniques. However, the\nphysical models underlying these methods do not include fiber mechanics,\nrestricting their capacity to accurately explain cardiac function. In this\nwork, we introduce WarpPINN-fibers, a physics-informed neural network framework\nto accurately obtain cardiac motion and strains enhanced by fiber information.\nWe train our neural network to satisfy a hyper-elastic model and promote fiber\ncontraction with the goal to predict the deformation field of the heart from\ncine magnetic resonance images. For this purpose, we build a loss function\ncomposed of three terms: a data-similarity loss between the reference and the\nwarped template images, a regularizer enforcing near-incompressibility of\ncardiac tissue and a fiber-stretch penalization that controls strain in the\ndirection of synthetically produced fibers. We show that our neural network\nimproves the former WarpPINN model and effectively controls fiber stretch in a\nsynthetic phantom experiment. Then, we demonstrate that WarpPINN-fibers\noutperforms alternative methodologies in landmark-tracking and strain curve\nprediction for a cine-MRI benchmark with a cohort of 15 healthy volunteers. We\nexpect that our method will enable a more precise quantification of cardiac\nstrains through accurate deformation fields that are consistent with fiber\nphysiology, without requiring imaging techniques more sophisticated than MRI.", "AI": {"tldr": "The paper introduces WarpPINN-fibers, a neural network model integrating cardiac fiber information to enhance strain analysis from MRI images.", "motivation": "Current methods for cardiac strain analysis fail to incorporate fiber mechanics, limiting their ability to accurately describe heart function and related pathologies.", "method": "The authors developed WarpPINN-fibers, combining a physics-informed neural network framework trained using a hyper-elastic model, cine MRI images, and a loss function promoting fiber contraction.", "result": "WarpPINN-fibers improved upon previous WarpPINN models, successfully controlled fiber stretch in synthetic tests, and outperformed other methods in real MRI dataset evaluations.", "conclusion": "WarpPINN-fibers offers a promising tool for precise cardiac strain quantification that aligns with fiber physiology, using accessible MRI imaging techniques."}}
{"id": "2509.09429", "pdf": "https://arxiv.org/pdf/2509.09429", "abs": "https://arxiv.org/abs/2509.09429", "authors": ["Peisong Wen", "Qianqian Xu", "Siran Dai", "Runmin Cong", "Qingming Huang"], "title": "Semantic Concentration for Self-Supervised Dense Representations Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent advances in image-level self-supervised learning (SSL) have made\nsignificant progress, yet learning dense representations for patches remains\nchallenging. Mainstream methods encounter an over-dispersion phenomenon that\npatches from the same instance/category scatter, harming downstream performance\non dense tasks. This work reveals that image-level SSL avoids over-dispersion\nby involving implicit semantic concentration. Specifically, the non-strict\nspatial alignment ensures intra-instance consistency, while shared patterns,\ni.e., similar parts of within-class instances in the input space, ensure\ninter-image consistency. Unfortunately, these approaches are infeasible for\ndense SSL due to their spatial sensitivity and complicated scene-centric data.\nThese observations motivate us to explore explicit semantic concentration for\ndense SSL. First, to break the strict spatial alignment, we propose to distill\nthe patch correspondences. Facing noisy and imbalanced pseudo labels, we\npropose a noise-tolerant ranking loss. The core idea is extending the Average\nPrecision (AP) loss to continuous targets, such that its decision-agnostic and\nadaptive focusing properties prevent the student model from being misled.\nSecond, to discriminate the shared patterns from complicated scenes, we propose\nthe object-aware filter to map the output space to an object-based space.\nSpecifically, patches are represented by learnable prototypes of objects via\ncross-attention. Last but not least, empirical studies across various tasks\nsoundly support the effectiveness of our method. Code is available in\nhttps://github.com/KID-7391/CoTAP.", "AI": {"tldr": "This paper tackles the challenge of learning dense representations for patches in SSL by addressing over-dispersion and introducing methods such as patch correspondence distillation, ranking loss, and object-aware filtering.", "motivation": "There is a need to overcome the challenge of over-dispersion when learning dense representations for patches in SSL because it limits performance in downstream dense tasks.", "method": "The paper proposes distilling patch correspondences to break strict spatial alignment using a noise-tolerant ranking loss and introduces an object-aware filter to project patches into an object-based space.", "result": "Empirical studies demonstrate the effectiveness of the proposed methods across multiple tasks, yielding improvements in dense SSL performance.", "conclusion": "Explicit semantic concentration strategies, including the proposed noise-tolerant ranking loss and object-aware filtering, successfully tackle patch representation challenges in dense SSL, offering improved performance in downstream tasks."}}
{"id": "2509.09456", "pdf": "https://arxiv.org/pdf/2509.09456", "abs": "https://arxiv.org/abs/2509.09456", "authors": ["Yushen Xu", "Xiaosong Li", "Yuchun Wang", "Xiaoqi Cheng", "Huafeng Li", "Haishu Tan"], "title": "FlexiD-Fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model", "categories": ["cs.CV"], "comment": null, "summary": "Different modalities of medical images provide unique physiological and\nanatomical information for diseases. Multi-modal medical image fusion\nintegrates useful information from different complementary medical images with\ndifferent modalities, producing a fused image that comprehensively and\nobjectively reflects lesion characteristics to assist doctors in clinical\ndiagnosis. However, existing fusion methods can only handle a fixed number of\nmodality inputs, such as accepting only two-modal or tri-modal inputs, and\ncannot directly process varying input quantities, which hinders their\napplication in clinical settings. To tackle this issue, we introduce\nFlexiD-Fuse, a diffusion-based image fusion network designed to accommodate\nflexible quantities of input modalities. It can end-to-end process two-modal\nand tri-modal medical image fusion under the same weight. FlexiD-Fuse\ntransforms the diffusion fusion problem, which supports only fixed-condition\ninputs, into a maximum likelihood estimation problem based on the diffusion\nprocess and hierarchical Bayesian modeling. By incorporating the\nExpectation-Maximization algorithm into the diffusion sampling iteration\nprocess, FlexiD-Fuse can generate high-quality fused images with cross-modal\ninformation from source images, independently of the number of input images. We\ncompared the latest two and tri-modal medical image fusion methods, tested them\non Harvard datasets, and evaluated them using nine popular metrics. The\nexperimental results show that our method achieves the best performance in\nmedical image fusion with varying inputs. Meanwhile, we conducted extensive\nextension experiments on infrared-visible, multi-exposure, and multi-focus\nimage fusion tasks with arbitrary numbers, and compared them with the\nperspective SOTA methods. The results of the extension experiments consistently\ndemonstrate the effectiveness and superiority of our method.", "AI": {"tldr": "This paper presents FlexiD-Fuse, a novel diffusion-based method for fusing medical images from multiple modalities, accommodating flexible input quantities while producing high-quality fused outputs.", "motivation": "Current medical image fusion methods are limited to fixed numbers of input modalities, which restricts their usability in diverse clinical scenarios where input quantities vary.", "method": "The authors propose FlexiD-Fuse, a diffusion-based network using hierarchical Bayesian modeling and the EM algorithm. This approach allows for end-to-end fusion of both two-modal and tri-modal medical images under the same framework while supporting flexible modality inputs.", "result": "FlexiD-Fuse outperforms state-of-the-art methods in both two-modal and tri-modal medical image fusion tasks and demonstrates superior adaptability in non-medical scenarios like infrared-visible and multi-focus fusion tasks.", "conclusion": "FlexiD-Fuse successfully handles varying quantities of input modalities, making it more versatile and effective for clinical diagnosis and beyond, as proven by extensive experiments and comparative analyses."}}
{"id": "2509.08950", "pdf": "https://arxiv.org/pdf/2509.08950", "abs": "https://arxiv.org/abs/2509.08950", "authors": ["Jarvis Haupt", "Qin Lu", "Yanning Shen", "Jia Chen", "Yue Dong", "Dan McCreary", "Mehmet Ak\u00e7akaya", "Georgios B. Giannakis"], "title": "Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted to the IEEE Signal Processing Magazine Special Issue on\n  Artificial Intelligence for Education: A Signal Processing Perspective", "summary": "Powerful artificial intelligence (AI) tools that have emerged in recent years\n-- including large language models, automated coding assistants, and advanced\nimage and speech generation technologies -- are the result of monumental human\nachievements. These breakthroughs reflect mastery across multiple technical\ndisciplines and the resolution of significant technological challenges.\nHowever, some of the most profound challenges may still lie ahead. These\nchallenges are not purely technical but pertain to the fair and responsible use\nof AI in ways that genuinely improve the global human condition. This article\nexplores one promising application aligned with that vision: the use of AI\ntools to facilitate and enhance education, with a specific focus on signal\nprocessing (SP). It presents two interrelated perspectives: identifying and\naddressing technical limitations, and applying AI tools in practice to improve\neducational experiences. Primers are provided on several core technical issues\nthat arise when using AI in educational settings, including how to ensure\nfairness and inclusivity, handle hallucinated outputs, and achieve efficient\nuse of resources. These and other considerations -- such as transparency,\nexplainability, and trustworthiness -- are illustrated through the development\nof an immersive, structured, and reliable \"smart textbook.\" The article serves\nas a resource for researchers and educators seeking to advance AI's role in\nengineering education.", "AI": {"tldr": "This paper explores how AI tools can enhance education, focusing on signal processing via a smart textbook with considerations for fairness, inclusivity, and trust.", "motivation": "To address both the technical and ethical challenges associated with using AI tools in education, aiming to improve the global human condition.", "method": "The authors investigate AI's application in education by tackling technical issues and creating a smart textbook for immersive learning experiences.", "result": "Key considerations like fairness, inclusivity, and resource efficiency are highlighted through the smart textbook's development and its implementation examples.", "conclusion": "AI has the potential to transform education if used responsibly, factoring in challenges like hallucinations, inclusivity, and transparency for better learning outcomes."}}
{"id": "2509.09469", "pdf": "https://arxiv.org/pdf/2509.09469", "abs": "https://arxiv.org/abs/2509.09469", "authors": ["Freedmore Sidume", "Oumayma Soula", "Joseph Muthui Wacira", "YunFei Zhu", "Abbas Rabiu Muhammad", "Abderrazek Zeraii", "Oluwaseun Kalejaye", "Hajer Ibrahim", "Olfa Gaddour", "Brain Halubanza", "Dong Zhang", "Udunna C Anazodo", "Confidence Raymond"], "title": "Resource-Efficient Glioma Segmentation on Sub-Saharan MRI", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 7 figures", "summary": "Gliomas are the most prevalent type of primary brain tumors, and their\naccurate segmentation from MRI is critical for diagnosis, treatment planning,\nand longitudinal monitoring. However, the scarcity of high-quality annotated\nimaging data in Sub-Saharan Africa (SSA) poses a significant challenge for\ndeploying advanced segmentation models in clinical workflows. This study\nintroduces a robust and computationally efficient deep learning framework\ntailored for resource-constrained settings. We leveraged a 3D Attention UNet\narchitecture augmented with residual blocks and enhanced through transfer\nlearning from pre-trained weights on the BraTS 2021 dataset. Our model was\nevaluated on 95 MRI cases from the BraTS-Africa dataset, a benchmark for glioma\nsegmentation in SSA MRI data. Despite the limited data quality and quantity,\nour approach achieved Dice scores of 0.76 for the Enhancing Tumor (ET), 0.80\nfor Necrotic and Non-Enhancing Tumor Core (NETC), and 0.85 for Surrounding\nNon-Functional Hemisphere (SNFH). These results demonstrate the\ngeneralizability of the proposed model and its potential to support clinical\ndecision making in low-resource settings. The compact architecture,\napproximately 90 MB, and sub-minute per-volume inference time on consumer-grade\nhardware further underscore its practicality for deployment in SSA health\nsystems. This work contributes toward closing the gap in equitable AI for\nglobal health by empowering underserved regions with high-performing and\naccessible medical imaging solutions.", "AI": {"tldr": "The paper proposes a lightweight deep learning framework for glioma segmentation in MRI, showcasing strong results despite limited data in Sub-Saharan Africa.", "motivation": "The paper addresses the need for accurate glioma segmentation in Sub-Saharan Africa, where high-quality annotated imaging data is scarce, to improve diagnosis and treatment planning.", "method": "The study developed a 3D Attention UNet with residual blocks, utilizing transfer learning from BraTS 2021 pre-trained weights and tested it on the BraTS-Africa dataset.", "result": "The model achieved impressive Dice scores: 0.76 for Enhancing Tumor, 0.80 for Necrotic and Non-Enhancing Tumor Core, and 0.85 for Surrounding Non-Functional Hemisphere.", "conclusion": "The proposed model is effective, practical for low-resource healthcare systems, and advances equitable AI solutions for global health challenges."}}
{"id": "2509.08954", "pdf": "https://arxiv.org/pdf/2509.08954", "abs": "https://arxiv.org/abs/2509.08954", "authors": ["Le Duc Hieu"], "title": "Convexity of Optimization Curves: Local Sharp Thresholds, Robustness Impossibility, and New Counterexamples", "categories": ["math.OC", "cs.LG", "90C25, 90C30, 65K05, 37N40, 26B25"], "comment": null, "summary": "We study when the \\emph{optimization curve} of first-order methods -- the\nsequence \\${f(x\\_n)}*{n\\ge0}\\$ produced by constant-stepsize iterations -- is\nconvex, equivalently when the forward differences \\$f(x\\_n)-f(x*{n+1})\\$ are\nnonincreasing. For gradient descent (GD) on convex \\$L\\$-smooth functions, the\ncurve is convex for all stepsizes \\$\\eta \\le 1.75/L\\$, and this threshold is\ntight. Moreover, gradient norms are nonincreasing for all \\$\\eta \\le 2/L\\$, and\nin continuous time (gradient flow) the curve is always convex. These results\ncomplement and refine the classical smooth convex optimization toolbox,\nconnecting discrete and continuous dynamics as well as worst-case analyses.", "AI": {"tldr": "The paper investigates the conditions under which the optimization sequence of first-order methods, specifically gradient descent, exhibits convex behavior and determines precise stepsize thresholds for such convexity.", "motivation": "The paper aims to deepen understanding of the behavior of optimization sequences in first-order methods, particularly in connecting convexity characteristics with step size choices.", "method": "The authors analyze the optimization curve of gradient descent on convex L-smooth functions using both discrete and continuous dynamics. They establish thresholds on the step size for convexity and nonincreasing gradient behavior.", "result": "It is shown that for gradient descent with step size \\( \\eta \\leq 1.75/L \\), the optimization curve is convex, and this threshold is tight. Gradient norms are nonincreasing for \\( \\eta \\leq 2/L \\), and convexity is guaranteed in continuous dynamics.", "conclusion": "The findings provide sharper insights into step size choices and their effects on the dynamics of optimization, enhancing the classical convex optimization framework and connecting discrete and continuous perspectives."}}
{"id": "2509.09495", "pdf": "https://arxiv.org/pdf/2509.09495", "abs": "https://arxiv.org/abs/2509.09495", "authors": ["Victor Livernoche", "Akshatha Arodi", "Andreea Musulan", "Zachary Yang", "Adam Salvail", "Ga\u00e9tan Marceau Caron", "Jean-Fran\u00e7ois Godbout", "Reihaneh Rabbany"], "title": "OpenFake: An Open Dataset and Platform Toward Large-Scale Deepfake Detection", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.4.9; I.5.4; I.2.10"], "comment": "25 pages, 12 figures", "summary": "Deepfakes, synthetic media created using advanced AI techniques, have\nintensified the spread of misinformation, particularly in politically sensitive\ncontexts. Existing deepfake detection datasets are often limited, relying on\noutdated generation methods, low realism, or single-face imagery, restricting\nthe effectiveness for general synthetic image detection. By analyzing social\nmedia posts, we identify multiple modalities through which deepfakes propagate\nmisinformation. Furthermore, our human perception study demonstrates that\nrecently developed proprietary models produce synthetic images increasingly\nindistinguishable from real ones, complicating accurate identification by the\ngeneral public. Consequently, we present a comprehensive, politically-focused\ndataset specifically crafted for benchmarking detection against modern\ngenerative models. This dataset contains three million real images paired with\ndescriptive captions, which are used for generating 963k corresponding\nhigh-quality synthetic images from a mix of proprietary and open-source models.\nRecognizing the continual evolution of generative techniques, we introduce an\ninnovative crowdsourced adversarial platform, where participants are\nincentivized to generate and submit challenging synthetic images. This ongoing\ncommunity-driven initiative ensures that deepfake detection methods remain\nrobust and adaptive, proactively safeguarding public discourse from\nsophisticated misinformation threats.", "AI": {"tldr": "The paper addresses limitations of existing deepfake detection datasets and introduces a politically-focused dataset of real and synthetic images, alongside a crowdsourced adversarial platform to improve deepfake detection methods.", "motivation": "Deepfakes are increasingly difficult to detect and are used to spread misinformation, particularly in political contexts, posing significant risks to public discourse.", "method": "The authors created a dataset of three million real images with captions and nearly one million high-quality synthetic images generated by proprietary and open-source models. They also developed a crowdsourced adversarial platform incentivizing users to produce challenging synthetic images.", "result": "The study provided a benchmark dataset for modern generative models, demonstrated the indistinguishability of synthetic images through a human perception study, and proposed a scalable framework to adapt to advancing deepfake generation techniques.", "conclusion": "The paper highlights the importance of continuously updated datasets and adaptive detection methods to counteract deepfake-related misinformation effectively, safeguarding the integrity of public discussions."}}
{"id": "2509.08967", "pdf": "https://arxiv.org/pdf/2509.08967", "abs": "https://arxiv.org/abs/2509.08967", "authors": ["Xinquan Huang", "Fu Wang", "Tariq Alkhalifah"], "title": "Physics-informed waveform inversion using pretrained wavefield neural operators", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Full waveform inversion (FWI) is crucial for reconstructing high-resolution\nsubsurface models, but it is often hindered, considering the limited data, by\nits null space resulting in low-resolution models, and more importantly, by its\ncomputational cost, especially if needed for real-time applications. Recent\nattempts to accelerate FWI using learned wavefield neural operators have shown\npromise in efficiency and differentiability, but typically suffer from noisy\nand unstable inversion performance. To address these limitations, we introduce\na novel physics-informed FWI framework to enhance the inversion in accuracy\nwhile maintaining the efficiency of neural operator-based FWI. Instead of\nrelying only on the L2 norm objective function via automatic differentiation,\nresulting in noisy model reconstruction, we integrate a physics constraint term\nin the loss function of FWI, improving the quality of the inverted velocity\nmodels. Specifically, starting with an initial model to simulate wavefields and\nthen evaluating the loss over how much the resulting wavefield obeys the\nphysical laws (wave equation) and matches the recorded data, we achieve a\nreduction in noise and artifacts. Numerical experiments using the OpenFWI and\nOverthrust models demonstrate our method's superior performance, offering\ncleaner and more accurate subsurface velocity than vanilla approaches.\nConsidering the efficiency of the approach compared to FWI, this advancement\nrepresents a significant step forward in the practical application of FWI for\nreal-time subsurface monitoring.", "AI": {"tldr": "The paper introduces a physics-informed framework for Full Waveform Inversion (FWI) that enhances accuracy and efficiency using neural operators and physics constraints.", "motivation": "The motivation is to overcome the limitations of traditional FWI methods, such as high computational costs and noisy reconstructions, while maintaining or improving model accuracy and efficiency.", "method": "The authors propose integrating a physics constraint into the loss function of neural operator-based FWI to reduce noise and enhance model accuracy, replacing reliance solely on the L2 norm objective function.", "result": "Numerical experiments on benchmark datasets, such as OpenFWI and Overthrust models, show that the new method achieves cleaner and more accurate subsurface velocity reconstructions than conventional FWI methods.", "conclusion": "This physics-informed FWI framework offers a significant improvement in both accuracy and computational efficiency, making it a viable approach for real-time subsurface monitoring."}}
{"id": "2509.09496", "pdf": "https://arxiv.org/pdf/2509.09496", "abs": "https://arxiv.org/abs/2509.09496", "authors": ["Ha Linh Nguyen", "Tze Ho Elden Tse", "Angela Yao"], "title": "Improving Human Motion Plausibility with Body Momentum", "categories": ["cs.CV"], "comment": "Accepted at BMVC 2025", "summary": "Many studies decompose human motion into local motion in a frame attached to\nthe root joint and global motion of the root joint in the world frame, treating\nthem separately. However, these two components are not independent. Global\nmovement arises from interactions with the environment, which are, in turn,\ndriven by changes in the body configuration. Motion models often fail to\nprecisely capture this physical coupling between local and global dynamics,\nwhile deriving global trajectories from joint torques and external forces is\ncomputationally expensive and complex. To address these challenges, we propose\nusing whole-body linear and angular momentum as a constraint to link local\nmotion with global movement. Since momentum reflects the aggregate effect of\njoint-level dynamics on the body's movement through space, it provides a\nphysically grounded way to relate local joint behavior to global displacement.\nBuilding on this insight, we introduce a new loss term that enforces\nconsistency between the generated momentum profiles and those observed in\nground-truth data. Incorporating our loss reduces foot sliding and jitter,\nimproves balance, and preserves the accuracy of the recovered motion. Code and\ndata are available at the project page https://hlinhn.github.io/momentum_bmvc.", "AI": {"tldr": "The paper presents a method to address the physical coupling between local and global motion by leveraging whole-body momentum as a constraint.", "motivation": "Current motion models often fail to capture the physical coupling between a body's local and global movements, and deriving global motion computationally is complex.", "method": "The authors propose using whole-body linear and angular momentum as a constraint, introducing a new loss term that ensures consistency between generated momentum profiles and ground-truth data.", "result": "The proposed method reduces foot sliding and jitter, enhances balance, and maintains accuracy in recovered motion.", "conclusion": "Using momentum as a constraint effectively links local and global motion, offering a physically meaningful way to improve motion models."}}
{"id": "2509.09501", "pdf": "https://arxiv.org/pdf/2509.09501", "abs": "https://arxiv.org/abs/2509.09501", "authors": ["Yingxuan Li", "Jiafeng Mao", "Qianru Qiu", "Yusuke Matsui"], "title": "Region-Wise Correspondence Prediction between Manga Line Art Images", "categories": ["cs.CV"], "comment": null, "summary": "Understanding region-wise correspondence between manga line art images is a\nfundamental task in manga processing, enabling downstream applications such as\nautomatic line art colorization and in-between frame generation. However, this\ntask remains largely unexplored, especially in realistic scenarios without\npre-existing segmentation or annotations. In this paper, we introduce a novel\nand practical task: predicting region-wise correspondence between raw manga\nline art images without any pre-existing labels or masks. To tackle this\nproblem, we divide each line art image into a set of patches and propose a\nTransformer-based framework that learns patch-level similarities within and\nacross images. We then apply edge-aware clustering and a region matching\nalgorithm to convert patch-level predictions into coherent region-level\ncorrespondences. To support training and evaluation, we develop an automatic\nannotation pipeline and manually refine a subset of the data to construct\nbenchmark datasets. Experiments on multiple datasets demonstrate that our\nmethod achieves high patch-level accuracy (e.g., 96.34%) and generates\nconsistent region-level correspondences, highlighting its potential for\nreal-world manga applications.", "AI": {"tldr": "This paper proposes a Transformer-based method to identify region-wise correspondence in manga line art images without segmentation or annotations.", "motivation": "To address the unexplored challenge of identifying region-wise correspondence in manga line art images, enabling applications like colorization and frame generation.", "method": "A Transformer-based framework is proposed to analyze patch-level similarities in manga line art images, complemented by edge-aware clustering and region matching.", "result": "The method achieves 96.34% patch-level accuracy and generates consistent region-level correspondences.", "conclusion": "The approach is effective and holds promise for real-world applications in manga processing."}}
{"id": "2509.09527", "pdf": "https://arxiv.org/pdf/2509.09527", "abs": "https://arxiv.org/abs/2509.09527", "authors": ["Jian Zhu", "Xin Zou", "Xi Wang", "Ning Zhang", "Bian Wu", "Yao Yang", "Ying Zhou", "Lingfang Zeng", "Chang Tang", "Cheng Luo"], "title": "Generative Diffusion Contrastive Network for Multi-View Clustering", "categories": ["cs.CV"], "comment": "This paper is submitted to International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP2026)", "summary": "In recent years, Multi-View Clustering (MVC) has been significantly advanced\nunder the influence of deep learning. By integrating heterogeneous data from\nmultiple views, MVC enhances clustering analysis, making multi-view fusion\ncritical to clustering performance. However, there is a problem of low-quality\ndata in multi-view fusion. This problem primarily arises from two reasons: 1)\nCertain views are contaminated by noisy data. 2) Some views suffer from missing\ndata. This paper proposes a novel Stochastic Generative Diffusion Fusion (SGDF)\nmethod to address this problem. SGDF leverages a multiple generative mechanism\nfor the multi-view feature of each sample. It is robust to low-quality data.\nBuilding on SGDF, we further present the Generative Diffusion Contrastive\nNetwork (GDCN). Extensive experiments show that GDCN achieves the\nstate-of-the-art results in deep MVC tasks. The source code is publicly\navailable at https://github.com/HackerHyper/GDCN.", "AI": {"tldr": "The paper introduces the Stochastic Generative Diffusion Fusion (SGDF) method to address low-quality data in Multi-View Clustering and extends it to the Generative Diffusion Contrastive Network (GDCN), achieving state-of-the-art results.", "motivation": "To improve clustering analysis in the presence of noisy and missing data in multiple views, which hampers the performance of multi-view fusion in deep learning-based Multi-View Clustering.", "method": "The paper proposes the SGDF method, which uses multiple generative mechanisms to handle multi-view features in clustering, making it robust to low-quality data. GDCN is then built upon SGDF for further improvements.", "result": "GDCN demonstrates state-of-the-art results in multi-view clustering tasks, validated by extensive experiments.", "conclusion": "The proposed methods (SGDF and GDCN) effectively enhance clustering performance and robustness in multi-view data scenarios, offering advancements in deep Multi-View Clustering."}}
{"id": "2509.09033", "pdf": "https://arxiv.org/pdf/2509.09033", "abs": "https://arxiv.org/abs/2509.09033", "authors": ["Hsin-Yuan Huang", "Michael Broughton", "Norhan Eassa", "Hartmut Neven", "Ryan Babbush", "Jarrod R. McClean"], "title": "Generative quantum advantage for classical and quantum problems", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Recent breakthroughs in generative machine learning, powered by massive\ncomputational resources, have demonstrated unprecedented human-like\ncapabilities. While beyond-classical quantum experiments can generate samples\nfrom classically intractable distributions, their complexity has thwarted all\nefforts toward efficient learning. This challenge has hindered demonstrations\nof generative quantum advantage: the ability of quantum computers to learn and\ngenerate desired outputs substantially better than classical computers. We\nresolve this challenge by introducing families of generative quantum models\nthat are hard to simulate classically, are efficiently trainable, exhibit no\nbarren plateaus or proliferating local minima, and can learn to generate\ndistributions beyond the reach of classical computers. Using a $68$-qubit\nsuperconducting quantum processor, we demonstrate these capabilities in two\nscenarios: learning classically intractable probability distributions and\nlearning quantum circuits for accelerated physical simulation. Our results\nestablish that both learning and sampling can be performed efficiently in the\nbeyond-classical regime, opening new possibilities for quantum-enhanced\ngenerative models with provable advantage.", "AI": {"tldr": "This paper introduces a generative quantum model that shows substantial advantages over classical systems, validated on a 68-qubit quantum processor.", "motivation": "To overcome challenges in demonstrating generative quantum advantage due to complexity in efficient learning and simulation.", "method": "The paper presents a family of generative quantum models that are classically hard to simulate, efficiently trainable, and free from barren plateaus or local minima issues. Validation was done using a 68-qubit superconducting quantum processor.", "result": "The proposed models successfully learned classically intractable probability distributions and quantum circuits for enhanced physical simulations, demonstrating quantum advantages.", "conclusion": "The study establishes practical and theoretical advances in generative quantum models, proving efficient learning and sampling in the beyond-classical regime and providing future opportunities for quantum-enhanced systems."}}
{"id": "2509.09530", "pdf": "https://arxiv.org/pdf/2509.09530", "abs": "https://arxiv.org/abs/2509.09530", "authors": ["Paul F. R. Wilson", "Matteo Ronchetti", "R\u00fcdiger G\u00f6bl", "Viktoria Markova", "Sebastian Rosenzweig", "Raphael Prevost", "Parvin Mousavi", "Oliver Zettinig"], "title": "DualTrack: Sensorless 3D Ultrasound needs Local and Global Context", "categories": ["cs.CV"], "comment": null, "summary": "Three-dimensional ultrasound (US) offers many clinical advantages over\nconventional 2D imaging, yet its widespread adoption is limited by the cost and\ncomplexity of traditional 3D systems. Sensorless 3D US, which uses deep\nlearning to estimate a 3D probe trajectory from a sequence of 2D US images, is\na promising alternative. Local features, such as speckle patterns, can help\npredict frame-to-frame motion, while global features, such as coarse shapes and\nanatomical structures, can situate the scan relative to anatomy and help\npredict its general shape. In prior approaches, global features are either\nignored or tightly coupled with local feature extraction, restricting the\nability to robustly model these two complementary aspects. We propose\nDualTrack, a novel dual-encoder architecture that leverages decoupled local and\nglobal encoders specialized for their respective scales of feature extraction.\nThe local encoder uses dense spatiotemporal convolutions to capture\nfine-grained features, while the global encoder utilizes an image backbone\n(e.g., a 2D CNN or foundation model) and temporal attention layers to embed\nhigh-level anatomical features and long-range dependencies. A lightweight\nfusion module then combines these features to estimate the trajectory.\nExperimental results on a large public benchmark show that DualTrack achieves\nstate-of-the-art accuracy and globally consistent 3D reconstructions,\noutperforming previous methods and yielding an average reconstruction error\nbelow 5 mm.", "AI": {"tldr": "DualTrack is a novel 3D ultrasound method that achieves accurate and consistent 3D reconstructions, reducing errors to below 5 mm compared to previous models.", "motivation": "The motivation is to overcome the limitations of costly and complex traditional 3D ultrasound systems, providing an alternative via sensorless 3D ultrasound with deep learning to predict probe trajectory.", "method": "They propose DualTrack, a dual-encoder architecture that separates local feature extraction (dense spatiotemporal convolutions) and global feature modeling (2D CNNs or foundation models with temporal attention), combining them via a fusion module.", "result": "Experimental results demonstrated that DualTrack outperforms previous approaches in state-of-the-art accuracy, achieving globally consistent 3D reconstructions with average errors below 5 mm.", "conclusion": "DualTrack offers a promising and accurate innovation in 3D ultrasound, providing clinical advantages through its decoupled feature extraction, leading to improved reconstruction performance."}}
{"id": "2509.09045", "pdf": "https://arxiv.org/pdf/2509.09045", "abs": "https://arxiv.org/abs/2509.09045", "authors": ["Shrabani Ghosh", "Erik Saule"], "title": "The Role of Community Detection Methods in Performance Variations of Graph Mining Tasks", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "In real-world scenarios, large graphs represent relationships among entities\nin complex systems. Mining these large graphs often containing millions of\nnodes and edges helps uncover structural patterns and meaningful insights.\nDividing a large graph into smaller subgraphs facilitates complex system\nanalysis by revealing local information. Community detection extracts clusters\nor communities of graphs based on statistical methods and machine learning\nmodels using various optimization techniques. Structure based community\ndetection methods are more suitable for applying to graphs because they do not\nrely heavily on rich node or edge attribute information. The features derived\nfrom these communities can improve downstream graph mining tasks, such as link\nprediction and node classification. In real-world applications, we often lack\nground truth community information. Additionally, there is neither a\nuniversally accepted gold standard for community detection nor a single method\nthat is consistently optimal across diverse applications. In many cases, it is\nunclear how practitioners select community detection methods, and choices are\noften made without explicitly considering their potential impact on downstream\ntasks. In this study, we investigate whether the choice of community detection\nalgorithm significantly influences the performance of downstream applications.\nWe propose a framework capable of integrating various community detection\nmethods to systematically evaluate their effects on downstream task outcomes.\nOur comparative analysis reveals that specific community detection algorithms\nyield superior results in certain applications, highlighting that method\nselection substantially affects performance.", "AI": {"tldr": "The paper studies the impact of community detection algorithm selection on downstream graph mining tasks and provides a framework for systematic evaluation.", "motivation": "Understanding how community detection methods influence the performance of graph mining tasks is crucial, especially in scenarios where no ground truth community information exists.", "method": "The authors propose a framework to integrate various community detection methods, systematically assess them, and conduct a comparative analysis for downstream tasks like link prediction and node classification.", "result": "They discover that the choice of community detection algorithm significantly impacts the performance of downstream tasks, with certain methods showing better suitability for specific applications.", "conclusion": "Method selection in community detection critically affects downstream applications; thus, careful evaluation and tailored selection are recommended."}}
{"id": "2509.09547", "pdf": "https://arxiv.org/pdf/2509.09547", "abs": "https://arxiv.org/abs/2509.09547", "authors": ["Dohun Lee", "Hyeonho Jeong", "Jiwook Kim", "Duygu Ceylan", "Jong Chul Ye"], "title": "Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 14 figures", "summary": "Video diffusion models have advanced rapidly in the recent years as a result\nof series of architectural innovations (e.g., diffusion transformers) and use\nof novel training objectives (e.g., flow matching). In contrast, less attention\nhas been paid to improving the feature representation power of such models. In\nthis work, we show that training video diffusion models can benefit from\naligning the intermediate features of the video generator with feature\nrepresentations of pre-trained vision encoders. We propose a new metric and\nconduct an in-depth analysis of various vision encoders to evaluate their\ndiscriminability and temporal consistency, thereby assessing their suitability\nfor video feature alignment. Based on the analysis, we present Align4Gen which\nprovides a novel multi-feature fusion and alignment method integrated into\nvideo diffusion model training. We evaluate Align4Gen both for unconditional\nand class-conditional video generation tasks and show that it results in\nimproved video generation as quantified by various metrics. Full video results\nare available on our project page: https://align4gen.github.io/align4gen/", "AI": {"tldr": "The paper introduces Align4Gen, an approach to improve video diffusion models by aligning their features with representations from pre-trained vision encoders. Their method enhances video generation quality for various tasks.", "motivation": "Current video diffusion models lack adequate representation power, and feature alignment with pre-trained vision encoders may address this gap.", "method": "The authors propose Align4Gen, a framework that incorporates multi-feature fusion and alignment into video diffusion model training, leveraging discriminability and temporal consistency of vision encoders.", "result": "Align4Gen improves video generation performance in both unconditional and class-conditional tasks, as shown through multiple evaluation metrics.", "conclusion": "Feature alignment using vision encoders enhances video diffusion models' generation quality, presenting a promising direction for future research in this domain."}}
{"id": "2509.09555", "pdf": "https://arxiv.org/pdf/2509.09555", "abs": "https://arxiv.org/abs/2509.09555", "authors": ["Sirui Xu", "Dongting Li", "Yucheng Zhang", "Xiyan Xu", "Qi Long", "Ziyin Wang", "Yunzhi Lu", "Shuchang Dong", "Hezi Jiang", "Akshat Gupta", "Yu-Xiong Wang", "Liang-Yan Gui"], "title": "InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "While large-scale human motion capture datasets have advanced human motion\ngeneration, modeling and generating dynamic 3D human-object interactions (HOIs)\nremain challenging due to dataset limitations. Existing datasets often lack\nextensive, high-quality motion and annotation and exhibit artifacts such as\ncontact penetration, floating, and incorrect hand motions. To address these\nissues, we introduce InterAct, a large-scale 3D HOI benchmark featuring dataset\nand methodological advancements. First, we consolidate and standardize 21.81\nhours of HOI data from diverse sources, enriching it with detailed textual\nannotations. Second, we propose a unified optimization framework to enhance\ndata quality by reducing artifacts and correcting hand motions. Leveraging the\nprinciple of contact invariance, we maintain human-object relationships while\nintroducing motion variations, expanding the dataset to 30.70 hours. Third, we\ndefine six benchmarking tasks and develop a unified HOI generative modeling\nperspective, achieving state-of-the-art performance. Extensive experiments\nvalidate the utility of our dataset as a foundational resource for advancing 3D\nhuman-object interaction generation. To support continued research in this\narea, the dataset is publicly available at\nhttps://github.com/wzyabcas/InterAct, and will be actively maintained.", "AI": {"tldr": "The paper introduces InterAct, a new dataset and framework to advance 3D human-object interaction (HOI) modeling, addressing issues of data quality and limited resources in existing datasets.", "motivation": "Current 3D HOI datasets lack quality and annotations, and exhibit issues such as motion artifacts and inaccurate interactions, which hinder progress in human-object interaction modeling.", "method": "The authors consolidate diverse HOI datasets, refine the data with an optimization framework, expand motion variations, and establish six benchmarking tasks with a unified generative modeling perspective.", "result": "The new InterAct dataset offers 30.70 hours of improved HOI data, achieves state-of-the-art performance in HOI generative modeling, and validates its effectiveness through extensive experiments.", "conclusion": "InterAct is a pivotal step toward improving 3D HOI modeling and is made publicly available to promote further research in this domain."}}
{"id": "2509.09558", "pdf": "https://arxiv.org/pdf/2509.09558", "abs": "https://arxiv.org/abs/2509.09558", "authors": ["Akshit Achara", "Esther Puyol Anton", "Alexander Hammers", "Andrew P. King"], "title": "Invisible Attributes, Visible Biases: Exploring Demographic Shortcuts in MRI-based Alzheimer's Disease Classification", "categories": ["cs.CV", "cs.AI"], "comment": "FAIMI @ MICCAI 2025", "summary": "Magnetic resonance imaging (MRI) is the gold standard for brain imaging. Deep\nlearning (DL) algorithms have been proposed to aid in the diagnosis of diseases\nsuch as Alzheimer's disease (AD) from MRI scans. However, DL algorithms can\nsuffer from shortcut learning, in which spurious features, not directly related\nto the output label, are used for prediction. When these features are related\nto protected attributes, they can lead to performance bias against\nunderrepresented protected groups, such as those defined by race and sex. In\nthis work, we explore the potential for shortcut learning and demographic bias\nin DL based AD diagnosis from MRI. We first investigate if DL algorithms can\nidentify race or sex from 3D brain MRI scans to establish the presence or\notherwise of race and sex based distributional shifts. Next, we investigate\nwhether training set imbalance by race or sex can cause a drop in model\nperformance, indicating shortcut learning and bias. Finally, we conduct a\nquantitative and qualitative analysis of feature attributions in different\nbrain regions for both the protected attribute and AD classification tasks.\nThrough these experiments, and using multiple datasets and DL models (ResNet\nand SwinTransformer), we demonstrate the existence of both race and sex based\nshortcut learning and bias in DL based AD classification. Our work lays the\nfoundation for fairer DL diagnostic tools in brain MRI. The code is provided at\nhttps://github.com/acharaakshit/ShortMR", "AI": {"tldr": "This paper explores demographic bias in deep learning algorithms for Alzheimer\u2019s disease classification using MRI scans, demonstrating that race and sex-based shortcut learning can affect performance.", "motivation": "To address concerns about shortcut learning in DL algorithms potentially causing biased Alzheimer\u2019s disease diagnosis from MRI scans based on race and sex demographics.", "method": "The researchers assessed DL algorithms' ability to infer race or sex from brain MRI data, analyzed performance under training set imbalances by race/sex, and conducted feature attribution analyses using ResNet and SwinTransformer.", "result": "They demonstrated that DL models exhibit race and sex-based shortcut learning, resulting in biased and unequal performance in Alzheimer's disease classification tasks.", "conclusion": "The study highlights the need for mitigating bias in DL medical diagnostic tools by ensuring fairness across protected demographic groups like race and sex."}}
{"id": "2509.09572", "pdf": "https://arxiv.org/pdf/2509.09572", "abs": "https://arxiv.org/abs/2509.09572", "authors": ["Sijun Dong", "Yuxuan Hu", "LiBo Wang", "Geng Chen", "Xiaoliang Meng"], "title": "PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection", "categories": ["cs.CV"], "comment": null, "summary": "To tackle the prevalence of pseudo changes, the scarcity of labeled samples,\nand the difficulty of cross-domain generalization in multi-temporal and\nmulti-source remote sensing imagery, we propose PeftCD, a change detection\nframework built upon Vision Foundation Models (VFMs) with Parameter-Efficient\nFine-Tuning (PEFT). At its core, PeftCD employs a weight-sharing Siamese\nencoder derived from a VFM, into which LoRA and Adapter modules are seamlessly\nintegrated. This design enables highly efficient task adaptation by training\nonly a minimal set of additional parameters. To fully unlock the potential of\nVFMs, we investigate two leading backbones: the Segment Anything Model v2\n(SAM2), renowned for its strong segmentation priors, and DINOv3, a\nstate-of-the-art self-supervised representation learner. The framework is\ncomplemented by a deliberately lightweight decoder, ensuring the focus remains\non the powerful feature representations from the backbones. Extensive\nexperiments demonstrate that PeftCD achieves state-of-the-art performance\nacross multiple public datasets, including SYSU-CD (IoU 73.81%), WHUCD\n(92.05%), MSRSCD (64.07%), MLCD (76.89%), CDD (97.01%), S2Looking (52.25%) and\nLEVIR-CD (85.62%), with notably precise boundary delineation and strong\nsuppression of pseudo-changes. In summary, PeftCD presents an optimal balance\nof accuracy, efficiency, and generalization. It offers a powerful and scalable\nparadigm for adapting large-scale VFMs to real-world remote sensing change\ndetection applications. The code and pretrained models will be released at\nhttps://github.com/dyzy41/PeftCD.", "AI": {"tldr": "PeftCD is a remote sensing change detection framework leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning to improve accuracy, efficiency, and generalization in change detection tasks.", "motivation": "Address the challenges of pseudo changes, limited labeled samples, and cross-domain generalization in multi-temporal and multi-source remote sensing imagery.", "method": "The framework uses a weight-sharing Siamese encoder with LoRA and Adapter modules integrated, based on VFMs like SAM2 and DINOv3, along with lightweight decoding for efficient task adaptation.", "result": "Achieved state-of-the-art performance across datasets with precise boundary delineation and effective suppression of pseudo-changes.", "conclusion": "PeftCD demonstrates an ideal balance between accuracy, efficiency, and scalability, making it highly effective for real-world remote sensing change detection."}}
{"id": "2509.09107", "pdf": "https://arxiv.org/pdf/2509.09107", "abs": "https://arxiv.org/abs/2509.09107", "authors": ["Pritam Sen", "Yao Ma", "Cristian Borcea"], "title": "CryptGNN: Enabling Secure Inference for Graph Neural Networks", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We present CryptGNN, a secure and effective inference solution for\nthird-party graph neural network (GNN) models in the cloud, which are accessed\nby clients as ML as a service (MLaaS). The main novelty of CryptGNN is its\nsecure message passing and feature transformation layers using distributed\nsecure multi-party computation (SMPC) techniques. CryptGNN protects the\nclient's input data and graph structure from the cloud provider and the\nthird-party model owner, and it protects the model parameters from the cloud\nprovider and the clients. CryptGNN works with any number of SMPC parties, does\nnot require a trusted server, and is provably secure even if P-1 out of P\nparties in the cloud collude. Theoretical analysis and empirical experiments\ndemonstrate the security and efficiency of CryptGNN.", "AI": {"tldr": "CryptGNN is a solution for secure inference of graph neural networks in the cloud, ensuring privacy using secure multi-party computation (SMPC) techniques.", "motivation": "The paper addresses the need for privacy-preserving machine learning services for graph neural networks, where secure inference is necessary to protect clients' data, graph structures, and third-party models in cloud environments.", "method": "CryptGNN uses distributed secure multi-party computation (SMPC) techniques to achieve secure message passing and feature transformation. It operates without requiring a trusted server and ensures security even in cases of collusion by up to P-1 parties in the cloud.", "result": "Theoretical and empirical evaluations demonstrate that CryptGNN is both secure and efficient.", "conclusion": "CryptGNN enables secure and effective cloud-based GNN inference as an MLaaS, protecting both client data and third-party models while maintaining computational efficiency."}}
{"id": "2509.09235", "pdf": "https://arxiv.org/pdf/2509.09235", "abs": "https://arxiv.org/abs/2509.09235", "authors": ["Sarah C. Irvine", "Christian Lucas", "Diana Kr\u00fcger", "Bianca Guedert", "Julian Moosmann", "Berit Zeller-Plumhoff"], "title": "Virtual staining for 3D X-ray histology of bone implants", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.comp-ph", "q-bio.QM"], "comment": null, "summary": "Three-dimensional X-ray histology techniques offer a non-invasive alternative\nto conventional 2D histology, enabling volumetric imaging of biological tissues\nwithout the need for physical sectioning or chemical staining. However, the\ninherent greyscale image contrast of X-ray tomography limits its biochemical\nspecificity compared to traditional histological stains. Within digital\npathology, deep learning-based virtual staining has demonstrated utility in\nsimulating stained appearances from label-free optical images. In this study,\nwe extend virtual staining to the X-ray domain by applying cross-modality image\ntranslation to generate artificially stained slices from\nsynchrotron-radiation-based micro-CT scans. Using over 50 co-registered image\npairs of micro-CT and toluidine blue-stained histology from bone-implant\nsamples, we trained a modified CycleGAN network tailored for limited paired\ndata. Whole slide histology images were downsampled to match the voxel size of\nthe CT data, with on-the-fly data augmentation for patch-based training. The\nmodel incorporates pixelwise supervision and greyscale consistency terms,\nproducing histologically realistic colour outputs while preserving\nhigh-resolution structural detail. Our method outperformed Pix2Pix and standard\nCycleGAN baselines across SSIM, PSNR, and LPIPS metrics. Once trained, the\nmodel can be applied to full CT volumes to generate virtually stained 3D\ndatasets, enhancing interpretability without additional sample preparation.\nWhile features such as new bone formation were able to be reproduced, some\nvariability in the depiction of implant degradation layers highlights the need\nfor further training data and refinement. This work introduces virtual staining\nto 3D X-ray imaging and offers a scalable route for chemically informative,\nlabel-free tissue characterisation in biomedical research.", "AI": {"tldr": "The authors propose a deep learning-based virtual staining method to enhance biochemical specificity in 3D X-ray histology using synchrotron-radiation micro-CT.", "motivation": "The motivation is to overcome the limitation of conventional X-ray tomography, which lacks biochemical specificity compared to traditional histological staining methods.", "method": "The authors used a modified CycleGAN for cross-modality image translation, applying pixelwise supervision and greyscale consistency terms for virtual staining of X-ray micro-CT scans.", "result": "The method demonstrated superior performance against baseline models (Pix2Pix and standard CycleGAN) across metrics like SSIM, PSNR, and LPIPS.", "conclusion": "Virtual staining offers scalable, chemically informative, label-free tissue characterization that enhances interpretability of 3D X-ray imaging for biomedical research."}}
{"id": "2509.09595", "pdf": "https://arxiv.org/pdf/2509.09595", "abs": "https://arxiv.org/abs/2509.09595", "authors": ["Yikang Ding", "Jiwen Liu", "Wenyuan Zhang", "Zekun Wang", "Wentao Hu", "Liyuan Cui", "Mingming Lao", "Yingchao Shao", "Hui Liu", "Xiaohan Li", "Ming Chen", "Xiaoqiang Liu", "Yu-Shen Liu", "Pengfei Wan"], "title": "Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis", "categories": ["cs.CV"], "comment": "Technical Report. Project Page: https://klingavatar.github.io/", "summary": "Recent advances in audio-driven avatar video generation have significantly\nenhanced audio-visual realism. However, existing methods treat instruction\nconditioning merely as low-level tracking driven by acoustic or visual cues,\nwithout modeling the communicative purpose conveyed by the instructions. This\nlimitation compromises their narrative coherence and character expressiveness.\nTo bridge this gap, we introduce Kling-Avatar, a novel cascaded framework that\nunifies multimodal instruction understanding with photorealistic portrait\ngeneration. Our approach adopts a two-stage pipeline. In the first stage, we\ndesign a multimodal large language model (MLLM) director that produces a\nblueprint video conditioned on diverse instruction signals, thereby governing\nhigh-level semantics such as character motion and emotions. In the second\nstage, guided by blueprint keyframes, we generate multiple sub-clips in\nparallel using a first-last frame strategy. This global-to-local framework\npreserves fine-grained details while faithfully encoding the high-level intent\nbehind multimodal instructions. Our parallel architecture also enables fast and\nstable generation of long-duration videos, making it suitable for real-world\napplications such as digital human livestreaming and vlogging. To\ncomprehensively evaluate our method, we construct a benchmark of 375 curated\nsamples covering diverse instructions and challenging scenarios. Extensive\nexperiments demonstrate that Kling-Avatar is capable of generating vivid,\nfluent, long-duration videos at up to 1080p and 48 fps, achieving superior\nperformance in lip synchronization accuracy, emotion and dynamic\nexpressiveness, instruction controllability, identity preservation, and\ncross-domain generalization. These results establish Kling-Avatar as a new\nbenchmark for semantically grounded, high-fidelity audio-driven avatar\nsynthesis.", "AI": {"tldr": "Kling-Avatar introduces a two-stage framework combining multimodal instruction understanding with photorealistic portrait generation to produce realistic, expressive, long-duration videos driven by audio cues.", "motivation": "Existing avatar generation methods fail to capture the communicative purpose conveyed by multimodal instructions, leading to issues in narrative coherence and character expressiveness.", "method": "Kling-Avatar employs a two-stage pipeline. First, a multimodal large language model (MLLM) creates a blueprint video based on instruction signals. Second, a first-last frame strategy generates multiple sub-clips guided by the blueprint keyframes for high fidelity and expressiveness.", "result": "Kling-Avatar demonstrates superior performance in lip synchronization, emotion portrayal, instruction controllability, and identity preservation. It can generate vivid long-duration videos up to 1080p and 48 fps, suitable for applications like livestreaming.", "conclusion": "Kling-Avatar sets a new benchmark for high-fidelity audio-driven avatar synthesis, unifying semantic modeling and expressive video generation while offering scalability for real-world applications."}}
{"id": "2509.09610", "pdf": "https://arxiv.org/pdf/2509.09610", "abs": "https://arxiv.org/abs/2509.09610", "authors": ["Daria Laslo", "Efthymios Georgiou", "Marius George Linguraru", "Andreas Rauschecker", "Sabine Muller", "Catherine R. Jutzeler", "Sarah Bruningk"], "title": "Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "Predicting the spatio-temporal progression of brain tumors is essential for\nguiding clinical decisions in neuro-oncology. We propose a hybrid mechanistic\nlearning framework that combines a mathematical tumor growth model with a\nguided denoising diffusion implicit model (DDIM) to synthesize anatomically\nfeasible future MRIs from preceding scans. The mechanistic model, formulated as\na system of ordinary differential equations, captures temporal tumor dynamics\nincluding radiotherapy effects and estimates future tumor burden. These\nestimates condition a gradient-guided DDIM, enabling image synthesis that\naligns with both predicted growth and patient anatomy. We train our model on\nthe BraTS adult and pediatric glioma datasets and evaluate on 60 axial slices\nof in-house longitudinal pediatric diffuse midline glioma (DMG) cases. Our\nframework generates realistic follow-up scans based on spatial similarity\nmetrics. It also introduces tumor growth probability maps, which capture both\nclinically relevant extent and directionality of tumor growth as shown by 95th\npercentile Hausdorff Distance. The method enables biologically informed image\ngeneration in data-limited scenarios, offering generative-space-time\npredictions that account for mechanistic priors.", "AI": {"tldr": "The paper proposes a hybrid framework integrating a tumor growth model with guided diffusion denoising for predicting brain tumor progression through future MRI scans.", "motivation": "Predicting tumor progression spatially and temporally is critical for enhancing clinical decision-making in neuro-oncology.", "method": "The framework combines a mathematical tumor growth model (ordinary differential equations) and a guided denoising diffusion implicit model (DDIM) for image synthesis of future MRIs using tumor estimates as conditioning inputs.", "result": "Using BraTS datasets and pediatric glioma scans, the model demonstrates realistic anonymized follow-up MRI generation and predicts tumor growth effectively, validated through metrics like Hausdorff Distance.", "conclusion": "The approach provides biologically realistic spatiotemporal tumor progression predictions, expanding interpretations in scenarios with limited data and mechanistic understanding."}}
{"id": "2509.09262", "pdf": "https://arxiv.org/pdf/2509.09262", "abs": "https://arxiv.org/abs/2509.09262", "authors": ["Seung Gyu Jeong", "Seong Eun Kim"], "title": "Adaptive Knowledge Distillation using a Device-Aware Teacher for Low-Complexity Acoustic Scene Classification", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "In this technical report, we describe our submission for Task 1,\nLow-Complexity Device-Robust Acoustic Scene Classification, of the DCASE 2025\nChallenge. Our work tackles the dual challenges of strict complexity\nconstraints and robust generalization to both seen and unseen devices, while\nalso leveraging the new rule allowing the use of device labels at test time.\nOur proposed system is based on a knowledge distillation framework where an\nefficient CP-MobileNet student learns from a compact, specialized two-teacher\nensemble. This ensemble combines a baseline PaSST teacher, trained with\nstandard cross-entropy, and a 'generalization expert' teacher. This expert is\ntrained using our novel Device-Aware Feature Alignment (DAFA) loss, adapted\nfrom prior work, which explicitly structures the feature space for device\nrobustness. To capitalize on the availability of test-time device labels, the\ndistilled student model then undergoes a final device-specific fine-tuning\nstage. Our proposed system achieves a final accuracy of 57.93\\% on the\ndevelopment set, demonstrating a significant improvement over the official\nbaseline, particularly on unseen devices.", "AI": {"tldr": "This paper addresses robust acoustic scene classification with low complexity, introducing a knowledge distillation model and device-specific fine-tuning for improved accuracy.", "motivation": "The authors aim to tackle acoustic scene classification challenges under strict computational constraints and ensure robust performance across various devices, including unseen ones.", "method": "They propose a CP-MobileNet student model trained using knowledge distillation with a two-teacher ensemble approach. Key innovations include a Device-Aware Feature Alignment (DAFA) loss for device robustness and device-specific fine-tuning using test-time device labels.", "result": "Their system achieved 57.93% accuracy on the development set, surpassing the baseline, especially on unseen devices.", "conclusion": "The proposed method shows significant improvements in device-robust acoustic scene classification within computational limitations, highlighting its potential for real-world applications."}}
{"id": "2509.09658", "pdf": "https://arxiv.org/pdf/2509.09658", "abs": "https://arxiv.org/abs/2509.09658", "authors": ["Bingkui Tong", "Jiaer Xia", "Sifeng Shang", "Kaiyang Zhou"], "title": "Measuring Epistemic Humility in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Hallucinations in multimodal large language models (MLLMs) -- where the model\ngenerates content inconsistent with the input image -- pose significant risks\nin real-world applications, from misinformation in visual question answering to\nunsafe errors in decision-making. Existing benchmarks primarily test\nrecognition accuracy, i.e., evaluating whether models can select the correct\nanswer among distractors. This overlooks an equally critical capability for\ntrustworthy AI: recognizing when none of the provided options are correct, a\nbehavior reflecting epistemic humility. We present HumbleBench, a new\nhallucination benchmark designed to evaluate MLLMs' ability to reject plausible\nbut incorrect answers across three hallucination types: object, relation, and\nattribute. Built from a panoptic scene graph dataset, we leverage fine-grained\nscene graph annotations to extract ground-truth entities and relations, and\nprompt GPT-4-Turbo to generate multiple-choice questions, followed by a\nrigorous manual filtering process. Each question includes a \"None of the above\"\noption, requiring models not only to recognize correct visual information but\nalso to identify when no provided answer is valid. We evaluate a variety of\nstate-of-the-art MLLMs -- including both general-purpose and specialized\nreasoning models -- on HumbleBench and share valuable findings and insights\nwith the community. By incorporating explicit false-option rejection,\nHumbleBench fills a key gap in current evaluation suites, providing a more\nrealistic measure of MLLM reliability in safety-critical settings. Our code and\ndataset are released publicly and can be accessed at\nhttps://github.com/maifoundations/HumbleBench.", "AI": {"tldr": "The paper introduces a benchmark called HumbleBench to evaluate Multimodal Large Language Models (MLLMs) on their ability to reject incorrect answers, a measure crucial for safety-critical applications.", "motivation": "To address the risks posed by hallucinations in MLLMs and the current lack of benchmarks that evaluate a model's ability to reject invalid answers, ensuring more trustworthy AI systems.", "method": "The authors developed HumbleBench using fine-grained scene graph annotations from a panoptic dataset. They employed GPT-4-Turbo to generate multiple-choice questions with manual curation, ensuring the inclusion of a \"None of the above\" option. Various state-of-the-art MLLMs were tested.", "result": "The benchmark revealed key insights on the capability gaps of current MLLMs in rejecting hallucinated answers across object, relation, and attribute types.", "conclusion": "HumbleBench bridges an essential evaluation gap by testing MLLMs' epistemic humility and helps assess their reliability in high-stakes scenarios. The dataset and code are made publicly available for community use."}}
{"id": "2509.09666", "pdf": "https://arxiv.org/pdf/2509.09666", "abs": "https://arxiv.org/abs/2509.09666", "authors": ["Zhiyuan Yan", "Kaiqing Lin", "Zongjian Li", "Junyan Ye", "Hui Han", "Zhendong Wang", "Hao Liu", "Bin Lin", "Hao Li", "Xue Xu", "Xinyan Xiao", "Jingdong Wang", "Haifeng Wang", "Li Yuan"], "title": "Can Understanding and Generation Truly Benefit Together -- or Just Coexist?", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce an insightful paradigm through the Auto-Encoder\nlens-understanding as the encoder (I2T) that compresses images into text, and\ngeneration as the decoder (T2I) that reconstructs images from that text. Using\nreconstruction fidelity as the unified training objective, we enforce the\ncoherent bidirectional information flow between the understanding and\ngeneration processes, bringing mutual gains. To implement this, we propose UAE,\na novel framework for unified multimodal learning. We begin by pre-training the\ndecoder with large-scale long-context image captions to capture fine-grained\nsemantic and complex spatial relationships. We then propose Unified-GRPO via\nreinforcement learning (RL), which covers three stages: (1) A cold-start phase\nto gently initialize both encoder and decoder with a semantic reconstruction\nloss; (2) Generation for Understanding, where the encoder is trained to\ngenerate informative captions that maximize the decoder's reconstruction\nquality, enhancing its visual understanding; (3) Understanding for Generation,\nwhere the decoder is refined to reconstruct from these captions, forcing it to\nleverage every detail and improving its long-context instruction following and\ngeneration fidelity. For evaluation, we introduce Unified-Bench, the first\nbenchmark tailored to assess the degree of unification of the UMMs. A\nsurprising \"aha moment\" arises within the multimodal learning domain: as RL\nprogresses, the encoder autonomously produces more descriptive captions, while\nthe decoder simultaneously demonstrates a profound ability to understand these\nintricate descriptions, resulting in reconstructions of striking fidelity.", "AI": {"tldr": "The paper introduces UAE, a framework for unified multimodal learning, using an encoder-decoder auto-encoder paradigm to improve both image-to-text understanding and text-to-image generation.", "motivation": "The paper aims to create a unified framework to bridge the gap between multimodal understanding (image-to-text) and generation (text-to-image) through a bidirectional information flow.", "method": "The UAE framework involves pre-training the decoder with large-scale image captions and uses a three-stage RL-based strategy: initialization, improving encoding for better captions, and refining decoding for better reconstructions.", "result": "The encoder autonomously generates more descriptive captions, and the decoder demonstrates improved reconstruction fidelity as RL progresses.", "conclusion": "UAE achieves significant advances in unified multimodal tasks, with improved coherence, long-context understanding, and generation fidelity, evaluated using a newly introduced benchmark."}}
{"id": "2509.09667", "pdf": "https://arxiv.org/pdf/2509.09667", "abs": "https://arxiv.org/abs/2509.09667", "authors": ["Zhengdi Yu", "Simone Foti", "Linguang Zhang", "Amy Zhao", "Cem Keskin", "Stefanos Zafeiriou", "Tolga Birdal"], "title": "Geometric Neural Distance Fields for Learning Human Motion Priors", "categories": ["cs.CV"], "comment": "8 pages", "summary": "We introduce Neural Riemannian Motion Fields (NRMF), a novel 3D generative\nhuman motion prior that enables robust, temporally consistent, and physically\nplausible 3D motion recovery. Unlike existing VAE or diffusion-based methods,\nour higher-order motion prior explicitly models the human motion in the zero\nlevel set of a collection of neural distance fields (NDFs) corresponding to\npose, transition (velocity), and acceleration dynamics. Our framework is\nrigorous in the sense that our NDFs are constructed on the product space of\njoint rotations, their angular velocities, and angular accelerations,\nrespecting the geometry of the underlying articulations. We further introduce:\n(i) a novel adaptive-step hybrid algorithm for projecting onto the set of\nplausible motions, and (ii) a novel geometric integrator to \"roll out\"\nrealistic motion trajectories during test-time-optimization and generation. Our\nexperiments show significant and consistent gains: trained on the AMASS\ndataset, NRMF remarkably generalizes across multiple input modalities and to\ndiverse tasks ranging from denoising to motion in-betweening and fitting to\npartial 2D / 3D observations.", "AI": {"tldr": "Neural Riemannian Motion Fields (NRMF) is a new generative model for 3D human motion recovery that ensures consistent and physically plausible motions using geometric insights.", "motivation": "To overcome limitations in existing human motion modeling methods like VAEs and diffusion models, and to create a model that ensures robustness, temporal consistency, and physical plausibility.", "method": "Uses neural distance fields (NDFs) to model human motion dynamics across pose, velocity, and acceleration in a mathematically rigorous way. Introduces an adaptive-step hybrid projection algorithm and a geometric integrator for realistic motion generation.", "result": "NRMF demonstrates superior performance on the AMASS dataset, generalizing across modalities and tasks like denoising, motion in-betweening, and partial 2D/3D motion fitting.", "conclusion": "NRMF provides a robust framework to improve 3D human motion recovery, systematically ensuring plausible and generalizable results for diverse applications."}}
{"id": "2509.09672", "pdf": "https://arxiv.org/pdf/2509.09672", "abs": "https://arxiv.org/abs/2509.09672", "authors": ["Artem Lukoianov", "Chenyang Yuan", "Justin Solomon", "Vincent Sitzmann"], "title": "Locality in Image Diffusion Models Emerges from Data Statistics", "categories": ["cs.CV"], "comment": "30 pages, 18 figures, 6 tables", "summary": "Among generative models, diffusion models are uniquely intriguing due to the\nexistence of a closed-form optimal minimizer of their training objective, often\nreferred to as the optimal denoiser. However, diffusion using this optimal\ndenoiser merely reproduces images in the training set and hence fails to\ncapture the behavior of deep diffusion models. Recent work has attempted to\ncharacterize this gap between the optimal denoiser and deep diffusion models,\nproposing analytical, training-free models that can generate images that\nresemble those generated by a trained UNet. The best-performing method\nhypothesizes that shift equivariance and locality inductive biases of\nconvolutional neural networks are the cause of the performance gap, hence\nincorporating these assumptions into its analytical model. In this work, we\npresent evidence that the locality in deep diffusion models emerges as a\nstatistical property of the image dataset, not due to the inductive bias of\nconvolutional neural networks. Specifically, we demonstrate that an optimal\nparametric linear denoiser exhibits similar locality properties to the deep\nneural denoisers. We further show, both theoretically and experimentally, that\nthis locality arises directly from the pixel correlations present in natural\nimage datasets. Finally, we use these insights to craft an analytical denoiser\nthat better matches scores predicted by a deep diffusion model than the prior\nexpert-crafted alternative.", "AI": {"tldr": "The paper explores locality in deep diffusion models, demonstrating it stems from dataset statistics rather than CNN biases, and develops a better analytical denoiser.", "motivation": "To close the gap between the theoretical optimal denoiser and practical deep diffusion models by understanding the root of locality in these models.", "method": "The authors compare an optimal linear parametric denoiser with deep neural network-based denoisers, analyze pixel correlations in datasets, and craft an improved analytical denoiser.", "result": "The locality in deep diffusion models is shown to emerge from statistical properties of image datasets. An improved analytical denoiser resembling deep diffusion models is developed.", "conclusion": "Locality in deep diffusion models is inherently tied to dataset statistics, not CNN inductive biases, leading to insights for better denoiser design."}}
{"id": "2509.09676", "pdf": "https://arxiv.org/pdf/2509.09676", "abs": "https://arxiv.org/abs/2509.09676", "authors": ["Jiahao Wang", "Yufeng Yuan", "Rujie Zheng", "Youtian Lin", "Jian Gao", "Lin-Zhuo Chen", "Yajie Bao", "Yi Zhang", "Chang Zeng", "Yanxi Zhou", "Xiaoxiao Long", "Hao Zhu", "Zhaoxiang Zhang", "Xun Cao", "Yao Yao"], "title": "SpatialVID: A Large-Scale Video Dataset with Spatial Annotations", "categories": ["cs.CV"], "comment": "Project page: https://nju-3dv.github.io/projects/SpatialVID/", "summary": "Significant progress has been made in spatial intelligence, spanning both\nspatial reconstruction and world exploration. However, the scalability and\nreal-world fidelity of current models remain severely constrained by the\nscarcity of large-scale, high-quality training data. While several datasets\nprovide camera pose information, they are typically limited in scale,\ndiversity, and annotation richness, particularly for real-world dynamic scenes\nwith ground-truth camera motion. To this end, we collect \\textbf{SpatialVID}, a\ndataset consists of a large corpus of in-the-wild videos with diverse scenes,\ncamera movements and dense 3D annotations such as per-frame camera poses,\ndepth, and motion instructions. Specifically, we collect more than 21,000 hours\nof raw video, and process them into 2.7 million clips through a hierarchical\nfiltering pipeline, totaling 7,089 hours of dynamic content. A subsequent\nannotation pipeline enriches these clips with detailed spatial and semantic\ninformation, including camera poses, depth maps, dynamic masks, structured\ncaptions, and serialized motion instructions. Analysis of SpatialVID's data\nstatistics reveals a richness and diversity that directly foster improved model\ngeneralization and performance, establishing it as a key asset for the video\nand 3D vision research community.", "AI": {"tldr": "The paper introduces SpatialVID, a large-scale dataset of in-the-wild video clips annotated with spatial and semantic information for training models in video and 3D vision tasks.", "motivation": "The scalability and real-world applicability of spatial intelligence models are limited by the lack of diverse, high-quality annotated datasets, particularly for dynamic real-world scenes.", "method": "The authors collected over 21,000 hours of raw video, processed them into clips using hierarchical filtering, and added detailed spatial and semantic annotations like camera poses, depth maps, and motion instructions.", "result": "SpatialVID comprises 7,089 hours of dynamic content, enriched with comprehensive annotations, showcasing greater diversity and depth compared to existing datasets.", "conclusion": "SpatialVID is a valuable resource for enhancing model generalization and advancing research in video and 3D vision, addressing key limitations of current datasets."}}
{"id": "2509.09371", "pdf": "https://arxiv.org/pdf/2509.09371", "abs": "https://arxiv.org/abs/2509.09371", "authors": ["Zitao Wang", "Nian Si", "Molei Liu"], "title": "Representation-Aware Distributionally Robust Optimization: A Knowledge Transfer Framework", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "We propose REpresentation-Aware Distributionally Robust Estimation (READ), a\nnovel framework for Wasserstein distributionally robust learning that accounts\nfor predictive representations when guarding against distributional shifts.\nUnlike classical approaches that treat all feature perturbations equally, READ\nembeds a multidimensional alignment parameter into the transport cost, allowing\nthe model to differentially discourage perturbations along directions\nassociated with informative representations. This yields robustness to feature\nvariation while preserving invariant structure. Our first contribution is a\ntheoretical foundation: we show that seminorm regularizations for linear\nregression and binary classification arise as Wasserstein distributionally\nrobust objectives, thereby providing tractable reformulations of READ and\nunifying a broad class of regularized estimators under the DRO lens. Second, we\nadopt a principled procedure for selecting the Wasserstein radius using the\ntechniques of robust Wasserstein profile inference. This further enables the\nconstruction of valid, representation-aware confidence regions for model\nparameters with distinct geometric features. Finally, we analyze the geometry\nof READ estimators as the alignment parameters vary and propose an optimization\nalgorithm to estimate the projection of the global optimum onto this solution\nsurface. This procedure selects among equally robust estimators while optimally\nconstructing a representation structure. We conclude by demonstrating the\neffectiveness of our framework through extensive simulations and a real-world\nstudy, providing a powerful robust estimation grounded in learning\nrepresentation.", "AI": {"tldr": "READ is a Wasserstein distributionally robust learning framework that incorporates predictive representations for handling distributional shifts, offering robust estimation while maintaining invariant structure.", "motivation": "To address the limitations of classical DRO approaches that treat all feature perturbations equally, and to create a framework that leverages predictive representations for improved robustness in handling distributional shifts.", "method": "READ embeds an alignment parameter into the transport cost to differentially handle perturbations along informative representations. It reformulates these objectives into tractable regularized estimators and applies Wasserstein profile inference for radius selection.", "result": "The paper introduces READ's theoretical foundation, develops a principled method for selecting Wasserstein radius, analyzes estimator geometry with varying alignment parameters, and proposes an optimization algorithm for robust solution selection.", "conclusion": "The framework demonstrates effectiveness in simulations and real-world applications, offering robust estimation that captures representation structures and preserves invariant features."}}
{"id": "2409.05569", "pdf": "https://arxiv.org/pdf/2409.05569", "abs": "https://arxiv.org/abs/2409.05569", "authors": ["Andreas Langer", "Sara Behnamian"], "title": "DeepTV: A neural network approach for total variation minimization", "categories": ["math.NA", "cs.CV", "cs.NA"], "comment": null, "summary": "Neural network approaches have been demonstrated to work quite well to solve\npartial differential equations in practice. In this context approaches like\nphysics-informed neural networks and the Deep Ritz method have become popular.\nIn this paper, we propose a similar approach to solve an infinite-dimensional\ntotal variation minimization problem using neural networks. We illustrate that\nthe resulting neural network problem does not have a solution in general. To\ncircumvent this theoretic issue, we consider an auxiliary neural network\nproblem, which indeed has a solution, and show that it converges in the sense\nof $\\Gamma$-convergence to the original problem. For computing a numerical\nsolution we further propose a discrete version of the auxiliary neural network\nproblem and again show its $\\Gamma$-convergence to the original\ninfinite-dimensional problem. In particular, the $\\Gamma$-convergence proof\nsuggests a particular discretization of the total variation. Moreover, we\nconnect the discrete neural network problem to a finite difference\ndiscretization of the infinite-dimensional total variation minimization\nproblem. Numerical experiments are presented supporting our theoretical\nfindings.", "AI": {"tldr": "This paper explores solving infinite-dimensional total variation minimization problems using neural networks, addressing the lack of solution by proposing an auxiliary and discrete problem approach, supported by theoretical and numerical findings.", "motivation": "Existing neural network methods perform well for solving partial differential equations, and this work seeks to extend such approaches to infinite-dimensional total variation minimization problems, which present theoretical and computational challenges.", "method": "The authors propose an auxiliary neural network problem to bypass the lack of solutions in the original setup. They prove its convergence to the original problem through $\\Gamma$-convergence and further design a discrete version for computational efficiency, ensuring this discrete problem matches theoretical requirements.", "result": "The paper demonstrates $\\Gamma$-convergence for both the auxiliary and discrete neural network problems to the original. Furthermore, it finds connections between the discrete problem and traditional finite difference methods for the infinite-dimensional case.", "conclusion": "Neural networks can effectively approximate infinite-dimensional total variation minimization problems, provided the issues with solution existence and computation are addressed via auxiliary formulations and discretization. The results bridge theoretical rigor and practical computation."}}
{"id": "2509.09482", "pdf": "https://arxiv.org/pdf/2509.09482", "abs": "https://arxiv.org/abs/2509.09482", "authors": ["Agapi Rissaki", "Ilias Fountalis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "Database Views as Explanations for Relational Deep Learning", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "In recent years, there has been significant progress in the development of\ndeep learning models over relational databases, including architectures based\non heterogeneous graph neural networks (hetero-GNNs) and heterogeneous graph\ntransformers. In effect, such architectures state how the database records and\nlinks (e.g., foreign-key references) translate into a large, complex numerical\nexpression, involving numerous learnable parameters. This complexity makes it\nhard to explain, in human-understandable terms, how a model uses the available\ndata to arrive at a given prediction. We present a novel framework for\nexplaining machine-learning models over relational databases, where\nexplanations are view definitions that highlight focused parts of the database\nthat mostly contribute to the model's prediction. We establish such global\nabductive explanations by adapting the classic notion of determinacy by Nash,\nSegoufin, and Vianu (2010). In addition to tuning the tradeoff between\ndeterminacy and conciseness, the framework allows controlling the level of\ngranularity by adopting different fragments of view definitions, such as ones\nhighlighting whole columns, foreign keys between tables, relevant groups of\ntuples, and so on. We investigate the realization of the framework in the case\nof hetero-GNNs. We develop heuristic algorithms that avoid the exhaustive\nsearch over the space of all databases. We propose techniques that are\nmodel-agnostic, and others that are tailored to hetero-GNNs via the notion of\nlearnable masking. Our approach is evaluated through an extensive empirical\nstudy on the RelBench collection, covering a variety of domains and different\nrecord-level tasks. The results demonstrate the usefulness of the proposed\nexplanations, as well as the efficiency of their generation.", "AI": {"tldr": "The paper introduces a framework for explaining machine-learning models applied to relational databases using view definitions that pinpoint critical database sections influencing predictions.", "motivation": "The motivation is to address the difficulty in interpreting how complex neural architectures, such as heterogeneous graph neural networks (hetero-GNNs), use relational database data for prediction.", "method": "The framework uses view definitions inspired by determinacy concepts to create explanations, employing heuristic algorithms and techniques like learnable masking tailored for hetero-GNNs.", "result": "Extensive experiments conducted on the RelBench collection show the proposed framework's explanations are both useful and efficient across diverse tasks and domains.", "conclusion": "The study validates the effectiveness of the explanation framework in improving human-understandable insights into machine-learning models operating on relational databases."}}
{"id": "2509.08947", "pdf": "https://arxiv.org/pdf/2509.08947", "abs": "https://arxiv.org/abs/2509.08947", "authors": ["Yancheng Cai", "Robert Wanat", "Rafal Mantiuk"], "title": "CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by SIGGRAPH Asia 2025", "summary": "Accurate measurement of images produced by electronic displays is critical\nfor the evaluation of both traditional and computational displays. Traditional\ndisplay measurement methods based on sparse radiometric sampling and fitting a\nmodel are inadequate for capturing spatially varying display artifacts, as they\nfail to capture high-frequency and pixel-level distortions. While cameras offer\nsufficient spatial resolution, they introduce optical, sampling, and\nphotometric distortions. Furthermore, the physical measurement must be combined\nwith a model of a visual system to assess whether the distortions are going to\nbe visible. To enable perceptual assessment of displays, we propose a\ncombination of a camera-based reconstruction pipeline with a visual difference\npredictor, which account for both the inaccuracy of camera measurements and\nvisual difference prediction. The reconstruction pipeline combines HDR image\nstacking, MTF inversion, vignetting correction, geometric undistortion,\nhomography transformation, and color correction, enabling cameras to function\nas precise display measurement instruments. By incorporating a Visual\nDifference Predictor (VDP), our system models the visibility of various stimuli\nunder different viewing conditions for the human visual system. We validate the\nproposed CameraVDP framework through three applications: defective pixel\ndetection, color fringing awareness, and display non-uniformity evaluation. Our\nuncertainty analysis framework enables the estimation of the theoretical upper\nbound for defect pixel detection performance and provides confidence intervals\nfor VDP quality scores.", "AI": {"tldr": "The paper proposes CameraVDP, a system using cameras and visual difference prediction to analyze display artifacts and assess visibility under varying conditions.", "motivation": "Traditional methods inadequately capture pixel-level and high-frequency distortions in display measurements.", "method": "A pipeline integrates camera corrections (HDR stacking, MTF inversion, etc.) with a Visual Difference Predictor for human visual system modeling.", "result": "The framework was validated on defective pixel detection, color fringing awareness, and display non-uniformity evaluation, with uncertainty analysis for performance bounds.", "conclusion": "CameraVDP improves display measurements by enabling accurate and perceptual assessments using cameras, accounting for both camera inaccuracies and human perception."}}
{"id": "2509.09414", "pdf": "https://arxiv.org/pdf/2509.09414", "abs": "https://arxiv.org/abs/2509.09414", "authors": ["Alan Said", "Maria Soledad Pera", "Michael D. Ekstrand"], "title": "We're Still Doing It (All) Wrong: Recommender Systems, Fifteen Years Later", "categories": ["cs.IR", "cs.AI"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  accepted for publication in the Beyond Algorithms: Reclaiming the\n  Interdisciplinary Roots of Recommender Systems Workshop (BEYOND 2025),\n  September 26th, 2025, co-located with the 19th ACM Recommender Systems\n  Conference, Prague, Czech Republic", "summary": "In 2011, Xavier Amatriain sounded the alarm: recommender systems research was\n\"doing it all wrong\" [1]. His critique, rooted in statistical misinterpretation\nand methodological shortcuts, remains as relevant today as it was then. But\nrather than correcting course, we added new layers of sophistication on top of\nthe same broken foundations. This paper revisits Amatriain's diagnosis and\nargues that many of the conceptual, epistemological, and infrastructural\nfailures he identified still persist, in more subtle or systemic forms. Drawing\non recent work in reproducibility, evaluation methodology, environmental\nimpact, and participatory design, we showcase how the field's accelerating\ncomplexity has outpaced its introspection. We highlight ongoing community-led\ninitiatives that attempt to shift the paradigm, including workshops, evaluation\nframeworks, and calls for value-sensitive and participatory research. At the\nsame time, we contend that meaningful change will require not only new metrics\nor better tooling, but a fundamental reframing of what recommender systems\nresearch is for, who it serves, and how knowledge is produced and validated.\nOur call is not just for technical reform, but for a recommender systems\nresearch agenda grounded in epistemic humility, human impact, and sustainable\npractice.", "AI": {"tldr": "The paper revisits and critiques persisting issues in recommender systems research, advocating for a paradigm shift towards humility, human impact, and sustainability.", "motivation": "The paper aims to address ongoing fundamental issues in recommender systems research, such as statistical misinterpretations and methodological shortcuts, which have lingered since Xavier Amatriain's 2011 critique.", "method": "The authors examine current challenges by analyzing recent work on reproducibility, evaluation methodology, environmental impact, and participatory design, while also highlighting community initiatives and alternative research paradigms.", "result": "The paper identifies persistent flaws in the field, demonstrates how complexity has outpaced introspection, and showcases various community efforts attempting to propose solutions.", "conclusion": "The authors argue for a systemic reframing of recommender systems research that centers on epistemic humility, human impact, and sustainable practices rather than solely technical fixes or improvements."}}
{"id": "2509.09513", "pdf": "https://arxiv.org/pdf/2509.09513", "abs": "https://arxiv.org/abs/2509.09513", "authors": ["Quentin Uhl", "Tommaso Pavan", "Julianna Gerold", "Kwok-Shing Chan", "Yohan Jun", "Shohei Fujita", "Aneri Bhatt", "Yixin Ma", "Qiaochu Wang", "Hong-Hsi Lee", "Susie Y. Huang", "Berkin Bilgic", "Ileana Jelescu"], "title": "Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner", "categories": ["physics.med-ph", "cs.AI", "cs.CV", "cs.LG", "eess.IV", "J.3"], "comment": "Submitted to IEEE Transactions on Medical Imaging (TMI). This\n  all-in-one version includes supplementary materials. 18 pages, 14 figures, 2\n  tables", "summary": "The diffusion MRI Neurite Exchange Imaging model offers a promising framework\nfor probing gray matter microstructure by estimating parameters such as\ncompartment sizes, diffusivities, and inter-compartmental water exchange time.\nHowever, existing protocols require long scan times. This study proposes a\nreduced acquisition scheme for the Connectome 2.0 scanner that preserves model\naccuracy while substantially shortening scan duration. We developed a\ndata-driven framework using explainable artificial intelligence with a guided\nrecursive feature elimination strategy to identify an optimal 8-feature subset\nfrom a 15-feature protocol. The performance of this optimized protocol was\nvalidated in vivo and benchmarked against the full acquisition and alternative\nreduction strategies. Parameter accuracy, preservation of anatomical contrast,\nand test-retest reproducibility were assessed. The reduced protocol yielded\nparameter estimates and cortical maps comparable to the full protocol, with low\nestimation errors in synthetic data and minimal impact on test-retest\nvariability. Compared to theory-driven and heuristic reduction schemes, the\noptimized protocol demonstrated superior robustness, reducing the deviation in\nwater exchange time estimates by over two-fold. In conclusion, this hybrid\noptimization framework enables viable imaging of neurite exchange in 14 minutes\nwithout loss of parameter fidelity. This approach supports the broader\napplication of exchange-sensitive diffusion magnetic resonance imaging in\nneuroscience and clinical research, and offers a generalizable method for\ndesigning efficient acquisition protocols in biophysical parameter mapping.", "AI": {"tldr": "This paper proposes and validates a reduced imaging protocol for diffusion MRI Neurite Exchange Imaging, optimizing accuracy while significantly decreasing scan times.", "motivation": "Existing diffusion MRI protocols require long scan durations, limiting their feasibility in probing gray matter microstructure.", "method": "An optimized 8-feature subset was identified from a 15-feature protocol using explainable AI and guided recursive feature elimination. Performance was validated in vivo and benchmarked against full and alternative reduction approaches.", "result": "The optimized protocol produced parameter estimates and cortical maps comparable to the original, exhibiting reduced estimation errors and improved robustness over other strategies.", "conclusion": "The hybrid optimization enabled reliable neurite exchange imaging in just 14 minutes, facilitating wider application in neuroscience and clinical research, while offering a generalizable optimization framework."}}
{"id": "2509.08973", "pdf": "https://arxiv.org/pdf/2509.08973", "abs": "https://arxiv.org/abs/2509.08973", "authors": ["Harshit Agrawal", "Ari Hietanen", "Simo S\u00e4rkk\u00e4"], "title": "Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "Purpose: Scatter artifacts drastically degrade the image quality of cone-beam\ncomputed tomography (CBCT) scans. Although deep learning-based methods show\npromise in estimating scatter from CBCT measurements, their deployment in\nmobile CBCT systems or edge devices is still limited due to the large memory\nfootprint of the networks. This study addresses the issue by applying networks\nat varying resolutions and suggesting an optimal one, based on speed and\naccuracy.\n  Methods: First, the reconstruction error in down-up sampling of CBCT scatter\nsignal was examined at six resolutions by comparing four interpolation methods.\nNext, a recent state-of-the-art method was trained across five image\nresolutions and evaluated for the reductions in floating-point operations\n(FLOPs), inference times, and GPU memory requirements.\n  Results: Reducing the input size and network parameters achieved a 78-fold\nreduction in FLOPs compared to the baseline method, while maintaining comarable\nperformance in terms of mean-absolute-percentage-error (MAPE) and\nmean-square-error (MSE). Specifically, the MAPE decreased to 3.85% compared to\n4.42%, and the MSE decreased to 1.34 \\times 10^{-2} compared to 2.01 \\times\n10^{-2}. Inference time and GPU memory usage were reduced by factors of 16 and\n12, respectively. Further experiments comparing scatter-corrected\nreconstructions on a large, simulated dataset and real CBCT scans from water\nand Sedentex CT phantoms clearly demonstrated the robustness of our method.\n  Conclusion: This study highlights the underappreciated role of downsampling\nin deep learning-based scatter estimation. The substantial reduction in FLOPs\nand GPU memory requirements achieved by our method enables scatter correction\nin resource-constrained environments, such as mobile CBCT and edge devices.", "AI": {"tldr": "The paper tackles scatter artifact issues in CBCT systems by optimizing deep learning networks for speed, accuracy, and memory efficiency, enabling their usage in resource-constrained devices.", "motivation": "The motivation is to address limitations in applying deep learning scatter correction methods to mobile CBCT systems or edge devices due to high memory and computational requirements.", "method": "The study evaluates reconstruction errors across six resolutions, implements a state-of-the-art method at five resolutions, and measures reductions in FLOPs, inference times, and GPU memory usage while assessing scatter correction performance.", "result": "The optimized method achieves a 78-fold reduction in FLOPs and dramatically reduces inference times and GPU memory demands, while maintaining comparable error metrics (e.g., MAPE reduced to 3.85%). Robustness is demonstrated using simulated and real-world datasets.", "conclusion": "Downsampling techniques significantly reduce computational demands, enabling scatter correction for mobile and edge CBCT systems without compromising performance."}}
{"id": "2509.09424", "pdf": "https://arxiv.org/pdf/2509.09424", "abs": "https://arxiv.org/abs/2509.09424", "authors": ["Zhiyu He", "Maojiang Wang", "Xinwen Gao", "Yuchuan Luo", "Lin Liu", "Shaojing Fu"], "title": "ENSI: Efficient Non-Interactive Secure Inference for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Secure inference enables privacy-preserving machine learning by leveraging\ncryptographic protocols that support computations on sensitive user data\nwithout exposing it. However, integrating cryptographic protocols with large\nlanguage models (LLMs) presents significant challenges, as the inherent\ncomplexity of these protocols, together with LLMs' massive parameter scale and\nsophisticated architectures, severely limits practical usability. In this work,\nwe propose ENSI, a novel non-interactive secure inference framework for LLMs,\nbased on the principle of co-designing the cryptographic protocols and LLM\narchitecture. ENSI employs an optimized encoding strategy that seamlessly\nintegrates CKKS scheme with a lightweight LLM variant, BitNet, significantly\nreducing the computational complexity of encrypted matrix multiplications. In\nresponse to the prohibitive computational demands of softmax under homomorphic\nencryption (HE), we pioneer the integration of the sigmoid attention mechanism\nwith HE as a seamless, retraining-free alternative. Furthermore, by embedding\nthe Bootstrapping operation within the RMSNorm process, we efficiently refresh\nciphertexts while markedly decreasing the frequency of costly bootstrapping\ninvocations. Experimental evaluations demonstrate that ENSI achieves\napproximately an 8x acceleration in matrix multiplications and a 2.6x speedup\nin softmax inference on CPU compared to state-of-the-art method, with the\nproportion of bootstrapping is reduced to just 1%.", "AI": {"tldr": "ENSI is a novel framework that combines cryptographic protocols and redesigned LLM architectures to enable faster, non-interactive secure inference.", "motivation": "The paper aims to address the challenges in integrating secure cryptographic protocols with Large Language Models (LLMs), which often face limitations due to high computational costs and architectural complexity.", "method": "ENSI proposes optimizations by co-designing the cryptographic protocols with a lightweight LLM architecture (BitNet), introducing techniques such as sigmoid attention and embedding bootstrapping into RMSNorm.", "result": "Experiments demonstrate ENSI achieves an 8x acceleration in matrix multiplications and a 2.6x speedup in softmax operations, with bootstrapping reduced to only 1%.", "conclusion": "ENSI makes significant progress in secure inference for LLMs by reducing computational overhead, thereby improving usability and efficiency while maintaining security."}}
{"id": "2509.09550", "pdf": "https://arxiv.org/pdf/2509.09550", "abs": "https://arxiv.org/abs/2509.09550", "authors": ["Harry Julia", "Rachel Beeson", "Lohith Konathala", "Johanna Ulin", "Jiameng Gao"], "title": "Finite Scalar Quantization Enables Redundant and Transmission-Robust Neural Audio Compression at Low Bit-rates", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Neural Audio Codecs (NACs) have become increasingly adopted in speech\nprocessing tasks due to their excellent rate-distortion performance and\ncompatibility with Large Language Models (LLMs) as discrete feature\nrepresentations for audio generation. While most existing codecs rely on\nResidual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has\nrecently emerged as a compelling alternative that simplifies training and\nnatively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC,\nand show that FSQ encodes baked-in redundancy which produces an encoding which\nis robust when transmitted through noisy channels. First, through an encoder\ndistillation experiment, we show that two different encoders can learn to\nencode identical audio into vastly different code sequences whilst maintaining\ncomparable reconstruction quality with the same quantizer and decoder. Second,\nwe demonstrate that FSQ has vastly superior bit-level perturbation robustness\nby comparing the performance of RVQ and FSQ codecs when simulating the\ntransmission of code sequences through a noisy channel.", "AI": {"tldr": "This paper introduces NeuCodec, a Neural Audio Codec based on Finite Scalar Quantization (FSQ), highlighting its robustness in noisy transmission scenarios compared to Residual Vector Quantization (RVQ).", "motivation": "Neural Audio Codecs are widely used in tasks like audio generation but face challenges like robustness and encoding efficiency, prompting the exploration of FSQ as an alternative to RVQ.", "method": "The authors designed NeuCodec, an FSQ-based codec, and conducted two experiments: encoder distillation to observe encoding redundancy and a noisy channel simulation to test robustness against bit-level perturbations.", "result": "The experiments revealed that FSQ-based codecs, like NeuCodec, maintain encoding quality across different encoders and demonstrate better robustness to noisy transmissions compared to RVQ.", "conclusion": "FSQ, implemented in NeuCodec, offers promising advantages in audio encoding, producing robust and efficient codec systems suitable for varying channel conditions."}}
{"id": "2509.09488", "pdf": "https://arxiv.org/pdf/2509.09488", "abs": "https://arxiv.org/abs/2509.09488", "authors": ["Felix M\u00e4chtle", "Ashwath Shetty", "Jonas Sander", "Nils Loose", "S\u00f6ren Pirk", "Thomas Eisenbarth"], "title": "Prompt Pirates Need a Map: Stealing Seeds helps Stealing Prompts", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Diffusion models have significantly advanced text-to-image generation,\nenabling the creation of highly realistic images conditioned on textual prompts\nand seeds. Given the considerable intellectual and economic value embedded in\nsuch prompts, prompt theft poses a critical security and privacy concern. In\nthis paper, we investigate prompt-stealing attacks targeting diffusion models.\nWe reveal that numerical optimization-based prompt recovery methods are\nfundamentally limited as they do not account for the initial random noise used\nduring image generation. We identify and exploit a noise-generation\nvulnerability (CWE-339), prevalent in major image-generation frameworks,\noriginating from PyTorch's restriction of seed values to a range of $2^{32}$\nwhen generating the initial random noise on CPUs. Through a large-scale\nempirical analysis conducted on images shared via the popular platform CivitAI,\nwe demonstrate that approximately 95% of these images' seed values can be\neffectively brute-forced in 140 minutes per seed using our seed-recovery tool,\nSeedSnitch. Leveraging the recovered seed, we propose PromptPirate, a genetic\nalgorithm-based optimization method explicitly designed for prompt stealing.\nPromptPirate surpasses state-of-the-art methods, i.e., PromptStealer, P2HP, and\nCLIP-Interrogator, achieving an 8-11% improvement in LPIPS similarity.\nFurthermore, we introduce straightforward and effective countermeasures that\nrender seed stealing, and thus optimization-based prompt stealing, ineffective.\nWe have disclosed our findings responsibly and initiated coordinated mitigation\nefforts with the developers to address this critical vulnerability.", "AI": {"tldr": "This paper analyzes prompt-stealing attacks in text-to-image diffusion models and exposes vulnerabilities related to random noise generation, proposing both an advanced attack method and countermeasures.", "motivation": "Prompt theft, which poses intellectual property and security risks, is a critical concern in text-to-image diffusion models, requiring investigation and mitigation.", "method": "The paper exposes a noise-generation vulnerability and introduces tools like SeedSnitch for seed recovery and PromptPirate, a genetic algorithm-based method for effective prompt stealing.", "result": "Using SeedSnitch, approximately 95% of seed values were brute-forced in 140 minutes per seed, and PromptPirate outperformed existing methods with an 8-11% improvement in LPIPS similarity.", "conclusion": "The findings highlight the need for robust countermeasures to address underlying vulnerabilities in diffusion models, and the authors propose effective steps to mitigate risks."}}
{"id": "2509.09564", "pdf": "https://arxiv.org/pdf/2509.09564", "abs": "https://arxiv.org/abs/2509.09564", "authors": ["Meghan Wilkinson", "Robert H Thomson"], "title": "What Does Normal Even Mean? Evaluating Benign Traffic in Intrusion Detection Datasets", "categories": ["cs.CR", "cs.LG"], "comment": "10 pages; accepted to SBP-BRiMS 2025 Poster Session", "summary": "Supervised machine learning techniques rely on labeled data to achieve high\ntask performance, but this requires the labels to capture some meaningful\ndifferences in the underlying data structure. For training network intrusion\ndetection algorithms, most datasets contain a series of attack classes and a\nsingle large benign class which captures all non-attack network traffic. A\nreview of intrusion detection papers and guides that explicitly state their\ndata preprocessing steps identified that the majority took the labeled\ncategories of the dataset at face value when training their algorithms. The\npresent paper evaluates the structure of benign traffic in several common\nintrusion detection datasets (NSL-KDD, UNSW-NB15, and CIC-IDS 2017) and\ndetermines whether there are meaningful sub-categories within this traffic\nwhich may improve overall multi-classification performance using common machine\nlearning techniques. We present an overview of some unsupervised clustering\ntechniques (e.g., HDBSCAN, Mean Shift Clustering) and show how they\ndifferentially cluster the benign traffic space.", "AI": {"tldr": "The paper reviews the structure of benign network traffic in intrusion detection datasets and explores using unsupervised clustering to identify meaningful sub-categories within this traffic.", "motivation": "The paper is motivated by recognizing that labeled categories in intrusion detection datasets may oversimplify benign traffic, limiting the performance of supervised learning techniques.", "method": "The authors evaluate intrusion datasets (NSL-KDD, UNSW-NB15, CIC-IDS 2017) and apply unsupervised clustering techniques like HDBSCAN and Mean Shift to examine the structure of benign traffic.", "result": "Unsupervised clustering shows potential in identifying meaningful sub-categories within benign traffic, offering insights to improve multi-classification performance.", "conclusion": "Accounting for nuanced benign traffic sub-categories can improve intrusion detection systems' performance by addressing the limitations of current labeling practices."}}
{"id": "2509.09508", "pdf": "https://arxiv.org/pdf/2509.09508", "abs": "https://arxiv.org/abs/2509.09508", "authors": ["Avinash Agarwal", "Manisha J. Nene"], "title": "Incorporating AI Incident Reporting into Telecommunications Law and Policy: Insights from India", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "16 pages, 2 figures, 1 table", "summary": "The integration of artificial intelligence (AI) into telecommunications\ninfrastructure introduces novel risks, such as algorithmic bias and\nunpredictable system behavior, that fall outside the scope of traditional\ncybersecurity and data protection frameworks. This paper introduces a precise\ndefinition and a detailed typology of telecommunications AI incidents,\nestablishing them as a distinct category of risk that extends beyond\nconventional cybersecurity and data protection breaches. It argues for their\nrecognition as a distinct regulatory concern. Using India as a case study for\njurisdictions that lack a horizontal AI law, the paper analyzes the country's\nkey digital regulations. The analysis reveals that India's existing legal\ninstruments, including the Telecommunications Act, 2023, the CERT-In Rules, and\nthe Digital Personal Data Protection Act, 2023, focus on cybersecurity and data\nbreaches, creating a significant regulatory gap for AI-specific operational\nincidents, such as performance degradation and algorithmic bias. The paper also\nexamines structural barriers to disclosure and the limitations of existing AI\nincident repositories. Based on these findings, the paper proposes targeted\npolicy recommendations centered on integrating AI incident reporting into\nIndia's existing telecom governance. Key proposals include mandating reporting\nfor high-risk AI failures, designating an existing government body as a nodal\nagency to manage incident data, and developing standardized reporting\nframeworks. These recommendations aim to enhance regulatory clarity and\nstrengthen long-term resilience, offering a pragmatic and replicable blueprint\nfor other nations seeking to govern AI risks within their existing sectoral\nframeworks.", "AI": {"tldr": "The paper identifies AI-specific risks in telecommunications, beyond traditional cybersecurity issues, using India as a case study, and provides policy recommendations to address regulatory gaps.", "motivation": "To address the lack of regulatory frameworks for AI-specific risks in telecommunications, particularly for jurisdictions without dedicated AI laws.", "method": "Analyzing India's legal frameworks and identifying gaps in addressing AI incidents. Proposing policies for AI incident reporting and regulatory integration.", "result": "The study found regulatory gaps in India's laws, which fail to adequately address AI-specific risks like bias and performance degradation.", "conclusion": "Targeted policies, such as mandatory AI incident reporting and standardized frameworks, are necessary to integrate AI governance into existing regulations, providing a roadmap for other jurisdictions."}}
{"id": "2509.09227", "pdf": "https://arxiv.org/pdf/2509.09227", "abs": "https://arxiv.org/abs/2509.09227", "authors": ["Yinzheng Zhao", "Zhihao Zhao", "Rundong Jiang", "Louisa Sackewitz", "Quanmin Liang", "Mathias Maier", "Daniel Zapp", "Peter Charbel Issa", "Mohammad Ali Nasseri"], "title": "Dynamic Structural Recovery Parameters Enhance Prediction of Visual Outcomes After Macular Hole Surgery", "categories": ["eess.IV", "cs.CV", "I.4.6"], "comment": "TVST", "summary": "Purpose: To introduce novel dynamic structural parameters and evaluate their\nintegration within a multimodal deep learning (DL) framework for predicting\npostoperative visual recovery in idiopathic full-thickness macular hole (iFTMH)\npatients. Methods: We utilized a publicly available longitudinal OCT dataset at\nfive stages (preoperative, 2 weeks, 3 months, 6 months, and 12 months). A stage\nspecific segmentation model delineated related structures, and an automated\npipeline extracted quantitative, composite, qualitative, and dynamic features.\nBinary logistic regression models, constructed with and without dynamic\nparameters, assessed their incremental predictive value for best-corrected\nvisual acuity (BCVA). A multimodal DL model combining clinical variables,\nOCT-derived features, and raw OCT images was developed and benchmarked against\nregression models. Results: The segmentation model achieved high accuracy\nacross all timepoints (mean Dice > 0.89). Univariate and multivariate analyses\nidentified base diameter, ellipsoid zone integrity, and macular hole area as\nsignificant BCVA predictors (P < 0.05). Incorporating dynamic recovery rates\nconsistently improved logistic regression AUC, especially at the 3-month\nfollow-up. The multimodal DL model outperformed logistic regression, yielding\nhigher AUCs and overall accuracy at each stage. The difference is as high as\n0.12, demonstrating the complementary value of raw image volume and dynamic\nparameters. Conclusions: Integrating dynamic parameters into the multimodal DL\nmodel significantly enhances the accuracy of predictions. This fully automated\nprocess therefore represents a promising clinical decision support tool for\npersonalized postoperative management in macular hole surgery.", "AI": {"tldr": "This study introduces dynamic structural parameters and their integration into a deep learning model, which significantly improves predictions of visual recovery in macular hole patients post-surgery.", "motivation": "To develop better tools for predicting postoperative visual outcomes in macular hole patients by integrating structural dynamics and machine learning.", "method": "Longitudinal OCT data was analyzed using segmentation, feature extraction pipelines, logistic regression models, and a multimodal DL framework combining clinical data, derived features, and raw images.", "result": "Dynamic parameters enhanced predictive accuracy in models, achieving high correlation with visual recovery metrics. The multimodal DL model outperformed logistic regression in accuracy and AUC, showing superior prediction capabilities.", "conclusion": "Dynamic structural parameters improve deep learning model predictions, offering a promising fully automated tool for macular hole surgery postoperative management."}}
{"id": "2509.09494", "pdf": "https://arxiv.org/pdf/2509.09494", "abs": "https://arxiv.org/abs/2509.09494", "authors": ["Zhuoyuan Li", "Jiacheng Li", "Yao Li", "Jialin Li", "Li Li", "Dong Liu", "Feng Wu"], "title": "In-Loop Filtering Using Learned Look-Up Tables for Video Coding", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "25 pages", "summary": "In-loop filtering (ILF) is a key technology in video coding standards to\nreduce artifacts and enhance visual quality. Recently, neural network-based ILF\nschemes have achieved remarkable coding gains, emerging as a powerful candidate\nfor next-generation video coding standards. However, the use of deep neural\nnetworks (DNN) brings significant computational and time complexity or high\ndemands for dedicated hardware, making it challenging for general use. To\naddress this limitation, we study a practical ILF solution by adopting look-up\ntables (LUTs). After training a DNN with a restricted reference range for ILF,\nall possible inputs are traversed, and the output values of the DNN are cached\ninto LUTs. During the coding process, the filtering process is performed by\nsimply retrieving the filtered pixel through locating the input pixels and\ninterpolating between the cached values, instead of relying on heavy inference\ncomputations. In this paper, we propose a universal LUT-based ILF framework,\ntermed LUT-ILF++. First, we introduce the cooperation of multiple kinds of\nfiltering LUTs and propose a series of customized indexing mechanisms to enable\nbetter filtering reference perception with limited storage consumption. Second,\nwe propose the cross-component indexing mechanism to enable the filtering of\ndifferent color components jointly. Third, in order to make our solution\npractical for coding uses, we propose the LUT compaction scheme to enable the\nLUT pruning, achieving a lower storage cost of the entire solution. The\nproposed framework is implemented in the VVC reference software. Experimental\nresults show that the proposed framework achieves on average 0.82%/2.97%/1.63%\nand 0.85%/4.11%/2.06% bitrate reduction for common test sequences, under the AI\nand RA configurations, respectively. Compared to DNN-based solutions, our\nproposed solution has much lower time complexity and storage cost.", "AI": {"tldr": "This paper introduces LUT-ILF++, a low-complexity, neural network-inspired method using look-up tables to improve in-loop filtering in video coding, achieving significant bitrate reduction while maintaining low computational and storage costs.", "motivation": "To overcome the limitations of DNN-based ILF solutions in video coding that have high computational complexity and hardware demands, making them unsuitable for general use.", "method": "The proposed LUT-ILF++ framework replaces heavy DNN-based computations with look-up tables, leveraging mechanisms like multiple LUT cooperation, customized indexing, cross-component indexing, and LUT compaction to balance storage use and performance.", "result": "The implementation in the VVC reference software shows average bitrate reductions of 0.82%/2.97%/1.63% (AI configuration) and 0.85%/4.11%/2.06% (RA configuration) on test sequences, with significantly lower complexity and storage requirements compared to DNN solutions.", "conclusion": "By leveraging LUTs and innovative indexing mechanisms, LUT-ILF++ offers a practical and efficient solution for ILF in video coding, balancing quality improvement, computational efficiency, and storage usage."}}
