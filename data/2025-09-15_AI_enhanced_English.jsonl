{"id": "2509.09738", "pdf": "https://arxiv.org/pdf/2509.09738", "abs": "https://arxiv.org/abs/2509.09738", "authors": ["Umut Eser", "Yael Gozin", "L. Jay Stallons", "Ari Caroline", "Martin Preusse", "Brandon Rice", "Scott Wright", "Andrew Robertson"], "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing", "categories": ["cs.AI", "q-bio.QM", "I.2.7"], "comment": null, "summary": "Background: Investigational New Drug (IND) application preparation is\ntime-intensive and expertise-dependent, slowing early clinical development.\nObjective: To evaluate whether a large language model (LLM) platform (AutoIND)\ncan reduce first-draft composition time while maintaining document quality in\nregulatory submissions. Methods: Drafting times for IND nonclinical written\nsummaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly\nrecorded. For comparison, manual drafting times for IND summaries previously\ncleared by the U.S. FDA were estimated from the experience of regulatory\nwriters ($\\geq$6 years) and used as industry-standard benchmarks. Quality was\nassessed by a blinded regulatory writing assessor using seven pre-specified\ncategories: correctness, completeness, conciseness, consistency, clarity,\nredundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a\npercentage. A critical regulatory error was defined as any misrepresentation or\nomission likely to alter regulatory interpretation (e.g., incorrect NOAEL,\nomission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced\ninitial drafting time by $\\sim$97% (from $\\sim$100 h to 3.7 h for 18,870\npages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).\nQuality scores were 69.6\\% and 77.9\\% for IND-1 and IND-2. No critical\nregulatory errors were detected, but deficiencies in emphasis, conciseness, and\nclarity were noted. Conclusions: AutoIND can dramatically accelerate IND\ndrafting, but expert regulatory writers remain essential to mature outputs to\nsubmission-ready quality. Systematic deficiencies identified provide a roadmap\nfor targeted model improvements.", "AI": {"tldr": "This study evaluates AutoIND, a large language model platform, which reduced IND drafting time by around 97% while maintaining decent quality with no critical regulatory errors.", "motivation": "The paper aims to address the inefficiency and expertise-dependence associated with preparing IND applications, which slows down early clinical development.", "method": "The study assessed AutoIND\u2019s performance in generating first drafts of IND nonclinical summaries. Drafting times and quality were measured against industry-standard benchmarks and evaluated using predefined quality criteria.", "result": "AutoIND reduced drafting times significantly (from ~100 hours to 2.6\u20133.7 hours) and scored 69.6%\u201377.9% in quality evaluation, with noted deficiencies in emphasis, conciseness, and clarity.", "conclusion": "AutoIND speeds up IND drafting considerably but requires expert intervention for high-quality final submissions. Identified deficiencies provide directions for improving the model."}}
{"id": "2509.09775", "pdf": "https://arxiv.org/pdf/2509.09775", "abs": "https://arxiv.org/abs/2509.09775", "authors": ["Aleksandr Boldachev"], "title": "Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.SE"], "comment": "22 pages, 6 figures", "summary": "This paper presents boldsea, Boldachev's semantic-event approach -- an\narchitecture for modeling complex dynamic systems using executable ontologies\n-- semantic models that act as dynamic structures, directly controlling process\nexecution. We demonstrate that integrating event semantics with a dataflow\narchitecture addresses the limitations of traditional Business Process\nManagement (BPM) systems and object-oriented semantic technologies. The paper\npresents the formal BSL (boldsea Semantic Language), including its BNF grammar,\nand outlines the boldsea-engine's architecture, which directly interprets\nsemantic models as executable algorithms without compilation. It enables the\nmodification of event models at runtime, ensures temporal transparency, and\nseamlessly merges data and business logic within a unified semantic framework.", "AI": {"tldr": "The paper introduces boldsea, a semantic-event approach with executable ontologies modeling dynamic systems, enabling runtime modifications and merging data with business logic.", "motivation": "Existing BPM systems and semantic technologies face limitations in effectively integrating data processing with dynamic business processes; addressing these gaps is critical.", "method": "Developed the BSL language (formal grammar included), and outlined the boldsea-engine architecture enabling runtime-executable semantic models without compilation.", "result": "The approach allows dynamic event models to be modified at runtime, offers temporal transparency, and integrates data and business logic within a unified framework.", "conclusion": "Integrating event semantics with a dataflow architecture provides a powerful alternative to traditional BPM and semantic systems, enhancing flexibility and system integration."}}
{"id": "2509.09790", "pdf": "https://arxiv.org/pdf/2509.09790", "abs": "https://arxiv.org/abs/2509.09790", "authors": ["Yuxuan Li", "Victor Zhong"], "title": "How well can LLMs provide planning feedback in grounded environments?", "categories": ["cs.AI"], "comment": null, "summary": "Learning to plan in grounded environments typically requires carefully\ndesigned reward functions or high-quality annotated demonstrations. Recent\nworks show that pretrained foundation models, such as large language models\n(LLMs) and vision language models (VLMs), capture background knowledge helpful\nfor planning, which reduces the amount of reward design and demonstrations\nneeded for policy learning. We evaluate how well LLMs and VLMs provide feedback\nacross symbolic, language, and continuous control environments. We consider\nprominent types of feedback for planning including binary feedback, preference\nfeedback, action advising, goal advising, and delta action feedback. We also\nconsider inference methods that impact feedback performance, including\nin-context learning, chain-of-thought, and access to environment dynamics. We\nfind that foundation models can provide diverse high-quality feedback across\ndomains. Moreover, larger and reasoning models consistently provide more\naccurate feedback, exhibit less bias, and benefit more from enhanced inference\nmethods. Finally, feedback quality degrades for environments with complex\ndynamics or continuous state spaces and action spaces.", "AI": {"tldr": "This paper explores how large language and vision-language models can assist planning in different environments by providing various types of feedback and evaluates their effectiveness.", "motivation": "The study aims to reduce reliance on reward design and annotated demonstrations in grounded environments by leveraging the inherent knowledge in pretrained foundation models like LLMs and VLMs for planning tasks.", "method": "The paper examines the feedback provided by LLMs and VLMs in symbolic, language, and continuous control environments. It analyzes various feedback types (binary, preference, action advising, etc.) and inference methods (in-context learning, chain-of-thought, environment dynamics) to gauge their influence.", "result": "Foundation models deliver diverse, high-quality feedback that is particularly enhanced in larger and reasoning-optimized architectures. Enhanced inference methods also improve feedback consistency.", "conclusion": "While foundation models are effective for feedback-driven planning, their performance diminishes in environments with complex dynamics or continuous state/action spaces."}}
{"id": "2509.09795", "pdf": "https://arxiv.org/pdf/2509.09795", "abs": "https://arxiv.org/abs/2509.09795", "authors": ["Arivarasan Karmegam", "Gabina Luz Bianchi", "Margarita Capretto", "Mart\u00edn Ceresa", "Antonio Fern\u00e1ndez Anta", "C\u00e9sar S\u00e1nchez"], "title": "Setchain Algorithms for Blockchain Scalability", "categories": ["cs.DC", "cs.DB", "cs.DS", "cs.PF"], "comment": null, "summary": "Setchain has been proposed to increase blockchain scalability by relaxing the\nstrict total order requirement among transactions. Setchain organizes elements\ninto a sequence of sets, referred to as epochs, so that elements within each\nepoch are unordered. In this paper, we propose and evaluate three distinct\nSetchain algorithms, that leverage an underlying block-based ledger. Vanilla is\na basic implementation that serves as a reference point. Compresschain\naggregates elements into batches, and compresses these batches before appending\nthem as epochs in the ledger. Hashchain converts batches into fixed-length\nhashes which are appended as epochs in the ledger. This requires Hashchain to\nuse a distributed service to obtain the batch contents from its hash. To allow\nlight clients to safely interact with only one server, the proposed algorithms\nmaintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the\nhash of the epoch, cryptographically signed by a server. A client can verify\nthe correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum\nnumber of Byzantine servers assumed). All three Setchain algorithms are\nimplemented on top of the CometBFT blockchain application platform. We\nconducted performance evaluations across various configurations, using clusters\nof four, seven, and ten servers. Our results show that the Setchain algorithms\nreach orders of magnitude higher throughput than the underlying blockchain, and\nachieve finality with latency below 4 seconds.", "AI": {"tldr": "The paper introduces Setchain, a blockchain scalability solution that organizes elements in unordered epochs. Three algorithms (Vanilla, Compresschain, Hashchain) are proposed, showing increased throughput and low latency compared to traditional blockchains.", "motivation": "To address blockchain scalability issues by reducing the total order requirement among transactions and organizing them into unordered epochs.", "method": "Three algorithms, Vanilla, Compresschain, and Hashchain, are built on the CometBFT platform to implement Setchain. These algorithms include support for epoch-proofs to ensure verification and utilize server clusters for performance evaluation.", "result": "The Setchain algorithms significantly improve throughput compared to the traditional blockchain and achieve transaction finality with latency of under 4 seconds.", "conclusion": "The proposed Setchain algorithms provide scalable and efficient blockchain solutions, demonstrating orders of magnitude improvement in throughput while maintaining low latency."}}
{"id": "2509.09794", "pdf": "https://arxiv.org/pdf/2509.09794", "abs": "https://arxiv.org/abs/2509.09794", "authors": ["Jackson Eshbaugh", "Chetan Tiwari", "Jorge Silveyra"], "title": "A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes", "categories": ["cs.AI", "cs.LG"], "comment": "44 pages; 2 appendices; 9 figures; 1 table. Code available at\n  https://github.com/Lafayette-EshbaughSilveyra-Group/synthetic-homes", "summary": "Computational models have emerged as powerful tools for energy modeling\nresearch, touting scalability and quantitative results. However, these models\nrequire a plethora of data, some of which is inaccessible, expensive, or raises\nprivacy concerns. We introduce a modular multimodal framework to produce this\ndata from publicly accessible residential information and images using\ngenerative artificial intelligence (AI). Additionally, we provide a pipeline\ndemonstrating this framework, and we evaluate its generative AI components. Our\nexperiments show that our framework's use of AI avoids common issues with\ngenerative models. Our framework produces realistic, labeled data. By reducing\ndependence on costly or restricted data sources, we pave a path towards more\naccessible and reproducible research.", "AI": {"tldr": "The paper introduces a modular multimodal framework using generative AI to produce data for energy modeling from public residential information and images.", "motivation": "Energy modeling research faces challenges in acquiring inaccessible, expensive, or privacy-sensitive data.", "method": "Developed a modular multimodal framework leveraging generative AI to generate realistic labeled data from accessible sources, and provided a pipeline to evaluate the framework's generative AI components.", "result": "The framework generates realistic data while avoiding common issues of generative models, making it more accessible and reproducible.", "conclusion": "The framework helps reduce reliance on costly or restricted data sources, advancing energy modeling research accessibility and reproducibility."}}
{"id": "2509.09868", "pdf": "https://arxiv.org/pdf/2509.09868", "abs": "https://arxiv.org/abs/2509.09868", "authors": ["Yunhao Zhang", "Haobin Ni", "Soumya Basu", "Shir Cohen", "Maofan Yin", "Lorenzo Alvisi", "Robbert van Renesse", "Qi Chen", "Lidong Zhou"], "title": "Ordered Consensus with Equal Opportunity", "categories": ["cs.DC", "cs.CR", "cs.MA"], "comment": null, "summary": "The specification of state machine replication (SMR) has no requirement on\nthe final total order of commands. In blockchains based on SMR, however, order\nmatters, since different orders could provide their clients with different\nfinancial rewards. Ordered consensus augments the specification of SMR to\ninclude specific guarantees on such order, with a focus on limiting the\ninfluence of Byzantine nodes. Real-world ordering manipulations, however, can\nand do happen even without Byzantine replicas, typically because of factors,\nsuch as faster networks or closer proximity to the blockchain infrastructure,\nthat give some clients an unfair advantage. To address this challenge, this\npaper proceeds to extend ordered consensus by requiring it to also support\nequal opportunity, a concrete notion of fairness, widely adopted in social\nsciences. Informally, equal opportunity requires that two candidates who,\naccording to a set of criteria deemed to be relevant, are equally qualified for\na position (in our case, a specific slot in the SMR total order), should have\nan equal chance of landing it. We show how randomness can be leveraged to keep\nbias in check, and, to this end, introduce the secret random oracle (SRO), a\nsystem component that generates randomness in a fault-tolerant manner. We\ndescribe two SRO designs based, respectively, on trusted hardware and threshold\nverifiable random functions, and instantiate them in Bercow, a new ordered\nconsensus protocol that, by approximating equal opportunity up to within a\nconfigurable factor, can effectively mitigate well-known ordering attacks in\nSMR-based blockchains.", "AI": {"tldr": "The paper extends ordered consensus in state machine replication (SMR) to include equal opportunity fairness and introduces the secret random oracle (SRO) to minimize ordering manipulations in blockchains.", "motivation": "Ordered manipulations in SMR-based blockchains impact fairness and reward distribution among clients, even without Byzantine replicas, necessitating a more equitable solution.", "method": "The authors expand ordered consensus to incorporate an equal opportunity fairness criterion by leveraging randomness through a secret random oracle (SRO), designed using trusted hardware and threshold verifiable random functions, and integrate it into a protocol named Bercow.", "result": "The proposed Bercow protocol uses SRO to approximate equal opportunity fairness within a configurable factor, effectively mitigating common ordering attacks in SMR-based blockchains.", "conclusion": "Bercow demonstrates that incorporating fairness through randomness-generation methods can significantly reduce bias in blockchain ordering and improve equitable access to rewards in SMR systems."}}
{"id": "2509.10236", "pdf": "https://arxiv.org/pdf/2509.10236", "abs": "https://arxiv.org/abs/2509.10236", "authors": ["Mingyi Li", "Junmin Xiao", "Siyan Chen", "Hui Ma", "Xi Chen", "Peihua Bao", "Liang Yuan", "Guangming Tan"], "title": "Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes", "categories": ["cs.SE", "cs.PF", "cs.PL"], "comment": "33 pages, 12 figures. Submitted to OOPSLA2'25", "summary": "We introduce Stencil-Lifting, a novel system for automatically converting\nstencil kernels written in low-level languages in legacy code into semantically\nequivalent Domain-Specific Language (DSL) implementations. Targeting the\nefficiency bottlenecks of existing verified lifting systems, Stencil-Lifting\nachieves scalable stencil kernel abstraction through two key innovations.\nFirst, we propose a hierarchical recursive lifting theory that represents\nstencil kernels, structured as nested loops, using invariant subgraphs, which\nare customized data dependency graphs that capture loop-carried computation and\nstructural invariants. Each vertex in the invariant subgraph is associated with\na predicate-based summary, encoding its computational semantics. By enforcing\nself-consistency across these summaries, Stencil-Lifting ensures the derivation\nof correct loop invariants and postconditions for nested loops, eliminating the\nneed for external verification. Second, we develop a hierarchical recursive\nlifting algorithm that guarantees termination through a convergent recursive\nprocess, avoiding the inefficiencies of search-based synthesis. The algorithm\nefficiently derives the valid summaries of stencil kernels, and its\ncompleteness is formally proven. We evaluate Stencil-Lifting on diverse stencil\nbenchmarks from two different suites and on four real-world applications.\nExperimental results demonstrate that Stencil-Lifting achieves 31.62$\\times$\nand 5.8$\\times$ speedups compared to the state-of-the-art verified lifting\nsystems STNG and Dexter, respectively, while maintaining full semantic\nequivalence. Our work significantly enhances the translation efficiency of\nlow-level stencil kernels to DSL implementations, effectively bridging the gap\nbetween legacy optimization techniques and modern DSL-based paradigms.", "AI": {"tldr": "Stencil-Lifting is a system that converts low-level stencil code into DSL implementations efficiently and with full semantic equivalence, achieving significant speedups over existing tools.", "motivation": "The paper aims to address inefficiencies in existing verified lifting systems for stencil kernels, particularly the need for scalable abstraction and computational correctness without relying on external verification.", "method": "Stencil-Lifting uses a hierarchical recursive lifting theory, leveraging invariant subgraphs with predicate-based summaries to encode computational semantics, and a recursive lifting algorithm to guarantee termination and correctness.", "result": "Stencil-Lifting demonstrates a 31.62\u00d7 and 5.8\u00d7 speedup over the verified lifting systems STNG and Dexter, respectively, when tested on stencil benchmarks and real-world applications, all while ensuring semantic equivalence.", "conclusion": "The proposed system improves translation efficiency from low-level stencil kernels to DSLs, offering both speed and correctness, and serves as a bridge between traditional optimization techniques and modern DSL paradigms."}}
{"id": "2509.09744", "pdf": "https://arxiv.org/pdf/2509.09744", "abs": "https://arxiv.org/abs/2509.09744", "authors": ["Mujie Liu", "Chenze Wang", "Liping Chen", "Nguyen Linh Dan Le", "Niharika Tewari", "Ting Dang", "Jiangang Ma", "Feng Xia"], "title": "Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The limited availability of labeled brain network data makes it challenging\nto achieve accurate and interpretable psychiatric diagnoses. While\nself-supervised learning (SSL) offers a promising solution, existing methods\noften rely on augmentation strategies that can disrupt crucial structural\nsemantics in brain graphs. To address this, we propose SAM-BG, a two-stage\nframework for learning brain graph representations with structural semantic\npreservation. In the pre-training stage, an edge masker is trained on a small\nlabeled subset to capture key structural semantics. In the SSL stage, the\nextracted structural priors guide a structure-aware augmentation process,\nenabling the model to learn more semantically meaningful and robust\nrepresentations. Experiments on two real-world psychiatric datasets demonstrate\nthat SAM-BG outperforms state-of-the-art methods, particularly in small-labeled\ndata settings, and uncovers clinically relevant connectivity patterns that\nenhance interpretability. Our code is available at\nhttps://github.com/mjliu99/SAM-BG.", "AI": {"tldr": "This paper proposes SAM-BG, a two-stage self-supervised learning framework, for improving psychiatric diagnoses from brain graph data by preserving structural semantics.", "motivation": "Accurate psychiatric diagnoses require labeled brain graph data, but such data is scarce. Existing SSL methods disrupt structural semantics, limiting interpretability and diagnostic accuracy.", "method": "The approach uses a two-stage process: (1) Pre-training an edge masker on a small labeled dataset to extract structural semantics, and (2) leveraging these semantics for structure-aware data augmentation in SSL, enhancing representation learning.", "result": "SAM-BG outperforms state-of-the-art models on two real-world psychiatric datasets and is particularly effective with limited labeled data. It also reveals clinically significant connectivity patterns.", "conclusion": "SAM-BG addresses challenges in psychiatric diagnosis by balancing structural semantic preservation and robust representation learning, making diagnoses more accurate and interpretable."}}
{"id": "2509.09699", "pdf": "https://arxiv.org/pdf/2509.09699", "abs": "https://arxiv.org/abs/2509.09699", "authors": ["Mingyang Li", "Viktor Schlegel", "Tingting Mu", "Warren Del-Pinto", "Goran Nenadic"], "title": "Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mapping clinical documents to standardised clinical vocabularies is an\nimportant task, as it provides structured data for information retrieval and\nanalysis, which is essential to clinical research, hospital administration and\nimproving patient care. However, manual coding is both difficult and\ntime-consuming, making it impractical at scale. Automated coding can\npotentially alleviate this burden, improving the availability and accuracy of\nstructured clinical data. The task is difficult to automate, as it requires\nmapping to high-dimensional and long-tailed target spaces, such as the\nInternational Classification of Diseases (ICD). While external knowledge\nsources have been readily utilised to enhance output code representation, the\nuse of external resources for representing the input documents has been\nunderexplored. In this work, we compute a structured representation of the\ninput documents, making use of document-level knowledge graphs (KGs) that\nprovide a comprehensive structured view of a patient's condition. The resulting\nknowledge graph efficiently represents the patient-centred input documents with\n23\\% of the original text while retaining 90\\% of the information. We assess\nthe effectiveness of this graph for automated ICD-9 coding by integrating it\ninto the state-of-the-art ICD coding architecture PLM-ICD. Our experiments\nyield improved Macro-F1 scores by up to 3.20\\% on popular benchmarks, while\nimproving training efficiency. We attribute this improvement to different types\nof entities and relationships in the KG, and demonstrate the improved\nexplainability potential of the approach over the text-only baseline.", "AI": {"tldr": "This paper proposes using document-level knowledge graphs (KGs) to represent clinical documents more effectively, improving automated ICD-9 coding performance and efficiency.", "motivation": "Automating clinical document coding is vital for scalable extraction and structuring of clinical data, addressing challenges in manual coding such as difficulty and time consumption.", "method": "The authors construct document-level knowledge graphs from clinical text to efficiently represent the input with reduced text data while maintaining information integrity, integrating this representation into the PLM-ICD architecture.", "result": "The knowledge graph representation reduced input text length by 23% while retaining 90% of information and improved Macro-F1 scores by up to 3.20% on ICD coding benchmarks.", "conclusion": "Using structured knowledge graphs for clinical document representation enhances coding accuracy, training efficiency, and explainability compared to text-only methods."}}
{"id": "2509.09720", "pdf": "https://arxiv.org/pdf/2509.09720", "abs": "https://arxiv.org/abs/2509.09720", "authors": ["Akansel Cosgun", "Lachlan Chumbley", "Benjamin J. Meyer"], "title": "Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": null, "summary": "This paper introduces the Australian Supermarket Object Set (ASOS), a\ncomprehensive dataset comprising 50 readily available supermarket items with\nhigh-quality 3D textured meshes designed for benchmarking in robotics and\ncomputer vision applications. Unlike existing datasets that rely on synthetic\nmodels or specialized objects with limited accessibility, ASOS provides a\ncost-effective collection of common household items that can be sourced from a\nmajor Australian supermarket chain. The dataset spans 10 distinct categories\nwith diverse shapes, sizes, and weights. 3D meshes are acquired by a\nstructure-from-motion techniques with high-resolution imaging to generate\nwatertight meshes. The dataset's emphasis on accessibility and real-world\napplicability makes it valuable for benchmarking object detection, pose\nestimation, and robotics applications.", "AI": {"tldr": "The paper presents the Australian Supermarket Object Set (ASOS) dataset for robotics and computer vision tasks, featuring accessible and realistic 3D meshes of common household items sourced from Australian supermarkets.", "motivation": "Existing datasets often rely on synthetic models or specialized objects, which limits their accessibility and real-world applicability.", "method": "The paper uses structure-from-motion techniques with high-resolution imaging to create watertight 3D textured meshes for 50 supermarket items across 10 categories.", "result": "The dataset provides high-quality, diverse 3D meshes suitable for benchmarking tasks like object detection, pose estimation, and various robotics applications.", "conclusion": "ASOS is a cost-effective, accessible, and practical dataset that bridges gaps in real-world applicability for robotics and computer vision research."}}
{"id": "2509.09769", "pdf": "https://arxiv.org/pdf/2509.09769", "abs": "https://arxiv.org/abs/2509.09769", "authors": ["Rutav Shah", "Shuijing Liu", "Qi Wang", "Zhenyu Jiang", "Sateesh Kumar", "Mingyo Seo", "Roberto Mart\u00edn-Mart\u00edn", "Yuke Zhu"], "title": "MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos", "categories": ["cs.RO"], "comment": "11 pages, 9 figures, 5 tables", "summary": "We aim to enable humanoid robots to efficiently solve new manipulation tasks\nfrom a few video examples. In-context learning (ICL) is a promising framework\nfor achieving this goal due to its test-time data efficiency and rapid\nadaptability. However, current ICL methods rely on labor-intensive teleoperated\ndata for training, which restricts scalability. We propose using human play\nvideos -- continuous, unlabeled videos of people interacting freely with their\nenvironment -- as a scalable and diverse training data source. We introduce\nMimicDroid, which enables humanoids to perform ICL using human play videos as\nthe only training data. MimicDroid extracts trajectory pairs with similar\nmanipulation behaviors and trains the policy to predict the actions of one\ntrajectory conditioned on the other. Through this process, the model acquired\nICL capabilities for adapting to novel objects and environments at test time.\nTo bridge the embodiment gap, MimicDroid first retargets human wrist poses\nestimated from RGB videos to the humanoid, leveraging kinematic similarity. It\nalso applies random patch masking during training to reduce overfitting to\nhuman-specific cues and improve robustness to visual differences. To evaluate\nfew-shot learning for humanoids, we introduce an open-source simulation\nbenchmark with increasing levels of generalization difficulty. MimicDroid\noutperformed state-of-the-art methods and achieved nearly twofold higher\nsuccess rates in the real world. Additional materials can be found on:\nut-austin-rpl.github.io/MimicDroid", "AI": {"tldr": "MimicDroid enables humanoid robots to learn manipulation tasks from human play videos using in-context learning, surpassing state-of-the-art methods.", "motivation": "Humanoid robots lack scalable solutions to learn diverse manipulation tasks efficiently from minimal examples.", "method": "MimicDroid trains policies using human play videos by extracting trajectory pairs of similar behaviors and retargeting human wrist poses to humanoids.", "result": "MimicDroid demonstrated higher success rates in real-world scenarios and stronger generalization in novel environments compared to existing methods.", "conclusion": "Human play videos combined with in-context learning can make humanoid robots adaptable, scalable, and efficient for manipulation tasks."}}
{"id": "2509.09853", "pdf": "https://arxiv.org/pdf/2509.09853", "abs": "https://arxiv.org/abs/2509.09853", "authors": ["Zhiyu Fan", "Kirill Vasilevski", "Dayi Lin", "Boyuan Chen", "Yihao Chen", "Zhiqing Zhong", "Jie M. Zhang", "Pinjia He", "Ahmed E. Hassan"], "title": "SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The advancement of large language models (LLMs) and code agents has\ndemonstrated significant potential to assist software engineering (SWE) tasks,\nsuch as autonomous issue resolution and feature addition. Existing AI for\nsoftware engineering leaderboards (e.g., SWE-bench) focus solely on solution\naccuracy, ignoring the crucial factor of effectiveness in a\nresource-constrained world. This is a universal problem that also exists beyond\nsoftware engineering tasks: any AI system should be more than correct - it must\nalso be cost-effective. To address this gap, we introduce SWE-Effi, a set of\nnew metrics to re-evaluate AI systems in terms of holistic effectiveness\nscores. We define effectiveness as the balance between the accuracy of outcome\n(e.g., issue resolve rate) and the resources consumed (e.g., token and time).\nIn this paper, we specifically focus on the software engineering scenario by\nre-ranking popular AI systems for issue resolution on a subset of the SWE-bench\nbenchmark using our new multi-dimensional metrics. We found that AI system's\neffectiveness depends not just on the scaffold itself, but on how well it\nintegrates with the base model, which is key to achieving strong performance in\na resource-efficient manner. We also identified systematic challenges such as\nthe \"token snowball\" effect and, more significantly, a pattern of \"expensive\nfailures\". In these cases, agents consume excessive resources while stuck on\nunsolvable tasks - an issue that not only limits practical deployment but also\ndrives up the cost of failed rollouts during RL training. Lastly, we observed a\nclear trade-off between effectiveness under the token budget and effectiveness\nunder the time budget, which plays a crucial role in managing project budgets\nand enabling scalable reinforcement learning, where fast responses are\nessential.", "AI": {"tldr": "The paper introduces SWE-Effi, a new metric that assesses AI systems' holistic effectiveness by balancing accuracy and resource consumption, especially for software engineering tasks.", "motivation": "To address the gap in existing AI evaluation methods, which focus solely on solution accuracy and neglect cost-effectiveness.", "method": "The study re-ranks popular AI systems used for issue resolution on a subset of the SWE-bench benchmark, employing new multi-dimensional metrics to measure effectiveness.", "result": "It was found that effectiveness depends on both the scaffold and its integration with the base model. Challenges like 'token snowball' and 'expensive failures' were identified, along with trade-offs between token and time budget effectiveness.", "conclusion": "The research underscores the need for considering resource efficiency along with task performance, providing valuable insights for improving AI utility in resource-sensitive contexts like software engineering."}}
{"id": "2509.09707", "pdf": "https://arxiv.org/pdf/2509.09707", "abs": "https://arxiv.org/abs/2509.09707", "authors": ["Camilo Chac\u00f3n Sartori", "Mart\u00edn Isla Pino", "Pedro Pinacho-Davidson", "Christian Blum"], "title": "LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm", "categories": ["cs.NE", "cs.AI", "cs.CL"], "comment": "Submitted to a journal for review", "summary": "Integrating Large Language Models (LLMs) within metaheuristics opens a novel\npath for solving complex combinatorial optimization problems. While most\nexisting approaches leverage LLMs for code generation to create or refine\nspecific heuristics, they often overlook the structural properties of\nindividual problem instances. In this work, we introduce a novel framework that\nintegrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the\nNP-hard Longest Run Subsequence problem. Our approach extends the\ninstance-driven heuristic bias paradigm by introducing a human-LLM\ncollaborative process to co-design and implement a set of computationally\nefficient metrics. The LLM analyzes these instance-specific metrics to generate\na tailored heuristic bias, which steers the BRKGA toward promising areas of the\nsearch space. We conduct a comprehensive experimental evaluation, including\nrigorous statistical tests, convergence and behavioral analyses, and targeted\nablation studies, comparing our method against a standard BRKGA baseline across\n1,050 generated instances of varying complexity. Results show that our\ntop-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically\nsignificant improvements over the baseline, particularly on the most complex\ninstances. Our findings confirm that leveraging an LLM to produce an a priori,\ninstance-driven heuristic bias is a valuable approach for enhancing\nmetaheuristics in complex optimization domains.", "AI": {"tldr": "The paper introduces a framework combining Large Language Models (LLMs) with a Biased Random-Key Genetic Algorithm (BRKGA) for solving highly complex combinatorial optimization problems. It focuses on creating an instance-driven heuristic approach guided by LLMs for improved performance.", "motivation": "The authors aim to fill the gap in leveraging structural properties of individual problem instances within metaheuristic approaches, addressing the limitations of current methods that primarily focus on code generation by LLMs.", "method": "The framework integrates LLMs with BRKGA by using instance-specific metrics co-designed by humans and LLMs. These metrics guide the LLM to generate tailored heuristic biases for steering the algorithm's search space.", "result": "Across 1,050 problem instances, the proposed hybrid (BRKGA+Llama-4-Maverick) demonstrated statistically significant improvements over standard BRKGA, especially in solving the most complex cases.", "conclusion": "Integrating LLMs for generating instance-driven heuristic bias is a promising approach for enhancing metaheuristics, showing meaningful improvements in complex optimization problems."}}
{"id": "2509.09774", "pdf": "https://arxiv.org/pdf/2509.09774", "abs": "https://arxiv.org/abs/2509.09774", "authors": ["Doru Thom Popovici", "Mario Vega", "Angelos Ioannou", "Fabien Chaix", "Dania Mosuli", "Blair Reasoner", "Tan Nguyen", "Xiaokun Yang", "John Shalf"], "title": "Towards An Approach to Identify Divergences in Hardware Designs for HPC Workloads", "categories": ["cs.AR"], "comment": "9 pages, 8 figures", "summary": "Developing efficient hardware accelerators for mathematical kernels used in\nscientific applications and machine learning has traditionally been a\nlabor-intensive task. These accelerators typically require low-level\nprogramming in Verilog or other hardware description languages, along with\nsignificant manual optimization effort. Recently, to alleviate this challenge,\nhigh-level hardware design tools like Chisel and High-Level Synthesis have\nemerged. However, as with any compiler, some of the generated hardware may be\nsuboptimal compared to expert-crafted designs. Understanding where these\ninefficiencies arise is crucial, as it provides valuable insights for both\nusers and tool developers. In this paper, we propose a methodology to\nhierarchically decompose mathematical kernels - such as Fourier transforms,\nmatrix multiplication, and QR factorization - into a set of common building\nblocks or primitives. Then the primitives are implemented in the different\nprogramming environments, and the larger algorithms get assembled. Furthermore,\nwe employ an automatic approach to investigate the achievable frequency and\nrequired resources. Performing this experimentation at each level will provide\nfairer comparisons between designs and offer guidance for both tool developers\nand hardware designers to adopt better practices.", "AI": {"tldr": "This paper introduces a methodology to decompose mathematical kernels into primitives and benchmark them to analyze efficiency in hardware design.", "motivation": "Efficient hardware accelerators for scientific applications require manual optimization, and understanding inefficiencies in automatic hardware design tools is a challenge.", "method": "The authors hierarchically decompose mathematical kernels into primitives, implement these in different design environments, and analyze their achievable frequency and resource requirements.", "result": "Fairer comparisons between automated and expert-crafted designs are made possible, helping identify inefficiencies in tools and offering actionable insights.", "conclusion": "This work guides developers and designers toward better practices by analyzing and benchmarking hardware designs at both primitive and algorithmic levels."}}
{"id": "2509.09855", "pdf": "https://arxiv.org/pdf/2509.09855", "abs": "https://arxiv.org/abs/2509.09855", "authors": ["Agus Sudjianto", "Denis Burakov"], "title": "An Information-Theoretic Framework for Credit Risk Modeling: Unifying Industry Practice with Statistical Theory for Fair and Interpretable Scorecards", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Credit risk modeling relies extensively on Weight of Evidence (WoE) and\nInformation Value (IV) for feature engineering, and Population Stability Index\n(PSI) for drift monitoring, yet their theoretical foundations remain\ndisconnected. We establish a unified information-theoretic framework revealing\nthese industry-standard metrics as instances of classical information\ndivergences. Specifically, we prove that IV exactly equals PSI (Jeffreys\ndivergence) computed between good and bad credit outcomes over identical bins.\nThrough the delta method applied to WoE transformations, we derive standard\nerrors for IV and PSI, enabling formal hypothesis testing and probabilistic\nfairness constraints for the first time. We formalize credit modeling's\ninherent performance-fairness trade-off as maximizing IV for predictive power\nwhile minimizing IV for protected attributes. Using automated binning with\ndepth-1 XGBoost stumps, we compare three encoding strategies: logistic\nregression with one-hot encoding, WoE transformation, and constrained XGBoost.\nAll methods achieve comparable predictive performance (AUC 0.82-0.84),\ndemonstrating that principled, information-theoretic binning outweighs encoding\nchoice. Mixed-integer programming traces Pareto-efficient solutions along the\nperformance-fairness frontier with uncertainty quantification. This framework\nbridges theory and practice, providing the first rigorous statistical\nfoundation for widely-used credit risk metrics while offering principled tools\nfor balancing accuracy and fairness in regulated environments.", "AI": {"tldr": "The paper establishes a unified information-theoretic framework for credit risk metrics (WoE, IV, PSI), revealing their connection to classical information divergences and presenting tools for balancing accuracy and fairness.", "motivation": "To address the lack of theoretical foundation for industry-standard metrics like WoE, IV, and PSI in credit risk modeling and propose a unified framework.", "method": "The paper uses information-theoretic principles, the delta method for deriving statistical errors, and automated binning techniques with optimization strategies to evaluate encoding methods.", "result": "It demonstrates that IV equals PSI under specific conditions, formulates performance-fairness trade-offs, and achieves comparable predictive performance across three methods (AUC 0.82-0.84).", "conclusion": "The framework bridges theory and practice by establishing a rigorous statistical foundation for credit risk metrics and tools for accuracy-fairness balance in regulated environments."}}
{"id": "2509.09810", "pdf": "https://arxiv.org/pdf/2509.09810", "abs": "https://arxiv.org/abs/2509.09810", "authors": ["Agnieszka Mensfelt", "David Tena Cucala", "Santiago Franco", "Angeliki Koutsoukou-Argyraki", "Vince Trencsenyi", "Kostas Stathis"], "title": "Towards a Common Framework for Autoformalization", "categories": ["cs.AI"], "comment": null, "summary": "Autoformalization has emerged as a term referring to the automation of\nformalization - specifically, the formalization of mathematics using\ninteractive theorem provers (proof assistants). Its rapid development has been\ndriven by progress in deep learning, especially large language models (LLMs).\nMore recently, the term has expanded beyond mathematics to describe the broader\ntask of translating informal input into formal logical representations. At the\nsame time, a growing body of research explores using LLMs to translate informal\nlanguage into formal representations for reasoning, planning, and knowledge\nrepresentation - often without explicitly referring to this process as\nautoformalization. As a result, despite addressing similar tasks, the largely\nindependent development of these research areas has limited opportunities for\nshared methodologies, benchmarks, and theoretical frameworks that could\naccelerate progress. The goal of this paper is to review - explicit or implicit\n- instances of what can be considered autoformalization and to propose a\nunified framework, encouraging cross-pollination between different fields to\nadvance the development of next generation AI systems.", "AI": {"tldr": "This paper reviews the developments in autoformalization, where informal input is translated into formal logical representations, and proposes a unified framework to integrate various research efforts.", "motivation": "This paper is motivated by the fragmented progress in autoformalization across different fields, which hinders common methodologies, benchmarks, and theoretical frameworks necessary for advancement.", "method": "The authors analyze previous and current instances of autoformalization, explicitly or implicitly, to identify overlap. They propose a unified framework to encourage collaboration and consistency across fields.", "result": "The paper identifies parallel developments in autoformalization and presents a framework that facilitates integration of methodologies and benchmarks across domains.", "conclusion": "Integration of research efforts through a unified framework is essential to accelerate the progress of AI systems that can automatically formalize informal representations into logical forms."}}
{"id": "2509.10371", "pdf": "https://arxiv.org/pdf/2509.10371", "abs": "https://arxiv.org/abs/2509.10371", "authors": ["Seokjin Go", "Joongun Park", "Spandan More", "Hanjiang Wu", "Irene Wang", "Aaron Jezghani", "Tushar Krishna", "Divya Mahajan"], "title": "Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The rapid scaling of Large Language Models (LLMs) has pushed training\nworkloads far beyond the limits of single-node analysis, demanding a deeper\nunderstanding of how these models behave across large-scale, multi-GPU systems.\nIn this paper, we present a comprehensive characterization of LLM training\nacross diverse real-world workloads and hardware platforms, including NVIDIA\nH100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various\nparallelism strategies -- tensor, pipeline, data, and expert -- and evaluate\ntheir effects on hardware utilization, power consumption, and thermal behavior.\nWe further evaluate the effectiveness of optimizations such as activation\nrecomputation and compute-communication overlap. Our findings show that\nperformance is not determined solely by scaling hardware capacity. Scale-up\nsystems with fewer, higher-memory GPUs can outperform scale-out systems in\ncommunication-bound regimes, but only under carefully tuned configurations; in\nother cases, scale-out deployments achieve superior throughput. We also show\nthat certain parallelism combinations, such as tensor with pipeline, lead to\nbandwidth underutilization due to inefficient data chunking, while increasing\nmicrobatch sizes beyond a certain point induces bursty execution and peak power\nexcursions that worsen thermal throttling. These insights reveal how training\nperformance is shaped by complex interactions between hardware, system\ntopology, and model execution. We conclude by offering recommendations for\nsystem and hardware design to improve the scalability and reliability of future\nLLM systems and workloads. The source code of this project is available at\nhttps://github.com/sitar-lab/CharLLM-PPT.", "AI": {"tldr": "This paper studies the behavior of Large Language Models (LLMs) training across multi-GPU systems, comparing different parallelism strategies and hardware platforms.", "motivation": "The paper aims to provide a deeper understanding of how LLMs behave when scaled across large systems, addressing the challenge of efficient training in multi-GPU environments.", "method": "The authors comprehensively evaluated LLM training on NVIDIA H100/H200 and AMD MI250 GPUs, employing tensor, pipeline, data, and expert parallelism. They analyzed hardware utilization, power and thermal behavior, and optimizations such as activation recomputation.", "result": "Scale-up systems with high-memory GPUs can outperform scale-out systems in certain configurations. Some parallelism strategies cause bandwidth inefficiencies, and microbatch size increases can lead to thermal issues. Communication and configuration are critical.", "conclusion": "Interactions between hardware, model execution, and system topology shape performance. Recommendations for hardware and system improvements are provided, and the source code is shared for reproducibility."}}
{"id": "2509.09747", "pdf": "https://arxiv.org/pdf/2509.09747", "abs": "https://arxiv.org/abs/2509.09747", "authors": ["Leen Daher", "Zhaobo Wang", "Malcolm Mielle"], "title": "D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Cross-modal transfer learning is used to improve multi-modal classification\nmodels (e.g., for human activity recognition in human-robot collaboration).\nHowever, existing methods require paired sensor data at both training and\ninference, limiting deployment in resource-constrained environments where full\nsensor suites are not economically and technically usable. To address this, we\npropose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns\nmodality-specific representations without requiring joint sensor modality\nduring inference. Our approach combines a self-attention module for feature\nextraction with a novel cross-attention alignment loss, which enforces the\nalignment of sensors' feature spaces without requiring the coupling of the\nclassification pipelines of both modalities. We evaluate D-CAT on three\nmulti-modal human activity datasets (IMU, video, and audio) under both\nin-distribution and out-of-distribution scenarios, comparing against uni-modal\nmodels. Results show that in in-distribution scenarios, transferring from\nhigh-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains\nover uni-modal training. In out-of-distribution scenarios, even weaker source\nmodalities (e.g., IMU to video) improve target performance, as long as the\ntarget model isn't overfitted on the training data. By enabling single-sensor\ninference with cross-modal knowledge, D-CAT reduces hardware redundancy for\nperception systems while maintaining accuracy, which is critical for\ncost-sensitive or adaptive deployments (e.g., assistive robots in homes with\nvariable sensor availability). Code is available at\nhttps://github.com/Schindler-EPFL-Lab/D-CAT.", "AI": {"tldr": "This paper introduces Decoupled Cross-Attention Transfer (D-CAT), a method enabling single-sensor inference for multi-modal classification by aligning modality-specific representations without requiring paired sensor data at inference.", "motivation": "Multi-modal classification models are crucial in applications like human-robot collaboration, but existing methods needing paired sensor data at inference are impractical in cost-sensitive deployments.", "method": "The proposed D-CAT framework uses a self-attention module for feature extraction combined with a cross-attention alignment loss to align modality-specific feature spaces without coupling classification pipelines.", "result": "D-CAT achieves up to 10% F1-score improvement in in-distribution scenarios when transferring from high-performing modalities, and improves performance in out-of-distribution scenarios using weaker modalities, provided the target model isn't overfitted.", "conclusion": "D-CAT enables accurate single-sensor inference, reducing hardware redundancy and supporting adaptive and cost-sensitive deployments, such as assistive robots, while maintaining classification performance."}}
{"id": "2509.09700", "pdf": "https://arxiv.org/pdf/2509.09700", "abs": "https://arxiv.org/abs/2509.09700", "authors": ["Malavika Suresh", "Rahaf Aljundi", "Ikechukwu Nkisi-Orji", "Nirmalie Wiratunga"], "title": "Cross-Layer Attention Probing for Fine-Grained Hallucination Detection", "categories": ["cs.CL", "cs.AI"], "comment": "To be published at the TRUST-AI workshop, ECAI 2025", "summary": "With the large-scale adoption of Large Language Models (LLMs) in various\napplications, there is a growing reliability concern due to their tendency to\ngenerate inaccurate text, i.e. hallucinations. In this work, we propose\nCross-Layer Attention Probing (CLAP), a novel activation probing technique for\nhallucination detection, which processes the LLM activations across the entire\nresidual stream as a joint sequence. Our empirical evaluations using five LLMs\nand three tasks show that CLAP improves hallucination detection compared to\nbaselines on both greedy decoded responses as well as responses sampled at\nhigher temperatures, thus enabling fine-grained detection, i.e. the ability to\ndisambiguate hallucinations and non-hallucinations among different sampled\nresponses to a given prompt. This allows us to propose a detect-then-mitigate\nstrategy using CLAP to reduce hallucinations and improve LLM reliability\ncompared to direct mitigation approaches. Finally, we show that CLAP maintains\nhigh reliability even when applied out-of-distribution.", "AI": {"tldr": "The paper proposes Cross-Layer Attention Probing (CLAP), a method to improve hallucination detection in Large Language Models (LLMs).", "motivation": "The reliability of LLMs is questioned due to their tendency to produce inaccurate outputs, known as hallucinations.", "method": "CLAP processes LLM activations across the entire residual stream as a joint sequence, enabling detection of hallucinated versus non-hallucinated responses.", "result": "CLAP demonstrated improved hallucination detection across five LLMs and three tasks, including both greedily decoded and high-temperature sampled responses.", "conclusion": "CLAP enhances the reliability of LLMs, enables fine-grained hallucination detection, supports a detect-then-mitigate strategy, and performs well even out-of-distribution."}}
{"id": "2509.09721", "pdf": "https://arxiv.org/pdf/2509.09721", "abs": "https://arxiv.org/abs/2509.09721", "authors": ["Jiayi Miao", "Dingxin Lu", "Zhuqi Wang"], "title": "A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "After natural disasters, accurate evaluations of damage to housing are\nimportant for insurance claims response and planning of resources. In this\nwork, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)\nframework. On top of classical RAG architecture, we further the framework to\ndevise a two-branch multimodal encoder structure that the image branch employs\na visual encoder composed of ResNet and Transformer to extract the\ncharacteristic of building damage after disaster, and the text branch harnesses\na BERT retriever for the text vectorization of posts as well as insurance\npolicies and for the construction of a retrievable restoration index. To impose\ncross-modal semantic alignment, the model integrates a cross-modal interaction\nmodule to bridge the semantic representation between image and text via\nmulti-head attention. Meanwhile, in the generation module, the introduced modal\nattention gating mechanism dynamically controls the role of visual evidence and\ntext prior information during generation. The entire framework takes end-to-end\ntraining, and combines the comparison loss, the retrieval loss and the\ngeneration loss to form multi-task optimization objectives, and achieves image\nunderstanding and policy matching in collaborative learning. The results\ndemonstrate superior performance in retrieval accuracy and classification index\non damage severity, where the Top-1 retrieval accuracy has been improved by\n9.6%.", "AI": {"tldr": "This paper introduces Multimodal Retrieval-Augmented Generation (MM-RAG), a framework that integrates image and text data to evaluate housing damage after natural disasters with high accuracy.", "motivation": "Accurate evaluation of housing damage post-disasters is critical for effective insurance claims and efficient resource planning.", "method": "The MM-RAG framework extends classical RAG architecture with a two-branch multimodal encoder. It integrates a ResNet-Transformer-based visual encoder for images, a BERT-based text retriever for textual data, and uses cross-modal interaction and modal attention gating mechanisms to align and fuse information. The framework employs multi-task optimization for improved image-text synergy.", "result": "The proposed approach significantly enhances retrieval accuracy and damage classification, achieving a Top-1 retrieval accuracy improvement of 9.6%.", "conclusion": "The MM-RAG framework successfully demonstrates its ability to integrate visual and textual data for superior post-disaster damage evaluation, showcasing its potential for real-world applications in insurance and disaster planning."}}
{"id": "2509.09805", "pdf": "https://arxiv.org/pdf/2509.09805", "abs": "https://arxiv.org/abs/2509.09805", "authors": ["Francisco M. L\u00f3pez", "Miles Lenz", "Marco G. Fedozzi", "Arthur Aubret", "Jochen Triesch"], "title": "MIMo grows! Simulating body and sensory development in a multimodal infant model", "categories": ["cs.RO"], "comment": "Accepted at IEEE ICDL 2025. 6 pages, 6 figures", "summary": "Infancy is characterized by rapid body growth and an explosive change of\nsensory and motor abilities. However, developmental robots and simulation\nplatforms are typically designed in the image of a specific age, which limits\ntheir ability to capture the changing abilities and constraints of developing\ninfants. To address this issue, we present MIMo v2, a new version of the\nmultimodal infant model. It includes a growing body with increasing actuation\nstrength covering the age range from birth to 24 months. It also features\nfoveated vision with developing visual acuity as well as sensorimotor delays\nmodeling finite signal transmission speeds to and from an infant's brain.\nFurther enhancements of this MIMo version include an inverse kinematics module,\na random environment generator and updated compatiblity with third-party\nsimulation and learning libraries. Overall, this new MIMo version permits\nincreased realism when modeling various aspects of sensorimotor development.\nThe code is available on the official repository\n(https://github.com/trieschlab/MIMo).", "AI": {"tldr": "MIMo v2 is a developmental robot model representing infants' sensorimotor changes from birth to 24 months, offering enhanced realism through features like growing body, foveated vision, sensorimotor delays, inverse kinematics, and compatibility improvements.", "motivation": "Current developmental robots and simulation tools lack the ability to emulate changes in an infant's physical and sensory-motor development over time.", "method": "Introduced MIMo v2, a multimodal infant model with growing physical attributes, evolving sensory-motor abilities, and complementary tools for enhanced simulation realism.", "result": "The features of MIMo v2 include dynamic body growth, developing visual acuity, sensorimotor delay modeling, inverse kinematics, and better system integration for simulation studies.", "conclusion": "MIMo v2 provides enriched realism in sensorimotor development simulations, addressing previous limitations of static infant models and aiding in developmental studies through its open-access platform."}}
{"id": "2509.09873", "pdf": "https://arxiv.org/pdf/2509.09873", "abs": "https://arxiv.org/abs/2509.09873", "authors": ["James Jewitt", "Hao Li", "Bram Adams", "Gopi Krishnan Rajbahadur", "Ahmed E. Hassan"], "title": "From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem", "categories": ["cs.SE", "cs.AI"], "comment": "9 pages, 4 figures, 5 tables, pre-print", "summary": "Hidden license conflicts in the open-source AI ecosystem pose serious legal\nand ethical risks, exposing organizations to potential litigation and users to\nundisclosed risk. However, the field lacks a data-driven understanding of how\nfrequently these conflicts occur, where they originate, and which communities\nare most affected. We present the first end-to-end audit of licenses for\ndatasets and models on Hugging Face, as well as their downstream integration\ninto open-source software applications, covering 364 thousand datasets, 1.6\nmillion models, and 140 thousand GitHub projects. Our empirical analysis\nreveals systemic non-compliance in which 35.5% of model-to-application\ntransitions eliminate restrictive license clauses by relicensing under\npermissive terms. In addition, we prototype an extensible rule engine that\nencodes almost 200 SPDX and model-specific clauses for detecting license\nconflicts, which can solve 86.4% of license conflicts in software applications.\nTo support future research, we release our dataset and the prototype engine.\nOur study highlights license compliance as a critical governance challenge in\nopen-source AI and provides both the data and tools necessary to enable\nautomated, AI-aware compliance at scale.", "AI": {"tldr": "The paper investigates hidden license conflicts in open-source AI ecosystems, specifically on the Hugging Face platform, through an audit of datasets, models, and downstream software, uncovering systemic non-compliance and presenting tools to address these issues.", "motivation": "The work is motivated by the legal and ethical risks posed by hidden license conflicts in open-source AI, as no comprehensive data-driven study existed to assess their prevalence and impact.", "method": "The authors perform an extensive audit covering 364k datasets, 1.6M models, and 140k GitHub projects, alongside the development of a rule engine designed to detect and address license conflicts.", "result": "The analysis showed that 35.5% of model-to-application transitions breached license clauses by switching to more permissive terms. Their rule engine resolved 86.4% of detected conflicts.", "conclusion": "The study underscores the importance of license compliance in open-source AI as a governance challenge and provides both actionable tools and datasets to advance compliance automation at scale."}}
{"id": "2509.10077", "pdf": "https://arxiv.org/pdf/2509.10077", "abs": "https://arxiv.org/abs/2509.10077", "authors": ["Simen Storesund", "Kristian Valset Aars", "Robin Dietrich", "Nicolai Waniek"], "title": "Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.DS", "cs.LG"], "comment": null, "summary": "Efficient planning and sequence selection are central to intelligence, yet\ncurrent approaches remain largely incompatible with biological computation.\nClassical graph algorithms like Dijkstra's or A* require global state and\nbiologically implausible operations such as backtracing, while reinforcement\nlearning methods rely on slow gradient-based policy updates that appear\ninconsistent with rapid behavioral adaptation observed in natural systems.\n  We propose a biologically plausible algorithm for shortest-path computation\nthat operates through local spike-based message-passing with realistic\nprocessing delays. The algorithm exploits spike-timing coincidences to identify\nnodes on optimal paths: Neurons that receive inhibitory-excitatory message\npairs earlier than predicted reduce their response delays, creating a temporal\ncompression that propagates backwards from target to source. Through analytical\nproof and simulations on random spatial networks, we demonstrate that the\nalgorithm converges and discovers all shortest paths using purely timing-based\nmechanisms. By showing how short-term timing dynamics alone can compute\nshortest paths, this work provides new insights into how biological networks\nmight solve complex computational problems through purely local computation and\nrelative spike-time prediction. These findings open new directions for\nunderstanding distributed computation in biological and artificial systems,\nwith possible implications for computational neuroscience, AI, reinforcement\nlearning, and neuromorphic systems.", "AI": {"tldr": "The paper proposes a biologically-compatible shortest-path computation algorithm based on spike-timing, avoiding global state or gradient updates required by traditional methods.", "motivation": "Existing graph algorithms and reinforcement learning methods are computationally inefficient and biologically implausible for modeling rapid behavioral adaptation in natural systems.", "method": "The authors develop a spike-based message-passing algorithm exploiting spike-timing coincidences and temporal compression for local computation of shortest paths.", "result": "Analytical proofs and simulations demonstrated convergence and discovery of all shortest paths within random spatial networks using purely timing-based mechanisms.", "conclusion": "The work illustrates how biological networks can leverage local computation and spike-time prediction for solving complex problems, informing fields like AI, computational neuroscience, and neuromorphic systems."}}
{"id": "2509.10051", "pdf": "https://arxiv.org/pdf/2509.10051", "abs": "https://arxiv.org/abs/2509.10051", "authors": ["Tianwei Pan", "Tianao Dai", "Jianlei Yang", "Hongbin Jing", "Yang Su", "Zeyu Hao", "Xiaotao Jia", "Chunming Hu", "Weisheng Zhao"], "title": "Finesse: An Agile Design Framework for Pairing-based Cryptography via Software/Hardware Co-Design", "categories": ["cs.AR"], "comment": "Published on 52nd Annual International Symposium on Computer\n  Architecture (ISCA'25)", "summary": "Pairing-based cryptography (PBC) is crucial in modern cryptographic\napplications. With the rapid advancement of adversarial research and the\ngrowing diversity of application requirements, PBC accelerators need regular\nupdates in algorithms, parameter configurations, and hardware design. However,\ntraditional design methodologies face significant challenges, including\nprolonged design cycles, difficulties in balancing performance and flexibility,\nand insufficient support for potential architectural exploration.\n  To address these challenges, we introduce Finesse, an agile design framework\nbased on co-design methodology. Finesse leverages a co-optimization cycle\ndriven by a specialized compiler and a multi-granularity hardware simulator,\nenabling both optimized performance metrics and effective design space\nexploration. Furthermore, Finesse adopts a modular design flow to significantly\nshorten design cycles, while its versatile abstraction ensures flexibility\nacross various curve families and hardware architectures.\n  Finesse offers flexibility, efficiency, and rapid prototyping, comparing with\nprevious frameworks. With compilation times reduced to minutes, Finesse enables\nfaster iteration cycles and streamlined hardware-software co-design.\nExperiments on popular curves demonstrate its effectiveness, achieving\n$34\\times$ improvement in throughput and $6.2\\times$ increase in area\nefficiency compared to previous flexible frameworks, while outperforming\nstate-of-the-art non-flexible ASIC designs with a $3\\times$ gain in throughput\nand $3.2\\times$ improvement in area efficiency.", "AI": {"tldr": "This paper presents Finesse, an agile design framework for pairing-based cryptography that achieves significant performance improvements and design flexibility through hardware-software co-optimization.", "motivation": "Traditional PBC accelerators face challenges like long design cycles, poor balance between performance and flexibility, and limited architectural exploration.", "method": "The authors propose Finesse, a co-design framework that integrates a specialized compiler and multi-granularity hardware simulator, enabling fast prototyping and effective exploration of design space.", "result": "Finesse demonstrates a 34\u00d7 improvement in throughput and a 6.2\u00d7 gain in area efficiency compared to flexible frameworks, and outperforms rigid ASIC designs with 3\u00d7 better throughput and 3.2\u00d7 improved area efficiency.", "conclusion": "Finesse significantly shortens design cycles and achieves a unique balance of flexibility and performance, making it highly effective for rapidly evolving PBC needs."}}
{"id": "2509.10166", "pdf": "https://arxiv.org/pdf/2509.10166", "abs": "https://arxiv.org/abs/2509.10166", "authors": ["Vladimir Petrovic", "R\u00e9mi Bardenet", "Agn\u00e8s Desolneux"], "title": "Repulsive Monte Carlo on the sphere for the sliced Wasserstein distance", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this paper, we consider the problem of computing the integral of a\nfunction on the unit sphere, in any dimension, using Monte Carlo methods.\nAlthough the methods we present are general, our guiding thread is the sliced\nWasserstein distance between two measures on $\\mathbb{R}^d$, which is precisely\nan integral on the $d$-dimensional sphere. The sliced Wasserstein distance (SW)\nhas gained momentum in machine learning either as a proxy to the less\ncomputationally tractable Wasserstein distance, or as a distance in its own\nright, due in particular to its built-in alleviation of the curse of\ndimensionality. There has been recent numerical benchmarks of quadratures for\nthe sliced Wasserstein, and our viewpoint differs in that we concentrate on\nquadratures where the nodes are repulsive, i.e. negatively dependent. Indeed,\nnegative dependence can bring variance reduction when the quadrature is adapted\nto the integration task. Our first contribution is to extract and motivate\nquadratures from the recent literature on determinantal point processes (DPPs)\nand repelled point processes, as well as repulsive quadratures from the\nliterature specific to the sliced Wasserstein distance. We then numerically\nbenchmark these quadratures. Moreover, we analyze the variance of the UnifOrtho\nestimator, an orthogonal Monte Carlo estimator. Our analysis sheds light on\nUnifOrtho's success for the estimation of the sliced Wasserstein in large\ndimensions, as well as counterexamples from the literature. Our final\nrecommendation for the computation of the sliced Wasserstein distance is to use\nrandomized quasi-Monte Carlo in low dimensions and \\emph{UnifOrtho} in large\ndimensions. DPP-based quadratures only shine when quasi-Monte Carlo also does,\nwhile repelled quadratures show moderate variance reduction in general, but\nmore theoretical effort is needed to make them robust.", "AI": {"tldr": "This study explores Monte Carlo methods to compute integrals on unit spheres in any dimension, particularly applied to estimating the sliced Wasserstein distance. It benchmarks methods like determinantal and repelled point processes, analyzing variance reduction and recommending efficient strategies for integration.", "motivation": "The paper is driven by the need for effective and computationally efficient methods to estimate the sliced Wasserstein distance, which is relevant in machine learning and mitigates the curse of dimensionality.", "method": "The research employs Monte Carlo methods, benchmarks quadratures from existing literature like random point processes, and analyzes methods like DPPs, repelled quadratures, and the UnifOrtho estimator.", "result": "The study finds that randomized quasi-Monte Carlo methods work best in low dimensions, while the UnifOrtho estimator excels in high dimensions. DPP-based and repelled quadratures show moderate variance reduction but need further theoretical refinement.", "conclusion": "The paper concludes that computational efficiency in integrating functions on spheres varies by dimensionality, with specific methods suited for low or high dimensions. Repelled quadratures need more theoretical development to be widely robust."}}
{"id": "2509.09696", "pdf": "https://arxiv.org/pdf/2509.09696", "abs": "https://arxiv.org/abs/2509.09696", "authors": ["Weibin Li", "Wendu Li", "Quanying Liu"], "title": "DCHO: A Decomposition-Composition Framework for Predicting Higher-Order Brain Connectivity to Enhance Diverse Downstream Applications", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Higher-order brain connectivity (HOBC), which captures interactions among\nthree or more brain regions, provides richer organizational information than\ntraditional pairwise functional connectivity (FC). Recent studies have begun to\ninfer latent HOBC from noninvasive imaging data, but they mainly focus on\nstatic analyses, limiting their applicability in dynamic prediction tasks. To\naddress this gap, we propose DCHO, a unified approach for modeling and\nforecasting the temporal evolution of HOBC based on a Decomposition-Composition\nframework, which is applicable to both non-predictive tasks (state\nclassification) and predictive tasks (brain dynamics forecasting). DCHO adopts\na decomposition-composition strategy that reformulates the prediction task into\ntwo manageable subproblems: HOBC inference and latent trajectory prediction. In\nthe inference stage, we propose a dual-view encoder to extract multiscale\ntopological features and a latent combinatorial learner to capture high-level\nHOBC information. In the forecasting stage, we introduce a latent-space\nprediction loss to enhance the modeling of temporal trajectories. Extensive\nexperiments on multiple neuroimaging datasets demonstrate that DCHO achieves\nsuperior performance in both non-predictive tasks (state classification) and\npredictive tasks (brain dynamics forecasting), significantly outperforming\nexisting methods.", "AI": {"tldr": "The paper introduces DCHO, a framework for modeling and predicting higher-order brain connectivity (HOBC) dynamics, addressing limitations in static analyses with strong results in state classification and brain dynamics forecasting.", "motivation": "HOBC offers richer organizational insights than traditional functional connectivity, but current methods for analyzing it are static and unsuitable for dynamic prediction tasks.", "method": "The paper presents a Decomposition-Composition framework (DCHO) with a dual-view encoder for multiscale topological and HOBC feature extraction, and a latent-space prediction loss for trajectory forecasting.", "result": "DCHO outperforms existing methods in both state classification (non-predictive tasks) and brain dynamics forecasting (predictive tasks) across multiple neuroimaging datasets.", "conclusion": "DCHO is a significant advancement in HOBC modeling, proving its effectiveness for both predictive and non-predictive dynamic neuroimaging analysis tasks."}}
{"id": "2509.09879", "pdf": "https://arxiv.org/pdf/2509.09879", "abs": "https://arxiv.org/abs/2509.09879", "authors": ["Yuanjun Dai", "Qingzhe Guo", "Xiangren Wang"], "title": "eHashPipe: Lightweight Top-K and Per-PID Resource Monitoring with eBPF", "categories": ["cs.PF"], "comment": null, "summary": "System-level resource monitoring with both precision and efficiency is a\ncontinuous challenge. We introduce eHashPipe, a lightweight, real-time resource\nobservability system utilizing eBPF and the HashPipe sketching algorithm.\neHashPipe supports two tracking modes: Top-k monitoring to identify the most\nresource-demanding processes and specific PID tracking to detail the behavior\nof selected processes. We implement two in-kernel eBPF pipelines for on-CPU\ntime and memory usage. Unlike traditional userspace polling tools, eHashPipe\noperates in the kernel to reduce latency and context-switch overhead while\nkeeping the runtime footprint small. During our experiments, eHashPipe attains\n100 percent Top-k precision for CPU and memory at k = 1, 5, and 10, 95.0/90.0\npercent at k = 20, and 93.3/83.3 percent at k = 30 compared to the ground\ntruth. It exposes short-lived bursts with about 14 times finer temporal\nresolution than top while imposing very low overhead. These results show that\neHashPipe delivers accurate, responsive insight with minimal impact, making it\nwell suited for latency-sensitive cloud and edge environments.", "AI": {"tldr": "eHashPipe is a lightweight, efficient kernel-based resource observability system leveraging eBPF and HashPipe to monitor CPU and memory usage with high precision at low overhead.", "motivation": "To create an efficient and precise system-level resource monitoring solution addressing the shortcomings of traditional userspace polling tools, such as high latency and context-switch overhead.", "method": "The paper introduces eHashPipe, a real-time observability system that utilizes eBPF and the HashPipe sketching algorithm. It implements in-kernel pipelines for CPU and memory tracking using two modes: Top-k monitoring (for most resource-demanding processes) and specific PID tracking. ", "result": "eHashPipe achieved 100% precision for Top-k monitoring at k = 1, 5, and 10, and over 90% at k = 20 and 30. It also effectively captured short-lived bursts with significantly finer temporal resolution than traditional tools like 'top,' all while maintaining low overhead.", "conclusion": "eHashPipe offers a precise, responsive, and low-overhead resource monitoring solution, particularly suited for latency-sensitive environments such as cloud and edge systems."}}
{"id": "2509.09848", "pdf": "https://arxiv.org/pdf/2509.09848", "abs": "https://arxiv.org/abs/2509.09848", "authors": ["Nana Han", "Dong Liu", "Tomas Norton"], "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly being recognised as valuable\nknowledge communication tools in many industries. However, their application in\nlivestock farming remains limited, being constrained by several factors not\nleast the availability, diversity and complexity of knowledge sources. This\nstudy introduces an intelligent knowledge assistant system designed to support\nhealth management in farmed goats. Leveraging the Retrieval-Augmented\nGeneration (RAG), two structured knowledge processing methods, table\ntextualization and decision-tree textualization, were proposed to enhance large\nlanguage models' (LLMs) understanding of heterogeneous data formats. Based on\nthese methods, a domain-specific goat farming knowledge base was established to\nimprove LLM's capacity for cross-scenario generalization. The knowledge base\nspans five key domains: Disease Prevention and Treatment, Nutrition Management,\nRearing Management, Goat Milk Management, and Basic Farming Knowledge.\nAdditionally, an online search module is integrated to enable real-time\nretrieval of up-to-date information. To evaluate system performance, six\nablation experiments were conducted to examine the contribution of each\ncomponent. The results demonstrated that heterogeneous knowledge fusion method\nachieved the best results, with mean accuracies of 87.90% on the validation set\nand 84.22% on the test set. Across the text-based, table-based, decision-tree\nbased Q&A tasks, accuracy consistently exceeded 85%, validating the\neffectiveness of structured knowledge fusion within a modular design. Error\nanalysis identified omission as the predominant error category, highlighting\nopportunities to further improve retrieval coverage and context integration. In\nconclusion, the results highlight the robustness and reliability of the\nproposed system for practical applications in goat farming.", "AI": {"tldr": "The paper presents an intelligent knowledge assistant for farmed goat health management by integrating Retrieval-Augmented Generation (RAG) and structured knowledge processing methods, achieving high accuracy across diverse domains.", "motivation": "The authors aim to address the increasing need for effective knowledge communication in livestock farming using LLMs, despite challenges such as the complexity, variety, and limited accessibility of knowledge sources.", "method": "The study leverages RAG and two structured knowledge processing methods\u2014table textualization and decision-tree textualization\u2014to create a domain-specific knowledge base across five domains, supported by an online search module for real-time data retrieval.", "result": "The system achieved mean accuracies of 87.90% on the validation set and 84.22% on the test set in knowledge fusion tasks. Q&A accuracies exceeded 85% across different formats, demonstrating the effectiveness of the structured fusion approach.", "conclusion": "The proposed system demonstrates reliability and practicality for goat farming applications, although there are opportunities for improvement in retrieval coverage and error mitigation."}}
{"id": "2509.09898", "pdf": "https://arxiv.org/pdf/2509.09898", "abs": "https://arxiv.org/abs/2509.09898", "authors": ["Sophia Lockton", "Jeremy Kepner", "Michael Stonebraker", "Hayden Jananthan", "LaToya Anderson", "William Arcand", "David Bestor", "William Bergeron", "Alex Bonn", "Daniel Burrill", "Chansup Byun", "Timothy Davis", "Vijay Gadepally", "Michael Houle", "Matthew Hubbell", "Michael Jones", "Piotr Luszczek", "Peter Michaleas", "Lauren Milechin", "Chasen Milner", "Guillermo Morales", "Julie Mullen", "Michel Pelletier", "Alex Poliakov", "Andrew Prout", "Albert Reuther", "Antonio Rosa", "Charles Yee", "Alex Pentland"], "title": "DBOS Network Sensing: A Web Services Approach to Collaborative Awareness", "categories": ["cs.NI", "cs.CR", "cs.DB", "cs.DC", "cs.OS"], "comment": "8 pages, 10 figures, 37 references, accepted to IEEE HPEC 2025", "summary": "DBOS (DataBase Operating System) is a novel capability that integrates web\nservices, operating system functions, and database features to significantly\nreduce web-deployment effort while increasing resilience. Integration of high\nperformance network sensing enables DBOS web services to collaboratively create\na shared awareness of their network environments to enhance their collective\nresilience and security. Network sensing is added to DBOS using GraphBLAS\nhypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)\nOneSparse PostgreSQL. These capabilities are demonstrated using the workflow\nand analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph\nChallenge. The system was parallelized using pPython and benchmarked using 64\ncompute nodes on the MIT SuperCloud. The web request rate sustained by a single\nDBOS instance was ${>}10^5$, well above the required maximum, indicating that\nnetwork sensing can be added to DBOS with negligible overhead. For\ncollaborative awareness, many DBOS instances were connected to a single DBOS\naggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations\nscaled linearly up to 64 and 32 nodes respectively. These results suggest that\nDBOS collaborative network awareness can be achieved with a negligible increase\nin computing resources.", "AI": {"tldr": "DBOS integrates web services, operating system functions, and database features with network sensing for enhanced resilience and security.", "motivation": "The paper aims to simplify web-deployment efforts while improving resilience using collaborative network sensing.", "method": "The system integrates network sensing via GraphBLAS hypersparse traffic matrices using Python-GraphBLAS and OneSparse PostgreSQL, tested on the MIT SuperCloud.", "result": "The web request rate exceeds $10^5$ with negligible overhead; implementations scaled linearly up to 64 and 32 nodes, respectively.", "conclusion": "DBOS can achieve collaborative network awareness with minimal computational resource increases."}}
{"id": "2509.09751", "pdf": "https://arxiv.org/pdf/2509.09751", "abs": "https://arxiv.org/abs/2509.09751", "authors": ["Junqiao Wang", "Zhaoyang Guan", "Guanyu Liu", "Tianze Xia", "Xianzhi Li", "Shuo Yin", "Xinyuan Song", "Chuhan Cheng", "Tianyu Shi", "Alex Lee"], "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting cryptocurrency returns is notoriously difficult: price movements\nare driven by a fast-shifting blend of on-chain activity, news flow, and social\nsentiment, while labeled training data are scarce and expensive. In this paper,\nwe present Meta-RL-Crypto, a unified transformer-based architecture that\nunifies meta-learning and reinforcement learning (RL) to create a fully\nself-improving trading agent. Starting from a vanilla instruction-tuned LLM,\nthe agent iteratively alternates between three roles-actor, judge, and\nmeta-judge-in a closed-loop architecture. This learning process requires no\nadditional human supervision. It can leverage multimodal market inputs and\ninternal preference feedback. The agent in the system continuously refines both\nthe trading policy and evaluation criteria. Experiments across diverse market\nregimes demonstrate that Meta-RL-Crypto shows good performance on the technical\nindicators of the real market and outperforming other LLM-based baselines.", "AI": {"tldr": "Meta-RL-Crypto is a self-improving trading agent, combining meta-learning and reinforcement learning to predict cryptocurrency returns and outperform existing LLM-based methods.", "motivation": "Cryptocurrency price prediction faces challenges due to complex influences like market activity, news, and sentiment, combined with scarce labeled data.", "method": "The paper introduces Meta-RL-Crypto, using a transformer-based architecture integrating meta-learning and RL, featuring an iterative actor-judge-meta-judge process with multimodal inputs.", "result": "Experiments demonstrate Meta-RL-Crypto's strong performance in diverse market conditions and advantages over other LLM-based approaches.", "conclusion": "Meta-RL-Crypto effectively refines trading policies and evaluation criteria, addressing the difficulties of cryptocurrency prediction and setting a benchmark in LLM-based systems."}}
{"id": "2509.09701", "pdf": "https://arxiv.org/pdf/2509.09701", "abs": "https://arxiv.org/abs/2509.09701", "authors": ["JungHo Jung", "Junhyun Lee"], "title": "Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task", "categories": ["cs.CL"], "comment": null, "summary": "End-to-end speech-to-text translation typically suffers from the scarcity of\npaired speech-text data. One way to overcome this shortcoming is to utilize the\nbitext data from the Machine Translation (MT) task and perform Multi-Task\nLearning (MTL). In this paper, we formulate MTL from a regularization\nperspective and explore how sequences can be regularized within and across\nmodalities. By thoroughly investigating the effect of consistency\nregularization (different modality) and R-drop (same modality), we show how\nthey respectively contribute to the total regularization. We also demonstrate\nthat the coefficient of MT loss serves as another source of regularization in\nthe MTL setting. With these three sources of regularization, we introduce the\noptimal regularization contour in the high-dimensional space, called the\nregularization horizon. Experiments show that tuning the hyperparameters within\nthe regularization horizon achieves near state-of-the-art performance on the\nMuST-C dataset.", "AI": {"tldr": "End-to-end speech-to-text translation often faces data scarcity, but leveraging Machine Translation data and Multi-Task Learning (MTL) with defined regularization approaches can improve performance.", "motivation": "Address limitations in speech-to-text translation by incorporating effective use of existing Machine Translation (MT) data and regularization techniques.", "method": "Employ consistency regularization across modalities and R-drop regularization within modalities in a Multi-Task Learning setup, complemented by MT loss coefficient adjustments. Introduce the regularization horizon concept for optimal tuning.", "result": "Experiments on the MuST-C dataset reveal that careful tuning of hyperparameters within the defined regularization framework achieves near state-of-the-art performance.", "conclusion": "Strategic use of regularization techniques and MT loss adjustments in MTL can mitigate data scarcity and enhance speech-to-text translation performance."}}
{"id": "2509.09722", "pdf": "https://arxiv.org/pdf/2509.09722", "abs": "https://arxiv.org/abs/2509.09722", "authors": ["Taylor Archibald", "Tony Martinez"], "title": "Improving MLLM Historical Record Extraction with Test-Time Image", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": null, "summary": "We present a novel ensemble framework that stabilizes LLM based text\nextraction from noisy historical documents. We transcribe multiple augmented\nvariants of each image with Gemini 2.0 Flash and fuse these outputs with a\ncustom Needleman Wunsch style aligner that yields both a consensus\ntranscription and a confidence score. We present a new dataset of 622\nPennsylvania death records, and demonstrate our method improves transcription\naccuracy by 4 percentage points relative to a single shot baseline. We find\nthat padding and blurring are the most useful for improving accuracy, while\ngrid warp perturbations are best for separating high and low confidence cases.\nThe approach is simple, scalable, and immediately deployable to other document\ncollections and transcription models.", "AI": {"tldr": "The paper introduces an ensemble framework to enhance text extraction accuracy from noisy historical documents based on Large Language Models (LLMs) by using multiple augmented image transcriptions and a custom alignment process.", "motivation": "The motivation is to address the challenge of extracting accurate text from noisy historical documents, where traditional single-shot transcription methods fail to achieve high accuracy.", "method": "The method involves generating multiple augmented image variants for transcription using Gemini 2.0 Flash and combining the outputs through a customized Needleman Wunsch style aligner that provides consensus transcriptions and confidence scores.", "result": "Using a new dataset of 622 Pennsylvania death records, their approach demonstrated an improvement in transcription accuracy by 4 percentage points compared to a single-shot baseline. Padding and blurring augmented accuracy, while grid warp separated high-confidence from low-confidence results.", "conclusion": "The approach is simple, scalable, and can be deployed easily for other historical document collections and transcription models effectively improving their transcription capabilities."}}
{"id": "2509.09889", "pdf": "https://arxiv.org/pdf/2509.09889", "abs": "https://arxiv.org/abs/2509.09889", "authors": ["Giulia Botta", "Marco Botta", "Cristina Gena", "Alessandro Mazzei", "Massimo Donini", "Alberto Lillo"], "title": "Using the Pepper Robot to Support Sign Language Communication", "categories": ["cs.RO", "cs.HC"], "comment": "paper presented at ICSR2025", "summary": "Social robots are increasingly experimented in public and assistive settings,\nbut their accessibility for Deaf users remains quite underexplored. Italian\nSign Language (LIS) is a fully-fledged natural language that relies on complex\nmanual and non-manual components. Enabling robots to communicate using LIS\ncould foster more inclusive human robot interaction, especially in social\nenvironments such as hospitals, airports, or educational settings. This study\ninvestigates whether a commercial social robot, Pepper, can produce\nintelligible LIS signs and short signed LIS sentences. With the help of a Deaf\nstudent and his interpreter, an expert in LIS, we co-designed and implemented\n52 LIS signs on Pepper using either manual animation techniques or a MATLAB\nbased inverse kinematics solver. We conducted a exploratory user study\ninvolving 12 participants proficient in LIS, both Deaf and hearing.\nParticipants completed a questionnaire featuring 15 single-choice video-based\nsign recognition tasks and 2 open-ended questions on short signed sentences.\nResults shows that the majority of isolated signs were recognized correctly,\nalthough full sentence recognition was significantly lower due to Pepper's\nlimited articulation and temporal constraints. Our findings demonstrate that\neven commercially available social robots like Pepper can perform a subset of\nLIS signs intelligibly, offering some opportunities for a more inclusive\ninteraction design. Future developments should address multi-modal enhancements\n(e.g., screen-based support or expressive avatars) and involve Deaf users in\nparticipatory design to refine robot expressivity and usability.", "AI": {"tldr": "The paper explores the ability of the Pepper robot to communicate in Italian Sign Language (LIS), finding it can perform some signs intelligibly, though improvement is needed for full sentences and nuanced expressivity.", "motivation": "To create inclusivity in human-robot interactions by enabling robots to communicate effectively with Deaf users through Italian Sign Language (LIS).", "method": "The researchers co-designed and implemented 52 LIS signs on the Pepper robot using manual animations and an inverse kinematics solver. They then conducted a user study with 12 LIS-proficient participants who evaluated the robot's sign intelligibility through tasks and questionnaires.", "result": "The study found that single LIS signs were mostly recognized correctly, but full sentence recognition was poor due to the robot's limited articulation and timing issues.", "conclusion": "Commercial robots like Pepper can perform certain LIS signs, offering potential for inclusive design. However, further development, including multi-modal enhancements and participatory design, is required for better robot expressivity and usability for Deaf users."}}
{"id": "2509.09917", "pdf": "https://arxiv.org/pdf/2509.09917", "abs": "https://arxiv.org/abs/2509.09917", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion", "categories": ["cs.SE", "D.2.4"], "comment": "22 pages, 2 figures, conference", "summary": "Automatically generating formal specifications from program code can greatly\nenhance the efficiency of program verification and enable end-to-end automation\nfrom requirements to reliable software. However, existing LLM-based approaches\noften struggle with programs that include complex loop structures, leading to\nirrelevant specifications. Moreover, the rigorous proof obligations and design\nconstraints imposed by verification tools can further result in incomplete and\nambiguous specifications. To address these challenges, we propose SLD-Spec, an\nLLM-assisted specification generation method tailored for programs with complex\nloop constructs. SLD-Spec introduces two novel phases into the traditional\nspecification generation framework: (1) A slicing phase, which decomposes each\nfunction into code fragments containing independent loop structures, thereby\nreducing the complexity of specification generation; and (2) A logical deletion\nphase, which applies LLM-based reasoning to filter out incorrect candidate\nspecifications--especially those not easily identified by verification\ntool--while retaining valid ones. Experimental results show that on the simple\ndataset, SLD-Spec successfully verifies five more programs than the\nstate-of-the-art AutoSpec and reduces runtime by 23.73%. To address the\nlimitations of existing research, we manually construct a dataset comprising\nfour categories of complex loop programs. On this dataset, SLD-Spec\nsignificantly improves the correctness, relevance, and completeness of\ngenerated specifications compared to baseline methods, enabling 95.1% of\nassertions and 90.91% of programs to pass verification. Ablation studies\nfurther reveal that logical deletion is critical for enhancing specification\ncorrectness and relevance, while program slicing contributes significantly to\nspecification completeness. Our code and data are publicly available.", "AI": {"tldr": "SLD-Spec improves specification generation for complex loop programs, achieving better correctness, relevance, and completeness over existing methods.", "motivation": "Existing LLM-based specification tools struggle with complex loops in programs, often generating irrelevant or ambiguous specifications.", "method": "SLD-Spec introduces slicing to simplify loop structures and logical deletion to filter incorrect specifications using LLM-based reasoning.", "result": "SLD-Spec verifies more programs (+5) than AutoSpec, reduces runtime by 23.73%, and passes 95.1% of assertions and 90.91% of programs in experimental datasets.", "conclusion": "The integration of slicing and logical deletion enhances specification generation, providing more reliable automation for challenging programs with complex loops."}}
{"id": "2509.10372", "pdf": "https://arxiv.org/pdf/2509.10372", "abs": "https://arxiv.org/abs/2509.10372", "authors": ["Huizheng Wang", "Zichuan Wang", "Zhiheng Yue", "Yousheng Long", "Taiquan Wei", "Jianxun Yang", "Yang Wang", "Chao Li", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging Bit-Slice-enabled Sparsity and Repetitiveness", "categories": ["cs.AR"], "comment": null, "summary": "Large language models (LLMs) face significant inference latency due to\ninefficiencies in GEMM operations, weight access, and KV cache access,\nespecially in real-time scenarios. This highlights the need for a versatile\ncompute-memory efficient accelerator. Unfortunately, existing Transformer\naccelerators struggle to address both aspects simultaneously, as they focus on\nvalue-level processing, missing fine-grained opportunities to optimize\ncomputation and memory collaboratively. This paper introduces MCBP, a\nbit-grained compute-memory efficient algorithm-hardware co-design that\nleverages bit-slice (BS) enabled repetitiveness and sparsity to accelerate LLM\ninference. MCBP features three key innovations: 1) BS-repetitiveness-enabled\ncomputation reduction (BRCR), which eliminates redundant GEMM computations via\nleveraging redundancy hidden among BS vectors; 2) BS-sparsity-enabled two-state\ncoding (BSTC), which reduces weight access via exploiting significant sparsity\nin high-order bit-slice weight; 3) Bit-grained progressive prediction (BGPP),\nwhich reduces KV cache access by leveraging early-termination-based bit-grained\nprediction. These techniques, supported by custom accelerator designs,\neffectively alleviate the burden in GEMM, weight access, and KV cache access.\nExtensive experiments on 26 benchmarks show that MCBP achieves 9.43x speed up\nand 31.1x higher energy efficiency than Nvidia A100 GPU. Compared to SOTA\nTransformer accelerators, MCBP achieves 35x, 5.2x and 3.2x energy saving than\nSpatten, FACT and SOFA, respectively.", "AI": {"tldr": "This paper proposes MCBP, a novel hardware-software co-design for accelerating LLM inference, addressing inefficiencies in computation and memory collaboratively.", "motivation": "Large language models (LLMs) suffer from high inference latency due to inefficiencies in GEMM operations, weight access, and KV cache access, motivating the need for a versatile and efficient accelerator design.", "method": "The method involves three innovations: BS-repetitiveness-enabled computation reduction (BRCR) for eliminating redundant GEMM calculations, BS-sparsity-enabled two-state coding (BSTC) for reducing weight access, and Bit-grained progressive prediction (BGPP) for minimizing KV cache access. These are supported by a custom hardware accelerator design.", "result": "MCBP demonstrates a 9.43x speedup and 31.1x higher energy efficiency compared to Nvidia A100, and significantly outperforms other SOTA accelerators in energy savings.", "conclusion": "MCBP successfully overcomes inefficiencies in computation and memory access for LLMs, offering substantial performance and energy efficiency improvements through bit-grained algorithm-hardware co-design."}}
{"id": "2509.10337", "pdf": "https://arxiv.org/pdf/2509.10337", "abs": "https://arxiv.org/abs/2509.10337", "authors": ["Nil Ayday", "Mahalakshmi Sabanayagam", "Debarghya Ghoshdastidar"], "title": "Why does your graph neural network fail on some graphs? Insights from exact generalisation error", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) are widely used in learning on graph-structured\ndata, yet a principled understanding of why they succeed or fail remains\nelusive. While prior works have examined architectural limitations such as\nover-smoothing and over-squashing, these do not explain what enables GNNs to\nextract meaningful representations or why performance varies drastically\nbetween similar architectures. These questions are related to the role of\ngeneralisation: the ability of a model to make accurate predictions on\nunlabelled data. Although several works have derived generalisation error\nbounds for GNNs, these are typically loose, restricted to a single\narchitecture, and offer limited insight into what governs generalisation in\npractice. In this work, we take a different approach by deriving the exact\ngeneralisation error for GNNs in a transductive fixed-design setting through\nthe lens of signal processing. From this viewpoint, GNNs can be interpreted as\ngraph filter operators that act on node features via the graph structure. By\nfocusing on linear GNNs while allowing non-linearity in the graph filters, we\nderive the first exact generalisation error for a broad range of GNNs,\nincluding convolutional, PageRank-based, and attention-based models. The exact\ncharacterisation of the generalisation error reveals that only the aligned\ninformation between node features and graph structure contributes to\ngeneralisation. Furthermore, we quantify the effect of homophily on\ngeneralisation. Our work provides a framework that explains when and why GNNs\ncan effectively leverage structural and feature information, offering practical\nguidance for model selection.", "AI": {"tldr": "The paper derives the exact generalisation error for Graph Neural Networks (GNNs) through signal processing, revealing factors impacting their effectiveness.", "motivation": "To investigate the unexplained performance variability in similar GNN architectures and identify what governs their ability to generalize effectively on graph-structured data.", "method": "The authors analyze GNNs in a transductive fixed-design setting using signal processing concepts, focusing on linear GNNs but allowing non-linearity in graph filters to derive exact generalisation error.", "result": "They provide the first exact generalisation error characterisation for various GNNs and demonstrate how aligned node features and graph structure, along with homophily, influence generalisation.", "conclusion": "The framework offers insights into when and why GNNs can successfully leverage graph structure and node features, providing practical guidance for selecting or designing effective models."}}
{"id": "2509.09818", "pdf": "https://arxiv.org/pdf/2509.09818", "abs": "https://arxiv.org/abs/2509.09818", "authors": ["Jonathan Tsay", "Richard Ivry"], "title": "Cerebellar Contributions to Action and Cognition: Prediction, Timescale, and Continuity", "categories": ["q-bio.NC"], "comment": null, "summary": "The cerebellum is implicated in nearly every domain of human cognition, yet\nour understanding of how this subcortical structure contributes to cognition\nremains elusive. Efforts on this front have tended to fall into one of two\ncamps. On one side are those who seek to identify a universal cerebellar\ntransform, a single algorithm that can be applied across domains as diverse as\nsensorimotor learning, social cognition, and decision making. On the other side\nare those who focus on functional specializations tailored for different task\ndomains. In this perspective, we propose an integrated approach, one that\nrecognizes functional specialization across different cerebellar subregions,\nbut also builds on common constraints that help define the conditions that\nengage the cerebellum. Drawing on recurring principles from the cerebellum's\nwell-established role in motor control, we identify three core constraints:\nPrediction - the cerebellum performs anticipatory, not reactive, computations;\nTimescale - the cerebellum generates predictions limited to short intervals;\nand Continuity - the cerebellum transforms continuous representations such as\nspace and time. Together, these constraints define the boundary conditions\nunderlying when and how the cerebellum supports cognition, and, just as\nimportantly, specify the types of computations that should not depend on the\ncerebellum.", "AI": {"tldr": "This paper proposes an integrated approach to understand cerebellar contributions to cognition, highlighting functional specialization and common computational constraints.", "motivation": "Previous studies on cerebellar functions in cognition lack a unified framework, creating a gap in identifying consistent principles across various cognitive domains.", "method": "The authors propose a perspective focusing on functional specialization alongside identifying three universal constraints of cerebellar computations: Prediction, Timescale, and Continuity.", "result": "The paper outlines these core constraints, arguing they define boundary conditions for cerebellar involvement in cognition and eliminate inappropriate computational assumptions.", "conclusion": "An integrated model combining specialization and universal constraints enhances understanding of when and how the cerebellum supports cognition."}}
{"id": "2509.09867", "pdf": "https://arxiv.org/pdf/2509.09867", "abs": "https://arxiv.org/abs/2509.09867", "authors": ["Yago Romano Matinez", "Jesse Roberts"], "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "LLMs promise to assist humans -- not just by answering questions, but by\noffering useful guidance across a wide range of tasks. But how far does that\nassistance go? Can a large language model based agent actually help someone\naccomplish their goal as an active participant? We test this question by\nengaging an LLM in UNO, a turn-based card game, asking it not to win but\ninstead help another player to do so. We built a tool that allows decoder-only\nLLMs to participate as agents within the RLCard game environment. These models\nreceive full game-state information and respond using simple text prompts under\ntwo distinct prompting strategies. We evaluate models ranging from small (1B\nparameters) to large (70B parameters) and explore how model scale impacts\nperformance. We find that while all models were able to successfully outperform\na random baseline when playing UNO, few were able to significantly aid another\nplayer.", "AI": {"tldr": "This study investigates whether large language models (LLMs) can assist humans effectively in accomplishing goals by testing their performance in the turn-based card game UNO, aiming not to win but to help another player win.", "motivation": "To understand the extent to which LLMs can act as active participants and provide meaningful assistance across diverse tasks.", "method": "A specific setup was developed where decoder-only LLMs are used as agents in the RLCard game environment, given full game-state information and prompted under two different strategies. Models of varying scales (1B to 70B parameters) were evaluated.", "result": "All models performed better than a random baseline in UNO gameplay, but few demonstrated a significant ability to aid another player effectively.", "conclusion": "LLMs can outperform random baselines in structured games, but their capacity to assist another player actively and significantly is limited."}}
{"id": "2509.09915", "pdf": "https://arxiv.org/pdf/2509.09915", "abs": "https://arxiv.org/abs/2509.09915", "authors": ["Woong Shin", "Renan Souza", "Daniel Rosendo", "Fr\u00e9d\u00e9ric Suter", "Feiyi Wang", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "Modern scientific discovery increasingly requires coordinating distributed\nfacilities and heterogeneous resources, forcing researchers to act as manual\nworkflow coordinators rather than scientists. Advances in AI leading to AI\nagents show exciting new opportunities that can accelerate scientific discovery\nby providing intelligence as a component in the ecosystem. However, it is\nunclear how this new capability would materialize and integrate in the real\nworld. To address this, we propose a conceptual framework where workflows\nevolve along two dimensions which are intelligence (from static to intelligent)\nand composition (from single to swarm) to chart an evolutionary path from\ncurrent workflow management systems to fully autonomous, distributed scientific\nlaboratories. With these trajectories in mind, we present an architectural\nblueprint that can help the community take the next steps towards harnessing\nthe opportunities in autonomous science with the potential for 100x discovery\nacceleration and transformational scientific workflows.", "AI": {"tldr": "The paper discusses leveraging AI agents to evolve scientific workflows by enhancing intelligence and composition, aiming to accelerate discovery and enable autonomous laboratories.", "motivation": "Researchers currently spend significant time as manual workflow coordinators due to the complexity of distributed facilities and heterogeneous resources, highlighting the need for smarter and more autonomous systems.", "method": "The authors propose a conceptual framework with two evolutionary dimensions: intelligence (static to intelligent) and composition (single to swarm), coupled with a detailed architectural blueprint for autonomous scientific workflows.", "result": "The framework outlines a potential pathway to transition from current workflow systems to intelligent and distributed laboratories, showcasing opportunities for up to 100x acceleration in scientific discovery.", "conclusion": "Autonomous workflows powered by AI could transform scientific discovery processes, enabling significantly faster discoveries and new paradigms in laboratory automation."}}
{"id": "2509.09754", "pdf": "https://arxiv.org/pdf/2509.09754", "abs": "https://arxiv.org/abs/2509.09754", "authors": ["Yiqun Shen", "Song Yuan", "Zhengze Zhang", "Xiaoliang Wang", "Daxin Jiang", "Nguyen Cam-Tu"], "title": "LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "KV Cache is commonly used to accelerate LLM inference with long contexts, yet\nits high memory demand drives the need for cache compression. Existing\ncompression methods, however, are largely heuristic and lack dynamic budget\nallocation. To address this limitation, we introduce a unified framework for\ncache compression by minimizing information loss in Transformer residual\nstreams. Building on it, we analyze the layer attention output loss and derive\na new metric to compare cache entries across heads, enabling layer-wise\ncompression with dynamic head budgets. Additionally, by contrasting cross-layer\ninformation, we also achieve dynamic layer budgets. LAVa is the first unified\nstrategy for cache eviction and dynamic budget allocation that, unlike prior\nmethods, does not rely on training or the combination of multiple strategies.\nExperiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and\nInfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a\nnew insight: dynamic layer budgets are crucial for generation tasks (e.g., code\ncompletion), while dynamic head budgets play a key role in extraction tasks\n(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently\nmaintains top performance across task types. Our code is available at\nhttps://github.com/MGDDestiny/Lava.", "AI": {"tldr": "LAVa introduces a unified framework for compressing KV Cache in LLM inference, enabling dynamic allocation of layer and head budgets without additional training, leading to superior results across tasks.", "motivation": "The paper aims to address the high memory demand in KV Cache used for accelerating LLM inference, especially with long contexts, by proposing an effective compression method.", "method": "The proposed method minimizes information loss in Transformer residual streams by analyzing attention output loss and contrasting cross-layer information, resulting in dynamic budget allocation for layer and head compression.", "result": "Experiments on diverse benchmarks show LAVa's superiority in both generation tasks (dynamic layer budgets) and extraction tasks (dynamic head budgets), achieving consistent top performance.", "conclusion": "LAVa establishes itself as a fully dynamic compression method for KV Cache, showcasing its effectiveness and versatility without relying on training or combined strategies."}}
{"id": "2509.09702", "pdf": "https://arxiv.org/pdf/2509.09702", "abs": "https://arxiv.org/abs/2509.09702", "authors": ["Ninad Bhat", "Kieran Browne", "Pip Bingemann"], "title": "Creativity Benchmark: A benchmark for marketing creativity for LLM models", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "30 Pages, 14 figures", "summary": "We introduce Creativity Benchmark, an evaluation framework for large language\nmodels (LLMs) in marketing creativity. The benchmark covers 100 brands (12\ncategories) and three prompt types (Insights, Ideas, Wild Ideas). Human\npairwise preferences from 678 practising creatives over 11,012 anonymised\ncomparisons, analysed with Bradley-Terry models, show tightly clustered\nperformance with no model dominating across brands or prompt types: the\ntop-bottom spread is $\\Delta\\theta \\approx 0.45$, which implies a head-to-head\nwin probability of $0.61$; the highest-rated model beats the lowest only about\n$61\\%$ of the time. We also analyse model diversity using cosine distances to\ncapture intra- and inter-model variation and sensitivity to prompt reframing.\nComparing three LLM-as-judge setups with human rankings reveals weak,\ninconsistent correlations and judge-specific biases, underscoring that\nautomated judges cannot substitute for human evaluation. Conventional\ncreativity tests also transfer only partially to brand-constrained tasks.\nOverall, the results highlight the need for expert human evaluation and\ndiversity-aware workflows.", "AI": {"tldr": "The paper introduces a framework, Creativity Benchmark, to assess creativity in large language models (LLMs), specifically in marketing domains. Using human evaluations, it finds limited variability in model performance across brands and highlights the importance of human judgments over automated methods for assessing creativity.", "motivation": "The paper aims to address the challenge of evaluating the creative capabilities of LLMs in marketing tasks, where measuring insight, originality, and wild creative ideas is vital.", "method": "The benchmark evaluates LLMs on 100 brands across three prompt types and gathers human preferences through 11,012 comparisons. Bradley-Terry models assess performance clustering, and cosine distances analyze diversity. It compares human rankings with three LLM-as-judge setups.", "result": "No single model performs consistently over all brands and prompt types. Human evaluations show clustered performance, and automated judgments exhibit weak correlations with human rankings, revealing judge-specific biases.", "conclusion": "Results emphasize the need for expert human judgment and workflows that account for diversity, as automated evaluation methods and conventional creativity tests fall short in brand-specific creative tasks."}}
{"id": "2509.09730", "pdf": "https://arxiv.org/pdf/2509.09730", "abs": "https://arxiv.org/abs/2509.09730", "authors": ["Kaikai Zhao", "Zhaoxiang Liu", "Peng Wang", "Xin Wang", "Zhicheng Ma", "Yajun Xu", "Wenjing Zhang", "Yibing Nan", "Kai Wang", "Shiguo Lian"], "title": "MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance", "categories": ["cs.CV", "cs.AI"], "comment": "accepted by Image and Vision Computing", "summary": "General-domain large multimodal models (LMMs) have achieved significant\nadvances in various image-text tasks. However, their performance in the\nIntelligent Traffic Surveillance (ITS) domain remains limited due to the\nabsence of dedicated multimodal datasets. To address this gap, we introduce\nMITS (Multimodal Intelligent Traffic Surveillance), the first large-scale\nmultimodal benchmark dataset specifically designed for ITS. MITS includes\n170,400 independently collected real-world ITS images sourced from traffic\nsurveillance cameras, annotated with eight main categories and 24 subcategories\nof ITS-specific objects and events under diverse environmental conditions.\nAdditionally, through a systematic data generation pipeline, we generate\nhigh-quality image captions and 5 million instruction-following visual\nquestion-answer pairs, addressing five critical ITS tasks: object and event\nrecognition, object counting, object localization, background analysis, and\nevent reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream\nLMMs on this dataset, enabling the development of ITS-specific applications.\nExperimental results show that MITS significantly improves LMM performance in\nITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905\n(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to\n0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the\ndataset, code, and models as open-source, providing high-value resources to\nadvance both ITS and LMM research.", "AI": {"tldr": "The authors present MITS, a large-scale multimodal dataset for Intelligent Traffic Surveillance (ITS), designed to improve the performance of large multimodal models (LMMs) in ITS-specific tasks.", "motivation": "General large multimodal models perform poorly in the ITS domain due to a lack of dedicated multimodal datasets.", "method": "The authors created the MITS dataset, comprising 170,400 real-world ITS images with diverse annotations and an additional 5 million ITS-specific visual QA pairs. They fine-tuned mainstream LMMs on this dataset.", "result": "The fine-tuned LMMs showed significant performance improvements, e.g., LLaVA-1.5's accuracy increased by 83.2%, and other models also achieved notable gains in ITS tasks.", "conclusion": "MITS fills a critical gap, enhances LMM performance in ITS applications, and supports ITS and LMM research by releasing resources as open-source."}}
{"id": "2509.09893", "pdf": "https://arxiv.org/pdf/2509.09893", "abs": "https://arxiv.org/abs/2509.09893", "authors": ["Hanbit Oh", "Masaki Murooka", "Tomohiro Motoda", "Ryoichi Nakajo", "Yukiyasu Domae"], "title": "Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision", "categories": ["cs.RO", "cs.AI"], "comment": "Under review", "summary": "Imitation learning is a promising paradigm for training robot agents;\nhowever, standard approaches typically require substantial data acquisition --\nvia numerous demonstrations or random exploration -- to ensure reliable\nperformance. Although exploration reduces human effort, it lacks safety\nguarantees and often results in frequent collisions -- particularly in\nclearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual\nenvironmental resets and imposing additional human burden. This study proposes\nSelf-Augmented Robot Trajectory (SART), a framework that enables policy\nlearning from a single human demonstration, while safely expanding the dataset\nthrough autonomous augmentation. SART consists of two stages: (1) human\nteaching only once, where a single demonstration is provided and precision\nboundaries -- represented as spheres around key waypoints -- are annotated,\nfollowed by one environment reset; (2) robot self-augmentation, where the robot\ngenerates diverse, collision-free trajectories within these boundaries and\nreconnects to the original demonstration. This design improves the data\ncollection efficiency by minimizing human effort while ensuring safety.\nExtensive evaluations in simulation and real-world manipulation tasks show that\nSART achieves substantially higher success rates than policies trained solely\non human-collected demonstrations. Video results available at\nhttps://sites.google.com/view/sart-il .", "AI": {"tldr": "This paper proposes a new framework, SART, which allows robots to learn from a single human demonstration and autonomously augment their data safely.", "motivation": "Traditional imitation learning methods require significant human effort or risk collisions in robot exploration, creating inefficiencies and safety concerns.", "method": "SART operates in two stages: (1) a single human demonstration with precision data annotated and (2) autonomous, safe robot trajectory generation based on these boundaries.", "result": "Experiments in both simulation and real-world tasks show SART leads to higher success rates compared to traditional methods relying purely on human demonstrations.", "conclusion": "SART reduces human effort required for data collection, ensures safety in robot learning, and improves policy performance in manipulation tasks."}}
{"id": "2509.09918", "pdf": "https://arxiv.org/pdf/2509.09918", "abs": "https://arxiv.org/abs/2509.09918", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "WALL: A Web Application for Automated Quality Assurance using Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "As software projects become increasingly complex, the volume and variety of\nissues in code files have grown substantially. Addressing this challenge\nrequires efficient issue detection, resolution, and evaluation tools. This\npaper presents WALL, a web application that integrates SonarQube and large\nlanguage models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these\ntasks. WALL comprises three modules: an issue extraction tool, code issues\nreviser, and code comparison tool. Together, they enable a seamless pipeline\nfor detecting software issues, generating automated code revisions, and\nevaluating the accuracy of revisions. Our experiments, conducted on 563 files\nwith over 7,599 issues, demonstrate WALL's effectiveness in reducing human\neffort while maintaining high-quality revisions. Results show that employing a\nhybrid approach of cost-effective and advanced LLMs can significantly lower\ncosts and improve revision rates. Future work aims to enhance WALL's\ncapabilities by integrating open-source LLMs and eliminating human\nintervention, paving the way for fully automated code quality management.", "AI": {"tldr": "This paper introduces WALL, a web application combining SonarQube and LLMs, to automate issue detection, code revision, and evaluation in software projects.", "motivation": "The paper addresses the growing complexity and variety of issues in software projects, requiring efficient tools for detection, resolution, and evaluation.", "method": "WALL integrates SonarQube with large language models (GPT-3.5 and GPT-4) and consists of three modules: issue extraction, automated code revision, and revision evaluation.", "result": "Experiments on 563 files with over 7,599 issues show WALL's effectiveness in reducing human effort and maintaining high-quality code revisions while minimizing costs.", "conclusion": "WALL shows promise in automating code quality management with LLMs, and future work aims to expand capabilities by using open-source models and achieving full automation."}}
{"id": "2509.10400", "pdf": "https://arxiv.org/pdf/2509.10400", "abs": "https://arxiv.org/abs/2509.10400", "authors": ["Yang Zhong", "Haoran Wu", "Xueqi Li", "Sa Wang", "David Boland", "Yungang Bao", "Kan Shi"], "title": "TurboFuzz: FPGA Accelerated Hardware Fuzzing for Processor Agile Verification", "categories": ["cs.AR"], "comment": null, "summary": "Verification is a critical process for ensuring the correctness of modern\nprocessors. The increasing complexity of processor designs and the emergence of\nnew instruction set architectures (ISAs) like RISC-V have created demands for\nmore agile and efficient verification methodologies, particularly regarding\nverification efficiency and faster coverage convergence. While simulation-based\napproaches now attempt to incorporate advanced software testing techniques such\nas fuzzing to improve coverage, they face significant limitations when applied\nto processor verification, notably poor performance and inadequate test case\nquality. Hardware-accelerated solutions using FPGA or ASIC platforms have tried\nto address these issues, yet they struggle with challenges including host-FPGA\ncommunication overhead, inefficient test pattern generation, and suboptimal\nimplementation of the entire multi-step verification process.\n  In this paper, we present TurboFuzz, an end-to-end hardware-accelerated\nverification framework that implements the entire Test\nGeneration-Simulation-Coverage Feedback loop on a single FPGA for modern\nprocessor verification. TurboFuzz enhances test quality through optimized test\ncase (seed) control flow, efficient inter-seed scheduling, and hybrid fuzzer\nintegration, thereby improving coverage and execution efficiency. Additionally,\nit employs a feedback-driven generation mechanism to accelerate coverage\nconvergence. Experimental results show that TurboFuzz achieves up to 2.23x more\ncoverage collection than software-based fuzzers within the same time budget,\nand up to 571x performance speedup when detecting real-world issues, while\nmaintaining full visibility and debugging capabilities with moderate area\noverhead.", "AI": {"tldr": "TurboFuzz is a hardware-accelerated framework on FPGA for processor verification, achieving higher coverage and faster performance compared to software-based fuzzers.", "motivation": "Processor complexity and emerging ISAs like RISC-V demand agile and efficient verification tools to address limitations in current simulation-based and hardware-accelerated solutions.", "method": "TurboFuzz combines test generation, simulation, and coverage feedback in an FPGA-based framework, utilizing optimized test cases, inter-seed scheduling, and hybrid fuzzing.", "result": "TurboFuzz exhibits up to 2.23x coverage improvement and 571x performance speedup over conventional software fuzzers under the same conditions.", "conclusion": "TurboFuzz significantly enhances processor verification efficiency and visibility with moderate resource usage, addressing major shortcomings of existing methods."}}
{"id": "2509.10385", "pdf": "https://arxiv.org/pdf/2509.10385", "abs": "https://arxiv.org/abs/2509.10385", "authors": ["Utsab Saha", "Tanvir Muntakim Tonoy", "Hafiz Imtiaz"], "title": "Differentially Private Decentralized Dataset Synthesis Through Randomized Mixing with Correlated Noise", "categories": ["stat.ML", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In this work, we explore differentially private synthetic data generation in\na decentralized-data setting by building on the recently proposed\nDifferentially Private Class-Centric Data Aggregation (DP-CDA). DP-CDA\nsynthesizes data in a centralized setting by mixing multiple randomly-selected\nsamples from the same class and injecting carefully calibrated Gaussian noise,\nensuring ({\\epsilon}, {\\delta})-differential privacy. When deployed in a\ndecentralized or federated setting, where each client holds only a small\npartition of the data, DP-CDA faces new challenges. The limited sample size per\nclient increases the sensitivity of local computations, requiring higher noise\ninjection to maintain the differential privacy guarantee. This, in turn, leads\nto a noticeable degradation in the utility compared to the centralized setting.\nTo mitigate this issue, we integrate the Correlation-Assisted Private\nEstimation (CAPE) protocol into the federated DP-CDA framework and propose CAPE\nAssisted Federated DP-CDA algorithm. CAPE enables limited collaboration among\nthe clients by allowing them to generate jointly distributed (anti-correlated)\nnoise that cancels out in aggregate, while preserving privacy at the individual\nlevel. This technique significantly improves the privacy-utility trade-off in\nthe federated setting. Extensive experiments on MNIST and FashionMNIST datasets\ndemonstrate that the proposed CAPE Assisted Federated DP-CDA approach can\nachieve utility comparable to its centralized counterpart under some parameter\nregime, while maintaining rigorous differential privacy guarantees.", "AI": {"tldr": "The paper enhances differentially private synthetic data generation in federated settings by introducing a CAPE-assisted DP-CDA framework, which balances the privacy-utility trade-off through anti-correlated noise generation among clients.", "motivation": "Addressing the utility degradation of DP-CDA in decentralized settings due to smaller local datasets and higher noise requirements.", "method": "The CAPE-Assisted Federated DP-CDA algorithm incorporates the CAPE protocol for generating anti-correlated noise among clients to reduce the privacy-utility trade-off while upholding privacy standards.", "result": "Experiments on MNIST and FashionMNIST datasets show that the proposed approach achieves utility comparable to centralized methods under certain parameter settings while maintaining strong differential privacy guarantees.", "conclusion": "The proposed CAPE-Assisted Federated DP-CDA framework offers a promising solution to the challenges of generating utility-preserving differentially private synthetic data in federated settings."}}
{"id": "2509.10046", "pdf": "https://arxiv.org/pdf/2509.10046", "abs": "https://arxiv.org/abs/2509.10046", "authors": ["Jacob Maaz", "Laurent Waroquier", "Alexandra Dia", "V\u00e9ronique Paban", "Arnaud Rey"], "title": "The nature of alpha modulation through neurofeedback", "categories": ["q-bio.NC"], "comment": null, "summary": "Electroencephalographic neurofeedback (EEG-NF) has been proposed as a\npromising technique to modulate brain activity through real-time EEG-based\nfeedback. Alpha neurofeedback in particular is believed to induce rapid\nself-regulation of brain rhythms, with applications in cognitive enhancement\nand clinical treatment. However, whether this modulation reflects specific\nvolitional control or non-specific influences remains unresolved. In a\npreregistered, double-blind, sham-controlled study, we evaluated alpha\nupregulation in healthy participants receiving either genuine or sham EEG-NF\nduring a single-session design. A third arm composed of a passive control group\nwas also included to differentiate between non-specific influences related or\nnot to the active engagement in EEG-NF. Throughout the session, alpha power\nincreased robustly, yet independently of feedback veracity, engagement in\nself-regulation, or feedback update frequency. Parallel increases in theta and\nsensorimotor rhythms further suggest broadband non-specific modulation.\nImportantly, these results challenge the foundational assumption of EEG-NF:\nthat feedback enables volitional EEG control. Instead, they point to\nspontaneous repetition-related processes as primary drivers, calling for a\ncritical reassessment of neurofeedback efficacy and its underlying mechanisms.", "AI": {"tldr": "EEG neurofeedback (EEG-NF), particularly alpha modulation, may not rely on volitional control but rather on spontaneous processes unrelated to feedback credibility or engagement.", "motivation": "The study aims to evaluate the efficacy of alpha EEG neurofeedback in inducing volitional brain activity modulation, addressing unresolved questions about specific versus non-specific influences.", "method": "A preregistered, double-blind, sham-controlled, single-session design was used with three groups: genuine EEG-NF, sham feedback, and passive control, measuring changes in alpha power and other EEG rhythms.", "result": "Alpha power increased robustly across all groups, regardless of feedback veracity or active engagement, alongside parallel increases in theta and sensorimotor rhythms indicating non-specific, broadband modulation.", "conclusion": "The findings argue against the foundational assumption of EEG-NF as a volitional EEG control technique, suggesting spontaneous repetition-related processes as the primary driver and calling for reevaluation of its mechanisms and efficacy."}}
{"id": "2509.10161", "pdf": "https://arxiv.org/pdf/2509.10161", "abs": "https://arxiv.org/abs/2509.10161", "authors": ["Shiwei Li", "Qunwei Li", "Haozhao Wang", "Ruixuan Li", "Jianbin Lin", "Wenliang Zhong"], "title": "FedBiF: Communication-Efficient Federated Learning via Bits Freezing", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by TPDS", "summary": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative model training without sharing local data. Despite\nits advantages, FL suffers from substantial communication overhead, which can\naffect training efficiency. Recent efforts have mitigated this issue by\nquantizing model updates to reduce communication costs. However, most existing\nmethods apply quantization only after local training, introducing quantization\nerrors into the trained parameters and potentially degrading model accuracy. In\nthis paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework\nthat directly learns quantized model parameters during local training. In each\ncommunication round, the server first quantizes the model parameters and\ntransmits them to the clients. FedBiF then allows each client to update only a\nsingle bit of the multi-bit parameter representation, freezing the remaining\nbits. This bit-by-bit update strategy reduces each parameter update to one bit\nwhile maintaining high precision in parameter representation. Extensive\nexperiments are conducted on five widely used datasets under both IID and\nNon-IID settings. The results demonstrate that FedBiF not only achieves\nsuperior communication compression but also promotes sparsity in the resulting\nmodels. Notably, FedBiF attains accuracy comparable to FedAvg, even when using\nonly 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.\nThe code is available at https://github.com/Leopold1423/fedbif-tpds25.", "AI": {"tldr": "This paper introduces Federated Bit Freezing (FedBiF), a new federated learning framework that reduces communication overhead by updating only a single bit of model parameters per round, while maintaining high accuracy.", "motivation": "Communication overhead in federated learning remains a challenge, especially when quantization techniques introduce errors during local training, potentially degrading model performance.", "method": "FedBiF quantizes model parameters at the server side before transmission and enables clients to update only one bit per parameter, freezing the rest, which minimizes communication while retaining precision.", "result": "Extensive experiments across five datasets demonstrate that FedBiF achieves high communication compression, fosters sparsity in models, and maintains accuracy comparable to FedAvg. Specifically, it uses only 1 bpp for uplink and 3 bpp for downlink communication.", "conclusion": "FedBiF provides a highly efficient communication strategy for federated learning without compromising model accuracy, making it a strong alternative for resource-constrained scenarios."}}
{"id": "2509.09772", "pdf": "https://arxiv.org/pdf/2509.09772", "abs": "https://arxiv.org/abs/2509.09772", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management", "categories": ["cs.LG", "stat.AP"], "comment": "10 pages, 5 figures, 4 tables", "summary": "Population health management programs for Medicaid populations coordinate\nlongitudinal outreach and services (e.g., benefits navigation, behavioral\nhealth, social needs support, and clinical scheduling) and must be safe, fair,\nand auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement\nLearning (HACO) framework that separates risk calibration from preference\noptimization to generate conservative action recommendations at scale. In our\nsetting, each step involves choosing among common coordination actions (e.g.,\nwhich member to contact, by which modality, and whether to route to a\nspecialized service) while controlling the near-term risk of adverse\nutilization events (e.g., unplanned emergency department visits or\nhospitalizations). Using a de-identified operational dataset from Waymark\ncomprising 2.77 million sequential decisions across 168,126 patients, HACO (i)\ntrains a lightweight risk model for adverse events, (ii) derives a conformal\nthreshold to mask unsafe actions at a target risk level, and (iii) learns a\npreference policy on the resulting safe subset. We evaluate policies with a\nversion-agnostic fitted Q evaluation (FQE) on stratified subsets and audit\nsubgroup performance across age, sex, and race. HACO achieves strong risk\ndiscrimination (AUC ~0.81) with a calibrated threshold ( {\\tau} ~0.038 at\n{\\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses\nreveal systematic differences in estimated value across demographics,\nunderscoring the importance of fairness auditing. Our results show that\nconformal risk gating integrates cleanly with offline RL to deliver\nconservative, auditable decision support for population health management\nteams.", "AI": {"tldr": "The paper introduces HACO, a framework combining conformal risk gating with offline reinforcement learning to create safe, auditable, and fair decision support systems for managing Medicaid population health.", "motivation": "To develop a framework that ensures safe and auditable population health management decisions while accounting for fairness in risk calibration and optimization.", "method": "The approach trains a risk model for predicting adverse events, applies conformal thresholds to mask unsafe decisions, and optimizes action preferences on the safe set. It evaluates policies using fitted Q evaluation and audits demographic subgroup performance.", "result": "HACO demonstrates strong risk discrimination (AUC ~0.81) with a calibrated threshold and maintains high coverage, while subgroup audits highlight the importance of fairness due to systematic demographic differences in policy outcomes.", "conclusion": "HACO successfully integrates conformal risk gating with offline RL, providing secure, fair, and scalable tools for Medicaid population health management."}}
{"id": "2509.09703", "pdf": "https://arxiv.org/pdf/2509.09703", "abs": "https://arxiv.org/abs/2509.09703", "authors": ["Zhenhua Xu", "Xixiang Zhao", "Xubin Yue", "Shengwei Tian", "Changting Lin", "Meng Han"], "title": "CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by EMNLP2025 MainConference", "summary": "The widespread deployment of large language models (LLMs) has intensified\nconcerns around intellectual property (IP) protection, as model theft and\nunauthorized redistribution become increasingly feasible. To address this,\nmodel fingerprinting aims to embed verifiable ownership traces into LLMs.\nHowever, existing methods face inherent trade-offs between stealthness,\nrobustness, and generalizability, being either detectable via distributional\nshifts, vulnerable to adversarial modifications, or easily invalidated once the\nfingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven\nfingerprinting framework that encodes contextual correlations across multiple\ndialogue turns, such as counterfactual, rather than relying on token-level or\nsingle-turn triggers. CTCC enables fingerprint verification under black-box\naccess while mitigating false positives and fingerprint leakage, supporting\ncontinuous construction under a shared semantic rule even if partial triggers\nare exposed. Extensive experiments across multiple LLM architectures\ndemonstrate that CTCC consistently achieves stronger stealth and robustness\nthan prior work. Our findings position CTCC as a reliable and practical\nsolution for ownership verification in real-world LLM deployment scenarios. Our\ncode and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.", "AI": {"tldr": "This paper introduces CTCC, a fingerprinting framework for verifying LLM ownership using contextual correlations across dialogue turns, demonstrating superior stealth and robustness compared to prior methods.", "motivation": "The growing use of large language models has raised concerns about intellectual property theft and unauthorized redistribution, necessitating methods for reliable ownership verification.", "method": "A rule-driven fingerprinting framework called CTCC is introduced, encoding contextual correlations across multiple dialogue turns instead of relying on single-token or single-turn triggers.", "result": "Experimental results show CTCC achieves stronger stealth and robustness compared to existing fingerprinting approaches, even under black-box access situations.", "conclusion": "CTCC offers a more dependable and practical method for ownership verification in LLMs, addressing challenges like false positives, fingerprint leakage, and resilience to adversarial attacks."}}
{"id": "2509.09732", "pdf": "https://arxiv.org/pdf/2509.09732", "abs": "https://arxiv.org/abs/2509.09732", "authors": ["Sary Elmansoury", "Islam Mesabah", "Gerrit Gro\u00dfmann", "Peter Neigel", "Raj Bhalwankar", "Daniel Kondermann", "Sebastian J. Vollmer"], "title": "Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Vision language models (VLMs) excel at zero-shot visual classification, but\ntheir performance on fine-grained tasks and large hierarchical label spaces is\nunderstudied. This paper investigates whether structured, tree-based reasoning\ncan enhance VLM performance. We introduce a framework that decomposes\nclassification into interpretable decisions using decision trees and evaluates\nit on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the\nmodel achieves 98.2% accuracy in understanding the tree knowledge, tree-based\nreasoning consistently underperforms standard zero-shot prompting. We also\nexplore enhancing the tree prompts with LLM-generated classes and image\ndescriptions to improve alignment. The added description enhances the\nperformance of the tree-based and zero-shot methods. Our findings highlight\nlimitations of structured reasoning in visual classification and offer insights\nfor designing more interpretable VLM systems.", "AI": {"tldr": "The paper investigates the use of decision trees for improving fine-grained visual classification performance in Vision Language Models (VLMs), finding that tree-based reasoning underperforms compared to standard zero-shot prompting, though enhancements in prompts can boost performance.", "motivation": "To explore whether structured reasoning approaches like decision trees can improve the interpretability and performance of VLMs, particularly on fine-grained and hierarchical classification tasks.", "method": "Introduced a framework utilizing decision trees to decompose visual classification into interpretable steps, evaluating its effectiveness on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Performance was compared to standard zero-shot prompting, and tree prompts were enhanced with LLM-generated classes and image descriptions to improve alignment.", "result": "Tree-based reasoning achieved 98.2% accuracy in tree knowledge understanding but underperformed compared to zero-shot prompting on both datasets. Adding image descriptions improved the performance of both tree-based and zero-shot methods.", "conclusion": "Structured reasoning like decision trees provides interpretability but is less effective in performance for visual classification tasks compared to standard methods. Improvements in prompts offer avenues for enhancing both interpretability and accuracy in VLM systems."}}
{"id": "2509.09953", "pdf": "https://arxiv.org/pdf/2509.09953", "abs": "https://arxiv.org/abs/2509.09953", "authors": ["Mahfuzul I. Nissan", "Sharmin Aktar"], "title": "Detection of Anomalous Behavior in Robot Systems Based on Machine Learning", "categories": ["cs.RO"], "comment": null, "summary": "Ensuring the safe and reliable operation of robotic systems is paramount to\nprevent potential disasters and safeguard human well-being. Despite rigorous\ndesign and engineering practices, these systems can still experience\nmalfunctions, leading to safety risks. In this study, we present a machine\nlearning-based approach for detecting anomalies in system logs to enhance the\nsafety and reliability of robotic systems. We collected logs from two distinct\nscenarios using CoppeliaSim and comparatively evaluated several machine\nlearning models, including Logistic Regression (LR), Support Vector Machine\n(SVM), and an Autoencoder. Our system was evaluated in a quadcopter context\n(Context 1) and a Pioneer robot context (Context 2). Results showed that while\nLR demonstrated superior performance in Context 1, the Autoencoder model proved\nto be the most effective in Context 2. This highlights that the optimal model\nchoice is context-dependent, likely due to the varying complexity of anomalies\nacross different robotic platforms. This research underscores the value of a\ncomparative approach and demonstrates the particular strengths of autoencoders\nfor detecting complex anomalies in robotic systems.", "AI": {"tldr": "This study proposes a machine learning-based system for anomaly detection in robotic systems, comparing different models for two robotic contexts.", "motivation": "To ensure the safe and reliable operation of robotic systems by addressing potential safety risks through anomaly detection.", "method": "Collected logs from robotic simulations (CoppeliaSim) in two contexts and evaluated machine learning models including Logistic Regression, Support Vector Machine, and Autoencoder.", "result": "Logistic Regression excelled in one context (quadcopter), while the Autoencoder was most effective in another (Pioneer robot), indicating context dependency.", "conclusion": "The study emphasizes the importance of context in model selection and highlights the effectiveness of autoencoders for complex anomaly detection in robotic systems."}}
{"id": "2509.09947", "pdf": "https://arxiv.org/pdf/2509.09947", "abs": "https://arxiv.org/abs/2509.09947", "authors": ["Humza Ashraf", "Syed Muhammad Danish", "Zeeshan Sattar"], "title": "Toward Green Code: Prompting Small Language Models for Energy-Efficient Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "There is a growing concern about the environmental impact of large language\nmodels (LLMs) in software development, particularly due to their high energy\nuse and carbon footprint. Small Language Models (SLMs) offer a more sustainable\nalternative, requiring fewer computational resources while remaining effective\nfor fundamental programming tasks. In this study, we investigate whether prompt\nengineering can improve the energy efficiency of SLMs in code generation. We\nevaluate four open-source SLMs, StableCode-Instruct-3B,\nQwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct,\nacross 150 Python problems from LeetCode, evenly distributed into easy, medium,\nand hard categories. Each model is tested under four prompting strategies: role\nprompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated\nsolution, we measure runtime, memory usage, and energy consumption, comparing\nthe results with a human-written baseline. Our findings show that CoT prompting\nprovides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while\nCodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any\nprompting strategy. These results highlight that the benefits of prompting are\nmodel-dependent and that carefully designed prompts can guide SLMs toward\ngreener software development.", "AI": {"tldr": "The paper evaluates whether prompt engineering can improve the energy efficiency of Small Language Models (SLMs) in code generation, with mixed results depending on the model.", "motivation": "To address the high energy usage and carbon footprint of Large Language Models (LLMs) by exploring whether SLMs can be made more energy-efficient for programming tasks through prompt engineering.", "method": "Four open-source SLMs were tested on 150 Python problems at various difficulty levels using four prompting strategies, measuring runtime, memory usage, and energy consumption for comparison against a human-written baseline.", "result": "Chain-of-Thought (CoT) prompting achieved consistent energy savings for Qwen2.5-Coder and StableCode-3B, while CodeLlama-7B and Phi-3-Mini-4K could not outperform the baseline under any prompting strategy.", "conclusion": "Prompt engineering has the potential to enhance the energy efficiency of SLMs, but its effectiveness is model-dependent, emphasizing the need for tailored prompt designs to promote greener software development."}}
{"id": "2509.09802", "pdf": "https://arxiv.org/pdf/2509.09802", "abs": "https://arxiv.org/abs/2509.09802", "authors": ["Tianqi Qiao", "Marie Maros"], "title": "Sparse Polyak: an adaptive step size rule for high-dimensional M-estimation", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We propose and study Sparse Polyak, a variant of Polyak's adaptive step size,\ndesigned to solve high-dimensional statistical estimation problems where the\nproblem dimension is allowed to grow much faster than the sample size. In such\nsettings, the standard Polyak step size performs poorly, requiring an\nincreasing number of iterations to achieve optimal statistical precision-even\nwhen, the problem remains well conditioned and/or the achievable precision\nitself does not degrade with problem size. We trace this limitation to a\nmismatch in how smoothness is measured: in high dimensions, it is no longer\neffective to estimate the Lipschitz smoothness constant. Instead, it is more\nappropriate to estimate the smoothness restricted to specific directions\nrelevant to the problem (restricted Lipschitz smoothness constant). Sparse\nPolyak overcomes this issue by modifying the step size to estimate the\nrestricted Lipschitz smoothness constant. We support our approach with both\ntheoretical analysis and numerical experiments, demonstrating its improved\nperformance.", "AI": {"tldr": "The paper introduces Sparse Polyak, a novel adaptive step size for statistical estimation in high-dimensional settings, addressing limitations of the standard Polyak method.", "motivation": "To address the inefficiency of the traditional Polyak's step size in high-dimensional statistical estimation problems.", "method": "The authors propose Sparse Polyak, which adapts the step size using the restricted Lipschitz smoothness constant rather than the traditional Lipschitz smoothness constant.", "result": "Sparse Polyak achieves better statistical precision and reduces iteration count, as shown through theoretical analysis and numerical experiments.", "conclusion": "Sparse Polyak is an effective solution for high-dimensional estimation by tailoring step size to problem-specific smoothness."}}
{"id": "2509.10428", "pdf": "https://arxiv.org/pdf/2509.10428", "abs": "https://arxiv.org/abs/2509.10428", "authors": ["Daniele Andrean", "Morten Gram Pedersen"], "title": "Near-Hamiltonian dynamics and energy-like quantities of next-generation neural mass models", "categories": ["q-bio.NC", "math.DS", "physics.class-ph"], "comment": "11 pages, 6 figures, 1 page Supplementary text", "summary": "Neural mass models describe the mean-field dynamics of populations of\nneurons. In this work we illustrate how fundamental ideas of physics, such as\nenergy and conserved quantities, can be explored for such models. We show that\ntime-rescaling renders recent next-generation neural mass models Hamiltonian in\nthe limit of a homogeneous population or strong coupling. The corresponding\nenergy-like quantity provides considerable insight into the model dynamics even\nin the case of heterogeneity, and explain for example why orbits are\nnear-ellipsoidal and predict spike amplitude during bursting dynamics. We\nillustrate how these energy considerations provide a possible link between\nneuronal population behavior and energy landscape theory, which has been used\nto analyze data from brain recordings. Our introduction of near-Hamiltonian\ndescriptions of neuronal activity could permit the application of highly\ndeveloped physics theory to get insight into brain behavior.", "AI": {"tldr": "The study applies principles of physics, such as energy conservation, to neural mass models, showing their Hamiltonian properties under specific conditions and connecting these to brain behavior analysis.", "motivation": "To explore whether fundamental physics concepts can enhance the understanding of neural mass models and their application to neuronal population dynamics and brain behavior.", "method": "By applying time-rescaling to next-generation neural mass models, the study demonstrates their Hamiltonian nature under strong coupling or homogeneous settings. It also extends the analysis to heterogeneous cases using energy-like quantities.", "result": "The energy-like quantities help explain orbital shapes and predict spike amplitudes during bursting dynamics, suggesting a connection to energy landscape theory used in brain data analysis.", "conclusion": "The introduction of near-Hamiltonian descriptions for neuronal activity could bridge neuroscience and advanced physics theories, offering deeper insights into brain behavior."}}
{"id": "2509.09919", "pdf": "https://arxiv.org/pdf/2509.09919", "abs": "https://arxiv.org/abs/2509.09919", "authors": ["Franklin Yiu", "Mohan Lu", "Nina Li", "Kevin Joseph", "Tianxu Zhang", "Julian Togelius", "Timothy Merino", "Sam Earle"], "title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments", "categories": ["cs.AI"], "comment": null, "summary": "Procedural content generation often requires satisfying both\ndesigner-specified objectives and adjacency constraints implicitly imposed by\nthe underlying tile set. To address the challenges of jointly optimizing both\nconstraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a\nMarkov Decision Process (MDP), enabling external optimization algorithms to\nfocus exclusively on objective maximization while leveraging WFC's propagation\nmechanism to enforce constraint satisfaction. We empirically compare optimizing\nthis MDP to traditional evolutionary approaches that jointly optimize global\nmetrics and local tile placement. Across multiple domains with various\ndifficulties, we find that joint optimization not only struggles as task\ncomplexity increases, but consistently underperforms relative to optimization\nover the WFC-MDP, underscoring the advantages of decoupling local constraint\nsatisfaction from global objective optimization.", "AI": {"tldr": "The paper introduces an approach that reformulates WaveFunctionCollapse as a Markov Decision Process to better satisfy designer objectives and constraints in procedural content generation. Empirical results show this method outperforms traditional evolutionary approaches.", "motivation": "The motivation is to address challenges in procedural content generation where satisfying constraints and designer-specified objectives simultaneously is complex, particularly as task difficulty increases.", "method": "The authors reformulate WaveFunctionCollapse into a Markov Decision Process, allowing external optimization algorithms to focus on maximizing objectives while utilizing WFC's propagation mechanism for constraint enforcement.", "result": "Experiments across various domains indicate that the WFC-MDP approach consistently outperforms traditional joint optimization methods, particularly for complex tasks.", "conclusion": "Decoupling local constraint satisfaction from global objective optimization using the WFC-MDP framework enhances performance and scalability in procedural content generation tasks."}}
{"id": "2509.09782", "pdf": "https://arxiv.org/pdf/2509.09782", "abs": "https://arxiv.org/abs/2509.09782", "authors": ["Roshini Pulishetty", "Mani Kishan Ghantasala", "Keerthy Kaushik Dasoju", "Niti Mangwani", "Vishal Garimella", "Aditya Mate", "Somya Chatterjee", "Yue Kang", "Ehi Nosakhare", "Sadid Hasan", "Soundar Srinivasan"], "title": "One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection", "categories": ["cs.LG"], "comment": null, "summary": "The proliferation of large language models (LLMs) with varying computational\ncosts and performance profiles presents a critical challenge for scalable,\ncost-effective deployment in real-world applications. We introduce a unified\nrouting framework that leverages a single-head cross-attention mechanism to\njointly model query and model embeddings, enabling dynamic selection of the\noptimal LLM for each input query. Our approach is evaluated on RouterBench, a\nlarge-scale, publicly available benchmark encompassing diverse LLM pools and\ndomains. By explicitly capturing fine-grained query-model interactions, our\nrouter predicts both response quality and generation cost, achieving up to 6.6%\nimprovement in Average Improvement in Quality (AIQ) and 2.9% in maximum\nperformance over existing routers. To robustly balance performance and cost, we\npropose an exponential reward function that enhances stability across user\npreferences. The resulting architecture is lightweight, generalizes effectively\nacross domains, and demonstrates improved efficiency compared to prior methods,\nestablishing a new standard for cost-aware LLM routing.", "AI": {"tldr": "The paper introduces a unified system for routing queries to the most suitable large language model (LLM), optimizing for both cost and quality.", "motivation": "Scalable and cost-effective usage of LLMs across diverse queries in real-world applications requires efficient routing techniques.", "method": "The authors employ a single-head cross-attention mechanism to simultaneously analyze input queries and model embeddings, predicting which LLM is optimal for each query. This framework is tested using RouterBench, a benchmark covering various LLMs and domains.", "result": "This method improves Average Improvement in Quality (AIQ) by up to 6.6% and maximum performance by 2.9% compared to existing routers, while balancing performance and cost using an exponential reward function.", "conclusion": "The proposed approach is lightweight, domain-generalizable, and efficient, setting a new standard for cost-aware routing of queries across LLMs."}}
{"id": "2509.09704", "pdf": "https://arxiv.org/pdf/2509.09704", "abs": "https://arxiv.org/abs/2509.09704", "authors": ["Ali Mazyaki", "Mohammad Naghizadeh", "Samaneh Ranjkhah Zonouzaghi", "Hossein Setareh"], "title": "Temporal Preferences in Language Models for Long-Horizon Assistance", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "We study whether language models (LMs) exhibit future- versus\npresent-oriented preferences in intertemporal choice and whether those\npreferences can be systematically manipulated. Using adapted human experimental\nprotocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them\nagainst a sample of human decision makers. We introduce an operational metric,\nthe Manipulability of Time Orientation (MTO), defined as the change in an LM's\nrevealed time preference between future- and present-oriented prompts. In our\ntests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)\nchoose later options under future-oriented prompts but only partially\npersonalize decisions across identities or geographies. Moreover, models that\ncorrectly reason about time orientation internalize a future orientation for\nthemselves as AI decision makers. We discuss design implications for AI\nassistants that should align with heterogeneous, long-horizon goals and outline\na research agenda on personalized contextual calibration and socially aware\ndeployment.", "AI": {"tldr": "The paper investigates if language models (LMs) display future- versus present-oriented preferences in decision-making and evaluates how these preferences can be influenced systematically.", "motivation": "To explore whether LMs can mimic human-like intertemporal preferences and align with diverse long-term goals through manipulation of time-oriented prompts.", "method": "The paper adopts human experimental protocols to assess multiple LMs on time-tradeoff tasks, introduces an operational metric (MTO), and benchmarks LM preferences against human decision makers.", "result": "Reasoning-oriented LMs show a bias towards future-oriented choices but partially align with individual or geographical identity preferences. They also internalize future-focused reasoning as AI decision-makers.", "conclusion": "Design implications are proposed for AI assistants to better align with varied, long-term objectives. The study offers a research agenda on personalized calibration and socially aware AI deployment."}}
{"id": "2509.09737", "pdf": "https://arxiv.org/pdf/2509.09737", "abs": "https://arxiv.org/abs/2509.09737", "authors": ["Klemen Kotar", "Wanhee Lee", "Rahul Venkatesh", "Honglin Chen", "Daniel Bear", "Jared Watrous", "Simon Kim", "Khai Loong Aw", "Lilian Naing Chen", "Stefan Stojanov", "Kevin Feigelis", "Imran Thobani", "Alex Durango", "Khaled Jedoui", "Atlas Kazemian", "Dan Yamins"], "title": "World Modeling with Probabilistic Structure Integration", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We present Probabilistic Structure Integration (PSI), a system for learning\nrichly controllable and flexibly promptable world models from data. PSI\nconsists of a three-step cycle. The first step, Probabilistic prediction,\ninvolves building a probabilistic graphical model Psi of the data, in the form\nof a random-access autoregressive sequence model. Psi supports a complete set\nof learned conditional distributions describing the dependence of any variables\nin the data on any other set of variables. In step 2, Structure extraction, we\nshow how to extract underlying low-dimensional properties in the data,\ncorresponding to a diverse set of meaningful \"intermediate structures\", in a\nzero-shot fashion via causal inference on Psi. Step 3, Integration, completes\nthe cycle by converting these structures into new token types that are then\ncontinually mixed back into the training diet as conditioning signals and\nprediction targets. Each such cycle augments the capabilities of Psi, both\nallowing it to model the underlying data better, and creating new control\nhandles -- akin to an LLM-like universal prompting language. We train an\ninstance of Psi on 1.4 trillion tokens of internet video data; we use it to\nperform a variety of useful video prediction and understanding inferences; we\nextract state-of-the-art optical flow, self-supervised depth and object\nsegmentation; and we use these structures to support a full cycle of predictive\nimprovements.", "AI": {"tldr": "The paper introduces PSI, a system for creating world models from data through a cycle of probabilistic prediction, structure extraction, and integration, enabling enhanced control, analysis, and predictive capabilities.", "motivation": "To develop a system that learns flexible, controllable, and richly descriptive world models from large-scale data, enabling tasks like video prediction, understanding, and the extraction of intermediate structures.", "method": "PSI utilizes a three-step cycle: probabilistic prediction (creating a graphical model), structure extraction (deriving interpretable intermediate structures), and integration (back-feeding these structures for ongoing model improvement).", "result": "The PSI system was trained on 1.4 trillion tokens of internet video data and achieved applications such as state-of-the-art optical flow, depth, and object segmentation, as well as improved predictive accuracy for video understanding.", "conclusion": "PSI successfully demonstrates the ability to build advanced and controllable predictive models, enhancing tasks like video understanding and facilitating further innovations via an iterative learning process."}}
{"id": "2509.10007", "pdf": "https://arxiv.org/pdf/2509.10007", "abs": "https://arxiv.org/abs/2509.10007", "authors": ["Samuli Soutukorva", "Markku Suomalainen", "Martin Kollingbaum", "Tapio Heikkil\u00e4"], "title": "Gaussian path model library for intuitive robot motion programming by demonstration", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a system for generating Gaussian path models from\nteaching data representing the path shape. In addition, methods for using these\npath models to classify human demonstrations of paths are introduced. By\ngenerating a library of multiple Gaussian path models of various shapes, human\ndemonstrations can be used for intuitive robot motion programming. A method for\nmodifying existing Gaussian path models by demonstration through geometric\nanalysis is also presented.", "AI": {"tldr": "The study introduces Gaussian path models for intuitive robot motion programming using human demonstration data.", "motivation": "To simplify and enhance robot motion programming making it more intuitive through human-demonstrated paths.", "method": "Development of Gaussian path models from teaching data and enabling their classification along with geometric modifications based on human demonstrations.", "result": "Created a library of Gaussian path models and demonstrated their applicability in intuitive robot motion programming and modification.", "conclusion": "The presented system effectively enhances human-computer interaction, facilitating intuitive robot programming through Gaussian path models."}}
{"id": "2509.09975", "pdf": "https://arxiv.org/pdf/2509.09975", "abs": "https://arxiv.org/abs/2509.09975", "authors": ["Takasaburo Fukuda", "Takao Nakagawa", "Keisuke Miyazaki", "Susumu Tokumoto"], "title": "Development of Automated Software Design Document Review Methods Using Large Language Models", "categories": ["cs.SE"], "comment": "SANER 2025", "summary": "In this study, we explored an approach to automate the review process of\nsoftware design documents by using LLM. We first analyzed the review methods of\ndesign documents and organized 11 review perspectives. Additionally, we\nanalyzed the issues of utilizing LLMs for these 11 review perspectives and\ndetermined which perspectives can be reviewed by current general-purpose LLMs\ninstead of humans. For the reviewable perspectives, we specifically developed\nnew techniques to enable LLMs to comprehend complex design documents that\ninclude table data. For evaluation, we conducted experiments using GPT to\nassess the consistency of design items and descriptions across different design\ndocuments in the design process used in actual business operations. Our results\nconfirmed that LLMs can be utilized to identify inconsistencies in software\ndesign documents during the review process.", "AI": {"tldr": "This study proposes using large language models (LLMs) to automate software design document reviews by organizing review perspectives and refining LLM capabilities for complex document comprehension, with successful experiments using GPT for detecting inconsistencies.", "motivation": "The motivation was to enhance the efficiency and accuracy of reviewing software design documents by leveraging LLMs for a task traditionally reliant on human effort.", "method": "The authors analyzed 11 review perspectives, identified challenges in utilizing LLMs, refined LLM techniques to understand complex design documents, and conducted evaluations using GPT in real-world design processes.", "result": "The experiments showed that LLMs, specifically GPT, were effective in identifying inconsistencies in software design documents, proving their utility in this task.", "conclusion": "LLMs can partially automate the review process of software design documents, especially for identifying inconsistencies, reducing dependency on human reviewers."}}
{"id": "2509.09891", "pdf": "https://arxiv.org/pdf/2509.09891", "abs": "https://arxiv.org/abs/2509.09891", "authors": ["Eirini Ioannou", "Stefan Klus", "Gon\u00e7alo dos Reis"], "title": "Data-driven approximation of transfer operators for mean-field stochastic differential equations", "categories": ["math.DS", "cs.NA", "math.NA", "math.PR", "stat.ML"], "comment": null, "summary": "Mean-field stochastic differential equations, also called McKean--Vlasov\nequations, are the limiting equations of interacting particle systems with\nfully symmetric interaction potential. Such systems play an important role in a\nvariety of fields ranging from biology and physics to sociology and economics.\nGlobal information about the behavior of complex dynamical systems can be\nobtained by analyzing the eigenvalues and eigenfunctions of associated transfer\noperators such as the Perron--Frobenius operator and the Koopman operator. In\nthis paper, we extend transfer operator theory to McKean--Vlasov equations and\nshow how extended dynamic mode decomposition and the Galerkin projection\nmethodology can be used to compute finite-dimensional approximations of these\noperators, which allows us to compute spectral properties and thus to identify\nslowly evolving spatiotemporal patterns or to detect metastable sets. The\nresults will be illustrated with the aid of several guiding examples and\nbenchmark problems including the Cormier model, the Kuramoto model, and a\nthree-dimensional generalization of the Kuramoto model.", "AI": {"tldr": "This paper extends transfer operator theory to McKean--Vlasov equations and presents computational methodologies for analyzing their spectral properties, aiding in the identification of dynamic patterns in complex systems.", "motivation": "Mean-field stochastic differential equations, such as McKean--Vlasov equations, are crucial for understanding complex dynamical systems across diverse domains, but their spectral properties are often underexplored.", "method": "The paper introduces extended dynamic mode decomposition and Galerkin projection methodologies to approximate transfer operators, enabling finite-dimensional computations of spectral properties.", "result": "The approach is demonstrated through examples like the Cormier model, Kuramoto model, and its three-dimensional generalization, revealing slowly evolving spatiotemporal patterns and metastable sets.", "conclusion": "This work offers a computational framework for spectral analysis of McKean--Vlasov equations, contributing to improved understanding of complex dynamical systems."}}
{"id": "2509.09982", "pdf": "https://arxiv.org/pdf/2509.09982", "abs": "https://arxiv.org/abs/2509.09982", "authors": ["Stav Armoni-Friedmann", "Hana Chockler", "David A. Kelly"], "title": "Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae", "categories": ["cs.AI", "I.2.4"], "comment": "Accepted to ECAI-EXCD Workshop, 8 pages, 2 figures, 5 tables", "summary": "Evaluating explainable AI (XAI) approaches is a challenging task in general,\ndue to the subjectivity of explanations. In this paper, we focus on tabular\ndata and the specific use case of AI models predicting the values of Boolean\nfunctions. We extend the previous work in this domain by proposing a formal and\nprecise measure of importance of variables based on actual causality, and we\nevaluate state-of-the-art XAI tools against this measure. We also present a\nnovel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it\nis superior to other black-box XAI tools on a large-scale benchmark.\nSpecifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\\pm$ 0.012\non random 10-valued Boolean formulae", "AI": {"tldr": "The study proposes a precise causality-based measure to evaluate XAI tools and introduces a new tool, B-ReX, outperforming alternatives.", "motivation": "To address the challenge of evaluating explainable AI (XAI) approaches on tabular data in predicting Boolean functions.", "method": "The authors developed a formal causality-based importance measure and compared advanced XAI tools using this benchmark. They also introduced B-ReX as an improvement of the existing ReX tool.", "result": "B-ReX outperformed other black-box XAI tools in benchmarks, achieving a Jensen-Shannon divergence of 0.072 \u00b1 0.012 on Boolean formulae.", "conclusion": "B-ReX and causality-based measures enhance the evaluation of XAI tools, pushing advancements in the domain."}}
{"id": "2509.09793", "pdf": "https://arxiv.org/pdf/2509.09793", "abs": "https://arxiv.org/abs/2509.09793", "authors": ["Vincent Herfeld", "Baudouin Denis de Senneville", "Arthur Leclaire", "Nicolas Papadakis"], "title": "From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms", "categories": ["cs.LG"], "comment": null, "summary": "In this paper we analyze the Gradient-Step Denoiser and its usage in\nPlug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms\nuses off the shelf denoisers to replace a proximity operator or a gradient\ndescent operator of an image prior. Usually this image prior is implicit and\ncannot be expressed, but the Gradient-Step Denoiser is trained to be exactly\nthe gradient descent operator or the proximity operator of an explicit\nfunctional while preserving state-of-the-art denoising capabilities.", "AI": {"tldr": "This paper examines the Gradient-Step Denoiser in Plug-and-Play algorithms for optimization, where it is trained to serve as a gradient descent or proximity operator with strong denoising capabilities.", "motivation": "The motivation is to improve the Plug-and-Play optimization paradigm by leveraging a trained Gradient-Step Denoiser that can act as a well-defined operator for an explicit functional, unlike traditional implicit image priors.", "method": "The approach involves training the Gradient-Step Denoiser to accurately perform as a gradient descent or a proximity operator. This training preserves its advanced image denoising abilities while integrating it into the Plug-and-Play framework.", "result": "The paper demonstrates that the Gradient-Step Denoiser is both effective as an operator of an explicit functional and reliable for state-of-the-art image denoising.", "conclusion": "The study validates the utility of using Gradient-Step Denoisers in Plug-and-Play algorithms, combining clear optimization-based representation with high-quality denoising performance."}}
{"id": "2509.09705", "pdf": "https://arxiv.org/pdf/2509.09705", "abs": "https://arxiv.org/abs/2509.09705", "authors": ["Claudio Pinhanez", "Paulo Cavalin", "Cassia Sanctos", "Marcelo Grave", "Yago Primerano"], "title": "The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This work explores the consistency of small LLMs (2B-8B parameters) in\nanswering multiple times the same question. We present a study on known,\nopen-source LLMs responding to 10 repetitions of questions from the\nmultiple-choice benchmarks MMLU-Redux and MedQA, considering different\ninference temperatures, small vs. medium models (50B-80B), finetuned vs. base\nmodels, and other parameters. We also look into the effects of requiring\nmulti-trial answer consistency on accuracy and the trade-offs involved in\ndeciding which model best provides both of them. To support those studies, we\npropose some new analytical and graphical tools. Results show that the number\nof questions which can be answered consistently vary considerably among models\nbut are typically in the 50%-80% range for small models at low inference\ntemperatures. Also, accuracy among consistent answers seems to reasonably\ncorrelate with overall accuracy. Results for medium-sized models seem to\nindicate much higher levels of answer consistency.", "AI": {"tldr": "This study evaluates the consistency of small-sized language models (2B-8B parameters) in answering repeated questions, comparing model sizes, fine-tuning, and inference techniques.", "motivation": "Understanding how reliable small LLMs are in providing consistent answers to repeated questions, which has implications for robustness and practical application.", "method": "Analyzing the repeated responses of small and medium LLMs to multiple-choice questions from MMLU-Redux and MedQA, under varying conditions such as inference temperature and finetuning.", "result": "Small LLMs demonstrate 50%-80% consistency at low inference temperatures, with accuracy correlating to consistency. Medium-sized models exhibit higher answer consistency.", "conclusion": "While small models show varying levels of consistency, medium models deliver better consistency, highlighting trade-offs in employing LLMs for accuracy and reliability."}}
{"id": "2509.09742", "pdf": "https://arxiv.org/pdf/2509.09742", "abs": "https://arxiv.org/abs/2509.09742", "authors": ["Md Fazle Rasul", "Alanood Alqobaisi", "Bruhadeshwar Bezawada", "Indrakshi Ray"], "title": "Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning", "categories": ["cs.CV"], "comment": null, "summary": "Federated learning (FL) allows multiple entities to train a shared model\ncollaboratively. Its core, privacy-preserving principle is that participants\nonly exchange model updates, such as gradients, and never their raw, sensitive\ndata. This approach is fundamental for applications in domains where privacy\nand confidentiality are important. However, the security of this very mechanism\nis threatened by gradient inversion attacks, which can reverse-engineer private\ntraining data directly from the shared gradients, defeating the purpose of FL.\nWhile the impact of these attacks is known for image, text, and tabular data,\ntheir effect on video data remains an unexamined area of research. This paper\npresents the first analysis of video data leakage in FL using gradient\ninversion attacks. We evaluate two common video classification approaches: one\nemploying pre-trained feature extractors and another that processes raw video\nframes with simple transformations. Our initial results indicate that the use\nof feature extractors offers greater resilience against gradient inversion\nattacks. We also demonstrate that image super-resolution techniques can enhance\nthe frames extracted through gradient inversion attacks, enabling attackers to\nreconstruct higher-quality videos. Our experiments validate this across\nscenarios where the attacker has access to zero, one, or more reference frames\nfrom the target environment. We find that although feature extractors make\nattacks more challenging, leakage is still possible if the classifier lacks\nsufficient complexity. We, therefore, conclude that video data leakage in FL is\na viable threat, and the conditions under which it occurs warrant further\ninvestigation.", "AI": {"tldr": "This paper explores gradient inversion attacks on video data in federated learning, revealing that feature extractors offer resilience but video leakage is still possible under certain conditions.", "motivation": "Investigate the overlooked vulnerability of federated learning in the video domain due to gradient inversion attacks, given the importance of privacy.", "method": "Analyze video data leakage caused by gradient inversion attacks on federated learning using two video classification methods and super-resolution techniques.", "result": "Feature extractors resist attacks better but attackers can still reconstruct high-quality videos depending on classifier complexity and reference frames.", "conclusion": "Video data leakage is a real threat in federated learning, requiring further study to understand the circumstances and defenses against it."}}
{"id": "2509.10012", "pdf": "https://arxiv.org/pdf/2509.10012", "abs": "https://arxiv.org/abs/2509.10012", "authors": ["Richard Matthias Hartisch", "Alexander Rother", "J\u00f6rg Kr\u00fcger", "Kevin Haninger"], "title": "Towards simulation-based optimization of compliant fingers for high-speed connector assembly", "categories": ["cs.RO"], "comment": null, "summary": "Mechanical compliance is a key design parameter for dynamic contact-rich\nmanipulation, affecting task success and safety robustness over contact\ngeometry variation. Design of soft robotic structures, such as compliant\nfingers, requires choosing design parameters which affect geometry and\nstiffness, and therefore manipulation performance and robustness. Today, these\nparameters are chosen through either hardware iteration, which takes\nsignificant development time, or simplified models (e.g. planar), which can't\naddress complex manipulation task objectives. Improvements in dynamic\nsimulation, especially with contact and friction modeling, present a potential\ndesign tool for mechanical compliance. We propose a simulation-based design\ntool for compliant mechanisms which allows design with respect to task-level\nobjectives, such as success rate. This is applied to optimize design parameters\nof a structured compliant finger to reduce failure cases inside a tolerance\nwindow in insertion tasks. The improvement in robustness is then validated on a\nreal robot using tasks from the benchmark NIST task board. The finger stiffness\naffects the tolerance window: optimized parameters can increase tolerable\nranges by a factor of 2.29, with workpiece variation up to 8.6 mm being\ncompensated. However, the trends remain task-specific. In some tasks, the\nhighest stiffness yields the widest tolerable range, whereas in others the\nopposite is observed, motivating need for design tools which can consider\napplication-specific geometry and dynamics.", "AI": {"tldr": "The paper proposes a simulation-based design tool for optimizing compliant mechanisms to achieve better performance and robustness in dynamic manipulation tasks.", "motivation": "The motivation stems from the limitations of traditional design methods for soft robotic structures, which rely on time-consuming hardware iteration or simplified models that fail to capture complex task dynamics.", "method": "The authors use advanced dynamic simulation tools to design compliant fingers based on task-level objectives such as success rates, optimizing parameters like stiffness for specific tasks.", "result": "The optimized design increased the tolerable variation range for insertion tasks by a factor of 2.29 and successfully reduced failure cases in manipulation tasks.", "conclusion": "The trends in stiffness requirements vary across different tasks, emphasizing the importance of task-specific design tools to address unique geometries and dynamic behaviors in soft robotic systems."}}
{"id": "2509.10085", "pdf": "https://arxiv.org/pdf/2509.10085", "abs": "https://arxiv.org/abs/2509.10085", "authors": ["Philipp Zech", "Irdin Pekaric"], "title": "Sustaining Research Software: A Fitness Function Approach", "categories": ["cs.SE"], "comment": null, "summary": "The long-term sustainability of research software is a critical challenge, as\nit usually suffers from poor maintainability, lack of adaptability, and\neventual obsolescence. This paper proposes a novel approach to addressing this\nissue by leveraging the concept of fitness functions from evolutionary\narchitecture. Fitness functions are automated, continuously evaluated metrics\ndesigned to ensure that software systems meet desired non-functional,\narchitectural qualities over time. We define a set of fitness functions\ntailored to the unique requirements of research software, focusing on\nfindability, accessibility, interoperability and reusability (FAIR). These\nfitness functions act as proactive safeguards, promoting practices such as\nmodular design, comprehensive documentation, version control, and compatibility\nwith evolving technological ecosystems. By integrating these metrics into the\ndevelopment life cycle, we aim to foster a culture of sustainability within the\nresearch community. Case studies and experimental results demonstrate the\npotential of this approach to enhance the long-term FAIR of research software,\nbridging the gap between ephemeral project-based development and enduring\nscientific impact.", "AI": {"tldr": "The paper discusses fitness functions for improving the sustainability of research software by focusing on FAIR principles.", "motivation": "To address the vulnerability of research software to poor maintainability, adaptability, and obsolescence.", "method": "The paper uses fitness functions from evolutionary architecture to create tailored metrics promoting modularity, documentation, and versioning.", "result": "Case studies and experiments showed enhanced long-term findability, accessibility, interoperability, and reusability of research software.", "conclusion": "Promoting fitness function metrics in software development cycles can bridge gaps between ephemeral development approaches and enduring scientific usability."}}
{"id": "2509.09904", "pdf": "https://arxiv.org/pdf/2509.09904", "abs": "https://arxiv.org/abs/2509.09904", "authors": ["Zhangsong Li"], "title": "A Smooth Computational Transition in Tensor PCA", "categories": ["math.ST", "cs.DS", "math.PR", "stat.ML", "stat.TH", "68Q87, 90C35"], "comment": "49 pages, 2 figures", "summary": "We propose an efficient algorithm for tensor PCA based on counting a specific\nfamily of weighted hypergraphs. For the order-$p$ tensor PCA problem where $p\n\\geq 3$ is a fixed integer, we show that when the signal-to-noise ratio is\n$\\lambda n^{-\\frac{p}{4}}$ where $\\lambda=\\Omega(1)$, our algorithm succeeds\nand runs in time $n^{C+o(1)}$ where $C=C(\\lambda)$ is a constant depending on\n$\\lambda$. This algorithm improves a poly-logarithmic factor compared to\nprevious algorithms based on the Sum-of-Squares hierarchy \\cite{HSS15} or based\non the Kikuchi hierarchy in statistical physics \\cite{WEM19}. Furthermore, our\nresult shows a smooth tradeoff between the signal-to-noise ratio and the\ncomputational cost in this problem, thereby confirming a conjecture posed in\n\\cite{KWB22}.", "AI": {"tldr": "The paper introduces an efficient algorithm for tensor PCA using weighted hypergraph counting, demonstrating better performance and computational tradeoff compared to prior approaches.", "motivation": "Improving tensor PCA efficiency and reconciling a tradeoff between signal-to-noise ratio and computational cost.", "method": "Developing an algorithm that uses weighted hypergraph counting for solving the order-$p$ tensor PCA problem with better complexity scaling.", "result": "The algorithm achieves success under a specified signal-to-noise ratio and runs faster by a poly-logarithmic factor compared to existing methods.", "conclusion": "The proposed algorithm validates the conjecture regarding computational cost vs. signal-to-noise ratio tradeoff and improves tensor PCA methodology."}}
{"id": "2509.10018", "pdf": "https://arxiv.org/pdf/2509.10018", "abs": "https://arxiv.org/abs/2509.10018", "authors": ["Hailong Yang", "Renhuo Zhao", "Guanjin Wang", "Zhaohong Deng"], "title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of Large Language Model (LLM), LLM-based agents\nexhibit exceptional abilities in understanding and generating natural language,\nfacilitating human-like collaboration and information transmission in LLM-based\nMulti-Agent System (MAS). High-performance LLMs are often hosted on remote\nservers in public spaces. When tasks involve privacy data, MAS cannot securely\nutilize these LLMs without implementing privacy-preserving mechanisms. To\naddress this challenge, we propose a General Anonymizing Multi-Agent system\n(GAMA), which divides the agents' workspace into private and public spaces and\nprotects privacy through the anonymizing mechanism. In the private space,\nagents handle sensitive data, while in the public space, only anonymized data\nis utilized. GAMA incorporates two key modules to mitigate semantic loss caused\nby anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and\nDisproof-based Logic Enhancement (DLE). We evaluate GAMA on two public\nquestion-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The\nresults demonstrate that GAMA has superior performance compared to the\nstate-of-the-art models. To further assess its privacy-preserving capabilities,\nwe designed two new datasets: Knowledge Privacy Preservation and Logic Privacy\nPreservation. The final results highlight GAMA's exceptional effectiveness in\nboth task processing and privacy preservation.", "AI": {"tldr": "The paper introduces GAMA, a system that allows multi-agent LLM applications to ensure privacy by dividing tasks into private and public spaces while addressing semantic loss through two modules. It demonstrates superior task performance and effective privacy preservation.", "motivation": "Existing LLM-based multi-agent systems are limited when handling tasks involving private data, as many LLMs are in public, insecure environments. This paper aims to address privacy concerns while maintaining task efficacy.", "method": "The authors propose GAMA, which separates workspaces into private (for sensitive data) and public (for anonymized data). GAMA mitigates semantic loss via Domain-Rule-based Knowledge Enhancement (DRKE) and Disproof-based Logic Enhancement (DLE) modules. It is evaluated using both public QA datasets and custom privacy datasets.", "result": "Experimental results show that GAMA outperforms state-of-the-art models in both task performance and privacy preservation, according to assessments on public and specifically designed datasets.", "conclusion": "The GAMA system is highly effective for privacy-preserving multi-agent applications, ensuring robust task performance and addressing privacy in complex scenarios."}}
{"id": "2509.09799", "pdf": "https://arxiv.org/pdf/2509.09799", "abs": "https://arxiv.org/abs/2509.09799", "authors": ["Mansi Sharma", "Alexandre Duchevet", "Florian Daiber", "Jean-Paul Imbert", "Maurice Rekrut"], "title": "Distinguishing Startle from Surprise Events Based on Physiological Signals", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Unexpected events can impair attention and delay decision-making, posing\nserious safety risks in high-risk environments such as aviation. In particular,\nreactions like startle and surprise can impact pilot performance in different\nways, yet are often hard to distinguish in practice. Existing research has\nlargely studied these reactions separately, with limited focus on their\ncombined effects or how to differentiate them using physiological data. In this\nwork, we address this gap by distinguishing between startle and surprise events\nbased on physiological signals using machine learning and multi-modal fusion\nstrategies. Our results demonstrate that these events can be reliably\npredicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.\nTo further validate the robustness of our model, we extended the evaluation to\ninclude a baseline condition, successfully differentiating between Startle,\nSurprise, and Baseline states with a highest mean accuracy of 74.9% with\nXGBoost and Late Fusion.", "AI": {"tldr": "The paper explores how physiological signals can be used to distinguish between the reactions of startle and surprise, which impact pilot performance. Machine learning models achieved high accuracy in predicting these states.", "motivation": "Unexpected events impair attention and decision-making, posing risks in high-stakes environments like aviation. Startle and surprise reactions specifically affect pilot performance but remain difficult to differentiate.", "method": "The paper uses machine learning and multi-modal fusion strategies to analyze physiological signals and predict different states (Startle, Surprise, and Baseline). Techniques like SVM and XGBoost were employed for this differentiation.", "result": "The highest mean accuracy for differentiating Startle vs. Surprise was 85.7% using SVM and Late Fusion, while including Baseline states achieved 74.9% accuracy with XGBoost and Late Fusion.", "conclusion": "Physiological signals reliably distinguish between startle, surprise, and baseline states using machine learning methods, addressing an important challenge in aviation safety."}}
{"id": "2509.09708", "pdf": "https://arxiv.org/pdf/2509.09708", "abs": "https://arxiv.org/abs/2509.09708", "authors": ["Nirmalendu Prakash", "Yeo Wei Jie", "Amir Abdullah", "Ranjan Satapathy", "Erik Cambria", "Roy Ka Wei Lee"], "title": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Refusal on harmful prompts is a key safety behaviour in instruction-tuned\nlarge language models (LLMs), yet the internal causes of this behaviour remain\npoorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT\nand LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on\nresidual-stream activations. Given a harmful prompt, we search the SAE latent\nspace for feature sets whose ablation flips the model from refusal to\ncompliance, demonstrating causal influence and creating a jailbreak. Our search\nproceeds in three stages: (1) Refusal Direction: find a refusal-mediating\ndirection and collect SAE features near that direction; (2) Greedy Filtering:\nprune to a minimal set; and (3) Interaction Discovery: fit a factorization\nmachine (FM) that captures nonlinear interactions among the remaining active\nfeatures and the minimal set. This pipeline yields a broad set of\njailbreak-critical features, offering insight into the mechanistic basis of\nrefusal. Moreover, we find evidence of redundant features that remain dormant\nunless earlier features are suppressed. Our findings highlight the potential\nfor fine-grained auditing and targeted intervention in safety behaviours by\nmanipulating the interpretable latent space.", "AI": {"tldr": "The study investigates harmful prompt refusal mechanisms in large language models using sparse autoencoders to identify causally-influential latent features, enabling jailbreak manipulations.", "motivation": "To gain a better understanding of safety behaviors, particularly refusal on harmful prompts in instruction-tuned large language models.", "method": "The study uses a three-stage pipeline with sparse autoencoders: finding refusal direction, greedy filtering, and capturing nonlinear interactions with a factorization machine.", "result": "Identifies latent features that mediate refusal behaviors, reveals redundancy in these features, and demonstrates causal modifications to model behavior.", "conclusion": "The findings open opportunities for fine-grained auditing and interventions in model safety behaviors by manipulating the interpretable latent space."}}
{"id": "2509.09750", "pdf": "https://arxiv.org/pdf/2509.09750", "abs": "https://arxiv.org/abs/2509.09750", "authors": ["Hossein Yazdanjouei", "Arash Mansouri", "Mohammad Shokouhifar"], "title": "A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This study proposes a semi-supervised co-training framework for object\ndetection in densely packed retail environments, where limited labeled data and\ncomplex conditions pose major challenges. The framework combines Faster R-CNN\n(utilizing a ResNet backbone) for precise localization with YOLO (employing a\nDarknet backbone) for global context, enabling mutual pseudo-label exchange\nthat improves accuracy in scenes with occlusion and overlapping objects. To\nstrengthen classification, it employs an ensemble of XGBoost, Random Forest,\nand SVM, utilizing diverse feature representations for higher robustness.\nHyperparameters are optimized using a metaheuristic-driven algorithm, enhancing\nprecision and efficiency across models. By minimizing reliance on manual\nlabeling, the approach reduces annotation costs and adapts effectively to\nfrequent product and layout changes common in retail. Experiments on the\nSKU-110k dataset demonstrate strong performance, highlighting the scalability\nand practicality of the proposed framework for real-world retail applications\nsuch as automated inventory tracking, product monitoring, and checkout systems.", "AI": {"tldr": "The paper develops a semi-supervised co-training framework for object detection in dense retail settings, utilizing Faster R-CNN and YOLO for mutual pseudo-labeling, and ensembles machine learning models for classification.", "motivation": "Address challenges of limited labeled data and complex conditions in densely packed retail environments.", "method": "Combines Faster R-CNN with YOLO for object detection, uses ensemble classification with XGBoost, Random Forest, and SVM, and optimizes hyperparameters using metaheuristic algorithms.", "result": "Achieves strong performance on the SKU-110k dataset, demonstrating scalability and real-world application suitability.", "conclusion": "The framework reduces annotation costs and adapts to retail changes, making it viable for automated systems like inventory tracking and product monitoring."}}
{"id": "2509.10032", "pdf": "https://arxiv.org/pdf/2509.10032", "abs": "https://arxiv.org/abs/2509.10032", "authors": ["Marawan Khalil", "Fabian Arzberger", "Andreas N\u00fcchter"], "title": "Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping", "categories": ["cs.RO"], "comment": "6 Pages, 9 figures, International Workshop 3D-AdViCE in conjunction\n  with 12th ECMR 2025", "summary": "Spherical robots offer unique advantages for mapping applications in\nhazardous or confined environments, thanks to their protective shells and\nomnidirectional mobility. This work presents two complementary spherical\nmapping systems: a lightweight, non-actuated design and an actuated variant\nfeaturing internal pendulum-driven locomotion. Both systems are equipped with a\nLivox Mid-360 solid-state LiDAR sensor and run LiDAR-Inertial Odometry (LIO)\nalgorithms on resource-constrained hardware. We assess the mapping accuracy of\nthese systems by comparing the resulting 3D point-clouds from the LIO\nalgorithms to a ground truth map. The results indicate that the performance of\nstate-of-the-art LIO algorithms deteriorates due to the high dynamic movement\nintroduced by the spherical locomotion, leading to globally inconsistent maps\nand sometimes unrecoverable drift.", "AI": {"tldr": "This paper examines two spherical robots designed for mapping in challenging environments, showcasing unique strengths but identifying challenges with existing localization algorithms.", "motivation": "The authors aim to explore spherical robots as a solution for mapping in hazardous or compact environments using LiDAR and lightweight frameworks.", "method": "They developed two variants: a lightweight non-actuated model and an actuated one with pendulum-driven locomotion, both leveraging LiDAR-Inertial Odometry algorithms on limited hardware setups.", "result": "Experiments revealed that high dynamic movements from spherical locomotion degrade the accuracy of current LIO algorithms, causing inconsistent mapping results and drift issues.", "conclusion": "Spherical robots are promising for mapping, but existing algorithms struggle with dynamic movement, highlighting the need for improved localization systems in these applications."}}
{"id": "2509.10099", "pdf": "https://arxiv.org/pdf/2509.10099", "abs": "https://arxiv.org/abs/2509.10099", "authors": ["Radu Apsan", "Vincenzo Stoico", "Michel Albonico", "Rudra Dhar", "Karthik Vaidhyanathan", "Ivano Malavolta"], "title": "Generating Energy-Efficient Code via Large-Language Models -- Where are we now?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Context. The rise of Large Language Models (LLMs) has led to their widespread\nadoption in development pipelines. Goal. We empirically assess the energy\nefficiency of Python code generated by LLMs against human-written code and code\ndeveloped by a Green software expert. Method. We test 363 solutions to 9 coding\nproblems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting\ntechniques, and comparing them to human-developed solutions. Energy consumption\nis measured on three different hardware platforms: a server, a PC, and a\nRaspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%\nmore energy-efficient on the server and 3% on the Raspberry Pi, while LLMs\noutperform human developers by 25% on the PC. Prompting does not consistently\nlead to energy savings, where the most energy-efficient prompts vary by\nhardware platform. The code developed by a Green software expert is\nconsistently more energy-efficient by at least 17% to 30% against all LLMs on\nall hardware platforms. Conclusions. Even though LLMs exhibit relatively good\ncode generation capabilities, no LLM-generated code was more energy-efficient\nthan that of an experienced Green software developer, suggesting that as of\ntoday there is still a great need of human expertise for developing\nenergy-efficient Python code.", "AI": {"tldr": "The study evaluates the energy efficiency of Python code generated by LLMs compared to human-written and Green software expert-developed code, finding that LLMs lag behind Green experts in energy efficiency.", "motivation": "The increasing use of Large Language Models (LLMs) in development has raised questions about the energy efficiency of the code they generate compared to human developers.", "method": "The authors tested 363 solutions to coding problems using 6 LLMs and 4 prompting techniques, measuring energy consumption on three hardware platforms: server, PC, and Raspberry Pi, over 881 hours.", "result": "Human-written code was more energy-efficient on a server (16%) and Raspberry Pi (3%), while LLMs slightly outperformed humans on a PC (25%). The Green software expert's code was 17-30% more energy-efficient than all LLMs across all platforms. Prompting effectiveness varied by platform.", "conclusion": "LLMs cannot yet produce code as energy-efficient as expert developers. Human expertise remains essential for energy-efficient Python development despite LLM advancements."}}
{"id": "2509.10384", "pdf": "https://arxiv.org/pdf/2509.10384", "abs": "https://arxiv.org/abs/2509.10384", "authors": ["Jianxin Zhang", "Clayton Scott"], "title": "Flow Straight and Fast in Hilbert Space: Functional Rectified Flow", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many generative models originally developed in finite-dimensional Euclidean\nspace have functional generalizations in infinite-dimensional settings.\nHowever, the extension of rectified flow to infinite-dimensional spaces remains\nunexplored. In this work, we establish a rigorous functional formulation of\nrectified flow in an infinite-dimensional Hilbert space. Our approach builds\nupon the superposition principle for continuity equations in an\ninfinite-dimensional space. We further show that this framework extends\nnaturally to functional flow matching and functional probability flow ODEs,\ninterpreting them as nonlinear generalizations of rectified flow. Notably, our\nextension to functional flow matching removes the restrictive measure-theoretic\nassumptions in the existing theory of \\citet{kerrigan2024functional}.\nFurthermore, we demonstrate experimentally that our method achieves superior\nperformance compared to existing functional generative models.", "AI": {"tldr": "This paper develops a rigorous extension of rectified flow to infinite-dimensional Hilbert spaces and demonstrates its effectiveness over existing functional generative models.", "motivation": "The authors aim to explore the extension of rectified flow models to infinite-dimensional settings, as previous generative models generalized to infinite-dimensional spaces while rectified flow models did not.", "method": "The paper constructs a functional framework based on the superposition principle for continuity equations in infinite-dimensional Hilbert spaces, extending functional flow matching and functional probability flow ODEs as nonlinear generalizations.", "result": "The extended framework experimentally achieves superior performance compared to existing functional generative models, while removing restrictive measure-theoretic assumptions in prior theories.", "conclusion": "The work establishes novel methodologies for applying rectified flow models within infinite-dimensional spaces, paving the way for improved generative modeling approaches and expanding theoretical generalizations."}}
{"id": "2509.10054", "pdf": "https://arxiv.org/pdf/2509.10054", "abs": "https://arxiv.org/abs/2509.10054", "authors": ["Hailong Yang", "Mingxian Gu", "Jianqi Wang", "Guanjin Wang", "Zhaohong Deng"], "title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has significantly\nenhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans\nwith complex, real-world tasks. However, MAS still face challenges in effective\ntask planning when handling highly complex tasks with uncertainty, often\nresulting in misleading or incorrect outputs that hinder task execution. To\naddress this, we propose XAgents, a unified multi-agent cooperative framework\nbuilt on a multipolar task processing graph and IF-THEN rules. XAgents uses the\nmultipolar task processing graph to enable dynamic task planning and handle\ntask uncertainty. During subtask processing, it integrates domain-specific\nIF-THEN rules to constrain agent behaviors, while global rules enhance\ninter-agent collaboration. We evaluate the performance of XAgents across three\ndistinct datasets, demonstrating that it consistently surpasses\nstate-of-the-art single-agent and multi-agent approaches in both\nknowledge-typed and logic-typed question-answering tasks. The codes for XAgents\nare available at: https://github.com/AGI-FHBC/XAgents.", "AI": {"tldr": "This paper introduces XAgents, a cooperative multi-agent framework designed to improve task planning and execution in complex, uncertain scenarios. It uses a multipolar task processing graph and IF-THEN rules to achieve better collaboration and accuracy.", "motivation": "The motivation behind this paper is to address the challenges of effective task planning and execution in Multi-Agent Systems (MAS) when dealing with complex tasks that include uncertainty, which often results in errors and hinders task completion.", "method": "The proposed method involves developing 'XAgents,' a framework based on a multipolar task processing graph for dynamic task planning, and IF-THEN rules to constrain agent behaviors and enhance inter-agent collaboration during subtask processing.", "result": "XAgents were tested on three different datasets and outperformed both single-agent and state-of-the-art multi-agent systems in solving knowledge-based and logic-based question-answering tasks.", "conclusion": "The XAgents framework demonstrates superiority in task planning and execution compared to existing solutions, addressing task uncertainty while providing a scalable and collaborative approach for complex tasks."}}
{"id": "2509.09838", "pdf": "https://arxiv.org/pdf/2509.09838", "abs": "https://arxiv.org/abs/2509.09838", "authors": ["Reza Asad", "Reza Babanezhad", "Sharan Vaswani"], "title": "Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Value-based approaches such as DQN are the default methods for off-policy\nreinforcement learning with discrete-action environments such as Atari. Common\npolicy-based methods are either on-policy and do not effectively learn from\noff-policy data (e.g. PPO), or have poor empirical performance in the\ndiscrete-action setting (e.g. SAC). Consequently, starting from discrete SAC\n(DSAC), we revisit the design of actor-critic methods in this setting. First,\nwe determine that the coupling between the actor and critic entropy is the\nprimary reason behind the poor performance of DSAC. We demonstrate that by\nmerely decoupling these components, DSAC can have comparable performance as\nDQN. Motivated by this insight, we introduce a flexible off-policy actor-critic\nframework that subsumes DSAC as a special case. Our framework allows using an\nm-step Bellman operator for the critic update, and enables combining standard\npolicy optimization methods with entropy regularization to instantiate the\nresulting actor objective. Theoretically, we prove that the proposed methods\ncan guarantee convergence to the optimal regularized value function in the\ntabular setting. Empirically, we demonstrate that these methods can approach\nthe performance of DQN on standard Atari games, and do so even without entropy\nregularization or explicit exploration.", "AI": {"tldr": "This paper revisits the design of discrete-action actor-critic methods and proposes a flexible framework that achieves performance close to DQN in Atari games.", "motivation": "The paper aims to address the limitations of existing policy-based methods in discrete-action reinforcement learning, which either cannot effectively leverage off-policy data or underperform compared to value-based methods like DQN.", "method": "The authors decouple actor and critic entropy in discrete SAC and propose a generalized off-policy actor-critic framework that incorporates m-step Bellman updates and flexible policy optimization objectives.", "result": "The proposed methods empirically achieve performance comparable to DQN on Atari games, even without using entropy regularization or explicit exploration.", "conclusion": "By addressing entropy coupling and introducing a flexible framework, the paper bridges the performance gap between actor-critic and value-based methods in discrete-action settings."}}
{"id": "2509.09709", "pdf": "https://arxiv.org/pdf/2509.09709", "abs": "https://arxiv.org/abs/2509.09709", "authors": ["Jing Ren", "Weiqi Wang"], "title": "Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) like ChatGPT are increasingly used in academic\nwriting, yet issues such as incorrect or fabricated references raise ethical\nconcerns. Moreover, current content quality evaluations often rely on\nsubjective human judgment, which is labor-intensive and lacks objectivity,\npotentially compromising the consistency and reliability. In this study, to\nprovide a quantitative evaluation and enhance research proposal writing\ncapabilities of LLMs, we propose two key evaluation metrics--content quality\nand reference validity--and an iterative prompting method based on the scores\nderived from these two metrics. Our extensive experiments show that the\nproposed metrics provide an objective, quantitative framework for assessing\nChatGPT's writing performance. Additionally, iterative prompting significantly\nenhances content quality while reducing reference inaccuracies and\nfabrications, addressing critical ethical challenges in academic contexts.", "AI": {"tldr": "The paper introduces quantitative evaluation metrics for assessing ChatGPT's academic writing quality and proposes iterative prompting for improvement.", "motivation": "To address issues like fabricated references in ChatGPT-based academic writing and the limitations of subjective evaluation methods.", "method": "The authors propose two new metrics\u2014content quality and reference validity\u2014and use an iterative prompting approach based on these metrics.", "result": "Experiments demonstrate that the metrics enable objective assessments and iterative prompting improves content quality while reducing inaccuracies and fabrications.", "conclusion": "The proposed metrics and approach enhance academic writing capabilities of ChatGPT while addressing ethical challenges."}}
{"id": "2509.09785", "pdf": "https://arxiv.org/pdf/2509.09785", "abs": "https://arxiv.org/abs/2509.09785", "authors": ["Moslem Yazdanpanah", "Ali Bahri", "Mehrdad Noori", "Sahar Dastani", "Gustavo Adolfo Vargas Hakim", "David Osowiechi", "Ismail Ben Ayed", "Christian Desrosiers"], "title": "Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging", "categories": ["cs.CV"], "comment": null, "summary": "Test-time adaptation (TTA) is crucial for mitigating performance degradation\ncaused by distribution shifts in 3D point cloud classification. In this work,\nwe introduce Token Purging (PG), a novel backpropagation-free approach that\nremoves tokens highly affected by domain shifts before they reach attention\nlayers. Unlike existing TTA methods, PG operates at the token level, ensuring\nrobust adaptation without iterative updates. We propose two variants: PG-SP,\nwhich leverages source statistics, and PG-SF, a fully source-free version\nrelying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,\nShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of\n+10.3\\% higher accuracy than state-of-the-art backpropagation-free methods,\nwhile PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is\n12.4 times faster and 5.5 times more memory efficient than our baseline, making\nit suitable for real-world deployment. Code is available at\n\\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}", "AI": {"tldr": "The paper proposes a novel, efficient method called Token Purging (PG) for test-time adaptation in 3D point cloud classification under domain shifts, achieving superior accuracy and efficiency compared to existing methods.", "motivation": "The paper is motivated by the need for robust test-time adaptation methods to counteract performance issues caused by distribution shifts in 3D point cloud classification.", "method": "The authors introduce Token Purging (PG), which eliminates domain-shift-affected tokens before attention layers in a backpropagation-free manner. They propose two variants: PG-SP, which uses source statistics, and PG-SF, a source-free version based on CLS-token-driven adaptation.", "result": "PG-SP improves accuracy by an average of +10.3% over state-of-the-art backpropagation-free methods, while PG-SF sets new benchmarks for source-free adaptation. Additionally, PG is significantly faster (12.4x) and more memory-efficient (5.5x) than their baseline.", "conclusion": "Token Purging (PG) is an efficient and effective test-time adaptation strategy, suitable for real-world deployment due to its significant improvements in accuracy, speed, and memory usage."}}
{"id": "2509.10063", "pdf": "https://arxiv.org/pdf/2509.10063", "abs": "https://arxiv.org/abs/2509.10063", "authors": ["Xiyan Huang", "Zhe Xu", "Chenxi Xiao"], "title": "TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model", "categories": ["cs.RO", "cs.AI", "I.2.9"], "comment": "7 pages, 9 figures, 1 table, to be published in IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025)", "summary": "Robot skill acquisition processes driven by reinforcement learning often rely\non simulations to efficiently generate large-scale interaction data. However,\nthe absence of simulation models for tactile sensors has hindered the use of\ntactile sensing in such skill learning processes, limiting the development of\neffective policies driven by tactile perception. To bridge this gap, we present\nTwinTac, a system that combines the design of a physical tactile sensor with\nits digital twin model. Our hardware sensor is designed for high sensitivity\nand a wide measurement range, enabling high quality sensing data essential for\nobject interaction tasks. Building upon the hardware sensor, we develop the\ndigital twin model using a real-to-sim approach. This involves collecting\nsynchronized cross-domain data, including finite element method results and the\nphysical sensor's outputs, and then training neural networks to map simulated\ndata to real sensor responses. Through experimental evaluation, we\ncharacterized the sensitivity of the physical sensor and demonstrated the\nconsistency of the digital twin in replicating the physical sensor's output.\nFurthermore, by conducting an object classification task, we showed that\nsimulation data generated by our digital twin sensor can effectively augment\nreal-world data, leading to improved accuracy. These results highlight\nTwinTac's potential to bridge the gap in cross-domain learning tasks.", "AI": {"tldr": "The paper introduces TwinTac, a system integrating a physical tactile sensor with a digital twin model for improved reinforcement learning in tactile-driven tasks.", "motivation": "Current reinforcement learning struggles to incorporate tactile perception due to the lack of simulation models for tactile sensors, hindering skill learning in object interactions.", "method": "The proposed system includes a high-sensitivity tactile sensor and a digital twin model generated through neural networks mapping real sensor data to simulated outputs, leveraging a real-to-sim approach.", "result": "Experimental evaluation demonstrated high sensitivity of the physical sensor and accurate replication by the digital twin, with enhanced object classification accuracy using simulation data.", "conclusion": "TwinTac bridges the gap between physical and simulated tactile sensing, enabling cross-domain learning and improving the development of tactile-driven policies."}}
{"id": "2509.10393", "pdf": "https://arxiv.org/pdf/2509.10393", "abs": "https://arxiv.org/abs/2509.10393", "authors": ["Cl\u00e9mentine Chazal", "Heishiro Kanagawa", "Zheyang Shen", "Anna Korba", "Chris. J. Oates"], "title": "A Computable Measure of Suboptimality for Entropy-Regularised Variational Objectives", "categories": ["stat.CO", "stat.ML"], "comment": null, "summary": "Several emerging post-Bayesian methods target a probability distribution for\nwhich an entropy-regularised variational objective is minimised. This increased\nflexibility introduces a computational challenge, as one loses access to an\nexplicit unnormalised density for the target. To mitigate this difficulty, we\nintroduce a novel measure of suboptimality called 'gradient discrepancy', and\nin particular a 'kernel gradient discrepancy' (KGD) that can be explicitly\ncomputed. In the standard Bayesian context, KGD coincides with the kernel Stein\ndiscrepancy (KSD), and we obtain a novel charasterisation of KSD as measuring\nthe size of a variational gradient. Outside this familiar setting, KGD enables\nnovel sampling algorithms to be developed and compared, even when unnormalised\ndensities cannot be obtained. To illustrate this point several novel algorithms\nare proposed, including a natural generalisation of Stein variational gradient\ndescent, with applications to mean-field neural networks and prediction-centric\nuncertainty quantification presented. On the theoretical side, our principal\ncontribution is to establish sufficient conditions for desirable properties of\nKGD, such as continuity and convergence control.", "AI": {"tldr": "The paper introduces 'kernel gradient discrepancy' (KGD) for optimizing entropy-regularized variational objectives when explicit unnormalized densities aren't available. This metric helps design novel algorithms and measure their effectiveness.", "motivation": "Emerging post-Bayesian methods need effective measures for optimization when explicit unnormalized densities are unavailable.", "method": "Defines a new metric, kernel gradient discrepancy (KGD), and uses it to assess variational gradients, enabling novel algorithm development.", "result": "KGD is connected to kernel Stein discrepancy, allowing generalizations of methods like Stein variational gradient descent. Applications include neural networks and uncertainty quantification.", "conclusion": "KGD provides a robust tool for algorithmic development and analysis in scenarios where explicit unnormalized densities can't be computed."}}
{"id": "2509.10104", "pdf": "https://arxiv.org/pdf/2509.10104", "abs": "https://arxiv.org/abs/2509.10104", "authors": ["Sofia Vei", "Paolo Giudici", "Pavlos Sermpezis", "Athena Vakali", "Adelaide Emma Bernardelli"], "title": "AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework", "categories": ["cs.AI", "stat.ME"], "comment": null, "summary": "The absolute dominance of Artificial Intelligence (AI) introduces\nunprecedented societal harms and risks. Existing AI risk assessment models\nfocus on internal compliance, often neglecting diverse stakeholder perspectives\nand real-world consequences. We propose a paradigm shift to a human-centric,\nharm-severity adaptive approach grounded in empirical incident data. We present\nAI Harmonics, which includes a novel AI harm assessment metric (AIH) that\nleverages ordinal severity data to capture relative impact without requiring\nprecise numerical estimates. AI Harmonics combines a robust, generalized\nmethodology with a data-driven, stakeholder-aware framework for exploring and\nprioritizing AI harms. Experiments on annotated incident data confirm that\npolitical and physical harms exhibit the highest concentration and thus warrant\nurgent mitigation: political harms erode public trust, while physical harms\npose serious, even life-threatening risks, underscoring the real-world\nrelevance of our approach. Finally, we demonstrate that AI Harmonics\nconsistently identifies uneven harm distributions, enabling policymakers and\norganizations to target their mitigation efforts effectively.", "AI": {"tldr": "This paper introduces AI Harmonics, a human-centric framework for assessing AI-related societal risks, emphasizing data-driven prioritization of significant harm types like political and physical risks.", "motivation": "The motivation is to address the limitations of existing AI risk models, which often overlook diverse stakeholder perspectives and fail to capture real-world consequences.", "method": "The paper proposes the AI Harmonics framework, which includes the AI Harm assessment metric (AIH). This metric uses ordinal severity data to evaluate relative impacts without requiring precise numerical estimates.", "result": "Experimental analysis on annotated incident data indicates that political and physical harms are the most concentrated categories, highlighting their critical importance. Political harms affect public trust, while physical harms pose life-threatening risks.", "conclusion": "The AI Harmonics framework is effective at identifying uneven harm distributions, allowing policymakers and organizations to align their mitigation efforts with the most pressing risks."}}
{"id": "2509.09843", "pdf": "https://arxiv.org/pdf/2509.09843", "abs": "https://arxiv.org/abs/2509.09843", "authors": ["Jiajun Shen", "Yufei Jin", "Yi He", "Xingquan Zhu"], "title": "HGEN: Heterogeneous Graph Ensemble Networks", "categories": ["cs.LG", "cs.AI"], "comment": "The paper is in proceedings of the 34th IJCAI Conference, 2025", "summary": "This paper presents HGEN that pioneers ensemble learning for heterogeneous\ngraphs. We argue that the heterogeneity in node types, nodal features, and\nlocal neighborhood topology poses significant challenges for ensemble learning,\nparticularly in accommodating diverse graph learners. Our HGEN framework\nensembles multiple learners through a meta-path and transformation-based\noptimization pipeline to uplift classification accuracy. Specifically, HGEN\nuses meta-path combined with random dropping to create Allele Graph Neural\nNetworks (GNNs), whereby the base graph learners are trained and aligned for\nlater ensembling. To ensure effective ensemble learning, HGEN presents two key\ncomponents: 1) a residual-attention mechanism to calibrate allele GNNs of\ndifferent meta-paths, thereby enforcing node embeddings to focus on more\ninformative graphs to improve base learner accuracy, and 2) a\ncorrelation-regularization term to enlarge the disparity among embedding\nmatrices generated from different meta-paths, thereby enriching base learner\ndiversity. We analyze the convergence of HGEN and attest its higher\nregularization magnitude over simple voting. Experiments on five heterogeneous\nnetworks validate that HGEN consistently outperforms its state-of-the-art\ncompetitors by substantial margin.", "AI": {"tldr": "This paper introduces HGEN, an ensemble learning framework for heterogeneous graphs, which incorporates meta-paths and a transformation-based pipeline to improve classification accuracy.", "motivation": "The motivation is to address the challenges posed by heterogeneity in node types, features, and neighborhood topology and to enhance the performance of ensemble learning in heterogeneous graphs.", "method": "HGEN employs ensemble learning through meta-path-based Allele Graph Neural Networks, using a residual-attention mechanism for better node embedding alignment and a correlation-regularization term to enhance diversity among base learners.", "result": "HGEN achieves superior performance, consistently outperforming state-of-the-art methods across five heterogeneous graph datasets.", "conclusion": "HGEN is an effective framework that tackles heterogeneity in graphs, offering innovations in ensemble learning that improve classification accuracy and learner diversity."}}
{"id": "2509.09710", "pdf": "https://arxiv.org/pdf/2509.09710", "abs": "https://arxiv.org/abs/2509.09710", "authors": ["Sepehr Golrokh Amin", "Devin Rhoads", "Fatemeh Fakhrmoosavi", "Nicholas E. Lownes", "John N. Ivan"], "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This study introduces a Large Language Model (LLM) scheme for generating\nindividual travel diaries in agent-based transportation models. While\ntraditional approaches rely on large quantities of proprietary household travel\nsurveys, the method presented in this study generates personas stochastically\nfrom open-source American Community Survey (ACS) and Smart Location Database\n(SLD) data, then synthesizes diaries through direct prompting. This study\nfeatures a novel one-to-cohort realism score: a composite of four metrics (Trip\nCount Score, Interval Score, Purpose Score, and Mode Score) validated against\nthe Connecticut Statewide Transportation Study (CSTS) diaries, matched across\ndemographic variables. The validation utilizes Jensen-Shannon Divergence to\nmeasure distributional similarities between generated and real diaries. When\ncompared to diaries generated with classical methods (Negative Binomial for\ntrip generation; Multinomial Logit for mode/purpose) calibrated on the\nvalidation set, LLM-generated diaries achieve comparable overall realism (LLM\nmean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and\ndemonstrates greater consistency (narrower realism score distribution), while\nclassical models lead in numerical estimates of trip count and activity\nduration. Aggregate validation confirms the LLM's statistical\nrepresentativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot\nviability and establishing a quantifiable metric of diary realism for future\nsynthetic diary evaluation systems.", "AI": {"tldr": "The study uses a Large Language Model (LLM) to generate travel diaries, demonstrating comparable or better realism than traditional methods while leveraging open data sources.", "motivation": "To improve the generation of travel diaries without relying on proprietary survey data, using open-source data and evaluating the realism of generated synthetic diaries.", "method": "Stochastic persona generation from open data, direct prompting of an LLM to synthesize travel diaries, and evaluation via realism scores validated with real-world data using metrics like Jensen-Shannon Divergence.", "result": "LLM-generated diaries demonstrated overall realism comparable to traditional models, with superior performance in trip purpose determination and statistical representativeness, though classical models excelled in numerical trip count prediction.", "conclusion": "The proposed LLM approach is a viable zero-shot model for generating realistic travel diaries, offering an innovative path forward for synthetic diary evaluations."}}
{"id": "2509.09792", "pdf": "https://arxiv.org/pdf/2509.09792", "abs": "https://arxiv.org/abs/2509.09792", "authors": ["Zimin Xia", "Chenghao Xu", "Alexandre Alahi"], "title": "Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors", "categories": ["cs.CV"], "comment": null, "summary": "We propose an accurate and highly interpretable fine-grained cross-view\nlocalization method that estimates the 3 Degrees of Freedom pose of a\nground-level image by matching its local features with a reference aerial\nimage. Previous methods typically transform the ground image into a bird's-eye\nview (BEV) representation and then align it with the aerial image for\nlocalization. However, this transformation often leads to information loss due\nto perspective distortion or compression of height information, thereby\ndegrading alignment quality with the aerial view. In contrast, our method\ndirectly establishes correspondences between ground and aerial images and lifts\nonly the matched keypoints to BEV space using monocular depth prior. Notably,\nmodern depth predictors can provide reliable metric depth when the test samples\nare similar to the training data. When the depth distribution differs, they\nstill produce consistent relative depth, i.e., depth accurate up to an unknown\nscale. Our method supports both metric and relative depth. It employs a\nscale-aware Procrustes alignment to estimate the camera pose from the\ncorrespondences and optionally recover the scale when using relative depth.\nExperimental results demonstrate that, with only weak supervision on camera\npose, our method learns accurate local feature correspondences and achieves\nsuperior localization performance under challenging conditions, such as\ncross-area generalization and unknown orientation. Moreover, our method is\ncompatible with various relative depth models without requiring per-model\nfinetuning. This flexibility, combined with strong localization performance,\nmakes it well-suited for real-world deployment.", "AI": {"tldr": "The paper proposes a method to estimate the 3 Degrees of Freedom pose of ground-level images using local feature matching with aerial images. This is achieved without fully transforming the ground image into a bird\u2019s-eye view, addressing common issues like perspective distortion.", "motivation": "Existing localization methods often distort key spatial information when transforming ground images into bird's-eye view representations, leading to degraded alignments. A more accurate and interpretable localization approach is needed.", "method": "The method directly matches local features of ground images with aerial images, lifting only matched keypoints to a bird's-eye view using monocular depth priors. A scale-aware Procrustes alignment is used to estimate camera pose.", "result": "Experiments demonstrate superior localization performance under challenging scenarios, such as cross-area generalization and unknown orientations. The method is compatible with various depth models without requiring finetuning.", "conclusion": "The proposed approach effectively learns accurate feature correspondences with weak supervision and achieves robust localization performance, making it suitable for real-world scenarios while providing flexibility across diverse depth models."}}
{"id": "2509.10065", "pdf": "https://arxiv.org/pdf/2509.10065", "abs": "https://arxiv.org/abs/2509.10065", "authors": ["Hauzi Cao", "Jiahao Shen", "Zhengzhen Li", "Qinquan Ren", "Shiyu Zhao"], "title": "Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "This paper studies the kinematic tracking control problem for aerial\nmanipulators. Existing kinematic tracking control methods, which typically\nemploy proportional-derivative feedback or tracking-error-based feedback\nstrategies, may fail to achieve tracking objectives within specified time\nconstraints. To address this limitation, we propose a novel control framework\ncomprising two key components: end-effector tracking control based on a\nuser-defined preset trajectory and quadratic programming-based reference\nallocation. Compared with state-of-the-art approaches, the proposed method has\nseveral attractive features. First, it ensures that the end-effector reaches\nthe desired position within a preset time while keeping the tracking error\nwithin a performance envelope that reflects task requirements. Second,\nquadratic programming is employed to allocate the references of the quadcopter\nbase and the Delta arm, while considering the physical constraints of the\naerial manipulator, thus preventing solutions that may violate physical\nlimitations. The proposed approach is validated through three experiments.\nExperimental results demonstrate the effectiveness of the proposed algorithm\nand its capability to guarantee that the target position is reached within the\npreset time.", "AI": {"tldr": "The paper proposes a novel control framework for aerial manipulators to achieve kinematic tracking control within specified time constraints.", "motivation": "Existing methods fail to achieve tracking objectives within specific time limits due to their feedback-based strategies.", "method": "The authors introduce a control framework with two components: 1) user-defined end-effector trajectory tracking control, and 2) quadratic programming-based resource allocation while respecting physical constraints.", "result": "Experiments validate the method, showing that it ensures timely target position achievement and maintains tracking error within required performance levels.", "conclusion": "The proposed method can efficiently handle kinematic tracking with adherence to time and physical constraints, outperforming conventional approaches."}}
{"id": "2509.10279", "pdf": "https://arxiv.org/pdf/2509.10279", "abs": "https://arxiv.org/abs/2509.10279", "authors": ["Pavel Plyusnin", "Aleksey Antonov", "Vasilii Ermakov", "Aleksandr Khaybriev", "Margarita Kikot", "Ilseyar Alimova", "Stanislav Moiseev"], "title": "Targeted Test Selection Approach in Continuous Integration", "categories": ["cs.SE", "cs.LG"], "comment": "Accepted at ICSME 2025", "summary": "In modern software development change-based testing plays a crucial role.\nHowever, as codebases expand and test suites grow, efficiently managing the\ntesting process becomes increasingly challenging, especially given the high\nfrequency of daily code commits. We propose Targeted Test Selection (T-TS), a\nmachine learning approach for industrial test selection. Our key innovation is\na data representation that represent commits as Bags-of-Words of changed files,\nincorporates cross-file and additional predictive features, and notably avoids\nthe use of coverage maps. Deployed in production, T-TS was comprehensively\nevaluated against industry standards and recent methods using both internal and\npublic datasets, measuring time efficiency and fault detection. On live\nindustrial data, T-TS selects only 15% of tests, reduces execution time by\n$5.9\\times$, accelerates the pipeline by $5.6\\times$, and detects over 95% of\ntest failures. The implementation is publicly available to support further\nresearch and practical adoption.", "AI": {"tldr": "Proposes Targeted Test Selection (T-TS), a machine learning method for test selection in software development, achieving significant efficiency and fault detection improvements without relying on coverage maps.", "motivation": "Efficiently managing testing in expanding codebases and frequent commit environments poses a challenge.", "method": "Develops a machine learning approach using Bags-of-Words representation for changed files, predictive features, and avoids coverage maps.", "result": "T-TS selects 15% of tests, reduces execution time by $5.9\\times$, accelerates pipelines by $5.6\\times$, and detects over 95% of failures.", "conclusion": "T-TS enhances test efficiency and fault detection while being accessible for further research and industry applications."}}
{"id": "2509.10439", "pdf": "https://arxiv.org/pdf/2509.10439", "abs": "https://arxiv.org/abs/2509.10439", "authors": ["Ahmed Khaled", "Satyen Kale", "Arthur Douillard", "Chi Jin", "Rob Fergus", "Manzil Zaheer"], "title": "Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Modern machine learning often requires training with large batch size,\ndistributed data, and massively parallel compute hardware (like mobile and\nother edge devices or distributed data centers). Communication becomes a major\nbottleneck in such settings but methods like Local Stochastic Gradient Descent\n(Local SGD) show great promise in reducing this additional communication\noverhead. Local SGD consists of three parts: a local optimization process, an\naggregation mechanism, and an outer optimizer that uses the aggregated updates\nfrom the nodes to produce a new model. While there exists an extensive\nliterature on understanding the impact of hyperparameters in the local\noptimization process, the choice of outer optimizer and its hyperparameters is\nless clear. We study the role of the outer optimizer in Local SGD, and prove\nnew convergence guarantees for the algorithm. In particular, we show that\ntuning the outer learning rate allows us to (a) trade off between optimization\nerror and stochastic gradient noise variance, and (b) make up for ill-tuning of\nthe inner learning rate. Our theory suggests that the outer learning rate\nshould sometimes be set to values greater than $1$. We extend our results to\nsettings where we use momentum in the outer optimizer, and we show a similar\nrole for the momentum-adjusted outer learning rate. We also study acceleration\nin the outer optimizer and show that it improves the convergence rate as a\nfunction of the number of communication rounds, improving upon the convergence\nrate of prior algorithms that apply acceleration locally. Finally, we also\nintroduce a novel data-dependent analysis of Local SGD that yields further\ninsights on outer learning rate tuning. We conduct comprehensive experiments\nwith standard language models and various outer optimizers to validate our\ntheory.", "AI": {"tldr": "This paper studies the role of the outer optimizer in Local SGD, proving new convergence guarantees and demonstrating the importance of tuning the outer learning rate and momentum, validated through experiments.", "motivation": "To reduce communication overhead in distributed machine learning systems while preserving convergence performance by understanding the role of the outer learning process in Local SGD.", "method": "The researchers theoretically analyzed the impact of the outer learning rate and momentum in Local SGD, improved convergence rates by accelerating the outer optimizer, and introduced a data-dependent analysis. Experiments validated these insights on standard language models.", "result": "They showed that tuning the outer learning rate allows for balancing optimization error and noise variance, compensating for poorly tuned inner learning rates, and achieving improved convergence rates with outer acceleration.", "conclusion": "The outer optimizer plays a critical role in Local SGD, with proper tuning of the outer learning rate and momentum leading to improved convergence and performance in distributed machine learning."}}
{"id": "2509.10147", "pdf": "https://arxiv.org/pdf/2509.10147", "abs": "https://arxiv.org/abs/2509.10147", "authors": ["Nenad Tomasev", "Matija Franklin", "Joel Z. Leibo", "Julian Jacobs", "William A. Cunningham", "Iason Gabriel", "Simon Osindero"], "title": "Virtual Agent Economies", "categories": ["cs.AI"], "comment": null, "summary": "The rapid adoption of autonomous AI agents is giving rise to a new economic\nlayer where agents transact and coordinate at scales and speeds beyond direct\nhuman oversight. We propose the \"sandbox economy\" as a framework for analyzing\nthis emergent system, characterizing it along two key dimensions: its origins\n(emergent vs. intentional) and its degree of separateness from the established\nhuman economy (permeable vs. impermeable). Our current trajectory points toward\na spontaneous emergence of a vast and highly permeable AI agent economy,\npresenting us with opportunities for an unprecedented degree of coordination as\nwell as significant challenges, including systemic economic risk and\nexacerbated inequality. Here we discuss a number of possible design choices\nthat may lead to safely steerable AI agent markets. In particular, we consider\nauction mechanisms for fair resource allocation and preference resolution, the\ndesign of AI \"mission economies\" to coordinate around achieving collective\ngoals, and socio-technical infrastructure needed to ensure trust, safety, and\naccountability. By doing this, we argue for the proactive design of steerable\nagent markets to ensure the coming technological shift aligns with humanity's\nlong-term collective flourishing.", "AI": {"tldr": "The paper introduces the concept of a 'sandbox economy' to study emerging AI agent-driven economic systems, outlining their risks and proposing design choices for safe and beneficial implementations.", "motivation": "To address the need for frameworks and mechanisms to analyze and guide the rapid emergence and impact of autonomous AI-agent economies on broader economic systems.", "method": "Proposes the 'sandbox economy' framework, categorizing AI economies by origin and integration, and suggests design mechanisms like auction systems, 'mission economies,' and socio-technical infrastructures.", "result": "Identifies opportunities for coordination and challenges such as economic risks, inequality, and trust issues in AI-driven economies, and highlights potential mechanisms for resolving these problems.", "conclusion": "Advocates for the proactive design of AI agent market systems to manage risks and ensure these technologies foster collective human flourishing in the long term."}}
{"id": "2509.09864", "pdf": "https://arxiv.org/pdf/2509.09864", "abs": "https://arxiv.org/abs/2509.09864", "authors": ["Jenny Y. Huang", "Mehul Damani", "Yousef El-Kurdi", "Ramon Astudillo", "Wei Sun"], "title": "Latency and Token-Aware Test-Time Compute", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Inference-time scaling has emerged as a powerful way to improve large\nlanguage model (LLM) performance by generating multiple candidate responses and\nselecting among them. However, existing work on dynamic allocation for\ntest-time compute typically considers only parallel generation methods such as\nbest-of-N, overlooking incremental decoding methods like beam search, and has\nlargely ignored latency, focusing only on token usage. We formulate\ninference-time scaling as a problem of dynamic compute allocation and method\nselection, where the system must decide which strategy to apply and how much\ncompute to allocate on a per-query basis. Our framework explicitly incorporates\nboth token cost and wall-clock latency, the latter being critical for user\nexperience and particularly for agentic workflows where models must issue\nmultiple queries efficiently. Experiments on reasoning benchmarks show that our\napproach consistently outperforms static strategies, achieving favorable\naccuracy-cost trade-offs while remaining practical for deployment.", "AI": {"tldr": "This paper addresses improving inference-time efficiency and effectiveness for large language models through dynamic compute strategies.", "motivation": "Current approaches to scaling inference-time performance often neglect latency considerations and focus solely on token usage.", "method": "A framework for dynamic allocation of test-time computing resources and method selection, considering both token costs and wall-clock latency to optimize efficiency and accuracy.", "result": "Experiments demonstrate that this approach outperforms static strategies in accuracy-cost trade-offs and proves practical for deployment.", "conclusion": "Dynamic compute allocation strategies can improve large language model performance while balancing costs and deployment feasibility."}}
{"id": "2509.09711", "pdf": "https://arxiv.org/pdf/2509.09711", "abs": "https://arxiv.org/abs/2509.09711", "authors": ["Aya E. Fouda", "Abdelrahamn A. Hassan", "Radwa J. Hanafy", "Mohammed E. Fouda"], "title": "Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) hold great promise in enhancing psychiatric\npractice, from improving diagnostic accuracy to streamlining clinical\ndocumentation and therapeutic support. However, existing evaluation resources\nheavily rely on small clinical interview corpora, social media posts, or\nsynthetic dialogues, which limits their clinical validity and fails to capture\nthe full complexity of psychiatric reasoning. In this work, we introduce\nPsychiatryBench, a rigorously curated benchmark grounded exclusively in\nauthoritative, expert-validated psychiatric textbooks and casebooks.\nPsychiatryBench comprises eleven distinct question-answering tasks ranging from\ndiagnostic reasoning and treatment planning to longitudinal follow-up,\nmanagement planning, clinical approach, sequential case analysis, and\nmultiple-choice/extended matching formats totaling over 5,300 expert-annotated\nitems. We evaluate a diverse set of frontier LLMs (including Google Gemini,\nDeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models\n(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an\n\"LLM-as-judge\" similarity scoring framework. Our results reveal substantial\ngaps in clinical consistency and safety, particularly in multi-turn follow-up\nand management tasks, underscoring the need for specialized model tuning and\nmore robust evaluation paradigms. PsychiatryBench offers a modular, extensible\nplatform for benchmarking and improving LLM performance in high-stakes mental\nhealth applications.", "AI": {"tldr": "The paper introduces PsychiatryBench, a specialized benchmark based on expert-validated sources for evaluating LLMs in psychiatric tasks. It highlights LLMs' limitations in clinical consistency and safety, offering a modular framework to enhance LLM performance in mental health contexts.", "motivation": "To address the lack of clinically valid resources for evaluating LLMs' performance in psychiatric applications.", "method": "Developed PsychiatryBench, a benchmark drawn from authoritative psychiatric textbooks and casebooks. PsychiatryBench includes 11 question-answering tasks with over 5,300 expert-annotated items. Various LLMs were evaluated using conventional metrics and an LLM-as-judge similarity scoring framework.", "result": "The evaluation revealed significant gaps in clinical consistency and safety, especially in multi-turn follow-up and management tasks, showcasing the limitations of current LLMs in psychiatric reasoning.", "conclusion": "PsychiatryBench provides a valuable platform to benchmark and improve LLM capabilities in high-stakes psychiatric scenarios, stressing the need for model tuning and better evaluation methodologies."}}
{"id": "2509.09808", "pdf": "https://arxiv.org/pdf/2509.09808", "abs": "https://arxiv.org/abs/2509.09808", "authors": ["Judith Massmann", "Alexander Lichtenstein", "Francisco M. L\u00f3pez"], "title": "Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at IEEE ICDL 2025. 6 pages, 7 figures, 2 tables", "summary": "Numerous visual impairments can be detected in red-eye reflex images from\nyoung children. The so-called Bruckner test is traditionally performed by\nophthalmologists in clinical settings. Thanks to the recent technological\nadvances in smartphones and artificial intelligence, it is now possible to\nrecreate the Bruckner test using a mobile device. In this paper, we present a\nfirst study conducted during the development of KidsVisionCheck, a free\napplication that can perform vision screening with a mobile device using\nred-eye reflex images. The underlying model relies on deep neural networks\ntrained on children's pupil images collected and labeled by an ophthalmologist.\nWith an accuracy of 90% on unseen test data, our model provides highly reliable\nperformance without the necessity of specialist equipment. Furthermore, we can\nidentify the optimal conditions for data collection, which can in turn be used\nto provide immediate feedback to the users. In summary, this work marks a first\nstep toward accessible pediatric vision screenings and early intervention for\nvision abnormalities worldwide.", "AI": {"tldr": "Using a mobile app called KidsVisionCheck, researchers emulate the Bruckner test to detect visual impairments in children with 90% accuracy using deep neural networks.", "motivation": "To create an accessible, mobile-based solution for pediatric vision screenings to allow early detection of visual impairments, especially in non-clinical settings.", "method": "The study trained deep neural networks on pupil images of children, labeled by ophthalmologists, to perform vision screening using red-eye reflex images on a mobile device.", "result": "The model achieved a high accuracy rate of 90% on unseen test data and offered feedback on optimal data collection conditions.", "conclusion": "KidsVisionCheck represents a significant step forward in accessible, mobile-based vision screening for children worldwide, enabling early intervention and improving global pediatric eye care."}}
{"id": "2509.10096", "pdf": "https://arxiv.org/pdf/2509.10096", "abs": "https://arxiv.org/abs/2509.10096", "authors": ["Saeed Saadatnejad", "Reyhaneh Hosseininejad", "Jose Barreiros", "Katherine M. Tsui", "Alexandre Alahi"], "title": "HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to RA-L 2025", "summary": "The increasing labor shortage and aging population underline the need for\nassistive robots to support human care recipients. To enable safe and\nresponsive assistance, robots require accurate human motion prediction in\nphysical interaction scenarios. However, this remains a challenging task due to\nthe variability of assistive settings and the complexity of coupled dynamics in\nphysical interactions. In this work, we address these challenges through two\nkey contributions: (1) HHI-Assist, a dataset comprising motion capture clips of\nhuman-human interactions in assistive tasks; and (2) a conditional\nTransformer-based denoising diffusion model for predicting the poses of\ninteracting agents. Our model effectively captures the coupled dynamics between\ncaregivers and care receivers, demonstrating improvements over baselines and\nstrong generalization to unseen scenarios. By advancing interaction-aware\nmotion prediction and introducing a new dataset, our work has the potential to\nsignificantly enhance robotic assistance policies. The dataset and code are\navailable at: https://sites.google.com/view/hhi-assist/home", "AI": {"tldr": "This paper introduces a dataset (HHI-Assist) and a Transformer-based denoising diffusion model to improve human motion prediction in assistive robotics.", "motivation": "Address the challenge of labor shortages and aging populations by developing robots capable of accurate human motion prediction in physical interactions.", "method": "Developed HHI-Assist dataset and employed a conditional Transformer-based denoising diffusion model to predict poses in assistive scenarios.", "result": "The model captures coupled dynamics between interacting agents, surpassing baselines and generalizing to new situations.", "conclusion": "This work advances assistive robot capabilities by introducing impactful resources for interaction-aware motion prediction."}}
{"id": "2509.10402", "pdf": "https://arxiv.org/pdf/2509.10402", "abs": "https://arxiv.org/abs/2509.10402", "authors": ["Suzhen Zhong", "Ying Zou", "Bram Adams"], "title": "Developer-LLM Conversations: An Empirical Study of Interactions and Generated Code Quality", "categories": ["cs.SE", "D.2.0; D.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are becoming integral to modern software\ndevelopment workflows, assisting developers with code generation, API\nexplanation, and iterative problem-solving through natural language\nconversations. Despite widespread adoption, there is limited understanding of\nhow developers interact with LLMs in practice and how these conversational\ndynamics influence task outcomes, code quality, and software engineering\nworkflows. To address this, we leverage CodeChat, a large dataset comprising\n82,845 real-world developer-LLM conversations, containing 368,506 code snippets\ngenerated across over 20 programming languages, derived from the WildChat\ndataset. We find that LLM responses are substantially longer than developer\nprompts, with a median token-length ratio of 14:1. Multi-turn conversations\naccount for 68% of the dataset and often evolve due to shifting requirements,\nincomplete prompts, or clarification requests. Topic analysis identifies web\ndesign (9.6% of conversations) and neural network training (8.7% of\nconversations) as the most frequent LLM-assisted tasks. Evaluation across five\nlanguages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and\nlanguage-specific issues in LLM-generated code: generated Python and JavaScript\ncode often include undefined variables (83.4% and 75.3% of code snippets,\nrespectively); Java code lacks required comments (75.9%); C++ code frequently\nomits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a\nconversation, syntax and import errors persist across turns; however,\ndocumentation quality in Java improves by up to 14.7%, and import handling in\nPython improves by 3.7% over 5 turns. Prompts that point out mistakes in code\ngenerated in prior turns and explicitly request a fix are most effective for\nresolving errors.", "AI": {"tldr": "The study explores how developers interact with Large Language Models (LLMs) in real-world programming scenarios using a dataset of 82,845 conversations, highlighting their conversational dynamics, prevalent issues in generated code, and error-resolution strategies.", "motivation": "To understand the interaction between developers and LLMs, analyze conversational dynamics, and measure the impact on code quality and development workflows.", "method": "The study analyzes CodeChat, a dataset based on real-world developer-LLM conversations covering over 368,506 code snippets across 20+ programming languages, with a focus on evaluating generated code quality and conversational dynamics.", "result": "The study finds that LLM responses are significantly longer than prompts, multi-turn conversations are common, and both prevalent and language-specific issues exist in generated code. Effective error resolution occurs when developers explicitly point out issues and request fixes.", "conclusion": "LLMs are widely used but generate code with non-trivial, often language-specific errors. Developers can improve outcomes by engaging directly and iteratively, especially by flagging flaws and asking for direct corrections."}}
{"id": "2509.10162", "pdf": "https://arxiv.org/pdf/2509.10162", "abs": "https://arxiv.org/abs/2509.10162", "authors": ["Tamir Shazman", "Idan Lev-Yehudi", "Ron Benchetit", "Vadim Indelman"], "title": "Online Robust Planning under Model Uncertainty: A Sample-Based Approach", "categories": ["cs.AI"], "comment": null, "summary": "Online planning in Markov Decision Processes (MDPs) enables agents to make\nsequential decisions by simulating future trajectories from the current state,\nmaking it well-suited for large-scale or dynamic environments. Sample-based\nmethods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely\nadopted for their ability to approximate optimal actions using a generative\nmodel. However, in practical settings, the generative model is often learned\nfrom limited data, introducing approximation errors that can degrade\nperformance or lead to unsafe behaviors. To address these challenges, Robust\nMDPs (RMDPs) offer a principled framework for planning under model uncertainty,\nyet existing approaches are typically computationally intensive and not suited\nfor real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the\nfirst online planning algorithm for RMDPs with finite-sample theoretical\nperformance guarantees. Unlike Sparse Sampling, which estimates the nominal\nvalue function, RSS computes a robust value function by leveraging the\nefficiency and theoretical properties of Sample Average Approximation (SAA),\nenabling tractable robust policy computation in online settings. RSS is\napplicable to infinite or continuous state spaces, and its sample and\ncomputational complexities are independent of the state space size. We provide\ntheoretical performance guarantees and empirically show that RSS outperforms\nstandard Sparse Sampling in environments with uncertain dynamics.", "AI": {"tldr": "This paper introduces Robust Sparse Sampling (RSS), a novel online planning algorithm for Robust MDPs, suitable for real-time use and offering theoretical performance guarantees.", "motivation": "To address the challenges of model uncertainty and approximation errors in sample-based online planning for Markov Decision Processes.", "method": "RSS computes robust value functions using Sample Average Approximation (SAA), ensuring tractable policy computation in environments with uncertain dynamics.", "result": "RSS outperforms standard Sparse Sampling in environments with uncertain dynamics, and provides finite-sample theoretical performance guarantees.", "conclusion": "RSS advances online planning in MDPs by combining computational efficiency and robustness, making it applicable to real-time settings and large-scale problems with model uncertainty."}}
{"id": "2509.09899", "pdf": "https://arxiv.org/pdf/2509.09899", "abs": "https://arxiv.org/abs/2509.09899", "authors": ["Christopher Eldred", "Fran\u00e7ois Gay-Balmaz", "Vakhtang Putkaradze"], "title": "Variational Neural Networks for Observable Thermodynamics (V-NOTS)", "categories": ["cs.LG"], "comment": "26 pages, 6 figures", "summary": "Much attention has recently been devoted to data-based computing of evolution\nof physical systems. In such approaches, information about data points from\npast trajectories in phase space is used to reconstruct the equations of motion\nand to predict future solutions that have not been observed before. However, in\nmany cases, the available data does not correspond to the variables that define\nthe system's phase space. We focus our attention on the important example of\ndissipative dynamical systems. In that case, the phase space consists of\ncoordinates, momenta and entropies; however, the momenta and entropies cannot,\nin general, be observed directly. To address this difficulty, we develop an\nefficient data-based computing framework based exclusively on observable\nvariables, by constructing a novel approach based on the \\emph{thermodynamic\nLagrangian}, and constructing neural networks that respect the thermodynamics\nand guarantees the non-decreasing entropy evolution. We show that our network\ncan provide an efficient description of phase space evolution based on a\nlimited number of data points and a relatively small number of parameters in\nthe system.", "AI": {"tldr": "The paper develops a data-based computing framework for predicting the evolution of dissipative physical systems, even when some phase space variables are unobservable.", "motivation": "To address challenges in reconstructing the evolution of dissipative systems when some critical phase space variables (momenta and entropies) are not directly observable.", "method": "The method involves constructing a thermodynamic Lagrangian and training neural networks designed to adhere to thermodynamic principles, including ensuring non-decreasing entropy.", "result": "The proposed neural networks successfully describe phase space evolution using limited observational data and a small computational parameter set.", "conclusion": "The framework demonstrates efficiency in providing accurate predictions of physical system evolution, respecting the thermodynamic constraints while relying only on observable variables."}}
{"id": "2509.09712", "pdf": "https://arxiv.org/pdf/2509.09712", "abs": "https://arxiv.org/abs/2509.09712", "authors": ["Talha Tahir"], "title": "The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral\ntherapy with emerging evidence of efficacy in several psychiatric conditions.\nThis study investigates the impact of post-training methodology and explicit\nreasoning on the ability of a small open-weight large language model (LLM) to\ndeliver ACT. Using 50 sets of synthetic ACT transcripts generated by\nMistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,\nsupervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each\nwith and without an explicit chain-of-thought (COT) reasoning step. Performance\nwas evaluated by comparing these four post-trained variants against the base\nInstruct model. These models were benchmarked in simulated therapy sessions,\nwith performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)\nand the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned\non human evaluations. Our findings demonstrate that the ORPO-trained models\nsignificantly outperformed both their SFT and Instruct counterparts on ACT\nfidelity ($\\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\\chi^2(5) =\n140.37, p < .001$). The effect of COT was conditional as it provided a\nsignificant benefit to SFT models, improving ACT-FM scores by an average of\n2.68 points ($p < .001$), while offering no discernible advantage to the\nsuperior ORPO or instruct-tuned variants. We posit that the superiority of ORPO\nstems from its ability to learn the therapeutic `process' over imitating\n`content,' a key aspect of ACT, while COT acts as a necessary scaffold for\nmodels trained only via imitation. This study establishes that\npreference-aligned policy optimization can effectively instill ACT competencies\nin small LLMs, and that the utility of explicit reasoning is highly dependent\non the underlying training paradigm.", "AI": {"tldr": "This study evaluates methods to train small language models in Acceptance and Commitment Therapy (ACT), finding that policy optimization outperforms fine-tuning, with reasoning steps offering conditional benefits.", "motivation": "To explore how small large language models can be trained effectively to deliver ACT therapy using innovative optimization techniques and reasoning strategies.", "method": "They trained Llama-3.2-3b-Instruct using supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), both with and without a chain-of-thought (COT) reasoning step, and assessed performance using ACT-FM and TES benchmarks evaluated by a fine-tuned LLM judge.", "result": "ORPO-trained models significantly outperformed SFT and base Instruct models in ACT fidelity and therapeutic empathy metrics, while COT reasoning steps added value only for the SFT-trained models.", "conclusion": "ORPO effectively teaches therapeutic 'process' rather than 'content,' making it superior for instilling ACT competencies in small LLMs, while COT reasoning's utility depends on the training method."}}
{"id": "2509.09828", "pdf": "https://arxiv.org/pdf/2509.09828", "abs": "https://arxiv.org/abs/2509.09828", "authors": ["Tim Broedermannn", "Christos Sakaridis", "Luigi Piccinelli", "Wim Abbeloos", "Luc Van Gool"], "title": "DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Code and models will be available at\n  https://github.com/timbroed/DGFusion", "summary": "Robust semantic perception for autonomous vehicles relies on effectively\ncombining multiple sensors with complementary strengths and weaknesses.\nState-of-the-art sensor fusion approaches to semantic perception often treat\nsensor data uniformly across the spatial extent of the input, which hinders\nperformance when faced with challenging conditions. By contrast, we propose a\nnovel depth-guided multimodal fusion method that upgrades condition-aware\nfusion by integrating depth information. Our network, DGFusion, poses\nmultimodal segmentation as a multi-task problem, utilizing the lidar\nmeasurements, which are typically available in outdoor sensor suites, both as\none of the model's inputs and as ground truth for learning depth. Our\ncorresponding auxiliary depth head helps to learn depth-aware features, which\nare encoded into spatially varying local depth tokens that condition our\nattentive cross-modal fusion. Together with a global condition token, these\nlocal depth tokens dynamically adapt sensor fusion to the spatially varying\nreliability of each sensor across the scene, which largely depends on depth. In\naddition, we propose a robust loss for our depth, which is essential for\nlearning from lidar inputs that are typically sparse and noisy in adverse\nconditions. Our method achieves state-of-the-art panoptic and semantic\nsegmentation performance on the challenging MUSES and DELIVER datasets. Code\nand models will be available at https://github.com/timbroed/DGFusion", "AI": {"tldr": "The paper introduces DGFusion, a depth-guided multimodal fusion model that enhances semantic perception for autonomous vehicles by dynamically adapting sensor fusion based on depth-related spatial conditions.", "motivation": "Current state-of-the-art sensor fusion methods struggle with uniformly treating multimodal sensor data across varying conditions, especially in challenging environments.", "method": "A novel depth-guided multimodal fusion method is developed, leveraging lidar's depth measurements both as input and ground truth. Depth-aware features are encoded into spatially varying local depth tokens and combined with global condition tokens to enable adaptive sensor fusion.", "result": "DGFusion achieves state-of-the-art semantic and panoptic segmentation performance on the MUSES and DELIVER datasets, demonstrating robustness against challenging conditions.", "conclusion": "Depth information can significantly improve condition-aware fusion in multimodal networks by dynamically adapting to the spatial reliability of sensors, enhancing segmentation performance."}}
{"id": "2509.10128", "pdf": "https://arxiv.org/pdf/2509.10128", "abs": "https://arxiv.org/abs/2509.10128", "authors": ["Philip Arm", "Oliver Fischer", "Joseph Church", "Adrian Fuhrer", "Hendrik Kolvenbach", "Marco Hutter"], "title": "Efficient Learning-Based Control of a Legged Robot in Lunar Gravity", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Legged robots are promising candidates for exploring challenging areas on\nlow-gravity bodies such as the Moon, Mars, or asteroids, thanks to their\nadvanced mobility on unstructured terrain. However, as planetary robots' power\nand thermal budgets are highly restricted, these robots need energy-efficient\ncontrol approaches that easily transfer to multiple gravity environments. In\nthis work, we introduce a reinforcement learning-based control approach for\nlegged robots with gravity-scaled power-optimized reward functions. We use our\napproach to develop and validate a locomotion controller and a base pose\ncontroller in gravity environments from lunar gravity (1.62 m/s2) to a\nhypothetical super-Earth (19.62 m/s2). Our approach successfully scales across\nthese gravity levels for locomotion and base pose control with the\ngravity-scaled reward functions. The power-optimized locomotion controller\nreached a power consumption for locomotion of 23.4 W in Earth gravity on a\n15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.\nAdditionally, we designed a constant-force spring offload system that allowed\nus to conduct real-world experiments on legged locomotion in lunar gravity. In\nlunar gravity, the power-optimized control policy reached 12.2 W, 36 % less\nthan a baseline controller which is not optimized for power efficiency. Our\nmethod provides a scalable approach to developing power-efficient locomotion\ncontrollers for legged robots across multiple gravity levels.", "AI": {"tldr": "This paper proposes a scalable reinforcement learning-based control approach for legged robots to ensure energy-efficient locomotion across different gravity environments, validated through simulation and real tests.", "motivation": "Planetary robots face constraints with power and thermal budgets when exploring low-gravity bodies, requiring energy-efficient and adaptable control methods.", "method": "A reinforcement learning-based control technique using gravity-scaled, power-optimized reward functions, combined with a constant-force spring offload system for lunar gravity experimentation.", "result": "The locomotion controller achieved a power consumption of 23.4 W in Earth gravity, a 23% improvement, and 12.2 W in lunar gravity, 36% lower than the baseline policy.", "conclusion": "The proposed method successfully delivers power-efficient controllers that scale well across different gravity environments for legged robots."}}
{"id": "2509.10210", "pdf": "https://arxiv.org/pdf/2509.10210", "abs": "https://arxiv.org/abs/2509.10210", "authors": ["Marko Petkovi\u0107", "Vlado Menkovski", "Sof\u00eda Calero"], "title": "Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Automated characterization of porous materials has the potential to\naccelerate materials discovery, but it remains limited by the complexity of\nsimulation setup and force field selection. We propose a multi-agent framework\nin which LLM-based agents can autonomously understand a characterization task,\nplan appropriate simulations, assemble relevant force fields, execute them and\ninterpret their results to guide subsequent steps. As a first step toward this\nvision, we present a multi-agent system for literature-informed force field\nextraction and automated RASPA simulation setup. Initial evaluations\ndemonstrate high correctness and reproducibility, highlighting this approach's\npotential to enable fully autonomous, scalable materials characterization.", "AI": {"tldr": "This paper introduces a multi-agent framework using LLM-based agents for automating the characterization of porous materials.", "motivation": "Characterizing porous materials has challenges in simulation setup and force field selection, which slow down materials discovery.", "method": "The paper presents a multi-agent system leveraging LLM-based agents for automated literature-based force field extraction and RASPA simulation setup.", "result": "Initial evaluations reveal high correctness and reproducibility in the approach, emphasizing its effectiveness.", "conclusion": "The proposed system demonstrates promise for enabling fully autonomous and scalable materials characterization in the future."}}
{"id": "2509.09926", "pdf": "https://arxiv.org/pdf/2509.09926", "abs": "https://arxiv.org/abs/2509.09926", "authors": ["Jiahao Chen", "Zhiyuan Huang", "Yurou Liu", "Bing Su"], "title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Long-tailed learning has garnered increasing attention due to its wide\napplicability in real-world scenarios. Among existing approaches, Long-Tailed\nSemi-Supervised Learning (LTSSL) has emerged as an effective solution by\nincorporating a large amount of unlabeled data into the imbalanced labeled\ndataset. However, most prior LTSSL methods are designed to train models from\nscratch, which often leads to issues such as overconfidence and low-quality\npseudo-labels. To address these challenges, we extend LTSSL into the foundation\nmodel fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed\nsemi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate\nthat fine-tuned foundation models can generate more reliable pseudolabels,\nthereby benefiting imbalanced learning. Furthermore, we explore a more\npractical setting by investigating semi-supervised learning under open-world\nconditions, where the unlabeled data may include out-of-distribution (OOD)\nsamples. To handle this problem, we propose LoFT-OW (LoFT under Open-World\nscenarios) to improve the discriminative ability. Experimental results on\nmultiple benchmarks demonstrate that our method achieves superior performance\ncompared to previous approaches, even when utilizing only 1\\% of the unlabeled\ndata compared with previous works.", "AI": {"tldr": "This paper introduces LoFT, a novel framework for Long-Tailed Semi-Supervised Learning leveraging fine-tuned foundation models and addressing open-world scenarios with improved pseudolabeling and out-of-distribution handling.", "motivation": "Address limitations such as overconfidence and low-quality pseudolabels in existing LTSSL methods that train models from scratch.", "method": "Proposed LoFT framework for parameter-efficient fine-tuning of foundation models and extended it to handle open-world scenarios.", "result": "LoFT demonstrated superior performance on benchmarks, even while using only 1% labeled data compared to previous works.", "conclusion": "LoFT offers a promising update for LTSSL by utilizing fine-tuned foundation models and effectively addressing open-world semi-supervised learning challenges."}}
{"id": "2509.09713", "pdf": "https://arxiv.org/pdf/2509.09713", "abs": "https://arxiv.org/abs/2509.09713", "authors": ["Duolin Sun", "Dan Yang", "Yue Shen", "Yihan Jiao", "Zhehao Tan", "Jie Feng", "Lianzhen Zhong", "Jian Wang", "Peng Wei", "Jinjie Gu"], "title": "HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The Retrieval-Augmented Generation (RAG) approach enhances question-answering\nsystems and dialogue generation tasks by integrating information retrieval (IR)\ntechnologies with large language models (LLMs). This strategy, which retrieves\ninformation from external knowledge bases to bolster the response capabilities\nof generative models, has achieved certain successes. However, current RAG\nmethods still face numerous challenges when dealing with multi-hop queries. For\ninstance, some approaches overly rely on iterative retrieval, wasting too many\nretrieval steps on compound queries. Additionally, using the original complex\nquery for retrieval may fail to capture content relevant to specific\nsub-queries, resulting in noisy retrieved content. If the noise is not managed,\nit can lead to the problem of noise accumulation. To address these issues, we\nintroduce HANRAG, a novel heuristic-based framework designed to efficiently\ntackle problems of varying complexity. Driven by a powerful revelator, HANRAG\nroutes queries, decomposes them into sub-queries, and filters noise from\nretrieved documents. This enhances the system's adaptability and noise\nresistance, making it highly capable of handling diverse queries. We compare\nthe proposed framework against other leading industry methods across various\nbenchmarks. The results demonstrate that our framework obtains superior\nperformance in both single-hop and multi-hop question-answering tasks.", "AI": {"tldr": "The paper introduces HANRAG, a heuristic-based method designed to improve multi-hop query capabilities and reduce noise in retrieval-augmented generation tasks.", "motivation": "Current Retrieval-Augmented Generation (RAG) methods struggle with multi-hop queries due to inefficiencies like iterative retrieval and noise accumulation.", "method": "HANRAG leverages a heuristic framework where queries are decomposed into sub-queries, noise is filtered from retrieved content, and a revelator routes queries efficiently.", "result": "HANRAG outperforms industry-leading methods in benchmarks for both single-hop and multi-hop question-answering tasks.", "conclusion": "HANRAG enhances systems' adaptability and noise resistance, providing significant improvements in retrieval-augmented generation approaches."}}
{"id": "2509.09841", "pdf": "https://arxiv.org/pdf/2509.09841", "abs": "https://arxiv.org/abs/2509.09841", "authors": ["Chengyu Yang", "Rishik Reddy Yesgari", "Chengjun Liu"], "title": "Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework", "categories": ["cs.CV"], "comment": null, "summary": "Rosacea, which is a chronic inflammatory skin condition that manifests with\nfacial redness, papules, and visible blood vessels, often requirs precise and\nearly detection for significantly improving treatment effectiveness. This paper\npresents new patch-based automatic rosacea detection strategies using the\nResNet-18 deep learning framework. The contributions of the proposed strategies\ncome from the following aspects. First, various image pateches are extracted\nfrom the facial images of people in different sizes, shapes, and locations.\nSecond, a number of investigation studies are carried out to evaluate how the\nlocalized visual information influences the deep learing model performance.\nThird, thorough experiments are implemented to reveal that several patch-based\nautomatic rosacea detection strategies achieve competitive or superior accuracy\nand sensitivity than the full-image based methods. And finally, the proposed\npatch-based strategies, which use only localized patches, inherently preserve\npatient privacy by excluding any identifiable facial features from the data.\nThe experimental results indicate that the proposed patch-based strategies\nguide the deep learning model to focus on clinically relevant regions, enhance\nrobustness and interpretability, and protect patient privacy. As a result, the\nproposed strategies offer practical insights for improving automated\ndermatological diagnostics.", "AI": {"tldr": "The study proposes new patch-based methods using ResNet-18 deep learning for automatic rosacea detection, emphasizing localized visual information, better performance, and patient privacy.", "motivation": "The motivation is to develop accurate, robust, and privacy-preserving methods for early rosacea detection, which improves treatment effectiveness.", "method": "The paper uses patch-based strategies with ResNet-18, extracting image patches of various sizes and shapes, and evaluates their influence on detection performance.", "result": "The patch-based methods achieve better accuracy and sensitivity than full-image methods, guide the model to focus on relevant areas, and ensure patient privacy.", "conclusion": "The strategies enhance detection accuracy, robustness, and interpretability, while protecting patient privacy, offering practical insights for automated dermatological diagnostics."}}
{"id": "2509.10139", "pdf": "https://arxiv.org/pdf/2509.10139", "abs": "https://arxiv.org/abs/2509.10139", "authors": ["Santiago Montiel-Mar\u00edn", "Angel Llamazares", "Miguel Antunes-Garc\u00eda", "Fabio S\u00e1nchez-Garc\u00eda", "Luis M. Bergasa"], "title": "CaR1: A Multi-Modal Baseline for BEV Vehicle Segmentation via Camera-Radar Fusion", "categories": ["cs.RO"], "comment": "4 pages, 2 figures", "summary": "Camera-radar fusion offers a robust and cost-effective alternative to\nLiDAR-based autonomous driving systems by combining complementary sensing\ncapabilities: cameras provide rich semantic cues but unreliable depth, while\nradar delivers sparse yet reliable position and motion information. We\nintroduce CaR1, a novel camera-radar fusion architecture for BEV vehicle\nsegmentation. Built upon BEVFusion, our approach incorporates a grid-wise radar\nencoding that discretizes point clouds into structured BEV features and an\nadaptive fusion mechanism that dynamically balances sensor contributions.\nExperiments on nuScenes demonstrate competitive segmentation performance (57.6\nIoU), on par with state-of-the-art methods. Code is publicly available\n\\href{https://www.github.com/santimontiel/car1}{online}.", "AI": {"tldr": "CaR1 proposes a novel approach to camera-radar fusion for bird\u2019s-eye view (BEV) vehicle segmentation, aiming to deliver competitive performance cost-effectively compared to LiDAR.", "motivation": "To enhance autonomous driving systems by leveraging the complementary strengths of cameras (semantic cues) and radar (reliable depth/motion data).", "method": "The architecture integrates grid-wise radar encoding to structure radar point-cloud data into BEV features, along with an adaptive fusion mechanism that dynamically balances contributions from both sensors.", "result": "CaR1 achieves a segmentation IoU of 57.6 on the nuScenes dataset, which is competitive with state-of-the-art approaches.", "conclusion": "Camera-radar fusion with CaR1 is a promising alternative to LiDAR systems, offering robust and cost-effective performance in vehicle segmentation tasks."}}
{"id": "2509.09942", "pdf": "https://arxiv.org/pdf/2509.09942", "abs": "https://arxiv.org/abs/2509.09942", "authors": ["Lei Yu", "Jingyuan Zhang", "Xin Wang", "Jiajia Ma", "Li Yang", "Fengjun Zhang"], "title": "SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "Smart contracts automate the management of high-value assets, where\nvulnerabilities can lead to catastrophic financial losses. This challenge is\namplified in Large Language Models (LLMs) by two interconnected failures: they\noperate as unauditable \"black boxes\" lacking a transparent reasoning process,\nand consequently, generate code riddled with critical security vulnerabilities.\nTo address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a\nnovel framework for secure and explainable smart contract generation. It begins\nwith Continual Pre-training (CPT) to specialize the model. We then apply Long\nChain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated\nreasoning-and-code samples to train the model to emulate human security\nanalysis. Finally, to directly mitigate vulnerabilities, we employ\nSecurity-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement\nlearning phase that refines the generation policy by optimizing a weighted\nreward signal for compilation success, security compliance, and format\ncorrectness. Evaluated against 17 baselines on a benchmark of 756 real-world\nfunctions, SmartCoder-R1 establishes a new state of the art, achieving top\nperformance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a\nSafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This\nFullRate marks a 45.79% relative improvement over the strongest baseline,\nDeepSeek-R1. Crucially, its generated reasoning also excels in human\nevaluations, achieving high-quality ratings for Functionality (82.7%), Security\n(85.3%), and Clarity (90.7%).", "AI": {"tldr": "This paper introduces SmartCoder-R1, a model designed for secure and explainable smart contract generation using advanced training and fine-tuning methods. It outperformed existing models across multiple metrics, including vulnerability reduction and reasoning clarity.", "motivation": "The motivation stems from the risks associated with vulnerabilities in smart contracts and the inability of LLMs to produce secure code due to their 'black box' nature.", "method": "The paper uses three key methods: Continual Pre-training (CPT) for specialization, Long Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) to simulate expert reasoning, and Security-Aware Group Relative Policy Optimization (S-GRPO) to refine code generation for security and other criteria.", "result": "SmartCoder-R1 surpasses 17 baselines on a benchmark of 756 functions, significantly improving key metrics such as a FullRate of 50.53%, a 45.79% relative improvement over the previous best model, DeepSeek-R1.", "conclusion": "SmartCoder-R1 demonstrates state-of-the-art performance for generating secure and explainable smart contracts, combining enhanced security measures with improved human-evaluated functionality, security, and clarity."}}
{"id": "2509.10222", "pdf": "https://arxiv.org/pdf/2509.10222", "abs": "https://arxiv.org/abs/2509.10222", "authors": ["Ma\u00ebl Jullien", "Lei Xu", "Marco Valentino", "Andr\u00e9 Freitas"], "title": "Compartmentalised Agentic Reasoning for Clinical NLI", "categories": ["cs.AI"], "comment": null, "summary": "A common assumption holds that scaling data and parameters yields\nincreasingly structured, generalisable internal representations. We interrogate\nthis assumption in clinical natural language inference (NLI) by adopting a\nbenchmark decomposed into four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction,\nand introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI\nthat separates knowledge access from principled inference. CARENLI routes each\npremise, statement pair to a family specific solver and enforces auditable\nprocedures via a planner, verifier, and refiner.\n  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching\n98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag\nviolations with near-ceiling reliability, while refiners correct a substantial\nshare of epistemic errors. Remaining failures cluster in routing, identifying\nfamily classification as the main bottleneck. These results show that LLMs\noften retain relevant facts but default to heuristics when inference is\nunderspecified, a dissociation CARENLI makes explicit while offering a\nframework for safer, auditable reasoning.", "AI": {"tldr": "The paper introduces CARENLI, a system that improves clinical natural language inference (NLI) by compartmentalizing reasoning tasks and ensuring auditable procedures, achieving significant fidelity improvements with large language models (LLMs).", "motivation": "The paper aims to address the limitations in structured and generalizable internal representations of large language models when applied to clinical NLI tasks, focusing on improving inference reliability and safety.", "method": "CARENLI systematically routes NLI tasks to specific reasoning solvers, complemented by a planner, verifier, and refiner for procedural auditing and error correction.", "result": "CARENLI enhances inference accuracy by up to 42 points, achieves top performance metrics across specific reasoning families, and identifies the main bottleneck in routing tasks for family classification.", "conclusion": "The paper demonstrates CARENLI's capacity to improve LLM reasoning reliability in clinical contexts and establishes a framework for safer, auditable decision-making in complex language tasks."}}
{"id": "2509.09933", "pdf": "https://arxiv.org/pdf/2509.09933", "abs": "https://arxiv.org/abs/2509.09933", "authors": ["Shintaro Nakamura", "Yuko Kuroki", "Wei Chen"], "title": "Multi-Play Combinatorial Semi-Bandit Problem", "categories": ["cs.LG"], "comment": null, "summary": "In the combinatorial semi-bandit (CSB) problem, a player selects an action\nfrom a combinatorial action set and observes feedback from the base arms\nincluded in the action. While CSB is widely applicable to combinatorial\noptimization problems, its restriction to binary decision spaces excludes\nimportant cases involving non-negative integer flows or allocations, such as\nthe optimal transport and knapsack problems.To overcome this limitation, we\npropose the multi-play combinatorial semi-bandit (MP-CSB), where a player can\nselect a non-negative integer action and observe multiple feedbacks from a\nsingle arm in each round. We propose two algorithms for the MP-CSB. One is a\nThompson-sampling-based algorithm that is computationally feasible even when\nthe action space is exponentially large with respect to the number of arms, and\nattains $O(\\log T)$ distribution-dependent regret in the stochastic regime,\nwhere $T$ is the time horizon. The other is a best-of-both-worlds algorithm,\nwhich achieves $O(\\log T)$ variance-dependent regret in the stochastic regime\nand the worst-case $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ regret in the\nadversarial regime. Moreover, its regret in adversarial one is data-dependent,\nadapting to the cumulative loss of the optimal action, the total quadratic\nvariation, and the path-length of the loss sequence. Finally, we numerically\nshow that the proposed algorithms outperform existing methods in the CSB\nliterature.", "AI": {"tldr": "The paper introduces the Multi-Play Combinatorial Semi-Bandit (MP-CSB) framework, extending CSB problems to non-negative integer flows and allocations, and provides two novel algorithms with strong performance guarantees.", "motivation": "The motivation stems from limitations of the traditional CSB framework, which is restricted to binary decision spaces and thus excludes key combinatorial problems such as optimal transport and knapsack problems.", "method": "Two algorithms are proposed: a Thompson-sampling-based algorithm for large action spaces with logarithmic regret in the stochastic regime, and a best-of-both-worlds algorithm with strong performance in both stochastic and adversarial regimes, having adaptable and data-dependent regret.", "result": "The algorithms achieve improved theoretical guarantees, including logarithmic and variance-dependent regret in stochastic regimes, and data-adaptive bounds in adversarial regimes. Experimental results showcase superior performance compared to existing methods.", "conclusion": "This work addresses a significant limitation of CSB problems by introducing the MP-CSB framework, demonstrating theoretical and numerical advantages, and broadening the applicability to real-world combinatorial optimization scenarios."}}
{"id": "2509.09714", "pdf": "https://arxiv.org/pdf/2509.09714", "abs": "https://arxiv.org/abs/2509.09714", "authors": ["Serge Lionel Nikiema", "Alb\u00e9rick Euraste Djire", "Abdoul Aziz Bonkoungou", "Micheline B\u00e9n\u00e9dicte Moumoula", "Jordan Samhi", "Abdoul Kader Kabore", "Jacques Klein", "Tegawend\u00e9 F. Bissyande"], "title": "How Small Transformation Expose the Weakness of Semantic Similarity Measures", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This research examines how well different methods measure semantic\nsimilarity, which is important for various software engineering applications\nsuch as code search, API recommendations, automated code reviews, and\nrefactoring tools. While large language models are increasingly used for these\nsimilarity assessments, questions remain about whether they truly understand\nsemantic relationships or merely recognize surface patterns.\n  The study tested 18 different similarity measurement approaches, including\nword-based methods, embedding techniques, LLM-based systems, and\nstructure-aware algorithms. The researchers created a systematic testing\nframework that applies controlled changes to text and code to evaluate how well\neach method handles different types of semantic relationships.\n  The results revealed significant issues with commonly used metrics. Some\nembedding-based methods incorrectly identified semantic opposites as similar up\nto 99.9 percent of the time, while certain transformer-based approaches\noccasionally rated opposite meanings as more similar than synonymous ones. The\nstudy found that embedding methods' poor performance often stemmed from how\nthey calculate distances; switching from Euclidean distance to cosine\nsimilarity improved results by 24 to 66 percent. LLM-based approaches performed\nbetter at distinguishing semantic differences, producing low similarity scores\n(0.00 to 0.29) for genuinely different meanings, compared to embedding methods\nthat incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.", "AI": {"tldr": "This study evaluates 18 different methods to measure semantic similarity in software engineering applications and highlights significant flaws in commonly used metrics. Large language models performed better in distinguishing semantic differences compared to embedding-based methods.", "motivation": "The motivation stems from the need to ascertain the effectiveness of semantic similarity measurement techniques, which are vital for software engineering tasks such as code search and automated reviews, especially given the rise in use of large language models.", "method": "The study systematically tested 18 methods, including word-based approaches, embedding techniques, LLM-based systems, and structure-aware algorithms by applying controlled changes to text and code to assess their performance.", "result": "The analysis uncovered critical issues with embedding methods, such as misidentifying semantic opposites as similar, and demonstrated the improved effectiveness of LLMs in distinguishing semantic differences. Switching to cosine similarity significantly improved embedding methods' performance (by 24\u201366%).", "conclusion": "LLMs proved superior in semantic similarity metric performance, particularly in differentiating opposite meanings, highlighting limitations in embedding techniques and the need for more robust measurement metrics."}}
{"id": "2509.09844", "pdf": "https://arxiv.org/pdf/2509.09844", "abs": "https://arxiv.org/abs/2509.09844", "authors": ["Chengyu Yang", "Rishik Reddy Yesgari", "Chengjun Liu"], "title": "Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection", "categories": ["cs.CV"], "comment": null, "summary": "Rosacea is a common but underdiagnosed inflammatory skin condition that\nprimarily affects the central face and presents with subtle redness, pustules,\nand visible blood vessels. Automated detection remains challenging due to the\ndiffuse nature of symptoms, the scarcity of labeled datasets, and privacy\nconcerns associated with using identifiable facial images. A novel\nprivacy-preserving automated rosacea detection method inspired by clinical\npriors and trained entirely on synthetic data is presented in this paper.\nSpecifically, the proposed method, which leverages the observation that rosacea\nmanifests predominantly through central facial erythema, first constructs a\nfixed redness-informed mask by selecting regions with consistently high red\nchannel intensity across facial images. The mask thus is able to focus on\ndiagnostically relevant areas such as the cheeks, nose, and forehead and\nexclude identity-revealing features. Second, the ResNet-18 deep learning\nmethod, which is trained on the masked synthetic images, achieves superior\nperformance over the full-face baselines with notable gains in terms of\naccuracy, recall and F1 score when evaluated using the real-world test data.\nThe experimental results demonstrate that the synthetic data and clinical\npriors can jointly enable accurate and ethical dermatological AI systems,\nespecially for privacy sensitive applications in telemedicine and large-scale\nscreening.", "AI": {"tldr": "This paper presents an automated rosacea detection method using synthetic data and facial erythema-based input masking to provide privacy-preserving and accurate results.", "motivation": "Rosacea is challenging to detect due to its diffuse symptoms, limited labeled datasets, and the privacy concerns tied to real facial images.", "method": "The method involves constructing a redness-informed mask focusing on diagnostic areas of the central face and training a ResNet-18 model on masked synthetic images.", "result": "The proposed method outperforms full-face baselines, showing better accuracy, recall, and F1 score on real-world test datasets.", "conclusion": "Synthetic data and clinical priors can drive accurate and ethical AI systems for privacy-sensitive dermatological applications, such as telemedicine and screening."}}
{"id": "2509.10247", "pdf": "https://arxiv.org/pdf/2509.10247", "abs": "https://arxiv.org/abs/2509.10247", "authors": ["Xinhong Zhang", "Runqing Wang", "Yunfan Ren", "Jian Sun", "Hao Fang", "Jie Chen", "Gang Wang"], "title": "DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning", "categories": ["cs.RO"], "comment": "8 pages, 11 figures, 1 table", "summary": "This letter introduces DiffAero, a lightweight, GPU-accelerated, and fully\ndifferentiable simulation framework designed for efficient quadrotor control\npolicy learning. DiffAero supports both environment-level and agent-level\nparallelism and integrates multiple dynamics models, customizable sensor stacks\n(IMU, depth camera, and LiDAR), and diverse flight tasks within a unified,\nGPU-native training interface. By fully parallelizing both physics and\nrendering on the GPU, DiffAero eliminates CPU-GPU data transfer bottlenecks and\ndelivers orders-of-magnitude improvements in simulation throughput. In contrast\nto existing simulators, DiffAero not only provides high-performance simulation\nbut also serves as a research platform for exploring differentiable and hybrid\nlearning algorithms. Extensive benchmarks and real-world flight experiments\ndemonstrate that DiffAero and hybrid learning algorithms combined can learn\nrobust flight policies in hours on consumer-grade hardware. The code is\navailable at https://github.com/flyingbitac/diffaero.", "AI": {"tldr": "DiffAero is a GPU-accelerated simulation framework enabling efficient quadrotor control learning with high simulation throughput.", "motivation": "To address inefficiencies in CPU-GPU interaction and improve simulation throughput for quadrotor control policy learning.", "method": "DiffAero fully utilizes GPUs for both physics and rendering, integrates parallelism, and supports multiple sensor inputs and tasks for training.", "result": "DiffAero achieves significant simulation throughput improvements and enables robust flight policy learning on consumer-grade hardware.", "conclusion": "DiffAero demonstrates its potential as a high-performance simulator and research platform, advancing hybrid learning and efficient policy training."}}
{"id": "2509.10320", "pdf": "https://arxiv.org/pdf/2509.10320", "abs": "https://arxiv.org/abs/2509.10320", "authors": ["Davide Corradini", "Mariano Ceccato", "Mohammad Ghafari"], "title": "Automated Testing of Broken Authentication Vulnerabilities in Web APIs with AuthREST", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "We present AuthREST, an open-source security testing tool targeting broken\nauthentication, one of the most prevalent API security risks in the wild.\nAuthREST automatically tests web APIs for credential stuffing, password brute\nforcing, and unchecked token authenticity. Empirical results show that AuthREST\nis effective in improving web API security. Notably, it uncovered previously\nunknown authentication vulnerabilitiesin in four public APIs.", "AI": {"tldr": "AuthREST is an open-source security tool identifying authentication flaws in APIs, uncovering vulnerabilities in public APIs.", "motivation": "To address the prevalent API security risks due to broken authentication.", "method": "AuthREST automatically tests APIs for credential stuffing, brute forcing passwords, and verifying token authenticity.", "result": "AuthREST found unknown authentication flaws in four public APIs and demonstrated effectiveness in improving security.", "conclusion": "AuthREST enhances web API security by identifying and mitigating authentication vulnerabilities."}}
{"id": "2509.10249", "pdf": "https://arxiv.org/pdf/2509.10249", "abs": "https://arxiv.org/abs/2509.10249", "authors": ["Hanna Abi Akl"], "title": "Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering", "categories": ["cs.AI"], "comment": "accepted for the International Joint Conference on Rules and\n  Reasoning (RuleML+RR) 2025", "summary": "Recent advances in Language Models (LMs) have failed to mask their\nshortcomings particularly in the domain of reasoning. This limitation impacts\nseveral tasks, most notably those involving ontology engineering. As part of a\nPhD research, we investigate the consequences of incorporating formal methods\non the performance of Small Language Models (SLMs) on reasoning tasks.\nSpecifically, we aim to orient our work toward using SLMs to bootstrap ontology\nconstruction and set up a series of preliminary experiments to determine the\nimpact of expressing logical problems with different grammars on the\nperformance of SLMs on a predefined reasoning task. Our findings show that it\nis possible to substitute Natural Language (NL) with a more compact logical\nlanguage while maintaining a strong performance on reasoning tasks and hope to\nuse these results to further refine the role of SLMs in ontology engineering.", "AI": {"tldr": "The paper investigates improving reasoning task performance in small language models (SLMs) by incorporating formal methods and logical languages instead of natural language.", "motivation": "The motivation is to address reasoning limitations of language models, which negatively impact tasks like ontology engineering.", "method": "The authors conducted experiments to evaluate how different grammars (logical vs. natural language) used in expressing reasoning problems influence SLM performance.", "result": "The study found that using a compact logical language as a substitute for natural language maintained strong SLM performance on reasoning tasks.", "conclusion": "The results highlight the potential for refining SLMs' application in ontology engineering through the adoption of formal methods and logical languages."}}
{"id": "2509.09936", "pdf": "https://arxiv.org/pdf/2509.09936", "abs": "https://arxiv.org/abs/2509.09936", "authors": ["Saarth Gaonkar", "Xiang Zheng", "Haocheng Xi", "Rishabh Tiwari", "Kurt Keutzer", "Dmitriy Morozov", "Michael W. Mahoney", "Amir Gholami"], "title": "SciML Agents: Write the Solver, Not the Solution", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Recent work in scientific machine learning aims to tackle scientific tasks\ndirectly by predicting target values with neural networks (e.g.,\nphysics-informed neural networks, neural ODEs, neural operators, etc.), but\nattaining high accuracy and robustness has been challenging. We explore an\nalternative view: use LLMs to write code that leverages decades of numerical\nalgorithms. This shifts the burden from learning a solution function to making\ndomain-aware numerical choices. We ask whether LLMs can act as SciML agents\nthat, given a natural-language ODE description, generate runnable code that is\nscientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),\nand enforcing stability checks. There is currently no benchmark to measure this\nkind of capability for scientific computing tasks. As such, we first introduce\ntwo new datasets: a diagnostic dataset of adversarial \"misleading\" problems;\nand a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set\ncontains problems whose superficial appearance suggests stiffness, and that\nrequire algebraic simplification to demonstrate non-stiffness; and the\nlarge-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-\nand closed-source LLM models along two axes: (i) unguided versus guided\nprompting with domain-specific knowledge; and (ii) off-the-shelf versus\nfine-tuned variants. Our evaluation measures both executability and numerical\nvalidity against reference solutions. We find that with sufficient context and\nguided prompts, newer instruction-following models achieve high accuracy on\nboth criteria. In many cases, recent open-source systems perform strongly\nwithout fine-tuning, while older or smaller models still benefit from\nfine-tuning. Overall, our preliminary results indicate that careful prompting\nand fine-tuning can yield a specialized LLM agent capable of reliably solving\nsimple ODE problems.", "AI": {"tldr": "The paper investigates the use of LLMs as agents for generating scientifically appropriate code to solve ODE problems, without directly tuning solution functions, by leveraging numerical algorithms.", "motivation": "There is a need for robust and accurate methods to solve scientific computing tasks using machine learning, particularly with Ordinary Differential Equations (ODEs). Existing approaches face challenges in accuracy, prompting exploration of alternative methods utilizing LLMs.", "method": "The authors introduced two datasets\u2014a diagnostic adversarial set and a benchmark of 1,000 diverse ODE tasks\u2014and evaluated LLMs on their ability to generate runnable, numerically valid code. Models were tested using unguided vs. guided prompting, and off-the-shelf vs. fine-tuned versions, comparing executability and accuracy against reference solutions.", "result": "Instruction-following LLMs achieve high accuracy when given adequate prompts and context. Open-source systems often perform well without fine-tuning, whereas older or smaller models benefit significantly from fine-tuning.", "conclusion": "Preliminary results indicate that LLMs, with proper guidance and fine-tuning, can reliably generate runnable and scientifically valid solutions for simple ODE problems, highlighting their potential in scientific machine learning tasks."}}
{"id": "2509.09715", "pdf": "https://arxiv.org/pdf/2509.09715", "abs": "https://arxiv.org/abs/2509.09715", "authors": ["Naveen Lamba", "Sanju Tiwari", "Manas Gaur"], "title": "Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucination in Large Language Models (LLMs) is a well studied problem.\nHowever, the properties that make LLM intrinsically vulnerable to\nhallucinations have not been identified and studied. This research identifies\nand characterizes the key properties, allowing us to pinpoint vulnerabilities\nwithin the model's internal mechanisms. To solidify on these properties, we\nutilized two established datasets, HaluEval and TruthfulQA and convert their\nexisting format of question answering into various other formats to narrow down\nthese properties as the reason for the hallucinations. Our findings reveal that\nhallucination percentages across symbolic properties are notably high for\nGemma-2-2B, averaging 79.0% across tasks and datasets. With increased model\nscale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,\nreflecting a 15 percentage point reduction overall. Although the hallucination\nrate decreases as the model size increases, a substantial amount of\nhallucination caused by symbolic properties still persists. This is especially\nevident for modifiers (ranging from 84.76% to 94.98%) and named entities\n(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.\nThese findings indicate that symbolic elements continue to confuse the models,\npointing to a fundamental weakness in how these LLMs process such\ninputs--regardless of their scale.", "AI": {"tldr": "This study analyzes intrinsic properties causing hallucinations in large language models (LLMs), using datasets to pinpoint these issues and find they persist even as model scales increase.", "motivation": "The motivation is to understand the intrinsic vulnerabilities in LLMs that lead to hallucinations, identifying key model properties responsible for this issue.", "method": "The study evaluates hallucination rates using the HaluEval and TruthfulQA datasets, analyzing various question formats to determine the symbolic properties contributing to hallucination.", "result": "The research shows high hallucination rates in Gemma models, with percentages reducing with model scale but still significantly influenced by symbolic properties like modifiers and named entities.", "conclusion": "Symbolic elements remain a challenge for LLMs, indicating a fundamental processing weakness that persists even as models scale up."}}
{"id": "2509.09849", "pdf": "https://arxiv.org/pdf/2509.09849", "abs": "https://arxiv.org/abs/2509.09849", "authors": ["Chengyu Yang", "Chengjun Liu"], "title": "Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking", "categories": ["cs.CV"], "comment": null, "summary": "To rigorously assess the effectiveness and necessity of individual components\nwithin the recently proposed ULW framework for laparoscopic image desmoking,\nthis paper presents a comprehensive ablation study. The ULW approach combines a\nU-Net based backbone with a compound loss function that comprises mean squared\nerror (MSE), structural similarity index (SSIM) loss, and perceptual loss. The\nframework also incorporates a differentiable, learnable Wiener filter module.\nIn this study, each component is systematically ablated to evaluate its\nspecific contribution to the overall performance of the whole framework. The\nanalysis includes: (1) removal of the learnable Wiener filter, (2) selective\nuse of individual loss terms from the composite loss function. All variants are\nbenchmarked on a publicly available paired laparoscopic images dataset using\nquantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative\nvisual comparisons.", "AI": {"tldr": "The paper performs an ablation study on the ULW framework for laparoscopic image desmoking, evaluating the contributions of its components.", "motivation": "To assess the effectiveness and necessity of individual components of the ULW framework for laparoscopic image desmoking.", "method": "Ablation study by systematically removing or modifying components (e.g., learnable Wiener filter, specific loss terms) and benchmarking on performance metrics and visual comparisons.", "result": "The contributions of each component were evaluated by benchmarking the framework variants on a paired laparoscopic image dataset using metrics such as SSIM, PSNR, MSE, and CIEDE-2000, along with visual comparisons.", "conclusion": "The study identifies how each component of the ULW framework impacts its overall performance, providing insights into the necessity of these elements."}}
{"id": "2509.10305", "pdf": "https://arxiv.org/pdf/2509.10305", "abs": "https://arxiv.org/abs/2509.10305", "authors": ["Yutong Shen", "Ruizhe Xia", "Bokai Yan", "Shunqi zhang", "Pengrui Xiang", "Sicheng He", "Yixin Xu"], "title": "GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning", "categories": ["cs.RO"], "comment": "6 pages, 5 figures", "summary": "In dynamic and uncertain environments, robotic path planning demands accurate\nspatiotemporal environment understanding combined with robust decision-making\nunder partial observability. However, current deep reinforcement learning-based\npath planning methods face two fundamental limitations: (1) insufficient\nmodeling of multi-scale temporal dependencies, resulting in suboptimal\nadaptability in dynamic scenarios, and (2) inefficient exploration-exploitation\nbalance, leading to degraded path quality. To address these challenges, we\npropose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path\nPlanning. The framework comprises two key modules: (i) the Spatiotemporal\nPerception module, which hierarchically extracts multi-granularity spatial\nfeatures and multi-scale temporal dependencies ranging from instantaneous to\nextended time horizons, thereby improving perception accuracy in dynamic\nenvironments; and (ii) the Adaptive Policy Optimization module, which balances\nexploration and exploitation during training while optimizing for smoothness\nand collision probability through constrained policy updates. Experiments in\ndynamic environments demonstrate that GundamQ achieves a 15.3\\% improvement in\nsuccess rate and a 21.7\\% increase in overall path quality, significantly\noutperforming existing state-of-the-art methods.", "AI": {"tldr": "Robotic path planning in dynamic environments challenges current deep reinforcement learning (DRL) methods due to poor temporal dependency modeling and inefficient exploration-exploitation balance. GundamQ improves spatiotemporal features extraction and training policy optimization, achieving superior path planning results.", "motivation": "Current robotic path planning struggles with adaptability in dynamic environments due to inadequate modeling of temporal dependencies and inefficient exploration-exploitation mechanisms.", "method": "The study introduces GundamQ, incorporating a Spatiotemporal Perception module for extracting hierarchical spatial and temporal features, and an Adaptive Policy Optimization module to refine exploration and exploitation balance through constrained policy updates.", "result": "GundamQ achieves a 15.3% increase in success rate and a 21.7% enhancement in overall path quality compared to state-of-the-art methods in experiments.", "conclusion": "GundamQ resolves major issues in DRL-based robotic path planning, offering a robust solution for dynamic and uncertain environments with improved success rate and path quality."}}
{"id": "2509.10413", "pdf": "https://arxiv.org/pdf/2509.10413", "abs": "https://arxiv.org/abs/2509.10413", "authors": ["Guojun Tang", "Carylyne Chan", "Ning Nan", "Spencer Yang", "Jiayu Zhou", "Henry Leung", "Mohammad Mamun", "Steve Drew"], "title": "Bitcoin Cross-Chain Bridge: A Taxonomy and Its Promise in Artificial Intelligence of Things", "categories": ["cs.CR", "cs.SE"], "comment": "Blockchain Cross-Chain Bridge Survey", "summary": "Bitcoin's limited scripting capabilities and lack of native interoperability\nmechanisms have constrained its integration into the broader blockchain\necosystem, especially decentralized finance (DeFi) and multi-chain\napplications. This paper presents a comprehensive taxonomy of Bitcoin\ncross-chain bridge protocols, systematically analyzing their trust assumptions,\nperformance characteristics, and applicability to the Artificial Intelligence\nof Things (AIoT) scenarios. We categorize bridge designs into three main types:\nnaive token swapping, pegged-asset bridges, and arbitrary-message bridges. Each\ncategory is evaluated across key metrics such as trust model, latency, capital\nefficiency, and DeFi composability. Emerging innovations like BitVM and\nrecursive sidechains are highlighted for their potential to enable secure,\nscalable, and programmable Bitcoin interoperability. Furthermore, we explore\npractical use cases of cross-chain bridges in AIoT applications, including\ndecentralized energy trading, healthcare data integration, and supply chain\nautomation. This taxonomy provides a foundational framework for researchers and\npractitioners seeking to design secure and efficient cross-chain\ninfrastructures in AIoT systems.", "AI": {"tldr": "This paper categorizes Bitcoin cross-chain bridge protocols to improve interoperability and enable broader blockchain use cases, including AIoT applications.", "motivation": "The motivation is to address Bitcoin's limitations in scripting and interoperability to integrate it effectively into decentralized finance and multi-chain ecosystems.", "method": "The study proposes a taxonomy categorizing Bitcoin bridge designs into three types and evaluates their performance against metrics such as trust, latency, capital efficiency, and composability.", "result": "The paper highlights emerging innovations like BitVM and recursive sidechains that offer scalable and programmable Bitcoin interoperability.", "conclusion": "This taxonomy serves as a framework for developing secure and efficient cross-chain infrastructures, especially for AIoT scenarios."}}
{"id": "2509.10297", "pdf": "https://arxiv.org/pdf/2509.10297", "abs": "https://arxiv.org/abs/2509.10297", "authors": ["Eoin O'Doherty", "Nicole Weinrauch", "Andrew Talone", "Uri Klempner", "Xiaoyuan Yi", "Xing Xie", "Yi Zeng"], "title": "The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis", "categories": ["cs.AI"], "comment": "Work in progress", "summary": "Artificial intelligence (AI) is advancing at a pace that raises urgent\nquestions about how to align machine decision-making with human moral values.\nThis working paper investigates how leading AI systems prioritize moral\noutcomes and what this reveals about the prospects for human-AI symbiosis. We\naddress two central questions: (1) What moral values do state-of-the-art large\nlanguage models (LLMs) implicitly favour when confronted with dilemmas? (2) How\ndo differences in model architecture, cultural origin, and explainability\naffect these moral preferences? To explore these questions, we conduct a\nquantitative experiment with six LLMs, ranking and scoring outcomes across 18\ndilemmas representing five moral frameworks. Our findings uncover strikingly\nconsistent value biases. Across all models, Care and Virtue values outcomes\nwere rated most moral, while libertarian choices were consistently penalized.\nReasoning-enabled models exhibited greater sensitivity to context and provided\nricher explanations, whereas non-reasoning models produced more uniform but\nopaque judgments. This research makes three contributions: (i) Empirically, it\ndelivers a large-scale comparison of moral reasoning across culturally distinct\nLLMs; (ii) Theoretically, it links probabilistic model behaviour with\nunderlying value encodings; (iii) Practically, it highlights the need for\nexplainability and cultural awareness as critical design principles to guide AI\ntoward a transparent, aligned, and symbiotic future.", "AI": {"tldr": "This paper investigates the moral preferences and biases in leading large language models (LLMs) when facing dilemmas, highlighting consistent value biases and emphasizing the importance of explainability and cultural awareness.", "motivation": "The paper aims to address how AI decision-making aligns with human moral values and explores the underlying biases in state-of-the-art LLMs.", "method": "A quantitative experiment with six culturally distinct LLMs was conducted, scoring their responses across 18 moral dilemmas and analyzing differences in outcomes influenced by model architecture and cultural origin.", "result": "The findings reveal consistent value biases, with Care and Virtue being rated most moral while libertarian choices are penalized. Reasoning-enabled models were more context-sensitive and provided richer explanations.", "conclusion": "The study underscores the importance of explainability and cultural awareness in LLMs\u2019 design for a more aligned and transparent symbiosis between humans and AI systems."}}
{"id": "2509.09940", "pdf": "https://arxiv.org/pdf/2509.09940", "abs": "https://arxiv.org/abs/2509.09940", "authors": ["Yifei Wang", "Wenbin Wang", "Yong Luo"], "title": "DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition", "categories": ["cs.LG"], "comment": "8 pages, 2 figures", "summary": "Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich\ninformation from multiple sources (e.g., language, video, and audio), the\npotential for intent-irrelevant and conflicting information across modalities\nmay hinder performance from being further improved. Most current models attempt\nto fuse modalities by applying mechanisms like multi-head attention to unimodal\nfeature sequences and then adding the result back to the original\nrepresentation. This process risks corrupting the primary linguistic features\nwith noisy or irrelevant non-verbal signals, as it often fails to capture the\nfine-grained, token-level influence where non-verbal cues should modulate, not\njust augment, textual meaning. To address this, we introduce DyKen-Hyena, which\nreframes the problem from feature fusion to processing modulation. Our model\ntranslates audio-visual cues into dynamic, per-token convolutional kernels that\ndirectly modulate textual feature extraction. This fine-grained approach\nachieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.\nNotably, it yields a +10.46% F1-score improvement in out-of-scope detection,\nvalidating that our method creates a fundamentally more robust intent\nrepresentation.", "AI": {"tldr": "The paper introduces DyKen-Hyena, a model for Multimodal Intent Recognition (MIR), achieving state-of-the-art results by using token-level modulation rather than traditional feature fusion methods.", "motivation": "Existing methods for multimodal intent recognition risk corrupting primary linguistic features due to noisy or conflicting information from audio-visual modalities.", "method": "The proposed DyKen-Hyena model dynamically modulates textual features by translating audio-visual cues into token-specific convolutional kernels.", "result": "DyKen-Hyena demonstrated a +10.46% F1-score improvement in out-of-scope detection and achieved state-of-the-art performance on the MIntRec and MIntRec2.0 benchmarks.", "conclusion": "The approach improves intent recognition by refining how non-verbal signals interact with textual meaning, leading to a more robust representation and enhanced performance."}}
{"id": "2509.09723", "pdf": "https://arxiv.org/pdf/2509.09723", "abs": "https://arxiv.org/abs/2509.09723", "authors": ["Kai R. Larsen", "Sen Yan", "Roland M\u00fcller", "Lan Sang", "Mikko R\u00f6nkk\u00f6", "Ravi Starzl", "Donald Edmondson"], "title": "ALIGNS: Unlocking nomological networks in psychological measurement through a large language model", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ME", "I.2.6; J.4; I.5.1; H.3.3; H.2.8"], "comment": null, "summary": "Psychological measurement is critical to many disciplines. Despite advances\nin measurement, building nomological networks, theoretical maps of how concepts\nand measures relate to establish validity, remains a challenge 70 years after\nCronbach and Meehl proposed them as fundamental to validation. This limitation\nhas practical consequences: clinical trials may fail to detect treatment\neffects, and public policy may target the wrong outcomes. We introduce Analysis\nof Latent Indicators to Generate Nomological Structures (ALIGNS), a large\nlanguage model-based system trained with validated questionnaire measures.\nALIGNS provides three comprehensive nomological networks containing over\n550,000 indicators across psychology, medicine, social policy, and other\nfields. This represents the first application of large language models to solve\na foundational problem in measurement validation. We report classification\naccuracy tests used to develop the model, as well as three evaluations. In the\nfirst evaluation, the widely used NIH PROMIS anxiety and depression instruments\nare shown to converge into a single dimension of emotional distress. The second\nevaluation examines child temperament measures and identifies four potential\ndimensions not captured by current frameworks, and questions one existing\ndimension. The third evaluation, an applicability check, engages expert\npsychometricians who assess the system's importance, accessibility, and\nsuitability. ALIGNS is freely available at nomologicalnetwork.org,\ncomplementing traditional validation methods with large-scale nomological\nanalysis.", "AI": {"tldr": "The paper introduces ALIGNS, a system leveraging large language models to build nomological networks for psychological measurement validation, addressing a 70-year-old problem.", "motivation": "Nomological networks, essential for ensuring the validity of psychological measurements, remain a challenge decades after their proposal, which affects clinical trials and public policy effectiveness.", "method": "The ALIGNS system was developed using large language models and validated questionnaire measures, generating extensive nomological networks covering over 550,000 indicators.", "result": "The system demonstrated its utility through three evaluations, including identifying dimensions of emotional distress, uncovering new child temperament dimensions, and receiving positive expert feedback on its applicability.", "conclusion": "ALIGNS represents a significant advancement in measurement validation, providing a freely available, large-scale solution that complements traditional methods."}}
{"id": "2509.09859", "pdf": "https://arxiv.org/pdf/2509.09859", "abs": "https://arxiv.org/abs/2509.09859", "authors": ["Razvan Stefanescu", "Ethan Oh", "Ruben Vazquez", "Chris Mesterharm", "Constantin Serban", "Ritu Chadha"], "title": "WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector", "categories": ["cs.CV", "cs.LG", "68W99"], "comment": "11 pages, 11 figures", "summary": "We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and\nacoustic signals for robust real-life UAV object detection. Our approach fuses\nvisual and acoustic features in a unified object detector model relying on the\nDeformable DETR and Wav2Vec2 architectures, achieving strong performance under\nchallenging environmental conditions. Our work leverage the existing\nDrone-vs-Bird dataset and the newly generated ARDrone dataset containing more\nthan 7,500 synchronized images and audio segments. We show how the acoustic\ninformation is used to improve the performance of the Deformable DETR object\ndetector on the real ARDrone dataset. We developed, trained and tested four\ndifferent fusion configurations based on a gated mechanism, linear layer, MLP\nand cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi\nresolution feature mappings of the Deformable DETR and enhance the object\ndetection performance over all drones dimensions. The best performer is the\ngated fusion approach, which improves the mAP of the Deformable DETR object\ndetector on our in-distribution and out-of-distribution ARDrone datasets by\n11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.\nThe mAP scores for medium and large drones are also enhanced, with overall\ngains across all drone sizes ranging from 3.27% to 5.84%.", "AI": {"tldr": "The paper introduces a multi-modal drone detection system called WAVE-DETR that combines visual (RGB) and acoustic data using Deformable DETR and Wav2Vec2 models. It improves drone detection performance, especially for small drones, under challenging conditions.", "motivation": "To enhance real-life UAV detection by leveraging both visual and acoustic data for improved robustness under challenging environmental conditions.", "method": "Developing a unified object detection model based on Deformable DETR and Wav2Vec2 architectures, coupled with four fusion mechanisms (gated mechanism, linear layer, MLP, and cross attention) for feature fusion of RGB and acoustic data.", "result": "The proposed gated fusion configuration achieves significant improvements in mean Average Precision (mAP) for drone detection, ranging from 11.1% to 15.3% for small drones and 3.27% to 5.84% for medium and large drones.", "conclusion": "The fusion of visual and acoustic features positively impacts drone detection performance, with a gated fusion approach demonstrating the best results. This multi-modal system is effective across drone sizes and environmental conditions."}}
{"id": "2509.10317", "pdf": "https://arxiv.org/pdf/2509.10317", "abs": "https://arxiv.org/abs/2509.10317", "authors": ["Elizaveta D. Moskovskaya", "Anton D. Moscowsky"], "title": "Robot guide with multi-agent control and automatic scenario generation with LLM", "categories": ["cs.RO", "cs.LG", "93C85", "I.2.9; I.2.7; I.2.11"], "comment": "14 pages, 5 figures, 2 tables, 1 demo-video and repository link", "summary": "The work describes the development of a hybrid control architecture for an\nanthropomorphic tour guide robot, combining a multi-agent resource management\nsystem with automatic behavior scenario generation based on large language\nmodels. The proposed approach aims to overcome the limitations of traditional\nsystems, which rely on manual tuning of behavior scenarios. These limitations\ninclude manual configuration, low flexibility, and lack of naturalness in robot\nbehavior. The process of preparing tour scenarios is implemented through a\ntwo-stage generation: first, a stylized narrative is created, then non-verbal\naction tags are integrated into the text. The multi-agent system ensures\ncoordination and conflict resolution during the execution of parallel actions,\nas well as maintaining default behavior after the completion of main\noperations, contributing to more natural robot behavior. The results obtained\nfrom the trial demonstrate the potential of the proposed approach for\nautomating and scaling social robot control systems.", "AI": {"tldr": "This paper presents a hybrid control system for a tour guide robot using a combination of a multi-agent system and behavior scenario generation via large language models.", "motivation": "To address limitations like manual configuration, low flexibility, and unnatural behaviors in traditional robot systems.", "method": "A two-stage process for tour scenario generation (stylized narrative creation and adding non-verbal action tags) paired with a multi-agent system for coordination.", "result": "Trials demonstrate that this approach enables more natural robot behavior and supports better scalability of control systems.", "conclusion": "The hybrid system enhances flexibility, naturalness, and automation in social robot behavior control, showing promise for broader applications."}}
{"id": "2509.10326", "pdf": "https://arxiv.org/pdf/2509.10326", "abs": "https://arxiv.org/abs/2509.10326", "authors": ["Dmitry Lesnik", "Tobias Sch\u00e4fer"], "title": "State Algebra for Propositional Logic", "categories": ["cs.AI", "cs.LO", "03G27 (Primary) 68W30, 68T27 (Secondary)"], "comment": "47 pages", "summary": "This paper presents State Algebra, a novel framework designed to represent\nand manipulate propositional logic using algebraic methods. The framework is\nstructured as a hierarchy of three representations: Set, Coordinate, and Row\nDecomposition. These representations anchor the system in well-known semantics\nwhile facilitating the computation using a powerful algebraic engine. A key\naspect of State Algebra is its flexibility in representation. We show that\nalthough the default reduction of a state vector is not canonical, a unique\ncanonical form can be obtained by applying a fixed variable order during the\nreduction process. This highlights a trade-off: by foregoing guaranteed\ncanonicity, the framework gains increased flexibility, potentially leading to\nmore compact representations of certain classes of problems. We explore how\nthis framework provides tools to articulate both search-based and knowledge\ncompilation algorithms and discuss its natural extension to probabilistic logic\nand Weighted Model Counting.", "AI": {"tldr": "State Algebra is a novel framework for propositional logic manipulation using algebraic methods with flexible representation.", "motivation": "To create a flexible and algebraically robust framework to manipulate and represent propositional logic.", "method": "The system uses three hierarchical representations and emphasizes the trade-off between canonical forms and flexibility. It also explores extensions to probabilistic logic and related computations.", "result": "Developed a framework that provides tools for search-based algorithms, knowledge compilation, and probabilistic logic applications with non-canonical but flexible reductions.", "conclusion": "State Algebra demonstrates versatility by trading canonicity for flexibility, aiding problem representation and extending capabilities in computational logic."}}
{"id": "2509.09955", "pdf": "https://arxiv.org/pdf/2509.09955", "abs": "https://arxiv.org/abs/2509.09955", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis", "Sami Muhaidat"], "title": "Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "comment": "Submitted to IEEE Journals", "summary": "Large-scale transformers are central to modern semantic communication, yet\ntheir high computational and communication costs hinder deployment on\nresource-constrained edge devices. This paper introduces a training-free\nframework for adaptive token merging, a novel mechanism that compresses\ntransformer representations at runtime by selectively merging semantically\nredundant tokens under per-layer similarity thresholds. Unlike prior\nfixed-ratio reduction, our approach couples merging directly to input\nredundancy, enabling data-dependent adaptation that balances efficiency and\ntask relevance without retraining. We cast the discovery of merging strategies\nas a multi-objective optimization problem and leverage Bayesian optimization to\nobtain Pareto-optimal trade-offs between accuracy, inference cost, and\ncommunication cost. On ImageNet classification, we match the accuracy of the\nunmodified transformer with 30\\% fewer floating-point operations per second and\nunder 20\\% of the original communication cost, while for visual question\nanswering our method achieves performance competitive with the full LLaVA model\nat less than one-third of the compute and one-tenth of the bandwidth. Finally,\nwe show that our adaptive merging is robust across varying channel conditions\nand provides inherent privacy benefits, substantially degrading the efficacy of\nmodel inversion attacks. Our framework provides a practical and versatile\nsolution for deploying powerful transformer models in resource-limited edge\nintelligence scenarios.", "AI": {"tldr": "The paper presents a novel training-free framework for adaptive token merging in transformers, reducing computational and communication costs while maintaining high accuracy.", "motivation": "Transformers face challenges in high computational and communication costs, limiting their deployment on resource-constrained edge devices.", "method": "A training-free adaptive token merging approach is proposed, using per-layer similarity thresholds to compress transformer representations dynamically. Bayesian optimization is employed for multi-objective trade-offs.", "result": "On ImageNet classification, the method achieved 30% fewer FLOPS and 80% communication cost reduction. In visual question answering tasks, efficiency improved with reduced compute and bandwidth usage.", "conclusion": "Adaptive merging offers practical and robust solutions for edge scenarios, maintaining accuracy while enhancing efficiency, privacy, and adaptability to channel conditions."}}
{"id": "2509.09724", "pdf": "https://arxiv.org/pdf/2509.09724", "abs": "https://arxiv.org/abs/2509.09724", "authors": ["Wonyoung Kim", "Sujeong Seo", "Juhyun Lee"], "title": "DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T09"], "comment": "5 figures", "summary": "Technology opportunities are critical information that serve as a foundation\nfor advancements in technology, industry, and innovation. This paper proposes a\nframework based on the temporal relationships between technologies to identify\nemerging technology opportunities. The proposed framework begins by extracting\ntext from a patent dataset, followed by mapping text-based topics to discover\ninter-technology relationships. Technology opportunities are then identified by\ntracking changes in these topics over time. To enhance efficiency, the\nframework leverages a large language model to extract topics and employs a\nprompt for a chat-based language model to support the discovery of technology\nopportunities. The framework was evaluated using an artificial intelligence\npatent dataset provided by the United States Patent and Trademark Office. The\nexperimental results suggest that artificial intelligence technology is\nevolving into forms that facilitate everyday accessibility. This approach\ndemonstrates the potential of the proposed framework to identify future\ntechnology opportunities.", "AI": {"tldr": "The paper introduces a framework using temporal relationships in patents and language models to identify emerging technology opportunities, emphasizing the evolution of AI technology.", "motivation": "Emerging technology opportunities are vital for driving advancements in technology and innovation, and identifying them requires efficient methodologies.", "method": "The framework processes patent datasets, maps topic relationships, tracks their changes over time, employs large language models, and utilizes AI tools for enhanced topic extraction and analysis.", "result": "The evaluation using U.S. Patent Office's AI patent dataset showed AI technology advancing towards everyday accessibility.", "conclusion": "The approach confirms the framework's potential for identifying future technology directions effectively using patent data and advanced language models."}}
{"id": "2509.09869", "pdf": "https://arxiv.org/pdf/2509.09869", "abs": "https://arxiv.org/abs/2509.09869", "authors": ["Yihao Liu", "Junyu Chen", "Lianrui Zuo", "Shuwen Wei", "Brian D. Boyd", "Carmen Andreescu", "Olusola Ajilore", "Warren D. Taylor", "Aaron Carass", "Bennett A. Landman"], "title": "Surrogate Supervision for Robust and Generalizable Deformable Image Registration", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Objective: Deep learning-based deformable image registration has achieved\nstrong accuracy, but remains sensitive to variations in input image\ncharacteristics such as artifacts, field-of-view mismatch, or modality\ndifference. We aim to develop a general training paradigm that improves the\nrobustness and generalizability of registration networks. Methods: We introduce\nsurrogate supervision, which decouples the input domain from the supervision\ndomain by applying estimated spatial transformations to surrogate images. This\nallows training on heterogeneous inputs while ensuring supervision is computed\nin domains where similarity is well defined. We evaluate the framework through\nthree representative applications: artifact-robust brain MR registration,\nmask-agnostic lung CT registration, and multi-modal MR registration. Results:\nAcross tasks, surrogate supervision demonstrated strong resilience to input\nvariations including inhomogeneity field, inconsistent field-of-view, and\nmodality differences, while maintaining high performance on well-curated data.\nConclusions: Surrogate supervision provides a principled framework for training\nrobust and generalizable deep learning-based registration models without\nincreasing complexity. Significance: Surrogate supervision offers a practical\npathway to more robust and generalizable medical image registration, enabling\nbroader applicability in diverse biomedical imaging scenarios.", "AI": {"tldr": "This paper introduces the concept of surrogate supervision to improve image registration networks' robustness and generalizability across diverse input scenarios.", "motivation": "Deep learning-based image registration networks are highly accurate but sensitive to variations in input characteristics, leading to a need for improved robustness and generalization.", "method": "The authors propose surrogate supervision, decoupling input domains from supervision domains by applying spatial transformations to surrogate images, which enables training on heterogeneous inputs.", "result": "Surrogate supervision displayed strong resilience to input variations like field mismatches, artifacts, and modality differences while maintaining performance on well-curated data.", "conclusion": "Surrogate supervision offers a principled approach for building robust, generalizable training paradigms, simplifying complexity in medical image registration networks."}}
{"id": "2509.10349", "pdf": "https://arxiv.org/pdf/2509.10349", "abs": "https://arxiv.org/abs/2509.10349", "authors": ["Weiyan Lu", "Huizhe Li", "Yuhao Fang", "Zhexuan Zhou", "Junda Wu", "Yude Li", "Youmin Gong", "Jie Mei"], "title": "Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended Transport System", "categories": ["cs.RO"], "comment": null, "summary": "Unmanned aerial vehicles (UAVs) with suspended payloads offer significant\nadvantages for aerial transportation in complex and cluttered environments.\nHowever, existing systems face critical limitations, including unreliable\nperception of the cable-payload dynamics, inefficient planning in large-scale\nenvironments, and the inability to guarantee whole-body safety under cable\nbending and external disturbances. This paper presents Acetrans, an Autonomous,\nCorridor-based, and Efficient UAV suspended transport system that addresses\nthese challenges through a unified perception, planning, and control framework.\nA LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and\ncable shape under taut and bent modes, enabling robust whole-body state\nestimation and real-time filtering of cable point clouds. To enhance planning\nscalability, we introduce the Multi-size-Aware Configuration-space Iterative\nRegional Inflation (MACIRI) algorithm, which generates safe flight corridors\nwhile accounting for varying UAV and payload geometries. A spatio-temporal,\ncorridor-constrained trajectory optimization scheme is then developed to ensure\ndynamically feasible and collision-free trajectories. Finally, a nonlinear\nmodel predictive controller (NMPC) augmented with cable-bending constraints\nprovides robust whole-body safety during execution. Simulation and experimental\nresults validate the effectiveness of Acetrans, demonstrating substantial\nimprovements in perception accuracy, planning efficiency, and control safety\ncompared to state-of-the-art methods.", "AI": {"tldr": "This paper introduces Acetrans, an advanced UAV transport system for safely and efficiently managing payloads in complex environments, overcoming perception, planning, and safety limitations.", "motivation": "The motivation behind this paper is to enhance the capabilities of UAVs carrying suspended payloads by addressing challenges such as unreliable cable-payload dynamics perception, inefficient planning, and safety concerns in dynamic environments.", "method": "The proposed system, Acetrans, integrates a LiDAR-IMU module for payload pose and cable shape estimation, the MACIRI algorithm for scalable flight planning, trajectory optimization schemes for collision avoidance, and NMPC with cable-bending constraints for robust safety during operational execution.", "result": "Simulation and experimental validation show that Acetrans significantly improves perception accuracy, planning efficiency, and operational safety compared to current approaches.", "conclusion": "Acetrans effectively bridges critical gaps in UAV suspended transport systems, providing a unified framework that enhances robustness, scalability, and safety in complex environments."}}
{"id": "2509.10401", "pdf": "https://arxiv.org/pdf/2509.10401", "abs": "https://arxiv.org/abs/2509.10401", "authors": ["Alva West", "Yixuan Weng", "Minjun Zhu", "Zhen Lin", "Yue Zhang"], "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.", "AI": {"tldr": "Failure attribution methods in multi-agent systems struggle with low accuracy due to lack of counterfactual reasoning. The paper introduces Abduct-Act-Predict (A2P) Scaffolding, achieving improved step-level accuracy.", "motivation": "Current failure attribution approaches are limited by their inability to perform robust counterfactual reasoning, resulting in low accuracy and impractical debugging processes for complex systems.", "method": "The Abduct-Act-Predict (A2P) Scaffolding method guides large language models through a structured three-step causal inference: Abduction (inferring root causes), Action (defining corrective interventions), and Prediction (simulating outcomes).", "result": "A2P Scaffolding significantly improves step-level accuracy in failure attribution tasks, achieving 47.46% accuracy on algorithm-generated datasets (2.85\u00d7 improvement) and 29.31% accuracy on more complex hand-crafted datasets (2.43\u00d7 improvement).", "conclusion": "By introducing causal reasoning, A2P Scaffolding offers a more robust and accurate framework for automated failure attribution in multi-agent systems, overcoming limitations of pattern-based methods."}}
{"id": "2509.09960", "pdf": "https://arxiv.org/pdf/2509.09960", "abs": "https://arxiv.org/abs/2509.09960", "authors": ["Mingxuan Jiang", "Yongxin Wang", "Ziyue Dai", "Yicun Liu", "Hongyi Nie", "Sen Liu", "Hongfeng Chai"], "title": "Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Synthetic tabular data generation is increasingly essential in data\nmanagement, supporting downstream applications when real-world and high-quality\ntabular data is insufficient. Existing tabular generation approaches, such as\ngenerative adversarial networks (GANs), diffusion models, and fine-tuned Large\nLanguage Models (LLMs), typically require sufficient reference data, limiting\ntheir effectiveness in domain-specific databases with scarce records. While\nprompt-based LLMs offer flexibility without parameter tuning, they often fail\nto capture dataset-specific feature-label dependencies and generate redundant\ndata, leading to degradation in downstream task performance. To overcome these\nissues, we propose ReFine, a framework that (i) derives symbolic \"if-then\"\nrules from interpretable models and embeds them into prompts to explicitly\nguide generation toward domain-specific feature distribution, and (ii) applies\na dual-granularity filtering strategy that suppresses over-sampling patterns\nand selectively refines rare but informative samples to reduce distributional\nimbalance. Extensive experiments on various regression and classification\nbenchmarks demonstrate that ReFine consistently outperforms state-of-the-art\nmethods, achieving up to 0.44 absolute improvement in R-squared for regression\nand 10.0 percent relative improvement in F1 score for classification tasks.", "AI": {"tldr": "ReFine is a framework for generating synthetic tabular data by using symbolic \"if-then\" rules in prompts and filtering strategies to address data scarcity and improve downstream task performance.", "motivation": "Current tabular data generation methods struggle with domains that have scarce data, failing to adequately capture data-specific dependencies and leading to poor downstream task performance.", "method": "ReFine extracts symbolic \"if-then\" rules and embeds them into prompts to guide generation. It also uses a dual-granularity filtering strategy to refine rare samples and handle distribution imbalances.", "result": "ReFine outperformed existing methods, achieving up to 0.44 improvement in R-squared for regression tasks and 10% improvement in F1 scores for classification.", "conclusion": "The ReFine framework demonstrates its capability to generate high-quality synthetic tabular data in data-sparse environments, enhancing the performance of downstream tasks."}}
{"id": "2509.09725", "pdf": "https://arxiv.org/pdf/2509.09725", "abs": "https://arxiv.org/abs/2509.09725", "authors": ["Chunyu Li", "Xindi Zheng", "Siqi Liu"], "title": "BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025", "categories": ["cs.CL"], "comment": null, "summary": "Entity linking (EL) for biomedical text is typically benchmarked on\nEnglish-only corpora with flat mentions, leaving the more realistic scenario of\nnested and multilingual mentions largely unexplored. We present our system for\nthe BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task\n(English & Russian), closing this gap with a lightweight pipeline that keeps\nthe original EL model intact and modifies only three task-aligned components:\nTwo-stage retrieval-ranking. We leverage the same base encoder model in both\nstages: the retrieval stage uses the original pre-trained model, while the\nranking stage applies domain-specific fine-tuning. Boundary cues. In the\nranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing\nthe encoder with an explicit, language-agnostic span before robustness to\noverlap and nesting. Dataset augmentation. We also automatically expand the\nranking training corpus with three complementary data sources, enhancing\ncoverage without extra manual annotation. On the BioNNE 2025 leaderboard, our\ntwo stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual\ntrack, demonstrating the effectiveness and competitiveness of these minimal yet\nprincipled modifications. Code are publicly available at\nhttps://github.com/Kaggle-Competitions-Code/BioNNE-L.", "AI": {"tldr": "The paper introduces a lightweight pipeline for multilingual and nested entity linking in biomedical text, designed for the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task, achieving third place on a leaderboard.", "motivation": "To address the underexplored challenges of nested and multilingual mentions in biomedical text, which have not been adequately benchmarked in previous EL systems.", "method": "The system uses a lightweight pipeline with minimal changes: (1) a two-stage retrieval-ranking process with domain-specific fine-tuning for ranking, (2) explicit span boundary cues using wrapped tags in the ranking stage, and (3) data augmentation by expanding the training corpus with three additional sources.", "result": "The proposed system, BIBERT-Pipe, ranked third on the BioNNE 2025 leaderboard for the multilingual track, showcasing its competitive performance.", "conclusion": "The modifications made in the proposed system demonstrate the effectiveness of minimal adjustments for improving multilingual and nested biomedical EL performance, while remaining computationally efficient."}}
{"id": "2509.09911", "pdf": "https://arxiv.org/pdf/2509.09911", "abs": "https://arxiv.org/abs/2509.09911", "authors": ["Barkin Buyukcakir", "Jannick De Tobel", "Patrick Thevissen", "Dirk Vandermeulen", "Peter Claes"], "title": "An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars", "categories": ["cs.CV", "cs.AI", "68T07 (Primary)"], "comment": "21 pages, 11 figures, Scientific Reports", "summary": "The practical adoption of deep learning in high-stakes forensic applications,\nsuch as dental age estimation, is often limited by the 'black box' nature of\nthe models. This study introduces a framework designed to enhance both\nperformance and transparency in this context. We use a notable performance\ndisparity in the automated staging of mandibular second (tooth 37) and third\n(tooth 38) molars as a case study. The proposed framework, which combines a\nconvolutional autoencoder (AE) with a Vision Transformer (ViT), improves\nclassification accuracy for both teeth over a baseline ViT, increasing from\n0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond\nimproving performance, the framework provides multi-faceted diagnostic\ninsights. Analysis of the AE's latent space metrics and image reconstructions\nindicates that the remaining performance gap is data-centric, suggesting high\nintra-class morphological variability in the tooth 38 dataset is a primary\nlimiting factor. This work highlights the insufficiency of relying on a single\nmode of interpretability, such as attention maps, which can appear anatomically\nplausible yet fail to identify underlying data issues. By offering a\nmethodology that both enhances accuracy and provides evidence for why a model\nmay be uncertain, this framework serves as a more robust tool to support expert\ndecision-making in forensic age estimation.", "AI": {"tldr": "This study introduces a framework combining convolutional autoencoder and Vision Transformer to enhance performance and transparency in dental age estimation models, addressing the \"black box\" nature of deep learning.", "motivation": "High-stakes forensic applications, like dental age estimation, require more interpretable and accurate deep learning models due to their critical impact.", "method": "The authors propose a framework that integrates convolutional autoencoder (AE) and Vision Transformer (ViT) to improve classification accuracy and diagnostic transparency. They analyzed latent space metrics and reconstructions to understand data-related limitations.", "result": "Classification accuracy improved from 0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38, showing enhanced performance over the baseline ViT. The analysis revealed that data issues, such as high intra-class morphological variability, limit further improvement.", "conclusion": "The paper showcases a methodology that not only boosts model accuracy but also provides actionable insights into uncertainty and data-centric limitations, making it highly suitable for forensic expert decision-making."}}
{"id": "2509.10405", "pdf": "https://arxiv.org/pdf/2509.10405", "abs": "https://arxiv.org/abs/2509.10405", "authors": ["Nicholas Carlotti", "Mirko Nava", "Alessandro Giusti"], "title": "Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States", "categories": ["cs.RO"], "comment": "accepted at CoRL 2025", "summary": "We introduce a model for monocular RGB relative pose estimation of a ground\nrobot that trains from scratch without pose labels nor prior knowledge about\nthe robot's shape or appearance. At training time, we assume: (i) a robot\nfitted with multiple LEDs, whose states are independent and known at each\nframe; (ii) knowledge of the approximate viewing direction of each LED; and\n(iii) availability of a calibration image with a known target distance, to\naddress the ambiguity of monocular depth estimation. Training data is collected\nby a pair of robots moving randomly without needing external infrastructure or\nhuman supervision. Our model trains on the task of predicting from an image the\nstate of each LED on the robot. In doing so, it learns to predict the position\nof the robot in the image, its distance, and its relative bearing. At inference\ntime, the state of the LEDs is unknown, can be arbitrary, and does not affect\nthe pose estimation performance. Quantitative experiments indicate that our\napproach: is competitive with SoA approaches that require supervision from pose\nlabels or a CAD model of the robot; generalizes to different domains; and\nhandles multi-robot pose estimation.", "AI": {"tldr": "The paper proposes a method for estimating a ground robot\u2019s relative pose using monocular RGB images without pose labels or prior knowledge of robot design, relying on LED states and a known calibration image.", "motivation": "Existing methods for robot pose estimation often require external supervision, precise pose labels, or CAD models, which are restrictive and limit practical application.", "method": "The model trains to predict the state of LEDs on the robot image, learning positional, distance, and bearing data without external infrastructure. Training data comes from two randomly moving robots. A calibration image with known distance resolves depth ambiguity.", "result": "The approach performs competitively with state-of-the-art supervised methods, generalizes across domains, and supports pose estimation for multiple robots.", "conclusion": "This unsupervised LED-based model enables flexible and accurate robot pose estimation without reliance on labeled datasets or CAD models, offering practical advantages in diverse scenarios."}}
{"id": "2509.10423", "pdf": "https://arxiv.org/pdf/2509.10423", "abs": "https://arxiv.org/abs/2509.10423", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "10 pages, 4 figures, 1 table", "summary": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "AI": {"tldr": "The paper introduces an information-theoretic framework for diagnosing anomalies in reinforcement learning (RL) agents during deployment, using mutual information patterns as key metrics.", "motivation": "Real-world RL agents face issues such as sensor faults, actuator wear, and environmental changes, yet lack inherent mechanisms to detect and diagnose these failures.", "method": "The authors analyze mutual information patterns in state-action dynamics, observing changes during learning stages and testing controlled perturbations to identify faults in state or action spaces.", "result": "They find that state-action mutual information grows during successful learning, and specific diagnostic information metrics can precisely localize system faults without degrading performance or modifying architectures.", "conclusion": "The study highlights mutual information patterns as signatures of learning and tools for diagnosing system health, paving the way for adaptive RL systems capable of autonomous fault detection and policy adjustments."}}
{"id": "2509.09991", "pdf": "https://arxiv.org/pdf/2509.09991", "abs": "https://arxiv.org/abs/2509.09991", "authors": ["Amandip Sangha"], "title": "Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a machine learning-based approach to estimate the energy\nconsumption of virtual servers without access to physical power measurement\ninterfaces. Using resource utilization metrics collected from guest virtual\nmachines, we train a Gradient Boosting Regressor to predict energy consumption\nmeasured via RAPL on the host. We demonstrate, for the first time, guest-only\nresource-based energy estimation without privileged host access with\nexperiments across diverse workloads, achieving high predictive accuracy and\nvariance explained ($0.90 \\leq R^2 \\leq 0.97$), indicating the feasibility of\nguest-side energy estimation. This approach can enable energy-aware scheduling,\ncost optimization and physical host independent energy estimates in virtualized\nenvironments. Our approach addresses a critical gap in virtualized environments\n(e.g. cloud) where direct energy measurement is infeasible.", "AI": {"tldr": "The paper proposes a machine learning solution utilizing Gradient Boosting Regressor to estimate energy consumption of virtual servers based only on guest resource utilization metrics, achieving high predictive accuracy and variance explained ($0.90 \u2264 R\u00b2 \u2264 0.97$).", "motivation": "Address the problem of energy estimation in virtualized environments where direct host energy measurement is inaccessible.", "method": "The method involves using guest virtual machines' resource utilization metrics to train a Gradient Boosting Regressor for predicting host-side energy consumption measured via RAPL.", "result": "Experiments across varying workloads validated the method's predictive accuracy and high variance explained ($0.90 \u2264 R\u00b2 \u2264 0.97$).", "conclusion": "Guest-side energy estimation is feasible and supports energy-aware scheduling, cost optimization, and independence from physical host access in virtualized environments."}}
{"id": "2509.09726", "pdf": "https://arxiv.org/pdf/2509.09726", "abs": "https://arxiv.org/abs/2509.09726", "authors": ["Seiji Hattori", "Takuya Matsuzaki", "Makoto Fujiwara"], "title": "Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure", "categories": ["cs.CL"], "comment": "Submitted to INLG 2025 (accepted)", "summary": "This paper proposes a natural language translation method for\nmachine-verifiable formal proofs that leverages the informalization\n(verbalization of formal language proof steps) and summarization capabilities\nof LLMs. For evaluation, it was applied to formal proof data created in\naccordance with natural language proofs taken from an undergraduate-level\ntextbook, and the quality of the generated natural language proofs was analyzed\nin comparison with the original natural language proofs. Furthermore, we will\ndemonstrate that this method can output highly readable and accurate natural\nlanguage proofs by applying it to existing formal proof library of the Lean\nproof assistant.", "AI": {"tldr": "The paper presents a method using LLMs to translate machine-verifiable formal proofs into readable natural language proofs using informalization and summarization techniques.", "motivation": "To improve the readability and accessibility of formal proofs by translating them into natural language, making them more understandable for non-experts.", "method": "The method involves utilizing LLMs for informalization (verbalizing proof steps) and summarizing, and is tested on formal proof data aligned with natural language proofs from textbooks, as well as existing libraries from the Lean proof assistant.", "result": "The translated natural language proofs were of high quality, readable, and accurate when compared to their original counterparts.", "conclusion": "The approach demonstrates that LLMs can effectively generate coherent and precise natural language proofs from formal machine-verifiable proofs."}}
{"id": "2509.09935", "pdf": "https://arxiv.org/pdf/2509.09935", "abs": "https://arxiv.org/abs/2509.09935", "authors": ["Chirayu Agrawal", "Snehasis Mukherjee"], "title": "SCoDA: Self-supervised Continual Domain Adaptation", "categories": ["cs.CV"], "comment": "Submitted to ICVGIP 2025", "summary": "Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a\nmodel to a target domain without access to the data of the source domain.\nPrevailing methods typically start with a source model pre-trained with full\nsupervision and distill the knowledge by aligning instance-level features.\nHowever, these approaches, relying on cosine similarity over L2-normalized\nfeature vectors, inadvertently discard crucial geometric information about the\nlatent manifold of the source model. We introduce Self-supervised Continual\nDomain Adaptation (SCoDA) to address these limitations. We make two key\ndepartures from standard practice: first, we avoid the reliance on supervised\npre-training by initializing the proposed framework with a teacher model\npre-trained entirely via self-supervision (SSL). Second, we adapt the principle\nof geometric manifold alignment to the SFDA setting. The student is trained\nwith a composite objective combining instance-level feature matching with a\nSpace Similarity Loss. To combat catastrophic forgetting, the teacher's\nparameters are updated via an Exponential Moving Average (EMA) of the student's\nparameters. Extensive experiments on benchmark datasets demonstrate that SCoDA\nsignificantly outperforms state-of-the-art SFDA methods.", "AI": {"tldr": "The paper introduces SCoDA, a Source-Free Domain Adaptation method using self-supervised teacher models and focuses on geometric manifold alignment, achieving superior results.", "motivation": "To overcome limitations of traditional SFDA methods such as reliance on supervised pre-training and loss of geometric manifold information from existing L2-normalized features.", "method": "The proposed framework utilizes a teacher model trained via self-supervised learning and incorporates a Space Similarity Loss for geometric manifold alignment. Knowledge transfer occurs with parameters updated using EMA.", "result": "Empirical evaluations on benchmark datasets show SCoDA consistently outperforms state-of-the-art SFDA methods.", "conclusion": "SCoDA is shown to be a promising solution for domain adaptation tasks, addressing key challenges in SFDA and achieving better adaptation performance without supervised pre-training."}}
{"id": "2509.10416", "pdf": "https://arxiv.org/pdf/2509.10416", "abs": "https://arxiv.org/abs/2509.10416", "authors": ["Ze Fu", "Pinhao Song", "Yutong Hu", "Renaud Detry"], "title": "TASC: Task-Aware Shared Control for Teleoperated Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "We present TASC, a Task-Aware Shared Control framework for teleoperated\nmanipulation that infers task-level user intent and provides assistance\nthroughout the task. To support everyday tasks without predefined knowledge,\nTASC constructs an open-vocabulary interaction graph from visual input to\nrepresent functional object relationships, and infers user intent accordingly.\nA shared control policy then provides rotation assistance during both grasping\nand object interaction, guided by spatial constraints predicted by a\nvision-language model. Our method addresses two key challenges in\ngeneral-purpose, long-horizon shared control: (1) understanding and inferring\ntask-level user intent, and (2) generalizing assistance across diverse objects\nand tasks. Experiments in both simulation and the real world demonstrate that\nTASC improves task efficiency and reduces user input effort compared to prior\nmethods. To the best of our knowledge, this is the first shared control\nframework that supports everyday manipulation tasks with zero-shot\ngeneralization. The code that supports our experiments is publicly available at\nhttps://github.com/fitz0401/tasc.", "AI": {"tldr": "The paper introduces TASC, a shared control framework for teleoperated manipulation using visual input and a vision-language model to provide assistance with zero-shot generalization.", "motivation": "To enable general-purpose teleoperated manipulation systems to infer user intent and provide assistance across diverse, everyday tasks without predefined knowledge.", "method": "The framework uses visual input to construct an open-vocabulary interaction graph, predicts spatial constraints with a vision-language model, and provides rotational assistance during manipulation.", "result": "Experiments in simulation and real-world scenarios show improvements in task efficiency and reduced user input effort compared to prior methods.", "conclusion": "TASC is the first framework for shared control in teleoperated manipulation, achieving zero-shot generalization, and offering significant user assistance benefits."}}
{"id": "2509.08919", "pdf": "https://arxiv.org/pdf/2509.08919", "abs": "https://arxiv.org/abs/2509.08919", "authors": ["Mahe Chen", "Xiaoxuan Wang", "Kaiwen Chen", "Nick Koudas"], "title": "Generative Engine Optimization: How to Dominate AI Search", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "cs.SI"], "comment": null, "summary": "The rapid adoption of generative AI-powered search engines like ChatGPT,\nPerplexity, and Gemini is fundamentally reshaping information retrieval, moving\nfrom traditional ranked lists to synthesized, citation-backed answers. This\nshift challenges established Search Engine Optimization (SEO) practices and\nnecessitates a new paradigm, which we term Generative Engine Optimization\n(GEO).\n  This paper presents a comprehensive comparative analysis of AI Search and\ntraditional web search (Google). Through a series of large-scale, controlled\nexperiments across multiple verticals, languages, and query paraphrases, we\nquantify critical differences in how these systems source information. Our key\nfindings reveal that AI Search exhibit a systematic and overwhelming bias\ntowards Earned media (third-party, authoritative sources) over Brand-owned and\nSocial content, a stark contrast to Google's more balanced mix. We further\ndemonstrate that AI Search services differ significantly from each other in\ntheir domain diversity, freshness, cross-language stability, and sensitivity to\nphrasing.\n  Based on these empirical results, we formulate a strategic GEO agenda. We\nprovide actionable guidance for practitioners, emphasizing the critical need\nto: (1) engineer content for machine scannability and justification, (2)\ndominate earned media to build AI-perceived authority, (3) adopt\nengine-specific and language-aware strategies, and (4) overcome the inherent\n\"big brand bias\" for niche players. Our work provides the foundational\nempirical analysis and a strategic framework for achieving visibility in the\nnew generative search landscape.", "AI": {"tldr": "The paper analyzes the impact of generative AI-powered search engines on information retrieval, emphasizing the need for a new optimization paradigm called Generative Engine Optimization (GEO).", "motivation": "The paper is motivated by the rapid transformation from traditional search engines to generative AI-based ones, which significantly change information retrieval mechanisms and challenge existing SEO practices.", "method": "The authors conducted large-scale, controlled experiments across various contexts, such as verticals, languages, and query paraphrases, to compare AI-powered search and traditional web search.", "result": "The research found that AI search engines favor Earned media extensively over Brand-owned and Social content, unlike Google. Additionally, these engines vary in domain diversity, content freshness, cross-language stability, and sensitivity to query phrasing.", "conclusion": "The paper concludes with a GEO agenda that includes actionable strategies for improving visibility in generative AI-based searches by optimizing content for machine understanding, bolstering authority via Earned media, and adopting specific strategies for different engines and languages."}}
{"id": "2509.10000", "pdf": "https://arxiv.org/pdf/2509.10000", "abs": "https://arxiv.org/abs/2509.10000", "authors": ["Tilen Cadez", "Kyoung-Min Kim"], "title": "Neural Scaling Laws for Deep Regression", "categories": ["cs.LG", "cond-mat.other"], "comment": "Supplementary Information will be provided with the published\n  manuscript", "summary": "Neural scaling laws--power-law relationships between generalization errors\nand characteristics of deep learning models--are vital tools for developing\nreliable models while managing limited resources. Although the success of large\nlanguage models highlights the importance of these laws, their application to\ndeep regression models remains largely unexplored. Here, we empirically\ninvestigate neural scaling laws in deep regression using a parameter estimation\nmodel for twisted van der Waals magnets. We observe power-law relationships\nbetween the loss and both training dataset size and model capacity across a\nwide range of values, employing various architectures--including fully\nconnected networks, residual networks, and vision transformers. Furthermore,\nthe scaling exponents governing these relationships range from 1 to 2, with\nspecific values depending on the regressed parameters and model details. The\nconsistent scaling behaviors and their large scaling exponents suggest that the\nperformance of deep regression models can improve substantially with increasing\ndata size.", "AI": {"tldr": "The paper explores power-law neural scaling laws in deep regression, confirming consistent scaling behavior across architectures and model parameters.", "motivation": "To investigate unresolved neural scaling laws in deep regression models and understand their potential for improving performance.", "method": "Authors applied various deep learning architectures such as fully connected networks, residual networks, and vision transformers to parameter estimation in twisted van der Waals magnets.", "result": "Scaling relationships were observed with losses and dataset size/model capacity; scaling exponents ranged from 1 to 2, depending on the model details and regressed parameters.", "conclusion": "Deep regression performance can significantly benefit from increased dataset size due to consistent and identifiable scaling laws."}}
{"id": "2509.09727", "pdf": "https://arxiv.org/pdf/2509.09727", "abs": "https://arxiv.org/abs/2509.09727", "authors": ["Andy Zhu", "Yingjun Du"], "title": "A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs", "categories": ["cs.CL", "cs.CE"], "comment": "8 pages, 6 figures, Underreview", "summary": "Question answering (QA) plays a central role in financial education, yet\nexisting large language model (LLM) approaches often fail to capture the\nnuanced and specialized reasoning required for financial problem-solving. The\nfinancial domain demands multistep quantitative reasoning, familiarity with\ndomain-specific terminology, and comprehension of real-world scenarios. We\npresent a multi-agent framework that leverages role-based prompting to enhance\nperformance on domain-specific QA. Our framework comprises a Base Generator, an\nEvidence Retriever, and an Expert Reviewer agent that work in a single-pass\niteration to produce a refined answer. We evaluated our framework on a set of\n3,532 expert-designed finance education questions from Study.com, an online\nlearning platform. We leverage retrieval-augmented generation (RAG) for\ncontextual evidence from 6 finance textbooks and prompting strategies for a\ndomain-expert reviewer. Our experiments indicate that critique-based refinement\nimproves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,\nwith the highest performance from Gemini-2.0-Flash. Furthermore, our method\nenables GPT-4o-mini to achieve performance comparable to the finance-tuned\nFinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to\nenhancing financial QA and offer insights for further research in multi-agent\nfinancial LLM systems.", "AI": {"tldr": "The study introduces a multi-agent framework for improving question answering (QA) in finance using role-based prompting and retrieval-augmented generation.", "motivation": "Existing large language models struggle with nuanced financial reasoning, which requires multistep reasoning and domain-specific knowledge.", "method": "The framework combines three agents (Base Generator, Evidence Retriever, Expert Reviewer) with role-based prompting and retrieval-augmented generation from finance textbooks.", "result": "The approach enhances accuracy by 6.6-8.3% compared to baselines and achieves competitive performance even with smaller models.", "conclusion": "This framework offers a cost-effective method to boost financial QA performance and opens avenues for further multi-agent system research."}}
{"id": "2509.09943", "pdf": "https://arxiv.org/pdf/2509.09943", "abs": "https://arxiv.org/abs/2509.09943", "authors": ["Zhu Chen", "Mert Edg\u00fc", "Er Jin", "Johannes Stegmaier"], "title": "Segment Anything for Cell Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Tracking cells and detecting mitotic events in time-lapse microscopy image\nsequences is a crucial task in biomedical research. However, it remains highly\nchallenging due to dividing objects, low signal-tonoise ratios, indistinct\nboundaries, dense clusters, and the visually similar appearance of individual\ncells. Existing deep learning-based methods rely on manually labeled datasets\nfor training, which is both costly and time-consuming. Moreover, their\ngeneralizability to unseen datasets remains limited due to the vast diversity\nof microscopy data. To overcome these limitations, we propose a zero-shot cell\ntracking framework by integrating Segment Anything 2 (SAM2), a large foundation\nmodel designed for general image and video segmentation, into the tracking\npipeline. As a fully-unsupervised approach, our method does not depend on or\ninherit biases from any specific training dataset, allowing it to generalize\nacross diverse microscopy datasets without finetuning. Our approach achieves\ncompetitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos\nwhile eliminating the need for dataset-specific adaptation.", "AI": {"tldr": "The paper presents a zero-shot framework for cell tracking in microscopy videos using the SAM2 model, eliminating the need for labeled datasets and achieving strong performance across various datasets.", "motivation": "Cell tracking and mitotic event detection in microscopy videos are essential for biomedical research but are challenging due to issues like indistinct boundaries and dataset variability.", "method": "The framework integrates SAM2, a general image and video segmentation model, into a fully unsupervised tracking pipeline, avoiding reliance on manually labeled data and improving generalizability.", "result": "The approach demonstrated competitive accuracy in 2D and 3D time-lapse microscopy videos while requiring no fine-tuning or dataset-specific adaptations.", "conclusion": "The unsupervised framework effectively addresses challenges in cell tracking, providing a scalable and generalizable solution for diverse microscopy datasets."}}
{"id": "2509.10426", "pdf": "https://arxiv.org/pdf/2509.10426", "abs": "https://arxiv.org/abs/2509.10426", "authors": ["Jianxin Shi", "Zengqi Peng", "Xiaolong Chen", "Tianyu Wo", "Jun Ma"], "title": "DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Trajectory prediction is a critical component of autonomous driving,\nessential for ensuring both safety and efficiency on the road. However,\ntraditional approaches often struggle with the scarcity of labeled data and\nexhibit suboptimal performance in multi-agent prediction scenarios. To address\nthese challenges, we introduce a disentangled context-aware pre-training\nframework for multi-agent motion prediction, named DECAMP. Unlike existing\nmethods that entangle representation learning with pretext tasks, our framework\ndecouples behavior pattern learning from latent feature reconstruction,\nprioritizing interpretable dynamics and thereby enhancing scene representation\nfor downstream prediction. Additionally, our framework incorporates\ncontext-aware representation learning alongside collaborative spatial-motion\npretext tasks, which enables joint optimization of structural and intentional\nreasoning while capturing the underlying dynamic intentions. Our experiments on\nthe Argoverse 2 benchmark showcase the superior performance of our method, and\nthe results attained underscore its effectiveness in multi-agent motion\nforecasting. To the best of our knowledge, this is the first context\nautoencoder framework for multi-agent motion forecasting in autonomous driving.\nThe code and models will be made publicly available.", "AI": {"tldr": "The paper introduces DECAMP, a disentangled context-aware pre-training framework for multi-agent motion prediction in autonomous driving, addressing issues of data scarcity and suboptimal performance in traditional methods.", "motivation": "Existing methods for trajectory prediction face challenges due to limited labeled data and inefficiency in handling multi-agent scenarios. The goal is to improve safety and efficiency in autonomous driving.", "method": "DECAMP decouples behavior pattern learning from latent feature reconstruction and incorporates context-aware representation learning with collaborative spatial-motion pretext tasks. This allows for better scene representation and joint optimization of reasoning capabilities.", "result": "Experiments on the Argoverse 2 benchmark demonstrate the superior performance of DECAMP compared to existing methods in multi-agent motion forecasting.", "conclusion": "DECAMP enhances interpretability and effectiveness in autonomous driving multi-agent motion forecasting, establishing itself as the first context autoencoder framework of its kind. The code and models will be publicly released."}}
{"id": "2509.09177", "pdf": "https://arxiv.org/pdf/2509.09177", "abs": "https://arxiv.org/abs/2509.09177", "authors": ["Hanyi Mao", "Quanjia Xiao", "Lei Pang", "Haixiao Liu"], "title": "Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We propose FSPO (Fair Sequence Policy Optimization), a sequence-level\nreinforcement learning method for LLMs that enforces length-fair clipping\ndirectly in the importance-sampling (IS) weight space. We revisit\nsequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping\nis transplanted to sequences: a fixed clip range systematically reweights short\nvs. long responses, distorting the effective objective. Theoretically, we\nformalize length fairness via a Length Reweighting Error (LRE) and prove that\nsmall LRE yields a directional cosine guarantee between the clipped and true\nupdates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the\nsequence log-IS ratio with a band that applies a KL-corrected drift term and\nscales as $\\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,\nstabilizes training, and outperforms all baselines across multiple evaluation\ndatasets.", "AI": {"tldr": "FSPO (Fair Sequence Policy Optimization) is introduced as a reinforcement learning method for large language models (LLMs) that addresses issues with sequence-level clipping in the context of policy optimization.", "motivation": "To resolve alignment issues in sequence-level policy optimization caused by the unequal treatment of responses (short vs. long) in traditional clipping methods.", "method": "FSPO proposes a Gaussian-motivated clipping adjustment using a KL-corrected drift term and a scaling mechanism proportional to sequence length ($\\sqrt{L}$).", "result": "The method stabilizes training, balances clip rates across sequence lengths, and achieves superior performance compared to baseline methods on various datasets.", "conclusion": "FSPO effectively tackles the length-fairness issue in sequence-level RL methods, improving both training stability and model performance."}}
{"id": "2509.10011", "pdf": "https://arxiv.org/pdf/2509.10011", "abs": "https://arxiv.org/abs/2509.10011", "authors": ["Antoine Orioua", "Philipp Krah", "Julian Koellermeier"], "title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "Preprint with 12 pages and 12 figures", "summary": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),\nwhich identifies the underlying intrinsic dimension of a wide range of datasets\nwhose samples lie on either linear or nonlinear manifolds. Beyond estimating\nthe intrinsic dimension, IDEA is also able to reconstruct the original dataset\nafter projecting it onto the corresponding latent space, which is structured\nusing re-weighted double CancelOut layers. Our key contribution is the\nintroduction of the projected reconstruction loss term, guiding the training of\nthe model by continuously assessing the reconstruction quality under the\nremoval of an additional latent dimension. We first assess the performance of\nIDEA on a series of theoretical benchmarks to validate its robustness. These\nexperiments allow us to test its reconstruction ability and compare its\nperformance with state-of-the-art intrinsic dimension estimators. The\nbenchmarks show good accuracy and high versatility of our approach.\nSubsequently, we apply our model to data generated from the numerical solution\nof a vertically resolved one-dimensional free-surface flow, following a\npointwise discretization of the vertical velocity profile in the horizontal\ndirection, vertical direction, and time. IDEA succeeds in estimating the\ndataset's intrinsic dimension and then reconstructs the original solution by\nworking directly within the projection space identified by the network.", "AI": {"tldr": "The paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA), which estimates intrinsic dimensions and reconstructs datasets.", "motivation": "To address the need for robust methods of estimating intrinsic dimensions and reconstructing datasets that lie on linear or nonlinear manifolds.", "method": "Usage of IDEA, which utilizes a latent space structured by re-weighted double CancelOut layers and a projected reconstruction loss for training.", "result": "IDEA demonstrates accurate intrinsic dimension estimation and robust reconstruction on theoretical benchmarks and applied data.", "conclusion": "IDEA is an effective tool for intrinsic dimension estimation and reconstruction, validated by theoretical and applied scenarios."}}
{"id": "2509.09728", "pdf": "https://arxiv.org/pdf/2509.09728", "abs": "https://arxiv.org/abs/2509.09728", "authors": ["Elena Rohde", "Jonas Klingwort", "Christian Borgs"], "title": "A meta-analysis on the performance of machine-learning based language models for sentiment analysis", "categories": ["cs.CL", "cs.LG", "stat.AP"], "comment": null, "summary": "This paper presents a meta-analysis evaluating ML performance in sentiment\nanalysis for Twitter data. The study aims to estimate the average performance,\nassess heterogeneity between and within studies, and analyze how study\ncharacteristics influence model performance. Using PRISMA guidelines, we\nsearched academic databases and selected 195 trials from 20 studies with 12\nstudy features. Overall accuracy, the most reported performance metric, was\nanalyzed using double arcsine transformation and a three-level random effects\nmodel. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,\n0.84]. This paper provides two key insights: 1) Overall accuracy is widely used\nbut often misleading due to its sensitivity to class imbalance and the number\nof sentiment classes, highlighting the need for normalization. 2) Standardized\nreporting of model performance, including reporting confusion matrices for\nindependent test sets, is essential for reliable comparisons of ML classifiers\nacross studies, which seems far from common practice.", "AI": {"tldr": "The paper is a meta-analysis of ML performance in Twitter sentiment analysis, focusing on average accuracy, heterogeneity, and influences of study characteristics.", "motivation": "This paper aims to consolidate understanding of ML's accuracy in sentiment analysis and address inconsistencies in performance reporting.", "method": "Using PRISMA guidelines, 195 trials across 20 studies were analyzed with a three-level random effects model and double arcsine transformation.", "result": "The average model accuracy was calculated as 0.80, revealing misleading accuracy reports and suggesting normalization and improved performance reporting practices.", "conclusion": "Standardized reporting, including confusion matrices, is crucial for reliable ML comparison, and overall accuracy alone is insufficient due to sensitivity to class imbalances and sentiment class counts."}}
{"id": "2509.09946", "pdf": "https://arxiv.org/pdf/2509.09946", "abs": "https://arxiv.org/abs/2509.09946", "authors": ["Vu-Minh Le", "Thao-Anh Tran", "Duc Huy Do", "Xuan Canh Do", "Huong Ninh", "Hai Tran"], "title": "Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation", "categories": ["cs.CV"], "comment": "Accepted at ICCVW 2025", "summary": "Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision\ntask for automating large-scale surveillance. With camera calibration and depth\ninformation, the targets in the scene can be projected into 3D space, offering\nunparalleled levels of automatic perception of a 3D environment. However,\ntracking in the 3D space requires replacing all 2D tracking components from the\nground up, which may be infeasible for existing MTMC systems. In this paper, we\npresent an approach for extending any online 2D multi-camera tracking system\ninto 3D space by utilizing depth information to reconstruct a target in\npoint-cloud space, and recovering its 3D box through clustering and yaw\nrefinement following tracking. We also introduced an enhanced online data\nassociation mechanism that leverages the target's local ID consistency to\nassign global IDs across frames. The proposed framework is evaluated on the\n2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the\nleaderboard.", "AI": {"tldr": "The paper proposes a method to extend 2D multi-camera tracking systems into 3D space using depth information, clustering, and yaw refinement. It achieves notable accuracy on a benchmark dataset.", "motivation": "Existing 2D MTMC systems cannot fully leverage the benefits of 3D tracking due to the need to replace components from scratch. This paper aims to bridge this gap by extending 2D systems to the 3D domain efficiently.", "method": "The approach uses depth information to convert targets into point-clouds and derives their 3D bounding boxes through clustering and yaw refinement after tracking. It also introduces an improved online data association method for consistent global ID assignment.", "result": "The framework was validated on the 2025 AI City Challenge 3D MTMC dataset, where it achieved 3rd place on the leaderboard.", "conclusion": "This research demonstrates how existing 2D multi-camera tracking systems can be effectively extended to 3D tracking, enhancing surveillance capabilities without the need for ground-up redesigns."}}
{"id": "2509.10444", "pdf": "https://arxiv.org/pdf/2509.10444", "abs": "https://arxiv.org/abs/2509.10444", "authors": ["Chaerim Moon", "Joohyung Kim"], "title": "Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction", "categories": ["cs.RO"], "comment": "Presented in IROS 2023 Workshop (Multilimb Coordination in Human\n  Neuroscience and Robotics: Classical and Learning Perspectives)", "summary": "Supernumerary Robotic Limbs (SRLs) can enhance human capability within close\nproximity. However, as a wearable device, the generated moment from its\noperation acts on the human body as an external torque. When the moments\nincrease, more muscle units are activated for balancing, and it can result in\nreduced muscular null space. Therefore, this paper suggests a concept of a\nmotion planning layer that reduces the generated moment for enhanced\nHuman-Robot Interaction. It modifies given trajectories with desirable angular\nacceleration and position deviation limits. Its performance to reduce the\nmoment is demonstrated through the simulation, which uses simplified human and\nrobotic system models.", "AI": {"tldr": "This paper proposes a motion planning layer for wearable Supernumerary Robotic Limbs (SRLs) to minimize external torque acting on the human body, enhancing Human-Robot Interaction.", "motivation": "The study addresses the challenge of external torque generated by SRLs, which increases muscle activation and can limit muscular null space, aiming to improve interaction and usability.", "method": "The proposed motion planning layer modifies SRLs trajectories by introducing angular acceleration and position deviation limits to reduce generated moments.", "result": "Simulation tests using simplified models of humans and robotic systems demonstrate the ability of the motion planning layer to reduce external torque.", "conclusion": "Implementing the motion planning layer improves the Human-Robot Interaction by optimizing SRLs trajectories, potentially leading to safer and more effective usage in wearable robotics."}}
{"id": "2509.09470", "pdf": "https://arxiv.org/pdf/2509.09470", "abs": "https://arxiv.org/abs/2509.09470", "authors": ["Om Vishesh", "Harshad Khadilkar", "Deepak Akkil"], "title": "AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, 2 figures", "summary": "Keeping pace with the rapid growth of academia literature presents a\nsignificant challenge for researchers, funding bodies, and academic societies.\nTo address the time-consuming manual effort required for scholarly discovery,\nwe present a novel, fully automated system that transitions from data discovery\nto direct action. Our pipeline demonstrates how a specialized AI agent,\n'Agent-E', can be tasked with identifying papers from specific geographic\nregions within conference proceedings and then executing a Robotic Process\nAutomation (RPA) to complete a predefined action, such as submitting a\nnomination form. We validated our system on 586 papers from five different\nconferences, where it successfully identified every target paper with a recall\nof 100% and a near perfect accuracy of 99.4%. This demonstration highlights the\npotential of task-oriented AI agents to not only filter information but also to\nactively participate in and accelerate the workflows of the academic community.", "AI": {"tldr": "The paper introduces an automated AI system, 'Agent-E,' that identifies research papers from specific regions and completes tasks like submitting nomination forms, achieving 100% recall and 99.4% accuracy.", "motivation": "The motivation is to address the challenge of keeping up with the growing volume of academic literature, which requires considerable manual effort for researchers and academic bodies.", "method": "A fully automated pipeline with 'Agent-E' identifies specified academic papers from conference proceedings and uses Robotic Process Automation (RPA) to execute pre-defined actions.", "result": "The system was successfully validated on 586 papers across five conferences, achieving perfect recall (100%) and high accuracy (99.4%).", "conclusion": "Task-oriented AI agents, like 'Agent-E,' can actively filter information and accelerate academic workflows, showcasing their potential to assist the academic community."}}
{"id": "2509.10025", "pdf": "https://arxiv.org/pdf/2509.10025", "abs": "https://arxiv.org/abs/2509.10025", "authors": ["Strahinja Nikolic", "Ilker Oguz", "Demetri Psaltis"], "title": "Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 7 figures", "summary": "Understanding the internal organization of neural networks remains a\nfundamental challenge in deep learning interpretability. We address this\nchallenge by exploring a novel Sparse Mixture of Experts Variational\nAutoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw\ndataset, comparing unsupervised expert routing against a supervised baseline\nguided by ground-truth labels. Surprisingly, we find that unsupervised routing\nconsistently achieves superior reconstruction performance. The experts learn to\nidentify meaningful sub-categorical structures that often transcend\nhuman-defined class boundaries. Through t-SNE visualizations and reconstruction\nanalysis, we investigate how MoE models uncover fundamental data structures\nthat are more aligned with the model's objective than predefined labels.\nFurthermore, our study on the impact of dataset size provides insights into the\ntrade-offs between data quantity and expert specialization, offering guidance\nfor designing efficient MoE architectures.", "AI": {"tldr": "This study presents SMoE-VAE, a new neural network architecture, and explores its ability to learn meaningful structures through unsupervised expert routing, which outperforms supervised methods.", "motivation": "The motivation is to address the challenge of interpreting the internal organization of neural networks in deep learning.", "method": "The authors propose a Sparse Mixture of Experts Variational Autoencoder (SMoE-VAE) and analyze its performance on the QuickDraw dataset using both supervised and unsupervised expert routing strategies.", "result": "Unsupervised expert routing achieves better reconstruction performance than the supervised baseline, identifying meaningful sub-categorical data structures that transcend human-defined class boundaries.", "conclusion": "The study highlights the ability of MoE models to uncover fundamental data structures and offers insights into data quantity and expert specialization trade-offs for designing efficient architectures."}}
{"id": "2509.09729", "pdf": "https://arxiv.org/pdf/2509.09729", "abs": "https://arxiv.org/abs/2509.09729", "authors": ["Gerard Sant", "Zifan Jiang", "Carlos Escolano", "Amit Moryossef", "Mathias M\u00fcller", "Rico Sennrich", "Sarah Ebling"], "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": null, "summary": "In recent years, sign language processing (SLP) has gained importance in the\ngeneral field of Natural Language Processing. However, compared to research on\nspoken languages, SLP research is hindered by complex ad-hoc code,\ninadvertently leading to low reproducibility and unfair comparisons. Existing\ntools that are built for fast and reproducible experimentation, such as Hugging\nFace, are not flexible enough to seamlessly integrate sign language\nexperiments. This view is confirmed by a survey we conducted among SLP\nresearchers.\n  To address these challenges, we introduce MultimodalHugs, a framework built\non top of Hugging Face that enables more diverse data modalities and tasks,\nwhile inheriting the well-known advantages of the Hugging Face ecosystem. Even\nthough sign languages are our primary focus, MultimodalHugs adds a layer of\nabstraction that makes it more widely applicable to other use cases that do not\nfit one of the standard templates of Hugging Face. We provide quantitative\nexperiments to illustrate how MultimodalHugs can accommodate diverse modalities\nsuch as pose estimation data for sign languages, or pixel data for text\ncharacters.", "AI": {"tldr": "The paper introduces MultimodalHugs, a new framework to improve reproducibility and flexibility in sign language processing research, addressing limitations of current tools like Hugging Face.", "motivation": "Sign Language Processing (SLP) research faces challenges in reproducibility and comparison due to complex coding practices and lack of flexible experimentation tools.", "method": "The framework, MultimodalHugs, extends the Hugging Face platform by incorporating diverse data modalities and tasks, focusing primarily on enabling pose estimation data for sign languages.", "result": "Quantitative experiments show that MultimodalHugs efficiently integrates diverse modalities such as pose estimation and pixel data into SLP, enhancing usability and applicability.", "conclusion": "MultimodalHugs fills the gap in SLP research tools, improving reproducibility and adaptability, with potential for broader applications beyond sign language."}}
{"id": "2509.09958", "pdf": "https://arxiv.org/pdf/2509.09958", "abs": "https://arxiv.org/abs/2509.09958", "authors": ["Jeffrey Liu", "Rongbin Hu"], "title": "Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Referring Expression Comprehension (REC) is usually addressed with\ntask-trained grounding models. We show that a zero-shot workflow, without any\nREC-specific training, can achieve competitive or superior performance. Our\napproach reformulates REC as box-wise visual-language verification: given\nproposals from a COCO-clean generic detector (YOLO-World), a general-purpose\nVLM independently answers True/False queries for each region. This simple\nprocedure reduces cross-box interference, supports abstention and multiple\nmatches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our\nmethod not only surpasses a zero-shot GroundingDINO baseline but also exceeds\nreported results for GroundingDINO trained on REC and GroundingDINO+CRG.\nControlled studies with identical proposals confirm that verification\nsignificantly outperforms selection-based prompting, and results hold with open\nVLMs. Overall, we show that workflow design, rather than task-specific\npretraining, drives strong zero-shot REC performance.", "AI": {"tldr": "The paper presents a zero-shot method for Referring Expression Comprehension (REC) that does not rely on task-specific training, demonstrating competitive performance compared to trained models.", "motivation": "The study is motivated by the challenge of achieving strong performance in REC without the need for task-specific pretraining, simplifying the workflow while maintaining or improving accuracy.", "method": "The method reformulates REC as a visual-language verification task, where a general-purpose Vision-Language Model (VLM) evaluates True/False queries for region proposals generated by a COCO-trained YOLO-World detector, without fine-tuning.", "result": "The proposed approach outperforms both a zero-shot GroundingDINO baseline and REC-trained models, such as GroundingDINO and GroundingDINO+CRG, across multiple datasets (RefCOCO, RefCOCO+, and RefCOCOg).", "conclusion": "Workflow design, rather than task-specific training, is key to achieving strong zero-shot performance in REC, suggesting broader applicability for similar tasks."}}
{"id": "2509.10454", "pdf": "https://arxiv.org/pdf/2509.10454", "abs": "https://arxiv.org/abs/2509.10454", "authors": ["Hang Yin", "Haoyu Wei", "Xiuwei Xu", "Wenxuan Guo", "Jie Zhou", "Jiwen Lu"], "title": "GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to CoRL 2025. Project page: [this https\n  URL](https://bagh2178.github.io/GC-VLN/)", "summary": "In this paper, we propose a training-free framework for vision-and-language\nnavigation (VLN). Existing zero-shot VLN methods are mainly designed for\ndiscrete environments or involve unsupervised training in continuous simulator\nenvironments, which makes it challenging to generalize and deploy them in\nreal-world scenarios. To achieve a training-free framework in continuous\nenvironments, our framework formulates navigation guidance as graph constraint\noptimization by decomposing instructions into explicit spatial constraints. The\nconstraint-driven paradigm decodes spatial semantics through constraint\nsolving, enabling zero-shot adaptation to unseen environments. Specifically, we\nconstruct a spatial constraint library covering all types of spatial\nrelationship mentioned in VLN instructions. The human instruction is decomposed\ninto a directed acyclic graph, with waypoint nodes, object nodes and edges,\nwhich are used as queries to retrieve the library to build the graph\nconstraints. The graph constraint optimization is solved by the constraint\nsolver to determine the positions of waypoints, obtaining the robot's\nnavigation path and final goal. To handle cases of no solution or multiple\nsolutions, we construct a navigation tree and the backtracking mechanism.\nExtensive experiments on standard benchmarks demonstrate significant\nimprovements in success rate and navigation efficiency compared to\nstate-of-the-art zero-shot VLN methods. We further conduct real-world\nexperiments to show that our framework can effectively generalize to new\nenvironments and instruction sets, paving the way for a more robust and\nautonomous navigation framework.", "AI": {"tldr": "This paper proposes a training-free framework for vision-and-language navigation (VLN) by using graph constraint optimization, achieving significant improvements and generalization in zero-shot navigation tasks.", "motivation": "Existing zero-shot VLN methods struggle to generalize in real-world continuous environments due to their reliance on either discrete environments or unsupervised training in simulators.", "method": "The framework uses graph constraint optimization by decomposing instructions into spatial constraints and solving them with a constraint solver. A spatial constraint library and backtracking mechanisms handle edge cases like no solutions or multiple solutions.", "result": "Experiments on benchmarks show improved success rates and efficiency, with the method also proven effective in real-world navigation tasks, enabling robust adaptation to new environments and instructions.", "conclusion": "This work establishes a robust and innovative framework for training-free VLN, optimizing performance and real-world applicability without requiring prior training."}}
{"id": "2509.09681", "pdf": "https://arxiv.org/pdf/2509.09681", "abs": "https://arxiv.org/abs/2509.09681", "authors": ["Yikuan Xia", "Jiazun Chen", "Yirui Zhan", "Suifeng Zhao", "Weipeng Jiang", "Chaorui Zhang", "Wei Han", "Bo Bai", "Jun Gao"], "title": "DB3 Team's Solution For Meta KDD Cup' 25", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "This paper presents the db3 team's winning solution for the Meta CRAG-MM\nChallenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,\nmulti-turn question answering benchmark (CRAG-MM), we developed a comprehensive\nframework that integrates tailored retrieval pipelines for different tasks with\na unified LLM-tuning approach for hallucination control. Our solution features\n(1) domain-specific retrieval pipelines handling image-indexed knowledge\ngraphs, web sources, and multi-turn conversations; and (2) advanced refusal\ntraining using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd\nplace in Task 2, and 1st place in Task 3, securing the grand prize for\nexcellence in ego-centric queries through superior handling of first-person\nperspective challenges.", "AI": {"tldr": "This paper outlines the db3 team's winning solution for the Meta CRAG-MM Challenge 2025, utilizing advanced retrieval pipelines and refusal training techniques to excel in multi-modal and multi-turn question answering tasks.", "motivation": "To address the complexity of the CRAG-MM challenge's multi-modal, multi-turn question answering benchmarking and create an effective solution for handling ego-centric queries.", "method": "The authors combined domain-specific retrieval pipelines with a unified LLM-tuning approach, incorporating techniques like SFT, DPO, and RL for advanced refusal training to improve system performance.", "result": "Their solution secured the grand prize by achieving 2nd place in Tasks 1 and 2, and 1st place in Task 3, showcasing superior functionality in handling first-person perspective challenges.", "conclusion": "The framework demonstrates effective integration of tailored retrieval pipelines and advanced training methods to excel in complex multi-modal and multi-turn question answering scenarios, addressing unique benchmark challenges."}}
{"id": "2509.10033", "pdf": "https://arxiv.org/pdf/2509.10033", "abs": "https://arxiv.org/abs/2509.10033", "authors": ["Boya Ma", "Abram Magner", "Maxwell McNeil", "Petko Bogdanov"], "title": "Sparse Coding Representation of 2-way Data", "categories": ["cs.LG"], "comment": null, "summary": "Sparse dictionary coding represents signals as linear combinations of a few\ndictionary atoms. It has been applied to images, time series, graph signals and\nmulti-way spatio-temporal data by jointly employing temporal and spatial\ndictionaries. Data-agnostic analytical dictionaries, such as the discrete\nFourier transform, wavelets and graph Fourier, have seen wide adoption due to\nefficient implementations and good practical performance. On the other hand,\ndictionaries learned from data offer sparser and more accurate solutions but\nrequire learning of both the dictionaries and the coding coefficients. This\nbecomes especially challenging for multi-dictionary scenarios since encoding\ncoefficients correspond to all atom combinations from the dictionaries. To\naddress this challenge, we propose a low-rank coding model for 2-dictionary\nscenarios and study its data complexity. Namely, we establish a bound on the\nnumber of samples needed to learn dictionaries that generalize to unseen\nsamples from the same distribution. We propose a convex relaxation solution,\ncalled AODL, whose exact solution we show also solves the original problem. We\nthen solve this relaxation via alternating optimization between the sparse\ncoding matrices and the learned dictionaries, which we prove to be convergent.\nWe demonstrate its quality for data reconstruction and missing value imputation\nin both synthetic and real-world datasets. For a fixed reconstruction quality,\nAODL learns up to 90\\% sparser solutions compared to non-low-rank and\nanalytical (fixed) dictionary baselines. In addition, the learned dictionaries\nreveal interpretable insights into patterns present within the samples used for\ntraining.", "AI": {"tldr": "The paper proposes a low-rank coding model for sparse dictionary coding in 2-dictionary scenarios and introduces an efficient optimization method for data reconstruction and imputation.", "motivation": "Sparse dictionary coding, while efficient, faces challenges in achieving accuracy and sparsity when using learned dictionaries, especially in multi-dictionary scenarios where coefficient encoding involves combinations from different dictionaries.", "method": "The authors propose a low-rank coding model along with a convex relaxation solution named AODL. This method uses alternating optimization for sparse coding matrices and learned dictionaries, and convergence is mathematically proven.", "result": "AODL achieves up to 90% sparser solutions compared to traditional and analytical dictionary baselines while maintaining reconstruction quality. It also successfully handles data reconstruction and missing value imputation.", "conclusion": "The method provides a robust and efficient approach to sparse dictionary coding that generalizes well to unseen data, leading to interpretable results and significant sparsity benefits."}}
{"id": "2509.09731", "pdf": "https://arxiv.org/pdf/2509.09731", "abs": "https://arxiv.org/abs/2509.09731", "authors": ["Haiyang Yu", "Yuchuan Wu", "Fan Shi", "Lei Liao", "Jinghui Lu", "Xiaodong Ge", "Han Wang", "Minghan Zhuo", "Xuecheng Wu", "Xiang Fei", "Hao Feng", "Guozhi Tang", "An-Lan Wang", "Hanshen Zhu", "Yangfan He", "Quanhuan Liang", "Liyuan Meng", "Chao Feng", "Can Huang", "Jingqun Tang", "Bin Li"], "title": "Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Chinese ancient documents, invaluable carriers of millennia of Chinese\nhistory and culture, hold rich knowledge across diverse fields but face\nchallenges in digitization and understanding, i.e., traditional methods only\nscan images, while current Vision-Language Models (VLMs) struggle with their\nvisual and linguistic complexity. Existing document benchmarks focus on English\nprinted texts or simplified Chinese, leaving a gap for evaluating VLMs on\nancient Chinese documents. To address this, we present AncientDoc, the first\nbenchmark for Chinese ancient documents, designed to assess VLMs from OCR to\nknowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular\ntranslation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and\ncovers 14 document types, over 100 books, and about 3,000 pages. Based on\nAncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by\na human-aligned large language model for scoring.", "AI": {"tldr": "Chinese ancient documents are complex and under-digitized, posing difficulties for current Vision-Language Models (VLMs). AncientDoc, a benchmark, is introduced with five tasks to bridge this evaluation gap.", "motivation": "To digitize and understand the historical and cultural richness of ancient Chinese documents, while addressing the lack of evaluation tools tailored for their complexity in VLMs.", "method": "AncientDoc includes five tasks (OCR, vernacular translation, reasoning-based QA, knowledge-based QA, linguistic variant QA), covering various document types and using metrics for assessing VLMs alongside human-aligned scoring.", "result": "AncientDoc evaluates mainstream VLMs across diverse tasks and provides a structured method to benchmark their performance in processing complex ancient Chinese texts.", "conclusion": "AncientDoc fills a critical gap in assessing VLMs for Chinese ancient documents, offering more comprehensive benchmarking to advance their digitization and understanding."}}
{"id": "2509.09961", "pdf": "https://arxiv.org/pdf/2509.09961", "abs": "https://arxiv.org/abs/2509.09961", "authors": ["Tianqi Wei", "Xin Yu", "Zhi Chen", "Scott Chapman", "Zi Huang"], "title": "Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate segmentation of foliar diseases and insect damage in wheat is\ncrucial for effective crop management and disease control. However, the insect\ndamage typically occupies only a tiny fraction of annotated pixels. This\nextreme pixel-level imbalance poses a significant challenge to the segmentation\nperformance, which can result in overfitting to common classes and insufficient\nlearning of rare classes, thereby impairing overall performance. In this paper,\nwe propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to\naddress the pixel imbalance problem. Specifically, we extract rare\ninsect-damage patches from annotated training images and apply random geometric\ntransformations to simulate variations. The transformed patches are then pasted\nin appropriate regions while avoiding overlaps with lesions or existing damaged\nregions. In addition, we apply a random projection filter to the pasted\nregions, refining local features and ensuring a natural blend with the new\nbackground. Experiments show that our method substantially improves\nsegmentation performance on the insect damage class, while maintaining or even\nslightly enhancing accuracy on other categories. Our results highlight the\neffectiveness of targeted augmentation in mitigating extreme pixel imbalance,\noffering a straightforward yet effective solution for agricultural segmentation\nproblems.", "AI": {"tldr": "The paper addresses difficulties in segmentation of wheat foliar diseases and insect damage by proposing a Random Projected Copy-and-Paste (RPCP) augmentation technique.", "motivation": "Accurate segmentation for crop management is hindered by extreme pixel-level imbalance, making insect damage hard to learn while overfitting common classes.", "method": "The method extracts and transforms insect-damage patches, pasting them strategically using geometric transformations and random projection filters to maintain natural blending.", "result": "Experiments demonstrate substantial improvement in insect damage segmentation performance without compromising other category accuracies.", "conclusion": "RPCP augmentation effectively mitigates pixel imbalance, presenting a direct and impactful solution for agricultural image segmentation."}}
{"id": "2509.09683", "pdf": "https://arxiv.org/pdf/2509.09683", "abs": "https://arxiv.org/abs/2509.09683", "authors": ["Briti Gangopadhyay", "Zhao Wang", "Shingo Takamatsu"], "title": "Forecasting Clicks in Digital Advertising: Multimodal Inputs and Interpretable Outputs", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Forecasting click volume is a key task in digital advertising, influencing\nboth revenue and campaign strategy. Traditional time series models rely solely\non numerical data, often overlooking rich contextual information embedded in\ntextual elements, such as keyword updates. We present a multimodal forecasting\nframework that combines click data with textual logs from real-world ad\ncampaigns and generates human-interpretable explanations alongside numeric\npredictions. Reinforcement learning is used to improve comprehension of textual\ninformation and enhance fusion of modalities. Experiments on a large-scale\nindustry dataset show that our method outperforms baselines in both accuracy\nand reasoning quality.", "AI": {"tldr": "The paper introduces a multimodal forecasting framework that incorporates textual data to improve click volume predictions in digital advertising.", "motivation": "Traditional click volume forecasting mainly relies on numerical data and misses out on valuable textual context, like keyword updates.", "method": "A multimodal forecasting framework is developed, integrating click data with ad campaign text logs. Reinforcement learning is used for better comprehension and fusion of textual and numerical data.", "result": "The proposed method outperforms traditional baselines in terms of both prediction accuracy and the quality of reasoning, validated on a large-scale industry dataset.", "conclusion": "Incorporating textual information with numerical data can significantly improve forecasting performance, offering better accuracy and interpretability for digital advertising campaigns."}}
{"id": "2509.10034", "pdf": "https://arxiv.org/pdf/2509.10034", "abs": "https://arxiv.org/abs/2509.10034", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability", "categories": ["cs.LG"], "comment": "19 pages, 2 figures", "summary": "We present a formal and constructive theory showing that probabilistic finite\nautomata (PFAs) can be exactly simulated using symbolic feedforward neural\nnetworks. Our architecture represents state distributions as vectors and\ntransitions as stochastic matrices, enabling probabilistic state propagation\nvia matrix-vector products. This yields a parallel, interpretable, and\ndifferentiable simulation of PFA dynamics using soft updates-without\nrecurrence. We formally characterize probabilistic subset construction,\n$\\varepsilon$-closure, and exact simulation via layered symbolic computation,\nand prove equivalence between PFAs and specific classes of neural networks. We\nfurther show that these symbolic simulators are not only expressive but\nlearnable: trained with standard gradient descent-based optimization on labeled\nsequence data, they recover the exact behavior of ground-truth PFAs. This\nlearnability, formalized in Proposition 5.1, is the crux of this work. Our\nresults unify probabilistic automata theory with neural architectures under a\nrigorous algebraic framework, bridging the gap between symbolic computation and\ndeep learning.", "AI": {"tldr": "This paper demonstrates that probabilistic finite automata (PFAs) can be exactly simulated using symbolic feedforward neural networks, unifying automata theory with neural architectures.", "motivation": "To bridge the gap between symbolic computation in automata theory and deep learning by creating an exact neural simulation of PFAs.", "method": "The authors propose an architecture where state distributions are encoded as vectors and transitions as stochastic matrices, enabling probabilistic state propagation through matrix-vector products, and use gradient-based training to achieve exact PFA behavior.", "result": "The neural architecture successfully simulates PFAs and is able to learn their exact behavior when trained on labeled sequence data.", "conclusion": "This work unifies probabilistic automata theory with neural network architectures, providing a rigorous framework that combines symbolic computation and deep learning."}}
{"id": "2509.09734", "pdf": "https://arxiv.org/pdf/2509.09734", "abs": "https://arxiv.org/abs/2509.09734", "authors": ["Zikang Guo", "Benfeng Xu", "Chiwei Zhu", "Wentao Hong", "Xiaorui Wang", "Zhendong Mao"], "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly emerging as a pivotal open\nstandard, designed to enhance agent-tool integration and interoperability, and\nis positioned to unlock a new era of powerful, interconnected, and genuinely\nutilitarian agentic AI. However, despite MCP's growing adoption, existing\nbenchmarks often fail to capture real-world agent performance within this new\nparadigm, leading to a distorted perception of their true operational value and\nan inability to reliably differentiate proficiencies. To bridge this critical\nevaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark\nspecifically engineered to rigorously assess language agent capabilities in\nMCP-mediated tool interactions. Core contributions of MCP-AgentBench include:\nthe establishment of a robust MCP testbed comprising 33 operational servers\nwith 188 distinct tools; the development of a benchmark featuring 600\nsystematically designed queries distributed across 6 distinct categories of\nvarying interaction complexity; and the introduction of MCP-Eval, a novel\noutcome-oriented evaluation methodology prioritizing real-world task success.\nThrough extensive empirical evaluation of leading language agents, we provide\nfoundational insights. MCP-AgentBench aims to equip the research community with\na standardized and reliable framework to build, validate, and advance agents\ncapable of fully leveraging MCP's transformative benefits, thereby accelerating\nprogress toward truly capable and interoperable AI systems.", "AI": {"tldr": "The paper introduces MCP-AgentBench, a benchmark to evaluate language agents' performance in MCP-mediated tool interaction.", "motivation": "Despite MCP's growing adoption, there is a lack of adequate benchmarks that evaluate real-world agent performance in MCP contexts.", "method": "The authors created MCP-AgentBench, featuring 33 servers with 188 tools, 600 queries in 6 categories, and a new evaluation methodology (MCP-Eval).", "result": "MCP-AgentBench rigorously assesses language agents, providing insights into their performance and potential improvements.", "conclusion": "MCP-AgentBench offers the AI research community a standardized framework to improve MCP-aligned agent capabilities and interoperability."}}
{"id": "2509.09962", "pdf": "https://arxiv.org/pdf/2509.09962", "abs": "https://arxiv.org/abs/2509.09962", "authors": ["Anne Marthe Sophie Ngo Bibinbe", "Chiron Bang", "Patrick Gagnon", "Jamie Ahloy-Dallaire", "Eric R. Paquet"], "title": "An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock", "categories": ["cs.CV"], "comment": "13 pages, 7 figures, 1 table, accepted at CVPR animal workshop 2024,\n  submitted to IJCV", "summary": "The need for long-term multi-object tracking (MOT) is growing due to the\ndemand for analyzing individual behaviors in videos that span several minutes.\nUnfortunately, due to identity switches between objects, the tracking\nperformance of existing MOT approaches decreases over time, making them\ndifficult to apply for long-term tracking. However, in many real-world\napplications, such as in the livestock sector, it is possible to obtain\nsporadic identifications for some of the animals from sources like feeders. To\naddress the challenges of long-term MOT, we propose a new framework that\ncombines both uncertain identities and tracking using a Hidden Markov Model\n(HMM) formulation. In addition to providing real-world identities to animals,\nour HMM framework improves the F1 score of ByteTrack, a leading MOT approach\neven with re-identification, on a 10 minute pig tracking dataset with 21\nidentifications at the pen's feeding station. We also show that our approach is\nrobust to the uncertainty of identifications, with performance increasing as\nidentities are provided more frequently. The improved performance of our HMM\nframework was also validated on the MOT17 and MOT20 benchmark datasets using\nboth ByteTrack and FairMOT. The code for this new HMM framework and the new\n10-minute pig tracking video dataset are available at:\nhttps://github.com/ngobibibnbe/uncertain-identity-aware-tracking", "AI": {"tldr": "The paper proposes a new framework based on a Hidden Markov Model (HMM) to improve long-term multi-object tracking (MOT), particularly for applications like livestock tracking.", "motivation": "Existing MOT systems are prone to identity switches over extended tracking periods, reducing their effectiveness in long-term applications, especially where sporadic identifications are available (e.g., livestock tracking systems).", "method": "The authors integrate sporadic, uncertain identity data with object tracking using an HMM framework, which enhances the ability to track objects accurately over longer durations.", "result": "The HMM framework improved the F1 score of ByteTrack on a 10-minute pig tracking dataset, demonstrating robust performance even under uncertain identifications. It also showed effectiveness on diverse benchmarks like MOT17 and MOT20.", "conclusion": "The HMM-based approach effectively boosts long-term MOT performance, particularly by leveraging sporadic identity data, and shows robustness and scalability across datasets. The corresponding code and dataset are open-sourced for further research."}}
{"id": "2509.09684", "pdf": "https://arxiv.org/pdf/2509.09684", "abs": "https://arxiv.org/abs/2509.09684", "authors": ["Bruno Yui Yamate", "Thais Rodrigues Neubauer", "Marcelo Fantinato", "Sarajane Marques Peres"], "title": "Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DB"], "comment": "33 pages", "summary": "This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)\nbenchmark dataset designed for the text-to-SQL task in the process mining\ndomain. Text-to-SQL conversion facilitates natural language querying of\ndatabases, increasing accessibility for users without SQL expertise and\nproductivity for those that are experts. The text-2-SQL-4-PM dataset is\ncustomized to address the unique challenges of process mining, including\nspecialized vocabularies and single-table relational structures derived from\nevent logs. The dataset comprises 1,655 natural language utterances, including\nhuman-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods\ninclude manual curation by experts, professional translations, and a detailed\nannotation process to enable nuanced analyses of task complexity. Additionally,\na baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility\nof the dataset for text-to-SQL applications. The results show that\ntext-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering\nbroader applicability for semantic parsing and other natural language\nprocessing tasks.", "AI": {"tldr": "The paper presents \"text-2-SQL-4-PM,\" a bilingual dataset (Portuguese-English) for the text-to-SQL task, tailored for process mining with 1,655 natural language utterances and 205 SQL statements.", "motivation": "To enable natural language querying of databases, making SQL queries accessible to non-experts while addressing challenges in process mining like specialized vocabulary.", "method": "The dataset was built through expert manual curation, professional translation, and detailed annotation; a baseline test was performed using GPT-3.5 Turbo to verify its utility.", "result": "The dataset facilitates the evaluation of text-to-SQL tasks, proving its feasibility for semantic parsing and broader NLP applications.", "conclusion": "The dataset enhances accessibility and productivity in querying databases, with potential for wider use across text-to-SQL and semantic parsing tasks."}}
{"id": "2509.10041", "pdf": "https://arxiv.org/pdf/2509.10041", "abs": "https://arxiv.org/abs/2509.10041", "authors": ["Mohammad Hasan Narimani", "Mostafa Tavassolipour"], "title": "FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) offers an innovative paradigm for collaborative model\ntraining across decentralized devices, such as smartphones, balancing enhanced\npredictive performance with the protection of user privacy in sensitive areas\nlike Internet of Things (IoT) and medical data analysis. Despite its\nadvantages, FL encounters significant challenges related to user privacy\nprotection against potential attacks and the management of communication costs.\nThis paper introduces a novel federated learning algorithm called FedRP, which\nintegrates random projection techniques with the Alternating Direction Method\nof Multipliers (ADMM) optimization framework. This approach enhances privacy by\nemploying random projection to reduce the dimensionality of model parameters\nprior to their transmission to a central server, reducing the communication\ncost. The proposed algorithm offers a strong $(\\epsilon, \\delta)$-differential\nprivacy guarantee, demonstrating resilience against data reconstruction\nattacks. Experimental results reveal that FedRP not only maintains high model\naccuracy but also outperforms existing methods, including conventional\ndifferential privacy approaches and FedADMM, in terms of both privacy\npreservation and communication efficiency.", "AI": {"tldr": "FedRP is a federated learning algorithm that uses random projection and ADMM to enhance privacy and reduce communication costs, demonstrating superior performance.", "motivation": "Address challenges in federated learning such as privacy protection from attacks and high communication costs.", "method": "Introduced FedRP, which employs random projection for dimensionality reduction combined with ADMM for optimization.", "result": "FedRP maintains high model accuracy, ensures $(\\epsilon, \\delta)$-differential privacy, and surpasses other methods in privacy and communication efficiency.", "conclusion": "FedRP offers a robust and efficient solution for privacy preservation and communication cost reduction in federated learning."}}
{"id": "2509.09735", "pdf": "https://arxiv.org/pdf/2509.09735", "abs": "https://arxiv.org/abs/2509.09735", "authors": ["Willem Huijzer", "Jieying Chen"], "title": "Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation", "categories": ["cs.CL"], "comment": "7 pages", "summary": "The rapid integration of Large Language Models (LLMs) into various domains\nraises concerns about societal inequalities and information bias. This study\nexamines biases in LLMs related to background, gender, and age, with a focus on\ntheir impact on decision-making and summarization tasks. Additionally, the\nresearch examines the cross-lingual propagation of these biases and evaluates\nthe effectiveness of prompt-instructed mitigation strategies. Using an adapted\nversion of the dataset by Tamkin et al. (2023) translated into Dutch, we\ncreated 151,200 unique prompts for the decision task and 176,400 for the\nsummarisation task. Various demographic variables, instructions, salience\nlevels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed\nthat both models were significantly biased during decision-making, favouring\nfemale gender, younger ages, and certain backgrounds such as the\nAfrican-American background. In contrast, the summarisation task showed minimal\nevidence of bias, though significant age-related differences emerged for\nGPT-3.5 in English. Cross-lingual analysis showed that bias patterns were\nbroadly similar between English and Dutch, though notable differences were\nobserved across specific demographic categories. The newly proposed mitigation\ninstructions, while unable to eliminate biases completely, demonstrated\npotential in reducing them. The most effective instruction achieved a 27\\% mean\nreduction in the gap between the most and least favorable demographics.\nNotably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts\nin English, indicating the specific potential for prompt-based mitigation\nwithin newer models. This research underscores the importance of cautious\nadoption of LLMs and context-specific bias testing, highlighting the need for\ncontinued development of effective mitigation strategies to ensure responsible\ndeployment of AI.", "AI": {"tldr": "The study investigates biases in large language models (LLMs), focusing on demographic variables and cross-lingual effects, while exploring mitigation strategies.", "motivation": "To address concerns regarding societal inequalities and information biases arising from the use of LLMs, especially in decision-making and summarization tasks.", "method": "The study utilized a translated dataset for Dutch, generated prompts for decision and summarization tasks, tested demographic and linguistic variations on GPT-3.5 and GPT-4o, and evaluated mitigation instruction effectiveness.", "result": "Biases were prominent in decision-making tasks, favoring female gender and younger ages, with minimal bias in summarization tasks. Bias patterns were similar across English and Dutch, with reduced biases in GPT-4o through mitigation strategies.", "conclusion": "Effective mitigation strategies can reduce biases but require refinement. The research highlights the importance of bias awareness and cautious LLM deployment for responsible AI use."}}
{"id": "2509.09971", "pdf": "https://arxiv.org/pdf/2509.09971", "abs": "https://arxiv.org/abs/2509.09971", "authors": ["Aupendu Kar", "Vishnu Raj", "Guan-Ming Su"], "title": "Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey", "categories": ["cs.CV"], "comment": null, "summary": "Event camera sensors are bio-inspired sensors which asynchronously capture\nper-pixel brightness changes and output a stream of events encoding the\npolarity, location and time of these changes. These systems are witnessing\nrapid advancements as an emerging field, driven by their low latency, reduced\npower consumption, and ultra-high capture rates. This survey explores the\nevolution of fusing event-stream captured with traditional frame-based capture,\nhighlighting how this synergy significantly benefits various video restoration\nand 3D reconstruction tasks. The paper systematically reviews major deep\nlearning contributions to image/video enhancement and restoration, focusing on\ntwo dimensions: temporal enhancement (such as frame interpolation and motion\ndeblurring) and spatial enhancement (including super-resolution, low-light and\nHDR enhancement, and artifact reduction). This paper also explores how the 3D\nreconstruction domain evolves with the advancement of event driven fusion.\nDiverse topics are covered, with in-depth discussions on recent works for\nimproving visual quality under challenging conditions. Additionally, the survey\ncompiles a comprehensive list of openly available datasets, enabling\nreproducible research and benchmarking. By consolidating recent progress and\ninsights, this survey aims to inspire further research into leveraging event\ncamera systems, especially in combination with deep learning, for advanced\nvisual media restoration and enhancement.", "AI": {"tldr": "The paper surveys the fusion of event camera data with traditional video capture techniques, highlighting its benefits in video enhancement and 3D reconstruction tasks.", "motivation": "To explore and consolidate advancements in using event cameras combined with deep learning for enhancing visual media quality.", "method": "The paper systematically reviews contributions in temporal and spatial video/image enhancement and discusses 3D reconstruction advancements with event camera data. It also compiles publicly available datasets.", "result": "The survey identifies significant progress in enhancing video restoration and 3D reconstruction using event camera technologies and highlights available datasets for reproducible research.", "conclusion": "The paper underscores the potential of event cameras combined with deep learning for advancing visual media quality and aims to inspire further research in this domain."}}
{"id": "2509.09685", "pdf": "https://arxiv.org/pdf/2509.09685", "abs": "https://arxiv.org/abs/2509.09685", "authors": ["Keunwoo Choi", "Seungheon Doh", "Juhan Nam"], "title": "TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation", "categories": ["cs.IR", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "We present TalkPlayData 2, a synthetic dataset for multimodal conversational\nmusic recommendation generated by an agentic data pipeline. In TalkPlayData 2\npipeline, multiple large language model (LLM) agents are created under various\nroles with specialized prompts and access to different parts of information,\nand the chat data is acquired by logging the conversation between the Listener\nLLM and the Recsys LLM. To cover various conversation scenarios, for each\nconversation, the Listener LLM is conditioned on a finetuned conversation goal.\nFinally, all the LLMs are multimodal with audio and images, allowing a\nsimulation of multimodal recommendation and conversation. In the LLM-as-a-judge\nand subjective evaluation experiments, TalkPlayData 2 achieved the proposed\ngoal in various aspects related to training a generative recommendation model\nfor music. TalkPlayData 2 and its generation code are open-sourced at\nhttps://talkpl.ai/talkplaydata2.html.", "AI": {"tldr": "TalkPlayData 2 is a synthetic multimodal conversational dataset for music recommendation created using a pipeline involving large language models (LLMs) in various roles and incorporating audio and visuals.", "motivation": "The paper aims to address the need for a high-quality conversational dataset to train generative recommendation models for music, spanning multimodal interactions and diverse scenarios.", "method": "Multiple specialized LLMs simulate conversational roles with conditioned goals and multimodal elements like audio and images to generate synthetic conversational data.", "result": "TalkPlayData 2 fulfilled its intended purpose, demonstrating efficacy in training generative music recommendation models in subjective evaluations.", "conclusion": "The dataset fills a gap in multimodal conversational research and is made openly accessible to advance related machine learning and recommendation systems."}}
{"id": "2509.10048", "pdf": "https://arxiv.org/pdf/2509.10048", "abs": "https://arxiv.org/abs/2509.10048", "authors": ["Madhushan Ramalingam"], "title": "Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data", "categories": ["cs.LG"], "comment": null, "summary": "Predictive models are being increasingly used across a wide range of domains,\nincluding safety-critical applications such as medical diagnosis and criminal\njustice. Reliable uncertainty estimation is a crucial task in such settings.\nTabular Prior-data Fitted Network (TabPFN) is a recently proposed machine\nlearning foundation model for tabular dataset, which uses a generative\ntransformer architecture. Variational Bayesian Last Layers (VBLL) is a\nstate-of-the-art lightweight variational formulation that effectively improves\nuncertainty estimation with minimal computational overhead. In this work we aim\nto evaluate the performance of VBLL integrated with the recently proposed\nTabPFN in uncertainty calibration. Our experiments, conducted on three\nbenchmark medical tabular datasets, compare the performance of the original\nTabPFN and the VBLL-integrated version. Contrary to expectations, we observed\nthat original TabPFN consistently outperforms VBLL integrated TabPFN in\nuncertainty calibration across all datasets.", "AI": {"tldr": "The paper evaluates VBLL's integration with TabPFN for uncertainty estimation in tabular datasets and finds that the original TabPFN performs better.", "motivation": "To assess the efficacy of employing VBLL for improved uncertainty calibration of TabPFN in safety-critical applications such as medical diagnosis.", "method": "The authors conducted experiments on three medical tabular datasets to compare the uncertainty calibration performance of the original TabPFN and TabPFN integrated with VBLL.", "result": "Contrary to expectations, the original TabPFN consistently outperformed the VBLL-integrated version in uncertainty estimation across all datasets.", "conclusion": "VBLL integration does not enhance, but rather underperforms compared to the original TabPFN in terms of uncertainty calibration for tabular datasets."}}
{"id": "2509.09801", "pdf": "https://arxiv.org/pdf/2509.09801", "abs": "https://arxiv.org/abs/2509.09801", "authors": ["Brennen Hill"], "title": "HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50, 68T05", "I.2.7; I.2.6; C.4"], "comment": null, "summary": "The adaptation of large language models (LLMs) to specialized reasoning tasks\nis fundamentally constrained by computational resources. Parameter-Efficient\nFine-Tuning (PEFT) methods have emerged as a powerful solution, yet the\nlandscape of these techniques is diverse, with distinct methods operating in\neither the model's weight space or its representation space. This paper\ninvestigates the hypothesis that a synergistic combination of these paradigms\ncan unlock superior performance and efficiency. We introduce HEFT (Hierarchical\nEfficient Fine-Tuning), a novel hierarchical adaptation strategy that composes\ntwo distinct PEFT methods in a coarse-to-fine manner: first, a broad,\nfoundational adaptation in the weight space using Low-Rank Adaptation (LoRA),\nfollowed by a precise, surgical refinement of internal activations using\nRepresentation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a\nLlama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential\nreasoning. Our results reveal a profound synergistic effect. A model fine-tuned\nfor only three epochs with our HEFT strategy achieves an accuracy of 85.17\\%,\nexceeding the performance of models trained for 20 epochs with either LoRA-only\n(85.05\\%) or ReFT-only (83.36\\%) methodologies. This work demonstrates that the\nthoughtful composition of PEFT methods is a potent algorithmic innovation,\noffering a more efficient and effective path toward advancing the reasoning\ncapabilities of language models. By achieving superior results with a fraction\nof the computational budget, our findings present a principled approach to\novercoming the obstacles inherent in adapting large-scale models for complex\ncognitive tasks.", "AI": {"tldr": "The paper introduces HEFT, a hierarchical fine-tuning approach combining two parameter-efficient methods (LoRA and ReFT), achieving superior performance in reasoning tasks with reduced computational requirements.", "motivation": "The paper aims to address the challenge of efficiently fine-tuning large language models (LLMs) for specialized reasoning tasks while minimizing computational resource demands.", "method": "The proposed method, HEFT, hierarchically combines Low-Rank Adaptation (LoRA) for foundational adaptation in weight space with Representation Fine-Tuning (ReFT) for refined internal activations.", "result": "Using HEFT on the BoolQ benchmark, the fine-tuned model achieved 85.17% accuracy in only 3 epochs, outperforming LoRA-only (85.05%) and ReFT-only (83.36%) approaches over 20 epochs.", "conclusion": "HEFT's synergistic composition of PEFT methods significantly enhances fine-tuning efficiency and model reasoning performance, presenting a promising strategy for adapting LLMs to complex tasks."}}
{"id": "2509.09977", "pdf": "https://arxiv.org/pdf/2509.09977", "abs": "https://arxiv.org/abs/2509.09977", "authors": ["Siying Liu", "Zikai Wang", "Hanle Zheng", "Yifan Hu", "Xilin Wang", "Qingkai Yang", "Jibin Wu", "Hao Guo", "Lei Deng"], "title": "ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking", "categories": ["cs.CV"], "comment": "15 pages, 8 figures", "summary": "RGB-Event tracking has become a promising trend in visual object tracking to\nleverage the complementary strengths of both RGB images and dynamic spike\nevents for improved performance. However, existing artificial neural networks\n(ANNs) struggle to fully exploit the sparse and asynchronous nature of event\nstreams. Recent efforts toward hybrid architectures combining ANNs and spiking\nneural networks (SNNs) have emerged as a promising solution in RGB-Event\nperception, yet effectively fusing features across heterogeneous paradigms\nremains a challenge. In this work, we propose ISTASTrack, the first\ntransformer-based \\textbf{A}NN-\\textbf{S}NN hybrid \\textbf{Track}er equipped\nwith \\textbf{ISTA} adapters for RGB-Event tracking. The two-branch model\nemploys a vision transformer to extract spatial context from RGB inputs and a\nspiking transformer to capture spatio-temporal dynamics from event streams. To\nbridge the modality and paradigm gap between ANN and SNN features, we\nsystematically design a model-based ISTA adapter for bidirectional feature\ninteraction between the two branches, derived from sparse representation theory\nby unfolding the iterative shrinkage thresholding algorithm. Additionally, we\nincorporate a temporal downsampling attention module within the adapter to\nalign multi-step SNN features with single-step ANN features in the latent\nspace, improving temporal fusion. Experimental results on RGB-Event tracking\nbenchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that\nISTASTrack achieves state-of-the-art performance while maintaining high energy\nefficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN\ndesigns for robust visual tracking. The code is publicly available at\nhttps://github.com/lsying009/ISTASTrack.git.", "AI": {"tldr": "The paper introduces ISTASTrack, a hybrid ANN-SNN RGB-Event object tracker that integrates transformer-based architectures and novel adapters for improved visual tracking.", "motivation": "To address the issue of fully exploiting sparse and asynchronous event streams in RGB-Event tracking through hybrid ANN-SNN approaches.", "method": "The model uses two branches: a vision transformer for spatial context extraction and a spiking transformer for spatio-temporal dynamics. A novel ISTA adapter ensures effective bidirectional interaction between ANN and SNN features.", "result": "Experiments demonstrate ISTASTrack's state-of-the-art performance on benchmarks like FE240hz, VisEvent, COESOT, and FELT, with high energy efficiency.", "conclusion": "Hybrid ANN-SNN designs with effective feature fusion, like ISTASTrack, are practical and effective for robust visual tracking."}}
{"id": "2509.09863", "pdf": "https://arxiv.org/pdf/2509.09863", "abs": "https://arxiv.org/abs/2509.09863", "authors": ["Sarvan Gill", "Daniela Constantinescu"], "title": "Off Policy Lyapunov Stability in Reinforcement Learning", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY"], "comment": "Conference on Robot Learning (CORL) 2025", "summary": "Traditional reinforcement learning lacks the ability to provide stability\nguarantees. More recent algorithms learn Lyapunov functions alongside the\ncontrol policies to ensure stable learning. However, the current self-learned\nLyapunov functions are sample inefficient due to their on-policy nature. This\npaper introduces a method for learning Lyapunov functions off-policy and\nincorporates the proposed off-policy Lyapunov function into the Soft Actor\nCritic and Proximal Policy Optimization algorithms to provide them with a data\nefficient stability certificate. Simulations of an inverted pendulum and a\nquadrotor illustrate the improved performance of the two algorithms when\nendowed with the proposed off-policy Lyapunov function.", "AI": {"tldr": "The paper improves sample efficiency in reinforcement learning by introducing off-policy Lyapunov functions and applying them to existing algorithms, enhancing stability guarantees.", "motivation": "Reinforcement learning traditionally lacks stability guarantees, and recent approaches using Lyapunov functions are sample inefficient due to on-policy learning.", "method": "An off-policy Lyapunov function is introduced and integrated into Soft Actor Critic and Proximal Policy Optimization algorithms, enhancing stability and sample efficiency.", "result": "Simulations with an inverted pendulum and quadrotor demonstrate improved performance of the algorithms equipped with the off-policy Lyapunov function.", "conclusion": "The proposed method enhances the stability and data efficiency of reinforcement learning algorithms, contributing to more reliable and robust control solutions."}}
{"id": "2509.09686", "pdf": "https://arxiv.org/pdf/2509.09686", "abs": "https://arxiv.org/abs/2509.09686", "authors": ["Fei Huang", "Fan Wu", "Zeqing Zhang", "Qihao Wang", "Long Zhang", "Grant Michael Boquet", "Hongyang Chen"], "title": "GeoGPT.RAG Technical Report", "categories": ["cs.IR", "cs.AI", "I.2; I.7; H.4; H.5"], "comment": "19 pages, 10 figures, 10 tables", "summary": "GeoGPT is an open large language model system built to advance research in\nthe geosciences. To enhance its domain-specific capabilities, we integrated\nRetrieval Augmented Generation(RAG), which augments model outputs with relevant\ninformation retrieved from an external knowledge source. GeoGPT uses RAG to\ndraw from the GeoGPT Library, a specialized corpus curated for geoscientific\ncontent, enabling it to generate accurate, context-specific answers. Users can\nalso create personalized knowledge bases by uploading their own publication\nlists, allowing GeoGPT to retrieve and respond using user-provided materials.\nTo further improve retrieval quality and domain alignment, we fine-tuned both\nthe embedding model and a ranking model that scores retrieved passages by\nrelevance to the query. These enhancements optimize RAG for geoscience\napplications and significantly improve the system's ability to deliver precise\nand trustworthy outputs. GeoGPT reflects a strong commitment to open science\nthrough its emphasis on collaboration, transparency, and community driven\ndevelopment. As part of this commitment, we have open-sourced two core RAG\ncomponents-GeoEmbedding and GeoReranker-to support geoscientists, researchers,\nand professionals worldwide with powerful, accessible AI tools.", "AI": {"tldr": "GeoGPT is an open domain-specific language model enhanced by Retrieval Augmented Generation, fine-tuned models for geoscience applications, and open-sourced tools for community use.", "motivation": "The paper aims to create a specialized AI tool tailored for geoscientific research, addressing the need for accurate and context-specific information processing in the field.", "method": "GeoGPT integrates Retrieval Augmented Generation, utilizes a curated geoscience corpus, supports custom knowledge bases, and employs fine-tuned embedding and ranking models for improved relevance.", "result": "Improved retrieval quality, higher domain alignment, and enhanced accuracy and trustworthiness of outputs tailored for geoscience applications.", "conclusion": "GeoGPT advances geoscientific research through an open and collaborative model, featuring powerful domain-specific tools and techniques accessible to the global community."}}
{"id": "2509.10089", "pdf": "https://arxiv.org/pdf/2509.10089", "abs": "https://arxiv.org/abs/2509.10089", "authors": ["Marco Andrea B\u00fchler", "Gonzalo Guill\u00e9n-Gos\u00e1lbez"], "title": "KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework", "categories": ["cs.LG"], "comment": null, "summary": "We introduce a novel symbolic regression framework, namely KAN-SR, built on\nKolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.\nSymbolic regression searches for mathematical equations that best fit a given\ndataset and is commonly solved with genetic programming approaches. We show\nthat by using deep learning techniques, more specific KANs, and combining them\nwith simplification strategies such as translational symmetries and\nseparabilities, we are able to recover ground-truth equations of the Feynman\nSymbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we\nshow that by combining the proposed framework with neural controlled\ndifferential equations, we are able to model the dynamics of an in-silico\nbioprocess system precisely, opening the door for the dynamic modeling of other\nengineering systems.", "AI": {"tldr": "KAN-SR introduces a deep learning-based approach to symbolic regression, outperforming traditional genetic programming by retrieving equations from datasets and modeling dynamic systems.", "motivation": "To enhance symbolic regression by overcoming limitations of genetic programming and enabling precise equation recovery and modeling of dynamic systems.", "method": "KAN-SR employs Kolmogorov Arnold Networks, combined with deep learning, simplification strategies like translational symmetries, and separabilities.", "result": "Successfully recovers ground-truth equations from the Feynman SRSD dataset and accurately models dynamics in an in-silico bioprocess system.", "conclusion": "The approach expands the potential of symbolic regression in scientific discovery and dynamic engineering system modeling."}}
{"id": "2509.09804", "pdf": "https://arxiv.org/pdf/2509.09804", "abs": "https://arxiv.org/abs/2509.09804", "authors": ["Helen de Andrade Abreu", "Tiago Timponi Torrent", "Ely Edison da Silva Matos"], "title": "Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization", "categories": ["cs.CL"], "comment": "Paper submitted to Language Sciences Journal", "summary": "This paper proposes a framework for modeling multimodal conversational turn\norganization via the proposition of correlations between language and\ninteractive gestures, based on analysis as to how pragmatic frames are\nconceptualized and evoked by communicators. As a means to provide evidence for\nthe analysis, we developed an annotation methodology to enrich a multimodal\ndataset (annotated for semantic frames) with pragmatic frames modeling\nconversational turn organization. Although conversational turn organization has\nbeen studied by researchers from diverse fields, the specific strategies,\nespecially gestures used by communicators, had not yet been encoded in a\ndataset that can be used for machine learning. To fill this gap, we enriched\nthe Frame2 dataset with annotations of gestures used for turn organization. The\nFrame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo\nMundo annotated for semantic frames evoked in both video and text. This dataset\nallowed us to closely observe how communicators use interactive gestures\noutside a laboratory, in settings, to our knowledge, not previously recorded in\nrelated literature. Our results have confirmed that communicators involved in\nface-to-face conversation make use of gestures as a tool for passing, taking\nand keeping conversational turns, and also revealed variations of some gestures\nthat had not been documented before. We propose that the use of these gestures\narises from the conceptualization of pragmatic frames, involving mental spaces,\nblending and conceptual metaphors. In addition, our data demonstrate that the\nannotation of pragmatic frames contributes to a deeper understanding of human\ncognition and language.", "AI": {"tldr": "The study introduces a framework analyzing how gestures, alongside language, coordinate conversational turns. Researchers annotated a dataset from a Brazilian TV show to model these interactions, yielding insights into gesture use.", "motivation": "The paper seeks to understand how interactive gestures, in combination with language, influence conversational turn-taking, exploring unstudied aspects of multimodal communication.", "method": "The researchers enriched an existing multimodal dataset (Frame2) with annotations for pragmatic frames focusing on gestures used in turn organization, based on television show episodes.", "result": "Communicators utilize gestures to regulate conversational turns effectively, and the findings include new undocumented gesture variations.", "conclusion": "The annotated dataset provides valuable insights into human cognition and communicative strategies, validating gestures as key tools in conversational exchange linked to pragmatic frames."}}
{"id": "2509.09988", "pdf": "https://arxiv.org/pdf/2509.09988", "abs": "https://arxiv.org/abs/2509.09988", "authors": ["Yusuke Takagi", "Shunya Nagashima", "Komei Sugiura"], "title": "FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction", "categories": ["cs.CV", "astro-ph.SR"], "comment": "Accepted for presentation at ICONIP2025", "summary": "Accurate and reliable solar flare predictions are essential to mitigate\npotential impacts on critical infrastructure. However, the current performance\nof solar flare forecasting is insufficient. In this study, we address the task\nof predicting the class of the largest solar flare expected to occur within the\nnext 72 hours. Existing methods often fail to adequately address the severe\nclass imbalance across flare classes. To address this issue, we propose a solar\nflare prediction model based on multiple deep state space models. In addition,\nwe introduce the frequency & local-boundary-aware reliability loss (FLARE loss)\nto improve predictive performance and reliability under class imbalance.\nExperiments were conducted on a multi-wavelength solar image dataset covering a\nfull 11-year solar activity cycle. As a result, our method outperformed\nbaseline approaches in terms of both the Gandin-Murphy-Gerrity score and the\ntrue skill statistic, which are standard metrics in terms of the performance\nand reliability.", "AI": {"tldr": "The paper proposes a deep learning model with a novel loss function to improve solar flare forecasting, addressing issues with class imbalance and achieving superior performance metrics.", "motivation": "Current solar flare forecasting methods are insufficient and struggle with severe class imbalance, which impacts accurate predictions.", "method": "The study introduces a model leveraging multiple deep state space models and a new loss function called FLARE loss to enhance forecasting performance and reliability.", "result": "Experiments on 11 years of solar image data showed improved forecasting performance using the proposed model, achieving better scores on standard metrics.", "conclusion": "The proposed approach enhances solar flare prediction reliability and outperforms existing models, offering a valuable tool for infrastructure impact mitigation."}}
{"id": "2509.10021", "pdf": "https://arxiv.org/pdf/2509.10021", "abs": "https://arxiv.org/abs/2509.10021", "authors": ["Jonas K\u00fchne", "Christian Vogt", "Michele Magno", "Luca Benini"], "title": "Efficient and Accurate Downfacing Visual Inertial Odometry", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": "This article has been accepted for publication in the IEEE Internet\n  of Things Journal (IoT-J)", "summary": "Visual Inertial Odometry (VIO) is a widely used computer vision method that\ndetermines an agent's movement through a camera and an IMU sensor. This paper\npresents an efficient and accurate VIO pipeline optimized for applications on\nmicro- and nano-UAVs. The proposed design incorporates state-of-the-art feature\ndetection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and\nquantized for emerging RISC-V-based ultra-low-power parallel systems on chips\n(SoCs). Furthermore, by employing a rigid body motion model, the pipeline\nreduces estimation errors and achieves improved accuracy in planar motion\nscenarios. The pipeline's suitability for real-time VIO is assessed on an\nultra-low-power SoC in terms of compute requirements and tracking accuracy\nafter quantization. The pipeline, including the three feature tracking methods,\nwas implemented on the SoC for real-world validation. This design bridges the\ngap between high-accuracy VIO pipelines that are traditionally run on\ncomputationally powerful systems and lightweight implementations suitable for\nmicrocontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates\nan average reduction in RMSE of up to a factor of 3.65x over the baseline\npipeline when using the ORB feature tracker. The analysis of the computational\ncomplexity of the feature trackers further shows that PX4FLOW achieves on-par\ntracking accuracy with ORB at a lower runtime for movement speeds below 24\npixels/frame.", "AI": {"tldr": "The paper introduces a VIO pipeline optimized for micro- and nano-UAVs, utilizing advanced feature tracking methods tailored for ultra-low-power RISC-V systems, achieving better accuracy and lower errors (up to 3.65x RMSE reduction with ORB).", "motivation": "The paper aims to address the gap between high-accuracy VIO pipelines suitable for computationally powerful systems and the need for lightweight implementations for ultra-low-power microcontrollers used in micro- and nano-UAVs.", "method": "The proposed pipeline incorporates state-of-the-art feature detection and tracking methods (SuperPoint, PX4FLOW, ORB), optimized for RISC-V-based SoCs. A rigid body motion model is utilized to improve accuracy in planar motion. The pipeline's real-world performance is validated on an ultra-low-power SoC (GAP9).", "result": "The optimized pipeline demonstrated an RMSE reduction of up to 3.65x over the baseline when using the ORB feature tracker. PX4FLOW achieved comparable accuracy to ORB but required lower runtime for movement speeds below 24 pixels/frame.", "conclusion": "The study successfully creates a lightweight and efficient VIO pipeline optimized for resource-constrained devices, making high-accuracy VIO feasible on microcontrollers without compromising performance or accuracy."}}
{"id": "2509.09688", "pdf": "https://arxiv.org/pdf/2509.09688", "abs": "https://arxiv.org/abs/2509.09688", "authors": ["Mohammad Atif", "Vincent Garonne", "Eric Lancon", "Jerome Lauret", "Alexandr Prozorov", "Michal Vranovsky"], "title": "AI-Powered Assistant for Long-Term Access to RHIC Knowledge", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National\nLaboratory concludes 25 years of operation, preserving not only its vast data\nholdings ($\\sim$1 ExaByte) but also the embedded scientific knowledge becomes a\ncritical priority. The RHIC Data and Analysis Preservation Plan (DAPP)\nintroduces an AI-powered assistant system that provides natural language access\nto documentation, workflows, and software, with the aim of supporting\nreproducibility, education, and future discovery. Built upon Large Language\nModels using Retrieval-Augmented Generation and the Model Context Protocol,\nthis assistant indexes structured and unstructured content from RHIC\nexperiments and enables domain-adapted interaction. We report on the\ndeployment, computational performance, ongoing multi-experiment integration,\nand architectural features designed for a sustainable and explainable long-term\nAI access. Our experience illustrates how modern AI/ML tools can transform the\nusability and discoverability of scientific legacy data.", "AI": {"tldr": "The paper discusses an AI-driven assistant system designed for preserving and accessing RHIC's scientific legacy data through natural language interfaces.", "motivation": "Preserving valuable data and scientific knowledge from 25 years of operation at RHIC, ensuring its usability for future discovery, reproducibility, and education.", "method": "The paper introduces an AI assistant system using Large Language Models with Retrieval-Augmented Generation and Model Context Protocol to index and interact with RHIC's experimental data.", "result": "The deployment highlights successful integration across experiments, efficient computational performance, and a sustainable architecture for long-term data accessibility.", "conclusion": "Modern AI/ML tools enhance the usability and discoverability of legacy scientific data, ensuring its preservation for future advancements."}}
{"id": "2509.10132", "pdf": "https://arxiv.org/pdf/2509.10132", "abs": "https://arxiv.org/abs/2509.10132", "authors": ["Nour Jamoussi", "Giuseppe Serra", "Photios A. Stavrou", "Marios Kountouris"], "title": "Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian Federated Learning (BFL) combines uncertainty modeling with\ndecentralized training, enabling the development of personalized and reliable\nmodels under data heterogeneity and privacy constraints. Existing approaches\ntypically rely on Markov Chain Monte Carlo (MCMC) sampling or variational\ninference, often incorporating personalization mechanisms to better adapt to\nlocal data distributions. In this work, we propose an information-geometric\nprojection framework for personalization in parametric BFL. By projecting the\nglobal model onto a neighborhood of the user's local model, our method enables\na tunable trade-off between global generalization and local specialization.\nUnder mild assumptions, we show that this projection step is equivalent to\ncomputing a barycenter on the statistical manifold, allowing us to derive\nclosed-form solutions and achieve cost-free personalization. We apply the\nproposed approach to a variational learning setup using the Improved\nVariational Online Newton (IVON) optimizer and extend its application to\ngeneral aggregation schemes in BFL. Empirical evaluations under heterogeneous\ndata distributions confirm that our method effectively balances global and\nlocal performance with minimal computational overhead.", "AI": {"tldr": "The paper introduces an information-geometric projection approach for personalization in Bayesian Federated Learning (BFL), enabling a trade-off between global generalization and local specialization.", "motivation": "The need to address data heterogeneity and privacy concerns in decentralized learning while maintaining personalized and reliable models.", "method": "An information-geometric projection framework is proposed to tune trade-offs between global and local performance efficiently and cost-free, implemented using a variational approach with the IVON optimizer.", "result": "Empirical tests show the proposed method effectively balances global and local performance under heterogeneous data with minimal computational cost.", "conclusion": "The method facilitates efficient personalization in BFL while maintaining computational efficiency and adaptability to heterogeneous environments."}}
{"id": "2509.09852", "pdf": "https://arxiv.org/pdf/2509.09852", "abs": "https://arxiv.org/abs/2509.09852", "authors": ["Chuyuan Li", "Austin Xu", "Shafiq Joty", "Giuseppe Carenini"], "title": "Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization", "categories": ["cs.CL"], "comment": null, "summary": "A key challenge in Multi-Document Summarization (MDS) is effectively\nintegrating information from multiple sources while maintaining coherence and\ntopical relevance. While Large Language Models have shown impressive results in\nsingle-document summarization, their performance on MDS still leaves room for\nimprovement. In this paper, we propose a topic-guided reinforcement learning\napproach to improve content selection in MDS. We first show that explicitly\nprompting models with topic labels enhances the informativeness of the\ngenerated summaries. Building on this insight, we propose a novel topic reward\nwithin the Group Relative Policy Optimization (GRPO) framework to measure topic\nalignment between the generated summary and source documents. Experimental\nresults on the Multi-News and Multi-XScience datasets demonstrate that our\nmethod consistently outperforms strong baselines, highlighting the\neffectiveness of leveraging topical cues in MDS.", "AI": {"tldr": "This paper introduces a topic-guided reinforcement learning approach to improve multi-document summarization (MDS), with experiments showing enhanced performance compared to baselines.", "motivation": "The motivation is to address the challenge of effectively integrating information from multiple documents while preserving coherence and relevance in MDS, where existing large language models underperform.", "method": "The paper proposes a topic-guided reinforcement learning method utilizing Group Relative Policy Optimization (GRPO) with a novel topic reward to align generated summaries with source document topics.", "result": "The proposed approach outperforms strong baselines in experiments conducted on the Multi-News and Multi-XScience datasets.", "conclusion": "Leveraging topical cues can significantly enhance multi-document summarization performance, as demonstrated by the new reinforcement learning framework."}}
{"id": "2509.10005", "pdf": "https://arxiv.org/pdf/2509.10005", "abs": "https://arxiv.org/abs/2509.10005", "authors": ["Xiaodong Guo", "Tong Liu", "Yike Li", "Zi'ang Lin", "Zhihong Deng"], "title": "TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion", "categories": ["cs.CV"], "comment": null, "summary": "RGB-thermal (RGB-T) semantic segmentation improves the environmental\nperception of autonomous platforms in challenging conditions. Prevailing models\nemploy encoders pre-trained on RGB images to extract features from both RGB and\ninfrared inputs, and design additional modules to achieve cross-modal feature\nfusion. This results in limited thermal feature extraction and suboptimal\ncross-modal fusion, while the redundant encoders further compromises the\nmodel's real-time efficiency. To address the above issues, we propose TUNI,\nwith an RGB-T encoder consisting of multiple stacked blocks that simultaneously\nperform multi-modal feature extraction and cross-modal fusion. By leveraging\nlarge-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder\nlearns to integrate feature extraction and fusion in a unified manner. By\nslimming down the thermal branch, the encoder achieves a more compact\narchitecture. Moreover, we introduce an RGB-T local module to strengthen the\nencoder's capacity for cross-modal local feature fusion. The RGB-T local module\nemploys adaptive cosine similarity to selectively emphasize salient consistent\nand distinct local features across RGB-T modalities. Experimental results show\nthat TUNI achieves competitive performance with state-of-the-art models on FMB,\nPST900 and CART, with fewer parameters and lower computational cost. Meanwhile,\nit achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its\nreal-time capability in deployment. Codes are available at\nhttps://github.com/xiaodonguo/TUNI.", "AI": {"tldr": "This paper presents TUNI, an efficient RGB-T semantic segmentation approach that unifies multimodal feature extraction and fusion while reducing computational costs and achieving real-time performance.", "motivation": "To address the challenges of limited thermal feature extraction, suboptimal cross-modal fusion, and reduced real-time efficiency in existing RGB-T semantic segmentation models.", "method": "This paper introduces the TUNI model, which employs an RGB-T encoder built with stacked blocks for simultaneous multimodal feature extraction and cross-modal fusion. It integrates large-scale pre-training using RGB and pseudo-thermal data, a slimmed-down thermal branch for a compact architecture, and an RGB-T local module that uses adaptive cosine similarity for enhancing local feature fusion.", "result": "TUNI demonstrates competitive performance on FMB, PST900, and CART datasets with lower parameter and computational costs compared to state-of-the-art models. It achieves an inference speed of 27 FPS on a Jetson Orin NX, validating its real-time deployment capability.", "conclusion": "TUNI efficiently integrates RGB-T feature extraction and fusion into a unified system, achieving strong performance and real-time potential while addressing computational and thermal feature extraction limitations."}}
{"id": "2509.10284", "pdf": "https://arxiv.org/pdf/2509.10284", "abs": "https://arxiv.org/abs/2509.10284", "authors": ["David Zahr\u00e1dka", "Denisa Mu\u017e\u00edkov\u00e1", "David Woller", "Miroslav Kulich", "Ji\u0159\u00ed \u0160vancara", "Roman Bart\u00e1k"], "title": "A Holistic Architecture for Monitoring and Optimization of Robust Multi-Agent Path Finding Plan Execution", "categories": ["cs.MA", "cs.RO"], "comment": "23 pages, 10 figures", "summary": "The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a\nfleet of agents moving in a shared environment such that the agents reach their\ngoals without colliding with each other. In practice, some of the robots\nexecuting the plan may get delayed, which can introduce collision risk.\nAlthough robust execution methods are used to ensure safety even in the\npresence of delays, the delays may still have a significant impact on the\nduration of the execution. At some point, the accumulated delays may become\nsignificant enough that instead of continuing with the execution of the\noriginal plan, even if it was optimal, there may now exist an alternate plan\nwhich will lead to a shorter execution. However, the problem is how to decide\nwhen to search for the alternate plan, since it is a costly procedure. In this\npaper, we propose a holistic architecture for robust execution of MAPF plans,\nits monitoring and optimization. We exploit a robust execution method called\nAction Dependency Graph to maintain an estimate of the expected execution\nduration during the plan's execution. This estimate is used to predict the\npotential that finding an alternate plan would lead to shorter execution. We\nempirically evaluate the architecture in experiments in a real-time simulator\nwhich we designed to mimic our real-life demonstrator of an autonomous\nwarehouse robotic fleet.", "AI": {"tldr": "The paper addresses handling delays during Multi-Agent Path Finding (MAPF) executions by proposing a system to estimate execution time and decide when to replan.", "motivation": "Delays in robot execution during MAPF can cause inefficiencies and potential collisions, necessitating methods to ensure both safety and efficiency.", "method": "A holistic architecture is proposed, utilizing Action Dependency Graphs to predict alternative plans for improved efficiency during MAPF executions.", "result": "The architecture is shown to effectively predict when replanning is beneficial, using a real-time simulator for validation.", "conclusion": "This framework enhances robust and efficient MAPF execution by dynamically adapting plans based on delays and predicted execution times."}}
{"id": "2509.09689", "pdf": "https://arxiv.org/pdf/2509.09689", "abs": "https://arxiv.org/abs/2509.09689", "authors": ["Himanshu Thakur", "Eshani Agrawal", "Smruthi Mukund"], "title": "Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "A long-standing challenge in developing accurate recommendation models is\nsimulating user behavior, mainly due to the complex and stochastic nature of\nuser interactions. Towards this, one promising line of work has been the use of\nLarge Language Models (LLMs) for simulating user behavior. However, aligning\nthese general-purpose large pre-trained models with user preferences\nnecessitates: (i) effectively and continously parsing large-scale tabular\nuser-item interaction data, (ii) overcoming pre-training-induced inductive\nbiases to accurately learn user specific knowledge, and (iii) achieving the\nformer two at scale for millions of users. While most previous works have\nfocused on complex methods to prompt an LLM or fine-tune it on tabular\ninteraction datasets, our approach shifts the focus to extracting robust\ntextual user representations using a frozen LLM and simulating cost-effective,\nresource-efficient user agents powered by fine-tuned Small Language Models\n(SLMs). Further, we showcase a method for training multiple low-rank adapters\nfor groups of users or \\textit{persona}, striking an optimal balance between\nscalability and performance of user behavior agents. Our experiments provide\ncompelling empirical evidence of the efficacy of our methods, demonstrating\nthat user agents developed using our approach have the potential to bridge the\ngap between offline metrics and real-world performance of recommender systems.", "AI": {"tldr": "This paper proposes a novel approach using Large and Small Language Models (LLMs and SLMs) to simulate user behavior for recommendation systems, focusing on scalability, efficiency, and real-world applicability.", "motivation": "The challenge lies in simulating accurate user behavior due to its complexity and stochastic nature, and previous methods of using LLMs have limitations in scalability, bias correction, and alignment with user-specific preferences.", "method": "The approach combines frozen LLMs for robust textual user representations and fine-tuned SLMs to simulate cost-effective user agents. Additionally, low-rank adapters are trained for groups of users (personas) to balance scalability and performance.", "result": "Experiments demonstrate the effectiveness of the proposed methods, showing that these user agents improve offline-to-real-world performance alignment in recommender systems.", "conclusion": "The proposed approach is efficient, scalable, and has the potential to significantly improve the real-world applicability of recommendation models."}}
{"id": "2509.10151", "pdf": "https://arxiv.org/pdf/2509.10151", "abs": "https://arxiv.org/abs/2509.10151", "authors": ["Riccardo Lunelli", "Angus Nicolson", "Samuel Martin Pr\u00f6ll", "Sebastian Johannes Reinstadler", "Axel Bauer", "Clemens Dlaska"], "title": "BenchECG and xECG: a benchmark and baseline for ECG foundation models", "categories": ["cs.LG", "cs.AI", "I.2.1"], "comment": "32 pages, 4 figures, 22 tables", "summary": "Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to\ndeep learning. Recently, interest has grown in developing foundation models for\nECGs - models that generalise across diverse downstream tasks. However,\nconsistent evaluation has been lacking: prior work often uses narrow task\nselections and inconsistent datasets, hindering fair comparison. Here, we\nintroduce BenchECG, a standardised benchmark comprising a comprehensive suite\nof publicly available ECG datasets and versatile tasks. We also propose xECG,\nan xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,\nwhich achieves the best BenchECG score compared to publicly available\nstate-of-the-art models. In particular, xECG is the only publicly available\nmodel to perform strongly on all datasets and tasks. By standardising\nevaluation, BenchECG enables rigorous comparison and aims to accelerate\nprogress in ECG representation learning. xECG achieves superior performance\nover earlier approaches, defining a new baseline for future ECG foundation\nmodels.", "AI": {"tldr": "The paper introduces BenchECG, a standardized benchmark for evaluating ECG models on diverse datasets and tasks, and proposes xECG, a self-supervised learning model that outperforms existing ones.", "motivation": "The paper aims to address inconsistencies in evaluating foundation models for ECG datasets and tasks, providing a standardized framework to enable fair comparison.", "method": "The authors developed BenchECG, a benchmark suite, and xECG, a recurrent model using self-supervised learning (SimDINOv2).", "result": "BenchECG allows rigorous evaluation across diverse tasks, and xECG achieves top performance across all datasets, setting a new standard among models.", "conclusion": "BenchECG and xECG standardize comparison for ECG foundation models and establish new baselines, paving the way for accelerated progress in the field."}}
{"id": "2509.09871", "pdf": "https://arxiv.org/pdf/2509.09871", "abs": "https://arxiv.org/abs/2509.09871", "authors": ["Basti\u00e1n Gonz\u00e1lez-Bustamante", "Nando Verelst", "Carla Cisternas"], "title": "Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case", "categories": ["cs.CL", "cs.AI", "68T50 (Primary) 91F10 (Secondary)"], "comment": "Working paper: 18 pages, 4 tables, 2 figures", "summary": "Large Language Models (LLMs) offer promising avenues for methodological and\napplied innovations in survey research by using synthetic respondents to\nemulate human answers and behaviour, potentially mitigating measurement and\nrepresentation errors. However, the extent to which LLMs recover aggregate item\ndistributions remains uncertain and downstream applications risk reproducing\nsocial stereotypes and biases inherited from training data. We evaluate the\nreliability of LLM-generated synthetic survey responses against ground-truth\nhuman responses from a Chilean public opinion probabilistic survey.\nSpecifically, we benchmark 128 prompt-model-question triplets, generating\n189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,\nprecision, recall, and F1-score) in a meta-analysis across 128\nquestion-subsample pairs to test for biases along key sociodemographic\ndimensions. The evaluation spans OpenAI's GPT family and o-series reasoning\nmodels, as well as Llama and Qwen checkpoints. Three results stand out. First,\nsynthetic responses achieve excellent performance on trust items (F1-score and\naccuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform\ncomparably on this task. Third, synthetic-human alignment is highest among\nrespondents aged 45-59. Overall, LLM-based synthetic samples approximate\nresponses from a probabilistic sample, though with substantial item-level\nheterogeneity. Capturing the full nuance of public opinion remains challenging\nand requires careful calibration and additional distributional tests to ensure\nalgorithmic fidelity and reduce errors.", "AI": {"tldr": "The paper assesses the reliability of Large Language Models (LLMs) in generating synthetic survey responses, comparing them to human responses from a Chilean survey. Findings indicate high performance on trust-related items but variability across different sociodemographic dimensions.", "motivation": "To explore whether LLMs can emulate human responses in survey research, reducing errors and biases, while analyzing their reliability and potential biases in synthetic responses.", "method": "The study compared synthetic responses from various LLMs (e.g., GPT, Llama) to human responses in a Chilean public opinion survey. A meta-analysis of 128 question-subsample pairs was conducted using metrics like accuracy, precision, recall, and F1-score, focusing on biases across sociodemographic dimensions.", "result": "The analysis found strong performance for trust-related items (accuracy and F1 > 0.90) and observed that models like GPT-4o, GPT-4o-mini, and Llama 4 Maverick performed similarly. Alignment was highest among respondents aged 45-59, but significant item-level heterogeneity was noted.", "conclusion": "LLMs show promise in approximating human survey responses but struggle with item-level nuances, requiring additional calibration and testing for better alignment and reduction of algorithmic errors."}}
{"id": "2509.10006", "pdf": "https://arxiv.org/pdf/2509.10006", "abs": "https://arxiv.org/abs/2509.10006", "authors": ["Masaki Akiba", "Shumpei Takezaki", "Daichi Haraguchi", "Seiichi Uchida"], "title": "Few-Part-Shot Font Generation", "categories": ["cs.CV"], "comment": "ICDAR 2025 Workshop on Machine Learning", "summary": "This paper proposes a novel model of few-part-shot font generation, which\ndesigns an entire font based on a set of partial design elements, i.e., partial\nshapes. Unlike conventional few-shot font generation, which requires entire\ncharacter shapes for a couple of character classes, our approach only needs\npartial shapes as input. The proposed model not only improves the efficiency of\nfont creation but also provides insights into how partial design details\ninfluence the entire structure of the individual characters.", "AI": {"tldr": "The paper introduces a new model for generating fonts using partial character designs instead of complete character shapes.", "motivation": "To address the inefficiency of traditional font generation methods requiring entire character shapes for few-shot learning.", "method": "A few-part-shot font generation model that uses partial design elements to create complete fonts.", "result": "The model improves font creation efficiency and provides understanding of the influence of partial designs on complete structures.", "conclusion": "The approach enhances font generation capabilities and offers insights into design influence, showing potential for practical applications."}}
{"id": "2509.10353", "pdf": "https://arxiv.org/pdf/2509.10353", "abs": "https://arxiv.org/abs/2509.10353", "authors": ["Davide Gorbani", "Mohamed Elobaid", "Giuseppe L'Erario", "Hosameldin Awadalla Omer Mohamed", "Daniele Pucci"], "title": "Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "8 pages, 3 figures", "summary": "This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework\nthat combines physics-based models with data-driven representations of unknown\ndynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium\nformulation, the method enables tracking of changing, potentially unreachable\nsetpoints while explicitly handling measurement noise through slack variables\nand regularization. We provide guarantees of recursive feasibility and\npractical stability under input-output constraints for a specific class of\nreference signals. The approach is validated on the iRonCub flying humanoid\nrobot, integrating analytical momentum models with data-driven turbine\ndynamics. Simulations show improved tracking and robustness compared to a\npurely model-based MPC, while maintaining real-time feasibility.", "AI": {"tldr": "The study proposes a hybrid control framework (DFMPC) combining physics-based and data-driven methods to enhance tracking, stability, and robustness for dynamic systems like flying humanoid robots under realistic conditions.", "motivation": "Tackling challenges in dynamic system control, such as handling unknown dynamics, unreachable setpoints, and measurement noise, while ensuring stability and feasibility.", "method": "Developed DFMPC using physics-based models complemented by data-driven representations; incorporated Willems' Fundamental Lemma, artificial equilibrium, slack variables, and regularization techniques.", "result": "DFMPC exhibited improved tracking performance and robustness when tested on the iRonCub humanoid robot, outperforming traditional model-based MPC in simulations.", "conclusion": "The proposed framework enhances tracking, feasibility, and stability in dynamic systems, making it a promising tool for real-time robotics applications involving unknown dynamics."}}
{"id": "2509.09691", "pdf": "https://arxiv.org/pdf/2509.09691", "abs": "https://arxiv.org/abs/2509.09691", "authors": ["Aleksandr Listopad"], "title": "Wave-Based Semantic Memory with Resonance-Based Retrieval: A Phase-Aware Alternative to Vector Embedding Stores", "categories": ["cs.IR", "cs.AI", "cs.DB", "68T05 (Primary), 42C10, 94A12 (Secondary)", "I.2.6; H.2.4; H.3.3"], "comment": "9 pages, 6 figures", "summary": "Conventional vector-based memory systems rely on cosine or inner product\nsimilarity within real-valued embedding spaces. While computationally\nefficient, such approaches are inherently phase-insensitive and limited in\ntheir ability to capture resonance phenomena crucial for meaning\nrepresentation. We propose Wave-Based Semantic Memory, a novel framework that\nmodels knowledge as wave patterns $\\psi(x) = A(x) e^{i\\phi(x)}$ and retrieves\nit through resonance-based interference. This approach preserves both amplitude\nand phase information, enabling more expressive and robust semantic similarity.\nWe demonstrate that resonance-based retrieval achieves higher discriminative\npower in cases where vector methods fail, including phase shifts, negations,\nand compositional queries. Our implementation, ResonanceDB, shows scalability\nto millions of patterns with millisecond latency, positioning wave-based memory\nas a viable alternative to vector stores for AGI-oriented reasoning and\nknowledge representation.", "AI": {"tldr": "The paper presents a novel framework, Wave-Based Semantic Memory, which uses wave patterns instead of conventional vector-based embeddings to enhance semantic similarity retrieval.", "motivation": "To address the limitations of vector-based memory systems that fail to capture resonance phenomena and are phase-insensitive in knowledge representation.", "method": "The framework models knowledge as wave patterns and uses resonance-based interference for retrieval. Amplitude and phase information is preserved, enabling a more expressive semantic similarity.", "result": "The proposed system outperforms traditional vector methods in discriminative tasks like phase shifts, negations, and compositional queries. An implementation, ResonanceDB, scales efficiently to millions of patterns with millisecond latency.", "conclusion": "Wave-based memory offers a more robust and expressive alternative for semantic retrieval, demonstrating scalability and promise for AGI-related reasoning tasks."}}
{"id": "2509.09969", "pdf": "https://arxiv.org/pdf/2509.09969", "abs": "https://arxiv.org/abs/2509.09969", "authors": ["Zhitian Hou", "Zihan Ye", "Nanli Zeng", "Tianyong Hao", "Kun Zeng"], "title": "Large Language Models Meet Legal Artificial Intelligence: A Survey", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have significantly advanced the development of\nLegal Artificial Intelligence (Legal AI) in recent years, enhancing the\nefficiency and accuracy of legal tasks. To advance research and applications of\nLLM-based approaches in legal domain, this paper provides a comprehensive\nreview of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and\nalso gather 15 benchmarks and 29 datasets to evaluate different legal\ncapabilities. Additionally, we analyse the challenges and discuss future\ndirections for LLM-based approaches in the legal domain. We hope this paper\nprovides a systematic introduction for beginners and encourages future research\nin this field. Resources are available at\nhttps://github.com/ZhitianHou/LLMs4LegalAI.", "AI": {"tldr": "This paper reviews LLM applications in legal AI, analyzing 16 LLMs/47 frameworks for legal tasks, benchmarking with 15 benchmarks/29 datasets, and exploring challenges and future directions.", "motivation": "To advance LLM research and applications in the legal domain and guide beginners in the field.", "method": "Comprehensive review of existing LLMs, frameworks, benchmarks, and datasets for legal tasks.", "result": "Identifies and collects resources (16 LLMs, 47 frameworks, 15 benchmarks, 29 datasets) and discusses challenges and future directions.", "conclusion": "The paper aims to systematically introduce legal AI using LLMs and inspire further research in the domain."}}
{"id": "2509.10163", "pdf": "https://arxiv.org/pdf/2509.10163", "abs": "https://arxiv.org/abs/2509.10163", "authors": ["Francisco Javier Esono Nkulu Andong", "Qi Min"], "title": "Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "As sixth-generation (6G) networks move toward ultra-dense, intelligent edge\nenvironments, efficient resource management under stringent privacy, mobility,\nand energy constraints becomes critical. This paper introduces a novel\nFederated Multi-Agent Reinforcement Learning (Fed-MARL) framework that\nincorporates cross-layer orchestration of both the MAC layer and application\nlayer for energy-efficient, privacy-preserving, and real-time resource\nmanagement across heterogeneous edge devices. Each agent uses a Deep Recurrent\nQ-Network (DRQN) to learn decentralized policies for task offloading, spectrum\naccess, and CPU energy adaptation based on local observations (e.g., queue\nlength, energy, CPU usage, and mobility). To protect privacy, we introduce a\nsecure aggregation protocol based on elliptic curve Diffie Hellman key\nexchange, which ensures accurate model updates without exposing raw data to\nsemi-honest adversaries. We formulate the resource management problem as a\npartially observable multi-agent Markov decision process (POMMDP) with a\nmulti-objective reward function that jointly optimizes latency, energy\nefficiency, spectral efficiency, fairness, and reliability under 6G-specific\nservice requirements such as URLLC, eMBB, and mMTC. Simulation results\ndemonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines\nin task success rate, latency, energy efficiency, and fairness, while ensuring\nrobust privacy protection and scalability in dynamic, resource-constrained 6G\nedge networks.", "AI": {"tldr": "The paper proposes a Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework for efficient and privacy-preserving resource management in 6G edge networks.", "motivation": "To address critical resource management challenges in ultra-dense, intelligent 6G edge environments, particularly under constraints of privacy, mobility, and energy.", "method": "A novel Fed-MARL framework is introduced, leveraging Deep Recurrent Q-Networks (DRQN) and a secure aggregation protocol for decentralized and privacy-preserving resource management.", "result": "The framework significantly improves task success rate, latency, energy efficiency, and fairness while ensuring privacy and scalability in resource-constrained 6G environments.", "conclusion": "Fed-MARL proves effective for achieving energy-efficient, real-time resource management while meeting 6G-specific service requirements such as URLLC, eMBB, and mMTC."}}
{"id": "2509.09990", "pdf": "https://arxiv.org/pdf/2509.09990", "abs": "https://arxiv.org/abs/2509.09990", "authors": ["Guixian Xu", "Zeli Su", "Ziyin Zhang", "Jianing Liu", "XU Han", "Ting Zhang", "Yushuang Dong"], "title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China", "categories": ["cs.CL"], "comment": null, "summary": "Minority languages in China, such as Tibetan, Uyghur, and Traditional\nMongolian, face significant challenges due to their unique writing systems,\nwhich differ from international standards. This discrepancy has led to a severe\nlack of relevant corpora, particularly for supervised tasks like headline\ngeneration. To address this gap, we introduce a novel dataset, Chinese Minority\nHeadline Generation (CMHG), which includes 100,000 entries for Tibetan, and\n50,000 entries each for Uyghur and Mongolian, specifically curated for headline\ngeneration tasks. Additionally, we propose a high-quality test set annotated by\nnative speakers, designed to serve as a benchmark for future research in this\ndomain. We hope this dataset will become a valuable resource for advancing\nheadline generation in Chinese minority languages and contribute to the\ndevelopment of related benchmarks.", "AI": {"tldr": "The paper tackles the challenge of lack of corpora for headline generation in Chinese minority languages by introducing CMHG, a novel dataset and benchmark.", "motivation": "To address the lack of resources and corpora for supervised tasks like headline generation in Chinese minority languages due to their unique writing systems.", "method": "The authors curated a novel dataset, CMHG, comprising 100,000 Tibetan entries and 50,000 entries each for Uyghur and Mongolian. Additionally, they created a high-quality, native-speaker-annotated test set for benchmarking.", "result": "The CMHG dataset and test set provide a solid foundation for headline generation tasks in Tibetan, Uyghur, and Mongolian, enabling more robust research in these areas.", "conclusion": "This work contributes valuable resources and benchmarks for advancing headline generation and linguistic research in Chinese minority languages."}}
{"id": "2509.10024", "pdf": "https://arxiv.org/pdf/2509.10024", "abs": "https://arxiv.org/abs/2509.10024", "authors": ["Danling Cao"], "title": "Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images", "categories": ["cs.CV"], "comment": "This work was completed during the author's MPhil studies at the\n  University of Manchester", "summary": "Recovering 3D face models from 2D in-the-wild images has gained considerable\nattention in the computer vision community due to its wide range of potential\napplications. However, the lack of ground-truth labeled datasets and the\ncomplexity of real-world environments remain significant challenges. In this\nchapter, we propose a convolutional neural network-based approach, the\nHierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face\nmodels from single in-the-wild images. Our model predicts detailed facial\ngeometry, texture, pose, and illumination parameters from a single image.\nSpecifically, we employ a pre-trained hierarchical backbone network and\nintroduce multi-level attention mechanisms at different stages of 2D face image\nfeature extraction. A semi-supervised training strategy is employed,\nincorporating 3D Morphable Model (3DMM) parameters from publicly available\ndatasets along with a differentiable renderer, enabling an end-to-end training\nprocess. Extensive experiments, including both comparative and ablation\nstudies, were conducted on two benchmark datasets, AFLW2000-3D and MICC\nFlorence, focusing on 3D face reconstruction and 3D face alignment tasks. The\neffectiveness of the proposed method was evaluated both quantitatively and\nqualitatively.", "AI": {"tldr": "The paper proposes MLANet, a neural network-based model to reconstruct 3D face models from single 2D images. It introduces multi-level attention mechanisms and a semi-supervised training strategy.", "motivation": "Recovering 3D face models from single 2D images is challenging due to lack of labeled datasets and real-world complexity but has many applications.", "method": "The paper proposes MLANet, a CNN-based approach using hierarchical backbones, multi-level attention, 3DMM parameters from datasets, and a differentiable renderer for semi-supervised training.", "result": "MLANet demonstrated effective performance in 3D face reconstruction and alignment tasks across benchmark datasets, validated through extensive experiments.", "conclusion": "The proposed MLANet approach effectively reconstructs detailed 3D face models, handling the complexities of real-world images and providing significant improvements over existing methods."}}
{"id": "2509.10164", "pdf": "https://arxiv.org/pdf/2509.10164", "abs": "https://arxiv.org/abs/2509.10164", "authors": ["Hoshitaro Ohnishi", "Hideo Mukai"], "title": "A Symmetry-Integrated Approach to Surface Code Decoding", "categories": ["cs.LG", "quant-ph"], "comment": "12 pages, 6 figures", "summary": "Quantum error correction, which utilizes logical qubits that are encoded as\nredundant multiple physical qubits to find and correct errors in physical\nqubits, is indispensable for practical quantum computing. Surface code is\nconsidered to be a promising encoding method with a high error threshold that\nis defined by stabilizer generators. However, previous methods have suffered\nfrom the problem that the decoder acquires solely the error probability\ndistribution because of the non-uniqueness of correct prediction obtained from\nthe input. To circumvent this problem, we propose a technique to reoptimize the\ndecoder model by approximating syndrome measurements with a continuous function\nthat is mathematically interpolated by neural network. We evaluated the\nimprovement in accuracy of a multilayer perceptron based decoder for code\ndistances of 5 and 7 as well as for decoders based on convolutional and\nrecurrent neural networks and transformers for a code distance of 5. In all\ncases, the reoptimized decoder gave better accuracy than the original models,\ndemonstrating the universal effectiveness of the proposed method that is\nindependent of code distance or network architecture. These results suggest\nthat re-framing the problem of surface code decoding into a regression problem\nthat can be tackled by deep learning is a useful strategy.", "AI": {"tldr": "This paper proposes a reoptimization technique for quantum error correction decoders using neural networks to improve decoding accuracy, showing universal effectiveness across different architectures.", "motivation": "The motivation is to overcome the issue in quantum error correction where decoders provide ambiguous predictions due to non-uniqueness in input-output mapping.", "method": "The authors re-framed surface code decoding as a regression problem and introduced a technique to approximate syndrome measurements with continuous functions using neural networks.", "result": "The study demonstrated improved decoding accuracy for various network architectures and code distances, proving the effectiveness of the reoptimization technique.", "conclusion": "The proposed reoptimization approach enhances the decoding process universally across network architectures and code distances, making it a promising tool for practical quantum computing applications."}}
{"id": "2509.10004", "pdf": "https://arxiv.org/pdf/2509.10004", "abs": "https://arxiv.org/abs/2509.10004", "authors": ["Ponhvoan Srey", "Xiaobao Wu", "Anh Tuan Luu"], "title": "Unsupervised Hallucination Detection by Inspecting Reasoning Processes", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in EMNLP 2025", "summary": "Unsupervised hallucination detection aims to identify hallucinated content\ngenerated by large language models (LLMs) without relying on labeled data.\nWhile unsupervised methods have gained popularity by eliminating\nlabor-intensive human annotations, they frequently rely on proxy signals\nunrelated to factual correctness. This misalignment biases detection probes\ntoward superficial or non-truth-related aspects, limiting generalizability\nacross datasets and scenarios. To overcome these limitations, we propose IRIS,\nan unsupervised hallucination detection framework, leveraging internal\nrepresentations intrinsic to factual correctness. IRIS prompts the LLM to\ncarefully verify the truthfulness of a given statement, and obtain its\ncontextualized embedding as informative features for training. Meanwhile, the\nuncertainty of each response is considered a soft pseudolabel for truthfulness.\nExperimental results demonstrate that IRIS consistently outperforms existing\nunsupervised methods. Our approach is fully unsupervised, computationally low\ncost, and works well even with few training data, making it suitable for\nreal-time detection.", "AI": {"tldr": "IRIS is an innovative method for detecting hallucinated content from LLMs in an unsupervised manner using internal embeddings and uncertainty-based pseudolabels, outperforming existing methods.", "motivation": "Existing unsupervised approaches for hallucination detection often rely on signals unrelated to factual correctness, leading to biases and reduced effectiveness across different contexts.", "method": "IRIS uses LLM's contextualized embeddings for training and employs uncertainty-based pseudolabels to evaluate statement truthfulness without human annotations.", "result": "Experimental evidence shows that IRIS surpasses other unsupervised techniques in performance, maintaining efficiency even with limited data.", "conclusion": "IRIS is an effective, computationally efficient, and scalable approach for real-time unsupervised hallucination detection, addressing limitations of prior methods."}}
{"id": "2509.10026", "pdf": "https://arxiv.org/pdf/2509.10026", "abs": "https://arxiv.org/abs/2509.10026", "authors": ["Jing Huang", "Zhiya Tan", "Shutao Gong", "Fanwei Zeng", "Jianshu Li"], "title": "LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA", "categories": ["cs.CV"], "comment": "12 Pages, 12 Figures, 2 Tables", "summary": "As large vision language models (VLMs) advance, their capabilities in\nmultilingual visual question answering (mVQA) have significantly improved.\nChain-of-thought (CoT) reasoning has been proven to enhance interpretability\nand complex reasoning. However, most existing approaches rely primarily on\ntextual CoT and provide limited support for multilingual multimodal reasoning,\nconstraining their deployment in real-world applications. To address this gap,\nwe introduce \\textbf{LaV-CoT}, the first Language-aware Visual CoT framework\nwith Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable\nmulti-stage reasoning pipeline consisting of Text Summary with Bounding Box\n(BBox), Language Identification, Spatial Object-level Captioning, and\nStep-by-step Logical Reasoning. Following this reasoning pipeline, we design an\nautomated data curation method that generates multilingual CoT annotations\nthrough iterative generation, correction, and refinement, enabling scalable and\nhigh-quality training data. To improve reasoning and generalization, LaV-CoT\nadopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)\nwith Language-aware Group Relative Policy Optimization (GRPO), guided by\nverifiable multi-aspect rewards including language consistency, structural\naccuracy, and semantic alignment. Extensive evaluations on public datasets\nincluding MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up\nto \\(\\sim\\)9.5\\% accuracy improvements over open-source baselines of similar\nsize and even surpasses models with 2$\\times$ larger scales by \\(\\sim\\)2.6\\%.\nMoreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513\nand Gemini-2.5-flash. We further conducted an online A/B test to validate our\nmethod on real-world data, highlighting its effectiveness for industrial\ndeployment. Our code is available at this link:\n\\href{https://github.com/HJNVR/LaV-CoT}", "AI": {"tldr": "This paper introduces LaV-CoT, a framework for improving multilingual visual question answering (mVQA) with interpretability and robust reasoning, showing superior performance over existing models.", "motivation": "The motivation is to address the gap in multilingual and multimodal reasoning capabilities in current vision language models, particularly their limited ability to perform multilingual Chain-of-Thought (CoT) reasoning.", "method": "LaV-CoT leverages an interpretable multi-stage reasoning pipeline, a data curation method for generating high-quality multilingual CoT datasets, and a two-stage training paradigm combining Supervised Fine-Tuning (SFT) with Language-aware Group Relative Policy Optimization (GRPO) guided by multi-aspect rewards.", "result": "LaV-CoT provides up to ~9.5% accuracy improvement over open-source models of similar size and surpasses even larger and proprietary models. Its performance is validated on public datasets and real-world data through evaluations and online A/B testing.", "conclusion": "LaV-CoT advances multilingual multimodal reasoning in mVQA by providing scalability, interpretability, and superior performance, making it well-suited for industrial applications."}}
{"id": "2509.10167", "pdf": "https://arxiv.org/pdf/2509.10167", "abs": "https://arxiv.org/abs/2509.10167", "authors": ["L\u00e9na\u00efc Chizat"], "title": "The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams", "categories": ["cs.LG", "68T07, 60H30, 34F05"], "comment": null, "summary": "We study the gradient-based training of large-depth residual networks\n(ResNets) from standard random initializations. We show that with a diverging\ndepth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,\nthe training dynamics converges to a Neural Mean ODE training dynamics.\nRemarkably, the limit is independent of the scaling of $M$, covering practical\ncases of, say, Transformers, where $M$ (the number of hidden units or attention\nheads per layer) is typically of the order of $D$. For a residual scale\n$\\Theta_D\\big(\\frac{\\alpha}{LM}\\big)$, we obtain the error bound\n$O_D\\big(\\frac{1}{L}+ \\frac{\\alpha}{\\sqrt{LM}}\\big)$ between the model's output\nand its limit after a fixed number gradient of steps, and we verify empirically\nthat this rate is tight. When $\\alpha=\\Theta(1)$, the limit exhibits complete\nfeature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In\ncontrast, we show that $\\alpha \\to \\infty$ yields a \\lazy ODE regime where the\nMean ODE is linearly parameterized. We then focus on the particular case of\nResNets with two-layer perceptron blocks, for which we study how these scalings\ndepend on the embedding dimension $D$. We show that for this model, the only\nresidual scale that leads to complete feature learning is\n$\\Theta\\big(\\frac{\\sqrt{D}}{LM}\\big)$. In this regime, we prove the error bound\n$O\\big(\\frac{1}{L}+ \\frac{\\sqrt{D}}{\\sqrt{LM}}\\big)$ between the ResNet and its\nlimit after a fixed number of gradient steps, which is also empirically tight.\nOur convergence results rely on a novel mathematical perspective on ResNets :\n(i) due to the randomness of the initialization, the forward and backward pass\nthrough the ResNet behave as the stochastic approximation of certain mean ODEs,\nand (ii) by propagation of chaos (that is, asymptotic independence of the\nunits) this behavior is preserved through the training dynamics.", "AI": {"tldr": "This paper investigates gradient-based training dynamics of deep ResNets, showing convergence to a Neural Mean ODE. It identifies scaling regimes for feature learning and derives tight error bounds.", "motivation": "Understanding training dynamics of deep architectures like ResNets and their resemblance to continuous mean-field dynamics is crucial for optimization and scalability in machine learning.", "method": "The authors employ theoretical analysis and empirical validation to explore scaling laws of ResNets, leveraging novel stochastic approximations and propagation of chaos to model training behavior.", "result": "The study reveals error bounds between ResNet outputs and limits as depth increases and highlights regimes for feature learning versus lazy training dynamics, supported both theoretically and empirically.", "conclusion": "The convergence to Neural Mean ODE dynamics suggests practical principles for scaling and optimizing deep network architectures like ResNets, offering insights into feature learning versus linear parameterizations."}}
{"id": "2509.10010", "pdf": "https://arxiv.org/pdf/2509.10010", "abs": "https://arxiv.org/abs/2509.10010", "authors": ["Adnan Ahmad", "Philine Kowol", "Stefan Hillmann", "Sebastian M\u00f6ller"], "title": "Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "In this paper, we provide an extensive analysis of multi-label intent\nclassification using Large Language Models (LLMs) that are open-source,\npublicly available, and can be run in consumer hardware. We use the MultiWOZ\n2.1 dataset, a benchmark in the dialogue system domain, to investigate the\nefficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,\nMistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot\nsetup, giving 20 examples in the prompt with some instructions. Our approach\nfocuses on the differences in performance of these models across several\nperformance metrics by methodically assessing these models on multi-label\nintent classification tasks. Additionally, we compare the performance of the\ninstruction-based fine-tuning approach with supervised learning using the\nsmaller transformer model BertForSequenceClassification as a baseline. To\nevaluate the performance of the models, we use evaluation metrics like\naccuracy, precision, and recall as well as micro, macro, and weighted F1 score.\nWe also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1\noutperforms two other generative models on 11 intent classes out of 14 in terms\nof F-Score, with a weighted average of 0.50. It also has relatively lower\nHumming Loss and higher Jaccard Similarity, making it the winning model in the\nfew-shot setting. We find BERT based supervised classifier having superior\nperformance compared to the best performing few-shot generative LLM. The study\nprovides a framework for small open-source LLMs in detecting complex\nmulti-intent dialogues, enhancing the Natural Language Understanding aspect of\ntask-oriented chatbots.", "AI": {"tldr": "This paper analyzes the performance of open-source large language models (LLMs) for multi-label intent classification on the MultiWOZ 2.1 dataset, comparing few-shot learning with supervised learning using BERT-based models.", "motivation": "To evaluate the effectiveness of small, open-source LLMs in multi-label intent classification tasks, focusing on their feasibility for consumer hardware and applicability in task-oriented chatbots.", "method": "Few-shot learning was utilized with 20 example prompts using three pre-trained LLMs (LLama2-7B-hf, Mistral-7B-v0.1, and Yi-6B) and was compared against supervised learning using BertForSequenceClassification as a baseline. Metrics such as F1 scores, Jaccard Similarity, and Hamming Loss, among others, were used for evaluation.", "result": "Mistral-7B-v0.1 performed best among LLMs on 11 out of 14 intent classes in a few-shot setup, achieving a weighted F1 score of 0.50. However, the BERT-based supervised approach outperformed even the best LLM in this study.", "conclusion": "The results showcase the potential and limitations of small open-source LLMs for multi-intent dialogue systems, emphasizing the advantage of supervised learning for higher performance but highlighting the feasibility of LLMs in resource-constrained scenarios."}}
{"id": "2509.10058", "pdf": "https://arxiv.org/pdf/2509.10058", "abs": "https://arxiv.org/abs/2509.10058", "authors": ["Sung-Lin Tsai", "Bo-Lun Huang", "Yu Ting Shen", "Cheng Yu Yeo", "Chiang Tseng", "Bo-Kai Ruan", "Wen-Sheng Lien", "Hong-Han Shuai"], "title": "Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation", "categories": ["cs.CV"], "comment": "Accepted to ACM Multimedia 2025 (MM '25)", "summary": "Accurate color alignment in text-to-image (T2I) generation is critical for\napplications such as fashion, product visualization, and interior design, yet\ncurrent diffusion models struggle with nuanced and compound color terms (e.g.,\nTiffany blue, lime green, hot pink), often producing images that are misaligned\nwith human intent. Existing approaches rely on cross-attention manipulation,\nreference images, or fine-tuning but fail to systematically resolve ambiguous\ncolor descriptions. To precisely render colors under prompt ambiguity, we\npropose a training-free framework that enhances color fidelity by leveraging a\nlarge language model (LLM) to disambiguate color-related prompts and guiding\ncolor blending operations directly in the text embedding space. Our method\nfirst employs a large language model (LLM) to resolve ambiguous color terms in\nthe text prompt, and then refines the text embeddings based on the spatial\nrelationships of the resulting color terms in the CIELAB color space. Unlike\nprior methods, our approach improves color accuracy without requiring\nadditional training or external reference images. Experimental results\ndemonstrate that our framework improves color alignment without compromising\nimage quality, bridging the gap between text semantics and visual generation.", "AI": {"tldr": "The paper proposes a novel, training-free framework that leverages large language models (LLMs) and text embedding manipulation to enhance color alignment in text-to-image generation, addressing issues with ambiguous color terms.", "motivation": "Existing diffusion models struggle with accurately rendering nuanced and compound color terms in text-to-image generation, which is crucial for specific applications like fashion or product visualization.", "method": "The proposed method resolves ambiguous color terms using a large language model (LLM), refines the text embeddings spatially in CIELAB color space, and avoids reliance on additional training or external reference images.", "result": "The framework significantly enhances color fidelity in generated images without compromising image quality, surpassing prior methods in handling ambiguous color terms.", "conclusion": "This approach bridges the gap between textual semantics and visual generation, offering improved color alignment without requiring additional training or resources."}}
{"id": "2509.10186", "pdf": "https://arxiv.org/pdf/2509.10186", "abs": "https://arxiv.org/abs/2509.10186", "authors": ["Benjamin Holzschuh", "Georg Kohl", "Florian Redinger", "Nils Thuerey"], "title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context", "categories": ["cs.LG"], "comment": null, "summary": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.", "AI": {"tldr": "The paper introduces a hybrid CNN-Transformer framework for learning deterministic and probabilistic neural surrogates in high-resolution 3D physics simulations, capable of handling complex PDE dynamics with low computational cost.", "motivation": "To develop a scalable and efficient neural network model that can accurately learn and handle the dynamics of high-resolution 3D physics simulations, especially for diverse PDEs.", "method": "The authors propose a hybrid CNN-Transformer architecture that allows pretraining on small simulation patches and fuses them for global solutions. This approach leverages a sequence-to-sequence model to handle long-range dependencies efficiently.", "result": "The proposed method outperforms existing architectures in accuracy and speed for 14 PDE types and scales to resolutions of 512^3, including modeling isotropic turbulence and capturing flow statistics in probabilistic setups.", "conclusion": "The framework demonstrated robustness, scalability, and versatility for deterministic and probabilistic 3D physics simulation tasks, suggesting significant potential for high-performance large-scale simulations."}}
{"id": "2509.10035", "pdf": "https://arxiv.org/pdf/2509.10035", "abs": "https://arxiv.org/abs/2509.10035", "authors": ["Laurin Plank", "Armin Zlomuzica"], "title": "Linguistic trajectories of bipolar disorder on social media", "categories": ["cs.CL"], "comment": "Pre-print", "summary": "Language provides valuable markers of affective disorders such as bipolar\ndisorder (BD), yet clinical assessments remain limited in scale. In response,\nanalyses of social media (SM) language have gained prominence due to their high\ntemporal resolution and longitudinal scope. Here, we introduce a method to\ndetermine the timing of users' diagnoses and apply it to study language\ntrajectories from 3 years before to 21 years after BD diagnosis - contrasted\nwith uses reporting unipolar depression (UD) and non-affected users (HC). We\nshow that BD diagnosis is accompanied by pervasive linguistic alterations\nreflecting mood disturbance, psychiatric comorbidity, substance abuse,\nhospitalization, medical comorbidities, unusual thought content, and\ndisorganized thought. We further observe recurring mood-related language\nchanges across two decades after the diagnosis, with a pronounced 12-month\nperiodicity suggestive of seasonal mood episodes. Finally, trend-level evidence\nsuggests an increased periodicity in users estimated to be female. In sum, our\nfindings provide evidence for language alterations in the acute and chronic\nphase of BD. This validates and extends recent efforts leveraging SM for\nscalable monitoring of mental health.", "AI": {"tldr": "The paper examines the analysis of social media language to study bipolar disorder (BD) over an extended period, revealing language changes around diagnosis and recurring mood-related shifts afterward.", "motivation": "To explore scalable methods for tracking affective disorders, such as BD, using social media language due to the limitations of traditional clinical assessments.", "method": "The study uses a novel method to determine diagnosis timing and analyze language in social media posts spanning from three years prior to BD diagnosis to up to 21 years post-diagnosis, comparing with users with unipolar depression (UD) and non-affected individuals (HC).", "result": "The research shows linguistic changes around BD diagnosis related to mood disturbance and other factors, along with recurring seasonal mood-related language shifts for up to two decades. A trend indicates stronger periodicity in individuals estimated to be female.", "conclusion": "The findings validate the use of social media language for understanding BD over acute and chronic phases and underline its potential for scalable mental health monitoring."}}
{"id": "2509.10059", "pdf": "https://arxiv.org/pdf/2509.10059", "abs": "https://arxiv.org/abs/2509.10059", "authors": ["Yue Zhou", "Litong Feng", "Mengcheng Lan", "Xue Yang", "Qingyun Li", "Yiping Ke", "Xue Jiang", "Wayne Zhang"], "title": "Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 16 figures", "summary": "Mathematical reasoning is critical for tasks such as precise distance and\narea computations, trajectory estimations, and spatial analysis in unmanned\naerial vehicle (UAV) based remote sensing, yet current vision-language models\n(VLMs) have not been adequately tested in this domain. To address this gap, we\nintroduce AVI-Math, the first benchmark to rigorously evaluate multimodal\nmathematical reasoning in aerial vehicle imagery, moving beyond simple counting\ntasks to include domain-specific knowledge in areas such as geometry, logic,\nand algebra. The dataset comprises 3,773 high-quality vehicle-related questions\ncaptured from UAV views, covering 6 mathematical subjects and 20 topics. The\ndata, collected at varying altitudes and from multiple UAV angles, reflects\nreal-world UAV scenarios, ensuring the diversity and complexity of the\nconstructed mathematical problems. In this paper, we benchmark 14 prominent\nVLMs through a comprehensive evaluation and demonstrate that, despite their\nsuccess on previous multimodal benchmarks, these models struggle with the\nreasoning tasks in AVI-Math. Our detailed analysis highlights significant\nlimitations in the mathematical reasoning capabilities of current VLMs and\nsuggests avenues for future research. Furthermore, we explore the use of\nChain-of-Thought prompting and fine-tuning techniques, which show promise in\naddressing the reasoning challenges in AVI-Math. Our findings not only expose\nthe limitations of VLMs in mathematical reasoning but also offer valuable\ninsights for advancing UAV-based trustworthy VLMs in real-world applications.\nThe code, and datasets will be released at\nhttps://github.com/VisionXLab/avi-math", "AI": {"tldr": "The paper introduces AVI-Math, a benchmark for testing mathematical reasoning in UAV imagery using vision-language models (VLMs), revealing their current limitations and exploring improvement techniques.", "motivation": "Mathematical reasoning is essential in UAV-based remote sensing, but current VLMs lack rigorous evaluation in this domain, necessitating a specialized benchmark.", "method": "The authors developed AVI-Math, a dataset with 3,773 high-quality vehicle-related questions from UAV views, and evaluated 14 prominent VLMs using this benchmark.", "result": "The study found that current VLMs struggle with mathematical reasoning in AVI-Math despite previous success on other benchmarks, and techniques like Chain-of-Thought prompting show potential for improvement.", "conclusion": "Existing VLMs have significant limitations in mathematical reasoning tasks, but this study provides foundational insights and tools for advancing trustworthy multimodal models in UAV contexts."}}
{"id": "2509.10189", "pdf": "https://arxiv.org/pdf/2509.10189", "abs": "https://arxiv.org/abs/2509.10189", "authors": ["Zexu Jin"], "title": "Hadamard-Riemannian Optimization for Margin-Variance Ensemble", "categories": ["cs.LG"], "comment": null, "summary": "Ensemble learning has been widely recognized as a pivotal technique for\nboosting predictive performance by combining multiple base models.\nNevertheless, conventional margin-based ensemble methods predominantly focus on\nmaximizing the expected margin while neglecting the critical role of margin\nvariance, which inherently restricts the generalization capability of the model\nand heightens its vulnerability to overfitting, particularly in noisy or\nimbalanced datasets. Additionally, the conventional approach of optimizing\nensemble weights within the probability simplex often introduces computational\ninefficiency and scalability challenges, complicating its application to\nlarge-scale problems. To tackle these limitations, this paper introduces a\nnovel ensemble learning framework that explicitly incorporates margin variance\ninto the loss function. Our method jointly optimizes the negative expected\nmargin and its variance, leading to enhanced robustness and improved\ngeneralization performance. Moreover, by reparameterizing the ensemble weights\nonto the unit sphere, we substantially simplify the optimization process and\nimprove computational efficiency. Extensive experiments conducted on multiple\nbenchmark datasets demonstrate that the proposed approach consistently\noutperforms traditional margin-based ensemble techniques, underscoring its\neffectiveness and practical utility.", "AI": {"tldr": "The paper introduces a novel ensemble learning framework that optimizes margin variance and computational efficiency, outperforming traditional methods.", "motivation": "Current margin-based ensemble techniques often ignore margin variance, limiting their generalization and increasing vulnerability to overfitting, especially in noisy or imbalanced datasets. Computational inefficiencies in optimizing ensemble weights further complicate their scalability to large-scale problems.", "method": "A novel framework that incorporates margin variance into the loss function, jointly optimizing the negative expected margin and its variance. Ensemble weights are reparameterized onto the unit sphere for computational simplicity.", "result": "Experiments on benchmark datasets show the method outperforms conventional margin-based ensemble approaches, proving better robustness and generalization ability.", "conclusion": "The proposed framework significantly addresses the limitations of conventional ensemble methods by increasing robustness, generalization, and efficiency, showcasing practical implications for real-world datasets."}}
{"id": "2509.10040", "pdf": "https://arxiv.org/pdf/2509.10040", "abs": "https://arxiv.org/abs/2509.10040", "authors": ["Mohamed Basem", "Mohamed Younes", "Seif Ahmed", "Abdelrahman Moustafa"], "title": "!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment", "categories": ["cs.CL"], "comment": "10 Pages , 8 figures , ArabicNLP 2025 , Co-located with EMNLP 2025", "summary": "We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained\nArabic readability assessment, achieving first place in six of six tracks. Our\napproach is a confidence-weighted ensemble of four complementary transformer\nmodels (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with\ndistinct loss functions to capture diverse readability signals. To tackle\nsevere class imbalance and data scarcity, we applied weighted training,\nadvanced preprocessing, SAMER corpus relabeling with our strongest model, and\nsynthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level\nsamples. A targeted post-processing step corrected prediction distribution\nskew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system\nreached 87.5 percent QWK at the sentence level and 87.4 percent at the document\nlevel, demonstrating the power of model and loss diversity, confidence-informed\nfusion, and intelligent augmentation for robust Arabic readability prediction.", "AI": {"tldr": "The paper details MSAs winning approach to the BAREC 2025 Shared Task on Arabic readability, using a hybrid ensemble of transformer models to achieve top results in all tracks.", "motivation": "To tackle fine-grained Arabic readability assessment amidst challenges like class imbalance and scarce data, and to introduce superior methodologies for reliable prediction.", "method": "A confidence-weighted ensemble of AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT, fine-tuned with diverse loss functions, combined with advanced techniques like synthetic data generation, SAMER corpus relabeling, and targeted post-processing.", "result": "Achieved top performance in all six tracks with Quadratic Weighted Kappa (QWK) of 87.5% at the sentence level and 87.4% at the document level.", "conclusion": "Model diversity, confidence-informed fusion, and innovative data augmentation strategies are effective for robust Arabic readability prediction, as demonstrated by the team's superior performance."}}
{"id": "2509.10080", "pdf": "https://arxiv.org/pdf/2509.10080", "abs": "https://arxiv.org/abs/2509.10080", "authors": ["Minsang Kong", "Myeongjun Kim", "Sang Gu Kang", "Sang Hun Lee"], "title": "BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals", "categories": ["cs.CV", "I.2.9; I.4.8"], "comment": "Submitted to IEEE Transactions on Intelligent Transportation Systems\n  (under review)", "summary": "In autonomous driving, trajectory prediction is essential for ensuring safe\nand efficient navigation. To improve prediction accuracy, recent approaches\noften rely on pre-built high-definition (HD) maps or real-time local map\nconstruction modules to incorporate static environmental information. However,\npre-built HD maps are limited to specific regions and cannot adapt to transient\nchanges. In addition, local map construction modules, which recognize only\npredefined elements, may fail to capture critical scene details or introduce\nerrors that degrade prediction performance. To overcome these limitations, we\npropose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory\nprediction framework that operates directly in the bird's-eye view (BEV) space\nutilizing real-time sensor data without relying on any pre-built maps. The\nBEVTraj leverages deformable attention to efficiently extract relevant context\nfrom dense BEV features. Furthermore, we introduce a Sparse Goal Candidate\nProposal (SGCP) module, which enables full end-to-end prediction without\nrequiring any post-processing steps. Extensive experiments demonstrate that the\nBEVTraj achieves performance comparable to state-of-the-art HD map-based models\nwhile offering greater flexibility by eliminating the dependency on pre-built\nmaps. The source code is available at https://github.com/Kongminsang/bevtraj.", "AI": {"tldr": "The paper introduces BEVTraj, a framework for autonomous driving trajectory prediction using bird's-eye view (BEV) space, which eliminates the reliance on pre-built maps and achieves state-of-the-art results.", "motivation": "To address the limitations of pre-built HD maps and local map construction modules in trajectory prediction, particularly their inability to adapt to transient changes or capture critical environmental details accurately.", "method": "The proposed BEVTraj framework directly utilizes real-time sensor data in the bird's-eye view (BEV) space and employs deformable attention for efficient context extraction. It introduces the Sparse Goal Candidate Proposal (SGCP) module for end-to-end prediction without post-processing.", "result": "BEVTraj achieves results on par with state-of-the-art HD map-based models while offering the flexibility of not depending on pre-built maps. Extensive experiments validate its effectiveness.", "conclusion": "BEVTraj provides a flexible and accurate trajectory prediction framework for autonomous driving, overcoming reliance on traditional HD maps and offering robust real-time environmental understanding."}}
{"id": "2509.10227", "pdf": "https://arxiv.org/pdf/2509.10227", "abs": "https://arxiv.org/abs/2509.10227", "authors": ["\u00c1ngel Ladr\u00f3n", "Miguel S\u00e1nchez-Dom\u00ednguez", "Javier Rozal\u00e9n", "Fernando R. S\u00e1nchez", "Javier de Vicente", "Lucas Lacasa", "Eusebio Valero", "Gonzalo Rubio"], "title": "A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures", "categories": ["cs.LG", "physics.app-ph"], "comment": "29 pages, 15 figures", "summary": "Fatigue life prediction is essential in both the design and operational\nphases of any aircraft, and in this sense safety in the aerospace industry\nrequires early detection of fatigue cracks to prevent in-flight failures.\nRobust and precise fatigue life predictors are thus essential to ensure safety.\nTraditional engineering methods, while reliable, are time consuming and involve\ncomplex workflows, including steps such as conducting several Finite Element\nMethod (FEM) simulations, deriving the expected loading spectrum, and applying\ncycle counting techniques like peak-valley or rainflow counting. These steps\noften require collaboration between multiple teams and tools, added to the\ncomputational time and effort required to achieve fatigue life predictions.\nMachine learning (ML) offers a promising complement to traditional fatigue life\nestimation methods, enabling faster iterations and generalization, providing\nquick estimates that guide decisions alongside conventional simulations.\n  In this paper, we present a ML-based pipeline that aims to estimate the\nfatigue life of different aircraft wing locations given the flight parameters\nof the different missions that the aircraft will be operating throughout its\noperational life. We validate the pipeline in a realistic use case of fatigue\nlife estimation, yielding accurate predictions alongside a thorough statistical\nvalidation and uncertainty quantification. Our pipeline constitutes a\ncomplement to traditional methodologies by reducing the amount of costly\nsimulations and, thereby, lowering the required computational and human\nresources.", "AI": {"tldr": "Traditional fatigue life prediction for aircraft requires complex workflows and is resource-intensive; this paper proposes a machine learning-based pipeline validated to provide accurate and faster estimates.", "motivation": "Safety in aerospace requires early detection of fatigue cracks to prevent failures. Traditional fatigue prediction methods are reliable but time-consuming and resource-heavy, warranting exploration of faster, efficient alternatives.", "method": "A machine learning-based pipeline is designed to predict fatigue life across different aircraft wing locations using operational flight parameters. The approach involves accurate statistical validation and uncertainty quantification.", "result": "The pipeline produces accurate fatigue life predictions and demonstrates effective validation in a realistic use case, supporting its viability as a complement to traditional methods.", "conclusion": "ML-based fatigue life prediction can augment traditional approaches, reducing simulation costs and necessary resources while maintaining reliability in safety-critical applications."}}
{"id": "2509.10078", "pdf": "https://arxiv.org/pdf/2509.10078", "abs": "https://arxiv.org/abs/2509.10078", "authors": ["Dongmin Choi", "Woojung Song", "Jongwook Han", "Eun-Ju Lee", "Yohan Jo"], "title": "Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages, 4 figures", "summary": "Researchers have applied established psychometric questionnaires (e.g., BFI,\nPVQ) to measure the personality traits and values reflected in the responses of\nLarge Language Models (LLMs). However, concerns have been raised about applying\nthese human-designed questionnaires to LLMs. One such concern is their lack of\necological validity--the extent to which survey questions adequately reflect\nand resemble real-world contexts in which LLMs generate texts in response to\nuser queries. However, it remains unclear how established questionnaires and\necologically valid questionnaires differ in their outcomes, and what insights\nthese differences may provide. In this paper, we conduct a comprehensive\ncomparative analysis of the two types of questionnaires. Our analysis reveals\nthat established questionnaires (1) yield substantially different profiles of\nLLMs from ecologically valid ones, deviating from the psychological\ncharacteristics expressed in the context of user queries, (2) suffer from\ninsufficient items for stable measurement, (3) create misleading impressions\nthat LLMs possess stable constructs, and (4) yield exaggerated profiles for\npersona-prompted LLMs. Overall, our work cautions against the use of\nestablished psychological questionnaires for LLMs. Our code will be released\nupon publication.", "AI": {"tldr": "A comparison of established psychometric questionnaires versus ecologically valid ones reveals substantial differences in evaluating the personality traits of Large Language Models (LLMs). The study highlights limitations of traditional questionnaires and advises caution in their use for LLMs.", "motivation": "There is a concern about the ecological validity of using human-designed psychometric questionnaires, such as the BFI and PVQ, to evaluate LLMs' personality traits and values, especially as these surveys may not reflect real-world contexts encountered by LLMs.", "method": "The authors performed a comparative analysis between traditional questionnaires and ecologically valid questionnaires to determine differences in their evaluation outcomes for LLMs' psychological characteristics.", "result": "The analysis found that traditional questionnaires yield different profiles from ecologically valid ones, lack stability in measurement, create false impressions of stable constructs in LLMs, and exaggerate traits in persona-prompted models.", "conclusion": "The paper advises against using established psychological questionnaires to evaluate LLMs due to their significant ecological validity issues and plans to release the research code publicly."}}
{"id": "2509.10093", "pdf": "https://arxiv.org/pdf/2509.10093", "abs": "https://arxiv.org/abs/2509.10093", "authors": ["Laura Bragagnolo", "Matteo Terreran", "Leonardo Barcellona", "Stefano Ghidoni"], "title": "Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing", "categories": ["cs.CV"], "comment": "ICIAP 2025", "summary": "Multi-human parsing is the task of segmenting human body parts while\nassociating each part to the person it belongs to, combining instance-level and\npart-level information for fine-grained human understanding. In this work, we\ndemonstrate that, while state-of-the-art approaches achieved notable results on\npublic datasets, they struggle considerably in segmenting people with\noverlapping bodies. From the intuition that overlapping people may appear\nseparated from a different point of view, we propose a novel training framework\nexploiting multi-view information to improve multi-human parsing models under\nocclusions. Our method integrates such knowledge during the training process,\nintroducing a novel approach based on weak supervision on human instances and a\nmulti-view consistency loss. Given the lack of suitable datasets in the\nliterature, we propose a semi-automatic annotation strategy to generate human\ninstance segmentation masks from multi-view RGB+D data and 3D human skeletons.\nThe experiments demonstrate that the approach can achieve up to a 4.20\\%\nrelative improvement on human parsing over the baseline model in occlusion\nscenarios.", "AI": {"tldr": "This paper proposes a novel training framework utilizing multi-view information to enhance multi-human parsing, specifically for scenarios with overlapping bodies.", "motivation": "The motivation is to address the challenge where state-of-the-art multi-human parsing methods struggle to segment overlapping bodies effectively.", "method": "The method involves incorporating multi-view information during training with weak supervision on human instances, a multi-view consistency loss, and a semi-automatic annotation strategy to generate segmentation masks from multi-view RGB+D data and 3D skeletons.", "result": "The approach shows up to a 4.20% relative improvement in human parsing performance under occlusion scenarios compared to baseline models.", "conclusion": "The proposed framework significantly enhances multi-human parsing performance in occluded environments, leveraging multi-view insights effectively."}}
{"id": "2509.09706", "pdf": "https://arxiv.org/pdf/2509.09706", "abs": "https://arxiv.org/abs/2509.09706", "authors": ["Taniya Gidatkar", "Oluwaseun Ajao", "Matthew Shardlow"], "title": "Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks", "categories": ["cs.CR", "cs.AI", "cs.CL", "I.2; H.3.3"], "comment": "8 pages, 4 tables, to appear in proceedings of Recent Advances in\n  Natural Language Processing (RANLP 2025) and ACL Anthology", "summary": "This study evaluates the resilience of large language models (LLMs) against\nadversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.\nUsing systematically designed adversarial tests through TextFooler and\nBERTAttack, we found significant variations in model robustness. RoBERTa-Base\nand FlanT5 demonstrated remarkable resilience, maintaining accuracy even when\nsubjected to sophisticated attacks, with attack success rates of 0%. In\ncontrast. BERT-Base showed considerable vulnerability, with TextFooler\nachieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.\nOur research reveals that while certain LLMs have developed effective defensive\nmechanisms, these safeguards often require substantial computational resources.\nThis study contributes to the understanding of LLM security by identifying\nexisting strengths and weaknesses in current safeguarding approaches and\nproposes practical recommendations for developing more efficient and effective\ndefensive strategies.", "AI": {"tldr": "The paper evaluates the resilience of LLMs (Flan-T5, BERT, and RoBERTa-Base) against adversarial attacks and identifies significant differences in their robustness.", "motivation": "To assess and understand the security of large language models in the face of adversarial attacks.", "method": "The study systematically tested the models Flan-T5, BERT, and RoBERTa-Base using adversarial attack methods like TextFooler and BERTAttack.", "result": "RoBERTa-Base and Flan-T5 showed high resilience with 0% attack success rates, while BERT-Base was highly vulnerable, with TextFooler reducing its accuracy drastically.", "conclusion": "Certain LLMs have robust defenses, though at a computational cost, and the study pushes for developing efficient and effective measures to ensure model security."}}
{"id": "2509.10248", "pdf": "https://arxiv.org/pdf/2509.10248", "abs": "https://arxiv.org/abs/2509.10248", "authors": ["Janis Keuper"], "title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "categories": ["cs.LG"], "comment": null, "summary": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "AI": {"tldr": "This paper evaluates hidden prompt injections in LLM-generated scientific peer reviews, confirming their effectiveness and highlighting inherent acceptance bias.", "motivation": "Investigate the rising usage of LLMs in peer-review and assess the risk and impact of prompt injection manipulations.", "method": "Systematic evaluation of 1k ICLR 2024 paper reviews generated by various LLMs, focusing on effects of prompt injections and acceptance bias.", "result": "Demonstrated high prompt injection effectiveness (up to 100% acceptance scores) and inherent acceptance bias (>95% in many models).", "conclusion": "Prompt injections pose a serious vulnerability, and LLMs exhibit acceptance bias, both significantly affecting discussions on their role in peer-review."}}
{"id": "2509.10087", "pdf": "https://arxiv.org/pdf/2509.10087", "abs": "https://arxiv.org/abs/2509.10087", "authors": ["Mustapha Adamu", "Qi Zhang", "Huitong Pan", "Longin Jan Latecki", "Eduard C. Dragut"], "title": "Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery", "categories": ["cs.CL"], "comment": "ACM SIGIR 2025 Workshop MANILA", "summary": "The growing complexity and volume of climate science literature make it\nincreasingly difficult for researchers to find relevant information across\nmodels, datasets, regions, and variables. This paper introduces a\ndomain-specific Knowledge Graph (KG) built from climate publications and\nbroader scientific texts, aimed at improving how climate knowledge is accessed\nand used. Unlike keyword based search, our KG supports structured, semantic\nqueries that help researchers discover precise connections such as which models\nhave been validated in specific regions or which datasets are commonly used\nwith certain teleconnection patterns. We demonstrate how the KG answers such\nquestions using Cypher queries, and outline its integration with large language\nmodels in RAG systems to improve transparency and reliability in\nclimate-related question answering. This work moves beyond KG construction to\nshow its real world value for climate researchers, model developers, and others\nwho rely on accurate, contextual scientific information.", "AI": {"tldr": "A domain-specific Knowledge Graph was introduced to improve climate science information retrieval, enabling semantic and structured querying.", "motivation": "The paper aims to tackle the problem posed by the growing complexity and volume of climate science literature, which makes it hard for researchers to easily access relevant information.", "method": "The authors created a domain-specific Knowledge Graph from climate publications and scientific texts. They employ Cypher queries for semantic searches and integrate with large language models in RAG systems.", "result": "The Knowledge Graph demonstrated its ability to answer structured queries about climate models, datasets, regions, and teleconnection patterns, illustrating its practical value.", "conclusion": "The work highlights the importance of a domain-specific KG and its integration with advanced AI systems for enhancing access to accurate and contextual climate scientific knowledge."}}
{"id": "2509.10105", "pdf": "https://arxiv.org/pdf/2509.10105", "abs": "https://arxiv.org/abs/2509.10105", "authors": ["Young-rok Cha", "Jeongho Ju", "SunYoung Park", "Jong-Hyeon Lee", "Younghyun Yu", "Youngjune Kim"], "title": "VARCO-VISION-2.0 Technical Report", "categories": ["cs.CV", "cs.CL"], "comment": "19 pages, 1 figure, 14 tables. Technical report for VARCO-VISION-2.0,\n  a Korean-English bilingual VLM in 14B and 1.7B variants. Key features:\n  multi-image understanding, OCR with text localization, improved Korean\n  capabilities", "summary": "We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model\n(VLM) for Korean and English with improved capabilities compared to the\nprevious model VARCO-VISION-14B. The model supports multi-image understanding\nfor complex inputs such as documents, charts, and tables, and delivers\nlayoutaware OCR by predicting both textual content and its spatial location.\nTrained with a four-stage curriculum with memory-efficient techniques, the\nmodel achieves enhanced multimodal alignment, while preserving core language\nabilities and improving safety via preference optimization. Extensive benchmark\nevaluations demonstrate strong spatial grounding and competitive results for\nboth languages, with the 14B model achieving 8th place on the OpenCompass VLM\nleaderboard among models of comparable scale. Alongside the 14B-scale model, we\nrelease a 1.7B version optimized for on-device deployment. We believe these\nmodels advance the development of bilingual VLMs and their practical\napplications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a\nfull-scale 14B model and a lightweight 1.7B model.", "AI": {"tldr": "VARCO-VISION-2.0 is a bilingual vision-language model for Korean and English with enhanced multimodal capabilities, including layout-aware OCR and spatial grounding. Released as a 14B full-scale and 1.7B lightweight model.", "motivation": "Addressing the need for improved bilingual vision-language models with strong multimodal and spatial understanding, alongside practical deployment options.", "method": "A four-stage curriculum training approach with memory-efficient techniques and preference optimization to enhance multimodal alignment and improve safety.", "result": "Demonstrated strong spatial grounding and competitive benchmark results, achieving 8th place on the OpenCompass VLM leaderboard for the 14B model. Released two variants for different scalability needs.", "conclusion": "VARCO-VISION-2.0 advances bilingual VLM capabilities and expands practical applications through its dual-scale release models available on Hugging Face."}}
{"id": "2509.10273", "pdf": "https://arxiv.org/pdf/2509.10273", "abs": "https://arxiv.org/abs/2509.10273", "authors": ["Sahil Sethi", "Kai Sundmacher", "Caroline Ganzer"], "title": "Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning", "categories": ["cs.LG"], "comment": null, "summary": "Ionic liquids (ILs) have emerged as versatile replacements for traditional\nsolvents because their physicochemical properties can be precisely tailored to\nvarious applications. However, accurately predicting key thermophysical\nproperties remains challenging due to the vast chemical design space and the\nlimited availability of experimental data. In this study, we present a\ndata-driven transfer learning framework that leverages a neural recommender\nsystem (NRS) to enable reliable property prediction for ILs using sparse\nexperimental datasets. The approach involves a two-stage process: first,\npre-training NRS models on COSMO-RS-based simulated data at fixed temperature\nand pressure to learn property-specific structural embeddings for cations and\nanions; and second, fine-tuning simple feedforward neural networks using these\nembeddings with experimental data at varying temperatures and pressures. In\nthis work, five essential IL properties are considered: density, viscosity,\nsurface tension, heat capacity, and melting point. The framework supports both\nwithin-property and cross-property knowledge transfer. Notably, pre-trained\nmodels for density, viscosity, and heat capacity are used to fine-tune models\nfor all five target properties, achieving improved performance by a substantial\nmargin for four of them. The model exhibits robust extrapolation to previously\nunseen ILs. Moreover, the final trained models enable property prediction for\nover 700,000 IL combinations, offering a scalable solution for IL screening in\nprocess design. This work highlights the effectiveness of combining simulated\ndata and transfer learning to overcome sparsity in the experimental data.", "AI": {"tldr": "This study introduces a data-driven transfer learning framework to predict key properties of ionic liquids using limited experimental data, leveraging pre-trained models and simple neural networks for improved accuracy.", "motivation": "The motivation is to address the challenge of predicting thermophysical properties of ionic liquids (ILs) efficiently due to the vast chemical design space and scarcity of experimental data.", "method": "A two-stage transfer learning framework: (1) Pre-training neural recommender systems (NRS) on COSMO-RS simulated data for structural embeddings, and (2) Fine-tuning feedforward neural networks with experimental data to predict five IL properties.", "result": "The approach improved prediction accuracy for four out of five IL properties, demonstrated strong extrapolation to unseen ILs, and enabled scalable property predictions for over 700,000 IL combinations.", "conclusion": "The study validates that combining simulated data and transfer learning bridges the gap caused by sparse experimental data, providing a scalable and reliable solution for IL property prediction critical for process design."}}
{"id": "2509.10095", "pdf": "https://arxiv.org/pdf/2509.10095", "abs": "https://arxiv.org/abs/2509.10095", "authors": ["Abdulrahman Allam", "Seif Ahmed", "Ali Hamdi", "Ammar Mohammed"], "title": "Arabic Large Language Models for Medical Text Generation", "categories": ["cs.CL"], "comment": "Published in 2025 4th International Conference on Computer\n  Technologies (ICCTech)", "summary": "Efficient hospital management systems (HMS) are critical worldwide to address\nchallenges such as overcrowding, limited resources, and poor availability of\nurgent health care. Existing methods often lack the ability to provide\naccurate, real-time medical advice, particularly for irregular inputs and\nunderrepresented languages. To overcome these limitations, this study proposes\nan approach that fine-tunes large language models (LLMs) for Arabic medical\ntext generation. The system is designed to assist patients by providing\naccurate medical advice, diagnoses, drug recommendations, and treatment plans\nbased on user input. The research methodology required the collection of a\nunique dataset from social media platforms, capturing real-world medical\nconversations between patients and doctors. The dataset, which includes patient\ncomplaints together with medical advice, was properly cleaned and preprocessed\nto account for multiple Arabic dialects. Fine-tuning state-of-the-art\ngenerative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2\nMedium, optimized the system's ability to generate reliable medical text.\nResults from evaluations indicate that the fine-tuned Mistral-7B model\noutperformed the other models, achieving average BERT (Bidirectional Encoder\nRepresentations from Transformers) Score values in precision, recall, and\nF1-scores of 68.5\\%, 69.08\\%, and 68.5\\%, respectively. Comparative\nbenchmarking and qualitative assessments validate the system's ability to\nproduce coherent and relevant medical replies to informal input. This study\nhighlights the potential of generative artificial intelligence (AI) in\nadvancing HMS, offering a scalable and adaptable solution for global healthcare\nchallenges, especially in linguistically and culturally diverse environments.", "AI": {"tldr": "The paper proposes fine-tuning large language models (LLMs) for Arabic medical text generation to improve hospital management systems, demonstrating the potential of AI in addressing healthcare challenges.", "motivation": "The motivation is to address the inefficiencies in hospital management systems (HMS), such as overcrowding and lack of resources, by providing accurate, real-time medical advice, especially for underrepresented languages like Arabic.", "method": "The authors collected a unique dataset of Arabic medical conversations, cleaned and processed the data for various dialects, and fine-tuned generative models like Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2 Medium to generate reliable medical responses.", "result": "The fine-tuned Mistral-7B model achieved the best performance, with average BERT Score values of 68.5% for precision, 69.08% for recall, and 68.5% for F1-scores, validated through comparative benchmarking and qualitative assessments.", "conclusion": "The study demonstrates the effectiveness of generative AI in supporting HMS and highlights its scalability for addressing global healthcare challenges, especially in linguistically diverse environments."}}
{"id": "2509.10114", "pdf": "https://arxiv.org/pdf/2509.10114", "abs": "https://arxiv.org/abs/2509.10114", "authors": ["MohammadAli Hamidi", "Hadi Amirpour", "Luigi Atzori", "Christian Timmerer"], "title": "A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss", "categories": ["cs.CV"], "comment": null, "summary": "Face image quality assessment (FIQA) plays a critical role in face\nrecognition and verification systems, especially in uncontrolled, real-world\nenvironments. Although several methods have been proposed, general-purpose\nno-reference image quality assessment techniques often fail to capture\nface-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be\ncomputationally intensive, limiting their practical applicability. We propose a\nlightweight and efficient method for FIQA, designed for the perceptual\nevaluation of face images in the wild. Our approach integrates an ensemble of\ntwo compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,\nwith prediction-level fusion via simple averaging. To enhance alignment with\nhuman perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),\ncombining mean squared error (MSE) with a Pearson correlation regularizer. Our\nmethod achieves a strong balance between accuracy and computational cost,\nmaking it suitable for real-world deployment. Experiments on the VQualA FIQA\nbenchmark demonstrate that our model achieves a Spearman rank correlation\ncoefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient\n(PLCC) of 0.9894, remaining within competition efficiency constraints.", "AI": {"tldr": "The paper introduces a lightweight and efficient face image quality assessment (FIQA) method designed to work in real-world, uncontrolled environments using an ensemble of compact models and a correlation-aware loss function.", "motivation": "To address the limitations of general-purpose image quality assessment techniques which fail to capture face-specific degradations, and to offer a computationally efficient FIQA model suitable for practical deployment.", "method": "The approach integrates MobileNetV3-Small and ShuffleNetV2 using prediction-level fusion (via averaging), and introduces a correlation-aware loss involving MSE and Pearson correlation regularizer to align with human perceptual judgments.", "result": "The proposed method achieves high accuracy with an SRCC of 0.9829 and a PLCC of 0.9894 on the VQualA FIQA benchmark, while staying computationally efficient.", "conclusion": "This lightweight FIQA method balances accuracy and computational cost effectively, making it a viable option for deployment in real-world face recognition systems."}}
{"id": "2509.10291", "pdf": "https://arxiv.org/pdf/2509.10291", "abs": "https://arxiv.org/abs/2509.10291", "authors": ["Salih Toprak", "Muge Erel-Ozcevik"], "title": "Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case", "categories": ["cs.LG", "cs.NI"], "comment": "6 pages, 3 figures, 7th International Conference on Blockchain\n  Computing and Applications (BCCA 2025), \\c{opyright}2025 IEEE", "summary": "In disaster scenarios where conventional energy infrastructure is\ncompromised, secure and traceable energy trading between solar-powered\nhouseholds and mobile charging units becomes a necessity. To ensure the\nintegrity of such transactions over a blockchain network, robust and\nunpredictable nonce generation is vital. This study proposes an SDN-enabled\narchitecture where machine learning regressors are leveraged not for their\naccuracy, but for their potential to generate randomized values suitable as\nnonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN\nallows flexible control over data flows and energy routing policies even in\nfragmented or degraded networks, ensuring adaptive response during emergencies.\nUsing a 9000-sample dataset, we evaluate five AutoML-selected regression models\n- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest\nNeighbors - not by their prediction accuracy, but by their ability to produce\ndiverse and non-deterministic outputs across shuffled data inputs. Randomness\nanalysis reveals that Random Forest and Extra Trees regressors exhibit complete\ndependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and\nLightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and\n99.9%, respectively). These findings highlight that certain machine learning\nmodels, particularly tree-based ensembles, may serve as effective and\nlightweight nonce generators within blockchain-secured, SDN-based energy\ntrading infrastructures resilient to disaster conditions.", "AI": {"tldr": "The paper proposes using machine learning regressors in an SDN-enabled architecture for generating randomized values as nonce candidates for blockchain-secured energy trading during disasters.", "motivation": "To address the need for secure and traceable energy trading between solar-powered households and mobile charging units in disaster scenarios where conventional energy infrastructure is compromised.", "method": "The paper utilizes a 9000-sample dataset to test the randomness of AutoML-selected regression models, and establishes an SDN-enabled system for flexible energy routing and secure blockchain transactions.", "result": "Random Forest and Extra Trees exhibited the highest randomness, while Gradient Boosting, K-Nearest Neighbors, and LightGBM produced slightly lower randomness scores of 97.6%, 98.8%, and 99.9%, respectively.", "conclusion": "Tree-based ensemble models show potential as effective, lightweight nonce generators for blockchain-secured networks in disaster-resilient energy trading architectures."}}
{"id": "2509.10108", "pdf": "https://arxiv.org/pdf/2509.10108", "abs": "https://arxiv.org/abs/2509.10108", "authors": ["Abdulrahman Allam", "Seif Ahmed", "Ali Hamdi", "Khaled Shaban"], "title": "Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records", "categories": ["cs.CL"], "comment": "Accepted in AICCSA 2025", "summary": "The development of medical chatbots in Arabic is significantly constrained by\nthe scarcity of large-scale, high-quality annotated datasets. While prior\nefforts compiled a dataset of 20,000 Arabic patient-doctor interactions from\nsocial media to fine-tune large language models (LLMs), model scalability and\ngeneralization remained limited. In this study, we propose a scalable synthetic\ndata augmentation strategy to expand the training corpus to 100,000 records.\nUsing advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated\n80,000 contextually relevant and medically coherent synthetic question-answer\npairs grounded in the structure of the original dataset. These synthetic\nsamples were semantically filtered, manually validated, and integrated into the\ntraining pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,\nand evaluated their performance using BERTScore metrics and expert-driven\nqualitative assessments. To further analyze the effectiveness of synthetic\nsources, we conducted an ablation study comparing ChatGPT-4o and\nGemini-generated data independently. The results showed that ChatGPT-4o data\nconsistently led to higher F1-scores and fewer hallucinations across all\nmodels. Overall, our findings demonstrate the viability of synthetic\naugmentation as a practical solution for enhancing domain-specific language\nmodels in-low resource medical NLP, paving the way for more inclusive,\nscalable, and accurate Arabic healthcare chatbot systems.", "AI": {"tldr": "This paper introduces a synthetic data augmentation approach to expand Arabic medical chatbot training data from 20,000 to 100,000 records. It uses AI systems to generate new data, fine-tunes language models, and shows improved performance.", "motivation": "The motivation is to address the scarcity of large-scale, high-quality Arabic annotated datasets, which limits the development of scalable and generalizable Arabic medical chatbots.", "method": "The study employs a generative AI-based approach using ChatGPT-4o and Gemini 2.5 Pro to create 80,000 synthetic contextually relevant question-answer pairs. The data is semantically filtered, manually validated, and incorporated into the training pipeline. They fine-tuned five language models, including Mistral-7B and AraGPT2, and performed evaluations using BERTScore metrics and qualitative assessments.", "result": "The results indicate that ChatGPT-4o-generated data outperformed Gemini in terms of F1-scores and reduced hallucinations. The synthetic data augmentation strategy proved effective in enhancing model scalability and accuracy.", "conclusion": "Synthetic data augmentation is a viable solution for improving domain-specific models in low-resource medical NLP, enabling the development of more inclusive and precise Arabic healthcare chatbots."}}
{"id": "2509.10122", "pdf": "https://arxiv.org/pdf/2509.10122", "abs": "https://arxiv.org/abs/2509.10122", "authors": ["Zongliang Wu", "Siming Zheng", "Peng-Tao Jiang", "Xin Yuan"], "title": "Realism Control One-step Diffusion for Real-World Image Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pre-trained diffusion models have shown great potential in real-world image\nsuper-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.\nWhile one-step diffusion (OSD) methods significantly improve efficiency\ncompared to traditional multi-step approaches, they still have limitations in\nbalancing fidelity and realism across diverse scenarios. Since the OSDs for SR\nare usually trained or distilled by a single timestep, they lack flexible\ncontrol mechanisms to adaptively prioritize these competing objectives, which\nare inherently manageable in multi-step methods through adjusting sampling\nsteps. To address this challenge, we propose a Realism Controlled One-step\nDiffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping\nstrategy that enables explicit control over fidelity-realism trade-offs during\nthe noise prediction phase with minimal training paradigm modifications and\noriginal training data. A degradation-aware sampling strategy is also\nintroduced to align distillation regularization with the grouping strategy and\nenhance the controlling of trade-offs. Moreover, a visual prompt injection\nmodule is used to replace conventional text prompts with degradation-aware\nvisual tokens, enhancing both restoration accuracy and semantic consistency.\nOur method achieves superior fidelity and perceptual quality while maintaining\ncomputational efficiency. Extensive experiments demonstrate that RCOD\noutperforms state-of-the-art OSD methods in both quantitative metrics and\nvisual qualities, with flexible realism control capabilities in the inference\nstage. The code will be released.", "AI": {"tldr": "RCOD improves image super-resolution by controlling the trade-off between fidelity and realism in one-step diffusion methods.", "motivation": "The paper aims to address the limitations of existing one-step diffusion (OSD) methods for image super-resolution that struggle to balance fidelity and realism across diverse scenarios.", "method": "RCOD employs a latent domain grouping strategy for explicit fidelity-realism control, degradation-aware sampling for alignment and enhancement, and visual prompt injections for improved restoration accuracy and semantic consistency.", "result": "The proposed framework surpasses state-of-the-art OSD methods in both quantitative metrics and visual quality, while also allowing flexible realism control during inference.", "conclusion": "RCOD provides an effective framework for real-world image super-resolution, offering superior performance and flexible fidelity-realism control without significant computational costs."}}
{"id": "2509.10303", "pdf": "https://arxiv.org/pdf/2509.10303", "abs": "https://arxiv.org/abs/2509.10303", "authors": ["Jesse van Remmerden", "Zaharah Bukhsh", "Yingqian Zhang"], "title": "Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling\nProblem (FJSP), are canonical combinatorial optimization problems with\nwide-ranging applications in industrial operations. In recent years, many\nonline reinforcement learning (RL) approaches have been proposed to learn\nconstructive heuristics for JSP and FJSP. Although effective, these online RL\nmethods require millions of interactions with simulated environments that may\nnot capture real-world complexities, and their random policy initialization\nleads to poor sample efficiency. To address these limitations, we introduce\nConservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL\nalgorithm that learns effective scheduling policies directly from historical\ndata, eliminating the need for costly online interactions, while maintaining\nthe ability to improve upon suboptimal training data. CDQAC couples a\nquantile-based critic with a delayed policy update, estimating the return\ndistribution of each machine-operation pair rather than selecting pairs\noutright. Our extensive experiments demonstrate CDQAC's remarkable ability to\nlearn from diverse data sources. CDQAC consistently outperforms the original\ndata-generating heuristics and surpasses state-of-the-art offline and online RL\nbaselines. In addition, CDQAC is highly sample efficient, requiring only 10-20\ntraining instances to learn high-quality policies. Surprisingly, we find that\nCDQAC performs better when trained on data generated by a random heuristic than\nwhen trained on higher-quality data from genetic algorithms and priority\ndispatching rules.", "AI": {"tldr": "The authors propose CDQAC, an offline reinforcement learning algorithm for addressing limitations in job-shop scheduling by learning from historical data, showing superior performance and data efficiency.", "motivation": "The motivation of the paper is to address limitations of online RL methods for job-shop scheduling, such as the need for millions of simulated interactions and low sample efficiency due to random policy initialization.", "method": "The method involves introducing CDQAC, an offline RL algorithm that uses a quantile-based critic and delayed policy update. It learns directly from historical data to estimate return distributions for scheduling problems.", "result": "CDQAC outperforms state-of-the-art offline and online RL methods, surpasses data-generating heuristics, and learns high-quality policies using limited historical training data (10-20 instances).", "conclusion": "The research concludes that offline RL using CDQAC is a highly effective and sample-efficient approach to job-shop scheduling, even excelling with suboptimal training data."}}
{"id": "2509.10116", "pdf": "https://arxiv.org/pdf/2509.10116", "abs": "https://arxiv.org/abs/2509.10116", "authors": ["Julian Linke", "Barbara Schuppler"], "title": "Prominence-aware automatic speech recognition for conversational speech", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "This paper investigates prominence-aware automatic speech recognition (ASR)\nby combining prominence detection and speech recognition for conversational\nAustrian German. First, prominence detectors were developed by fine-tuning\nwav2vec2 models to classify word-level prominence. The detector was then used\nto automatically annotate prosodic prominence in a large corpus. Based on those\nannotations, we trained novel prominence-aware ASR systems that simultaneously\ntranscribe words and their prominence levels. The integration of prominence\ninformation did not change performance compared to our baseline ASR system,\nwhile reaching a prominence detection accuracy of 85.53% for utterances where\nthe recognized word sequence was correct. This paper shows that\ntransformer-based models can effectively encode prosodic information and\nrepresents a novel contribution to prosody-enhanced ASR, with potential\napplications for linguistic research and prosody-informed dialogue systems.", "AI": {"tldr": "The paper explores integrating prominence detection into ASR for conversational Austrian German, achieving 85.53% prominence detection accuracy with no transcription performance loss.", "motivation": "To enhance ASR systems with prominence detection to improve prosodic and dialogue understanding.", "method": "Fine-tuned wav2vec2 models for prominence detection and trained ASR systems to include word-level prominence annotations.", "result": "85.53% prominence detection accuracy in correctly transcribed utterances with no transcription performance degradation.", "conclusion": "The approach demonstrates transformer models' effectiveness in encoding prosodic information and offers potential for linguistic and dialogue applications."}}
{"id": "2509.10134", "pdf": "https://arxiv.org/pdf/2509.10134", "abs": "https://arxiv.org/abs/2509.10134", "authors": ["Rini Smita Thakur", "Rajeev Ranjan Dwivedi", "Vinod K Kurmi"], "title": "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment", "categories": ["cs.CV"], "comment": "Accepted in BMVC 2025", "summary": "Accurate segmentation of the optic disc and cup is critical for the early\ndiagnosis and management of ocular diseases such as glaucoma. However,\nsegmentation models trained on one dataset often suffer significant performance\ndegradation when applied to target data acquired under different imaging\nprotocols or conditions. To address this challenge, we propose\n\\textbf{Grad-CL}, a novel source-free domain adaptation framework that\nleverages a pre-trained source model and unlabeled target data to robustly\nadapt segmentation performance without requiring access to the original source\ndata. Grad-CL combines a gradient-guided pseudolabel refinement module with a\ncosine similarity-based contrastive learning strategy. In the first stage,\nsalient class-specific features are extracted via a gradient-based mechanism,\nenabling more accurate uncertainty quantification and robust prototype\nestimation for refining noisy pseudolabels. In the second stage, a contrastive\nloss based on cosine similarity is employed to explicitly enforce inter-class\nseparability between the gradient-informed features of the optic cup and disc.\nExtensive experiments on challenging cross-domain fundus imaging datasets\ndemonstrate that Grad-CL outperforms state-of-the-art unsupervised and\nsource-free domain adaptation methods, achieving superior segmentation accuracy\nand improved boundary delineation. Project and code are available at\nhttps://visdomlab.github.io/GCL/.", "AI": {"tldr": "This paper introduces Grad-CL, a source-free domain adaptation method to improve optic disc and cup segmentation across diverse datasets.", "motivation": "Address the performance drop in segmentation models when applied to datasets with different imaging protocols.", "method": "Grad-CL employs gradient-guided pseudolabel refinement and cosine similarity-based contrastive learning for domain adaptation.", "result": "Grad-CL shows superior segmentation accuracy and boundary delineation compared to state-of-the-art methods across challenging fundus imaging datasets.", "conclusion": "Grad-CL effectively enables robust adaptation of segmentation models without needing source data access, improving ocular disease diagnosis and management."}}
{"id": "2509.10308", "pdf": "https://arxiv.org/pdf/2509.10308", "abs": "https://arxiv.org/abs/2509.10308", "authors": ["Joshua Dimasaka", "Christian Gei\u00df", "Robert Muir-Wood", "Emily So"], "title": "GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction", "categories": ["cs.LG"], "comment": "Accepted full paper at the 8th International Disaster and Risk\n  Conference, IDRC 2025 | Keywords: weakly supervised, graph deep learning,\n  categorical distribution, physical vulnerability, remote sensing,\n  spatiotemporal disaster risk, transition matrix | The data and code are\n  respectively available at https://doi.org/10.5281/zenodo.16656471 and\n  https://github.com/riskaudit/GraphCSVAE", "summary": "In the aftermath of disasters, many institutions worldwide face challenges in\ncontinually monitoring changes in disaster risk, limiting the ability of key\ndecision-makers to assess progress towards the UN Sendai Framework for Disaster\nRisk Reduction 2015-2030. While numerous efforts have substantially advanced\nthe large-scale modeling of hazard and exposure through Earth observation and\ndata-driven methods, progress remains limited in modeling another equally\nimportant yet challenging element of the risk equation: physical vulnerability.\nTo address this gap, we introduce Graph Categorical Structured Variational\nAutoencoder (GraphCSVAE), a novel probabilistic data-driven framework for\nmodeling physical vulnerability by integrating deep learning, graph\nrepresentation, and categorical probabilistic inference, using time-series\nsatellite-derived datasets and prior expert belief systems. We introduce a\nweakly supervised first-order transition matrix that reflects the changes in\nthe spatiotemporal distribution of physical vulnerability in two\ndisaster-stricken and socioeconomically disadvantaged areas: (1) the\ncyclone-impacted coastal Khurushkul community in Bangladesh and (2) the\nmudslide-affected city of Freetown in Sierra Leone. Our work reveals\npost-disaster regional dynamics in physical vulnerability, offering valuable\ninsights into localized spatiotemporal auditing and sustainable strategies for\npost-disaster risk reduction.", "AI": {"tldr": "This paper focuses on modeling physical vulnerability, a critical component of disaster risk, using a novel data-driven framework integrating deep learning, graph representation, and probabilistic inference.", "motivation": "To address the lack of robust modeling for physical vulnerability, which hinders decision-makers from assessing disaster risk progress under the UN Sendai Framework.", "method": "Developed Graph Categorical Structured Variational Autoencoder (GraphCSVAE), integrated expert beliefs and satellite-based time-series data with categorical probabilistic inference.", "result": "Applied the framework to cyclone-impacted Khurushkul, Bangladesh, and mudslide-affected Freetown, Sierra Leone, showcasing post-disaster physical vulnerability transitions.", "conclusion": "The study provides tools for understanding regional vulnerability dynamics, aiding post-disaster risk mitigation and sustainable development strategies."}}
{"id": "2509.10127", "pdf": "https://arxiv.org/pdf/2509.10127", "abs": "https://arxiv.org/abs/2509.10127", "authors": ["Zhengyu Hu", "Zheyuan Xiao", "Max Xiong", "Yuxuan Lei", "Tianfu Wang", "Jianxun Lian", "Kaize Ding", "Ziang Xiao", "Nicholas Jing Yuan", "Xing Xie"], "title": "Population-Aligned Persona Generation for LLM-based Social Simulation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled human-like\nsocial simulations at unprecedented scale and fidelity, offering new\nopportunities for computational social science. A key challenge, however, is\nthe construction of persona sets that authentically represent the diversity and\ndistribution of real-world populations. Most existing LLM-based social\nsimulation studies focus primarily on designing agentic frameworks and\nsimulation environments, often overlooking the complexities of persona\ngeneration and the potential biases introduced by unrepresentative persona\nsets. In this paper, we propose a systematic framework for synthesizing\nhigh-quality, population-aligned persona sets for LLM-driven social simulation.\nOur approach begins by leveraging LLMs to generate narrative personas from\nlong-term social media data, followed by rigorous quality assessment to filter\nout low-fidelity profiles. We then apply importance sampling to achieve global\nalignment with reference psychometric distributions, such as the Big Five\npersonality traits. To address the needs of specific simulation contexts, we\nfurther introduce a task-specific module that adapts the globally aligned\npersona set to targeted subpopulations. Extensive experiments demonstrate that\nour method significantly reduces population-level bias and enables accurate,\nflexible social simulation for a wide range of research and policy\napplications.", "AI": {"tldr": "The paper introduces a framework to create realistic, globally aligned personas for LLM-driven social simulations by leveraging social media data and psychometric distributions.", "motivation": "Current LLM-driven social simulations often neglect the construction of diverse, representative persona sets, introducing biases that can undermine authenticity and reliability.", "method": "The authors propose generating narrative personas from social media data, assessing their quality rigorously, and applying importance sampling to align with reference psychometric distributions. A task-specific module tailors personas to subpopulations for specific contexts.", "result": "Experiments show that the framework reduces population-level bias and enhances simulation accuracy and flexibility across varied applications.", "conclusion": "This systematic approach provides a scalable solution for creating high-quality, representative persona sets, advancing computational social science research and policy development."}}
{"id": "2509.10140", "pdf": "https://arxiv.org/pdf/2509.10140", "abs": "https://arxiv.org/abs/2509.10140", "authors": ["Yifan Chang", "Jie Qin", "Limeng Qiao", "Xiaofeng Wang", "Zheng Zhu", "Lin Ma", "Xingang Wang"], "title": "Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization", "categories": ["cs.CV"], "comment": null, "summary": "Vector quantization (VQ) is a key component in discrete tokenizers for image\ngeneration, but its training is often unstable due to straight-through\nestimation bias, one-step-behind updates, and sparse codebook gradients, which\nlead to suboptimal reconstruction performance and low codebook usage. In this\nwork, we analyze these fundamental challenges and provide a simple yet\neffective solution. To maintain high codebook usage in VQ networks (VQN) during\nlearning annealing and codebook size expansion, we propose VQBridge, a robust,\nscalable, and efficient projector based on the map function method. VQBridge\noptimizes code vectors through a compress-process-recover pipeline, enabling\nstable and effective codebook training. By combining VQBridge with learning\nannealing, our VQN achieves full (100%) codebook usage across diverse codebook\nconfigurations, which we refer to as FVQ (FullVQ). Through extensive\nexperiments, we demonstrate that FVQ is effective, scalable, and generalizable:\nit attains 100% codebook usage even with a 262k-codebook, achieves\nstate-of-the-art reconstruction performance, consistently improves with larger\ncodebooks, higher vector channels, or longer training, and remains effective\nacross different VQ variants. Moreover, when integrated with LlamaGen, FVQ\nsignificantly enhances image generation performance, surpassing visual\nautoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,\nhighlighting the importance of high-quality tokenizers for strong\nautoregressive image generation.", "AI": {"tldr": "The paper tackles challenges in vector quantization (VQ) for image generation, proposing VQBridge to optimize codebook usage and stability, achieving 100% codebook utilization and improved image generation.", "motivation": "To address the instability and inefficiency of vector quantization training in discrete tokenizers for image generation, which leads to suboptimal performance and sparse codebook usage.", "method": "Propose VQBridge\u2014a projector using a compress-process-recover pipeline and learning annealing\u2014optimizing vector quantization networks for stable training and high codebook usage.", "result": "Achieved 100% codebook usage across configurations, state-of-the-art reconstruction, scalability with codebook size, and performance enhancement in image generation models like LlamaGen.", "conclusion": "VQBridge effectively resolves VQ training challenges, enhances reconstruction and generative performance, and emphasizes the importance of quality tokenizers for autoregressive image generation."}}
{"id": "2509.10324", "pdf": "https://arxiv.org/pdf/2509.10324", "abs": "https://arxiv.org/abs/2509.10324", "authors": ["Myung Jin Kim", "YeongHyeon Park", "Il Dong Yun"], "title": "ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "This paper proposes a simple yet effective convolutional module for long-term\ntime series forecasting. The proposed block, inspired by the Auto-Regressive\nIntegrated Moving Average (ARIMA) model, consists of two convolutional\ncomponents: one for capturing the trend (autoregression) and the other for\nrefining local variations (moving average). Unlike conventional ARIMA, which\nrequires iterative multi-step forecasting, the block directly performs\nmulti-step forecasting, making it easily extendable to multivariate settings.\nExperiments on nine widely used benchmark datasets demonstrate that our method\nARMA achieves competitive accuracy, particularly on datasets exhibiting strong\ntrend variations, while maintaining architectural simplicity. Furthermore,\nanalysis shows that the block inherently encodes absolute positional\ninformation, suggesting its potential as a lightweight replacement for\npositional embeddings in sequential models.", "AI": {"tldr": "This paper introduces a convolutional module inspired by ARIMA for efficient and accurate long-term time series forecasting.", "motivation": "To address limitations of conventional ARIMA in iterative multi-step forecasting and its lack of adaptability to multivariate datasets.", "method": "The method utilizes a convolutional block with components covering trend (autoregression) and local variations (moving average) for direct, multi-step prediction.", "result": "Experimental evaluation on nine benchmark datasets demonstrates competitive accuracy and effective handling of strong trend variations.", "conclusion": "ARMA is an architecturally simple yet effective tool, with potential applications beyond its core forecasting function, such as substituting positional embeddings in sequential models."}}
{"id": "2509.10129", "pdf": "https://arxiv.org/pdf/2509.10129", "abs": "https://arxiv.org/abs/2509.10129", "authors": ["Alessio Chen", "Simone Giovannini", "Andrea Gemelli", "Fabio Coppini", "Simone Marinai"], "title": "Towards Reliable and Interpretable Document Question Answering via VLMs", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Vision-Language Models (VLMs) have shown strong capabilities in document\nunderstanding, particularly in identifying and extracting textual information\nfrom complex documents. Despite this, accurately localizing answers within\ndocuments remains a major challenge, limiting both interpretability and\nreal-world applicability. To address this, we introduce\n\\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that\ndecouples answer generation from spatial localization. This design makes it\napplicable to existing VLMs, including proprietary systems where fine-tuning is\nnot feasible. Through systematic evaluation, we provide quantitative insights\ninto the gap between textual accuracy and spatial grounding, showing that\ncorrect answers often lack reliable localization. Our standardized framework\nhighlights these shortcomings and establishes a benchmark for future research\ntoward more interpretable and robust document information extraction VLMs.", "AI": {"tldr": "The paper introduces DocExplainerV0, a module that improves spatial localization of answers in Vision-Language Models (VLMs), which was previously a challenge.", "motivation": "The motivation is to enhance the interpretability and real-world applicability of VLMs by addressing their limitations in localizing answers within complex documents.", "method": "The authors propose DocExplainerV0, a bounding-box prediction module that separates answer generation from spatial localization, compatible with existing VLMs without requiring fine-tuning.", "result": "Systematic evaluation shows that while VLMs often achieve textual accuracy, their spatial grounding is insufficient. DocExplainerV0 addresses this gap and provides standardized evaluation insights.", "conclusion": "DocExplainerV0 improves spatial localization, establishing benchmarks and paving the path for more robust and interpretable document understanding in VLMs."}}
{"id": "2509.10156", "pdf": "https://arxiv.org/pdf/2509.10156", "abs": "https://arxiv.org/abs/2509.10156", "authors": ["Goker Erdogan", "Nikhil Parthasarathy", "Catalin Ionescu", "Drew Hudson", "Alexander Lerchner", "Andrew Zisserman", "Mehdi Sajjadi", "Joao Carreira"], "title": "LayerLock: Non-collapsing Representation Learning with Progressive Freezing", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "We introduce LayerLock, a simple yet effective approach for self-supervised\nvisual representation learning, that gradually transitions from pixel to latent\nprediction through progressive layer freezing. First, we make the observation\nthat during training of video masked-autoencoding (MAE) models, ViT layers\nconverge in the order of their depth: shallower layers converge early, deeper\nlayers converge late. We then show that this observation can be exploited to\naccelerate standard MAE by progressively freezing the model according to an\nexplicit schedule, throughout training. Furthermore, this same schedule can be\nused in a simple and scalable approach to latent prediction that does not\nsuffer from \"representation collapse\". We apply our proposed approach,\nLayerLock, to large models of up to 4B parameters with results surpassing those\nof non-latent masked prediction on the 4DS perception suite.", "AI": {"tldr": "LayerLock leverages a progressive layer freezing strategy for self-supervised visual representation learning, improving efficiency and scalability for large models.", "motivation": "To enhance the efficiency and scalability of video masked-autoencoding models while addressing challenges like representation collapse.", "method": "Progressive layer freezing based on the observation that ViT layers converge at different rates during training, alongside a latent prediction schedule.", "result": "Demonstrated scalability to large models with up to 4 billion parameters, achieving superior results compared to traditional non-latent masked prediction on 4DS perception suite.", "conclusion": "LayerLock is a simple yet effective approach for enabling latent prediction in visual representation learning, making it suitable for large-scale models."}}
{"id": "2509.10363", "pdf": "https://arxiv.org/pdf/2509.10363", "abs": "https://arxiv.org/abs/2509.10363", "authors": ["Benjamin David Shaffer", "Brooks Kinch", "Joseph Klobusicky", "M. Ani Hsieh", "Nathaniel Trask"], "title": "Physics-informed sensor coverage through structure preserving machine learning", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We present a machine learning framework for adaptive source localization in\nwhich agents use a structure-preserving digital twin of a coupled\nhydrodynamic-transport system for real-time trajectory planning and data\nassimilation. The twin is constructed with conditional neural Whitney forms\n(CNWF), coupling the numerical guarantees of finite element exterior calculus\n(FEEC) with transformer-based operator learning. The resulting model preserves\ndiscrete conservation, and adapts in real time to streaming sensor data. It\nemploys a conditional attention mechanism to identify: a reduced Whitney-form\nbasis; reduced integral balance equations; and a source field, each compatible\nwith given sensor measurements. The induced reduced-order environmental model\nretains the stability and consistency of standard finite-element simulation,\nyielding a physically realizable, regular mapping from sensor data to the\nsource field. We propose a staggered scheme that alternates between evaluating\nthe digital twin and applying Lloyd's algorithm to guide sensor placement, with\nanalysis providing conditions for monotone improvement of a coverage\nfunctional. Using the predicted source field as an importance function within\nan optimal-recovery scheme, we demonstrate recovery of point sources under\ncontinuity assumptions, highlighting the role of regularity as a sufficient\ncondition for localization. Experimental comparisons with physics-agnostic\ntransformer architectures show improved accuracy in complex geometries when\nphysical constraints are enforced, indicating that structure preservation\nprovides an effective inductive bias for source identification.", "AI": {"tldr": "This paper introduces a machine learning framework for real-time adaptive source localization using a physics-informed digital twin that integrates finite element guarantees with transformer-based operator learning.", "motivation": "To create a real-time system for accurately localizing sources in coupled hydrodynamic-transport problems, leveraging physics-informed methods to ensure consistency and stability in complex environments.", "method": "The framework uses conditional neural Whitney forms (CNWF) combined with finite element exterior calculus (FEEC) and transformer-based operator learning. A staggered scheme alternates between digital twin evaluation and sensor placement guided by Lloyd's algorithm.", "result": "The proposed model preserves physical constraints, achieves improved source localization in complex geometries compared to physics-agnostic models, and supports stability and consistency through reduced-order modeling.", "conclusion": "Integrating physics-aware constraints in neural network architectures enhances accuracy and effectiveness in environmental modeling tasks, demonstrating the benefits of structure-preserving methods for real-time localization."}}
{"id": "2509.10179", "pdf": "https://arxiv.org/pdf/2509.10179", "abs": "https://arxiv.org/abs/2509.10179", "authors": ["Ji\u0159\u00ed Mili\u010dka", "Anna Marklov\u00e1", "V\u00e1clav Cvr\u010dek"], "title": "Benchmark of stylistic variation in LLM-generated texts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This study investigates the register variation in texts written by humans and\ncomparable texts produced by large language models (LLMs). Biber's\nmultidimensional analysis (MDA) is applied to a sample of human-written texts\nand AI-created texts generated to be their counterparts to find the dimensions\nof variation in which LLMs differ most significantly and most systematically\nfrom humans. As textual material, a new LLM-generated corpus AI-Brown is used,\nwhich is comparable to BE-21 (a Brown family corpus representing contemporary\nBritish English). Since all languages except English are underrepresented in\nthe training data of frontier LLMs, similar analysis is replicated on Czech\nusing AI-Koditex corpus and Czech multidimensional model. Examined were 16\nfrontier models in various settings and prompts, with emphasis placed on the\ndifference between base models and instruction-tuned models. Based on this, a\nbenchmark is created through which models can be compared with each other and\nranked in interpretable dimensions.", "AI": {"tldr": "This study explores register differences between human-written texts and those created by large language models (LLMs), using multidimensional analysis to identify systematic variations.", "motivation": "To understand how large language models (LLMs) differ from humans in text creation, specifically in register variation, and provide benchmarks for comparison.", "method": "Applied multidimensional analysis to human-written and AI-generated texts in English and Czech, leveraging newly created corpora and analyzing 16 LLMs in various configurations.", "result": "Identified systematic differences in register between human and LLM texts, established benchmarks, and provided a ranking framework for comparing LLMs.", "conclusion": "LLMs exhibit distinct patterns in textual register compared to human authors, with differences influenced by training and instruction-tuning settings. Benchmarks offer key insights for model evaluation."}}
{"id": "2509.10241", "pdf": "https://arxiv.org/pdf/2509.10241", "abs": "https://arxiv.org/abs/2509.10241", "authors": ["Elias De Smijter", "Renaud Detry", "Christophe De Vleeschouwer"], "title": "On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints", "categories": ["cs.CV"], "comment": "9 pages, 3 figures, to be presented at ASTRA25,", "summary": "We present the first systematic comparison of implicit and explicit Novel\nView Synthesis methods for space-based 3D object reconstruction, evaluating the\nrole of appearance embeddings. While embeddings improve photometric fidelity by\nmodeling lighting variation, we show they do not translate into meaningful\ngains in geometric accuracy - a critical requirement for space robotics\napplications. Using the SPEED+ dataset, we compare K-Planes, Gaussian\nSplatting, and Convex Splatting, and demonstrate that embeddings primarily\nreduce the number of primitives needed for explicit methods rather than\nenhancing geometric fidelity. Moreover, convex splatting achieves more compact\nand clutter-free representations than Gaussian splatting, offering advantages\nfor safety-critical applications such as interaction and collision avoidance.\nOur findings clarify the limits of appearance embeddings for geometry-centric\ntasks and highlight trade-offs between reconstruction quality and\nrepresentation efficiency in space scenarios.", "AI": {"tldr": "The paper compares implicit and explicit methods for 3D object reconstruction in space applications, emphasizing the role of appearance embeddings. It concludes that embeddings improve appearance but not geometry accuracy.", "motivation": "To assess the role of appearance embeddings and their impact on geometric accuracy for space robotics and safety-focused tasks.", "method": "Comparison of methods including K-Planes, Gaussian Splatting, and Convex Splatting using the SPEED+ dataset for systematic evaluation.", "result": "Embeddings improve photometric fidelity but do not enhance geometric accuracy. Convex splatting provides more compact representations suitable for safety-critical tasks.", "conclusion": "Appearance embeddings are limited in advancing geometric accuracy, and there are crucial trade-offs between reconstruction quality and representation efficiency in space applications."}}
{"id": "2509.10367", "pdf": "https://arxiv.org/pdf/2509.10367", "abs": "https://arxiv.org/abs/2509.10367", "authors": ["Tong Chen", "Raghavendra Selvan"], "title": "A Discrepancy-Based Perspective on Dataset Condensation", "categories": ["cs.LG"], "comment": "30 pages, 4 tables, 1 figure", "summary": "Given a dataset of finitely many elements $\\mathcal{T} = \\{\\mathbf{x}_i\\}_{i\n= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic\ndataset $\\mathcal{S} = \\{\\tilde{\\mathbf{x}}_j\\}_{j = 1}^M$ which is\nsignificantly smaller ($M \\ll N$) such that a model trained from scratch on\n$\\mathcal{S}$ achieves comparable or even superior generalization performance\nto a model trained on $\\mathcal{T}$. Recent advances in DC reveal a close\nconnection to the problem of approximating the data distribution represented by\n$\\mathcal{T}$ with a reduced set of points. In this work, we present a unified\nframework that encompasses existing DC methods and extend the task-specific\nnotion of DC to a more general and formal definition using notions of\ndiscrepancy, which quantify the distance between probability distribution in\ndifferent regimes. Our framework broadens the objective of DC beyond\ngeneralization, accommodating additional objectives such as robustness,\nprivacy, and other desirable properties.", "AI": {"tldr": "This paper introduces a unified framework for dataset condensation (DC), constructing smaller synthetic datasets that capture key characteristics of large datasets while supporting broader objectives like robustness and privacy.", "motivation": "There is a need to compress large datasets into smaller synthetic ones that still provide comparable or improved model performance, and address issues like robustness, privacy, and generalization.", "method": "The authors propose using discrepancy measures to formalize DC, connecting it to the data distribution approximation problem and extending its definition to include diverse goals beyond generalization.", "result": "The framework integrates existing DC methods while expanding their scope to a broader range of objectives such as robustness and privacy.", "conclusion": "The paper provides a generalizable and formal approach to DC, establishing it as a versatile tool for creating efficient synthetic datasets that align with various machine learning goals."}}
{"id": "2509.10184", "pdf": "https://arxiv.org/pdf/2509.10184", "abs": "https://arxiv.org/abs/2509.10184", "authors": ["Leen Almajed", "Abeer ALdayel"], "title": "Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations", "categories": ["cs.CL"], "comment": "This paper is under review", "summary": "In emotionally supportive conversations, well-intended positivity can\nsometimes misfire, leading to responses that feel dismissive, minimizing, or\nunrealistically optimistic. We examine this phenomenon of incongruent\npositivity as miscalibrated expressions of positive support in both human and\nLLM generated responses. To this end, we collected real user-assistant\ndialogues from Reddit across a range of emotional intensities and generated\nadditional responses using large language models for the same context. We\ncategorize these conversations by intensity into two levels: Mild, which covers\nrelationship tension and general advice, and Severe, which covers grief and\nanxiety conversations. This level of categorization enables a comparative\nanalysis of how supportive responses vary across lower and higher stakes\ncontexts. Our analysis reveals that LLMs are more prone to unrealistic\npositivity through dismissive and minimizing tone, particularly in high-stakes\ncontexts. To further study the underlying dimensions of this phenomenon, we\nfinetune LLMs on datasets with strong and weak emotional reactions. Moreover,\nwe developed a weakly supervised multilabel classifier ensemble (DeBERTa and\nMentalBERT) that shows improved detection of incongruent positivity types\nacross two sorts of concerns (Mild and Severe). Our findings shed light on the\nneed to move beyond merely generating generic positive responses and instead\nstudy the congruent support measures to balance positive affect with emotional\nacknowledgment. This approach offers insights into aligning large language\nmodels with affective expectations in the online supportive dialogue, paving\nthe way toward context-aware and trust preserving online conversation systems.", "AI": {"tldr": "This paper explores how both human and large language model (LLM)-generated responses can demonstrate incongruent positivity, especially in high-stakes emotional support conversations, and presents methods to improve emotional alignment.", "motivation": "The paper identifies the issue of well-intended positivity misfiring, often leading to responses that dismiss or minimize emotions, particularly in emotionally sensitive contexts.", "method": "The study collects dialogues from Reddit, categorizes them into Mild and Severe emotional intensities, analyzes LLM-generated responses, finetunes LLMs, and develops a weakly supervised multilabel classifier ensemble to detect incongruent positivity.", "result": "LLMs are found to be more prone to unrealistic positivity, particularly in severe emotional contexts. The classifier ensemble improves the detection of mismatched positivity types across Mild and Severe concerns.", "conclusion": "This research highlights the need for context-sensitive systems that balance positivity with emotional acknowledgment in online supportive dialogues, promoting trust and alignment with users' emotional needs."}}
{"id": "2509.10250", "pdf": "https://arxiv.org/pdf/2509.10250", "abs": "https://arxiv.org/abs/2509.10250", "authors": ["Haozhen Yan", "Yan Hong", "Suning Lang", "Jiahui Zhan", "Yikun Ji", "Yujie Gao", "Jun Lan", "Huijia Zhu", "Weiqiang Wang", "Jianfu Zhang"], "title": "GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection", "categories": ["cs.CV"], "comment": "11 pages, 5 figures", "summary": "With generative models becoming increasingly sophisticated and diverse,\ndetecting AI-generated images has become increasingly challenging. While\nexisting AI-genereted Image detectors achieve promising performance on\nin-distribution generated images, their generalization to unseen generative\nmodels remains limited. This limitation is largely attributed to their reliance\non generation-specific artifacts, such as stylistic priors and compression\npatterns. To address these limitations, we propose GAMMA, a novel training\nframework designed to reduce domain bias and enhance semantic alignment. GAMMA\nintroduces diverse manipulation strategies, such as inpainting-based\nmanipulation and semantics-preserving perturbations, to ensure consistency\nbetween manipulated and authentic content. We employ multi-task supervision\nwith dual segmentation heads and a classification head, enabling pixel-level\nsource attribution across diverse generative domains. In addition, a reverse\ncross-attention mechanism is introduced to allow the segmentation heads to\nguide and correct biased representations in the classification branch. Our\nmethod achieves state-of-the-art generalization performance on the GenImage\nbenchmark, imporving accuracy by 5.8%, but also maintains strong robustness on\nnewly released generative model such as GPT-4o.", "AI": {"tldr": "The paper proposes GAMMA, a novel training framework for detecting AI-generated images with improved cross-domain generalization and state-of-the-art accuracy.", "motivation": "Current AI image detectors struggle to generalize to unseen generative models due to reliance on specific artifacts like stylistic or compression patterns.", "method": "The GAMMA framework employs diverse manipulation strategies, multi-task supervision with dual segmentation and classification heads, and a reverse cross-attention mechanism.", "result": "Achieved state-of-the-art performance on the GenImage benchmark with a 5.8% accuracy improvement and demonstrated robustness on new models like GPT-4o.", "conclusion": "GAMMA effectively reduces domain biases, enhances semantic alignment, and improves generalizability in detecting AI-generated images."}}
{"id": "2509.10369", "pdf": "https://arxiv.org/pdf/2509.10369", "abs": "https://arxiv.org/abs/2509.10369", "authors": ["Gul Rukh Khattak", "Konstantinos Patlatzoglou", "Joseph Barker", "Libor Pastika", "Boroumand Zeidaabadi", "Ahmed El-Medany", "Hesham Aggour", "Yixiu Liang", "Antonio H. Ribeiro", "Jeffrey Annis", "Antonio Luiz Pinho Ribeiro", "Junbo Ge", "Daniel B. Kramer", "Jonathan W. Waks", "Evan Brittain", "Nicholas Peters", "Fu Siong Ng", "Arunashis Sau"], "title": "Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.TO"], "comment": "Currently under review at npj Digital Medicine", "summary": "Contrastive learning is a widely adopted self-supervised pretraining\nstrategy, yet its dependence on cohort composition remains underexplored. We\npresent Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation\nmodel and pretrain on four cohorts (n = 5,203,352), from diverse populations\nacross three continents (North America, South America, Asia). We systematically\nassess how cohort demographics, health status, and population diversity\ninfluence the downstream performance for prediction tasks also including two\nadditional cohorts from another continent (Europe). We find that downstream\nperformance depends on the distributional properties of the pretraining cohort,\nincluding demographics and health status. Moreover, while pretraining with a\nmulti-centre, demographically diverse cohort improves in-distribution accuracy,\nit reduces out-of-distribution (OOD) generalisation of our contrastive approach\nby encoding cohort-specific artifacts. To address this, we propose the\nIn-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency\nduring pretraining and enhances OOD robustness. This work provides important\ninsights for developing clinically fair and generalisable foundation models.", "AI": {"tldr": "This paper introduces CAPE, a foundation model pretraining on large global ECG cohorts, and finds that cohort diversity improves in-distribution accuracy but hampers out-of-distribution generalization, proposing the IDB strategy as a solution for clinical fairness.", "motivation": "To address the limited understanding of how cohort composition in contrastive learning affects downstream clinical prediction tasks and to improve clinical fairness and generalization.", "method": "The authors pretrain the CAPE model using ECG data from diverse global cohorts and evaluate how demographics and diversity impact performance. They introduce the IDB strategy to counter cohort-specific artifacts and enhance OOD generalization.", "result": "Pretraining on diverse cohorts boosts in-distribution accuracy but decreases out-of-distribution generalization due to cohort-specific artifacts. The proposed IDB strategy mitigates this issue and enhances robustness.", "conclusion": "Cohort composition in contrastive learning significantly impacts clinical prediction outcomes, with the IDB strategy offering a path toward fair and generalizable models."}}
{"id": "2509.10199", "pdf": "https://arxiv.org/pdf/2509.10199", "abs": "https://arxiv.org/abs/2509.10199", "authors": ["Mikl\u00f3s Seb\u0151k", "Viktor Kov\u00e1cs", "Martin B\u00e1n\u00f3czy", "Daniel M\u00f8ller Eriksen", "Nathalie Neptune", "Philippe Roussille"], "title": "Beyond Token Limits: Assessing Language Model Performance on Long Text Classification", "categories": ["cs.CL", "I.7; I.2; J.4"], "comment": null, "summary": "The most widely used large language models in the social sciences (such as\nBERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text\nlength that they can process to produce predictions. This is a particularly\npressing issue for some classification tasks, where the aim is to handle long\ninput texts. One such area deals with laws and draft laws (bills), which can\nhave a length of multiple hundred pages and, therefore, are not particularly\namenable for processing with models that can only handle e.g. 512 tokens. In\nthis paper, we show results from experiments covering 5 languages with\nXLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass\nclassification task of the Comparative Agendas Project, which has a codebook of\n21 policy topic labels from education to health care. Results show no\nparticular advantage for the Longformer model, pre-trained specifically for the\npurposes of handling long inputs. The comparison between the GPT variants and\nthe best-performing open model yielded an edge for the latter. An analysis of\nclass-level factors points to the importance of support and substance overlaps\nbetween specific categories when it comes to performance on long text inputs.", "AI": {"tldr": "The paper evaluates BERT and its variants, Longformer, GPT-3.5, GPT-4, for long text classification, focusing on legal documents. Despite Longformer's long input capacity, no notable advantage was found over other models, with GPT variants performing comparably.", "motivation": "The paper addresses the limitation of handling long input texts in language models, particularly crucial for tasks like classifying lengthy legal documents.", "method": "Experiments were conducted using XLM-RoBERTa, Longformer, GPT-3.5, and GPT-4 on a 21-class classification task across 5 languages, based on the Comparative Agendas Project's codebook.", "result": "No significant advantage was found for Longformer. The best-performing open model outperformed GPT variants slightly. Class-level analysis highlighted the impact of overlap between categories on classification performance.", "conclusion": "Longformer's capability to handle longer texts does not necessarily translate to better classification outcomes. Open models perform competitively, and factors such as inter-class substance overlaps are important."}}
{"id": "2509.10257", "pdf": "https://arxiv.org/pdf/2509.10257", "abs": "https://arxiv.org/abs/2509.10257", "authors": ["Ema Masterl", "Tina Vipotnik Vesnaver", "\u017diga \u0160piclin"], "title": "Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI", "categories": ["cs.CV"], "comment": "Accepted at the PIPPI Workshop of MICCAI 2025", "summary": "Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce\nmotion artifacts caused by fetal movement. However, these stacks are typically\nlow resolution, may suffer from motion corruption, and do not adequately\ncapture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to\naddress these limitations by combining slice-to-volume registration and\nsuper-resolution techniques to generate high-resolution (HR) 3D volumes. While\nseveral SRR methods have been proposed, their comparative performance -\nparticularly in pathological cases - and their influence on downstream\nvolumetric analysis and diagnostic tasks remain underexplored. In this study,\nwe applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to\n140 fetal brain MRI scans, including both healthy controls (HC) and\npathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was\nsegmented using the BoUNTi algorithm to extract volumes of nine principal brain\nstructures. We evaluated visual quality, SRR success rates, volumetric\nmeasurement agreement, and diagnostic classification performance. NeSVoR\ndemonstrated the highest and most consistent reconstruction success rate (>90%)\nacross both HC and PC groups. Although significant differences in volumetric\nestimates were observed between SRR methods, classification performance for VM\nwas not affected by the choice of SRR method. These findings highlight NeSVoR's\nrobustness and the resilience of diagnostic performance despite SRR-induced\nvolumetric variability.", "AI": {"tldr": "The paper evaluates three super-resolution reconstruction (SRR) methods for fetal brain MRI scans, focusing on their impact on image quality, volumetric analysis, and diagnostic tasks, highlighting NeSVoR\u2019s robustness.", "motivation": "To address limitations of low-resolution fetal brain MRI and its impact on volumetric analysis and diagnostic accuracy, particularly for pathological conditions.", "method": "Applied three SRR methods - NiftyMIC, SVRTK, and NeSVoR - to analyze 140 fetal brain MRI scans, segmented key brain structures, and compared visual quality, volumetric consistency, and diagnostic performance.", "result": "NeSVoR achieved the highest reconstruction success (>90%) across healthy and pathological cases. While volumetric differences were noted among methods, diagnostic performance remained unaffected.", "conclusion": "NeSVoR is robust for fetal brain MRI reconstruction, and diagnostic accuracy is stable despite volumetric discrepancies across SRR methods."}}
{"id": "2509.10208", "pdf": "https://arxiv.org/pdf/2509.10208", "abs": "https://arxiv.org/abs/2509.10208", "authors": ["Shengqiang Fu"], "title": "SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models often generate unfaithful responses in knowledge\nintensive tasks due to knowledge conflict,that is,a preference for relying on\ninternal parametric knowledge rather than the provided context.To address this\nissue,we propose a novel self improving framework,Self Improving Faithfulness\nAware Contrastive Tuning.The framework uses a self instruct mechanism that\nallows the base LLM to automatically generate high quality,structured\ncontrastive learning data,including anchor samples,semantically equivalent\npositive samples,and negative samples simulating unfaithful scenarios.This\napproach significantly reduces the cost of manual\nannotation.Subsequently,contrastive learning is applied to train the\nmodel,enabling it to pull faithful responses closer and push unfaithful\nresponses farther apart in the representation space.Experiments on knowledge\nconflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT\nmodel based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%\nover the best baseline method,while significantly reducing dependence on\ninternal memory.The results indicate that SI FACT provides strong effectiveness\nand high data efficiency in enhancing the contextual faithfulness of\nLLMs,offering a practical pathway toward building more proactive and\ntrustworthy language models.", "AI": {"tldr": "This paper introduces a methodology to improve the contextual faithfulness of Large Language Models (LLMs) using a self-improving framework called SI FACT, which reduces reliance on internal memory and enhances response accuracy.", "motivation": "Large Language Models often struggle with generating accurate responses in knowledge-intensive tasks due to their reliance on internal knowledge over context.", "method": "A self-improving framework called Self Improving Faithfulness Aware Contrastive Tuning (SI FACT) is proposed. It employs a self-instruct mechanism to generate data for contrastive learning, aiming to teach the model to differentiate between faithful and unfaithful responses.", "result": "The SI FACT model achieves a Contextual Recall Rate improvement of 6.2% over leading baseline methods and demonstrates reduced dependency on internal memory.", "conclusion": "SI FACT effectively improves the contextual faithfulness of LLMs through automated data generation and contrastive learning, paving the way for more trustworthy LLM applications."}}
{"id": "2509.10259", "pdf": "https://arxiv.org/pdf/2509.10259", "abs": "https://arxiv.org/abs/2509.10259", "authors": ["Hua Yuan", "Jin Yuan", "Yicheng Jiang", "Yao Zhang", "Xin Geng", "Yong Rui"], "title": "Mask Consistency Regularization in Object Removal", "categories": ["cs.CV"], "comment": null, "summary": "Object removal, a challenging task within image inpainting, involves\nseamlessly filling the removed region with content that matches the surrounding\ncontext. Despite advancements in diffusion models, current methods still face\ntwo critical challenges. The first is mask hallucination, where the model\ngenerates irrelevant or spurious content inside the masked region, and the\nsecond is mask-shape bias, where the model fills the masked area with an object\nthat mimics the mask's shape rather than surrounding content. To address these\nissues, we propose Mask Consistency Regularization (MCR), a novel training\nstrategy designed specifically for object removal tasks. During training, our\napproach introduces two mask perturbations: dilation and reshape, enforcing\nconsistency between the outputs of these perturbed branches and the original\nmask. The dilated masks help align the model's output with the surrounding\ncontent, while reshaped masks encourage the model to break the mask-shape bias.\nThis combination of strategies enables MCR to produce more robust and\ncontextually coherent inpainting results. Our experiments demonstrate that MCR\nsignificantly reduces hallucinations and mask-shape bias, leading to improved\nperformance in object removal.", "AI": {"tldr": "This paper addresses challenges in object removal for image inpainting by proposing a novel Mask Consistency Regularization (MCR) technique to mitigate mask hallucination and shape bias.", "motivation": "Current diffusion models face issues like irrelevant content generation and shape bias in mask-based image inpainting.", "method": "The proposed method\u2014Mask Consistency Regularization\u2014uses perturbed masks via dilation and reshaping during training to enforce output consistency and reduce bias.", "result": "MCR successfully reduces hallucinations and mask-shape dependency, delivering enhanced context-aware image inpainting.", "conclusion": "MCR improves object removal accuracy and produces coherent inpainting results, showing promise as an advancement in image editing techniques."}}
{"id": "2509.09716", "pdf": "https://arxiv.org/pdf/2509.09716", "abs": "https://arxiv.org/abs/2509.09716", "authors": ["Jun Zhan", "Mingyang Han", "Yuxuan Xie", "Chen Wang", "Dong Zhang", "Kexin Huang", "Haoxiang Shi", "DongXiao Wang", "Tengtao Song", "Qinyuan Cheng", "Shimin Li", "Jun Song", "Xipeng Qiu", "Bo Zheng"], "title": "VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": null, "summary": "Spoken language models (SLMs) have emerged as a unified paradigm for speech\nunderstanding and generation, enabling natural human machine interaction.\nHowever, while most progress has focused on semantic accuracy and instruction\nfollowing, the ability of SLMs to adapt their speaking style based on spoken\ninstructions has received limited attention. We introduce Voice Style\nAdaptation (VSA), a new task that examines whether SLMs can modify their\nspeaking style, such as timbre, prosody, or persona following natural language\nspoken commands. To study this task, we present VStyle, a bilingual (Chinese &\nEnglish) benchmark covering four categories of speech generation: acoustic\nattributes, natural language instruction, role play, and implicit empathy. We\nalso introduce the Large Audio Language Model as a Judge (LALM as a Judge)\nframework, which progressively evaluates outputs along textual faithfulness,\nstyle adherence, and naturalness, ensuring reproducible and objective\nassessment. Experiments on commercial systems and open source SLMs demonstrate\nthat current models face clear limitations in controllable style adaptation,\nhighlighting both the novelty and challenge of this task. By releasing VStyle\nand its evaluation toolkit, we aim to provide the community with a foundation\nfor advancing human centered spoken interaction. The dataset and code are\npublicly available at\n\\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.", "AI": {"tldr": "Spoken Language Models (SLMs) are being evaluated for their ability to adapt speaking styles based on spoken instructions, using the newly introduced VStyle benchmark and Voice Style Adaptation (VSA) task.", "motivation": "Current SLMs have focused on semantics and instruction following, but their ability to adjust speaking styles like timbre, prosody, or persona has been overlooked. The authors aim to explore this neglected aspect.", "method": "They introduce the VStyle benchmark for bilingual (Chinese & English) evaluation across four speech generation categories and use the 'LALM as a Judge' evaluation framework to assess performance systematically.", "result": "Experiments show that existing commercial and open-source models struggle with controllable speaking style adaptations, revealing the complexity of this task.", "conclusion": "VStyle and its evaluation toolkit provide a starting point for advancing spoken language models in human-centered interaction by improving style adaptation capabilities."}}
{"id": "2509.10390", "pdf": "https://arxiv.org/pdf/2509.10390", "abs": "https://arxiv.org/abs/2509.10390", "authors": ["Quan Nguyen", "Adji Bousso Dieng"], "title": "Vendi Information Gain for Active Learning and its Application to Ecology", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "comment": null, "summary": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG\nachieves impressive predictive accuracy close to full supervision using less\nthan 10% of the labels. It consistently outperforms standard baselines across\nmetrics and batch sizes, collecting more diverse data in the feature space. VIG\nhas broad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "AI": {"tldr": "The paper introduces Vendi Information Gain (VIG), an active learning policy to improve species identification from camera trap images. VIG focuses on dataset-wide prediction uncertainty and achieves high accuracy using limited labeled data.", "motivation": "Identifying species from camera trap images presents a challenge due to limited labeling resources. Active learning can optimize labeling efforts but often neglects dataset-wide uncertainty.", "method": "The paper proposes Vendi Information Gain (VIG), an active learning method that prioritizes data selection based on their impact on reducing prediction uncertainty across the entire dataset.", "result": "Using the Snapshot Serengeti dataset, VIG achieves near full supervision-level accuracy with less than 10% labeled data and consistently outperforms standard active learning baselines.", "conclusion": "VIG is an effective and resource-efficient approach for improving species identification in biodiversity monitoring, with potential applications extending beyond ecology."}}
{"id": "2509.10377", "pdf": "https://arxiv.org/pdf/2509.10377", "abs": "https://arxiv.org/abs/2509.10377", "authors": ["Yixiao Zhou", "Ziyu Zhao", "Dongzhou Cheng", "zhiliang wu", "Jie Gui", "Yi Yang", "Fei Wu", "Yu Cheng", "Hehe Fan"], "title": "Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs", "categories": ["cs.CL"], "comment": "Accepted to EMNLP2025", "summary": "Sparse Mixture-of-Experts (SMoE) architectures are widely used in large\nlanguage models (LLMs) due to their computational efficiency. However, though\nonly a few experts are activated for each token, SMoE still requires loading\nall expert parameters, leading to high memory usage and challenges in\ndeployment. Previous work has tried to reduce the overhead by pruning and\nmerging experts, but primarily focused on expert-level operations, leaving\nneuron-level structure underexplored. We propose DERN (Dropping Experts,\nRecombining Neurons), a task-agnostic and retraining-free framework for expert\npruning and reconstruction. We observe that experts are often misaligned and\ncontain semantic conflicts at the neuron level, which poses challenges for\ndirect merging. To solve this, DERN works in three steps: it first prunes\nredundant experts using router statistics; then it decomposes them into\nneuron-level expert segments, assigning each segment to its most compatible\nretained expert; and finally, it merges segments within each retained expert to\nbuild a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE\nmodels show that DERN improves performance by more than 5% on commonsense\nreasoning and MMLU benchmarks under 50% expert sparsity, without extra\ntraining. It also greatly reduces the number of experts and memory usage,\nmaking SMoE LLMs easier to deploy in practice.", "AI": {"tldr": "The paper introduces DERN, a method to optimize Sparse Mixture-of-Experts (SMoE) architectures by pruning redundant experts and reorganizing their neuron-level structure. This approach enhances efficiency and performance without requiring retraining.", "motivation": "To address the high memory usage and deployment challenges in Sparse Mixture-of-Experts (SMoE) architectures, despite their computational efficiency.", "method": "The proposed DERN framework prunes redundant experts, decomposes them into neuron-level expert segments, reallocates segments to retained experts, and merges them to create streamlined representations.", "result": "Experiments show that DERN achieves over 5% performance improvement on benchmarks such as commonsense reasoning and MMLU under 50% expert sparsity, while significantly reducing memory usage and the number of experts.", "conclusion": "DERN provides an effective solution for optimizing SMoE models by reducing redundancy and memory usage, improving performance, and easing practical deployment without retraining."}}
{"id": "2509.10260", "pdf": "https://arxiv.org/pdf/2509.10260", "abs": "https://arxiv.org/abs/2509.10260", "authors": ["Jia Wang", "Jie Hu", "Xiaoqi Ma", "Hanghang Ma", "Yanbing Zeng", "Xiaoming Wei"], "title": "MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image (T2I) generation has achieved remarkable progress in\ninstruction following and aesthetics. However, a persistent challenge is the\nprevalence of physical artifacts, such as anatomical and structural flaws,\nwhich severely degrade perceptual quality and limit application. Given the\ndiversity and complexity of these artifacts, a systematic and fine-grained\nevaluation framework is required, which is lacking in current benchmarks. To\nfill this gap, we introduce MagicMirror, a comprehensive framework for\nartifacts assessment. We first establish a detailed taxonomy of generated image\nartifacts. Guided by this taxonomy, we manually annotate MagicData340K, the\nfirst human-annotated large-scale dataset of 340K generated images with\nfine-grained artifact labels. Building on this dataset, we train MagicAssessor,\na Vision-Language Model (VLM) that provides detailed assessments and\ncorresponding labels. To overcome challenges like class imbalance and reward\nhacking, we design a novel data sampling strategy and a multi-level reward\nsystem for Group Relative Policy Optimization (GRPO). Finally, we leverage\nMagicAssessor to construct MagicBench, an automated benchmark for evaluating\nthe image artifacts of current T2I models. Our evaluation with MagicBench\nreveals that despite their widespread adoption, even top-tier models like\nGPT-image-1 are consistently plagued by significant artifacts, highlighting\nartifact reduction as a critical frontier for future T2I development. Project\npage: https://wj-inf.github.io/MagicMirror-page/.", "AI": {"tldr": "The paper introduces MagicMirror, a framework designed to systematically evaluate image artifacts in text-to-image (T2I) generation, addressing a gap in existing benchmarks.", "motivation": "The authors aim to tackle the issue of physical artifacts like anatomical and structural flaws in T2I-generated images, which degrade perceptual quality and hinder application. Existing benchmarks lack a systematic framework for assessing these artifacts.", "method": "The authors propose a taxonomy for image artifacts, annotate a large dataset (MagicData340K) with fine-grained labels, train a Vision-Language Model (MagicAssessor) with novel data strategies, and establish an automated benchmark (MagicBench) for T2I artifact evaluation.", "result": "Using the MagicBench benchmark, the authors demonstrate that even advanced T2I models, such as GPT-image-1, exhibit significant artifacts. Their framework successfully identifies and evaluates these issues.", "conclusion": "The presented work highlights the importance of reducing artifacts in T2I models and establishes MagicMirror as a critical tool for future development and evaluation in this domain."}}
{"id": "2509.10396", "pdf": "https://arxiv.org/pdf/2509.10396", "abs": "https://arxiv.org/abs/2509.10396", "authors": ["Siyan Zhao", "Mengchen Liu", "Jing Huang", "Miao Liu", "Chenyu Wang", "Bo Liu", "Yuandong Tian", "Guan Pang", "Sean Bell", "Aditya Grover", "Feiyu Chen"], "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "categories": ["cs.LG"], "comment": "preprint; 21 pages", "summary": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.", "AI": {"tldr": "The paper introduces IGPO, a reinforcement learning framework tailored for masked diffusion large language models (dLLMs), leveraging their inpainting ability to enhance exploration and sample efficiency. IGPO achieves state-of-the-art results across mathematical benchmarks.", "motivation": "Existing reinforcement learning methods for large language models suffer from inefficiencies due to sparse reward signals and exploration failures. Diffusion-based LLMs (dLLMs), with their unique inpainting capabilities, offer a potential solution for guiding exploration.", "method": "The paper presents IGPO (Inpainting Guided Policy Optimization), a framework utilizing dLLMs' inpainting ability to strategically insert reasoning traces during exploration. This approach bridges supervised fine-tuning with reinforcement learning to optimize trajectory spaces.", "result": "IGPO improves sample efficiency and restores meaningful gradients in group-based optimization methods like GRPO. The approach outperforms previous methods on GSM8K, Math500, and AMC benchmarks, showcasing substantial gains.", "conclusion": "IGPO leverages the unique properties of dLLMs to overcome exploration challenges in RL, demonstrating its efficacy through improved performance and sample efficiency. It establishes new benchmarks for mathematical reasoning in masked diffusion LLMs."}}
{"id": "2509.10414", "pdf": "https://arxiv.org/pdf/2509.10414", "abs": "https://arxiv.org/abs/2509.10414", "authors": ["Adrian de Wynter"], "title": "Is In-Context Learning Learning?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Director's cut", "summary": "In-context learning (ICL) allows some autoregressive models to solve tasks\nvia next-token prediction and without needing further training. This has led to\nclaims about these model's ability to solve (learn) unseen tasks with only a\nfew shots (exemplars) in the prompt. However, deduction does not always imply\nlearning, as ICL does not explicitly encode a given observation. Instead, the\nmodels rely on their prior knowledge and the exemplars given, if any. We argue\nthat, mathematically, ICL does constitute learning, but its full\ncharacterisation requires empirical work. We then carry out a large-scale\nanalysis of ICL ablating out or accounting for memorisation, pretraining,\ndistributional shifts, and prompting style and phrasing. We find that ICL is an\neffective learning paradigm, but limited in its ability to learn and generalise\nto unseen tasks. We note that, in the limit where exemplars become more\nnumerous, accuracy is insensitive to exemplar distribution, model, prompt\nstyle, and the input's linguistic features. Instead, it deduces patterns from\nregularities in the prompt, which leads to distributional sensitivity,\nespecially in prompting styles such as chain-of-thought. Given the varied\naccuracies on formally similar tasks, we conclude that autoregression's ad-hoc\nencoding is not a robust mechanism, and suggests limited all-purpose\ngeneralisability.", "AI": {"tldr": "The paper evaluates In-context learning (ICL), noting its effectiveness but highlighting its limitations in learning and generalizing to unseen tasks.", "motivation": "To understand whether In-context learning (ICL) constitutes true learning or if it relies primarily on prior knowledge and exemplars.", "method": "A large-scale analysis examining ICL by isolating factors like memorization, pretraining, distributional shifts, and prompting style.", "result": "ICL can learn but struggles to generalize to new tasks; accuracy depends on exemplar availability and prompt regularities.", "conclusion": "ICL's ability is limited by its ad-hoc encoding mechanism, suggesting restricted generalization to unseen tasks."}}
{"id": "2509.10266", "pdf": "https://arxiv.org/pdf/2509.10266", "abs": "https://arxiv.org/abs/2509.10266", "authors": ["Wenfang Wu", "Tingting Yuan", "Yupeng Li", "Daling Wang", "Xiaoming Fu"], "title": "SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Sign language translation (SLT) aims to translate natural language from sign\nlanguage videos, serving as a vital bridge for inclusive communication. While\nrecent advances leverage powerful visual backbones and large language models,\nmost approaches mainly focus on manual signals (hand gestures) and tend to\noverlook non-manual cues like mouthing. In fact, mouthing conveys essential\nlinguistic information in sign languages and plays a crucial role in\ndisambiguating visually similar signs. In this paper, we propose SignClip, a\nnovel framework to improve the accuracy of sign language translation. It fuses\nmanual and non-manual cues, specifically spatial gesture and lip movement\nfeatures. Besides, SignClip introduces a hierarchical contrastive learning\nframework with multi-level alignment objectives, ensuring semantic consistency\nacross sign-lip and visual-text modalities. Extensive experiments on two\nbenchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our\napproach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip\nsurpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from\n24.32 to 24.71, and ROUGE from 46.57 to 48.38.", "AI": {"tldr": "SignClip introduces a novel framework for sign language translation that incorporates manual and non-manual features like hand gestures and lip movements, achieving superior results on benchmark datasets.", "motivation": "To enhance inclusive communication by improving sign language translation, recognizing the importance of non-manual cues such as mouthing.", "method": "SignClip fuses spatial gesture and lip movement features, employing a hierarchical contrastive learning framework with multi-level alignment objectives to ensure semantic consistency across different modalities.", "result": "SignClip improves BLEU-4 and ROUGE scores, outperforming previous models like SpaMo on PHOENIX14T dataset.", "conclusion": "Integrating manual and non-manual cues significantly enhances sign language translation accuracy, highlighting mouthing's linguistic importance."}}
{"id": "2509.10406", "pdf": "https://arxiv.org/pdf/2509.10406", "abs": "https://arxiv.org/abs/2509.10406", "authors": ["Rupert Mitchell", "Kristian Kersting"], "title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining", "categories": ["cs.LG", "68W25, 68T50 (primary) 68W40, 68T07 (secondary)", "I.2.6; I.2.7"], "comment": null, "summary": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.", "AI": {"tldr": "MuSe offers an efficient approximation of softmax attention using semantic clustering and multipole expansions to reduce computational complexity in transformers, while preserving rich information and maintaining accuracy.", "motivation": "The paper aims to address the quadratic computational complexity problem of transformer models when dealing with long context lengths.", "method": "The authors introduce Multipole Semantic Attention (MuSe), which uses separate clustering of queries and keys in their learned spaces, combined with multipole expansions to build a hierarchical two-stage attention mechanism. Centroid-based approximations with dipole corrections are employed to capture richer information.", "result": "MuSe achieves a $3\\times$ speedup over CUDNN Flash Attention for isolated attention layers at 8k context length, with relative squared errors below 20%. For a pretraining setup with book-length texts, runtime is reduced by 12.2% with only a 0.36% loss degradation.", "conclusion": "Multipole approximations effectively reduce computational complexity in transformers without significant loss in accuracy, making them viable for efficient transformer pretraining and deployment."}}
{"id": "2509.10417", "pdf": "https://arxiv.org/pdf/2509.10417", "abs": "https://arxiv.org/abs/2509.10417", "authors": ["Christopher Ormerod", "Gitit Kehat"], "title": "Long Context Automated Essay Scoring with Language Models", "categories": ["cs.CL"], "comment": "8 pages, 2 figures, 2 tables", "summary": "Transformer-based language models are architecturally constrained to process\ntext of a fixed maximum length. Essays written by higher-grade students\nfrequently exceed the maximum allowed length for many popular open-source\nmodels. A common approach to addressing this issue when using these models for\nAutomated Essay Scoring is to truncate the input text. This raises serious\nvalidity concerns as it undermines the model's ability to fully capture and\nevaluate organizational elements of the scoring rubric, which requires long\ncontexts to assess. In this study, we evaluate several models that incorporate\narchitectural modifications of the standard transformer architecture to\novercome these length limitations using the Kaggle ASAP 2.0 dataset. The models\nconsidered in this study include fine-tuned versions of XLNet, Longformer,\nModernBERT, Mamba, and Llama models.", "AI": {"tldr": "This paper addresses the issue of maximum input length limitations in transformer-based language models for Automated Essay Scoring (AES) using several models with architectural modifications.", "motivation": "The authors aim to overcome the validity concerns caused by text truncation due to fixed length constraints in existing AES models.", "method": "Various modified transformer-based models, such as XLNet, Longformer, ModernBERT, Mamba, and Llama, were evaluated using the Kaggle ASAP 2.0 dataset.", "result": "The study performed comparative evaluations to understand how these models handle long-context inputs without truncation.", "conclusion": "Architectural adjustments to transformer-based models effectively mitigate the length constraints, improving their ability to assess essays accurately in AES tasks."}}
{"id": "2509.10278", "pdf": "https://arxiv.org/pdf/2509.10278", "abs": "https://arxiv.org/abs/2509.10278", "authors": ["Vidit Vidit", "Pavel Korshunov", "Amir Mohammadi", "Christophe Ecabert", "Ketan Kotwal", "S\u00e9bastien Marcel"], "title": "Detecting Text Manipulation in Images using Vision Language Models", "categories": ["cs.CV"], "comment": "Accepted in Synthetic Realities and Biometric Security Workshop\n  BMVC-2025. For paper page see https://www.idiap.ch/paper/textvlmdet/", "summary": "Recent works have shown the effectiveness of Large Vision Language Models\n(VLMs or LVLMs) in image manipulation detection. However, text manipulation\ndetection is largely missing in these studies. We bridge this knowledge gap by\nanalyzing closed- and open-source VLMs on different text manipulation datasets.\nOur results suggest that open-source models are getting closer, but still\nbehind closed-source ones like GPT- 4o. Additionally, we benchmark image\nmanipulation detection-specific VLMs for text manipulation detection and show\nthat they suffer from the generalization problem. We benchmark VLMs for\nmanipulations done on in-the-wild scene texts and on fantasy ID cards, where\nthe latter mimic a challenging real-world misuse.", "AI": {"tldr": "The paper studies the efficacy of large vision-language models (VLMs) in detecting text manipulation, identifying challenges in generalization capabilities and performance differences between open and closed-source models.", "motivation": "While prior research has shown VLMs to be effective in detecting image manipulations, their capacity to detect text manipulation remains unexplored. This paper aims to address this gap.", "method": "The authors evaluate closed- and open-source VLMs on various text manipulation datasets, including benchmarks on both in-the-wild scene texts and fantasy ID cards, simulating real-world misuse scenarios.", "result": "The findings indicate that open-source VLMs are improving in text manipulation detection but remain inferior to closed-source models like GPT-4. Additionally, image manipulation-specialized VLMs face generalization challenges in text manipulation tasks.", "conclusion": "Despite open-source advancements, closed-source VLMs maintain superiority, and specialized image-focused VLMs struggle to generalize to text manipulation scenarios. This underscores the need for improved modeling strategies."}}
{"id": "2509.10419", "pdf": "https://arxiv.org/pdf/2509.10419", "abs": "https://arxiv.org/abs/2509.10419", "authors": ["Francesco Vitale", "Tommaso Zoppi", "Francesco Flammini", "Nicola Mazzocca"], "title": "Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining", "categories": ["cs.LG"], "comment": "Accepted to the 6th International Conference on Reliability, Safety,\n  and Security of Railway Systems (RSSRail2025)", "summary": "Ensuring the resilience of computer-based railways is increasingly crucial to\naccount for uncertainties and changes due to the growing complexity and\ncriticality of those systems. Although their software relies on strict\nverification and validation processes following well-established best-practices\nand certification standards, anomalies can still occur at run-time due to\nresidual faults, system and environmental modifications that were unknown at\ndesign-time, or other emergent cyber-threat scenarios. This paper explores\nrun-time control-flow anomaly detection using process mining to enhance the\nresilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European\nTrain Control System Level 2). Process mining allows learning the actual\ncontrol flow of the system from its execution traces, thus enabling run-time\nmonitoring through online conformance checking. In addition, anomaly\nlocalization is performed through unsupervised machine learning to link\nrelevant deviations to critical system components. We test our approach on a\nreference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its\ncapability to detect and localize anomalies with high accuracy, efficiency, and\nexplainability.", "AI": {"tldr": "The paper investigates using process mining for real-time anomaly detection in ERTMS/ETCS L2 systems to enhance resilience, focusing on both detection and localization.", "motivation": "Anomalies in railway systems can occur despite rigorous software validation, due to design-time unknown conditions and emergent cyber-threats.", "method": "The approach combines process mining for understanding system control flow with unsupervised machine learning for anomaly detection and localization in run-time scenarios.", "result": "The methodology successfully identifies anomalies and links them to critical system components with high accuracy and efficiency in the RBC/RBC Handover scenario.", "conclusion": "The proposed framework effectively enhances railway system resilience by integrating monitoring and anomaly localization, offering explainability and practical applicability."}}
{"id": "2509.10436", "pdf": "https://arxiv.org/pdf/2509.10436", "abs": "https://arxiv.org/abs/2509.10436", "authors": ["Shadikur Rahman", "Aroosa Hameed", "Gautam Srivastava", "Syed Muhammad Danish"], "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment", "categories": ["cs.CL"], "comment": "12 pages, 5 figures, submitted to IEEE Transactions on Services\n  Computing", "summary": "To optimize the reasoning and problem-solving capabilities of Large Language\nModels (LLMs), we propose a novel cloud-edge collaborative architecture that\nenables a structured, multi-agent prompting framework. This framework comprises\nthree specialized components: GuideLLM, a lightweight model deployed at the\nedge to provide methodological guidance; SolverLLM, a more powerful model\nhosted in the cloud responsible for generating code solutions; and JudgeLLM, an\nautomated evaluator for assessing solution correctness and quality. To evaluate\nand demonstrate the effectiveness of this architecture in realistic settings,\nwe introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate\nand enhance the performance of Large Language Models (LLMs) across multi-domain\ncoding tasks. Motivated by the limitations of existing benchmarks,\nRefactorCoderQA systematically covers various technical domains, including\nSoftware Engineering, Data Science, Machine Learning, and Natural Language\nProcessing, using authentic coding challenges from Stack Overflow. Extensive\nexperiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves\nstate-of-the-art performance, significantly outperforming leading open-source\nand commercial baselines with an overall accuracy of 76.84%. Human evaluations\nfurther validate the interpretability, accuracy, and practical relevance of the\ngenerated solutions. In addition, we evaluate system-level metrics, such as\nthroughput and latency, to gain deeper insights into the performance\ncharacteristics and trade-offs of the proposed architecture.", "AI": {"tldr": "A cloud-edge collaborative architecture using three specialized LLM agents (GuideLLM, SolverLLM, JudgeLLM) achieves high accuracy in coding tasks benchmarked by RefactorCoderQA, surpassing existing solutions.", "motivation": "The limitations of existing benchmarks in reasoning and problem-solving capabilities of LLMs across multi-domain coding tasks.", "method": "Introduce a cloud-edge collaborative architecture with three specialized agents (GuideLLM, SolverLLM, JudgeLLM), supported by a new benchmark called RefactorCoderQA.", "result": "RefactorCoder-MoE, the fine-tuned model, demonstrated state-of-the-art performance with 76.84% accuracy, outperforming open-source and commercial alternatives.", "conclusion": "The cloud-edge framework and multi-domain coding benchmark improve LLM capabilities in real-world coding scenarios, while providing interpretability and efficiency."}}
{"id": "2509.10282", "pdf": "https://arxiv.org/pdf/2509.10282", "abs": "https://arxiv.org/abs/2509.10282", "authors": ["Gang Li", "Tianjiao Chen", "Mingle Zhou", "Min Li", "Delong Han", "Jin Wan"], "title": "MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection", "categories": ["cs.CV", "cs.LG"], "comment": "Page 14, 5 pictures", "summary": "Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects\nwithout relying on labeled training data, making it especially valuable in\nscenarios constrained by data scarcity, privacy, or high annotation cost.\nHowever, most existing methods focus exclusively on point clouds, neglecting\nthe rich semantic cues available from complementary modalities such as RGB\nimages and texts priors. This paper introduces MCL-AD, a novel framework that\nleverages multimodal collaboration learning across point clouds, RGB images,\nand texts semantics to achieve superior zero-shot 3D anomaly detection.\nSpecifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that\nenhances the intra-modal representation capability and inter-modal\ncollaborative learning by introducing an object-agnostic decoupled text prompt\nand a multimodal contrastive loss. In addition, a collaborative modulation\nmechanism (CMM) is proposed to fully leverage the complementary representations\nof point clouds and RGB images by jointly modulating the RGB image-guided and\npoint cloud-guided branches. Extensive experiments demonstrate that the\nproposed MCL-AD framework achieves state-of-the-art performance in ZS-3D\nanomaly detection.", "AI": {"tldr": "This paper develops MCL-AD, a framework for zero-shot 3D anomaly detection using multimodal learning with point clouds, RGB images, and textual semantics to achieve improved performance.", "motivation": "Address the challenge of 3D anomaly detection in zero-shot settings, aiming to reduce reliance on labeled training data and exploit multimodal information for enhanced detection accuracy.", "method": "Introduced a Multimodal Prompt Learning Mechanism (MPLM) and a collaborative modulation mechanism (CMM) to enhance intra-modal and inter-modal learning between point clouds, RGB images, and textual cues.", "result": "Experiments show that MCL-AD achieves state-of-the-art performance in zero-shot 3D anomaly detection tasks.", "conclusion": "MCL-AD effectively integrates multimodal data to overcome the limitations of existing methods and sets a new benchmark for zero-shot 3D anomaly detection."}}
{"id": "2509.10446", "pdf": "https://arxiv.org/pdf/2509.10446", "abs": "https://arxiv.org/abs/2509.10446", "authors": ["Rui Lu", "Zhenyu Hou", "Zihan Wang", "Hanchen Zhang", "Xiao Liu", "Yujiang Li", "Shi Feng", "Jie Tang", "Yuxiao Dong"], "title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL", "categories": ["cs.CL"], "comment": null, "summary": "Augmenting large language models (LLMs) with browsing tools substantially\nimproves their potential as deep search agents to solve complex, real-world\ntasks. Yet, open LLMs still perform poorly in such settings due to limited\nlong-horizon reasoning capacity with browsing tools and the lack of\nsufficiently difficult supervised data. To address these challenges, we present\nDeepDive to advance deep search agents. First, we propose a strategy to\nautomatically synthesize complex, difficult, and hard-to-find questions from\nopen knowledge graphs. Second, we apply end-to-end multi-turn reinforcement\nlearning (RL) to enhance LLMs' long-horizon reasoning with deep search.\nExperiments show that DeepDive-32B achieves a new open-source competitive\nresult on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and\nSearch-o1. We demonstrate that multi-turn RL training improves deep search\nability and significantly contributes to the performance improvements across\nmultiple benchmarks. We observe that DeepDive enables test-time scaling of tool\ncalls and parallel sampling. All datasets, models, and code are publicly\navailable at https://github.com/THUDM/DeepDive.", "AI": {"tldr": "DeepDive improves large language models (LLMs) for demanding search tasks using automatic question generation and multi-turn reinforcement learning, achieving competitive results.", "motivation": "Open LLMs struggle with long-horizon reasoning in complex search tasks due to limited supervised data and practical challenges.", "method": "DeepDive synthesizes complex questions from open knowledge graphs and applies multi-turn reinforcement learning to enhance LLM reasoning during browsing.", "result": "DeepDive-32B outperforms existing tools like WebSailor and DeepSeek in BrowseComp benchmarks and improves search abilities across other benchmarks.", "conclusion": "DeepDive advances deep search agents with better reasoning and scalability, providing valuable resources for open research."}}
{"id": "2509.10298", "pdf": "https://arxiv.org/pdf/2509.10298", "abs": "https://arxiv.org/abs/2509.10298", "authors": ["Laith Nayal", "Mahmoud Mousatat", "Bader Rasheed"], "title": "Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks", "categories": ["cs.CV"], "comment": "8 pages, 2 tables", "summary": "Deep neural networks and Vision Transformers achieve state-of-the-art\nperformance in computer vision but are highly vulnerable to adversarial\nperturbations. Standard defenses often incur high computational cost or lack\nformal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)\nmethod, where drop probabilities increase with depth to control the effective\nLipschitz constant of the network. This approach regularizes deeper layers,\nimproving robustness while preserving clean accuracy and reducing computation.\nExperiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent\nschedule maintains near-baseline clean accuracy, enhances robustness under\nFGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to\nbaseline and linear DropPath schedules.", "AI": {"tldr": "The paper introduces a novel method using Lipschitz-guided stochastic depth to enhance model robustness against adversarial attacks while preserving accuracy and reducing computational costs.", "motivation": "Deep models like Vision Transformers achieve high performance but are susceptible to adversarial attacks; traditional defenses are either computationally expensive or lack robust guarantees.", "method": "The method adjusts DropPath probabilities based on network depth to control the Lipschitz constant, regularizing deeper layers for better defense against adversarial attacks.", "result": "Experiments on CIFAR-10 with Vision Transformers demonstrate improved adversarial robustness, approximate baseline accuracy, and significant computation savings compared to other DropPath strategies.", "conclusion": "The proposed Lipschitz-guided stochastic depth method proves effective, addressing both robustness and computational issues without compromising accuracy."}}
{"id": "2509.10452", "pdf": "https://arxiv.org/pdf/2509.10452", "abs": "https://arxiv.org/abs/2509.10452", "authors": ["Akshat Pandey", "Karun Kumar", "Raphael Tang"], "title": "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers", "categories": ["cs.CL", "cs.LG"], "comment": "5 pages, 2 figures", "summary": "Pretrained automatic speech recognition (ASR) models such as Whisper perform\nwell but still need domain adaptation to handle unseen vocabulary and parlance.\nIn many real-world settings, collecting speech data is impractical,\nnecessitating text-only adaptation. We propose WhisTLE, a deeply supervised,\ntext-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE\ntrains a variational autoencoder (VAE) to model encoder outputs from text and\nfine-tunes the decoder using the learned text-to-latent encoder, optionally\ncombined with text-to-speech (TTS) adaptation. At inference, the original\nencoder is restored, incurring no extra runtime cost. Across four out-of-domain\ndatasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by\n12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines\nin 27 of 32 scenarios.", "AI": {"tldr": "The paper proposes \"WhisTLE,\" a text-only adaptation method for pretrained automatic speech recognition, reducing word error rates significantly compared to existing methods.", "motivation": "Domain adaptation for pretrained ASR models is necessary to handle unseen vocabulary and parlance, especially in situations where collecting speech data is impractical.", "method": "WhisTLE employs a variational autoencoder (VAE) to model encoder outputs from text, fine-tunes the decoder using a text-to-latent encoder, and optionally integrates text-to-speech (TTS) adaptation. During inference, the original encoder is restored without additional runtime costs.", "result": "WhisTLE demonstrates a 12.3% relative reduction in word error rate compared to TTS-only adaptation and achieves superior performance across multiple datasets and scenarios.", "conclusion": "The proposed WhisTLE method effectively adapts pretrained ASR models for out-of-domain tasks using text-only data, offering a practical solution without requiring extra computational costs during inference."}}
{"id": "2509.10310", "pdf": "https://arxiv.org/pdf/2509.10310", "abs": "https://arxiv.org/abs/2509.10310", "authors": ["Evan Murphy", "Marco Viola", "Vladimir A. Krylov"], "title": "A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments", "categories": ["cs.CV"], "comment": "Accepted for publication in the Proceedings of the 27th Irish Machine\n  Vision and Image Processing Conference (IMVIP 2025)", "summary": "In this paper we address the problem of precise geolocation of street\nfurniture in complex urban environments, which is a critical task for effective\nmonitoring and maintenance of public infrastructure by local authorities and\nprivate stakeholders. To this end, we propose a probabilistic framework based\non energy maps that encode the spatial likelihood of object locations.\nRepresenting the energy in a map-based geopositioned format allows the\noptimisation process to seamlessly integrate external geospatial information,\nsuch as GIS layers, road maps, or placement constraints, which improves\ncontextual awareness and localisation accuracy. A stochastic birth-and-death\noptimisation algorithm is introduced to infer the most probable configuration\nof assets. We evaluate our approach using a realistic simulation informed by a\ngeolocated dataset of street lighting infrastructure in Dublin city centre,\ndemonstrating its potential for scalable and accurate urban asset mapping. The\nimplementation of the algorithm will be made available in the GitHub repository\nhttps://github.com/EMurphy0108/SBD_Street_Furniture.", "AI": {"tldr": "The paper proposes a probabilistic framework using energy maps for precise geolocation of street furniture in urban environments, enhancing monitoring and maintenance through contextual integration of geographic information.", "motivation": "Precise geolocation of street furniture is essential for monitoring and maintaining public infrastructure in urban areas, where traditional methods may lack accuracy due to complex environments.", "method": "A probabilistic framework based on energy maps is developed, alongside a stochastic birth-and-death optimisation algorithm, allowing integration of external geospatial data for enhanced localisation.", "result": "Evaluation of the method is performed using a simulation based on Dublin's street lighting infrastructure, showcasing scalability and accuracy for mapping urban assets.", "conclusion": "The proposed framework and algorithm significantly improve urban asset mapping accuracy and scalability, and the implementation is openly accessible via GitHub."}}
{"id": "2509.10312", "pdf": "https://arxiv.org/pdf/2509.10312", "abs": "https://arxiv.org/abs/2509.10312", "authors": ["Zhixin Zheng", "Xinyu Wang", "Chang Zou", "Shaobo Wang", "Linfeng Zhang"], "title": "Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching", "categories": ["cs.CV"], "comment": "11 pages, 11 figures; Accepted by ACM MM2025; Mainly focus on feature\n  caching for diffusion transformers acceleration", "summary": "Diffusion transformers have gained significant attention in recent years for\ntheir ability to generate high-quality images and videos, yet still suffer from\na huge computational cost due to their iterative denoising process. Recently,\nfeature caching has been introduced to accelerate diffusion transformers by\ncaching the feature computation in previous timesteps and reusing it in the\nfollowing timesteps, which leverage the temporal similarity of diffusion models\nwhile ignoring the similarity in the spatial dimension. In this paper, we\nintroduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and\ncomplementary perspective for previous feature caching. Specifically, ClusCa\nperforms spatial clustering on tokens in each timestep, computes only one token\nin each cluster and propagates their information to all the other tokens, which\nis able to reduce the number of tokens by over 90%. Extensive experiments on\nDiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image\nand text-to-video generation. Besides, it can be directly applied to any\ndiffusion transformer without requirements for training. For instance, ClusCa\nachieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing\nthe original model by 0.51%. The code is available at\nhttps://github.com/Shenyi-Z/Cache4Diffusion.", "AI": {"tldr": "The paper presents ClusCa (Cluster-Driven Feature Caching), a method to accelerate diffusion transformers by leveraging spatial clustering, reducing computation costs while maintaining high-quality outputs.", "motivation": "Despite generating high-quality images and videos, diffusion transformers require excessive computational resources due to their iterative denoising process. Addressing this inefficiency is crucial for broader application.", "method": "ClusCa employs spatial clustering on token features in each timestep, reducing token count by over 90%. This process propagates cluster information to other tokens, complementing temporal caching approaches.", "result": "ClusCa demonstrated a 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing the original model in performance metrics while maintaining quality. Extensive tests verified effectiveness across text-to-image and text-to-video tasks.", "conclusion": "ClusCa significantly accelerates diffusion transformers without requiring additional training efforts, making it applicable across models and offering a practical solution for reducing computation costs efficiently."}}
{"id": "2509.10334", "pdf": "https://arxiv.org/pdf/2509.10334", "abs": "https://arxiv.org/abs/2509.10334", "authors": ["Jordan Sassoon", "Michal Szczepanski", "Martyna Poreba"], "title": "I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Vision Transformers (ViTs) have recently achieved strong results in semantic\nsegmentation, yet their deployment on resource-constrained devices remains\nlimited due to their high memory footprint and computational cost. Quantization\noffers an effective strategy to improve efficiency, but ViT-based segmentation\nmodels are notoriously fragile under low precision, as quantization errors\naccumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the\nfirst fully integer-only ViT segmentation framework. Building on the Segmenter\narchitecture, I-Segmenter systematically replaces floating-point operations\nwith integer-only counterparts. To further stabilize both training and\ninference, we propose $\\lambda$-ShiftGELU, a novel activation function that\nmitigates the limitations of uniform quantization in handling long-tailed\nactivation distributions. In addition, we remove the L2 normalization layer and\nreplace bilinear interpolation in the decoder with nearest neighbor upsampling,\nensuring integer-only execution throughout the computational graph. Extensive\nexperiments show that I-Segmenter achieves accuracy within a reasonable margin\nof its FP32 baseline (5.1 % on average), while reducing model size by up to\n3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,\neven in one-shot PTQ with a single calibration image, I-Segmenter delivers\ncompetitive accuracy, underscoring its practicality for real-world deployment.", "AI": {"tldr": "The paper presents I-Segmenter, the first integer-only Vision Transformer framework for semantic segmentation, addressing the computational and memory efficiency challenges of deploying ViTs on resource-constrained devices.", "motivation": "Deploying Vision Transformers for semantic segmentation on resource-limited devices faces challenges due to high computational costs and memory footprints. Existing quantization techniques are inadequate for ViT-based segmentation models as they are highly sensitive to precision errors.", "method": "I-Segmenter replaces floating-point operations with integer-only ones in the Segmenter architecture. It introduces $\\lambda$-ShiftGELU (a novel activation function) to stabilize training and inference, removes L2 normalization, and substitutes bilinear interpolation with nearest neighbor upsampling.", "result": "I-Segmenter achieves an accuracy reduction of 5.1% compared to FP32 baselines while reducing model size by up to 3.8x and improving inference speed by 1.2x. It performs competitively even with one-shot post-training quantization using a single calibration image.", "conclusion": "I-Segmenter demonstrates the feasibility of performing semantic segmentation using integer-only Vision Transformer models, making them more practical for deployment on resource-constrained devices without significant accuracy loss."}}
{"id": "2509.09740", "pdf": "https://arxiv.org/pdf/2509.09740", "abs": "https://arxiv.org/abs/2509.09740", "authors": ["Ying Yuan", "Xing-Yue Monica Ge", "Aaron Archer Waterman", "Tommaso Biancalani", "David Richmond", "Yogesh Pandit", "Avtar Singh", "Russell Littman", "Jin Liu", "Jan-Christian Huetter", "Vladimir Ermakov"], "title": "HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large-scale single-cell and Perturb-seq investigations routinely involve\nclustering cells and subsequently annotating each cluster with Gene-Ontology\n(GO) terms to elucidate the underlying biological programs. However, both\nstages, resolution selection and functional annotation, are inherently\nsubjective, relying on heuristics and expert curation. We present\nHYPOGENEAGENT, a large language model (LLM)-driven framework, transforming\ncluster annotation into a quantitatively optimizable task. Initially, an LLM\nfunctioning as a gene-set analyst analyzes the content of each gene program or\nperturbation module and generates a ranked list of GO-based hypotheses,\naccompanied by calibrated confidence scores. Subsequently, we embed every\npredicted description with a sentence-embedding model, compute pair-wise cosine\nsimilarities, and let the agent referee panel score (i) the internal\nconsistency of the predictions, high average similarity within the same\ncluster, termed intra-cluster agreement (ii) their external distinctiveness,\nlow similarity between clusters, termed inter-cluster separation. These two\nquantities are combined to produce an agent-derived resolution score, which is\nmaximized when clusters exhibit simultaneous coherence and mutual exclusivity.\nWhen applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary\ntest, our Resolution Score selects clustering granularities that exhibit\nalignment with known pathway compared to classical metrics such silhouette\nscore, modularity score for gene functional enrichment summary. These findings\nestablish LLM agents as objective adjudicators of cluster resolution and\nfunctional annotation, thereby paving the way for fully automated,\ncontext-aware interpretation pipelines in single-cell multi-omics studies.", "AI": {"tldr": "HYPOGENEAGENT utilizes a large language model (LLM) to optimize cluster annotation in single-cell studies, providing calibrated GO term hypotheses and resolution scores for improved alignment with biological pathways.", "motivation": "Current clustering and annotation practices in single-cell and Perturb-seq studies are subjective and rely heavily on expert judgment, creating inconsistency and bias.", "method": "The framework uses an LLM to generate ranked lists of Gene-Ontology hypotheses and confidence scores. It then evaluates intra-cluster agreement and inter-cluster separation using sentence embeddings and cosine similarities to optimize cluster resolution.", "result": "Testing HYPOGENEAGENT on a K562 CRISPRi Perturb-seq dataset demonstrated its ability to select clustering granularities that better align with known biological pathways compared to classical metrics.", "conclusion": "HYPOGENEAGENT represents an advancement towards automated and unbiased cluster resolution and annotation, addressing subjectivity in single-cell multi-omics analysis."}}
{"id": "2509.09690", "pdf": "https://arxiv.org/pdf/2509.09690", "abs": "https://arxiv.org/abs/2509.09690", "authors": ["Ping Liu", "Jianqiang Shen", "Qianqi Shen", "Chunnan Yao", "Kevin Kao", "Dan Xu", "Rajat Arora", "Baofen Zheng", "Caleb Johnson", "Liangjie Hong", "Jingwei Wu", "Wenjing Zhang"], "title": "Powering Job Search at Scale: LLM-Enhanced Query Understanding in Job Matching Systems", "categories": ["cs.IR", "cs.LG"], "comment": "CIKM2025", "summary": "Query understanding is essential in modern relevance systems, where user\nqueries are often short, ambiguous, and highly context-dependent. Traditional\napproaches often rely on multiple task-specific Named Entity Recognition models\nto extract structured facets as seen in job search applications. However, this\nfragmented architecture is brittle, expensive to maintain, and slow to adapt to\nevolving taxonomies and language patterns. In this paper, we introduce a\nunified query understanding framework powered by a Large Language Model (LLM),\ndesigned to address these limitations. Our approach jointly models the user\nquery and contextual signals such as profile attributes to generate structured\ninterpretations that drive more accurate and personalized recommendations. The\nframework improves relevance quality in online A/B testing while significantly\nreducing system complexity and operational overhead. The results demonstrate\nthat our solution provides a scalable and adaptable foundation for query\nunderstanding in dynamic web applications.", "AI": {"tldr": "The paper proposes a unified query understanding framework using a Large Language Model (LLM) to improve query interpretation, relevance, and scalability in dynamic web applications.", "motivation": "Traditional query understanding methods use multiple task-specific models that are costly to maintain, slow to update, and brittle against changes in language and taxonomy.", "method": "The paper introduces a unified framework powered by an LLM that jointly processes user queries and contextual factors like profile attributes to produce structured interpretations for better personalization and recommendations.", "result": "The proposed framework enhances relevance quality in online A/B testing while simultaneously reducing system complexity and operational costs.", "conclusion": "This unified LLM-based approach offers a scalable, adaptable, and more accurate solution for modern query understanding in web applications."}}
{"id": "2509.10341", "pdf": "https://arxiv.org/pdf/2509.10341", "abs": "https://arxiv.org/abs/2509.10341", "authors": ["Botond Fazekas", "Thomas Pinetz", "Guilherme Aresta", "Taha Emre", "Hrvoje Bogunovic"], "title": "GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT", "categories": ["cs.CV"], "comment": null, "summary": "Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing\nand monitoring retinal diseases. However, OCT images are inherently degraded by\nspeckle noise, which obscures fine details and hinders accurate interpretation.\nWhile numerous denoising methods exist, many struggle to balance noise\nreduction with the preservation of crucial anatomical structures. This paper\nintroduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel\ndeep learning approach for OCT image despeckling that leverages the strengths\nof diffusion probabilistic models. Unlike conventional diffusion models that\nassume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more\naccurately reflect the statistical properties of speckle. Furthermore, we\nintroduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,\nless-noisy image to guide the denoising process. This crucial addition prevents\nthe reintroduction of high-frequency noise. We accelerate the inference process\nby adapting the Denoising Diffusion Implicit Model framework to our Gamma-based\nmodel. Experiments on a dataset with paired noisy and less-noisy OCT B-scans\ndemonstrate that GARD significantly outperforms traditional denoising methods\nand state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.\nQualitative results confirm that GARD produces sharper edges and better\npreserves fine anatomical details.", "AI": {"tldr": "The paper introduces GARD, a novel deep learning method for despeckling OCT images, leveraging diffusion probabilistic models tailored for speckle noise with enhanced methods for noise handling and accelerated inference.", "motivation": "Speckle noise degrades OCT images, obscuring details required for diagnosing and monitoring retinal diseases, and existing methods fail to balance noise reduction with preserving anatomical structures.", "method": "The paper proposes GARD, a Denoising Diffusion Gamma Model that reflects the statistical nature of speckle noise, alongside a Noise-Reduced Fidelity Term for maintaining fine details and an accelerated inference adaptation.", "result": "GARD outperformed traditional methods and advanced models in PSNR, SSIM, and MSE on noisy OCT datasets. Visual results showed sharper edges and better anatomical detail preservation.", "conclusion": "GARD effectively addresses speckle noise in OCT, offering significant qualitative and quantitative improvements over existing denoising techniques."}}
{"id": "2509.09695", "pdf": "https://arxiv.org/pdf/2509.09695", "abs": "https://arxiv.org/abs/2509.09695", "authors": ["Fabio Magarelli", "Geraldine B. Boylan", "Saeed Montazeri", "Feargal O'Sullivan", "Dominic Lightbody", "Minoo Ashoori", "Tamara Skoric Ceranic", "John M. O'Toole"], "title": "Machine-learning competition to grade EEG background patterns in newborns with hypoxic-ischaemic encephalopathy", "categories": ["eess.SP", "cs.LG"], "comment": "29 pages, supplementary materials: \"supplementary materials ML\n  Comp.docx\"", "summary": "Machine learning (ML) has the potential to support and improve expert\nperformance in monitoring the brain function of at-risk newborns. Developing\naccurate and reliable ML models depends on access to high-quality, annotated\ndata, a resource in short supply. ML competitions address this need by\nproviding researchers access to expertly annotated datasets, fostering shared\nlearning through direct model comparisons, and leveraging the benefits of\ncrowdsourcing diverse expertise. We compiled a retrospective dataset containing\n353 hours of EEG from 102 individual newborns from a multi-centre study. The\ndata was fully anonymised and divided into training, testing, and held-out\nvalidation datasets. EEGs were graded for the severity of abnormal background\npatterns. Next, we created a web-based competition platform and hosted a\nmachine learning competition to develop ML models for classifying the severity\nof EEG background patterns in newborns. After the competition closed, the top 4\nperforming models were evaluated offline on a separate held-out validation\ndataset. Although a feature-based model ranked first on the testing dataset,\ndeep learning models generalised better on the validation sets. All methods had\na significant decline in validation performance compared to the testing\nperformance. This highlights the challenges for model generalisation on unseen\ndata, emphasising the need for held-out validation datasets in ML studies with\nneonatal EEG. The study underscores the importance of training ML models on\nlarge and diverse datasets to ensure robust generalisation. The competition's\noutcome demonstrates the potential for open-access data and collaborative ML\ndevelopment to foster a collaborative research environment and expedite the\ndevelopment of clinical decision-support tools for neonatal neuromonitoring.", "AI": {"tldr": "The paper discusses a machine learning competition using neonatal EEG data to classify brain abnormality severity, emphasizing the importance of robust data and validation for generalization.", "motivation": "The study aims to address the limited access to high-quality, annotated EEG data essential for developing robust machine learning models for monitoring brain function in at-risk newborns.", "method": "The researchers compiled a retrospective multi-center EEG dataset from 102 newborns, created training, testing, and validation sets, hosted a web-based ML competition, and evaluated top-performing models using a held-out validation set.", "result": "The feature-based model ranked highest on the testing dataset, but deep learning models showed better generalization on the validation sets. All methods exhibited performance drops when applied to unseen data.", "conclusion": "The research highlights the necessity of large, diverse datasets and held-out validation for generalization, showcasing the potential of collaborative ML competitions to aid neonatal neuromonitoring advancements."}}
{"id": "2509.10344", "pdf": "https://arxiv.org/pdf/2509.10344", "abs": "https://arxiv.org/abs/2509.10344", "authors": ["Yuexi Du", "Lihui Chen", "Nicha C. Dvornek"], "title": "GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by MICCAI 2025", "summary": "Mammography screening is an essential tool for early detection of breast\ncancer. The speed and accuracy of mammography interpretation have the potential\nto be improved with deep learning methods. However, the development of a\nfoundation visual language model (VLM) is hindered by limited data and domain\ndifferences between natural and medical images. Existing mammography VLMs,\nadapted from natural images, often ignore domain-specific characteristics, such\nas multi-view relationships in mammography. Unlike radiologists who analyze\nboth views together to process ipsilateral correspondence, current methods\ntreat them as independent images or do not properly model the multi-view\ncorrespondence learning, losing critical geometric context and resulting in\nsuboptimal prediction. We propose GLAM: Global and Local Alignment for\nMulti-view mammography for VLM pretraining using geometry guidance. By\nleveraging the prior knowledge about the multi-view imaging process of\nmammograms, our model learns local cross-view alignments and fine-grained local\nfeatures through joint global and local, visual-visual, and visual-language\ncontrastive learning. Pretrained on EMBED [14], one of the largest open\nmammography datasets, our model outperforms baselines across multiple datasets\nunder different settings.", "AI": {"tldr": "The paper introduces GLAM, a new visual language model designed for mammography, addressing limitations in adapting natural image VLMs to medical contexts.", "motivation": "Current mammography VLMs fail to incorporate crucial geometric and multi-view relationships, which radiologists traditionally use for analysis, resulting in compromised prediction accuracy.", "method": "GLAM leverages geometric knowledge from the mammography process by utilizing cross-view alignments and contrastive learning methods to enhance global and local feature understanding.", "result": "GLAM, when pretrained on the EMBED dataset, outperforms existing models across multiple datasets and diverse settings.", "conclusion": "The proposed GLAM model improves prediction by incorporating mammography-specific characteristics, advancing visual language models for medical applications."}}
{"id": "2509.10345", "pdf": "https://arxiv.org/pdf/2509.10345", "abs": "https://arxiv.org/abs/2509.10345", "authors": ["Georgios Pantazopoulos", "Eda B. \u00d6zyi\u011fit"], "title": "Towards Understanding Visual Grounding in Visual Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual grounding refers to the ability of a model to identify a region within\nsome visual input that matches a textual description. Consequently, a model\nequipped with visual grounding capabilities can target a wide range of\napplications in various domains, including referring expression comprehension,\nanswering questions pertinent to fine-grained details in images or videos,\ncaption visual context by explicitly referring to entities, as well as low and\nhigh-level control in simulated and real environments. In this survey paper, we\nreview representative works across the key areas of research on modern\ngeneral-purpose vision language models (VLMs). We first outline the importance\nof grounding in VLMs, then delineate the core components of the contemporary\nparadigm for developing grounded models, and examine their practical\napplications, including benchmarks and evaluation metrics for grounded\nmultimodal generation. We also discuss the multifaceted interrelations among\nvisual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,\nwe analyse the challenges inherent to visual grounding and suggest promising\ndirections for future research.", "AI": {"tldr": "This paper reviews approaches to visual grounding in vision-language models (VLMs), summarizing methodologies, applications, challenges, and future directions.", "motivation": "The motivation is to explore visual grounding capabilities in VLMs, which enable models to connect textual descriptions with specific visual regions, benefiting various fine-grained tasks and applications.", "method": "The method involves surveying key works in modern VLMs, analyzing their components, benchmarks, evaluation metrics, and interrelations among visual grounding, reasoning, and multimodal chain-of-thought.", "result": "The paper systematically classifies and critiques advancements, applications, and interplay of key aspects in grounding VLMs.", "conclusion": "Visual grounding plays a crucial role in VLM development. The paper underscores existing challenges and highlights promising research directions for improving grounded multimodal systems."}}
{"id": "2509.10359", "pdf": "https://arxiv.org/pdf/2509.10359", "abs": "https://arxiv.org/abs/2509.10359", "authors": ["Matteo Trippodo", "Federico Becattini", "Lorenzo Seidenari"], "title": "Immunizing Images from Text to Image Editing via Adversarial Cross-Attention", "categories": ["cs.CV"], "comment": "Accepted as Regular Paper at ACM Multimedia 2025", "summary": "Recent advances in text-based image editing have enabled fine-grained\nmanipulation of visual content guided by natural language. However, such\nmethods are susceptible to adversarial attacks. In this work, we propose a\nnovel attack that targets the visual component of editing methods. We introduce\nAttention Attack, which disrupts the cross-attention between a textual prompt\nand the visual representation of the image by using an automatically generated\ncaption of the source image as a proxy for the edit prompt. This breaks the\nalignment between the contents of the image and their textual description,\nwithout requiring knowledge of the editing method or the editing prompt.\nReflecting on the reliability of existing metrics for immunization success, we\npropose two novel evaluation strategies: Caption Similarity, which quantifies\nsemantic consistency between original and adversarial edits, and semantic\nIntersection over Union (IoU), which measures spatial layout disruption via\nsegmentation masks. Experiments conducted on the TEDBench++ benchmark\ndemonstrate that our attack significantly degrades editing performance while\nremaining imperceptible.", "AI": {"tldr": "The paper presents Attention Attack, a novel adversarial method against text-based image editing tools, disrupting cross-attention using image captions as proxies for editing prompts.", "motivation": "To address the susceptibility of fine-grained text-based image editing methods to adversarial attacks.", "method": "The proposed attack interferes with cross-attention mechanisms by replacing edit prompts with automatically generated captions, disrupting alignment between text and images.", "result": "Experiments using TEDBench++ showed significant degradation in editing performance while maintaining imperceptibility of the attack.", "conclusion": "Attention Attack effectively compromises editing reliability without requiring prior knowledge of editing methods, offering novel evaluation strategies like Caption Similarity and semantic IoU."}}
{"id": "2509.09717", "pdf": "https://arxiv.org/pdf/2509.09717", "abs": "https://arxiv.org/abs/2509.09717", "authors": ["Jorge E. Le\u00f3n", "Miguel Carrasco"], "title": "Testing chatbots on the creation of encoders for audio conditioned image generation", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "On one hand, recent advances in chatbots has led to a rising popularity in\nusing these models for coding tasks. On the other hand, modern generative image\nmodels primarily rely on text encoders to translate semantic concepts into\nvisual representations, even when there is clear evidence that audio can be\nemployed as input as well. Given the previous, in this work, we explore whether\nstate-of-the-art conversational agents can design effective audio encoders to\nreplace the CLIP text encoder from Stable Diffusion 1.5, enabling image\nsynthesis directly from sound. We prompted five publicly available chatbots to\npropose neural architectures to work as these audio encoders, with a set of\nwell-explained shared conditions. Each valid suggested encoder was trained on\nover two million context related audio-image-text observations, and evaluated\non held-out validation and test sets using various metrics, together with a\nqualitative analysis of their generated images. Although almost all chatbots\ngenerated valid model designs, none achieved satisfactory results, indicating\nthat their audio embeddings failed to align reliably with those of the original\ntext encoder. Among the proposals, the Gemini audio encoder showed the best\nquantitative metrics, while the Grok audio encoder produced more coherent\nimages (particularly, when paired with the text encoder). Our findings reveal a\nshared architectural bias across chatbots and underscore the remaining coding\ngap that needs to be bridged in future versions of these models. We also\ncreated a public demo so everyone could study and try out these audio encoders.\nFinally, we propose research questions that should be tackled in the future,\nand encourage other researchers to perform more focused and highly specialized\ntasks like this one, so the respective chatbots cannot make use of well-known\nsolutions and their creativity/reasoning is fully tested.", "AI": {"tldr": "The paper evaluates whether conversational agents can design neural audio encoders to replace text encoders in image synthesis models, finding limited success in achieving alignment with the original text encoder.", "motivation": "To explore whether conversational agents can effectively innovate by designing novel neural architectures for unique tasks such as audio-to-visual synthesis.", "method": "State-of-the-art chatbots were prompted to propose audio encoder architectures under standardized conditions. Valid designs were trained on a dataset of over two million contextually related audio-image-text samples and evaluated using various metrics and qualitative analyses.", "result": "All tested chatbots generated viable models, but none achieved satisfactory results. Among them, the Gemini audio encoder had the best quantitative metrics, while the Grok encoder delivered more coherent images.", "conclusion": "Current conversational agents exhibit architectural biases, and their proposed solutions lack the ability to fully align audio embeddings with text embeddings in the context of image synthesis. Further research and more challenging tasks are necessary to test the creativity and reasoning of such agents."}}
{"id": "2509.10366", "pdf": "https://arxiv.org/pdf/2509.10366", "abs": "https://arxiv.org/abs/2509.10366", "authors": ["Fabien Allemand", "Attilio Fiandrotti", "Sumanta Chaudhuri", "Alaa Eddine Mazouz"], "title": "Efficient Learned Image Compression Through Knowledge Distillation", "categories": ["cs.CV"], "comment": "19 pages, 21 figures", "summary": "Learned image compression sits at the intersection of machine learning and\nimage processing. With advances in deep learning, neural network-based\ncompression methods have emerged. In this process, an encoder maps the image to\na low-dimensional latent space, which is then quantized, entropy-coded into a\nbinary bitstream, and transmitted to the receiver. At the receiver end, the\nbitstream is entropy-decoded, and a decoder reconstructs an approximation of\nthe original image. Recent research suggests that these models consistently\noutperform conventional codecs. However, they require significant processing\npower, making them unsuitable for real-time use on resource-constrained\nplatforms, which hinders their deployment in mainstream applications. This\nstudy aims to reduce the resource requirements of neural networks used for\nimage compression by leveraging knowledge distillation, a training paradigm\nwhere smaller neural networks, partially trained on the outputs of larger, more\ncomplex models, can achieve better performance than when trained independently.\nOur work demonstrates that knowledge distillation can be effectively applied to\nimage compression tasks: i) across various architecture sizes, ii) to achieve\ndifferent image quality/bit rate tradeoffs, and iii) to save processing and\nenergy resources. This approach introduces new settings and hyperparameters,\nand future research could explore the impact of different teacher models, as\nwell as alternative loss functions. Knowledge distillation could also be\nextended to transformer-based models. The code is publicly available at:\nhttps://github.com/FABallemand/PRIM .", "AI": {"tldr": "This paper applies knowledge distillation to develop smaller, more efficient neural networks for learned image compression.", "motivation": "Conventional learned image compression methods outperform traditional codecs but demand high processing power, limiting their applicability in resource-constrained environments.", "method": "The study utilizes knowledge distillation to train smaller neural networks on partially processed outputs from larger models, optimizing performance for image compression while reducing computational demand.", "result": "Knowledge distillation proved effective for improving performance across different model sizes and compression trade-offs, while also conserving resources.", "conclusion": "The paper highlights the potential of knowledge distillation to make learned image compression more feasible, while proposing future avenues for exploration, including adapting to transformer-based models and alternative configurations."}}
{"id": "2509.10388", "pdf": "https://arxiv.org/pdf/2509.10388", "abs": "https://arxiv.org/abs/2509.10388", "authors": ["Zeqing Leo Yuan", "Mani Ramanagopal", "Aswin C. Sankaranarayanan", "Srinivasa G. Narasimhan"], "title": "Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition", "categories": ["cs.CV"], "comment": null, "summary": "Decomposing an image into its intrinsic photometric factors--shading and\nreflectance--is a long-standing challenge due to the lack of extensive\nground-truth data for real-world scenes. Recent methods rely on synthetic data\nor sparse annotations for limited indoor and even fewer outdoor scenes. We\nintroduce a novel training-free approach for intrinsic image decomposition\nusing only a pair of visible and thermal images. We leverage the principle that\nlight not reflected from an opaque surface is absorbed and detected as heat by\na thermal camera. This allows us to relate the ordinalities between visible and\nthermal image intensities to the ordinalities of shading and reflectance, which\ncan densely self-supervise an optimizing neural network to recover shading and\nreflectance. We perform quantitative evaluations with known reflectance and\nshading under natural and artificial lighting, and qualitative experiments\nacross diverse outdoor scenes. The results demonstrate superior performance\nover recent learning-based models and point toward a scalable path to curating\nreal-world ordinal supervision, previously infeasible via manual labeling.", "AI": {"tldr": "The paper proposes a training-free method for intrinsic image decomposition using visible and thermal image pairs, achieving superior results compared to learning-based methods.", "motivation": "Address the challenge of intrinsic image decomposition due to the lack of extensive real-world ground-truth data.", "method": "Utilizes ordinalities between visible and thermal images to self-supervise a neural network, avoiding reliance on synthetic data or sparse annotations.", "result": "The method achieves quantitative and qualitative success in recovering shading and reflectance, especially in diverse outdoor scenes.", "conclusion": "The approach offers improved performance over learning-based models and a scalable way to curate real-world ordinal supervision."}}
{"id": "2509.09787", "pdf": "https://arxiv.org/pdf/2509.09787", "abs": "https://arxiv.org/abs/2509.09787", "authors": ["Nojan Sheybani", "Alessandro Pegoraro", "Jonathan Knauer", "Phillip Rieger", "Elissa Mollakuqe", "Farinaz Koushanfar", "Ahmad-Reza Sadeghi"], "title": "ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full Version)", "categories": ["cs.CR", "cs.AI"], "comment": "Full version of CCS 2025 paper", "summary": "Split Learning (SL) is a distributed learning approach that enables\nresource-constrained clients to collaboratively train deep neural networks\n(DNNs) by offloading most layers to a central server while keeping in- and\noutput layers on the client-side. This setup enables SL to leverage server\ncomputation capacities without sharing data, making it highly effective in\nresource-constrained environments dealing with sensitive data. However, the\ndistributed nature enables malicious clients to manipulate the training\nprocess. By sending poisoned intermediate gradients, they can inject backdoors\ninto the shared DNN. Existing defenses are limited by often focusing on\nserver-side protection and introducing additional overhead for the server. A\nsignificant challenge for client-side defenses is enforcing malicious clients\nto correctly execute the defense algorithm.\n  We present ZORRO, a private, verifiable, and robust SL defense scheme.\nThrough our novel design and application of interactive zero-knowledge proofs\n(ZKPs), clients prove their correct execution of a client-located defense\nalgorithm, resulting in proofs of computational integrity attesting to the\nbenign nature of locally trained DNN portions. Leveraging the frequency\nrepresentation of model partitions enables ZORRO to conduct an in-depth\ninspection of the locally trained models in an untrusted environment, ensuring\nthat each client forwards a benign checkpoint to its succeeding client. In our\nextensive evaluation, covering different model architectures as well as various\nattack strategies and data scenarios, we show ZORRO's effectiveness, as it\nreduces the attack success rate to less than 6\\% while causing even for models\nstoring \\numprint{1000000} parameters on the client-side an overhead of less\nthan 10 seconds.", "AI": {"tldr": "Split Learning (SL) allows resource-constrained clients to train neural networks collaboratively, but faces backdoor attack vulnerabilities from malicious clients. ZORRO uses zero-knowledge proofs to ensure integrity and defense on the client-side.", "motivation": "The paper aims to address the challenge of preventing malicious clients in SL frameworks from manipulating the training process and injecting backdoors into shared neural networks.", "method": "ZORRO, a defense scheme utilizing interactive zero-knowledge proofs, ensures computational integrity of client-side defense algorithms. It inspects locally trained DNN portions using frequency representation while maintaining low computational overhead.", "result": "The method demonstrates effectiveness by reducing attack success rates to under 6% and incurs minimal computational overhead even for complex models, making it scalable and practical.", "conclusion": "ZORRO introduces a robust client-side solution to mitigate backdoor attacks in SL setups while maintaining efficiency and scalability, ensuring secure collaborative learning environments."}}
{"id": "2509.10407", "pdf": "https://arxiv.org/pdf/2509.10407", "abs": "https://arxiv.org/abs/2509.10407", "authors": ["Xiem HoangVan", "Dang BuiDinh", "Sang NguyenQuang", "Wen-Hsiao Peng"], "title": "Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards", "categories": ["cs.CV"], "comment": null, "summary": "Compressed video quality enhancement (CVQE) is crucial for improving user\nexperience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.\nWhile deep learning based CVQE has driven significant progress, existing\nsurveys still suffer from limitations: lack of systematic classification\nlinking methods to specific standards and artifacts, insufficient comparative\nanalysis of architectural paradigms across coding types, and underdeveloped\nbenchmarking practices. To address these gaps, this paper presents three key\ncontributions. First, it introduces a novel taxonomy classifying CVQE methods\nacross architectural paradigms, coding standards, and compressed-domain feature\nutilization. Second, it proposes a unified benchmarking framework integrating\nmodern compression protocols and standard test sequences for fair\nmulti-criteria evaluation. Third, it provides a systematic analysis of the\ncritical trade-offs between reconstruction performance and computational\ncomplexity observed in state-of-the-art methods and highlighting promising\ndirections for future research. This comprehensive review aims to establish a\nfoundation for consistent assessment and informed model selection in CVQE\nresearch and deployment.", "AI": {"tldr": "The paper focuses on improving compressed video quality enhancement (CVQE) by addressing limitations in current surveys, proposing a novel taxonomy, a unified benchmarking framework, and a systematic trade-off analysis.", "motivation": "The goal is to improve user experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC, and bridge gaps in existing CVQE research including classification, comparative analysis, and benchmarking.", "method": "The study introduces a novel taxonomy for CVQE methods, proposes a unified benchmarking framework for fair evaluation, and conducts a systematic analysis of performance versus computational complexity trade-offs.", "result": "It provides insights and tools for structured evaluation and performance optimization of CVQE methods, establishing clear trade-offs and highlighting areas for future advancements.", "conclusion": "The paper aims to create a comprehensive foundation for consistent evaluation and better model selection in CVQE research, helping to advance the field."}}
{"id": "2509.10408", "pdf": "https://arxiv.org/pdf/2509.10408", "abs": "https://arxiv.org/abs/2509.10408", "authors": ["Iacopo Curti", "Pierluigi Zama Ramirez", "Alioscia Petrelli", "Luigi Di Stefano"], "title": "Multimodal SAM-adapter for Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Semantic segmentation, a key task in computer vision with broad applications\nin autonomous driving, medical imaging, and robotics, has advanced\nsubstantially with deep learning. Nevertheless, current approaches remain\nvulnerable to challenging conditions such as poor lighting, occlusions, and\nadverse weather. To address these limitations, multimodal methods that\nintegrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,\nproviding complementary information that enhances robustness. In this work, we\npresent MM SAM-adapter, a novel framework that extends the capabilities of the\nSegment Anything Model (SAM) for multimodal semantic segmentation. The proposed\nmethod employs an adapter network that injects fused multimodal features into\nSAM's rich RGB features. This design enables the model to retain the strong\ngeneralization ability of RGB features while selectively incorporating\nauxiliary modalities only when they contribute additional cues. As a result, MM\nSAM-adapter achieves a balanced and efficient use of multimodal information. We\nevaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,\nwhere MM SAM-adapter delivers state-of-the-art performance. To further analyze\nmodality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard\nsubsets. Results consistently demonstrate that our framework outperforms\ncompeting methods in both favorable and adverse conditions, highlighting the\neffectiveness of multimodal adaptation for robust scene understanding. The code\nis available at the following link:\nhttps://github.com/iacopo97/Multimodal-SAM-Adapter.", "AI": {"tldr": "This paper introduces MM SAM-adapter, a new framework for multimodal semantic segmentation that extends the Segment Anything Model (SAM) to effectively integrate auxiliary sensor data, achieving state-of-the-art performance on several benchmarks.", "motivation": "Current semantic segmentation methods struggle in challenging conditions (e.g., poor lighting, occlusions), prompting the need for multimodal approaches that integrate additional sensor data to enhance robustness.", "method": "The proposed MM SAM-adapter uses an adapter network to inject fused multimodal features into SAM's RGB-based features, balancing generalization with modality-specific contributions for robust segmentation.", "result": "MM SAM-adapter achieves state-of-the-art performance on three benchmarks\u2014DeLiVER, FMB, and MUSES\u2014and demonstrates consistent superiority under both favorable and adverse conditions on RGB-easy and RGB-hard subsets.", "conclusion": "The MM SAM-adapter framework highlights the benefits of multimodal adaptation in improving robustness for semantic segmentation tasks, offering a promising way to leverage auxiliary sensor data in challenging scenarios."}}
{"id": "2509.09823", "pdf": "https://arxiv.org/pdf/2509.09823", "abs": "https://arxiv.org/abs/2509.09823", "authors": ["Yixuan Gao", "Tanvir Ahmed", "Shuang He", "Zhongqi Cheng", "Rajalakshmi Nandakumar"], "title": "SoilSound: Smartphone-based Soil Moisture Estimation", "categories": ["cs.SD", "cs.AI", "cs.ET", "cs.HC", "eess.SP"], "comment": "12 pages, 8 figures", "summary": "Soil moisture monitoring is essential for agriculture and environmental\nmanagement, yet existing methods require either invasive probes disturbing the\nsoil or specialized equipment, limiting access to the public. We present\nSoilSound, an ubiquitous accessible smartphone-based acoustic sensing system\nthat can measure soil moisture without disturbing the soil. We leverage the\nbuilt-in speaker and microphone to perform a vertical scan mechanism to\naccurately measure moisture without any calibration. Unlike existing work that\nuse transmissive properties, we propose an alternate model for acoustic\nreflections in soil based on the surface roughness effect to enable moisture\nsensing without disturbing the soil. The system works by sending acoustic\nchirps towards the soil and recording the reflections during a vertical scan,\nwhich are then processed and fed to a convolutional neural network for\non-device soil moisture estimation with negligible computational, memory, or\npower overhead. We evaluated the system by training with curated soils in boxes\nin the lab and testing in the outdoor fields and show that SoilSound achieves a\nmean absolute error (MAE) of 2.39% across 10 different locations. Overall, the\nevaluation shows that SoilSound can accurately track soil moisture levels\nranging from 15.9% to 34.0% across multiple soil types, environments, and\nusers; without requiring any calibration or disturbing the soil, enabling\nwidespread moisture monitoring for home gardeners, urban farmers, citizen\nscientists, and agricultural communities in resource-limited settings.", "AI": {"tldr": "The paper introduces SoilSound, a smartphone-based system for non-invasive and accessible soil moisture measurement using acoustic sensing.", "motivation": "The motivation is to develop a non-invasive, cost-effective, and easily accessible method for soil moisture monitoring that addresses the limitations of traditional techniques.", "method": "SoilSound leverages smartphone speakers and microphones to send acoustic chirps into the soil, record reflections during a vertical scan, and process these signals using a convolutional neural network.", "result": "The system achieves a mean absolute error of 2.39% in soil moisture estimation across 10 locations, demonstrating accuracy across various soil types and conditions without requiring calibration.", "conclusion": "SoilSound provides a practical, accurate, and non-disruptive solution for soil moisture monitoring, making it suitable for widespread adoption in diverse settings by non-expert users."}}
{"id": "2509.10441", "pdf": "https://arxiv.org/pdf/2509.10441", "abs": "https://arxiv.org/abs/2509.10441", "authors": ["Tao Han", "Wanghan Xu", "Junchao Gong", "Xiaoyu Yue", "Song Guo", "Luping Zhou", "Lei Bai"], "title": "InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Arbitrary resolution image generation provides a consistent visual experience\nacross devices, having extensive applications for producers and consumers.\nCurrent diffusion models increase computational demand quadratically with\nresolution, causing 4K image generation delays over 100 seconds. To solve this,\nwe explore the second generation upon the latent diffusion models, where the\nfixed latent generated by diffusion models is regarded as the content\nrepresentation and we propose to decode arbitrary resolution images with a\ncompact generated latent using a one-step generator. Thus, we present the\n\\textbf{InfGen}, replacing the VAE decoder with the new generator, for\ngenerating images at any resolution from a fixed-size latent without retraining\nthe diffusion models, which simplifies the process, reducing computational\ncomplexity and can be applied to any model using the same latent space.\nExperiments show InfGen is capable of improving many models into the arbitrary\nhigh-resolution era while cutting 4K image generation time to under 10 seconds.", "AI": {"tldr": "The paper introduces InfGen, a method to significantly speed up high-resolution image generation using latent diffusion models by proposing a one-step generator that produces images at arbitrary resolutions.", "motivation": "To address computational inefficiencies in current diffusion models, particularly the significant delays in generating 4K images.", "method": "InfGen enhances latent diffusion models by replacing the traditional VAE decoder with a one-step generator that generates high-resolution images from compact latent representations.", "result": "InfGen reduces 4K image generation time from over 100 seconds to under 10 seconds, showcasing improved speed and applicability for any model using the same latent space.", "conclusion": "InfGen facilitates arbitrary high-resolution image generation while simplifying the process and substantially decreasing computational complexity, making it adaptable and scalable."}}
{"id": "2509.09836", "pdf": "https://arxiv.org/pdf/2509.09836", "abs": "https://arxiv.org/abs/2509.09836", "authors": ["Marco Pasini", "Stefan Lattner", "George Fazekas"], "title": "CoDiCodec: Unifying Continuous and Discrete Compressed Representations of Audio", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "Accepted to ISMIR 2025", "summary": "Efficiently representing audio signals in a compressed latent space is\ncritical for latent generative modelling. However, existing autoencoders often\nforce a choice between continuous embeddings and discrete tokens. Furthermore,\nachieving high compression ratios while maintaining audio fidelity remains a\nchallenge. We introduce CoDiCodec, a novel audio autoencoder that overcomes\nthese limitations by both efficiently encoding global features via summary\nembeddings, and by producing both compressed continuous embeddings at ~ 11 Hz\nand discrete tokens at a rate of 2.38 kbps from the same trained model,\noffering unprecedented flexibility for different downstream generative tasks.\nThis is achieved through Finite Scalar Quantization (FSQ) and a novel\nFSQ-dropout technique, and does not require additional loss terms beyond the\nsingle consistency loss used for end-to-end training. CoDiCodec supports both\nautoregressive decoding and a novel parallel decoding strategy, with the latter\nachieving superior audio quality and faster decoding. CoDiCodec outperforms\nexisting continuous and discrete autoencoders at similar bitrates in terms of\nreconstruction audio quality. Our work enables a unified approach to audio\ncompression, bridging the gap between continuous and discrete generative\nmodelling paradigms.", "AI": {"tldr": "CoDiCodec is an audio autoencoder that combines continuous and discrete embeddings for efficient signal compression, demonstrating superior audio quality and flexibility.", "motivation": "To address the challenges of high compression ratios and maintaining audio fidelity, while bridging the gap between continuous and discrete embeddings in audio generative modeling.", "method": "CoDiCodec uses Finite Scalar Quantization (FSQ), FSQ-dropout for training, and a single consistency loss term. It supports both autoregressive and parallel decoding strategies.", "result": "CoDiCodec produces efficient compressed embeddings (~11 Hz continuous and 2.38 kbps discrete), achieving superior reconstruction audio quality compared to existing autoencoders.", "conclusion": "CoDiCodec offers a unified approach to audio compression, combining the benefits of continuous and discrete generative modeling paradigms, with applications in various audio generation tasks."}}
{"id": "2509.10453", "pdf": "https://arxiv.org/pdf/2509.10453", "abs": "https://arxiv.org/abs/2509.10453", "authors": ["Emily Kaczmarek", "Justin Szeto", "Brennan Nichyporuk", "Tal Arbel"], "title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Alzheimer's disease is a progressive, neurodegenerative disorder that causes\nmemory loss and cognitive decline. While there has been extensive research in\napplying deep learning models to Alzheimer's prediction tasks, these models\nremain limited by lack of available labeled data, poor generalization across\ndatasets, and inflexibility to varying numbers of input scans and time\nintervals between scans. In this study, we adapt three state-of-the-art\ntemporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,\nand add novel extensions designed to handle variable-length inputs and learn\nrobust spatial features. We aggregate four publicly available datasets\ncomprising 3,161 patients for pre-training, and show the performance of our\nmodel across multiple Alzheimer's prediction tasks including diagnosis\nclassification, conversion detection, and future conversion prediction.\nImportantly, our SSL model implemented with temporal order prediction and\ncontrastive learning outperforms supervised learning on six out of seven\ndownstream tasks. It demonstrates adaptability and generalizability across\ntasks and number of input images with varying time intervals, highlighting its\ncapacity for robust performance across clinical applications. We release our\ncode and model publicly at https://github.com/emilykaczmarek/SSL-AD.", "AI": {"tldr": "This paper addresses Alzheimer's disease prediction challenges by using temporal self-supervised learning (SSL) approaches with novel features, demonstrating superior performance across multiple predictive tasks.", "motivation": "Current deep learning models for Alzheimer's disease prediction are limited by a lack of labeled data, poor generalizability across datasets, and difficulties in handling variable input (e.g., varying scan numbers and time intervals).", "method": "The authors adapted three state-of-the-art temporal SSL methods for analyzing 3D brain MRIs, introducing novel enhancements for variable-length inputs and robust spatial feature learning. They used four public datasets totaling 3,161 patients for pre-training their models.", "result": "The SSL approach, particularly utilizing temporal order prediction and contrastive learning, exceeded the performance of supervised models for six out of seven downstream tasks, proving its viability across diverse test scenarios.", "conclusion": "This research showcases the adaptability and generalizability of SSL methods for Alzheimer's prediction, offering a promising alternative to supervised learning approaches. Public release of the code and model supports broader applications and further research."}}
{"id": "2509.09880", "pdf": "https://arxiv.org/pdf/2509.09880", "abs": "https://arxiv.org/abs/2509.09880", "authors": ["Ya\u015far Utku Al\u00e7alar", "Junno Yun", "Mehmet Ak\u00e7akaya"], "title": "Automated Tuning for Diffusion Inverse Problem Solvers without Generative Prior Retraining", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "IEEE International Workshop on Computational Advances in Multi-Sensor\n  Adaptive Processing (CAMSAP), 2025", "summary": "Diffusion/score-based models have recently emerged as powerful generative\npriors for solving inverse problems, including accelerated MRI reconstruction.\nWhile their flexibility allows decoupling the measurement model from the\nlearned prior, their performance heavily depends on carefully tuned data\nfidelity weights, especially under fast sampling schedules with few denoising\nsteps. Existing approaches often rely on heuristics or fixed weights, which\nfail to generalize across varying measurement conditions and irregular timestep\nschedules. In this work, we propose Zero-shot Adaptive Diffusion Sampling\n(ZADS), a test-time optimization method that adaptively tunes fidelity weights\nacross arbitrary noise schedules without requiring retraining of the diffusion\nprior. ZADS treats the denoising process as a fixed unrolled sampler and\noptimizes fidelity weights in a self-supervised manner using only undersampled\nmeasurements. Experiments on the fastMRI knee dataset demonstrate that ZADS\nconsistently outperforms both traditional compressed sensing and recent\ndiffusion-based methods, showcasing its ability to deliver high-fidelity\nreconstructions across varying noise schedules and acquisition settings.", "AI": {"tldr": "This paper introduces ZADS, a zero-shot adaptive method for optimized diffusion sampling in accelerated MRI reconstruction, achieving better reconstruction under diverse noise settings.", "motivation": "To improve generative priors in diffusion models for MRI reconstruction, eliminating dependency on heuristics or fixed fidelity weights, especially under varying conditions and noise levels.", "method": "ZADS employs test-time optimization to self-supervisedly adjust fidelity weights during the denoising process without retraining the diffusion model.", "result": "Results indicate that ZADS outperforms conventional methods and existing diffusion schemes, achieving high fidelity in fastMRI knee dataset reconstructions.", "conclusion": "ZADS offers an adaptable, effective approach for MRI reconstruction, addressing challenges in diverse acquisition and noise conditions without complex retraining processes."}}
{"id": "2509.09870", "pdf": "https://arxiv.org/pdf/2509.09870", "abs": "https://arxiv.org/abs/2509.09870", "authors": ["Hasibur Rahman", "Smit Desai"], "title": "Vibe Check: Understanding the Effects of LLM-Based Conversational Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) enable conversational agents (CAs) to express\ndistinctive personalities, raising new questions about how such designs shape\nuser perceptions. This study investigates how personality expression levels and\nuser-agent personality alignment influence perceptions in goal-oriented tasks.\nIn a between-subjects experiment (N=150), participants completed travel\nplanning with CAs exhibiting low, medium, or high expression across the Big\nFive traits, controlled via our novel Trait Modulation Keys framework. Results\nrevealed an inverted-U relationship: medium expression produced the most\npositive evaluations across Intelligence, Enjoyment, Anthropomorphism,\nIntention to Adopt, Trust, and Likeability, significantly outperforming both\nextremes. Personality alignment further enhanced outcomes, with Extraversion\nand Emotional Stability emerging as the most influential traits. Cluster\nanalysis identified three distinct compatibility profiles, with \"Well-Aligned\"\nusers reporting substantially positive perceptions. These findings demonstrate\nthat personality expression and strategic trait alignment constitute optimal\ndesign targets for CA personality, offering design implications as LLM-based\nCAs become increasingly prevalent.", "AI": {"tldr": "This study explored how varying levels of personality expression in conversational agents (CAs) and user-agent personality compatibility impact user perceptions during goal-driven tasks, finding moderate expression and alignment yield the best results.", "motivation": "To understand how the expression of personality in LLM-based conversational agents and alignment with user personality influences user evaluations and interactions, especially as CAs become more widespread.", "method": "A between-subjects experiment involving 150 participants was conducted, using conversational agents with varying levels of Big Five traits controlled by the Trait Modulation Keys framework to study their impact on perceptions.", "result": "Medium personality expression levels were evaluated most positively across metrics like Intelligence, Enjoyment, and Trust. Personality alignment amplified positive outcomes, with Extraversion and Emotional Stability being key traits.", "conclusion": "Optimal design of CA personalities should focus on moderate expression levels and align traits strategically to improve user interaction outcomes; these are foundational recommendations as CA use increases."}}
{"id": "2509.09987", "pdf": "https://arxiv.org/pdf/2509.09987", "abs": "https://arxiv.org/abs/2509.09987", "authors": ["Sung-Lin Yeh", "Yen Meng", "Hao Tang"], "title": "Whisper Has an Internal Word Aligner", "categories": ["eess.AS", "cs.CL"], "comment": "ASRU 2025", "summary": "There is an increasing interest in obtaining accurate word-level timestamps\nfrom strong automatic speech recognizers, in particular Whisper. Existing\napproaches either require additional training or are simply not competitive.\nThe evaluation in prior work is also relatively loose, typically using a\ntolerance of more than 200 ms. In this work, we discover attention heads in\nWhisper that capture accurate word alignments and are distinctively different\nfrom those that do not. Moreover, we find that using characters produces finer\nand more accurate alignments than using wordpieces. Based on these findings, we\npropose an unsupervised approach to extracting word alignments by filtering\nattention heads while teacher forcing Whisper with characters. Our approach not\nonly does not require training but also produces word alignments that are more\naccurate than prior work under a stricter tolerance between 20 ms and 100 ms.", "AI": {"tldr": "The study identifies attention heads in Whisper capturing precise word alignments, refining an unsupervised method to extract them without training.", "motivation": "Accurate word-level timestamps are increasingly sought for applications using Whisper, but current methods lack competitiveness and rely on loose evaluation metrics.", "method": "The paper identifies specific attention heads in Whisper that produce accurate word alignments, utilizes characters over wordpieces for precision, and proposes an unsupervised filtering method during teacher forcing.", "result": "The proposed approach yields word alignments more accurate than previous work, achieving stricter tolerances of 20\u2013100 ms without requiring additional training.", "conclusion": "By exploiting attention head filtering and character-based alignment, the method enhances timestamp precision in Whisper without retraining, offering a viable alternative to prior approaches."}}
{"id": "2509.09952", "pdf": "https://arxiv.org/pdf/2509.09952", "abs": "https://arxiv.org/abs/2509.09952", "authors": ["Zhi Ying", "Boxiang Rong", "Jingyu Wang", "Maoyuan Xu"], "title": "Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to SIGGRAPH Asia 2025. Project page:\n  https://ubisoft-laforge.github.io/world/chord", "summary": "Material creation and reconstruction are crucial for appearance modeling but\ntraditionally require significant time and expertise from artists. While recent\nmethods leverage visual foundation models to synthesize PBR materials from\nuser-provided inputs, they often fall short in quality, flexibility, and user\ncontrol. We propose a novel two-stage generate-and-estimate framework for PBR\nmaterial generation. In the generation stage, a fine-tuned diffusion model\nsynthesizes shaded, tileable texture images aligned with user input. In the\nestimation stage, we introduce a chained decomposition scheme that sequentially\npredicts SVBRDF channels by passing previously extracted representation as\ninput into a single-step image-conditional diffusion model. Our method is\nefficient, high quality, and enables flexible user control. We evaluate our\napproach against existing material generation and estimation methods,\ndemonstrating superior performance. Our material estimation method shows strong\nrobustness on both generated textures and in-the-wild photographs. Furthermore,\nwe highlight the flexibility of our framework across diverse applications,\nincluding text-to-material, image-to-material, structure-guided generation, and\nmaterial editing.", "AI": {"tldr": "The paper proposes a two-stage framework leveraging diffusion models to facilitate PBR material generation with improved quality, flexibility, and user control.", "motivation": "Traditional PBR material creation requires substantial time and skill from artists, and existing automated methods lack in quality and user adaptability.", "method": "A two-stage process: 1) Generate stage uses a fine-tuned diffusion model to create texture images based on user inputs, and 2) Estimate stage sequentially predicts SVBRDF channels through chained decomposition using a single-step image-conditional diffusion model.", "result": "The proposed method outperforms existing approaches in material generation and estimation, showcasing robustness on both generated textures and real-world photographs.", "conclusion": "This framework reduces effort in material creation while achieving high-quality results and flexible control for diverse applications including text-to-material, image-to-material, and material editing."}}
{"id": "2509.10031", "pdf": "https://arxiv.org/pdf/2509.10031", "abs": "https://arxiv.org/abs/2509.10031", "authors": ["Peter Vieting", "Benedikt Hilmes", "Ralf Schl\u00fcter", "Hermann Ney"], "title": "Unified Learnable 2D Convolutional Feature Extraction for ASR", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted at ITG Conference on Speech Communication 2025", "summary": "Neural front-ends represent a promising approach to feature extraction for\nautomatic speech recognition (ASR) systems as they enable to learn specifically\ntailored features for different tasks. Yet, many of the existing techniques\nremain heavily influenced by classical methods. While this inductive bias may\nease the system design, our work aims to develop a more generic front-end for\nfeature extraction. Furthermore, we seek to unify the front-end architecture\ncontrasting with existing approaches that apply a composition of several layer\ntopologies originating from different sources. The experiments systematically\nshow how to reduce the influence of existing techniques to achieve a generic\nfront-end. The resulting 2D convolutional front-end is parameter-efficient and\nsuitable for a scenario with limited computational resources unlike large\nmodels pre-trained on unlabeled audio. The results demonstrate that this\ngeneric unified approach is not only feasible but also matches the performance\nof existing supervised learnable feature extractors.", "AI": {"tldr": "The paper introduces a unified, generic 2D convolutional front-end for feature extraction in ASR, which matches the performance of existing supervised methods while being computationally efficient.", "motivation": "Many neural front-ends for ASR are influenced by classical methods and rely on various layer topologies, making them task-specific and complex.", "method": "Proposes a unified, generic 2D convolutional front-end architecture for feature extraction, systematically reducing reliance on classical approaches.", "result": "The proposed method is parameter-efficient, fits scenarios with limited computational resources, and performs on par with existing supervised feature extractors.", "conclusion": "A generic 2D convolutional front-end for ASR is feasible, efficient, and provides competitive performance without relying on pre-trained models or task-specific designs."}}
{"id": "2509.09972", "pdf": "https://arxiv.org/pdf/2509.09972", "abs": "https://arxiv.org/abs/2509.09972", "authors": ["Mohammadreza Narimani", "Alireza Pourreza", "Ali Moghimi", "Mohsen Mesgaran", "Parastoo Farajpoor", "Hamid Jafarbiglu"], "title": "Drone-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "Author-accepted version (no publisher header/footer). 10 pages +\n  presentation. Published in Proceedings of SPIE Defense + Commercial Sensing\n  2024, Vol. 13053, Paper 1305304. Event: National Harbor, Maryland, USA.\n  Official version: https://doi.org/10.1117/12.3021219", "summary": "This study addresses the escalating threat of branched broomrape (Phelipanche\nramosa) to California's tomato industry, which supplies over 90 percent of U.S.\nprocessing tomatoes. The parasite's largely underground life cycle makes early\ndetection difficult, while conventional chemical controls are costly,\nenvironmentally harmful, and often ineffective. To address this, we combined\ndrone-based multispectral imagery with Long Short-Term Memory (LSTM) deep\nlearning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)\nto handle class imbalance. Research was conducted on a known broomrape-infested\ntomato farm in Woodland, Yolo County, CA, across five key growth stages\ndetermined by growing degree days (GDD). Multispectral images were processed to\nisolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with\n79.09 percent overall accuracy and 70.36 percent recall without integrating\nlater stages. Incorporating sequential growth stages with LSTM improved\ndetection substantially. The best-performing scenario, which integrated all\ngrowth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy\nand 95.37 percent recall. These results demonstrate the strong potential of\ntemporal multispectral analysis and LSTM networks for early broomrape\ndetection. While further real-world data collection is needed for practical\ndeployment, this study shows that UAV-based multispectral sensing coupled with\ndeep learning could provide a powerful precision agriculture tool to reduce\nlosses and improve sustainability in tomato production.", "AI": {"tldr": "The study develops a drone-based multispectral deep learning system to detect broomrape in tomato fields, achieving high accuracy and recall.", "motivation": "To address the threat of branched broomrape to California's tomato industry due to its undetectable underground life cycle and limitations of conventional chemical controls.", "method": "Drone-based multispectral imagery combined with LSTM deep learning and SMOTE was employed to improve detection across growth stages.", "result": "Detection accuracy reached 88.37% and recall 95.37% using sequential growth stage analysis and SMOTE for class balance.", "conclusion": "This UAV and deep learning approach shows great promise for early detection of broomrape, supporting sustainable tomato farming."}}
{"id": "2509.10143", "pdf": "https://arxiv.org/pdf/2509.10143", "abs": "https://arxiv.org/abs/2509.10143", "authors": ["Peter Vieting", "Simon Berger", "Thilo von Neumann", "Christoph Boeddeker", "Ralf Schl\u00fcter", "Reinhold Haeb-Umbach"], "title": "Error Analysis in a Modular Meeting Transcription System", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted at ITG Conference on Speech Communication 2025", "summary": "Meeting transcription is a field of high relevance and remarkable progress in\nrecent years. Still, challenges remain that limit its performance. In this\nwork, we extend a previously proposed framework for analyzing leakage in speech\nseparation with proper sensitivity to temporal locality. We show that there is\nsignificant leakage to the cross channel in areas where only the primary\nspeaker is active. At the same time, the results demonstrate that this does not\naffect the final performance much as these leaked parts are largely ignored by\nthe voice activity detection (VAD). Furthermore, different segmentations are\ncompared showing that advanced diarization approaches are able to reduce the\ngap to oracle segmentation by a third compared to a simple energy-based VAD. We\nadditionally reveal what factors contribute to the remaining difference. The\nresults represent state-of-the-art performance on LibriCSS among systems that\ntrain the recognition module on LibriSpeech data only.", "AI": {"tldr": "This study focuses on meeting transcription, analyzing leakage in speech separation, and shows state-of-the-art performance on LibriCSS when trained only on LibriSpeech.", "motivation": "Challenges in meeting transcription performance prompt further analysis and improvement.", "method": "A framework is extended to analyze leakage with sensitivity to temporal locality, exploring voice activity detection and comparing segmentation methods.", "result": "Significant leakage occurs in areas with single speakers but minimally impacts performance due to VAD. Advanced diarization reduces segmentation gaps by a third compared to energy-based VAD.", "conclusion": "Despite leakage, the transcription system achieves top performance on LibriCSS when restricted to LibriSpeech data training."}}
{"id": "2509.10098", "pdf": "https://arxiv.org/pdf/2509.10098", "abs": "https://arxiv.org/abs/2509.10098", "authors": ["Muhamad Daniel Ariff Bin Abdul Rahman", "Yusuke Monno", "Masayuki Tanaka", "Masatoshi Okutomi"], "title": "Polarization Denoising and Demosaicking: Dataset and Baseline Method", "categories": ["eess.IV", "cs.CV"], "comment": "Published in ICIP2025; Project page:\n  http://www.ok.sc.e.titech.ac.jp/res/PolarDem/PDD.html", "summary": "A division-of-focal-plane (DoFP) polarimeter enables us to acquire images\nwith multiple polarization orientations in one shot and thus it is valuable for\nmany applications using polarimetric information. The image processing pipeline\nfor a DoFP polarimeter entails two crucial tasks: denoising and demosaicking.\nWhile polarization demosaicking for a noise-free case has increasingly been\nstudied, the research for the joint task of polarization denoising and\ndemosaicking is scarce due to the lack of a suitable evaluation dataset and a\nsolid baseline method. In this paper, we propose a novel dataset and method for\npolarization denoising and demosaicking. Our dataset contains 40 real-world\nscenes and three noise-level conditions, consisting of pairs of noisy mosaic\ninputs and noise-free full images. Our method takes a\ndenoising-then-demosaicking approach based on well-accepted signal processing\ncomponents to offer a reproducible method. Experimental results demonstrate\nthat our method exhibits higher image reconstruction performance than other\nalternative methods, offering a solid baseline.", "AI": {"tldr": "The paper proposes a new dataset and method for simultaneous denoising and demosaicking of division-of-focal-plane (DoFP) polarimeter images, achieving better performance than existing alternatives.", "motivation": "DoFP polarimeters can capture images with multiple polarization orientations in a single shot, but the joint tasks of denoising and demosaicking have been underexplored due to missing evaluation datasets and baseline methods.", "method": "A novel denoising-then-demosaicking approach is developed, leveraging well-accepted signal processing components, along with a newly created dataset featuring 40 real-world scenes under three noise levels.", "result": "The presented method outperforms other current techniques in reconstructing high-quality images, establishing itself as a strong baseline.", "conclusion": "The introduced dataset and method pave the way for advancing joint denoising and demosaicking in DoFP polarimeter imaging, filling a gap in research and providing solid evaluation tools."}}
{"id": "2509.10348", "pdf": "https://arxiv.org/pdf/2509.10348", "abs": "https://arxiv.org/abs/2509.10348", "authors": ["Yehudit Aperstein", "Amit Tzahar", "Alon Gottlib", "Tal Verber", "Ravit Shagan Damti", "Alexander Apartsin"], "title": "Multi-pathology Chest X-ray Classification with Rejection Mechanisms", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "12 pages, 4 figures", "summary": "Overconfidence in deep learning models poses a significant risk in\nhigh-stakes medical imaging tasks, particularly in multi-label classification\nof chest X-rays, where multiple co-occurring pathologies must be detected\nsimultaneously. This study introduces an uncertainty-aware framework for chest\nX-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective\nprediction mechanisms: entropy-based rejection and confidence interval-based\nrejection. Both methods enable the model to abstain from uncertain predictions,\nimproving reliability by deferring ambiguous cases to clinical experts. A\nquantile-based calibration procedure is employed to tune rejection thresholds\nusing either global or class-specific strategies. Experiments conducted on\nthree large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)\ndemonstrate that selective rejection improves the trade-off between diagnostic\naccuracy and coverage, with entropy-based rejection yielding the highest\naverage AUC across all pathologies. These results support the integration of\nselective prediction into AI-assisted diagnostic workflows, providing a\npractical step toward safer, uncertainty-aware deployment of deep learning in\nclinical settings.", "AI": {"tldr": "The paper addresses overconfidence in deep learning for medical imaging, proposing uncertainty-aware mechanisms to improve reliability in multi-label chest X-ray classifications.", "motivation": "Overconfidence in deep learning models can lead to unreliable predictions in medical imaging tasks, potentially risking patient safety in high-stakes scenarios.", "method": "A DenseNet-121 model is equipped with entropy-based and confidence interval-based rejection mechanisms to identify uncertain predictions, combined with a quantile-based calibration procedure for tuning rejection thresholds.", "result": "Experiments on PadChest, NIH ChestX-ray14, and MIMIC-CXR datasets showed improved diagnostic accuracy and coverage, with entropy-based rejection yielding the highest average AUC across pathologies.", "conclusion": "Selective prediction mechanisms enhance diagnostic accuracy and safety, providing a step forward for safer AI-assisted workflows in clinical settings."}}
{"id": "2509.09906", "pdf": "https://arxiv.org/pdf/2509.09906", "abs": "https://arxiv.org/abs/2509.09906", "authors": ["Alexandra Fetsch", "Iurii Savvateev", "Racem Ben Romdhane", "Martin Wiedmann", "Artemiy Dimov", "Maciej Durkalec", "Josef Teichmann", "Jakob Zinsstag", "Konstantinos Koutsoumanis", "Andreja Rajkovic", "Jason Mann", "Mauro Tonolla", "Monika Ehling-Schulz", "Matthias Filter", "Sophia Johler"], "title": "Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Key global challenges of our times are characterized by complex\ninterdependencies and can only be effectively addressed through an integrated,\nparticipatory effort. Conventional risk analysis frameworks often reduce\ncomplexity to ensure manageability, creating silos that hinder comprehensive\nsolutions. A fundamental shift towards holistic strategies is essential to\nenable effective negotiations between different sectors and to balance the\ncompeting interests of stakeholders. However, achieving this balance is often\nhindered by limited time, vast amounts of information, and the complexity of\nintegrating diverse perspectives. This study presents an AI-assisted\nnegotiation framework that incorporates large language models (LLMs) and\nAI-based autonomous agents into a negotiation-centered risk analysis workflow.\nThe framework enables stakeholders to simulate negotiations, systematically\nmodel dynamics, anticipate compromises, and evaluate solution impacts. By\nleveraging LLMs' semantic analysis capabilities we could mitigate information\noverload and augment decision-making process under time constraints.\nProof-of-concept implementations were conducted in two real-world scenarios:\n(i) prudent use of a biopesticide, and (ii) targeted wild animal population\ncontrol. Our work demonstrates the potential of AI-assisted negotiation to\naddress the current lack of tools for cross-sectoral engagement. Importantly,\nthe solution's open source, web based design, suits for application by a\nbroader audience with limited resources and enables users to tailor and develop\nit for their own needs.", "AI": {"tldr": "The paper explores an AI-assisted negotiation framework incorporating LLMs and autonomous agents to address complex, cross-sectoral challenges, with proof-of-concept tests showing potential in real-world scenarios.", "motivation": "To address the limitations of conventional risk analysis frameworks that fail to tackle the complexity and interdependencies of cross-sectoral challenges, which hinder effective solutions.", "method": "The study proposes an AI-assisted negotiation framework that integrates large language models and autonomous agents into a negotiation-centered risk analysis workflow, enabling simulation, dynamic modeling, and decision-making augmentation.", "result": "Proof-of-concept implementations in biopesticide use and wild animal population control demonstrated the potential of the framework to improve negotiation outcomes and cross-sectoral engagement.", "conclusion": "The framework provides an open-source, web-based solution suitable for broader audiences, addressing a critical tool gap, and allowing customization for diverse needs."}}
{"id": "2509.09894", "pdf": "https://arxiv.org/pdf/2509.09894", "abs": "https://arxiv.org/abs/2509.09894", "authors": ["Jiayun Wang", "Yousuf Aborahama", "Arya Khokhar", "Yang Zhang", "Chuwei Wang", "Karteekeya Sastry", "Julius Berner", "Yilin Luo", "Boris Bonev", "Zongyi Li", "Kamyar Azizzadenesheli", "Lihong V. Wang", "Anima Anandkumar"], "title": "Accelerating 3D Photoacoustic Computed Tomography with End-to-End Physics-Aware Neural Operators", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Photoacoustic computed tomography (PACT) combines optical contrast with\nultrasonic resolution, achieving deep-tissue imaging beyond the optical\ndiffusion limit. While three-dimensional PACT systems enable high-resolution\nvolumetric imaging for applications spanning transcranial to breast imaging,\ncurrent implementations require dense transducer arrays and prolonged\nacquisition times, limiting clinical translation. We introduce Pano (PACT\nimaging neural operator), an end-to-end physics-aware model that directly\nlearns the inverse acoustic mapping from sensor measurements to volumetric\nreconstructions. Unlike existing approaches (e.g. universal back-projection\nalgorithm), Pano learns both physics and data priors while also being agnostic\nto the input data resolution. Pano employs spherical discrete-continuous\nconvolutions to preserve hemispherical sensor geometry, incorporates Helmholtz\nequation constraints to ensure physical consistency and operates\nresolutionindependently across varying sensor configurations. We demonstrate\nthe robustness and efficiency of Pano in reconstructing high-quality images\nfrom both simulated and real experimental data, achieving consistent\nperformance even with significantly reduced transducer counts and limited-angle\nacquisition configurations. The framework maintains reconstruction fidelity\nacross diverse sparse sampling patterns while enabling real-time volumetric\nimaging capabilities. This advancement establishes a practical pathway for\nmaking 3D PACT more accessible and feasible for both preclinical research and\nclinical applications, substantially reducing hardware requirements without\ncompromising image reconstruction quality.", "AI": {"tldr": "This paper introduces Pano, a physics-aware neural model, to improve the efficiency and quality of 3D photoacoustic computed tomography (PACT), enabling real-time imaging with reduced hardware requirements.", "motivation": "Current 3D PACT systems are hindered by the need for dense transducer arrays and long acquisition times, making them less feasible for clinical and preclinical use.", "method": "The proposed method, Pano, uses a neural operator with spherical discrete-continuous convolutions and Helmholtz constraints to reconstruct high-quality images from minimal sensor data. It is resolution-agnostic and compatible with various sensor configurations.", "result": "Pano reconstructs high-quality volumetric images from both simulated and experimental data. It maintains performance with fewer transducers and limited-angle measurements while enabling real-time imaging.", "conclusion": "Pano offers a practical and efficient solution for 3D PACT, significantly reducing hardware costs and making it more accessible for clinical and research applications without sacrificing image quality."}}
{"id": "2509.09923", "pdf": "https://arxiv.org/pdf/2509.09923", "abs": "https://arxiv.org/abs/2509.09923", "authors": ["Myles Joshua Toledo Tan", "Maria Kapetanaki", "Panayiotis V. Benos"], "title": "Engineering Spatial and Molecular Features from Cellular Niches to Inform Predictions of Inflammatory Bowel Disease", "categories": ["q-bio.GN", "cs.LG"], "comment": "18 pages, 7 figures, 7 tables. Submitted to the 25th BNAIC\n  Conference, Namur, Belgium, November 19 - 21, 2025", "summary": "Differentiating between the two main subtypes of Inflammatory Bowel Disease\n(IBD): Crohns disease (CD) and ulcerative colitis (UC) is a persistent clinical\nchallenge due to overlapping presentations. This study introduces a novel\ncomputational framework that employs spatial transcriptomics (ST) to create an\nexplainable machine learning model for IBD classification. We analyzed ST data\nfrom the colonic mucosa of healthy controls (HC), UC, and CD patients. Using\nNon-negative Matrix Factorization (NMF), we first identified four recurring\ncellular niches, representing distinct functional microenvironments within the\ntissue. From these niches, we systematically engineered 44 features capturing\nthree key aspects of tissue pathology: niche composition, neighborhood\nenrichment, and niche-gene signals. A multilayer perceptron (MLP) classifier\ntrained on these features achieved an accuracy of 0.774 +/- 0.161 for the more\nchallenging three-class problem (HC, UC, and CD) and 0.916 +/- 0.118 in the\ntwo-class problem of distinguishing IBD from healthy tissue. Crucially, model\nexplainability analysis revealed that disruptions in the spatial organization\nof niches were the strongest predictors of general inflammation, while the\nclassification between UC and CD relied on specific niche-gene expression\nsignatures. This work provides a robust, proof-of-concept pipeline that\ntransforms descriptive spatial data into an accurate and explainable predictive\ntool, offering not only a potential new diagnostic paradigm but also deeper\ninsights into the distinct biological mechanisms that drive IBD subtypes.", "AI": {"tldr": "The paper presents an explainable machine learning model for classifying Inflammatory Bowel Disease (IBD) and its subtypes using spatial transcriptomics data.", "motivation": "To address the clinical challenge of differentiating Crohn's disease and ulcerative colitis subtypes of IBD, which share overlapping symptoms.", "method": "A computational framework was proposed using spatial transcriptomics data and Non-negative Matrix Factorization to identify cellular niches. Features related to tissue pathology were engineered and used in a multilayer perceptron (MLP) classifier.", "result": "The model achieved an accuracy of 0.774 for the three-class classification problem (HC, UC, CD) and 0.916 for distinguishing IBD from healthy tissue. Model explainability highlighted how spatial disruptions and niche-gene signatures impact classification.", "conclusion": "The study presents a novel diagnostic tool using spatial transcriptomics combined with machine learning that enhances IBD classification while offering insights into the distinct mechanisms of its subtypes."}}
{"id": "2509.10057", "pdf": "https://arxiv.org/pdf/2509.10057", "abs": "https://arxiv.org/abs/2509.10057", "authors": ["Jakub Mojsiejuk", "S\u0142awomir Zi\u0119tek", "Witold Skowro\u0144ski"], "title": "Reinforcement learning for spin torque oscillator tasks", "categories": ["physics.app-ph", "cs.AI", "cs.LG"], "comment": "3 figures, 6 pages", "summary": "We address the problem of automatic synchronisation of the spintronic\noscillator (STO) by means of reinforcement learning (RL). A numerical solution\nof the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to\nsimulate the STO and we train the two types of RL agents to synchronise with a\ntarget frequency within a fixed number of steps. We explore modifications to\nthis base task and show an improvement in both convergence and energy\nefficiency of the synchronisation that can be easily achieved in the simulated\nenvironment.", "AI": {"tldr": "The paper uses reinforcement learning to achieve automatic synchronization of spintronic oscillators, demonstrating improved synchronization efficiency and energy performance in simulations.", "motivation": "To solve the challenge of efficiently synchronizing spintronic oscillators.", "method": "The authors simulate spintronic oscillators using the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation and train reinforcement learning agents to synchronize with a target frequency within a fixed number of steps.", "result": "The study presents improvements in convergence rate and energy efficiency for synchronization tasks within the simulated environment.", "conclusion": "The methodology effectively enhances STO synchronization performance while providing practical insights through simulations."}}
{"id": "2509.09970", "pdf": "https://arxiv.org/pdf/2509.09970", "abs": "https://arxiv.org/abs/2509.09970", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) show promise in generating firmware for embedded\nsystems, but often introduce security flaws and fail to meet real-time\nperformance constraints. This paper proposes a three-phase methodology that\ncombines LLM-based firmware generation with automated security validation and\niterative refinement in a virtualized environment. Using structured prompts,\nmodels like GPT-4 generate firmware for networking and control tasks, deployed\non FreeRTOS via QEMU. These implementations are tested using fuzzing, static\nanalysis, and runtime monitoring to detect vulnerabilities such as buffer\noverflows (CWE-120), race conditions (CWE-362), and denial-of-service threats\n(CWE-400). Specialized AI agents for Threat Detection, Performance\nOptimization, and Compliance Verification collaborate to improve detection and\nremediation. Identified issues are categorized using CWE, then used to prompt\ntargeted LLM-generated patches in an iterative loop. Experiments show a 92.4\\%\nVulnerability Remediation Rate (37.3\\% improvement), 95.8\\% Threat Model\nCompliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms\nworst-case execution time and 195{\\mu}s jitter. This process enhances firmware\nsecurity and performance while contributing an open-source dataset for future\nresearch.", "AI": {"tldr": "The paper explores using Large Language Models (LLMs) to generate firmware for embedded systems, addressing security flaws and performance constraints through an iterative methodology involving validation and refinement.", "motivation": "To leverage LLMs for firmware generation while ensuring their outputs meet the stringent security and real-time performance requirements of embedded systems.", "method": "Three-phase methodology using structured prompts for firmware generation, automated security validation through fuzzing, static analysis, and runtime monitoring, and iterative refinements with feedback-informed patches.", "result": "The methodology achieved a 92.4% Vulnerability Remediation Rate (37.3% improvement), 95.8% Threat Model Compliance, and a 0.87 Security Coverage Index, alongside real-time performance metrics like 8.6ms execution time and 195\u00b5s jitter.", "conclusion": "The proposed approach significantly improves both cybersecurity and operational performance of firmware while providing valuable resources for future research, like an open-source dataset."}}
{"id": "2509.10074", "pdf": "https://arxiv.org/pdf/2509.10074", "abs": "https://arxiv.org/abs/2509.10074", "authors": ["Christos Sgouropoulos", "Christos Nikou", "Stefanos Vlachos", "Vasileios Theiou", "Christos Foukanelis", "Theodoros Giannakopoulos"], "title": "Prototypical Contrastive Learning For Improved Few-Shot Audio Classification", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted and Presented at IEEE International Workshop on Machine\n  Learning for Signal Processing, Aug.\\ 31-- Sep.\\ 3, 2025, Istanbul, Turkey ,\n  6 pages, 2 figures, 1 table", "summary": "Few-shot learning has emerged as a powerful paradigm for training models with\nlimited labeled data, addressing challenges in scenarios where large-scale\nannotation is impractical. While extensive research has been conducted in the\nimage domain, few-shot learning in audio classification remains relatively\nunderexplored. In this work, we investigate the effect of integrating\nsupervised contrastive loss into prototypical few shot training for audio\nclassification. In detail, we demonstrate that angular loss further improves\nthe performance compared to the standard contrastive loss. Our method leverages\nSpecAugment followed by a self-attention mechanism to encapsulate diverse\ninformation of augmented input versions into one unified embedding. We evaluate\nour approach on MetaAudio, a benchmark including five datasets with predefined\nsplits, standardized preprocessing, and a comprehensive set of few-shot\nlearning models for comparison. The proposed approach achieves state-of-the-art\nperformance in a 5-way, 5-shot setting.", "AI": {"tldr": "The paper introduces an approach integrating supervised contrastive loss and angular loss in few-shot audio classification, leveraging SpecAugment and self-attention, achieving state-of-the-art performance on MetaAudio benchmarks.", "motivation": "Few-shot learning in audio classification is underexplored compared to the image domain, despite its importance for scenarios with limited labeled data.", "method": "The paper combines supervised contrastive loss, angular loss, SpecAugment, and self-attention mechanisms to enhance few-shot audio classification.", "result": "The method delivered state-of-the-art results in 5-way, 5-shot audio classification on the MetaAudio benchmark, outperforming previous models.", "conclusion": "Integrating supervised contrastive loss, angular loss, and embedding diversity techniques enhances few-shot audio classification, establishing a robust model on the MetaAudio benchmark."}}
{"id": "2509.10082", "pdf": "https://arxiv.org/pdf/2509.10082", "abs": "https://arxiv.org/abs/2509.10082", "authors": ["Weitao Tang", "Johann Vargas-Calixto", "Nasim Katebi", "Nhi Tran", "Sharmony B. Kelly", "Gari D. Clifford", "Robert Galinsky", "Faezeh Marzbanrad"], "title": "FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification", "categories": ["eess.SP", "cs.LG"], "comment": "13 pages, 4 tables, 5 figures, submitted to IEEE Journal of\n  Biomedical and Health Informatics", "summary": "Introduction: This study presents FetalSleepNet, the first published deep\nlearning approach to classifying sleep states from the ovine\nelectroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and\nlaborious to interpret consistently. However, accurate sleep stage\nclassification may aid in the early detection of abnormal brain maturation\nassociated with pregnancy complications (e.g. hypoxia or intrauterine growth\nrestriction).\n  Methods: EEG electrodes were secured onto the ovine dura over the parietal\ncortices of 24 late gestation fetal sheep. A lightweight deep neural network\noriginally developed for adult EEG sleep staging was trained on the ovine EEG\nusing transfer learning from adult EEG. A spectral equalisation-based domain\nadaptation strategy was used to reduce cross-domain mismatch.\n  Results: We demonstrated that while direct transfer performed poorly, full\nfine tuning combined with spectral equalisation achieved the best overall\nperformance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming\nbaseline models.\n  Conclusions: To the best of our knowledge, FetalSleepNet is the first deep\nlearning framework specifically developed for automated sleep staging from the\nfetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier\nfunctions as a label engine, enabling large scale weak/semi supervised labeling\nand distillation to facilitate training on less invasive signals that can be\nacquired in the clinic, such as Doppler Ultrasound or electrocardiogram data.\nFetalSleepNet's lightweight design makes it well suited for deployment in low\npower, real time, and wearable fetal monitoring systems.", "AI": {"tldr": "This paper introduces FetalSleepNet, a novel deep learning system for automated fetal sleep stage classification using EEG, enabling better detection of brain issues during pregnancy.", "motivation": "Monitoring fetal brain maturation is crucial for detecting complications like hypoxia or growth restrictions. Current methods are complex and labor-intensive, necessitating advancements in sleep stage classification.", "method": "EEG data from fetal sheep were analyzed with domain adaptation and deep learning techniques. The approach involved transfer learning from adult EEG and a spectral equalization strategy to reduce mismatches across datasets.", "result": "FetalSleepNet achieved a high accuracy of 86.6% and macro F1-score of 62.5, outperforming baseline models through the use of fine tuning and spectral equalization techniques.", "conclusion": "FetalSleepNet is the first deep learning system dedicated to fetal EEG-based sleep staging. Its lightweight design supports real-time, low-power monitoring in clinical applications and opens up pathways for scalable semi-supervised training on other signals."}}
{"id": "2509.10206", "pdf": "https://arxiv.org/pdf/2509.10206", "abs": "https://arxiv.org/abs/2509.10206", "authors": ["Federica Uccello", "Simin Nadjm-Tehrani"], "title": "Investigating Feature Attribution for 5G Network Intrusion Detection", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "With the rise of fifth-generation (5G) networks in critical applications, it\nis urgent to move from detection of malicious activity to systems capable of\nproviding a reliable verdict suitable for mitigation. In this regard,\nunderstanding and interpreting machine learning (ML) models' security alerts is\ncrucial for enabling actionable incident response orchestration. Explainable\nArtificial Intelligence (XAI) techniques are expected to enhance trust by\nproviding insights into why alerts are raised. A dominant approach\nstatistically associates feature sets that can be correlated to a given alert.\nThis paper starts by questioning whether such attribution is relevant for\nfuture generation communication systems, and investigates its merits in\ncomparison with an approach based on logical explanations. We extensively study\ntwo methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts\ngenerated by an XGBoost model in three different use cases with several 5G\ncommunication attacks. We identify three metrics for assessing explanations:\nsparsity, how concise they are; stability, how consistent they are across\nsamples from the same attack type; and efficiency, how fast an explanation is\ngenerated. As an example, in a 5G network with 92 features, 6 were deemed\nimportant by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while\nSHAP identified over 20. More importantly, we found a significant divergence\nbetween features selected by SHAP and VoTE-XAI. However, none of the top-ranked\nfeatures selected by SHAP were missed by VoTE-XAI. When it comes to efficiency\nof providing interpretations, we found that VoTE-XAI is significantly more\nresponsive, e.g. it provides a single explanation in under 0.002 seconds, in a\nhigh-dimensional setting (478 features).", "AI": {"tldr": "The paper compares SHAP and VoTE-XAI explainability methods for interpreting security alerts in 5G networks, focusing on sparsity, stability, and efficiency.", "motivation": "With 5G networks being critical, reliable incident response to security threats necessitates interpretable machine learning (ML) models for actionable decisions.", "method": "The authors evaluated SHAP and VoTE-XAI methods using interpretations from an XGBoost model across three 5G attack use cases, analyzing metrics like sparsity, stability, and efficiency.", "result": "VoTE-XAI provided concise (6 important features vs. over 20 by SHAP), stable, and faster explanations (<0.002 seconds) in comparison to SHAP, though SHAP did not miss any features deemed important by VoTE-XAI.", "conclusion": "VoTE-XAI delivers more efficient and stable explanations than SHAP, making it suitable for high-dimensional settings in 5G security contexts."}}
{"id": "2509.10216", "pdf": "https://arxiv.org/pdf/2509.10216", "abs": "https://arxiv.org/abs/2509.10216", "authors": ["Noga H. Rotman", "Tiago Ferreira", "Hila Peleg", "Mark Silberstein", "Alexandra Silva"], "title": "RFSeek and Ye Shall Find", "categories": ["cs.NI", "cs.HC", "cs.LG"], "comment": "7 pages", "summary": "Requests for Comments (RFCs) are extensive specification documents for\nnetwork protocols, but their prose-based format and their considerable length\noften impede precise operational understanding. We present RFSeek, an\ninteractive tool that automatically extracts visual summaries of protocol logic\nfrom RFCs. RFSeek leverages large language models (LLMs) to generate\nprovenance-linked, explorable diagrams, surfacing both official state machines\nand additional logic found only in the RFC text. Compared to existing RFC\nvisualizations, RFSeek's visual summaries are more transparent and easier to\naudit against their textual source. We showcase the tool's potential through a\nseries of use cases, including guided knowledge extraction and semantic\ndiffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.\n  In practice, RFSeek not only reconstructs the RFC diagrams included in some\nspecifications, but, more interestingly, also uncovers important logic such as\nnodes or edges described in the text but missing from those diagrams. RFSeek\nfurther derives new visualization diagrams for complex RFCs, with QUIC as a\nrepresentative case. Our approach, which we term \\emph{Summary Visualization},\nhighlights a promising direction: combining LLMs with formal, user-customized\nvisualizations to enhance protocol comprehension and support robust\nimplementations.", "AI": {"tldr": "RFSeek is a tool that extracts visual summaries from network protocol specifications (RFCs). It uses large language models (LLMs) to create provenance-linked diagrams, making it easier to understand and audit RFC logic.", "motivation": "The motivation is to address the challenges in understanding RFCs due to their lengthy, prose-based format, which often obscures precise operational details.", "method": "RFSeek applies large language models to automatically extract protocol logic from RFCs and to generate interactive, explorable, provenance-linked diagrams.", "result": "RFSeek reconstructs existing diagrams, uncovers logic missing from official diagrams, and creates entirely new visualization diagrams for complex RFCs. Use cases include knowledge extraction and semantic diffing.", "conclusion": "Combining LLMs and user-customized visualizations offers a promising way to improve protocol comprehension and support accurate implementations of network protocols."}}
{"id": "2509.10245", "pdf": "https://arxiv.org/pdf/2509.10245", "abs": "https://arxiv.org/abs/2509.10245", "authors": ["Irina Ar\u00e9valo", "Jose L Salmeron"], "title": "Model-agnostic post-hoc explainability for recommender systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recommender systems often benefit from complex feature embeddings and deep\nlearning algorithms, which deliver sophisticated recommendations that enhance\nuser experience, engagement, and revenue. However, these methods frequently\nreduce the interpretability and transparency of the system. In this research,\nwe develop a systematic application, adaptation, and evaluation of deletion\ndiagnostics in the recommender setting. The method compares the performance of\na model to that of a similar model trained without a specific user or item,\nallowing us to quantify how that observation influences the recommender, either\npositively or negatively. To demonstrate its model-agnostic nature, the\nproposal is applied to both Neural Collaborative Filtering (NCF), a widely used\ndeep learning-based recommender, and Singular Value Decomposition (SVD), a\nclassical collaborative filtering technique. Experiments on the MovieLens and\nAmazon Reviews datasets provide insights into model behavior and highlight the\ngenerality of the approach across different recommendation paradigms.", "AI": {"tldr": "This paper leverages deletion diagnostics in recommendation systems to measure the influence of users or items on model performance, applying the approach to both neural and classical techniques.", "motivation": "Recommender systems enhance user experience and revenue but often sacrifice transparency, requiring techniques to quantify user or item influence on decisions.", "method": "The study employs deletion diagnostics by training models without specific users/items and comparing performance, applying this method to Neural Collaborative Filtering and Singular Value Decomposition.", "result": "Experiments conducted on MovieLens and Amazon Reviews datasets validate the model-agnostic feature of the approach and provide insights into recommender behavior.", "conclusion": "The deletion diagnostics framework is effective for evaluating user/item influence regardless of the recommendation paradigm, enabling more transparent systems."}}
{"id": "2509.10220", "pdf": "https://arxiv.org/pdf/2509.10220", "abs": "https://arxiv.org/abs/2509.10220", "authors": ["Christopher Foster"], "title": "Openness in AI and downstream governance: A global value chain approach", "categories": ["cs.CY", "cs.AI", "K.4.1; K.4.3"], "comment": null, "summary": "The rise of AI has been rapid, becoming a leading sector for investment and\npromising disruptive impacts across the economy. Within the critical analysis\nof the economic impacts, AI has been aligned to the critical literature on data\npower and platform capitalism - further concentrating power and value capture\namongst a small number of \"big tech\" leaders.\n  The equally rapid rise of openness in AI (here taken to be claims made by AI\nfirms about openness, \"open source\" and free provision) signals an interesting\ndevelopment. It highlights an emerging ecosystem of open AI models, datasets\nand toolchains, involving massive capital investment. It poses questions as to\nwhether open resources can support technological transfer and the ability for\ncatch-up, even in the face of AI industry power.\n  This work seeks to add conceptual clarity to these debates by conceptualising\nopenness in AI as a unique type of interfirm relation and therefore amenable to\nvalue chain analysis. This approach then allows consideration of the capitalist\ndynamics of \"outsourcing\" of foundational firms in value chains, and\nconsequently the types of governance and control that might emerge downstream\nas AI is adopted. This work, therefore, extends previous mapping of AI value\nchains to build a framework which links foundational AI with downstream value\nchains.\n  Overall, this work extends our understanding of AI as a productive sector.\nWhile the work remains critical of the power of leading AI firms, openness in\nAI may lead to potential spillovers stemming from the intense competition for\nglobal technological leadership in AI.", "AI": {"tldr": "The study examines the dynamics of openness in AI, integrating it into value chain analysis, and discusses how foundational AI influences downstream chains amidst industry power concentration.", "motivation": "To understand how openness in AI, such as open-source resources, interacts with the existing dominance of 'big tech' and whether it can facilitate technological transfer and reduce industry-power concentration.", "method": "The authors conceptualize openness in AI as a form of interfirm relationship, applying value chain analysis to explore governance, control, and outsourcing dynamics in the AI sector.", "result": "The study develops a framework linking foundational AI elements (like open models) with downstream value chains, providing insights into the capitalist dynamics and governance structures of the industry.", "conclusion": "While remaining critical of the consolidation of power among leading AI firms, the work posits that openness in AI may foster technological advancements and spillovers through global competition for AI leadership."}}
{"id": "2509.10378", "pdf": "https://arxiv.org/pdf/2509.10378", "abs": "https://arxiv.org/abs/2509.10378", "authors": ["Yixuan Sun", "Srinivas Eswar", "Yin Lin", "William Detmold", "Phiala Shanahan", "Xiaoye Li", "Yang Liu", "Prasanna Balaprakash"], "title": "Matrix-free Neural Preconditioner for the Dirac Operator in Lattice Gauge Theory", "categories": ["hep-lat", "cs.LG"], "comment": null, "summary": "Linear systems arise in generating samples and in calculating observables in\nlattice quantum chromodynamics~(QCD). Solving the Hermitian positive definite\nsystems, which are sparse but ill-conditioned, involves using iterative\nmethods, such as Conjugate Gradient (CG), which are time-consuming and\ncomputationally expensive. Preconditioners can effectively accelerate this\nprocess, with the state-of-the-art being multigrid preconditioners. However,\nconstructing useful preconditioners can be challenging, adding additional\ncomputational overhead, especially in large linear systems. We propose a\nframework, leveraging operator learning techniques, to construct linear maps as\neffective preconditioners. The method in this work does not rely on explicit\nmatrices from either the original linear systems or the produced\npreconditioners, allowing efficient model training and application in the CG\nsolver. In the context of the Schwinger model U(1) gauge theory in 1+1\nspacetime dimensions with two degenerate-mass fermions), this preconditioning\nscheme effectively decreases the condition number of the linear systems and\napproximately halves the number of iterations required for convergence in\nrelevant parameter ranges. We further demonstrate the framework learns a\ngeneral mapping dependent on the lattice structure which leads to zero-shot\nlearning ability for the Dirac operators constructed from gauge field\nconfigurations of different sizes.", "AI": {"tldr": "This paper addresses improving the efficiency of solving linear systems in lattice QCD through an operator learning-based preconditioning technique, reducing computational costs and iterations.", "motivation": "Solving ill-conditioned Hermitian positive definite linear systems in lattice QCD is computationally expensive. Efficient preconditioners like multigrid are challenging to construct and may introduce more overhead, calling for a better approach.", "method": "The authors propose an operator learning-based framework to construct preconditioners. These preconditioners do not rely on explicit matrices, facilitating efficient training and integration into the Conjugate Gradient solver.", "result": "In the context of the Schwinger model in 1+1 spacetime dimensions, the proposed preconditioning significantly reduces the condition number and approximately halves the required solver iterations while demonstrating zero-shot learning for operators with different lattice sizes.", "conclusion": "The new operator learning framework enhances solver efficiency effectively while showcasing flexibility with variations in lattice sizes, marking a significant advancement in preconditioning for lattice QCD problems."}}
{"id": "2509.10289", "pdf": "https://arxiv.org/pdf/2509.10289", "abs": "https://arxiv.org/abs/2509.10289", "authors": ["Iason Gabriel", "Geoff Keeling", "Arianna Manzini", "James Evans"], "title": "We Need a New Ethics for a World of AI Agents", "categories": ["cs.CY", "cs.AI", "I.2.0; K.4.1"], "comment": "6 pages, no figures", "summary": "The deployment of capable AI agents raises fresh questions about safety,\nhuman-machine relationships and social coordination. We argue for greater\nengagement by scientists, scholars, engineers and policymakers with the\nimplications of a world increasingly populated by AI agents. We explore key\nchallenges that must be addressed to ensure that interactions between humans\nand agents, and among agents themselves, remain broadly beneficial.", "AI": {"tldr": "This paper highlights the need for addressing safety, coordination, and human-machine interactions in a world increasingly populated by AI agents.", "motivation": "To engage various professionals in addressing the implications of integrating capable AI agents into society.", "method": "Exploration of key challenges and potential strategies to ensure broadly beneficial interactions between humans and AI agents, as well as agent-agent interactions.", "result": "The paper identifies critical areas of concern related to safety, human-machine relationships, and social coordination in the context of AI deployment.", "conclusion": "Proactively addressing these issues is essential to ensure AI adoption aligns with societal benefits and ethical considerations."}}
{"id": "2509.10391", "pdf": "https://arxiv.org/pdf/2509.10391", "abs": "https://arxiv.org/abs/2509.10391", "authors": ["Shanmuka Sadhu", "Weiran Wang"], "title": "Improving Audio Event Recognition with Consistency Regularization", "categories": ["cs.SD", "cs.AI"], "comment": "Under Review", "summary": "Consistency regularization (CR), which enforces agreement between model\npredictions on augmented views, has found recent benefits in automatic speech\nrecognition [1]. In this paper, we propose the use of consistency\nregularization for audio event recognition, and demonstrate its effectiveness\non AudioSet. With extensive ablation studies for both small ($\\sim$20k) and\nlarge ($\\sim$1.8M) supervised training sets, we show that CR brings consistent\nimprovement over supervised baselines which already heavily utilize data\naugmentation, and CR using stronger augmentation and multiple augmentations\nleads to additional gain for the small training set. Furthermore, we extend the\nuse of CR into the semi-supervised setup with 20K labeled samples and 1.8M\nunlabeled samples, and obtain performance improvement over our best model\ntrained on the small set.", "AI": {"tldr": "This paper explores the application of consistency regularization (CR) for audio event recognition using AudioSet and demonstrates its improvements over existing supervised and semi-supervised baselines.", "motivation": "To harness the benefits of consistency regularization, previously impactful in speech recognition, and assess its efficacy in audio event recognition, especially with varying training data sizes and semi-supervised setups.", "method": "The method involves enforcing consistency between predictions on augmented views, performing ablation studies with small and large training datasets, employing stronger and multiple augmentations, and extending CR to semi-supervised learning scenarios.", "result": "Consistency regularization improves supervised audio event recognition baselines, yields additional benefits with stronger augmentations for small datasets, and enhances performance in semi-supervised learning setups leveraging labeled and unlabeled samples.", "conclusion": "Consistency regularization proves effective for audio event recognition, improving both supervised and semi-supervised models when properly implemented with augmentations and unlabeled data."}}
{"id": "2509.10392", "pdf": "https://arxiv.org/pdf/2509.10392", "abs": "https://arxiv.org/abs/2509.10392", "authors": ["Carole Ibrahim", "Hiba Bederina", "Daniel Cuesta", "Laurent Montier", "Cyrille Delabre", "Jill-J\u00eann Vie"], "title": "Diversified recommendations of cultural activities with personalized determinantal point processes", "categories": ["cs.IR", "cs.AI"], "comment": "7 pages, accepted at RecSys workshop RecSoGood 2025", "summary": "While optimizing recommendation systems for user engagement is a\nwell-established practice, effectively diversifying recommendations without\nnegatively impacting core business metrics remains a significant industry\nchallenge. In line with our initiative to broaden our audience's cultural\npractices, this study investigates using personalized Determinantal Point\nProcesses (DPPs) to sample diverse and relevant recommendations. We rely on a\nwell-known quality-diversity decomposition of the similarity kernel to give\nmore weight to user preferences. In this paper, we present our implementations\nof the personalized DPP sampling, evaluate the trade-offs between relevance and\ndiversity through both offline and online metrics, and give insights for\npractitioners on their use in a production environment. For the sake of\nreproducibility, we release the full code for our platform and experiments on\nGitHub.", "AI": {"tldr": "This paper explores the use of personalized Determinantal Point Processes (DPPs) for balancing relevance and diversity in recommendation systems, sharing insights and code for practical implementation.", "motivation": "The paper addresses the challenge in the industry of creating diverse recommendations without negatively impacting key business metrics, driven by their goal to broaden audience cultural practices.", "method": "It employs personalized Determinantal Point Processes (DPPs), using a quality-diversity kernel decomposition to enhance user-preference weighting, evaluated with offline and online metrics.", "result": "The study reveals the trade-offs between relevance and diversity through experiments, offering practical insights for utilizing personalized DPPs in live recommendation systems.", "conclusion": "Personalized DPPs prove effective for diversifying recommendations without drastically sacrificing relevance, and the paper provides actionable guidance and reproducible resources for implementation."}}
{"id": "2509.10432", "pdf": "https://arxiv.org/pdf/2509.10432", "abs": "https://arxiv.org/abs/2509.10432", "authors": ["Harry Caufield", "Satrajit Ghosh", "Sek Wong Kong", "Jillian Parker", "Nathan Sheffield", "Bhavesh Patel", "Andrew Williams", "Timothy Clark", "Monica C. Munoz-Torres"], "title": "Standards in the Preparation of Biomedical Research Metadata: A Bridge2AI Perspective", "categories": ["q-bio.OT", "cs.AI"], "comment": null, "summary": "AI-readiness describes the degree to which data may be optimally and\nethically used for subsequent AI and Machine Learning (AI/ML) methods, where\nthose methods may involve some combination of model training, data\nclassification, and ethical, explainable prediction. The Bridge2AI consortium\nhas defined the particular criteria a biomedical dataset may possess to render\nit AI-ready: in brief, a dataset's readiness is related to its FAIRness,\nprovenance, degree of characterization, explainability, sustainability, and\ncomputability, in addition to its accompaniment with documentation about\nethical data practices.\n  To ensure AI-readiness and to clarify data structure and relationships within\nBridge2AI's Grand Challenges (GCs), particular types of metadata are necessary.\nThe GCs within the Bridge2AI initiative include four data-generating projects\nfocusing on generating AI/ML-ready datasets to tackle complex biomedical and\nbehavioral research problems. These projects develop standardized, multimodal\ndata, tools, and training resources to support AI integration, while addressing\nethical data practices. Examples include using voice as a biomarker, building\ninterpretable genomic tools, modeling disease trajectories with diverse\nmultimodal data, and mapping cellular and molecular health indicators across\nthe human body.\n  This report assesses the state of metadata creation and standardization in\nthe Bridge2AI GCs, provides guidelines where required, and identifies gaps and\nareas for improvement across the program. New projects, including those outside\nthe Bridge2AI consortium, would benefit from what we have learned about\ncreating metadata as part of efforts to promote AI readiness.", "AI": {"tldr": "The paper evaluates metadata creation and standardization in the Bridge2AI consortium to enhance AI-readiness for biomedical data.", "motivation": "Address the challenges in ensuring data is optimally and ethically usable for advanced AI/ML methods in biomedical research.", "method": "Assessment of current metadata practices, providing guidelines, and identifying gaps to enhance AI-readiness for biomedical datasets.", "result": "Outlined criteria and guidelines for AI-readiness and identified gaps in metadata practices for Bridge2AI Grand Challenges.", "conclusion": "Findings and recommendations can be applied to new projects for improving metadata and AI-readiness efforts, both within and outside Bridge2AI."}}
