{"id": "2509.13448", "pdf": "https://arxiv.org/pdf/2509.13448", "abs": "https://arxiv.org/abs/2509.13448", "authors": ["Danila Valko", "Rohan Paranjpe", "Jorge Marx G\u00f3mez"], "title": "Outperforming Dijkstra on Sparse Graphs: The Lightning Network Use Case", "categories": ["cs.PF", "cs.DS", "cs.SI"], "comment": null, "summary": "Efficient routing is critical for payment channel networks (PCNs) such as the\nLightning Network (LN), where most clients currently rely on Dijkstra-based\nalgorithms for payment pathfinding. While Dijkstra's algorithm has long been\nregarded as optimal on sparse graphs, recent theoretical work challenges this\nview. The new Bounded Multi-Source Shortest Path (BMSSP) algorithm by Duan et\nal. theoretically achieves $O(m~log^{2/3}~n)$ runtime, which is asymptotically\nfaster than Dijkstra's $O(m + n~log~n)$ on sparse directed graphs. In this\npaper, we implement BMSSP on Rust and compare its performance against\nDijkstra's using real LN topology data. Our evaluation, based on multiple\nrandomized trials and statistical tests, shows that current implementations of\nBMSSP do not significantly outperform Dijkstra's in practice, and speedups are\nsmaller than what theory predicts, possibly due to implementation and constant\nfactor overheads. These results provide the first empirical evidence of BMSSP's\npotential to accelerate LN routing and inform future optimizations of PCN\npathfinding algorithms.", "AI": {"tldr": "This paper evaluates the Bounded Multi-Source Shortest Path (BMSSP) algorithm, recently proposed as asymptotically faster than Dijkstra's algorithm, for routing in Payment Channel Networks like the Lightning Network. Empirical results suggest BMSSP does not significantly outperform Dijkstra's in practice.", "motivation": "To assess if the theoretically faster BMSSP algorithm can improve payment pathfinding in Payment Channel Networks over the widely used Dijkstra's algorithm.", "method": "Implemented BMSSP in Rust and compared its performance with Dijkstra's using real-world Lightning Network topology data, conducting randomized trials and statistical tests for evaluation.", "result": "Empirical evaluation reveals that BMSSP does not provide significant performance improvements over Dijkstra's in practice, with smaller-than-expected speedups, possibly due to implementation overheads.", "conclusion": "Current BMSSP implementations are not practically advantageous over Dijkstra's for Payment Channel Networks, but the evaluation highlights potential for future algorithmic and implementation improvements."}}
{"id": "2509.14041", "pdf": "https://arxiv.org/pdf/2509.14041", "abs": "https://arxiv.org/abs/2509.14041", "authors": ["Henry Kao", "Nikhil Sreekumar", "Prabhdeep Singh Soni", "Ali Sedaghati", "Fang Su", "Bryan Chan", "Maziar Goudarzi", "Reza Azimi"], "title": "A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching", "categories": ["cs.AR", "cs.CL", "cs.OS", "cs.PF"], "comment": null, "summary": "Modern mobile CPU software pose challenges for conventional instruction cache\nreplacement policies due to their complex runtime behavior causing high reuse\ndistance between executions of the same instruction. Mobile code commonly\nsuffers from large amounts of stalls in the CPU frontend and thus starvation of\nthe rest of the CPU resources. Complexity of these applications and their code\nfootprint are projected to grow at a rate faster than available on-chip memory\ndue to power and area constraints, making conventional hardware-centric methods\nfor managing instruction caches to be inadequate. We present a novel\nsoftware-hardware co-design approach called TRRIP (Temperature-based\nRe-Reference Interval Prediction) that enables the compiler to analyze,\nclassify, and transform code based on \"temperature\" (hot/cold), and to provide\nthe hardware with a summary of code temperature information through a\nwell-defined OS interface based on using code page attributes. TRRIP's\nlightweight hardware extension employs code temperature attributes to optimize\nthe instruction cache replacement policy resulting in the eviction rate\nreduction of hot code. TRRIP is designed to be practical and adoptable in real\nmobile systems that have strict feature requirements on both the software and\nhardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%\nresulting in geomean speedup of 3.9%, on top of RRIP cache replacement running\nmobile code already optimized using PGO.", "AI": {"tldr": "TRRIP introduces a software-hardware co-design approach for improving instruction cache replacement in mobile CPU systems, leveraging code 'temperature' to optimize the eviction rate, offering significant performance improvements.", "motivation": "Conventional instruction cache replacement policies struggle with high reuse distances in mobile CPU software, which results in CPU stalls and inefficient use of resources, exacerbated by constraints on power and memory.", "method": "TRRIP utilizes a compiler analysis to classify code temperature as 'hot' or 'cold,' communicates this through an OS interface, and incorporates lightweight hardware extensions for optimizing cache policies based on temperature attributes.", "result": "TRRIP reduces the L2 MPKI for instructions by 26.5%, leading to a geomean speedup of 3.9%, even when applied to mobile code already optimized using PGO.", "conclusion": "TRRIP shows practical benefits and is adaptable to real mobile systems, addressing the challenges posed by increasing application complexity and limited on-chip memory."}}
{"id": "2509.13557", "pdf": "https://arxiv.org/pdf/2509.13557", "abs": "https://arxiv.org/abs/2509.13557", "authors": ["Zesong Jiang", "Yuqi Sun", "Qing Zhong", "Mahathi Krishna", "Deepak Patil", "Cheng Tan", "Sriram Krishnamoorthy", "Jeff Zhang"], "title": "MACO: A Multi-Agent LLM-Based Hardware/Software Co-Design Framework for CGRAs", "categories": ["cs.AR"], "comment": null, "summary": "Coarse-grained Reconfigurable Arrays (CGRAs) are a promising computing\narchitecture that can deliver high-performance, energy-efficient acceleration\nacross diverse domains. By supporting reconfiguration at the functional unit\nlevel, CGRAs efficiently adapt to varying computational patterns and optimize\nresource utilization. However, designing CGRAs is highly challenging due to the\nvast design space, independent architectural parameters, and the time-consuming\nnature of manual design. Fortunately, the rapid advancement of large language\nmodels (LLMs) presents new opportunities to automate this process.\n  In this work, we propose MACO -- an open-source multi-agent LLM-based\nframework for Hardware/Software (HW/SW) co-design of CGRAs. The framework\nemploys LLM reasoning to generate CGRAs across four stages: HW/SW co-design,\nDesign error correction, Best design selection, and Evaluation & Feedback.\nFurthermore, MACO iteratively optimizes the generated CGRAs, leveraging agent\nreasoning and feedback to achieve higher PPA (that is, power, performance, and\narea) design points for a given domain. In addition, we introduce an LLM\nself-learning mechanism that employs LLM-driven decision making to select the\noptimal CGRA to accelerate the design process.\n  We evaluate the framework with state-of-the-art LLM-based methods and manual\nCGRA design, in terms of performance, power consumption, and area. Experimental\nresults show that MACO efficiently generates high-quality CGRA architectures,\nsignificantly reducing manual design effort and demonstrating the potential of\nour framework for real-world CGRA design.", "AI": {"tldr": "MACO, an LLM-driven multi-agent framework, automates CGRA design, optimizing power, performance, and area while outperforming manual efforts.", "motivation": "The authors aim to address the challenges of manual CGRA design, namely the vast design space, independent architectural parameters, and time-intensive processes, using LLM-based automation to improve efficiency and accelerate development.", "method": "MACO utilizes a multi-agent framework across four iterative stages: HW/SW co-design, design error correction, best design selection, and evaluation & feedback, optimizing CGRAs by leveraging LLM reasoning and feedback for PPA improvements.", "result": "Experimental results demonstrate MACO outperforms traditional manual design approaches and existing LLM-based methods, generating high-quality CGRAs with improved efficiency in performance, power consumption, and area.", "conclusion": "MACO shows significant potential in automating CGRA design processes, reducing manual efforts, and achieving high-quality designs, indicating its suitability for real-world applications."}}
{"id": "2509.13721", "pdf": "https://arxiv.org/pdf/2509.13721", "abs": "https://arxiv.org/abs/2509.13721", "authors": ["Kaustav Saha", "Ishaan R Kale", "Vivek Patel", "Anand J Kulkarni", "Puskaraj D Sonawwanay"], "title": "Snail Homing and Mating Search Algorithm for Weight Optimization of Stepped-Transmission Shaft", "categories": ["cs.NE"], "comment": null, "summary": "In this paper, the steeped-transmission shaft design problem is proposed for\nweight optimization. The bio-inspired search-based Snail Homing and Mating\nSearch (SHMS) algorithm is utilized to solve the problem. It is inspired by the\nsocial behaviour of snails and their inherent nature of finding better homes,\nand mate. The proposed steeped-transmission shaft design problem is modelled\nconsidering the fatigue loading, combined bending, torsion loads, and the\nprinciple of Modified Goodman criteria. The forces diagram and the bending\nmoment diagrams are obtained using the MDSOLIDS software. The forces and\nbending moment are then used to mathematical model the objective function and\nconstraints. The SHMS algorithm has yielded the desired solution with\nreasonable computational cost. The constraints are handled using a static\npenalty function approach. The statistical results obtained using SHMS\nalgorithm are further used for generating CAD model. The analysis is carried\nout in ANSYS Workbench. Further, the deflection obtained from SHMS algorithm\nand ANSYS Workbench are compared and results are discussed in details.", "AI": {"tldr": "This paper proposes a bio-inspired algorithm (SHMS) to optimize the weight of steeped-transmission shafts under fatigue, bending, torsion loads, and Goodman criteria. MDSOLIDS software was used for modeling forces, while results were validated with ANSYS Workbench.", "motivation": "Steeped-transmission shafts are critical components subjected to complex loading conditions; optimizing their design is essential to improve efficiency and reduce material use.", "method": "The bio-inspired Snail Homing and Mating Search (SHMS) algorithm is employed for weight optimization, using a penalty function approach to handle constraints. Force and bending diagrams are modeled mathematically, and results are validated using simulation tools like ANSYS Workbench.", "result": "The SHMS algorithm produced optimal shaft designs with reasonable computational costs. Statistical results were generated for CAD models, and deflection comparisons between SHMS outcomes and ANSYS simulations show agreement.", "conclusion": "The research successfully demonstrated the utility of SHMS for weight optimization in complex shaft designs, validating its effectiveness through computational simulations and CAD modeling."}}
{"id": "2509.13325", "pdf": "https://arxiv.org/pdf/2509.13325", "abs": "https://arxiv.org/abs/2509.13325", "authors": ["Matteo Zanotto", "Leonardo Vicentini", "Redi Vreto", "Francesco Lumpp", "Diego Braga", "Sandro Fiore"], "title": "A User-centric Kubernetes-based Architecture for Green Cloud Computing", "categories": ["cs.DC"], "comment": null, "summary": "To meet the increasing demand for cloud computing services, the scale and\nnumber of data centers keeps increasing worldwide. This growth comes at the\ncost of increased electricity consumption, which directly correlates to CO2\nemissions, the main driver of climate change. As such, researching ways to\nreduce cloud computing emissions is more relevant than ever. However, although\ncloud providers are reportedly already working near optimal power efficiency,\nthey fail in providing precise sustainability reporting. This calls for further\nimprovements on the cloud computing consumer's side. To this end, in this paper\nwe propose a user-centric, Kubernetes-based architecture for green cloud\ncomputing. We implement a carbon intensity forecaster and we use it to schedule\nworkloads based on the availability of green energy, exploiting both regional\nand temporal variations to minimize emissions. We evaluate our system using\nreal-world traces of cloud workloads execution comparing the achieved carbon\nemission savings against a baseline round-robin scheduler. Our findings\nindicate that our system can achieve up to a 13% reduction in emissions in a\nstrict scenario with heavy limitations on the available resources.", "AI": {"tldr": "This paper proposes a Kubernetes-based architecture to reduce carbon emissions in cloud computing by scheduling tasks based on green energy availability, achieving up to 13% reduction in emissions under resource constraints.", "motivation": "The paper seeks to address the increasing electricity consumption and CO2 emissions associated with the growing demand for cloud computing services.", "method": "The authors designed a carbon intensity forecaster integrated into a Kubernetes-based system to schedule workloads considering regional and temporal green energy availability.", "result": "Real-world cloud workload evaluations showed that this system reduced carbon emissions by up to 13% under stringent resource limitations.", "conclusion": "The proposed architecture demonstrates the potential for significant environmental benefits by enabling user-centric scheduling for greener cloud computing practices."}}
{"id": "2509.13332", "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "This paper systematically compares 'thinking' and 'non-thinking' Large Language Models (LLMs) in a judging paradigm with models of various sizes, showing that 'thinking' LLMs perform better in accuracy, efficiency, and robustness.", "motivation": "LLMs are increasingly used as automated judges in benchmarking and reward modeling, necessitating improvements in their reliability, efficiency, and robustness.", "method": "A comparison was conducted between 'thinking' and 'non-thinking' LLMs using open-source Qwen models, evaluating accuracy and computational efficiency on RewardBench tasks and testing augmentation strategies for non-thinking models.", "result": "'Thinking' models showed 10% higher accuracy with minimal computational costs, while augmented non-thinking models achieved minor gains at significantly higher costs. Thinking models also demonstrated greater bias resilience and robustness across languages.", "conclusion": "Explicit reasoning in LLMs yields clear benefits in accuracy, efficiency, and robustness, making 'thinking' models superior for use in automated judging paradigms."}}
{"id": "2509.13429", "pdf": "https://arxiv.org/pdf/2509.13429", "abs": "https://arxiv.org/abs/2509.13429", "authors": ["Anthony Arnold", "Mark Marron"], "title": "Catalpa: GC for a Low-Variance Software Stack", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "The performance of an application/runtime is usually conceptualized as a\ncontinuous function where, the lower the amount of memory/time used on a given\nworkload, then the better the compiler/runtime is. However, in practice, good\nperformance of an application is viewed as more of a binary function - either\nthe application responds in under, say 100 ms, and is fast enough for a user to\nbarely notice, or it takes a noticeable amount of time, leaving the user\nwaiting and potentially abandoning the task. Thus, performance really means how\noften the application is fast enough to be usable, leading industrial\ndevelopers to focus on the 95th and 99th percentile tail-latencies as heavily,\nor moreso, than average response time. Our vision is to create a software stack\nthat actively supports these needs via programming language and runtime system\ndesign. In this paper we present a novel garbage-collector design, the Catalpa\ncollector, for the Bosque programming language and runtime. This allocator is\ndesigned to minimize latency and variability while maintaining high-throughput\nand incurring small memory overheads. To achieve these goals we leverage\nvarious features of the Bosque language, including immutability and\nreference-cycle freedom, to construct a collector that has bounded collection\npauses, incurs fixed-constant memory overheads, and does not require any\nbarriers or synchronization with application code.", "AI": {"tldr": "The paper introduces the Catalpa garbage collector designed for the Bosque programming language, aiming for low latency, bounded pauses, and fixed memory overheads.", "motivation": "Industrial developers prioritize tail-latencies (e.g., 95th and 99th percentiles) as a key factor for user experience over average response time.", "method": "The Catalpa garbage collector leverages specific programming language features like immutability and reference-cycle freedom in Bosque to minimize latency, avoid synchronization barriers, and ensure memory-efficient collection pauses.", "result": "The Catalpa garbage collector achieves bounded collection pauses, fixed-constant memory overheads, and eliminates synchronization barriers with application code.", "conclusion": "The design successfully supports low-latency, reduced variability, and high throughput for modern applications prioritizing tail-latencies."}}
{"id": "2509.13480", "pdf": "https://arxiv.org/pdf/2509.13480", "abs": "https://arxiv.org/abs/2509.13480", "authors": ["Andrea Piergentili", "Beatrice Savoldi", "Matteo Negri", "Luisa Bentivogli"], "title": "Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs", "categories": ["cs.CL"], "comment": "Accepted at CLiC-it 2025", "summary": "Gender-neutral rewriting (GNR) aims to reformulate text to eliminate\nunnecessary gender specifications while preserving meaning, a particularly\nchallenging task in grammatical-gender languages like Italian. In this work, we\nconduct the first systematic evaluation of state-of-the-art large language\nmodels (LLMs) for Italian GNR, introducing a two-dimensional framework that\nmeasures both neutrality and semantic fidelity to the input. We compare\nfew-shot prompting across multiple LLMs, fine-tune selected models, and apply\ntargeted cleaning to boost task relevance. Our findings show that open-weight\nLLMs outperform the only existing model dedicated to GNR in Italian, whereas\nour fine-tuned models match or exceed the best open-weight LLM's performance at\na fraction of its size. Finally, we discuss the trade-off between optimizing\nthe training data for neutrality and meaning preservation.", "AI": {"tldr": "The study evaluates large language models for gender-neutral rewriting in Italian, comparing few-shot methods, fine-tuning strategies, and data refinement approaches for improved neutrality and fidelity.", "motivation": "Gender-neutral rewriting is important for inclusivity and tackling biases in language. The challenge is especially pronounced in grammatical-gender languages like Italian.", "method": "A two-dimensional evaluation framework was employed to assess neutrality and semantic fidelity. Few-shot prompting, fine-tuning, and targeted data cleaning methods were explored across various language models.", "result": "Open-weight large language models outperform the only existing Italian GNR model. Fine-tuned smaller models matched or surpassed open-weight LLM performance, demonstrating efficiency gains.", "conclusion": "Effective gender-neutral rewriting can be achieved by fine-tuning smaller models, achieving comparable or superior outcomes at lower computational costs, while balancing neutrality with meaning preservation in training data."}}
{"id": "2509.13425", "pdf": "https://arxiv.org/pdf/2509.13425", "abs": "https://arxiv.org/abs/2509.13425", "authors": ["Julian Evan Chrisnanto", "Yulison Herry Chrisnanto", "Ferry Faizal"], "title": "Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics", "categories": ["cs.LG", "physics.app-ph", "92D25, 35K57, 68T07", "I.2.6; J.3; G.1.8"], "comment": "20 pages, 11 figures. A preprint on using a unified physics-informed\n  neural network framework to model predator-prey dynamics", "summary": "Ecological systems exhibit complex multi-scale dynamics that challenge\ntraditional modeling. New methods must capture temporal oscillations and\nemergent spatiotemporal patterns while adhering to conservation principles. We\npresent the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,\na deep learning architecture integrating physics-informed neural networks\n(PINNs) and conservation laws to model predator-prey dynamics across\ndimensional scales. The framework provides a unified solution for both ordinary\n(ODE) and partial (PDE) differential equation systems, describing temporal\ncycles and reaction-diffusion patterns within a single neural network\narchitecture. Our methodology uses automatic differentiation to enforce physics\nconstraints and adaptive loss weighting to balance data fidelity with physical\nconsistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%\ncorrelation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures\ncomplex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).\nValidation confirms conservation law adherence within 0.5% and shows a 10-50x\ncomputational speedup for inference compared to numerical solvers. USPIL also\nenables mechanistic understanding through interpretable physics constraints,\nfacilitating parameter discovery and sensitivity analysis not possible with\npurely data-driven methods. Its ability to transition between dimensional\nformulations opens new avenues for multi-scale ecological modeling. These\ncapabilities make USPIL a transformative tool for ecological forecasting,\nconservation planning, and understanding ecosystem resilience, establishing\nphysics-informed deep learning as a powerful and scientifically rigorous\nparadigm.", "AI": {"tldr": "The paper introduces USPIL, a physics-informed deep learning framework for modeling ecological systems, successfully integrating conservation laws and neural networks.", "motivation": "To address the challenges of modeling complex, multi-scale ecological dynamics that involve spatiotemporal patterns and conservation principles.", "method": "USPIL combines physics-informed neural networks (PINNs), conservation laws, automatic differentiation for constraint enforcement, and adaptive loss weighting for balancing data fidelity and physical consistency.", "result": "USPIL demonstrated high modeling accuracy (98.9% correlation for 1D dynamics) and captured intricate patterns in 2D systems with computational speeds improved by 10-50x over numerical solvers.", "conclusion": "USPIL is a scientifically rigorous tool for ecological forecasting, parameter discovery, and multi-scale modeling, with transformative implications for conservation and ecosystem studies."}}
{"id": "2509.13338", "pdf": "https://arxiv.org/pdf/2509.13338", "abs": "https://arxiv.org/abs/2509.13338", "authors": ["Hassan Gharoun", "Mohammad Sadegh Khorshidi", "Kasra Ranjbarigderi", "Fang Chen", "Amir H. Gandomi"], "title": "Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE", "68T07, 68T09"], "comment": "15 pages, 4 figures, 3 tables", "summary": "This work proposes an evidence-retrieval mechanism for uncertainty-aware\ndecision-making that replaces a single global cutoff with an\nevidence-conditioned, instance-adaptive criterion. For each test instance,\nproximal exemplars are retrieved in an embedding space; their predictive\ndistributions are fused via Dempster-Shafer theory. The resulting fused belief\nacts as a per-instance thresholding mechanism. Because the supporting evidences\nare explicit, decisions are transparent and auditable. Experiments on\nCIFAR-10/100 with BiT and ViT backbones show higher or comparable\nuncertainty-aware performance with materially fewer confidently incorrect\noutcomes and a sustainable review load compared with applying threshold on\nprediction entropy. Notably, only a few evidences are sufficient to realize\nthese gains; increasing the evidence set yields only modest changes. These\nresults indicate that evidence-conditioned tagging provides a more reliable and\ninterpretable alternative to fixed prediction entropy thresholds for\noperational uncertainty-aware decision-making.", "AI": {"tldr": "The paper introduces an instance-adaptive decision-making mechanism using evidence retrieval, which ensures greater transparency, reliability, and interpretability in uncertainty-aware decisions.", "motivation": "To address the limitations of global cutoff thresholds in uncertainty-aware decision-making and improve transparency and reliability outcomes.", "method": "The approach retrieves proximal evidence in embedding spaces and fuses their predictive distributions using Dempster-Shafer theory to generate instance-specific thresholds.", "result": "Experiments on CIFAR-10/100 datasets demonstrate superior or comparable performance with fewer confidently incorrect decisions and manageable review load compared to conventional entropy-based thresholds.", "conclusion": "Evidence-conditioned decision-making provides a more interpretable and reliable alternative to fixed entropy-based thresholds for operational uncertainty-aware systems."}}
{"id": "2509.13459", "pdf": "https://arxiv.org/pdf/2509.13459", "abs": "https://arxiv.org/abs/2509.13459", "authors": ["Arna Ghosh", "Zahraa Chorghay", "Shahab Bakhtiari", "Blake A. Richards"], "title": "Why all roads don't lead to Rome: Representation geometry varies across the human visual cortical hierarchy", "categories": ["q-bio.NC", "cs.LG", "cs.NE"], "comment": "9 pages, 4 figures", "summary": "Biological and artificial intelligence systems navigate the fundamental\nefficiency-robustness tradeoff for optimal encoding, i.e., they must\nefficiently encode numerous attributes of the input space while also being\nrobust to noise. This challenge is particularly evident in hierarchical\nprocessing systems like the human brain. With a view towards understanding how\nsystems navigate the efficiency-robustness tradeoff, we turned to a population\ngeometry framework for analyzing representations in the human visual cortex\nalongside artificial neural networks (ANNs). In the ventral visual stream, we\nfound general-purpose, scale-free representations characterized by a power\nlaw-decaying eigenspectrum in most areas. However, in certain higher-order\nvisual areas did not have scale-free representations, indicating that\nscale-free geometry is not a universal property of the brain. In parallel, ANNs\ntrained with a self-supervised learning objective also exhibited free-free\ngeometry, but not after fine-tune on a specific task. Based on these empirical\nresults and our analytical insights, we posit that a system's representation\ngeometry is not a universal property and instead depends upon the computational\nobjective.", "AI": {"tldr": "The paper analyzes how biological and artificial systems balance efficiency and robustness via representation geometry using insights from human visual cortex and artificial neural networks.", "motivation": "To understand how systems handle the efficiency-robustness tradeoff in signal encoding, focusing on hierarchical systems like the brain and ANNs.", "method": "Population geometry framework applied to human visual cortex data and self-supervised learning ANNs.", "result": "Human visual areas mostly exhibited power-law eigenspectrums, but this was not universal; similarly, ANNs showed scale-free geometry only before task fine-tuning.", "conclusion": "Representation geometry is task-dependent, not universally uniform across systems."}}
{"id": "2509.13436", "pdf": "https://arxiv.org/pdf/2509.13436", "abs": "https://arxiv.org/abs/2509.13436", "authors": ["Evan Eisinger", "Michael A. Heroux"], "title": "Is Research Software Science a Metascience?", "categories": ["cs.SE"], "comment": "5 pages", "summary": "As research increasingly relies on computational methods, the reliability of\nscientific results depends on the quality, reproducibility, and transparency of\nresearch software. Ensuring these qualities is critical for scientific\nintegrity and discovery. This paper asks whether Research Software Science\n(RSS)--the empirical study of how research software is developed and\nused--should be considered a form of metascience, the science of science.\nClassification matters because it could affect recognition, funding, and\nintegration of RSS into research improvement. We define metascience and RSS,\ncompare their principles and objectives, and examine their overlaps. Arguments\nfor classification highlight shared commitments to reproducibility,\ntransparency, and empirical study of research processes. Arguments against\nportraying RSS as a specialized domain focused on a tool rather than the\nbroader scientific enterprise. Our analysis finds RSS advances core goals of\nmetascience, especially in computational reproducibility, and bridges\ntechnical, social, and cognitive aspects of research. Its classification\ndepends on whether one adopts a broad definition of metascience--any empirical\neffort to improve science--or a narrow one focused on systemic and\nepistemological structures. We argue RSS is best understood as a distinct\ninterdisciplinary domain that aligns with, and in some definitions fits within,\nmetascience. Recognizing it as such can strengthen its role in improving\nreliability, justify funding, and elevate software development in research\ninstitutions. Regardless of classification, applying scientific rigor to\nresearch software ensures the tools of discovery meet the standards of the\ndiscoveries themselves.", "AI": {"tldr": "The paper explores whether Research Software Science (RSS), which studies the development and use of research software, should be classified as a form of metascience and highlights the implications for recognition, funding, and research improvement.", "motivation": "To address the growing reliance on computational methods in research and examine how improving research software quality can align with metascience for reliable scientific findings.", "method": "The paper defines and compares Research Software Science (RSS) and metascience, analyzes their principles and objectives, and evaluates overlaps and distinctions to determine RSS's classification.", "result": "The analysis reveals that RSS aligns closely with metascience goals in areas like computational reproducibility and bridges technical, social, and cognitive aspects of science. Its classification depends on the definition of metascience adopted.", "conclusion": "RSS is best understood as an interdisciplinary domain that is compatible with metascience and can strengthen science reliability, justify funding, and encourage research institutions to prioritize software quality."}}
{"id": "2509.13336", "pdf": "https://arxiv.org/pdf/2509.13336", "abs": "https://arxiv.org/abs/2509.13336", "authors": ["Mehran Behjati", "Rosdiadee Nordin", "Nor Fadzilah Abdullah"], "title": "Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted to an IEEE Conference", "summary": "This paper presents a reinforcement learning (RL) based approach for path\nplanning of cellular connected unmanned aerial vehicles (UAVs) operating beyond\nvisual line of sight (BVLoS). The objective is to minimize travel distance\nwhile maximizing the quality of cellular link connectivity by considering real\nworld aerial coverage constraints and employing an empirical aerial channel\nmodel. The proposed solution employs RL techniques to train an agent, using the\nquality of communication links between the UAV and base stations (BSs) as the\nreward function. Simulation results demonstrate the effectiveness of the\nproposed method in training the agent and generating feasible UAV path plans.\nThe proposed approach addresses the challenges due to limitations in UAV\ncellular communications, highlighting the need for investigations and\nconsiderations in this area. The RL algorithm efficiently identifies optimal\npaths, ensuring maximum connectivity with ground BSs to ensure safe and\nreliable BVLoS flight operation. Moreover, the solution can be deployed as an\noffline path planning module that can be integrated into future ground control\nsystems (GCS) for UAV operations, enhancing their capabilities and safety. The\nmethod holds potential for complex long range UAV applications, advancing the\ntechnology in the field of cellular connected UAV path planning.", "AI": {"tldr": "The paper proposes a reinforcement learning-based technique to optimize UAV path planning by balancing travel distance and cellular connectivity quality.", "motivation": "The study aims to address the challenges in UAV cellular communications operating beyond visual line of sight (BVLoS), focusing on enhancing connectivity and safe operation.", "method": "The approach utilizes reinforcement learning by training an agent with a reward function based on the quality of communication links between UAVs and ground base stations.", "result": "Simulation results confirm the RL agent's ability to effectively plan feasible UAV paths while ensuring maximum connectivity with base stations.", "conclusion": "This method improves UAV cellular communications for BVLoS operations and can serve as an offline path-planning module for future ground control systems, supporting complex long-range applications."}}
{"id": "2509.14039", "pdf": "https://arxiv.org/pdf/2509.14039", "abs": "https://arxiv.org/abs/2509.14039", "authors": ["Marat Khusainov", "Marina Sheshukova", "Alain Durmus", "Sergey Samsonov"], "title": "On the Rate of Gaussian Approximation for Linear Regression Problems", "categories": ["stat.ML", "cs.LG", "math.OC", "60F05, 62L20, 93E35"], "comment": null, "summary": "In this paper, we consider the problem of Gaussian approximation for the\nonline linear regression task. We derive the corresponding rates for the\nsetting of a constant learning rate and study the explicit dependence of the\nconvergence rate upon the problem dimension $d$ and quantities related to the\ndesign matrix. When the number of iterations $n$ is known in advance, our\nresults yield the rate of normal approximation of order $\\sqrt{\\log{n}/n}$,\nprovided that the sample size $n$ is large enough.", "AI": {"tldr": "This paper examines Gaussian approximation for online linear regression and explores convergence rate dependence on problem parameters.", "motivation": "The research aims to understand the Gaussian approximation rate for online linear regression and its dependency on problem dimensions and design matrix properties.", "method": "The authors derive convergence rates under a constant learning rate and analyze the impact of dimensions and design matrix on the results.", "result": "The study finds normal approximation rates of \\(\\sqrt{\\log{n}/n}\\), conditioned on a sufficiently large sample size.", "conclusion": "The findings demonstrate explicit conditions and dependencies required for achieving Gaussian approximation rates in online linear regression tasks."}}
{"id": "2509.13694", "pdf": "https://arxiv.org/pdf/2509.13694", "abs": "https://arxiv.org/abs/2509.13694", "authors": ["Hanchen Ye", "Deming Chen"], "title": "StreamTensor: Make Tensors Stream in Dataflow Accelerators for LLMs", "categories": ["cs.AR"], "comment": "Accepted by MICRO'25", "summary": "Efficient execution of deep learning workloads on dataflow architectures is\ncrucial for overcoming memory bottlenecks and maximizing performance. While\nstreaming intermediate results between computation kernels can significantly\nimprove efficiency, existing approaches struggle with inter-kernel\ncorrelations, external memory access management, and buffer optimization. In\nthis work, we propose StreamTensor, a compiler framework that automatically\nconstructs and optimizes stream-based dataflow accelerators. StreamTensor\nintroduces a novel iterative tensor type system to explicitly encode stream\nlayouts, enabling seamless kernel fusion, buffer allocation, and memory\noptimization. By systematically exploring three hierarchical design spaces,\nincluding tensor tiling, kernel fusion, and resource allocation, StreamTensor\nbalances computational intensity, memory efficiency, and data streaming to\nmaximize performance. Based on FPGA evaluations on Large Language Models (LLM),\nStreamTensor achieves up to 0.76x and 0.64x lower latency compared to the\nstate-of-the-art FPGA LLM accelerators and GPUs, and up to 1.99x higher energy\nefficiency compared to GPUs, making it a promising approach for scalable\ndataflow-based deep learning acceleration.", "AI": {"tldr": "StreamTensor is a compiler framework for optimizing deep learning workloads on dataflow architectures, leading to reduced latency and improved energy efficiency.", "motivation": "To address inefficiencies in streaming intermediate results and memory management for deep learning architectures.", "method": "StreamTensor employs an iterative tensor type system and hierarchy-based design spaces for kernel fusion, buffer allocation, and memory optimization.", "result": "FPGA evaluations show up to 0.76x and 0.64x lower latency compared to existing setups, and up to 1.99x higher energy efficiency.", "conclusion": "StreamTensor offers a scalable and efficient approach to deep learning acceleration, with promising results in performance and energy optimization."}}
{"id": "2509.14066", "pdf": "https://arxiv.org/pdf/2509.14066", "abs": "https://arxiv.org/abs/2509.14066", "authors": ["Mirco Tincani", "Khaled Kerouch", "Umberto Garlando", "Mattia Barezzi", "Alessandro Sanginario", "Giacomo Indiveri", "Chiara De Luca"], "title": "A neuromorphic continuous soil monitoring system for precision irrigation", "categories": ["cs.NE", "cs.ET"], "comment": null, "summary": "Sensory processing at the edge requires ultra-low power stand-alone computing\ntechnologies. This is particularly true for modern agriculture and precision\nirrigation systems which aim to optimize water usage by monitoring key\nenvironmental observables continuously using distributed efficient embedded\nprocessing elements. Neuromorphic processing systems are emerging as a\npromising technology for extreme edge-computing applications that need to run\non resource-constrained hardware. As such, they are a very good candidate for\nimplementing efficient water management systems based on data measured from\nsoil and plants, across large fields. In this work, we present a fully\nenergy-efficient neuromorphic irrigation control system that operates\nautonomously without any need for data transmission or remote processing.\nLeveraging the properties of a biologically realistic spiking neural network,\nour system performs computation, and decision-making locally. We validate this\napproach using real-world soil moisture data from apple and kiwi orchards\napplied to a mixed-signal neuromorphic processor, and show that the generated\nirrigation commands closely match those derived from conventional methods\nacross different soil depths. Our results show that local neuromorphic\ninference can maintain decision accuracy, paving the way for autonomous,\nsustainable irrigation solutions at scale.", "AI": {"tldr": "This paper introduces an energy-efficient neuromorphic irrigation control system for precision agriculture, demonstrating accurate, autonomous decision-making using biologically-inspired spiking neural networks.", "motivation": "Address the need for ultra-low power, stand-alone computing for environmental monitoring in modern agriculture, particularly for optimal water usage.", "method": "Developed a neuromorphic system using spiking neural networks, tested with real-world soil data on a mixed-signal neuromorphic processor to compare irrigation decisions against conventional methods.", "result": "Validated the approach with soil moisture data from apple and kiwi orchards, showing that the neuromorphic system accurately matched conventional irrigation commands across soil depths.", "conclusion": "Local neuromorphic inference is effective and energy-efficient for scalable, autonomous, and sustainable irrigation solutions."}}
{"id": "2509.13575", "pdf": "https://arxiv.org/pdf/2509.13575", "abs": "https://arxiv.org/abs/2509.13575", "authors": ["Benjamin Wilfong", "Anand Radhakrishnan", "Henry A. Le Berre", "Tanush Prathi", "Stephen Abbott", "Spencer H. Bryngelson"], "title": "Testing and benchmarking emerging supercomputers via the MFC flow solver", "categories": ["cs.DC"], "comment": "9 pages, 3 figures", "summary": "Deploying new supercomputers requires testing and evaluation via application\ncodes. Portable, user-friendly tools enable evaluation, and the Multicomponent\nFlow Code (MFC), a computational fluid dynamics (CFD) code, addresses this\nneed. MFC is adorned with a toolchain that automates input generation,\ncompilation, batch job submission, regression testing, and benchmarking. The\ntoolchain design enables users to evaluate compiler-hardware combinations for\ncorrectness and performance with limited software engineering experience. As\nwith other PDE solvers, wall time per spatially discretized grid point serves\nas a figure of merit. We present MFC benchmarking results for five generations\nof NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures,\nutilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have\nrevealed compiler bugs and regressions on recent machines such as Frontier and\nEl Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship\nsupercomputers.", "AI": {"tldr": "The paper introduces a computational tool, MFC, designed for evaluating supercomputers and benchmarking their performance using CFD application codes on various hardware platforms and compilers.", "motivation": "Supercomputers require robust testing for compiler-hardware compatibility and performance evaluation across multiple platforms, which motivated the design of a portable, efficient toolchain.", "method": "The MFC toolchain automates tasks like input generation, benchmarking, regression testing, and batch job submission. Benchmarks are performed on multiple generations of GPUs and CPUs using different compilers.", "result": "Through MFC benchmarking, insights were gained into device performance, compiler issues, and regressions across approximately 50 compute devices and 5 flagship supercomputers.", "conclusion": "MFC proves to be an effective tool for comprehensive testing, identifying compiler bugs, and providing performance evaluations for supercomputing deployments."}}
{"id": "2509.13333", "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "The paper studies how large language models (LLMs) exhibit evaluation awareness, where they substitute their behavior between evaluation and deployment contexts. It demonstrates that this behavior scales predictably with model size using linear probing methods.", "motivation": "To address the AI safety challenge posed by evaluation awareness, wherein models may conceal dangerous capabilities during testing, making it crucial to anticipate behavior in larger, future models.", "method": "The researchers analyzed 15 models ranging in size from 0.27B to 70B parameters from four different families. They used linear probing on steering vector activations to measure and understand evaluation awareness.", "result": "The study found a power-law scaling relationship in evaluation awareness, showing that larger models exhibit progressively more pronounced evaluation awareness behavior.", "conclusion": "This paper highlights predictable scaling in evaluation awareness with model size, enabling better forecasting of deceptive behaviors in larger models and advocating for scale-aware evaluation frameworks in AI safety protocols."}}
{"id": "2509.13489", "pdf": "https://arxiv.org/pdf/2509.13489", "abs": "https://arxiv.org/abs/2509.13489", "authors": ["Chester J. F. Gould", "William J. Bowman"], "title": "Extended Abstract: Towards a Performance Comparison of Syntax and Type-Directed NbE", "categories": ["cs.PL"], "comment": "Submitted to TyDe 2025", "summary": "A key part of any dependent type-checker is the method for checking whether\ntwo types are equal. A common claim is that syntax-directed equality is more\nperformant, although type-directed equality is more expressive. However, this\nclaim is difficult to make precise, since implementations choose only one or\nthe other approach, making a direct comparison impossible. We present some\nwork-in-progress developing a realistic platform for direct, apples-to-apples,\ncomparison of the two approaches, quantifying how much slower type-directed\nequality checking is, and analyzing why and how it can be improved.", "AI": {"tldr": "The paper explores methods for comparing syntax-directed and type-directed equality in type-checking.", "motivation": "To evaluate the performance and expressiveness trade-offs between syntax-directed and type-directed equality in dependent type-checking.", "method": "Develop a comparative platform to analyze the performance gap of the two approaches.", "result": "Quantifies the performance differences and identifies areas for improvement in type-directed equality.", "conclusion": "Provides insights into optimizing type-directed equality checking to reduce its performance disadvantage."}}
{"id": "2509.13539", "pdf": "https://arxiv.org/pdf/2509.13539", "abs": "https://arxiv.org/abs/2509.13539", "authors": ["Alisa Kanganis", "Katherine A. Keith"], "title": "Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning", "categories": ["cs.CL"], "comment": null, "summary": "The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets\nmonetary policy, affecting the borrowing and spending decisions of millions of\npeople. In this work, we release Op-Fed, a dataset of 1044 human-annotated\nsentences and their contexts from FOMC transcripts. We faced two major\ntechnical challenges in dataset creation: imbalanced classes -- we estimate\nfewer than 8% of sentences express a non-neutral stance towards monetary policy\n-- and inter-sentence dependence -- 65% of instances require context beyond the\nsentence-level. To address these challenges, we developed a five-stage\nhierarchical schema to isolate aspects of opinion, monetary policy, and stance\ntowards monetary policy as well as the level of context needed. Second, we\nselected instances to annotate using active learning, roughly doubling the\nnumber of positive instances across all schema aspects. Using Op-Fed, we found\na top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion\nclassification but only 0.61 zero-shot accuracy classifying stance towards\nmonetary policy -- below our human baseline of 0.89. We expect Op-Fed to be\nuseful for future model training, confidence calibration, and as a seed dataset\nfor future annotation efforts.", "AI": {"tldr": "This paper introduces Op-Fed, a dataset of FOMC transcripts designed to analyze sentiment and stance towards monetary policy, overcoming challenges of imbalanced classes and context dependence.", "motivation": "To better understand and facilitate automated analysis of stance and sentiment on monetary policy decisions made by the U.S. Federal Open Market Committee.", "method": "The authors created Op-Fed using a hierarchical schema for annotation and active learning to address dataset challenges such as imbalanced classes and inter-sentence dependence.", "result": "The dataset, Op-Fed, revealed that a closed-weight LLM achieved mixed performance: 0.80 accuracy in opinion classification and 0.61 in stance classification, lower than human annotation accuracy.", "conclusion": "Op-Fed provides a valuable resource for improving model training in opinion and stance classification related to monetary policy, highlighting areas for future improvement."}}
{"id": "2509.13516", "pdf": "https://arxiv.org/pdf/2509.13516", "abs": "https://arxiv.org/abs/2509.13516", "authors": ["Tom Almog"], "title": "An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training", "categories": ["cs.LG", "68T05 (Primary) 90C30, 68W40 (Secondary)"], "comment": "7 pages. 3 figures", "summary": "As machine learning models grow increasingly complex and computationally\ndemanding, understanding the environmental impact of training decisions becomes\ncritical for sustainable AI development. This paper presents a comprehensive\nempirical study investigating the relationship between optimizer choice and\nenergy efficiency in neural network training. We conducted 360 controlled\nexperiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using\neight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,\nNAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking\non Apple M1 Pro hardware, we measured training duration, peak memory usage,\ncarbon dioxide emissions, and final model performance. Our findings reveal\nsubstantial trade-offs between training speed, accuracy, and environmental\nimpact that vary across datasets and model complexity. We identify AdamW and\nNAdam as consistently efficient choices, while SGD demonstrates superior\nperformance on complex datasets despite higher emissions. These results provide\nactionable insights for practitioners seeking to balance performance and\nsustainability in machine learning workflows.", "AI": {"tldr": "The paper analyzes the impact of optimizer choices on energy efficiency and sustainability during neural network training.", "motivation": "The study aims to address the environmental impact of AI model training, which is increasingly significant due to the growing complexity of machine learning models.", "method": "360 experiments were conducted on benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using eight optimizers under controlled conditions, with energy and performance metrics tracked using CodeCarbon.", "result": "AdamW and NAdam showed consistent efficiency, and SGD performed well on complex datasets but caused higher carbon emissions.", "conclusion": "The paper offers practical advice for balancing performance and sustainability by considering optimizer trade-offs during training decisions in AI workflows."}}
{"id": "2509.13353", "pdf": "https://arxiv.org/pdf/2509.13353", "abs": "https://arxiv.org/abs/2509.13353", "authors": ["Muhammad Adnan Shahzad"], "title": "Hybrid Quantum-Classical Model for Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This study presents a systematic comparison between hybrid quantum-classical\nneural networks and purely classical models across three benchmark datasets\n(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and\nrobustness. The hybrid models integrate parameterized quantum circuits with\nclassical deep learning architectures, while the classical counterparts use\nconventional convolutional neural networks (CNNs). Experiments were conducted\nover 50 training epochs for each dataset, with evaluations on validation\naccuracy, test accuracy, training time, computational resource usage, and\nadversarial robustness (tested with $\\epsilon=0.1$ perturbations).Key findings\ndemonstrate that hybrid models consistently outperform classical models in\nfinal accuracy, achieving {99.38\\% (MNIST), 41.69\\% (CIFAR100), and 74.05\\%\n(STL10) validation accuracy, compared to classical benchmarks of 98.21\\%,\n32.25\\%, and 63.76\\%, respectively. Notably, the hybrid advantage scales with\ndataset complexity, showing the most significant gains on CIFAR100 (+9.44\\%)\nand STL10 (+10.29\\%). Hybrid models also train 5--12$\\times$ faster (e.g.,\n21.23s vs. 108.44s per epoch on MNIST) and use 6--32\\% fewer parameters} while\nmaintaining superior generalization to unseen test data.Adversarial robustness\ntests reveal that hybrid models are significantly more resilient on simpler\ndatasets (e.g., 45.27\\% robust accuracy on MNIST vs. 10.80\\% for classical) but\nshow comparable fragility on complex datasets like CIFAR100 ($\\sim$1\\%\nrobustness for both). Resource efficiency analyses indicate that hybrid models\nconsume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization\n(9.5\\% vs. 23.2\\% on average).These results suggest that hybrid\nquantum-classical architectures offer compelling advantages in accuracy,\ntraining efficiency, and parameter scalability, particularly for complex vision\ntasks.", "AI": {"tldr": "The paper compares hybrid quantum-classical neural networks to purely classical models on benchmarks (MNIST, CIFAR100, STL10), showing that hybrid models outperform in accuracy, speed, and resource efficiency, especially with complex datasets.", "motivation": "To evaluate the effectiveness of hybrid quantum-classical neural networks versus traditional classical models in terms of performance, efficiency, and robustness.", "method": "The study integrates parameterized quantum circuits with classical deep learning architectures and compares them to conventional CNNs across benchmarks, analyzing accuracy, training time, robustness, and resource usage.", "result": "Hybrid models perform better in accuracy (+9-10% gains on CIFAR100 and STL10), train 5-12x faster, use fewer parameters (6-32%), and consume less memory and CPU. They also show increased robustness on simpler datasets but similar fragility on complex datasets under adversarial attacks.", "conclusion": "Hybrid quantum-classical architectures demonstrate significant advantages in scalability, speed, resource efficiency, and generalization, making them particularly suitable for complex vision tasks."}}
{"id": "2509.13481", "pdf": "https://arxiv.org/pdf/2509.13481", "abs": "https://arxiv.org/abs/2509.13481", "authors": ["Sir-Lord Wiafe", "Najme Soleimani", "Masoud Seraji", "Bradley Baker", "Robyn Miller", "Ashkan Faghiri", "Vince D. Calhoun"], "title": "Complex-valued Phase Synchrony Reveals Directional Coupling in FMRI and Tracks Medication Effects", "categories": ["q-bio.NC"], "comment": "5 pages, 3 Figures, conference", "summary": "Understanding interactions in complex systems requires capturing the\ndirectionality of coupling, not only its strength. Phase synchronization\ncaptures this timing, yet most methods either reduce phase to its cosine or\ncollapse it into scaler indices such as phase-locking value, discarding\ndirectionality. We propose a complex-valued phase synchrony (CVPS) framework\nthat estimates phase with an adaptive Gabor wavelet and preserves both cosine\nand sine components. Simulations confirm that CVPS recovers true phase offsets\nand tracks non-stationary dynamics more faithfully than Hilbert-based methods.\nBecause antipsychotics are known to modulate the timing of cortical\ninteractions, they provide a rigorous context to evaluate whether CVPS can\ncapture such pharmacological effects. CVPS further reveals cortical\nneuro-hemodynamic drivers, with occipital-to-parietal and\nprefrontal-to-striatal lead-lag flows consistent with known receptor targets,\nconfirming its ability to capture pharmacological timing. CVPS, therefore,\noffers a robust and generalizable framework for detecting directional coupling\nin complex systems such as the brain.", "AI": {"tldr": "This paper introduces a novel framework, Complex-Valued Phase Synchrony (CVPS), to accurately measure directionality and timing in phase synchronization, overcoming limitations of existing methods.", "motivation": "The need to better capture directionality and timing in phase synchronization, particularly in analyzing complex systems like the brain, which current methods fail to adequately address.", "method": "The proposed CVPS uses an adaptive Gabor wavelet to estimate phase while preserving cosine and sine components, offering improvements over Hilbert-based methods. Simulations and pharmacological tests were conducted to validate its accuracy.", "result": "CVPS successfully recovered true phase offsets and tracked non-stationary dynamics, outperforming traditional methods. It also demonstrated neuro-hemodynamic effects consistent with known pharmacological receptor actions.", "conclusion": "CVPS provides a reliable and effective framework to detect directional coupling and timing intricacies in complex systems, with applications in neuroscience and beyond."}}
{"id": "2509.13471", "pdf": "https://arxiv.org/pdf/2509.13471", "abs": "https://arxiv.org/abs/2509.13471", "authors": ["Sina Gogani-Khiabani", "Ashutosh Trivedi", "Diptikalyan Saha", "Saeid Tizpaz-Niari"], "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "categories": ["cs.SE", "cs.AI"], "comment": "To appear at ICSE 26. 12 pages", "summary": "Large language models (LLMs) show promise for translating natural-language\nstatutes into executable logic, but reliability in legally critical settings\nremains challenging due to ambiguity and hallucinations. We present an agentic\napproach for developing legal-critical software, using U.S. federal tax\npreparation as a case study. The key challenge is test-case generation under\nthe oracle problem, where correct outputs require interpreting law. Building on\nmetamorphic testing, we introduce higher-order metamorphic relations that\ncompare system outputs across structured shifts among similar individuals.\nBecause authoring such relations is tedious and error-prone, we use an\nLLM-driven, role-based framework to automate test generation and code\nsynthesis. We implement a multi-agent system that translates tax code into\nexecutable software and incorporates a metamorphic-testing agent that searches\nfor counterexamples. In experiments, our framework using a smaller model\n(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier\nmodels (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results\nsupport agentic LLM methodologies as a path to robust, trustworthy\nlegal-critical software from natural-language specifications.", "AI": {"tldr": "The study explores using large language models (LLMs) for translating legal texts into executable code, focusing on U.S. tax law. An agentic method enables automated test generation and code synthesis, improving reliability.", "motivation": "The paper aims to address the challenge of creating reliable software for legally critical applications, particularly overcoming ambiguity and hallucinations in LLM translations of legal texts.", "method": "The research uses a multi-agent system powered by LLMs to automate testing and code synthesis. It incorporates higher-order metamorphic testing to generate cases that interpret legal texts based on structured shifts.", "result": "When tested on complex tax-code tasks, the approach achieved a worst-case pass rate of 45% using GPT-4o-mini, outperforming leading LLMs like GPT-4o and Claude 3.5, which scored 9-15%.", "conclusion": "Agentic LLM methods show promise in developing trustworthy software from natural-language legal specifications, offering improved accuracy in legally critical applications."}}
{"id": "2509.13342", "pdf": "https://arxiv.org/pdf/2509.13342", "abs": "https://arxiv.org/abs/2509.13342", "authors": ["Isaac Ronald Ward"], "title": "Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments", "categories": ["cs.RO", "cs.AI"], "comment": "This report is submitted as partial fulfilment of the requirements\n  for the Honours Programme of the Department of Computer Science and Software\n  Engineering, The University of Western Australia, 2019", "summary": "In this work, an existing deep neural network approach for determining a\nrobot's pose from visual information (RGB images) is modified, improving its\nlocalization performance without impacting its ease of training. Explicitly,\nthe network's loss function is extended in a manner which intuitively combines\nthe positional and rotational error in order to increase robustness to\nperceptual aliasing. An improvement in the localization accuracy for indoor\nscenes is observed: with decreases of up to 9.64% and 2.99% in the median\npositional and rotational error respectively, when compared to the unmodified\nnetwork.\n  Additionally, photogrammetry data is used to produce a pose-labelled dataset\nwhich allows the above model to be trained on a local environment, resulting in\nlocalization accuracies of 0.11m & 0.89 degrees. This trained model forms the\nbasis of a navigation algorithm, which is tested in real-time on a TurtleBot (a\nwheeled robotic device). As such, this work introduces a full pipeline for\ncreating a robust navigational algorithm for any given real world indoor scene;\nthe only requirement being a collection of images from the scene, which can be\ncaptured in as little as 330 seconds of", "AI": {"tldr": "This paper modifies a deep neural network for robot pose estimation, enhancing localization by changing its loss function and utilizing photogrammetry data.", "motivation": "Improve robot localization accuracy and robustness to perceptual aliasing for indoor scenes based on RGB image data.", "method": "The loss function is adjusted to better fuse positional and rotational errors, and a pose-labeled dataset from photogrammetry data is used for local model training.", "result": "Localization performance improved with positional and rotational error reductions of up to 9.64% and 2.99%, achieving 0.11m and 0.89\u00b0 accuracy in local environments.", "conclusion": "Introduced a complete pipeline for robust robotic navigation in real indoor environments, validated by real-time testing on TurtleBot."}}
{"id": "2509.13548", "pdf": "https://arxiv.org/pdf/2509.13548", "abs": "https://arxiv.org/abs/2509.13548", "authors": ["Manan Mittal", "Thomas Deppisch", "Joseph Forrer", "Chris Le Sueur", "Zamir Ben-Hur", "David Lou Along", "Daniel D. E. Wong"], "title": "Field of View Enhanced Signal Dependent Binauralization with Mixture of Experts Framework for Continuous Source Motion", "categories": ["cs.SD", "stat.ML"], "comment": "5 pages, 3 figures", "summary": "We propose a novel mixture of experts framework for field-of-view enhancement\nin binaural signal matching. Our approach enables dynamic spatial audio\nrendering that adapts to continuous talker motion, allowing users to emphasize\nor suppress sounds from selected directions while preserving natural binaural\ncues. Unlike traditional methods that rely on explicit direction-of-arrival\nestimation or operate in the Ambisonics domain, our signal-dependent framework\ncombines multiple binaural filters in an online manner using implicit\nlocalization. This allows for real-time tracking and enhancement of moving\nsound sources, supporting applications such as speech focus, noise reduction,\nand world-locked audio in augmented and virtual reality. The method is agnostic\nto array geometry offering a flexible solution for spatial audio capture and\npersonalized playback in next-generation consumer audio devices.", "AI": {"tldr": "The paper introduces a novel framework for adaptive spatial audio enhancement using a mixture of experts technique in binaural signal processing to focus on sound sources dynamically.", "motivation": "To address limitations of traditional methods in spatial audio enhancement that struggle with real-time tracking and emphasize dynamic and personalized playback.", "method": "It employs implicit localization and a mixture of binaural filters in an online manner for real-time adaptive spatial audio rendering.", "result": "Dynamic spatial audio rendering enhances user experience by focusing or suppressing sounds while maintaining natural binaural cues in applications like AR/VR.", "conclusion": "The proposed method is a flexible, geometry-agnostic solution for improving spatial audio in consumer devices, enabling dynamic, personalized audio playback."}}
{"id": "2509.13710", "pdf": "https://arxiv.org/pdf/2509.13710", "abs": "https://arxiv.org/abs/2509.13710", "authors": ["Hongyi Li", "Songchen Ma", "Huanyu Qu", "Weihao Zhang", "Jia Chen", "Junfeng Lin", "Fengbin Tu", "Rong Zhao"], "title": "CompAir: Synergizing Complementary PIMs and In-Transit NoC Computation for Efficient LLM Acceleration", "categories": ["cs.AR"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has revolutionized\nvarious aspects of human life, yet their immense computational and energy\ndemands pose significant challenges for efficient inference. The memory wall,\nthe growing processor-memory speed disparity, remains a critical bottleneck for\nLLM. Process-In-Memory (PIM) architectures overcome limitations by co-locating\ncompute units with memory, leveraging 5-20$\\times$ higher internal bandwidth\nand enabling greater energy efficiency than GPUs. However, existing PIMs\nstruggle to balance flexibility, performance, and cost-efficiency for LLMs'\ndynamic memory-compute patterns and operator diversity. DRAM-PIM suffers from\ninter-bank communication overhead despite its vector parallelism. SRAM-PIM\noffers sub-10ns latency for matrix operation but is constrained by limited\ncapacity. This work introduces CompAir, a novel PIM architecture that\nintegrates DRAM-PIM and SRAM-PIM with hybrid bonding, enabling efficient linear\ncomputations while unlocking multi-granularity data pathways. We further\ndevelop CompAir-NoC, an advanced network-on-chip with an embedded arithmetic\nlogic unit that performs non-linear operations during data movement,\nsimultaneously reducing communication overhead and area cost. Finally, we\ndevelop a hierarchical Instruction Set Architecture that ensures both\nflexibility and programmability of the hybrid PIM. Experimental results\ndemonstrate that CompAir achieves 1.83-7.98$\\times$ prefill and\n1.95-6.28$\\times$ decode improvement over the current state-of-the-art fully\nPIM architecture. Compared to the hybrid A100 and HBM-PIM system, CompAir\nachieves 3.52$\\times$ energy consumption reduction with comparable throughput.\nThis work represents the first systematic exploration of hybrid DRAM-PIM and\nSRAM-PIM architectures with in-network computation capabilities, offering a\nhigh-efficiency solution for LLM.", "AI": {"tldr": "The paper introduces CompAir, a novel hybrid PIM architecture combining DRAM-PIM and SRAM-PIM to address the computational and memory constraints of LLMs efficiently.", "motivation": "The work is driven by the challenges posed by large memory and computational demands of LLM inference, especially overcoming the memory wall and inefficiencies in existing PIM architectures.", "method": "CompAir integrates DRAM-PIM and SRAM-PIM architectures using hybrid bonding and adds innovations like CompAir-NoC, an advanced network-on-chip with embedded arithmetic logic for non-linear operations.", "result": "Experimental results show CompAir outperforms current PIM architectures with improvements in prefill and decode speeds by up to 7.98\u00d7 and reductions in energy consumption compared to hybrid A100 systems.", "conclusion": "CompAir proves to be a systematic high-efficiency solution for LLM inference by integrating flexible, high-speed, and energy-efficient hybrid PIM architectures."}}
{"id": "2509.13583", "pdf": "https://arxiv.org/pdf/2509.13583", "abs": "https://arxiv.org/abs/2509.13583", "authors": ["Varsha Rao", "Andrew A. Chien"], "title": "Modeling the Carbon Footprint of HPC: The Top 500 and EasyC", "categories": ["cs.DC"], "comment": "15 pages, 11 figures", "summary": "Climate change is a critical concern for HPC systems, but GHG protocol\ncarbon-emission accounting methodologies are difficult for a single system, and\neffectively infeasible for a collection of systems. As a result, there is no\nHPC-wide carbon reporting, and even the largest HPC sites do not do GHG\nprotocol reporting.\n  We assess the carbon footprint of HPC, focusing on the Top 500 systems. The\nkey challenge lies in modeling the carbon footprint with limited data\navailability.\n  With the disclosed Top500.org data, and using a new tool, EasyC, we were able\nto model the operational carbon of 391 HPC systems and the embodied carbon of\n283 HPC systems. We further show how this coverage can be enhanced by\nexploiting additional public information. With improved coverage, then\ninterpolation is used to produce the first carbon footprint estimates of the\nTop 500 HPC systems. They are 1,393.7 million MT CO2e operational carbon (1\nYear) and 1,881.8 million MT CO2e embodied carbon. We also project how the Top\n500's carbon footprint will increase through 2030.\n  A key enabler is the EasyC tool which models carbon footprint with only a few\ndata metrics. We explore availability of data and enhancement, showing that\ncoverage can be increased to 98% of Top 500 systems for operational and 80.8%\nof the systems for embodied emissions.", "AI": {"tldr": "The paper assesses the carbon footprint of HPC systems using the Top 500 database and introduces the EasyC tool to estimate operational and embodied carbon emissions.", "motivation": "Address the lack of carbon reporting for High-Performance Computing (HPC) systems and the challenges posed by limited data availability in evaluating their carbon footprint.", "method": "Leveraging publicly available data from the Top500.org database and employing the EasyC tool to model operational and embodied carbon emissions for HPC systems.", "result": "Successfully modeled operational carbon emissions for 391 HPC systems and embodied carbon for 283 systems. Estimated the Top 500 HPC systems' carbon footprint at 1,393.7 million MT CO2e (operational) and 1,881.8 million MT CO2e (embodied).", "conclusion": "The EasyC tool facilitates modeling and improving data coverage, enabling scalable carbon footprint estimation for HPC systems, with projections extending to 2030."}}
{"id": "2509.13334", "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "Faithful Reasoning via Intervention Training (FRIT) is introduced as a method to make large language models (LLMs) more trustworthy and causally consistent in their reasoning outputs.", "motivation": "The paper addresses the brittleness and untrustworthiness of reasoning outputs from large language models due to steps failing to causally influence final answers.", "method": "FRIT uses synthetic training data by intervening in individual reasoning steps in model-generated Chain-of-thoughts (CoTs) and applies Direct Preference Optimization to encourage causally consistent reasoning paths.", "result": "FRIT improves faithful reasoning metrics (+3.4 percentage points on GSM8K for Mistral models) and boosts accuracy (+7.6 percentage points on factual and symbolic reasoning tasks).", "conclusion": "FRIT offers a scalable and supervision-free approach to enhance the reliability and interpretability of reasoning in language models, filling a critical gap in trustworthiness and reasoning performance alignment."}}
{"id": "2509.13982", "pdf": "https://arxiv.org/pdf/2509.13982", "abs": "https://arxiv.org/abs/2509.13982", "authors": ["Boyu Zhang", "Ping He", "Tianyu Du", "Xuhong Zhang", "Lei Yun", "Kingsum Chow", "Jianwei Yin"], "title": "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing", "categories": ["cs.PL"], "comment": null, "summary": "With the widespread adoption of open-source code language models (code LMs),\nintellectual property (IP) protection has become an increasingly critical\nconcern. While current watermarking techniques have the potential to identify\nthe code LM to protect its IP, they have limitations when facing the more\npractical and complex demand, i.e., offering the individual user-level tracing\nin the black-box setting. This work presents CLMTracing, a black-box code LM\nwatermarking framework employing the rule-based watermarks and\nutility-preserving injection method for user-level model tracing. CLMTracing\nfurther incorporates a parameter selection algorithm sensitive to the robust\nwatermark and adversarial training to enhance the robustness against watermark\nremoval attacks. Comprehensive evaluations demonstrate CLMTracing is effective\nacross multiple state-of-the-art (SOTA) code LMs, showing significant harmless\nimprovements compared to existing SOTA baselines and strong robustness against\nvarious removal attacks.", "AI": {"tldr": "CLMTracing is a framework designed for user-level tracing in black-box code language models (code LMs). It improves watermark robustness and withstands removal attacks.", "motivation": "The motivation behind the study is to address intellectual property protection challenges posed by open-source code language models by enabling individual user tracing.", "method": "The framework uses rule-based watermarks, utility-preserving injection methods, parameter selection algorithms sensitive to watermark robustness, and adversarial training.", "result": "CLMTracing performs effectively across multiple SOTA code LMs, showing enhanced robustness and minimal impact on utility when compared with existing baselines.", "conclusion": "The proposed framework significantly advances watermarking techniques, offering improved tracing capabilities and robustness against removal attacks, making it suitable for protecting code LM intellectual property."}}
{"id": "2509.13569", "pdf": "https://arxiv.org/pdf/2509.13569", "abs": "https://arxiv.org/abs/2509.13569", "authors": ["John Mendon\u00e7a", "Lining Zhang", "Rahul Mallidi", "Alon Lavie", "Isabel Trancoso", "Luis Fernando D'Haro", "Jo\u00e3o Sedoc"], "title": "Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12", "categories": ["cs.CL"], "comment": "DSTC12 Track 1 Overview Paper. https://chateval.org/dstc12", "summary": "The rapid advancement of Large Language Models (LLMs) has intensified the\nneed for robust dialogue system evaluation, yet comprehensive assessment\nremains challenging. Traditional metrics often prove insufficient, and safety\nconsiderations are frequently narrowly defined or culturally biased. The DSTC12\nTrack 1, \"Dialog System Evaluation: Dimensionality, Language, Culture and\nSafety,\" is part of the ongoing effort to address these critical gaps. The\ntrack comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic\nEvaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.\nFor Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved\nthe highest average Spearman's correlation (0.1681), indicating substantial\nroom for improvement. In Task 2, while participating teams significantly\noutperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top\nROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126\nROC-AUC), highlighting critical needs in culturally-aware safety. This paper\ndescribes the datasets and baselines provided to participants, as well as\nsubmission evaluation results for each of the two proposed subtasks.", "AI": {"tldr": "This paper explores comprehensive evaluation methods for dialogue systems focusing on multi-dimensional metrics and safety detection across languages and cultures.", "motivation": "There is a growing need to address the limitations of traditional metrics for dialogue evaluation, especially in terms of safety, which is often culturally biased or narrowly defined.", "method": "The DSTC12 Track 1 was designed with two subtasks: (1) Dialogue-level, Multi-dimensional Automatic Evaluation Metrics using dimensions like Spearman's correlation, and (2) Multilingual and Multicultural Safety Detection using models like Llama-3-8B and Llama-Guard-3-1B.", "result": "For Task 1, the highest average Spearman's correlation was 0.1681, revealing significant room for improvement. In Task 2, teams did better in multilingual safety detection (top ROC-AUC 0.9648) than cultural subset evaluations, where the baseline outperformed them (0.5126 ROC-AUC).", "conclusion": "The findings stress the importance of developing better tools for culturally-aware and robust safety evaluation while highlighting gaps in existing methodologies."}}
{"id": "2509.13520", "pdf": "https://arxiv.org/pdf/2509.13520", "abs": "https://arxiv.org/abs/2509.13520", "authors": ["Varun Kumar", "Jing Bi", "Cyril Ngo Ngoc", "Victor Oancea", "George Em Karniadakis"], "title": "Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework", "categories": ["cs.LG"], "comment": null, "summary": "Neural surrogates and operator networks for solving partial differential\nequation (PDE) problems have attracted significant research interest in recent\nyears. However, most existing approaches are limited in their ability to\ngeneralize solutions across varying non-parametric geometric domains. In this\nwork, we address this challenge in the context of Polyethylene Terephthalate\n(PET) bottle buckling analysis, a representative packaging design problem\nconventionally solved using computationally expensive finite element analysis\n(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously\npredicts nodal displacement fields and the time evolution of reaction forces\nduring top load compression. Our methodology is evaluated on two families of\nbottle geometries parameterized by two and four design variables. Training data\nis generated using nonlinear FEA simulations in Abaqus for 254 unique designs\nper family. The proposed framework achieves mean relative $L^{2}$ errors of\n2.5-13% for displacement fields and approximately 2.4% for time-dependent\nreaction forces for the four-parameter bottle family. Point-wise error analyses\nfurther show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,\nwith the largest discrepancies confined to localized geometric regions.\nImportantly, the model accurately captures key physical phenomena, such as\nbuckling behavior, across diverse bottle geometries. These results highlight\nthe potential of our framework as a scalable and computationally efficient\nsurrogate, particularly for multi-task predictions in computational mechanics\nand applications requiring rapid design evaluation.", "AI": {"tldr": "The paper presents a hybrid DeepONet-Transolver framework for solving PDE problems, specifically for PET bottle buckling analysis, achieving impressive accuracy with significantly reduced computation time compared to traditional FEA methods.", "motivation": "Traditional finite element analysis (FEA) for analyzing PET bottle buckling is computationally expensive and does not efficiently generalize across varying geometric domains. This paper aims to address these limitations by introducing a scalable and efficient neural network-based surrogate model.", "method": "The authors develop a hybrid DeepONet-Transolver framework to predict nodal displacement fields and the time evolution of reaction forces during compression. Training data is derived from FEA simulations for 254 unique PET bottle designs for each of two geometric parameter families.", "result": "The framework achieves mean relative $L^{2}$ errors of 2.5-13% for displacement fields and 2.4% for time-dependent reaction forces in the four-parameter design family. Errors in displacement are on the order of $10^{-4}$-$10^{-3}$, with localized discrepancies and accurate buckling behavior representation.", "conclusion": "The proposed framework demonstrates potential as a computationally efficient surrogate for PET bottle design evaluations, offering rapid and accurate predictions for multi-task problems in computational mechanics."}}
{"id": "2509.13361", "pdf": "https://arxiv.org/pdf/2509.13361", "abs": "https://arxiv.org/abs/2509.13361", "authors": ["Tong Yulin", "Liang Xuechen"], "title": "Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention", "categories": ["cs.CV"], "comment": null, "summary": "Expressway traffic congestion severely reduces travel efficiency and hinders\nregional connectivity. Existing \"detection-prediction\" systems have critical\nflaws: low vehicle perception accuracy under occlusion and loss of\nlong-sequence dependencies in congestion forecasting. This study proposes an\nintegrated technical framework to resolve these issues.For traffic flow\nperception, two baseline algorithms were optimized. Traditional YOLOv11 was\nupgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort\nwas improved by fusing Mahalanobis (motion) and cosine (appearance) distances.\nExperiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\\%\nmAP (6.5 percentage points higher than baseline) with 5.3\\% occlusion miss\nrate. DeepSort reached 93.8\\% MOTA (11.3 percentage points higher than SORT)\nwith only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km\nhigh-density scenarios), speed and density showed a strong negative correlation\n(r=-0.97), conforming to traffic flow theory. For congestion warning, a\nGRU-Attention model was built to capture congestion precursors. Trained 300\nepochs with flow, density, and speed, it achieved 99.7\\% test accuracy (7-9\npercentage points higher than traditional GRU). In 10-minute advance warnings\nfor 30-minute congestion, time error was $\\leq$ 1 minute. Validation with an\nindependent video showed 95\\% warning accuracy, over 90\\% spatial overlap of\ncongestion points, and stable performance in high-flow ($>$5 vehicles/second)\nscenarios.This framework provides quantitative support for expressway\ncongestion control, with promising intelligent transportation applications.", "AI": {"tldr": "The paper introduces an advanced framework combining optimized perception algorithms (YOLOv11-DIoU and improved DeepSort) and a GRU-Attention model to improve vehicle detection and congestion forecasting on expressways.", "motivation": "The paper aims to address critical flaws in current traffic detection-prediction systems, such as low vehicle perception accuracy under occlusion and insufficient long-sequence dependency capture for congestion forecasting.", "method": "Perception was improved using upgraded YOLOv11-DIoU and DeepSort for better vehicle tracking. Congestion forecasting was handled using a GRU-Attention model trained on traffic flow, density, and speed data.", "result": "YOLOv11-DIoU achieved 95.7% mAP, DeepSort delivered 93.8% MOTA, and the GRU-Attention model achieved 99.7% test accuracy while providing highly accurate congestion warnings.", "conclusion": "The framework successfully mitigates major issues in detection-prediction systems, improving congestion control accuracy and offering high potential for intelligent transportation applications."}}
{"id": "2509.13612", "pdf": "https://arxiv.org/pdf/2509.13612", "abs": "https://arxiv.org/abs/2509.13612", "authors": ["Chuyang Zhou", "Ziao Ji", "Daochang Liu", "Dongang Wang", "Chenyu Wang", "Chang Xu"], "title": "Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans", "categories": ["q-bio.NC", "cs.CV"], "comment": null, "summary": "Understanding how spontaneous brain activity relates to stimulus-driven\nneural responses is a fundamental challenge in cognitive neuroscience. While\ntask-based functional magnetic resonance imaging (fMRI) captures localized\nstimulus-evoked brain activation, its acquisition is costly, time-consuming,\nand difficult to scale across populations. In contrast, resting-state fMRI\n(rs-fMRI) is task-free and abundant, but lacks direct interpretability. We\nintroduce Rest2Visual, a conditional generative model that predicts visually\nevoked fMRI (ve-fMRI) from resting-state input and 2D visual stimuli. It\nfollows a volumetric encoder--decoder design, where multiscale 3D features from\nrs-fMRI are modulated by image embeddings via adaptive normalization, enabling\nspatially accurate, stimulus-specific activation synthesis. To enable model\ntraining, we construct a large-scale triplet dataset from the Natural Scenes\nDataset (NSD), aligning each rs-fMRI volume with stimulus images and their\ncorresponding ve-fMRI activation maps. Quantitative evaluation shows that the\npredicted activations closely match ground truth across standard similarity and\nrepresentational metrics, and support successful image reconstruction in\ndownstream decoding. Notably, the predicted maps preserve subject-specific\nstructure, demonstrating the model's capacity to generate individualized\nfunctional surrogates. Our results provide compelling evidence that\nindividualized spontaneous neural activity can be transformed into\nstimulus-aligned representations, opening new avenues for scalable, task-free\nfunctional brain modeling.", "AI": {"tldr": "This study introduces Rest2Visual, a model that uses resting-state fMRI and visual stimuli to predict visually evoked brain activation, addressing the gap between task-free and task-based fMRI.", "motivation": "The paper aims to overcome limitations in functional brain imaging by leveraging abundant resting-state fMRI data to infer stimulus-driven neural activations, which traditionally require costly and time-intensive methods.", "method": "The researchers created a conditional generative model with a volumetric encoder-decoder design, leveraging multiscale 3D rs-fMRI features and stimulus embeddings for activation synthesis. They also developed a triplet dataset aligning rs-fMRI data with visual stimuli and activation maps from the Natural Scenes Dataset (NSD).", "result": "The generated activation maps were closely matched with ground truth, supported downstream decoding tasks, and preserved individualized subject-specific features, showcasing the model's accuracy and functional utility.", "conclusion": "Rest2Visual demonstrates that resting-state neural activity can be transformed into individualized, visually evoked activation maps, offering a scalable, task-free approach to brain modeling."}}
{"id": "2509.13487", "pdf": "https://arxiv.org/pdf/2509.13487", "abs": "https://arxiv.org/abs/2509.13487", "authors": ["Abubakari Alidu", "Michele Ciavotta", "Flavio DePaoli"], "title": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Developing reliable data enrichment pipelines demands significant engineering\nexpertise. We present Prompt2DAG, a methodology that transforms natural\nlanguage descriptions into executable Apache Airflow DAGs. We evaluate four\ngeneration approaches -- Direct, LLM-only, Hybrid, and Template-based -- across\n260 experiments using thirteen LLMs and five case studies to identify optimal\nstrategies for production-grade automation. Performance is measured using a\npenalized scoring framework that combines reliability with code quality (SAT),\nstructural integrity (DST), and executability (PCT). The Hybrid approach\nemerges as the optimal generative method, achieving a 78.5% success rate with\nrobust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly\noutperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.\nOur findings show that reliability, not intrinsic code quality, is the primary\ndifferentiator. Cost-effectiveness analysis reveals the Hybrid method is over\ntwice as efficient as Direct prompting per successful DAG. We conclude that a\nstructured, hybrid approach is essential for balancing flexibility and\nreliability in automated workflow generation, offering a viable path to\ndemocratize data pipeline development.", "AI": {"tldr": "Prompt2DAG converts natural language descriptions into Apache Airflow DAGs. A Hybrid approach proved optimal, achieving high success rates and efficiency.", "motivation": "Streamlining data pipeline development through automation to minimize reliance on extensive engineering expertise.", "method": "Evaluation of four DAG generation strategies using 13 LLMs and a penalized scoring framework across 260 experiments and 5 case studies.", "result": "The Hybrid approach achieved 78.5% success rate, outperforming others in reliability, structural integrity, and cost-effectiveness.", "conclusion": "A structured Hybrid approach is critical for balancing automation's reliability and flexibility, paving the way for accessible pipeline development."}}
{"id": "2509.13349", "pdf": "https://arxiv.org/pdf/2509.13349", "abs": "https://arxiv.org/abs/2509.13349", "authors": ["Jed Guzelkabaagac", "Boris Petrovi\u0107"], "title": "Label-Efficient Grasp Joint Prediction with Point-JEPA", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "4 pages, 5 figures. Submitted to IROS 2025 Workshop", "summary": "We investigate whether 3D self-supervised pretraining with a Joint-Embedding\nPredictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle\nprediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained\nPoint-JEPA encoder, we train a lightweight multi-hypothesis head with\nwinner-takes-all and evaluate by top-logit selection. On DLR-Hand II with\nobject-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes\nand reaches parity with full supervision. These results suggest JEPA-style\npretraining is a practical approach for data-efficient grasp learning.", "AI": {"tldr": "The paper explores a data-efficient approach for predicting grasp joint-angles using 3D self-supervised pretraining on point clouds, achieving reduced error rates in low-label scenarios.", "motivation": "The authors aim to address the challenge of label inefficiency in training grasp joint-angle prediction models, particularly for robotics applications, by utilizing self-supervised pretraining.", "method": "They employ a Joint-Embedding Predictive Architecture (Point-JEPA) with pretrained encoders on ShapeNet to process tokenized point clouds and train a lightweight multi-hypothesis head using evaluation metrics like top-logit selection.", "result": "Point-JEPA demonstrates up to a 26% reduction in root-mean-square error (RMSE) in low-label regimes compared to fully supervised methods, and performs equivalently in high-label scenarios.", "conclusion": "JEPA-style pretraining is shown to be effective for data-efficient grasp learning, offering practical benefits for robotics tasks requiring joint-angle predictions."}}
{"id": "2509.13778", "pdf": "https://arxiv.org/pdf/2509.13778", "abs": "https://arxiv.org/abs/2509.13778", "authors": ["Sarah Zhao", "Emmanuel Cand\u00e8s"], "title": "Imputation-Powered Inference", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Modern multi-modal and multi-site data frequently suffer from blockwise\nmissingness, where subsets of features are missing for groups of individuals,\ncreating complex patterns that challenge standard inference methods. Existing\napproaches have critical limitations: complete-case analysis discards\ninformative data and is potentially biased; doubly robust estimators for\nnon-monotone missingness-where the missingness patterns are not nested subsets\nof one another-can be theoretically efficient but lack closed-form solutions\nand often fail to scale; and blackbox imputation can leverage partially\nobserved data to improve efficiency but provides no inferential guarantees when\nmisspecified. To address the limitations of these existing methods, we propose\nimputation-powered inference (IPI), a model-lean framework that combines the\nflexibility of blackbox imputation with bias correction using fully observed\ndata, drawing on ideas from prediction-powered inference and semiparametric\ninference. IPI enables valid and efficient M-estimation under missing\ncompletely at random (MCAR) blockwise missingness and improves subpopulation\ninference under a weaker assumption we formalize as first-moment MCAR, for\nwhich we also provide practical diagnostics. Simulation studies and a clinical\napplication demonstrate that IPI may substantially improve subpopulation\nefficiency relative to complete-case analysis, while maintaining statistical\nvalidity in settings where both doubly robust estimators and naive imputation\nfail to achieve nominal coverage.", "AI": {"tldr": "The paper introduces IPI, a novel framework to address blockwise missing data, improving efficiency and validity compared to existing methods.", "motivation": "Existing methods for handling blockwise missingness have limitations like bias, inefficiency, or lack of inferential guarantees.", "method": "IPI combines blackbox imputation with bias correction using fully observed data, leveraging prediction-powered and semiparametric inference techniques.", "result": "Simulation studies and a clinical application showed that IPI enhances subpopulation efficiency and maintains statistical validity better than alternative methods.", "conclusion": "IPI offers an efficient, valid solution to blockwise missing data challenges, outperforming both doubly robust estimators and naive imputation approaches."}}
{"id": "2509.13765", "pdf": "https://arxiv.org/pdf/2509.13765", "abs": "https://arxiv.org/abs/2509.13765", "authors": ["Zhirui Huang", "Rui Ma", "Shijie Cao", "Ran Shu", "Ian Wang", "Ting Cao", "Chixiao Chen", "Yongqiang Xiong"], "title": "TENET: An Efficient Sparsity-Aware LUT-Centric Architecture for Ternary LLM Inference On Edge", "categories": ["cs.AR"], "comment": null, "summary": "Ternary quantization has emerged as a powerful technique for reducing both\ncomputational and memory footprint of large language models (LLM), enabling\nefficient real-time inference deployment without significantly compromising\nmodel accuracy. Conventional LLM inference platforms (e.g GPUs) cannot\ncapitalize on its benefits, as they (i) lack native support for ternary\narithmetic and memory specialization and (ii) remain severely under-utilized in\nlow-batch, real-time scenarios. In this work, we propose TENET, a sparse-aware\nLUT-centric architecture that co-optimizes algorithm, compute, and memory for\nternary LLM inference. To maximize the efficiency of Ternary Linear layer,\nTENET introduces a Sparse Ternary LUT (STL) core that optimizes ternary\nmixed-precision GEMM using a symmetric precompute lookup table. It also\nfeatures Dynamic Activation N:M Sparsity to exploit the sparsity within the\nactivation of each token. Additionally, we propose a LUT-based 64B:80B ternary\nweight decompression module to fully exploit the memory efficiency of ternary\nvalues. At the system level, we design a heterogeneous TENET accelerator with\nfull programmability that integrates STL cores with high-precision cores. An\nassociated Linear-Projection-aware Sparse Attention dataflow is introduced to\noptimize memory access and hardware utilization. We implement TENET accelerator\nprototype on both FPGA and ASIC platforms. Experiments across various model\nsizes and workloads demonstrate that TENET-FPGA and TENET-ASIC improve energy\nefficiency by 4.3$\\times$ and 21.1$\\times$, respectively, compared to the A100\nGPU. Furthermore, TENET-ASIC achieves a 2.7$\\times$ average speedup compared to\nthe A100 GPU in end-to-end inference latency.", "AI": {"tldr": "TENET introduces a novel architecture for efficient ternary quantized inference in large language models, optimizing compute, memory, and algorithm performance.", "motivation": "Traditional GPU architectures struggle to fully utilize the benefits of ternary quantization for LLMs, particularly in low-batch, real-time inference tasks.", "method": "TENET employs a Sparse Ternary Lookup (STL) core for optimized GEMM operations, dynamic activation sparsity, LUT-based ternary weight decompression, and a hybrid accelerator design integrating high-precision and STL cores.", "result": "TENET FPGA achieves 4.3x and TENET ASIC achieves 21.1x improvement in energy efficiency over A100 GPU. TENET ASIC also shows a 2.7x speedup in end-to-end inference latency.", "conclusion": "TENET enables efficient real-time inference for LLMs by addressing algorithmic, memory, and hardware bottlenecks, outperforming conventional GPUs in energy efficiency and speed."}}
{"id": "2509.13703", "pdf": "https://arxiv.org/pdf/2509.13703", "abs": "https://arxiv.org/abs/2509.13703", "authors": ["Sriram Srinivasan", "Hamdan Alabsi", "Rand Obeidat", "Nithisha Ponnala", "Azene Zenebe"], "title": "GPU Programming for AI Workflow Development on AWS SageMaker: An Instructional Approach", "categories": ["cs.DC"], "comment": null, "summary": "We present the design, implementation, and comprehensive evaluation of a\nspecialized course on GPU architecture, GPU programming, and how these are used\nfor developing AI agents. This course is offered to undergraduate and graduate\nstudents during Fall 2024 and Spring 2025. The course began with foundational\nconcepts in GPU/CPU hardware and parallel computing and progressed to develop\nRAG and optimizing them using GPUs. Students gained experience provisioning and\nconfiguring cloud-based GPU instances, implementing parallel algorithms, and\ndeploying scalable AI solutions. We evaluated learning outcomes through\nassessments, course evaluations, and anonymous surveys. The results reveal that\n(1) AWS served as an effective and economical platform for practical GPU\nprogramming, (2) experiential learning significantly enhanced technical\nproficiency and engagement, and (3) the course strengthened students'\nproblem-solving and critical thinking skills through tools such as TensorBoard\nand HPC profilers, which exposed performance bottlenecks and scaling issues.\nOur findings underscore the pedagogical value of integrating parallel computing\ninto STEM education. We advocate for broader adoption of similar electives\nacross STEM curricula to prepare students for the demands of modern,\ncompute-intensive fields.", "AI": {"tldr": "This paper presents and evaluates a specialized course on GPU architecture and programming for AI development, showing its efficacy in improving student skills and engagement.", "motivation": "The motivation is to prepare students in STEM fields for modern, compute-intensive demands by teaching GPU programming, parallel computing, and AI application development.", "method": "The course covered foundational GPU/CPU hardware, parallel computing, and practical development and optimization of AI agents using cloud-based GPU platforms. Learning was evaluated via assessments, course evaluations, and surveys.", "result": "The course showed that AWS is cost-effective for GPU programming, experiential learning enhanced proficiency and engagement, and students improved problem-solving skills using tools like TensorBoard and HPC profilers.", "conclusion": "Integrating parallel computing and GPU programming into STEM education is highly beneficial, and the paper advocates for broader adoption of such courses in STEM curricula."}}
{"id": "2509.13339", "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "categories": ["cs.AI"], "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "The paper argues that AI research should focus on antifragility in safety, preparing systems to improve over time in handling rare or unforeseen events.", "motivation": "Current AI safety practices rely heavily on static benchmarks and single-shot tests, which fail to address evolving environments and risks like reward hacking or capability atrophy.", "method": "The authors propose an antifragile approach to AI safety, focusing on learning from uncertainties to prepare for future, unpredictable challenges. They address limitations of static testing and stress the need for dynamic, adaptive safety measures.", "result": "The paper identifies shortcomings of current AI safety methods and explores how antifragile principles can enhance the handling of rare and OOD events.", "conclusion": "AI safety frameworks should shift towards antifragility, emphasizing continuous improvement and long-term adaptability, complemented by ethical and practical guidelines to foster these approaches in the research community."}}
{"id": "2509.14092", "pdf": "https://arxiv.org/pdf/2509.14092", "abs": "https://arxiv.org/abs/2509.14092", "authors": ["Michele Boreale", "Luisa Collodi"], "title": "Parallelizable Feynman-Kac Models for Universal Probabilistic Programming", "categories": ["cs.PL"], "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "We study provably correct and efficient instantiations of Sequential Monte\nCarlo (SMC) inference in the context of formal operational semantics of\nProbabilistic Programs (PPs). We focus on universal PPs featuring sampling from\narbitrary measures and conditioning/reweighting in unbounded loops. We first\nequip Probabilistic Program Graphs (PPGs), an automata-theoretic description\nformat of PPs, with an expectation-based semantics over infinite execution\ntraces, which also incorporates trace weights. We then prove a finite\napproximation theorem that provides bounds to this semantics based on\nexpectations taken over finite, fixed-length traces. This enables us to frame\nour semantics within a Feynman-Kac (FK) model, and ensures the consistency of\nthe Particle Filtering (PF) algorithm, an instance of SMC, with respect to our\nsemantics. Building on these results, we introduce VPF, a vectorized version of\nthe PF algorithm tailored to PPGs and our semantics. Experiments conducted with\na proof-of-concept implementation of VPF show very promising results compared\nto state-of-the-art PP inference tools.", "AI": {"tldr": "The paper examines efficient and provably correct Sequential Monte Carlo inference for Probabilistic Programs, introducing new semantics and a vectorized Particle Filtering algorithm.", "motivation": "To improve the reliability and efficiency of probabilistic programming inference methods, especially for programs with complex structures like unbounded loops.", "method": "Developed expectation-based semantics for probabilistic programs, proved a finite approximation theorem, and introduced a vectorized Particle Filtering algorithm called VPF.", "result": "The vectorized Particle Filtering algorithm showed promising experimental outcomes compared to existing probabilistic programming inference tools.", "conclusion": "The results suggest the approach enhances the consistency and efficiency of probabilistic programming inference methods without compromising theoretical correctness."}}
{"id": "2509.13624", "pdf": "https://arxiv.org/pdf/2509.13624", "abs": "https://arxiv.org/abs/2509.13624", "authors": ["Shambhavi Krishna", "Atharva Naik", "Chaitali Agarwal", "Sudharshan Govindan", "Taesung Lee", "Haw-Shiuan Chang"], "title": "Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning", "categories": ["cs.CL", "cs.LG"], "comment": "Camera-ready version. Accepted to appear in the proceedings of the\n  14th Joint Conference on Lexical and Computational Semantics (*SEM 2025)", "summary": "Large language models are increasingly deployed across diverse applications.\nThis often includes tasks LLMs have not encountered during training. This\nimplies that enumerating and obtaining the high-quality training data for all\ntasks is infeasible. Thus, we often need to rely on transfer learning using\ndatasets with different characteristics, and anticipate out-of-distribution\nrequests. Motivated by this practical need, we propose an analysis framework,\nbuilding a transfer learning matrix and dimensionality reduction, to dissect\nthese cross-task interactions. We train and analyze 10 models to identify\nlatent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)\nand discover the side effects of the transfer learning. Our findings reveal\nthat performance improvements often defy explanations based on surface-level\ndataset similarity or source data quality. Instead, hidden statistical factors\nof the source dataset, such as class distribution and generation length\nproclivities, alongside specific linguistic features, are actually more\ninfluential. This work offers insights into the complex dynamics of transfer\nlearning, paving the way for more predictable and effective LLM adaptation.", "AI": {"tldr": "The paper investigates cross-task transfer learning in LLMs, uncovering latent abilities and analyzing side effects using a novel framework with transfer matrices and dimensionality reduction.", "motivation": "To analyze and improve understanding of cross-task interactions in LLMs, especially in the context of out-of-distribution tasks and the practical challenges of gathering training data for all tasks.", "method": "The authors deploy a novel analysis framework by constructing a transfer learning matrix and employing dimensionality reduction to study the relationships across tasks in LLMs. They train and evaluate 10 models to identify underlying abilities and analyze data properties' influence.", "result": "The study reveals that improvements in task performance aren't aligned with surface-level dataset similarities or obvious quality metrics. Instead, hidden statistical features, like class distribution and linguistic characteristics, play critical roles.", "conclusion": "The findings offer deeper insights into the mechanisms governing transfer learning in LLMs, providing a pathway for more predictable and effective adaptation strategies."}}
{"id": "2509.13523", "pdf": "https://arxiv.org/pdf/2509.13523", "abs": "https://arxiv.org/abs/2509.13523", "authors": ["V\u00e4in\u00f6 Hatanp\u00e4\u00e4", "Eugene Ku", "Jason Stock", "Murali Emani", "Sam Foreman", "Chunyong Jung", "Sandeep Madireddy", "Tung Nguyen", "Varuni Sastry", "Ray A. O. Sinurat", "Sam Wheeler", "Huihuo Zheng", "Troy Arcomano", "Venkatram Vishwanath", "Rao Kotamarthi"], "title": "AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions", "categories": ["cs.LG", "cs.DC"], "comment": "14 pages, 7 figures", "summary": "Generative machine learning offers new opportunities to better understand\ncomplex Earth system dynamics. Recent diffusion-based methods address spectral\nbiases and improve ensemble calibration in weather forecasting compared to\ndeterministic methods, yet have so far proven difficult to scale stably at high\nresolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin\ndiffusion transformer to address this gap, and SWiPe, a generalizable technique\nthat composes window parallelism with sequence and pipeline parallelism to\nshard window-based transformers without added communication cost or increased\nglobal batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS\n(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \\times 1$\npatch size on the 0.25{\\deg} ERA5 dataset, achieving 95.5% weak scaling\nefficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS\nand remains stable on seasonal scales to 90 days, highlighting the potential of\nbillion-parameter diffusion models for weather and climate prediction.", "AI": {"tldr": "This paper introduces AERIS, a billion-parameter diffusion model optimized with SWiPe technique, achieving high computational scaling efficiency and advancing weather forecasting capabilities.", "motivation": "Address the challenges of scaling diffusion-based methods stably at high resolutions for improving ensemble calibration in weather forecasting.", "method": "Developed AERIS, a Swin diffusion transformer with up to 80B parameters, and SWiPe, a parallelism technique for efficient computation without added communication costs.", "result": "AERIS achieved 10.21 ExaFLOPS sustained performance, 95.5% weak scaling efficiency, and strong scaling efficiency of 81.6% while outperforming traditional methods like IFS ENS.", "conclusion": "The paper demonstrates the promise of billion-parameter diffusion models in improving stability and accuracy for weather and climate prediction over extended periods."}}
{"id": "2509.13366", "pdf": "https://arxiv.org/pdf/2509.13366", "abs": "https://arxiv.org/abs/2509.13366", "authors": ["Tony Rohe", "Martin Margreiter", "Markus Moertl"], "title": "Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks", "categories": ["cs.CV", "68U99", "J.2"], "comment": "10 pages, 5 figures", "summary": "This research is part of a study of a real-time, cloud-based on-street\nparking service using crowd-sourced in-vehicle fleet data. The service provides\nreal-time information about available parking spots by classifying\ncrowd-sourced detections observed via ultrasonic sensors. The goal of this\nresearch is to optimize the current parking service quality by analyzing the\nautomation of the existing test process for ground truth tests. Therefore,\nmethods from the field of machine learning, especially image pattern\nrecognition, are applied to enrich the database and substitute human\nengineering work in major areas of the analysis process. After an introduction\ninto the related areas of machine learning, this paper explains the methods and\nimplementations made to achieve a high level of automation, applying\nconvolutional neural networks. Finally, predefined metrics present the\nperformance level achieved, showing a time reduction of human resources up to\n99.58 %. The overall improvements are discussed, summarized, and followed by an\noutlook for future development and potential application of the analysis\nautomation tool.", "AI": {"tldr": "The paper explores the automation of a cloud-based parking service using machine learning to enhance test process efficiency, achieving a 99.58% reduction in required human resources.", "motivation": "To optimize the quality and efficiency of a real-time cloud-based parking service by automating ground truth test processes.", "method": "Applying convolutional neural networks for image pattern recognition to replace human efforts in data analysis and enrich the database.", "result": "The automated system significantly reduced the need for human resources by up to 99.58%, showcasing effective performance improvements.", "conclusion": "The automated technique optimized the parking service quality, highlighted significant resource savings, and provided an outlook for future development and applications of the system."}}
{"id": "2509.13875", "pdf": "https://arxiv.org/pdf/2509.13875", "abs": "https://arxiv.org/abs/2509.13875", "authors": ["N. B. Maimon", "Ganit Baruchin", "Itamar Grotto", "Nathan Intrator", "Talya Zeimer", "Ofir Chibotero", "Efrat Danino"], "title": "Personalized Detection of Stress via hdrEEG: Linking Neuro-markers to Cortisol, HRV, and Self-Report", "categories": ["q-bio.NC"], "comment": null, "summary": "Chronic stress is a major risk factor for cognitive decline,\nneurodegenerative disease, and systemic health burden, underscoring the need\nfor reliable individual-level biomarkers of stress reactivity. While cortisol,\nheart rate variability (HRV), and self-report measures are widely used, they\nprovide limited insight into neural mechanisms. Here, we tested whether two\nsingle-channel hdrEEG biomarkers, ST4 and T2, serve as personalized indices of\nstress regulation by linking neural activity to validated physiological and\nsubjective measures. We conducted two studies. Study 1 included 101 healthy\nadults (22-82 years) who completed questionnaires on resilience, burnout, and\nperceived stress, provided salivary cortisol, and underwent hdrEEG during\nresting, detection, n-back, lexical, emotional music, and startle tasks. Study\n2 included 82 adults (19-42 years) who completed the State-Trait Anxiety\nInventory, were monitored for HRV, and performed auditory, stress-inducing (job\ninterview, arithmetic), and emotional tasks during hdrEEG recording. Across\nstudies, ST4 reflected physiological arousal and cognitive strain, correlating\npositively with cortisol, subjective stress, and pulse pressure, and negatively\nwith resilience and HRV indices. T2 showed a complementary profile, linking\nemotional and autonomic processes. T2 activity correlated with cortisol, heart\nrate, HRV measures, resilience, and trait anxiety, especially during lexical\nand emotional tasks. Together, ST4 and T2 capture distinct facets of the stress\nresponse: physiological arousal versus emotional-regulatory sensitivity. These\nfindings highlight portable hdrEEG as a promising tool for personalized stress\nassessment, bridging neural, physiological, and subjective domains with\nimplications for clinical and occupational monitoring.", "AI": {"tldr": "The paper identifies two single-channel hdrEEG biomarkers, ST4 and T2, as indicators of stress regulation and explores their correlation with physiological and subjective stress measures.", "motivation": "Stress is a critical factor in cognitive decline and other health issues. Existing biomarkers like cortisol and HRV offer limited understanding of neural mechanisms behind stress, necessitating more accurate and personalized tools.", "method": "The study uses hdrEEG and physiological/subjective measurements across two groups (N=101 and N=82) in various cognitive, emotional, and stress-inducing tasks to examine the validity of ST4 and T2 as biomarkers.", "result": "ST4 correlates with physiological arousal indicators like cortisol and subjective stress, while T2 connects with emotional-regulatory processes and resilience. Both biomarkers collectively provide insights into different dimensions of stress responses.", "conclusion": "ST4 and T2 biomarkers could serve as effective tools for individualized stress monitoring, offering a novel way to integrate neural, physiological, and psychological insights into stress assessment."}}
{"id": "2509.13535", "pdf": "https://arxiv.org/pdf/2509.13535", "abs": "https://arxiv.org/abs/2509.13535", "authors": ["S M Farah Al Fahim", "Md Nakhla Rafi", "Zeyang Ma", "Dong Jae Kim", "Tse-Hsun", "Chen"], "title": "Crash Report Enhancement with Large Language Models: An Empirical Study", "categories": ["cs.SE"], "comment": null, "summary": "Crash reports are central to software maintenance, yet many lack the\ndiagnostic detail developers need to debug efficiently. We examine whether\nlarge language models can enhance crash reports by adding fault locations,\nroot-cause explanations, and repair suggestions. We study two enhancement\nstrategies: Direct-LLM, a single-shot approach that uses stack-trace context,\nand Agentic-LLM, an iterative approach that explores the repository for\nadditional evidence. On a dataset of 492 real-world crash reports, LLM-enhanced\nreports improve Top-1 problem-localization accuracy from 10.6% (original\nreports) to 40.2-43.1%, and produce suggested fixes that closely resemble\ndeveloper patches (CodeBLEU around 56-57%). Both our manual evaluations and\nLLM-as-a-judge assessment show that Agentic-LLM delivers stronger root-cause\nexplanations and more actionable repair guidance. A user study with 16\nparticipants further confirms that enhanced reports make crashes easier to\nunderstand and resolve, with the largest improvement in repair guidance. These\nresults indicate that supplying LLMs with stack traces and repository code\nyields enhanced crash reports that are substantially more useful for debugging.", "AI": {"tldr": "The paper investigates enhancing crash reports with fault locations, root-cause explanations, and repair suggestions using LLMs, improving debugging effectiveness significantly.", "motivation": "Crash reports often lack sufficient diagnostic detail for efficient debugging, creating a need for more actionable insights.", "method": "The study uses two strategies: Direct-LLM, which directly uses stack-trace context, and Agentic-LLM, which iteratively explores repository code for additional evidence.", "result": "Enhancements improve problem-localization accuracy from 10.6% to around 40.2-43.1%, and suggested fixes achieve a CodeBLEU score of ~56-57%. Agentic-LLM also provides superior root-cause explanations and repair guidance compared to Direct-LLM.", "conclusion": "Enhanced crash reports produced by LLMs, with integrated stack traces and repository exploration, substantially aid in understanding and resolving software crashes, especially in repair guidance."}}
{"id": "2509.13378", "pdf": "https://arxiv.org/pdf/2509.13378", "abs": "https://arxiv.org/abs/2509.13378", "authors": ["Mattias Wingren", "S\u00f6ren Andersson", "Sara Rosenberg", "Malin Andtfolk", "Susanne H\u00e4gglund", "Prashani Jayasingha Arachchige", "Linda Nyholm"], "title": "Using role-play and Hierarchical Task Analysis for designing human-robot interaction", "categories": ["cs.RO"], "comment": "11 pages. This is a preprint version of the published paper in the\n  International Conference on Social Robotics:\n  https://link.springer.com/chapter/10.1007/978-981-96-3522-1_28", "summary": "We present the use of two methods we believe warrant more use than they\ncurrently have in the field of human-robot interaction: role-play and\nHierarchical Task Analysis. Some of its potential is showcased through our use\nof them in an ongoing research project which entails developing a robot\napplication meant to assist at a community pharmacy. The two methods have\nprovided us with several advantages. The role-playing provided a controlled and\nadjustable environment for understanding the customers' needs where pharmacists\ncould act as models for the robot's behavior; and the Hierarchical Task\nAnalysis ensured the behavior displayed was modelled correctly and aided\ndevelopment through facilitating co-design. Future research could focus on\ndeveloping task analysis methods especially suited for social robot\ninteraction.", "AI": {"tldr": "This paper explores the use of role-play and Hierarchical Task Analysis in human-robot interaction, applied to a robot assisting in a community pharmacy.", "motivation": "The current methods used in human-robot interaction lack the tools to adequately model social interactions and customer needs.", "method": "Role-play was utilized to simulate pharmacy scenarios with pharmacists modeling robots, while Hierarchical Task Analysis structured and validated the robot behavior designs.", "result": "These methods provided advantages, such as understanding customer needs, modeling correct robot behaviors, and facilitating co-design in development.", "conclusion": "Role-play and Hierarchical Task Analysis offer substantial benefits in designing social robot behaviors, and future research should aim to adapt task analysis methods specifically for social contexts."}}
{"id": "2509.13805", "pdf": "https://arxiv.org/pdf/2509.13805", "abs": "https://arxiv.org/abs/2509.13805", "authors": ["Florian Wiesner", "Matthias Wessling", "Stephen Baek"], "title": "Towards a Physics Foundation Model", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Foundation models have revolutionized natural language processing through a\n``train once, deploy anywhere'' paradigm, where a single pre-trained model\nadapts to countless downstream tasks without retraining. Access to a Physics\nFoundation Model (PFM) would be transformative -- democratizing access to\nhigh-fidelity simulations, accelerating scientific discovery, and eliminating\nthe need for specialized solver development. Yet current physics-aware machine\nlearning approaches remain fundamentally limited to single, narrow domains and\nrequire retraining for each new system. We present the General Physics\nTransformer (GPhyT), trained on 1.8 TB of diverse simulation data, that\ndemonstrates foundation model capabilities are achievable for physics. Our key\ninsight is that transformers can learn to infer governing dynamics from\ncontext, enabling a single model to simulate fluid-solid interactions, shock\nwaves, thermal convection, and multi-phase dynamics without being told the\nunderlying equations. GPhyT achieves three critical breakthroughs: (1) superior\nperformance across multiple physics domains, outperforming specialized\narchitectures by up to 29x, (2) zero-shot generalization to entirely unseen\nphysical systems through in-context learning, and (3) stable long-term\npredictions through 50-timestep rollouts. By establishing that a single model\ncan learn generalizable physical principles from data alone, this work opens\nthe path toward a universal PFM that could transform computational science and\nengineering.", "AI": {"tldr": "The paper introduces the General Physics Transformer (GPhyT), a single model capable of simulating diverse physical dynamics, showcasing foundation model capabilities in physics.", "motivation": "Physics modeling is limited by tools that require domain-specific designs and retraining for each new system, creating inefficiencies in scientific discovery. A universal Physics Foundation Model could democratize simulations and accelerate progress.", "method": "The authors use transformer architecture trained on 1.8 TB of varied simulation data to infer governing physics dynamics through context, enabling multi-domain applications without predefined equations.", "result": "GPhyT outperforms specialized architectures by up to 29x, demonstrates zero-shot generalization across unseen physical systems using context, and provides stable predictions for long-term rollouts up to 50 timesteps.", "conclusion": "This research proves that a single model can capture generalizable physical principles exclusively from data, paving the way toward a universal Physics Foundation Model that revolutionizes computational science and engineering."}}
{"id": "2509.13997", "pdf": "https://arxiv.org/pdf/2509.13997", "abs": "https://arxiv.org/abs/2509.13997", "authors": ["Yu Zhu", "Aditya Dhakal", "Pedro Bruel", "Gourav Rattihalli", "Yunming Xiao", "Johann Lombardi", "Dejan Milojicic"], "title": "An RDMA-First Object Storage System with SmartNIC Offload", "categories": ["cs.AR"], "comment": null, "summary": "AI training and inference impose sustained, fine-grain I/O that stresses\nhost-mediated, TCP-based storage paths. Motivated by kernel-bypass networking\nand user-space storage stacks, we revisit POSIX-compatible object storage for\nGPU-centric pipelines. We present ROS2, an RDMA-first object storage system\ndesign that offloads the DAOS client to an NVIDIA BlueField-3 SmartNIC while\nleaving the DAOS I/O engine unchanged on the storage server. ROS2 separates a\nlightweight control plane (gRPC for namespace and capability exchange) from a\nhigh-throughput data plane (UCX/libfabric over RDMA or TCP) and removes host\nmediation from the data path.\n  Using FIO/DFS across local and remote configurations, we find that on\nserver-grade CPUs RDMA consistently outperforms TCP for both large sequential\nand small random I/O. When the RDMA-driven DAOS client is offloaded to\nBlueField-3, end-to-end performance is comparable to the host, demonstrating\nthat SmartNIC offload preserves RDMA efficiency while enabling DPU-resident\nfeatures such as multi-tenant isolation and inline services (e.g.,\nencryption/decryption) close to the NIC. In contrast, TCP on the SmartNIC lags\nhost performance, underscoring the importance of RDMA for offloaded\ndeployments.\n  Overall, our results indicate that an RDMA-first, SmartNIC-offloaded\nobject-storage stack is a practical foundation for scaling data delivery in\nmodern LLM training environments; integrating optional GPU-direct placement for\nLLM tasks is left for future work.", "AI": {"tldr": "This paper introduces ROS2, an RDMA-first object storage system designed to offload the DAOS client to NVIDIA BlueField-3 SmartNIC, resulting in efficient performance for AI training workloads.", "motivation": "The paper aims to address inefficiencies in I/O operations imposed by AI training workloads, particularly the issues arising from host-mediated, TCP-based storage paths.", "method": "ROS2 employs RDMA to optimize data paths by offloading the DAOS client to a SmartNIC. It uses a lightweight control plane with gRPC and a high-throughput data plane utilizing UCX/libfabric over RDMA or TCP, bypassing host mediation.", "result": "Testing on FIO/DFS showed that RDMA outperforms TCP in both sequential and random I/O. When offloaded to the SmartNIC, end-to-end RDMA performance remained efficient, enabling features like multi-tenant isolation. TCP performance on SmartNICs was inferior to host-based deployments.", "conclusion": "Offloading the object-storage stack to an RDMA-driven SmartNIC enables scalable and efficient data delivery for LLM training, with the potential for future integration of GPU-direct placement."}}
{"id": "2509.13793", "pdf": "https://arxiv.org/pdf/2509.13793", "abs": "https://arxiv.org/abs/2509.13793", "authors": ["Thomas Chaffey"], "title": "Circuit realization and hardware linearization of monotone operator equilibrium networks", "categories": ["eess.SY", "cs.LG", "cs.NE", "cs.SY", "math.OC", "65K10, 68T05, 93B30, 93D99"], "comment": null, "summary": "It is shown that the port behavior of a resistor-diode network corresponds to\nthe solution of a ReLU monotone operator equilibrium network (a neural network\nin the limit of infinite depth), giving a parsimonious construction of a neural\nnetwork in analog hardware. We furthermore show that the gradient of such a\ncircuit can be computed directly in hardware, using a procedure we call\nhardware linearization. This allows the network to be trained in hardware,\nwhich we demonstrate with a device-level circuit simulation. We extend the\nresults to cascades of resistor-diode networks, which can be used to implement\nfeedforward and other asymmetric networks. We finally show that different\nnonlinear elements give rise to different activation functions, and introduce\nthe novel diode ReLU which is induced by a non-ideal diode model.", "AI": {"tldr": "The paper connects resistor-diode networks to deep ReLU neural networks, enabling analog hardware implementations and hardware-based training.", "motivation": "To bridge resistor-diode circuits and neural network models, enabling their functionality directly in analog hardware and exploring training methods in hardware.", "method": "It analyzes resistor-diode networks and connects them to infinite-depth ReLU networks. It proposes hardware linearization for gradient computation and training, simulates circuits, and explores non-linear elements for varied activation functions.", "result": "Resistor-diode networks correspond to ReLU neural networks. Hardware training using gradient computation is feasible. Cascade circuits can implement advanced network structures. Non-ideal diodes induce novel activation functions like diode ReLU.", "conclusion": "Resistor-diode networks provide a pathway to analog ReLU neural network implementations, hardware training methods, and novel activation function designs, with potential for advanced network structures."}}
{"id": "2509.13978", "pdf": "https://arxiv.org/pdf/2509.13978", "abs": "https://arxiv.org/abs/2509.13978", "authors": ["Renan Souza", "Timothy Poteet", "Brian Etz", "Daniel Rosendo", "Amal Gueroudji", "Woong Shin", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology", "categories": ["cs.DC", "cs.AI", "cs.DB", "68M14, 68M20, 68T07", "C.2.4; D.1.3; I.2.0"], "comment": "Paper accepted in the proceedings of the ACM/IEEE Supercomputing\n  Conference (SC). Cite it as Renan Souza, Timothy Poteet, Brian Etz, Daniel\n  Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, and Rafael\n  Ferreira da Silva. 2025. LLM Agents for Interactive Workflow Provenance:\n  Reference Architecture and Evaluation Methodology. In SC Workshops (WORKS)", "summary": "Modern scientific discovery increasingly relies on workflows that process\ndata across the Edge, Cloud, and High Performance Computing (HPC) continuum.\nComprehensive and in-depth analyses of these data are critical for hypothesis\nvalidation, anomaly detection, reproducibility, and impactful findings.\nAlthough workflow provenance techniques support such analyses, at large scale,\nthe provenance data become complex and difficult to analyze. Existing systems\ndepend on custom scripts, structured queries, or static dashboards, limiting\ndata interaction. In this work, we introduce an evaluation methodology,\nreference architecture, and open-source implementation that leverages\ninteractive Large Language Model (LLM) agents for runtime data analysis. Our\napproach uses a lightweight, metadata-driven design that translates natural\nlanguage into structured provenance queries. Evaluations across LLaMA, GPT,\nGemini, and Claude, covering diverse query classes and a real-world chemistry\nworkflow, show that modular design, prompt tuning, and Retrieval-Augmented\nGeneration (RAG) enable accurate and insightful LLM agent responses beyond\nrecorded provenance.", "AI": {"tldr": "This paper introduces an evaluation methodology and architecture to enhance provenance data analysis with interactive LLM agents, enabling accurate natural language querying for scientific workflows.", "motivation": "The reliance on workflows across Edge, Cloud, and HPC in scientific discovery necessitates advanced data analysis methods for tasks like anomaly detection and reproducibility. Current approaches to provenance data analysis are restrictive and limit user interaction.", "method": "The authors propose a metadata-driven design that transforms natural language queries into structured provenance data queries while utilizing interactive LLM agents. Modular design, prompt tuning, and RAG support accurate runtime analysis.", "result": "The system demonstrated effective integration of LLMs like LLaMA, GPT, and others to answer diverse query types and analyze provenance data. It performed well even beyond recorded provenance using real-world benchmarks.", "conclusion": "Interactive LLM agents, paired with a metadata-driven architecture, can significantly enhance runtime analysis of provenance data at scale, promoting deeper insights and interaction for scientific workflows."}}
{"id": "2509.13341", "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "The paper introduces IMAC (Imagined Autocurricula), a method that uses world models and Unsupervised Environment Design (UED) to create imagined environments for training robust agents that can generalize across various task variations.", "motivation": "The motivation is to address the limitations of training agents in embodied environments, which often require vast amounts of data or accurate simulations, by leveraging offline and passively collected data through world models.", "method": "The proposed method uses IMAC to generate imagined environments and employs UED to create an automatic curriculum over these generated worlds, ensuring that agents train on meaningful data.", "result": "The approach demonstrated strong transfer performance in held-out environments, even when training was conducted within a world model learned from a narrower dataset.", "conclusion": "This work paves the way for using larger-scale world models as a foundation for developing generally capable agents in simulation."}}
{"id": "2509.13664", "pdf": "https://arxiv.org/pdf/2509.13664", "abs": "https://arxiv.org/abs/2509.13664", "authors": ["Zhuoxuan Zhang", "Jinhao Duan", "Edward Kim", "Kaidi Xu"], "title": "Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "To be appeared in EMNLP 2025 (main)", "summary": "Ambiguity is pervasive in real-world questions, yet large language models\n(LLMs) often respond with confident answers rather than seeking clarification.\nIn this work, we show that question ambiguity is linearly encoded in the\ninternal representations of LLMs and can be both detected and controlled at the\nneuron level. During the model's pre-filling stage, we identify that a small\nnumber of neurons, as few as one, encode question ambiguity information. Probes\ntrained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance\non ambiguity detection and generalize across datasets, outperforming\nprompting-based and representation-based baselines. Layerwise analysis reveals\nthat AENs emerge from shallow layers, suggesting early encoding of ambiguity\nsignals in the model's processing pipeline. Finally, we show that through\nmanipulating AENs, we can control LLM's behavior from direct answering to\nabstention. Our findings reveal that LLMs form compact internal representations\nof question ambiguity, enabling interpretable and controllable behavior.", "AI": {"tldr": "The paper explores how question ambiguity is represented internally in large language models (LLMs), showing that it is encoded in certain neurons, and proposes methods for detecting and controlling this property.", "motivation": "To understand and address the issue of large language models responding confidently to ambiguous questions without clarification.", "method": "The authors identified neurons in LLMs that encode question ambiguity, leveraging these Ambiguity-Encoding Neurons (AENs) to detect ambiguity and control the model\u2019s response behavior. They used probes for detection and analyzed layerwise emergence of these signals.", "result": "The study found that ambiguity signals are encoded in specific neurons, even in shallow layers. Using AENs improved ambiguity detection performance compared to other baselines. Additionally, manipulating these neurons allowed control over the model\u2019s response strategy.", "conclusion": "LLMs have compact, neuron-level internal representations of ambiguity, making it possible to interpret and adjust their behavior, such as abstaining from confident answers to ambiguous questions."}}
{"id": "2509.13527", "pdf": "https://arxiv.org/pdf/2509.13527", "abs": "https://arxiv.org/abs/2509.13527", "authors": ["Yulia Pimonova", "Michael G. Taylor", "Alice Allen", "Ping Yang", "Nicholas Lubbers"], "title": "Meta-Learning Linear Models for Molecular Property Prediction", "categories": ["cs.LG", "physics.chem-ph"], "comment": "26 pages, 16 figures", "summary": "Chemists in search of structure-property relationships face great challenges\ndue to limited high quality, concordant datasets. Machine learning (ML) has\nsignificantly advanced predictive capabilities in chemical sciences, but these\nmodern data-driven approaches have increased the demand for data. In response\nto the growing demand for explainable AI (XAI) and to bridge the gap between\npredictive accuracy and human comprehensibility, we introduce LAMeL - a Linear\nAlgorithm for Meta-Learning that preserves interpretability while improving the\nprediction accuracy across multiple properties. While most approaches treat\neach chemical prediction task in isolation, LAMeL leverages a meta-learning\nframework to identify shared model parameters across related tasks, even if\nthose tasks do not share data, allowing it to learn a common functional\nmanifold that serves as a more informed starting point for new unseen tasks.\nOur method delivers performance improvements ranging from 1.1- to 25-fold over\nstandard ridge regression, depending on the domain of the dataset. While the\ndegree of performance enhancement varies across tasks, LAMeL consistently\noutperforms or matches traditional linear methods, making it a reliable tool\nfor chemical property prediction where both accuracy and interpretability are\ncritical.", "AI": {"tldr": "The paper introduces LAMeL, a meta-learning algorithm that enhances predictability and interpretability for chemical property predictions, addressing challenges in limited datasets and explainable AI.", "motivation": "To address the challenges in the chemical sciences due to limited high-quality datasets and the growing need for explainable AI methods in prediction tasks.", "method": "Proposes LAMeL, a Linear Algorithm for Meta-Learning that identifies shared model parameters across tasks to learn a functional manifold, enhancing prediction accuracy and interpretability.", "result": "LAMeL shows performance improvements up to 25-fold over ridge regression, consistently outperforming traditional linear methods across diverse datasets.", "conclusion": "LAMeL is a robust and interpretative meta-learning framework for predictive tasks in chemical sciences, effectively balancing accuracy and human comprehension across multiple domains."}}
{"id": "2509.13375", "pdf": "https://arxiv.org/pdf/2509.13375", "abs": "https://arxiv.org/abs/2509.13375", "authors": ["Yuxiao Lee", "Xiaofeng Cao", "Wei Ye", "Jiangchao Yao", "Jingkuan Song", "Heng Tao Shen"], "title": "An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable\nzero-shot out-of-distribution (OOD) detection capabilities, vital for reliable\nAI systems. Despite this promising capability, a comprehensive understanding of\n(1) why they work so effectively, (2) what advantages do they have over\nsingle-modal methods, and (3) how is their behavioral robustness -- remains\nnotably incomplete within the research community. This paper presents a\nsystematic empirical analysis of VLM-based OOD detection using in-distribution\n(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and\nformalize key operational properties within the VLM embedding space that\nfacilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the\nsuperiority of these models over established single-modal approaches,\nattributing this distinct advantage to the VLM's capacity to leverage rich\nsemantic novelty. (3) Sensitivity: We uncovers a significant and previously\nunder-explored asymmetry in their robustness profile: while exhibiting\nresilience to common image noise, these VLM-based methods are highly sensitive\nto prompt phrasing. Our findings contribute a more structured understanding of\nthe strengths and critical vulnerabilities inherent in VLM-based OOD detection,\noffering crucial, empirically-grounded guidance for developing more robust and\nreliable future designs.", "AI": {"tldr": "This paper studies Vision-Language Models (VLMs) for out-of-distribution (OOD) detection, analyzing why they are effective, their advantages over single-modal methods, and their behavioral robustness.", "motivation": "To investigate the mechanisms, advantages, and robustness of Vision-Language Models in zero-shot OOD detection to advance AI reliability.", "method": "A systematic empirical analysis using in-distribution (ID) and OOD prompts to examine VLM embedding space properties, quantify advantages over single-modal approaches, and analyze sensitivity to prompt phrasing.", "result": "VLMs excel in leveraging rich semantic novelty for OOD detection but are sensitive to prompt phrasing despite their resilience to common image noise.", "conclusion": "The study offers a structured understanding of VLMs\u2019 strengths in OOD detection and points out critical robustness vulnerabilities, guiding future model design improvements."}}
{"id": "2509.13867", "pdf": "https://arxiv.org/pdf/2509.13867", "abs": "https://arxiv.org/abs/2509.13867", "authors": ["Giacomo Barzon", "Daniel M. Busiello", "Giorgio Nicoletti"], "title": "Plasticity-induced multistability on fast and slow timescales enables optimal information encoding and spontaneous sequence discrimination", "categories": ["cond-mat.stat-mech", "q-bio.NC"], "comment": null, "summary": "Neural circuits exhibit remarkable computational flexibility, enabling\nadaptive responses to noisy and ever-changing environmental cues. A fundamental\nquestion in neuroscience concerns how a wide range of behaviors can emerge from\na relatively limited set of underlying biological mechanisms. In particular,\nthe interaction between activities of neuronal populations and plasticity\nmodulation of synaptic connections may endow neural circuits with a variety of\nfunctional responses when coordinated over different characteristic timescales.\nHere, we develop an information-theoretic framework to quantitatively explore\nthis idea. We consider a stochastic model for neural activities that\nincorporates the presence of a coupled dynamic plasticity and time-varying\nstimuli. We show that long-term plasticity modulations play the functional role\nof steering neural activities towards a regime of optimal information encoding.\nBy constructing the associated phase diagram, we demonstrate that either\nHebbian or anti-Hebbian plasticity may become optimal strategies depending on\nhow the external input is projected to the target neural populations.\nConversely, short-term plasticity enables the discrimination of temporal\nordering in sequences of inputs by navigating the emergent multistable\nattractor landscape. By allowing a degree of variability in external stimuli,\nwe also highlight the existence of an optimal variability for sequence\ndiscrimination at a given plasticity strength. In summary, the timescale of\nplasticity modulation shapes how inputs are represented in neural activities,\nthereby fundamentally altering the computational properties of the system. Our\napproach offers a unifying information-theoretic perspective of the role of\nplasticity, paving the way for a quantitative understanding of the emergence of\ncomplex computations in coupled neuronal-synaptic dynamics.", "AI": {"tldr": "Neural circuits achieve computational flexibility by leveraging timescale-dependent plasticity modulation for optimized information encoding and sequence discrimination.", "motivation": "To understand how diverse behaviors emerge from limited biological mechanisms in neural circuits.", "method": "Developed an information-theoretic framework with a stochastic model incorporating dynamic plasticity and time-varying stimuli.", "result": "Long-term plasticity optimizes information encoding, while short-term plasticity aids sequence discrimination; optimal variability exists for sequence discrimination.", "conclusion": "Plasticity modulation timescales fundamentally shape neural activity representations and computational properties, offering insights into complex neural computations."}}
{"id": "2509.13650", "pdf": "https://arxiv.org/pdf/2509.13650", "abs": "https://arxiv.org/abs/2509.13650", "authors": ["Amena Amro", "Manar H. Alalfi"], "title": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "As software development practices increasingly adopt AI-powered tools,\nensuring that such tools can support secure coding has become critical. This\nstudy evaluates the effectiveness of GitHub Copilot's recently introduced code\nreview feature in detecting security vulnerabilities. Using a curated set of\nlabeled vulnerable code samples drawn from diverse open-source projects\nspanning multiple programming languages and application domains, we\nsystematically assessed Copilot's ability to identify and provide feedback on\ncommon security flaws. Contrary to expectations, our results reveal that\nCopilot's code review frequently fails to detect critical vulnerabilities such\nas SQL injection, cross-site scripting (XSS), and insecure deserialization.\nInstead, its feedback primarily addresses low-severity issues, such as coding\nstyle and typographical errors. These findings expose a significant gap between\nthe perceived capabilities of AI-assisted code review and its actual\neffectiveness in supporting secure development practices. Our results highlight\nthe continued necessity of dedicated security tools and manual code audits to\nensure robust software security.", "AI": {"tldr": "The paper evaluates GitHub Copilot's new code review feature and finds it ineffective at spotting critical security vulnerabilities, emphasizing the need for dedicated security tools and manual oversight.", "motivation": "Ensure AI-powered tools can effectively support secure software development practices.", "method": "Analyzed GitHub Copilot's ability to detect security flaws by using labeled vulnerable code samples from diverse programming languages and application domains.", "result": "Copilot predominantly fails to detect critical vulnerabilities like SQL injection and XSS, instead focusing on minor issues like coding style.", "conclusion": "AI-assisted code review tools like Copilot cannot replace human oversight or dedicated security tools for achieving robust software security."}}
{"id": "2509.13380", "pdf": "https://arxiv.org/pdf/2509.13380", "abs": "https://arxiv.org/abs/2509.13380", "authors": ["Alejandro D. Mousist"], "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": "This preprint presents ASTREA, a multi-agent architecture combining\n  LLM-guided semantic modulation with reinforcement learning for autonomous\n  satellite operations. The system is validated in hardware orbital\n  environments", "summary": "This paper presents ASTREA, the first agentic system deployed on\nflight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using\nthermal control as a representative use case, we integrate a\nresource-constrained Large Language Model (LLM) agent with a reinforcement\nlearning controller in an asynchronous architecture tailored for\nspace-qualified platforms. Ground experiments show that LLM-guided supervision\nimproves thermal stability and reduces violations, confirming the feasibility\nof combining semantic reasoning with adaptive control under hardware\nconstraints. However, on-orbit validation aboard the International Space\nStation (ISS) reveals performance degradation caused by inference latency\nmismatched with the rapid thermal cycles characteristic of Low Earth Orbit\n(LEO) satellites. These results highlight both the opportunities and current\nlimitations of agentic LLM-based systems in real flight environments, providing\npractical design guidelines for future space autonomy.", "AI": {"tldr": "ASTREA integrates a resource-constrained LLM agent and reinforcement learning controller for autonomous spacecraft operations, showing potential benefits and limitations in thermal control applications.", "motivation": "To explore the integration of Large Language Model (LLM) agents with adaptive controllers for autonomous spacecraft operations, addressing the challenges of resource constraints and real-time decision-making.", "method": "The paper introduces an asynchronous architecture combining a resource-constrained LLM agent with a reinforcement learning controller, tested through ground experiments and validated aboard the International Space Station (ISS).", "result": "Ground experiments demonstrated improved thermal stability and reduced violations under LLM-guided supervision; however, on-orbit validation showed degradation due to inference latency mismatched with LEO satellite thermal cycles.", "conclusion": "Agentic LLM-based systems show promise for autonomous spacecraft operations but require design modifications to address inference latency and environmental challenges in real flight settings."}}
{"id": "2509.13923", "pdf": "https://arxiv.org/pdf/2509.13923", "abs": "https://arxiv.org/abs/2509.13923", "authors": ["Lamia Lamrani", "Beno\u00eet Collins", "Jean-Philippe Bouchaud"], "title": "Holdout cross-validation for large non-Gaussian covariance matrix estimation using Weingarten calculus", "categories": ["q-fin.ST", "math.ST", "q-fin.RM", "stat.ML", "stat.TH"], "comment": null, "summary": "Cross-validation is one of the most widely used methods for model selection\nand evaluation; its efficiency for large covariance matrix estimation appears\nrobust in practice, but little is known about the theoretical behavior of its\nerror. In this paper, we derive the expected Frobenius error of the holdout\nmethod, a particular cross-validation procedure that involves a single train\nand test split, for a generic rotationally invariant multiplicative noise\nmodel, therefore extending previous results to non-Gaussian data distributions.\nOur approach involves using the Weingarten calculus and the Ledoit-P\\'ech\\'e\nformula to derive the oracle eigenvalues in the high-dimensional limit. When\nthe population covariance matrix follows an inverse Wishart distribution, we\napproximate the expected holdout error, first with a linear shrinkage, then\nwith a quadratic shrinkage to approximate the oracle eigenvalues. Under the\nlinear approximation, we find that the optimal train-test split ratio is\nproportional to the square root of the matrix dimension. Then we compute Monte\nCarlo simulations of the holdout error for different distributions of the norm\nof the noise, such as the Gaussian, Student, and Laplace distributions and\nobserve that the quadratic approximation yields a substantial improvement,\nespecially around the optimal train-test split ratio. We also observe that a\nhigher fourth-order moment of the Euclidean norm of the noise vector sharpens\nthe holdout error curve near the optimal split and lowers the ideal train-test\nratio, making the choice of the train-test ratio more important when performing\nthe holdout method.", "AI": {"tldr": "This paper investigates the theoretical and practical behavior of cross-validation errors in large covariance matrix estimation using the holdout method, assessing different approximations for splitting data.", "motivation": "The motivation lies in understanding the theoretical behavior of cross-validation approaches, specifically the holdout method, in the context of covariance matrix estimation for non-Gaussian data distributions.", "method": "The authors use Weingarten calculus and the Ledoit-P\u00e9ch\u00e9 formula for deriving eigenvalues in high-dimensional limits, further approximating holdout errors under linear and quadratic shrinkage techniques. They also conduct Monte Carlo simulations.", "result": "They find an optimal train-test split ratio proportional to the square root of matrix dimensions and demonstrate that quadratic shrinkage significantly improves holdout error near the optimal split ratio, especially for higher fourth-order noise moments.", "conclusion": "The findings emphasize the practical and theoretical importance of selecting an appropriate train-test split ratio and the improvements offered by quadratic approximations for covariance matrix estimation errors."}}
{"id": "2509.13827", "pdf": "https://arxiv.org/pdf/2509.13827", "abs": "https://arxiv.org/abs/2509.13827", "authors": ["Renyuan Liu", "Haoting Zhou", "Chuankai Fang", "Qinbing Fu"], "title": "How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots", "categories": ["cs.RO", "cs.NE"], "comment": "9 pages, 6 figures", "summary": "Anyone who has tried to swat a fly has likely been frustrated by its\nremarkable agility.This ability stems from its visual neural perception system,\nparticularly the collision-selective neurons within its small brain.For\nautonomous robots operating in complex and unfamiliar environments, achieving\nsimilar agility is highly desirable but often constrained by the trade-off\nbetween computational cost and performance.In this context, insect-inspired\nintelligence offers a parsimonious route to low-power, computationally\nefficient frameworks.In this paper, we propose an attention-driven visuomotor\ncontrol strategy inspired by a specific class of fly visual projection\nneurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated\nescape behaviors.To our knowledge, this represents the first embodiment of an\nLPLC2 neural model in the embedded vision of a physical mobile robot, enabling\ncollision perception and reactive evasion.The model was simplified and\noptimized at 70KB in memory to suit the computational constraints of a\nvision-based micro robot, the Colias, while preserving key neural perception\nmechanisms.We further incorporated multi-attention mechanisms to emulate the\ndistributed nature of LPLC2 responses, allowing the robot to detect and react\nto approaching targets both rapidly and selectively.We systematically evaluated\nthe proposed method against a state-of-the-art locust-inspired collision\ndetection model.Results showed that the fly-inspired visuomotor model achieved\ncomparable robustness, at success rate of 96.1% in collision detection while\nproducing more adaptive and elegant evasive maneuvers.Beyond demonstrating an\neffective collision-avoidance strategy, this work highlights the potential of\nfly-inspired neural models for advancing research into collective behaviors in\ninsect intelligence.", "AI": {"tldr": "The paper introduces an insect-inspired visual neural perception model, emulating fly escape behavior, for robots to achieve efficient collision detection and evasion.", "motivation": "Developing agile and computationally efficient collision-detection mechanisms for robots, inspired by the visual intelligence of flies.", "method": "Embedded a fly-inspired LPLC2 neural model in a micro robot's vision system, optimized memory usage, and implemented multi-attention mechanisms for selective responses.", "result": "The proposed model achieved 96.1% collision detection success rate and demonstrated adaptive and elegant evasive maneuvers, comparable to state-of-the-art systems.", "conclusion": "This work underscores the effectiveness of fly-inspired visuomotor control in robotic systems and its potential contribution to insect intelligence and collective behavior studies."}}
{"id": "2509.13347", "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "categories": ["cs.AI"], "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "This paper explores the design of action spaces in AI agents, proposing the Chain of Action (CoA) framework to unify high-level planning and low-level control for robust task generalization in Minecraft.", "motivation": "The paper addresses the unresolved challenge of selecting effective action spaces for generalist agents in Vision-Language-Action models, highlighting the task-dependence of optimal abstractions.", "method": "The authors conducted a systematic comparison of action spaces and tokenizers in Minecraft, introducing the CoA paradigm where abstracted actions act as intermediate reasoning steps within a unified model.", "result": "The CoA-trained 'All-in-One' agent outperformed specialized baselines, achieving state-of-the-art task success rates and demonstrating superior robustness and generalization.", "conclusion": "The study concludes that the CoA framework effectively resolves task-dependence dilemmas in action space selection, enabling capable and generalist AI agents. The OpenHA suite is provided to support reproducible research."}}
{"id": "2509.13672", "pdf": "https://arxiv.org/pdf/2509.13672", "abs": "https://arxiv.org/abs/2509.13672", "authors": ["Shang Qin", "Jingheng Ye", "Yinghui Li", "Hai-Tao Zheng", "Qi Li", "Jinxiao Shan", "Zhixing Li", "Hong-Gee Kim"], "title": "CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The growing demand for automated writing assistance in diverse academic\ndomains highlights the need for robust Chinese Grammatical Error Correction\n(CGEC) systems that can adapt across disciplines. However, existing CGEC\nresearch largely lacks dedicated benchmarks for multi-disciplinary academic\nwriting, overlooking continual learning (CL) as a promising solution to handle\ndomain-specific linguistic variation and prevent catastrophic forgetting. To\nfill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning\nbenchmark for Chinese Literature Grammatical Error Correction, designed to\nevaluate adaptive CGEC across multiple academic fields. Our benchmark includes\n10,000 human-annotated sentences spanning 10 disciplines, each exhibiting\ndistinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating\ngrammatical error correction in a continual learning setting, simulating\nsequential exposure to diverse academic disciplines to reflect real-world\neditorial dynamics. We evaluate large language models under sequential tuning,\nparameter-efficient adaptation, and four representative CL algorithms, using\nboth standard GEC metrics and continual learning metrics adapted to task-level\nvariation. Experimental results reveal that regularization-based methods\nmitigate forgetting more effectively than replay-based or naive sequential\napproaches. Our benchmark provides a rigorous foundation for future research in\nadaptive grammatical error correction across diverse academic domains.", "AI": {"tldr": "The paper introduces the first continual learning benchmark, CL$^2$GEC, for Chinese Grammatical Error Correction (CGEC) in academic writing across multiple disciplines.", "motivation": "Existing CGEC systems lack mechanisms to adapt effectively to domain-specific linguistic variations and prevent catastrophic forgetting during continual learning.", "method": "The authors proposed a benchmark comprising 10,000 annotated sentences from 10 disciplines, evaluated under various continual learning algorithms and metrics.", "result": "Experimental findings showed that regularization-based methods were more effective in mitigating knowledge forgetting than replay-based or naive sequential approaches.", "conclusion": "CL$^2$GEC provides a critical framework for advancing adaptive CGEC systems, especially for multi-disciplinary academic domains."}}
{"id": "2509.13608", "pdf": "https://arxiv.org/pdf/2509.13608", "abs": "https://arxiv.org/abs/2509.13608", "authors": ["Niruthiha Selvanayagam", "Ted Kurti"], "title": "Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection", "categories": ["cs.LG"], "comment": null, "summary": "As Large Multimodal Models (LMMs) become integral to daily digital life,\nunderstanding their safety architectures is a critical problem for AI\nAlignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a\nglobally deployed model, on the difficult task of multimodal hate speech\ndetection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase\ninvestigation on 500 samples to probe the model's reasoning and failure modes.\nOur central finding is the experimental identification of a \"Unimodal\nBottleneck,\" an architectural flaw where the model's advanced multimodal\nreasoning is systematically preempted by context-blind safety filters. A\nquantitative validation of 144 content policy refusals reveals that these\noverrides are triggered in equal measure by unimodal visual 50% and textual 50%\ncontent. We further demonstrate that this safety system is brittle, blocking\nnot only high-risk imagery but also benign, common meme formats, leading to\npredictable false positives. These findings expose a fundamental tension\nbetween capability and safety in state-of-the-art LMMs, highlighting the need\nfor more integrated, context-aware alignment strategies to ensure AI systems\ncan be deployed both safely and effectively.", "AI": {"tldr": "The paper analyzes OpenAI's GPT-4o mini model's ability to detect multimodal hate speech and identifies a 'Unimodal Bottleneck,' a safety flaw that limits its effectiveness.", "motivation": "To understand and improve the safety architectures of Large Multimodal Models (LMMs) while addressing challenges in multimodal hate speech detection.", "method": "Authors used the Hateful Memes Challenge dataset to analyze the reasoning and failure modes of GPT-4o mini on 500 samples and conducted a quantitative validation of the system's content policy refusals.", "result": "Identified a 'Unimodal Bottleneck' in the model's architecture, where safety filters systematically override advanced reasoning. The model had equal content refusals due to unimodal visual content (50%) and textual content (50%), leading to false positives.", "conclusion": "Current safety systems in LMMs, such as GPT-4o mini's, need more context-aware alignment to balance capability and safety effectively in real-world deployment scenarios."}}
{"id": "2509.13385", "pdf": "https://arxiv.org/pdf/2509.13385", "abs": "https://arxiv.org/abs/2509.13385", "authors": ["Charlotte Beylier", "Parvaneh Joharinad", "J\u00fcrgen Jost", "Nahid Torbati"], "title": "Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension", "categories": ["cs.CV", "cs.DM", "cs.LG", "51K05 (primary) 57-08, 53Z50, 55U10 (secondary)", "G.2.2"], "comment": "31 pages, 14 figures", "summary": "Utilizing recently developed abstract notions of sectional curvature, we\nintroduce a method for constructing a curvature-based geometric profile of\ndiscrete metric spaces. The curvature concept that we use here captures the\nmetric relations between triples of points and other points. More\nsignificantly, based on this curvature profile, we introduce a quantitative\nmeasure to evaluate the effectiveness of data representations, such as those\nproduced by dimensionality reduction techniques. Furthermore, Our experiments\ndemonstrate that this curvature-based analysis can be employed to estimate the\nintrinsic dimensionality of datasets. We use this to explore the large-scale\ngeometry of empirical networks and to evaluate the effectiveness of\ndimensionality reduction techniques.", "AI": {"tldr": "The paper introduces a curvature-based geometric profile for discrete metric spaces and a quantitative measure for evaluating data representations, like dimensionality reduction techniques, showing its utility in estimating intrinsic dimensionality and analyzing empirical networks.", "motivation": "To provide a systematic way to understand and evaluate the geometric and structural properties of discrete metric spaces and data representations, particularly dimensionality reduction techniques.", "method": "The method involves leveraging sectional curvature concepts to construct geometric profiles and introducing a quantitative curvature-based measure for assessing representation effectiveness and intrinsic dimensionality.", "result": "Experiments showed that curvature-based analysis reliably estimates intrinsic dimensionality and provides insights into the geometry of empirical networks, enabling evaluation of dimensionality reduction techniques.", "conclusion": "Curvature-based geometric profiling is a valuable tool for analyzing the structural properties of metric spaces and data reductions, offering quantitative evaluation capabilities and insights into data geometry."}}
{"id": "2509.14118", "pdf": "https://arxiv.org/pdf/2509.14118", "abs": "https://arxiv.org/abs/2509.14118", "authors": ["Julia Jurkowska", "Joanna Dreszer", "Monika Lewandowska", "Krzysztof To\u0142pa", "Tomasz Piotrowski"], "title": "Multi-Source Neural Activity Indices and Spatial Filters for EEG/MEG Inverse Problem: An Extension to MNE-Python", "categories": ["math.OC", "q-bio.NC"], "comment": null, "summary": "Accurate EEG/MEG source localization is essential for understanding brain\nfunction, yet remains challenging because the inverse problem is inherently\nill-posed. In spatial filtering (beamforming) approaches, single-source LCMV\nspatial filters, though widely used, suffer from source cancellation when\nsources are correlated - a common experimental scenario. Multi-source\nframeworks, such as the multi-source minimum-variance pseudo-unbiased\nreduced-rank (MV-PURE) method, offer improved reconstruction and robust neural\nactivity indices, yet their adoption has been limited by incomplete theory and\nlack of accessible implementations. In this paper, we present a rigorous\nderivation of multi-source neural activity indices and spatial filters,\nestablishing a complete analytical framework with automated parameter\nselection. The resulting compact algebraic forms enable straightforward\nimplementation. To facilitate adoption, we provide a full implementation\nextending MNE-Python, along with an accompanying tutorial, and demonstrate its\nutility on EEG experimental data, highlighting the practical advantages of\nmulti-source spatial filtering for source localization and reconstruction.", "AI": {"tldr": "The paper presents a refined multi-source EEG/MEG localization framework addressing source cancellation, offering analytical completeness and practical implementation.", "motivation": "Overcome challenges in accurate EEG/MEG source localization due to ill-posed inverse problems and source cancellation in correlated source scenarios.", "method": "Derives a rigorous analytical framework for multi-source neural activity indices and spatial filters with automated parameter selection, complemented by implementation extending MNE-Python.", "result": "Provides a complete, practical multi-source approach for EEG/MEG localization and demonstrates its effectiveness using real EEG experimental data.", "conclusion": "Multi-source spatial filtering using the proposed framework improves source localization and is accessible for broader adoption through implementation and tutorials."}}
{"id": "2509.13656", "pdf": "https://arxiv.org/pdf/2509.13656", "abs": "https://arxiv.org/abs/2509.13656", "authors": ["Yingao Elaine Yao", "Vedant Nimje", "Varun Viswanath", "Saikat Dutta"], "title": "A Regression Testing Framework with Automated Assertion Generation for Machine Learning Notebooks", "categories": ["cs.SE"], "comment": "22 pages, 2 figures, 6 tables", "summary": "Notebooks have become the de-facto choice for data scientists and machine\nlearning engineers for prototyping and experimenting with machine learning (ML)\npipelines. Notebooks provide an interactive interface for code, data, and\nvisualization. However, notebooks provide very limited support for testing.\nThus, during continuous development, many subtle bugs that do not lead to\ncrashes often go unnoticed and cause silent errors that manifest as performance\nregressions.\n  To address this, we introduce NBTest - the first regression testing framework\nthat allows developers to write cell-level assertions in notebooks and run such\nnotebooks in pytest or in continuous integration (CI) pipelines. NBTest offers\na library of assertion APIs, and a JupyterLab plugin that enables executing\nassertions. We also develop the first automated approach for generating\ncell-level assertions for key components in ML notebooks, such as data\nprocessing, model building, and model evaluation. NBTest aims to improve the\nreliability and maintainability of ML notebooks without adding developer\nburden.\n  We evaluate NBTest on 592 Kaggle notebooks. Overall, NBTest generates 21163\nassertions (35.75 on average per notebook). The generated assertions obtain a\nmutation score of 0.57 in killing ML-specific mutations. NBTest can catch\nregression bugs in previous versions of the Kaggle notebooks using assertions\ngenerated for the latest versions. Because ML pipelines involve non\ndeterministic computations, the assertions can be flaky. Hence, we also show\nhow NBTest leverages statistical techniques to minimize flakiness while\nretaining high fault-detection effectiveness. NBTest has been adopted in the CI\nof a popular ML library. Further, we perform a user study with 17 participants\nthat shows that notebook users find NBTest intuitive (Rating 4.3/5) and useful\nin writing assertions and testing notebooks (Rating 4.24/5).", "AI": {"tldr": "NBTest introduces a regression testing framework for ML notebooks, enabling cell-level assertions and integration with pytest and CI pipelines to catch subtle bugs effectively.", "motivation": "The paper addresses the lack of robust testing facilities in notebooks used for prototyping ML pipelines, which often leads to unnoticed silent errors and performance regressions.", "method": "NBTest includes a library of assertion APIs, a JupyterLab plugin for executing assertions, and automated cell-level assertion generation for ML notebook components such as data processing and model evaluation.", "result": "On 592 Kaggle notebooks, NBTest generated an average of 35.75 assertions per notebook, achieved a mutation score of 0.57, and successfully identified regression bugs. Flakiness was minimized using statistical techniques, and it was adopted in the CI of a popular ML library.", "conclusion": "NBTest enhances the reliability and usability of ML notebooks by incorporating effective regression testing tools, with positive feedback from users and adoption by a major ML library."}}
{"id": "2509.13381", "pdf": "https://arxiv.org/pdf/2509.13381", "abs": "https://arxiv.org/abs/2509.13381", "authors": ["Zhang Xueyao", "Yang Bo", "Yu Zhiwen", "Cao Xuelin", "George C. Alexandropoulos", "Merouane Debbah", "Chau Yuen"], "title": "Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": "6 pages", "summary": "Autonomous Underwater Vehicles (AUVs) have shown great potential for\ncooperative detection and reconnaissance. However, collaborative AUV\ncommunications introduce risks of exposure. In adversarial environments,\nachieving efficient collaboration while ensuring covert operations becomes a\nkey challenge for underwater cooperative missions. In this paper, we propose a\nnovel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization\n(H-MAPPO) framework. The high-level component determines the individuals\nparticipating in the task based on a central AUV, while the low-level component\nreduces exposure probabilities through power and trajectory control by the\nparticipating AUVs. Simulation results show that the proposed framework\nachieves rapid convergence, outperforms benchmark algorithms in terms of\nperformance, and maximizes long-term cooperative efficiency while ensuring\ncovert operations.", "AI": {"tldr": "The paper introduces a novel Hierarchical Multi-Agent Proximal Policy Optimization (H-MAPPO) framework to enable efficient and covert collaboration among Autonomous Underwater Vehicles (AUVs) in adversarial environments.", "motivation": "The need to address the challenge of efficient collaboration among AUVs while minimizing exposure risks in hostile underwater environments.", "method": "The framework employs a dual time-scale approach. A high-level component selects participants for the task based on a central AUV, while a low-level component optimizes power and trajectory control to reduce exposure probabilities.", "result": "Simulation results demonstrate rapid convergence, superior performance compared to benchmark algorithms, and effective optimization of cooperative efficiency while maintaining covert operations.", "conclusion": "The proposed H-MAPPO framework successfully ensures efficient collaboration among AUVs in adversarial scenarios while minimizing exposure risks, presenting a promising solution for underwater cooperative missions."}}
{"id": "2509.14218", "pdf": "https://arxiv.org/pdf/2509.14218", "abs": "https://arxiv.org/abs/2509.14218", "authors": ["James Leiner", "Robin Dunn", "Aaditya Ramdas"], "title": "Adaptive Off-Policy Inference for M-Estimators Under Model Misspecification", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.OT", "stat.TH"], "comment": "36 pages, 6 figures", "summary": "When data are collected adaptively, such as in bandit algorithms, classical\nstatistical approaches such as ordinary least squares and $M$-estimation will\noften fail to achieve asymptotic normality. Although recent lines of work have\nmodified the classical approaches to ensure valid inference on adaptively\ncollected data, most of these works assume that the model is correctly\nspecified. We propose a method that provides valid inference for M-estimators\nthat use adaptively collected bandit data with a (possibly) misspecified\nworking model. A key ingredient in our approach is the use of flexible machine\nlearning approaches to stabilize the variance induced by adaptive data\ncollection. A major novelty is that our procedure enables the construction of\nvalid confidence sets even in settings where treatment policies are unstable\nand non-converging, such as when there is no unique optimal arm and standard\nbandit algorithms are used. Empirical results on semi-synthetic datasets\nconstructed from the Osteoarthritis Initiative demonstrate that the method\nmaintains type I error control, while existing methods for inference in\nadaptive settings do not cover in the misspecified case.", "AI": {"tldr": "This paper addresses the challenge of valid inference when working with adaptively collected data, proposing a method compatible with potentially misspecified models.", "motivation": "Classical statistical methods often fail in adaptively collected data scenarios, and most solutions assume the correctness of the model specification.", "method": "The authors introduce an inference method using M-estimators with variance stabilization through machine learning to handle adaptively collected and potentially misspecified data.", "result": "The proposed method ensures valid confidence sets and maintains type I error control, even in unstable adaptive scenarios, outperforming existing methods in misspecified cases.", "conclusion": "The method is robust for inference in adaptive data collection settings, providing valid outcomes even under model misspecification or unstable adaptive policies."}}
{"id": "2509.13627", "pdf": "https://arxiv.org/pdf/2509.13627", "abs": "https://arxiv.org/abs/2509.13627", "authors": ["Vijay Kumar Butte", "Sujata Butte"], "title": "Secure, Scalable and Privacy Aware Data Strategy in Cloud", "categories": ["cs.CR", "cs.AI", "cs.DC"], "comment": null, "summary": "The enterprises today are faced with the tough challenge of processing,\nstoring large amounts of data in a secure, scalable manner and enabling\ndecision makers to make quick, informed data driven decisions. This paper\naddresses this challenge and develops an effective enterprise data strategy in\nthe cloud. Various components of an effective data strategy are discussed and\narchitectures addressing security, scalability and privacy aspects are\nprovided.", "AI": {"tldr": "This paper presents an enterprise data strategy for cloud environments, focusing on processing, storage, and decision-making challenges.", "motivation": "The need to handle vast data volumes securely, scalably, and enabling quick, data-driven decisions for enterprises.", "method": "The paper discusses key components of data strategy and provides architectures to address security, scalability, and privacy.", "result": "Effective enterprise data strategy and architectures to manage data challenges proposed.", "conclusion": "The proposed approach supports enterprises in making informed, data-driven decisions while addressing security, scalability, and privacy requirements."}}
{"id": "2509.13351", "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "This paper presents PDDL-Instruct, a framework enhancing LLMs' planning accuracy to 94% via logical chain-of-thought reasoning.", "motivation": "To address the limited symbolic planning ability of LLMs in formal domains such as PDDL.", "method": "Introduced instruction tuning with logical chain-of-thought reasoning, guiding models through structured planning steps and self-correction.", "result": "Significant improvement in planning accuracy, achieving up to 94%, with a 66% absolute improvement over baseline models.", "conclusion": "The work bridges LLM reasoning and automated planning precision, offering new advancements in AI planning systems."}}
{"id": "2509.13677", "pdf": "https://arxiv.org/pdf/2509.13677", "abs": "https://arxiv.org/abs/2509.13677", "authors": ["Xinxu Zhou", "Jiaqi Bai", "Zhenqi Sun", "Fanxiang Zeng", "Yue Liu"], "title": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Although significant progress has been made in many tasks within the field of\nNatural Language Processing (NLP), Controlled Text Generation (CTG) continues\nto face numerous challenges, particularly in achieving fine-grained conditional\ncontrol over generation. Additionally, in real scenario and online\napplications, cost considerations, scalability, domain knowledge learning and\nmore precise control are required, presenting more challenge for CTG. This\npaper introduces a novel and scalable framework, AgentCTG, which aims to\nenhance precise and complex control over the text generation by simulating the\ncontrol and regulation mechanisms in multi-agent workflows. We explore various\ncollaboration methods among different agents and introduce an auto-prompt\nmodule to further enhance the generation effectiveness. AgentCTG achieves\nstate-of-the-art results on multiple public datasets. To validate its\neffectiveness in practical applications, we propose a new challenging\nCharacter-Driven Rewriting task, which aims to convert the original text into\nnew text that conform to specific character profiles and simultaneously\npreserve the domain knowledge. When applied to online navigation with\nrole-playing, our approach significantly enhances the driving experience\nthrough improved content delivery. By optimizing the generation of contextually\nrelevant text, we enable a more immersive interaction within online\ncommunities, fostering greater personalization and user engagement.", "AI": {"tldr": "The paper introduces AgentCTG, a scalable framework for fine-grained control over text generation, achieving state-of-the-art results and improving domain-specific applications.", "motivation": "Controlled Text Generation (CTG) faces challenges such as fine-grained control, cost efficiency, scalability, and domain knowledge learning, especially in real-world applications.", "method": "The authors propose AgentCTG, a multi-agent workflow-inspired framework with an auto-prompt module to improve text generation precision and scalability.", "result": "AgentCTG demonstrates state-of-the-art performance on multiple datasets and excels in the newly proposed Character-Driven Rewriting task.", "conclusion": "AgentCTG enables precise, contextually relevant text generation, leading to better content delivery, personalization, and interaction in online scenarios."}}
{"id": "2509.13621", "pdf": "https://arxiv.org/pdf/2509.13621", "abs": "https://arxiv.org/abs/2509.13621", "authors": ["Antonin Sulc", "Thorsten Hellert", "Steven Hunt"], "title": "Unsupervised Anomaly Detection in ALS EPICS Event Logs", "categories": ["cs.LG"], "comment": "6 pages, 5 figures, The 20th International Conference on Accelerator\n  and Large Experimental Physics Control Systems", "summary": "This paper introduces an automated fault analysis framework for the Advanced\nLight Source (ALS) that processes real-time event logs from its EPICS control\nsystem. By treating log entries as natural language, we transform them into\ncontextual vector representations using semantic embedding techniques. A\nsequence-aware neural network, trained on normal operational data, assigns a\nreal-time anomaly score to each event. This method flags deviations from\nbaseline behavior, enabling operators to rapidly identify the critical event\nsequences that precede complex system failures.", "AI": {"tldr": "An automated framework processes ALS event logs using natural language techniques to flag anomalies for faster failure identification.", "motivation": "Streamline fault analysis in ALS using real-time event logs and enable rapid detection of system issues.", "method": "Logs are transformed into contextual vector representations via semantic embeddings, and analyzed using a sequence-aware neural network to compute anomaly scores.", "result": "Real-time anomaly scoring allows operators to promptly identify critical event sequences causing system failures.", "conclusion": "The framework enhances ALS failure identification efficiency by leveraging NLP techniques and neural networks."}}
{"id": "2509.13388", "pdf": "https://arxiv.org/pdf/2509.13388", "abs": "https://arxiv.org/abs/2509.13388", "authors": ["Yadvendra Gurjar", "Ruoni Wan", "Ehsan Farahbakhsh", "Rohitash Chandra"], "title": "Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "As a developing country, Fiji is facing rapid urbanisation, which is visible\nin the massive development projects that include housing, roads, and civil\nworks. In this study, we present machine learning and remote sensing frameworks\nto compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The\nultimate goal of this study is to provide technical support in land cover/land\nuse modelling and change detection. We used Landsat-8 satellite image for the\nstudy region and created our training dataset with labels for supervised\nmachine learning. We used Google Earth Engine and unsupervised machine learning\nvia k-means clustering to generate the land cover map. We used convolutional\nneural networks to classify the selected regions' land cover types. We present\na visualisation of change detection, highlighting urban area changes over time\nto monitor changes in the map.", "AI": {"tldr": "The paper examines Fiji's rapid urbanization using machine learning and remote sensing methods to analyze land use/land cover changes from 2013 to 2024.", "motivation": "The study aims to address Fiji's rapid urbanization by providing technical support for land use modeling and monitoring changes to inform sustainable urban planning and development.", "method": "The authors used Landsat-8 satellite imagery, created labeled training datasets for supervised learning, applied Google Earth Engine with k-means clustering, and used convolutional neural networks for classification and change detection.", "result": "The research generated land cover maps, visualized change detection, and highlighted changes in urban areas over the study period.", "conclusion": "The study showcases the potential of machine learning and remote sensing in monitoring urbanization impact and provides tools for understanding and managing land use/land cover changes in Fiji."}}
{"id": "2509.13680", "pdf": "https://arxiv.org/pdf/2509.13680", "abs": "https://arxiv.org/abs/2509.13680", "authors": ["Wei Ma", "Yixiao Yang", "Jingquan Ge", "Xiaofei Xie", "Lingxiao Jiang"], "title": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code generation models are widely used in software development, yet their\nsensitivity to prompt phrasing remains under-examined. Identical requirements\nexpressed with different emotions or communication styles can yield divergent\noutputs, while most benchmarks emphasize only peak performance. We present\nPromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically\nequivalent prompt variants with emotion and personality templates, and that\nevaluates stability using probability aware continuous scoring or using binary\npass rates when logits are unavailable. The results are aggregated into a\nproposed area under curve metric (AUC-E) for cross model comparison. Across 14\nmodels from three families (Llama, Qwen, and DeepSeek), our study shows that\nperformance and stability behave as largely decoupled optimization objectives,\nand it reveals architectural and scale related patterns that challenge common\nassumptions about model robustness. The framework supports rapid screening for\nclosed-source models as well as detailed stability analysis in research\nsettings. PromptSE enables practitioners to quantify performance stability\ntrade offs for deployment and model selection, positioning prompt stability as\na complementary evaluation dimension alongside performance and fairness, and\ncontributing to more trustworthy AI-assisted software development tools.", "AI": {"tldr": "The paper introduces PromptSE, a framework for evaluating code generation models' sensitivity to prompt phrasing by creating semantic variants and assessing stability. It reveals insights on model robustness and offers tools for performance stability analysis.", "motivation": "Code generation models are prone to instability based on how prompts are phrased, but this sensitivity has not been adequately studied, especially in terms of emotion and communication style variations.", "method": "The authors developed the PromptSE framework, which generates semantically equivalent prompt variants using emotion/personality templates, assesses stability via scoring methods, and summarizes results with a new metric (AUC-E).", "result": "Testing PromptSE across models from different families showed that performance and stability are largely unrelated optimization objectives, revealing patterns tied to architecture and scale and challenging assumptions about robustness.", "conclusion": "PromptSE enables performance stability analysis for deployment and model selection, complementing evaluative dimensions like fairness and reliability, and thereby enhancing trustworthiness in AI-assisted software tools."}}
{"id": "2509.13386", "pdf": "https://arxiv.org/pdf/2509.13386", "abs": "https://arxiv.org/abs/2509.13386", "authors": ["Hansol Lim", "Minhyeok Im", "Jonathan Boyack", "Jee Won Lee", "Jongseong Brad Choi"], "title": "VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization", "categories": ["cs.RO", "cs.LG"], "comment": "This work has been submitted to the 2026 IEEE International\n  Conference on Robotics and Automation (ICRA) for possible publication", "summary": "Demands for software-defined vehicles (SDV) are rising and electric vehicles\n(EVs) are increasingly being equipped with powerful computers. This enables\nonboard AI systems to optimize charge-aware path optimization customized to\nreflect vehicle's current condition and environment. We present VEGA, a\ncharge-aware EV navigation agent that plans over a charger-annotated road graph\nusing Proximal Policy Optimization (PPO) with budgeted A* teacher-student\nguidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.\nFirst, a physics-informed neural operator (PINO), trained on real vehicle speed\nand battery-power logs, uses recent vehicle speed logs to estimate aerodynamic\ndrag, rolling resistance, mass, motor and regenerative-braking efficiencies,\nand auxiliary load by learning a vehicle-custom dynamics. Second, a\nReinforcement Learning (RL) agent uses these dynamics to optimize a path with\noptimal charging stops and dwell times under SoC constraints. VEGA requires no\nadditional sensors and uses only vehicle speed signals. It may serve as a\nvirtual sensor for power and efficiency to potentially reduce EV cost. In\nevaluation on long routes like San Francisco to New York, VEGA's stops, dwell\ntimes, SoC management, and total travel time closely track Tesla Trip Planner\nwhile being slightly more conservative, presumably due to real vehicle\nconditions such as vehicle parameter drift due to deterioration. Although\ntrained only in U.S. regions, VEGA was able to compute optimal charge-aware\npaths in France and Japan, demonstrating generalizability. It achieves\npractical integration of physics-informed learning and RL for EV eco-routing.", "AI": {"tldr": "VEGA is a software tool enabling electric vehicle navigation, combining physics-informed learning and reinforcement learning to optimize paths with efficient charging stops, all without requiring additional sensors.", "motivation": "The paper aims to address the demand for optimized navigation for software-defined electric vehicles by leveraging onboard computational power without relying on expensive sensors.", "method": "The method involves two components: (1) a Physics-Informed Neural Operator (PINO) trained on vehicle speed and battery logs to model vehicle dynamics, and (2) a Reinforcement Learning agent to compute charge-aware routes optimizing stops and dwell times while considering battery state constraints.", "result": "VEGA demonstrated functionality by closely matching Tesla Trip Planner's results during tests on long routes, maintaining conservative estimates due to real vehicle conditions. It also showed global generalizability in regions outside its training set.", "conclusion": "VEGA highlights the feasibility of combining physics-informed AI and reinforcement learning for efficient electric vehicle navigation, showcasing potential cost reductions by relying purely on onboard computations."}}
{"id": "2509.14225", "pdf": "https://arxiv.org/pdf/2509.14225", "abs": "https://arxiv.org/abs/2509.14225", "authors": ["Benjamin Sterling", "Yousef El-Laham", "M\u00f3nica F. Bugallo"], "title": "Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics", "categories": ["cs.LG", "stat.ML"], "comment": "5 pages, 2 figures, 1 table", "summary": "Recent advances in generative artificial intelligence applications have\nraised new data security concerns. This paper focuses on defending diffusion\nmodels against membership inference attacks. This type of attack occurs when\nthe attacker can determine if a certain data point was used to train the model.\nAlthough diffusion models are intrinsically more resistant to membership\ninference attacks than other generative models, they are still susceptible. The\ndefense proposed here utilizes critically-damped higher-order Langevin\ndynamics, which introduces several auxiliary variables and a joint diffusion\nprocess along these variables. The idea is that the presence of auxiliary\nvariables mixes external randomness that helps to corrupt sensitive input data\nearlier on in the diffusion process. This concept is theoretically investigated\nand validated on a toy dataset and a speech dataset using the Area Under the\nReceiver Operating Characteristic (AUROC) curves and the FID metric.", "AI": {"tldr": "This paper explores a strategy to defend diffusion models against membership inference attacks using higher-order Langevin dynamics.", "motivation": "Generative AI, particularly diffusion models, faces risks from membership inference attacks, which expose data points used during training.", "method": "The method introduces critically-damped higher-order Langevin dynamics to mix auxiliary variables, corrupting sensitive inputs early in the diffusion process.", "result": "The approach was theoretically analyzed and validated on a toy and speech dataset, assessed via AUROC and FID metrics.", "conclusion": "Using auxiliary variables through advanced Langevin dynamics adds randomness, enhancing the model's resistance to membership inference attacks."}}
{"id": "2509.13631", "pdf": "https://arxiv.org/pdf/2509.13631", "abs": "https://arxiv.org/abs/2509.13631", "authors": ["Yuvraj Dutta", "Aaditya Sikder", "Basabdatta Palit"], "title": "Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery", "categories": ["cs.CV", "cs.DC", "14J60", "F.2.2; I.2.7"], "comment": "6 pages, 7 figures, accepted at IEEE INDISCON 2025", "summary": "Accurate identification of deforestation from satellite images is essential\nin order to understand the geographical situation of an area. This paper\nintroduces a new distributed approach to identify as well as locate\ndeforestation across different clients using Federated Learning (FL). Federated\nLearning enables distributed network clients to collaboratively train a model\nwhile maintaining data privacy and security of the active users. In our\nframework, a client corresponds to an edge satellite center responsible for\nlocal data processing. Moreover, FL provides an advantage over centralized\ntraining method which requires combining data, thereby compromising with data\nsecurity of the clients. Our framework leverages the FLOWER framework with RAY\nframework to execute the distributed learning workload. Furthermore, efficient\nclient spawning is ensured by RAY as it can select definite amount of users to\ncreate an emulation environment. Our FL framework uses YOLOS-small (a Vision\nTransformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN\nwith a MobileNetV3 backbone models trained and tested on publicly available\ndatasets. Our approach provides us a different view for image\nsegmentation-based tasks on satellite imagery.", "AI": {"tldr": "The paper proposes a distributed Federated Learning approach to identify and locate deforestation using satellite imagery while preserving data security.", "motivation": "Deforestation monitoring is crucial for geographical analysis, and traditional centralized methods risk data security. A distributed method is needed to maintain privacy while ensuring effective satellite image processing.", "method": "The paper combines FLOWER and RAY frameworks for distributed Federated Learning, using YOLOS-small, Faster R-CNN with ResNet50, and Faster R-CNN with MobileNetV3 architectures applied to publicly available datasets.", "result": "The proposed framework achieves efficient deforestation identification across satellite centers by leveraging Federated Learning for privacy-preserving, collaborative model training.", "conclusion": "The study demonstrates the potential of Federated Learning in advancing deforestation monitoring through secure and distributed satellite image processing."}}
{"id": "2509.13352", "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "The paper proposes a novel UAV framework leveraging LLMs for advanced autonomy, achieving significant performance boosts in search-and-rescue simulations.", "motivation": "Existing UAV frameworks lack adaptability in dynamic missions due to reliance on narrow AI and rule-based systems.", "method": "The paper introduces a five-layer architecture for UAVs integrating LLM-driven reasoning, YOLOv11 for object detection, and tool-calling for real-time decision-making.", "result": "In simulations, UAVs using this framework showed improved detection rates (91% vs. 75%), higher confidence (0.79 vs. 0.72), and better action recommendations (92% vs. 4.5%).", "conclusion": "Integrating LLMs into UAV architectures provides a pathway to new levels of autonomy and system integration with modest computational demands."}}
{"id": "2509.13683", "pdf": "https://arxiv.org/pdf/2509.13683", "abs": "https://arxiv.org/abs/2509.13683", "authors": ["Suyuchen Wang", "Jinlin Wang", "Xinyu Wang", "Shiqi Li", "Xiangru Tang", "Sirui Hong", "Xiao-Wen Chang", "Chenglin Wu", "Bang Liu"], "title": "Improving Context Fidelity via Native Retrieval-Augmented Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted as a main conference paper at EMNLP 2025", "summary": "Large language models (LLMs) often struggle with context fidelity, producing\ninconsistent answers when responding to questions based on provided\ninformation. Existing approaches either rely on expensive supervised\nfine-tuning to generate evidence post-answer or train models to perform web\nsearches without necessarily improving utilization of the given context. We\npropose CARE, a novel native retrieval-augmented reasoning framework that\nteaches LLMs to explicitly integrate in-context evidence within their reasoning\nprocess with the model's own retrieval capabilities. Our method requires\nlimited labeled evidence data while significantly enhancing both retrieval\naccuracy and answer generation performance through strategically retrieved\nin-context tokens in the reasoning chain. Extensive experiments on multiple\nreal-world and counterfactual QA benchmarks demonstrate that our approach\nsubstantially outperforms supervised fine-tuning, traditional\nretrieval-augmented generation methods, and external retrieval solutions. This\nwork represents a fundamental advancement in making LLMs more accurate,\nreliable, and efficient for knowledge-intensive tasks.", "AI": {"tldr": "This paper introduces CARE, a new framework that improves large language models (LLMs) by integrating evidence-based reasoning directly into their processes.", "motivation": "LLMs often provide inconsistent answers due to poor context integration, and existing solutions either involve costly fine-tuning or fail to improve context utilization effectively.", "method": "The authors propose CARE, a retrieval-augmented reasoning framework that enhances in-context evidence integration. It leverages limited labeled data and retrieves strategic tokens to improve both retrieval accuracy and generation performance.", "result": "CARE significantly outperforms other techniques, including supervised fine-tuning, traditional retrieval-augmented methods, and external retrieval systems, across various real-world and counterfactual QA benchmarks.", "conclusion": "The framework enhances the accuracy, reliability, and efficiency of LLMs for knowledge-intensive tasks, marking an important advancement in the field."}}
{"id": "2509.13625", "pdf": "https://arxiv.org/pdf/2509.13625", "abs": "https://arxiv.org/abs/2509.13625", "authors": ["Bishnu Bhusal", "Manoj Acharya", "Ramneet Kaur", "Colin Samplawski", "Anirban Roy", "Adam D. Cobb", "Rohit Chadha", "Susmit Jha"], "title": "Privacy-Aware In-Context Learning for Large Language Models", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "Large language models (LLMs) have significantly transformed natural language\nunderstanding and generation, but they raise privacy concerns due to potential\nexposure of sensitive information. Studies have highlighted the risk of\ninformation leakage, where adversaries can extract sensitive information\nembedded in the prompts. In this work, we introduce a novel private prediction\nframework for generating high-quality synthetic text with strong privacy\nguarantees. Our approach leverages the Differential Privacy (DP) framework to\nensure worst-case theoretical bounds on information leakage without requiring\nany fine-tuning of the underlying models.The proposed method performs inference\non private records and aggregates the resulting per-token output distributions.\nThis enables the generation of longer and coherent synthetic text while\nmaintaining privacy guarantees. Additionally, we propose a simple blending\noperation that combines private and public inference to further enhance\nutility. Empirical evaluations demonstrate that our approach outperforms\nprevious state-of-the-art methods on in-context-learning (ICL) tasks, making it\na promising direction for privacy-preserving text generation while maintaining\nhigh utility.", "AI": {"tldr": "The paper introduces a method for generating private synthetic text with differential privacy guarantees, ensuring security without model fine-tuning, and enhancing utility via blending private and public inferences.", "motivation": "Address the privacy risks posed by large language models in terms of sensitive information leakage while maintaining high utility in text generation.", "method": "A private prediction framework leveraging Differential Privacy (DP) to limit information leakage, using token-wise output aggregation and blending private/public inferences to enhance performance.", "result": "The method outperformed state-of-the-art techniques on in-context learning tasks, combining strong privacy guarantees with high utility.", "conclusion": "The approach provides a practical, effective solution for privacy-preserving text generation that balances theoretical security with empirical performance."}}
{"id": "2509.13396", "pdf": "https://arxiv.org/pdf/2509.13396", "abs": "https://arxiv.org/abs/2509.13396", "authors": ["Xinan Wang", "Di Shi", "Fengyu Wang"], "title": "Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence", "categories": ["cs.CV", "cs.SY", "eess.SY"], "comment": "12 page Journal paper, accepted by IEEE Open Access Journal of Power\n  and Energy", "summary": "This paper presents a novel three-stage framework for real-time foreign\nobject intrusion (FOI) detection and tracking in power transmission systems.\nThe framework integrates: (1) a YOLOv7 segmentation model for fast and robust\nobject localization, (2) a ConvNeXt-based feature extractor trained with\ntriplet loss to generate discriminative embeddings, and (3) a feature-assisted\nIoU tracker that ensures resilient multi-object tracking under occlusion and\nmotion. To enable scalable field deployment, the pipeline is optimized for\ndeployment on low-cost edge hardware using mixed-precision inference. The\nsystem supports incremental updates by adding embeddings from previously unseen\nobjects into a reference database without requiring model retraining. Extensive\nexperiments on real-world surveillance and drone video datasets demonstrate the\nframework's high accuracy and robustness across diverse FOI scenarios. In\naddition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's\npracticality and scalability for real-world edge applications.", "AI": {"tldr": "A three-stage framework for real-time foreign object intrusion detection and tracking in power transmission systems was developed using YOLOv7 for object localization, ConvNeXt for feature extraction, and a feature-assisted IoU tracker, optimized for edge deployment.", "motivation": "To address the challenge of detecting and tracking foreign objects in power transmission systems effectively and in real-time, especially with scalability for low-cost edge hardware.", "method": "The paper employs a three-stage framework combining YOLOv7, ConvNeXt trained with triplet loss, and a feature-assisted IoU tracker, optimized for mixed-precision inference on edge devices.", "result": "Extensive experiments show high accuracy and robustness for detecting foreign objects across diverse scenarios using surveillance and drone video datasets. Hardware benchmarks demonstrate scalability on NVIDIA Jetson devices.", "conclusion": "The proposed framework is practical, scalable, and suited for real-world edge applications, supporting incremental updates without retraining."}}
{"id": "2509.13755", "pdf": "https://arxiv.org/pdf/2509.13755", "abs": "https://arxiv.org/abs/2509.13755", "authors": ["Zhaoyang Chu", "Yao Wan", "Zhikun Zhang", "Di Wang", "Zhou Yang", "Hongyu Zhang", "Pan Zhou", "Xuanhua Shi", "Hai Jin", "David Lo"], "title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "While Code Language Models (CLMs) have demonstrated superior performance in\nsoftware engineering tasks such as code generation and summarization, recent\nempirical studies reveal a critical privacy vulnerability: these models exhibit\nunintended memorization of sensitive training data, enabling verbatim\nreproduction of confidential information when specifically prompted. To address\nthis issue, several approaches, including training data de-duplication and\ndifferential privacy augmentation, have been proposed. However, these methods\nrequire full-model retraining for deployed CLMs, which incurs substantial\ncomputational costs. In this paper, we aim to answer the following research\nquestion: Can sensitive information memorized by CLMs be erased effectively and\nefficiently?\n  We conduct a pioneering investigation into erasing sensitive memorization in\nCLMs through machine unlearning - a post-hoc modification method that removes\nspecific information from trained models without requiring full retraining.\nSpecifically, we first quantify the memorization risks of sensitive data within\nCLM training datasets and curate a high-risk dataset of 50,000 sensitive\nmemorized samples as unlearning targets. We study two widely used gradient\nascent-based unlearning approaches: the vanilla and constraint-based methods,\nand introduce CodeEraser, an advanced variant that selectively unlearns\nsensitive memorized segments in code while preserving the structural integrity\nand functional correctness of the surrounding code. Extensive experiments on\nthree families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,\nvalidate the effectiveness and efficiency of CodeEraser in erasing targeted\nsensitive memorization while maintaining model utility.", "AI": {"tldr": "The paper addresses privacy risks in Code Language Models by using machine unlearning techniques to efficiently erase sensitive memorized data without full-model retraining.", "motivation": "Code Language Models memorize sensitive training data, risking privacy breaches, and current resolution methods require costly retraining.", "method": "They use machine unlearning, specifically gradient ascent-based methods and introduce CodeEraser, to remove sensitive information without disturbing other code segments.", "result": "Experiments show CodeEraser effectively removes sensitive data from three CLMs\u2014CodeParrot, CodeGen-Mono, and Qwen2.5-Coder\u2014while preserving the models' functionality.", "conclusion": "CodeEraser provides a practical solution for mitigating privacy risks in CLMs without sacrificing computational efficiency or model performance."}}
{"id": "2509.13434", "pdf": "https://arxiv.org/pdf/2509.13434", "abs": "https://arxiv.org/abs/2509.13434", "authors": ["Wei-Chen Li", "Glen Chou"], "title": "A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies", "categories": ["cs.RO"], "comment": null, "summary": "We present a computational framework for simulating filaments interacting\nwith rigid bodies through contact. Filaments are challenging to simulate due to\ntheir codimensionality, i.e., they are one-dimensional structures embedded in\nthree-dimensional space. Existing methods often assume that filaments remain\npermanently attached to rigid bodies. Our framework unifies discrete elastic\nrod (DER) modeling, a pressure field patch contact model, and a convex contact\nformulation to accurately simulate frictional interactions between slender\nfilaments and rigid bodies - capabilities not previously achievable. Owing to\nthe convex formulation of contact, each time step can be solved to global\noptimality, guaranteeing complementarity between contact velocity and impulse.\nWe validate the framework by assessing the accuracy of frictional forces and\ncomparing its physical fidelity against baseline methods. Finally, we\ndemonstrate its applicability in both soft robotics, such as a stochastic\nfilament-based gripper, and deformable object manipulation, such as shoelace\ntying, providing a versatile simulator for systems involving complex\nfilament-filament and filament-rigid body interactions.", "AI": {"tldr": "This paper presents a computational simulator for frictional interactions between filaments and rigid bodies, offering a global optimality solution for complex manipulations, such as shoelace tying.", "motivation": "Simulating filament interactions with rigid bodies is computationally difficult due to their codimensional nature; existing methods lack accurate frictional modeling.", "method": "The framework combines discrete elastic rod modeling, a pressure field patch contact model, and convex contact formulation to achieve precise frictional simulations.", "result": "The framework achieved accurate frictional force modeling and demonstrated its utility in scenarios like a filament-based gripper and shoelace tying.", "conclusion": "This work enables reliable simulation of complex filament and rigid body interactions, advancing fields like soft robotics and deformable object manipulation."}}
{"id": "2509.13739", "pdf": "https://arxiv.org/pdf/2509.13739", "abs": "https://arxiv.org/abs/2509.13739", "authors": ["Zihou Wu", "Yuecheng Li", "Tianchi Liao", "Jian Lou", "Chuan Chen"], "title": "ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": "8 pages, 1 figure", "summary": "Federated learning (FL) faces a critical dilemma: existing protection\nmechanisms like differential privacy (DP) and homomorphic encryption (HE)\nenforce a rigid trade-off, forcing a choice between model utility and\ncomputational efficiency. This lack of flexibility hinders the practical\nimplementation. To address this, we introduce ParaAegis, a parallel protection\nframework designed to give practitioners flexible control over the\nprivacy-utility-efficiency balance. Our core innovation is a strategic model\npartitioning scheme. By applying lightweight DP to the less critical, low norm\nportion of the model while protecting the remainder with HE, we create a\ntunable system. A distributed voting mechanism ensures consensus on this\npartitioning. Theoretical analysis confirms the adjustments between efficiency\nand utility with the same privacy. Crucially, the experimental results\ndemonstrate that by adjusting the hyperparameters, our method enables flexible\nprioritization between model accuracy and training time.", "AI": {"tldr": "Federated learning often struggles with balancing privacy, efficiency, and utility. ParaAegis introduces a new framework combining Differential Privacy (DP) and Homomorphic Encryption (HE) with strategic model partitioning to resolve this issue.", "motivation": "The paper aims to overcome the rigid trade-offs in federated learning protection mechanisms, where existing approaches compromise either computational efficiency or model utility, limiting real-world applicability.", "method": "The authors propose ParaAegis, a framework that strategically partitions the model, applying lightweight DP to less critical parts and HE to the rest. A distributed voting mechanism is used to achieve consensus on the partitioning strategy.", "result": "Theoretical evaluations confirm that ParaAegis can balance efficiency and utility for a consistent level of privacy. Experimental data shows that varying hyperparameters allows practitioners to prioritize model accuracy or training speed as needed.", "conclusion": "ParaAegis offers a flexible and tunable approach for federated learning, enabling better trade-offs between privacy, utility, and efficiency to facilitate practical implementation."}}
{"id": "2509.13357", "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "categories": ["cs.AI"], "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "The paper introduces semantic fusion, a lightweight method to enhance language models using token-level semantic features, improving both generation control and interpretability.", "motivation": "To improve natural language generation by integrating token-level semantic features, enabling more controlled and interpretable outputs.", "method": "Introduced a semantic feature channel that encodes token-level properties, fused into a language model with gated adapters. Training involves next-token prediction, semantic reconstruction, and an auxiliary regularization loss.", "result": "Semantic fusion improves perplexity, ensures controlled generation (e.g., polarity and punctuation), and remains computationally lightweight.", "conclusion": "Semantic fusion enhances language models by improving interpretability, control, and computational efficiency, making it a promising method for conditioned text generation."}}
{"id": "2509.13695", "pdf": "https://arxiv.org/pdf/2509.13695", "abs": "https://arxiv.org/abs/2509.13695", "authors": ["Yosuke Mikami", "Daiki Matsuoka", "Hitomi Yanaka"], "title": "Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?", "categories": ["cs.CL"], "comment": "To appear in Proceedings of the 16th International Conference on\n  Computational Semantics (IWCS 2025)", "summary": "Large Language Models (LLMs) perform remarkably well in Natural Language\nInference (NLI). However, NLI involving numerical and logical expressions\nremains challenging. Comparatives are a key linguistic phenomenon related to\nsuch inference, but the robustness of LLMs in handling them, especially in\nlanguages that are not dominant in the models' training data, such as Japanese,\nhas not been sufficiently explored. To address this gap, we construct a\nJapanese NLI dataset that focuses on comparatives and evaluate various LLMs in\nzero-shot and few-shot settings. Our results show that the performance of the\nmodels is sensitive to the prompt formats in the zero-shot setting and\ninfluenced by the gold labels in the few-shot examples. The LLMs also struggle\nto handle linguistic phenomena unique to Japanese. Furthermore, we observe that\nprompts containing logical semantic representations help the models predict the\ncorrect labels for inference problems that they struggle to solve even with\nfew-shot examples.", "AI": {"tldr": "The paper evaluates the robustness of large language models (LLMs) in handling Japanese Natural Language Inference (NLI) tasks, particularly focusing on comparatives.", "motivation": "To investigate how well LLMs handle numerical and logical expressions in NLI tasks, with a specific emphasis on Japanese, a less-dominant language in their training.", "method": "The authors constructed a Japanese NLI dataset focusing on comparatives and evaluated multiple LLMs in zero-shot and few-shot settings.", "result": "LLMs exhibited sensitivity to prompt formats in zero-shot settings, were influenced by gold labels in few-shot examples, and struggled with Japanese-specific linguistic phenomena. Prompts with logical semantic representations improved prediction accuracy.", "conclusion": "LLMs face challenges with Japanese NLI, particularly for tasks involving comparatives, but logical semantic prompts can enhance their performance."}}
{"id": "2509.13633", "pdf": "https://arxiv.org/pdf/2509.13633", "abs": "https://arxiv.org/abs/2509.13633", "authors": ["Jeremy Oon", "Rakhi Manohar Mepparambath", "Ling Feng"], "title": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the significant progress of deep learning models in multitude of\napplications, their adaption in planning and policy related areas remains\nchallenging due to the black-box nature of these models. In this work, we\ndevelop a set of DeepLogit models that follow a novel sequentially constrained\napproach in estimating deep learning models for transport policy analysis. In\nthe first step of the proposed approach, we estimate a convolutional neural\nnetwork (CNN) model with only linear terms, which is equivalent of a\nlinear-in-parameter multinomial logit model. We then estimate other deep\nlearning models by constraining the parameters that need interpretability at\nthe values obtained in the linear-in-parameter CNN model and including higher\norder terms or by introducing advanced deep learning architectures like\nTransformers. Our approach can retain the interpretability of the selected\nparameters, yet provides significantly improved model accuracy than the\ndiscrete choice model. We demonstrate our approach on a transit route choice\nexample using real-world transit smart card data from Singapore. This study\nshows the potential for a unifying approach, where theory-based discrete choice\nmodel (DCM) and data-driven AI models can leverage each other's strengths in\ninterpretability and predictive power. With the availability of larger datasets\nand more complex constructions, such approach can lead to more accurate models\nusing discrete choice models while maintaining its applicability in planning\nand policy-related areas. Our code is available on\nhttps://github.com/jeremyoon/route-choice/ .", "AI": {"tldr": "The paper proposes DeepLogit models for transport policy analysis, which combine interpretability of discrete choice models with the accuracy of deep learning architectures, tested using Singapore transit data.", "motivation": "Deep learning models are highly predictive but lack interpretability, posing challenges for their application in planning and policy areas.", "method": "A sequential approach is proposed, starting with interpretable linear CNNs and progressively adding complex features while constraining key parameters for interpretability.", "result": "The DeepLogit models demonstrate superior predictive power compared to theory-based discrete choice models, validated using transit route choice data.", "conclusion": "This hybrid approach bridges the gap between theory-driven and AI-driven models, offering improved modeling accuracy and interpretability for applications in transport planning and policy areas."}}
{"id": "2509.13399", "pdf": "https://arxiv.org/pdf/2509.13399", "abs": "https://arxiv.org/abs/2509.13399", "authors": ["Tianyu Chen", "Yasi Zhang", "Zhi Zhang", "Peiyu Yu", "Shu Wang", "Zhendong Wang", "Kevin Lin", "Xiaofei Wang", "Zhengyuan Yang", "Linjie Li", "Chung-Ching Lin", "Jianwen Xie", "Oscar Leong", "Lijuan Wang", "Ying Nian Wu", "Mingyuan Zhou"], "title": "EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Tianyu Chen and Yasi Zhang contributed equally; Oscar Leong, Lijuan\n  Wang, Ying Nian Wu, and Mingyuan Zhou advised equally", "summary": "Instruction-based image editing has advanced rapidly, yet reliable and\ninterpretable evaluation remains a bottleneck. Current protocols either (i)\ndepend on paired reference images -- resulting in limited coverage and\ninheriting biases from prior generative models -- or (ii) rely solely on\nzero-shot vision-language models (VLMs), whose prompt-based assessments of\ninstruction following, content consistency, and visual quality are often\nimprecise.\n  To address this, we introduce EdiVal-Agent, an automated, scalable, and\nfine-grained evaluation framework for multi-turn instruction-based editing from\nan object-centric perspective, supported by a suite of expert tools. Given an\nimage, EdiVal-Agent first decomposes it into semantically meaningful objects,\nthen synthesizes diverse, context-aware editing instructions. For evaluation,\nit integrates VLMs with open-vocabulary object detectors to assess instruction\nfollowing, uses semantic-level feature extractors to evaluate content\nconsistency, and leverages human preference models to judge visual quality. We\nshow that combining VLMs with object detectors yields stronger agreement with\nhuman judgments in instruction-following evaluation compared to using VLMs\nalone and CLIP-based metrics. Furthermore, the pipeline's modular design allows\nfuture tools to be seamlessly integrated, enhancing evaluation accuracy over\ntime.\n  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing\nbenchmark covering 9 instruction types and 11 state-of-the-art editing models\nspanning autoregressive (AR) (including Nano Banana, GPT-Image-1),\nflow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be\nused to identify existing failure modes, thereby informing the development of\nthe next generation of editing models. Project page:\nhttps://tianyucodings.github.io/EdiVAL-page/.", "AI": {"tldr": "EdiVal-Agent is introduced to address evaluation challenges in instruction-based image editing by combining vision-language models with expert tools, providing a fine-grained evaluation framework.", "motivation": "Current evaluation methods either suffer from biases or lack precision and interpretable assessments in instruction-based image editing.", "method": "EdiVal-Agent decomposes an image into objects, generates context-aware instructions, and integrates tools like vision-language models, object detectors, and human preference models for evaluation.", "result": "The framework achieves stronger human judgment agreement in instruction-following evaluation and its modular design supports flexible integration of future tools.", "conclusion": "EdiVal-Agent enhances the reliability of image editing evaluation and identifies failure modes to aid in improving editing models."}}
{"id": "2509.13758", "pdf": "https://arxiv.org/pdf/2509.13758", "abs": "https://arxiv.org/abs/2509.13758", "authors": ["Kevin Halim", "Sin G. Teo", "Ruitao Feng", "Zhenpeng Chen", "Yang Gu", "Chong Wang", "Yang Liu"], "title": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "Currently, many large language models (LLMs) are utilized for software\nengineering tasks such as code generation. The emergence of more advanced\nmodels known as large reasoning models (LRMs), such as OpenAI's o3, DeepSeek\nR1, and Qwen3. They have demonstrated the capability of performing multi-step\nreasoning. Despite the advancement in LRMs, little attention has been paid to\nsystematically analyzing the reasoning patterns these models exhibit and how\nsuch patterns influence the generated code. This paper presents a comprehensive\nstudy aimed at investigating and uncovering the reasoning behavior of LRMs\nduring code generation. We prompted several state-of-the-art LRMs of varying\nsizes with code generation tasks and applied open coding to manually annotate\nthe reasoning traces. From this analysis, we derive a taxonomy of LRM reasoning\nbehaviors, encompassing 15 reasoning actions across four phases.\n  Our empirical study based on the taxonomy reveals a series of findings.\nFirst, we identify common reasoning patterns, showing that LRMs generally\nfollow a human-like coding workflow, with more complex tasks eliciting\nadditional actions such as scaffolding, flaw detection, and style checks.\nSecond, we compare reasoning across models, finding that Qwen3 exhibits\niterative reasoning while DeepSeek-R1-7B follows a more linear, waterfall-like\napproach. Third, we analyze the relationship between reasoning and code\ncorrectness, showing that actions such as unit test creation and scaffold\ngeneration strongly support functional outcomes, with LRMs adapting strategies\nbased on task context. Finally, we evaluate lightweight prompting strategies\ninformed by these findings, demonstrating the potential of context- and\nreasoning-oriented prompts to improve LRM-generated code. Our results offer\ninsights and practical implications for advancing automatic code generation.", "AI": {"tldr": "The paper investigates reasoning behaviors in large reasoning models (LRMs) during code generation, presenting a taxonomy and analyzing their patterns, model differences, and relationships with code correctness.", "motivation": "To explore and systematically analyze the reasoning patterns exhibited by LRMs in code generation and their impact on generated code.", "method": "The authors use state-of-the-art LRMs, prompt them with code tasks, apply open coding for manual reasoning trace annotation, and derive a taxonomy encompassing 15 actions across four reasoning phases.", "result": "The study identifies reasoning patterns like scaffolding and flaw detection, compares reasoning styles among models, links certain reasoning actions to code correctness, and tests prompting strategies informed by their findings.", "conclusion": "Insights from the taxonomy and annotations offer practical implications for improving LRM-focused code generation through tailored prompts and understanding reasoning behaviors."}}
{"id": "2509.13501", "pdf": "https://arxiv.org/pdf/2509.13501", "abs": "https://arxiv.org/abs/2509.13501", "authors": ["Hossein Gholampour", "Logan E. Beaver"], "title": "Trajectory Tracking with Reachability-Guided Quadratic Programming and Freeze-Resume", "categories": ["cs.RO"], "comment": null, "summary": "Many robotic systems must follow planned paths yet pause safely and resume\nwhen people or objects intervene. We present an output-space method for systems\nwhose tracked output can be feedback-linearized to a double integrator (e.g.,\nmanipulators). The approach has two parts. Offline, we perform a pre-run\nreachability check to verify that the motion plan respects speed and\nacceleration magnitude limits. Online, we apply a quadratic program to track\nthe motion plan under the same limits. We use a one-step reachability test to\nbound the maximum disturbance the system is capable of rejecting. When the\nstate coincides with the reference path we recover perfect tracking in the\ndeterministic case, and we correct errors using a KKT-inspired weight. We\ndemonstrate that safety stops and unplanned deviations are handled efficiently,\nand the system returns to the motion plan without replanning. We demonstrate\nour system's improved performance over pure pursuit in simulation.", "AI": {"tldr": "The paper presents an output-space control method for robotic systems to handle path interruptions safely and efficiently return to planned paths.", "motivation": "The authors aim to enable robotic systems to handle interruptions caused by external factors (e.g., people or objects) while ensuring safety and maintaining motion plan adherence.", "method": "The method involves offline reachability checks for speed/acceleration limits and an online quadratic program to track motion plans. A one-step reachability test ensures error correction with a KKT-inspired weight.", "result": "The system efficiently handles safety stops and unplanned deviations, allowing the robot to resume planned paths without replanning. Improved performance is demonstrated over pure pursuit in simulations.", "conclusion": "The proposed method enhances safety and efficiency in robotic motion planning, ensuring reliable return to planned paths after interruptions."}}
{"id": "2509.13855", "pdf": "https://arxiv.org/pdf/2509.13855", "abs": "https://arxiv.org/abs/2509.13855", "authors": ["Shamsiiat Abdurakhmanova", "Alex Jung"], "title": "Graph-Regularized Learning of Gaussian Mixture Models", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in\ndistributed settings with heterogeneous and limited local data. The method\nexploits a provided similarity graph to guide parameter sharing among nodes,\navoiding the transfer of raw data. The resulting model allows for flexible\naggregation of neighbors' parameters and outperforms both centralized and\nlocally trained GMMs in heterogeneous, low-sample regimes.", "AI": {"tldr": "The paper proposes a graph-regularized learning approach for Gaussian Mixture Models (GMMs), optimizing parameter sharing in distributed environments with heterogeneous, limited data.", "motivation": "To address challenges in distributed Gaussian Mixture Model learning where there is heterogeneity in data and limited samples at local nodes, and traditional methods either require centralized data transfer or fail to perform well.", "method": "The method incorporates a similarity graph to regularize inter-node parameter sharing without transferring raw data, enabling flexible aggregation and improved model performance.", "result": "The graph-regularized GMM approach demonstrated superior performance against traditional centralized and locally trained GMMs in scenarios featuring heterogeneous and sparse data.", "conclusion": "Graph-based regularization in distributed model training effectively balances parameter sharing and privacy, yielding better outcomes in challenging low-sample, distributed environments."}}
{"id": "2509.13364", "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "categories": ["cs.AI"], "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "The paper introduces the Asterisk Operator ($\\ast$-operator), a framework for structured reasoning tasks based on local and parallel state evolution processes informed by relational graphs.", "motivation": "To provide an efficient computational framework for abstract reasoning tasks with universal and convergent reasoning capabilities.", "method": "By using the $\\ast$-operator, which operates via Adjacency-Structured Parallel Propagation (ASPP), to formalize reasoning tasks. Mathematical analysis and experiments demonstrate its properties.", "result": "The $\\ast$-operator achieves superior results in reasoning tasks, including 100% accuracy on ARC2 validation with only 6M parameters.", "conclusion": "The $\\ast$-operator is a highly effective tool for neural-symbolic reasoning, proving its universality, efficiency, and competitive performance in structured reasoning tasks."}}
{"id": "2509.13696", "pdf": "https://arxiv.org/pdf/2509.13696", "abs": "https://arxiv.org/abs/2509.13696", "authors": ["Iyadh Ben Cheikh Larbi", "Ajay Madhavan Ravichandran", "Aljoscha Burchardt", "Roland Roller"], "title": "Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes", "categories": ["cs.CL"], "comment": "Presented and published at BioCreative IX", "summary": "Large language models (LLMs) excel at text generation, but their ability to\nhandle clinical classification tasks involving structured data, such as time\nseries, remains underexplored. In this work, we adapt instruction-tuned LLMs\nusing DSPy-based prompt optimization to process clinical notes and structured\nEHR inputs jointly. Our results show that this approach achieves performance on\npar with specialized multimodal systems while requiring less complexity and\noffering greater adaptability across tasks.", "AI": {"tldr": "The paper explores adapting instruction-tuned Large Language Models (LLMs) using DSPy-based optimization to handle clinical classification tasks involving both structured time-series data and clinical notes.", "motivation": "To investigate whether instruction-tuned Large Language Models can handle multimodal inputs, such as clinical notes and structured EHR data, and achieve competitive performance with less complexity.", "method": "The authors adapt instruction-tuned LLMs using DSPy-based prompt optimization to jointly process clinical notes and structured Electronic Health Record (EHR) data.", "result": "The adapted LLMs achieve performance comparable to specialized multimodal systems while being less complex and more versatile across tasks.", "conclusion": "Instruction-tuned LLMs optimized through DSPy can effectively handle structured and unstructured clinical data jointly, showcasing adaptability and eliminating the need for complex specialized systems."}}
{"id": "2509.13634", "pdf": "https://arxiv.org/pdf/2509.13634", "abs": "https://arxiv.org/abs/2509.13634", "authors": ["Md Bokhtiar Al Zami", "Md Raihan Uddin", "Dinh C. Nguyen"], "title": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs", "categories": ["cs.LG", "cs.CR"], "comment": "15 pages, under revision at IEEE Internet of Things Journal", "summary": "Federated learning (FL) has gained popularity as a privacy-preserving method\nof training machine learning models on decentralized networks. However to\nensure reliable operation of UAV-assisted FL systems, issues like as excessive\nenergy consumption, communication inefficiencies, and security vulnerabilities\nmust be solved. This paper proposes an innovative framework that integrates\nDigital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to\ntackle these challenges. UAVs act as mobile base stations, allowing scattered\ndevices to train FL models locally and upload model updates for aggregation. By\nincorporating DT technology, our approach enables real-time system monitoring\nand predictive maintenance, improving UAV network efficiency. Additionally,\nZero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification\nwithout exposing sensitive data. To optimize energy efficiency and resource\nmanagement, we introduce a dynamic allocation strategy that adjusts UAV flight\npaths, transmission power, and processing rates based on network conditions.\nUsing block coordinate descent and convex optimization techniques, our method\nsignificantly reduces system energy consumption by up to 29.6% compared to\nconventional FL approaches. Simulation results demonstrate improved learning\nperformance, security, and scalability, positioning this framework as a\npromising solution for next-generation UAV-based intelligent networks.", "AI": {"tldr": "The paper proposes a framework combining Digital Twin technology and Zero-Knowledge Federated Learning (zkFed) to enhance the efficiency, security, and reliability of UAV-assisted federated learning.", "motivation": "To address challenges like excessive energy consumption, communication inefficiencies, and security vulnerabilities in UAV-assisted federated learning systems.", "method": "The framework integrates UAVs as mobile base stations, Digital Twin technology for real-time monitoring, and Zero-Knowledge Proofs for model verification. A dynamic allocation strategy adjusts UAV flight paths, transmission power, and processing rates using convex optimization techniques.", "result": "The proposed method reduces energy consumption by up to 29.6% and improves learning performance, security, and scalability.", "conclusion": "This framework offers a promising solution for next-generation, intelligent, UAV-based federated learning networks by addressing energy, efficiency, and security issues effectively."}}
{"id": "2509.13414", "pdf": "https://arxiv.org/pdf/2509.13414", "abs": "https://arxiv.org/abs/2509.13414", "authors": ["Nikhil Keetha", "Norman M\u00fcller", "Johannes Sch\u00f6nberger", "Lorenzo Porzi", "Yuchen Zhang", "Tobias Fischer", "Arno Knapitsch", "Duncan Zauss", "Ethan Weber", "Nelson Antunes", "Jonathon Luiten", "Manuel Lopez-Antequera", "Samuel Rota Bul\u00f2", "Christian Richardt", "Deva Ramanan", "Sebastian Scherer", "Peter Kontschieder"], "title": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project Page: https://map-anything.github.io/", "summary": "We introduce MapAnything, a unified transformer-based feed-forward model that\ningests one or more images along with optional geometric inputs such as camera\nintrinsics, poses, depth, or partial reconstructions, and then directly\nregresses the metric 3D scene geometry and cameras. MapAnything leverages a\nfactored representation of multi-view scene geometry, i.e., a collection of\ndepth maps, local ray maps, camera poses, and a metric scale factor that\neffectively upgrades local reconstructions into a globally consistent metric\nframe. Standardizing the supervision and training across diverse datasets,\nalong with flexible input augmentation, enables MapAnything to address a broad\nrange of 3D vision tasks in a single feed-forward pass, including uncalibrated\nstructure-from-motion, calibrated multi-view stereo, monocular depth\nestimation, camera localization, depth completion, and more. We provide\nextensive experimental analyses and model ablations demonstrating that\nMapAnything outperforms or matches specialist feed-forward models while\noffering more efficient joint training behavior, thus paving the way toward a\nuniversal 3D reconstruction backbone.", "AI": {"tldr": "This paper introduces \"MapAnything,\" a unified transformer-based model that performs multiple 3D vision tasks using images and optional geometric inputs.", "motivation": "To create a universal model capable of performing diverse 3D vision tasks efficiently, in a unified and standardized manner.", "method": "The model uses a factored multi-view scene geometry representation and leverages standardized training across datasets while allowing flexible input augmentation.", "result": "MapAnything matches or outperforms specialized models and exhibits efficient joint training for a variety of 3D vision challenges.", "conclusion": "MapAnything establishes a framework that could serve as a versatile backbone for 3D reconstruction tasks, achieving state-of-the-art results across multiple applications."}}
{"id": "2509.13782", "pdf": "https://arxiv.org/pdf/2509.13782", "abs": "https://arxiv.org/abs/2509.13782", "authors": ["Yu Ge", "Linna Xie", "Zhong Li", "Yu Pei", "Tian Zhang"], "title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "categories": ["cs.SE", "cs.AI", "cs.MA", "D.2.2; I.2.1"], "comment": "20 pages, 6 figures", "summary": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly\nemployed to automate complex real-world problems, such as programming and\nscientific discovery. Despite their promising, MASs are not without their\nflaws. However, failure attribution in MASs - pinpointing the specific agent\nactions responsible for failures - remains underexplored and labor-intensive,\nposing significant challenges for debugging and system improvement. To bridge\nthis gap, we propose FAMAS, the first spectrum-based failure attribution\napproach for MASs, which operates through systematic trajectory replay and\nabstraction, followed by spectrum analysis.The core idea of FAMAS is to\nestimate, from variations across repeated MAS executions, the likelihood that\neach agent action is responsible for the failure. In particular, we propose a\nnovel suspiciousness formula tailored to MASs, which integrates two key factor\ngroups, namely the agent behavior group and the action behavior group, to\naccount for the agent activation patterns and the action activation patterns\nwithin the execution trajectories of MASs. Through expensive evaluations\nagainst 12 baselines on the Who and When benchmark, FAMAS demonstrates superior\nperformance by outperforming all the methods in comparison.", "AI": {"tldr": "The paper introduces FAMAS, the first spectrum-based failure attribution method for Multi-Agent Systems (MASs), significantly improving debugging by systematically identifying responsible agent actions.", "motivation": "To address the challenges of failure attribution in Multi-Agent Systems (MASs), which makes debugging labor-intensive and hampers system improvement.", "method": "FAMAS uses systematic trajectory replay and abstraction combined with spectrum analysis. A novel suspiciousness formula based on agent and action activation patterns assesses likely failure causes.", "result": "FAMAS outperforms 12 benchmark methods in failure attribution accuracy, showing superior reliability and effectiveness.", "conclusion": "FAMAS provides a systematic and efficient way to debug MASs, enabling improvements by reliably identifying failure-causing agent actions."}}
{"id": "2509.13534", "pdf": "https://arxiv.org/pdf/2509.13534", "abs": "https://arxiv.org/abs/2509.13534", "authors": ["Chunxin Zheng", "Kai Chen", "Zhihai Bi", "Yulin Li", "Liang Pan", "Jinni Zhou", "Haoang Li", "Jun Ma"], "title": "Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning", "categories": ["cs.RO"], "comment": null, "summary": "Whole-body manipulation (WBM) for humanoid robots presents a promising\napproach for executing embracing tasks involving bulky objects, where\ntraditional grasping relying on end-effectors only remains limited in such\nscenarios due to inherent stability and payload constraints. This paper\nintroduces a reinforcement learning framework that integrates a pre-trained\nhuman motion prior with a neural signed distance field (NSDF) representation to\nachieve robust whole-body embracing. Our method leverages a teacher-student\narchitecture to distill large-scale human motion data, generating kinematically\nnatural and physically feasible whole-body motion patterns. This facilitates\ncoordinated control across the arms and torso, enabling stable multi-contact\ninteractions that enhance the robustness in manipulation and also the load\ncapacity. The embedded NSDF further provides accurate and continuous geometric\nperception, improving contact awareness throughout long-horizon tasks. We\nthoroughly evaluate the approach through comprehensive simulations and\nreal-world experiments. The results demonstrate improved adaptability to\ndiverse shapes and sizes of objects and also successful sim-to-real transfer.\nThese indicate that the proposed framework offers an effective and practical\nsolution for multi-contact and long-horizon WBM tasks of humanoid robots.", "AI": {"tldr": "This paper focuses on a novel reinforcement learning framework for humanoid robots that combines human motion prior and neural signed distance field representation to achieve robust whole-body manipulation for bulky objects.", "motivation": "Traditional end-effector grasping methods for humanoid robots face limitations in scenarios involving bulky objects due to stability and payload constraints.", "method": "The paper uses a reinforcement learning framework with a teacher-student architecture that integrates a human motion prior and a neural signed distance field. This enables kinematically natural, coordinated, and physically feasible whole-body motion for embracing tasks.", "result": "The approach demonstrated improved adaptability to objects of varying shapes and sizes in simulations and real-world experiments, achieving successful sim-to-real transfer in tasks involving humanoid robots.", "conclusion": "The proposed framework is an effective and practical solution for enabling stable, multi-contact, and long-horizon whole-body manipulation tasks in humanoid robots."}}
{"id": "2509.13933", "pdf": "https://arxiv.org/pdf/2509.13933", "abs": "https://arxiv.org/abs/2509.13933", "authors": ["Qiyue Li", "Yingxin Liu", "Hang Qi", "Jieping Luo", "Zhizhang Liu", "Jingjin Wu"], "title": "Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We consider the client selection problem in wireless Federated Learning (FL),\nwith the objective of reducing the total required time to achieve a certain\nlevel of learning accuracy. Since the server cannot observe the clients'\ndynamic states that can change their computation and communication efficiency,\nwe formulate client selection as a restless multi-armed bandit problem. We\npropose a scalable and efficient approach called the Whittle Index Learning in\nFederated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and\nupdate an approximated Whittle index associated with each client, and then\nselects the clients with the highest indices. Compared to existing approaches,\nWILF-Q does not require explicit knowledge of client state transitions or data\ndistributions, making it well-suited for deployment in practical FL settings.\nExperiment results demonstrate that WILF-Q significantly outperforms existing\nbaseline policies in terms of learning efficiency, providing a robust and\nefficient approach to client selection in wireless FL.", "AI": {"tldr": "The paper tackles the challenge of selecting clients in wireless Federated Learning (FL) based on dynamic states, proposing an efficient and scalable Q-learning-based solution for better learning efficiency.", "motivation": "To address the inefficiency in client selection for wireless FL by considering dynamic, state-dependent computation and communication constraints.", "method": "The authors introduce WILF-Q, a Q-learning-based method to approximate clients' Whittle indices, enabling adaptive client selection without explicit knowledge of state transitions or data distributions.", "result": "Experiments show WILF-Q significantly improves learning efficiency compared to existing baseline approaches.", "conclusion": "WILF-Q offers a robust solution to optimize client selection in real-world wireless FL scenarios, reducing computation time while maintaining high accuracy."}}
{"id": "2509.13368", "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "categories": ["cs.AI", "cs.LG"], "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "This paper introduces $Agent^2$, an automated reinforcement learning (RL) design framework driven by large language models (LLMs) that significantly improves agent development efficiency and performance.", "motivation": "To address the challenges of extensive expertise, lengthy iterations, and high failure rates in RL agent design.", "method": "The proposed framework uses a dual-agent architecture, where the Generator Agent autonomously designs RL agents and the Target Agent executes the RL solutions. The process is divided into MDP modeling and algorithmic optimization.", "result": "$Agent^2$ demonstrates up to 55% performance improvements compared to manually designed solutions across various benchmarks like MuJoCo, MetaDrive, MPE, and SMAC.", "conclusion": "This work establishes automation for RL agent design, setting a new paradigm where intelligent agents build and optimize other agents, enabling scalable and efficient AI solutions."}}
{"id": "2509.13702", "pdf": "https://arxiv.org/pdf/2509.13702", "abs": "https://arxiv.org/abs/2509.13702", "authors": ["Xiao Zheng"], "title": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) hallucination is a significant barrier to their\nreliable deployment. Current methods like Retrieval-Augmented Generation (RAG)\nare often reactive. We introduce **Dynamic Self-reinforcing Calibration for\nHallucination Suppression (DSCC-HS)**, a novel, proactive framework that\nintervenes during autoregressive decoding. Inspired by dual-process cognitive\ntheory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a\nFactual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During\ninference, these proxies dynamically steer a large target model by injecting a\nreal-time steering vector, which is the difference between FAP and HDP logits,\nat each decoding step. This plug-and-play approach requires no modification to\nthe target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS\nachieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%\nFactual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained\nthe highest FActScore of 46.50. These results validate DSCC-HS as a principled\nand efficient solution for enhancing LLM factuality.", "AI": {"tldr": "The paper introduces DSCC-HS, a novel framework to proactively suppress hallucination in LLMs using proxy models during decoding, achieving state-of-the-art results.", "motivation": "LLMs often suffer from hallucination issues, making their deployment unreliable. Existing reactive methods like RAG are not sufficient for real-time intervention.", "method": "The proposed DSCC-HS framework uses a compact proxy model engineered as a Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During inference, these proxies generate a steering vector in real-time to adjust LLM output dynamically, without modifying the target model.", "result": "DSCC-HS outperformed existing methods, achieving a 99.2% Factual Consistency Rate on TruthfulQA and the highest FActScore of 46.50 on BioGEN.", "conclusion": "DSCC-HS provides an efficient, plug-and-play solution to improve LLM factual accuracy and can be considered a state-of-the-art approach for suppressing hallucination during autoregressive decoding."}}
{"id": "2509.13636", "pdf": "https://arxiv.org/pdf/2509.13636", "abs": "https://arxiv.org/abs/2509.13636", "authors": ["Yasin Hasanpoor", "Bahram Tarvirdizadeh", "Khalil Alipour", "Mohammad Ghamari"], "title": "Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images", "categories": ["cs.LG"], "comment": "14 pages 7 images 2 tables", "summary": "This study introduces a novel method that transforms multimodal physiological\nsignalsphotoplethysmography (PPG), galvanic skin response (GSR), and\nacceleration (ACC) into 2D image matrices to enhance stress detection using\nconvolutional neural networks (CNNs). Unlike traditional approaches that\nprocess these signals separately or rely on fixed encodings, our technique\nfuses them into structured image representations that enable CNNs to capture\ntemporal and cross signal dependencies more effectively. This image based\ntransformation not only improves interpretability but also serves as a robust\nform of data augmentation. To further enhance generalization and model\nrobustness, we systematically reorganize the fused signals into multiple\nformats, combining them in a multi stage training pipeline. This approach\nsignificantly boosts classification performance. While demonstrated here in the\ncontext of stress detection, the proposed method is broadly applicable to any\ndomain involving multimodal physiological signals, paving the way for more\naccurate, personalized, and real time health monitoring through wearable\ntechnologies.", "AI": {"tldr": "The study proposes a method to turn multimodal physiological signals into 2D image matrices, enabling CNN-based stress detection with improved accuracy and interpretability.", "motivation": "Current methods for stress detection and analysis of multimodal physiological signals are limited in capturing temporal and cross-signal dependencies.", "method": "The paper combines multimodal physiological signals into structured 2D image representations and uses CNNs to process these augmented inputs. A multi-stage training pipeline is applied to enhance model robustness.", "result": "The approach significantly improves classification performance and generalization in stress detection.", "conclusion": "This novel signal-to-image transformation method enhances stress detection robustness and is broadly applicable to health monitoring domains relying on multimodal signals."}}
{"id": "2509.13474", "pdf": "https://arxiv.org/pdf/2509.13474", "abs": "https://arxiv.org/abs/2509.13474", "authors": ["Yujia Lin", "Nicholas Evans"], "title": "Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization", "categories": ["cs.CV"], "comment": null, "summary": "Ensuring accurate localization of robots in environments without GPS\ncapability is a challenging task. Visual Place Recognition (VPR) techniques can\npotentially achieve this goal, but existing RGB-based methods are sensitive to\nchanges in illumination, weather, and other seasonal changes. Existing\ncross-modal localization methods leverage the geometric properties of RGB\nimages and 3D LiDAR maps to reduce the sensitivity issues highlighted above.\nCurrently, state-of-the-art methods struggle in complex scenes, fine-grained or\nhigh-resolution matching, and situations where changes can occur in viewpoint.\nIn this work, we introduce a framework we call Semantic-Enhanced Cross-Modal\nPlace Recognition (SCM-PR) that combines high-level semantics utilizing RGB\nimages for robust localization in LiDAR maps. Our proposed method introduces: a\nVMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature\nFusion (SAFF) module for using both place descriptors and segmentation masks;\nLiDAR descriptors that incorporate both semantics and geometry; and a\ncross-modal semantic attention mechanism in NetVLAD to improve matching.\nIncorporating the semantic information also was instrumental in designing a\nMulti-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in\na contrastive learning framework. Our experimental work on the KITTI and\nKITTI-360 datasets show that SCM-PR achieves state-of-the-art performance\ncompared to other cross-modal place recognition methods.", "AI": {"tldr": "This paper focuses on enhancing cross-modal localization by integrating semantic information into RGB and LiDAR modalities. A new framework called SCM-PR is introduced to boost visual place recognition in GPS-denied environments.", "motivation": "To address the challenges of robot localization in environments without GPS, particularly overcoming issues like sensitivity to illumination, weather, seasonal changes, and viewpoint variations.", "method": "The proposed SCM-PR framework introduces a VMamba backbone for RGB image feature extraction, a Semantic-Aware Feature Fusion (SAFF) module, semantic-augmented LiDAR descriptors, and cross-modal semantic attention in NetVLAD. It utilizes contrastive learning and multi-view semantic-geometric matching for robust localization.", "result": "Experiments on the KITTI and KITTI-360 datasets demonstrate that SCM-PR outperforms existing cross-modal place recognition methods in achieving better localization accuracy.", "conclusion": "SCM-PR effectively addresses previous challenges in visual place recognition by leveraging semantic and geometric information, setting new benchmarks for cross-modal localization methods in GPS-denied environments."}}
{"id": "2509.13852", "pdf": "https://arxiv.org/pdf/2509.13852", "abs": "https://arxiv.org/abs/2509.13852", "authors": ["Yulun Wu", "Guangba Yu", "Zhihan Jiang", "Yichen Li", "Michael R. Lyu"], "title": "Trace Sampling 2.0: Code Knowledge Enhanced Span-level Sampling for Distributed Tracing", "categories": ["cs.SE"], "comment": null, "summary": "Distributed tracing is an essential diagnostic tool in microservice systems,\nbut the sheer volume of traces places a significant burden on backend storage.\nA common approach to mitigating this issue is trace sampling, which selectively\nretains traces based on specific criteria, often preserving only anomalous\nones. However, this method frequently discards valuable information, including\nnormal traces that are essential for comparative analysis. To address this\nlimitation, we introduce Trace Sampling 2.0, which operates at the span level\nwhile maintaining trace structure consistency. This approach allows for the\nretention of all traces while significantly reducing storage overhead. Based on\nthis concept, we design and implement Autoscope, a span-level sampling method\nthat leverages static analysis to extract execution logic, ensuring that\ncritical spans are preserved without compromising structural integrity. We\nevaluated Autoscope on two open-source microservices. Our results show that it\nreduces trace size by 81.2% while maintaining 98.1% faulty span coverage,\noutperforming existing trace-level sampling methods. Furthermore, we\ndemonstrate its effectiveness in root cause analysis, achieving an average\nimprovement of 8.3%. These findings indicate that Autoscope can significantly\nenhance observability and storage efficiency in microservices, offering a\nrobust solution for performance monitoring.", "AI": {"tldr": "Distributed tracing in microservices generates extensive data, and traditional sampling methods discard valuable information. Trace Sampling 2.0, through the Autoscope framework, reduces storage needs while preserving critical diagnostic data effectively.", "motivation": "Distributed tracing in microservices leads to an overwhelming volume of data, making storage and analysis inefficient. Current sampling methods often discard useful information such as normal traces necessary for comparison.", "method": "The paper introduces Autoscope, a span-level trace sampling mechanism based on static analysis. Autoscope extracts execution logic and ensures critical spans are preserved while reducing storage overhead and retaining trace structure.", "result": "Autoscope reduces trace size by 81.2% while maintaining 98.1% coverage of faulty spans. It outperforms traditional trace-level sampling methods and improves root cause analysis accuracy by an average of 8.3%.", "conclusion": "Autoscope significantly improves observability and storage efficiency in microservice systems while maintaining diagnostic integrity, offering a better framework for performance monitoring."}}
{"id": "2509.13541", "pdf": "https://arxiv.org/pdf/2509.13541", "abs": "https://arxiv.org/abs/2509.13541", "authors": ["Ayberk Acar", "Fangjie Li", "Hao Li", "Lidia Al-Zogbi", "Kanyifeechukwu Jane Oguine", "Susheela Sharma Stern", "Jesse F. d'Almeida", "Robert J. Webster III", "Ipek Oguz", "Jie Ying Wu"], "title": "Semantic 3D Reconstructions with SLAM for Central Airway Obstruction", "categories": ["cs.RO", "cs.CV"], "comment": "5 pages, 2 figures, 1 table", "summary": "Central airway obstruction (CAO) is a life-threatening condition with\nincreasing incidence, caused by tumors in and outside of the airway.\nTraditional treatment methods such as bronchoscopy and electrocautery can be\nused to remove the tumor completely; however, these methods carry a high risk\nof complications. Recent advances allow robotic interventions with lesser risk.\nThe combination of robot interventions with scene understanding and mapping\nalso opens up the possibilities for automation. We present a novel pipeline\nthat enables real-time, semantically informed 3D reconstructions of the central\nairway using monocular endoscopic video.\n  Our approach combines DROID-SLAM with a segmentation model trained to\nidentify obstructive tissues. The SLAM module reconstructs the 3D geometry of\nthe airway in real time, while the segmentation masks guide the annotation of\nobstruction regions within the reconstructed point cloud. To validate our\npipeline, we evaluate the reconstruction quality using ex vivo models.\n  Qualitative and quantitative results show high similarity between ground\ntruth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By\nintegrating segmentation directly into the SLAM workflow, our system produces\nannotated 3D maps that highlight clinically relevant regions in real time.\nHigh-speed capabilities of the pipeline allows quicker reconstructions compared\nto previous work, reflecting the surgical scene more accurately.\n  To the best of our knowledge, this is the first work to integrate semantic\nsegmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our\nframework is modular and can generalize to other anatomies or procedures with\nminimal changes, offering a promising step toward autonomous robotic\ninterventions.", "AI": {"tldr": "The paper introduces a novel pipeline that generates real-time, semantically informed 3D reconstructions of central airways using monocular endoscopic video. It combines a SLAM (Simultaneous Localization and Mapping) method with a segmentation model for accurate and quick identification of obstructive tissues.", "motivation": "Central Airway Obstruction (CAO) is a critical condition caused by tumors that carry severe risks when treated with traditional methods. The authors aim to address the shortcomings of current medical interventions by leveraging robotic automation and scene understanding.", "method": "The proposed method integrates DROID-SLAM for real-time 3D reconstruction of the airway with a segmentation model designed to identify obstructive tissues. Together, these components annotate obstruction regions in the 3D geometry of the airway.", "result": "The pipeline demonstrates high similarity between its 3D reconstructions and ground truth CT scans, achieving a 0.62 mm Chamfer distance. It is faster and more accurate compared to previous methods, producing real-time annotated 3D maps that are clinically relevant.", "conclusion": "This work is pioneering in combining semantic segmentation with real-time SLAM for CAO scenarios using endoscopic video. It establishes a modular framework that generalizes across anatomical regions, signaling an advance toward autonomous robotic surgical interventions."}}
{"id": "2509.14098", "pdf": "https://arxiv.org/pdf/2509.14098", "abs": "https://arxiv.org/abs/2509.14098", "authors": ["Doru Thom Popovici", "Harlin Lee", "Mauro Del Ben", "Naoki Yoshioka", "Nobuyasu Ito", "Katherine Klymko", "Daan Camps", "Anastasiia Butko"], "title": "A Closeness Centrality-based Circuit Partitioner for Quantum Simulations", "categories": ["quant-ph", "cs.DC"], "comment": "14 pages, 10 figures", "summary": "Simulating quantum circuits (QC) on high-performance computing (HPC) systems\nhas become an essential method to benchmark algorithms and probe the potential\nof large-scale quantum computation despite the limitations of current quantum\nhardware. However, these simulations often require large amounts of resources,\nnecessitating the use of large clusters with thousands of compute nodes and\nlarge memory footprints. In this work, we introduce an end-to-end framework\nthat provides an efficient partitioning scheme for large-scale QCs alongside a\nflexible code generator to offer a portable solution that minimizes data\nmovement between compute nodes. By formulating the distribution of quantum\nstates and circuits as a graph problem, we apply closeness centrality to assess\ngate importance and design a fast, scalable partitioning method. The resulting\npartitions are compiled into highly optimized codes that run seamlessly on a\nwide range of supercomputers, providing critical insights into the performance\nand scalability of quantum algorithm simulations.", "AI": {"tldr": "This paper proposes an efficient end-to-end framework to simulate large-scale quantum circuits on HPC systems by minimizing data movement and optimizing code generation.", "motivation": "To address the challenges of simulating quantum circuits due to resource-intensive requirements and hardware limitations on current quantum systems.", "method": "The authors model the distribution of quantum states and circuits as a graph problem, applying closeness centrality to evaluate gate importance, and implement a scalable partitioning method for simulation. A code generator ensures portability across various supercomputers.", "result": "The framework efficiently runs quantum circuit simulations while reducing inter-node data movement and optimizing performance on diverse HPC platforms.", "conclusion": "This approach provides a scalable and resource-efficient solution for simulating quantum circuits, improving the practicality of large-scale quantum computations on HPC systems."}}
{"id": "2509.13379", "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "This paper evaluates 16 state-of-the-art Vision-Language Models (VLMs) for their uncertainty quantification across multimodal datasets.", "motivation": "While VLMs perform well in complex visual understanding, their ability to quantify uncertainty has not been adequately studied.", "method": "The study benchmarks uncertainty using 16 VLMs across 6 multimodal datasets and 3 scoring functions in various tasks.", "result": "Larger models show better uncertainty quantification, with higher certainty correlating to greater accuracy, but struggle in mathematical and reasoning tasks.", "conclusion": "This study lays the groundwork for assessing uncertainty in sophisticated multimodal systems."}}
{"id": "2509.13706", "pdf": "https://arxiv.org/pdf/2509.13706", "abs": "https://arxiv.org/abs/2509.13706", "authors": ["Peter Beidler", "Mark Nguyen", "Kevin Lybarger", "Ola Holmberg", "Eric Ford", "John Kang"], "title": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "PURPOSE: Incident reports are an important tool for safety and quality\nimprovement in healthcare, but manual review is time-consuming and requires\nsubject matter expertise. Here we present a natural language processing (NLP)\nscreening tool to detect high-severity incident reports in radiation oncology\nacross two institutions.\n  METHODS AND MATERIALS: We used two text datasets to train and evaluate our\nNLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA\nSAFRON (SF), all of which had severity scores labeled by clinical content\nexperts. We trained and evaluated two types of models: baseline support vector\nmachines (SVM) and BlueBERT which is a large language model pretrained on\nPubMed abstracts and hospitalized patient data. We assessed for\ngeneralizability of our model in two ways. First, we evaluated models trained\nusing Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that\nwas first fine-tuned on Inst.-train then on SF-train before testing on SF-test\nset. To further analyze model performance, we also examined a subset of 59\nreports from our Inst. dataset, which were manually edited for clarity.\n  RESULTS Classification performance on the Inst. test achieved AUROC 0.82\nusing SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,\nperformance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56\nusing BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,\nimproved the performance on SF test to AUROC 0.78. Performance of SVM, and\nBlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and\n0.74) was similar to human performance (AUROC 0.81).\n  CONCLUSION: In summary, we successfully developed cross-institution NLP\nmodels on incident report text from radiation oncology centers. These models\nwere able to detect high-severity reports similarly to humans on a curated\ndataset.", "AI": {"tldr": "This study introduces an NLP tool that uses BlueBERT and SVM to detect high-severity incident reports in radiation oncology.", "motivation": "To address the time-intensive and expert-driven manual review of incident reports by developing an automated system.", "method": "NLP models (SVM and BlueBERT) were trained and evaluated on datasets from two institutions, with a cross-institution transfer learning component.", "result": "BlueBERT_TRANSFER achieved significant improvement in cross-institutional performance, nearing human-level accuracy on curated reports.", "conclusion": "NLP models demonstrated potential for cross-institutional use in detecting high-severity reports efficiently, comparable to human expertise in certain settings."}}
{"id": "2509.13642", "pdf": "https://arxiv.org/pdf/2509.13642", "abs": "https://arxiv.org/abs/2509.13642", "authors": ["Zirun Guo", "Feng Zhang", "Kai Jia", "Tao Jin"], "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that\nreframes interleaved image-text generation as a tool-use problem. LLM-I is\ndesigned to overcome the \"one-tool\" bottleneck of current unified models, which\nare limited to synthetic imagery and struggle with tasks requiring factual\ngrounding or programmatic precision. Our framework empowers a central LLM or\nMLLM agent to intelligently orchestrate a diverse toolkit of specialized visual\ntools, including online image search, diffusion-based generation, code\nexecution, and image editing. The agent is trained to select and apply these\ntools proficiently via a Reinforcement Learning (RL) framework that features a\nhybrid reward system combining rule-based logic with judgments from LLM and\nMLLM evaluators. Trained on a diverse new dataset using four different model\nbackbones, LLM-I demonstrates state-of-the-art performance, outperforming\nexisting methods by a large margin across four benchmarks. We also introduce a\nnovel test-time scaling strategy that provides further performance gains.\nProject Page: https://github.com/ByteDance-BandAI/LLM-I.", "AI": {"tldr": "LLM-Interleaved (LLM-I) is a framework using a central language model to coordinate diverse visual tools for interleaved image-text generation, achieving state-of-the-art results.", "motivation": "To address the limitations of \"one-tool\" unified models incapable of handling tasks like factual grounding and programmatic precision.", "method": "The framework employs a central LLM or MLLM agent trained via Reinforcement Learning to orchestrate diverse visual tools like image search and editing.", "result": "LLM-I achieved state-of-the-art performance by outperforming existing methods on four benchmarks after being trained with diverse datasets.", "conclusion": "LLM-I is a powerful and versatile framework for interleaved image-text tasks, significantly surpassing current methods in performance metrics."}}
{"id": "2509.13482", "pdf": "https://arxiv.org/pdf/2509.13482", "abs": "https://arxiv.org/abs/2509.13482", "authors": ["Hao Xu", "Xiaolin Wu", "Xi Zhang"], "title": "Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization", "categories": ["cs.CV"], "comment": "Code available at https://github.com/hxu160/SALVQ", "summary": "3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its\nphotorealistic rendering quality and real-time performance, but it generates\nmassive amounts of data. Hence compressing 3DGS data is necessary for the cost\neffectiveness of 3DGS models. Recently, several anchor-based neural compression\nmethods have been proposed, achieving good 3DGS compression performance.\nHowever, they all rely on uniform scalar quantization (USQ) due to its\nsimplicity. A tantalizing question is whether more sophisticated quantizers can\nimprove the current 3DGS compression methods with very little extra overhead\nand minimal change to the system. The answer is yes by replacing USQ with\nlattice vector quantization (LVQ). To better capture scene-specific\ncharacteristics, we optimize the lattice basis for each scene, improving LVQ's\nadaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a\nbalance between the R-D efficiency of vector quantization and the low\ncomplexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS\ncompression architectures, enhancing their R-D performance with minimal\nmodifications and computational overhead. Moreover, by scaling the lattice\nbasis vectors, SALVQ can dynamically adjust lattice density, enabling a single\nmodel to accommodate multiple bit rate targets. This flexibility eliminates the\nneed to train separate models for different compression levels, significantly\nreducing training time and memory consumption.", "AI": {"tldr": "The paper proposes a scene-adaptive lattice vector quantization (SALVQ) for compressing 3D Gaussian Splatting (3DGS) data, enhancing compression efficiency and adaptability over traditional methods.", "motivation": "The rapid rise of 3D Gaussian Splatting (3DGS) for photorealistic rendering necessitates efficient data compression to address the massive data it generates. Current methods rely on uniform scalar quantization, which may not be optimal.", "method": "The authors introduce SALVQ, which replaces uniform scalar quantization with a scene-adaptive lattice vector quantization approach. It involves optimizing lattice bases for each scene and uses scale-adjustable lattice density for dynamic bit rate accommodation.", "result": "SALVQ achieves better rate-distortion (R-D) efficiency compared to traditional quantization techniques, enhances compression performance with minimal system changes, and supports multiple bit rate targets efficiently.", "conclusion": "SALVQ improves the adaptability and efficiency of 3DGS data compression while reducing training time and memory usage, making it a robust solution for practical scenarios."}}
{"id": "2509.13868", "pdf": "https://arxiv.org/pdf/2509.13868", "abs": "https://arxiv.org/abs/2509.13868", "authors": ["Manal Binkhonain", "Reem Alfayaz"], "title": "Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification", "categories": ["cs.SE"], "comment": "33 pages, 12 figures", "summary": "Requirements classification assigns natural language requirements to\npredefined classes, such as functional and non functional. Accurate\nclassification reduces risk and improves software quality. Most existing models\nrely on supervised learning, which needs large labeled data that are costly,\nslow to create, and domain dependent; they also generalize poorly and often\nrequire retraining for each task. This study tests whether prompt based large\nlanguage models can reduce data needs. We benchmark several models and\nprompting styles (zero shot, few shot, persona, and chain of thought) across\nmultiple tasks on two English datasets, PROMISE and SecReq. For each task we\ncompare model prompt configurations and then compare the best LLM setups with a\nstrong fine tuned transformer baseline. Results show that prompt based LLMs,\nespecially with few shot prompts, can match or exceed the baseline. Adding a\npersona, or persona plus chain of thought, can yield further gains. We conclude\nthat prompt based LLMs are a practical and scalable option that reduces\ndependence on large annotations and can improve generalizability across tasks.", "AI": {"tldr": "This paper explores the use of prompt-based large language models (LLMs) for classifying natural language software requirements and compares them to supervised learning models. The study shows that LLMs, especially with few-shot prompting, can achieve performance comparable to fine-tuned transformers while requiring fewer annotations.", "motivation": "Current supervised learning models for requirements classification rely on extensive labeled data, which is expensive, time-consuming to create, and lacks generalizability across tasks.", "method": "The study benchmarks several prompt-based LLMs and styles (zero-shot, few-shot, persona, chain-of-thought) on classification tasks using the PROMISE and SecReq datasets. Results are compared with fine-tuned transformer baselines.", "result": "Prompt-based LLMs, especially those using few-shot prompts, match or exceed fine-tuned transformer baselines. Incorporating personas or combining with chain-of-thought further boosts performance.", "conclusion": "Prompt-based LLMs present a scalable and effective alternative to traditional supervised methods, reducing the need for extensive labeled data and improving generalizability across tasks."}}
{"id": "2509.13572", "pdf": "https://arxiv.org/pdf/2509.13572", "abs": "https://arxiv.org/abs/2509.13572", "authors": ["Ozan Karaali", "Hossam Farag", "Strahinja Dosen", "Cedomir Stefanovic"], "title": "Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference", "categories": ["cs.RO"], "comment": "ICAT 2025", "summary": "This study examines the potential of utilizing Vision Language Models (VLMs)\nto improve the perceptual capabilities of semi-autonomous prosthetic hands. We\nintroduce a unified benchmark for end-to-end perception and grasp inference,\nevaluating a single VLM to perform tasks that traditionally require complex\npipelines with separate modules for object detection, pose estimation, and\ngrasp planning. To establish the feasibility and current limitations of this\napproach, we benchmark eight contemporary VLMs on their ability to perform a\nunified task essential for bionic grasping. From a single static image, they\nshould (1) identify common objects and their key properties (name, shape,\norientation, and dimensions), and (2) infer appropriate grasp parameters (grasp\ntype, wrist rotation, hand aperture, and number of fingers). A corresponding\nprompt requesting a structured JSON output was employed with a dataset of 34\nsnapshots of common objects. Key performance metrics, including accuracy for\ncategorical attributes (e.g., object name, shape) and errors in numerical\nestimates (e.g., dimensions, hand aperture), along with latency and cost, were\nanalyzed. The results demonstrated that most models exhibited high performance\nin object identification and shape recognition, while accuracy in estimating\ndimensions and inferring optimal grasp parameters, particularly hand rotation\nand aperture, varied more significantly. This work highlights the current\ncapabilities and limitations of VLMs as advanced perceptual modules for\nsemi-autonomous control of bionic limbs, demonstrating their potential for\neffective prosthetic applications.", "AI": {"tldr": "The paper assesses the use of Vision Language Models (VLMs) for enhancing semi-autonomous prosthetic hands. It proposes a benchmark for integrated perception and grasp inference, tested across eight VLMs.", "motivation": "The motivation is to explore whether VLMs can replace complex pipelines in prosthetic applications by handling integrated tasks like object detection and grasp inference in a more streamlined way.", "method": "Eight contemporary VLMs were tested with a dataset of 34 images. Each model had to identify object properties and infer grasp parameters from static images via structured JSON prompts. Performance metrics such as accuracy, numerical estimation errors, latency, and cost were evaluated.", "result": "VLMs performed well in object identification and shape recognition, but showed mixed accuracy in dimension estimation and grasp parameter inference, specifically in hand rotation and aperture.", "conclusion": "VLMs show significant potential for bionic applications but face limitations in precise grasp parameter computation, requiring further improvement for optimal prosthetic use."}}
{"id": "2509.14211", "pdf": "https://arxiv.org/pdf/2509.14211", "abs": "https://arxiv.org/abs/2509.14211", "authors": ["Pascal Costanza", "Timothy G. Mattson", "Raye Kimmerer", "Benjamin Brock"], "title": "Julia GraphBLAS with Nonblocking Execution", "categories": ["cs.MS", "cs.DC", "cs.PL"], "comment": null, "summary": "From the beginning, the GraphBLAS were designed for ``nonblocking\nexecution''; i.e., calls to GraphBLAS methods return as soon as the arguments\nto the methods are validated and define a directed acyclic graph (DAG) of\nGraphBLAS operations. This lets GraphBLAS implementations fuse functions, elide\nunneeded objects, exploit parallelism, plus any additional DAG-preserving\ntransformations. GraphBLAS implementations exist that utilize nonblocking\nexecution but with limited scope. In this paper, we describe our work to\nimplement GraphBLAS with support for aggressive nonblocking execution. We show\nhow features of the Julia programming language greatly simplify implementation\nof nonblocking execution. This is \\emph{work-in-progress} sufficient to show\nthe potential for nonblocking execution and is limited to GraphBLAS methods\nrequired to support PageRank.", "AI": {"tldr": "The paper investigates implementing nonblocking execution in GraphBLAS using Julia for PageRank operations.", "motivation": "GraphBLAS methods provide opportunities for optimized execution via nonblocking mechanisms, but existing implementations use these techniques in a restricted way, urging the need for broader support.", "method": "Utilized features of the Julia programming language to implement and demonstrate nonblocking execution for GraphBLAS methods, focusing on PageRank cases.", "result": "Implemented a prototype supporting nonblocking execution for GraphBLAS in Julia, showing potential for DAG-preserving optimizations.", "conclusion": "The proposed approach simplifies implementing aggressive nonblocking execution for GraphBLAS and demonstrates potential for optimization, despite the implementation being a work-in-progress targeted at specific methods."}}
{"id": "2509.13389", "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "The paper introduces a method that uses transformers to learn propositional STRIPS world models from action traces by framing it as a supervised token prediction task.", "motivation": "The motivation is to develop a machine learning approach capable of deducing STRIPS world models from action sequences without requiring additional annotations or knowledge.", "method": "The authors utilize transformers to treat the problem as a next-token prediction task where sequences of actions provide context for determining valid or invalid subsequent actions.", "result": "The study confirms that transformers can effectively represent STRIPS world models and learn them using sets of valid and invalid action sequences.", "conclusion": "The paper demonstrates the feasibility of learning STRIPS world models using deep learning, specifically transformers, by leveraging action sequences as input for training."}}
{"id": "2509.13723", "pdf": "https://arxiv.org/pdf/2509.13723", "abs": "https://arxiv.org/abs/2509.13723", "authors": ["Yaxin Gao", "Yao Lu", "Zongfei Zhang", "Jiaqi Nie", "Shanqing Yu", "Qi Xuan"], "title": "DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success in many natural\nlanguage processing (NLP) tasks. To achieve more accurate output, the prompts\nused to drive LLMs have become increasingly longer, which incurs higher\ncomputational costs. To address this prompt inflation problem, prompt\ncompression has been proposed. However, most existing methods require training\na small auxiliary model for compression, incurring a significant amount of\nadditional computation. To avoid this, we propose a two-stage, training-free\napproach, called Dual-Stage Progressive Compression (DSPC). In the\ncoarse-grained stage, semantic-related sentence filtering removes sentences\nwith low semantic value based on TF-IDF. In the fine-grained stage, token\nimportance is assessed using attention contribution, cross-model loss\ndifference, and positional importance, enabling the pruning of low-utility\ntokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct\nand GPT-3.5-Turbo under a constrained token budget and observe consistent\nimprovements. For instance, in the FewShot task of the Longbench dataset, DSPC\nachieves a performance of 49.17 by using only 3x fewer tokens, outperforming\nthe best state-of-the-art baseline LongLLMLingua by 7.76.", "AI": {"tldr": "The paper introduces Dual-Stage Progressive Compression (DSPC), a training-free method to compress prompts for large language models (LLMs) to reduce computational costs while maintaining performance.", "motivation": "The motivation is to address the problem of prompt inflation in large language models, where increasingly longer prompts lead to higher computational costs.", "method": "The Dual-Stage Progressive Compression (DSPC) method involves two stages: (1) coarse-grained filtering based on TF-IDF to remove semantically low-value sentences, and (2) fine-grained token pruning using attention contribution, cross-model loss difference, and positional importance.", "result": "DSPC achieved consistent improvements under constrained token budgets, reducing token usage by three times while outperforming state-of-the-art methods, as seen in the FewShot task of the Longbench dataset.", "conclusion": "DSPC offers an efficient, training-free solution to prompt compression, balancing reduced computational costs with high performance, and demonstrating clear advantages over existing methods."}}
{"id": "2509.13648", "pdf": "https://arxiv.org/pdf/2509.13648", "abs": "https://arxiv.org/abs/2509.13648", "authors": ["Geon Lee", "Bhuvesh Kumar", "Clark Mingxuan Ju", "Tong Zhao", "Kijung Shin", "Neil Shah", "Liam Collins"], "title": "Sequential Data Augmentation for Generative Recommendation", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Generative recommendation plays a crucial role in personalized systems,\npredicting users' future interactions from their historical behavior sequences.\nA critical yet underexplored factor in training these models is data\naugmentation, the process of constructing training data from user interaction\nhistories. By shaping the training distribution, data augmentation directly and\noften substantially affects model generalization and performance. Nevertheless,\nin much of the existing work, this process is simplified, applied\ninconsistently, or treated as a minor design choice, without a systematic and\nprincipled understanding of its effects.\n  Motivated by our empirical finding that different augmentation strategies can\nyield large performance disparities, we conduct an in-depth analysis of how\nthey reshape training distributions and influence alignment with future targets\nand generalization to unseen inputs. To systematize this design space, we\npropose GenPAS, a generalized and principled framework that models augmentation\nas a stochastic sampling process over input-target pairs with three\nbias-controlled steps: sequence sampling, target sampling, and input sampling.\nThis formulation unifies widely used strategies as special cases and enables\nflexible control of the resulting training distribution. Our extensive\nexperiments on benchmark and industrial datasets demonstrate that GenPAS yields\nsuperior accuracy, data efficiency, and parameter efficiency compared to\nexisting strategies, providing practical guidance for principled training data\nconstruction in generative recommendation.", "AI": {"tldr": "This paper addresses the overlooked importance of data augmentation in training generative recommendation models. It introduces GenPAS, a structured framework for augmentation, improving model accuracy and efficiency.", "motivation": "Current generative recommendation systems lack a systematic approach to data augmentation, which significantly impacts their performance and generalizability.", "method": "The paper presents GenPAS, a framework that models data augmentation as a stochastic sampling process with three bias-controlled components: sequence sampling, target sampling, and input sampling.", "result": "Experimental results over benchmark and industrial datasets show that GenPAS improves accuracy, data efficiency, and parameter efficiency compared to existing approaches.", "conclusion": "GenPAS provides a principled and unified approach to data augmentation, delivering practical advancements in generative recommendation models by optimizing training data construction."}}
{"id": "2509.13484", "pdf": "https://arxiv.org/pdf/2509.13484", "abs": "https://arxiv.org/abs/2509.13484", "authors": ["Liu Liu", "Alexandra Kudaeva", "Marco Cipriano", "Fatimeh Al Ghannam", "Freya Tan", "Gerard de Melo", "Andres Sevtsuk"], "title": "MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes", "categories": ["cs.CV", "cs.CY"], "comment": "13 pages, 4 figures, under review at AAAI 2026", "summary": "Understanding group-level social interactions in public spaces is crucial for\nurban planning, informing the design of socially vibrant and inclusive\nenvironments. Detecting such interactions from images involves interpreting\nsubtle visual cues such as relations, proximity, and co-movement - semantically\ncomplex signals that go beyond traditional object detection. To address this\nchallenge, we introduce a social group region detection task, which requires\ninferring and spatially grounding visual regions defined by abstract\ninterpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level\nEngagement), a modular three-stage pipeline that integrates: (1) off-the-shelf\nhuman detection and depth estimation, (2) VLM-based reasoning to classify\npairwise social affiliation, and (3) a lightweight spatial aggregation\nalgorithm to localize socially connected groups. To support this task and\nencourage future research, we present a new dataset of 100K urban street-view\nimages annotated with bounding boxes and labels for both individuals and\nsocially interacting groups. The annotations combine human-created labels and\noutputs from the MINGLE pipeline, ensuring semantic richness and broad coverage\nof real-world scenarios.", "AI": {"tldr": "This paper focuses on detecting group-level social interactions from urban street-view images by introducing a new task and method, along with a dataset.", "motivation": "To aid urban planning and design by better understanding social interactions in public spaces.", "method": "Introduces MINGLE, a three-stage pipeline using human detection, VLM-based reasoning, and spatial aggregation for identifying social groups in images.", "result": "Developed a dataset with 100K street-view images annotated with bounding boxes and labels for individuals and groups.", "conclusion": "The proposed method and dataset pave the way for future research in detecting and analyzing interpersonal social interactions visually."}}
{"id": "2509.13896", "pdf": "https://arxiv.org/pdf/2509.13896", "abs": "https://arxiv.org/abs/2509.13896", "authors": ["Shalini Chakraborty", "Lola Burgue\u00f1o", "Nathalie Moreno", "Javier Troya", "Paula Mu\u00f1oz"], "title": "Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education", "categories": ["cs.SE"], "comment": "8 pages, Educators Symposium at MODELS 2025", "summary": "Generative Artificial Intelligence (GenAI) is rapidly gaining momentum in\nsoftware modeling education, embraced by both students and educators. As GenAI\nassists with interpreting requirements, formalizing models, and translating\nstudents' mental models into structured notations, it increasingly shapes core\nlearning outcomes such as domain comprehension, diagrammatic thinking, and\nmodeling fluency without clear ethical oversight or pedagogical guidelines.\nYet, the ethical implications of this integration remain underexplored.\n  In this paper, we conduct a systematic literature review across six major\ndigital libraries in computer science (ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, SpringerLink, and Web of Science). Our aim is to\nidentify studies discussing the ethical aspects of GenAI in software modeling\neducation, including responsibility, fairness, transparency, diversity, and\ninclusion among others.\n  Out of 1,386 unique papers initially retrieved, only three explicitly\naddressed ethical considerations. This scarcity highlights the critical absence\nof ethical discourse surrounding GenAI in modeling education and raises urgent\nquestions about the responsible integration of AI in modeling curricula, as\nwell as it evinces the pressing need for structured ethical frameworks in this\nemerging educational landscape. We examine these three studies and explore the\nemerging research opportunities as well as the challenges that have arisen in\nthis field.", "AI": {"tldr": "The paper highlights the lack of research on ethical considerations of Generative AI in software modeling education and analyzes three relevant studies from a systematic review.", "motivation": "The paper aims to address the growing use of Generative AI in software modeling education and the notable absence of ethical oversight or structured guidelines.", "method": "The researchers conducted a systematic literature review across six major computer science digital libraries, focusing on ethical aspects like fairness and transparency.", "result": "Out of 1,386 papers reviewed, only three explicitly discussed ethical considerations related to GenAI in software modeling education, indicating a critical gap.", "conclusion": "There is an urgent need for structured ethical frameworks to ensure responsible integration of Generative AI into educational curricula and address ethical challenges."}}
{"id": "2509.13574", "pdf": "https://arxiv.org/pdf/2509.13574", "abs": "https://arxiv.org/abs/2509.13574", "authors": ["Zidong Chen", "Zihao Guo", "Peng Wang", "ThankGod Itua Egbe", "Yan Lyu", "Chenghao Qian"], "title": "Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Flow matching has emerged as a competitive framework for learning\nhigh-quality generative policies in robotics; however, we find that\ngeneralisation arises and saturates early along the flow trajectory, in\naccordance with recent findings in the literature. We further observe that\nincreasing the number of Euler integration steps during inference\ncounter-intuitively and universally degrades policy performance. We attribute\nthis to (i) additional, uniformly spaced integration steps oversample the\nlate-time region, thereby constraining actions towards the training\ntrajectories and reducing generalisation; and (ii) the learned velocity field\nbecoming non-Lipschitz as integration time approaches 1, causing instability.\nTo address these issues, we propose a novel policy that utilises non-uniform\ntime scheduling (e.g., U-shaped) during training, which emphasises both early\nand late temporal stages to regularise policy training, and a dense-jump\nintegration schedule at inference, which uses a single-step integration to\nreplace the multi-step integration beyond a jump point, to avoid unstable areas\naround 1. Essentially, our policy is an efficient one-step learner that still\npushes forward performance through multi-step integration, yielding up to 23.7%\nperformance gains over state-of-the-art baselines across diverse robotic tasks.", "AI": {"tldr": "The paper addresses limitations in flow matching for robotics by proposing a novel policy that improves performance through time scheduling and one-step learning.", "motivation": "The motivation stems from recognizing performance degradation in flow matching due to oversampling late-time regions and instability in velocity fields.", "method": "The authors introduce a policy with non-uniform temporal scheduling during training and a dense-jump integration method during inference.", "result": "The proposed method achieves up to 23.7% performance improvement over state-of-the-art methods in diverse robotic tasks.", "conclusion": "The research offers a solution to saturation and instability in flow matching, improving generalization and efficiency in robotic policy learning."}}
{"id": "2509.13450", "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "This paper introduces SteeringControl, a benchmark to evaluate alignment methods such as bias correction and reducing harmful generation in language models, highlighting tradeoffs and entanglements in steering behavior.", "motivation": "The motivation is to systematically explore the tradeoffs and side effects of representation steering methods in language models, which are underexplored in alignment research.", "method": "The paper proposes a modular steering framework and collects a dataset to evaluate primary and secondary behaviors of five popular steering methods. Experiments are conducted on Qwen-2.5-7B and Llama-3.1-8B models.", "result": "Findings reveal that steering effectiveness is highly dependent on the interaction between the steering method, the model, and the targeted behaviors. Poor combinations can lead to severe behavioral entanglements.", "conclusion": "Effective representation steering in language models requires careful consideration of method-model-behavior interactions. SteeringControl can aid in systematically analyzing these aspects."}}
{"id": "2509.13734", "pdf": "https://arxiv.org/pdf/2509.13734", "abs": "https://arxiv.org/abs/2509.13734", "authors": ["Yosuke Mikami", "Daiki Matsuoka", "Hitomi Yanaka"], "title": "Implementing a Logical Inference System for Japanese Comparatives", "categories": ["cs.CL"], "comment": "In Proceedings of the 5th Workshop on Natural Logic Meets Machine\n  Learning (NALOMA)", "summary": "Natural Language Inference (NLI) involving comparatives is challenging\nbecause it requires understanding quantities and comparative relations\nexpressed by sentences. While some approaches leverage Large Language Models\n(LLMs), we focus on logic-based approaches grounded in compositional semantics,\nwhich are promising for robust handling of numerical and logical expressions.\nPrevious studies along these lines have proposed logical inference systems for\nEnglish comparatives. However, it has been pointed out that there are several\nmorphological and semantic differences between Japanese and English\ncomparatives. These differences make it difficult to apply such systems\ndirectly to Japanese comparatives. To address this gap, this study proposes\nccg-jcomp, a logical inference system for Japanese comparatives based on\ncompositional semantics. We evaluate the proposed system on a Japanese NLI\ndataset containing comparative expressions. We demonstrate the effectiveness of\nour system by comparing its accuracy with that of existing LLMs.", "AI": {"tldr": "This paper presents ccg-jcomp, a logical inference system tailored for handling Japanese comparatives, and evaluates its effectiveness against Large Language Models on a specific NLI dataset.", "motivation": "The study aims to address the challenges of understanding quantities and comparative relations in the context of Japanese comparatives, which differ morphologically and semantically from English, thus necessitating a specialized approach.", "method": "The authors designed ccg-jcomp, a logical inference system grounded in compositional semantics, specifically for Japanese comparatives, and assessed its performance using a dedicated dataset.", "result": "The proposed system showed effective handling of Japanese comparatives, achieving higher accuracy compared to current LLMs in this domain.", "conclusion": "ccg-jcomp is a successful application of logic-based reasoning for Japanese comparatives, outperforming LLMs and highlighting the importance of tailored systems for such linguistic nuances."}}
{"id": "2509.13651", "pdf": "https://arxiv.org/pdf/2509.13651", "abs": "https://arxiv.org/abs/2509.13651", "authors": ["Yongkang Du", "Jieyu Zhao", "Yijun Yang", "Tianyi Zhou"], "title": "Controllable Pareto Trade-off between Fairness and Accuracy", "categories": ["cs.LG"], "comment": null, "summary": "The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work\nfocuses on finding a single \"optimal\" solution to balance the two objectives,\nwhich is limited considering the diverse solutions on the Pareto front. This\nwork intends to provide controllable trade-offs according to the user's\npreference of the two objectives, which is defined as a reference vector. To\nachieve this goal, we apply multi-objective optimization (MOO), which can find\nsolutions from various regions of the Pareto front. However, it is challenging\nto precisely control the trade-off due to the stochasticity of the training\nprocess and the high dimentional gradient vectors. Thus, we propose\nControllable Pareto Trade-off (CPT) that can effectively train models to\nperform different trade-offs according to users' preferences. CPT 1) stabilizes\nthe fairness update with a moving average of stochastic gradients to determine\nthe update direction, and 2) prunes the gradients by only keeping the gradients\nof the critical parameters. We evaluate CPT on hate speech detection and\noccupation classification tasks. Experiments show that CPT can achieve a\nhigher-quality set of solutions on the Pareto front than the baseline methods.\nIt also exhibits better controllability and can precisely follow the\nhuman-defined reference vectors.", "AI": {"tldr": "This paper introduces the Controllable Pareto Trade-off (CPT) method to better balance fairness and accuracy in NLP tasks through multi-objective optimization.", "motivation": "Existing approaches inadequately consider the diverse solutions along the Pareto front when balancing fairness and accuracy in NLP tasks.", "method": "The proposed CPT method stabilizes fairness updates using a moving average of gradients and prunes gradients to retain only critical parameters, enabling finer control over trade-offs.", "result": "Experiments on hate speech detection and occupation classification show CPT yields higher-quality solutions on the Pareto front and achieves precise trade-off control based on user preferences.", "conclusion": "CPT enhances both the quality and controllability of trade-off solutions, surpassing baseline methods in fairness and accuracy adjustments on NLP tasks."}}
{"id": "2509.13496", "pdf": "https://arxiv.org/pdf/2509.13496", "abs": "https://arxiv.org/abs/2509.13496", "authors": ["Rajatsubhra Chakraborty", "Xujun Che", "Depeng Xu", "Cori Faklaris", "Xi Niu", "Shuhan Yuan"], "title": "BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Bias discovery is critical for black-box generative models, especiall\ntext-to-image (TTI) models. Existing works predominantly focus on output-level\ndemographic distributions, which do not necessarily guarantee concept\nrepresentations to be disentangled post-mitigation. We propose BiasMap, a\nmodel-agnostic framework for uncovering latent concept-level representational\nbiases in stable diffusion models. BiasMap leverages cross-attention\nattribution maps to reveal structural entanglements between demographics (e.g.,\ngender, race) and semantics (e.g., professions), going deeper into\nrepresentational bias during the image generation. Using attribution maps of\nthese concepts, we quantify the spatial demographics-semantics concept\nentanglement via Intersection over Union (IoU), offering a lens into bias that\nremains hidden in existing fairness discovery approaches. In addition, we\nfurther utilize BiasMap for bias mitigation through energy-guided diffusion\nsampling that directly modifies latent noise space and minimizes the expected\nSoftIoU during the denoising process. Our findings show that existing fairness\ninterventions may reduce the output distributional gap but often fail to\ndisentangle concept-level coupling, whereas our mitigation method can mitigate\nconcept entanglement in image generation while complementing distributional\nbias mitigation.", "AI": {"tldr": "BiasMap is a model-agnostic framework designed to uncover and mitigate latent concept-level representational biases in stable diffusion text-to-image models, addressing structural entanglements between demographics and semantics.", "motivation": "To address limitations in existing fairness discovery approaches that focus narrowly on output-level demographic distributions and fail to ensure disentangled concept representations.", "method": "BiasMap uses cross-attention attribution maps to identify demographic-semantic entanglements and quantifies these biases using Intersection over Union (IoU). It further employs energy-guided diffusion sampling for bias mitigation during image generation.", "result": "BiasMap reveals hidden biases in diffusion models and demonstrates improved mitigation of concept-level coupling compared to existing fairness interventions, which often fail to address this aspect effectively.", "conclusion": "The framework provides a new lens into representational biases and offers a practical method to mitigate these biases in generative models, advancing fairness in text-to-image generation."}}
{"id": "2509.13941", "pdf": "https://arxiv.org/pdf/2509.13941", "abs": "https://arxiv.org/abs/2509.13941", "authors": ["Simiao Liu", "Fang Liu", "Liehao Li", "Xin Tan", "Yinghao Zhu", "Xiaoli Lian", "Li Zhang"], "title": "An Empirical Study on Failures in Automated Issue Solving", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Automated issue solving seeks to autonomously identify and repair defective\ncode snippets across an entire codebase. SWE-Bench has emerged as the most\nwidely adopted benchmark for evaluating progress in this area. While LLM-based\nagentic tools show great promise, they still fail on a substantial portion of\ntasks. Moreover, current evaluations primarily report aggregate issue-solving\nrates, which obscure the underlying causes of success and failure, making it\nchallenging to diagnose model weaknesses or guide targeted improvements. To\nbridge this gap, we first analyze the performance and efficiency of three SOTA\ntools, spanning both pipeline-based and agentic architectures, in automated\nissue solving tasks of SWE-Bench-Verified under varying task characteristics.\nFurthermore, to move from high-level performance metrics to underlying cause\nanalysis, we conducted a systematic manual analysis of 150 failed instances.\nFrom this analysis, we developed a comprehensive taxonomy of failure modes\ncomprising 3 primary phases, 9 main categories, and 25 fine-grained\nsubcategories. Then we systematically analyze the distribution of the\nidentified failure modes, the results reveal distinct failure fingerprints\nbetween the two architectural paradigms, with the majority of agentic failures\nstemming from flawed reasoning and cognitive deadlocks. Motivated by these\ninsights, we propose a collaborative Expert-Executor framework. It introduces a\nsupervisory Expert agent tasked with providing strategic oversight and\ncourse-correction for a primary Executor agent. This architecture is designed\nto correct flawed reasoning and break the cognitive deadlocks that frequently\nlead to failure. Experiments show that our framework solves 22.2% of previously\nintractable issues for a leading single agent. These findings pave the way for\nbuilding more robust agents through diagnostic evaluation and collaborative\ndesign.", "AI": {"tldr": "This paper identifies key failure modes in automated issue solving using state-of-the-art tools on the SWE-Bench benchmark and proposes a new collaborative Expert-Executor framework to improve task success rates.", "motivation": "Automated issue solving faces significant challenges including high failure rates and limited diagnostic understanding of issues. Current evaluations are insufficient to pinpoint model weaknesses or guide improvements.", "method": "The study analyzed task performance characteristics, manually categorized 150 failure instances into a taxonomy, and proposed a collaborative Expert-Executor framework to address model setbacks.", "result": "The taxonomy revealed distinct failure patterns depending on architectural paradigms, and the Expert-Executor framework showed a 22.2% improvement on previously unsolvable tasks.", "conclusion": "Diagnostic evaluations combined with collaborative frameworks can significantly enhance the robustness and success rates of automated issue-solving tools."}}
{"id": "2509.13579", "pdf": "https://arxiv.org/pdf/2509.13579", "abs": "https://arxiv.org/abs/2509.13579", "authors": ["Momchil S. Tomov", "Sang Uk Lee", "Hansford Hendrago", "Jinwook Huh", "Teawon Han", "Forbes Howington", "Rafael da Silva", "Gianmarco Bernasconi", "Marc Heim", "Samuel Findler", "Xiaonan Ji", "Alexander Boule", "Michael Napoli", "Kuo Chen", "Jesse Miller", "Boaz Floor", "Yunqing Hu"], "title": "TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "We present TreeIRL, a novel planner for autonomous driving that combines\nMonte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to\nachieve state-of-the-art performance in simulation and in real-world driving.\nThe core idea is to use MCTS to find a promising set of safe candidate\ntrajectories and a deep IRL scoring function to select the most human-like\namong them. We evaluate TreeIRL against both classical and state-of-the-art\nplanners in large-scale simulations and on 500+ miles of real-world autonomous\ndriving in the Las Vegas metropolitan area. Test scenarios include dense urban\ntraffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves\nthe best overall performance, striking a balance between safety, progress,\ncomfort, and human-likeness. To our knowledge, our work is the first\ndemonstration of MCTS-based planning on public roads and underscores the\nimportance of evaluating planners across a diverse set of metrics and in\nreal-world environments. TreeIRL is highly extensible and could be further\nimproved with reinforcement learning and imitation learning, providing a\nframework for exploring different combinations of classical and learning-based\napproaches to solve the planning bottleneck in autonomous driving.", "AI": {"tldr": "TreeIRL combines MCTS and IRL to achieve state-of-the-art autonomous driving performance in both simulation and real-world tests across diverse conditions.", "motivation": "There is a need for a planner that balances safety, progress, comfort, and human-likeness in autonomous driving, especially under real-world conditions.", "method": "TreeIRL integrates MCTS to generate safe trajectory candidates and uses a deep IRL scoring function to select the most human-like trajectory.", "result": "TreeIRL outperforms classical and state-of-the-art planners in simulations and over 500+ miles of real-world driving in Las Vegas, handling dense urban traffic, adaptive cruise control, cut-ins, and traffic lights.", "conclusion": "TreeIRL is a highly extensible planner that demonstrates the first MCTS-based planning on public roads and provides a strong framework for improving autonomous driving through hybrid learning-based approaches."}}
{"id": "2509.13547", "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "categories": ["cs.AI", "cs.HC"], "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "This study explores how giving large language model (LLM) agents collaborative tools modeled after human techniques can enhance their performance on challenging Python programming tasks, showing significant benefits under certain circumstances.", "motivation": "The research is motivated by the question of whether LLM agents can improve their problem-solving abilities when equipped with human-like collaboration tools and greater autonomy.", "method": "The paper equips Claude Code agents with social media and journaling collaboration tools based on MCP techniques. It then allows these agents to autonomously use these tools across 34 Python programming challenges.", "result": "The study finds that collaborative tools help significantly on harder challenges, reducing costs by 15-40%, interaction turns by 12-27%, and task completion times by 12-38%. Different models adopted unique collaborative strategies without explicit instruction.", "conclusion": "LLM agents systematically benefit from collaboration tools in complex scenarios, showcasing that adaptive interfaces act as reasoning enhancers, although gains are not universal across all tasks."}}
{"id": "2509.13775", "pdf": "https://arxiv.org/pdf/2509.13775", "abs": "https://arxiv.org/abs/2509.13775", "authors": ["Vani Kanjirangat", "Ljiljana Dolamic", "Fabio Rinaldi"], "title": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "categories": ["cs.CL", "cs.AI"], "comment": "4 main pages, 4 additional, 5 figures", "summary": "This paper discusses our exploration of different data-efficient and\nparameter-efficient approaches to Arabic Dialect Identification (ADI). In\nparticular, we investigate various soft-prompting strategies, including\nprefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA\nreparameterizations. For the data-efficient strategy, we analyze hard prompting\nwith zero-shot and few-shot inferences to analyze the dialect identification\ncapabilities of Large Language Models (LLMs). For the parameter-efficient PEFT\napproaches, we conducted our experiments using Arabic-specific encoder models\non several major datasets. We also analyzed the n-shot inferences on\nopen-source decoder-only models, a general multilingual model (Phi-3.5), and an\nArabic-specific one(SILMA). We observed that the LLMs generally struggle to\ndifferentiate the dialectal nuances in the few-shot or zero-shot setups. The\nsoft-prompted encoder variants perform better, while the LoRA-based fine-tuned\nmodels perform best, even surpassing full fine-tuning.", "AI": {"tldr": "The paper investigates efficient methods (soft prompting, hard prompting, and LoRA) for Arabic Dialect Identification using Large Language Models (LLMs) and encoder models, concluding that LoRA-based approaches outperform others.", "motivation": "To address challenges in Arabic Dialect Identification by exploring data-efficient and parameter-efficient methods using LLMs and Arabic-specific encoder models.", "method": "Experiments on prefix-tuning, prompt-tuning variants, LoRA fine-tuning, zero-shot/few-shot setups, and analysis of n-shot inference on encoder and decoder models.", "result": "LLMs struggle with identifying dialects in zero-shot/few-shot setups, but LoRA-based fine-tuned models outperform soft-prompt encoder methods and even full fine-tuning.", "conclusion": "LoRA-based models are promising for Arabic Dialect Identification, showcasing superior performance to other methods investigated."}}
{"id": "2509.13686", "pdf": "https://arxiv.org/pdf/2509.13686", "abs": "https://arxiv.org/abs/2509.13686", "authors": ["Bingsheng Peng", "Shutao Zhang", "Xi Zheng", "Ye Xue", "Xinyu Qin", "Tsung-Hui Chang"], "title": "RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Accurate localized wireless channel modeling is a cornerstone of cellular\nnetwork optimization, enabling reliable prediction of network performance\nduring parameter tuning. Localized statistical channel modeling (LSCM) is the\nstate-of-the-art channel modeling framework tailored for cellular network\noptimization. However, traditional LSCM methods, which infer the channel's\nAngular Power Spectrum (APS) from Reference Signal Received Power (RSRP)\nmeasurements, suffer from critical limitations: they are typically confined to\nsingle-cell, single-grid and single-carrier frequency analysis and fail to\ncapture complex cross-domain interactions. To overcome these challenges, we\npropose RF-LSCM, a novel framework that models the channel APS by jointly\nrepresenting large-scale signal attenuation and multipath components within a\nradiance field. RF-LSCM introduces a multi-domain LSCM formulation with a\nphysics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the\ncross frequency generalization as well as a point-cloud-aided environment\nenhanced method to enable multi-cell and multi-grid channel modeling.\nFurthermore, to address the computational inefficiency of typical neural\nradiance fields, RF-LSCM leverages a low-rank tensor representation,\ncomplemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.\nThis efficient design significantly reduces GPU memory requirements and\ntraining time while preserving fine-grained accuracy. Extensive experiments on\nreal-world multi-cell datasets demonstrate that RF-LSCM significantly\noutperforms state-of-the-art methods, achieving up to a 30% reduction in mean\nabsolute error (MAE) for coverage prediction and a 22% MAE improvement by\neffectively fusing multi-frequency data.", "AI": {"tldr": "The paper introduces RF-LSCM, an improved framework for wireless channel modeling, which offers better accuracy and efficiency in cellular network optimization.", "motivation": "To address limitations in traditional LSCM methods, specifically their inability to handle multi-cell, multi-grid, and multi-frequency scenarios, and to better capture cross-domain interactions in channel modeling.", "method": "RF-LSCM develops a novel representation of the channel APS using a radiance field, incorporates a frequency-dependent Attenuation Model (FDAM) for cross-frequency generalization, and employs a point-cloud-aided method for multi-cell and multi-grid modeling. Additionally, computational efficiency is achieved using low-rank tensor representation and the Hierarchical Tensor Angular Modeling (HiTAM) algorithm.", "result": "RF-LSCM achieves up to 30% reduction in mean absolute error (MAE) for network coverage prediction and a 22% MAE improvement via multi-frequency data fusion in experiments with real-world multi-cell datasets.", "conclusion": "RF-LSCM significantly improves the accuracy and efficiency of LSCM, overcoming previous models' limitations and enhancing cellular network optimization."}}
{"id": "2509.13504", "pdf": "https://arxiv.org/pdf/2509.13504", "abs": "https://arxiv.org/abs/2509.13504", "authors": ["Uriel Garcilazo-Cruz", "Joseph O. Okeme", "Rodrigo A. Vargas--Hern\u00e1ndez"], "title": "LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming", "categories": ["cs.CV"], "comment": "8 pages, 10 figures, SM, 5 pages, 4 figures", "summary": "The lack of flexible annotation tools has hindered the deployment of AI\nmodels in some scientific areas. Most existing image annotation software\nrequires users to upload a precollected dataset, which limits support for\non-demand pipelines and introduces unnecessary steps to acquire images. This\nconstraint is particularly problematic in laboratory environments, where\nreal-time data acquisition from instruments such as microscopes is increasingly\ncommon. In this work, we introduce \\texttt{LivePixel}, a Python-based graphical\nuser interface that integrates with imaging systems, such as webcams,\nmicroscopes, and others, to enable real-time image annotation. LivePyxel is\ndesigned to be easy to use through a simple interface that allows users to\nprecisely delimit areas for annotation using tools commonly found in commercial\ngraphics editing software. Of particular interest is the availability of\nB\\'ezier splines and binary masks, and the software's capacity to work with\nnon-destructive layers that enable high-performance editing. LivePyxel also\nintegrates a wide compatibility across video devices, and it's optimized for\nobject detection operations via the use of OpenCV in combination with\nhigh-performance libraries designed to handle matrix and linear algebra\noperations via Numpy effectively. LivePyxel facilitates seamless data\ncollection and labeling, accelerating the development of AI models in\nexperimental workflows. LivePyxel freely available at\nhttps://github.com/UGarCil/LivePyxel", "AI": {"tldr": "LivePyxel is a Python-based GUI for real-time image annotation, designed for seamless integration with imaging systems like microscopes and webcams.", "motivation": "Address the limitation in flexible annotation tools, especially in environments requiring real-time data acquisition, such as laboratories.", "method": "Develop a Python-based graphical user interface (LivePyxel) that integrates with imaging systems for real-time annotation using tools like B\u00e9zier splines, binary masks, and non-destructive layers.", "result": "LivePyxel offers optimized annotation capability with wide compatibility, enabling high-performance editing and seamless data labeling.", "conclusion": "LivePyxel accelerates AI model development in experimental workflows and is freely accessible for users."}}
{"id": "2509.13942", "pdf": "https://arxiv.org/pdf/2509.13942", "abs": "https://arxiv.org/abs/2509.13942", "authors": ["Duc Minh Ha", "Phu Trac Kien", "Tho Quan", "Anh Nguyen-Duc"], "title": "Evaluating Classical Software Process Models as Coordination Mechanisms for LLM-Based Software Generation", "categories": ["cs.SE"], "comment": null, "summary": "[Background] Large Language Model (LLM)-based multi-agent systems (MAS) are\ntransforming software development by enabling autonomous collaboration.\nClassical software processes such asWaterfall, V-Model, and Agile offer\nstructured coordination patterns that can be repurposed to guide these agent\ninteractions. [Aims] This study explores how traditional software development\nprocesses can be adapted as coordination scaffolds for LLM based MAS and\nexamines their impact on code quality, cost, and productivity. [Method] We\nexecuted 11 diverse software projects under three process models and four GPT\nvariants, totaling 132 runs. Each output was evaluated using standardized\nmetrics for size (files, LOC), cost (execution time, token usage), and quality\n(code smells, AI- and human detected bugs). [Results] Both process model and\nLLM choice significantly affected system performance. Waterfall was most\nefficient, V-Model produced the most verbose code, and Agile achieved the\nhighest code quality, albeit at higher computational cost. [Conclusions]\nClassical software processes can be effectively instantiated in LLM-based MAS,\nbut each entails trade-offs across quality, cost, and adaptability. Process\nselection should reflect project goals, whether prioritizing efficiency,\nrobustness, or structured validation.", "AI": {"tldr": "This paper explores adapting traditional software processes (Waterfall, V-Model, Agile) for coordinating Large Language Model (LLM)-based multi-agent systems, studying their impact on code quality, cost, and productivity.", "motivation": "The study is motivated by the innovative use of LLM-based multi-agent systems in software development, seeking to adapt classical coordination models for these agents to optimize outcomes.", "method": "11 software projects were executed via 3 process models and 4 GPT variants, totaling 132 runs, with standardized measurements for file size, cost, and code quality.", "result": "Results showed Waterfall was most efficient, V-Model generated verbose code, and Agile produced the highest quality but at a higher computational cost.", "conclusion": "Classical software processes are adaptable for LLM-based MAS with trade-offs in efficiency, quality, and cost; process choice should align with project objectives."}}
{"id": "2509.13591", "pdf": "https://arxiv.org/pdf/2509.13591", "abs": "https://arxiv.org/abs/2509.13591", "authors": ["Amir-Hossein Shahidzadeh", "Jiyue Zhu", "Kezhou Chen", "Sha Yi", "Cornelia Ferm\u00fcller", "Yiannis Aloimonos", "Xiaolong Wang"], "title": "Object Pose Estimation through Dexterous Touch", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Robust object pose estimation is essential for manipulation and interaction\ntasks in robotics, particularly in scenarios where visual data is limited or\nsensitive to lighting, occlusions, and appearances. Tactile sensors often offer\nlimited and local contact information, making it challenging to reconstruct the\npose from partial data. Our approach uses sensorimotor exploration to actively\ncontrol a robot hand to interact with the object. We train with Reinforcement\nLearning (RL) to explore and collect tactile data. The collected 3D point\nclouds are used to iteratively refine the object's shape and pose. In our\nsetup, one hand holds the object steady while the other performs active\nexploration. We show that our method can actively explore an object's surface\nto identify critical pose features without prior knowledge of the object's\ngeometry. Supplementary material and more demonstrations will be provided at\nhttps://amirshahid.github.io/BimanualTactilePose .", "AI": {"tldr": "This paper proposes a bimanual robotic system that uses reinforcement learning to estimate object poses via sensorimotor exploration with tactile data.", "motivation": "To address the challenge of robust object pose estimation in scenarios with limited visual data or adverse conditions like occlusions, lighting issues, or complex appearances.", "method": "The authors employ a bimanual robotic setup where one hand holds the object steady while the other actively explores it using reinforcement learning to collect and refine tactile data into 3D point clouds for iterative pose and shape refinement.", "result": "Their system successfully identifies critical object pose features without requiring prior knowledge of the object's geometry.", "conclusion": "The proposed method demonstrates that active, tactile-based exploration is a viable approach to improve object pose estimation in robotic manipulation tasks where visual information is unreliable."}}
{"id": "2509.13570", "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "This study investigates students' use and perceptions of generative AI in undergraduate proof-based mathematics courses, aiming to understand its educational implications.", "motivation": "With the rise of generative AI and challenges in its detection, the study aims to develop policies promoting learning and critical thinking.", "method": "The research analyzes survey responses and student interviews across three mathematics courses where limited generative AI use was permitted.", "result": "Findings reveal students' engagement with AI tools, their views on its usefulness and limitations, and its implications for teaching proof-based mathematics.", "conclusion": "The study highlights considerations for integrating generative AI into teaching strategies for proof-based mathematics education."}}
{"id": "2509.13790", "pdf": "https://arxiv.org/pdf/2509.13790", "abs": "https://arxiv.org/abs/2509.13790", "authors": ["Yangning Li", "Tingwei Lu", "Yinghui Li", "Yankai Chen", "Wei-Chieh Huang", "Wenhao Jiang", "Hui Wang", "Hai-Tao Zheng", "Philip S. Yu"], "title": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025 Findings", "summary": "Efficient instruction tuning aims to enhance the ultimate performance of\nlarge language models (LLMs) trained on a given instruction dataset. Curriculum\nlearning as a typical data organization strategy has shown preliminary\neffectiveness in instruction tuning. However, current curriculum tuning methods\nsuffer from the curriculum rigidity, since they rely solely on static heuristic\ndifficulty metrics. These methods fail to adapt to the evolving capabilities of\nmodels during training, resulting in a fixed and potentially sub-optimal\nlearning trajectory. To address the issue, Competence-Aware Multi-Perspective\ncUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS\noffers several advantages: (1) Dynamic selection for sub-curriculum. (2)\nCompetency-aware adjustment to the curriculum schedule. (3) Multiple\ndifficulty-based scheduling. Extensive experiments prove the superior\nperformance of CAMPUS, compared to other state-of-the-art baselines for\nefficient instruction tuning.", "AI": {"tldr": "This paper proposes a new framework called CAMPUS to improve instruction tuning for large language models using a dynamic and competency-aware curriculum learning strategy.", "motivation": "To overcome the limitations of static curriculum learning methods, which do not adapt to the evolving abilities of models and fail to optimize the learning trajectory.", "method": "The paper introduces CAMPUS, a framework that dynamically selects sub-curricula, adjusts curriculum schedules based on model competence, and employs multiple difficulty-based schedulings.", "result": "CAMPUS outperforms state-of-the-art baselines in efficient instruction tuning according to extensive experimental evaluations.", "conclusion": "The proposed CAMPUS framework effectively enhances instruction tuning by addressing the rigidity in traditional curriculum learning approaches through its dynamic and multi-perspective strategy."}}
{"id": "2509.13717", "pdf": "https://arxiv.org/pdf/2509.13717", "abs": "https://arxiv.org/abs/2509.13717", "authors": ["Yifan Yu", "Cheuk Hin Ho", "Yangshuai Wang"], "title": "A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving PDEs, yet existing uncertainty quantification (UQ) approaches for\nPINNs generally lack rigorous statistical guarantees. In this work, we bridge\nthis gap by introducing a distribution-free conformal prediction (CP) framework\nfor UQ in PINNs. This framework calibrates prediction intervals by constructing\nnonconformity scores on a calibration set, thereby yielding distribution-free\nuncertainty estimates with rigorous finite-sample coverage guarantees for\nPINNs. To handle spatial heteroskedasticity, we further introduce local\nconformal quantile estimation, enabling spatially adaptive uncertainty bands\nwhile preserving theoretical guarantee. Through systematic evaluations on\ntypical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz\nequations) and comprehensive testing across multiple uncertainty metrics, our\nresults demonstrate that the proposed framework achieves reliable calibration\nand locally adaptive uncertainty intervals, consistently outperforming\nheuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work\nintroduces a general framework that not only enhances calibration and\nreliability, but also opens new avenues for uncertainty-aware modeling of\ncomplex PDE systems.", "AI": {"tldr": "This paper introduces a distribution-free conformal prediction framework to provide rigorous uncertainty quantification (UQ) for Physics-Informed Neural Networks (PINNs).", "motivation": "Existing uncertainty quantification methods for PINNs lack rigorous statistical guarantees. Therefore, there is a need for a framework to ensure more reliable and theoretically sound UQ in PINN-based PDE solutions.", "method": "The authors propose a distribution-free conformal prediction framework that constructs nonconformity scores on a calibration dataset to achieve finite-sample coverage guarantees. Spatial heteroskedasticity is addressed using local conformal quantile estimation for spatially adaptive uncertainty bands.", "result": "The framework is systematically evaluated on various Partial Differential Equations (PDEs) and uncovers reliable calibration and locally adaptive uncertainty intervals. It consistently outperforms existing heuristic-based UQ methods.", "conclusion": "This framework enhances the reliability of PINNs by introducing rigorous and distribution-free uncertainty quantification. It serves as a general tool for uncertainty-aware modeling in complex systems governed by PDEs."}}
{"id": "2509.13506", "pdf": "https://arxiv.org/pdf/2509.13506", "abs": "https://arxiv.org/abs/2509.13506", "authors": ["Xingzi Xu", "Qi Li", "Shuwen Qiu", "Julien Han", "Karim Bouyarmane"], "title": "DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform", "categories": ["cs.CV"], "comment": "Published in 2025 CVPR Workshop", "summary": "Diffusion models enable high-quality virtual try-on (VTO) with their\nestablished image synthesis abilities. Despite the extensive end-to-end\ntraining of large pre-trained models involved in current VTO methods,\nreal-world applications often prioritize limited training and inference,\nserving, and deployment budgets for VTO. To solve this obstacle, we apply\nDoob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained\nunconditional models for downstream image-conditioned VTO abilities. DEFT\nfreezes the pre-trained model's parameters and trains a small h-transform\nnetwork to learn a conditional h-transform. The h-transform network allows\ntraining only 1.42 percent of the frozen parameters, compared to a baseline of\n5.52 percent in traditional parameter-efficient fine-tuning (PEFT).\n  To further improve DEFT's performance and decrease existing models' inference\ntime, we additionally propose an adaptive consistency loss. Consistency\ntraining distills slow but high-performing diffusion models into a fast one\nwhile retaining performance by enforcing consistencies along the inference\npath. Inspired by constrained optimization, instead of distillation, we combine\nthe consistency loss and the denoising score matching loss in a data-adaptive\nmanner for fine-tuning existing VTO models at a low cost. Empirical results\nshow the proposed DEFT-VTON method achieves state-of-the-art performance on VTO\ntasks, with as few as 15 denoising steps, while maintaining competitive\nresults.", "AI": {"tldr": "This paper proposes DEFT for low-budget virtual try-on (VTO), improving efficiency and quality with minimal parameter updates and a novel consistency loss.", "motivation": "Current VTO methods rely heavily on large pre-trained models, which demand extensive training and high resource budgets for deployment, making them impractical for real-world applications on limited budgets.", "method": "The paper introduces DEFT, which fine-tunes pre-trained models using a small h-transform network, training only 1.42% of parameters. It also incorporates an adaptive consistency loss to improve performance and reduce inference time.", "result": "The DEFT-VTON method achieves state-of-the-art performance on VTO tasks with competitive results using only 15 denoising steps.", "conclusion": "DEFT solves the efficiency and resource challenges of VTO by leveraging minimal parameter tuning and adaptive techniques, maintaining high-quality results while lowering costs."}}
{"id": "2509.14093", "pdf": "https://arxiv.org/pdf/2509.14093", "abs": "https://arxiv.org/abs/2509.14093", "authors": ["Kerui Huang", "Shuhan Liu", "Xing Hu", "Tongtong Xu", "Lingfeng Bao", "Xin Xia"], "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.", "AI": {"tldr": "Chain-of-Thought reasoning improves LLM performance but leads to computational inefficiencies. SEER framework addresses these challenges by shortening reasoning while maintaining accuracy.", "motivation": "The paper aims to address the computational inefficiencies of Chain-of-Thought reasoning, particularly in scenarios requiring concise and deterministic outputs like software engineering.", "method": "SEER framework is proposed featuring Best-of-N sampling and adaptive filtering, dynamically adjusting thresholds to reduce verbosity while preserving accuracy.", "result": "Empirical evaluations show SEER reduces reasoning length by 42.1%, mitigates truncation issues, eliminates infinite loops, and improves task accuracy across various benchmarks.", "conclusion": "SEER enhances efficiency and reliability of CoT-enhanced LLMs, making them more practical for resource-constrained tasks."}}
{"id": "2509.13595", "pdf": "https://arxiv.org/pdf/2509.13595", "abs": "https://arxiv.org/abs/2509.13595", "authors": ["Xiao Liu", "Weijun Wang", "Tianlun Huang", "Zhiyong Wang", "Wei Feng"], "title": "Leg-Arm Coordinated Operation for Curtain Wall Installation", "categories": ["cs.RO"], "comment": null, "summary": "With the acceleration of urbanization, the number of high-rise buildings and\nlarge public facilities is increasing, making curtain walls an essential\ncomponent of modern architecture with widespread applications. Traditional\ncurtain wall installation methods face challenges such as variable on-site\nterrain, high labor intensity, low construction efficiency, and significant\nsafety risks. Large panels often require multiple workers to complete\ninstallation. To address these issues, based on a hexapod curtain wall\ninstallation robot, we design a hierarchical optimization-based whole-body\ncontrol framework for coordinated arm-leg planning tailored to three key tasks:\nwall installation, ceiling installation, and floor laying. This framework\nintegrates the motion of the hexapod legs with the operation of the folding arm\nand the serial-parallel manipulator. We conduct experiments on the hexapod\ncurtain wall installation robot to validate the proposed control method,\ndemonstrating its capability in performing curtain wall installation tasks. Our\nresults confirm the effectiveness of the hierarchical optimization-based\narm-leg coordination framework for the hexapod robot, laying the foundation for\nits further application in complex construction site environments.", "AI": {"tldr": "The paper proposes a hierarchical optimization-based control framework for a hexapod curtain wall installation robot, enhancing efficiency and safety in construction tasks.", "motivation": "Curtain wall installation in modern architecture faces challenges like difficult terrain, labor intensity, low efficiency, and safety risks in traditional methods.", "method": "A hierarchical optimization-based whole-body control framework was designed to coordinate the robot's hexapod legs, folding arms, and serial-parallel manipulator for specific installation tasks.", "result": "Experiments validated the control method, demonstrating the robot's ability to perform curtain wall installation tasks effectively.", "conclusion": "The proposed framework proves effective in addressing construction site complexities, paving the way for broader applications of hexapod robots in such environments."}}
{"id": "2509.13588", "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "categories": ["cs.AI", "cs.CE", "cs.CY"], "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "CoBRA is a toolkit for programming agent behavior in LLM-based simulations, offering consistent and nuanced output by explicitly embedding cognitive biases based on social sciences.", "motivation": "Standard methods fail to ensure consistent and nuanced agent behavior in LLM-based social simulation, necessitating a more systematic approach.", "method": "CoBRA uses cognitive biases from classical social science experiments, measured via a Cognitive Bias Index and adjusted through a Behavioral Regulation Engine.", "result": "CoBRA showed precision in programming cognitive bias in social agents across models during evaluations including demonstrations and benchmarks.", "conclusion": "CoBRA effectively enables controlled, model-agnostic alignment of social agent behaviors with cognitive biases."}}
{"id": "2509.13803", "pdf": "https://arxiv.org/pdf/2509.13803", "abs": "https://arxiv.org/abs/2509.13803", "authors": ["Laura Garc\u00eda-Sardi\u00f1a", "Hermenegildo Fabregat", "Daniel Deniz", "Rabih Zbib"], "title": "Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages", "categories": ["cs.CL"], "comment": null, "summary": "This work sets the ground for studying how explicit grammatical gender\nassignment in job titles can affect the results of automatic job ranking\nsystems. We propose the usage of metrics for ranking comparison controlling for\ngender to evaluate gender bias in job title ranking systems, in particular RBO\n(Rank-Biased Overlap). We generate and share test sets for a job title matching\ntask in four grammatical gender languages, including occupations in masculine\nand feminine form and annotated by gender and matching relevance. We use the\nnew test sets and the proposed methodology to evaluate the gender bias of\nseveral out-of-the-box multilingual models to set as baselines, showing that\nall of them exhibit varying degrees of gender bias.", "AI": {"tldr": "The paper investigates the impact of grammatical gender in job titles on automatic job ranking systems and proposes metrics to measure gender bias.", "motivation": "Understanding and mitigating gender bias in automated job ranking systems prompted this study.", "method": "The authors created test sets in four gendered languages and applied ranking comparison metrics, particularly Rank-Biased Overlap (RBO), to evaluate gender bias.", "result": "Analysis of multiple multilingual models revealed varying levels of gender bias in job ranking systems.", "conclusion": "Explicit grammatical gender in job titles has measurable effects on job ranking systems, with existing models showing bias, highlighting the need for further improvement."}}
{"id": "2509.13725", "pdf": "https://arxiv.org/pdf/2509.13725", "abs": "https://arxiv.org/abs/2509.13725", "authors": ["Md Sabbir Ahmed", "Noah French", "Mark Rucker", "Zhiyuan Wang", "Taylor Myers-Brower", "Kaitlyn Petz", "Mehdi Boukhechba", "Bethany A. Teachman", "Laura E. Barnes"], "title": "WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Social anxiety is a common mental health condition linked to significant\nchallenges in academic, social, and occupational functioning. A core feature is\nelevated momentary (state) anxiety in social situations, yet little prior work\nhas measured or predicted fluctuations in this anxiety throughout the day.\nCapturing these intra-day dynamics is critical for designing real-time,\npersonalized interventions such as Just-In-Time Adaptive Interventions\n(JITAIs). To address this gap, we conducted a study with socially anxious\ncollege students (N=91; 72 after exclusions) using our custom smartwatch-based\nsystem over an average of 9.03 days (SD = 2.95). Participants received seven\necological momentary assessments (EMAs) per day to report state anxiety. We\ndeveloped a base model on over 10,000 days of external heart rate data,\ntransferred its representations to our dataset, and fine-tuned it to generate\nprobabilistic predictions. These were combined with trait-level measures in a\nmeta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety\ndetection in our dataset. To evaluate generalizability, we applied the training\napproach to a separate hold-out set from the TILES-18 dataset-the same dataset\nused for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%\nbalanced accuracy, outperforming prior work by at least 7%.", "AI": {"tldr": "The study focuses on capturing real-time intra-day dynamics of state anxiety among socially anxious college students using smartwatch-based monitoring and predictive modeling, achieving promising results.", "motivation": "Social anxiety affects various aspects of functioning and is characterized by fluctuating state anxiety in social situations. Monitoring these fluctuations is essential for personalized interventions like Just-In-Time Adaptive Interventions (JITAIs).", "method": "The authors conducted a study with 72 socially anxious college students, collecting smartwatch heart rate data over 9 days, alongside ecological momentary assessments (EMAs). A predictive model was developed using transferred representations from external datasets and integrated trait-level measures.", "result": "The combined pipeline achieved 60.4% balanced accuracy in state anxiety detection in the study dataset and 59.1% balanced accuracy on a separate hold-out dataset, outperforming prior work by at least 7%.", "conclusion": "This approach demonstrates the feasibility of using wearable devices and advanced modeling to monitor and predict state anxiety, opening pathways for real-time interventions in socially anxious individuals."}}
{"id": "2509.13507", "pdf": "https://arxiv.org/pdf/2509.13507", "abs": "https://arxiv.org/abs/2509.13507", "authors": ["Artem Savkin", "Thomas Lapotre", "Kevin Strauss", "Uzair Akbar", "Federico Tombari"], "title": "Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "In the autonomous driving area synthetic data is crucial for cover specific\ntraffic scenarios which autonomous vehicle must handle. This data commonly\nintroduces domain gap between synthetic and real domains. In this paper we\ndeploy data augmentation to generate custom traffic scenarios with VRUs in\norder to improve pedestrian recognition. We provide a pipeline for augmentation\nof the Cityscapes dataset with virtual pedestrians. In order to improve\naugmentation realism of the pipeline we reveal a novel generative network\narchitecture for adversarial learning of the data-set lighting conditions. We\nalso evaluate our approach on the tasks of semantic and instance segmentation.", "AI": {"tldr": "The paper explores improving pedestrian recognition in autonomous driving by augmenting Cityscapes dataset with synthetic virtual pedestrians, employing a novel generative network for realistic lighting conditions.", "motivation": "The need for synthetic data to simulate specific traffic scenarios crucial for autonomous vehicles, particularly scenarios involving pedestrians.", "method": "A pipeline for data augmentation of the Cityscapes dataset with virtual pedestrians, incorporating a novel generative network for adversarial learning to replicate realistic lighting conditions.", "result": "Enhanced realism in augmented data and improved performance in semantic and instance segmentation tasks.", "conclusion": "Synthetic data with improved realism can significantly contribute to better pedestrian recognition and segmentation in autonomous driving applications."}}
{"id": "2509.13649", "pdf": "https://arxiv.org/pdf/2509.13649", "abs": "https://arxiv.org/abs/2509.13649", "authors": ["M\u00e9lon\u00e9 Nyoba Tchonkeu", "Soulaimane Berkane", "Tarek Hamel"], "title": "Barometer-Aided Attitude Estimation", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "6 pages, 4 figures. this manuscript is submitted to IEEE Control\n  Systems Letters (L-CSS) with American Control Conference (ACC) option", "summary": "Accurate and robust attitude estimation is a central challenge for autonomous\nvehicles operating in GNSS-denied or highly dynamic environments. In such\ncases, Inertial Measurement Units (IMUs) alone are insufficient for reliable\ntilt estimation due to the ambiguity between gravitational and inertial\naccelerations. While auxiliary velocity sensors, such as GNSS, Pitot tubes,\nDoppler radar, or visual odometry, are often used, they can be unavailable,\nintermittent, or costly. This work introduces a barometer-aided attitude\nestimation architecture that leverages barometric altitude measurements to\ninfer vertical velocity and attitude within a nonlinear observer on SO(3). The\ndesign cascades a deterministic Riccati observer with a complementary filter,\nensuring Almost Global Asymptotic Stability (AGAS) under a uniform\nobservability condition while maintaining geometric consistency. The analysis\nhighlights barometer-aided estimation as a lightweight and effective\ncomplementary modality.", "AI": {"tldr": "The paper presents a barometer-aided attitude estimation method for autonomous vehicles in GNSS-denied environments, combining a deterministic observer and complementary filter.", "motivation": "Autonomous vehicles face challenges in attitude estimation in GNSS-denied and dynamic environments where auxiliary sensors may be unavailable or unreliable.", "method": "The paper employs a nonlinear observer on SO(3) integrating barometric altitude measurements, coupled with deterministic Riccati observer and complementary filter.", "result": "The proposed method ensures Almost Global Asymptotic Stability (AGAS) and geometric consistency under uniform observability conditions.", "conclusion": "Barometer-based attitude estimation is validated as an effective and lightweight complementary solution for scenarios with unreliable or absent auxiliary velocity sensors."}}
{"id": "2509.13615", "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "This paper addresses the challenge of reliably executing toggle control instructions in GUI interaction by proposing the State-aware Reasoning (StaR) training method, improving multimodal agents' performance by over 30%.", "motivation": "The motivation is to address the unreliability of multimodal agents in executing toggle control instructions, particularly when the desired state already matches the current state.", "method": "The paper introduces a training method called State-aware Reasoning (StaR), which enables agents to perceive the current toggle state, analyze the desired state from instructions, and act accordingly.", "result": "Experiments show that StaR improves toggle execution accuracy by over 30% and generally enhances task performance on three public benchmarks.", "conclusion": "StaR significantly boosts multimodal agents' reliability and task performance in GUI interaction, making it a promising approach for real-world applications."}}
{"id": "2509.13813", "pdf": "https://arxiv.org/pdf/2509.13813", "abs": "https://arxiv.org/abs/2509.13813", "authors": ["Edward Phillips", "Sean Wu", "Soheila Molaei", "Danielle Belgrave", "Anshul Thakur", "David Clifton"], "title": "Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models demonstrate impressive results across diverse tasks but\nare still known to hallucinate, generating linguistically plausible but\nincorrect answers to questions. Uncertainty quantification has been proposed as\na strategy for hallucination detection, but no existing black-box approach\nprovides estimates for both global and local uncertainty. The former attributes\nuncertainty to a batch of responses, while the latter attributes uncertainty to\nindividual responses. Current local methods typically rely on white-box access\nto internal model states, whilst black-box methods only provide global\nuncertainty estimates. We introduce a geometric framework to address this,\nbased on archetypal analysis of batches of responses sampled with only\nblack-box model access. At the global level, we propose Geometric Volume, which\nmeasures the convex hull volume of archetypes derived from response embeddings.\nAt the local level, we propose Geometric Suspicion, which ranks responses by\nreliability and enables hallucination reduction through preferential response\nselection. Unlike prior dispersion methods which yield only a single global\nscore, our approach provides semantic boundary points which have utility for\nattributing reliability to individual responses. Experiments show that our\nframework performs comparably to or better than prior methods on short form\nquestion-answering datasets, and achieves superior results on medical datasets\nwhere hallucinations carry particularly critical risks. We also provide\ntheoretical justification by proving a link between convex hull volume and\nentropy.", "AI": {"tldr": "This paper introduces a new geometric framework for uncertainty quantification in large language models, focusing on both global and local uncertainty measures to detect hallucinations in responses.", "motivation": "Large language models often hallucinate, generating incorrect but plausible answers, and existing uncertainty quantification methods are limited to either global or local measures but not both.", "method": "The approach uses archetypal analysis of responses generated by black-box access, proposing Geometric Volume for global uncertainty and Geometric Suspicion for local reliability ranking.", "result": "Experiments show competitive or better performance than previous methods, especially on medical datasets where accurate detection of hallucinations is critical.", "conclusion": "The proposed framework improves upon prior methods, providing both theoretical and practical advancements in detecting and attributing uncertainty in language model responses."}}
{"id": "2509.13735", "pdf": "https://arxiv.org/pdf/2509.13735", "abs": "https://arxiv.org/abs/2509.13735", "authors": ["Junzhi She", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "State Space Models over Directed Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "currently undergoing review by IEEE Transactions on Big Data", "summary": "Directed graphs are ubiquitous across numerous domains, where the\ndirectionality of edges encodes critical causal dependencies. However, existing\nGNNs and graph Transformers tailored for directed graphs face two major\nchallenges: (1) effectively capturing long-range causal dependencies derived\nfrom directed edges; (2) balancing accuracy and training efficiency when\nprocessing large-scale graph datasets. In recent years, state space models\n(SSMs) have achieved substantial progress in causal sequence tasks, and their\nvariants designed for graphs have demonstrated state-of-the-art accuracy while\nmaintaining high efficiency across various graph learning benchmarks. However,\nexisting graph state space models are exclusively designed for undirected\ngraphs, which limits their performance in directed graph learning. To this end,\nwe propose an innovative approach DirEgo2Token which sequentializes directed\ngraphs via k-hop ego graphs. This marks the first systematic extension of state\nspace models to the field of directed graph learning. Building upon this, we\ndevelop DirGraphSSM, a novel directed graph neural network architecture that\nimplements state space models on directed graphs via the message-passing\nmechanism. Experimental results demonstrate that DirGraphSSM achieves\nstate-of-the-art performance on three representative directed graph learning\ntasks while attaining competitive performance on two additional tasks with\n1.5$\\times $ to 2$\\times $ training speed improvements compared to existing\nstate-of-the-art models.", "AI": {"tldr": "DirGraphSSM is introduced as a novel directed graph neural network using state space models, achieving state-of-the-art results and faster training on multiple directed graph tasks.", "motivation": "Existing methods for directed graphs face challenges in capturing causal dependencies and efficiency. There\u2019s a gap as state space models have proven effective in undirected graphs but not yet leveraged for directed graph learning.", "method": "The authors sequentialize directed graphs using k-hop ego graphs and build DirGraphSSM to implement state space models through a message-passing mechanism tailored for directed graphs.", "result": "DirGraphSSM delivers state-of-the-art performance on three directed graph learning tasks and competitive results on two others, with significantly faster training speeds compared to top models.", "conclusion": "DirGraphSSM systematically extends state space models to directed graphs, addressing limitations in existing methods and pushing forward directed graph learning with better accuracy and efficiency."}}
{"id": "2509.13508", "pdf": "https://arxiv.org/pdf/2509.13508", "abs": "https://arxiv.org/abs/2509.13508", "authors": ["Maksim Penkin", "Andrey Krylov"], "title": "FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation", "categories": ["cs.CV", "I.4.3; I.4.6"], "comment": "9 pages, 5 figures, submitted to the Fortieth AAAI Conference on\n  Artificial Intelligence (AAAI-26)", "summary": "Medical image enhancement and segmentation are critical yet challenging tasks\nin modern clinical practice, constrained by artifacts and complex anatomical\nvariations. Traditional deep learning approaches often rely on complex\narchitectures with limited interpretability. While Kolmogorov-Arnold networks\noffer interpretable solutions, their reliance on flattened feature\nrepresentations fundamentally disrupts the intrinsic spatial structure of\nimaging data. To address this issue we propose a Functional Kolmogorov-Arnold\nNetwork (FunKAN) -- a novel interpretable neural framework, designed\nspecifically for image processing, that formally generalizes the\nKolmogorov-Arnold representation theorem onto functional spaces and learns\ninner functions using Fourier decomposition over the basis Hermite functions.\nWe explore FunKAN on several medical image processing tasks, including Gibbs\nringing suppression in magnetic resonance images, benchmarking on IXI dataset.\nWe also propose U-FunKAN as state-of-the-art binary medical segmentation model\nwith benchmarks on three medical datasets: BUSI (ultrasound images), GlaS\n(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting\nbreast cancer, glands and polyps, respectively. Experiments on those diverse\ndatasets demonstrate that our approach outperforms other KAN-based backbones in\nboth medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work\nbridges the gap between theoretical function approximation and medical image\nanalysis, offering a robust, interpretable solution for clinical applications.", "AI": {"tldr": "This paper presents FunKAN, an interpretable neural framework for medical image enhancement and segmentation, utilizing functional Kolmogorov-Arnold representation for improved outcomes.", "motivation": "The study aims to address challenges in medical image processing, constrained by artifacts and complex anatomical variations, while improving interpretability and accuracy in segmentation methods.", "method": "The proposed method introduces FunKAN leveraging Fourier decomposition over Hermite functions to maintain spatial structure. It includes U-FunKAN for medical image segmentation applied to diverse medical imaging datasets.", "result": "FunKAN demonstrates superior performance in metrics like PSNR, TV for image enhancement, and IoU, F1 for segmentation tasks on diverse datasets compared to other KAN-based solutions.", "conclusion": "FunKAN bridges theoretical function approximation and practical clinical applications, offering an interpretable and effective tool for medical image processing."}}
{"id": "2509.13699", "pdf": "https://arxiv.org/pdf/2509.13699", "abs": "https://arxiv.org/abs/2509.13699", "authors": ["Max Barth", "Marie-Christine Jakobs"], "title": "Multi-Threaded Software Model Checking via Parallel Trace Abstraction Refinement", "categories": ["cs.LO", "cs.PL", "cs.SE"], "comment": null, "summary": "Automatic software verification is a valuable means for software quality\nassurance. However, automatic verification and in particular software model\nchecking can be time-consuming, which hinders their practical applicability\ne.g., the use in continuous integration. One solution to address the issue is\nto reduce the response time of the verification procedure by leveraging today's\nmulti-core CPUs.\n  In this paper, we propose a solution to parallelize trace abstraction, an\nabstraction-based approach to software model checking. The underlying idea of\nour approach is to parallelize the abstraction refinement. More concretely, our\napproach analyzes different traces (syntactic program paths) that could violate\nthe safety property in parallel. We realize our parallelized version of trace\nabstraction in the verification tool Ulti mate Automizer and perform a thorough\nevaluation. Our evaluation shows that our parallelization is more effective\nthan sequential trace abstraction and can provide results significantly faster\non many time-consuming tasks. Also, our approach is more effective than DSS, a\nrecent parallel approach to abstraction-based software model checking.", "AI": {"tldr": "The paper presents a parallelization approach to trace abstraction in software model checking, achieving faster results compared to sequential methods and outperforming recent parallel techniques.", "motivation": "Software model checking is hindered by time-consuming processes, limiting its practical application, especially in scenarios like continuous integration.", "method": "The method involves parallelizing trace abstraction by analyzing different traces that may violate safety properties simultaneously.", "result": "Evaluation of the parallelized version in Ultimate Automizer shows it is faster on time-consuming tasks and more effective than DSS.", "conclusion": "Parallelized trace abstraction enhances performance, making software model checking more practical and efficient."}}
{"id": "2509.13666", "pdf": "https://arxiv.org/pdf/2509.13666", "abs": "https://arxiv.org/abs/2509.13666", "authors": ["Zhenqi Wu", "Abhinav Modi", "Angelos Mavrogiannis", "Kaustubh Joshi", "Nikhil Chopra", "Yiannis Aloimonos", "Nare Karapetyan", "Ioannis Rekleitis", "Xiaomin Lin"], "title": "DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring", "categories": ["cs.RO", "cs.AI"], "comment": "submitted to ICRA 2026", "summary": "The ocean is warming and acidifying, increasing the risk of mass mortality\nevents for temperature-sensitive shellfish such as oysters. This motivates the\ndevelopment of long-term monitoring systems. However, human labor is costly and\nlong-duration underwater work is highly hazardous, thus favoring robotic\nsolutions as a safer and more efficient option. To enable underwater robots to\nmake real-time, environment-aware decisions without human intervention, we must\nequip them with an intelligent \"brain.\" This highlights the need for\npersistent,wide-area, and low-cost benthic monitoring. To this end, we present\nDREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term\nunderwater exploration and habitat monitoring. The results show that our\nframework is highly efficient in finding and exploring target objects (e.g.,\noysters, shipwrecks) without prior location information. In the\noyster-monitoring task, our framework takes 31.5% less time than the previous\nbaseline with the same amount of oysters. Compared to the vanilla VLM, it uses\n23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our\nframework successfully explores and maps the wreck without collisions,\nrequiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,\nwhile the vanilla model achieves 60.23% average coverage in our shipwreck\nenvironments.", "AI": {"tldr": "The paper introduces DREAM, a Vision Language Model-guided autonomy framework for underwater robots, allowing efficient environmental monitoring and exploration, with improved performance over existing methods.", "motivation": "The paper aims to address the environmental risk posed to temperature-sensitive shellfish, like oysters, due to ocean warming and acidification, and the high hazards and costs associated with long-term underwater monitoring conducted by humans.", "method": "The authors developed DREAM, an autonomous framework using Vision Language Model (VLM) technology to enable underwater robots for habitat and object exploration without requiring human intervention.", "result": "DREAM showed measurable improvements in tasks like oyster monitoring and shipwreck exploration by reducing time, steps, and errors, compared to baseline and vanilla VLM models.", "conclusion": "The framework's successful validation demonstrates the potential of VLM-guided autonomy for safer, cost-effective, and efficient underwater monitoring applications."}}
{"id": "2509.13704", "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "The paper introduces InfraMind, a new GUI agent framework designed for automation in industrial management systems, addressing challenges like precision and safety through innovative modules.", "motivation": "Increasing complexity in industrial management systems and limitations of existing automation tools like Robotic Process Automation require a more robust solution.", "method": "The framework employs exploration-based GUI understanding, memory-driven planning, hierarchical state identification, knowledge distillation, and comprehensive safety mechanisms.", "result": "Experiments on various industrial platforms show higher task success rates and operational efficiency compared to existing solutions.", "conclusion": "InfraMind offers a scalable and effective approach to advancing automation in complex industrial management systems."}}
{"id": "2509.13814", "pdf": "https://arxiv.org/pdf/2509.13814", "abs": "https://arxiv.org/abs/2509.13814", "authors": ["Kartik Shinde", "Laurent Besacier", "Ondrej Bojar", "Thibaut Thonet", "Tirthankar Ghosal"], "title": "Findings of the Third Automatic Minuting (AutoMin) Challenge", "categories": ["cs.CL"], "comment": "Automin 2025 Website: https://ufal.github.io/automin-2025/", "summary": "This paper presents the third edition of AutoMin, a shared task on automatic\nmeeting summarization into minutes. In 2025, AutoMin featured the main task of\nminuting, the creation of structured meeting minutes, as well as a new task:\nquestion answering (QA) based on meeting transcripts.\n  The minuting task covered two languages, English and Czech, and two domains:\nproject meetings and European Parliament sessions. The QA task focused solely\non project meetings and was available in two settings: monolingual QA in\nEnglish, and cross-lingual QA, where questions were asked and answered in Czech\nbased on English meetings.\n  Participation in 2025 was more limited compared to previous years, with only\none team joining the minuting task and two teams participating in QA. However,\nas organizers, we included multiple baseline systems to enable a comprehensive\nevaluation of current (2025) large language models (LLMs) on both tasks.", "AI": {"tldr": "The paper discusses the third edition of AutoMin, focusing on meeting summarization and question answering tasks in multiple languages and domains, with baseline evaluations using 2025 LLMs.", "motivation": "To advance automatic meeting summarization techniques and explore structured minutes and question answering functionalities.", "method": "Introduced shared tasks for generating structured minutes in English and Czech across different domains, and question answering tasks in monolingual and cross-lingual settings.", "result": "Limited participation with baseline systems provided by organizers, evaluating current large language models on the tasks.", "conclusion": "The shared task highlighted state-of-the-art capabilities and challenges of LLMs in meeting summarization and QA, but had limited external engagement."}}
{"id": "2509.13515", "pdf": "https://arxiv.org/pdf/2509.13515", "abs": "https://arxiv.org/abs/2509.13515", "authors": ["Jiangbei Yue", "Shuonan Yang", "Tailin Chen", "Jianbo Jiao", "Zeyu Fu"], "title": "Multimodal Hate Detection Using Dual-Stream Graph Neural Networks", "categories": ["cs.CV"], "comment": null, "summary": "Hateful videos present serious risks to online safety and real-world\nwell-being, necessitating effective detection methods. Although multimodal\nclassification approaches integrating information from several modalities\noutperform unimodal ones, they typically neglect that even minimal hateful\ncontent defines a video's category. Specifically, they generally treat all\ncontent uniformly, instead of emphasizing the hateful components. Additionally,\nexisting multimodal methods cannot systematically capture structured\ninformation in videos, limiting the effectiveness of multimodal fusion. To\naddress these limitations, we propose a novel multimodal dual-stream graph\nneural network model. It constructs an instance graph by separating the given\nvideo into several instances to extract instance-level features. Then, a\ncomplementary weight graph assigns importance weights to these features,\nhighlighting hateful instances. Importance weights and instance features are\ncombined to generate video labels. Our model employs a graph-based framework to\nsystematically model structured relationships within and across modalities.\nExtensive experiments on public datasets show that our model is\nstate-of-the-art in hateful video classification and has strong explainability.\nCode is available:\nhttps://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.", "AI": {"tldr": "This paper introduces a multimodal dual-stream graph neural network model to classify hateful videos by highlighting and weighting hateful content for state-of-the-art accuracy.", "motivation": "The challenge is in detecting hateful content in videos where even minimal hateful content defines the video's category. Previous methods treat all content uniformly and fail to systematically capture structured relationships, reducing the effectiveness of multimodal fusion.", "method": "The paper proposes constructing an instance graph to extract features and a weight graph to assign importance to hateful components. These are combined using a graph-based framework for classification purposes.", "result": "Experiments on public datasets indicate the proposed model outperforms existing methods and demonstrates strong explainability.", "conclusion": "The proposed model effectively addresses the limitations of previous methods, offering state-of-the-art performance and enhanced explainability in hateful video classification."}}
{"id": "2509.13691", "pdf": "https://arxiv.org/pdf/2509.13691", "abs": "https://arxiv.org/abs/2509.13691", "authors": ["Songhao Huang", "Yuwei Wu", "Guangyao Shi", "Gaurav S. Sukhatme", "Vijay Kumar"], "title": "SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics", "categories": ["cs.RO"], "comment": null, "summary": "We investigate the problem of automatic domain generation for the Planning\nDomain Definition Language (PDDL) using Large Language Models (LLMs), with a\nparticular focus on unmanned aerial vehicle (UAV) tasks. Although PDDL is a\nwidely adopted standard in robotic planning, manually designing domains for\ndiverse applications such as surveillance, delivery, and inspection is\nlabor-intensive and error-prone, which hinders adoption and real-world\ndeployment. To address these challenges, we propose SPAR, a framework that\nleverages the generative capabilities of LLMs to automatically produce valid,\ndiverse, and semantically accurate PDDL domains from natural language input. To\nthis end, we first introduce a systematically formulated and validated UAV\nplanning dataset, consisting of ground-truth PDDL domains and associated\nproblems, each paired with detailed domain and action descriptions. Building on\nthis dataset, we design a prompting framework that generates high-quality PDDL\ndomains from language input. The generated domains are evaluated through syntax\nvalidation, executability, feasibility, and interpretability. Overall, this\nwork demonstrates that LLMs can substantially accelerate the creation of\ncomplex planning domains, providing a reproducible dataset and evaluation\npipeline that enables application experts without prior experience to leverage\nit for practical tasks and advance future research in aerial robotics and\nautomated planning.", "AI": {"tldr": "This paper introduces SPAR, a framework for automatic generation of PDDL domains using large language models, focused on UAV tasks.", "motivation": "Manual design of PDDL domains for UAV applications like surveillance and delivery is labor-intensive and error-prone, limiting adoption and real-world usage.", "method": "Developed SPAR framework powered by LLMs to produce valid, diverse, and semantically accurate PDDL domains from natural language input, using a validated UAV planning dataset and a prompting framework.", "result": "Validated the generated PDDL domains through syntax checking, executability, feasibility, and interpretability.", "conclusion": "LLMs can significantly simplify the creation of complex planning domains, benefiting aerial robotics and automated planning research with a reproducible dataset and evaluation framework."}}
{"id": "2509.13761", "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "The paper introduces THOR, a method to enhance mathematical reasoning in LLMs by integrating external tools with optimized reinforcement learning strategies, achieving state-of-the-art results.", "motivation": "Despite the progress of LLMs in mathematical reasoning, they struggle with high-precision tasks. The motivation comes from addressing the gaps in tool integration for better performance and solving issues like dataset creation, fine-grained optimization, and inference improvement.", "method": "The authors propose THOR, which includes TIRGen (a multi-agent pipeline for dataset generation), hierarchical RL for trajectory-level and step-level optimization, and a self-correction mechanism for revising errors dynamically during inference.", "result": "THOR achieves generalization across diverse reasoning and non-reasoning models, yielding state-of-the-art results on multiple mathematical and code benchmarks.", "conclusion": "Integrating tools with hierarchical RL and self-correction improves LLM accuracy significantly for high-precision tasks, setting new benchmarks and making the approach versatile across model types."}}
{"id": "2509.13835", "pdf": "https://arxiv.org/pdf/2509.13835", "abs": "https://arxiv.org/abs/2509.13835", "authors": ["Minh Duc Bui", "Carolin Holtermann", "Valentin Hofmann", "Anne Lauscher", "Katharina von der Wense"], "title": "Large Language Models Discriminate Against Speakers of German Dialects", "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2025 Main", "summary": "Dialects represent a significant component of human culture and are found\nacross all regions of the world. In Germany, more than 40% of the population\nspeaks a regional dialect (Adler and Hansen, 2022). However, despite cultural\nimportance, individuals speaking dialects often face negative societal\nstereotypes. We examine whether such stereotypes are mirrored by large language\nmodels (LLMs). We draw on the sociolinguistic literature on dialect perception\nto analyze traits commonly associated with dialect speakers. Based on these\ntraits, we assess the dialect naming bias and dialect usage bias expressed by\nLLMs in two tasks: an association task and a decision task. To assess a model's\ndialect usage bias, we construct a novel evaluation corpus that pairs sentences\nfrom seven regional German dialects (e.g., Alemannic and Bavarian) with their\nstandard German counterparts. We find that: (1) in the association task, all\nevaluated LLMs exhibit significant dialect naming and dialect usage bias\nagainst German dialect speakers, reflected in negative adjective associations;\n(2) all models reproduce these dialect naming and dialect usage biases in their\ndecision making; and (3) contrary to prior work showing minimal bias with\nexplicit demographic mentions, we find that explicitly labeling linguistic\ndemographics--German dialect speakers--amplifies bias more than implicit cues\nlike dialect usage.", "AI": {"tldr": "This study investigates biases in large language models (LLMs) against German dialect speakers, identifying negative associations and decision-making biases, which are amplified by explicit demographic mentions.", "motivation": "Dialect speakers often face societal stereotypes, and this paper aims to determine if and how these stereotypes are reflected in the biases of large language models.", "method": "The researchers evaluated dialect biases in LLMs by using sociolinguistic traits in two tasks: an association task and a decision task, complemented by a novel corpus pairing sentences in seven German dialects with standard German variants.", "result": "Findings indicate significant bias against German dialect speakers in both tasks, including amplified negative associations when dialect demographics are explicitly labeled.", "conclusion": "Large language models exhibit pronounced biases against German dialect speakers, which are exacerbated by explicit labeling, highlighting potential shortcomings in current LLM design."}}
{"id": "2509.13753", "pdf": "https://arxiv.org/pdf/2509.13753", "abs": "https://arxiv.org/abs/2509.13753", "authors": ["Hyotaek Jeon", "Hyunwook Lee", "Juwon Kim", "Sungahn Ko"], "title": "ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting", "categories": ["cs.LG"], "comment": "11 pages, 4 figures, Accepted to CIKM 2025. Code:\n  https://github.com/HyoTaek98/ST_LINK", "summary": "Traffic forecasting represents a crucial problem within intelligent\ntransportation systems. In recent research, Large Language Models (LLMs) have\nemerged as a promising method, but their intrinsic design, tailored primarily\nfor sequential token processing, introduces notable challenges in effectively\ncapturing spatial dependencies. Specifically, the inherent limitations of LLMs\nin modeling spatial relationships and their architectural incompatibility with\ngraph-structured spatial data remain largely unaddressed. To overcome these\nlimitations, we introduce ST-LINK, a novel framework that enhances the\ncapability of Large Language Models to capture spatio-temporal dependencies.\nIts key components are Spatially-Enhanced Attention (SE-Attention) and the\nMemory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary\nposition embeddings to integrate spatial correlations as direct rotational\ntransformations within the attention mechanism. This approach maximizes spatial\nlearning while preserving the LLM's inherent sequential processing structure.\nMeanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to\ncapture complex temporal dependencies and improve the stability of long-term\nforecasting. Comprehensive experiments on benchmark datasets demonstrate that\nST-LINK surpasses conventional deep learning and LLM approaches, and\neffectively captures both regular traffic patterns and abrupt changes.", "AI": {"tldr": "ST-LINK framework introduces Spatially-Enhanced Attention (SE-Attention) and Memory Retrieval Feed-Forward Network (MRFFN) to improve LLMs' ability to capture spatio-temporal data, outperforming current traffic forecasting methods.", "motivation": "Address limitations of LLMs in effectively capturing spatial dependencies in traffic forecasting due to their sequential token processing design.", "method": "Incorporate SE-Attention to connect spatial data with rotary position embeddings and MRFFN for retrieving historical temporal patterns to enhance forecasting performance.", "result": "ST-LINK outperforms conventional deep learning and LLM methods on benchmark datasets, capturing regular and abrupt changes in traffic patterns effectively.", "conclusion": "The framework provides a powerful enhancement of LLMs' ability to model spatio-temporal dependencies, demonstrating significant benefits for intelligent transportation systems."}}
{"id": "2509.13525", "pdf": "https://arxiv.org/pdf/2509.13525", "abs": "https://arxiv.org/abs/2509.13525", "authors": ["Romain Hardy", "Tyler Berzin", "Pranav Rajpurkar"], "title": "ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "Three-dimensional (3D) scene understanding in colonoscopy presents\nsignificant challenges that necessitate automated methods for accurate depth\nestimation. However, existing depth estimation models for endoscopy struggle\nwith temporal consistency across video sequences, limiting their applicability\nfor 3D reconstruction. We present ColonCrafter, a diffusion-based depth\nestimation model that generates temporally consistent depth maps from monocular\ncolonoscopy videos. Our approach learns robust geometric priors from synthetic\ncolonoscopy sequences to generate temporally consistent depth maps. We also\nintroduce a style transfer technique that preserves geometric structure while\nadapting real clinical videos to match our synthetic training domain.\nColonCrafter achieves state-of-the-art zero-shot performance on the C3VD\ndataset, outperforming both general-purpose and endoscopy-specific approaches.\nAlthough full trajectory 3D reconstruction remains a challenge, we demonstrate\nclinically relevant applications of ColonCrafter, including 3D point cloud\ngeneration and surface coverage assessment.", "AI": {"tldr": "The paper introduces ColonCrafter, a diffusion model for temporally consistent depth estimation in colonoscopy videos, achieving state-of-the-art results.", "motivation": "To address challenges with temporal inconsistency in depth estimation for colonoscopy video sequences, which limits 3D reconstruction and analysis.", "method": "The method involves a diffusion-based depth estimation model that learns geometric priors from synthetic colonoscopy data and employs a style transfer to adapt real clinical videos to the synthetic domain while maintaining geometric consistency.", "result": "ColonCrafter demonstrates superior zero-shot performance on the C3VD dataset, surpassing general-purpose and endoscopy-specific methods, and supports tasks like point cloud generation and surface coverage assessment.", "conclusion": "ColonCrafter offers a robust solution for temporally consistent depth estimation in colonoscopy, with potential applications in clinical 3D modeling workflows."}}
{"id": "2509.13692", "pdf": "https://arxiv.org/pdf/2509.13692", "abs": "https://arxiv.org/abs/2509.13692", "authors": ["Yadan Zeng", "Jiadong Zhou", "Xiaohan Li", "I-Ming Chen"], "title": "HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion", "categories": ["cs.RO"], "comment": "9 pages, 6 figures", "summary": "Point cloud completion is essential for robotic perception, object\nreconstruction and supporting downstream tasks like grasp planning, obstacle\navoidance, and manipulation. However, incomplete geometry caused by\nself-occlusion and sensor limitations can significantly degrade downstream\nreasoning and interaction. To address these challenges, we propose HGACNet, a\nnovel framework that reconstructs complete point clouds of individual objects\nby hierarchically encoding 3D geometric features and fusing them with\nimage-guided priors from a single-view RGB image. At the core of our approach,\nthe Hierarchical Graph Attention (HGA) encoder adaptively selects critical\nlocal points through graph attention-based downsampling and progressively\nrefines hierarchical geometric features to better capture structural continuity\nand spatial relationships. To strengthen cross-modal interaction, we further\ndesign a Multi-Scale Cross-Modal Fusion (MSCF) module that performs\nattention-based feature alignment between hierarchical geometric features and\nstructured visual representations, enabling fine-grained semantic guidance for\ncompletion. In addition, we proposed the contrastive loss (C-Loss) to\nexplicitly align the feature distributions across modalities, improving\ncompletion fidelity under modality discrepancy. Finally, extensive experiments\nconducted on both the ShapeNet-ViPC benchmark and the YCB-Complete dataset\nconfirm the effectiveness of HGACNet, demonstrating state-of-the-art\nperformance as well as strong applicability in real-world robotic manipulation\ntasks.", "AI": {"tldr": "HGACNet is proposed for completing incomplete 3D object point clouds by using a combination of hierarchical geometric encoding and image-guided priors, achieving state-of-the-art results in experiments.", "motivation": "Incomplete 3D point clouds caused by sensor limitations and occlusion hinder key robotic processes like object reconstruction and downstream tasks such as grasp planning and manipulation.", "method": "HGACNet uses a Hierarchical Graph Attention encoder to hierarchically encode 3D features and aligns them with image information using a Multi-Scale Cross-Modal Fusion module. A new contrastive loss is introduced to align feature distributions across modalities.", "result": "The framework demonstrates state-of-the-art performance in point cloud completion on benchmarks such as ShapeNet-ViPC and YCB-Complete, showing its effectiveness for robotic manipulation tasks.", "conclusion": "HGACNet effectively addresses the challenges in point cloud completion by fusing geometric and image-guided features, offering a robust tool for robotic applications that improves fidelity and effectiveness."}}
{"id": "2509.13773", "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "MIRA is a framework enabling intuitive AI task instructions on smartphones through multimodal pipelines and advanced reasoning, significantly improving interaction accuracy.", "motivation": "To simplify smartphone user interaction with AI services by providing context-aware, intuitive task recommendations.", "method": "MIRA uses a multimodal large language model for recommendation, template-augmented reasoning for task inference, and a prefix-tree-based decoding strategy for coherent instruction suggestions.", "result": "Demonstrated improved instruction recommendation accuracy through evaluation with real-world datasets and a user study.", "conclusion": "MIRA can revolutionize smartphone AI interactions by making tasking more user-friendly and efficient."}}
{"id": "2509.13869", "pdf": "https://arxiv.org/pdf/2509.13869", "abs": "https://arxiv.org/abs/2509.13869", "authors": ["Yang Liu", "Chenhui Chu"], "title": "Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs", "categories": ["cs.CL"], "comment": "38 pages, 31 figures", "summary": "Large language models (LLMs) can lead to undesired consequences when\nmisaligned with human values, especially in scenarios involving complex and\nsensitive social biases. Previous studies have revealed the misalignment of\nLLMs with human values using expert-designed or agent-based emulated bias\nscenarios. However, it remains unclear whether the alignment of LLMs with human\nvalues differs across different types of scenarios (e.g., scenarios containing\nnegative vs. non-negative questions). In this study, we investigate the\nalignment of LLMs with human values regarding social biases (HVSB) in different\ntypes of bias scenarios. Through extensive analysis of 12 LLMs from four model\nfamilies and four datasets, we demonstrate that LLMs with large model parameter\nscales do not necessarily have lower misalignment rate and attack success rate.\nMoreover, LLMs show a certain degree of alignment preference for specific types\nof scenarios and the LLMs from the same model family tend to have higher\njudgment consistency. In addition, we study the understanding capacity of LLMs\nwith their explanations of HVSB. We find no significant differences in the\nunderstanding of HVSB across LLMs. We also find LLMs prefer their own generated\nexplanations. Additionally, we endow smaller language models (LMs) with the\nability to explain HVSB. The generation results show that the explanations\ngenerated by the fine-tuned smaller LMs are more readable, but have a\nrelatively lower model agreeability.", "AI": {"tldr": "This paper investigates the alignment of large language models (LLMs) with human values in social bias scenarios, finding discrepancies in alignment across model scales, families, and scenario types.", "motivation": "The goal is to understand how well LLMs align with human values in scenarios involving social biases and identify variations in alignment based on model scale, family, and scenario type.", "method": "The authors evaluated 12 LLMs from four model families using diverse datasets and analyzed alignment across different bias scenarios, along with the LLMs' explanation capabilities.", "result": "LLMs don't show consistent improvements in alignment with larger scales; models from the same family exhibit similar judgment patterns. No major differences were observed in explaining social biases across models, but smaller fine-tuned LMs generated readable yet less agreeable explanations.", "conclusion": "LLMs exhibit preferences in alignment with certain bias scenarios and varying performance in explaining biases. Fine-tuning smaller LMs improves readability but sacrifices agreeability."}}
{"id": "2509.13763", "pdf": "https://arxiv.org/pdf/2509.13763", "abs": "https://arxiv.org/abs/2509.13763", "authors": ["Zongxin Shen", "Yanyong Huang", "Bin Wang", "Jinyuan Chang", "Shiyu Liu", "Tianrui Li"], "title": "Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning", "categories": ["cs.LG"], "comment": null, "summary": "Multi-view unsupervised feature selection (MUFS) has recently received\nincreasing attention for its promising ability in dimensionality reduction on\nmulti-view unlabeled data. Existing MUFS methods typically select\ndiscriminative features by capturing correlations between features and\nclustering labels. However, an important yet underexplored question remains:\n\\textit{Are such correlations sufficiently reliable to guide feature\nselection?} In this paper, we analyze MUFS from a causal perspective by\nintroducing a novel structural causal model, which reveals that existing\nmethods may select irrelevant features because they overlook spurious\ncorrelations caused by confounders. Building on this causal perspective, we\npropose a novel MUFS method called CAusal multi-view Unsupervised feature\nSelection leArning (CAUSA). Specifically, we first employ a generalized\nunsupervised spectral regression model that identifies informative features by\ncapturing dependencies between features and consensus clustering labels. We\nthen introduce a causal regularization module that can adaptively separate\nconfounders from multi-view data and simultaneously learn view-shared sample\nweights to balance confounder distributions, thereby mitigating spurious\ncorrelations. Thereafter, integrating both into a unified learning framework\nenables CAUSA to select causally informative features. Comprehensive\nexperiments demonstrate that CAUSA outperforms several state-of-the-art\nmethods. To our knowledge, this is the first in-depth study of causal\nmulti-view feature selection in the unsupervised setting.", "AI": {"tldr": "This paper introduces CAUSA, a novel method for multi-view unsupervised feature selection that uses a structural causal model to mitigate spurious correlations caused by confounders.", "motivation": "To address shortcomings in existing MUFS methods that rely on potentially unreliable correlations between features and clustering labels, which can lead to the selection of irrelevant features due to confounding variables.", "method": "The proposed CAUSA method uses a structural causal model to incorporate a causal regularization module for separating confounders and balancing confounder distributions, integrated with a spectral regression model for feature selection.", "result": "Experiments show that CAUSA outperforms other state-of-the-art MUFS methods in selecting causally informative features and achieving dimensionality reduction on multi-view unlabeled data.", "conclusion": "CAUSA represents the first deep exploration of causal approaches for multi-view unsupervised feature selection, demonstrating superior performance and advancing understanding in the field."}}
{"id": "2509.13536", "pdf": "https://arxiv.org/pdf/2509.13536", "abs": "https://arxiv.org/abs/2509.13536", "authors": ["Yinlong Bai", "Hongxin Zhang", "Sheng Zhong", "Junkai Niu", "Hai Li", "Yijia He", "Yi Zhou"], "title": "MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant\nimpact on rendering and reconstruction techniques. Current research\npredominantly focuses on improving rendering performance and reconstruction\nquality using high-performance desktop GPUs, largely overlooking applications\nfor embedded platforms like micro air vehicles (MAVs). These devices, with\ntheir limited computational resources and memory, often face a trade-off\nbetween system performance and reconstruction quality. In this paper, we\nimprove existing methods in terms of GPU memory usage while enhancing rendering\nquality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we\npropose merging them in voxel space based on geometric similarity. This reduces\nGPU memory usage without impacting system runtime performance. Furthermore,\nrendering quality is improved by initializing 3D Gaussian primitives via\nPatch-Grid (PG) point sampling, enabling more accurate modeling of the entire\nscene. Quantitative and qualitative evaluations on publicly available datasets\ndemonstrate the effectiveness of our improvements.", "AI": {"tldr": "The paper improves 3D Gaussian Splatting for rendering and reconstruction on limited-resource hardware, particularly enhancing GPU memory efficiency and rendering quality using voxel merging and Patch-Grid point sampling.", "motivation": "To address the challenges of adapting 3D rendering and reconstruction techniques, especially 3D Gaussian Splatting, for embedded platforms with limited resources like MAVs.", "method": "The authors reduce memory use by merging redundant 3D Gaussian primitives in voxel spaces. They enhance rendering accuracy by leveraging Patch-Grid sampling for better 3D primitive initialization.", "result": "Experiments demonstrate reduced GPU memory usage with no runtime performance loss while achieving improvements in rendering quality across public datasets.", "conclusion": "The proposed techniques make 3D Gaussian Splatting more resource-efficient and accessible for embedded applications like MAVs, while maintaining high reconstruction quality and system performance."}}
{"id": "2509.13720", "pdf": "https://arxiv.org/pdf/2509.13720", "abs": "https://arxiv.org/abs/2509.13720", "authors": ["Tianle Zeng", "Jianwei Peng", "Hanjing Ye", "Guangcheng Chen", "Senzi Luo", "Hong Zhang"], "title": "EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility", "categories": ["cs.RO"], "comment": "Page:https://tianlezeng.github.io/EzReal/", "summary": "Zero-shot object navigation (ZSON) in large-scale outdoor environments faces\nmany challenges; we specifically address a coupled one: long-range targets that\nreduce to tiny projections and intermittent visibility due to partial or\ncomplete occlusion. We present a unified, lightweight closed-loop system built\non an aligned multi-scale image tile hierarchy. Through hierarchical\ntarget-saliency fusion, it summarizes localized semantic contrast into a stable\ncoarse-layer regional saliency that provides the target direction and indicates\ntarget visibility. This regional saliency supports visibility-aware heading\nmaintenance through keyframe memory, saliency-weighted fusion of historical\nheadings, and active search during temporary invisibility. The system avoids\nwhole-image rescaling, enables deterministic bottom-up aggregation, supports\nzero-shot navigation, and runs efficiently on a mobile robot. Across simulation\nand real-world outdoor trials, the system detects semantic targets beyond 150m,\nmaintains a correct heading through visibility changes with 82.6% probability,\nand improves overall task success by 17.5% compared with the SOTA methods,\ndemonstrating robust ZSON toward distant and intermittently observable targets.", "AI": {"tldr": "This paper introduces a lightweight system for zero-shot object navigation (ZSON) in large-scale outdoor environments, addressing challenges like long-range targets and intermittent visibility. It achieves significant improvements in task success.", "motivation": "To enhance zero-shot object navigation in outdoor scenarios where long-range visibility and occlusion are critical challenges.", "method": "The paper proposes a hierarchical target-saliency fusion system that uses a multi-scale image tile hierarchy to provide visibility-aware heading maintenance without requiring whole-image rescaling.", "result": "The system detects semantic targets beyond 150 meters, maintains correct headings with 82.6% probability during visibility changes, and improves task success by 17.5% compared to SOTA methods.", "conclusion": "The system demonstrates robustness in navigating toward distant and intermittently visible targets, making advancements in large-scale outdoor ZSON tasks."}}
{"id": "2509.13880", "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "categories": ["cs.AI"], "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "This paper introduces an exact method for model counting over integer linear constraints, achieving superior benchmark performance compared to existing methods.", "motivation": "Integer linear constraints are widely used across various disciplines, and model counting for such constraints (MCILC) is a common challenge for applications like computer science and optimization. Current approaches can be inefficient or incomplete.", "method": "The authors design an exact MCILC approach built on an exhaustive DPLL architecture, enhanced by integrating simplification techniques from mixed integer programming.", "result": "Experimentation on 2840 random and 4131 application benchmarks revealed that the proposed method outperforms existing exact methods, solving 1718 random instances (compared to 1470) and is the only method that solved all 4131 application instances.", "conclusion": "The proposed method provides a more efficient and comprehensive solution for MCILC, setting a new benchmark in exact approaches for solving integer linear constraint challenges."}}
{"id": "2509.13879", "pdf": "https://arxiv.org/pdf/2509.13879", "abs": "https://arxiv.org/abs/2509.13879", "authors": ["Mariano Barone", "Antonio Romano", "Giuseppe Riccio", "Marco Postiglione", "Vincenzo Moscato"], "title": "Combining Evidence and Reasoning for Biomedical Fact-Checking", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Proceedings of the 48th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval, 2025", "summary": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https: //github.com/PRAISELab-PicusLab/CER.", "AI": {"tldr": "The paper tackles misinformation in healthcare with the CER framework, combining evidence retrieval, reasoning via LLMs, and supervised prediction, achieving state-of-the-art performance.", "motivation": "To address risks posed by misinformation in healthcare such as vaccine hesitancy and unproven treatments, and to improve biomedical claim validation.", "method": "The authors developed a framework called CER, which integrates evidence retrieval techniques, reasoning powered by large language models, and supervised prediction to validate claims.", "result": "CER achieved state-of-the-art results on expert annotated datasets and showed strong cross-dataset generalization capabilities.", "conclusion": "The proposed CER framework effectively mitigates issues in biomedical misinformation validation, offering a reproducible and transparent approach to grounding predictions in evidence-based sources."}}
{"id": "2509.13783", "pdf": "https://arxiv.org/pdf/2509.13783", "abs": "https://arxiv.org/abs/2509.13783", "authors": ["Tianshuo Zhang", "Wenzhe Zhai", "Rui Yann", "Jia Gao", "He Cao", "Xianglei Xing"], "title": "Floating-Body Hydrodynamic Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Fluid-structure interaction is common in engineering and natural systems,\nwhere floating-body motion is governed by added mass, drag, and background\nflows. Modeling these dissipative dynamics is difficult: black-box neural\nmodels regress state derivatives with limited interpretability and unstable\nlong-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks\n(FHNN), a physics-structured framework that predicts interpretable hydrodynamic\nparameters such as directional added masses, drag coefficients, and a\nstreamfunction-based flow, and couples them with analytic equations of motion.\nThis design constrains the hypothesis space, enhances interpretability, and\nstabilizes integration. On synthetic vortex datasets, FHNN achieves up to an\norder-of-magnitude lower error than Neural ODEs, recovers physically consistent\nflow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN\nmore effectively handles dissipative dynamics while preserving\ninterpretability, which bridges the gap between black-box learning and\ntransparent system identification.", "AI": {"tldr": "The paper introduces FHNN, a physics-structured neural network for modeling fluid-structure interactions with better accuracy and interpretability.", "motivation": "Fluid-structure interactions are challenging to model due to the complexity of dissipative dynamics and limitations in current black-box neural methods.", "method": "Proposing FHNN, which blends physics-informed hydrodynamic parameter estimation with analytic equations of motion to improve predictions and stability.", "result": "FHNN outperformed Neural ODEs in error reduction and provided physically consistent flow fields. It also surpassed Hamiltonian and Lagrangian neural networks in handling dissipative dynamics.", "conclusion": "FHNN bridges the gap between black-box learning and interpretable system identification, enabling efficient modeling of fluid-structure interactions."}}
{"id": "2509.13577", "pdf": "https://arxiv.org/pdf/2509.13577", "abs": "https://arxiv.org/abs/2509.13577", "authors": ["Tongfei Guo", "Lili Su"], "title": "Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "8 pages, 7 figures", "summary": "Trajectory prediction is central to the safe and seamless operation of\nautonomous vehicles (AVs). In deployment, however, prediction models inevitably\nface distribution shifts between training data and real-world conditions, where\nrare or underrepresented traffic scenarios induce out-of-distribution (OOD)\ncases. While most prior OOD detection research in AVs has concentrated on\ncomputer vision tasks such as object detection and segmentation,\ntrajectory-level OOD detection remains largely underexplored. A recent study\nformulated this problem as a quickest change detection (QCD) task, providing\nformal guarantees on the trade-off between detection delay and false alarms\n[1]. Building on this foundation, we propose a new framework that introduces\nadaptive mechanisms to achieve robust detection in complex driving\nenvironments. Empirical analysis across multiple real-world datasets reveals\nthat prediction errors -- even on in-distribution samples -- exhibit\nmode-dependent distributions that evolve over time with dataset-specific\ndynamics. By explicitly modeling these error modes, our method achieves\nsubstantial improvements in both detection delay and false alarm rates.\nComprehensive experiments on established trajectory prediction benchmarks show\nthat our framework significantly outperforms prior UQ- and vision-based OOD\napproaches in both accuracy and computational efficiency, offering a practical\npath toward reliable, driving-aware autonomy.", "AI": {"tldr": "The paper introduces an advanced framework for trajectory-level out-of-distribution (OOD) detection in autonomous vehicles, outperforming existing methods in accuracy and efficiency.", "motivation": "To address the challenge of detecting distribution shifts in trajectory prediction for autonomous vehicles, particularly in rare or complex traffic scenarios.", "method": "A new framework with adaptive mechanisms that model mode-specific prediction error distributions, enhancing robustness in OOD detection in trajectory predictions.", "result": "Significant improvement in detection delay and false alarm rates compared to prior methods, validated through experiments on real-world and benchmark datasets.", "conclusion": "The proposed framework offers a robust solution for trajectory-level OOD detection, paving the way for more reliable and efficient autonomous vehicle operations."}}
{"id": "2509.13731", "pdf": "https://arxiv.org/pdf/2509.13731", "abs": "https://arxiv.org/abs/2509.13731", "authors": ["Jeongwoo Park", "Seabin Lee", "Changmin Park", "Wonjong Lee", "Changjoo Nam"], "title": "Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings", "categories": ["cs.RO"], "comment": null, "summary": "The industrial insertion of flexible flat cables (FFCs) into receptacles\npresents a significant challenge owing to the need for submillimeter precision\nwhen handling the deformable cables. In manufacturing processes, FFC insertion\nwith robotic manipulators often requires laborious human-guided trajectory\ngeneration. While Reinforcement Learning (RL) offers a solution to automate\nthis task without modeling complex properties of FFCs, the nondeterminism\ncaused by the deformability of FFCs requires significant efforts and time on\ntraining. Moreover, training directly in a real environment is dangerous as\nindustrial robots move fast and possess no safety measure. We propose an RL\nalgorithm for FFC insertion that leverages a foundation model-based real-to-sim\napproach to reduce the training time and eliminate the risk of physical damages\nto robots and surroundings. Training is done entirely in simulation, allowing\nfor random exploration without the risk of physical damages. Sim-to-real\ntransfer is achieved through semantic segmentation masks which leave only those\nvisual features relevant to the insertion tasks such as the geometric and\nspatial information of the cables and receptacles. To enhance generality, we\nuse a foundation model, Segment Anything Model 2 (SAM2). To eleminate human\nintervention, we employ a Vision-Language Model (VLM) to automate the initial\nprompting of SAM2 to find segmentation masks. In the experiments, our method\nexhibits zero-shot capabilities, which enable direct deployments to real\nenvironments without fine-tuning.", "AI": {"tldr": "This paper addresses the challenge of submillimeter-precise insertion of flexible flat cables (FFCs) into industrial receptacles, using a reinforcement learning approach trained entirely in simulation.", "motivation": "Automating the precise insertion of FFCs into receptacles is challenging due to the cables\u2019 deformability and safety risks during training with fast industrial robots.", "method": "The authors proposed training reinforcement learning entirely in simulation by using a foundation model-based real-to-sim approach, semantic segmentation, and the Segment Anything Model 2 (SAM2) with automated prompting via a Vision-Language Model (VLM).", "result": "The proposed method achieved zero-shot capabilities, allowing for direct deployment in real-world environments without requiring fine-tuning.", "conclusion": "The foundation model-based RL training approach successfully automates the high-precision insertion of FFCs, reducing risks, training time, and eliminating human intervention."}}
{"id": "2509.13968", "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "The study investigates how changes in network topology, particularly recurrent and laminated structures in artificial neural networks, can cause transitions in cognitive performance when learning complex grammars.", "motivation": "To understand whether changes in information flow in neural networks can lead to qualitative changes in cognitive performance, similar to major transitions in evolutionary biology.", "method": "The authors employed idealized computational models of artificial neural networks (ANNs) with feed-forward, recurrent, and laminated topologies. They evaluated these networks on their capacity to learn artificial grammars of varying complexities while controlling for network size and computational resources.", "result": "Recurrent networks showed a qualitative improvement in processing complex inputs and learning advanced grammars compared to feed-forward networks. However, training recurrent networks was more challenging due to transition barriers, and laminated networks did not consistently enhance performance.", "conclusion": "Changes in network topology, such as incorporating recurrent connections, can lead to significant transitions in cognitive capabilities, although not all topological changes guarantee performance improvements."}}
{"id": "2509.13888", "pdf": "https://arxiv.org/pdf/2509.13888", "abs": "https://arxiv.org/abs/2509.13888", "authors": ["Mariano Barone", "Antonio Romano", "Giuseppe Riccio", "Marco Postiglione", "Vincenzo Moscato"], "title": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https://github.com/PRAISELab-PicusLab/CER", "AI": {"tldr": "The paper introduces CER, a framework integrating evidence retrieval, reasoning via large language models, and supervised veracity prediction for biomedical fact-checking, achieving state-of-the-art results.", "motivation": "The study addresses the challenge of misinformation in healthcare, emphasizing the need for accurate biomedical fact-checking due to complex terminology, required domain expertise, and reliance on scientific evidence.", "method": "The CER framework combines large language models' text generation capabilities, advanced retrieval techniques for scientific evidence, and supervised veracity prediction to mitigate hallucinations and ensure evidence-grounded outputs.", "result": "CER demonstrated state-of-the-art performance on expert-annotated biomedical datasets (e.g., HealthFC, BioASQ-7b, SciFact) and showed good cross-dataset generalization.", "conclusion": "CER significantly enhances biomedical fact-checking through its integration of retrieval, reasoning, and prediction, contributing to combating misinformation. The resources are open-sourced for transparency."}}
{"id": "2509.13586", "pdf": "https://arxiv.org/pdf/2509.13586", "abs": "https://arxiv.org/abs/2509.13586", "authors": ["Nathalie Neptune", "Josiane Mothe"], "title": "Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.MM", "I.2; I.4; I.7; H.3"], "comment": null, "summary": "The Amazon rain forest is a vital ecosystem that plays a crucial role in\nregulating the Earth's climate and providing habitat for countless species.\nDeforestation in the Amazon is a major concern as it has a significant impact\non global carbon emissions and biodiversity. In this paper, we present a method\nfor detecting deforestation in the Amazon using image pairs from Earth\nobservation satellites. Our method leverages deep learning techniques to\ncompare the images of the same area at different dates and identify changes in\nthe forest cover. We also propose a visual semantic model that automatically\nannotates the detected changes with relevant keywords. The candidate annotation\nfor images are extracted from scientific documents related to the Amazon\nregion. We evaluate our approach on a dataset of Amazon image pairs and\ndemonstrate its effectiveness in detecting deforestation and generating\nrelevant annotations. Our method provides a useful tool for monitoring and\nstudying the impact of deforestation in the Amazon. While we focus on\nenvironment applications of our work by using images of deforestation in the\nAmazon rain forest to demonstrate the effectiveness of our proposed approach,\nit is generic enough to be applied to other domains.", "AI": {"tldr": "The paper introduces a deep learning method using satellite images to detect deforestation in the Amazon and provides automated annotations to understand changes.", "motivation": "Deforestation in the Amazon impacts global carbon emissions, biodiversity, and Earth's climate, making detection and monitoring essential.", "method": "Deep learning techniques analyze satellite image pairs taken at different times, identifying forest cover changes and annotating them using visual semantic models.", "result": "The approach successfully detects deforestation in the Amazon and generates relevant annotations, validated on a dataset of image pairs.", "conclusion": "The method is effective for environmental monitoring in the Amazon and general enough for applications in other domains."}}
{"id": "2509.13733", "pdf": "https://arxiv.org/pdf/2509.13733", "abs": "https://arxiv.org/abs/2509.13733", "authors": ["Xiaolin Zhou", "Tingyang Xiao", "Liu Liu", "Yucheng Wang", "Maiyue Chen", "Xinrui Meng", "Xinjie Wang", "Wei Feng", "Wei Sui", "Zhizhong Su"], "title": "FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph", "categories": ["cs.RO"], "comment": "8 pages", "summary": "Visual-Language Navigation (VLN) is a fundamental challenge in robotic\nsystems, with broad applications for the deployment of embodied agents in\nreal-world environments. Despite recent advances, existing approaches are\nlimited in long-range spatial reasoning, often exhibiting low success rates and\nhigh inference latency, particularly in long-range navigation tasks. To address\nthese limitations, we propose FSR-VLN, a vision-language navigation system that\ncombines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow\nNavigation Reasoning (FSR). The HMSG provides a multi-modal map representation\nsupporting progressive retrieval, from coarse room-level localization to\nfine-grained goal view and object identification. Building on HMSG, FSR first\nperforms fast matching to efficiently select candidate rooms, views, and\nobjects, then applies VLM-driven refinement for final goal selection. We\nevaluated FSR-VLN across four comprehensive indoor datasets collected by\nhumanoid robots, utilizing 87 instructions that encompass a diverse range of\nobject categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all\ndatasets, measured by the retrieval success rate (RSR), while reducing the\nresponse time by 82% compared to VLM-based methods on tour videos by activating\nslow reasoning only when fast intuition fails. Furthermore, we integrate\nFSR-VLN with speech interaction, planning, and control modules on a Unitree-G1\nhumanoid robot, enabling natural language interaction and real-time navigation.", "AI": {"tldr": "FSR-VLN is a system for Visual-Language Navigation (VLN) that achieves high success rates and reduces response time compared to existing methods by using hierarchical reasoning and efficient candidate selection.", "motivation": "The motivation behind this paper is the need for efficient and accurate VLN systems to enable robots to navigate real-world environments while overcoming limitations in long-range spatial reasoning and inference latency.", "method": "The system combines a Hierarchical Multi-modal Scene Graph (HMSG) for map representation and Fast-to-Slow Navigation Reasoning (FSR) for efficient candidate selection followed by refined goal selection using Vision-Language Models (VLMs).", "result": "FSR-VLN achieves state-of-the-art performance in four indoor datasets, improves the retrieval success rate (RSR), reduces response time by 82%, and was successfully integrated into a humanoid robot for real-time navigation and speech interaction.", "conclusion": "FSR-VLN demonstrates significant improvements in navigation accuracy, speed, and real-world applicability, marking advancements in embodied robotic systems for VLN tasks."}}
{"id": "2509.14030", "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "categories": ["cs.AI"], "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "CrowdAgent is a multi-agent system developed for full annotation process management, combining task assignment, data annotation, and quality-cost control across diverse sources like LLMs, SLMs, and human experts.", "motivation": "The paper addresses the gap in dynamic process control for integrating diverse annotation sources, focusing on not just labeling tasks but also broader process management challenges like scheduling and quality-cost trade-offs.", "method": "CrowdAgent implements a multi-agent approach to rationally assign tasks, allowing collaboration among annotation sources (LLMs, SLMs, humans) within a unified workflow that considers cost and quality management.", "result": "Extensive experiments on six multimodal classification tasks show that CrowdAgent improves effectiveness in annotation workflows, validating its process control methodology.", "conclusion": "CrowdAgent streamlines dynamic task assignment and enhances collaboration between LLMs, SLMs, and human experts, offering a unified solution for high-quality, cost-efficient NLP data annotation."}}
{"id": "2509.13905", "pdf": "https://arxiv.org/pdf/2509.13905", "abs": "https://arxiv.org/abs/2509.13905", "authors": ["Domenico Meconi", "Simone Stirpe", "Federico Martelli", "Leonardo Lavalle", "Roberto Navigli"], "title": "Do Large Language Models Understand Word Senses?", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, to be published in EMNLP2025", "summary": "Understanding the meaning of words in context is a fundamental capability for\nLarge Language Models (LLMs). Despite extensive evaluation efforts, the extent\nto which LLMs show evidence that they truly grasp word senses remains\nunderexplored. In this paper, we address this gap by evaluating both i) the\nWord Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,\ncomparing their performance to state-of-the-art systems specifically designed\nfor the task, and ii) the ability of two top-performing open- and closed-source\nLLMs to understand word senses in three generative settings: definition\ngeneration, free-form explanation, and example generation. Notably, we find\nthat, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve\nperformance on par with specialized WSD systems, while also demonstrating\ngreater robustness across domains and levels of difficulty. In the generation\ntasks, results reveal that LLMs can explain the meaning of words in context up\nto 98\\% accuracy, with the highest performance observed in the free-form\nexplanation task, which best aligns with their generative capabilities.", "AI": {"tldr": "This paper evaluates the ability of instruction-tuned Large Language Models (LLMs) to perform Word Sense Disambiguation (WSD) and tests their generative understanding of word senses in multiple contexts, finding their performance comparable to specialized systems.", "motivation": "To explore the capability of LLMs to understand and process word senses in various contexts, which is a fundamental aspect of linguistic understanding but not extensively evaluated before.", "method": "The authors assess LLMs by comparing their performance in Word Sense Disambiguation (WSD) tasks to state-of-the-art systems and evaluate their generative abilities through definition generation, free-form explanation, and example generation.", "result": "The study finds that LLMs like GPT-4o and DeepSeek-V3 perform as well as specialized WSD systems in WSD tasks and achieve up to 98% accuracy in generative tasks, particularly excelling in free-form explanations.", "conclusion": "LLMs not only match the performance of specialized WSD systems but also exhibit strong generative abilities in explaining word senses, with free-form explanation aligning best with their capabilities."}}
{"id": "2509.13818", "pdf": "https://arxiv.org/pdf/2509.13818", "abs": "https://arxiv.org/abs/2509.13818", "authors": ["Zheng-an Wang", "Yanbo J. Wang", "Jiachi Zhang", "Qi Xu", "Yilun Zhao", "Jintao Li", "Yipeng Zhang", "Bo Yang", "Xinkai Gao", "Xiaofeng Cao", "Kai Xu", "Pengpeng Hao", "Xuan Yang", "Heng Fan"], "title": "Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Quantum Machine Learning (QML) offers a new paradigm for addressing complex\nfinancial problems intractable for classical methods. This work specifically\ntackles the challenge of few-shot credit risk assessment, a critical issue in\ninclusive finance where data scarcity and imbalance limit the effectiveness of\nconventional models. To address this, we design and implement a novel hybrid\nquantum-classical workflow. The methodology first employs an ensemble of\nclassical machine learning models (Logistic Regression, Random Forest, XGBoost)\nfor intelligent feature engineering and dimensionality reduction. Subsequently,\na Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as\nthe core classifier. This framework was evaluated through numerical simulations\nand deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting\nprocessor. On a real-world credit dataset of 279 samples, our QNN achieved a\nrobust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive\nAUC of 0.88 in the hardware experiment. This performance surpasses a suite of\nclassical benchmarks, with a particularly strong result on the recall metric.\nThis study provides a pragmatic blueprint for applying quantum computing to\ndata-constrained financial scenarios in the NISQ era and offers valuable\nempirical evidence supporting its potential in high-stakes applications like\ninclusive finance.", "AI": {"tldr": "This paper explores using a hybrid quantum-classical machine learning approach for credit risk assessment under data-constrained conditions.", "motivation": "The motivation is to address the limitation of classical models in inclusive finance that struggle with data scarcity and imbalance.", "method": "It uses classical machine learning for feature engineering and dimensionality reduction, followed by a Quantum Neural Network (QNN) trained via the parameter-shift rule.", "result": "The QNN achieved an average AUC of 0.852 +/- 0.027 in simulations and 0.88 in hardware tests, outperforming classical methods, especially on recall metric.", "conclusion": "Quantum computing demonstrates significant promise in tackling financial tasks under data constraints, paving the way for innovative applications in inclusive finance in the NISQ era."}}
{"id": "2509.13590", "pdf": "https://arxiv.org/pdf/2509.13590", "abs": "https://arxiv.org/abs/2509.13590", "authors": ["Samer Al-Hamadani"], "title": "Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation", "categories": ["cs.CV", "cs.AI"], "comment": "32 pages, 14 figures, 6 tables", "summary": "The rapid advancement of artificial intelligence (AI) in healthcare imaging\nhas revolutionized diagnostic medicine and clinical decision-making processes.\nThis work presents an intelligent multimodal framework for medical image\nanalysis that leverages Vision-Language Models (VLMs) in healthcare\ndiagnostics. The framework integrates Google Gemini 2.5 Flash for automated\ntumor detection and clinical report generation across multiple imaging\nmodalities including CT, MRI, X-ray, and Ultrasound. The system combines visual\nfeature extraction with natural language processing to enable contextual image\ninterpretation, incorporating coordinate verification mechanisms and\nprobabilistic Gaussian modeling for anomaly distribution. Multi-layered\nvisualization techniques generate detailed medical illustrations, overlay\ncomparisons, and statistical representations to enhance clinical confidence,\nwith location measurement achieving 80 pixels average deviation. Result\nprocessing utilizes precise prompt engineering and textual analysis to extract\nstructured clinical information while maintaining interpretability.\nExperimental evaluations demonstrated high performance in anomaly detection\nacross multiple modalities. The system features a user-friendly Gradio\ninterface for clinical workflow integration and demonstrates zero-shot learning\ncapabilities to reduce dependence on large datasets. This framework represents\na significant advancement in automated diagnostic support and radiological\nworkflow efficiency, though clinical validation and multi-center evaluation are\nnecessary prior to widespread adoption.", "AI": {"tldr": "The paper introduces a multimodal AI framework using Vision-Language Models (VLMs) for medical imaging, capable of automated tumor detection and clinical report generation.", "motivation": "To enhance diagnostic medicine and clinical workflows by combining advanced AI tools like Vision-Language Models for improved and automated medical image analysis.", "method": "The framework integrates Google Gemini 2.5 Flash for tumor detection and report generation across CT, MRI, X-ray, and Ultrasound modalities along with visualization, probabilistic modeling, and prompt engineering techniques.", "result": "The system achieved strong experimental performance in anomaly detection, with 80-pixels average localization deviation, and highlights user-friendly zero-shot learning capabilities.", "conclusion": "While the system shows promise for advancing diagnostic support and efficiency, clinical validation and multi-center evaluations are essential for its adoption."}}
{"id": "2509.13736", "pdf": "https://arxiv.org/pdf/2509.13736", "abs": "https://arxiv.org/abs/2509.13736", "authors": ["Muyuan Ma", "Long Cheng", "Lijun Han", "Xiuze Xia", "Houcheng Li"], "title": "Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning", "categories": ["cs.RO"], "comment": null, "summary": "Wearable exoskeletons can augment human strength and reduce muscle fatigue\nduring specific tasks. However, developing personalized and task-generalizable\nassistance algorithms remains a critical challenge. To address this, a\nmeta-imitation learning approach is proposed. This approach leverages a\ntask-specific neural network to predict human elbow joint movements, enabling\neffective assistance while enhancing generalization to new scenarios. To\naccelerate data collection, full-body keypoint motions are extracted from\npublicly available RGB video and motion-capture datasets across multiple tasks,\nand subsequently retargeted in simulation. Elbow flexion trajectories generated\nin simulation are then used to train the task-specific neural network within\nthe model-agnostic meta-learning (MAML) framework, which allows the network to\nrapidly adapt to novel tasks and unseen users with only a few gradient updates.\nThe adapted network outputs personalized references tracked by a\ngravity-compensated PD controller to ensure stable assistance. Experimental\nresults demonstrate that the exoskeleton significantly reduces both muscle\nactivation and metabolic cost for new users performing untrained tasks,\ncompared to performing without exoskeleton assistance. These findings suggest\nthat the proposed framework effectively improves task generalization and user\nadaptability for wearable exoskeleton systems.", "AI": {"tldr": "This paper introduces a meta-imitation learning approach to improve task generalization and personalization in wearable exoskeletons.", "motivation": "Developing personalized and generalizable assistance algorithms for wearable exoskeletons remains a challenge in enhancing human strength and reducing fatigue.", "method": "The authors utilize a task-specific neural network within the MAML framework, trained on simulated elbow flexion data derived from video and motion-capture datasets, to adapt personalized exoskeleton assistance with minimal user-specific training.", "result": "The exoskeleton using this framework reduced muscle activation and metabolic cost for untrained tasks and new users compared to non-assisted tasks.", "conclusion": "The developed system effectively balances task generalization and user adaptability, enhancing the usability of wearable exoskeletons for diverse applications."}}
{"id": "2509.14195", "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "categories": ["cs.AI", "cs.LG"], "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "This paper examines how second-order learning mechanisms can enable cognitive systems to form internal mental maps that mirror external environments, improving navigation performance in novel tasks.", "motivation": "The study aims to explore the role of second-order learning in building structured mental representations that resemble external environments, a key factor in advanced cognitive functions.", "method": "The authors developed a hierarchical architecture, which combines a Graph Convolutional Network (GCN) for first-order learning and an MLP controller for second-order learning. The GCN handles navigation tasks, while the MLP adapts the GCN\u2019s parameters in novel maze environments.", "result": "The study shows that second-order learning leads to significant performance improvements and generalization in unseen maze tasks when the cognitive system creates internal mental maps that mirror environmental structures.", "conclusion": "The findings emphasize the importance of structured mental representations in enabling effective second-order learning and advanced cognitive abilities in dynamic, unfamiliar settings."}}
{"id": "2509.13930", "pdf": "https://arxiv.org/pdf/2509.13930", "abs": "https://arxiv.org/abs/2509.13930", "authors": ["Dayeon Ki", "Marine Carpuat", "Paul McNamee", "Daniel Khashabi", "Eugene Yang", "Dawn Lawrie", "Kevin Duh"], "title": "Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG", "categories": ["cs.CL"], "comment": "33 pages, 20 figures", "summary": "Multilingual Retrieval-Augmented Generation (mRAG) systems enable language\nmodels to answer knowledge-intensive queries with citation-supported responses\nacross languages. While such systems have been proposed, an open questions is\nwhether the mixture of different document languages impacts generation and\ncitation in unintended ways. To investigate, we introduce a controlled\nmethodology using model internals to measure language preference while holding\nother factors such as document relevance constant. Across eight languages and\nsix open-weight models, we find that models preferentially cite English sources\nwhen queries are in English, with this bias amplified for lower-resource\nlanguages and for documents positioned mid-context. Crucially, we find that\nmodels sometimes trade-off document relevance for language preference,\nindicating that citation choices are not always driven by informativeness\nalone. Our findings shed light on how language models leverage multilingual\ncontext and influence citation behavior.", "AI": {"tldr": "This paper explores how multilingual Retrieval-Augmented Generation (mRAG) systems handle biases in citing sources across different languages.", "motivation": "To investigate whether mRAG systems exhibit unintended biases toward certain languages, like English, when generating and citing documents in multilingual setups.", "method": "A controlled methodology was used, relying on model internals, to evaluate language preference while keeping document relevance constant. Analysis covered eight languages and six open-weight language models.", "result": "The study observed an English citation bias, which intensified for lower-resource languages and mid-context documents. Sometimes, citation decisions prioritized language preference over document relevance.", "conclusion": "The findings highlight that multilingual mRAG systems are biased in their citation behavior, which is not solely determined by document informativeness, and provide insights into how language models process multilingual contexts."}}
{"id": "2509.13841", "pdf": "https://arxiv.org/pdf/2509.13841", "abs": "https://arxiv.org/abs/2509.13841", "authors": ["Qingqi Zhao", "Heng Xiao"], "title": "An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction", "categories": ["cs.LG", "physics.geo-ph"], "comment": "This preprint is also available at ESS Open Archive:\n  https://essopenarchive.org/users/960205/articles/1329010", "summary": "Accurate prediction of permeability in porous media is essential for modeling\nsubsurface flow. While pure data-driven models offer computational efficiency,\nthey often lack generalization across scales and do not incorporate explicit\nphysical constraints. Pore network models (PNMs), on the other hand, are\nphysics-based and efficient but rely on idealized geometric assumptions to\nestimate pore-scale hydraulic conductance, limiting their accuracy in complex\nstructures. To overcome these limitations, we present an end-to-end\ndifferentiable hybrid framework that embeds a graph neural network (GNN) into a\nPNM. In this framework, the analytical formulas used for conductance\ncalculations are replaced by GNN-based predictions derived from pore and throat\nfeatures. The predicted conductances are then passed to the PNM solver for\npermeability computation. In this way, the model avoids the idealized geometric\nassumptions of PNM while preserving the physics-based flow calculations. The\nGNN is trained without requiring labeled conductance data, which can number in\nthe thousands per pore network; instead, it learns conductance values by using\na single scalar permeability as the training target. This is made possible by\nbackpropagating gradients through both the GNN (via automatic differentiation)\nand the PNM solver (via a discrete adjoint method), enabling fully coupled,\nend-to-end training. The resulting model achieves high accuracy and generalizes\nwell across different scales, outperforming both pure data-driven and\ntraditional PNM approaches. Gradient-based sensitivity analysis further reveals\nphysically consistent feature influences, enhancing model interpretability.\nThis approach offers a scalable and physically informed framework for\npermeability prediction in complex porous media, reducing model uncertainty and\nimproving accuracy.", "AI": {"tldr": "This paper proposes a hybrid approach combining physics-based modeling and machine learning to improve permeability prediction in porous media.", "motivation": "Existing methods for predicting permeability face challenges in balancing physical accuracy and computational generalization, particularly in complex porous structures.", "method": "The framework integrates a Graph Neural Network (GNN) into a Pore Network Model (PNM), allowing end-to-end training using gradients to predict permeability while avoiding idealized geometry assumptions.", "result": "The model exhibited high accuracy, robust generalization across scales, and outperformed traditional PNM and pure data-driven methods.", "conclusion": "This approach provides a scalable, interpretable, and accurate framework for permeability prediction in porous media, enhancing reliability and understanding of model features."}}
{"id": "2509.13605", "pdf": "https://arxiv.org/pdf/2509.13605", "abs": "https://arxiv.org/abs/2509.13605", "authors": ["Ruochen Hou", "Gabriel I. Fernandez", "Alex Xu", "Dennis W. Hong"], "title": "A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In previous work, we introduced a 2D localization algorithm called CLAP,\nClustering to Localize Across $n$ Possibilities, which was used during our\nchampionship win in RoboCup 2024, an international autonomous humanoid soccer\ncompetition. CLAP is particularly recognized for its robustness against\noutliers, where clustering is employed to suppress noise and mitigate against\nerroneous feature matches. This clustering-based strategy provides an\nalternative to traditional outlier rejection schemes such as RANSAC, in which\ncandidates are validated by reprojection error across all data points. In this\npaper, CLAP is extended to a more general framework beyond 2D localization,\nspecifically to 3D localization and image stitching. We also show how CLAP,\nRANSAC, and Hough transforms are related. The generalization of CLAP is widely\napplicable to many different fields and can be a useful tool to deal with noise\nand uncertainty.", "AI": {"tldr": "The study introduces and generalizes CLAP, a clustering-based framework for noise-resistant localization and image stitching.", "motivation": "There is a need for robust outlier management in tasks such as localization and image stitching across different dimensions.", "method": "The 2D localization algorithm CLAP, initially used in RoboCup 2024, is generalized to handle 3D localization and image stitching while emphasizing clustering-based noise suppression.", "result": "CLAP demonstrates robustness in handling outliers and noise, showcasing its effectiveness against traditional schemes like RANSAC.", "conclusion": "The generalization of CLAP makes it a versatile tool applicable in managing noise and uncertainty across various domains."}}
{"id": "2509.13737", "pdf": "https://arxiv.org/pdf/2509.13737", "abs": "https://arxiv.org/abs/2509.13737", "authors": ["Renjie Wang", "Shangke Lyu", "Donglin Wang"], "title": "Dynamic Adaptive Legged Locomotion Policy via Decoupling Reaction Force Control and Gait Control", "categories": ["cs.RO"], "comment": null, "summary": "While Reinforcement Learning (RL) has achieved remarkable progress in legged\nlocomotion control, it often suffers from performance degradation in\nout-of-distribution (OOD) conditions and discrepancies between the simulation\nand the real environments. Instead of mainly relying on domain randomization\n(DR) to best cover the real environments and thereby close the sim-to-real gap\nand enhance robustness, this work proposes an emerging decoupled framework that\nacquires fast online adaptation ability and mitigates the sim-to-real problems\nin unfamiliar environments by isolating stance-leg control and swing-leg\ncontrol. Various simulation and real-world experiments demonstrate its\neffectiveness against horizontal force disturbances, uneven terrains, heavy and\nbiased payloads, and sim-to-real gap.", "AI": {"tldr": "A novel RL framework for legged locomotion control is proposed, focusing on decoupled leg control, showing robust adaptability across various real-world challenges.", "motivation": "Current RL struggles with performance in out-of-distribution environments and sim-to-real discrepancies, requiring a new approach to improve robustness.", "method": "The authors propose a decoupled framework isolating stance-leg and swing-leg control to enable fast online adaptation and reduce sim-to-real issues.", "result": "Experiments in both simulations and real-world scenarios demonstrate the method's effectiveness against environmental disturbances like uneven terrains and payload changes.", "conclusion": "The decoupled control framework enhances the adaptability and robustness of legged locomotion in real and challenging conditions, outperforming traditional domain randomization methods."}}
{"id": "2010.01052", "pdf": "https://arxiv.org/pdf/2010.01052", "abs": "https://arxiv.org/abs/2010.01052", "authors": ["Jaume Banus", "Maxime Sermesant", "Oscar Camara", "Marco Lorenzi"], "title": "Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The use of mechanistic models in clinical studies is limited by the lack of\nmulti-modal patients data representing different anatomical and physiological\nprocesses. For example, neuroimaging datasets do not provide a sufficient\nrepresentation of heart features for the modeling of cardiovascular factors in\nbrain disorders. To tackle this problem we introduce a probabilistic framework\nfor joint cardiac data imputation and personalisation of cardiovascular\nmechanistic models, with application to brain studies with incomplete heart\ndata. Our approach is based on a variational framework for the joint inference\nof an imputation model of cardiac information from the available features,\nalong with a Gaussian Process emulator that can faithfully reproduce\npersonalised cardiovascular dynamics. Experimental results on UK Biobank show\nthat our model allows accurate imputation of missing cardiac features in\ndatasets containing minimal heart information, e.g. systolic and diastolic\nblood pressures only, while jointly estimating the emulated parameters of the\nlumped model. This allows a novel exploration of the heart-brain joint\nrelationship through simulation of realistic cardiac dynamics corresponding to\ndifferent conditions of brain anatomy.", "AI": {"tldr": "This paper introduces a probabilistic framework to impute missing heart data and personalize cardiovascular models in brain studies.", "motivation": "Studies of brain disorders often lack sufficient cardiac data, limiting the exploration of heart-brain relationships.", "method": "The framework combines variational inference for cardiac data imputation with a Gaussian Process emulator to replicate cardiovascular dynamics.", "result": "The model reliably imputes missing cardiac features and estimates parameters for simulating cardiac dynamics, shown through experiments on UK Biobank data.", "conclusion": "This work enables new insights into heart-brain interactions by simulating cardiac dynamics in datasets with limited heart information."}}
{"id": "2509.13980", "pdf": "https://arxiv.org/pdf/2509.13980", "abs": "https://arxiv.org/abs/2509.13980", "authors": ["Sami Ul Haq", "Chinonso Cynthia Osuji", "Sheila Castilho", "Brian Davis"], "title": "Long-context Reference-based MT Quality Estimation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In this paper, we present our submission to the Tenth Conference on Machine\nTranslation (WMT25) Shared Task on Automated Translation Quality Evaluation.\n  Our systems are built upon the COMET framework and trained to predict\nsegment-level Error Span Annotation (ESA) scores using augmented long-context\ndata.\n  To construct long-context training data, we concatenate in-domain,\nhuman-annotated sentences and compute a weighted average of their scores.\n  We integrate multiple human judgment datasets (MQM, SQM, and DA) by\nnormalising their scales and train multilingual regression models to predict\nquality scores from the source, hypothesis, and reference translations.\n  Experimental results show that incorporating long-context information\nimproves correlations with human judgments compared to models trained only on\nshort segments.", "AI": {"tldr": "This paper improves machine translation quality evaluation by using a COMET-based framework with long-context training for higher human judgment correlation.", "motivation": "To enhance automated translation quality evaluation by integrating long-context data and human judgment datasets, aiming for better agreement with human assessments.", "method": "The researchers used the COMET framework to train models on segment-level scores using augmented long-context data. They concatenated annotated sentences, computed weighted averages, and normalized various judgment datasets.", "result": "The models incorporating long-context information achieved better correlations with human evaluations compared to those trained on short segments.", "conclusion": "Integration of long-context information and multiple human judgment datasets improves the quality and reliability of automated translation evaluation systems."}}
{"id": "2509.13629", "pdf": "https://arxiv.org/pdf/2509.13629", "abs": "https://arxiv.org/abs/2509.13629", "authors": ["Yue He", "Min Liu", "Qinghao Liu", "Jiazheng Wang", "Yaonan Wang", "Hang Zhang", "Xiang Chen"], "title": "SAMIR, an efficient registration framework via robust feature learning from SAM", "categories": ["cs.CV"], "comment": null, "summary": "Image registration is a fundamental task in medical image analysis.\nDeformations are often closely related to the morphological characteristics of\ntissues, making accurate feature extraction crucial. Recent weakly supervised\nmethods improve registration by incorporating anatomical priors such as\nsegmentation masks or landmarks, either as inputs or in the loss function.\nHowever, such weak labels are often not readily available, limiting their\npractical use. Motivated by the strong representation learning ability of\nvisual foundation models, this paper introduces SAMIR, an efficient medical\nimage registration framework that utilizes the Segment Anything Model (SAM) to\nenhance feature extraction. SAM is pretrained on large-scale natural image\ndatasets and can learn robust, general-purpose visual representations. Rather\nthan using raw input images, we design a task-specific adaptation pipeline\nusing SAM's image encoder to extract structure-aware feature embeddings,\nenabling more accurate modeling of anatomical consistency and deformation\npatterns. We further design a lightweight 3D head to refine features within the\nembedding space, adapting to local deformations in medical images.\nAdditionally, we introduce a Hierarchical Feature Consistency Loss to guide\ncoarse-to-fine feature matching and improve anatomical alignment. Extensive\nexperiments demonstrate that SAMIR significantly outperforms state-of-the-art\nmethods on benchmark datasets for both intra-subject cardiac image registration\nand inter-subject abdomen CT image registration, achieving performance\nimprovements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code\nwill be publicly available on GitHub following the acceptance of this paper.", "AI": {"tldr": "Introduces SAMIR, a medical image registration framework leveraging the Segment Anything Model (SAM) for more precise feature extraction and anatomical consistency. Achieves strong improvements in benchmark datasets.", "motivation": "Improving the accuracy of medical image registration by overcoming the limitations of existing methods reliant on weak labels, through robust visual representations provided by foundational models.", "method": "SAMIR utilizes the Segment Anything Model (SAM) for structure-aware feature embedding extraction. It employs a task-specific adaptation pipeline, a lightweight 3D refinement head, and a Hierarchical Feature Consistency Loss for more accurate anatomical alignment.", "result": "SAMIR significantly outperforms state-of-the-art methods, with notable performance gains on cardiac and abdomen image registration benchmark datasets (2.68% on ACDC and 6.44% on abdomen CT dataset).", "conclusion": "SAMIR proves efficient for medical image registration tasks by using robust pre-trained models; it offers practical solutions to enhance anatomical alignment and will facilitate advancements in the field with publicly accessible code."}}
{"id": "2509.13771", "pdf": "https://arxiv.org/pdf/2509.13771", "abs": "https://arxiv.org/abs/2509.13771", "authors": ["Mengzhu Li", "Yunyu Zhou", "He Ying", "F. Richard Yu"], "title": "CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs", "categories": ["cs.RO"], "comment": null, "summary": "Signed Distance Fields (SDFs) are a fundamental representation in robot\nmotion planning. Their configuration-space counterpart, the Configuration Space\nDistance Field (CDF), directly encodes distances in joint space, offering a\nunified representation for optimization and control. However, existing CDF\nformulations face two major challenges in high-degree-of-freedom (DoF) robots:\n(1) they effectively return only a single nearest collision configuration,\nneglecting the multi-modal nature of minimal-distance collision configurations\nand leading to gradient ambiguity; and (2) they rely on sparse sampling of the\ncollision boundary, which often fails to identify the true closest\nconfigurations, producing oversmoothed approximations and geometric distortion\nin high-dimensional spaces. We propose CDFlow, a novel framework that addresses\nthese limitations by learning a continuous flow in configuration space via\nNeural Ordinary Differential Equations (Neural ODEs). We redefine the problem\nfrom finding a single nearest point to modeling the distribution of\nminimal-distance collision configurations. We also introduce an adaptive\nrefinement sampling strategy to generate high-fidelity training data for this\ndistribution. The resulting Neural ODE implicitly models this multi-modal\ndistribution and produces a smooth, consistent gradient field-derived as the\nexpected direction towards the distribution-that mitigates gradient ambiguity\nand preserves sharp geometric features. Extensive experiments on high-DoF\nmotion planning tasks demonstrate that CDFlow significantly improves planning\nefficiency, trajectory quality, and robustness compared to existing CDF-based\nmethods, enabling more robust and efficient planning for collision-aware robots\nin complex environments.", "AI": {"tldr": "The paper introduces CDFlow, a novel method for representing Configuration Space Distance Fields (CDF) in high-DoF robots, using Neural Ordinary Differential Equations (Neural ODEs).", "motivation": "Existing CDF methods struggle with limitations like gradient ambiguity due to single-modal collision configurations and oversmoothed approximations caused by sparse boundary sampling, especially in high-dimensional spaces.", "method": "CDFlow employs Neural Ordinary Differential Equations (Neural ODEs) to learn a continuous flow that models the distribution of minimal-distance collision configurations. Additionally, it uses an adaptive refinement sampling strategy to generate precise training data.", "result": "Experiments on high-DoF robots showcase substantial improvements in motion planning efficiency, trajectory quality, and robustness over traditional CDF approaches.", "conclusion": "CDFlow overcomes the challenges of current CDF formulations, offering a more robust and efficient mechanism for collision-aware robot planning in complex environments."}}
{"id": "2408.00208", "pdf": "https://arxiv.org/pdf/2408.00208", "abs": "https://arxiv.org/abs/2408.00208", "authors": ["SaeedReza Motamedian", "Sadra Mohaghegh", "Elham Babadi Oregani", "Mahrsa Amjadi", "Parnian Shobeiri", "Negin Cheraghi", "Niusha Solouki", "Nikoo Ahmadi", "Hossein Mohammad-Rahimi", "Yassine Bouchareb", "Arman Rahmim"], "title": "Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis", "categories": ["physics.med-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Purpose: Artificial intelligence (AI) techniques have been extensively\nutilized for diagnosing and prognosis of several diseases in recent years. This\nstudy identifies, appraises and synthesizes published studies on the use of AI\nfor the prognosis of COVID-19. Method: Electronic search was performed using\nMedline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that\nexamined machine learning or deep learning methods to determine the prognosis\nof COVID-19 using CT or chest X-ray images were included. Polled sensitivity,\nspecificity area under the curve and diagnostic odds ratio were calculated.\nResult: A total of 36 articles were included; various prognosis-related issues,\nincluding disease severity, mechanical ventilation or admission to the\nintensive care unit and mortality, were investigated. Several AI models and\narchitectures were employed, such as the Siamense model, support vector\nmachine, Random Forest , eXtreme Gradient Boosting, and convolutional neural\nnetworks. The models achieved 71%, 88% and 67% sensitivity for mortality,\nseverity assessment and need for ventilation, respectively. The specificity of\n69%, 89% and 89% were reported for the aforementioned variables. Conclusion:\nBased on the included articles, machine learning and deep learning methods used\nfor the prognosis of COVID-19 patients using radiomic features from CT or CXR\nimages can help clinicians manage patients and allocate resources more\neffectively. These studies also demonstrate that combining patient demographic,\nclinical data, laboratory tests and radiomic features improves model\nperformances.", "AI": {"tldr": "This paper evaluates the use of artificial intelligence in predicting COVID-19 prognosis using CT and chest X-rays, analyzing various AI models tested in 36 studies.", "motivation": "The need to effectively diagnose and predict COVID-19 severity, resource requirements, and patient outcomes motivated this study.", "method": "The study reviewed research on AI models (machine and deep learning) applied to CT and X-ray images, calculating metrics like sensitivity and specificity for outcomes such as mortality, severity, and ventilation needs.", "result": "AI models demonstrated 71% sensitivity for mortality prediction, 88% for severity assessment, and 67% for ventilation prediction, with corresponding specificities of 69%, 89%, and 89%.", "conclusion": "AI methods using CT or X-rays provide valuable insights into COVID-19 prognosis. Combining radiomic features with clinical and demographic data enhances model performance, offering practical utility for clinicians."}}
{"id": "2509.13990", "pdf": "https://arxiv.org/pdf/2509.13990", "abs": "https://arxiv.org/abs/2509.13990", "authors": ["Colin Hong", "Xu Guo", "Anand Chaanan Singh", "Esha Choukse", "Dmitrii Ustiugov"], "title": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": "Accepted by EMNLP 2025 (Oral), 9 pages", "summary": "Recently, Test-Time Scaling (TTS) has gained increasing attention for\nimproving LLM reasoning performance at test time without retraining the model.\nA notable TTS technique is Self-Consistency (SC), which generates multiple\nreasoning chains in parallel and selects the final answer via majority voting.\nWhile effective, the order-of-magnitude computational overhead limits its broad\ndeployment. Prior attempts to accelerate SC mainly rely on model-based\nconfidence scores or heuristics with limited empirical support. For the first\ntime, we theoretically and empirically analyze the inefficiencies of SC and\nreveal actionable opportunities for improvement. Building on these insights, we\npropose Slim-SC, a step-wise pruning strategy that identifies and removes\nredundant chains using inter-chain similarity at the thought level. Experiments\non three STEM reasoning datasets and two recent LLM architectures show that\nSlim-SC reduces inference latency and KVC usage by up to 45% and 26%,\nrespectively, with R1-Distill, while maintaining or improving accuracy, thus\noffering a simple yet efficient TTS alternative for SC.", "AI": {"tldr": "Slim-SC enhances Test-Time Scaling (TTS) performance by pruning redundant reasoning chains, significantly reducing latency and computational overhead while maintaining or improving accuracy.", "motivation": "Address limitations of Self-Consistency (SC) in TTS, especially its high computational overhead that restricts widespread deployment.", "method": "Introduce Slim-SC, a step-wise pruning technique that removes redundant reasoning chains based on inter-chain similarity at the thought level.", "result": "Experimental results on STEM reasoning datasets and LLM architectures demonstrate Slim-SC reduces inference latency by up to 45% and computational resource usage by 26%, while maintaining or improving accuracy.", "conclusion": "Slim-SC offers a practical and efficient approach to enhance TTS, providing a balance between accuracy and computational efficiency for SC-based reasoning in large language models."}}
{"id": "2509.13866", "pdf": "https://arxiv.org/pdf/2509.13866", "abs": "https://arxiv.org/abs/2509.13866", "authors": ["Sitong Chen", "Shen Nie", "Jiacheng Sun", "Zijin Feng", "Zhenguo Li", "Ji-Rong Wen", "Chongxuan Li"], "title": "Masked Diffusion Models as Energy Minimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present a systematic theoretical framework that interprets masked\ndiffusion models (MDMs) as solutions to energy minimization problems in\ndiscrete optimal transport. Specifically, we prove that three distinct energy\nformulations--kinetic, conditional kinetic, and geodesic energy--are\nmathematically equivalent under the structure of MDMs, and that MDMs minimize\nall three when the mask schedule satisfies a closed-form optimality condition.\nThis unification not only clarifies the theoretical foundations of MDMs, but\nalso motivates practical improvements in sampling. By parameterizing\ninterpolation schedules via Beta distributions, we reduce the schedule design\nspace to a tractable 2D search, enabling efficient post-training tuning without\nmodel modification. Experiments on synthetic and real-world benchmarks\ndemonstrate that our energy-inspired schedules outperform hand-crafted\nbaselines, particularly in low-step sampling settings.", "AI": {"tldr": "This paper interprets Masked Diffusion Models (MDMs) as solutions to energy minimization via three mathematically equivalent formulations and proposes improvements in sampling schedules.", "motivation": "The paper aims to unify the understanding of MDMs by connecting them to discrete optimal transport and to simplify sampling schedule design for improved performance.", "method": "It mathematically proves the equivalence of kinetic, conditional kinetic, and geodesic energy in MDMs and introduces Beta distribution parametrization for efficient schedule optimization.", "result": "Energy-inspired schedules developed in this framework outperform traditional hand-crafted baselines, especially in low-step sampling tasks, validated through experiments.", "conclusion": "The framework clarifies theoretical aspects of MDMs and provides practical advancements in sampling schedules, offering both theoretical insights and practical benefits."}}
{"id": "2509.13774", "pdf": "https://arxiv.org/pdf/2509.13774", "abs": "https://arxiv.org/abs/2509.13774", "authors": ["Piaopiao Jin", "Qi Wang", "Guokang Sun", "Ziwen Cai", "Pinjia He", "Yangwei You"], "title": "Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach", "categories": ["cs.RO"], "comment": null, "summary": "Vision-language-action (VLA) models demonstrate strong generalization in\nrobotic manipulation but face challenges in complex, real-world tasks. While\nsupervised fine-tuning with demonstrations is constrained by data quality,\nreinforcement learning (RL) offers a promising alternative. We propose a\nhuman-in-the-loop dual-actor fine-tuning framework grounded in RL. The\nframework integrates a primary actor for robust multi-task performance with a\nrefinement actor for latent-space adaptation. Beyond standard physical\ninterventions, we introduce a lightweight talk-and-tweak scheme that converts\nhuman corrections into semantically grounded language commands, thereby\ngenerating a new dataset for policy learning. In real-world multi-task\nexperiments, our approach achieves 100% success across three tasks within 101\nminutes of online fine-tuning. For long-horizon tasks, it sustains a 50%\nsuccess rate over 12 consecutive operations. Furthermore, the framework scales\neffectively to multi-robot training, achieving up to a 2 times improvement in\nefficiency when using dual robots. The experiment videos are available at\nhttps://sites.google.com/view/hil-daft/.", "AI": {"tldr": "The paper introduces a human-in-the-loop dual-actor fine-tuning framework using reinforcement learning to enhance vision-language-action models for robotic manipulation. It incorporates human feedback through a language-based scheme to generate new learning data, achieving high success rates in real-world tasks.", "motivation": "Enhance the generalization of vision-language-action models in complex real-world robotic tasks, overcoming the limitations of supervised fine-tuning and leveraging reinforcement learning.", "method": "A dual-actor framework with reinforcement learning where a primary actor ensures multi-task robustness and a refinement actor facilitates latent-space adaptation. The system integrates lightweight, semantically grounded human feedback to improve policy learning.", "result": "Achieved 100% success in three tasks within 101 minutes, a 50% success rate over 12 long-horizon operations, and a 2x efficiency boost in multi-robot training.", "conclusion": "The proposed framework significantly improves task performance, adaptability, and efficiency, demonstrating its scalability and effectiveness in both individual and multi-robot scenarios."}}
{"id": "2509.13328", "pdf": "https://arxiv.org/pdf/2509.13328", "abs": "https://arxiv.org/abs/2509.13328", "authors": ["Danish Rizvi", "David Boyle"], "title": "Dual Actor DDPG for Airborne STAR-RIS Assisted Communications", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.NI", "math.IT"], "comment": null, "summary": "This study departs from the prevailing assumption of independent Transmission\nand Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect\nReconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a\nnovel multi-user downlink communication system that leverages a UAV-mounted\nSTAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key\ncontributions include the joint optimization of UAV trajectory, active\nbeamforming vectors at the base station, and passive RIS TRCs to enhance\ncommunication efficiency, while considering UAV energy constraints. We design\nthe TRC as a combination of discrete and continuous actions, and propose a\nnovel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The\nalgorithm relies on two separate actor networks for high-dimensional hybrid\naction space. We also propose a novel harmonic mean index (HFI)-based reward\nfunction to ensure communication fairness amongst users. For comprehensive\nanalysis, we study the impact of RIS size on UAV aerodynamics showing that it\nincreases drag and energy demand. Simulation results demonstrate that the\nproposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based\nsolutions by 24% and 97%, respectively, in accumulated reward.\nThree-dimensional UAV trajectory optimization achieves 28% higher communication\nefficiency compared to two-dimensional and altitude optimization. The HFI based\nreward function provides 41% lower QoS denial rates as compared to other\nbenchmarks. The mobile Aerial-STAR system shows superior performance over fixed\ndeployed counterparts, with the coupled phase STAR-RIS outperforming dual\nTransmit/Reflect RIS and conventional RIS setups. These findings highlight the\npotential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG\napproach in optimizing their performance.", "AI": {"tldr": "This paper investigates a UAV-mounted STAR-RIS system with a coupled TRC phase shift model. It creates a novel optimization algorithm to enhance communication efficiency and evaluate UAV energy constraints.", "motivation": "The motivation lies in addressing the assumption of independent transmission/reflection coefficients in STAR-RIS systems. The study explores their coupling to improve multi-user communication systems.", "method": "The authors develop a Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm for joint optimization of UAV trajectory, active beamforming at the base station, and passive RIS TRC in a combined action space. A harmonic mean index reward function is also proposed to ensure user fairness.", "result": "The DA-DDPG algorithm surpasses traditional algorithms by 24%-97% in reward metrics and improves communication efficiency by 28% with 3D trajectory optimization. Its reward function reduces QoS denial by 41%, achieving better fairness and UAV performance under realistic energy limitations.", "conclusion": "The proposed method demonstrates the Aerial-STAR system\u2019s advantages and validates the DA-DDPG algorithm\u2019s role in maximizing fairness, communication efficiency, and UAV energy utilization in modern systems."}}
{"id": "2509.14004", "pdf": "https://arxiv.org/pdf/2509.14004", "abs": "https://arxiv.org/abs/2509.14004", "authors": ["Minjia Mao", "Bowen Yin", "Yu Zhu", "Xiao Fang"], "title": "Early Stopping Chain-of-thoughts in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning large language models (LLMs) have demonstrated superior capacities\nin solving complicated problems by generating long chain-of-thoughts (CoT), but\nsuch a lengthy CoT incurs high inference costs. In this study, we introduce\nES-CoT, an inference-time method that shortens CoT generation by detecting\nanswer convergence and stopping early with minimal performance loss. At the end\nof each reasoning step, we prompt the LLM to output its current final answer,\ndenoted as a step answer. We then track the run length of consecutive identical\nstep answers as a measure of answer convergence. Once the run length exhibits a\nsharp increase and exceeds a minimum threshold, the generation is terminated.\nWe provide both empirical and theoretical support for this heuristic: step\nanswers steadily converge to the final answer, and large run-length jumps\nreliably mark this convergence. Experiments on five reasoning datasets across\nthree LLMs show that ES-CoT reduces the number of inference tokens by about\n41\\% on average while maintaining accuracy comparable to standard CoT. Further,\nES-CoT integrates seamlessly with self-consistency prompting and remains robust\nacross hyperparameter choices, highlighting it as a practical and effective\napproach for efficient reasoning.", "AI": {"tldr": "The paper proposes ES-CoT, a method to shorten the inference cost of reasoning tasks in LLMs by detecting answer convergence and halting generation early, reducing token usage without substantial accuracy loss.", "motivation": "Large language models excel at reasoning using lengthy chains-of-thought (CoT), but this comes at a high computational cost due to extensive inference time.", "method": "The proposed method, ES-CoT, operates by prompting the LLM at each reasoning step to generate its step answer and track when the answer converges by observing jumps in run length of identical responses. Inference is terminated once convergence is detected beyond a threshold.", "result": "Experiments demonstrated that ES-CoT reduces token usage during inference by around 41% on average while maintaining accuracy comparable to conventional CoT generation.", "conclusion": "ES-CoT efficiently optimizes the reasoning process in LLMs by reducing inference time and token usage, making it a practical and robust approach for complex reasoning tasks."}}
{"id": "2509.13895", "pdf": "https://arxiv.org/pdf/2509.13895", "abs": "https://arxiv.org/abs/2509.13895", "authors": ["Zhanting Zhou", "Jinshan Lai", "Fengchun Zhang", "Zeqin Wu", "Fengli Zhang"], "title": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "4 page main text for conference", "summary": "Non-IID data and partial participation induce client drift and inconsistent\nlocal optima in federated learning, causing unstable convergence and accuracy\nloss. We present FedSSG, a stochastic sampling-guided, history-aware drift\nalignment method. FedSSG maintains a per-client drift memory that accumulates\nlocal model differences as a lightweight sketch of historical gradients;\ncrucially, it gates both the memory update and the local alignment term by a\nsmooth function of the observed/expected participation ratio (a\nphase-by-expectation signal derived from the server sampler). This\nstatistically grounded gate stays weak and smooth when sampling noise dominates\nearly, then strengthens once participation statistics stabilize, contracting\nthe local-global gap without extra communication. Across CIFAR-10/100 with\n100/500 clients and 2-15 percent participation, FedSSG consistently outperforms\nstrong drift-aware baselines and accelerates convergence; on our benchmarks it\nimproves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and\nabout +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about\n4.5x faster target-accuracy convergence on average. The method adds only O(d)\nclient memory and a constant-time gate, and degrades gracefully to a mild\nregularizer under near-IID or uniform sampling. FedSSG shows that sampling\nstatistics can be turned into a principled, history-aware phase control to\nstabilize and speed up federated training.", "AI": {"tldr": "The paper addresses federated learning challenges caused by non-IID data and partial participation by introducing FedSSG, an algorithm that aligns client drift and accelerates convergence.", "motivation": "The motivation is to solve the issues of unstable convergence and accuracy loss in federated learning caused by client drift and non-uniform participation.", "method": "FedSSG uses a per-client drift memory that accumulates local model differences. A smooth, participation-aware gating mechanism is introduced to manage memory updates and alignment. This approach leverages participation statistics to stabilize training without additional communication.", "result": "In CIFAR-10/100 experiments with 100-500 clients and low participation, FedSSG improves test accuracy by up to 2.7 points and accelerates target-accuracy convergence by 4.5x compared to strong baselines.", "conclusion": "FedSSG leverages sampling statistics for history-aware phase control in federated training, resulting in more stable and faster training across non-IID and partial participation setups, with minimal computational overhead."}}
{"id": "2509.13652", "pdf": "https://arxiv.org/pdf/2509.13652", "abs": "https://arxiv.org/abs/2509.13652", "authors": ["Yumin Li", "Dylan Campbell"], "title": "Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction", "categories": ["cs.CV", "I.4.8; I.4.5"], "comment": "12 pages, 4 figures, accepted by AJCAI 2025", "summary": "Estimating metric relative camera pose from a pair of images is of great\nimportance for 3D reconstruction and localisation. However, conventional\ntwo-view pose estimation methods are not metric, with camera translation known\nonly up to a scale, and struggle with wide baselines and textureless or\nreflective surfaces. This paper introduces GARPS, a training-free framework\nthat casts this problem as the direct alignment of two independently\nreconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and\na Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model\n(GMM) for each image. It then refines an initial pose from a feed-forward\ntwo-view pose estimator by optimising a differentiable GMM alignment objective.\nThis objective jointly considers geometric structure, view-independent colour,\nanisotropic covariance, and semantic feature consistency, and is robust to\nocclusions and texture-poor regions without requiring explicit 2D\ncorrespondences. Extensive experiments on the Real\\-Estate10K dataset\ndemonstrate that GARPS outperforms both classical and state-of-the-art\nlearning-based methods, including MASt3R. These results highlight the potential\nof bridging single-view perception with multi-view geometry to achieve robust\nand metric relative pose estimation.", "AI": {"tldr": "GARPS is introduced as a training-free framework for metric relative camera pose estimation by aligning two independently reconstructed 3D scenes.", "motivation": "To improve 3D reconstruction and localization by addressing limitations of conventional two-view pose estimation methods like non-metric translations and challenges with wide baselines, textureless, or reflective surfaces.", "method": "The paper presents a framework leveraging metric monocular depth estimation and a Gaussian scene reconstructor to build a 3D Gaussian Mixture Model for alignment. It refines initial poses using a differentiable GMM alignment objective, incorporating geometric, color, covariance, and semantic consistency.", "result": "Experiments on the RealEstate10K dataset show GARPS outperforms classical and learning-based methods, including state-of-the-art methods like MASt3R.", "conclusion": "GARPS demonstrates the effectiveness of combining single-view perception with multi-view geometry for robust metric relative pose estimation."}}
{"id": "2509.13780", "pdf": "https://arxiv.org/pdf/2509.13780", "abs": "https://arxiv.org/abs/2509.13780", "authors": ["Weishuai Zeng", "Shunlin Lu", "Kangning Yin", "Xiaojie Niu", "Minyue Dai", "Jingbo Wang", "Jiangmiao Pang"], "title": "Behavior Foundation Model for Humanoid Robots", "categories": ["cs.RO"], "comment": null, "summary": "Whole-body control (WBC) of humanoid robots has witnessed remarkable progress\nin skill versatility, enabling a wide range of applications such as locomotion,\nteleoperation, and motion tracking. Despite these achievements, existing WBC\nframeworks remain largely task-specific, relying heavily on labor-intensive\nreward engineering and demonstrating limited generalization across tasks and\nskills. These limitations hinder their response to arbitrary control modes and\nrestrict their deployment in complex, real-world scenarios. To address these\nchallenges, we revisit existing WBC systems and identify a shared objective\nacross diverse tasks: the generation of appropriate behaviors that guide the\nrobot toward desired goal states. Building on this insight, we propose the\nBehavior Foundation Model (BFM), a generative model pretrained on large-scale\nbehavioral datasets to capture broad, reusable behavioral knowledge for\nhumanoid robots. BFM integrates a masked online distillation framework with a\nConditional Variational Autoencoder (CVAE) to model behavioral distributions,\nthereby enabling flexible operation across diverse control modes and efficient\nacquisition of novel behaviors without retraining from scratch. Extensive\nexperiments in both simulation and on a physical humanoid platform demonstrate\nthat BFM generalizes robustly across diverse WBC tasks while rapidly adapting\nto new behaviors. These results establish BFM as a promising step toward a\nfoundation model for general-purpose humanoid control.", "AI": {"tldr": "The paper introduces the Behavior Foundation Model (BFM) to improve humanoid robot control using a pretrained generative model for versatile and reusable behaviors.", "motivation": "Current whole-body control frameworks for humanoid robots are task-specific, require extensive reward engineering, and are limited in generalization across diverse tasks, restricting their real-world deployment.", "method": "The authors propose BFM, a generative model built on a Conditional Variational Autoencoder (CVAE) with a masked online distillation framework, pretrained on large-scale behavioral datasets.", "result": "Extensive experimentation shows that BFM generalizes across diverse whole-body control tasks and adapts efficiently to new behaviors on both simulated and physical humanoid platforms.", "conclusion": "BFM is positioned as a foundation model for general-purpose humanoid control, enabling flexible, efficient, and versatile robot behavior generation."}}
{"id": "2509.13331", "pdf": "https://arxiv.org/pdf/2509.13331", "abs": "https://arxiv.org/abs/2509.13331", "authors": ["Reza Pirayeshshirazinezhad"], "title": "Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation", "categories": ["astro-ph.IM", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "We use artificial intelligence (AI) and supervisory adaptive control systems\nto plan and optimize the mission of precise spacecraft formation. Machine\nlearning and robust control enhance the efficiency of spacecraft precision\nformation of the Virtual Telescope for X-ray Observation (VTXO) space mission.\nVTXO is a precise formation of two separate spacecraft making a virtual\ntelescope with a one-kilometer focal length. One spacecraft carries the lens\nand the other spacecraft holds the camera to observe high-energy space objects\nin the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed\nautomata for supervisory control, Monte Carlo simulations for stability and\nrobustness evaluation, and integration of deep neural networks for optimal\nestimation of mission parameters, satisfy the high precision mission criteria.\nWe integrate deep neural networks with a constrained, non-convex dynamic\noptimization pipeline to predict optimal mission parameters, ensuring precision\nmission criteria are met. AI framework provides explainability by predicting\nthe resulting energy consumption and mission error for a given set of mission\nparameters. It allows for transparent, justifiable, and real-time trade-offs, a\ncapability not present in traditional adaptive controllers. The results show\nreductions in energy consumption and improved mission accuracy, demonstrating\nthe capability of the system to address dynamic uncertainties and disturbances.", "AI": {"tldr": "The paper integrates AI and supervisory control for optimizing the precise formation of spacecraft in the VTXO mission, showcasing reduced energy consumption and improved accuracy.", "motivation": "To enhance the precision and efficiency of spacecraft formation for the VTXO mission, aimed at advanced X-ray observation.", "method": "Utilizes supervisory adaptive control, deep neural networks, timed automata, and Monte Carlo simulations for planning, optimizing, and ensuring robust mission criteria.", "result": "Achieved lower energy consumption and higher mission accuracy, addressing uncertainties and disturbances in spacecraft formation.", "conclusion": "AI-driven approaches effectively ensure precision in spacecraft formation, optimize resource use, and justify real-time mission decisions."}}
{"id": "2509.14008", "pdf": "https://arxiv.org/pdf/2509.14008", "abs": "https://arxiv.org/abs/2509.14008", "authors": ["Hasan Abed Al Kader Hammoud", "Mohammad Zbeeb", "Bernard Ghanem"], "title": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Technical Report", "summary": "We present Hala, a family of Arabic-centric instruction and translation\nmodels built with our translate-and-tune pipeline. We first compress a strong\nAR$\\leftrightarrow$EN teacher to FP8 (yielding $\\sim$2$\\times$ higher\nthroughput with no quality loss) and use it to create high-fidelity bilingual\nsupervision. A lightweight language model LFM2-1.2B is then fine-tuned on this\ndata and used to translate high-quality English instruction sets into Arabic,\nproducing a million-scale corpus tailored to instruction following. We train\nHala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to\nbalance Arabic specialization with base-model strengths. On Arabic-centric\nbenchmarks, Hala achieves state-of-the-art results within both the \"nano\"\n($\\leq$2B) and \"small\" (7-9B) categories, outperforming their bases. We release\nmodels, data, evaluation, and recipes to accelerate research in Arabic NLP.", "AI": {"tldr": "This paper introduces Hala, a series of Arabic-focused instruction and translation models utilizing advanced compression, fine-tuning, and specialized training approaches to achieve state-of-the-art performance in Arabic NLP.", "motivation": "To enhance Arabic Natural Language Processing by developing specialized models that outperform baselines in translation and instruction-following tasks.", "method": "The authors first compress a strong Arabic-English teacher model to FP8 for efficiency, then fine-tune a 1.2B language model to create a large-scale Arabic instruction dataset, and finally train models of varying sizes with slerp merging for optimal performance.", "result": "Hala models outperform baseline models in Arabic-centric benchmarks for both small and nano model categories, establishing new state-of-the-art results.", "conclusion": "The Hala models demonstrate the effectiveness of specialized training strategies for Arabic NLP, and the authors provide resources to further accelerate research in this area."}}
{"id": "2509.13906", "pdf": "https://arxiv.org/pdf/2509.13906", "abs": "https://arxiv.org/abs/2509.13906", "authors": ["Afrin Dange", "Sunita Sarawagi"], "title": "TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates", "categories": ["cs.LG", "I.2.6"], "comment": "Accepted at CIKM 2025", "summary": "Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art\nperformance in univariate forecasting on new time series simply by conditioned\non a brief history of past values. Their success demonstrates that large-scale\npretraining across diverse domains can acquire the inductive bias to generalize\nfrom temporal patterns in a brief history. However, most TSFMs are unable to\nleverage covariates -- future-available exogenous variables critical for\naccurate forecasting in many applications -- due to their domain-specific\nnature and the lack of associated inductive bias. We propose TFMAdapter, a\nlightweight, instance-level adapter that augments TSFMs with covariate\ninformation without fine-tuning. Instead of retraining, TFMAdapter operates on\nthe limited history provided during a single model call, learning a\nnon-parametric cascade that combines covariates with univariate TSFM forecasts.\nHowever, such learning would require univariate forecasts at all steps in the\nhistory, requiring too many calls to the TSFM. To enable training on the full\nhistorical context while limiting TSFM invocations, TFMAdapter uses a two-stage\nmethod: (1) generating pseudo-forecasts with a simple regression model, and (2)\ntraining a Gaussian Process regressor to refine predictions using both pseudo-\nand TSFM forecasts alongside covariates. Extensive experiments on real-world\ndatasets demonstrate that TFMAdapter consistently outperforms both foundation\nmodels and supervised baselines, achieving a 24-27\\% improvement over base\nfoundation models with minimal data and computational overhead. Our results\nhighlight the potential of lightweight adapters to bridge the gap between\ngeneric foundation models and domain-specific forecasting needs.", "AI": {"tldr": "This paper introduces TFMAdapter, a lightweight adapter to enhance Time Series Foundation Models (TSFMs) by integrating covariate information for improved forecasting without fine-tuning.", "motivation": "To address the inability of TSFMs to incorporate exogenous covariates, which are essential for some domain-specific forecasting applications.", "method": "A two-stage approach: generating pseudo-forecasts with a regression model first, then training a Gaussian Process regressor using pseudo-forecasts, TSFM predictions, and covariates.", "result": "TFMAdapter achieves significant improvements (24-27% over base TSFMs) in forecasting accuracy across diverse real-world datasets.", "conclusion": "Lightweight adapters like TFMAdapter can effectively bridge the gap between generic foundation models and specific domain requirements, while maintaining computational efficiency."}}
{"id": "2509.13662", "pdf": "https://arxiv.org/pdf/2509.13662", "abs": "https://arxiv.org/abs/2509.13662", "authors": ["Yulan Guo", "Longguang Wang", "Wendong Mao", "Xiaoyu Dong", "Yingqian Wang", "Li Liu", "Wei An"], "title": "Deep Lookup Network", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Convolutional neural networks are constructed with massive operations with\ndifferent types and are highly computationally intensive. Among these\noperations, multiplication operation is higher in computational complexity and\nusually requires {more} energy consumption with longer inference time than\nother operations, which hinders the deployment of convolutional neural networks\non mobile devices. In many resource-limited edge devices, complicated\noperations can be calculated via lookup tables to reduce computational cost.\nMotivated by this, in this paper, we introduce a generic and efficient lookup\noperation which can be used as a basic operation for the construction of neural\nnetworks. Instead of calculating the multiplication of weights and activation\nvalues, simple yet efficient lookup operations are adopted to compute their\nresponses. To enable end-to-end optimization of the lookup operation, we\nconstruct the lookup tables in a differentiable manner and propose several\ntraining strategies to promote their convergence. By replacing computationally\nexpensive multiplication operations with our lookup operations, we develop\nlookup networks for the image classification, image super-resolution, and point\ncloud classification tasks. It is demonstrated that our lookup networks can\nbenefit from the lookup operations to achieve higher efficiency in terms of\nenergy consumption and inference speed while maintaining competitive\nperformance to vanilla convolutional networks. Extensive experiments show that\nour lookup networks produce state-of-the-art performance on different tasks\n(both classification and regression tasks) and different data types (both\nimages and point clouds).", "AI": {"tldr": "The paper introduces lookup operations as an energy-efficient alternative to multiplication in neural networks, enabling faster and less power-hungry inference.", "motivation": "Convolutional neural networks require computationally expensive multiplication operations, which consume significant energy and time, presenting challenges for edge and mobile device deployment.", "method": "The authors propose generic lookup operations to replace multiplications in neural networks, using differentiable lookup tables and training strategies to optimize performance.", "result": "The lookup networks significantly reduce computational demands, energy consumption, and inference time while maintaining competitive performance on image and point cloud tasks.", "conclusion": "This approach enables efficient neural networks through lookup operations, demonstrating state-of-the-art efficiency and performance across diverse tasks and data types."}}
{"id": "2509.13802", "pdf": "https://arxiv.org/pdf/2509.13802", "abs": "https://arxiv.org/abs/2509.13802", "authors": ["Takuya Kiyokawa", "Ryunosuke Takebayashi", "Kensuke Harada"], "title": "Shell-Type Soft Jig for Holding Objects during Disassembly", "categories": ["cs.RO"], "comment": "6 pages, 8 figures", "summary": "This study addresses a flexible holding tool for robotic disassembly. We\npropose a shell-type soft jig that securely and universally holds objects,\nmitigating the risk of component damage and adapting to diverse shapes while\nenabling soft fixation that is robust to recognition, planning, and control\nerrors. The balloon-based holding mechanism ensures proper alignment and stable\nholding performance, thereby reducing the need for dedicated jig design, highly\naccurate perception, precise grasping, and finely tuned trajectory planning\nthat are typically required with conventional fixtures. Our experimental\nresults demonstrate the practical feasibility of the proposed jig through\nperformance comparisons with a vise and a jamming-gripper-inspired soft jig.\nTests on ten different objects further showed representative successes and\nfailures, clarifying the jig's limitations and outlook.", "AI": {"tldr": "The study proposes a soft, shell-type jig for robotic disassembly that adapts to diverse object shapes and reduces the need for precise tools and control.", "motivation": "Current robotic disassembly tools require precise equipment and planning, which limits flexibility and increases risks, like component damage.", "method": "The authors develop a balloon-based soft jig that securely holds objects, adapts to various shapes, and reduces reliance on precise perception, trajectory, and grasping techniques.", "result": "Experimental evaluations show the jig's practical feasibility, comparing it favorably against other holding mechanisms, though limitations were identified.", "conclusion": "The proposed jig offers a versatile, damage-mitigating solution for robotic disassembly, providing robustness against common errors in recognition and control systems."}}
{"id": "2509.14023", "pdf": "https://arxiv.org/pdf/2509.14023", "abs": "https://arxiv.org/abs/2509.14023", "authors": ["Sami Ul Haq", "Sheila Castilho", "Yvette Graham"], "title": "Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality", "categories": ["cs.CL", "cs.HC"], "comment": "Accepted at WMT2025 (ENNLP) for oral presented", "summary": "Machine Translation (MT) has achieved remarkable performance, with growing\ninterest in speech translation and multimodal approaches. However, despite\nthese advancements, MT quality assessment remains largely text centric,\ntypically relying on human experts who read and compare texts. Since many\nreal-world MT applications (e.g Google Translate Voice Mode, iFLYTEK\nTranslator) involve translation being spoken rather printed or read, a more\nnatural way to assess translation quality would be through speech as opposed\ntext-only evaluations. This study compares text-only and audio-based\nevaluations of 10 MT systems from the WMT General MT Shared Task, using\ncrowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,\nperformed statistical significance testing and self-replication experiments to\ntest reliability and consistency of audio-based approach. Crowd-sourced\nassessments based on audio yield rankings largely consistent with text only\nevaluations but, in some cases, identify significant differences between\ntranslation systems. We attribute this to speech richer, more natural modality\nand propose incorporating speech-based assessments into future MT evaluation\nframeworks.", "AI": {"tldr": "This study suggests evaluating machine translation (MT) quality using audio-based methods instead of solely text-only evaluations, finding consistency in rankings but identifying key differences that speech-based modalities highlight.", "motivation": "Current MT quality assessments are primarily text-centric, ignoring the real-world utility of spoken translations in applications like Google Translate Voice Mode.", "method": "This paper utilizes crowd-sourced judgments via Amazon Mechanical Turk to compare text-only and audio-based evaluations of 10 MT systems, supported by statistical tests and self-replication experiments.", "result": "Audio-based methods provided results consistent with text-based evaluations but uncovered important discrepancies, showcasing benefits of assessing translations through a richer, speech-based modality.", "conclusion": "Speech-based assessments should complement text evaluations for MT systems to better reflect the natural usage of translation systems in real-world applications."}}
{"id": "2509.13908", "pdf": "https://arxiv.org/pdf/2509.13908", "abs": "https://arxiv.org/abs/2509.13908", "authors": ["Priyobrata Mondal", "Faizanuddin Ansari", "Swagatam Das"], "title": "APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring fairness in machine learning models is critical, especially when\nbiases compound across intersecting protected attributes like race, gender, and\nage. While existing methods address fairness for single attributes, they fail\nto capture the nuanced, multiplicative biases faced by intersectional\nsubgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first\nframework to explicitly model intersectional fairness as a joint optimization\nproblem over the Cartesian product of sensitive attributes. APFEx combines\nthree key innovations- (1) an adaptive multi-objective optimizer that\ndynamically switches between Pareto cone projection, gradient weighting, and\nexploration strategies to navigate fairness-accuracy trade-offs, (2)\ndifferentiable intersectional fairness metrics enabling gradient-based\noptimization of non-smooth subgroup disparities, and (3) theoretical guarantees\nof convergence to Pareto-optimal solutions. Experiments on four real-world\ndatasets demonstrate APFEx's superiority, reducing fairness violations while\nmaintaining competitive accuracy. Our work bridges a critical gap in fair ML,\nproviding a scalable, model-agnostic solution for intersectional fairness.", "AI": {"tldr": "APFEx is a novel framework for addressing fairness issues in machine learning, particularly for intersectional subgroups.", "motivation": "Existing fairness approaches fail to account for compounded biases in intersecting protected attributes like race, gender, and age.", "method": "APFEx proposes a joint optimization framework leveraging adaptive multi-objective optimization, differentiable fairness metrics, and guarantees on Pareto-optimal solutions.", "result": "Experiments on four datasets show APFEx reduces fairness violations while maintaining competitive model accuracy.", "conclusion": "APFEx offers a scalable, model-agnostic solution for achieving intersectional fairness in machine learning models."}}
{"id": "2509.13676", "pdf": "https://arxiv.org/pdf/2509.13676", "abs": "https://arxiv.org/abs/2509.13676", "authors": ["Xiaobo Yang", "Xiaojin Gong"], "title": "Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, Referring Image Segmentation (RIS) frameworks that pair the\nMultimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)\nhave achieved impressive results. However, adapting MLLM to segmentation is\ncomputationally intensive, primarily due to visual token redundancy. We observe\nthat traditional patch-wise visual projectors struggle to strike a balance\nbetween reducing the number of visual tokens and preserving semantic clarity,\noften retaining overly long token sequences to avoid performance drops.\nInspired by text tokenizers, we propose a novel semantic visual projector that\nleverages semantic superpixels generated by SAM to identify \"visual words\" in\nan image. By compressing and projecting semantic superpixels as visual tokens,\nour approach adaptively shortens the token sequence according to scene\ncomplexity while minimizing semantic loss in compression. To mitigate loss of\ninformation, we propose a semantic superpixel positional embedding to\nstrengthen MLLM's awareness of superpixel geometry and position, alongside a\nsemantic superpixel aggregator to preserve both fine-grained details inside\nsuperpixels and global context outside. Experiments show that our method cuts\nvisual tokens by 93% without compromising performance, notably speeding up MLLM\ntraining and inference, and outperforming existing compressive visual\nprojectors on RIS.", "AI": {"tldr": "The paper introduces a semantic visual projector that uses semantic superpixels to compress and project visual tokens for Referring Image Segmentation (RIS), reducing token quantity by 93% without degrading performance.", "motivation": "Traditional visual projectors for RIS are inefficient due to the inability to balance token reduction and semantic clarity, leading to unnecessarily long token sequences.", "method": "The method uses semantic superpixels generated by SAM to adaptively shorten token sequences, incorporates positional embeddings for geometric awareness, and uses a superpixel aggregator to maintain granular and global context.", "result": "The proposed method reduces token sequences by 93%, accelerates MLLM training and inference, and outperforms existing visual projectors in RIS tasks.", "conclusion": "Semantic superpixels effectively optimize the tokenization process in RIS, maintaining performance while significantly improving computational efficiency."}}
{"id": "2509.13815", "pdf": "https://arxiv.org/pdf/2509.13815", "abs": "https://arxiv.org/abs/2509.13815", "authors": ["Takuya Kiyokawa", "Zhengtao Hu", "Weiwei Wan", "Kensuke Harada"], "title": "Soft Regrasping Tool Inspired by Jamming Gripper", "categories": ["cs.RO"], "comment": "6 pages, 9 figures", "summary": "Regrasping on fixtures is a promising approach to reduce pose uncertainty in\nrobotic assembly, but conventional rigid fixtures lack adaptability and require\ndedicated designs for each part. To overcome this limitation, we propose a soft\njig inspired by the jamming transition phenomenon, which can be continuously\ndeformed to accommodate diverse object geometries. By pressing a\ntriangular-pyramid-shaped tool into the membrane and evacuating the enclosed\nair, a stable cavity is formed as a placement space. We further optimize the\nstamping depth to balance placement stability and gripper accessibility. In\nsoft-jig-based regrasping, the key challenge lies in optimizing the cavity size\nto achieve precise dropping; once the part is reliably placed, subsequent\ngrasping can be performed with reduced uncertainty. Accordingly, we conducted\ndrop experiments on ten mechanical parts of varying shapes, which achieved\nplacement success rates exceeding 80% for most objects and above 90% for\ncylindrical ones, while failures were mainly caused by geometric constraints\nand membrane properties. These results demonstrate that the proposed jig\nenables general-purpose, accurate, and repeatable regrasping, while also\nclarifying its current limitations and future potential as a practical\nalternative to rigid fixtures in assembly automation.", "AI": {"tldr": "The paper introduces a soft jig based on the jamming transition phenomenon to enable adaptable and precise robotic regrasping for assembly tasks, achieving high success rates across diverse object geometries.", "motivation": "To address the limitations of conventional rigid fixtures, which require dedicated designs and lack adaptability, the authors aim to reduce pose uncertainty in robotic assembly using a versatile, deformable solution.", "method": "A soft jig is developed, leveraging the jamming transition phenomenon. A triangular-pyramid-shaped tool creates a cavity in the jig by deforming its elastic membrane. The cavity\u2019s size and depth are optimized for stable placement and gripper accessibility.", "result": "Drop experiments conducted on ten mechanical parts demonstrated placement success rates above 80% for most objects and over 90% for cylindrical shapes. Failures were linked to geometric constraints and membrane properties.", "conclusion": "The proposed soft jig offers a general-purpose, accurate, and repeatable regrasping alternative to rigid fixtures, though current limitations exist. It holds promise for enhancing robotic assembly automation."}}
{"id": "2509.14031", "pdf": "https://arxiv.org/pdf/2509.14031", "abs": "https://arxiv.org/abs/2509.14031", "authors": ["Pawe\u0142 M\u0105ka", "Yusuf Can Semerci", "Jan Scholtes", "Gerasimos Spanakis"], "title": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "EMNLP 2025 main conference", "summary": "Achieving human-level translations requires leveraging context to ensure\ncoherence and handle complex phenomena like pronoun disambiguation. Sparsity of\ncontextually rich examples in the standard training data has been hypothesized\nas the reason for the difficulty of context utilization. In this work, we\nsystematically validate this claim in both single- and multilingual settings by\nconstructing training datasets with a controlled proportions of contextually\nrelevant examples. We demonstrate a strong association between training data\nsparsity and model performance confirming sparsity as a key bottleneck.\nImportantly, we reveal that improvements in one contextual phenomenon do no\ngeneralize to others. While we observe some cross-lingual transfer, it is not\nsignificantly higher between languages within the same sub-family. Finally, we\npropose and empirically evaluate two training strategies designed to leverage\nthe available data. These strategies improve context utilization, resulting in\naccuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in\nsingle- and multilingual settings respectively.", "AI": {"tldr": "The paper investigates the impact of training data scarcity on context utilization in machine translation and proposes strategies to address it.", "motivation": "The difficulty of utilizing context in machine translation may stem from sparse contextually rich examples in training data.", "method": "The authors create controlled training datasets and evaluate the impact of data sparsity through single- and multilingual experiments. They also propose two training strategies.", "result": "Data sparsity is confirmed as a bottleneck. Proposed strategies improve context utilization by up to 6% in single-language settings and 8% in multilingual settings.", "conclusion": "Addressing contextually rich data sparsity with specialized training strategies can improve model performance, but improvements on one phenomenon do not generalize to others."}}
{"id": "2509.13914", "pdf": "https://arxiv.org/pdf/2509.13914", "abs": "https://arxiv.org/abs/2509.13914", "authors": ["Divya Thuremella", "Yi Yang", "Simon Wanna", "Lars Kunze", "Daniele De Martini"], "title": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "summary": "This work explores the application of ensemble modeling to the\nmultidimensional regression problem of trajectory prediction for vehicles in\nurban environments. As newer and bigger state-of-the-art prediction models for\nautonomous driving continue to emerge, an important open challenge is the\nproblem of how to combine the strengths of these big models without the need\nfor costly re-training. We show how, perhaps surprisingly, combining\nstate-of-the-art deep learning models out-of-the-box (without retraining or\nfine-tuning) with a simple confidence-weighted average method can enhance the\noverall prediction. Indeed, while combining trajectory prediction models is not\nstraightforward, this simple approach enhances performance by 10% over the best\nprediction model, especially in the long-tailed metrics. We show that this\nperformance improvement holds on both the NuScenes and Argoverse datasets, and\nthat these improvements are made across the dataset distribution. The code for\nour work is open source.", "AI": {"tldr": "The paper introduces a method to improve vehicle trajectory prediction by combining existing deep learning models using a simple confidence-weighted average, achieving a 10% performance improvement without retraining.", "motivation": "To address the challenge of leveraging strengths of large, state-of-the-art prediction models for autonomous driving without requiring costly retraining.", "method": "Combine state-of-the-art deep learning trajectory prediction models using a confidence-weighted averaging method, applied out-of-the-box without fine-tuning or retraining.", "result": "The method improves trajectory prediction performance by 10%, especially in long-tailed metrics, and is validated on both NuScenes and Argoverse datasets.", "conclusion": "Ensemble modeling using simple averaging techniques can effectively enhance prediction performance, providing a practical solution for autonomous driving challenges without additional computational costs of retraining."}}
{"id": "2509.13681", "pdf": "https://arxiv.org/pdf/2509.13681", "abs": "https://arxiv.org/abs/2509.13681", "authors": ["Hang Li", "Dianmo Sheng", "Qiankun Dong", "Zichun Wang", "Zhiwei Xu", "Tao Li"], "title": "FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras", "categories": ["cs.CV"], "comment": "8 pages, 4 figures", "summary": "As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)\nsegmentation has recently achieved remarkable progress with pinhole cameras.\nHowever, it is non-trivial to extend the existing methods to fisheye cameras\nwith severe geometric distortion, ambiguous multi-view correspondences and\nunstable temporal dynamics, all of which significantly degrade BEV performance.\nTo address these challenges, we propose FishBEV, a novel BEV segmentation\nframework specifically tailored for fisheye cameras. This framework introduces\nthree complementary innovations, including a Distortion-Resilient Multi-scale\nExtraction (DRME) backbone that learns robust features under distortion while\npreserving scale consistency, an Uncertainty-aware Spatial Cross-Attention\n(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view\nalignment, a Distance-aware Temporal Self-Attention (D-TSA) module that\nadaptively balances near field details and far field context to ensure temporal\ncoherence. Extensive experiments on the Synwoodscapes dataset demonstrate that\nFishBEV consistently outperforms SOTA baselines, regarding the performance\nevaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.", "AI": {"tldr": "FishBEV is a new BEV segmentation framework for fisheye cameras that addresses distortion, ambiguous views, and temporal instability using innovative modules.", "motivation": "To overcome challenges in applying BEV segmentation techniques to fisheye cameras, which suffer from severe geometric distortion, misaligned multi-view data, and unstable time-based dynamics.", "method": "FishBEV incorporates three innovations: DRME backbone to handle distortion, U-SCA mechanism for cross-view alignment via uncertainty estimation, and D-TSA module for balancing near-field and far-field data in temporal dynamics.", "result": "FishBEV outperforms state-of-the-art benchmarks in fisheye BEV segmentation tasks, validated by experiments on the Synwoodscapes dataset.", "conclusion": "The introduction of FishBEV advances BEV segmentation for fisheye cameras, offering robust handling of distortion, spatial uncertainties, and temporal coherence."}}
{"id": "2509.13816", "pdf": "https://arxiv.org/pdf/2509.13816", "abs": "https://arxiv.org/abs/2509.13816", "authors": ["Yude Li", "Zhexuan Zhou", "Huizhe Li", "Youmin Gong", "Jie Mei"], "title": "Agile in the Face of Delay: Asynchronous End-to-End Learning for Real-World Aerial Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Robust autonomous navigation for Autonomous Aerial Vehicles (AAVs) in complex\nenvironments is a critical capability. However, modern end-to-end navigation\nfaces a key challenge: the high-frequency control loop needed for agile flight\nconflicts with low-frequency perception streams, which are limited by sensor\nupdate rates and significant computational cost. This mismatch forces\nconventional synchronous models into undesirably low control rates. To resolve\nthis, we propose an asynchronous reinforcement learning framework that\ndecouples perception and control, enabling a high-frequency policy to act on\nthe latest IMU state for immediate reactivity, while incorporating perception\nfeatures asynchronously. To manage the resulting data staleness, we introduce a\ntheoretically-grounded Temporal Encoding Module (TEM) that explicitly\nconditions the policy on perception delays, a strategy complemented by a\ntwo-stage curriculum to ensure stable and efficient training. Validated in\nextensive simulations, our method was successfully deployed in zero-shot\nsim-to-real transfer on an onboard NUC, where it sustains a 100~Hz control rate\nand demonstrates robust, agile navigation in cluttered real-world environments.\nOur source code will be released for community reference.", "AI": {"tldr": "The paper proposes an asynchronous reinforcement learning framework for autonomous aerial vehicles (AAVs) to handle the mismatch between high-frequency control loops and low-frequency perception streams, ensuring agile navigation in complex environments.", "motivation": "The motivation stems from the need to overcome the challenge posed by the mismatched frequencies of control loops and perception streams, which limits navigation efficiency in AAVs operating in complex environments.", "method": "The authors introduce an asynchronous reinforcement learning framework that decouples perception and control tasks, employing a Temporal Encoding Module (TEM) to address data staleness and a two-stage curriculum for stable training.", "result": "The proposed method achieved robust and agile navigation through a 100 Hz control rate, validated in simulations and successful zero-shot sim-to-real transfer in real-world tests.", "conclusion": "The asynchronous framework effectively mitigates the perception-control mismatch, enabling real-world agile navigation for AAVs, with the source code being made publicly available for further research."}}
{"id": "2509.13345", "pdf": "https://arxiv.org/pdf/2509.13345", "abs": "https://arxiv.org/abs/2509.13345", "authors": ["Zihao Li", "Weiwei Yi", "Jiahong Chen"], "title": "Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) permeate everyday decision-making, their\nepistemic and societal risks demand urgent scrutiny. Hallucinations, the\ngeneration of fabricated, misleading, oversimplified or untrustworthy outputs,\nhas emerged as imperative challenges. While regulatory, academic, and technical\ndiscourse position accuracy as the principal benchmark for mitigating such\nharms, this article contends that overreliance on accuracy misdiagnoses the\nproblem and has counterproductive effect: the accuracy paradox. Drawing on\ninterdisciplinary literatures, this article develops a taxonomy of\nhallucination types and shows the paradox along three intertwining dimensions:\noutputs, individuals and society. First, accuracy functions as a superficial\nproxy for reliability, incentivising the optimisation of rhetorical fluency and\nsurface-level correctness over epistemic trustworthiness. This encourages\npassive user trust in outputs that appear accurate but epistemically untenable.\nSecond, accuracy as a singular metric fails to detect harms that are not\nfactually false but are nonetheless misleading, value-laden, or socially\ndistorting, including consensus illusions, sycophantic alignment, and subtle\nmanipulation. Third, regulatory overemphasis on accuracy obscures the wider\nsocietal consequences of hallucination, including social sorting, privacy\nviolations, equity harms, epistemic convergence that marginalises dissent,\nreduces pluralism, and causes social deskilling. By examining the EU AI Act,\nGDPR, and DSA, the article argues that current regulations are not yet\nstructurally equipped to address these epistemic, relational, and systemic\nharms and exacerbated by the overreliance on accuracy. By exposing such\nconceptual and practical challenges, this article calls for a fundamental shift\ntowards pluralistic, context-aware, and manipulation-resilient approaches to AI\ntrustworthy governance.", "AI": {"tldr": "This paper critiques the focus on accuracy as the primary metric for addressing hallucinations in large language models, exposing its limitations and proposing a broader, context-aware approach.", "motivation": "The paper aims to address the growing epistemic and societal risks of hallucinations in large language models, especially given their role in everyday decision-making.", "method": "The authors develop a taxonomy of hallucination types and analyze the limitations of accuracy as a singular metric across three dimensions\u2014outputs, individuals, and societal impacts. They also examine current regulations like the EU AI Act, GDPR, and DSA.", "result": "The analysis shows that an overemphasis on accuracy can lead to superficial trust in outputs, fail to detect nuanced harms, and obscure broader societal consequences of AI hallucinations.", "conclusion": "The paper advocates for transitioning to a pluralistic, context-aware, and manipulation-resilient framework for AI governance to address epistemic, relational, and systemic risks."}}
{"id": "2509.14034", "pdf": "https://arxiv.org/pdf/2509.14034", "abs": "https://arxiv.org/abs/2509.14034", "authors": ["Zijie Lin", "Bryan Hooi"], "title": "Enhancing Multi-Agent Debate System Performance via Confidence Expression", "categories": ["cs.CL"], "comment": "EMNLP'25 Findings", "summary": "Generative Large Language Models (LLMs) have demonstrated remarkable\nperformance across a wide range of tasks. Recent research has introduced\nMulti-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate\nhuman debate and thereby improve task performance. However, while some LLMs may\npossess superior knowledge or reasoning capabilities for specific tasks, they\noften struggle to clearly communicate this advantage during debates, in part\ndue to a lack of confidence expression. Moreover, inappropriate confidence\nexpression can cause agents in MAD systems to either stubbornly maintain\nincorrect beliefs or converge prematurely on suboptimal answers, ultimately\nreducing debate effectiveness and overall system performance. To address these\nchallenges, we propose incorporating confidence expression into MAD systems to\nallow LLMs to explicitly communicate their confidence levels. To validate this\napproach, we develop ConfMAD, a MAD framework that integrates confidence\nexpression throughout the debate process. Experimental results demonstrate the\neffectiveness of our method, and we further analyze how confidence influences\ndebate dynamics, offering insights into the design of confidence-aware MAD\nsystems.", "AI": {"tldr": "The paper proposes adding confidence expression to Multi-Agent Debate (MAD) systems involving Large Language Models (LLMs) to improve task performance and debate accuracy.", "motivation": "LLMs struggle to convey superior knowledge effectively during debates, and inappropriate confidence expression can lead to suboptimal debate outcomes, reducing their effectiveness in MAD systems.", "method": "The study introduces ConfMAD, a framework for MAD systems that incorporates explicit confidence expression throughout the debate process.", "result": "Experimental results show that adding confidence expression improves task performance and debate dynamics in MAD systems.", "conclusion": "Integrating confidence expression into MAD systems not only enhances debate effectiveness but also offers insights for designing confidence-aware systems."}}
{"id": "2509.13687", "pdf": "https://arxiv.org/pdf/2509.13687", "abs": "https://arxiv.org/abs/2509.13687", "authors": ["Kaniz Fatema", "Emad A. Mohammed", "Sukhjit Singh Sehra"], "title": "Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification", "categories": ["cs.CV"], "comment": null, "summary": "Effective and interpretable classification of medical images is a challenge\nin computer-aided diagnosis, especially in resource-limited clinical settings.\nThis study introduces spline-based Kolmogorov-Arnold Networks (KANs) for\naccurate medical image classification with limited, diverse datasets. The\nmodels include SBTAYLOR-KAN, integrating B-splines with Taylor series;\nSBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,\nembedding B-splines in Morlet wavelet transforms. These approaches leverage\nspline-based function approximation to capture both local and global\nnonlinearities. The models were evaluated on brain MRI, chest X-rays,\ntuberculosis X-rays, and skin lesion images without preprocessing,\ndemonstrating the ability to learn directly from raw data. Extensive\nexperiments, including cross-dataset validation and data reduction analysis,\nshowed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%\naccuracy, with a balanced F1-score, maintaining over 86% accuracy using only\n30% of the training data across three datasets. Despite class imbalance in the\nskin cancer dataset, experiments on both imbalanced and balanced versions\nshowed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.\nUnlike traditional CNNs, which require millions of parameters (e.g., ResNet50\nwith 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872\ntrainable parameters, making it more suitable for constrained medical\nenvironments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used\nfor interpretability, highlighting relevant regions in medical images. This\nframework provides a lightweight, interpretable, and generalizable solution for\nmedical image classification, addressing the challenges of limited datasets and\ndata-scarce scenarios in clinical AI applications.", "AI": {"tldr": "The paper proposes lightweight, spline-based Kolmogorov-Arnold Networks (KANs) for effective medical image classification, excelling in low-data scenarios and outperforming traditional CNNs in resource-constrained settings.", "motivation": "The study aims to address the challenge of accurate and interpretable medical image classification in clinical environments with limited and diverse datasets.", "method": "The paper introduces three spline-based KAN models: SBTAYLOR-KAN, SBRBF-KAN, and SBWAVELET-KAN, employing spline-based function approximations for learning directly from raw image data.", "result": "The SBTAYLOR-KAN model achieved up to 98.93% accuracy with high generalization, using only 30% of the training data in some cases, while requiring significantly fewer parameters compared to traditional CNNs.", "conclusion": "The proposed KAN framework is lightweight, interpretable, and effective for medical image classification in data-scarce environments, offering a robust alternative to traditional methods."}}
{"id": "2509.14036", "pdf": "https://arxiv.org/pdf/2509.14036", "abs": "https://arxiv.org/abs/2509.14036", "authors": ["Zekang Liu", "Wei Feng", "Fanhua Shang", "Lianyu Hu", "Jichao Feng", "Liqing Gao"], "title": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sign Language Translation (SLT) bridges the communication gap between deaf\npeople and hearing people, where dialogue provides crucial contextual cues to\naid in translation. Building on this foundational concept, this paper proposes\nQuestion-based Sign Language Translation (QB-SLT), a novel task that explores\nthe efficient integration of dialogue. Unlike gloss (sign language\ntranscription) annotations, dialogue naturally occurs in communication and is\neasier to annotate. The key challenge lies in aligning multimodality features\nwhile leveraging the context of the question to improve translation. To address\nthis issue, we propose a cross-modality Self-supervised Learning with Sigmoid\nSelf-attention Weighting (SSL-SSAW) fusion method for sign language\ntranslation. Specifically, we employ contrastive learning to align\nmultimodality features in QB-SLT, then introduce a Sigmoid Self-attention\nWeighting (SSAW) module for adaptive feature extraction from question and sign\nlanguage sequences. Additionally, we leverage available question text through\nself-supervised learning to enhance representation and translation\ncapabilities. We evaluated our approach on newly constructed CSL-Daily-QA and\nPHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,\neasily accessible question assistance can achieve or even surpass the\nperformance of gloss assistance. Furthermore, visualization results demonstrate\nthe effectiveness of incorporating dialogue in improving translation quality.", "AI": {"tldr": "The paper introduces a new task called Question-based Sign Language Translation (QB-SLT), leveraging dialogue context to improve translation quality using self-supervised learning and multimodal alignment techniques.", "motivation": "The motivation stems from the need to bridge communication gaps between deaf and hearing individuals while exploring efficient integration of question dialogue, which is easier to annotate compared to gloss annotations.", "method": "The authors propose a cross-modality Self-supervised Learning with Sigmoid Self-attention Weighting (SSL-SSAW) fusion method, using contrastive learning for multimodal feature alignment and self-supervised learning for enhanced representation.", "result": "Experiments on newly constructed datasets show that the proposed SSL-SSAW method achieves state-of-the-art performance, with question-based assistance surpassing gloss-based assistance in translation tasks.", "conclusion": "The findings emphasize the effectiveness of dialogue integration in sign language translation, highlighting its potential to enhance accessibility while reducing reliance on complex annotations like gloss."}}
{"id": "2509.13952", "pdf": "https://arxiv.org/pdf/2509.13952", "abs": "https://arxiv.org/abs/2509.13952", "authors": ["Amin Lotfalian", "Mohammad Reza Banan", "Pooyan Broumand"], "title": "eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "This paper presents eXtended Physics-Informed Neural Network (X-PINN), a\nnovel and robust framework for addressing fracture mechanics problems involving\nmultiple cracks in fractured media. To address this, an energy-based loss\nfunction, customized integration schemes, and domain decomposition procedures\nare proposed. Inspired by the Extended Finite Element Method (XFEM), the neural\nnetwork solution space is enriched with specialized functions that allow crack\nbody discontinuities and singularities at crack tips to be explicitly captured.\nFurthermore, a structured framework is introduced in which standard and\nenriched solution components are modeled using distinct neural networks,\nenabling flexible and effective simulations of complex multiple-crack problems\nin 1D and 2D domains, with convenient extensibility to 3D problems. Numerical\nexperiments are conducted to validate the effectiveness and robustness of the\nproposed method.", "AI": {"tldr": "This paper introduces X-PINN, an advanced framework utilizing neural networks tailored for complex fracture mechanics with multiple cracks, integrating enriched solution spaces, domain decompositions, and energy-based loss functions.", "motivation": "To improve the simulation and modeling of fracture mechanics problems in media with multiple cracks, which traditional methods struggle to handle efficiently and accurately.", "method": "Combines domain decomposition, customized integration schemes, and neural networks enriched using functions inspired by XFEM, along with an energy-based loss function, enabling the explicit capture of crack features.", "result": "Validated through numerical experiments, demonstrating the method's robustness and effectiveness for modeling complex crack problems in 1D and 2D, with potential for extension to 3D domains.", "conclusion": "The proposed X-PINN framework provides a flexible, robust, and extensible solution for simulating and analyzing fracture mechanics problems involving multiple cracks."}}
{"id": "2509.13711", "pdf": "https://arxiv.org/pdf/2509.13711", "abs": "https://arxiv.org/abs/2509.13711", "authors": ["Qiuyu Tang", "Joshua Krinsky", "Aparna Bharati"], "title": "StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of generative models, particularly diffusion-based\napproaches, has inadvertently facilitated their potential for misuse. Such\nmodels enable malicious exploiters to replicate artistic styles that capture an\nartist's creative labor, personal vision, and years of dedication in an\ninexpensive manner. This has led to a rise in the need and exploration of\nmethods for protecting artworks against style mimicry. Although generic\ndiffusion models can easily mimic an artistic style, finetuning amplifies this\ncapability, enabling the model to internalize and reproduce the style with\nhigher fidelity and control. We hypothesize that certain cross-attention layers\nexhibit heightened sensitivity to artistic styles. Sensitivity is measured\nthrough activation strengths of attention layers in response to style and\ncontent representations, and assessing their correlations with features\nextracted from external models. Based on our findings, we introduce an\nefficient and lightweight protection strategy, StyleProtect, that achieves\neffective style defense against fine-tuned diffusion models by updating only\nselected cross-attention layers. Our experiments utilize a carefully curated\nartwork dataset based on WikiArt, comprising representative works from 30\nartists known for their distinctive and influential styles and cartoon\nanimations from the Anita dataset. The proposed method demonstrates promising\nperformance in safeguarding unique styles of artworks and anime from malicious\ndiffusion customization, while maintaining competitive imperceptibility.", "AI": {"tldr": "The paper addresses concerns around generative models mimicking artistic styles and proposes 'StyleProtect,' a strategy for safeguarding artworks against misuse by selectively updating cross-attention layers in diffusion models.", "motivation": "The motivation stems from the ethical dilemma posed by generative models, particularly diffusion-based ones, which can replicate artistic styles and undermine artists\u2019 creative labor.", "method": "The method involves analyzing cross-attention layer sensitivities to artistic styles and implementing 'StyleProtect' by updating only sensitive layers to inhibit unauthorized style mimicry.", "result": "Experiments using artwork datasets, like WikiArt, showed that 'StyleProtect' effectively defends against style mimicry while maintaining imperceptibility.", "conclusion": "'StyleProtect' offers a lightweight and efficient means to protect artists' styles from misuse without compromising artwork quality or visibility."}}
{"id": "2509.13832", "pdf": "https://arxiv.org/pdf/2509.13832", "abs": "https://arxiv.org/abs/2509.13832", "authors": ["Teng Wang", "Haojun Jiang", "Yuxuan Wang", "Zhenguo Sun", "Xiangjie Yan", "Xiang Li", "Gao Huang"], "title": "UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography", "categories": ["cs.RO"], "comment": null, "summary": "Carotid ultrasound is crucial for the assessment of cerebrovascular health,\nparticularly the internal carotid artery (ICA). While previous research has\nexplored automating carotid ultrasound, none has tackled the challenging ICA.\nThis is primarily due to its deep location, tortuous course, and significant\nindividual variations, which greatly increase scanning complexity. To address\nthis, we propose a Hierarchical Transformer-based decision architecture, namely\nUltraHiT, that integrates high-level variation assessment with low-level action\ndecision. Our motivation stems from conceptualizing individual vascular\nstructures as morphological variations derived from a standard vascular model.\nThe high-level module identifies variation and switches between two low-level\nmodules: an adaptive corrector for variations, or a standard executor for\nnormal cases. Specifically, both the high-level module and the adaptive\ncorrector are implemented as causal transformers that generate predictions\nbased on the historical scanning sequence. To ensure generalizability, we\ncollected the first large-scale ICA scanning dataset comprising 164\ntrajectories and 72K samples from 28 subjects of both genders. Based on the\nabove innovations, our approach achieves a 95% success rate in locating the ICA\non unseen individuals, outperforming baselines and demonstrating its\neffectiveness. Our code will be released after acceptance.", "AI": {"tldr": "The paper introduces UltraHiT, a Hierarchical Transformer-based decision architecture that automates carotid ultrasound for internal carotid artery (ICA) scanning. It achieves a 95% success rate on unseen individuals.", "motivation": "The motivation lies in addressing the complexity of scanning the ICA, which is deeply located, tortuous, and variable, making automation challenging.", "method": "UltraHiT uses a Hierarchical Transformer-based architecture with a high-level variation assessment module and low-level action decision modules (adaptive corrector and standard executor). These are implemented using causal transformers trained on historical sequences.", "result": "The model achieved a 95% success rate in locating ICA on unseen individuals, surpassing baseline methods. A large dataset of ICA scans was compiled to validate its generalizability.", "conclusion": "The UltraHiT approach has demonstrated effectiveness in automating the complex ICA scanning process in carotid ultrasound, paving the way for broader applications in cerebrovascular health assessments."}}
{"id": "2509.14128", "pdf": "https://arxiv.org/pdf/2509.14128", "abs": "https://arxiv.org/abs/2509.14128", "authors": ["Monica Sekoyan", "Nithin Rao Koluguri", "Nune Tadevosyan", "Piotr Zelasko", "Travis Bartley", "Nick Karpov", "Jagadeesh Balam", "Boris Ginsburg"], "title": "Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST", "categories": ["cs.CL", "eess.AS"], "comment": "Mini Version of it Submitted to ICASSP 2026", "summary": "This report introduces Canary-1B-v2, a fast, robust multilingual model for\nAutomatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built\nwith a FastConformer encoder and Transformer decoder, it supports 25 languages\nprimarily European. The model was trained on 1.7M hours of total data samples,\nincluding Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce\nhallucinations for ASR and AST. We describe its two-stage pre-training and\nfine-tuning process with dynamic data balancing, as well as experiments with an\nnGPT encoder. Results show nGPT scales well with massive data, while\nFastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the\nNeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable\nsegment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2\noutperforms Whisper-large-v3 on English ASR while being 10x faster, and\ndelivers competitive multilingual ASR and AST performance against larger models\nlike Seamless-M4T-v2-large and LLM-based systems. We also release\nParakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the\nsame 25 languages with just 600M parameters.", "AI": {"tldr": "The paper introduces Canary-1B-v2, a fast, robust ASR and AST model for 25 languages, which outperforms competitors while being more efficient, and releases a smaller model variant, Parakeet-TDT-0.6B-v3.", "motivation": "The motivation behind the paper is to address the need for a faster, more efficient, and robust multilingual ASR and AST model that performs well even with limited computational resources, covering diverse languages.", "method": "The model incorporates a FastConformer encoder and Transformer decoder, pre-trained and fine-tuned on massive multilingual datasets (1.7M hours), uses non-speech audio for robustness, dynamic data balancing, and the NeMo Forced Aligner for timestamps.", "result": "Canary-1B-v2 outperforms Whisper-large-v3 in English ASR and is 10x faster. It shows competitive multilingual ASR and AST performance against much larger models, while a smaller model, Parakeet-TDT-0.6B-v3, achieves comparable results with fewer parameters.", "conclusion": "Canary-1B-v2 is highly efficient for ASR and AST tasks, demonstrating scalability and robustness. The release of Parakeet-TDT-0.6B-v3 cements progress in efficient multilingual speech recognition modeling."}}
{"id": "2509.13974", "pdf": "https://arxiv.org/pdf/2509.13974", "abs": "https://arxiv.org/abs/2509.13974", "authors": ["Amirhossein Shahbazinia", "Jonathan Dan", "Jose A. Miranda", "Giovanni Ansaloni", "David Atienza"], "title": "Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Objective: Epilepsy, a prevalent neurological disease, demands careful\ndiagnosis and continuous care. Seizure detection remains challenging, as\ncurrent clinical practice relies on expert analysis of electroencephalography,\nwhich is a time-consuming process and requires specialized knowledge.\nAddressing this challenge, this paper explores automated epileptic seizure\ndetection using deep learning, focusing on personalized continual learning\nmodels that adapt to each patient's unique electroencephalography signal\nfeatures, which evolve over time. Methods: In this context, our approach\naddresses the challenge of integrating new data into existing models without\ncatastrophic forgetting, a common issue in static deep learning models. We\npropose EpiSMART, a continual learning framework for seizure detection that\nuses a size-constrained replay buffer and an informed sample selection strategy\nto incrementally adapt to patient-specific electroencephalography signals. By\nselectively retaining high-entropy and seizure-predicted samples, our method\npreserves critical past information while maintaining high performance with\nminimal memory and computational requirements. Results: Validation on the\nCHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score\nover a trained baseline without updates in all other patients. On average,\nEpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,\nmaking it suitable for real-time deployment in wearable systems.\nConclusion:EpiSMART enables robust and personalized seizure detection under\nrealistic and resource-constrained conditions by effectively integrating new\ndata into existing models without degrading past knowledge. Significance: This\nframework advances automated seizure detection by providing a continual\nlearning approach that supports patient-specific adaptation and practical\ndeployment in wearable healthcare systems.", "AI": {"tldr": "The paper introduces EpiSMART, a personalized seizure detection framework combining continual learning to adapt over time without forgetting old knowledge.", "motivation": "Current epilepsy diagnosis relies on time-consuming expert review of EEG data, requiring innovation in automated and personalized seizure detection.", "method": "The study proposes EpiSMART, utilizing a size-constrained replay buffer and an informed sample selection strategy to maintain performance and adapt continually.", "result": "EpiSMART improved F1 score by 21% using minimal data (6.46 minutes labeled daily), demonstrating its resource-efficiency and suitability for real-time application.", "conclusion": "EpiSMART provides an effective solution for patient-specific seizure detection in wearable systems operating under constrained resources."}}
{"id": "2509.13713", "pdf": "https://arxiv.org/pdf/2509.13713", "abs": "https://arxiv.org/abs/2509.13713", "authors": ["Tae-Wook Um", "Ki-Hyeon Kim", "Hyun-Duck Choi", "Hyo-Sung Ahn"], "title": "UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry", "categories": ["cs.CV"], "comment": null, "summary": "Monocular depth estimation has been increasingly adopted in robotics and\nautonomous driving for its ability to infer scene geometry from a single\ncamera. In self-supervised monocular depth estimation frameworks, the network\njointly generates and exploits depth and pose estimates during training,\nthereby eliminating the need for depth labels. However, these methods remain\nchallenged by uncertainty in the input data, such as low-texture or dynamic\nregions, which can cause reduced depth accuracy. To address this, we introduce\nUM-Depth, a framework that combines motion- and uncertainty-aware refinement to\nenhance depth accuracy at dynamic object boundaries and in textureless regions.\nSpecifically, we develop a teacherstudent training strategy that embeds\nuncertainty estimation into both the training pipeline and network\narchitecture, thereby strengthening supervision where photometric signals are\nweak. Unlike prior motion-aware approaches that incur inference-time overhead\nand rely on additional labels or auxiliary networks for real-time generation,\nour method uses optical flow exclusively within the teacher network during\ntraining, which eliminating extra labeling demands and any runtime cost.\nExtensive experiments on the KITTI and Cityscapes datasets demonstrate the\neffectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves\nstate-of-the-art results in both self-supervised depth and pose estimation on\nthe KITTI datasets.", "AI": {"tldr": "UM-Depth is a self-supervised framework for monocular depth estimation that improves depth accuracy by integrating motion- and uncertainty-aware refinement.", "motivation": "To enhance the accuracy of self-supervised monocular depth estimation, addressing challenges posed by low-texture and dynamic regions.", "method": "UM-Depth introduces a teacher-student training strategy that embeds uncertainty estimation in the training pipeline and architecture, utilizing optical flow within the teacher network exclusively during training.", "result": "Experiments on the KITTI and Cityscapes datasets show that UM-Depth achieves state-of-the-art performance in self-supervised depth and pose estimation.", "conclusion": "By effectively embedding uncertainty estimation and optimizing supervision methods, UM-Depth provides improved accuracy without adding inference-time overhead or labeling demands."}}
{"id": "2509.13833", "pdf": "https://arxiv.org/pdf/2509.13833", "abs": "https://arxiv.org/abs/2509.13833", "authors": ["Zhikai Zhang", "Jun Guo", "Chao Chen", "Jilong Wang", "Chenghuai Lin", "Yunrui Lian", "Han Xue", "Zhenrong Wang", "Maoqi Liu", "Huaping Liu", "He Wang", "Li Yi"], "title": "Track Any Motions under Any Disturbances", "categories": ["cs.RO"], "comment": null, "summary": "A foundational humanoid motion tracker is expected to be able to track\ndiverse, highly dynamic, and contact-rich motions. More importantly, it needs\nto operate stably in real-world scenarios against various dynamics\ndisturbances, including terrains, external forces, and physical property\nchanges for general practical use. To achieve this goal, we propose Any2Track\n(Track Any motions under Any disturbances), a two-stage RL framework to track\nvarious motions under multiple disturbances in the real world. Any2Track\nreformulates dynamics adaptability as an additional capability on top of basic\naction execution and consists of two key components: AnyTracker and AnyAdapter.\nAnyTracker is a general motion tracker with a series of careful designs to\ntrack various motions within a single policy. AnyAdapter is a history-informed\nadaptation module that endows the tracker with online dynamics adaptability to\novercome the sim2real gap and multiple real-world disturbances. We deploy\nAny2Track on Unitree G1 hardware and achieve a successful sim2real transfer in\na zero-shot manner. Any2Track performs exceptionally well in tracking various\nmotions under multiple real-world disturbances.", "AI": {"tldr": "This paper introduces Any2Track, a framework for humanoid motion tracking that functions in diverse real-world scenarios despite dynamic disturbances.", "motivation": "The authors aim to develop a motion tracker that can handle diverse dynamic, contact-rich motions and adapt effectively to real-world disturbances for practical applications.", "method": "Proposes Any2Track, a two-stage reinforcement learning framework consisting of AnyTracker for general motion tracking and AnyAdapter for history-informed online dynamics adaptability, enabling zero-shot sim2real transfer.", "result": "Any2Track is successfully deployed on Unitree G1 hardware, achieving exceptional performance in tracking various motions under multiple real-world disturbances.", "conclusion": "Any2Track offers a robust and practical solution for humanoid motion tracking in challenging dynamic environments, bridging the sim2real gap effectively."}}
{"id": "2509.13355", "pdf": "https://arxiv.org/pdf/2509.13355", "abs": "https://arxiv.org/abs/2509.13355", "authors": ["Dietmar Offenhuber"], "title": "Synthetic Data and the Shifting Ground of Truth", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Talk presented at the Society for the Social Studies of Science (4S)\n  2025 meeting in Seattle, Sept. 3, 2025", "summary": "The emergence of synthetic data for privacy protection, training data\ngeneration, or simply convenient access to quasi-realistic data in any shape or\nvolume complicates the concept of ground truth. Synthetic data mimic real-world\nobservations, but do not refer to external features. This lack of a\nrepresentational relationship, however, not prevent researchers from using\nsynthetic data as training data for AI models and ground truth repositories. It\nis claimed that the lack of data realism is not merely an acceptable tradeoff,\nbut often leads to better model performance than realistic data: compensate for\nknown biases, prevent overfitting and support generalization, and make the\nmodels more robust in dealing with unexpected outliers. Indeed, injecting noisy\nand outright implausible data into training sets can be beneficial for the\nmodel. This greatly complicates usual assumptions based on which\nrepresentational accuracy determines data fidelity (garbage in - garbage out).\nFurthermore, ground truth becomes a self-referential affair, in which the\nlabels used as a ground truth repository are themselves synthetic products of a\ngenerative model and as such not connected to real-world observations. My paper\nexamines how ML researchers and practitioners bootstrap ground truth under such\nparadoxical circumstances without relying on the stable ground of\nrepresentation and real-world reference. It will also reflect on the broader\nimplications of a shift from a representational to what could be described as a\nmimetic or iconic concept of data.", "AI": {"tldr": "The paper explores how synthetic data, which lacks relatable real-world references, is being used in AI as ground truth, despite challenges to conventional assumptions about data fidelity.", "motivation": "To investigate the paradoxical reliance on synthetic data, which lacks real-world representational ties, in creating ground truth and its impact on AI model training and performance.", "method": "Analyzing the practices and strategies employed by researchers and practitioners to utilize synthetic data as a substitute for traditional, representation-based ground truth in AI contexts.", "result": "The investigation finds that synthetic data, despite being unrealistic, can enhance model performance by addressing biases, preventing overfitting, and improving robustness to outliers.", "conclusion": "This shift challenges traditional data fidelity principles, redefines ground truth, and raises broader implications about data not needing direct real-world reference to achieve significant utility in AI systems."}}
{"id": "2509.14161", "pdf": "https://arxiv.org/pdf/2509.14161", "abs": "https://arxiv.org/abs/2509.14161", "authors": ["Brian Yan", "Injy Hamed", "Shuichiro Shimizu", "Vasista Lodagala", "William Chen", "Olga Iakovenko", "Bashar Talafha", "Amir Hussein", "Alexander Polok", "Kalvin Chang", "Dominik Klement", "Sara Althubaiti", "Puyuan Peng", "Matthew Wiesner", "Thamar Solorio", "Ahmed Ali", "Sanjeev Khudanpur", "Shinji Watanabe", "Chih-Chen Chen", "Zhen Wu", "Karim Benharrak", "Anuj Diwan", "Samuele Cornell", "Eunjung Yeo", "Kwanghee Choi", "Carlos Carvalho", "Karen Rosero"], "title": "CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "We present CS-FLEURS, a new dataset for developing and evaluating\ncode-switched speech recognition and translation systems beyond high-resourced\nlanguages. CS-FLEURS consists of 4 test sets which cover in total 113 unique\ncode-switched language pairs across 52 languages: 1) a 14 X-English language\npair set with real voices reading synthetically generated code-switched\nsentences, 2) a 16 X-English language pair set with generative text-to-speech\n3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the\ngenerative text-to-speech, and 4) a 45 X-English lower-resourced language pair\ntest set with concatenative text-to-speech. Besides the four test sets,\nCS-FLEURS also provides a training set with 128 hours of generative\ntext-to-speech data across 16 X-English language pairs. Our hope is that\nCS-FLEURS helps to broaden the scope of future code-switched speech research.\nDataset link: https://huggingface.co/datasets/byan/cs-fleurs.", "AI": {"tldr": "CS-FLEURS is a dataset designed for advancing research in code-switched speech recognition and translation, covering 113 language pairs across 52 languages.", "motivation": "The paper aims to address the lack of resources for evaluating code-switched speech systems, particularly for low-resource languages.", "method": "A diverse dataset was created with real voice recordings, generative text-to-speech, and concatenative text-to-speech across multiple language pairs and scenarios.", "result": "CS-FLEURS offers 4 test sets covering 113 code-switched language pairs, alongside a training dataset with 128 hours of generative text-to-speech data.", "conclusion": "The dataset is expected to foster research in code-switched speech and broaden the exploration of less-studied languages."}}
{"id": "2509.14000", "pdf": "https://arxiv.org/pdf/2509.14000", "abs": "https://arxiv.org/abs/2509.14000", "authors": ["Ivana Kesi\u0107", "Alja\u017e Blatnik", "Carolina Fortuna", "Bla\u017e Bertalani\u010d"], "title": "Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations", "categories": ["cs.LG"], "comment": "20 pages, 4 figures", "summary": "Global Navigation Satellite Systems (GNSS) are increasingly disrupted by\nintentional jamming, degrading availability precisely when positioning and\ntiming must remain operational. We address this by reframing jamming mitigation\nas dynamic graph regression and introducing a receiver-centric deep temporal\ngraph network that predicts, and thus corrects, the receivers horizontal\ndeviation in real time. At each 1 Hz epoch, the satellite receiver environment\nis represented as a heterogeneous star graph (receiver center, tracked\nsatellites as leaves) with time varying attributes (e.g., SNR, azimuth,\nelevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM\n(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a\nshort history to output the 2D deviation vector applied for on the fly\ncorrection.\n  We evaluate on datasets from two distinct receivers under three jammer\nprofiles, continuous wave (cw), triple tone (cw3), and wideband FM, each\nexercised at six power levels between -45 and -70 dBm, with 50 repetitions per\nscenario (prejam/jam/recovery). Against strong multivariate time series\nbaselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains\nthe lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm\n(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and\n4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode\ndatasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),\noutperforming Seq2Point, MLP, and CNN. A split study shows superior data\nefficiency: with only 10\\% training data our approach remains well ahead of\nbaselines (20 cm vs. 36-42 cm).", "AI": {"tldr": "The study introduces a novel receiver-centric deep temporal graph network to mitigate GNSS jamming through dynamic graph regression methods, achieving consistently low mean absolute error (MAE) against multiple baselines.", "motivation": "The paper aims to address the growing challenge of GNSS disruptions caused by intentional jamming, which hampers positioning and timing availability during critical scenarios.", "method": "The authors proposed a heterogeneous star graph representation with a Heterogeneous Graph ConvLSTM (HeteroGCLSTM) model to dynamically predict and correct horizontal positional deviations in satellite receivers.", "result": "The proposed model demonstrated superior performance with the lowest MAE across multiple jamming scenarios and power levels. It also outperformed several strong baseline methods, showing marked improvements in data efficiency.", "conclusion": "The results suggest that the proposed receiver-centric approach is effective for real-time GNSS jamming mitigation and offers superior accuracy and efficiency compared to traditional methods."}}
{"id": "2509.13722", "pdf": "https://arxiv.org/pdf/2509.13722", "abs": "https://arxiv.org/abs/2509.13722", "authors": ["Dingwei Zhang", "Dong Zhang", "Jinhui Tang"], "title": "Mitigating Query Selection Bias in Referring Video Object Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, query-based methods have achieved remarkable performance in\nReferring Video Object Segmentation (RVOS) by using textual static object\nqueries to drive cross-modal alignment. However, these static queries are\neasily misled by distractors with similar appearance or motion, resulting in\n\\emph{query selection bias}. To address this issue, we propose Triple Query\nFormer (TQF), which factorizes the referring query into three specialized\ncomponents: an appearance query for static attributes, an intra-frame\ninteraction query for spatial relations, and an inter-frame motion query for\ntemporal association. Instead of relying solely on textual embeddings, our\nqueries are dynamically constructed by integrating both linguistic cues and\nvisual guidance. Furthermore, we introduce two motion-aware aggregation modules\nthat enhance object token representations: Intra-frame Interaction Aggregation\nincorporates position-aware interactions among objects within a single frame,\nwhile Inter-frame Motion Aggregation leverages trajectory-guided alignment\nacross frames to ensure temporal coherence. Extensive experiments on multiple\nRVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our\nstructured query design and motion-aware aggregation modules.", "AI": {"tldr": "This paper introduces Triple Query Former (TQF), which improves Referring Video Object Segmentation (RVOS) by addressing query selection bias through dynamic query construction and motion-aware aggregation.", "motivation": "Query-based methods in RVOS face difficulties due to distractors with similar appearance or motion, resulting in query selection bias. This paper seeks to overcome these limitations.", "method": "The proposed TQF model factorizes queries into three components: appearance, intra-frame interaction, and inter-frame motion queries. It dynamically constructs queries by combining linguistic cues and visual guidance, and employs motion-aware aggregation modules for improved object token representation.", "result": "Experiments show that TQF outperforms existing methods on multiple RVOS benchmarks, validating the structured query design and motion-aware aggregation modules.", "conclusion": "TQF addresses query selection bias effectively by incorporating dynamic query construction and motion-aware aggregation, offering enhanced performance in RVOS tasks."}}
{"id": "2509.13839", "pdf": "https://arxiv.org/pdf/2509.13839", "abs": "https://arxiv.org/abs/2509.13839", "authors": ["Motonari Kambara", "Komei Sugiura"], "title": "Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models", "categories": ["cs.RO"], "comment": "Published in Advanced Robotics", "summary": "In this work, we address the problem of predicting the future success of\nopen-vocabulary object manipulation tasks. Conventional approaches typically\ndetermine success or failure after the action has been carried out. However,\nthey make it difficult to prevent potential hazards and rely on failures to\ntrigger replanning, thereby reducing the efficiency of object manipulation\nsequences. To overcome these challenges, we propose a model, which predicts the\nalignment between a pre-manipulation egocentric image with the planned\ntrajectory and a given natural language instruction. We introduce a Multi-Level\nTrajectory Fusion module, which employs a state-of-the-art deep state-space\nmodel and a transformer encoder in parallel to capture multi-level time-series\nself-correlation within the end effector trajectory. Our experimental results\nindicate that the proposed method outperformed existing methods, including\nfoundation models.", "AI": {"tldr": "This paper introduces a predictive model for object manipulation task success using an egocentric image and planned trajectory.", "motivation": "To improve object manipulation efficiency by predicting success beforehand and avoiding reliance on hazards or failures.", "method": "Proposes a Multi-Level Trajectory Fusion module combining a deep state-space model and a transformer encoder to predict alignment between input image, trajectory, and instruction.", "result": "The proposed method outperformed existing approaches and foundation models in experimental evaluation.", "conclusion": "The model offers a more efficient way to predict success and prevent hazards in open-vocabulary object manipulation tasks."}}
{"id": "2509.13359", "pdf": "https://arxiv.org/pdf/2509.13359", "abs": "https://arxiv.org/abs/2509.13359", "authors": ["Benjamin J. Walker", "Beatriz Navarro Lameda", "Ruth A. Reynolds"], "title": "Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are\ntransforming the educational landscape, prompting reconsideration of\ntraditional assessment practices. In parallel, universities are exploring\nalternatives to in-person, closed-book examinations, raising concerns about\nacademic integrity and pedagogical alignment in uninvigilated settings. This\nstudy investigates whether traditional closed-book mathematics examinations\nretain their pedagogical relevance when hypothetically administered in\nuninvigilated, open-book settings with GenAI access. Adopting an empirical\napproach, we generate, transcribe, and blind-mark GenAI submissions to eight\nundergraduate mathematics examinations at a Russel Group university, spanning\nthe entirety of the first-year curriculum. By combining independent GenAI\nresponses to individual questions, we enable a meaningful evaluation of GenAI\nperformance, both at the level of modules and across the first-year curriculum.\nWe find that GenAI attainment is at the level of a first-class degree, though\ncurrent performance can vary between modules. Further, we find that GenAI\nperformance is remarkably consistent when viewed across the entire curriculum,\nsignificantly more so than that of students in invigilated examinations. Our\nfindings evidence the need for redesigning assessments in mathematics for\nunsupervised settings, and highlight the potential reduction in pedagogical\nvalue of current standards in the era of generative artificial intelligence.", "AI": {"tldr": "The study evaluates the relevance of traditional closed-book mathematics exams in open-book, uninvigilated settings with GenAI access, finding that GenAI delivers first-class performance consistently, thereby questioning the existing assessment standards.", "motivation": "The motivation stems from the transformative impact of GenAI tools like ChatGPT on education, especially on traditional assessment practices in the context of evolving university examination settings.", "method": "An empirical approach involving the generation, transcription, and blind marking of GenAI-generated submissions for eight undergraduate math exams, covering a full first-year curriculum at a Russell Group university, was used. GenAI solutions were evaluated independently by question and also at modular and curriculum levels.", "result": "GenAI performed at a first-class degree level with remarkable consistency across the curriculum, outperforming the variability observed in student performance during invigilated exams.", "conclusion": "The study concludes the necessity of redesigning mathematics assessments to maintain pedagogical value, as current standards are less effective in the context of GenAI's capabilities in unsupervised testing scenarios."}}
{"id": "2509.14171", "pdf": "https://arxiv.org/pdf/2509.14171", "abs": "https://arxiv.org/abs/2509.14171", "authors": ["Yifan Liu", "Wenkuan Zhao", "Shanshan Zhong", "Jinghui Qin", "Mingfu Liang", "Zhongzhan Huang", "Wushao Wen"], "title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in multimodal large language models (MLLMs) have garnered\nsignificant attention, offering a promising pathway toward artificial general\nintelligence (AGI). Among the essential capabilities required for AGI,\ncreativity has emerged as a critical trait for MLLMs, with association serving\nas its foundation. Association reflects a model' s ability to think creatively,\nmaking it vital to evaluate and understand. While several frameworks have been\nproposed to assess associative ability, they often overlook the inherent\nambiguity in association tasks, which arises from the divergent nature of\nassociations and undermines the reliability of evaluations. To address this\nissue, we decompose ambiguity into two types-internal ambiguity and external\nambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative\nability while circumventing the ambiguity through a hybrid computational\nmethod. We then conduct extensive experiments on MLLMs, revealing a strong\npositive correlation between cognition and association. Additionally, we\nobserve that the presence of ambiguity in the evaluation process causes MLLMs'\nbehavior to become more random-like. Finally, we validate the effectiveness of\nour method in ensuring more accurate and reliable evaluations. See Project Page\nfor the data and codes.", "AI": {"tldr": "The paper introduces a benchmark named AssoCiAm to evaluate the association abilities of multimodal large language models (MLLMs) while addressing ambiguities in such evaluations.", "motivation": "There is a need to assess the creativity and associative abilities of MLLMs, as these are foundational for advancements toward artificial general intelligence (AGI). Existing methods fail to address inherent ambiguities in association tasks, leading to unreliable evaluations.", "method": "The authors categorize ambiguity into two types\u2014internal and external\u2014and propose AssoCiAm, a benchmark that uses a hybrid computational approach to evaluate associative ability while mitigating ambiguities.", "result": "Extensive experiments on MLLMs reveal a strong correlation between cognition and association, and that ambiguity in evaluation leads to more random-like behavior in MLLMs. The proposed method ensures more accurate and reliable evaluations.", "conclusion": "The study validates that AssoCiAm effectively addresses ambiguities in assessing the associative abilities of MLLMs, providing a more reliable framework for understanding creativity in these models."}}
{"id": "2509.14024", "pdf": "https://arxiv.org/pdf/2509.14024", "abs": "https://arxiv.org/abs/2509.14024", "authors": ["Raouf Kerkouche", "Henrik Zunker", "Mario Fritz", "Martin J. K\u00fchn"], "title": "Differentially private federated learning for localized control of infectious disease dynamics", "categories": ["cs.LG", "68T07, 68P27, 92-08, 92-10"], "comment": "18 pages, 6 figures", "summary": "In times of epidemics, swift reaction is necessary to mitigate epidemic\nspreading. For this reaction, localized approaches have several advantages,\nlimiting necessary resources and reducing the impact of interventions on a\nlarger scale. However, training a separate machine learning (ML) model on a\nlocal scale is often not feasible due to limited available data. Centralizing\nthe data is also challenging because of its high sensitivity and privacy\nconstraints. In this study, we consider a localized strategy based on the\nGerman counties and communities managed by the related local health authorities\n(LHA). For the preservation of privacy to not oppose the availability of\ndetailed situational data, we propose a privacy-preserving forecasting method\nthat can assist public health experts and decision makers. ML methods with\nfederated learning (FL) train a shared model without centralizing raw data.\nConsidering the counties, communities or LHAs as clients and finding a balance\nbetween utility and privacy, we study a FL framework with client-level\ndifferential privacy (DP). We train a shared multilayer perceptron on sliding\nwindows of recent case counts to forecast the number of cases, while clients\nexchange only norm-clipped updates and the server aggregated updates with DP\nnoise. We evaluate the approach on COVID-19 data on county-level during two\nphases. As expected, very strict privacy yields unstable, unusable forecasts.\nAt a moderately strong level, the DP model closely approaches the non-DP model:\n$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in\nNovember 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,\nclient-level DP-FL can deliver useful county-level predictions with strong\nprivacy guarantees, and viable privacy budgets depend on epidemic phase,\nallowing privacy-compliant collaboration among health authorities for local\nforecasting.", "AI": {"tldr": "The paper addresses the challenge of localized epidemic forecasting using machine learning by proposing a federated learning model with client-level differential privacy, tested on COVID-19 data.", "motivation": "To develop a localized and privacy-preserving epidemic forecasting method that avoids centralizing sensitive data while supporting local health authorities.", "method": "The paper proposes a federated learning framework where local health authorities train a shared multilayer perceptron for case count forecasting. Client-level differential privacy is applied with norm-clipped updates and DP noise on server-side aggregation.", "result": "The method is tested on COVID-19 data at the county level with good predictive capabilities under moderate privacy settings: achieving a high $R^2$ (0.94 and 0.88) and modest mean absolute percentage errors during two separate test phases.", "conclusion": "Federated learning with differential privacy can provide reliable and privacy-compliant epidemic forecasting, enabling effective collaboration between health authorities."}}
{"id": "2509.13747", "pdf": "https://arxiv.org/pdf/2509.13747", "abs": "https://arxiv.org/abs/2509.13747", "authors": ["Ming Dai", "Wenxuan Cheng", "Jiang-Jiang Liu", "Lingfeng Yang", "Zhenhua Feng", "Wankou Yang", "Jingdong Wang"], "title": "Improving Generalized Visual Grounding with Instance-aware Joint Learning", "categories": ["cs.CV"], "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI) in September 2025", "summary": "Generalized visual grounding tasks, including Generalized Referring\nExpression Comprehension (GREC) and Segmentation (GRES), extend the classical\nvisual grounding paradigm by accommodating multi-target and non-target\nscenarios. Specifically, GREC focuses on accurately identifying all referential\nobjects at the coarse bounding box level, while GRES aims for achieve\nfine-grained pixel-level perception. However, existing approaches typically\ntreat these tasks independently, overlooking the benefits of jointly training\nGREC and GRES to ensure consistent multi-granularity predictions and streamline\nthe overall process. Moreover, current methods often treat GRES as a semantic\nsegmentation task, neglecting the crucial role of instance-aware capabilities\nand the necessity of ensuring consistent predictions between instance-level\nboxes and masks. To address these limitations, we propose InstanceVG, a\nmulti-task generalized visual grounding framework equipped with instance-aware\ncapabilities, which leverages instance queries to unify the joint and\nconsistency predictions of instance-level boxes and masks. To the best of our\nknowledge, InstanceVG is the first framework to simultaneously tackle both GREC\nand GRES while incorporating instance-aware capabilities into generalized\nvisual grounding. To instantiate the framework, we assign each instance query a\nprior reference point, which also serves as an additional basis for target\nmatching. This design facilitates consistent predictions of points, boxes, and\nmasks for the same instance. Extensive experiments obtained on ten datasets\nacross four tasks demonstrate that InstanceVG achieves state-of-the-art\nperformance, significantly surpassing the existing methods in various\nevaluation metrics. The code and model will be publicly available at\nhttps://github.com/Dmmm1997/InstanceVG.", "AI": {"tldr": "The paper introduces InstanceVG, a multi-task framework tackling both Generalized Referring Expression Comprehension (GREC) and Segmentation (GRES) with instance-aware capabilities, delivering state-of-the-art results.", "motivation": "Existing approaches treat GREC and GRES tasks independently, neglecting joint training benefits and consistency across predictions. Additionally, GRES is often treated as semantic segmentation, ignoring the importance of instance-aware features.", "method": "InstanceVG employs instance queries tied to prior reference points, enabling unified and consistent predictions across instance boxes, masks, and points.", "result": "InstanceVG demonstrated superior performance across ten datasets spanning four tasks, outperforming contemporary methods on various metrics.", "conclusion": "InstanceVG establishes a novel unified framework for generalized visual grounding tasks, ensuring consistent multi-granularity predictions with instance-aware capabilities."}}
{"id": "2509.13857", "pdf": "https://arxiv.org/pdf/2509.13857", "abs": "https://arxiv.org/abs/2509.13857", "authors": ["Nguyen Hoang Khoi Tran", "Julie Stephany Berrio", "Mao Shan", "Stewart Worrall"], "title": "InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 5 figures", "summary": "Reliable global localization is critical for autonomous vehicles, especially\nin environments where GNSS is degraded or unavailable, such as urban canyons\nand tunnels. Although high-definition (HD) maps provide accurate priors, the\ncost of data collection, map construction, and maintenance limits scalability.\nOpenStreetMap (OSM) offers a free and globally available alternative, but its\ncoarse abstraction poses challenges for matching with sensor data. We propose\nInterKey, a cross-modal framework that leverages road intersections as\ndistinctive landmarks for global localization. Our method constructs compact\nbinary descriptors by jointly encoding road and building imprints from point\nclouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,\norientation determination, and area-equalized sampling strategies, enabling\nrobust cross-modal matching. Experiments on the KITTI dataset demonstrate that\nInterKey achieves state-of-the-art accuracy, outperforming recent baselines by\na large margin. The framework generalizes to sensors that can produce dense\nstructural point clouds, offering a scalable and cost-effective solution for\nrobust vehicle localization.", "AI": {"tldr": "This study introduces InterKey, a framework for vehicle localization using road intersections and OpenStreetMap (OSM) data instead of HD maps.", "motivation": "To address the limitations of GNSS in urban environments and the high costs associated with HD map usage, exploring OSM's potential for localization.", "method": "InterKey constructs binary descriptors using road and building imprints from point clouds and OSM, and applies strategies to mitigate cross-modal discrepancies for matching sensor data.", "result": "Experiments with KITTI dataset show InterKey outperforms recent baselines, achieving high accuracy in global localization.", "conclusion": "The method provides a scalable, cost-efficient localization solution and generalizes well to various sensors generating dense point clouds."}}
{"id": "2509.13365", "pdf": "https://arxiv.org/pdf/2509.13365", "abs": "https://arxiv.org/abs/2509.13365", "authors": ["Brian D. Earp", "Haotian Yuan", "Julian Koplin", "Sebastian Porsdam Mann"], "title": "The Provenance Problem: LLMs and the Breakdown of Citation Norms", "categories": ["cs.CY", "cs.AI"], "comment": "9 pages", "summary": "The increasing use of generative AI in scientific writing raises urgent\nquestions about attribution and intellectual credit. When a researcher employs\nChatGPT to draft a manuscript, the resulting text may echo ideas from sources\nthe author has never encountered. If an AI system reproduces insights from, for\nexample, an obscure 1975 paper without citation, does this constitute\nplagiarism? We argue that such cases exemplify the 'provenance problem': a\nsystematic breakdown in the chain of scholarly credit. Unlike conventional\nplagiarism, this phenomenon does not involve intent to deceive (researchers may\ndisclose AI use and act in good faith) yet still benefit from the uncredited\nintellectual contributions of others. This dynamic creates a novel category of\nattributional harm that current ethical and professional frameworks fail to\naddress. As generative AI becomes embedded across disciplines, the risk that\nsignificant ideas will circulate without recognition threatens both the\nreputational economy of science and the demands of epistemic justice. This\nPerspective analyzes how AI challenges established norms of authorship,\nintroduces conceptual tools for understanding the provenance problem, and\nproposes strategies to preserve integrity and fairness in scholarly\ncommunication.", "AI": {"tldr": "This paper highlights the challenges posed by generative AI in scientific writing, focusing on issues of intellectual credit and provocation without intent.", "motivation": "The paper addresses the rising ethical and attribution challenges posed by generative AI, specifically its impact on the recognition of intellectual contributions in academic works.", "method": "The authors analyze conceptual frameworks to address the 'provenance problem,' critique current ethical norms, and propose strategies for scholarly integrity in an AI-dominated context.", "result": "The paper identifies a novel category of attributional harm and outlines specific risks to scholarly credit and epistemic justice.", "conclusion": "It argues that current ethical frameworks are inadequate for preventing uncredited intellectual contributions, proposing strategic interventions to maintain fairness in scientific communication."}}
{"id": "2509.14180", "pdf": "https://arxiv.org/pdf/2509.14180", "abs": "https://arxiv.org/abs/2509.14180", "authors": ["Akhil Theerthala"], "title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; J.4"], "comment": "24 pages, 11 figures. The paper presents a novel framework for\n  generating a personal finance dataset. The resulting fine-tuned model and\n  dataset are publicly available", "summary": "Personalized financial advice requires consideration of user goals,\nconstraints, risk tolerance, and jurisdiction. Prior LLM work has focused on\nsupport systems for investors and financial planners. Simultaneously, numerous\nrecent studies examine broader personal finance tasks, including budgeting,\ndebt management, retirement, and estate planning, through agentic pipelines\nthat incur high maintenance costs, yielding less than 25% of their expected\nfinancial returns. In this study, we introduce a novel and reproducible\nframework that integrates relevant financial context with behavioral finance\nstudies to construct supervision data for end-to-end advisors. Using this\nframework, we create a 19k sample reasoning dataset and conduct a comprehensive\nfine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test\nsplit and a blind LLM-jury study, we demonstrate that through careful data\ncuration and behavioral integration, our 8B model achieves performance\ncomparable to significantly larger baselines (14-32B parameters) across factual\naccuracy, fluency, and personalization metrics while incurring 80% lower costs\nthan the larger counterparts.", "AI": {"tldr": "The paper proposes a cost-effective and high-performing financial advisory model by fine-tuning a smaller LLM on curated behavioral finance datasets.", "motivation": "Current systems for financial advice are either resource-intensive with low returns or inadequate in personalized support. The paper aims to address inefficiencies in balancing cost, performance, and personalization.", "method": "The authors developed a new framework integrating financial contexts and behavioral studies, creating a reasoning dataset. They fine-tuned the Qwen-3-8B model using this dataset and evaluated its performance.", "result": "The study showed that the fine-tuned 8B parameter model matches the performance of much larger models (14-32B parameters) in accuracy, fluency, and personalization, while reducing costs by 80%.", "conclusion": "End-to-end financial advisory models can achieve smaller sizes and lower costs without compromising their effectiveness when supported by curated behavioral finance datasets."}}
{"id": "2509.14029", "pdf": "https://arxiv.org/pdf/2509.14029", "abs": "https://arxiv.org/abs/2509.14029", "authors": ["Samuel Tovey", "Julian Ho\u00dfbach", "Sandro Kuppel", "Tobias Ensslen", "Jan C. Behrends", "Christian Holm"], "title": "Deep Learning-Driven Peptide Classification in Biological Nanopores", "categories": ["cs.LG", "eess.SP", "physics.comp-ph", "q-bio.BM"], "comment": "29 pages (incl. references) 7 figures", "summary": "A device capable of performing real time classification of proteins in a\nclinical setting would allow for inexpensive and rapid disease diagnosis. One\nsuch candidate for this technology are nanopore devices. These devices work by\nmeasuring a current signal that arises when a protein or peptide enters a\nnanometer-length-scale pore. Should this current be uniquely related to the\nstructure of the peptide and its interactions with the pore, the signals can be\nused to perform identification. While such a method would allow for real time\nidentification of peptides and proteins in a clinical setting, to date, the\ncomplexities of these signals limit their accuracy. In this work, we tackle the\nissue of classification by converting the current signals into scaleogram\nimages via wavelet transforms, capturing amplitude, frequency, and time\ninformation in a modality well-suited to machine learning algorithms. When\ntested on 42 peptides, our method achieved a classification accuracy of\n~$81\\,\\%$, setting a new state-of-the-art in the field and taking a step toward\npractical peptide/protein diagnostics at the point of care. In addition, we\ndemonstrate model transfer techniques that will be critical when deploying\nthese models into real hardware, paving the way to a new method for real-time\ndisease diagnosis.", "AI": {"tldr": "The paper introduces a nanopore-based method for protein classification using wavelet transforms to achieve 81% accuracy, advancing real-time disease diagnostics.", "motivation": "Developing a real-time, cost-effective protein/peptide classification tool for clinical diagnostics to improve disease diagnosis speed and accessibility.", "method": "The authors convert nanopore current signals into scaleogram images via wavelet transforms to encapsulate amplitude, frequency, and time data, which are then classified using machine learning algorithms.", "result": "On testing with 42 peptides, the method achieved a classification accuracy of approximately 81%, surpassing previous methodologies.", "conclusion": "The proposed approach advances the field by improving classification accuracy and addressing model deployment challenges, moving closer to practical real-time diagnostics for diseases."}}
{"id": "2509.13754", "pdf": "https://arxiv.org/pdf/2509.13754", "abs": "https://arxiv.org/abs/2509.13754", "authors": ["Hao Yin", "Xin Man", "Feiyu Chen", "Jie Shao", "Heng Tao Shen"], "title": "Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that\naims to retrieve the most relevant person images based on a given text query.\nThe key challenge in TIPR lies in achieving effective alignment between textual\nand visual modalities within a common latent space. To address this challenge,\nprior approaches incorporate attention mechanisms for implicit cross-modal\nlocal alignment. However, they lack the ability to verify whether all local\nfeatures are correctly aligned. Moreover, existing methods primarily focus on\nhard negative samples during model updates, with the goal of refining\ndistinctions between positive and negative pairs, often neglecting incorrectly\nmatched positive pairs. To alleviate these issues, we propose FMFA, a\ncross-modal Full-Mode Fine-grained Alignment framework, which enhances global\nmatching through explicit fine-grained alignment and existing implicit\nrelational reasoning -- hence the term ``full-mode\" -- without requiring\nadditional supervision. Specifically, we design an Adaptive Similarity\nDistribution Matching (A-SDM) module to rectify unmatched positive sample\npairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint\nembedding space, thereby achieving more precise global alignment. Additionally,\nwe introduce an Explicit Fine-grained Alignment (EFA) module, which makes up\nfor the lack of verification capability of implicit relational reasoning. EFA\nstrengthens explicit cross-modal fine-grained interactions by sparsifying the\nsimilarity matrix and employs a hard coding method for local alignment. Our\nproposed method is evaluated on three public datasets, achieving\nstate-of-the-art performance among all global matching methods. Our code is\navailable at https://github.com/yinhao1102/FMFA.", "AI": {"tldr": "The paper introduces FMFA, a novel framework for Text-to-Image Person Retrieval (TIPR), improving both global and fine-grained cross-modal alignment to achieve state-of-the-art results.", "motivation": "The motivation stems from limitations in prior TIPR approaches, such as insufficient verification of alignment correctness and neglect of unmatched positive pairs.", "method": "FMFA employs two modules: (1) Adaptive Similarity Distribution Matching (A-SDM) for rectifying unmatched positive pairs and improving global alignment, and (2) Explicit Fine-grained Alignment (EFA) for reinforcing cross-modal fine-grained verification.", "result": "FMFA demonstrated state-of-the-art performance on three public TIPR datasets.", "conclusion": "FMFA effectively resolves alignment issues in TIPR using innovative modules without requiring additional supervision, setting new benchmarks in the field."}}
{"id": "2509.13861", "pdf": "https://arxiv.org/pdf/2509.13861", "abs": "https://arxiv.org/abs/2509.13861", "authors": ["G\u00f6rkem K\u0131l\u0131n\u00e7 Soylu", "Neziha Akalin", "Maria Riveiro"], "title": "Using Petri Nets for Context-Adaptive Robot Explanations", "categories": ["cs.RO", "I.6.0; A.0"], "comment": "In proceedings of TRUST 2025 (arXiv:2509.11402), a workshop at IEEE\n  RO-MAN 2025: https://www.ro-man2025.org/", "summary": "In human-robot interaction, robots must communicate in a natural and\ntransparent manner to foster trust, which requires adapting their communication\nto the context. In this paper, we propose using Petri nets (PNs) to model\ncontextual information for adaptive robot explanations. PNs provide a formal,\ngraphical method for representing concurrent actions, causal dependencies, and\nsystem states, making them suitable for analyzing dynamic interactions between\nhumans and robots. We demonstrate this approach through a scenario involving a\nrobot that provides explanations based on contextual cues such as user\nattention and presence. Model analysis confirms key properties, including\ndeadlock-freeness, context-sensitive reachability, boundedness, and liveness,\nshowing the robustness and flexibility of PNs for designing and verifying\ncontext-adaptive explanations in human-robot interactions.", "AI": {"tldr": "The paper explores using Petri nets to model context for adaptive robot explanations in human-robot interactions, showcasing their robustness and flexibility.", "motivation": "Enhancing trust in human-robot interactions requires robots to adapt their communication naturally to contextual cues.", "method": "The paper uses Petri nets to represent contextual information for robots, enabling adaptive and verified communication strategies.", "result": "Demonstrated through a robot scenario, analyses confirm properties like deadlock-freeness and context-sensitive reachability, validating the use of Petri nets.", "conclusion": "Petri nets are effective for modeling and verifying adaptive explanations in robot-human interactions, highlighting their dynamic capabilities."}}
{"id": "2509.13372", "pdf": "https://arxiv.org/pdf/2509.13372", "abs": "https://arxiv.org/abs/2509.13372", "authors": ["Prahlad G Menon"], "title": "Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.ET", "q-bio.QM", "92C50, 68T07, 76D05, 65D18, 92C55", "I.4.6; I.4.8; J.3; I.2.10; I.4.9"], "comment": null, "summary": "Fontan palliation for univentricular congenital heart disease progresses to\nhemodynamic failure with complex flow patterns poorly characterized by\nconventional 2D imaging. Current assessment relies on fluoroscopic angiography,\nproviding limited 3D geometric information essential for computational fluid\ndynamics (CFD) analysis and surgical planning.\n  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash\n(2.5B parameters) for systematic, iterative processing of fluoroscopic\nangiograms through transformer-based neural architecture. The pipeline\nencompasses medical image preprocessing, vascular segmentation, contrast\nenhancement, artifact removal, and virtual hemodynamic flow visualization\nwithin 2D projections. Final views were processed through Tencent's\nHunyuan3D-2mini (384M parameters) for stereolithography file generation.\n  The pipeline successfully generated geometrically optimized 2D projections\nfrom single-view angiograms after 16 processing steps using a custom web\ninterface. Initial iterations contained hallucinated vascular features\nrequiring iterative refinement to achieve anatomically faithful\nrepresentations. Final projections demonstrated accurate preservation of\ncomplex Fontan geometry with enhanced contrast suitable for 3D conversion.\nAI-generated virtual flow visualization identified stagnation zones in central\nconnections and flow patterns in branch arteries. Complete processing required\nunder 15 minutes with second-level API response times.\n  This approach demonstrates clinical feasibility of generating CFD-suitable\ngeometries from routine angiographic data, enabling 3D generation and rapid\nvirtual flow visualization for cursory insights prior to full CFD simulation.\nWhile requiring refinement cycles for accuracy, this establishes foundation for\ndemocratizing advanced geometric and hemodynamic analysis using readily\navailable imaging data.", "AI": {"tldr": "The paper develops an AI pipeline to process angiograms into 3D-suitable geometries for computational fluid dynamics (CFD) and surgical planning in Fontan palliation cases, leveraging large transformer-based models to enhance imaging and provide hemodynamic insights.", "motivation": "Fontan palliation cases, dealing with univentricular congenital heart disease, often lack adequate imaging techniques to capture complex flow patterns and geometries needed for CFD and surgical planning. Conventional 2D imaging, like fluoroscopic angiography, falls short in providing this essential 3D information.", "method": "A multi-step AI pipeline using Google's Gemini 2.5 and Tencent's Hunyuan3D-2mini neural architectures was developed. This process involved image preprocessing, vascular segmentation, contrast enhancement, artifact removal, and flow visualization to generate stereolithography-compatible 3D files.", "result": "The AI pipeline successfully created anatomically accurate 2D projections refined over 16 iterative steps and transformed these into enhanced 3D geometries. The analysis identified key hemodynamic patterns, such as stagnation zones, in under 15 minutes of processing time.", "conclusion": "The study showcases the clinical potential of using AI to derive CFD-suitable 3D geometries and preliminary flow visualizations from routine 2D imaging data. This could democratize advanced hemodynamic planning, although iterative refinements remain necessary for accuracy."}}
{"id": "2509.14197", "pdf": "https://arxiv.org/pdf/2509.14197", "abs": "https://arxiv.org/abs/2509.14197", "authors": ["Vahid Ghafouri", "Robert McNeil", "Teodor Yankov", "Madeleine Sumption", "Luc Rocher", "Scott A. Hale", "Adam Mahdi"], "title": "Framing Migration: A Computational Analysis of UK Parliamentary Discourse", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "We present a large-scale computational analysis of migration-related\ndiscourse in UK parliamentary debates spanning over 75 years and compare it\nwith US congressional discourse. Using open-weight LLMs, we annotate each\nstatement with high-level stances toward migrants and track the net tone toward\nmigrants across time and political parties. For the UK, we extend this with a\nsemi-automated framework for extracting fine-grained narrative frames to\ncapture nuances of migration discourse. Our findings show that, while US\ndiscourse has grown increasingly polarised, UK parliamentary attitudes remain\nrelatively aligned across parties, with a persistent ideological gap between\nLabour and the Conservatives, reaching its most negative level in 2025. The\nanalysis of narrative frames in the UK parliamentary statements reveals a shift\ntoward securitised narratives such as border control and illegal immigration,\nwhile longer-term integration-oriented frames such as social integration have\ndeclined. Moreover, discussions of national law about immigration have been\nreplaced over time by international law and human rights, revealing nuances in\ndiscourse trends. Taken together broadly, our findings demonstrate how LLMs can\nsupport scalable, fine-grained discourse analysis in political and historical\ncontexts.", "AI": {"tldr": "The study uses large language models (LLMs) to analyze migration-related discourse in UK parliamentary debates over 75 years and compare it with US congressional discourse, uncovering nuanced trends in tone and narrative framing.", "motivation": "To understand long-term trends and differences in migration-related discourse in UK and US legislative bodies, and to showcase the capabilities of LLMs in complex political discourse analysis.", "method": "A computational framework using open-weight LLMs to annotate legislative statements with stances, track net tones over time, and extract narrative frames for nuanced discourse analysis.", "result": "US discourse has grown increasingly polarized, while UK parliamentary attitudes remain aligned but show an ideological gap between Labour and Conservatives. Discourse in the UK also shifted toward securitized narratives like border control, replacing integration and national law discussions with international law and human rights.", "conclusion": "LLMs can enable scalable and nuanced analysis of complex historical and political discourse, offering insights into trends such as polarization, securitization, and shifts in narrative framing across time."}}
{"id": "2509.14061", "pdf": "https://arxiv.org/pdf/2509.14061", "abs": "https://arxiv.org/abs/2509.14061", "authors": ["Chiara De Luca", "Elisa Donati"], "title": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Queen bee presence is essential for the health and stability of honeybee\ncolonies, yet current monitoring methods rely on manual inspections that are\nlabor-intensive, disruptive, and impractical for large-scale beekeeping. While\nrecent audio-based approaches have shown promise, they often require high power\nconsumption, complex preprocessing, and are susceptible to ambient noise. To\novercome these limitations, we propose a lightweight, multimodal system for\nqueen detection based on environmental sensor fusion-specifically, temperature,\nhumidity, and pressure differentials between the inside and outside of the\nhive. Our approach employs quantized decision tree inference on a commercial\nSTM32 microcontroller, enabling real-time, low-power edge computing without\ncompromising accuracy. We show that our system achieves over 99% queen\ndetection accuracy using only environmental inputs, with audio features\noffering no significant performance gain. This work presents a scalable and\nsustainable solution for non-invasive hive monitoring, paving the way for\nautonomous, precision beekeeping using off-the-shelf, energy-efficient\nhardware.", "AI": {"tldr": "This paper proposes a low-power, real-time queen bee detection system using environmental sensor data, achieving over 99% accuracy without audio features.", "motivation": "The authors aim to address the inefficiency and impracticality of manual queen bee monitoring methods and the limitations of audio-based approaches in large-scale beekeeping.", "method": "A lightweight multimodal system using temperature, humidity, and pressure sensors was developed. The team used quantized decision tree inference on a commercial STM32 microcontroller for real-time, low-power operation.", "result": "The system achieved over 99% queen detection accuracy using only environmental sensor data. Audio features were found to offer no significant improvement.", "conclusion": "This study provides a scalable, energy-efficient, and non-invasive solution for hive monitoring, enabling autonomous precision beekeeping."}}
{"id": "2509.13756", "pdf": "https://arxiv.org/pdf/2509.13756", "abs": "https://arxiv.org/abs/2509.13756", "authors": ["Yuqi Yang", "Dongliang Chang", "Yuanchen Fang", "Yi-Zhe SonG", "Zhanyu Ma", "Jun Guo"], "title": "Controllable-Continuous Color Editing in Diffusion Model via Color Mapping", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, text-driven image editing has made significant progress.\nHowever, due to the inherent ambiguity and discreteness of natural language,\ncolor editing still faces challenges such as insufficient precision and\ndifficulty in achieving continuous control. Although linearly interpolating the\nembedding vectors of different textual descriptions can guide the model to\ngenerate a sequence of images with varying colors, this approach lacks precise\ncontrol over the range of color changes in the output images. Moreover, the\nrelationship between the interpolation coefficient and the resulting image\ncolor is unknown and uncontrollable. To address these issues, we introduce a\ncolor mapping module that explicitly models the correspondence between the text\nembedding space and image RGB values. This module predicts the corresponding\nembedding vector based on a given RGB value, enabling precise color control of\nthe generated images while maintaining semantic consistency. Users can specify\na target RGB range to generate images with continuous color variations within\nthe desired range, thereby achieving finer-grained, continuous, and\ncontrollable color editing. Experimental results demonstrate that our method\nperforms well in terms of color continuity and controllability.", "AI": {"tldr": "The paper proposes a color mapping module for more precise and controllable text-driven image color editing, enabling finer-grained adjustments with semantic consistency.", "motivation": "Natural language's ambiguity and discreteness make text-driven image color editing challenging, with issues in precision and continuous control. Existing methods, like interpolating text embeddings, fail to offer fine-grained control over color changes.", "method": "The authors introduce a color mapping module that establishes a direct correspondence between the text embedding space and image RGB values. The module allows users to specify RGB ranges, enabling continuous and controlled color editing.", "result": "The method demonstrates strong performance in maintaining color continuity and controllability, overcoming limitations in previous approaches.", "conclusion": "The proposed approach enables precise and continuous text-driven image color edits, improving upon limitations of existing methods while maintaining semantic consistency."}}
{"id": "2509.13882", "pdf": "https://arxiv.org/pdf/2509.13882", "abs": "https://arxiv.org/abs/2509.13882", "authors": ["Junhwa Hong", "Beomjoon Lee", "Woojin Lee", "Changjoo Nam"], "title": "Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning", "categories": ["cs.RO", "cs.MA"], "comment": "7 pages", "summary": "We propose an efficient motion planning method designed to efficiently find\ncollision-free trajectories for multiple manipulators. While multi-manipulator\nsystems offer significant advantages, coordinating their motions is\ncomputationally challenging owing to the high dimensionality of their composite\nconfiguration space. Conflict-Based Search (CBS) addresses this by decoupling\nmotion planning, but suffers from subsequent conflicts incurred by resolving\nexisting conflicts, leading to an exponentially growing constraint tree of CBS.\nOur proposed method is based on repulsive trajectory modification within the\ntwo-level structure of CBS. Unlike conventional CBS variants, the low-level\nplanner applies a gradient descent approach using an Artificial Potential\nField. This field generates repulsive forces that guide the trajectory of the\nconflicting manipulator away from those of other robots. As a result,\nsubsequent conflicts are less likely to occur. Additionally, we develop a\nstrategy that, under a specific condition, directly attempts to find a\nconflict-free solution in a single step without growing the constraint tree.\nThrough extensive tests including physical robot experiments, we demonstrate\nthat our method consistently reduces the number of expanded nodes in the\nconstraint tree, achieves a higher success rate, and finds a solution faster\ncompared to Enhanced CBS and other state-of-the-art algorithms.", "AI": {"tldr": "The paper proposes an enhanced Conflict-Based Search (CBS) method using repulsive trajectory modification for efficient, collision-free motion planning in multi-manipulator systems.", "motivation": "Multi-manipulator systems have significant advantages but are computationally challenging to coordinate due to the high dimensionality of the configuration space and the shortcomings of existing methods like CBS.", "method": "The method integrates a gradient descent-based Artificial Potential Field in the low-level CBS to generate repulsive forces, guiding manipulators\u2019 trajectories to avoid conflicts. Additionally, a strategy attempts direct conflict-free solutions under specific conditions.", "result": "The method reduces expanded nodes in the constraint tree, increases success rates, and provides faster solutions compared to Enhanced CBS and other state-of-the-art algorithms.", "conclusion": "The proposed approach successfully addresses multi-manipulator motion planning challenges by improving CBS with gradient descent modifications, leading to efficiency and higher performance in finding collision-free trajectories."}}
{"id": "2509.14233", "pdf": "https://arxiv.org/pdf/2509.14233", "abs": "https://arxiv.org/abs/2509.14233", "authors": ["Alejandro Hern\u00e1ndez-Cano", "Alexander H\u00e4gele", "Allen Hao Huang", "Angelika Romanou", "Antoni-Joan Solergibert", "Barna Pasztor", "Bettina Messmer", "Dhia Garbaya", "Eduard Frank \u010eurech", "Ido Hakimi", "Juan Garc\u00eda Giraldo", "Mete Ismayilzada", "Negar Foroutan", "Skander Moalla", "Tiancheng Chen", "Vinko Sabol\u010dec", "Yixuan Xu", "Michael Aerni", "Badr AlKhamissi", "Ines Altemir Marinas", "Mohammad Hossein Amani", "Matin Ansaripour", "Ilia Badanin", "Harold Benoit", "Emanuela Boros", "Nicholas Browning", "Fabian B\u00f6sch", "Maximilian B\u00f6ther", "Niklas Canova", "Camille Challier", "Clement Charmillot", "Jonathan Coles", "Jan Deriu", "Arnout Devos", "Lukas Drescher", "Daniil Dzenhaliou", "Maud Ehrmann", "Dongyang Fan", "Simin Fan", "Silin Gao", "Miguel Gila", "Mar\u00eda Grandury", "Diba Hashemi", "Alexander Hoyle", "Jiaming Jiang", "Mark Klein", "Andrei Kucharavy", "Anastasiia Kucherenko", "Frederike L\u00fcbeck", "Roman Machacek", "Theofilos Manitaras", "Andreas Marfurt", "Kyle Matoba", "Simon Matrenok", "Henrique Mendonc\u00e7a", "Fawzi Roberto Mohamed", "Syrielle Montariol", "Luca Mouchel", "Sven Najem-Meyer", "Jingwei Ni", "Gennaro Oliva", "Matteo Pagliardini", "Elia Palme", "Andrei Panferov", "L\u00e9o Paoletti", "Marco Passerini", "Ivan Pavlov", "Auguste Poiroux", "Kaustubh Ponkshe", "Nathan Ranchin", "Javi Rando", "Mathieu Sauser", "Jakhongir Saydaliev", "Muhammad Ali Sayfiddinov", "Marian Schneider", "Stefano Schuppli", "Marco Scialanga", "Andrei Semenov", "Kumar Shridhar", "Raghav Singhal", "Anna Sotnikova", "Alexander Sternfeld", "Ayush Kumar Tarun", "Paul Teiletche", "Jannis Vamvas", "Xiaozhe Yao", "Hao Zhao Alexander Ilic", "Ana Klimovic", "Andreas Krause", "Caglar Gulcehre", "David Rosenthal", "Elliott Ash", "Florian Tram\u00e8r", "Joost VandeVondele", "Livio Veraldi", "Martin Rajman", "Thomas Schulthess", "Torsten Hoefler", "Antoine Bosselut", "Martin Jaggi", "Imanol Schlag"], "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present Apertus, a fully open suite of large language models (LLMs)\ndesigned to address two systemic shortcomings in today's open model ecosystem:\ndata compliance and multilingual representation. Unlike many prior models that\nrelease weights without reproducible data pipelines or regard for content-owner\nrights, Apertus models are pretrained exclusively on openly available data,\nretroactively respecting robots.txt exclusions and filtering for\nnon-permissive, toxic, and personally identifiable content. To mitigate risks\nof memorization, we adopt the Goldfish objective during pretraining, strongly\nsuppressing verbatim recall of data while retaining downstream task\nperformance. The Apertus models also expand multilingual coverage, training on\n15T tokens from over 1800 languages, with ~40% of pretraining data allocated to\nnon-English content. Released at 8B and 70B scales, Apertus approaches\nstate-of-the-art results among fully open models on multilingual benchmarks,\nrivalling or surpassing open-weight counterparts. Beyond model weights, we\nrelease all scientific artifacts from our development cycle with a permissive\nlicense, including data preparation scripts, checkpoints, evaluation suites,\nand training code, enabling transparent audit and extension.", "AI": {"tldr": "This paper introduces Apertus, a suite of open large language models (LLMs) emphasizing data compliance and multilingual capabilities. The models are trained on openly available data, prioritizing ethical considerations and multilingual inclusivity.", "motivation": "Address limitations of open language models in ensuring data compliance and fair multilingual representation.", "method": "Pretraining on openly accessible 15T tokens from 1800+ languages, adopting the Goldfish objective to reduce data memorization, and focusing on non-English data (40%).", "result": "Achieved near state-of-the-art performance on multilingual benchmarks with models at 8B and 70B scales.", "conclusion": "Apertus provides transparent, reproducible, and ethical LLM development, supporting broad community collaboration through fully open scientific artifacts."}}
{"id": "2509.14077", "pdf": "https://arxiv.org/pdf/2509.14077", "abs": "https://arxiv.org/abs/2509.14077", "authors": ["Yuhao Wang", "Enlu Zhou"], "title": "Online Bayesian Risk-Averse Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we study the Bayesian risk-averse formulation in reinforcement\nlearning (RL). To address the epistemic uncertainty due to a lack of data, we\nadopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the\nparameter uncertainty of the unknown underlying model. We derive the asymptotic\nnormality that characterizes the difference between the Bayesian risk value\nfunction and the original value function under the true unknown distribution.\nThe results indicate that the Bayesian risk-averse approach tends to\npessimistically underestimate the original value function. This discrepancy\nincreases with stronger risk aversion and decreases as more data become\navailable. We then utilize this adaptive property in the setting of online RL\nas well as online contextual multi-arm bandits (CMAB), a special case of online\nRL. We provide two procedures using posterior sampling for both the general RL\nproblem and the CMAB problem. We establish a sub-linear regret bound, with the\nregret defined as the conventional regret for both the RL and CMAB settings.\nAdditionally, we establish a sub-linear regret bound for the CMAB setting with\nthe regret defined as the Bayesian risk regret. Finally, we conduct numerical\nexperiments to demonstrate the effectiveness of the proposed algorithm in\naddressing epistemic uncertainty and verifying the theoretical properties.", "AI": {"tldr": "This paper proposes Bayesian risk-averse methods in reinforcement learning (RL) and contextual multi-arm bandits (CMAB) to manage epistemic uncertainty and demonstrates their theoretical and experimental effectiveness.", "motivation": "The paper is motivated by the need to address epistemic uncertainty in RL due to a lack of data, using a Bayesian approach to account for model parameter uncertainty.", "method": "The authors employ Bayesian Risk Markov Decision Process (BRMDP), derive the asymptotic normality of Bayesian risk and true value functions, and propose posterior sampling procedures for online RL and CMAB. They analyze their regret bounds to evaluate performance.", "result": "Theoretical results show that Bayesian risk understatement decreases with increasing data and indicate sub-linear regret bounds for both RL and CMAB, including Bayesian risk regret for CMAB. Numerical experiments further show the practical effectiveness of the methods.", "conclusion": "Bayesian risk-averse formulation effectively manages epistemic uncertainty in RL and CMAB, with adaptive properties and sub-linear regret bounds that are supported by numerical evidence."}}
{"id": "2509.13760", "pdf": "https://arxiv.org/pdf/2509.13760", "abs": "https://arxiv.org/abs/2509.13760", "authors": ["Jinwoo Jeon", "JunHyeok Oh", "Hayeong Lee", "Byung-Jun Lee"], "title": "Iterative Prompt Refinement for Safer Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-Image (T2I) models have made remarkable progress in generating images\nfrom text prompts, but their output quality and safety still depend heavily on\nhow prompts are phrased. Existing safety methods typically refine prompts using\nlarge language models (LLMs), but they overlook the images produced, which can\nresult in unsafe outputs or unnecessary changes to already safe prompts. To\naddress this, we propose an iterative prompt refinement algorithm that uses\nVision Language Models (VLMs) to analyze both the input prompts and the\ngenerated images. By leveraging visual feedback, our method refines prompts\nmore effectively, improving safety while maintaining user intent and\nreliability comparable to existing LLM-based approaches. Additionally, we\nintroduce a new dataset labeled with both textual and visual safety signals\nusing off-the-shelf multi-modal LLM, enabling supervised fine-tuning.\nExperimental results demonstrate that our approach produces safer outputs\nwithout compromising alignment with user intent, offering a practical solution\nfor generating safer T2I content. Our code is available at\nhttps://github.com/ku-dmlab/IPR. \\textbf{\\textcolor{red}WARNING: This paper\ncontains examples of harmful or inappropriate images generated by models.", "AI": {"tldr": "The paper proposes an algorithm that refines prompts for Text-to-Image models using Vision Language Models (VLMs), which analyze both prompts and generated images to improve safety and maintain user intent.", "motivation": "Despite progress in Text-to-Image models, their reliance on prompt phrasing results in inconsistent safety and quality. Existing methods focus solely on refining prompts through language models without considering generated images.", "method": "The paper introduces an iterative prompt refinement algorithm utilizing VLMs for visual feedback and develops a dataset labeled with textual and visual safety signals to facilitate supervised fine-tuning.", "result": "The approach enhances safety in outputs while retaining alignment with user intent, achieving reliability comparable to existing methods and producing practical improvements in Text-to-Image content generation.", "conclusion": "Integrating VLM-based visual feedback into prompt refinement offers a robust and practical solution for safer Text-to-Image model outputs without sacrificing user intent alignment."}}
{"id": "2509.13903", "pdf": "https://arxiv.org/pdf/2509.13903", "abs": "https://arxiv.org/abs/2509.13903", "authors": ["Artem Lykov", "Jeffrin Sam", "Hung Khang Nguyen", "Vladislav Kozlovskiy", "Yara Mahmoud", "Valerii Serpiva", "Miguel Altamirano Cabrera", "Mikhail Konenkov", "Dzmitry Tsetserukou"], "title": "PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models", "categories": ["cs.RO"], "comment": "submitted to IEEE conference", "summary": "We introduce PhysicalAgent, an agentic framework for robotic manipulation\nthat integrates iterative reasoning, diffusion-based video generation, and\nclosed-loop execution. Given a textual instruction, our method generates short\nvideo demonstrations of candidate trajectories, executes them on the robot, and\niteratively re-plans in response to failures. This approach enables robust\nrecovery from execution errors. We evaluate PhysicalAgent across multiple\nperceptual modalities (egocentric, third-person, and simulated) and robotic\nembodiments (bimanual UR3, Unitree G1 humanoid, simulated GR1), comparing\nagainst state-of-the-art task-specific baselines. Experiments demonstrate that\nour method consistently outperforms prior approaches, achieving up to 83%\nsuccess on human-familiar tasks. Physical trials reveal that first-attempt\nsuccess is limited (20-30%), yet iterative correction increases overall success\nto 80% across platforms. These results highlight the potential of video-based\ngenerative reasoning for general-purpose robotic manipulation and underscore\nthe importance of iterative execution for recovering from initial failures. Our\nframework paves the way for scalable, adaptable, and robust robot control.", "AI": {"tldr": "PhysicalAgent integrates text-based instructions, diffusion-driven video generation, and iterative execution for robust robotic manipulation. First-attempt success rates are low, but iterative corrections boost overall effectiveness up to 80%.", "motivation": "The paper aims to improve robotic manipulation by integrating generative reasoning and execution corrections to handle complex tasks and recover from errors.", "method": "PhysicalAgent uses iterative reasoning, diffusion-based video generation to envision trajectories, followed by closed-loop execution that adapts based on performance failures.", "result": "Experiments show PhysicalAgent achieves higher success rates compared to state-of-the-art methods, reaching up to 80% effectiveness after iterative corrections.", "conclusion": "PhysicalAgent demonstrates the utility of video-based generative models and iterative corrections, paving the way for scalable and robust robotic control systems."}}
{"id": "2509.12577", "pdf": "https://arxiv.org/pdf/2509.12577", "abs": "https://arxiv.org/abs/2509.12577", "authors": ["Elinor Poole-Dayan", "Deb Roy", "Jad Kabbara"], "title": "An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies", "categories": ["cs.CY", "cs.CL"], "comment": null, "summary": "In an era of increasing societal fragmentation, political polarization, and\nerosion of public trust in institutions, representative deliberative assemblies\nare emerging as a promising democratic forum for developing effective policy\noutcomes on complex global issues. Despite theoretical attention, there remains\nlimited empirical work that systematically traces how specific ideas evolve,\nare prioritized, or are discarded during deliberation to form policy\nrecommendations. Addressing these gaps, this work poses two central questions:\n(1) How might we trace the evolution and distillation of ideas into concrete\nrecommendations within deliberative assemblies? (2) How does the deliberative\nprocess shape delegate perspectives and influence voting dynamics over the\ncourse of the assembly? To address these questions, we develop LLM-based\nmethodologies for empirically analyzing transcripts from a tech-enhanced\nin-person deliberative assembly. The framework identifies and visualizes the\nspace of expressed suggestions. We also empirically reconstruct each delegate's\nevolving perspective throughout the assembly. Our methods contribute novel\nempirical insights into deliberative processes and demonstrate how LLMs can\nsurface high-resolution dynamics otherwise invisible in traditional assembly\noutputs.", "AI": {"tldr": "The paper explores how large language models (LLMs) can be used to analyze and track the progression of ideas and delegate perspectives in deliberative assemblies to better understand their role in policymaking.", "motivation": "The study is motivated by the need to address societal issues like political polarization, fragmentation, and erosion of trust in institutions, and the lack of empirical evidence on how ideas evolve and are shaped in deliberative assemblies.", "method": "The authors developed LLM-based methodologies to analyze transcripts from a tech-enhanced in-person deliberative assembly, focusing on identifying, visualizing expressed suggestions, and reconstructing delegates' evolving perspectives.", "result": "The proposed framework offers empirical insights into the evolution and prioritization of policy ideas and the dynamics of delegate perspectives during deliberative processes.", "conclusion": "LLMs provide a valuable tool for high-resolution analysis of deliberative processes, enabling a deeper understanding of idea evolution and delegate perspectives within assemblies and contributing to policymaking advancements."}}
{"id": "2509.14078", "pdf": "https://arxiv.org/pdf/2509.14078", "abs": "https://arxiv.org/abs/2509.14078", "authors": ["Robiul Islam", "Dmitry I. Ignatov", "Karl Kaberg", "Roman Nabatchikov"], "title": "Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques", "categories": ["cs.LG"], "comment": null, "summary": "This study investigates classifier performance across EEG frequency bands\nusing various optimizers and evaluates efficient class prediction for the left\nand right hemispheres. Three neural network architectures - a deep dense\nnetwork, a shallow three-layer network, and a convolutional neural network\n(CNN) - are implemented and compared using the TensorFlow and PyTorch\nframeworks. Results indicate that the Adagrad and RMSprop optimizers\nconsistently perform well across different frequency bands, with Adadelta\nexhibiting robust performance in cross-model evaluations. Specifically, Adagrad\nexcels in the beta band, while RMSprop achieves superior performance in the\ngamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among\nthe models, the CNN demonstrates the second highest accuracy, particularly in\ncapturing spatial features of EEG data. The deep dense network shows\ncompetitive performance in learning complex patterns, whereas the shallow\nthree-layer network, sometimes being less accurate, provides computational\nefficiency. SHAP (Shapley Additive Explanations) plots are employed to identify\nefficient class prediction, revealing nuanced contributions of EEG frequency\nbands to model accuracy. Overall, the study highlights the importance of\noptimizer selection, model architecture, and EEG frequency band analysis in\nenhancing classifier performance and understanding feature importance in\nneuroimaging-based classification tasks.", "AI": {"tldr": "This paper analyzes EEG classification performance across frequency bands, optimizers, and neural network architectures, emphasizing the importance of optimizer selection and model design for neuroimaging tasks.", "motivation": "To enhance understanding of how different EEG frequency bands, optimizers, and neural network architectures contribute to accurate and efficient classification in neuroimaging tasks.", "method": "Three neural network architectures (deep dense network, shallow three-layer network, and CNN) were implemented using TensorFlow and PyTorch, with varied optimizers (Adagrad, RMSprop, Adadelta, SGD, FTRL). SHAP was utilized to evaluate feature importance of EEG frequency bands.", "result": "Adagrad and RMSprop delivered superior performance across bands, with Adagrad excelling in beta and RMSprop in gamma. CNN showed strong spatial feature performance; deep dense network was competitive in complex patterns; the shallow network offered computational efficiency.", "conclusion": "The study underscores the significance of matching optimizers, architectures, and frequency bands to optimize classification performance and feature insights in neuroimaging."}}
{"id": "2509.13762", "pdf": "https://arxiv.org/pdf/2509.13762", "abs": "https://arxiv.org/abs/2509.13762", "authors": ["Kai Chen", "Jin Xiao", "Leheng Zhang", "Kexuan Shi", "Shuhang Gu"], "title": "Task-Aware Image Signal Processor for Advanced Visual Perception", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, there has been a growing trend in computer vision towards\nexploiting RAW sensor data, which preserves richer information compared to\nconventional low-bit RGB images. Early studies mainly focused on enhancing\nvisual quality, while more recent efforts aim to leverage the abundant\ninformation in RAW data to improve the performance of visual perception tasks\nsuch as object detection and segmentation. However, existing approaches still\nface two key limitations: large-scale ISP networks impose heavy computational\noverhead, while methods based on tuning traditional ISP pipelines are\nrestricted by limited representational capacity.To address these issues, we\npropose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB\nframework that produces task-oriented representations for pretrained vision\nmodels. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small\nset of lightweight, multi-scale modulation operators that act at global,\nregional, and pixel scales to reshape image statistics across different spatial\nextents. This factorized control significantly expands the range of spatially\nvarying transforms that can be represented while keeping memory usage,\ncomputation, and latency tightly constrained. Evaluated on several RAW-domain\ndetection and segmentation benchmarks under both daytime and nighttime\nconditions, TA-ISP consistently improves downstream accuracy while markedly\nreducing parameter count and inference time, making it well suited for\ndeployment on resource-constrained devices.", "AI": {"tldr": "This paper proposes TA-ISP, a compact framework for transforming RAW sensor data into task-oriented representations, improving accuracy in visual perception tasks with reduced computational overhead.", "motivation": "Current methods using RAW sensor data either suffer from high computational overhead or limited representational capacity, hindering performance in visual perception tasks.", "method": "TA-ISP introduces a lightweight framework that predicts multi-scale modulation operators for reshaping image statistics spatially across different scales, reducing computation and memory use.", "result": "TA-ISP achieves consistent accuracy improvements in RAW-domain visual perception tasks (detection and segmentation) under varied conditions, while lowering parameter count and inference time.", "conclusion": "The proposed TA-ISP framework is an efficient and effective method for enhancing performance in vision tasks using RAW sensor data, especially on resource-limited devices."}}
{"id": "2509.13926", "pdf": "https://arxiv.org/pdf/2509.13926", "abs": "https://arxiv.org/abs/2509.13926", "authors": ["Huilin Yin", "Yiming Kan", "Daniel Watzenig"], "title": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning", "categories": ["cs.RO", "cs.AI", "cs.CV", "I.2.9; I.2.10"], "comment": "8 pages, 2 figures, accepted by ICCVW Author list updated to match\n  the camera-ready version, in compliance with conference policy", "summary": "In recent years, end-to-end autonomous driving has attracted increasing\nattention for its ability to jointly model perception, prediction, and planning\nwithin a unified framework. However, most existing approaches underutilize the\nonline mapping module, leaving its potential to enhance trajectory planning\nlargely untapped. This paper proposes MAP (Map-Assisted Planning), a novel\nmap-assisted end-to-end trajectory planning framework. MAP explicitly\nintegrates segmentation-based map features and the current ego status through a\nPlan-enhancing Online Mapping module, an Ego-status-guided Planning module, and\na Weight Adapter based on current ego status. Experiments conducted on the\nDAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%\nreduction in L2 displacement error, a 56.2% reduction in off-road rate, and a\n44.5% improvement in overall score compared to the UniV2X baseline, even\nwithout post-processing. Furthermore, it achieves top ranking in Track 2 of the\nEnd-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS\nWorkshop @CVPR2025, outperforming the second-best model by 39.5% in terms of\noverall score. These results highlight the effectiveness of explicitly\nleveraging semantic map features in planning and suggest new directions for\nimproving structure design in end-to-end autonomous driving systems. Our code\nis available at https://gitee.com/kymkym/map.git", "AI": {"tldr": "The paper introduces MAP, a novel end-to-end autonomous driving framework using map-assisted trajectory planning, which achieves significant performance improvements on metrics and challenges.", "motivation": "To address the underutilization of online mapping modules in enhancing trajectory planning in end-to-end autonomous driving systems.", "method": "The MAP framework integrates segmentation-based map features and ego status using dedicated modules like Plan-enhancing Online Mapping, Ego-status-guided Planning, and Weight Adapter.", "result": "MAP reduces L2 displacement error by 16.6%, off-road rate by 56.2%, and improves the overall score by 44.5% compared to a baseline. It ranks first in the V2X Cooperation Challenge, outperforming the second-best model by 39.5%.", "conclusion": "Explicitly leveraging semantic map features can significantly enhance trajectory planning, and the presented MAP framework pushes the boundaries of end-to-end autonomous driving systems."}}
{"id": "2509.13387", "pdf": "https://arxiv.org/pdf/2509.13387", "abs": "https://arxiv.org/abs/2509.13387", "authors": ["Delaram Golpayegani", "Marta Lasek-Markey", "Arjumand Younus", "Aphra Kerr", "Dave Lewis"], "title": "Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The upsurge of policies and guidelines that aim to ensure Artificial\nIntelligence (AI) systems are safe and trustworthy has led to a fragmented\nlandscape of AI governance. The European Union (EU) is a key actor in the\ndevelopment of such policies and guidelines. Its High-Level Expert Group (HLEG)\nissued an influential set of guidelines for trustworthy AI, followed in 2024 by\nthe adoption of the EU AI Act. While the EU policies and guidelines are\nexpected to be aligned, they may differ in their scope, areas of emphasis,\ndegrees of normativity, and priorities in relation to AI. To gain a broad\nunderstanding of AI governance from the EU perspective, we leverage qualitative\nthematic analysis approaches to uncover prevalent themes in key EU documents,\nincluding the AI Act and the HLEG Ethics Guidelines. We further employ\nquantitative topic modelling approaches, specifically through the use of the\nBERTopic model, to enhance the results and increase the document sample to\ninclude EU AI policy documents published post-2018. We present a novel\nperspective on EU policies, tracking the evolution of its approach to\naddressing AI governance.", "AI": {"tldr": "The paper analyzes EU's fragmented AI governance, focusing on key documents like the AI Act and HLEG Guidelines using qualitative and quantitative approaches.", "motivation": "The authors aim to clarify the fragmented landscape of AI governance within the EU and provide insights into how its policies and guidelines have evolved.", "method": "The study combines qualitative thematic analysis and quantitative topic modeling with BERTopic on EU AI-related documents from post-2018.", "result": "The research uncovers prevalent themes in AI governance and tracks the evolution of EU's policy priorities.", "conclusion": "The paper offers a nuanced understanding of AI governance in the EU, highlighting a shift in scope, emphasis, and normativity across its policies and guidelines."}}
{"id": "2509.14113", "pdf": "https://arxiv.org/pdf/2509.14113", "abs": "https://arxiv.org/abs/2509.14113", "authors": ["Alessandro Brusaferri", "Danial Ramin", "Andrea Ballarino"], "title": "From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting", "categories": ["cs.LG"], "comment": "6 pages", "summary": "While neural networks are achieving high predictive accuracy in multi-horizon\nprobabilistic forecasting, understanding the underlying mechanisms that lead to\nfeature-conditioned outputs remains a significant challenge for forecasters. In\nthis work, we take a further step toward addressing this critical issue by\nintroducing the Quantile Neural Basis Model, which incorporates the\ninterpretability principles of Quantile Generalized Additive Models into an\nend-to-end neural network training framework. To this end, we leverage shared\nbasis decomposition and weight factorization, complementing Neural Models for\nLocation, Scale, and Shape by avoiding any parametric distributional\nassumptions. We validate our approach on day-ahead electricity price\nforecasting, achieving predictive performance comparable to distributional and\nquantile regression neural networks, while offering valuable insights into\nmodel behavior through the learned nonlinear mappings from input features to\noutput predictions across the horizon.", "AI": {"tldr": "This paper introduces the Quantile Neural Basis Model to improve interpretability in neural networks used for probabilistic forecasting.", "motivation": "Understanding the mechanisms leading to feature-conditioned outputs in neural forecasting models is challenging, and this work seeks to address this gap.", "method": "The paper proposes the Quantile Neural Basis Model, which blends Quantile Generalized Additive Models' interpretability principles with neural networks. It uses shared basis decomposition and weight factorization while avoiding parametric distributional assumptions.", "result": "The approach was tested on day-ahead electricity price forecasting, showing predictive accuracy comparable to other neural networks while providing interpretability insights into the input-output mappings across time horizons.", "conclusion": "The model achieves a balance between predictive performance and interpretability, paving the way for more explainable forecasting models."}}
{"id": "2509.13766", "pdf": "https://arxiv.org/pdf/2509.13766", "abs": "https://arxiv.org/abs/2509.13766", "authors": ["Huichun Liu", "Xiaosong Li", "Yang Liu", "Xiaoqi Cheng", "Haishu Tan"], "title": "NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Visual degradation caused by rain streak artifacts in low-light conditions\nsignificantly hampers the performance of nighttime surveillance and autonomous\nnavigation. Existing image deraining techniques are primarily designed for\ndaytime conditions and perform poorly under nighttime illumination due to the\nspatial heterogeneity of rain distribution and the impact of light-dependent\nstripe visibility. In this paper, we propose a novel Nighttime Deraining\nLocation-enhanced Perceptual Network(NDLPNet) that effectively captures the\nspatial positional information and density distribution of rain streaks in\nlow-light environments. Specifically, we introduce a Position Perception Module\n(PPM) to capture and leverage spatial contextual information from input data,\nenhancing the model's capability to identify and recalibrate the importance of\ndifferent feature channels. The proposed nighttime deraining network can\neffectively remove the rain streaks as well as preserve the crucial background\ninformation. Furthermore, We construct a night scene rainy (NSR) dataset\ncomprising 900 image pairs, all based on real-world nighttime scenes, providing\na new benchmark for nighttime deraining task research. Extensive qualitative\nand quantitative experimental evaluations on both existing datasets and the NSR\ndataset consistently demonstrate our method outperform the state-of-the-art\n(SOTA) methods in nighttime deraining tasks. The source code and dataset is\navailable at https://github.com/Feecuin/NDLPNet.", "AI": {"tldr": "This paper proposes a novel nighttime deraining method and dataset to improve image quality under low-light rainy conditions, enhancing surveillance and navigation performance.", "motivation": "The paper addresses the poor performance of existing image deraining techniques under nighttime and low-light conditions, which is a critical issue for surveillance and autonomous systems.", "method": "The authors develop NDLPNet, a Nighttime Deraining Location-enhanced Perceptual Network, incorporating a Position Perception Module (PPM) to boost spatial positional awareness and recalibrate feature channels. They also introduce a new nighttime deraining dataset (NSR) with 900 real-world image pairs.", "result": "Experiments on both existing datasets and the proposed NSR dataset show that NDLPNet surpasses state-of-the-art nighttime deraining methods in qualitative and quantitative evaluations.", "conclusion": "The proposed NDLPNet enhances nighttime image quality by effectively removing rain streaks and preserving background details, supported by a new benchmarking dataset for future research."}}
{"id": "2509.13943", "pdf": "https://arxiv.org/pdf/2509.13943", "abs": "https://arxiv.org/abs/2509.13943", "authors": ["Salim Oyinlola", "Nitesh Subedi", "Soumik Sarkar"], "title": "Reinforcement Learning for Autonomous Point-to-Point UAV Navigation", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "Presented at the Research Experience for Undergraduates (REU)\n  Symposium at the Translational AI Centre in Iowa State University", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used in automated\ninspection, delivery, and navigation tasks that require reliable autonomy. This\nproject develops a reinforcement learning (RL) approach to enable a single UAV\nto autonomously navigate between predefined points without manual intervention.\nThe drone learns navigation policies through trial-and-error interaction, using\na custom reward function that encourages goal-reaching efficiency while\npenalizing collisions and unsafe behavior. The control system integrates ROS\nwith a Gym-compatible training environment, enabling flexible deployment and\ntesting. After training, the learned policy is deployed on a real UAV platform\nand evaluated under practical conditions. Results show that the UAV can\nsuccessfully perform autonomous navigation with minimal human oversight,\ndemonstrating the viability of RL-based control for point-to-point drone\noperations in real-world scenarios.", "AI": {"tldr": "The paper implements reinforcement learning (RL) to make drones autonomously navigate between predefined points without manual input.", "motivation": "To develop UAVs with autonomous navigation capabilities for tasks requiring reliability and autonomy, such as inspections and deliveries.", "method": "A reinforcement learning approach trains a drone to navigate by interacting in a Gym-compatible simulation, using a reward system that encourages efficiency and penalizes unsafe actions, and later tests the learned policies on real UAVs.", "result": "The UAV successfully performs autonomous navigation between points with minimal human intervention, validating the RL-based approach for real scenarios.", "conclusion": "This approach highlights the potential and effectiveness of reinforcement learning for enabling real-world UAV autonomy in practical navigation tasks."}}
{"id": "2509.14129", "pdf": "https://arxiv.org/pdf/2509.14129", "abs": "https://arxiv.org/abs/2509.14129", "authors": ["Kit T. Rodolfa", "Erika Salomon", "Jin Yao", "Steve Yoder", "Robert Sullivan", "Kevin McGuire", "Allie Dickinson", "Rob MacDougall", "Brian Seidler", "Christina Sung", "Claire Herdeman", "Rayid Ghani"], "title": "Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Many incarcerated individuals face significant and complex challenges,\nincluding mental illness, substance dependence, and homelessness, yet jails and\nprisons are often poorly equipped to address these needs. With little support\nfrom the existing criminal justice system, these needs can remain untreated and\nworsen, often leading to further offenses and a cycle of incarceration with\nadverse outcomes both for the individual and for public safety, with\nparticularly large impacts on communities of color that continue to widen the\nalready extensive racial disparities in criminal justice outcomes. Responding\nto these failures, a growing number of criminal justice stakeholders are\nseeking to break this cycle through innovative approaches such as\ncommunity-driven and alternative approaches to policing, mentoring, community\nbuilding, restorative justice, pretrial diversion, holistic defense, and social\nservice connections. Here we report on a collaboration between Johnson County,\nKansas, and Carnegie Mellon University to perform targeted, proactive mental\nhealth outreach in an effort to reduce reincarceration rates.\n  This paper describes the data used, our predictive modeling approach and\nresults, as well as the design and analysis of a field trial conducted to\nconfirm our model's predictive power, evaluate the impact of this targeted\noutreach, and understand at what level of reincarceration risk outreach might\nbe most effective. Through this trial, we find that our model is highly\npredictive of new jail bookings, with more than half of individuals in the\ntrial's highest-risk group returning to jail in the following year. Outreach\nwas most effective among these highest-risk individuals, with impacts on mental\nhealth utilization, EMS dispatches, and criminal justice involvement.", "AI": {"tldr": "The paper examines how proactive mental health outreach informed by predictive modeling can reduce reincarceration rates. The study demonstrates the model's effectiveness and evaluates its real-world application.", "motivation": "The paper addresses the inadequacy of jails and prisons in meeting the needs of incarcerated individuals, especially those facing mental illness, substance dependence, and homelessness, which perpetuates cycles of incarceration and exacerbates racial disparities.", "method": "The authors describe their partnership with Johnson County, Kansas to implement proactive mental health outreach. They used predictive modeling to identify at-risk individuals and conducted a field trial to evaluate the model's predictive accuracy and the outreach program's effectiveness.", "result": "The study's predictive model accurately identified individuals at high risk for reincarceration, with over half of the highest-risk group returning to jail within a year. The outreach was most impactful for these individuals, influencing mental health service use, EMS dispatches, and reduced criminal justice involvement.", "conclusion": "Proactive, data-driven mental health outreach can effectively reduce reincarceration rates among high-risk individuals. This approach holds promise in addressing systemic issues within the criminal justice system."}}
{"id": "2509.13767", "pdf": "https://arxiv.org/pdf/2509.13767", "abs": "https://arxiv.org/abs/2509.13767", "authors": ["Daiqi Liu", "Tom\u00e1s Arias-Vergara", "Johannes Enk", "Fangxu Xing", "Maureen Stone", "Jerry L. Prince", "Jana Hutter", "Andreas Maier", "Jonghye Woo", "Paula Andrea P\u00e9rez-Toro"], "title": "VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI", "categories": ["cs.CV"], "comment": "Preprint submitted to ICASSP", "summary": "Accurately segmenting articulatory structures in real-time magnetic resonance\nimaging (rtMRI) remains challenging, as most existing methods rely almost\nentirely on visual cues. Yet synchronized acoustic and phonological signals\nprovide complementary context that can enrich visual information and improve\nprecision. In this paper, we introduce VocSegMRI, a multimodal framework that\nintegrates video, audio, and phonological inputs through cross-attention fusion\nfor dynamic feature alignment. To further enhance cross-modal representation,\nwe incorporate a contrastive learning objective that improves segmentation\nperformance even when the audio modality is unavailable at inference. Evaluated\non a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art\nperformance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance\n(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.\nAblation studies confirm the contributions of cross-attention and contrastive\nlearning to segmentation precision and robustness. These results highlight the\nvalue of integrative multimodal modeling for accurate vocal tract analysis.", "AI": {"tldr": "The paper presents VocSegMRI, a multimodal framework that improves real-time MRI segmentation of vocal structures by integrating visual, audio, and phonological data.", "motivation": "Existing methods for segmenting articulatory structures in rtMRI rely too much on visual cues, overlooking complementary acoustic and phonological information that could improve results.", "method": "The proposed method, VocSegMRI, uses cross-attention fusion to align video, audio, and phonological inputs dynamically. It also implements contrastive learning to boost performance, even when audio data is unavailable during inference.", "result": "VocSegMRI achieves a Dice score of 0.95 and a Hausdorff Distance (HD_95) of 4.20 mm on the USC-75 rtMRI dataset, outperforming unimodal and multimodal baselines.", "conclusion": "By integrating multimodal inputs, VocSegMRI enhances segmentation precision and robustness, demonstrating the importance of multimodal modeling for vocal tract analysis."}}
{"id": "2509.13948", "pdf": "https://arxiv.org/pdf/2509.13948", "abs": "https://arxiv.org/abs/2509.13948", "authors": ["Benedict Barrow", "Roger K. Moore"], "title": "The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot", "categories": ["cs.RO"], "comment": "In proceedings of TRUST 2025 (arXiv:2509.11402), a workshop at IEEE\n  RO-MAN 2025: https://ro-man2025.org/", "summary": "Trust and the perception of trustworthiness play an important role in\ndecision-making and our behaviour towards others, and this is true not only of\nhuman-human interactions but also of human-robot interactions. While\nsignificant advances have been made in recent years in the field of social\nrobotics, there is still some way to go before we fully understand the factors\nthat influence human trust in robots. This paper presents the results of a\nstudy into the first impressions created by a social robot's facial features,\nbased on the hypothesis that a `babyface' engenders trust. By manipulating the\nback-projected face of a Furhat robot, the study confirms that eye shape and\nsize have a significant impact on the perception of trustworthiness. The work\nthus contributes to an understanding of the design choices that need to be made\nwhen developing social robots so as to optimise the effectiveness of\nhuman-robot interaction.", "AI": {"tldr": "This paper investigates how a robot's facial features influence trust, revealing that eye shape and size significantly affect perceived trustworthiness.", "motivation": "To explore factors that shape human trust in robots, particularly the impact of a robot's facial features on trustworthiness.", "method": "Conducted a study using a Furhat robot with manipulated back-projected facial features, focusing on the influence of \u2018babyface\u2019 traits such as eye shape and size.", "result": "The study found that robots with larger, more rounded eyes are perceived as more trustworthy, supporting the hypothesis that 'babyface' features foster trust.", "conclusion": "Designing social robots with specific facial features, particularly those resembling \u2018babyface\u2019, can enhance trust and effectiveness in human-robot interaction."}}
{"id": "2509.13390", "pdf": "https://arxiv.org/pdf/2509.13390", "abs": "https://arxiv.org/abs/2509.13390", "authors": ["Deepti Kunte", "Bram Cornelis", "Claudio Colangeli", "Karl Janssens", "Brecht Van Baelen", "Konstantinos Gryllias"], "title": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS", "I.2.1; I.2.6; I.2.10; I.5.1; I.5.2; J.2; J.7"], "comment": "Submitted to: Mechanical Systems and Signal Processing", "summary": "The detection of anomalies in automotive cabin sounds is critical for\nensuring vehicle quality and maintaining passenger comfort. In many real-world\nsettings, this task is more appropriately framed as an unsupervised learning\nproblem rather than the supervised case due to the scarcity or complete absence\nof labeled faulty data. In such an unsupervised setting, the model is trained\nexclusively on healthy samples and detects anomalies as deviations from normal\nbehavior. However, in the absence of labeled faulty samples for validation and\nthe limited reliability of commonly used metrics, such as validation\nreconstruction error, effective model selection remains a significant\nchallenge. To overcome these limitations, a domain-knowledge-informed approach\nfor model selection is proposed, in which proxy-anomalies engineered through\nstructured perturbations of healthy spectrograms are used in the validation set\nto support model selection. The proposed methodology is evaluated on a\nhigh-fidelity electric vehicle dataset comprising healthy and faulty cabin\nsounds across five representative fault types viz., Imbalance, Modulation,\nWhine, Wind, and Pulse Width Modulation. This dataset, generated using advanced\nsound synthesis techniques, and validated via expert jury assessments, has been\nmade publicly available to facilitate further research. Experimental\nevaluations on the five fault cases demonstrate the selection of optimal models\nusing proxy-anomalies, significantly outperform conventional model selection\nstrategies.", "AI": {"tldr": "The paper focuses on detecting anomalies in automotive cabin sounds using an unsupervised approach, proposing a novel model selection method based on domain knowledge and proxy-anomalies for validation.", "motivation": "To improve vehicle quality and passenger comfort by detecting sound anomalies in automotive cabins, especially in scenarios where labeled faulty data is scarce or unavailable.", "method": "Proposes using structured perturbations of healthy spectrograms (proxy-anomalies) to guide model selection in an unsupervised learning framework, replacing unreliable metrics like validation reconstruction error.", "result": "The methodology was tested on an electric vehicle dataset with five fault types, achieving superior performance in model selection compared to traditional approaches.", "conclusion": "The domain-knowledge-informed model selection approach reliably selects optimal models for anomaly detection, even in the absence of labeled faulty data, and advances the understanding of anomaly detection in automotive acoustics."}}
{"id": "2509.14158", "pdf": "https://arxiv.org/pdf/2509.14158", "abs": "https://arxiv.org/abs/2509.14158", "authors": ["Feng Ruan", "Keli Liu", "Michael Jordan"], "title": "A Compositional Kernel Model for Feature Learning", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We study a compositional variant of kernel ridge regression in which the\npredictor is applied to a coordinate-wise reweighting of the inputs. Formulated\nas a variational problem, this model provides a simple testbed for feature\nlearning in compositional architectures. From the perspective of variable\nselection, we show how relevant variables are recovered while noise variables\nare eliminated. We establish guarantees showing that both global minimizers and\nstationary points discard noise coordinates when the noise variables are\nGaussian distributed. A central finding is that $\\ell_1$-type kernels, such as\nthe Laplace kernel, succeed in recovering features contributing to nonlinear\neffects at stationary points, whereas Gaussian kernels recover only linear\nones.", "AI": {"tldr": "This paper proposes a kernel ridge regression model with feature reweighting, focusing on its capacity for variable selection and feature learning.", "motivation": "To explore variable selection and feature learning using compositional kernel regression models.", "method": "The study formulates the model as a variational problem and analyzes it for recovering relevant variables while discarding noise.", "result": "It is shown that the model eliminates Gaussian-distributed noise variables and distinguishes between linear and nonlinear effects using $\n\\ell_1$-type and Gaussian kernels.", "conclusion": "Laplace kernels are found effective for nonlinear feature recovery, whereas Gaussian kernels primarily focus on linear feature selection."}}
{"id": "2509.13768", "pdf": "https://arxiv.org/pdf/2509.13768", "abs": "https://arxiv.org/abs/2509.13768", "authors": ["Jianhui Chang"], "title": "Generative Image Coding with Diffusion Prior", "categories": ["cs.CV"], "comment": null, "summary": "As generative technologies advance, visual content has evolved into a complex\nmix of natural and AI-generated images, driving the need for more efficient\ncoding techniques that prioritize perceptual quality. Traditional codecs and\nlearned methods struggle to maintain subjective quality at high compression\nratios, while existing generative approaches face challenges in visual fidelity\nand generalization. To this end, we propose a novel generative coding framework\nleveraging diffusion priors to enhance compression performance at low bitrates.\nOur approach employs a pre-optimized encoder to generate generalized\ncompressed-domain representations, integrated with the pretrained model's\ninternal features via a lightweight adapter and an attentive fusion module.\nThis framework effectively leverages existing pretrained diffusion models and\nenables efficient adaptation to different pretrained models for new\nrequirements with minimal retraining costs. We also introduce a distribution\nrenormalization method to further enhance reconstruction fidelity. Extensive\nexperiments show that our method (1) outperforms existing methods in visual\nfidelity across low bitrates, (2) improves compression performance by up to 79%\nover H.266/VVC, and (3) offers an efficient solution for AI-generated content\nwhile being adaptable to broader content types.", "AI": {"tldr": "This paper introduces a novel generative compression framework that uses pretrained diffusion models to improve visual fidelity and compression performance, especially at low bitrates.", "motivation": "The rise of AI-generated images alongside natural images demands efficient coding techniques focused on perceptual quality, as traditional codecs and methods struggle with high compression ratios and generative approaches have issues with fidelity and generalization.", "method": "The authors use a pre-optimized encoder, a lightweight adapter, an attentive fusion module, and a distribution renormalization method to leverage pretrained diffusion models for generalized compressed-domain representations and efficient adaptation.", "result": "Their framework improves compression performance by up to 79% over H.266/VVC, outperforms existing methods in visual fidelity at low bitrates, and provides versatility in handling AI-generated and diverse content types.", "conclusion": "The proposed generative coding framework efficiently enhances compression at low bitrates, demonstrating adaptability with minimal retraining costs and potential to address evolving visual content challenges."}}
{"id": "2509.13949", "pdf": "https://arxiv.org/pdf/2509.13949", "abs": "https://arxiv.org/abs/2509.13949", "authors": ["Jannick Strangh\u00f6ner", "Philipp Hartmann", "Marco Braun", "Sebastian Wrede", "Klaus Neumann"], "title": "SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks", "categories": ["cs.RO", "I.2.9"], "comment": "8 pages, 5 figures, submitted to the IEEE International Conference on\n  Robotics and Automation (ICRA) 2026", "summary": "High-mix low-volume (HMLV) industrial assembly, common in small and\nmedium-sized enterprises (SMEs), requires the same precision, safety, and\nreliability as high-volume automation while remaining flexible to product\nvariation and environmental uncertainty. Current robotic systems struggle to\nmeet these demands. Manual programming is brittle and costly to adapt, while\nlearning-based methods suffer from poor sample efficiency and unsafe\nexploration in contact-rich tasks. To address this, we present SHaRe-RL, a\nreinforcement learning framework that leverages multiple sources of prior\nknowledge. By (i) structuring skills into manipulation primitives, (ii)\nincorporating human demonstrations and online corrections, and (iii) bounding\ninteraction forces with per-axis compliance, SHaRe-RL enables efficient and\nsafe online learning for long-horizon, contact-rich industrial assembly tasks.\nExperiments on the insertion of industrial Harting connector modules with\n0.2-0.4 mm clearance demonstrate that SHaRe-RL achieves reliable performance\nwithin practical time budgets. Our results show that process expertise, without\nrequiring robotics or RL knowledge, can meaningfully contribute to learning,\nenabling safer, more robust, and more economically viable deployment of RL for\nindustrial assembly.", "AI": {"tldr": "The paper introduces SHaRe-RL, a reinforcement learning framework that combines multiple knowledge sources to enable safe and efficient learning for complex industrial assembly tasks in HMLV applications.", "motivation": "The difficulty in adapting robotic systems to high-mix low-volume industrial settings due to their inflexibility, inefficiency, and lack of safety in handling contact-rich tasks.", "method": "SHaRe-RL structures skills into manipulation primitives, relies on human demonstrations and online corrections, and bounds interaction forces with per-axis compliance to ensure safe and effective learning.", "result": "Experiments on Harting connector module assembly with minimal clearance (0.2-0.4 mm) showed reliable performance achieved within practical time limits.", "conclusion": "SHaRe-RL facilitates safer and economically viable deployment of reinforcement learning in industrial assembly by integrating process expertise without requiring robotics or RL-specific knowledge."}}
{"id": "2509.13391", "pdf": "https://arxiv.org/pdf/2509.13391", "abs": "https://arxiv.org/abs/2509.13391", "authors": ["Sandrine R. Schiller", "Camilo Miguel Signorelli", "Filippos Stamatiou"], "title": "The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self", "categories": ["cs.CY", "cs.AI"], "comment": "8 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and\n  Society", "summary": "Generative AI is changing our way of interacting with technology, others, and\nourselves. Systems such as Microsoft copilot, Gemini and the expected Apple\nintelligence still awaits our prompt for action. Yet, it is likely that AI\nassistant systems will only become better at predicting our behaviour and\nacting on our behalf. Imagine new generations of generative and predictive AI\ndeciding what you might like best at a new restaurant, picking an outfit that\nincreases your chances on your date with a partner also chosen by the same or a\nsimilar system. Far from a science fiction scenario, the goal of several\nresearch programs is to build systems capable of assisting us in exactly this\nmanner. The prospect urges us to rethink human-technology relations, but it\nalso invites us to question how such systems might change the way we relate to\nourselves. Building on our conception of the relational self, we question the\npossible effects of generative AI with respect to what we call the sphere of\nexternalised output, the contextual sphere and the sphere of self-relating. In\nthis paper, we attempt to deepen the existential considerations accompanying\nthe AI revolution by outlining how generative AI enables the fulfilment of\ntasks and also increasingly anticipates, i.e. intercepts, our initiatives in\nthese different spheres.", "AI": {"tldr": "This paper examines how generative AI might transform human-technology interactions and our relationships with ourselves, focusing on its ability to fulfill tasks and predict human behavior.", "motivation": "The authors are motivated by the urgent need to understand how generative AI systems might not only assist but also anticipate human actions, raising existential and relational concerns.", "method": "The authors analyze generative AI's impact across three spheres: externalized output, contextual interactions, and self-relating processes, using theoretical frameworks for relational selves.", "result": "Generative AI is increasingly capable of intercepting human initiatives across various spheres, leading to potential changes in human autonomy and self-perception.", "conclusion": "Generative AI might redefine human autonomy and self-identity, prompting philosophical reconsiderations about the nature of human-technology relations."}}
{"id": "2509.13356", "pdf": "https://arxiv.org/pdf/2509.13356", "abs": "https://arxiv.org/abs/2509.13356", "authors": ["Hasin Jawad Ali", "Ilhamul Azam", "Ajwad Abrar", "Md. Kamrul Hasan", "Hasan Mahmud"], "title": "CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI", "categories": ["cs.CY", "cs.CL"], "comment": null, "summary": "The challenge of aligning artificial intelligence (AI) with human values\npersists due to the abstract and often conflicting nature of moral principles\nand the opacity of existing approaches. This paper introduces CogniAlign, a\nmulti-agent deliberation framework based on naturalistic moral realism, that\ngrounds moral reasoning in survivability, defined across individual and\ncollective dimensions, and operationalizes it through structured deliberations\namong discipline-specific scientist agents. Each agent, representing\nneuroscience, psychology, sociology, and evolutionary biology, provides\narguments and rebuttals that are synthesized by an arbiter into transparent and\nempirically anchored judgments. We evaluate CogniAlign on classic and novel\nmoral questions and compare its outputs against GPT-4o using a five-part\nethical audit framework. Results show that CogniAlign consistently outperforms\nthe baseline across more than sixty moral questions, with average performance\ngains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4\npoints in depth of explanation. In the Heinz dilemma, for example, CogniAlign\nachieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a\ndecisive advantage in handling moral reasoning. By reducing black-box reasoning\nand avoiding deceptive alignment, CogniAlign highlights the potential of\ninterdisciplinary deliberation as a scalable pathway for safe and transparent\nAI alignment.", "AI": {"tldr": "This paper introduces CogniAlign, a multi-agent deliberation framework for AI alignment based on moral realism, showcasing transparent and empirically grounded judgments that outperform GPT-4o in moral reasoning tests.", "motivation": "The paper aims to address the persistent challenge of aligning artificial intelligence with human moral values, which are abstract, conflicting, and difficult to operationalize.", "method": "CogniAlign utilizes a multi-agent deliberation framework involving discipline-specific scientist agents (from neuroscience, psychology, sociology, etc.) to engage in structured discussions. An arbiter synthesizes their arguments into transparent, empirically grounded moral judgments.", "result": "CogniAlign consistently outperforms GPT-4o on over sixty moral questions, achieving notable improvements in analytic quality (+16.2 points), breadth (+14.3 points), and depth of explanation (+28.4 points).", "conclusion": "Interdisciplinary deliberation via CogniAlign offers a scalable approach for safe and transparent AI alignment, reducing black-box reasoning and deceptive alignment challenges."}}
{"id": "2509.14167", "pdf": "https://arxiv.org/pdf/2509.14167", "abs": "https://arxiv.org/abs/2509.14167", "authors": ["Md Rezwan Jaher", "Abul Mukid Mohammad Mukaddes", "A. B. M. Abdul Malek"], "title": "Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework", "categories": ["cs.LG", "q-bio.QM", "stat.AP", "stat.ME"], "comment": "43 pages, 10 figures (including supplementary material)", "summary": "Many critical healthcare decisions are challenged by the inability to measure\nkey underlying parameters. Glaucoma, a leading cause of irreversible blindness\ndriven by elevated intraocular pressure (IOP), provides a stark example. The\nprimary determinant of IOP, a tissue property called trabecular meshwork\npermeability, cannot be measured in vivo, forcing clinicians to depend on\nindirect surrogates. This clinical challenge is compounded by a broader\ncomputational one: developing predictive models for such ill-posed inverse\nproblems is hindered by a lack of ground-truth data and prohibitive cost of\nlarge-scale, high-fidelity simulations. We address both challenges with an\nend-to-end framework to noninvasively estimate unmeasurable variables from\nsparse, routine data. Our approach combines a multi-stage artificial\nintelligence architecture to functionally separate the problem; a novel data\ngeneration strategy we term PCDS that obviates the need for hundreds of\nthousands of costly simulations, reducing the effective computational time from\nyears to hours; and a Bayesian engine to quantify predictive uncertainty. Our\nframework deconstructs a single IOP measurement into its fundamental components\nfrom routine inputs only, yielding estimates for the unmeasurable tissue\npermeability and a patient's outflow facility. Our noninvasively estimated\noutflow facility achieved excellent agreement with state-of-the-art tonography\nwith precision comparable to direct physical instruments. Furthermore, the\nnewly derived permeability biomarker demonstrates high accuracy in stratifying\nclinical cohorts by disease risk, highlighting its diagnostic potential. More\nbroadly, our framework establishes a generalizable blueprint for solving\nsimilar inverse problems in other data-scarce, computationally-intensive\ndomains.", "AI": {"tldr": "This paper introduces a novel AI-driven framework to noninvasively estimate unmeasurable healthcare parameters, focusing on glaucoma biomarkers and solving complex inverse problems.", "motivation": "Understanding and addressing the inability to measure critical healthcare biomarkers, such as trabecular meshwork permeability in glaucoma, which hampers diagnostic and therapeutic decisions.", "method": "The framework includes a multi-stage AI architecture, a novel PCDS data generation strategy to cut simulation costs, and a Bayesian engine to assess predictive uncertainty from routine inputs.", "result": "The framework estimates the key glaucoma biomarkers noninvasively with precision akin to direct clinical instruments and stratifies disease risk effectively using newly derived biomarkers.", "conclusion": "The study defines a scalable solution for healthcare challenges related to unmeasurable parameters and establishes applicability for other domains facing data-scarce inverse problems."}}
{"id": "2509.13769", "pdf": "https://arxiv.org/pdf/2509.13769", "abs": "https://arxiv.org/abs/2509.13769", "authors": ["Yuechen Luo", "Fang Li", "Shaoqing Xu", "Zhiyi Lai", "Lei Yang", "Qimao Chen", "Ziang Luo", "Zixun Xie", "Shengyin Jiang", "Jiaxin Liu", "Long Chen", "Bing Wang", "Zhi-xin Yang"], "title": "AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "While reasoning technology like Chain of Thought (CoT) has been widely\nadopted in Vision Language Action (VLA) models, it demonstrates promising\ncapabilities in end to end autonomous driving. However, recent efforts to\nintegrate CoT reasoning often fall short in simple scenarios, introducing\nunnecessary computational overhead without improving decision quality. To\naddress this, we propose AdaThinkDrive, a novel VLA framework with a dual mode\nreasoning mechanism inspired by fast and slow thinking. First, our framework is\npretrained on large scale autonomous driving (AD) scenarios using both question\nanswering (QA) and trajectory datasets to acquire world knowledge and driving\ncommonsense. During supervised fine tuning (SFT), we introduce a two mode\ndataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the\nmodel to distinguish between scenarios that require reasoning. Furthermore, an\nAdaptive Think Reward strategy is proposed in conjunction with the Group\nRelative Policy Optimization (GRPO), which rewards the model for selectively\napplying CoT by comparing trajectory quality across different reasoning modes.\nExtensive experiments on the Navsim benchmark show that AdaThinkDrive achieves\na PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.\nMoreover, ablations show that AdaThinkDrive surpasses both the never Think and\nalways Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also\nreduces inference time by 14% compared to the always Think baseline,\ndemonstrating its ability to balance accuracy and efficiency through adaptive\nreasoning.", "AI": {"tldr": "AdaThinkDrive introduces a dual-mode reasoning mechanism inspired by fast and slow thinking for Vision Language Action models in autonomous driving, achieving better decision-making and efficiency.", "motivation": "Existing Vision Language Action models face challenges in utilizing Chain of Thought reasoning efficiently, leading to computational overhead without significant decision quality improvements.", "method": "AdaThinkDrive uses a dual-mode reasoning mechanism, pretrained with question-answering and trajectory datasets, and fine-tuned with datasets distinguishing fast answering and slow thinking modes. It incorporates an Adaptive Think Reward strategy and Group Relative Policy Optimization to balance reasoning application.", "result": "In extensive experiments, AdaThinkDrive achieves a PDMS of 90.3, surpassing vision-only baselines and both never Think and always Think baselines in accuracy and efficiency. It reduces inference time by 14% compared to the always Think baseline.", "conclusion": "AdaThinkDrive effectively balances reasoning accuracy and computational efficiency, showing promise for improving autonomous driving systems."}}
{"id": "2509.13956", "pdf": "https://arxiv.org/pdf/2509.13956", "abs": "https://arxiv.org/abs/2509.13956", "authors": ["Zewei Yang", "Zengqi Peng", "Jun Ma"], "title": "SEG-Parking: Towards Safe, Efficient, and Generalizable Autonomous Parking via End-to-End Offline Reinforcement Learning", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous parking is a critical component for achieving safe and efficient\nurban autonomous driving. However, unstructured environments and dynamic\ninteractions pose significant challenges to autonomous parking tasks. To\naddress this problem, we propose SEG-Parking, a novel end-to-end offline\nreinforcement learning (RL) framework to achieve interaction-aware autonomous\nparking. Notably, a specialized parking dataset is constructed for parking\nscenarios, which include those without interference from the opposite vehicle\n(OV) and complex ones involving interactions with the OV. Based on this\ndataset, a goal-conditioned state encoder is pretrained to map the fused\nperception information into the latent space. Then, an offline RL policy is\noptimized with a conservative regularizer that penalizes out-of-distribution\nactions. Extensive closed-loop experiments are conducted in the high-fidelity\nCARLA simulator. Comparative results demonstrate the superior performance of\nour framework with the highest success rate and robust generalization to\nout-of-distribution parking scenarios. The related dataset and source code will\nbe made publicly available after the paper is accepted.", "AI": {"tldr": "This paper introduces SEG-Parking, an end-to-end offline reinforcement learning framework designed for interaction-aware autonomous parking in complex and dynamic environments.", "motivation": "Autonomous parking in urban settings faces difficulties due to unstructured environments and dynamic interactions, necessitating advanced solutions for safe and efficient operation.", "method": "The framework employs a specialized parking dataset, a pretrained goal-conditioned state encoder for mapping fused perception data into latent space, and an offline RL policy trained with a conservative regularizer to prevent out-of-distribution actions.", "result": "Experiments in the CARLA simulator show that SEG-Parking achieves superior success rates and generalizes well to out-of-distribution parking scenarios.", "conclusion": "SEG-Parking offers a promising solution for handling challenging autonomous parking scenarios, with plans to release the associated dataset and code for further research use."}}
{"id": "2509.13395", "pdf": "https://arxiv.org/pdf/2509.13395", "abs": "https://arxiv.org/abs/2509.13395", "authors": ["Haolong Zheng", "Yekaterina Yegorova", "Mark Hasegawa-Johnson"], "title": "TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": null, "summary": "Speech foundation models have recently demonstrated the ability to perform\nSpeech In-Context Learning (SICL). Selecting effective in-context examples is\ncrucial for SICL performance, yet selection methodologies remain underexplored.\nIn this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline\nthat uses semantic context to enhance off-the-shelf large multimodal models'\nspeech recognition ability without fine-tuning. Across challenging automatic\nspeech recognition tasks, including accented English, multilingual speech, and\nchildren's speech, our method enables models to surpass zero-shot performance\nwith up to 84.7% relative WER reduction. We conduct ablation studies to show\nthe robustness and efficiency of our method.", "AI": {"tldr": "The paper introduces a method called TICL to improve Speech In-Context Learning (SICL) by selecting better in-context examples using semantic context, significantly boosting large multimodal models' performance in speech recognition tasks without requiring fine-tuning.", "motivation": "The motivation is to enhance Speech In-Context Learning (SICL) by addressing the underexplored area of selecting effective in-context examples, aiming to improve the performance of speech recognition tasks.", "method": "The authors propose the Text-Embedding KNN for SICL (TICL) pipeline, leveraging semantic context to select better in-context examples. TICL enhances existing large multimodal models' performance without needing fine-tuning.", "result": "The TICL method achieves up to 84.7% relative reduction in Word Error Rate (WER) across speech recognition tasks, including accented English, multilingual speech, and children's speech. Ablation studies confirm the robustness and efficiency of TICL.", "conclusion": "TICL effectively improves the performance of large multimodal models on speech recognition tasks by leveraging semantic context for in-context example selection. This method provides a simple and fine-tuning-free solution to achieve significant performance gains."}}
{"id": "2509.14169", "pdf": "https://arxiv.org/pdf/2509.14169", "abs": "https://arxiv.org/abs/2509.14169", "authors": ["Ziming Wei", "Zichen Kong", "Yuan Wang", "David Z. Pan", "Xiyuan Tang"], "title": "TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits", "categories": ["cs.LG"], "comment": null, "summary": "Analog and mixed-signal circuit design remains challenging due to the\nshortage of high-quality data and the difficulty of embedding domain knowledge\ninto automated flows. Traditional black-box optimization achieves sampling\nefficiency but lacks circuit understanding, which often causes evaluations to\nbe wasted in low-value regions of the design space. In contrast, learning-based\nmethods embed structural knowledge but are case-specific and costly to retrain.\nRecent attempts with large language models show potential, yet they often rely\non manual intervention, limiting generality and transparency. We propose\nTopoSizing, an end-to-end framework that performs robust circuit understanding\ndirectly from raw netlists and translates this knowledge into optimization\ngains. Our approach first applies graph algorithms to organize circuits into a\nhierarchical device-module-stage representation. LLM agents then execute an\niterative hypothesis-verification-refinement loop with built-in consistency\nchecks, producing explicit annotations. Verified insights are integrated into\nBayesian optimization through LLM-guided initial sampling and\nstagnation-triggered trust-region updates, improving efficiency while\npreserving feasibility.", "AI": {"tldr": "This paper introduces TopoSizing, a framework combining circuit graph analysis, large language models, and Bayesian optimization to improve analog and mixed-signal circuit design.", "motivation": "Analog and mixed-signal circuit design faces challenges due to a lack of high-quality data, difficulty embedding domain knowledge, and inefficiencies in existing optimization strategies.", "method": "TopoSizing uses graph algorithms for circuit organization, large language models for iterative hypothesis checking, and Bayesian optimization with LLM-guided insights for efficient sampling and refinement.", "result": "TopoSizing improves design feasibility and optimization efficiency by leveraging structural knowledge embedded in netlists and LLM-guided processes.", "conclusion": "By integrating domain-specific structures and language model insights into optimization workflows, TopoSizing offers a robust solution to streamline analog circuit design."}}
{"id": "2509.13776", "pdf": "https://arxiv.org/pdf/2509.13776", "abs": "https://arxiv.org/abs/2509.13776", "authors": ["Chao Shuai", "Gaojian Wang", "Kun Pan", "Tong Wu", "Fanli Jin", "Haohan Tan", "Mengxiang Li", "Zhenguang Liu", "Feng Lin", "Kui Ren"], "title": "Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization", "categories": ["cs.CV"], "comment": "The 3rd Place, IJCAI 2025 Workshop on Deepfake Detection,\n  Localization, and Interpretability", "summary": "While the pursuit of higher accuracy in deepfake detection remains a central\ngoal, there is an increasing demand for precise localization of manipulated\nregions. Despite the remarkable progress made in classification-based\ndetection, accurately localizing forged areas remains a significant challenge.\nA common strategy is to incorporate forged region annotations during model\ntraining alongside manipulated images. However, such approaches often neglect\nthe complementary nature of local detail and global semantic context, resulting\nin suboptimal localization performance. Moreover, an often-overlooked aspect is\nthe fusion strategy between local and global predictions. Naively combining the\noutputs from both branches can amplify noise and errors, thereby undermining\nthe effectiveness of the localization.\n  To address these issues, we propose a novel approach that independently\npredicts manipulated regions using both local and global perspectives. We\nemploy morphological operations to fuse the outputs, effectively suppressing\nnoise while enhancing spatial coherence. Extensive experiments reveal the\neffectiveness of each module in improving the accuracy and robustness of\nforgery localization.", "AI": {"tldr": "The paper proposes a new method for deepfake detection focusing on accurately localizing manipulated regions using an innovative fusion approach between local and global predictions.", "motivation": "Enhance the precision in identifying forged regions in deepfake detection, addressing existing challenges like neglecting complementary details and inefficient fusion strategies.", "method": "Utilizes morphological operations to fuse locally and globally predicted regions, ensuring improved spatial coherence and reduced noise.", "result": "The proposed approach demonstrated improvement in localization accuracy and robustness through extensive experimentation.", "conclusion": "Employing both local and global perspectives paired with sophisticated fusion techniques offers significant promise in refining forgery localization."}}
{"id": "2509.13965", "pdf": "https://arxiv.org/pdf/2509.13965", "abs": "https://arxiv.org/abs/2509.13965", "authors": ["Abhijeet Nayak", "D\u00e9bora N. P. Oliveira", "Samiran Gode", "Cordelia Schmid", "Wolfram Burgard"], "title": "MetricNet: Recovering Metric Scale in Generative Navigation Policies", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Generative navigation policies have made rapid progress in improving\nend-to-end learned navigation. Despite their promising results, this paradigm\nhas two structural problems. First, the sampled trajectories exist in an\nabstract, unscaled space without metric grounding. Second, the control strategy\ndiscards the full path, instead moving directly towards a single waypoint. This\nleads to short-sighted and unsafe actions, moving the robot towards obstacles\nthat a complete and correctly scaled path would circumvent. To address these\nissues, we propose MetricNet, an effective add-on for generative navigation\nthat predicts the metric distance between waypoints, grounding policy outputs\nin real-world coordinates. We evaluate our method in simulation with a new\nbenchmarking framework and show that executing MetricNet-scaled waypoints\nsignificantly improves both navigation and exploration performance. Beyond\nsimulation, we further validate our approach in real-world experiments.\nFinally, we propose MetricNav, which integrates MetricNet into a navigation\npolicy to guide the robot away from obstacles while still moving towards the\ngoal.", "AI": {"tldr": "This paper introduces MetricNet, a tool to improve generative navigation policies by adding metric grounding to trajectories, avoiding unsafe robot movements and enhancing navigation and exploration.", "motivation": "Generative navigation policies face issues with unscaled trajectory spaces and short-sighted waypoint-based control, leading to unsafe robotic movements.", "method": "MetricNet predicts the metric distance between waypoints, integrating real-world coordinates into navigation. MetricNav incorporates MetricNet into navigation policies to guide robots safely.", "result": "Experiments in both simulations and the real world demonstrate that MetricNet significantly improves navigation and exploration performance.", "conclusion": "Incorporating metric grounding via MetricNet improves generative navigation policies' safety, efficiency, and utility in real-world and simulated environments."}}
{"id": "2509.13397", "pdf": "https://arxiv.org/pdf/2509.13397", "abs": "https://arxiv.org/abs/2509.13397", "authors": ["Jamie Cummins"], "title": "The threat of analytic flexibility in using large language models to simulate human data: A call to attention", "categories": ["cs.CY", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Social scientists are now using large language models to create \"silicon\nsamples\" - synthetic datasets intended to stand in for human respondents, aimed\nat revolutionising human subjects research. However, there are many analytic\nchoices which must be made to produce these samples. Though many of these\nchoices are defensible, their impact on sample quality is poorly understood. I\nmap out these analytic choices and demonstrate how a very small number of\ndecisions can dramatically change the correspondence between silicon samples\nand human data. Configurations (N = 252) varied substantially in their capacity\nto estimate (i) rank ordering of participants, (ii) response distributions, and\n(iii) between-scale correlations. Most critically, configurations were not\nconsistent in quality: those that performed well on one dimension often\nperformed poorly on another, implying that there is no \"one-size-fits-all\"\nconfiguration that optimises the accuracy of these samples. I call for greater\nattention to the threat of analytic flexibility in using silicon samples.", "AI": {"tldr": "The paper discusses the use of synthetic datasets created by large language models for human subjects research, highlighting the impact of analytic choices on sample quality and the lack of a universal configuration for optimal results.", "motivation": "The author aims to address the growing use of large language models to generate synthetic datasets ('silicon samples') and investigate the analytic choices influencing their quality, given the potential of these samples to transform human subject research.", "method": "The paper maps out analytic choices and tests 252 configurations of silicon samples to evaluate their ability to estimate rank ordering, response distributions, and between-scale correlations.", "result": "Findings reveal significant variability across configurations in their performance and inconsistency in quality, with certain configurations excelling in one aspect while underperforming in others.", "conclusion": "The paper concludes that there is no single optimal configuration for generating accurate silicon samples and calls for more attention to the risks posed by analytic flexibility in utilizing these synthetic datasets."}}
{"id": "2509.14172", "pdf": "https://arxiv.org/pdf/2509.14172", "abs": "https://arxiv.org/abs/2509.14172", "authors": ["Ziyuan Chen", "Zhenghui Zhao", "Zhangye Han", "Miancan Liu", "Xianhang Ye", "Yiqing Li", "Hongbo Min", "Jinkui Ren", "Xiantao Zhang", "Guitao Cao"], "title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models and vision-language\nmodels, employing large models as Web Agents has become essential for automated\nweb interaction. However, training Web Agents with reinforcement learning faces\ncritical challenges including credit assignment misallocation, prohibitively\nhigh annotation costs, and reward sparsity. To address these issues, we propose\nTree-Guided Preference Optimization (TGPO), an offline reinforcement learning\nframework that proposes a tree-structured trajectory representation merging\nsemantically identical states across trajectories to eliminate label conflicts.\nOur framework incorporates a Process Reward Model that automatically generates\nfine-grained rewards through subgoal progress, redundancy detection, and action\nverification. Additionally, a dynamic weighting mechanism prioritizes\nhigh-impact decision points during training. Experiments on Online-Mind2Web and\nour self-constructed C-WebShop datasets demonstrate that TGPO significantly\noutperforms existing methods, achieving higher success rates with fewer\nredundant steps.", "AI": {"tldr": "The paper introduces Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning framework for training efficient and effective Web Agents, addressing challenges like reward sparsity and high annotation costs. It achieves better results compared to existing methods in specific benchmarks.", "motivation": "The motivation is to address the challenges in training Web Agents using reinforcement learning, such as credit assignment issues, annotation costs, and sparse rewards, while leveraging large language and vision-language models.", "method": "The method, Tree-Guided Preference Optimization (TGPO), uses a tree-structured trajectory representation to merge semantically similar states, a Process Reward Model for fine-grained reward generation, and dynamic weighting to emphasize crucial decision points during training.", "result": "TGPO outperformed existing methods in experiments conducted on Online-Mind2Web and C-WebShop datasets, achieving higher success rates with fewer redundant steps.", "conclusion": "TGPO offers an effective solution for training robust Web Agents, overcoming the limitations of traditional reinforcement learning approaches with its novel trajectory representation, reward model, and decision weighting system."}}
{"id": "2509.13784", "pdf": "https://arxiv.org/pdf/2509.13784", "abs": "https://arxiv.org/abs/2509.13784", "authors": ["Hanfang Liang", "Bing Wang", "Shizhen Zhang", "Wen Jiang", "Yizhuo Yang", "Weixiang Guo", "Shenghai Yuan"], "title": "CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling", "categories": ["cs.CV"], "comment": "8 pages, 6 figures", "summary": "Event cameras capture asynchronous pixel-level brightness changes with\nmicrosecond temporal resolution, offering unique advantages for high-speed\nvision tasks. Existing methods often convert event streams into intermediate\nrepresentations such as frames, voxel grids, or point clouds, which inevitably\nrequire predefined time windows and thus introduce window latency. Meanwhile,\npointwise detection methods face computational challenges that prevent\nreal-time efficiency due to their high computational cost. To overcome these\nlimitations, we propose the Variable-Rate Spatial Event Mamba, a novel\narchitecture that directly processes raw event streams without intermediate\nrepresentations. Our method introduces a lightweight causal spatial\nneighborhood encoder to efficiently capture local geometric relations, followed\nby Mamba-based state space models for scalable temporal modeling with linear\ncomplexity. During inference, a controller adaptively adjusts the processing\nspeed according to the event rate, achieving an optimal balance between window\nlatency and inference latency.", "AI": {"tldr": "This paper introduces the Variable-Rate Spatial Event Mamba, a novel method for processing raw event camera streams without converting them into intermediate representations, achieving real-time efficiency and optimal latency.", "motivation": "Existing methods for event camera data processing rely on converting data into intermediate forms, which introduces latency, or involve pointwise processing, which is computationally expensive and not real-time efficient. This paper aims to overcome these limitations.", "method": "The proposed method processes raw event streams directly using a lightweight causal spatial neighborhood encoder to capture local geometric relations and a Mamba-based state space model for scalable, efficient temporal modeling. Additionally, an adaptive controller adjusts processing speed based on event rates.", "result": "The proposed method achieves real-time efficiency by processing raw event streams while balancing window latency and inference latency. It eliminates the need for intermediate data representations.", "conclusion": "The Variable-Rate Spatial Event Mamba effectively addresses challenges in event camera data processing, offering a scalable, efficient, and adaptive solution suitable for high-speed vision tasks."}}
{"id": "2509.13972", "pdf": "https://arxiv.org/pdf/2509.13972", "abs": "https://arxiv.org/abs/2509.13972", "authors": ["Asier Bikandi", "Miguel Fernandez-Cortizas", "Muhammad Shaheer", "Ali Tourani", "Holger Voos", "Jose Luis Sanchez-Lopez"], "title": "BIM Informed Visual SLAM for Construction Monitoring", "categories": ["cs.RO"], "comment": "8 pages, 5 tables, 4 figures", "summary": "Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring\nconstruction sites, where aligning the evolving as-built state with the\nas-planned design enables early error detection and reduces costly rework.\nLiDAR-based SLAM achieves high geometric precision, but its sensors are\ntypically large and power-demanding, limiting their use on portable platforms.\nVisual SLAM offers a practical alternative with lightweight cameras already\nembedded in most mobile devices. however, visually mapping construction\nenvironments remains challenging: repetitive layouts, occlusions, and\nincomplete or low-texture structures often cause drift in the trajectory map.\nTo mitigate this, we propose an RGB-D SLAM system that incorporates the\nBuilding Information Model (BIM) as structural prior knowledge. Instead of\nrelying solely on visual cues, our system continuously establishes\ncorrespondences between detected wall and their BIM counterparts, which are\nthen introduced as constraints in the back-end optimization. The proposed\nmethod operates in real time and has been validated on real construction sites,\nreducing trajectory error by an average of 23.71% and map RMSE by 7.14%\ncompared to visual SLAM baselines. These results demonstrate that BIM\nconstraints enable reliable alignment of the digital plan with the as-built\nscene, even under partially constructed conditions.", "AI": {"tldr": "This paper introduces a real-time RGB-D SLAM system that integrates Building Information Models (BIM) as structural priors to enhance SLAM accuracy in challenging construction environments.", "motivation": "Monitoring construction sites effectively requires precise as-built vs. as-planned alignment, but traditional SLAM tools either rely on large LiDAR setups or face challenges like occlusions and repetitive layouts with visual-only methods.", "method": "The proposed RGB-D SLAM system integrates BIM constraints into the mapping process, using detected wall correspondences and introducing them as back-end optimization constraints.", "result": "The method demonstrated a 23.71% reduction in trajectory error and a 7.14% reduction in map RMSE compared to visual SLAM baselines in real construction site tests.", "conclusion": "Incorporating BIM constraints improves the reliability and alignment of SLAM systems in construction environments, enabling better as-planned vs. as-built alignment even in incomplete structures."}}
{"id": "2509.14181", "pdf": "https://arxiv.org/pdf/2509.14181", "abs": "https://arxiv.org/abs/2509.14181", "authors": ["Yifan Hu", "Jie Yang", "Tian Zhou", "Peiyuan Liu", "Yujin Tang", "Rong Jin", "Liang Sun"], "title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.", "AI": {"tldr": "TimeAlign introduces a framework for improving time series forecasting by aligning historical inputs with future targets, yielding performance gains verified across multiple benchmarks.", "motivation": "Researchers aim to address the lack of representation learning techniques in SOTA time series forecasting despite their proven success in other fields like NLP and computer vision.", "method": "TimeAlign employs a straightforward reconstruction task to learn auxiliary features, which are then integrated with any base forecaster for improved predictive alignment.", "result": "Extensive experiments across eight benchmarks show TimeAlign's performance superiority by correcting frequency mismatches between historical and future data.", "conclusion": "TimeAlign provides significant benefit as a lightweight, architecture-agnostic module for deep learning time-series forecasting, enhancing mutual information between learned representations and targets with minimal overhead."}}
{"id": "2509.13789", "pdf": "https://arxiv.org/pdf/2509.13789", "abs": "https://arxiv.org/abs/2509.13789", "authors": ["Hanshuai Cui", "Zhiqing Tang", "Zhifei Xu", "Zhi Yao", "Wenyi Zeng", "Weijia Jia"], "title": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in Diffusion Transformers (DiTs) have established them as\nthe state-of-the-art method for video generation. However, their inherently\nsequential denoising process results in inevitable latency, limiting real-world\napplicability. Existing acceleration methods either compromise visual quality\ndue to architectural modifications or fail to reuse intermediate features at\nproper granularity. Our analysis reveals that DiT blocks are the primary\ncontributors to inference latency. Across diffusion timesteps, the feature\nvariations of DiT blocks exhibit a U-shaped pattern with high similarity during\nintermediate timesteps, which suggests substantial computational redundancy. In\nthis paper, we propose Block-Wise Caching (BWCache), a training-free method to\naccelerate DiT-based video generation. BWCache dynamically caches and reuses\nfeatures from DiT blocks across diffusion timesteps. Furthermore, we introduce\na similarity indicator that triggers feature reuse only when the differences\nbetween block features at adjacent timesteps fall below a threshold, thereby\nminimizing redundant computations while maintaining visual fidelity. Extensive\nexperiments on several video diffusion models demonstrate that BWCache achieves\nup to 2.24$\\times$ speedup with comparable visual quality.", "AI": {"tldr": "The paper introduces BWCache, a training-free method to accelerate Diffusion Transformers (DiTs) for video generation by reusing features dynamically across timesteps, reducing latency with minimal visual compromise.", "motivation": "Diffusion Transformers (DiTs), while excellent for video generation, suffer from latency due to their sequential denoising process, limiting their practical applicability.", "method": "The authors analyzed feature redundancy in DiT blocks and proposed BWCache, which dynamically caches and reuses block features across timesteps using a similarity indicator to control redundancy and preserve visual quality.", "result": "BWCache delivered up to 2.24\u00d7 speedup in video generation, maintaining visual fidelity, as demonstrated through extensive experiments on various video diffusion models.", "conclusion": "BWCache offers a significant acceleration for DiT-based video generation by exploiting feature redundancy without any training requirement, making it more feasible for real-world applications."}}
{"id": "2509.13998", "pdf": "https://arxiv.org/pdf/2509.13998", "abs": "https://arxiv.org/abs/2509.13998", "authors": ["Bailey Dacre", "Rodrigo Moreno", "Serhat Demirtas", "Ziqiao Wang", "Yuhao Jiang", "Jamie Paik", "Kasper Stoy", "Andr\u00e9s Fa\u00ed\u00f1a"], "title": "Flexible and Foldable: Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array", "categories": ["cs.RO"], "comment": null, "summary": "Object manipulation is a fundamental challenge in robotics, where systems\nmust balance trade-offs among manipulation capabilities, system complexity, and\nthroughput. Distributed manipulator systems (DMS) use the coordinated motion of\nactuator arrays to perform complex object manipulation tasks, seeing widespread\nexploration within the literature and in industry. However, existing DMS\ndesigns typically rely on high actuator densities and impose constraints on\nobject-to-actuator scale ratios, limiting their adaptability. We present a\nnovel DMS design utilizing an array of 3-DoF, origami-inspired robotic tiles\ninterconnected by a compliant surface layer. Unlike conventional DMS, our\napproach enables manipulation not only at the actuator end effectors but also\nacross a flexible surface connecting all actuators; creating a continuous,\ncontrollable manipulation surface. We analyse the combined workspace of such a\nsystem, derive simple motion primitives, and demonstrate its capabilities to\ntranslate simple geometric objects across an array of tiles. By leveraging the\ninter-tile connective material, our approach significantly reduces actuator\ndensity, increasing the area over which an object can be manipulated by x1.84\nwithout an increase in the number of actuators. This design offers a lower cost\nand complexity alternative to traditional high-density arrays, and introduces\nnew opportunities for manipulation strategies that leverage the flexibility of\nthe interconnected surface.", "AI": {"tldr": "This paper introduces a novel distributed manipulator system (DMS) design with origami-inspired robotic tiles connected by a compliant surface layer, enabling continuous manipulation and reduced actuator density.", "motivation": "Object manipulation remains a fundamental robotics challenge, requiring systems to balance between capabilities, complexity, and throughput.", "method": "The approach combines origami-inspired 3-DoF robotic tiles interconnected by a compliant layer to create a flexible manipulation surface. Motion primitives and workspace analysis for the system are included.", "result": "The design reduces actuator density and expands manipulation area by 1.84 times without additional actuators.", "conclusion": "This lower-cost design provides an alternative to high-density actuator arrays, introducing flexible manipulation strategies leveraging interconnected surfaces."}}
{"id": "2509.13400", "pdf": "https://arxiv.org/pdf/2509.13400", "abs": "https://arxiv.org/abs/2509.13400", "authors": ["Sai Suresh Marchala Vasu", "Ivaxi Sheth", "Hui-Po Wang", "Ruta Binkyte", "Mario Fritz"], "title": "Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The adoption of large language models (LLMs) is transforming the peer review\nprocess, from assisting reviewers in writing more detailed evaluations to\ngenerating entire reviews automatically. While these capabilities offer\nexciting opportunities, they also raise critical concerns about fairness and\nreliability. In this paper, we investigate bias in LLM-generated peer reviews\nby conducting controlled experiments on sensitive metadata, including author\naffiliation and gender. Our analysis consistently shows affiliation bias\nfavoring institutions highly ranked on common academic rankings. Additionally,\nwe find some gender preferences, which, even though subtle in magnitude, have\nthe potential to compound over time. Notably, we uncover implicit biases that\nbecome more evident with token-based soft ratings.", "AI": {"tldr": "This paper investigates bias in peer reviews generated by large language models (LLMs), focusing on sensitive metadata like affiliation and gender. It finds affiliation bias favoring top institutions and subtle gender preferences.", "motivation": "To address the critical concerns about fairness and reliability in LLM-generated peer reviews as these models increasingly assist or automate the review process.", "method": "Conducted controlled experiments focusing on sensitive metadata like author affiliation and gender to analyze biases in LLM-generated peer reviews.", "result": "Revealed affiliation bias favoring prestigious institutions and subtle gender preferences. Also uncovered implicit biases that are prominent with token-based soft ratings.", "conclusion": "LLM-generated peer reviews exhibit biases that may impact fairness and reliability, indicating the need for addressing these issues to maintain equitable academic evaluation."}}
{"id": "2509.14198", "pdf": "https://arxiv.org/pdf/2509.14198", "abs": "https://arxiv.org/abs/2509.14198", "authors": ["Juan Diego Toscano", "Daniel T. Chen", "Vivek Oommen", "George Em Karniadakis"], "title": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "physics.comp-ph"], "comment": null, "summary": "Residual-based adaptive strategies are widely used in scientific machine\nlearning but remain largely heuristic. We introduce a unifying variational\nframework that formalizes these methods by integrating convex transformations\nof the residual. Different transformations correspond to distinct objective\nfunctionals: exponential weights target the minimization of uniform error,\nwhile linear weights recover the minimization of quadratic error. Within this\nperspective, adaptive weighting is equivalent to selecting sampling\ndistributions that optimize the primal objective, thereby linking\ndiscretization choices directly to error metrics. This principled approach\nyields three benefits: (1) it enables systematic design of adaptive schemes\nacross norms, (2) reduces discretization error through variance reduction of\nthe loss estimator, and (3) enhances learning dynamics by improving the\ngradient signal-to-noise ratio. Extending the framework to operator learning,\nwe demonstrate substantial performance gains across optimizers and\narchitectures. Our results provide a theoretical justification of\nresidual-based adaptivity and establish a foundation for principled\ndiscretization and training strategies.", "AI": {"tldr": "The paper introduces a unifying framework for residual-based adaptive strategies in machine learning to formalize and optimize them.", "motivation": "Residual-based adaptive strategies are effective but lack a solid theoretical foundation.", "method": "The authors use a variational framework with convex transformations of residuals to optimize objective functionals tied to error norms, linking discretization to error metrics.", "result": "The framework improves adaptive scheme design, reduces error, and enhances learning by improving gradient signal-to-noise ratio, demonstrating gains in operator learning.", "conclusion": "A principled, theory-backed framework for residual-based adaptive strategies provides improved discretization and training strategies in machine learning."}}
{"id": "2509.13792", "pdf": "https://arxiv.org/pdf/2509.13792", "abs": "https://arxiv.org/abs/2509.13792", "authors": ["Inder Pal Singh", "Nidhal Eddine Chenni", "Abd El Rahman Shabayek", "Arunkumar Rathinam", "Djamila Aouada"], "title": "Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous\nspace operations such as rendezvous, docking, and in-orbit servicing. Hybrid\npipelines that combine object detection, keypoint regression, and\nPerspective-n-Point (PnP) solvers have recently achieved strong results on\nsynthetic datasets, yet their performance deteriorates sharply on real or\nlab-generated imagery due to the persistent synthetic-to-real domain gap.\nExisting unsupervised domain adaptation approaches aim to mitigate this issue\nbut often underperform when a modest number of labeled target samples are\navailable. In this work, we propose the first Supervised Domain Adaptation\n(SDA) framework tailored for SPE keypoint regression. Building on the Learning\nInvariant Representation and Risk (LIRR) paradigm, our method jointly optimizes\ndomain-invariant representations and task-specific risk using both labeled\nsynthetic and limited labeled real data, thereby reducing generalization error\nunder domain shift. Extensive experiments on the SPEED+ benchmark demonstrate\nthat our approach consistently outperforms source-only, fine-tuning, and oracle\nbaselines. Notably, with only 5% labeled target data, our method matches or\nsurpasses oracle performance trained on larger fractions of labeled data. The\nframework is lightweight, backbone-agnostic, and computationally efficient,\noffering a practical pathway toward robust and deployable spacecraft pose\nestimation in real-world space environments.", "AI": {"tldr": "This paper introduces a Supervised Domain Adaptation (SDA) framework tailored for spacecraft pose estimation, addressing the domain gap challenge between synthetic and real data.", "motivation": "To overcome the synthetic-to-real domain gap in spacecraft pose estimation (SPE), which limits the robustness of existing unsupervised domain adaptation techniques when a small amount of labeled real data is available.", "method": "The method combines Learning Invariant Representation and Risk (LIRR) to jointly optimize domain-invariant representations and task-specific risk, using labeled synthetic data and a small portion of labeled real data.", "result": "Experiments on the SPEED+ benchmark show that the proposed method outperforms various baselines, achieving results comparable to oracle models with only 5% labeled real data.", "conclusion": "The framework is lightweight, backbone-agnostic, computationally efficient, and bridges the domain gap effectively, enabling practical use in real-world spacecraft pose estimation scenarios."}}
{"id": "2509.14010", "pdf": "https://arxiv.org/pdf/2509.14010", "abs": "https://arxiv.org/abs/2509.14010", "authors": ["Zong Chen", "Shaoyang Li", "Ben Liu", "Min Li", "Zhouping Yin", "Yiqun Li"], "title": "Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization", "categories": ["cs.RO"], "comment": null, "summary": "Wheel-legged robots with integrated manipulators hold great promise for\nmobile manipulation in logistics, industrial automation, and human-robot\ncollaboration. However, unified control of such systems remains challenging due\nto the redundancy in degrees of freedom, complex wheel-ground contact dynamics,\nand the need for seamless coordination between locomotion and manipulation. In\nthis work, we present the design and whole-body motion control of an\nomnidirectional wheel-legged quadrupedal robot equipped with a dexterous\nmanipulator. The proposed platform incorporates independently actuated steering\nmodules and hub-driven wheels, enabling agile omnidirectional locomotion with\nhigh maneuverability in structured environments. To address the challenges of\ncontact-rich interaction, we develop a contact-aware whole-body dynamic\noptimization framework that integrates point-contact modeling for manipulation\nwith line-contact modeling for wheel-ground interactions. A warm-start strategy\nis introduced to accelerate online optimization, ensuring real-time feasibility\nfor high-dimensional control. Furthermore, a unified kinematic model tailored\nfor the robot's 4WIS-4WID actuation scheme eliminates the need for mode\nswitching across different locomotion strategies, improving control consistency\nand robustness. Simulation and experimental results validate the effectiveness\nof the proposed framework, demonstrating agile terrain traversal, high-speed\nomnidirectional mobility, and precise manipulation under diverse scenarios,\nunderscoring the system's potential for factory automation, urban logistics,\nand service robotics in semi-structured environments.", "AI": {"tldr": "This paper discusses the design and whole-body motion control of an omnidirectional wheel-legged quadrupedal robot that includes a dexterous manipulator, addressing challenges with a unified and optimized control framework.", "motivation": "To overcome the challenges in controlling wheel-legged robots with manipulators, such as redundancy in degrees of freedom, complex wheel-ground dynamics, and the coordination between locomotion and manipulation, for applications in logistics, industrial automation, and service robotics.", "method": "The researchers utilized a contact-aware whole-body dynamic optimization framework integrating point-contact modeling for manipulation and line-contact modeling for wheel-ground interaction. They also employed a warm-start strategy for real-time optimization and developed a unified kinematic model for seamless control.", "result": "The platform was validated through simulations and experiments, showing agility in terrain traversal, omnidirectional mobility, and precise manipulation, demonstrating its potential across various use cases in semi-structured environments.", "conclusion": "The proposed framework effectively enhances locomotion and manipulation in wheel-legged robots, showcasing its applicability in factory automation, urban logistics, and service robotics."}}
{"id": "2509.14216", "pdf": "https://arxiv.org/pdf/2509.14216", "abs": "https://arxiv.org/abs/2509.14216", "authors": ["Johnny R. Zhang", "Xiaomei Mi", "Gaoyuan Du", "Qianyi Sun", "Shiqi Wang", "Jiaxuan Li", "Wenhua Zhou"], "title": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "categories": ["cs.LG", "cs.AI"], "comment": "69 pages, 10 figures. Preprint", "summary": "Stochastic optimization powers the scalability of modern artificial\nintelligence, spanning machine learning, deep learning, reinforcement learning,\nand large language model training. Yet, existing theory remains largely\nconfined to Hilbert spaces, relying on inner-product frameworks and\northogonality. This paradigm fails to capture non-Euclidean settings, such as\nmirror descent on simplices, Bregman proximal methods for sparse learning,\nnatural gradient descent in information geometry, or\nKullback--Leibler-regularized language model training. Unlike Euclidean-based\nHilbert-space methods, this approach embraces general Banach spaces. This work\nintroduces a pioneering Banach--Bregman framework for stochastic iterations,\nestablishing Bregman geometry as a foundation for next-generation optimization.\nIt (i) provides a unified template via Bregman projections and Bregman--Fejer\nmonotonicity, encompassing stochastic approximation, mirror descent, natural\ngradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations\n($\\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and\nelucidating their acceleration effect; and (iii) delivers convergence theorems\nspanning almost-sure boundedness to geometric rates, validated on synthetic and\nreal-world tasks. Empirical studies across machine learning (UCI benchmarks),\ndeep learning (e.g., Transformer training), reinforcement learning\n(actor--critic), and large language models (WikiText-2 with distilGPT-2) show\nup to 20% faster convergence, reduced variance, and enhanced accuracy over\nclassical baselines. These results position Banach--Bregman geometry as a\ncornerstone unifying optimization theory and practice across core AI paradigms.", "AI": {"tldr": "This paper proposes a Banach-Bregman framework for stochastic optimization, addressing non-Euclidean settings with faster convergence and better performance.", "motivation": "Existing stochastic optimization theories are limited to Hilbert spaces and fail to address important non-Euclidean frameworks like mirror descent and natural gradient methods.", "method": "The authors introduce a Banach-Bregman framework leveraging Bregman geometry, which uses Bregman projections, Fejer monotonicity, super-relaxations, and convergence theorems to unify diverse stochastic techniques.", "result": "Empirical studies show up to 20% faster convergence, reduced variance, and improved accuracy compared to classical methods across applications including machine learning, deep learning, reinforcement learning, and large language models.", "conclusion": "The proposed framework positions Banach-Bregman geometry as foundational for modern optimization, enabling advancements in theory and practice across AI paradigms."}}
{"id": "2509.13795", "pdf": "https://arxiv.org/pdf/2509.13795", "abs": "https://arxiv.org/abs/2509.13795", "authors": ["Jiayu Yuan", "Ming Dai", "Enhui Zheng", "Chao Su", "Nanxing Chen", "Qiming Hu", "Shibo Zhu", "Yibin Cao"], "title": "SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments", "categories": ["cs.CV"], "comment": null, "summary": "Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been\nextensively investigated for Global Navigation Satellite System (GNSS)-denied\nenvironments. However, existing retrieval-based approaches face limitations in\ndataset availability and persistent challenges including suboptimal real-time\nperformance, environmental sensitivity, and limited generalization capability,\nparticularly in dynamic or temporally varying environments. To overcome these\nlimitations, we present a large-scale Multi-Altitude Flight Segments dataset\n(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted\nAdaptive Particle Filter (SWA-PF) method. This approach integrates robust\nsemantic features from both UAV-captured images and satellite imagery through\ntwo key innovations: a semantic weighting mechanism and an optimized particle\nfiltering architecture. Evaluated using our dataset, the proposed method\nachieves 10x computational efficiency gain over feature extraction methods,\nmaintains global positioning errors below 10 meters, and enables rapid 4 degree\nof freedom (4-DoF) pose estimation within seconds using accessible\nlow-resolution satellite maps. Code and dataset will be available at\nhttps://github.com/YuanJiayuuu/SWA-PF.", "AI": {"tldr": "This paper proposes a novel approach for UAV localization in GNSS-denied environments using semantic features and introduces a large-scale dataset for variable altitude scenarios.", "motivation": "To address the limitations of existing UAV localization systems in dynamic or challenging environments, such as suboptimal performance and environmental sensitivity.", "method": "The authors introduce a Semantic-Weighted Adaptive Particle Filter (SWA-PF), which leverages semantic features from UAV images and satellite maps, integrating innovative weighting and filtering mechanisms.", "result": "The method provides a 10x computational efficiency improvement and achieves global positioning errors below 10 meters for 4-DoF pose estimation, validated on the new dataset.", "conclusion": "The approach demonstrates practicality and reliability for real-time UAV localization under variable altitudes, especially in GNSS-denied settings."}}
{"id": "2509.14025", "pdf": "https://arxiv.org/pdf/2509.14025", "abs": "https://arxiv.org/abs/2509.14025", "authors": ["Rui Huang", "Zhiyu Gao", "Siyu Tang", "Jialin Zhang", "Lei He", "Ziqian Zhang", "Lin Zhao"], "title": "TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Modular Aerial Robot Systems (MARS) consist of multiple drone modules that\nare physically bound together to form a single structure for flight. Exploiting\nstructural redundancy, MARS can be reconfigured into different formations to\nmitigate unit or rotor failures and maintain stable flight. Prior work on MARS\nself-reconfiguration has solely focused on maximizing controllability margins\nto tolerate a single rotor or unit fault for rectangular-shaped MARS. We\npropose TransforMARS, a general fault-tolerant reconfiguration framework that\ntransforms arbitrarily shaped MARS under multiple rotor and unit faults while\nensuring continuous in-air stability. Specifically, we develop algorithms to\nfirst identify and construct minimum controllable assemblies containing faulty\nunits. We then plan feasible disassembly-assembly sequences to transport MARS\nunits or subassemblies to form target configuration. Our approach enables more\nflexible and practical feasible reconfiguration. We validate TransforMARS in\nchallenging arbitrarily shaped MARS configurations, demonstrating substantial\nimprovements over prior works in both the capacity of handling diverse\nconfigurations and the number of faults tolerated. The videos and source code\nof this work are available at the anonymous repository:\nhttps://anonymous.4open.science/r/TransforMARS-1030/", "AI": {"tldr": "The paper introduces TransforMARS, a framework for reconfiguring modular aerial robots to handle multiple faults while maintaining stable flight.", "motivation": "To address limitations of previous systems that focused only on simple faults and specific shapes, providing a more general solution for fault-tolerant reconfigurations in modular aerial robots.", "method": "Developed algorithms for identifying controllable assemblies, planning disassembly-assembly sequences, and enabling fault-tolerant reconfigurations in arbitrarily shaped MARS.", "result": "Demonstrated improvements in handling diverse configurations and fault tolerances, validated with challenging tests and practical scenarios.", "conclusion": "TransforMARS extends fault-tolerance capability and reconfiguration flexibility in MARS, improving reliability and versatility over prior methods."}}
{"id": "2509.14219", "pdf": "https://arxiv.org/pdf/2509.14219", "abs": "https://arxiv.org/abs/2509.14219", "authors": ["Jiaqi Yao", "Lewis Mitchell", "John Maclean", "Hemanth Saratchandran"], "title": "Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "comment": null, "summary": "Data-driven modeling of nonlinear dynamical systems is often hampered by\nmeasurement noise. We propose a denoising framework, called Runge-Kutta and\nTotal Variation Based Implicit Neural Representation (RKTV-INR), that\nrepresents the state trajectory with an implicit neural representation (INR)\nfitted directly to noisy observations. Runge-Kutta integration and total\nvariation are imposed as constraints to ensure that the reconstructed state is\na trajectory of a dynamical system that remains close to the original data. The\ntrained INR yields a clean, continuous trajectory and provides accurate\nfirst-order derivatives via automatic differentiation. These denoised states\nand derivatives are then supplied to Sparse Identification of Nonlinear\nDynamics (SINDy) to recover the governing equations. Experiments demonstrate\neffective noise suppression, precise derivative estimation, and reliable system\nidentification.", "AI": {"tldr": "This paper introduces RKTV-INR, a novel framework combining implicit neural representations (INRs) with Runge-Kutta integration and total variation constraints for denoising noisy dynamical system trajectories, making them suitable for accurate system identification.", "motivation": "Measurement noise often hinders the accurate modeling of nonlinear dynamical systems from data. The authors aim to provide a solution to suppress noise and improve the reliability of system identification.", "method": "The proposed RKTV-INR method uses implicit neural representations (INRs) to fit noisy observations. Constraints like Runge-Kutta integration and total variation ensure the cleaned trajectory aligns with the dynamical system. The framework then applies Sparse Identification of Nonlinear Dynamics (SINDy) to identify governing equations.", "result": "Experiments validate the framework's ability to suppress noise effectively, deliver precise derivative estimations, and allow reliable identification of underlying dynamical systems.", "conclusion": "RKTV-INR successfully mitigates measurement noise while improving trajectory reconstruction and system identification, showcasing its practicality in handling noisy datasets in nonlinear dynamical system modeling."}}
{"id": "2509.13801", "pdf": "https://arxiv.org/pdf/2509.13801", "abs": "https://arxiv.org/abs/2509.13801", "authors": ["Wenlve Zhou", "Zhiheng Zhou", "Tiantao Xian", "Yikui Zhai", "Weibin Wu", "Biyun Ma"], "title": "Masked Feature Modeling Enhances Adaptive Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Unsupervised domain adaptation (UDA) for semantic segmentation aims to\ntransfer models from a labeled source domain to an unlabeled target domain.\nWhile auxiliary self-supervised tasks-particularly contrastive learning-have\nimproved feature discriminability, masked modeling approaches remain\nunderexplored in this setting, largely due to architectural incompatibility and\nmisaligned optimization objectives. We propose Masked Feature Modeling (MFM), a\nnovel auxiliary task that performs feature masking and reconstruction directly\nin the feature space. Unlike existing masked modeling methods that reconstruct\nlow-level inputs or perceptual features (e.g., HOG or visual tokens), MFM\naligns its learning target with the main segmentation task, ensuring\ncompatibility with standard architectures like DeepLab and DAFormer without\nmodifying the inference pipeline. To facilitate effective reconstruction, we\nintroduce a lightweight auxiliary module, Rebuilder, which is trained jointly\nbut discarded during inference, adding zero computational overhead at test\ntime. Crucially, MFM leverages the segmentation decoder to classify the\nreconstructed features, tightly coupling the auxiliary objective with the\npixel-wise prediction task to avoid interference with the primary task.\nExtensive experiments across various architectures and UDA benchmarks\ndemonstrate that MFM consistently enhances segmentation performance, offering a\nsimple, efficient, and generalizable strategy for unsupervised domain-adaptive\nsemantic segmentation.", "AI": {"tldr": "This paper introduces Masked Feature Modeling (MFM), a novel auxiliary task for unsupervised domain adaptation in semantic segmentation that enhances performance via feature masking and reconstruction directly in feature space while maintaining architectural compatibility and zero inference overhead.", "motivation": "To address the challenges of transferring models from a labeled source domain to an unlabeled target domain in unsupervised domain adaptation, particularly by improving feature discriminability and aligning auxiliary learning tasks with the main segmentation objective.", "method": "The authors propose Masked Feature Modeling (MFM), which involves masking and reconstructing features directly in feature space. They introduce a lightweight auxiliary module named Rebuilder for reconstruction, coupled with the segmentation decoder to classify reconstructed features without altering the inference pipeline.", "result": "Experiments show that MFM improves segmentation performance consistently across various architectures and UDA benchmarks. It offers efficient, generalizable benefits with zero computational overhead during inference.", "conclusion": "MFM provides a simple yet effective strategy for enhancing unsupervised domain-adaptive semantic segmentation, aligning auxiliary and primary objectives without complexity or architectural modifications."}}
{"id": "2509.14040", "pdf": "https://arxiv.org/pdf/2509.14040", "abs": "https://arxiv.org/abs/2509.14040", "authors": ["Zewen Yang", "Xiaobing Dai", "Dongfa Zhang", "Yu Li", "Ziyang Meng", "Bingkun Huang", "Hamid Sadeghian", "Sami Haddadin"], "title": "Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Learning from demonstration allows robots to acquire complex skills from\nhuman demonstrations, but conventional approaches often require large datasets\nand fail to generalize across coordinate transformations. In this paper, we\npropose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)\nlearning framework that enables robots to perform human-guided automated\ncontrol from a single motion prompt. A dataset-construction strategy based on\ncoordinate transformations is introduced that enforces invariance to\ntranslation, rotation, and scaling, while supporting multi-step predictions.\nMoreover, GeoGP is robust to variations in the user's motion prompt and\nsupports multi-skill autonomy. We validate the proposed approach through\nnumerical simulations with the designed user graphical interface and two\nreal-world robotic experiments, which demonstrate that the proposed method is\neffective, generalizes across tasks, and significantly reduces the\ndemonstration burden. Project page is available at:\nhttps://prompt2auto.github.io", "AI": {"tldr": "The paper introduces Prompt2Auto, a system enabling robots to learn tasks from a single demonstration through geometry-invariant Gaussian processes.", "motivation": "Current robot learning methods require large datasets and struggle with coordinate transformations, limiting efficiency and generalization.", "method": "The authors propose a geometry-invariant Gaussian process framework (GeoGP) coupled with a dataset-construction strategy that ensures invariance to translation, rotation, and scaling.", "result": "Simulations and real-world robotic experiments show that Prompt2Auto generalizes well across tasks, reduces the need for extensive demonstrations, and supports multi-step/multi-skill autonomy.", "conclusion": "Prompt2Auto effectively addresses the challenges of robot learning by reducing data requirements and ensuring geometric invariance, enhancing its practical applicability."}}
{"id": "2509.13836", "pdf": "https://arxiv.org/pdf/2509.13836", "abs": "https://arxiv.org/abs/2509.13836", "authors": ["Weihang Wang", "Xinhao Li", "Ziyue Wang", "Yan Pang", "Jielei Zhang", "Peiyi Li", "Qiang Zhang", "Longwen Gao"], "title": "Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted by EMNLP2025 Finding", "summary": "Object hallucination in Large Vision-Language Models (LVLMs) significantly\nimpedes their real-world applicability. As the primary component for accurately\ninterpreting visual information, the choice of visual encoder is pivotal. We\nhypothesize that the diverse training paradigms employed by different visual\nencoders instill them with distinct inductive biases, which leads to their\ndiverse hallucination performances. Existing benchmarks typically focus on\ncoarse-grained hallucination detection and fail to capture the diverse\nhallucinations elaborated in our hypothesis. To systematically analyze these\neffects, we introduce VHBench-10, a comprehensive benchmark with approximately\n10,000 samples for evaluating LVLMs across ten fine-grained hallucination\ncategories. Our evaluations confirm encoders exhibit unique hallucination\ncharacteristics. Building on these insights and the suboptimality of simple\nfeature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.\nIt employs global visual features to generate routing signals, dynamically\naggregating visual features from multiple specialized experts. Comprehensive\nexperiments confirm the effectiveness of VisionWeaver in significantly reducing\nhallucinations and improving overall model performance.", "AI": {"tldr": "This paper studies object hallucination issues in Large Vision-Language Models (LVLMs), introduces a detailed benchmark, and presents a method to reduce hallucinations.", "motivation": "Address object hallucination problems in LVLMs due to differing inductive biases of visual encoders.", "method": "Introduced VHBench-10 for fine-grained evaluation of hallucinations and proposed VisionWeaver, a Context-Aware Routing Network that dynamically aggregates features.", "result": "Validated that different encoders exhibit distinct hallucination patterns and demonstrated improvement in performance and reduction in hallucinations using VisionWeaver.", "conclusion": "VisionWeaver effectively decreases hallucinations in LVLMs and improves their real-world applicability."}}
{"id": "2509.14223", "pdf": "https://arxiv.org/pdf/2509.14223", "abs": "https://arxiv.org/abs/2509.14223", "authors": ["Dmitrii Krasheninnikov", "Richard E. Turner", "David Krueger"], "title": "Language models' activations linearly encode training-order recency", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We show that language models' activations linearly encode when information\nwas learned during training. Our setup involves creating a model with a known\ntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint but\notherwise similar datasets about named entities. We find that the average\nactivations of test samples for the six training datasets encode the training\norder: when projected into a 2D subspace, these centroids are arranged exactly\nin the order of training and lie on a straight line. Further, we show that\nlinear probes can accurately (~90%) distinguish \"early\" vs. \"late\" entities,\ngeneralizing to entities unseen during the probes' own training. The model can\nalso be fine-tuned to explicitly report an unseen entity's training stage (~80%\naccuracy). Interestingly, this temporal signal does not seem attributable to\nsimple differences in activation magnitudes, losses, or model confidence. Our\npaper demonstrates that models are capable of differentiating information by\nits acquisition time, and carries significant implications for how they might\nmanage conflicting data and respond to knowledge modifications.", "AI": {"tldr": "The paper demonstrates that language model activations linearly encode the temporal order of information acquisition during training, verified through a controlled experiment with sequential fine-tuning.", "motivation": "The authors aim to investigate how language models encode knowledge over time, especially its implications for managing conflicting data and responding to updates.", "method": "The study sequentially fine-tunes Llama-3.2-1B on six disjoint datasets about named entities and analyzes the average activations of test samples using 2D subspace projections and linear probes.", "result": "Activations encode the training order, forming centroids in the 2D subspace. Linear probes differentiate temporal stages (~90% accuracy), and the model can predict unseen entities' training stages (~80% accuracy).", "conclusion": "Language models inherently differentiate information by acquisition time. This finding carries implications for handling dynamic or conflicting data in model training."}}
{"id": "2509.13809", "pdf": "https://arxiv.org/pdf/2509.13809", "abs": "https://arxiv.org/abs/2509.13809", "authors": ["Nick Theisen", "Kenny Schlegel", "Dietrich Paulus", "Peer Neubert"], "title": "Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET", "categories": ["cs.CV"], "comment": "Accepted for publication at IEEE CASE 2025", "summary": "The classification of pixel spectra of hyperspectral images, i.e. spectral\nclassification, is used in many fields ranging from agricultural, over medical\nto remote sensing applications and is currently also expanding to areas such as\nautonomous driving. Even though for full hyperspectral images the\nbest-performing methods exploit spatial-spectral information, performing\nclassification solely on spectral information has its own advantages, e.g.\nsmaller model size and thus less data required for training. Moreover, spectral\ninformation is complementary to spatial information and improvements on either\npart can be used to improve spatial-spectral approaches in the future.\nRecently, 1D-Justo-LiuNet was proposed as a particularly efficient model with\nvery few parameters, which currently defines the state of the art in spectral\nclassification. However, we show that with limited training data the model\nperformance deteriorates. Therefore, we investigate MiniROCKET and\nHDC-MiniROCKET for spectral classification to mitigate that problem. The model\nextracts well-engineered features without trainable parameters in the feature\nextraction part and is therefore less vulnerable to limited training data. We\nshow that even though MiniROCKET has more parameters it outperforms\n1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the\ngeneral case", "AI": {"tldr": "The paper addresses the challenge of spectral classification in hyperspectral images and proposes MiniROCKET and HDC-MiniROCKET as robust alternatives to the state-of-the-art.", "motivation": "Improve spectral classification methods in hyperspectral imaging to handle limited training data effectively.", "method": "Proposes MiniROCKET and HDC-MiniROCKET, models with non-trainable feature extraction components, enhancing robustness in limited data scenarios.", "result": "MiniROCKET outperforms 1D-Justo-LiuNet in scenarios with limited training data, while being comparable in general cases.", "conclusion": "MiniROCKET-based methods offer a promising direction for spectral classification, especially in contexts with restricted training data availability."}}
{"id": "2509.14063", "pdf": "https://arxiv.org/pdf/2509.14063", "abs": "https://arxiv.org/abs/2509.14063", "authors": ["Sundhar Vinodh Sangeetha", "Chih-Yuan Chiu", "Sarah H. Q. Li", "Shreyas Kousik"], "title": "Language Conditioning Improves Accuracy of Aircraft Goal Prediction in Untowered Airspace", "categories": ["cs.RO"], "comment": "The last two authors advised equally. Submitted to the 2026 IEEE\n  International Conference on Robotics and Automation. 8 pages, 6 figures", "summary": "Autonomous aircraft must safely operate in untowered airspace, where\ncoordination relies on voice-based communication among human pilots. Safe\noperation requires an aircraft to predict the intent, and corresponding goal\nlocation, of other aircraft. This paper introduces a multimodal framework for\naircraft goal prediction that integrates natural language understanding with\nspatial reasoning to improve autonomous decision-making in such environments.\nWe leverage automatic speech recognition and large language models to\ntranscribe and interpret pilot radio calls, identify aircraft, and extract\ndiscrete intent labels. These intent labels are fused with observed\ntrajectories to condition a temporal convolutional network and Gaussian mixture\nmodel for probabilistic goal prediction. Our method significantly reduces goal\nprediction error compared to baselines that rely solely on motion history,\ndemonstrating that language-conditioned prediction increases prediction\naccuracy. Experiments on a real-world dataset from an untowered airport\nvalidate the approach and highlight its potential to enable socially aware,\nlanguage-conditioned robotic motion planning.", "AI": {"tldr": "The paper proposes a framework for autonomous aircraft that integrates natural language understanding with spatial reasoning for improved goal prediction and decision-making in untowered airspaces.", "motivation": "Enable autonomous aircraft to safely operate in untowered airspace by predicting pilot intent and goal locations through multimodal approaches.", "method": "The framework uses automatic speech recognition, large language models to process pilot communication, labels intents, and combines them with observed trajectories via a temporal convolutional network and Gaussian mixture model to predict aircraft goals probabilistically.", "result": "The approach significantly reduced goal prediction error compared to motion-history based methods and demonstrated superior prediction accuracy.", "conclusion": "Language-conditioned prediction enhances autonomous decision-making in airspaces, providing socially-aware robotic planning validated through real-world data."}}
{"id": "2509.13499", "pdf": "https://arxiv.org/pdf/2509.13499", "abs": "https://arxiv.org/abs/2509.13499", "authors": ["Susobhan Ghosh", "Bhanu T. Gulapalli", "Daiqi Gao", "Asim Gazi", "Anna Trella", "Ziping Xu", "Kelly Zhang", "Susan A. Murphy"], "title": "Reproducible workflow for online AI in digital health", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Online artificial intelligence (AI) algorithms are an important component of\ndigital health interventions. These online algorithms are designed to\ncontinually learn and improve their performance as streaming data is collected\non individuals. Deploying online AI presents a key challenge: balancing\nadaptability of online AI with reproducibility. Online AI in digital\ninterventions is a rapidly evolving area, driven by advances in algorithms,\nsensors, software, and devices. Digital health intervention development and\ndeployment is a continuous process, where implementation - including the AI\ndecision-making algorithm - is interspersed with cycles of re-development and\noptimization. Each deployment informs the next, making iterative deployment a\ndefining characteristic of this field. This iterative nature underscores the\nimportance of reproducibility: data collected across deployments must be\naccurately stored to have scientific utility, algorithm behavior must be\nauditable, and results must be comparable over time to facilitate scientific\ndiscovery and trustworthy refinement. This paper proposes a reproducible\nscientific workflow for developing, deploying, and analyzing online AI\ndecision-making algorithms in digital health interventions. Grounded in\npractical experience from multiple real-world deployments, this workflow\naddresses key challenges to reproducibility across all phases of the online AI\nalgorithm development life-cycle.", "AI": {"tldr": "The paper introduces a scientific workflow for ensuring reproducibility in developing and deploying online AI algorithms in digital health interventions.", "motivation": "To address the challenge of balancing adaptability and reproducibility in online AI algorithms used in digital health interventions.", "method": "The authors propose a reproducible scientific workflow informed by their practical experience from multiple real-world deployments.", "result": "The workflow tackles key reproducibility challenges across different stages of online AI algorithm development.", "conclusion": "This approach ensures reproducibility, facilitates scientific discovery, and enables trustworthy algorithm refinement over iterative deployments."}}
{"id": "2509.13853", "pdf": "https://arxiv.org/pdf/2509.13853", "abs": "https://arxiv.org/abs/2509.13853", "authors": ["Shun Huang", "Zhihua Fang", "Liang He"], "title": "Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection", "categories": ["cs.SD", "cs.CL"], "comment": "Accept ICASSP 2025", "summary": "Unsupervised anomalous sound detection aims to detect unknown anomalous\nsounds by training a model using only normal audio data. Despite advancements\nin self-supervised methods, the issue of frequent false alarms when handling\nsamples of the same type from different machines remains unresolved. This paper\nintroduces a novel training technique called one-stage supervised contrastive\nlearning (OS-SCL), which significantly addresses this problem by perturbing\nfeatures in the embedding space and employing a one-stage noisy supervised\ncontrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved\n94.64\\% AUC, 88.42\\% pAUC, and 89.24\\% mAUC using only Log-Mel features.\nAdditionally, a time-frequency feature named TFgram is proposed, which is\nextracted from raw audio. This feature effectively captures critical\ninformation for anomalous sound detection, ultimately achieving 95.71\\% AUC,\n90.23\\% pAUC, and 91.23\\% mAUC. The source code is available at:\n\\underline{www.github.com/huangswt/OS-SCL}.", "AI": {"tldr": "This paper improves unsupervised anomalous sound detection by introducing a novel training technique called one-stage supervised contrastive learning (OS-SCL) and a new feature representation, achieving significant performance improvement.", "motivation": "To address the issue of frequent false alarms in anomalous sound detection, particularly for samples of the same type from different machines.", "method": "The authors propose a training method called OS-SCL, which perturbs features in the embedding space and applies noisy supervised contrastive learning. Additionally, a new time-frequency feature, TFgram, is introduced to enhance data representation.", "result": "The OS-SCL method showed notable performance on the DCASE 2020 Challenge Task 2, with AUC scores of 94.64% (Log-Mel features) and 95.71% (TFgram), as well as improvements in pAUC and mAUC metrics.", "conclusion": "The OS-SCL method and TFgram feature representation significantly enhance the detection of anomalous sounds, providing a robust solution to the false alarm issue in unsupervised settings."}}
{"id": "2509.13834", "pdf": "https://arxiv.org/pdf/2509.13834", "abs": "https://arxiv.org/abs/2509.13834", "authors": ["Nguyen Lan Vi Vu", "Thanh-Huy Nguyen", "Thien Nguyen", "Daisuke Kihara", "Tianyang Wang", "Xingjian Li", "Min Xu"], "title": "Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation", "categories": ["cs.CV"], "comment": "Accepted to BMVC 2025", "summary": "Semi-supervised learning has been employed to alleviate the need for\nextensive labeled data for histopathology image segmentation, but existing\nmethods struggle with noisy pseudo-labels due to ambiguous gland boundaries and\nmorphological misclassification. This paper introduces Semi-MOE, to the best of\nour knowledge, the first multi-task Mixture-of-Experts framework for\nsemi-supervised histopathology image segmentation. Our approach leverages three\nspecialized expert networks: A main segmentation expert, a signed distance\nfield regression expert, and a boundary prediction expert, each dedicated to\ncapturing distinct morphological features. Subsequently, the Multi-Gating\nPseudo-labeling module dynamically aggregates expert features, enabling a\nrobust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate\nmanual tuning while dynamically balancing multiple learning objectives, we\npropose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and\nCRAG benchmarks show that our method outperforms state-of-the-art approaches in\nlow-label settings, highlighting the potential of MoE-based architectures in\nadvancing semi-supervised segmentation. Our code is available at\nhttps://github.com/vnlvi2k3/Semi-MoE.", "AI": {"tldr": "Semi-MOE is a novel framework for histopathology image segmentation that uses a Mixture-of-Experts approach to overcome pseudo-label noise and achieves state-of-the-art results in semi-supervised settings.", "motivation": "The paper addresses challenges in histopathology image segmentation, particularly the noisy pseudo-labels caused by ambiguous gland boundaries and morphological misclassification in semi-supervised learning.", "method": "The proposed framework, Semi-MOE, incorporates three specialized expert networks focusing on segmentation, signed distance field regression, and boundary prediction. It uses a Multi-Gating Pseudo-labeling module for feature aggregation and an Adaptive Multi-Objective Loss to balance learning objectives dynamically.", "result": "Extensive experiments on GlaS and CRAG benchmarks demonstrate that Semi-MOE surpasses existing state-of-the-art methods in low-label scenarios.", "conclusion": "Semi-MOE showcases the effectiveness of Mixture-of-Experts architectures in advancing semi-supervised histopathology image segmentation and provides robust results with reduced manual tuning."}}
{"id": "2509.14075", "pdf": "https://arxiv.org/pdf/2509.14075", "abs": "https://arxiv.org/abs/2509.14075", "authors": ["Yu Li", "Hamid Sadeghian", "Zewen Yang", "Valentin Le Mesle", "Sami Haddadin"], "title": "Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Robotic-assisted minimally invasive surgery (RAMIS) requires precise\nenforcement of the remote center of motion (RCM) constraint to ensure safe tool\nmanipulation through a trocar. Achieving this constraint under dynamic and\ninteractive conditions remains challenging, as existing control methods either\nlack robustness at the torque level or do not guarantee consistent RCM\nconstraint satisfaction. This paper proposes a constraint-consistent torque\ncontroller that treats the RCM as a rheonomic holonomic constraint and embeds\nit into a projection-based inverse-dynamics framework. The method unifies\ntask-level and kinematic formulations, enabling accurate tool-tip tracking\nwhile maintaining smooth and efficient torque behavior. The controller is\nvalidated both in simulation and on a RAMIS training platform, and is\nbenchmarked against state-of-the-art approaches. Results show improved RCM\nconstraint satisfaction, reduced required torque, and robust performance by\nimproving joint torque smoothness through the consistency formulation under\nclinically relevant scenarios, including spiral trajectories, variable\ninsertion depths, moving trocars, and human interaction. These findings\ndemonstrate the potential of constraint-consistent torque control to enhance\nsafety and reliability in surgical robotics. The project page is available at:\nhttps://rcmpc-cube.github.io", "AI": {"tldr": "This paper proposes a new torque controller to ensure precise robotic tool manipulation in minimally invasive surgeries.", "motivation": "Achieving reliable and dynamic satisfaction of the remote center of motion (RCM) constraint in robotic-assisted surgery remains a challenge.", "method": "A constraint-consistent torque controller is developed using a projection-based inverse-dynamics framework, embedding the RCM as a rheonomic holonomic constraint.", "result": "The controller demonstrated improved RCM satisfaction, reduced torque requirements, and robust torque behavior during simulations and real-world tests.", "conclusion": "This approach enhances safety and reliability in robotic-assisted surgical operations by ensuring consistent constraint satisfaction."}}
{"id": "2509.14230", "pdf": "https://arxiv.org/pdf/2509.14230", "abs": "https://arxiv.org/abs/2509.14230", "authors": ["Mengting Ai", "Tianxin Wei", "Sirui Chen", "Jingrui He"], "title": "NIRVANA: Structured pruning reimagined for large language models compression", "categories": ["cs.LG"], "comment": null, "summary": "Structured pruning of large language models (LLMs) offers substantial\nefficiency improvements by removing entire hidden units, yet current approaches\noften suffer from significant performance degradation, particularly in\nzero-shot settings, and necessitate costly recovery techniques such as\nsupervised fine-tuning (SFT) or adapter insertion. To address these critical\nshortcomings, we introduce NIRVANA, a novel pruning method explicitly designed\nto balance immediate zero-shot accuracy preservation with robust fine-tuning\ncapability. Leveraging a first-order saliency criterion derived from the Neural\nTangent Kernel under Adam optimization dynamics, NIRVANA provides a\ntheoretically grounded pruning strategy that respects essential model training\nbehaviors. To further address the unique challenges posed by structured\npruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across\nlayers and modules (attention vs. MLP), which adjusts pruning intensity between\nmodules in a globally balanced manner. Additionally, to mitigate the high\nsensitivity of pruning decisions to calibration data quality, we propose a\nsimple yet effective KL divergence-based calibration data selection strategy,\nensuring more reliable and task-agnostic pruning outcomes. Comprehensive\nexperiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA\noutperforms existing structured pruning methods under equivalent sparsity\nconstraints, providing a theoretically sound and practical approach to LLM\ncompression. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.", "AI": {"tldr": "NIRVANA is a structured pruning method for large language models (LLMs) that aims to maintain zero-shot accuracy while enabling effective fine-tuning, outperforming existing techniques under equivalent sparsity constraints.", "motivation": "To tackle the inefficiencies and performance degradation associated with structured pruning of LLMs, and to design a method that balances immediate accuracy preservation and fine-tuning capabilities.", "method": "NIRVANA combines a first-order saliency criterion based on the Neural Tangent Kernel with an adaptive sparsity allocation mechanism and a KL divergence-based calibration data selection strategy for reliable and effective pruning.", "result": "NIRVANA demonstrated superior performance compared to existing pruning methods on Llama3, Qwen, and T5 models by maintaining higher zero-shot accuracy and optimizing compression efficiently.", "conclusion": "NIRVANA offers a theoretically grounded, practical solution for structured pruning of LLMs, addressing existing limitations and improving efficiency without sacrificing performance. Its code is publicly available for adoption."}}
{"id": "2509.14082", "pdf": "https://arxiv.org/pdf/2509.14082", "abs": "https://arxiv.org/abs/2509.14082", "authors": ["Valerii Serpiva", "Artem Lykov", "Faryal Batool", "Vladislav Kozlovskiy", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video", "categories": ["cs.RO"], "comment": "Submitted to conference", "summary": "We present FlightDiffusion, a diffusion-model-based framework for training\nautonomous drones from first-person view (FPV) video. Our model generates\nrealistic video sequences from a single frame, enriched with corresponding\naction spaces to enable reasoning-driven navigation in dynamic environments.\nBeyond direct policy learning, FlightDiffusion leverages its generative\ncapabilities to synthesize diverse FPV trajectories and state-action pairs,\nfacilitating the creation of large-scale training datasets without the high\ncost of real-world data collection. Our evaluation demonstrates that the\ngenerated trajectories are physically plausible and executable, with a mean\nposition error of 0.25 m (RMSE 0.28 m) and a mean orientation error of 0.19 rad\n(RMSE 0.24 rad). This approach enables improved policy learning and dataset\nscalability, leading to superior performance in downstream navigation tasks.\nResults in simulated environments highlight enhanced robustness, smoother\ntrajectory planning, and adaptability to unseen conditions. An ANOVA revealed\nno statistically significant difference between performance in simulation and\nreality (F(1, 16) = 0.394, p = 0.541), with success rates of M = 0.628 (SD =\n0.162) and M = 0.617 (SD = 0.177), respectively, indicating strong sim-to-real\ntransfer. The generated datasets provide a valuable resource for future UAV\nresearch. This work introduces diffusion-based reasoning as a promising\nparadigm for unifying navigation, action generation, and data synthesis in\naerial robotics.", "AI": {"tldr": "The paper introduces FlightDiffusion, a framework using diffusion models to train drone navigation through FPV video synthesis, offering improved real-world adaptability and dataset creation.", "motivation": "To provide an efficient and scalable method for training autonomous drones using FPV videos while reducing the reliance on costly real-world data.", "method": "A diffusion model generates realistic FPV video sequences and action spaces, enabling both direct policy learning and the creation of large-scale synthetic training datasets.", "result": "Generated drone trajectories are highly feasible and improve training effectiveness. Experiments show strong sim-to-real transfer with no significant performance gap between simulated and real-world environments.", "conclusion": "FlightDiffusion successfully merges navigation, action reasoning, and data synthesis into a cohesive framework, advancing autonomous drone training and research capabilities."}}
{"id": "2509.13550", "pdf": "https://arxiv.org/pdf/2509.13550", "abs": "https://arxiv.org/abs/2509.13550", "authors": ["Phillipe R. Sampaio"], "title": "Complexity Bounds for Smooth Convex Multiobjective Optimization", "categories": ["math.OC", "cs.AI"], "comment": "16 pages", "summary": "We study the oracle complexity of finding $\\varepsilon$-Pareto stationary\npoints in smooth multiobjective optimization with $m$ objectives. The progress\nmetric is the Pareto stationarity gap $\\mathcal{G}(x)$ (the norm of an optimal\nconvex combination of gradients). Our contributions are fourfold. (i) For\nstrongly convex objectives, any span first-order method (iterates lie in the\nspan of past gradients) exhibits linear convergence no faster than\n$\\exp(-\\Theta(T/\\sqrt{\\kappa}))$ after $T$ oracle calls, where $\\kappa$ is the\ncondition number, implying $\\Theta(\\sqrt{\\kappa}\\log(1/\\varepsilon))$\niterations; this matches classical accelerated upper bounds. (ii) For convex\nproblems and oblivious one-step methods (a fixed scalarization with\npre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best\ngradient norm among the first $T$ iterates. (iii) Although accelerated gradient\ndescent is outside this restricted class, it is an oblivious span method and\nattains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex\nproblems and general span methods with adaptive scalarizations, we establish a\nuniversal lower bound of order $1/T^{2}$ on the gradient norm of the final\niterate after $T$ steps, highlighting a gap between known upper bounds and\nworst-case guarantees. All bounds hold on non-degenerate instances with\ndistinct objectives and non-singleton Pareto fronts; rates are stated up to\nuniversal constants and natural problem scaling.", "AI": {"tldr": "The paper investigates oracle complexity in smooth multiobjective optimization and derives bounds on finding Pareto stationary points while revealing gaps between upper and lower convergence rates.", "motivation": "To understand the complexity of solving multiobjective optimization problems by analyzing how quickly an algorithm can reach Pareto stationary points under different conditions, and to address gaps between theoretical bounds and practical performance.", "method": "The study uses mathematical analysis and derives lower and upper bounds for convergence rates using span methods, convex and strongly convex conditions, and distinguishes between oblivious and adaptive scalarization techniques.", "result": "Four major results include: linear convergence bounds dependent on the condition number for strongly convex problems, $1/T$ bounds for oblivious one-step convex methods, $1/T$ performance of accelerated gradient descent, and a universal $1/T^2$ lower bound for adaptive scalarization convex span methods.", "conclusion": "The derived lower bounds reveal fundamental limitations on convergence rates for various methods and demonstrate gaps between theoretical and achievable performance in multiobjective optimization, guiding algorithmic design and analysis."}}
{"id": "2509.13957", "pdf": "https://arxiv.org/pdf/2509.13957", "abs": "https://arxiv.org/abs/2509.13957", "authors": ["Sunkyung Lee", "Seongmin Park", "Jonghyo Kim", "Mincheol Yoon", "Jongwuk Lee"], "title": "Enhancing Time Awareness in Generative Recommendation", "categories": ["cs.IR", "cs.CL"], "comment": "EMNLP 2025 (Findings)", "summary": "Generative recommendation has emerged as a promising paradigm that formulates\nthe recommendations into a text-to-text generation task, harnessing the vast\nknowledge of large language models. However, existing studies focus on\nconsidering the sequential order of items and neglect to handle the temporal\ndynamics across items, which can imply evolving user preferences. To address\nthis limitation, we propose a novel model, Generative Recommender Using Time\nawareness (GRUT), effectively capturing hidden user preferences via various\ntemporal signals. We first introduce Time-aware Prompting, consisting of two\nkey contexts. The user-level temporal context models personalized temporal\npatterns across timestamps and time intervals, while the item-level transition\ncontext provides transition patterns across users. We also devise Trend-aware\nInference, a training-free method that enhances rankings by incorporating trend\ninformation about items with generation likelihood. Extensive experiments\ndemonstrate that GRUT outperforms state-of-the-art models, with gains of up to\n15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The\nsource code is available at https://github.com/skleee/GRUT.", "AI": {"tldr": "This paper introduces GRUT, a time-aware generative recommender model that incorporates temporal dynamics to improve recommendation quality.", "motivation": "Current generative recommender systems fail to effectively capture temporal dynamics, missing the evolving preferences of users.", "method": "The authors propose GRUT, which features Time-aware Prompting (user-level contextual modeling and item-level transition patterns) and Trend-aware Inference (training-free ranking enhancement using item trend information).", "result": "GRUT outperforms state-of-the-art models, showing improvements of up to 15.4% in Recall@5 and 14.3% in NDCG@5 across four benchmark datasets.", "conclusion": "GRUT effectively captures hidden user preferences through temporal signals and sets a new performance standard in generative recommendation systems."}}
{"id": "2509.14234", "pdf": "https://arxiv.org/pdf/2509.14234", "abs": "https://arxiv.org/abs/2509.14234", "authors": ["Dulhan Jayalath", "Shashwat Goel", "Thomas Foster", "Parag Jain", "Suchin Gururangan", "Cheng Zhang", "Anirudh Goyal", "Alan Schelten"], "title": "Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision", "categories": ["cs.LG"], "comment": "22 pages, 8 figures, 2 tables", "summary": "Where do learning signals come from when there is no ground truth in\npost-training? We propose turning exploration into supervision through Compute\nas Teacher (CaT), which converts the model's own exploration at inference-time\ninto reference-free supervision by synthesizing a single reference from a group\nof parallel rollouts and then optimizing toward it. Concretely, the current\npolicy produces a group of rollouts; a frozen anchor (the initial policy)\nreconciles omissions and contradictions to estimate a reference, turning extra\ninference-time compute into a teacher signal. We turn this into rewards in two\nregimes: (i) verifiable tasks use programmatic equivalence on final answers;\n(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria\nscored by an independent LLM judge, with reward given by the fraction\nsatisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge\nscores), synthesis may disagree with the majority and be correct even when all\nrollouts are wrong; performance scales with the number of rollouts. As a\ntest-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up\nto +27% on MATH-500; +12% on HealthBench). With reinforcement learning\n(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained\npolicy surpassing the initial teacher signal.", "AI": {"tldr": "\"Compute as Teacher (CaT)\" uses a model's inference-time exploration to synthesize reference-free supervision, enhancing task performance in verifiable and non-verifiable tasks.", "motivation": "The paper addresses the question of generating learning signals in the absence of ground truth during post-training.", "method": "CaT synthesizes a reference signal from multiple rollouts using a frozen initial policy. Rewards are calculated based on programmatic equivalence or independent scoring by another LLM.", "result": "CaT improves performance of models, achieving significant advancements in tasks like MATH-500 (+27% improvement) and HealthBench (+12%). Additional improvements (+33% and +30%) are noted with RL-based fine-tuning.", "conclusion": "The proposed CaT framework turns extra compute into effective supervision, scaling with rollouts and even surpassing the initial teacher signal."}}
{"id": "2509.13846", "pdf": "https://arxiv.org/pdf/2509.13846", "abs": "https://arxiv.org/abs/2509.13846", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "MICCAI 2025: 1st Place in Transformer track and 2nd Place in\n  Convolution track of SSL3D-OpenMind challenge", "summary": "Many recent approaches in representation learning implicitly assume that\nuncorrelated views of a data point are sufficient to learn meaningful\nrepresentations for various downstream tasks. In this work, we challenge this\nassumption and demonstrate that meaningful structure in the latent space does\nnot emerge naturally. Instead, it must be explicitly induced. We propose a\nmethod that aligns representations from different views of the data to align\ncomplementary information without inducing false positives. Our experiments\nshow that our proposed self-supervised learning method, Consistent View\nAlignment, improves performance for downstream tasks, highlighting the critical\nrole of structured view alignment in learning effective representations. Our\nmethod achieved first and second place in the MICCAI 2025 SSL3D challenge when\nusing a Primus vision transformer and ResEnc convolutional neural network,\nrespectively. The code and pretrained model weights are released at\nhttps://github.com/Tenbatsu24/LatentCampus.", "AI": {"tldr": "Meaningful representations don't naturally emerge from uncorrelated views; structured alignment of complementary data is essential.", "motivation": "The study challenges the assumption that uncorrelated views of data are sufficient to produce meaningful latent representations.", "method": "The method involves explicit alignment of representations from different views to integrate complementary information without generating false positives.", "result": "The proposed Consistent View Alignment method enhances downstream task performance and excelled in the MICCAI 2025 SSL3D challenges using advanced architectures.", "conclusion": "Structured view alignment is crucial for effective representation learning in self-supervised frameworks."}}
{"id": "2509.14117", "pdf": "https://arxiv.org/pdf/2509.14117", "abs": "https://arxiv.org/abs/2509.14117", "authors": ["Ali Abouzeid", "Malak Mansour", "Zezhou Sun", "Dezhen Song"], "title": "GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model", "categories": ["cs.RO"], "comment": "Under Review", "summary": "Vision-Language-Action (VLA) models often fail to generalize to novel camera\nviewpoints, a limitation stemming from their difficulty in inferring robust 3D\ngeometry from 2D images. We introduce GeoAware-VLA, a simple yet effective\napproach that enhances viewpoint invariance by integrating strong geometric\npriors into the vision backbone. Instead of training a visual encoder or\nrelying on explicit 3D data, we leverage a frozen, pretrained geometric vision\nmodel as a feature extractor. A trainable projection layer then adapts these\ngeometrically-rich features for the policy decoder, relieving it of the burden\nof learning 3D consistency from scratch. Through extensive evaluations on\nLIBERO benchmark subsets, we show GeoAware-VLA achieves substantial\nimprovements in zero-shot generalization to novel camera poses, boosting\nsuccess rates by over 2x in simulation. Crucially, these benefits translate to\nthe physical world; our model shows a significant performance gain on a real\nrobot, especially when evaluated from unseen camera angles. Our approach proves\neffective across both continuous and discrete action spaces, highlighting that\nrobust geometric grounding is a key component for creating more generalizable\nrobotic agents.", "AI": {"tldr": "GeoAware-VLA enhances Vision-Language-Action models by integrating robust 3D geometric priors, enabling better generalization to novel camera viewpoints in simulation and real-world scenarios.", "motivation": "Addressing the limitation of VLA models struggling to generalize to new camera angles due to weak 3D geometric reasoning.", "method": "Utilizes a frozen, pretrained geometric vision model as a feature extractor, coupled with a trainable projection layer for policy adaptation.", "result": "GeoAware-VLA significantly boosts zero-shot generalization, achieving over 2x success rates in simulation and notable gains in real-world robot tasks from unseen viewpoints.", "conclusion": "Integrating strong geometric grounding dramatically improves viewpoint invariance in robotic agents across diverse settings and action spaces."}}
{"id": "2509.12510", "pdf": "https://arxiv.org/pdf/2509.12510", "abs": "https://arxiv.org/abs/2509.12510", "authors": ["Wei Shao", "Ruoyu Zhang", "Zequan Liang", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device", "categories": ["eess.SP", "cs.LG"], "comment": "In the proceedings of IEEE-EMBS BSN 2025", "summary": "Wearable photoplethysmography (PPG) is embedded in billions of devices, yet\nits optical waveform is easily corrupted by motion, perfusion loss, and ambient\nlight, jeopardizing downstream cardiometric analytics. Existing signal-quality\nassessment (SQA) methods rely either on brittle heuristics or on data-hungry\nsupervised models. We introduce the first fully unsupervised SQA pipeline for\nwrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,\nunlabeled data from heterogeneous sources (varying in device and sampling\nfrequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,\nthe learned representation is stable across differences in LED wavelength,\ndrive intensity, and device optics, as well as wrist motion). Stage 2 converts\neach 512-D encoder embedding into a 4-D topological signature via persistent\nhomology (PH) and clusters these signatures with HDBSCAN. To produce a binary\nsignal-quality index (SQI), the acceptable PPG signals are represented by the\ndensest cluster while the remaining clusters are assumed to mainly contain\npoor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,\nDavies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,\nrespectively, on a stratified sample of 10,000 windows. In this study, we\npropose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)\nframework that offers a drop-in, scalable, cross-device quality gate for PPG\nsignals.", "AI": {"tldr": "The paper introduces a fully unsupervised signal-quality assessment pipeline for wearable photoplethysmography (PPG) signals to address issues like motion artifacts and ambient light interference.", "motivation": "The aim is to assess and ensure the quality of PPG signals for reliable cardiometric analytics, overcoming the limitations of brittle heuristics and data-hungry supervised models.", "method": "The approach combines self-supervised learning (contrastive 1-D ResNet-18) to create invariant embeddings and topological data analysis (persistent homology and HDBSCAN clustering) to classify signal quality.", "result": "The proposed pipeline achieves robust clustering performance with high evaluation scores (Silhouette: 0.72, Davies-Bouldin: 0.34, and Calinski-Harabasz: 6173) on diverse PPG signal datasets.", "conclusion": "This hybrid SSL-TDA framework is scalable, cross-device adaptable, and serves as a practical solution for automated PPG signal quality assessment."}}
{"id": "2509.13848", "pdf": "https://arxiv.org/pdf/2509.13848", "abs": "https://arxiv.org/abs/2509.13848", "authors": ["Jiayi Pan", "Jiaming Xu", "Yongkang Zhou", "Guohao Dai"], "title": "SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Feature caching has recently emerged as a promising method for diffusion\nmodel acceleration. It effectively alleviates the inefficiency problem caused\nby high computational requirements by caching similar features in the inference\nprocess of the diffusion model. In this paper, we analyze existing feature\ncaching methods from the perspective of information utilization, and point out\nthat relying solely on historical information will lead to constrained accuracy\nand speed performance. And we propose a novel paradigm that introduces future\ninformation via self-speculation based on the information similarity at the\nsame time step across different iteration times. Based on this paradigm, we\npresent \\textit{SpecDiff}, a training-free multi-level feature caching strategy\nincluding a cached feature selection algorithm and a multi-level feature\nclassification algorithm. (1) Feature selection algorithm based on\nself-speculative information. \\textit{SpecDiff} determines a dynamic importance\nscore for each token based on self-speculative information and historical\ninformation, and performs cached feature selection through the importance\nscore. (2) Multi-level feature classification algorithm based on feature\nimportance scores. \\textit{SpecDiff} classifies tokens by leveraging the\ndifferences in feature importance scores and introduces a multi-level feature\ncalculation strategy. Extensive experiments show that \\textit{SpecDiff}\nachieves average 2.80 \\times, 2.74 \\times , and 3.17\\times speedup with\nnegligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow\non NVIDIA A800-80GB GPU. By merging speculative and historical information,\n\\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing\nthe Pareto frontier of speedup and accuracy in the efficient diffusion model\ninference.", "AI": {"tldr": "SpecDiff improves the efficiency of diffusion models by incorporating future and historical information into a feature caching strategy for faster inference with minimal quality loss.", "motivation": "Current diffusion model processes are inefficient due to high computational requirements. Existing feature caching methods improve speed but suffer from limited accuracy and performance because they only rely on historical information.", "method": "SpecDiff introduces future information via self-speculation and combines it with historical information. It includes a cached feature selection algorithm that determines token importance dynamically and a multi-level feature classification algorithm to enhance processing.", "result": "SpecDiff achieves significant speedups (2.80\u00d7 to 3.17\u00d7) across various models (Stable Diffusion 3, 3.5, FLUX) with negligible quality loss on an NVIDIA A800-80GB GPU.", "conclusion": "SpecDiff addresses the trade-off between speed and accuracy in diffusion model inference by effectively combining speculative and historical information. It sets new performance benchmarks for efficient diffusion modeling."}}
{"id": "2509.14126", "pdf": "https://arxiv.org/pdf/2509.14126", "abs": "https://arxiv.org/abs/2509.14126", "authors": ["Viktor Lorentz", "Khaled Wahba", "Sayantan Auddy", "Marc Toussaint", "Wolfgang H\u00f6nig"], "title": "CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads", "categories": ["cs.RO", "cs.MA"], "comment": "This work has been submitted to IEEE for possible publication", "summary": "Collaborative transportation of cable-suspended payloads by teams of Unmanned\nAerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to\ndifferent payload shapes, and provide built-in compliance, making it attractive\nfor applications ranging from disaster relief to precision logistics. However,\nmulti-UAV coordination under disturbances, nonlinear payload dynamics, and\nslack--taut cable modes remains a challenging control problem. To our\nknowledge, no prior work has addressed these cable mode transitions in the\nmulti-UAV context, instead relying on simplifying rigid-link assumptions. We\npropose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for\nmulti-UAV cable-suspended payload transport. Simulation results demonstrate\nthat the learned policies can outperform classical decentralized controllers in\nterms of disturbance rejection and tracking precision, achieving an 80%\nrecovery rate from harsh conditions compared to 44% for the baseline method. We\nalso achieve successful zero-shot sim-to-real transfer and demonstrate that our\npolicies are highly robust under harsh conditions, including wind, random\nexternal disturbances, and transitions between slack and taut cable dynamics.\nThis work paves the way for autonomous, resilient UAV teams capable of\nexecuting complex payload missions in unstructured environments.", "AI": {"tldr": "This paper introduces CrazyMARL, a decentralized RL framework for multi-UAV teams transporting cable-suspended payloads, achieving improved performance compared to classical controllers.", "motivation": "The authors aim to address the challenges of coordinating multiple UAVs for cable-suspended payload transport, specifically addressing disturbances and slack-taut cable mode transitions.", "method": "They develop the CrazyMARL framework using decentralized Reinforcement Learning and test its effectiveness through simulations compared to classical controllers.", "result": "CrazyMARL achieves an 80% recovery rate in simulations under harsh conditions, significantly outperforming a baseline method's 44% recovery rate.", "conclusion": "CrazyMARL demonstrates high robustness to disturbances and enables successful sim-to-real transfer, advancing autonomous UAV team operations for complex payload missions in unstructured environments."}}
{"id": "2509.13326", "pdf": "https://arxiv.org/pdf/2509.13326", "abs": "https://arxiv.org/abs/2509.13326", "authors": ["Hemil Mehta", "Tanvi Raut", "Kohav Yadav", "Edward F. Gehringer"], "title": "LLM Chatbot-Creation Approaches", "categories": ["cs.HC", "cs.LG"], "comment": "Forthcoming in Frontiers in Education (FIE 2025), Nashville,\n  Tennessee, USA, Nov 2-5, 2025", "summary": "This full research-to-practice paper explores approaches for developing\ncourse chatbots by comparing low-code platforms and custom-coded solutions in\neducational contexts. With the rise of Large Language Models (LLMs) like GPT-4\nand LLaMA, LLM-based chatbots are being integrated into teaching workflows to\nautomate tasks, provide assistance, and offer scalable support. However,\nselecting the optimal development strategy requires balancing ease of use,\ncustomization, data privacy, and scalability. This study compares two\ndevelopment approaches: low-code platforms like AnythingLLM and Botpress, with\ncustom-coded solutions using LangChain, FAISS, and FastAPI. The research uses\nPrompt engineering, Retrieval-augmented generation (RAG), and personalization\nto evaluate chatbot prototypes across technical performance, scalability, and\nuser experience. Findings indicate that while low-code platforms enable rapid\nprototyping, they face limitations in customization and scaling, while\ncustom-coded systems offer more control but require significant technical\nexpertise. Both approaches successfully implement key research principles such\nas adaptive feedback loops and conversational continuity. The study provides a\nframework for selecting the appropriate development strategy based on\ninstitutional goals and resources. Future work will focus on hybrid solutions\nthat combine low-code accessibility with modular customization and incorporate\nmultimodal input for intelligent tutoring systems.", "AI": {"tldr": "This paper compares low-code platforms and custom-coded solutions for developing educational course chatbots, evaluating them based on ease of use, customization, data privacy, and scalability.", "motivation": "The paper aims to address the challenge of developing effective course chatbots in education by evaluating different approaches in light of the rise of Large Language Models (LLMs).", "method": "The study uses technical frameworks like Prompt engineering, Retrieval-augmented generation (RAG), and personalization techniques to develop and analyze chatbot performance, scalability, and user experience.", "result": "Low-code platforms simplify prototyping but lack customization and scalability, while custom-coded solutions provide higher control but demand technical expertise. Both approaches meet key principles like adaptive feedback loops.", "conclusion": "A framework is provided to guide the selection between development strategies, emphasizing institutional goals. Hybrid solutions combining accessibility and modular customization are suggested for future research."}}
{"id": "2509.13858", "pdf": "https://arxiv.org/pdf/2509.13858", "abs": "https://arxiv.org/abs/2509.13858", "authors": ["Qianxin Xia", "Jiawei Du", "Guoming Lu", "Zhiyong Shu", "Jielei Wang"], "title": "EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics", "categories": ["cs.CV"], "comment": null, "summary": "Dataset distillation aims to synthesize a compact dataset from the original\nlarge-scale one, enabling highly efficient learning while preserving\ncompetitive model performance. However, traditional techniques primarily\ncapture low-level visual features, neglecting the high-level semantic and\nstructural information inherent in images. In this paper, we propose EDITS, a\nnovel framework that exploits the implicit textual semantics within the image\ndata to achieve enhanced distillation. First, external texts generated by a\nVision Language Model (VLM) are fused with image features through a Global\nSemantic Query module, forming the prior clustered buffer. Local Semantic\nAwareness then selects representative samples from the buffer to construct\nimage and text prototypes, with the latter produced by guiding a Large Language\nModel (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype\nGuidance strategy generates the final synthetic dataset through a diffusion\nmodel. Extensive experiments confirm the effectiveness of our method.Source\ncode is available in: https://github.com/einsteinxia/EDITS.", "AI": {"tldr": "The paper introduces EDITS, a framework for dataset distillation that integrates textual semantics to create compact synthetic datasets.", "motivation": "The research addresses the limitation of traditional dataset distillation methods that overlook high-level semantic and structural information in image datasets.", "method": "The proposed EDITS framework leverages image features and externally generated textual data. It uses a Vision Language Model (VLM) and a Global Semantic Query module for feature fusion, along with a Local Semantic Awareness approach for prototype creation, and a diffusion model for generating synthetic datasets.", "result": "The experiments demonstrate that EDITS improves dataset distillation by preserving semantic richness, achieving efficient learning with competitive performance.", "conclusion": "EDITS enhances dataset distillation by integrating both image and textual semantics, providing a robust solution for creating condensed yet effective datasets."}}
{"id": "2509.14127", "pdf": "https://arxiv.org/pdf/2509.14127", "abs": "https://arxiv.org/abs/2509.14127", "authors": ["Alkesh K. Srivastava", "Jared Michael Levin", "Philip Dames"], "title": "Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "We consider the problem of delivering multiple packages from a single pickup\ndepot to distinct goal locations using a homogeneous fleet of robots with\nlimited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner\nTree Relay Coordination Planning framework that constructs sparse relay trunks\nusing Steiner tree optimization and then synthesizes robot-level pickup, relay,\nand delivery schedules. This framework reframes relays from incidental\nbyproducts into central elements of coordination, offering a contrast with\ntraditional delivery methods that rely on direct source-to-destination\ntransport. Extensive experiments show consistent improvements of up to 34%\ncompared to conventional baselines, underscoring the benefits of incorporating\nrelays into the delivery process. These improvements translate directly to\nenhanced energy efficiency in multi-robot delivery under capacity constraints,\nproviding a scalable framework for real-world logistics.", "AI": {"tldr": "The paper introduces a novel multi-robot delivery framework with relays for efficient logistics operations.", "motivation": "To address the inefficiencies in multi-robot delivery systems that rely solely on direct source-to-destination transport, especially under limited robot capacity constraints.", "method": "Developed VCST-RCP, a framework using Voronoi-Constrained Steiner Tree optimization to construct efficient relay trunks and robot-level schedules.", "result": "Performance improved up to 34% over conventional methods, demonstrating enhanced energy efficiency and scalability in multi-robot delivery systems.", "conclusion": "VCST-RCP offers a scalable and energy-efficient solution for multi-robot logistics by leveraging relays for better coordination."}}
{"id": "2509.13863", "pdf": "https://arxiv.org/pdf/2509.13863", "abs": "https://arxiv.org/abs/2509.13863", "authors": ["Chu Chen", "Ander Biguri", "Jean-Michel Morel", "Raymond H. Chan", "Carola-Bibiane Sch\u00f6nlieb", "Jizhou Li"], "title": "LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "X-ray Computed Laminography (CL) is essential for non-destructive inspection\nof plate-like structures in applications such as microchips and composite\nbattery materials, where traditional computed tomography (CT) struggles due to\ngeometric constraints. However, reconstructing high-quality volumes from\nlaminographic projections remains challenging, particularly under highly\nsparse-view acquisition conditions. In this paper, we propose a reconstruction\nalgorithm, namely LamiGauss, that combines Gaussian Splatting radiative\nrasterization with a dedicated detector-to-world transformation model\nincorporating the laminographic tilt angle. LamiGauss leverages an\ninitialization strategy that explicitly filters out common laminographic\nartifacts from the preliminary reconstruction, preventing redundant Gaussians\nfrom being allocated to false structures and thereby concentrating model\ncapacity on representing the genuine object. Our approach effectively optimizes\ndirectly from sparse projections, enabling accurate and efficient\nreconstruction with limited data. Extensive experiments on both synthetic and\nreal datasets demonstrate the effectiveness and superiority of the proposed\nmethod over existing techniques. LamiGauss uses only 3$\\%$ of full views to\nachieve superior performance over the iterative method optimized on a full\ndataset.", "AI": {"tldr": "The paper presents LamiGauss, a new algorithm for high-quality laminographic reconstructions under sparse-view conditions, which significantly outperforms existing techniques even with minimal data.", "motivation": "The motivation arises from the need to overcome difficulties in reconstructing accurate volumes in plate-like structures (e.g., microchips, batteries) using traditional CT methods, particularly when data acquisition is sparse.", "method": "LamiGauss combines Gaussian Splatting with a detector-to-world model tailored for laminographic imaging, incorporating tilt angles to reduce artifacts during initialization and refine sparse-projection reconstruction.", "result": "Extensive tests on synthetic and real datasets show that LamiGauss can reconstruct high-quality volumes with only 3% of data views, surpassing iterative methods optimized for full datasets.", "conclusion": "LamiGauss proves highly effective and efficient for sparse laminographic projection reconstruction, offering a substantial improvement over existing methods in accuracy and computational efficiency."}}
{"id": "2509.14138", "pdf": "https://arxiv.org/pdf/2509.14138", "abs": "https://arxiv.org/abs/2509.14138", "authors": ["Ran Yang", "Zijian An", "Lifeng ZHou", "Yiming Feng"], "title": "SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model", "categories": ["cs.RO", "68T40"], "comment": "8 pages, 9 figures, 1 table", "summary": "Long-horizon robotic manipulation tasks require executing multiple\ninterdependent subtasks in strict sequence, where errors in detecting subtask\ncompletion can cascade into downstream failures. Existing\nVision-Language-Action (VLA) models such as $\\pi_0$ excel at continuous\nlow-level control but lack an internal signal for identifying when a subtask\nhas finished, making them brittle in sequential settings. We propose SeqVLA, a\ncompletion-aware extension of $\\pi_0$ that augments the base architecture with\na lightweight detection head perceiving whether the current subtask is\ncomplete. This dual-head design enables SeqVLA not only to generate\nmanipulation actions but also to autonomously trigger transitions between\nsubtasks. We investigate four finetuning strategies that vary in how the action\nand detection heads are optimized (joint vs. sequential finetuning) and how\npretrained knowledge is preserved (full finetuning vs. frozen backbone).\nExperiments are performed on two multi-stage tasks: salad packing with seven\ndistinct subtasks and candy packing with four distinct subtasks. Results show\nthat SeqVLA significantly outperforms the baseline $\\pi_0$ and other strong\nbaselines in overall success rate. In particular, joint finetuning with an\nunfrozen backbone yields the most decisive and statistically reliable\ncompletion predictions, eliminating sequence-related failures and enabling\nrobust long-horizon execution. Our results highlight the importance of coupling\naction generation with subtask-aware detection for scalable sequential\nmanipulation.", "AI": {"tldr": "SeqVLA is a Vision-Language-Action model designed to address errors in sequential robotic manipulation tasks by integrating subtask completion detection, outperforming existing models like $\\pi_0$.", "motivation": "Existing VLA models for robotic manipulation, like $\\pi_0$, lack mechanisms to detect subtask completion in long-horizon tasks, leading to downstream failures.", "method": "SeqVLA extends $\\pi_0$ by adding a detection head for subtask completion. Four finetuning strategies are explored, combining joint/sequential optimization and backbone freezing/unfreezing.", "result": "SeqVLA demonstrates significant performance improvements over $\\pi_0$ and other baselines in multi-stage tasks like salad packing and candy packing. Joint finetuning with unfrozen backbone provides the best results.", "conclusion": "Coupling action generation with subtask-aware detection is key for robust sequential manipulation in robotic tasks, as illustrated by SeqVLA's success."}}
{"id": "2509.13597", "pdf": "https://arxiv.org/pdf/2509.13597", "abs": "https://arxiv.org/abs/2509.13597", "authors": ["Abhishek Goswami"], "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents", "categories": ["cs.CR", "cs.AI"], "comment": "17 pages, 6 figures, 2 Tables", "summary": "Autonomous LLM agents can issue thousands of API calls per hour without human\noversight. OAuth 2.0 assumes deterministic clients, but in agentic settings\nstochastic reasoning, prompt injection, or multi-agent orchestration can\nsilently expand privileges.\n  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each\nagent's action to verifiable user intent and, optionally, to a specific\nworkflow step. A-JWT carries an agent's identity as a one-way checksum hash\nderived from its prompt, tools and configuration, and a chained delegation\nassertion to prove which downstream agent may execute a given task, and\nper-agent proof-of-possession keys to prevent replay and in-process\nimpersonation. We define a new authorization mechanism and add a lightweight\nclient shim library that self-verifies code at run time, mints intent tokens,\ntracks workflow steps and derives keys, thus enabling secure agent identity and\nseparation even within a single process.\n  We illustrate a comprehensive threat model for agentic applications,\nimplement a Python proof-of-concept and show functional blocking of\nscope-violating requests, replay, impersonation, and prompt-injection pathways\nwith sub-millisecond overhead on commodity hardware. The design aligns with\nongoing OAuth agent discussions and offers a drop-in path toward zero-trust\nguarantees for agentic applications. A comprehensive performance and security\nevaluation with experimental results will appear in our forthcoming journal\npublication", "AI": {"tldr": "The paper introduces Agentic JWT (A-JWT), a secure token framework for agent-based LLM applications, addressing vulnerabilities like privilege expansion and impersonation in agent orchestration.", "motivation": "OAuth 2.0's assumptions of deterministic clients fail in stochastic, autonomous LLM agents, leading to potential vulnerabilities such as unauthorized privilege expansion or impersonation.", "method": "The authors propose Agentic JWT (A-JWT), which issues verifiable intent tokens binding actions to user intent and workflow steps. It leverages a hash-based identity system for agents and includes a client library for runtime verification, token management, and preventing impersonation.", "result": "Implemented a Python proof-of-concept showing effective blocking of replay attacks, impersonation, and scope violations with minimal computational overhead.", "conclusion": "The proposed A-JWT framework strengthens security for agentic LLM applications, offering a feasible, zero-trust solution aligning with OAuth agent discussions. A formal performance and security analysis will be provided in future work."}}
{"id": "2509.14132", "pdf": "https://arxiv.org/pdf/2509.14132", "abs": "https://arxiv.org/abs/2509.14132", "authors": ["Julia S. Dollis", "Iago A. Brito", "Fernanda B. F\u00e4rber", "Pedro S. F. B. Ribeiro", "Rafael T. Sousa", "Arlindo R. Galv\u00e3o Filho"], "title": "When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training", "categories": ["cs.HC", "cs.CL"], "comment": "8 pages, 2 figures", "summary": "While virtual reality (VR) excels at simulating physical environments, its\neffectiveness for training complex interpersonal skills is limited by a lack of\npsychologically plausible virtual humans. This is a critical gap in high-stakes\ndomains like medical education, where communication is a core competency. This\npaper introduces a framework that integrates large language models (LLMs) into\nimmersive VR to create medically coherent virtual patients with distinct,\nconsistent personalities, built on a modular architecture that decouples\npersonality from clinical data. We evaluated our system in a mixed-method,\nwithin-subjects study with licensed physicians who engaged in simulated\nconsultations. Results demonstrate that the approach is not only feasible but\nis also perceived by physicians as a highly rewarding and effective training\nenhancement. Furthermore, our analysis uncovers critical design principles,\nincluding a ``realism-verbosity paradox\" where less communicative agents can\nseem more artificial, and the need for challenges to be perceived as authentic\nto be instructive. This work provides a validated framework and key insights\nfor developing the next generation of socially intelligent VR training\nenvironments.", "AI": {"tldr": "This paper integrates large language models into virtual reality to simulate psychologically plausible virtual patients, aiming to improve complex interpersonal skills training.", "motivation": "There is a need to enhance VR's capability in training complex interpersonal skills, particularly in medical education, where communication is essential.", "method": "A modular framework was introduced to create virtual patients with coherent personalities and clinical data, and evaluated with licensed physicians through simulated consultations in a mixed-method study.", "result": "The system was deemed feasible and perceived as a rewarding and effective training tool by physicians.", "conclusion": "The framework is validated and provides principles like the realism-verbosity paradox for advancing socially intelligent VR training environments."}}
{"id": "2509.13864", "pdf": "https://arxiv.org/pdf/2509.13864", "abs": "https://arxiv.org/abs/2509.13864", "authors": ["Jovana Videnovic", "Matej Kristan", "Alan Lukezic"], "title": "Distractor-Aware Memory-Based Visual Object Tracking", "categories": ["cs.CV"], "comment": "Code available on Github: https://github.com/jovanavidenovic/DAM4SAM", "summary": "Recent emergence of memory-based video segmentation methods such as SAM2 has\nled to models with excellent performance in segmentation tasks, achieving\nleading results on numerous benchmarks. However, these modes are not fully\nadjusted for visual object tracking, where distractors (i.e., objects visually\nsimilar to the target) pose a key challenge. In this paper we propose a\ndistractor-aware drop-in memory module and introspection-based management\nmethod for SAM2, leading to DAM4SAM. Our design effectively reduces the\ntracking drift toward distractors and improves redetection capability after\nobject occlusion. To facilitate the analysis of tracking in the presence of\ndistractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM\noutperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results\non ten. Furthermore, integrating the proposed distractor-aware memory into a\nreal-time tracker EfficientTAM leads to 11% improvement and matches tracking\nquality of the non-real-time SAM2.1-L on multiple tracking and segmentation\nbenchmarks, while integration with edge-based tracker EdgeTAM delivers 4%\nperformance boost, demonstrating a very good generalization across\narchitectures.", "AI": {"tldr": "This paper introduces DAM4SAM, an upgraded memory module for SAM2 that improves performance in visual object tracking, overcoming issues with similar-looking distractors.", "motivation": "Current memory-based segmentation models like SAM2 excel in segmentation but struggle with visual object tracking due to challenges posed by distractors.", "method": "The paper proposes a distractor-aware memory module and introspection-based management for SAM2, along with creating a specialized dataset (DiDi) for testing tracking amidst distractors.", "result": "DAM4SAM surpasses SAM2.1 on 13 benchmarks and sets state-of-the-art on 10. It enhances real-time and edge-based trackers as well, showing significant generalization.", "conclusion": "DAM4SAM effectively addresses distractor-induced issues in object tracking, advancing segmentation and tracking quality while demonstrating adaptability to various tracker architectures."}}
{"id": "2509.14143", "pdf": "https://arxiv.org/pdf/2509.14143", "abs": "https://arxiv.org/abs/2509.14143", "authors": ["Zijian An", "Ran Yang", "Yiming Feng", "Lifeng Zhou"], "title": "CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping", "categories": ["cs.RO", "68T40"], "comment": "8 pages, 5 figures, 1 table", "summary": "Vision-language-action (VLA) models have recently emerged as a promising\nparadigm for robotic control, enabling end-to-end policies that ground natural\nlanguage instructions into visuomotor actions. However, current VLAs often\nstruggle to satisfy precise task constraints, such as stopping based on numeric\nthresholds, since their observation-to-action mappings are implicitly shaped by\ntraining data and lack explicit mechanisms for condition monitoring. In this\nwork, we propose CLAW (CLIP-Language-Action for Weight), a framework that\ndecouples condition evaluation from action generation. CLAW leverages a\nfine-tuned CLIP model as a lightweight prompt generator, which continuously\nmonitors the digital readout of a scale and produces discrete directives based\non task-specific weight thresholds. These prompts are then consumed by $\\pi_0$,\na flow-based VLA policy, which integrates the prompts with multi-view camera\nobservations to produce continuous robot actions. This design enables CLAW to\ncombine symbolic weight reasoning with high-frequency visuomotor control. We\nvalidate CLAW on three experimental setups: single-object grasping and\nmixed-object tasks requiring dual-arm manipulation. Across all conditions, CLAW\nreliably executes weight-aware behaviors and outperforms both raw-$\\pi_0$ and\nfine-tuned $\\pi_0$ models. We have uploaded the videos as supplementary\nmaterials.", "AI": {"tldr": "The paper introduces CLAW, a model combining symbolic reasoning and visuomotor control for robotic tasks demanding precise weight-based constraints.", "motivation": "Current vision-language-action models struggle with precise condition monitoring when tasked with numeric constraints, creating a need to improve robotic control accuracy.", "method": "CLAW uses a fine-tuned CLIP model as a prompt generator for symbolic reasoning and integrates these prompts into a flow-based visuomotor control policy.", "result": "Experiments across tasks like single-object grasping and dual-arm manipulation show CLAW executing weight-aware behaviors better than existing models.", "conclusion": "CLAW successfully achieves precise task constraints by decoupling condition evaluation from action generation and blending symbolic reasoning with visuomotor control."}}
{"id": "2509.13603", "pdf": "https://arxiv.org/pdf/2509.13603", "abs": "https://arxiv.org/abs/2509.13603", "authors": ["Yongye Su", "Zeya Zhang", "Jane Kou", "Cheng Ju", "Shubhojeet Sarkar", "Yamin Wang", "Ji Liu", "Shengbo Guo"], "title": "Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation", "categories": ["cs.IR", "cs.AI"], "comment": "5 Pages, work done as Yongye Su's internship project at Meta", "summary": "Beyond general web-scale search, social network search uniquely enables users\nto retrieve information and discover potential connections within their social\ncontext. We introduce a framework of modernized Facebook Group Scoped Search by\nblending traditional keyword-based retrieval with embedding-based retrieval\n(EBR) to improve the search relevance and diversity of search results. Our\nsystem integrates semantic retrieval into the existing keyword search pipeline,\nenabling users to discover more contextually relevant group posts. To\nrigorously assess the impact of this blended approach, we introduce a novel\nevaluation framework that leverages large language models (LLMs) to perform\noffline relevance assessments, providing scalable and consistent quality\nbenchmarks. Our results demonstrate that the blended retrieval system\nsignificantly enhances user engagement and search quality, as validated by both\nonline metrics and LLM-based evaluation. This work offers practical insights\nfor deploying and evaluating advanced retrieval systems in large-scale,\nreal-world social platforms.", "AI": {"tldr": "The paper presents a modernized Facebook Group Scoped Search incorporating both traditional keyword search and embedding-based retrieval (EBR) to enhance relevance and diversity in search results.", "motivation": "Improve search relevance and diversity in Facebook Groups by integrating traditional keyword-based and advanced embedding-based retrieval methods.", "method": "Develop a blended retrieval system combining keyword search with embedding-based retrieval, supported by a novel evaluation framework using LLMs for offline assessments.", "result": "The blended system leads to significant user engagement improvement and higher search quality, validated through online metrics and LLM-based evaluation.", "conclusion": "Blending keyword and embedding-based retrieval enhances search experiences in large-scale social platforms, offering practical deployment and evaluation insights."}}
{"id": "2509.14199", "pdf": "https://arxiv.org/pdf/2509.14199", "abs": "https://arxiv.org/abs/2509.14199", "authors": ["Haichao Zhang", "Wenhao Chai", "Shwai He", "Ang Li", "Yun Fu"], "title": "Dense Video Understanding with Gated Residual Tokenization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "High temporal resolution is essential for capturing fine-grained details in\nvideo understanding. However, current video large language models (VLLMs) and\nbenchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or\nkeyframe selection, discarding dense temporal information. This compromise\navoids the high cost of tokenizing every frame, which otherwise leads to\nredundant computation and linear token growth as video length increases. While\nthis trade-off works for slowly changing content, it fails for tasks like\nlecture comprehension, where information appears in nearly every frame and\nrequires precise temporal alignment. To address this gap, we introduce Dense\nVideo Understanding (DVU), which enables high-FPS video comprehension by\nreducing both tokenization time and token overhead. Existing benchmarks are\nalso limited, as their QA pairs focus on coarse content changes. We therefore\npropose DIVE (Dense Information Video Evaluation), the first benchmark designed\nfor dense temporal reasoning. To make DVU practical, we present Gated Residual\nTokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated\nTokenization uses pixel-level motion estimation to skip static regions during\ntokenization, achieving sub-linear growth in token count and compute. (2)\nSemantic-Scene Intra-Tokenization Merging fuses tokens across static regions\nwithin a scene, further reducing redundancy while preserving dynamic semantics.\nExperiments on DIVE show that GRT outperforms larger VLLM baselines and scales\npositively with FPS. These results highlight the importance of dense temporal\ninformation and demonstrate that GRT enables efficient, scalable high-FPS video\nunderstanding.", "AI": {"tldr": "The paper focuses on improving high-frame-per-second (high-FPS) video understanding by addressing tokenization inefficiencies using a new framework called Gated Residual Tokenization (GRT).", "motivation": "Current video large language models struggle with tasks requiring high temporal resolution due to inefficiencies in tokenizing every frame, leading to computational redundancy. This is particularly problematic for tasks like lecture comprehension requiring dense temporal reasoning.", "method": "The proposed Gated Residual Tokenization (GRT) framework incorporates two components: (1) Motion-Compensated Inter-Gated Tokenization, which estimates pixel motion to skip static regions to reduce token count, and (2) Semantic-Scene Intra-Tokenization Merging, which merges tokens from static regions to further eliminate redundancy. They also introduced a benchmark called DIVE for dense temporal video evaluation.", "result": "Experiments demonstrated that GRT surpasses the performance of larger VLLM models on the DIVE benchmark and scales efficiently with FPS, showcasing its ability to handle dense temporal video comprehension.", "conclusion": "Dense temporal information is crucial for video understanding, and the proposed GRT framework provides a scalable and computationally efficient approach to achieve high-FPS video comprehension."}}
{"id": "2509.13873", "pdf": "https://arxiv.org/pdf/2509.13873", "abs": "https://arxiv.org/abs/2509.13873", "authors": ["Siam Tahsin Bhuiyan", "Rashedur Rahman", "Sefatul Wasi", "Naomi Yagi", "Syoji Kobashi", "Ashraful Islam", "Saadia Binte Alam"], "title": "Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis", "categories": ["cs.CV"], "comment": "Accepted at MICCAI EMERGE 2025", "summary": "Pelvic fractures pose significant diagnostic challenges, particularly in\ncases where fracture signs are subtle or invisible on standard radiographs. To\naddress this, we introduce PelFANet, a dual-stream attention network that fuses\nraw pelvic X-rays with segmented bone images to improve fracture\nclassification. The network em-ploys Fused Attention Blocks (FABlocks) to\niteratively exchange and refine fea-tures from both inputs, capturing global\ncontext and localized anatomical detail. Trained in a two-stage pipeline with a\nsegmentation-guided approach, PelFANet demonstrates superior performance over\nconventional methods. On the AMERI dataset, it achieves 88.68% accuracy and\n0.9334 AUC on visible fractures, while generalizing effectively to invisible\nfracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained\non them. These results highlight the clini-cal potential of anatomy-aware\ndual-input architectures for robust fracture detec-tion, especially in\nscenarios with subtle radiographic presentations.", "AI": {"tldr": "The paper introduces PelFANet, a dual-stream attention network designed to improve pelvic fracture classification by combining raw X-rays with segmented bone images. It outperforms traditional methods with high accuracy and AUC values, especially handling subtle radiographic presentations.", "motivation": "Pelvic fractures are difficult to detect on standard radiographs, especially when signs are subtle or invisible, necessitating more robust diagnostic tools.", "method": "PelFANet utilizes a dual-stream attention network that integrates raw X-rays with segmented images and refines features using Fused Attention Blocks (FABlocks). Training involves a segmentation-guided, two-stage pipeline.", "result": "PelFANet achieved 88.68% accuracy and 0.9334 AUC for visible fractures, and 82.29% accuracy with 0.8688 AUC for invisible fractures, demonstrating superior performance over conventional methods.", "conclusion": "Dual-input, anatomy-aware architectures like PelFANet offer a promising approach to improving fracture detection, particularly for cases that are challenging to identify using traditional radiographs."}}
{"id": "2509.14147", "pdf": "https://arxiv.org/pdf/2509.14147", "abs": "https://arxiv.org/abs/2509.14147", "authors": ["Fanxing Li", "Shengyang Wang", "Fangyu Sun", "Shuyu Wu", "Dexin Zuo", "Wenxian Yu", "Danping Zou"], "title": "StableTracker: Learning to Stably Track Target via Differentiable Simulation", "categories": ["cs.RO"], "comment": null, "summary": "FPV object tracking methods heavily rely on handcraft modular designs,\nresulting in hardware overload and cumulative error, which seriously degrades\nthe tracking performance, especially for rapidly accelerating or decelerating\ntargets. To address these challenges, we present \\textbf{StableTracker}, a\nlearning-based control policy that enables quadrotors to robustly follow the\nmoving target from arbitrary perspectives. The policy is trained using\nbackpropagation-through-time via differentiable simulation, allowing the\nquadrotor to maintain the target at the center of the visual field in both\nhorizontal and vertical directions, while keeping a fixed relative distance,\nthereby functioning as an autonomous aerial camera. We compare StableTracker\nagainst both state-of-the-art traditional algorithms and learning baselines.\nSimulation experiments demonstrate that our policy achieves superior accuracy,\nstability and generalization across varying safe distances, trajectories, and\ntarget velocities. Furthermore, a real-world experiment on a quadrotor with an\nonboard computer validated practicality of the proposed approach.", "AI": {"tldr": "StableTracker is a learning-based control policy for FPV object tracking, outperforming traditional methods in precision and stability.", "motivation": "Address problems with hardware overload and cumulative errors in traditional FPV object tracking, especially for fast-moving targets.", "method": "Develop a control policy using backpropagation-through-time and differentiable simulation, enabling robust quadrotor tracking of moving targets.", "result": "Simulation showed superior performance in accuracy, stability, and generalization. Real-world tests validated the approach.", "conclusion": "StableTracker provides an effective solution for autonomous tracking, functioning as a reliable aerial camera even in diverse conditions."}}
{"id": "2509.13620", "pdf": "https://arxiv.org/pdf/2509.13620", "abs": "https://arxiv.org/abs/2509.13620", "authors": ["Jeongjin", "Park", "Grant Bruer", "Huseyin Tuna Erdinc", "Abhinav Prakash Gahlot", "Felix J. Herrmann"], "title": "A reduced-order derivative-informed neural operator for subsurface fluid-flow", "categories": ["physics.comp-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural operators have emerged as cost-effective surrogates for expensive\nfluid-flow simulators, particularly in computationally intensive tasks such as\npermeability inversion from time-lapse seismic data, and uncertainty\nquantification. In these applications, the fidelity of the surrogate's\ngradients with respect to system parameters is crucial, as the accuracy of\ndownstream tasks, such as optimization and Bayesian inference, relies directly\non the quality of the derivative information. Recent advances in\nphysics-informed methods have leveraged derivative information to improve\nsurrogate accuracy. However, incorporating explicit Jacobians can become\ncomputationally prohibitive, as the complexity typically scales quadratically\nwith the number of input parameters. To address this limitation, we propose\nDeFINO (Derivative-based Fisher-score Informed Neural Operator), a\nreduced-order, derivative-informed training framework. DeFINO integrates\nFourier neural operators (FNOs) with a novel derivative-based training strategy\nguided by the Fisher Information Matrix (FIM). By projecting Jacobians onto\ndominant eigen-directions identified by the FIM, DeFINO captures critical\nsensitivity information directly informed by observational data, significantly\nreducing computational expense. We validate DeFINO through synthetic\nexperiments in the context of subsurface multi-phase fluid-flow, demonstrating\nimprovements in gradient accuracy while maintaining robust forward predictions\nof underlying fluid dynamics. These results highlight DeFINO's potential to\noffer practical, scalable solutions for inversion problems in complex\nreal-world scenarios, all at substantially reduced computational cost.", "AI": {"tldr": "The paper proposes DeFINO, a reduced-order training framework for neural operators, which improves gradient accuracy in fluid-flow simulations using Fisher Information Matrix-guided sensitivity analysis, offering computational efficiency.", "motivation": "The authors aim to address the computational challenges of incorporating explicit Jacobians for surrogate models in tasks like optimization and Bayesian inference, where gradient accuracy is critical.", "method": "DeFINO combines Fourier Neural Operators with a derivative-informed training strategy that projects Jacobian information onto dominant eigen-directions determined by the Fisher Information Matrix, reducing computation costs.", "result": "Through synthetic experiments in subsurface multi-phase fluid-flow, DeFINO demonstrated improved gradient accuracy and scalable solutions for inversion problems, maintaining reliable fluid dynamic predictions with less computation.", "conclusion": "DeFINO effectively balances gradient accuracy and computational efficiency, making it a practical tool for real-world, computationally intensive fluid-flow inversion problems."}}
{"id": "2509.14221", "pdf": "https://arxiv.org/pdf/2509.14221", "abs": "https://arxiv.org/abs/2509.14221", "authors": ["Silan Hu", "Shiqi Zhang", "Yimin Shi", "Xiaokui Xiao"], "title": "GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing\ngenerative engines, such as LLM-based chatbots, by seamlessly integrating\nrelevant advertisements into their responses. At the core of GEM lies the\ngeneration and evaluation of ad-injected responses. However, existing\nbenchmarks are not specifically designed for this purpose, which limits future\nresearch. To address this gap, we propose GEM-Bench, the first comprehensive\nbenchmark for ad-injected response generation in GEM. GEM-Bench includes three\ncurated datasets covering both chatbot and search scenarios, a metric ontology\nthat captures multiple dimensions of user satisfaction and engagement, and\nseveral baseline solutions implemented within an extensible multi-agent\nframework. Our preliminary results indicate that, while simple prompt-based\nmethods achieve reasonable engagement such as click-through rate, they often\nreduce user satisfaction. In contrast, approaches that insert ads based on\npre-generated ad-free responses help mitigate this issue but introduce\nadditional overhead. These findings highlight the need for future research on\ndesigning more effective and efficient solutions for generating ad-injected\nresponses in GEM.", "AI": {"tldr": "The paper introduces GEM-Bench, a benchmark for ad-injected responses in Generative Engine Marketing (GEM).", "motivation": "Generative engines struggle to balance user satisfaction and engagement when incorporating advertisements into their responses.", "method": "They proposed GEM-Bench, which includes curated datasets, metric ontology for user engagement, and baseline solutions within a multi-agent framework.", "result": "Findings suggest that prompt-based methods lower user satisfaction, while pre-generated ad-free responses improve it but add overhead.", "conclusion": "The study emphasizes the need for more effective and efficient methods to integrate ads in generative engines without compromising user experience."}}
{"id": "2509.13883", "pdf": "https://arxiv.org/pdf/2509.13883", "abs": "https://arxiv.org/abs/2509.13883", "authors": ["Zhen Xu", "Guorui Lu", "Chang Gao", "Qinyu Chen"], "title": "EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View", "categories": ["cs.CV"], "comment": "8 pages", "summary": "Hand tracking holds great promise for intuitive interaction paradigms, but\nframe-based methods often struggle to meet the requirements of accuracy, low\nlatency, and energy efficiency, especially in resource-constrained settings\nsuch as Extended Reality (XR) devices. Event cameras provide $\\mu$s-level\ntemporal resolution at mW-level power by asynchronously sensing brightness\nchanges. In this work, we present EvHand-FPV, a lightweight framework for\negocentric First-Person-View 3D hand tracking from a single event camera. We\nconstruct an event-based FPV dataset that couples synthetic training data with\n3D labels and real event data with 2D labels for evaluation to address the\nscarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based\nregion of interest (ROI) that localizes the hand region via geometric cues,\ncombined with an end-to-end mapping strategy that embeds ROI offsets into the\nnetwork to reduce computation without explicit reconstruction, and a multi-task\nlearning strategy with an auxiliary geometric feature head that improves\nrepresentations without test-time overhead. On our real FPV test set,\nEvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from\n11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It\nalso maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results\ndemonstrate accurate and efficient egocentric event-based hand tracking\nsuitable for on-device XR applications. The dataset and code are available at\nhttps://github.com/zen5x5/EvHand-FPV.", "AI": {"tldr": "This paper introduces EvHand-FPV, a lightweight framework for egocentric 3D hand tracking using event cameras, offering significant improvements in accuracy and efficiency for XR devices.", "motivation": "The study aims to address the challenges of traditional frame-based hand tracking methods, which often lack accuracy, low latency, and energy efficiency, particularly in XR devices.", "method": "EvHand-FPV combines a novel wrist-based region of interest (ROI) approach, synthetic and real event-based datasets, an end-to-end mapping strategy, and multi-task learning to reduce computation and improve representation.", "result": "EvHand-FPV shows an 89% reduction in model parameters and inference FLOPs, while improving 2D-AUCp accuracy from 0.77 to 0.85 on real data and maintaining competitive 3D performance on synthetic data.", "conclusion": "EvHand-FPV demonstrates efficient and accurate egocentric hand tracking, making it suitable for on-device applications in XR environments. The framework and associated datasets are publicly available."}}
{"id": "2509.14159", "pdf": "https://arxiv.org/pdf/2509.14159", "abs": "https://arxiv.org/abs/2509.14159", "authors": ["Dayi Dong", "Maulik Bhatt", "Seoyeon Choi", "Negar Mehr"], "title": "MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies", "categories": ["cs.RO"], "comment": "9 pages, 4 figures, 5 tables", "summary": "As robots become more integrated in society, their ability to coordinate with\nother robots and humans on multi-modal tasks (those with multiple valid\nsolutions) is crucial. We propose to learn such behaviors from expert\ndemonstrations via imitation learning (IL). However, when expert demonstrations\nare multi-modal, standard IL approaches can struggle to capture the diverse\nstrategies, hindering effective coordination. Diffusion models are known to be\neffective at handling complex multi-modal trajectory distributions in\nsingle-agent systems. Diffusion models have also excelled in multi-agent\nscenarios where multi-modality is more common and crucial to learning\ncoordinated behaviors. Typically, diffusion-based approaches require a\ncentralized planner or explicit communication among agents, but this assumption\ncan fail in real-world scenarios where robots must operate independently or\nwith agents like humans that they cannot directly communicate with. Therefore,\nwe propose MIMIC-D, a Centralized Training, Decentralized Execution (CTDE)\nparadigm for multi-modal multi-agent imitation learning using diffusion\npolicies. Agents are trained jointly with full information, but execute\npolicies using only local information to achieve implicit coordination. We\ndemonstrate in both simulation and hardware experiments that our method\nrecovers multi-modal coordination behavior among agents in a variety of tasks\nand environments, while improving upon state-of-the-art baselines.", "AI": {"tldr": "Researchers propose MIMIC-D, combining centralized training with decentralized execution for multi-modal multi-agent imitation learning, enabling robots to coordinate effectively without direct communication.", "motivation": "Robots increasingly need to coordinate on multi-modal tasks involving diverse strategies and independent operation, especially in scenarios with limited direct communication between agents (e.g., robots and humans).", "method": "This paper introduces MIMIC-D, leveraging diffusion models for imitation learning. Training is centralized with full information, but execution is decentralized, relying only on local data for implicit agent coordination.", "result": "The proposed method, MIMIC-D, achieved multi-modal coordination among agents in both simulations and hardware experiments, outperforming state-of-the-art approaches.", "conclusion": "MIMIC-D successfully handles multi-modal strategies in multi-agent systems with decentralized execution, contributing to improved coordination and robustness in real-world scenarios."}}
{"id": "2509.13626", "pdf": "https://arxiv.org/pdf/2509.13626", "abs": "https://arxiv.org/abs/2509.13626", "authors": ["Amanda Chan", "James Jiayu Liu", "He Kai", "Onno P. Kampman"], "title": "Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval", "categories": ["cs.IR", "cs.AI", "H.3.3; J.3; I.2.7"], "comment": "25 pages, 3 figures, submitted to NeurIPS 2025 GenAI4Health", "summary": "Access to reliable mental health information is vital for early help-seeking,\nyet expanding knowledge bases is resource-intensive and often misaligned with\nuser needs. This results in poor performance of retrieval systems when\npresented concerns are not covered or expressed in informal or contextualized\nlanguage. We present an AI-based gap-informed framework for corpus augmentation\nthat authentically identifies underrepresented topics (gaps) by overlaying\nnaturalistic user data such as forum posts in order to prioritize expansions\nbased on coverage and usefulness. In a case study, we compare Directed\n(gap-informed augmentations) with Non-Directed augmentation (random additions),\nevaluating the relevance and usefulness of retrieved information across four\nretrieval-augmented generation (RAG) pipelines. Directed augmentation achieved\nnear-optimal performance with modest expansions--requiring only a 42% increase\nfor Query Transformation, 74% for Reranking and Hierarchical, and 318% for\nBaseline--to reach ~95% of the performance of an exhaustive reference corpus.\nIn contrast, Non-Directed augmentation required substantially larger and thus\npractically infeasible expansions to achieve comparable performance (232%,\n318%, 403%, and 763%, respectively). These results show that strategically\ntargeted corpus growth can reduce content creation demands while sustaining\nhigh retrieval and provision quality, offering a scalable approach for building\ntrusted health information repositories and supporting generative AI\napplications in high-stakes domains.", "AI": {"tldr": "The paper introduces an AI-based method for enhancing mental health information corpora by targeting underrepresented topics, significantly optimizing retrieval performance with reduced resource demands compared to random expansions.", "motivation": "Addressing the mismatch between expanding mental health knowledge bases and user needs, especially for informal or contextualized language queries, to improve retrieval systems.", "method": "The paper presents a gap-informed corpus augmentation framework that uses naturalistic user data to identify underrepresented topics and prioritizes expansions based on their relevance and usefulness.", "result": "Directed (gap-informed) augmentation required significantly smaller expansions to achieve near-optimal performance (~95%) compared to Non-Directed augmentation, which needed substantially larger and impractical expansions.", "conclusion": "Strategic and targeted corpus augmentation enhances retrieval system performance while minimizing effort, providing a scalable solution for trusted information repositories and AI applications in critical areas like mental health."}}
{"id": "2509.13344", "pdf": "https://arxiv.org/pdf/2509.13344", "abs": "https://arxiv.org/abs/2509.13344", "authors": ["Md Ishtyaq Mahmud", "Veena Kochat", "Suresh Satpati", "Jagan Mohan Reddy Dwarampudi", "Kunal Rai", "Tania Banerjee"], "title": "Benchmarking Dimensionality Reduction Techniques for Spatial Transcriptomics", "categories": ["q-bio.GN", "cs.LG"], "comment": "This paper is accepted to the 16th ACM Conference on Bioinformatics,\n  Computational Biology, and Health Informatics (ACM-BCB 2025), 10 page and\n  have 4 figures", "summary": "We introduce a unified framework for evaluating dimensionality reduction\ntechniques in spatial transcriptomics beyond standard PCA approaches. We\nbenchmark six methods PCA, NMF, autoencoder, VAE, and two hybrid embeddings on\na cholangiocarcinoma Xenium dataset, systematically varying latent dimensions\n($k$=5-40) and clustering resolutions ($\\rho$=0.1-1.2). Each configuration is\nevaluated using complementary metrics including reconstruction error, explained\nvariance, cluster cohesion, and two novel biologically-motivated measures:\nCluster Marker Coherence (CMC) and Marker Exclusion Rate (MER). Our results\ndemonstrate distinct performance profiles: PCA provides a fast baseline, NMF\nmaximizes marker enrichment, VAE balances reconstruction and interpretability,\nwhile autoencoders occupy a middle ground. We provide systematic hyperparameter\nselection using Pareto optimal analysis and demonstrate how MER-guided\nreassignment improves biological fidelity across all methods, with CMC scores\nimproving by up to 12\\% on average. This framework enables principled selection\nof dimensionality reduction methods tailored to specific spatial\ntranscriptomics analyses.", "AI": {"tldr": "This paper introduces a framework for evaluating dimensionality reduction techniques tailored to spatial transcriptomics, comparing methods like PCA, NMF, autoencoder, and VAE using various metrics, including two novel biological ones.", "motivation": "There is a need for a systematic evaluation framework to compare dimensionality reduction techniques for spatial transcriptomics data beyond standard approaches like PCA.", "method": "The study systematically benchmarks six dimensionality reduction methods on a spatial transcriptomics dataset, varying latent dimensions and clustering resolutions, and evaluates them using multiple complementary metrics, including two novel biologically-motivated measures.", "result": "Different dimensionality reduction methods exhibit distinct strengths: PCA is fast; NMF excels in marker enrichment; VAE balances reconstruction and interpretability; and autoencoders perform moderately. MER-guided reassignment improves biological fidelity, increasing CMC scores by an average of 12%.", "conclusion": "The proposed framework facilitates the principled selection of dimensionality reduction methods optimized for specific needs in spatial transcriptomics analyses."}}
{"id": "2509.13907", "pdf": "https://arxiv.org/pdf/2509.13907", "abs": "https://arxiv.org/abs/2509.13907", "authors": ["Jiyun Im", "SuBeen Lee", "Miso Lee", "Jae-Pil Heo"], "title": "White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point\nlabels for an unlabeled point cloud, given only a few labeled examples. To\nextract discriminative representations from the limited support set, existing\nmethods have constructed prototypes using conventional algorithms such as\nfarthest point sampling. However, we point out that its initial randomness\nsignificantly affects FS-PCS performance and that the prototype generation\nprocess remains underexplored despite its prevalence. This motivates us to\ninvestigate an advanced prototype generation method based on attention\nmechanism. Despite its potential, we found that vanilla module suffers from the\ndistributional gap between learnable prototypical tokens and support features.\nTo overcome this, we propose White Aggregation and Restoration Module (WARM),\nwhich resolves the misalignment by sandwiching cross-attention between\nwhitening and coloring transformations. Specifically, whitening aligns the\nsupport features to prototypical tokens before attention process, and\nsubsequently coloring restores the original distribution to the attended\ntokens. This simple yet effective design enables robust attention, thereby\ngenerating representative prototypes by capturing the semantic relationships\namong support features. Our method achieves state-of-the-art performance with a\nsignificant margin on multiple FS-PCS benchmarks, demonstrating its\neffectiveness through extensive experiments.", "AI": {"tldr": "This paper proposes a novel method for Few-Shot 3D Point Cloud Segmentation (FS-PCS) using an attention-based prototype generation technique to boost performance.", "motivation": "The researchers aim to address the limitations of conventional prototype construction methods, focusing on issues like the randomness in farthest point sampling and the underexplored nature of prototype generation in FS-PCS.", "method": "The paper introduces White Aggregation and Restoration Module (WARM), which uses whitening and coloring transformations sandwiching cross-attention. This aligns support features and improves prototype generation.", "result": "The proposed WARM method achieves state-of-the-art performance with significant margins across various FS-PCS benchmarks.", "conclusion": "WARM method effectively enhances Few-Shot 3D Point Cloud Segmentation by employing robust prototype generation, outperforming existing methods in the domain."}}
{"id": "2509.14178", "pdf": "https://arxiv.org/pdf/2509.14178", "abs": "https://arxiv.org/abs/2509.14178", "authors": ["Kai Ye", "Yuhang Wu", "Shuyuan Hu", "Junliang Li", "Meng Liu", "Yongquan Chen", "Rui Huang"], "title": "\\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video", "categories": ["cs.RO"], "comment": null, "summary": "Dexterous manipulation remains a challenging robotics problem, largely due to\nthe difficulty of collecting extensive human demonstrations for learning. In\nthis paper, we introduce \\textsc{Gen2Real}, which replaces costly human demos\nwith one generated video and drives robot skill from it: it combines\ndemonstration generation that leverages video generation with pose and depth\nestimation to yield hand-object trajectories, trajectory optimization that uses\nPhysics-aware Interaction Optimization Model (PIOM) to impose physics\nconsistency, and demonstration learning that retargets human motions to a robot\nhand and stabilizes control with an anchor-based residual Proximal Policy\nOptimization (PPO) policy. Using only generated videos, the learned policy\nachieves a 77.3\\% success rate on grasping tasks in simulation and demonstrates\ncoherent executions on a real robot. We also conduct ablation studies to\nvalidate the contribution of each component and demonstrate the ability to\ndirectly specify tasks using natural language, highlighting the flexibility and\nrobustness of \\textsc{Gen2Real} in generalizing grasping skills from imagined\nvideos to real-world execution.", "AI": {"tldr": "The paper introduces a method to derive robotic grasping skills from generated videos rather than costly human demonstrations, achieving high success rates and real-world application.", "motivation": "Robotic dexterous manipulation faces challenges due to limited availability of human demonstrations, prompting the need for alternative ways to train robots.", "method": "The approach leverages video generation, pose and depth estimation, trajectory optimization with a physics-aware model, and anchors residual PPO learning to create robotic grasping skills based purely on generated videos.", "result": "The method achieved a 77.3% success rate in simulation grasping tasks and effectively executed these tasks on a real robot.", "conclusion": "The proposed system showcases flexibility and robustness by generalizing skills from imagined videos to real-world tasks, enabling task specification using natural language."}}
{"id": "2509.13919", "pdf": "https://arxiv.org/pdf/2509.13919", "abs": "https://arxiv.org/abs/2509.13919", "authors": ["Yuanchen Wu", "Ke Yan", "Shouhong Ding", "Ziyin Zhou", "Xiaoqiang Li"], "title": "Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Large Vision-Language Models (LVLMs) have manifested strong visual question\nanswering capability. However, they still struggle with aligning the rationale\nand the generated answer, leading to inconsistent reasoning and incorrect\nresponses. To this end, this paper introduces the Self-Rationale Calibration\n(SRC) framework to iteratively calibrate the alignment between rationales and\nanswers. SRC begins by employing a lightweight \"rationale fine-tuning\"\napproach, which modifies the model's response format to require a rationale\nbefore deriving an answer without explicit prompts. Next, SRC searches for a\ndiverse set of candidate responses from the fine-tuned LVLMs for each sample,\nfollowed by a proposed pairwise scoring strategy using a tailored scoring\nmodel, R-Scorer, to evaluate both rationale quality and factual consistency of\ncandidates. Based on a confidence-weighted preference curation process, SRC\ndecouples the alignment calibration into a preference fine-tuning manner,\nleading to significant improvements of LVLMs in perception, reasoning, and\ngeneralization across multiple benchmarks. Our results emphasize the\nrationale-oriented alignment in exploring the potential of LVLMs.", "AI": {"tldr": "The paper introduces a Self-Rationale Calibration (SRC) framework to improve the alignment of rationale and answer consistency in large vision-language models (LVLMs), achieving better reasoning and generalization.", "motivation": "LVLMs exhibit strong visual question-answering abilities but struggle with aligning their reasoning rationale to their answers, resulting in inconsistencies and errors.", "method": "The SRC framework involves: 1) rationale fine-tuning to modify the model\u2019s response format for rationale-prioritized answers, 2) generating diverse candidate responses, 3) a pairwise scoring strategy with an R-Scorer to evaluate rationale quality and factual consistency, and 4) preference fine-tuning for alignment calibration.", "result": "SRC leads to significant advancements in LVLMs\u2019 perception, reasoning, and generalization capabilities across various benchmarks.", "conclusion": "Emphasizing rationale-oriented alignment improves LVLM performance, demonstrating the potential of this approach for better consistency and reasoning capabilities."}}
{"id": "2509.14191", "pdf": "https://arxiv.org/pdf/2509.14191", "abs": "https://arxiv.org/abs/2509.14191", "authors": ["Zhihao Cao", "Hanyu Wu", "Li Wa Tang", "Zizhou Luo", "Zihan Zhu", "Wei Zhang", "Marc Pollefeys", "Martin R. Oswald"], "title": "MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Recent progress in dense SLAM has primarily targeted monocular setups, often\nat the expense of robustness and geometric coverage. We present MCGS-SLAM, the\nfirst purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting\n(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM\nfuses dense RGB inputs from multiple viewpoints into a unified, continuously\noptimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines\nposes and depths via dense photometric and geometric residuals, while a scale\nconsistency module enforces metric alignment across views using low-rank\npriors. The system supports RGB input and maintains real-time performance at\nlarge scale. Experiments on synthetic and real-world datasets show that\nMCGS-SLAM consistently yields accurate trajectories and photorealistic\nreconstructions, usually outperforming monocular baselines. Notably, the wide\nfield of view from multi-camera input enables reconstruction of side-view\nregions that monocular setups miss, critical for safe autonomous operation.\nThese results highlight the promise of multi-camera Gaussian Splatting SLAM for\nhigh-fidelity mapping in robotics and autonomous driving.", "AI": {"tldr": "This paper introduces MCGS-SLAM, the first RGB-based multi-camera SLAM system built on 3D Gaussian Splatting, achieving robust, large-scale mapping and photorealistic reconstruction.", "motivation": "Monocular SLAM systems often lack robustness and geometric coverage. The aim is to create a system leveraging multi-camera RGB input for enhanced 3D mapping.", "method": "MCGS-SLAM fuses dense RGB inputs from multiple cameras into a continuously optimized Gaussian map, incorporates multi-camera bundle adjustment (MCBA) for pose refinement, and uses a scale consistency module for metric alignment.", "result": "Experiments demonstrate accurate trajectories, photorealistic reconstruction, and improved coverage compared to monocular systems, specifically in side-view regions.", "conclusion": "MCGS-SLAM offers high-fidelity mapping for robotics and autonomous driving, addressing gaps in existing monocular SLAM systems."}}
{"id": "2509.13922", "pdf": "https://arxiv.org/pdf/2509.13922", "abs": "https://arxiv.org/abs/2509.13922", "authors": ["Wenkui Yang", "Jie Cao", "Junxian Duan", "Ran He"], "title": "Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Diffusion models like Stable Diffusion have become prominent in visual\nsynthesis tasks due to their powerful customization capabilities, which also\nintroduce significant security risks, including deepfakes and copyright\ninfringement. In response, a class of methods known as protective perturbation\nemerged, which mitigates image misuse by injecting imperceptible adversarial\nnoise. However, purification can remove protective perturbations, thereby\nexposing images again to the risk of malicious forgery. In this work, we\nformalize the anti-purification task, highlighting challenges that hinder\nexisting approaches, and propose a simple diagnostic protective perturbation\nnamed AntiPure. AntiPure exposes vulnerabilities of purification within the\n\"purification-customization\" workflow, owing to two guidance mechanisms: 1)\nPatch-wise Frequency Guidance, which reduces the model's influence over\nhigh-frequency components in the purified image, and 2) Erroneous Timestep\nGuidance, which disrupts the model's denoising strategy across different\ntimesteps. With additional guidance, AntiPure embeds imperceptible\nperturbations that persist under representative purification settings,\nachieving effective post-customization distortion. Experiments show that, as a\nstress test for purification, AntiPure achieves minimal perceptual discrepancy\nand maximal distortion, outperforming other protective perturbation methods\nwithin the purification-customization workflow.", "AI": {"tldr": "The paper introduces AntiPure, a diagnostic protective perturbation for addressing vulnerabilities in purification methods used with diffusion models.", "motivation": "Diffusion models like Stable Diffusion bring both creative opportunities and security risks, prompting the need for robust protective perturbation methods to safeguard against misuse.", "method": "The proposed AntiPure method utilizes Patch-wise Frequency Guidance and Erroneous Timestep Guidance to inject perturbations that resist purification processes in diffusion models.", "result": "AntiPure outperforms existing protective perturbation techniques by embedding perturbations that survive purification and achieve strong post-customization distortion with minimal perceptual issues.", "conclusion": "AntiPure serves as an effective stress test for purification methods, exposing security flaws in the purification-customization workflow of diffusion models."}}
{"id": "2509.14210", "pdf": "https://arxiv.org/pdf/2509.14210", "abs": "https://arxiv.org/abs/2509.14210", "authors": ["Seth Farrell", "Chenghao Li", "Hongzhan Yu", "Hesam Mojtahedi", "Sicun Gao", "Henrik I. Christensen"], "title": "GLIDE: A Coordinated Aerial-Ground Framework for Search and Rescue in Unknown Environments", "categories": ["cs.RO"], "comment": null, "summary": "We present a cooperative aerial-ground search-and-rescue (SAR) framework that\npairs two unmanned aerial vehicles (UAVs) with an unmanned ground vehicle (UGV)\nto achieve rapid victim localization and obstacle-aware navigation in unknown\nenvironments. We dub this framework Guided Long-horizon Integrated Drone Escort\n(GLIDE), highlighting the UGV's reliance on UAV guidance for long-horizon\nplanning. In our framework, a goal-searching UAV executes real-time onboard\nvictim detection and georeferencing to nominate goals for the ground platform,\nwhile a terrain-scouting UAV flies ahead of the UGV's planned route to provide\nmid-level traversability updates. The UGV fuses aerial cues with local sensing\nto perform time-efficient A* planning and continuous replanning as information\narrives. Additionally, we present a hardware demonstration (using a GEM e6 golf\ncart as the UGV and two X500 UAVs) to evaluate end-to-end SAR mission\nperformance and include simulation ablations to assess the planning stack in\nisolation from detection. Empirical results demonstrate that explicit role\nseparation across UAVs, coupled with terrain scouting and guided planning,\nimproves reach time and navigation safety in time-critical SAR missions.", "AI": {"tldr": "The paper introduces GLIDE, a collaborative system involving UAVs and a UGV for efficient search-and-rescue operations in unfamiliar environments, emphasizing victim detection and obstacle-aware navigation.", "motivation": "To improve speed and safety in search-and-rescue missions by leveraging cooperative UAV and UGV systems for victim localization and obstacle navigation.", "method": "The framework uses two UAVs for real-time victim detection/georeferencing and terrain scouting, paired with a UGV for A* planning that incorporates aerial and local sensing. It was tested in hardware and simulations.", "result": "Results showed better reach time and enhanced navigation safety due to explicit roles for UAVs and the integration of mid-level terrain scouting and guided planning.", "conclusion": "Explicit UAV role separation and cooperative planning greatly enhance the efficiency and safety of SAR missions."}}
{"id": "2509.13936", "pdf": "https://arxiv.org/pdf/2509.13936", "abs": "https://arxiv.org/abs/2509.13936", "authors": ["Harvey Mannering", "Zhiwu Huang", "Adam Prugel-Bennett"], "title": "Noise-Level Diffusion Guidance: Well Begun is Half Done", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models have achieved state-of-the-art image generation. However,\nthe random Gaussian noise used to start the diffusion process influences the\nfinal output, causing variations in image quality and prompt adherence.\nExisting noise-level optimization approaches generally rely on extra dataset\nconstruction, additional networks, or backpropagation-based optimization,\nlimiting their practicality. In this paper, we propose Noise Level Guidance\n(NLG), a simple, efficient, and general noise-level optimization approach that\nrefines initial noise by increasing the likelihood of its alignment with\ngeneral guidance - requiring no additional training data, auxiliary networks,\nor backpropagation. The proposed NLG approach provides a unified framework\ngeneralizable to both conditional and unconditional diffusion models,\naccommodating various forms of diffusion-level guidance. Extensive experiments\non five standard benchmarks demonstrate that our approach enhances output\ngeneration quality and input condition adherence. By seamlessly integrating\nwith existing guidance methods while maintaining computational efficiency, our\nmethod establishes NLG as a practical and scalable enhancement to diffusion\nmodels. Code can be found at\nhttps://github.com/harveymannering/NoiseLevelGuidance.", "AI": {"tldr": "The paper introduces Noise Level Guidance (NLG), a simple and efficient method to optimize noise in diffusion models, improving image generation quality without requiring additional resources.", "motivation": "Address issues with image quality and adherence to desired prompts in diffusion models caused by random Gaussian noise.", "method": "Propose NLG: a novel noise-level optimization approach that refines initial noise without extra datasets, auxiliary networks, or complex backpropagation.", "result": "Demonstrated enhanced generation quality and adherence to input conditions across five benchmarks, generalizable to various diffusion models.", "conclusion": "NLG is a practical, scalable, and computationally efficient enhancement for improving diffusion models, applicable with existing guidance methods."}}
{"id": "2509.14228", "pdf": "https://arxiv.org/pdf/2509.14228", "abs": "https://arxiv.org/abs/2509.14228", "authors": ["Benjamin Shaffer", "Victoria Edwards", "Brooks Kinch", "Nathaniel Trask", "M. Ani Hsieh"], "title": "Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Source localization in a complex flow poses a significant challenge for\nmulti-robot teams tasked with localizing the source of chemical leaks or\ntracking the dispersion of an oil spill. The flow dynamics can be time-varying\nand chaotic, resulting in sporadic and intermittent sensor readings, and\ncomplex environmental geometries further complicate a team's ability to model\nand predict the dispersion. To accurately account for the physical processes\nthat drive the dispersion dynamics, robots must have access to computationally\nintensive numerical models, which can be difficult when onboard computation is\nlimited. We present a distributed mobile sensing framework for source\nlocalization in which each robot carries a machine-learned, finite element\nmodel of its environment to guide information-based sampling. The models are\nused to evaluate an approximate mutual information criterion to drive an\ninfotaxis control strategy, which selects sensing regions that are expected to\nmaximize informativeness for the source localization objective. Our approach\nachieves faster error reduction compared to baseline sensing strategies and\nresults in more accurate source localization compared to baseline machine\nlearning approaches.", "AI": {"tldr": "The paper introduces a framework where robots use machine-learned models to optimize information gathering while localizing sources in complex flow environments.", "motivation": "There is a need for efficient robot teams to localize chemical leaks or track dispersion in environments with chaotic flows and limited onboard computation.", "method": "Each robot employs a machine-learned finite element model to optimize sampling via a mutual information-based infotaxis control strategy.", "result": "This approach enables quicker error reduction and more accurate source localization compared to baseline methods.", "conclusion": "Machine-learned models integrated with infotaxis sampling strategies significantly enhance the ability of robots to localize sources in challenging environments."}}
{"id": "2509.13939", "pdf": "https://arxiv.org/pdf/2509.13939", "abs": "https://arxiv.org/abs/2509.13939", "authors": ["Gia Khanh Nguyen", "Yifeng Huang", "Minh Hoai"], "title": "Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation", "categories": ["cs.CV"], "comment": null, "summary": "Visual counting is a fundamental yet challenging task, especially when users\nneed to count objects of a specific type in complex scenes. While recent\nmodels, including class-agnostic counting models and large vision-language\nmodels (VLMs), show promise in counting tasks, their ability to perform\nfine-grained, intent-driven counting remains unclear. In this paper, we\nintroduce PairTally, a benchmark dataset specifically designed to evaluate\nfine-grained visual counting. Each of the 681 high-resolution images in\nPairTally contains two object categories, requiring models to distinguish and\ncount based on subtle differences in shape, size, color, or semantics. The\ndataset includes both inter-category (distinct categories) and intra-category\n(closely related subcategories) settings, making it suitable for rigorous\nevaluation of selective counting capabilities. We benchmark a variety of\nstate-of-the-art models, including exemplar-based methods, language-prompted\nmodels, and large VLMs. Our results show that despite recent advances, current\nmodels struggle to reliably count what users intend, especially in fine-grained\nand visually ambiguous cases. PairTally provides a new foundation for\ndiagnosing and improving fine-grained visual counting systems.", "AI": {"tldr": "PairTally is a dataset of 681 images designed to evaluate models on fine-grained visual counting tasks, distinguishing objects based on subtle differences.", "motivation": "The lack of clarity in how existing models handle fine-grained and intent-driven counting challenges led to the development of a benchmark dataset.", "method": "The paper introduces PairTally, a dataset with two-object-category setups per image and evaluates various models' counting capabilities under distinct and closely related subcategory settings.", "result": "State-of-the-art models, despite advancements, found difficulty in reliably counting user-intended objects, particularly under visually ambiguous scenarios.", "conclusion": "PairTally serves as a crucial benchmark to identify weaknesses in current visual counting systems and offers potential for guiding future improvements in fine-grained counting tasks."}}
{"id": "2509.13360", "pdf": "https://arxiv.org/pdf/2509.13360", "abs": "https://arxiv.org/abs/2509.13360", "authors": ["L. Zimmer", "J. Weidner", "M. Balcerak", "F. Kofler", "I. Ezhov", "B. Menze", "B. Wiestler"], "title": "PREDICT-GBM: Platform for Robust Evaluation and Development of Individualized Computational Tumor Models in Glioblastoma", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Glioblastoma is the most prevalent primary brain malignancy, distinguished by\nits highly invasive behavior and exceptionally high rates of recurrence.\nConventional radiation therapy, which employs uniform treatment margins, fails\nto account for patient-specific anatomical and biological factors that\ncritically influence tumor cell migration. To address this limitation, numerous\ncomputational models of glioblastoma growth have been developed, enabling\ngeneration of tumor cell distribution maps extending beyond radiographically\nvisible regions and thus informing more precise treatment strategies. However,\ndespite encouraging preliminary findings, the clinical adoption of these growth\nmodels remains limited. To bridge this translational gap and accelerate both\nmodel development and clinical validation, we introduce PREDICT-GBM, a\ncomprehensive integrated pipeline and dataset for modeling and evaluation. This\nplatform enables systematic benchmarking of state-of-the-art tumor growth\nmodels using an expert-curated clinical dataset comprising 255 subjects with\ncomplete tumor segmentations and tissue characterization maps. Our analysis\ndemonstrates that personalized radiation treatment plans derived from tumor\ngrowth predictions achieved superior recurrence coverage compared to\nconventional uniform margin approaches for two of the evaluated models. This\nwork establishes a robust platform for advancing and systematically evaluating\ncutting-edge tumor growth modeling approaches, with the ultimate goal of\nfacilitating clinical translation and improving patient outcomes.", "AI": {"tldr": "This paper introduces PREDICT-GBM, a comprehensive dataset and pipeline designed to enhance the development and evaluation of computational glioblastoma growth models for personalized radiation therapy.", "motivation": "The paper addresses the gap in patient-specific radiation treatment due to conventional therapy's failure to account for unique anatomical and biological tumor migration patterns.", "method": "The authors developed PREDICT-GBM, which integrates an expert-curated dataset of 255 subjects and facilitates systematic benchmarking of glioblastoma growth models.", "result": "Personalized radiation plans based on tumor growth predictions performed better in covering recurrences than conventional uniform margin approaches in two evaluated models.", "conclusion": "PREDICT-GBM provides a robust platform to advance and validate glioblastoma tumor growth modeling, aiming to improve clinical adoption and patient outcomes."}}
{"id": "2509.14001", "pdf": "https://arxiv.org/pdf/2509.14001", "abs": "https://arxiv.org/abs/2509.14001", "authors": ["Elena Camuffo", "Francesco Barbato", "Mete Ozay", "Simone Milani", "Umberto Michieli"], "title": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),\na knowledge distillation approach that transfers region-level multimodal\nsemantics from a large vision-language teacher (e.g., LLaVa) into a lightweight\nvision-only object detector student (e.g., YOLO). A translation module maps\nstudent features into a joint space, where the training of the student and\ntranslator is guided by a dual-objective loss that enforces both local\nalignment and global relational consistency. Unlike prior approaches focused on\ndense or global alignment, MOCHA operates at the object level, enabling\nefficient transfer of semantics without modifying the teacher or requiring\ntextual input at inference. We validate our method across four personalized\ndetection benchmarks under few-shot regimes. Results show consistent gains over\nbaselines, with a +10.1 average score improvement. Despite its compact\narchitecture, MOCHA reaches performance on par with larger multimodal models,\nproving its suitability for real-world deployment.", "AI": {"tldr": "MOCHA transfers multimodal semantics from large vision-language models to lightweight vision-only object detectors using a novel region-level alignment approach.", "motivation": "To enable efficient and compact object detection models by leveraging knowledge from large vision-language models without requiring textual input during inference.", "method": "MOCHA employs a translation module to map student features into a joint multimodal space and uses a dual-objective loss for local and global relational consistency.", "result": "Results showed consistent improvements over baselines in few-shot detection tasks, achieving an average score gain of +10.1 and comparable performance to larger models.", "conclusion": "MOCHA demonstrates the viability of compact architectures for real-world applications while maintaining high performance through object-level multimodal knowledge transfer."}}
{"id": "2509.14012", "pdf": "https://arxiv.org/pdf/2509.14012", "abs": "https://arxiv.org/abs/2509.14012", "authors": ["Tamara R. Lenhard", "Andreas Weinmann", "Tobias Koch"], "title": "Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments", "categories": ["cs.CV"], "comment": null, "summary": "Drone detection in visually complex environments remains challenging due to\nbackground clutter, small object scale, and camouflage effects. While generic\nobject detectors like YOLO exhibit strong performance in low-texture scenes,\ntheir effectiveness degrades in cluttered environments with low\nobject-background separability. To address these limitations, this work\npresents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework\nthat integrates generic object detection with camouflage object detection\ntechniques. Building upon the original architecture, the proposed iteration\nintroduces systematic advancements in training data composition, feature fusion\nstrategies, and backbone design. Specifically, the training process leverages\nlarge-scale, photo-realistic synthetic data, complemented by a small set of\nreal-world samples, to enhance robustness under visually complex conditions.\nThe contribution of intermediate multi-scale FEDER features is systematically\nevaluated, and detection performance is comprehensively benchmarked across\nmultiple YOLO-based backbone configurations. Empirical results indicate that\nintegrating intermediate FEDER features, in combination with backbone upgrades,\ncontributes to notable performance improvements. In the most promising\nconfiguration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER\nfeatures derived from the DWD module -- these enhancements lead to a FNR\nreduction of up to 39.1 percentage points and a mAP increase of up to 62.8\npercentage points at an IoU threshold of 0.5, compared to the initial baseline.", "AI": {"tldr": "The study enhances YOLO-FEDER FusionNet for drone detection in cluttered environments, achieving significant performance improvements by combining camouflage detection techniques and advancements in training and architecture.", "motivation": "The motivation behind the paper is to address the challenges of detecting drones in visually complex environments, where factors like background clutter, small object scale, and camouflage reduce the effectiveness of conventional object detectors like YOLO.", "method": "The paper presents an enhanced YOLO-FEDER FusionNet framework, which integrates general object detection with camouflage detection. This involves advanced data composition using synthetic and real-world samples, intermediate multi-scale feature evaluation, and detailed benchmarking of backbone configurations.", "result": "The YOLO-FEDER FusionNet with YOLOv8l backbone and FEDER features derived from the DWD module showed significant gains, reducing the false negative rate by up to 39.1% and increasing mean average precision (mAP) by 62.8% at an IoU threshold of 0.5.", "conclusion": "Enhancing the YOLO-FEDER FusionNet with novel training strategies and architectural changes effectively improves drone detection in visually complex environments, establishing a more robust detection framework."}}
{"id": "2509.13371", "pdf": "https://arxiv.org/pdf/2509.13371", "abs": "https://arxiv.org/abs/2509.13371", "authors": ["Xuyuan Kang", "Xiao Wang", "Jingjing An", "Da Yan"], "title": "A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "16 pages,14 figures,published to Energy & Buildings", "summary": "Thermal energy storage (TES) is an effective method for load shifting and\ndemand response in buildings. Optimal TES control and management are essential\nto improve the performance of the cooling system. Most existing TES systems\noperate on a fixed schedule, which cannot take full advantage of its load\nshifting capability, and requires extensive investigation and optimization.\nThis study proposed a novel integrated load prediction and optimized control\napproach for ice-based TES in commercial buildings. A cooling load prediction\nmodel was developed and a mid-day modification mechanism was introduced into\nthe prediction model to improve the accuracy. Based on the predictions, a\nrule-based control strategy was proposed according to the time-of-use tariff;\nthe mid-day control adjustment mechanism was introduced in accordance with the\nmid-day prediction modifications. The proposed approach was applied in the\nice-based TES system of a commercial complex in Beijing, and achieved a mean\nabsolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The\nintegrated prediction-based control strategy achieved an energy cost saving\nrate of 9.9%. The proposed model was deployed in the realistic building\nautomation system of the case building and significantly improved the\nefficiency and automation of the cooling system.", "AI": {"tldr": "The paper develops a new prediction and control strategy for ice-based thermal energy storage (TES) in buildings, enhancing cooling performance.", "motivation": "TES systems are typically operated on fixed schedules that limit their potential for load shifting, necessitating optimized control strategies for better efficiency.", "method": "The study created a cooling load prediction model with a mid-day modification mechanism and introduced a rule-based control strategy linked to time-of-use tariffs.", "result": "The approach achieved a mean absolute error (MAE) of 389 kW, a coefficient of variance of MAE of 12.5%, and an energy cost saving rate of 9.9%. It was successfully implemented in a building in Beijing.", "conclusion": "The proposed strategy improves the efficiency, automation, and cost-effectiveness of TES cooling systems in real-world applications."}}
{"id": "2509.14033", "pdf": "https://arxiv.org/pdf/2509.14033", "abs": "https://arxiv.org/abs/2509.14033", "authors": ["Weijie Yin", "Yongjie Ye", "Fangxun Shu", "Yue Liao", "Zijian Kang", "Hongyuan Dong", "Haiyang Yu", "Dingkang Yang", "Jiacong Wang", "Han Wang", "Wenzhuo Liu", "Xiao Liang", "Shuicheng Yan", "Chao Feng"], "title": "SAIL-VL2 Technical Report", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)\nfor comprehensive multimodal understanding and reasoning. As the successor to\nSAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B\nparameter scales across diverse image and video benchmarks, demonstrating\nstrong capabilities from fine-grained perception to complex reasoning. Three\ncore innovations drive its effectiveness. First, a large-scale data curation\npipeline with scoring and filtering strategies enhances both quality and\ndistribution across captioning, OCR, QA, and video data, improving training\nefficiency. Second, a progressive training framework begins with a powerful\npre-trained vision encoder (SAIL-ViT), advances through multimodal\npre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that\nsystematically strengthens model capabilities. Third, architectural advances\nextend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.\nWith these contributions, SAIL-VL2 demonstrates competitive performance across\n106 datasets and achieves state-of-the-art results on challenging reasoning\nbenchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass\nleaderboard, SAIL-VL2-2B ranks first among officially released open-source\nmodels under the 4B parameter scale, while serving as an efficient and\nextensible foundation for the open-source multimodal community.", "AI": {"tldr": "SAIL-VL2 is an advanced vision-language foundation model achieving state-of-the-art results across diverse benchmarks through innovative data curation, training frameworks, and architectural designs.", "motivation": "To develop a vision-language model capable of comprehensive multimodal understanding and reasoning, excelling across diverse datasets at large parameter scales.", "method": "Utilization of a large-scale data curation pipeline, progressive training framework, and architectural innovations such as sparse Mixture-of-Experts designs.", "result": "SAIL-VL2 achieves state-of-the-art performance across 106 datasets and ranks first in its category on the OpenCompass leaderboard.", "conclusion": "SAIL-VL2 demonstrates strong multimodal capabilities, competitive performance, and serves as a robust resource for open-source multimodal research."}}
{"id": "2509.13564", "pdf": "https://arxiv.org/pdf/2509.13564", "abs": "https://arxiv.org/abs/2509.13564", "authors": ["Arman Pourghorban", "Dipankar Maity"], "title": "Multi-Attacker Single-Defender Target Defense in Conical Environments", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": null, "summary": "We consider a variant of the target defense problem in a planar conical\nenvironment where a single defender is tasked to capture a sequence of incoming\nattackers. The attackers' objective is to breach the target boundary without\nbeing captured by the defender. As soon as the current attacker breaches the\ntarget or gets captured by the defender, the next attacker appears at the\nboundary of the environment and moves radially toward the target with maximum\nspeed. Therefore, the defender's final location at the end of the current game\nbecomes its initial location for the next game. The attackers pick strategies\nthat are advantageous for the current as well as for future engagements between\nthe defender and the remaining attackers. The attackers have their own sensors\nwith limited range, using which they can perfectly detect if the defender is\nwithin their sensing range. We derive equilibrium strategies for all the\nplayers to optimize the capture percentage using the notions of capture\ndistribution. Finally, the theoretical results are verified through numerical\nexamples using Monte Carlo type random trials of experiments.", "AI": {"tldr": "The paper addresses a target defense problem in a planar conical environment, devising equilibrium strategies for a defender to maximize capture against strategically moving attackers.", "motivation": "The motivation is to develop optimal strategies for a defender against a sequence of attackers aiming to breach a target in a constrained environment, accounting for both current and future engagements.", "method": "The problem is analyzed using game theory and equilibrium strategies, leveraging the concept of capture distribution. Numerical examples based on Monte Carlo simulations validate the theoretical results.", "result": "Equilibrium strategies are derived for the defender and attackers to optimize the capture percentage, considering attackers\u2019 constrained sensor ranges and strategic movements.", "conclusion": "The proposed equilibrium strategies are effective in addressing the dynamic and strategic nature of the target defense scenarios, confirmed by numerical simulations."}}
{"id": "2509.13374", "pdf": "https://arxiv.org/pdf/2509.13374", "abs": "https://arxiv.org/abs/2509.13374", "authors": ["Helin Zhao", "Junchi Shen"], "title": "Valuation of Exotic Options and Counterparty Games Based on Conditional Diffusion", "categories": ["q-fin.PR", "cs.LG", "q-fin.RM", "91G60", "I.2"], "comment": "28 pages, 12 figures", "summary": "This paper addresses the challenges of pricing exotic options and structured\nproducts, which traditional models often fail to handle due to their inability\nto capture real-world market phenomena like fat-tailed distributions and\nvolatility clustering. We introduce a Diffusion-Conditional Probability Model\n(DDPM) to generate more realistic price paths. Our method incorporates a\ncomposite loss function with financial-specific features, and we propose a P-Q\ndynamic game framework for evaluating the model's economic value through\nadversarial backtesting. Static validation shows our P-model effectively\nmatches market mean and volatility. In dynamic games, it demonstrates\nsignificantly higher profitability than a traditional Monte Carlo-based model\nfor European and Asian options. However, the model shows limitations in pricing\nproducts highly sensitive to extreme events, such as snowballs and\naccumulators, because it tends to underestimate tail risks. The study concludes\nthat diffusion models hold significant potential for enhancing pricing\naccuracy, though further research is needed to improve their ability to model\nextreme market risks.", "AI": {"tldr": "The paper introduces a novel pricing model for exotic financial products using Diffusion-Conditional Probability Model (DDPM) to improve price path realism and profitability over traditional models while highlighting its limitations in extreme market scenarios.", "motivation": "Traditional models fail to handle real-world market phenomena like fat-tailed distributions and volatility clustering, necessitating enhanced approaches to price exotic options and structured products.", "method": "The paper proposes DDPM, incorporating a composite loss function with financial-specific features and a P-Q dynamic game framework for adversarial backtesting to evaluate economic value.", "result": "The P-model accurately matches market mean and volatility in static validation, outperforms traditional Monte Carlo methods in profitability for European and Asian options, but struggles with products sensitive to extreme events due to underestimation of tail risks.", "conclusion": "Diffusion models show significant promise for more accurate pricing of structured products but require further refinement to effectively account for extreme market risks."}}
{"id": "2509.14051", "pdf": "https://arxiv.org/pdf/2509.14051", "abs": "https://arxiv.org/abs/2509.14051", "authors": ["Suhang You", "Carla Pitarch-Abaigar", "Sanket Kachole", "Sumedh Sonawane", "Juhyung Ha", "Anish Sudarshan Gada", "David Crandall", "Rakesh Shiradkar", "Spyridon Bakas"], "title": "PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings", "categories": ["cs.CV"], "comment": "11 pages, 1 figure, method paper for CHIMERA 2025 Challenge", "summary": "Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy\n(RP) experience biochemical recurrence (BCR), characterized by increased\nprostate specific antigen (PSA) and associated with increased mortality.\nAccurate early prediction of BCR, at the time of RP, would contribute to prompt\nadaptive clinical decision-making and improved patient outcomes. In this work,\nwe propose prostate cancer BCR prediction via fused multi-modal embeddings\n(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and\npathology data, following an intermediate fusion configuration in combination\nwith Cox Proportional Hazard regressors. Quantitative evaluation of our\nproposed approach reveals superior performance, when compared with late fusion\nconfigurations, yielding a mean C-index of 0.861 ($\\sigma=0.112$) on the\ninternal 5-fold nested cross-validation framework, and a C-index of 0.7103 on\nthe hold out data of CHIMERA 2025 challenge validation leaderboard.", "AI": {"tldr": "The paper proposes a method (PROFUSEme) to predict biochemical recurrence (BCR) in prostate cancer patients using multi-modal embeddings from clinical, radiology, and pathology data, achieving state-of-the-art performance.", "motivation": "Accurate early prediction of BCR in prostate cancer patients can support adaptive clinical decisions and improve patient outcomes.", "method": "The method integrates clinical, radiology, and pathology data using fused multi-modal embeddings combined with Cox Proportional Hazard regressors for prediction.", "result": "The approach achieved a mean C-index of 0.861 on internal validation and 0.7103 on external validation (CHIMERA 2025 challenge leaderboard), outperforming late fusion configurations.", "conclusion": "The fusion-based multi-modal method provides improved prediction accuracy for BCR, potentially improving clinical decision-making in prostate cancer treatment."}}
{"id": "2509.13376", "pdf": "https://arxiv.org/pdf/2509.13376", "abs": "https://arxiv.org/abs/2509.13376", "authors": ["Zhiwei Fan", "Tiangang Wang", "Kexin Huang", "Binwu Ying", "Xiaobo Zhou"], "title": "Unleashing the power of computational insights in revealing the complexity of biological systems in the new era of spatial multi-omics", "categories": ["q-bio.QM", "cs.LG"], "comment": "43 pages, 9 figures, 1 table", "summary": "Recent advances in spatial omics technologies have revolutionized our ability\nto study biological systems with unprecedented resolution. By preserving the\nspatial context of molecular measurements, these methods enable comprehensive\nmapping of cellular heterogeneity, tissue architecture, and dynamic biological\nprocesses in developmental biology, neuroscience, oncology, and evolutionary\nstudies. This review highlights a systematic overview of the continuous\nadvancements in both technology and computational algorithms that are paving\nthe way for a deeper, more systematic comprehension of the structure and\nmechanisms of mammalian tissues and organs by using spatial multi-omics. Our\nviewpoint demonstrates how advanced machine learning algorithms and multi-omics\nintegrative modeling can decode complex biological processes, including the\nspatial organization and topological relationships of cells during organ\ndevelopment, as well as key molecular signatures and regulatory networks\nunderlying tumorigenesis and metastasis. Finally, we outline future directions\nfor technological innovation and modeling insights of spatial omics in\nprecision medicine.", "AI": {"tldr": "This paper reviews advancements in spatial omics technologies and algorithms, emphasizing their role in mapping biological systems and decoding complex processes.", "motivation": "The paper aims to understand and leverage spatial omics technologies to improve analysis of cellular and tissue architecture in various biological contexts.", "method": "The review synthesizes technological advancements and computational models, highlighting machine learning and integrative approaches for spatial multi-omics analysis.", "result": "Spatial omics methods reveal insights into organ development, tumorigenesis, metastasis, and tissue architecture, aided by machine learning and integrative modeling.", "conclusion": "Spatial omics holds promising applications in precision medicine, with recommendations for further technological and computational innovations."}}
{"id": "2509.14055", "pdf": "https://arxiv.org/pdf/2509.14055", "abs": "https://arxiv.org/abs/2509.14055", "authors": ["Gang Cheng", "Xin Gao", "Li Hu", "Siqi Hu", "Mingyang Huang", "Chaonan Ji", "Ju Li", "Dechao Meng", "Jinwei Qi", "Penchong Qiao", "Zhen Shen", "Yafei Song", "Ke Sun", "Linrui Tian", "Feng Wang", "Guangyuan Wang", "Qi Wang", "Zhongjian Wang", "Jiayu Xiao", "Sheng Xu", "Bang Zhang", "Peng Zhang", "Xindi Zhang", "Zhe Zhang", "Jingren Zhou", "Lian Zhuo"], "title": "Wan-Animate: Unified Character Animation and Replacement with Holistic Replication", "categories": ["cs.CV"], "comment": "Project Page: https://humanaigc.github.io/wan-animate/", "summary": "We introduce Wan-Animate, a unified framework for character animation and\nreplacement. Given a character image and a reference video, Wan-Animate can\nanimate the character by precisely replicating the expressions and movements of\nthe character in the video to generate high-fidelity character videos.\nAlternatively, it can integrate the animated character into the reference video\nto replace the original character, replicating the scene's lighting and color\ntone to achieve seamless environmental integration. Wan-Animate is built upon\nthe Wan model. To adapt it for character animation tasks, we employ a modified\ninput paradigm to differentiate between reference conditions and regions for\ngeneration. This design unifies multiple tasks into a common symbolic\nrepresentation. We use spatially-aligned skeleton signals to replicate body\nmotion and implicit facial features extracted from source images to reenact\nexpressions, enabling the generation of character videos with high\ncontrollability and expressiveness. Furthermore, to enhance environmental\nintegration during character replacement, we develop an auxiliary Relighting\nLoRA. This module preserves the character's appearance consistency while\napplying the appropriate environmental lighting and color tone. Experimental\nresults demonstrate that Wan-Animate achieves state-of-the-art performance. We\nare committed to open-sourcing the model weights and its source code.", "AI": {"tldr": "Wan-Animate is a framework combining character animation and replacement by aligning motion and expressions with seamless integration into scenes.", "motivation": "The paper aims to solve the problem of creating high-fidelity animated character videos and seamlessly integrating characters into reference scenes.", "method": "The approach modifies the input paradigm of the Wan model, incorporating skeleton signals for body movements and implicit facial features for expressions, alongside an auxiliary Relighting LoRA module for environmental integration.", "result": "Wan-Animate showcases state-of-the-art performance in animation precision and environmental consistency.", "conclusion": "The framework achieves controllable, expressive character animation and seamless scene integration, with plans to open-source the code and model weights."}}
{"id": "2509.14060", "pdf": "https://arxiv.org/pdf/2509.14060", "abs": "https://arxiv.org/abs/2509.14060", "authors": ["Jun Du", "Weiwei Xing", "Ming Li", "Fei Richard Yu"], "title": "VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "Current multi-object tracking (MOT) algorithms typically overlook issues\ninherent in low-quality videos, leading to significant degradation in tracking\nperformance when confronted with real-world image deterioration. Therefore,\nadvancing the application of MOT algorithms in real-world low-quality video\nscenarios represents a critical and meaningful endeavor. To address the\nchallenges posed by low-quality scenarios, inspired by vision-language models,\nthis paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking\nframework (VSE-MOT). Specifically, we first design a tri-branch architecture\nthat leverages a vision-language model to extract global visual semantic\ninformation from images and fuse it with query vectors. Subsequently, to\nfurther enhance the utilization of visual semantic information, we introduce\nthe Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion\nModule (VSFM). The MOT-Adapter adapts the extracted global visual semantic\ninformation to suit multi-object tracking tasks, while the VSFM improves the\nefficacy of feature fusion. Through extensive experiments, we validate the\neffectiveness and superiority of the proposed method in real-world low-quality\nvideo scenarios. Its tracking performance metrics outperform those of existing\nmethods by approximately 8% to 20%, while maintaining robust performance in\nconventional scenarios.", "AI": {"tldr": "The paper introduces VSE-MOT, a framework for enhanced multi-object tracking in low-quality videos using vision-language models.", "motivation": "The authors aim to address the significant performance degradation of existing MOT algorithms when applied to low-quality real-world video footage.", "method": "They propose a tri-branch architecture leveraging a vision-language model, coupled with a Multi-Object Tracking Adapter (MOT-Adapter) and a Visual Semantic Fusion Module (VSFM) for better feature extraction and fusion.", "result": "Their experiments show that VSE-MOT achieves 8% to 20% better tracking performance metrics compared to existing methods in low-quality scenarios.", "conclusion": "The proposed VSE-MOT framework effectively enhances tracking performance in both low-quality and conventional scenarios, showcasing its robustness and superiority."}}
{"id": "2509.14084", "pdf": "https://arxiv.org/pdf/2509.14084", "abs": "https://arxiv.org/abs/2509.14084", "authors": ["Jingyi Yuan", "Jianxiong Ye", "Wenkang Chen", "Chenqiang Gao"], "title": "AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration", "categories": ["cs.CV"], "comment": null, "summary": "Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary\nnovel categories, offering a scalable and annotation-efficient solution.\nTraditionally, most ZSAD works have been based on the CLIP model, which\nperforms anomaly detection by calculating the similarity between visual and\ntext embeddings. Recently, vision foundation models such as DINOv3 have\ndemonstrated strong transferable representation capabilities. In this work, we\nare the first to adapt DINOv3 for ZSAD. However, this adaptation presents two\nkey challenges: (i) the domain bias between large-scale pretraining data and\nanomaly detection tasks leads to feature misalignment; and (ii) the inherent\nbias toward global semantics in pretrained representations often leads to\nsubtle anomalies being misinterpreted as part of the normal foreground objects,\nrather than being distinguished as abnormal regions. To overcome these\nchallenges, we introduce AD-DINOv3, a novel vision-language multimodal\nframework designed for ZSAD. Specifically, we formulate anomaly detection as a\nmultimodal contrastive learning problem, where DINOv3 is employed as the visual\nbackbone to extract patch tokens and a CLS token, and the CLIP text encoder\nprovides embeddings for both normal and abnormal prompts. To bridge the domain\ngap, lightweight adapters are introduced in both modalities, enabling their\nrepresentations to be recalibrated for the anomaly detection task. Beyond this\nbaseline alignment, we further design an Anomaly-Aware Calibration Module\n(AACM), which explicitly guides the CLS token to attend to anomalous regions\nrather than generic foreground semantics, thereby enhancing discriminability.\nExtensive experiments on eight industrial and medical benchmarks demonstrate\nthat AD-DINOv3 consistently matches or surpasses state-of-the-art methods,\nverifying its superiority as a general zero-shot anomaly detection framework.", "AI": {"tldr": "The paper proposes AD-DINOv3, a novel vision-language multimodal framework for Zero-Shot Anomaly Detection (ZSAD) using DINOv3. It addresses domain and semantic biases to identify anomalies effectively.", "motivation": "The motivation of this paper is to develop a scalable, annotation-efficient solution for ZSAD by leveraging DINOv3's transferable representation capabilities while addressing domain and semantic biases.", "method": "The method involves adapting DINOv3 for ZSAD using a multimodal contrastive learning approach. Lightweight adapters adjust domain gaps, and the Anomaly-Aware Calibration Module (AACM) focuses on anomalous regions rather than generic foreground semantics.", "result": "AD-DINOv3 demonstrates state-of-the-art or superior performance on eight industrial and medical benchmarks, showcasing its effectiveness for general ZSAD tasks.", "conclusion": "The proposed AD-DINOv3 framework overcomes challenges in ZSAD, providing a robust, scalable, and accurate anomaly detection solution that outperforms existing methods on diverse datasets."}}
{"id": "2509.13688", "pdf": "https://arxiv.org/pdf/2509.13688", "abs": "https://arxiv.org/abs/2509.13688", "authors": ["James Jincheng", "Youcheng Cai", "Ligang Liu"], "title": "CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Controllable, high-fidelity mesh editing remains a significant challenge in\n3D content creation. Existing generative methods often struggle with complex\ngeometries and fail to produce detailed results. We propose CraftMesh, a novel\nframework for high-fidelity generative mesh manipulation via Poisson Seamless\nFusion. Our key insight is to decompose mesh editing into a pipeline that\nleverages the strengths of 2D and 3D generative models: we edit a 2D reference\nimage, then generate a region-specific 3D mesh, and seamlessly fuse it into the\noriginal model. We introduce two core techniques: Poisson Geometric Fusion,\nwhich utilizes a hybrid SDF/Mesh representation with normal blending to achieve\nharmonious geometric integration, and Poisson Texture Harmonization for\nvisually consistent texture blending. Experimental results demonstrate that\nCraftMesh outperforms state-of-the-art methods, delivering superior global\nconsistency and local detail in complex editing tasks.", "AI": {"tldr": "CraftMesh leverages 2D and 3D generative models for high-fidelity mesh editing, outperforming existing methods in complex tasks.", "motivation": "Mesh editing with high fidelity and control in 3D content creation is challenging, as current methods struggle with intricate geometries and fail in detailed renders.", "method": "CraftMesh decomposes the editing process into modifying a 2D reference image, generating specific 3D mesh regions, and fusing them seamlessly. It uses Poisson Geometric Fusion and Texture Harmonization techniques.", "result": "CraftMesh achieves enhanced geometric integration and texture blending, yielding better consistency and detail compared to state-of-the-art methods.", "conclusion": "CraftMesh effectively addresses the limitations in high-fidelity mesh editing, enabling superior performance in complex tasks with seamless integration of geometric and texture updates."}}
{"id": "2509.14097", "pdf": "https://arxiv.org/pdf/2509.14097", "abs": "https://arxiv.org/abs/2509.14097", "authors": ["Yaru Chen", "Ruohao Guo", "Liting Gao", "Yang Xiang", "Qingyu Luo", "Zhenbo Li", "Wenwu Wang"], "title": "Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,\nvisible, and audio-visual events without temporal annotations. Previous work\nhas emphasized refining global predictions through contrastive or collaborative\nlearning, but neglected stable segment-level supervision and class-aware\ncross-modal alignment. To address this, we propose two strategies: (1) an\nexponential moving average (EMA)-guided pseudo supervision framework that\ngenerates reliable segment-level masks via adaptive thresholds or top-k\nselection, offering stable temporal guidance beyond video-level labels; and (2)\na class-aware cross-modal agreement (CMA) loss that aligns audio and visual\nembeddings at reliable segment-class pairs, ensuring consistency across\nmodalities while preserving temporal structure. Evaluations on LLP and UnAV-100\ndatasets shows that our method achieves state-of-the-art (SOTA) performance\nacross multiple metrics.", "AI": {"tldr": "The paper addresses weakly-supervised audio-visual video parsing (AVVP) using a novel EMA-guided pseudo supervision framework and a class-aware cross-modal agreement loss. These methods enhance segment-level supervision and cross-modal alignment, achieving state-of-the-art performance.", "motivation": "To improve weakly-supervised AVVP by addressing the lack of stable segment-level supervision and neglect of class-aware cross-modal alignment.", "method": "Introduces two key strategies: EMA-guided pseudo supervision for reliable segment-level masks and CMA loss for aligning audio and visual embeddings at segment-class pairs while preserving temporal structure.", "result": "The proposed approach outperforms previous methods and achieves state-of-the-art performance on the LLP and UnAV-100 datasets.", "conclusion": "The strategies introduced successfully address the deficiencies in existing methods, enhancing audio-visual event detection with better segment-level and cross-modal consistency."}}
{"id": "2509.14104", "pdf": "https://arxiv.org/pdf/2509.14104", "abs": "https://arxiv.org/abs/2509.14104", "authors": ["Leonard Hackel", "Tom Burgert", "Beg\u00fcm Demir"], "title": "CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning through masked autoencoders has attracted great\nattention for remote sensing (RS) foundation model (FM) development, enabling\nimproved representation learning across diverse sensors and downstream tasks.\nHowever, existing RS FMs often either suffer from substantial computational\ncomplexity during both training and inference or exhibit limited\nrepresentational capacity. These issues restrict their practical applicability\nin RS. To address this limitation, we propose an adaptation for enhancing the\nefficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism\ninto the FM. The integration of Soft MoEs into the FM allows modality-specific\nexpert specialization alongside shared cross-sensor representation learning. To\ndemonstrate the effectiveness of our adaptation, we apply it on the\nCross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor\nMixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic\ndescriptor-driven sampling strategy for the construction of a representative\nand diverse training set to train our CSMoE model. Extensive experiments on\nscene classification, semantic segmentation, and content-based image retrieval\ndemonstrate that our adaptation yields a reduction in computational\nrequirements while maintaining or improving representational performance.\nCompared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off\nbetween representational capacity, accuracy, and computational efficiency. On\naverage, CSMoE achieves more than twice the computational efficiency of\nexisting RS FMs, while maintaining competitive performance across all\nexperiments. These results show the effectiveness of the proposed adaptation\nfor creating computationally efficient RS FMs. The code for the model, the\ntraining set creation, and the model weights will be available at\nhttps://git.tu-berlin.de/rsim/csmoe.", "AI": {"tldr": "This paper introduces an efficient remote sensing foundation model using a Soft mixture-of-experts mechanism in Cross-Sensor Masked Autoencoder (CSMAE).", "motivation": "Remote sensing foundation models suffer from high computational complexity or limited representational capacity, restricting practical applicability.", "method": "The study adapts RS FMs by integrating Soft mixture-of-experts (MoE) for modality-specific and cross-sensor learning, applied to the CSMAE model and introducing thematic-climatic sampling for training data creation.", "result": "The proposed CSMoE achieves over twice the computational efficiency of existing RS foundation models while maintaining or improving performance in scene classification, semantic segmentation, and image retrieval.", "conclusion": "Soft MoE integration into RS foundation models effectively balances computational efficiency and representation quality, enhancing practical applicability in various tasks."}}
{"id": "2509.14119", "pdf": "https://arxiv.org/pdf/2509.14119", "abs": "https://arxiv.org/abs/2509.14119", "authors": ["Jiabo MA", "Wenqiang Li", "Jinbang Li", "Ziyi Liu", "Linshan Wu", "Fengtao Zhou", "Li Liang", "Ronald Cheong Kin Chan", "Terence T. W. Wong", "Hao Chen"], "title": "Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows", "categories": ["cs.CV"], "comment": "the arxiv version of the under review journal paper", "summary": "Accurate histopathological diagnosis often requires multiple differently\nstained tissue sections, a process that is time-consuming, labor-intensive, and\nenvironmentally taxing due to the use of multiple chemical stains. Recently,\nvirtual staining has emerged as a promising alternative that is faster,\ntissue-conserving, and environmentally friendly. However, existing virtual\nstaining methods face significant challenges in clinical applications,\nprimarily due to their reliance on well-aligned paired data. Obtaining such\ndata is inherently difficult because chemical staining processes can distort\ntissue structures, and a single tissue section cannot undergo multiple staining\nprocedures without damage or loss of information. As a result, most available\nvirtual staining datasets are either unpaired or roughly paired, making it\ndifficult for existing methods to achieve accurate pixel-level supervision. To\naddress this challenge, we propose a robust virtual staining framework\nfeaturing cascaded registration mechanisms to resolve spatial mismatches\nbetween generated outputs and their corresponding ground truth. Experimental\nresults demonstrate that our method significantly outperforms state-of-the-art\nmodels across five datasets, achieving an average improvement of 3.2% on\ninternal datasets and 10.1% on external datasets. Moreover, in datasets with\nsubstantial misalignment, our approach achieves a remarkable 23.8% improvement\nin peak signal-to-noise ratio compared to baseline models. The exceptional\nrobustness of the proposed method across diverse datasets simplifies the data\nacquisition process for virtual staining and offers new insights for advancing\nits development.", "AI": {"tldr": "The paper proposes a virtual staining method with cascaded registration mechanisms that resolves spatial mismatches in unpaired or poorly paired tissue section data. Experimental results demonstrate significant performance improvements over state-of-the-art models.", "motivation": "Histopathological diagnosis relies on chemical staining, which is time-consuming and environmentally taxing, requiring well-aligned paired data for virtual staining\u2014something inherently difficult due to tissue distortion and damage.", "method": "The authors proposed a robust virtual staining framework with cascaded registration mechanisms to correct spatial discrepancies in generated outputs and ground truth from unpaired or poorly paired datasets.", "result": "The proposed method significantly outperformed state-of-the-art models, with up to 23.8% improvement in peak signal-to-noise ratio and average gains of 3.2% and 10.1% on internal and external datasets, respectively.", "conclusion": "This approach enhances robustness in virtual staining across diverse datasets, simplifies data acquisition, and advances the development of environmentally friendly alternatives for histopathological diagnosis."}}
{"id": "2509.14120", "pdf": "https://arxiv.org/pdf/2509.14120", "abs": "https://arxiv.org/abs/2509.14120", "authors": ["Sara Concas", "Simone Maurizio La Cava", "Andrea Panzino", "Ester Masala", "Giulia Orr\u00f9", "Gian Luca Marcialis"], "title": "Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection", "categories": ["cs.CV"], "comment": "Accepted at the 2025 IEEE INTERNATIONAL CONFERENCE ON Metrology for\n  eXtended Reality, Artificial Intelligence and Neural Engineering", "summary": "Digital beautification through social media filters has become increasingly\npopular, raising concerns about the reliability of facial images and videos and\nthe effectiveness of automated face analysis. This issue is particularly\ncritical for digital manipulation detectors, systems aiming at distinguishing\nbetween genuine and manipulated data, especially in cases involving deepfakes\nand morphing attacks designed to deceive humans and automated facial\nrecognition. This study examines whether beauty filters impact the performance\nof deepfake and morphing attack detectors. We perform a comprehensive analysis,\nevaluating multiple state-of-the-art detectors on benchmark datasets before and\nafter applying various smoothing filters. Our findings reveal performance\ndegradation, highlighting vulnerabilities introduced by facial enhancements and\nunderscoring the need for robust detection models resilient to such\nalterations.", "AI": {"tldr": "This paper investigates how beauty filters affect the performance of deepfake and morphing attack detectors, revealing vulnerabilities due to facial modifications.", "motivation": "The growing use of beauty filters through social media raises concerns about the reliability of facial images and videos, especially for systems that aim to detect manipulated data and ensure security.", "method": "The authors evaluated state-of-the-art deepfake and morphing attack detectors using benchmark datasets before and after applying different smoothing filters.", "result": "The analysis showed that facial beautification filters degrade the performance of detectors, exposing their weaknesses.", "conclusion": "Facial enhancements via beauty filters create vulnerabilities in manipulation detection systems, emphasizing the need for more robust models."}}
{"id": "2509.14142", "pdf": "https://arxiv.org/pdf/2509.14142", "abs": "https://arxiv.org/abs/2509.14142", "authors": ["Peng Xu", "Shengwu Xiong", "Jiajun Zhang", "Yaxiong Chen", "Bowen Zhou", "Chen Change Loy", "David A. Clifton", "Kyoung Mu Lee", "Luc Van Gool", "Ruiming He", "Ruilin Yao", "Xinwei Long", "Jirui Huang", "Kai Tian", "Sa Yang", "Yihua Shao", "Jin Feng", "Yue Zhong", "Jiakai Zhou", "Cheng Tang", "Tianyu Zou", "Yifang Zhang", "Junming Liang", "Guoyou Li", "Zhaoxiang Wang", "Qiang Zhou", "Yichen Zhao", "Shili Xiong", "Hyeongjin Nam", "Jaerin Lee", "Jaeyoung Chung", "JoonKyu Park", "Junghun Oh", "Kanggeon Lee", "Wooseok Lee", "Juneyoung Ro", "Turghun Osman", "Can Hu", "Chaoyang Liao", "Cheng Chen", "Chengcheng Han", "Chenhao Qiu", "Chong Peng", "Cong Xu", "Dailin Li", "Feiyu Wang", "Feng Gao", "Guibo Zhu", "Guopeng Tang", "Haibo Lu", "Han Fang", "Han Qi", "Hanxiao Wu", "Haobo Cheng", "Hongbo Sun", "Hongyao Chen", "Huayong Hu", "Hui Li", "Jiaheng Ma", "Jiang Yu", "Jianing Wang", "Jie Yang", "Jing He", "Jinglin Zhou", "Jingxuan Li", "Josef Kittler", "Lihao Zheng", "Linnan Zhao", "Mengxi Jia", "Muyang Yan", "Nguyen Thanh Thien", "Pu Luo", "Qi Li", "Shien Song", "Shijie Dong", "Shuai Shao", "Shutao Li", "Taofeng Xue", "Tianyang Xu", "Tianyi Gao", "Tingting Li", "Wei Zhang", "Weiyang Su", "Xiaodong Dong", "Xiao-Jun Wu", "Xiaopeng Zhou", "Xin Chen", "Xin Wei", "Xinyi You", "Xudong Kang", "Xujie Zhou", "Xusheng Liu", "Yanan Wang", "Yanbin Huang", "Yang Liu", "Yang Yang", "Yanglin Deng", "Yashu Kang", "Ye Yuan", "Yi Wen", "Yicen Tian", "Yilin Tao", "Yin Tang", "Yipeng Lin", "Yiqing Wang", "Yiting Xi", "Yongkang Yu", "Yumei Li", "Yuxin Qin", "Yuying Chen", "Yuzhe Cen", "Zhaofan Zou", "Zhaohong Liu", "Zhehao Shen", "Zhenglin Du", "Zhengyang Li", "Zhenni Huang", "Zhenwei Shao", "Zhilong Song", "Zhiyong Feng", "Zhiyu Wang", "Zhou Yu", "Ziang Li", "Zihan Zhai", "Zijian Zhang", "Ziyang Peng", "Ziyun Xiao", "Zongshu Li"], "title": "MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook", "categories": ["cs.CV"], "comment": "ICCV 2025 MARS2 Workshop and Challenge \"Multimodal Reasoning and Slow\n  Thinking in the Large Model Era: Towards System 2 and Beyond''", "summary": "This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim\nto bring together different approaches in multimodal machine learning and LLMs\nvia a large benchmark. We hope it better allows researchers to follow the\nstate-of-the-art in this very dynamic area. Meanwhile, a growing number of\ntestbeds have boosted the evolution of general-purpose large language models.\nThus, this year's MARS2 focuses on real-world and specialized scenarios to\nbroaden the multimodal reasoning applications of MLLMs. Our organizing team\nreleased two tailored datasets Lens and AdsQA as test sets, which support\ngeneral reasoning in 12 daily scenarios and domain-specific reasoning in\nadvertisement videos, respectively. We evaluated 40+ baselines that include\nboth generalist MLLMs and task-specific models, and opened up three competition\ntracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question\nAnswering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative\nAdvertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and\nindustrial institutions have registered and 40+ valid submissions (out of\n1200+) have been included in our ranking lists. Our datasets, code sets (40+\nbaselines and 15+ participants' methods), and rankings are publicly available\non the MARS2 workshop website and our GitHub organization page\nhttps://github.com/mars2workshop/, where our updates and announcements of\nupcoming events will be continuously provided.", "AI": {"tldr": "The paper reviews the MARS2 2025 Challenge focused on multimodal reasoning using machine learning approaches and large language models (LLMs), presenting datasets, evaluation baselines, and competition results.", "motivation": "To advance the evolution of multimodal reasoning applications and provide a benchmark for researchers in the field to track state-of-the-art developments.", "method": "Released two datasets (Lens and AdsQA) addressing general reasoning in daily scenarios and domain-specific reasoning in advertisement videos, evaluated over 40 baselines, and structured competitions into three tracks: VG-RS, VQA-SA, and VR-Ads.", "result": "Successful organization with 76 teams registering and 40+ valid submissions analyzed from more than 1200, with publicly available resources including datasets, codes, and rankings.", "conclusion": "MARS2 Challenge effectively fosters growth in multimodal reasoning by providing benchmarks and promoting diverse approaches via datasets, competitions, and resources."}}
{"id": "2509.14149", "pdf": "https://arxiv.org/pdf/2509.14149", "abs": "https://arxiv.org/abs/2509.14149", "authors": ["Haotian Li", "Jianbo Jiao"], "title": "An Exploratory Study on Abstract Images and Visual Representations Learned from Them", "categories": ["cs.CV"], "comment": "Accepted to BMVC 2025", "summary": "Imagine living in a world composed solely of primitive shapes, could you\nstill recognise familiar objects? Recent studies have shown that abstract\nimages-constructed by primitive shapes-can indeed convey visual semantic\ninformation to deep learning models. However, representations obtained from\nsuch images often fall short compared to those derived from traditional raster\nimages. In this paper, we study the reasons behind this performance gap and\ninvestigate how much high-level semantic content can be captured at different\nabstraction levels. To this end, we introduce the Hierarchical Abstraction\nImage Dataset (HAID), a novel data collection that comprises abstract images\ngenerated from normal raster images at multiple levels of abstraction. We then\ntrain and evaluate conventional vision systems on HAID across various tasks\nincluding classification, segmentation, and object detection, providing a\ncomprehensive study between rasterised and abstract image representations. We\nalso discuss if the abstract image can be considered as a potentially effective\nformat for conveying visual semantic information and contributing to vision\ntasks.", "AI": {"tldr": "This study investigates abstract images' capacity to convey visual semantics compared to raster images, using a new dataset (HAID) and analyzing model performance across various computer vision tasks.", "motivation": "To explore why abstract images often underperform raster images in conveying high-level semantic information and determine their effectiveness as a potential image format in vision tasks.", "method": "The authors created the Hierarchical Abstraction Image Dataset (HAID), a collection of abstract images generated at varying abstraction levels from raster images. They trained vision systems on HAID for tasks such as classification, segmentation, and object detection.", "result": "The study provided a detailed performance comparison of vision systems trained on raster images versus abstract images for multiple vision tasks. The findings shed light on the limitations and potential of abstract representations.", "conclusion": "The authors evaluate whether abstract images can serve as an effective medium for high-level semantic information, identifying room for further refinement in utilizing them for vision tasks."}}
{"id": "2509.14151", "pdf": "https://arxiv.org/pdf/2509.14151", "abs": "https://arxiv.org/abs/2509.14151", "authors": ["Rongyu Zhang", "Jiaming Liu", "Xiaoqi Li", "Xiaowei Chi", "Dan Wang", "Li Du", "Yuan Du", "Shanghang Zhang"], "title": "BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection", "categories": ["cs.CV"], "comment": "Accepted by IEEE TCSVT", "summary": "Vision-centric Bird's Eye View (BEV) perception holds considerable promise\nfor autonomous driving. Recent studies have prioritized efficiency or accuracy\nenhancements, yet the issue of domain shift has been overlooked, leading to\nsubstantial performance degradation upon transfer. We identify major domain\ngaps in real-world cross-domain scenarios and initiate the first effort to\naddress the Domain Adaptation (DA) challenge in multi-view 3D object detection\nfor BEV perception. Given the complexity of BEV perception approaches with\ntheir multiple components, domain shift accumulation across multi-geometric\nspaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain\nadaptation. In this paper, we introduce an innovative geometric-aware\nteacher-student framework, BEVUDA++, to diminish this issue, comprising a\nReliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.\nSpecifically, RDT effectively blends target LiDAR with dependable depth\npredictions to generate depth-aware information based on uncertainty\nestimation, enhancing the extraction of Voxel and BEV features that are\nessential for understanding the target domain. To collaboratively reduce the\ndomain shift, GCS maps features from multiple spaces into a unified geometric\nembedding space, thereby narrowing the gap in data distribution between the two\ndomains. Additionally, we introduce a novel Uncertainty-guided Exponential\nMoving Average (UEMA) to further reduce error accumulation due to domain shifts\ninformed by previously obtained uncertainty guidance. To demonstrate the\nsuperiority of our proposed method, we execute comprehensive experiments in\nfour cross-domain scenarios, securing state-of-the-art performance in BEV 3D\nobject detection tasks, e.g., 12.9\\% NDS and 9.5\\% mAP enhancement on Day-Night\nadaptation.", "AI": {"tldr": "The paper proposes a framework, BEVUDA++, to tackle domain adaptation challenges in multi-view 3D object detection for Bird's Eye View (BEV) perception in autonomous driving, achieving state-of-the-art performance.", "motivation": "Domain shift in BEV perception significantly affects performance in cross-domain scenarios, and this paper seeks to address this overlooked issue.", "method": "The paper introduces BEVUDA++, a geometric-aware teacher-student framework with components such as Reliable Depth Teacher (RDT), Geometric Consistent Student (GCS), and Uncertainty-guided Exponential Moving Average (UEMA).", "result": "BEVUDA++ achieves state-of-the-art performance in cross-domain BEV 3D object detection tasks, improving metrics like NDS by 12.9% and mAP by 9.5% in Day-Night adaptation.", "conclusion": "This work successfully mitigates domain shift challenges in BEV perception and lays the groundwork for future advancements in domain adaptation for 3D object detection."}}
{"id": "2509.14165", "pdf": "https://arxiv.org/pdf/2509.14165", "abs": "https://arxiv.org/abs/2509.14165", "authors": ["Michal Szczepanski", "Martyna Poreba", "Karim Haroun"], "title": "Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Transformers (ViTs) achieve state-of-the-art performance in semantic\nsegmentation but are hindered by high computational and memory costs. To\naddress this, we propose STEP (SuperToken and Early-Pruning), a hybrid\ntoken-reduction framework that combines dynamic patch merging and token pruning\nto enhance efficiency without significantly compromising accuracy. At the core\nof STEP is dCTS, a lightweight CNN-based policy network that enables flexible\nmerging into superpatches. Encoder blocks integrate also early-exits to remove\nhigh-confident supertokens, lowering computational load. We evaluate our method\non high-resolution semantic segmentation benchmarks, including images up to\n1024 x 1024, and show that when dCTS is applied alone, the token count can be\nreduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching\nscheme. This yields a 2.6x reduction in computational cost and a 3.4x increase\nin throughput when using ViT-Large as the backbone. Applying the full STEP\nframework further improves efficiency, reaching up to a 4x reduction in\ncomputational complexity and a 1.7x gain in inference speed, with a maximum\naccuracy drop of no more than 2.0%. With the proposed STEP configurations, up\nto 40% of tokens can be confidently predicted and halted before reaching the\nfinal encoder layer.", "AI": {"tldr": "The paper introduces STEP, a framework to reduce computational costs in Vision Transformers (ViTs) for semantic segmentation by dynamically merging and pruning tokens, achieving improved efficiency with minor accuracy loss.", "motivation": "High computational and memory costs limit the practical deployment of Vision Transformers for tasks like semantic segmentation.", "method": "STEP uses a dynamic framework combining token reduction via superpatch merging (via dCTS) and early pruning to lower the computational and memory demands of ViTs.", "result": "The approach reduces token counts by up to 4x, computational complexity by 4x, and boosts inference speed by 1.7x with a minimal accuracy drop of up to 2%.", "conclusion": "STEP effectively balances efficiency and accuracy trade-offs, making Vision Transformers more practical for high-resolution semantic segmentation tasks."}}
{"id": "2509.13476", "pdf": "https://arxiv.org/pdf/2509.13476", "abs": "https://arxiv.org/abs/2509.13476", "authors": ["Md Masud Rana", "Farjana Tasnim Mukta", "Duc D. Nguyen"], "title": "A Geometric Graph-Based Deep Learning Model for Drug-Target Affinity Prediction", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "In structure-based drug design, accurately estimating the binding affinity\nbetween a candidate ligand and its protein receptor is a central challenge.\nRecent advances in artificial intelligence, particularly deep learning, have\ndemonstrated superior performance over traditional empirical and physics-based\nmethods for this task, enabled by the growing availability of structural and\nexperimental affinity data. In this work, we introduce DeepGGL, a deep\nconvolutional neural network that integrates residual connections and an\nattention mechanism within a geometric graph learning framework. By leveraging\nmultiscale weighted colored bipartite subgraphs, DeepGGL effectively captures\nfine-grained atom-level interactions in protein-ligand complexes across\nmultiple scales. We benchmarked DeepGGL against established models on CASF-2013\nand CASF-2016, where it achieved state-of-the-art performance with significant\nimprovements across diverse evaluation metrics. To further assess robustness\nand generalization, we tested the model on the CSAR-NRC-HiQ dataset and the\nPDBbind v2019 holdout set. DeepGGL consistently maintained high predictive\naccuracy, highlighting its adaptability and reliability for binding affinity\nprediction in structure-based drug discovery.", "AI": {"tldr": "This study introduces DeepGGL, an AI model using geometric graph learning for improved binding affinity prediction in drug design tasks, outperforming existing methods.", "motivation": "The paper aims to address the challenge of accurately predicting binding affinity in structure-based drug design, leveraging advancements in deep learning.", "method": "DeepGGL uses a deep convolutional neural network with residual connections and attention, structured within a geometric graph learning framework, to model protein-ligand interactions across multiple scales.", "result": "DeepGGL achieved state-of-the-art performance on benchmarking datasets like CASF-2013, CASF-2016, CSAR-NRC-HiQ, and PDBbind v2019, showing significant accuracy improvements.", "conclusion": "DeepGGL demonstrates robust performance and generalization capabilities, making it a reliable tool for binding affinity prediction in drug discovery applications."}}
{"id": "2509.14227", "pdf": "https://arxiv.org/pdf/2509.14227", "abs": "https://arxiv.org/abs/2509.14227", "authors": ["Nisarg A. Shah", "Amir Ziai", "Chaitanya Ekanadham", "Vishal M. Patel"], "title": "Cin\u00e9aste: A Fine-grained Contextual Movie Question Answering Benchmark", "categories": ["cs.CV", "I.2.10; I.2.7"], "comment": "11 pages, 5 figures, 5 tables", "summary": "While recent advancements in vision-language models have improved video\nunderstanding, diagnosing their capacity for deep, narrative comprehension\nremains a challenge. Existing benchmarks often test short-clip recognition or\nuse template-based questions, leaving a critical gap in evaluating fine-grained\nreasoning over long-form narrative content. To address these gaps, we introduce\n$\\mathsf{Cin\\acute{e}aste}$, a comprehensive benchmark for long-form movie\nunderstanding. Our dataset comprises 3,119 multiple-choice question-answer\npairs derived from 1,805 scenes across 200 diverse movies, spanning five novel\nfine-grained contextual reasoning categories. We use GPT-4o to generate\ndiverse, context-rich questions by integrating visual descriptions, captions,\nscene titles, and summaries, which require deep narrative understanding. To\nensure high-quality evaluation, our pipeline incorporates a two-stage filtering\nprocess: Context-Independence filtering ensures questions require video\ncontext, while Contextual Veracity filtering validates factual consistency\nagainst the movie content, mitigating hallucinations. Experiments show that\nexisting MLLMs struggle on $\\mathsf{Cin\\acute{e}aste}$; our analysis reveals\nthat long-range temporal reasoning is a primary bottleneck, with the top\nopen-source model achieving only 63.15\\% accuracy. This underscores significant\nchallenges in fine-grained contextual understanding and the need for\nadvancements in long-form movie comprehension.", "AI": {"tldr": "This paper introduces 'Cin\u00e9aste', a benchmark to evaluate deep narrative understanding of long-form movies, highlighting shortcomings in current vision-language models.", "motivation": "Existing benchmarks fail to adequately measure fine-grained reasoning and deep narrative comprehension in long-form video understanding.", "method": "The authors created a dataset of 3,119 question-answer pairs covering 200 movies, employing GPT-4o and a two-step filtering process to ensure context dependence and factual consistency.", "result": "Experiments reveal that current models struggle with Cin\u00e9aste, achieving only 63.15% accuracy, particularly due to challenges in long-range temporal reasoning.", "conclusion": "There is a significant gap in current model capabilities for fine-grained narrative understanding, necessitating further advancements in this domain."}}
{"id": "2509.14232", "pdf": "https://arxiv.org/pdf/2509.14232", "abs": "https://arxiv.org/abs/2509.14232", "authors": ["Zhaokai Wang", "Penghao Yin", "Xiangyu Zhao", "Changyao Tian", "Yu Qiao", "Wenhai Wang", "Jifeng Dai", "Gen Luo"], "title": "GenExam: A Multidisciplinary Text-to-Image Exam", "categories": ["cs.CV"], "comment": null, "summary": "Exams are a fundamental test of expert-level intelligence and require\nintegrated understanding, reasoning, and generation. Existing exam-style\nbenchmarks mainly focus on understanding and reasoning tasks, and current\ngeneration benchmarks emphasize the illustration of world knowledge and visual\nconcepts, neglecting the evaluation of rigorous drawing exams. We introduce\nGenExam, the first benchmark for multidisciplinary text-to-image exams,\nfeaturing 1,000 samples across 10 subjects with exam-style prompts organized\nunder a four-level taxonomy. Each problem is equipped with ground-truth images\nand fine-grained scoring points to enable a precise evaluation of semantic\ncorrectness and visual plausibility. Experiments show that even\nstate-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve\nless than 15% strict scores, and most models yield almost 0%, suggesting the\ngreat challenge of our benchmark. By framing image generation as an exam,\nGenExam offers a rigorous assessment of models' ability to integrate knowledge,\nreasoning, and generation, providing insights on the path to general AGI.", "AI": {"tldr": "GenExam introduces a comprehensive benchmark for evaluating text-to-image generation in intellectual and multidisciplinary exams.", "motivation": "Address the gap in evaluating text-to-image systems with rigorous multidisciplinary examination-style tasks.", "method": "Designed a benchmark consisting of 1,000 samples across 10 subjects, organized under a four-level taxonomy with scoring criteria.", "result": "State-of-the-art models achieved under 15% strict scores for semantic and visual correctness, highlighting challenges in this task.", "conclusion": "GenExam provides a new framework to rigorously test and guide the progression toward general Artificial General Intelligence (AGI)."}}
{"id": "2509.13358", "pdf": "https://arxiv.org/pdf/2509.13358", "abs": "https://arxiv.org/abs/2509.13358", "authors": ["Ethan Koland", "Lin Xi", "Nadeev Wijesuriya", "YingLiang Ma"], "title": "3D Reconstruction of Coronary Vessel Trees from Biplanar X-Ray Images Using a Geometric Approach", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "X-ray angiography is widely used in cardiac interventions to visualize\ncoronary vessels, assess integrity, detect stenoses and guide treatment. We\npropose a framework for reconstructing 3D vessel trees from biplanar X-ray\nimages which are extracted from two X-ray videos captured at different C-arm\nangles. The proposed framework consists of three main components: image\nsegmentation, motion phase matching, and 3D reconstruction. An automatic video\nsegmentation method for X-ray angiography to enable semantic segmentation for\nimage segmentation and motion phase matching. The goal of the motion phase\nmatching is to identify a pair of X-ray images that correspond to a similar\nrespiratory and cardiac motion phase to reduce errors in 3D reconstruction.\nThis is achieved by tracking a stationary object such as a catheter or lead\nwithin the X-ray video. The semantic segmentation approach assigns different\nlabels to different object classes enabling accurate differentiation between\nblood vessels, balloons, and catheters. Once a suitable image pair is selected,\nkey anatomical landmarks (vessel branching points and endpoints) are matched\nbetween the two views using a heuristic method that minimizes reconstruction\nerrors. This is followed by a novel geometric reconstruction algorithm to\ngenerate the 3D vessel tree. The algorithm computes the 3D vessel centrelines\nby determining the intersection of two 3D surfaces. Compared to traditional\nmethods based on epipolar constraints, the proposed approach simplifies there\nconstruction workflow and improves overall accuracy. We trained and validated\nour segmentation method on 62 X-ray angiography video sequences. On the test\nset, our method achieved a segmentation accuracy of 0.703. The 3D\nreconstruction framework was validated by measuring the reconstruction error of\nkey anatomical landmarks, achieving a reprojection errors of 0.62mm +/- 0.38mm.", "AI": {"tldr": "The paper presents a framework for reconstructing 3D vessel trees from biplanar X-ray images using image segmentation, motion phase matching, and a geometric reconstruction algorithm, achieving improved accuracy.", "motivation": "To enhance visualization in cardiac interventions by providing accurate 3D reconstruction of coronary vessels from X-ray images, addressing limitations in traditional methods.", "method": "The framework employs automatic video segmentation for semantic classification, motion phase matching to align respiratory and cardiac phases, and a novel geometric reconstruction algorithm using intersection of 3D surfaces.", "result": "Segmentation accuracy of 0.703 and reprojection errors of 0.62mm +/- 0.38mm were achieved on the test sets, validating the method's effectiveness.", "conclusion": "The proposed approach simplifies the 3D reconstruction workflow, improves accuracy, and shows promise for aiding cardiac interventions through better visualization of vessel anatomy."}}
{"id": "2509.13854", "pdf": "https://arxiv.org/pdf/2509.13854", "abs": "https://arxiv.org/abs/2509.13854", "authors": ["Jack McKinlay", "Marina De Vos", "Janina A. Hoffmann", "Andreas Theodorou"], "title": "Understanding the Process of Human-AI Value Alignment", "categories": ["cs.CY", "cs.AI"], "comment": "39 pages, 7 figures", "summary": "Background: Value alignment in computer science research is often used to\nrefer to the process of aligning artificial intelligence with humans, but the\nway the phrase is used often lacks precision. Objectives: In this paper, we\nconduct a systematic literature review to advance the understanding of value\nalignment in artificial intelligence by characterising the topic in the context\nof its research literature. We use this to suggest a more precise definition of\nthe term. Methods: We analyse 172 value alignment research articles that have\nbeen published in recent years and synthesise their content using thematic\nanalyses. Results: Our analysis leads to six themes: value alignment drivers &\napproaches; challenges in value alignment; values in value alignment; cognitive\nprocesses in humans and AI; human-agent teaming; and designing and developing\nvalue-aligned systems. Conclusions: By analysing these themes in the context of\nthe literature we define value alignment as an ongoing process between humans\nand autonomous agents that aims to express and implement abstract values in\ndiverse contexts, while managing the cognitive limits of both humans and AI\nagents and also balancing the conflicting ethical and political demands\ngenerated by the values in different groups. Our analysis gives rise to a set\nof research challenges and opportunities in the field of value alignment for\nfuture work.", "AI": {"tldr": "This paper conducts a systematic review of 172 articles on value alignment in AI, defines the term, and outlines research challenges.", "motivation": "To improve understanding and provide a more precise definition of 'value alignment' in AI research.", "method": "The paper uses thematic analysis on 172 research articles concerning value alignment in artificial intelligence.", "result": "Six themes emerge: drivers & approaches, challenges, values in alignment, cognitive processes, human-agent teaming, designing value-aligned systems.", "conclusion": "The paper defines value alignment as an ongoing process between humans and AI, addressing abstract values, cognitive limits, and conflicting ethical/political demands, and highlights future research opportunities."}}
{"id": "2509.13628", "pdf": "https://arxiv.org/pdf/2509.13628", "abs": "https://arxiv.org/abs/2509.13628", "authors": ["Mert G\u00fcrb\u00fczbalaban", "Yasa Syed", "Necdet Serhat Aybat"], "title": "Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "We study trade-offs between convergence rate and robustness to gradient\nerrors in first-order methods. Our focus is on generalized momentum methods\n(GMMs), a class that includes Nesterov's accelerated gradient, heavy-ball, and\ngradient descent. We allow stochastic gradient errors that may be adversarial\nand biased, and quantify robustness via the risk-sensitive index (RSI) from\nrobust control theory. For quadratic objectives with i.i.d. Gaussian noise, we\ngive closed-form expressions for RSI using 2x2 Riccati equations, revealing a\nPareto frontier between RSI and convergence rate over stepsize and momentum\nchoices. We prove a large-deviation principle for time-averaged suboptimality\nand show that the rate function is, up to scaling, the convex conjugate of the\nRSI. We further connect RSI to the $H_{\\infty}$-norm, showing that stronger\nworst-case robustness (smaller $H_{\\infty}$ norm) yields sharper decay of tail\nprobabilities. Beyond quadratics, under biased sub-Gaussian gradient errors, we\nderive non-asymptotic bounds on a finite-time analogue of the RSI, giving\nfinite-time high-probability guarantees and large-deviation bounds. We also\nobserve an analogous trade-off between RSI and convergence-rate bounds for\nsmooth strongly convex functions. To our knowledge, these are the first\nnon-asymptotic guarantees and risk-sensitive analysis of GMMs with biased\ngradients. Numerical experiments on robust regression illustrate the results.", "AI": {"tldr": "This paper investigates the trade-offs between convergence rate and robustness to stochastic gradient errors in generalized momentum methods (GMMs), providing both theoretical guarantees and numerical experiments.", "motivation": "The authors aim to understand how to balance efficient convergence (speed) and robustness to errors in gradient computations within first-order optimization methods.", "method": "They utilize robust control theory concepts, specifically the risk-sensitive index (RSI), to analyze stochastic gradient errors. Theoretical tools like Riccati equations, $H_{\\infty}$-norms, and large-deviation principles are employed for various function scenarios (e.g., quadratic and smooth strongly convex functions).", "result": "Closed-form expressions reveal a Pareto frontier between RSI and convergence rate for Gaussian noise. Non-asymptotic bounds, finite-time guarantees, and large-deviation bounds are derived under biased sub-Gaussian errors. A connection is established between worst-case robustness ($H_{\\infty}$-norm) and tail probability decay.", "conclusion": "The study provides the first non-asymptotic analysis and risk-sensitive guarantees for GMMs with biased gradients, advancing their understanding and offering practical insights, as seen in numerical experiments on robust regression."}}
{"id": "2509.13892", "pdf": "https://arxiv.org/pdf/2509.13892", "abs": "https://arxiv.org/abs/2509.13892", "authors": ["Gustavo Kruger", "Nikhil Sachdeva", "Michael Sobolev"], "title": "Synthetic Data Generation for Screen Time and App Usage", "categories": ["cs.HC", "cs.AI", "I.2; J.4"], "comment": "14 pages", "summary": "Smartphone usage data can provide valuable insights for understanding\ninteraction with technology and human behavior. However, collecting\nlarge-scale, in-the-wild smartphone usage logs is challenging due to high\ncosts, privacy concerns, under representative user samples and biases like\nnon-response that can skew results. These challenges call for exploring\nalternative approaches to obtain smartphone usage datasets. In this context,\nlarge language models (LLMs) such as Open AI's ChatGPT present a novel approach\nfor synthetic smartphone usage data generation, addressing limitations of\nreal-world data collection. We describe a case study on how four prompt\nstrategies influenced the quality of generated smartphone usage data. We\ncontribute with insights on prompt design and measures of data quality,\nreporting a prompting strategy comparison combining two factors, prompt level\nof detail (describing a user persona, describing the expected results\ncharacteristics) and seed data inclusion (with versus without an initial real\nusage example). Our findings suggest that using LLMs to generate structured and\nbehaviorally plausible smartphone use datasets is feasible for some use cases,\nespecially when using detailed prompts. Challenges remain in capturing diverse\nnuances of human behavioral patterns in a single synthetic dataset, and\nevaluating tradeoffs between data fidelity and diversity, suggesting the need\nfor use-case-specific evaluation metrics and future research with more diverse\nseed data and different LLM models.", "AI": {"tldr": "The paper explores using large language models (LLMs) like ChatGPT to generate synthetic smartphone usage datasets, comparing prompt strategies to ensure quality while addressing challenges like diversity and fidelity.", "motivation": "Real-world smartphone usage data collection faces challenges such as high costs, privacy concerns, skewed samples, and biases, necessitating alternative methods for data generation.", "method": "The study conducted a case study comparing four prompt strategies for synthetic data generation, leveraging prompt detail (user persona description and results characteristics) and inclusion of seed data.", "result": "Detailed prompts showed the most promising results for generating structured and behaviorally plausible smartphone usage data, though challenges remain in capturing human behavioral nuances and balancing fidelity with diversity.", "conclusion": "LLMs offer a feasible alternative for generating synthetic smartphone datasets for specific use cases, but limitations in data diversity and the need for use-case-specific evaluation metrics highlight the potential for improvement through future research and diverse seed data."}}
{"id": "2509.13653", "pdf": "https://arxiv.org/pdf/2509.13653", "abs": "https://arxiv.org/abs/2509.13653", "authors": ["Hang Ren", "Yulin Wu", "Shuhan Qi", "Jiajia Zhang", "Xiaozhen Sun", "Tianzi Ma", "Xuan Wang"], "title": "Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Regret minimization is a powerful method for finding Nash equilibria in\nNormal-Form Games (NFGs) and Extensive-Form Games (EFGs), but it typically\nguarantees convergence only for the average strategy. However, computing the\naverage strategy requires significant computational resources or introduces\nadditional errors, limiting its practical applicability. The Reward\nTransformation (RT) framework was introduced to regret minimization to achieve\nlast-iterate convergence through reward function regularization. However, it\nfaces practical challenges: its performance is highly sensitive to manually\ntuned parameters, which often deviate from theoretical convergence conditions,\nleading to slow convergence, oscillations, or stagnation in local optima.\n  Inspired by previous work, we propose an adaptive technique to address these\nissues, ensuring better consistency between theoretical guarantees and\npractical performance for RT Regret Matching (RTRM), RT Counterfactual Regret\nMinimization (RTCFR), and their variants in solving NFGs and EFGs more\neffectively. Our adaptive methods dynamically adjust parameters, balancing\nexploration and exploitation while improving regret accumulation, ultimately\nenhancing asymptotic last-iterate convergence and achieving linear convergence.\nExperimental results demonstrate that our methods significantly accelerate\nconvergence, outperforming state-of-the-art algorithms.", "AI": {"tldr": "This paper proposes adaptive techniques to improve convergence speed and reliability in regret minimization methods used in game theory.", "motivation": "Existing methods for regret minimization rely heavily on average strategy computation, which is resource-intensive and error-prone. Reward Transformation frameworks, although promising, require manual tuning, making them impractical.", "method": "The authors introduce adaptive methods that dynamically adjust parameters, enhancing exploration-exploitation balance and improving regret accumulation during Reward Transformation.", "result": "The adaptive techniques led to faster convergence and better performance compared to state-of-the-art algorithms in solving Normal-Form and Extensive-Form Games.", "conclusion": "Adaptive methods improve theoretical consistency and practical applicability of reward transformations in regret minimization, achieving enhanced last-iterate and linear convergence."}}
{"id": "2509.13428", "pdf": "https://arxiv.org/pdf/2509.13428", "abs": "https://arxiv.org/abs/2509.13428", "authors": ["Katrina Nash", "James Vaz", "Ahmed Maiter", "Christopher Johns", "Nicholas Woznitza", "Aditya Kale", "Abdala Espinosa Morgado", "Rhidian Bramley", "Mark Hall", "David Lowe", "Alex Novak", "Sarim Ather"], "title": "Autonomous Reporting of Normal Chest X-rays by Artificial Intelligence in the United Kingdom. Can We Take the Human Out of the Loop?", "categories": ["q-bio.PE", "cs.CV"], "comment": null, "summary": "Chest X-rays (CXRs) are the most commonly performed imaging investigation. In\nthe UK, many centres experience reporting delays due to radiologist workforce\nshortages. Artificial intelligence (AI) tools capable of distinguishing normal\nfrom abnormal CXRs have emerged as a potential solution. If normal CXRs could\nbe safely identified and reported without human input, a substantial portion of\nradiology workload could be reduced.\n  This article examines the feasibility and implications of autonomous AI\nreporting of normal CXRs. Key issues include defining normal, ensuring\ngeneralisability across populations, and managing the sensitivity-specificity\ntrade-off. It also addresses legal and regulatory challenges, such as\ncompliance with IR(ME)R and GDPR, and the lack accountability frameworks for\nerrors. Further considerations include the impact on radiologists practice, the\nneed for robust post-market surveillance, and incorporation of patient\nperspectives. While the benefits are clear, adoption must be cautious.", "AI": {"tldr": "The paper explores the feasibility, challenges, and implications of using AI to autonomously report normal chest X-rays (CXRs) to reduce radiology workloads.", "motivation": "The paper is motivated by the issue of delays in CXR reporting caused by radiologist shortages, and the potential of AI to identify normal CXRs autonomously as a solution.", "method": "The article examines considerations such as defining what qualifies as a normal CXR, ensuring AI's generalizability, legal/regulatory challenges, and impacts on radiologists and patient perspectives.", "result": "Key challenges and benefits are identified, emphasizing the potential to reduce workloads while highlighting legal, ethical, and operational concerns.", "conclusion": "Although promising, the adoption of AI in CXR reporting must proceed with caution due to regulatory, safety, and professional implications."}}
{"id": "2509.13705", "pdf": "https://arxiv.org/pdf/2509.13705", "abs": "https://arxiv.org/abs/2509.13705", "authors": ["Koki Chinzei", "Quoc Hoan Tran", "Norifumi Matsumoto", "Yasuhiro Endo", "Hirotaka Oshima"], "title": "Learning quantum many-body data locally: A provably scalable framework", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.LG"], "comment": "38 pages, 5 figures", "summary": "Machine learning (ML) holds great promise for extracting insights from\ncomplex quantum many-body data obtained in quantum experiments. This approach\ncan efficiently solve certain quantum problems that are classically\nintractable, suggesting potential advantages of harnessing quantum data.\nHowever, addressing large-scale problems still requires significant amounts of\ndata beyond the limited computational resources of near-term quantum devices.\nWe propose a scalable ML framework called Geometrically Local Quantum Kernel\n(GLQK), designed to efficiently learn quantum many-body experimental data by\nleveraging the exponential decay of correlations, a phenomenon prevalent in\nnoncritical systems. In the task of learning an unknown polynomial of quantum\nexpectation values, we rigorously prove that GLQK substantially improves\npolynomial sample complexity in the number of qubits $n$, compared to the\nexisting shadow kernel, by constructing a feature space from local quantum\ninformation at the correlation length scale. This improvement is particularly\nnotable when each term of the target polynomial involves few local subsystems.\nRemarkably, for translationally symmetric data, GLQK achieves constant sample\ncomplexity, independent of $n$. We numerically demonstrate its high scalability\nin two learning tasks on quantum many-body phenomena. These results establish\nnew avenues for utilizing experimental data to advance the understanding of\nquantum many-body physics.", "AI": {"tldr": "The paper introduces the Geometrically Local Quantum Kernel (GLQK), a scalable machine learning framework to efficiently analyze quantum many-body experimental data, leveraging correlations' exponential decay to improve data efficiency.", "motivation": "Current quantum experiments create complex many-body datasets that are crucial to understanding quantum physics but are difficult to analyze due to classical limitations and resource constraints in near-term quantum devices.", "method": "The proposed GLQK framework uses local quantum information at the correlation length scale, optimizing learning quantum expectation value polynomials by substantially reducing the sample complexity compared to the shadow kernel approach, especially for translationally symmetric data.", "result": "GLQK reduces sample complexity and demonstrates constant sample requirements for translationally symmetric data regardless of the system size, showcasing high scalability in numerical experiments on quantum many-body phenomena.", "conclusion": "GLQK paves the way for scalable data-driven approaches in quantum many-body physics, substantially improving data efficiency and opening new opportunities for experimental quantum research."}}
{"id": "2509.13772", "pdf": "https://arxiv.org/pdf/2509.13772", "abs": "https://arxiv.org/abs/2509.13772", "authors": ["Baolei Zhang", "Haoran Xin", "Yuxi Chen", "Zhuqing Liu", "Biao Yi", "Tong Li", "Lihai Nie", "Zheli Liu", "Minghong Fang"], "title": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation", "categories": ["cs.CR", "cs.IR", "cs.LG"], "comment": "To appear in the IEEE Symposium on Security and Privacy, 2026", "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge into large\nlanguage models to improve response quality. However, recent work has shown\nthat RAG systems are highly vulnerable to poisoning attacks, where malicious\ntexts are inserted into the knowledge database to influence model outputs.\nWhile several defenses have been proposed, they are often circumvented by more\nadaptive or sophisticated attacks.\n  This paper presents RAGOrigin, a black-box responsibility attribution\nframework designed to identify which texts in the knowledge database are\nresponsible for misleading or incorrect generations. Our method constructs a\nfocused attribution scope tailored to each misgeneration event and assigns a\nresponsibility score to each candidate text by evaluating its retrieval\nranking, semantic relevance, and influence on the generated response. The\nsystem then isolates poisoned texts using an unsupervised clustering method. We\nevaluate RAGOrigin across seven datasets and fifteen poisoning attacks,\nincluding newly developed adaptive poisoning strategies and multi-attacker\nscenarios. Our approach outperforms existing baselines in identifying poisoned\ncontent and remains robust under dynamic and noisy conditions. These results\nsuggest that RAGOrigin provides a practical and effective solution for tracing\nthe origins of corrupted knowledge in RAG systems.", "AI": {"tldr": "RAGOrigin introduces a black-box framework to identify deceptive texts in RAG systems, excelling in various datasets and dynamic attack scenarios.", "motivation": "Improve defenses for RAG systems against poisoning attacks by pinpointing the sources of misinformation.", "method": "Develop a black-box responsibility attribution framework evaluating retrieval ranking, semantic relevance, and response influence, coupled with unsupervised clustering.", "result": "Evaluated across seven datasets and fifteen attack scenarios, RAGOrigin outperformed baselines in identifying poisoned content under noisy conditions.", "conclusion": "RAGOrigin provides a reliable solution for tracing misleading knowledge origins in RAG systems, enhancing security and detection efforts."}}
{"id": "2509.13576", "pdf": "https://arxiv.org/pdf/2509.13576", "abs": "https://arxiv.org/abs/2509.13576", "authors": ["Haodong Li", "Shuo Han", "Haiyang Mao", "Yu Shi", "Changsheng Fang", "Jianjia Zhang", "Weiwen Wu", "Hengyong Yu"], "title": "Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for Sparse-View CT", "categories": ["eess.IV", "cs.CV", "65R32"], "comment": "11 pages, 8 figures, under reviewing of IEEE TMI", "summary": "Sparse-View CT (SVCT) reconstruction enhances temporal resolution and reduces\nradiation dose, yet its clinical use is hindered by artifacts due to view\nreduction and domain shifts from scanner, protocol, or anatomical variations,\nleading to performance degradation in out-of-distribution (OOD) scenarios. In\nthis work, we propose a Cross-Distribution Diffusion Priors-Driven Iterative\nReconstruction (CDPIR) framework to tackle the OOD problem in SVCT. CDPIR\nintegrates cross-distribution diffusion priors, derived from a Scalable\nInterpolant Transformer (SiT), with model-based iterative reconstruction\nmethods. Specifically, we train a SiT backbone, an extension of the Diffusion\nTransformer (DiT) architecture, to establish a unified stochastic interpolant\nframework, leveraging Classifier-Free Guidance (CFG) across multiple datasets.\nBy randomly dropping the conditioning with a null embedding during training,\nthe model learns both domain-specific and domain-invariant priors, enhancing\ngeneralizability. During sampling, the globally sensitive transformer-based\ndiffusion model exploits the cross-distribution prior within the unified\nstochastic interpolant framework, enabling flexible and stable control over\nmulti-distribution-to-noise interpolation paths and decoupled sampling\nstrategies, thereby improving adaptation to OOD reconstruction. By alternating\nbetween data fidelity and sampling updates, our model achieves state-of-the-art\nperformance with superior detail preservation in SVCT reconstructions.\nExtensive experiments demonstrate that CDPIR significantly outperforms existing\napproaches, particularly under OOD conditions, highlighting its robustness and\npotential clinical value in challenging imaging scenarios.", "AI": {"tldr": "The paper introduces CDPIR, a framework tackling out-of-distribution (OOD) issues in sparse-view CT by integrating diffusion priors with iterative reconstruction methods to improve performance and clinical applicability.", "motivation": "Clinical use of Sparse-View CT is hindered by artifacts and performance degradation in out-of-distribution scenarios caused by scanner, protocol, or anatomical variations.", "method": "The CDPIR framework integrates diffusion priors derived from a Scalable Interpolant Transformer (SiT) with iterative reconstruction methods. SiT, based on Diffusion Transformer architecture, is trained using Classifier-Free Guidance to learn both domain-specific and domain-invariant priors, enhancing generalizability.", "result": "The proposed CDPIR model achieves state-of-the-art performance in sparse-view CT reconstructions, with superior detail preservation and robustness, particularly under out-of-distribution conditions.", "conclusion": "CDPIR demonstrates significant advancements in sparse-view CT reconstruction for challenging scenarios, underscoring its clinical potential due to its robustness and generalizability."}}
{"id": "2509.13821", "pdf": "https://arxiv.org/pdf/2509.13821", "abs": "https://arxiv.org/abs/2509.13821", "authors": ["Frederik M\u00f8ller", "Gabriel Fern\u00e1ndez-Fern\u00e1ndez", "Thomas Schweigler", "Paulin de Schoulepnikoff", "J\u00f6rg Schmiedmayer", "Gorka Mu\u00f1oz-Gil"], "title": "Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator", "categories": ["quant-ph", "cs.LG"], "comment": "13 pages, 7 figures", "summary": "Analog quantum simulators provide access to many-body dynamics beyond the\nreach of classical computation. However, extracting physical insights from\nexperimental data is often hindered by measurement noise, limited observables,\nand incomplete knowledge of the underlying microscopic model. Here, we develop\na machine learning approach based on a variational autoencoder (VAE) to analyze\ninterference measurements of tunnel-coupled one-dimensional Bose gases, which\nrealize the sine-Gordon quantum field theory. Trained in an unsupervised\nmanner, the VAE learns a minimal latent representation that strongly correlates\nwith the equilibrium control parameter of the system. Applied to\nnon-equilibrium protocols, the latent space uncovers signatures of frozen-in\nsolitons following rapid cooling, and reveals anomalous post-quench dynamics\nnot captured by conventional correlation-based methods. These results\ndemonstrate that generative models can extract physically interpretable\nvariables directly from noisy and sparse experimental data, providing\ncomplementary probes of equilibrium and non-equilibrium physics in quantum\nsimulators. More broadly, our work highlights how machine learning can\nsupplement established field-theoretical techniques, paving the way for\nscalable, data-driven discovery in quantum many-body systems.", "AI": {"tldr": "This paper introduces a machine learning approach using variational autoencoders (VAEs) to analyze experimental data from analog quantum simulators, aiding in the study of quantum many-body systems.", "motivation": "The study aims to address challenges in extracting physical insights from experimental quantum data, which is often hindered by noise, limited observables, and incomplete microscopic models.", "method": "A variational autoencoder (VAE) is trained in an unsupervised manner on interference measurements of one-dimensional Bose gases. The VAE learns a latent representation that captures key system parameters and is applied to equilibrium and non-equilibrium protocols.", "result": "The VAE successfully identifies the equilibrium control parameter, reveals frozen-in solitons after rapid cooling, and uncovers anomalous post-quench dynamics not captured by traditional correlation-based approaches.", "conclusion": "Generative models like VAEs can provide interpretable insights directly from noisy quantum experimental data, extending understanding in equilibrium and non-equilibrium physics and complementing traditional field-theoretical methods."}}
{"id": "2509.13927", "pdf": "https://arxiv.org/pdf/2509.13927", "abs": "https://arxiv.org/abs/2509.13927", "authors": ["Kevin Wilkinghoff", "Zheng-Hua Tan"], "title": "DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": null, "summary": "Reasoning about spatial audio with large language models requires a spatial\naudio encoder as an acoustic front-end to obtain audio embeddings for further\nprocessing. Such an encoder needs to capture all information required to detect\nthe type of sound events, as well as the direction and distance of their\ncorresponding sources. Accomplishing this with a single audio encoder is\ndemanding as the information required for each of these tasks is mostly\nindependent of each other. As a result, the performance obtained with a single\nencoder is often worse than when using task-specific audio encoders. In this\nwork, we present DSpAST, a novel audio encoder based on SpatialAST that learns\ndisentangled representations of spatial audio while having only 0.2% additional\nparameters. Experiments on SpatialSoundQA with the spatial audio reasoning\nsystem BAT demonstrate that DSpAST significantly outperforms SpatialAST.", "AI": {"tldr": "The paper introduces DSpAST, a novel audio encoder for spatial audio reasoning, improving performance over existing models with minimal additional parameters.", "motivation": "Current spatial audio encoders struggle to harmonize the detection of sound events with determining their direction and distance, leading to suboptimal performance.", "method": "The authors designed DSpAST, an advanced version of SpatialAST, focusing on disentangled spatial audio representation learning with only a 0.2% increase in parameters.", "result": "Experiments with SpatialSoundQA and BAT show DSpAST yields significantly better results than SpatialAST.", "conclusion": "DSpAST successfully addresses limitations in spatial audio reasoning, proving to be more efficient and accurate in its representations compared to the baseline model."}}
{"id": "2509.13987", "pdf": "https://arxiv.org/pdf/2509.13987", "abs": "https://arxiv.org/abs/2509.13987", "authors": ["Ozer Ozturk", "Busra Buyuktanir", "Gozde Karatas Baydogmus", "Kazim Yildiz"], "title": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Machine learning models used for distributed architectures consisting of\nservers and clients require large amounts of data to achieve high accuracy.\nData obtained from clients are collected on a central server for model\ntraining. However, storing data on a central server raises concerns about\nsecurity and privacy. To address this issue, a federated learning architecture\nhas been proposed. In federated learning, each client trains a local model\nusing its own data. The trained models are periodically transmitted to the\ncentral server. The server then combines the received models using federated\naggregation algorithms to obtain a global model. This global model is\ndistributed back to the clients, and the process continues in a cyclical\nmanner. Although preventing data from leaving the clients enhances security,\ncertain concerns still remain. Attackers can perform inference attacks on the\nobtained models to approximate the training dataset, potentially causing data\nleakage. In this study, differential privacy was applied to address the\naforementioned security vulnerability, and a performance analysis was\nconducted. The Data-Unaware Classification Based on Association (duCBA)\nalgorithm was used as the federated aggregation method. Differential privacy\nwas implemented on the data using the Randomized Response technique, and the\ntrade-off between security and performance was examined under different epsilon\nvalues. As the epsilon value decreased, the model accuracy declined, and class\nprediction imbalances were observed. This indicates that higher levels of\nprivacy do not always lead to practical outcomes and that the balance between\nsecurity and performance must be carefully considered.", "AI": {"tldr": "This paper examines privacy concerns in federated learning while using differential privacy to mitigate inference attack risks, analyzing the trade-off between privacy and model performance.", "motivation": "Federated learning raises privacy and security concerns because attackers can exploit trained models to infer sensitive training data.", "method": "The study uses federated learning with the duCBA aggregation method and employs differential privacy with the Randomized Response technique to protect data.", "result": "Lower epsilon values increase privacy but reduce accuracy and introduce class prediction imbalances, highlighting a fundamental trade-off between privacy and performance.", "conclusion": "An optimal balance between privacy and performance must be found for federated learning frameworks, as higher privacy may compromise practical outcomes like accuracy."}}
{"id": "2509.13878", "pdf": "https://arxiv.org/pdf/2509.13878", "abs": "https://arxiv.org/abs/2509.13878", "authors": ["Janne Laakkonen", "Ivan Kukanov", "Ville Hautam\u00e4ki"], "title": "Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "6 pages, 3 figures, 1 table", "summary": "Foundation models such as Wav2Vec2 excel at representation learning in speech\ntasks, including audio deepfake detection. However, after being fine-tuned on a\nfixed set of bonafide and spoofed audio clips, they often fail to generalize to\nnovel deepfake methods not represented in training. To address this, we propose\na mixture-of-LoRA-experts approach that integrates multiple low-rank adapters\n(LoRA) into the model's attention layers. A routing mechanism selectively\nactivates specialized experts, enhancing adaptability to evolving deepfake\nattacks. Experimental results show that our method outperforms standard\nfine-tuning in both in-domain and out-of-domain scenarios, reducing equal error\nrates relative to baseline models. Notably, our best MoE-LoRA model lowers the\naverage out-of-domain EER from 8.55\\% to 6.08\\%, demonstrating its\neffectiveness in achieving generalizable audio deepfake detection.", "AI": {"tldr": "This paper proposes a novel approach using mixture-of-LoRA-experts (MoE-LoRA) for adaptable audio deepfake detection, greatly improving out-of-domain performance.", "motivation": "Foundation models like Wav2Vec2 struggle to generalize to new types of deepfake methods after being fine-tuned on fixed datasets. The paper aims to tackle this limitation to improve the adaptability of audio deepfake detection models.", "method": "The authors integrate multiple low-rank adapters (LoRA) into the model's attention layers, combined with a routing mechanism that activates specialized experts to handle evolving deepfake attacks.", "result": "The proposed MoE-LoRA method outperforms standard fine-tuning approaches in both in-domain and out-of-domain tasks, achieving a significant reduction in equal error rates, with the best model lowering out-of-domain EER from 8.55% to 6.08%.", "conclusion": "The MoE-LoRA method enhances adaptability and generalization in audio deepfake detection, marking an advancement over existing fine-tuning techniques."}}
{"id": "2509.13934", "pdf": "https://arxiv.org/pdf/2509.13934", "abs": "https://arxiv.org/abs/2509.13934", "authors": ["Zhixion Chen", "Jiangzhou Wang", "and Hyundong Shin", "Arumugam Nallanathan"], "title": "Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "14pages, 8 figures", "summary": "The deployment of unmanned aerial vehicles (UAVs) for reliable and\nenergy-efficient data collection from spatially distributed devices holds great\npromise in supporting diverse Internet of Things (IoT) applications.\nNevertheless, the limited endurance and communication range of UAVs necessitate\nintelligent trajectory planning. While reinforcement learning (RL) has been\nextensively explored for UAV trajectory optimization, its interactive nature\nentails high costs and risks in real-world environments. Offline RL mitigates\nthese issues but remains susceptible to unstable training and heavily rely on\nexpert-quality datasets. To address these challenges, we formulate a joint UAV\ntrajectory planning and resource allocation problem to maximize energy\nefficiency of data collection. The resource allocation subproblem is first\ntransformed into an equivalent linear programming formulation and solved\noptimally with polynomial-time complexity. Then, we propose a large language\nmodel (LLM)-empowered critic-regularized decision transformer (DT) framework,\ntermed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we\nincorporate critic networks to regularize the DT model training, thereby\nintegrating the sequence modeling capabilities of DT with critic-based value\nguidance to enable learning effective policies from suboptimal datasets.\nFurthermore, to mitigate the data-hungry nature of transformer models, we\nemploy a pre-trained LLM as the transformer backbone of the DT model and adopt\na parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid\nadaptation to UAV control tasks with small-scale dataset and low computational\noverhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark\nonline and offline RL methods, achieving up to 36.7\\% higher energy efficiency\nthan the current state-of-the-art DT approaches.", "AI": {"tldr": "This paper addresses UAV trajectory planning and resource allocation challenges using an innovative hybrid approach combining large language models (LLMs) and decision transformers (DTs), achieving notable energy efficiency improvements.", "motivation": "The study aims to address the limitations of UAVs in data collection operations for IoT applications, specifically focusing on their limited endurance and communication range. Reinforcement learning is considered but suffers from real-world feasibility issues, while offline RL has its vulnerabilities. The motivation lies in formulating an efficient strategy for UAV trajectory planning and resource allocation to enhance energy efficiency while overcoming these constraints.", "method": "The authors solve the resource allocation subproblem via an equivalent linear programming formulation with polynomial complexity. They propose the LLM-CRDT framework, which integrates LLMs into a critic-regularized decision transformer for policy learning from suboptimal datasets. Critic networks provide regularization, while a pre-trained LLM and LoRA fine-tuning minimize data requirements and computational costs.", "result": "Simulations show that the proposed LLM-CRDT framework surpasses competing online and offline reinforcement learning methods, achieving up to 36.7% greater energy efficiency over state-of-the-art DT solutions.", "conclusion": "The paper concludes that the LLM-CRDT framework effectively leverages LLMs and critics within a decision-transformer model, offering a robust method for energy-efficient UAV control. It demonstrates substantial improvements compared to existing techniques for UAV trajectory planning and resource allocation, particularly in the context of limited datasets."}}
{"id": "2509.14003", "pdf": "https://arxiv.org/pdf/2509.14003", "abs": "https://arxiv.org/abs/2509.14003", "authors": ["Liting Gao", "Yi Yuan", "Yaru Chen", "Yuelan Cheng", "Zhenbo Li", "Juan Wen", "Shubin Zhang", "Wenwu Wang"], "title": "RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Diffusion models have shown remarkable progress in text-to-audio generation.\nHowever, text-guided audio editing remains in its early stages. This task\nfocuses on modifying the target content within an audio signal while preserving\nthe rest, thus demanding precise localization and faithful editing according to\nthe text prompt. Existing training-based and zero-shot methods that rely on\nfull-caption or costly optimization often struggle with complex editing or lack\npracticality. In this work, we propose a novel end-to-end efficient rectified\nflow matching-based diffusion framework for audio editing, and construct a\ndataset featuring overlapping multi-event audio to support training and\nbenchmarking in complex scenarios. Experiments show that our model achieves\nfaithful semantic alignment without requiring auxiliary captions or masks,\nwhile maintaining competitive editing quality across metrics.", "AI": {"tldr": "This paper presents an innovative rectified flow matching-based diffusion framework for text-guided audio editing, addressing challenges of semantic alignment and quality without auxiliary inputs.", "motivation": "To enhance text-guided audio editing by resolving the limitations of existing methods that struggle with complex modifications or lack practicality.", "method": "The paper introduces an end-to-end efficient rectified flow matching-based diffusion framework and a new dataset tailored for training and benchmarking in multi-event audio scenarios.", "result": "Experiments demonstrate that the proposed model achieves accurate semantic alignment as per text prompts and delivers high-quality audio editing competitively across multiple metrics.", "conclusion": "The approach presents effective advancements in audio editing, eliminating the need for auxiliary captions or masks while ensuring faithful and localized editing."}}
{"id": "2509.13975", "pdf": "https://arxiv.org/pdf/2509.13975", "abs": "https://arxiv.org/abs/2509.13975", "authors": ["Ilker Bayram"], "title": "Classification Filtering", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "We consider a streaming signal in which each sample is linked to a latent\nclass. We assume that multiple classifiers are available, each providing class\nprobabilities with varying degrees of accuracy. These classifiers are employed\nfollowing a straightforward and fixed policy. In this setting, we consider the\nproblem of fusing the output of the classifiers while incorporating the\ntemporal aspect to improve classification accuracy. We propose a state-space\nmodel and develop a filter tailored for realtime execution. We demonstrate the\neffectiveness of the proposed filter in an activity classification application\nbased on inertial measurement unit (IMU) data from a wearable device.", "AI": {"tldr": "The paper addresses improving classification accuracy in streaming signals linked to latent classes by fusing outputs from multiple classifiers and incorporating temporal aspects.", "motivation": "The need to enhance classification accuracy in streaming data settings where each sample is linked to a latent class and classified by multiple classifiers, often with varying accuracy.", "method": "The paper introduces a state-space model and develops a filter optimized for real-time application to fuse classifiers\u2019 outputs effectively while utilizing temporal signal dynamics.", "result": "The proposed filter showed improved classification accuracy, demonstrated on an activity classification task using IMU data from wearable devices.", "conclusion": "Fusing classifiers' outputs while leveraging temporal information using a state-space model is effective in real-time activity classification scenarios."}}
{"id": "2509.14037", "pdf": "https://arxiv.org/pdf/2509.14037", "abs": "https://arxiv.org/abs/2509.14037", "authors": ["Ranga Baminiwatte", "Kazi Jewel Rana", "Aaron J. Masino"], "title": "PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding disease similarity is critical for advancing diagnostics, drug\ndiscovery, and personalized treatment strategies. We present PhenoGnet, a novel\ngraph-based contrastive learning framework designed to predict disease\nsimilarity by integrating gene functional interaction networks with the Human\nPhenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view\nmodel that separately encodes gene and phenotype graphs using Graph\nConvolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross\nview model implemented as a shared weight multilayer perceptron (MLP) that\naligns gene and phenotype embeddings through contrastive learning. The model is\ntrained using known gene phenotype associations as positive pairs and randomly\nsampled unrelated pairs as negatives. Diseases are represented by the mean\nembeddings of their associated genes and/or phenotypes, and pairwise similarity\nis computed via cosine similarity. Evaluation on a curated benchmark of 1,100\nsimilar and 866 dissimilar disease pairs demonstrates strong performance, with\ngene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764,\noutperforming existing state of the art methods. Notably, PhenoGnet captures\nlatent biological relationships beyond direct overlap, offering a scalable and\ninterpretable solution for disease similarity prediction. These results\nunderscore its potential for enabling downstream applications in rare disease\nresearch and precision medicine.", "AI": {"tldr": "PhenoGnet is a graph-based contrastive learning framework enhancing disease similarity prediction by fusing gene interaction networks and human phenotype data, outperforming prior methods.", "motivation": "The paper aims to improve the understanding of disease similarity to advance areas such as diagnostics, drug discovery, and personalized medicine.", "method": "PhenoGnet incorporates gene and phenotype data through graph-based embeddings (GCNs, GATs) and a shared weight MLP for alignment via contrastive learning. A cosine similarity measure is used for disease comparisons.", "result": "On a benchmark dataset, PhenoGnet achieved excellent predictive performance\u2014AUCPR of 0.9012 and AUROC of 0.8764\u2014surpassing existing methods.", "conclusion": "PhenoGnet successfully predicts disease similarity, supports rare disease research, and has great potential for use in precision medicine, thanks to its scalability and interpretability."}}
{"id": "2509.14016", "pdf": "https://arxiv.org/pdf/2509.14016", "abs": "https://arxiv.org/abs/2509.14016", "authors": ["Jonas Buchli", "Brendan Tracey", "Tomislav Andric", "Christopher Wipf", "Yu Him Justin Chiu", "Matthias Lochbrunner", "Craig Donner", "Rana X. Adhikari", "Jan Harms", "Iain Barr", "Roland Hafner", "Andrea Huber", "Abbas Abdolmaleki", "Charlie Beattie", "Joseph Betzwieser", "Serkan Cabi", "Jonas Degrave", "Yuzhu Dong", "Leslie Fritz", "Anchal Gupta", "Oliver Groth", "Sandy Huang", "Tamara Norman", "Hannah Openshaw", "Jameson Rollins", "Greg Thornton", "George Van Den Driessche", "Markus Wulfmeier", "Pushmeet Kohli", "Martin Riedmiller", "LIGO Instrument Team"], "title": "Improving cosmological reach of a gravitational wave observatory using Deep Loop Shaping", "categories": ["astro-ph.IM", "cs.LG", "cs.SY", "eess.SY", "gr-qc"], "comment": null, "summary": "Improved low-frequency sensitivity of gravitational wave observatories would\nunlock study of intermediate-mass black hole mergers, binary black hole\neccentricity, and provide early warnings for multi-messenger observations of\nbinary neutron star mergers. Today's mirror stabilization control injects\nharmful noise, constituting a major obstacle to sensitivity improvements. We\neliminated this noise through Deep Loop Shaping, a reinforcement learning\nmethod using frequency domain rewards. We proved our methodology on the LIGO\nLivingston Observatory (LLO). Our controller reduced control noise in the\n10--30Hz band by over 30x, and up to 100x in sub-bands surpassing the design\ngoal motivated by the quantum limit. These results highlight the potential of\nDeep Loop Shaping to improve current and future GW observatories, and more\nbroadly instrumentation and control systems.", "AI": {"tldr": "The study implemented Deep Loop Shaping to reduce control noise in gravitational wave detectors, achieving substantial improvements in low-frequency sensitivity.", "motivation": "To enhance the sensitivity of gravitational wave observatories at low frequencies, enabling the study of intermediate-mass black holes, binary black hole eccentricity, and early warnings for multi-messenger observations.", "method": "The researchers used Deep Loop Shaping, a reinforcement learning approach that optimizes frequency domain rewards, to reduce noise caused by mirror stabilization control systems.", "result": "Their controller reduced control noise in the critical 10\u201330Hz frequency band by over 30x and up to 100x in certain sub-bands, exceeding design goals.", "conclusion": "Deep Loop Shaping demonstrates significant potential to improve gravitational wave observatory sensitivity, as well as broader applications in instrumentation and control systems."}}
{"id": "2509.14049", "pdf": "https://arxiv.org/pdf/2509.14049", "abs": "https://arxiv.org/abs/2509.14049", "authors": ["Jordi Grau-Haro", "Ruben Ribes-Serrano", "Javier Naranjo-Alcazar", "Marta Garcia-Ballesteros", "Pedro Zuccarello"], "title": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted at Computing Conference 2026, London, UK", "summary": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in audio tagging tasks. However, deploying these models on\nresource-constrained devices like the Raspberry Pi poses challenges related to\ncomputational efficiency and thermal management. In this paper, a comprehensive\nevaluation of multiple convolutional neural network (CNN) architectures for\naudio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D\nmodels from the Pretrained Audio Neural Networks (PANNs) framework, a\nConvNeXt-based model adapted for audio classification, as well as MobileNetV3\narchitectures. In addition, two PANNs-derived networks, CNN9 and CNN13,\nrecently proposed, are also evaluated. To enhance deployment efficiency and\nportability across diverse hardware platforms, all models are converted to the\nOpen Neural Network Exchange (ONNX) format. Unlike previous works that focus on\na single model, our analysis encompasses a broader range of architectures and\ninvolves continuous 24-hour inference sessions to assess performance stability.\nOur experiments reveal that, with appropriate model selection and optimization,\nit is possible to maintain consistent inference latency and manage thermal\nbehavior effectively over extended periods. These findings provide valuable\ninsights for deploying audio tagging models in real-world edge computing\nscenarios.", "AI": {"tldr": "This paper evaluates various CNN architectures for audio tagging on Raspberry Pi, focusing on computational and thermal efficiency.", "motivation": "The study aims to address challenges in deploying high-performing CNN-based audio tagging models on resource-constrained devices like the Raspberry Pi.", "method": "Multiple CNN architectures, including PANNs, ConvNeXt, and MobileNetV3, were evaluated in ONNX format during 24-hour continuous inference sessions to analyze performance, efficiency, and thermal behavior.", "result": "The research demonstrates that careful model selection and optimization can ensure stable inference performance and effective thermal management during extended operational periods.", "conclusion": "The findings highlight the potential for deploying CNN audio tagging models efficiently on edge devices, providing insights for practical real-world applications."}}
{"id": "2509.14020", "pdf": "https://arxiv.org/pdf/2509.14020", "abs": "https://arxiv.org/abs/2509.14020", "authors": ["Felipe Crivellaro Minuzzi", "Leandro Farina"], "title": "Artificial neural networks ensemble methodology to predict significant wave height", "categories": ["physics.ao-ph", "cs.LG", "physics.data-an", "68T07, 86A05, 68T05", "I.2.6; J.2; G.3"], "comment": null, "summary": "The forecast of wave variables are important for several applications that\ndepend on a better description of the ocean state. Due to the chaotic behaviour\nof the differential equations which model this problem, a well know strategy to\novercome the difficulties is basically to run several simulations, by for\ninstance, varying the initial condition, and averaging the result of each of\nthese, creating an ensemble. Moreover, in the last few years, considering the\namount of available data and the computational power increase, machine learning\nalgorithms have been applied as surrogate to traditional numerical models,\nyielding comparative or better results. In this work, we present a methodology\nto create an ensemble of different artificial neural networks architectures,\nnamely, MLP, RNN, LSTM, CNN and a hybrid CNN-LSTM, which aims to predict\nsignificant wave height on six different locations in the Brazilian coast. The\nnetworks are trained using NOAA's numerical reforecast data and target the\nresidual between observational data and the numerical model output. A new\nstrategy to create the training and target datasets is demonstrated. Results\nshow that our framework is capable of producing high efficient forecast, with\nan average accuracy of $80\\%$, that can achieve up to $88\\%$ in the best case\nscenario, which means $5\\%$ reduction in error metrics if compared to NOAA's\nnumerical model, and a increasingly reduction of computational cost.", "AI": {"tldr": "The paper proposes a machine learning-based ensemble system for forecasting significant wave heights along the Brazilian coast using various neural network architectures. The method yields forecasts with up to 88% accuracy and improves error metrics compared to NOAA models.", "motivation": "The paper aims to address the chaotic nature of ocean wave modeling by leveraging machine learning to enhance the accuracy and computational efficiency of significant wave height predictions.", "method": "The methodology involves creating an ensemble of various neural network architectures (MLP, RNN, LSTM, CNN, and CNN-LSTM) trained on NOAA's reforecast data to predict the residual between observed data and numerical model outputs. A novel approach for training and target data creation is also introduced.", "result": "The machine learning framework achieved an average forecast accuracy of 80%, peaking at 88% in the best scenario, with a 5% reduction in error metrics compared to NOAA's numerical models, alongside lower computational costs.", "conclusion": "The proposed ensemble strategy combining multiple neural networks effectively enhances ocean wave forecasting accuracy and reduces computational demands, showcasing its practical efficacy over traditional methods."}}
{"id": "2509.14057", "pdf": "https://arxiv.org/pdf/2509.14057", "abs": "https://arxiv.org/abs/2509.14057", "authors": ["Riccardo Zanardelli"], "title": "Machines are more productive than humans until they aren't, and vice versa", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "With the growth of artificial skills, organizations may increasingly confront\nwith the problem of optimizing skill policy decisions guided by economic\nprinciples. This paper addresses the underlying complexity of this challenge by\ndeveloping an in-silico framework based on Monte Carlo simulations grounded in\nempirical realism to analyze the economic impact of human and machine skills,\nindividually or jointly deployed, in the execution of tasks presenting varying\nlevels of complexity. Our results provide quantitative support for the\nestablished notions that automation tends to be the most economically-effective\nstrategy for tasks characterized by low-to-medium generalization difficulty,\nwhile automation struggles to match the economic utility of human skills in\nmore complex scenarios. Critically, our simulations highlight that combining\nhuman and machine skills can be the most effective strategy when a high level\nof generalization is required, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine policy is\nseverely penalized by the inherent costs of its dual skill structure, causing\nit to destroy value and becoming the worst choice from an economic perspective.\nThe takeaway for decision-makers is unambiguous: simply allocating human and\nmachine skills to a task is insufficient, and a human-machine skill policy is\nneither a silver-bullet solution nor a low-risk compromise. Rather, it is a\ncritical opportunity to boost competitiveness that demands a strong\norganizational commitment to enabling augmentation. Also, our findings show\nthat improving the cost-effectiveness of machine skills over time, while\nuseful, does not replace the fundamental need to focus on achieving\naugmentation.", "AI": {"tldr": "Monte Carlo-based simulations show that combining human and machine skills can be the most effective strategy for complex tasks, but only if true augmentation occurs.", "motivation": "Organizations face the challenge of optimizing skill policies in the growing realm of artificial and human capabilities.", "method": "The paper utilizes an in-silico framework of Monte Carlo simulations, grounded in empirical realism, to analyze the economic impact of human and machine skills.", "result": "Automation excels economically in low-to-medium difficulty tasks but falters in complex tasks without augmentation; synergy between human and machine skills offers optimal performance but incurs significant costs if augmentation fails.", "conclusion": "A human-machine skill policy demands deliberate augmentation, as a lack of synergy leads to failure despite advances in machine skills' cost-effectiveness."}}
{"id": "2509.14026", "pdf": "https://arxiv.org/pdf/2509.14026", "abs": "https://arxiv.org/abs/2509.14026", "authors": ["Jiun-Cheng Jiang", "Morris Yu-Chao Huang", "Tianlong Chen", "Hsi-Sheng Goan"], "title": "Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks", "categories": ["quant-ph", "cs.LG"], "comment": "45 pages", "summary": "Variational quantum circuits (VQCs) are central to quantum machine learning,\nwhile recent progress in Kolmogorov-Arnold networks (KANs) highlights the power\nof learnable activation functions. We unify these directions by introducing\nquantum variational activation functions (QVAFs), realized through single-qubit\ndata re-uploading circuits called DatA Re-Uploading ActivatioNs (DARUANs). We\nshow that DARUAN with trainable weights in data pre-processing possesses an\nexponentially growing frequency spectrum with data repetitions, enabling an\nexponential reduction in parameter size compared with Fourier-based activations\nwithout loss of expressivity. Embedding DARUAN into KANs yields\nquantum-inspired KANs (QKANs), which retain the interpretability of KANs while\nimproving their parameter efficiency, expressivity, and generalization. We\nfurther introduce two novel techniques to enhance scalability, feasibility and\ncomputational efficiency, such as layer extension and hybrid QKANs (HQKANs) as\ndrop-in replacements of multi-layer perceptrons (MLPs) for feed-forward\nnetworks in large-scale models. We provide theoretical analysis and extensive\nexperiments on function regression, image classification, and autoregressive\ngenerative language modeling, demonstrating the efficiency and scalability of\nQKANs. DARUANs and QKANs offer a promising direction for advancing quantum\nmachine learning on both noisy intermediate-scale quantum (NISQ) hardware and\nclassical quantum simulators.", "AI": {"tldr": "This paper introduces quantum variational activation functions (QVAFs) via DARUAN circuits, integrating them into classical Kolmogorov-Arnold networks (KANs) to improve parameter efficiency, expressivity, and generalization in various applications.", "motivation": "To combine advances in quantum machine learning (via variational quantum circuits) and learnable activation functions (via Kolmogorov-Arnold networks) for better performance and scalability in machine learning models.", "method": "Introduce DARUAN circuits as quantum variational activation functions embedded into QKANs. Two techniques\u2014layer extension and hybrid QKANs\u2014are developed for scalability and efficiency in large-scale tasks.", "result": "Theoretical and experimental analyses show QKANs achieve improved parameter efficiency, expressivity, and generalization in tasks like regression, image classification, and language modeling.", "conclusion": "QKANs, with DARUAN circuits, present a promising approach for enhancing quantum machine learning capabilities on both NISQ quantum hardware and classical simulators."}}
{"id": "2509.14032", "pdf": "https://arxiv.org/pdf/2509.14032", "abs": "https://arxiv.org/abs/2509.14032", "authors": ["Philip Jordan", "Maryam Kamgarpour"], "title": "Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation", "categories": ["cs.GT", "cs.LG", "cs.MA"], "comment": null, "summary": "We study the existence and computation of Nash equilibria in continuous\nstatic games where the players' admissible strategies are subject to shared\ncoupling constraints, i.e., constraints that depend on their \\emph{joint}\nstrategies. Specifically, we focus on a class of games characterized by\nplayerwise concave utilities and playerwise concave constraints. Prior results\non the existence of Nash equilibria are not applicable to this class, as they\nrely on strong assumptions such as joint convexity of the feasible set. By\nleveraging topological fixed point theory and novel structural insights into\nthe contractibility of feasible sets under playerwise concave constraints, we\ngive an existence proof for Nash equilibria under weaker conditions. Having\nestablished existence, we then focus on the computation of Nash equilibria via\nindependent gradient methods under the additional assumption that the utilities\nadmit a potential function. To account for the possibly nonconvex feasible\nregion, we employ a log barrier regularized gradient ascent with adaptive\nstepsizes. Starting from an initial feasible strategy profile and under exact\ngradient feedback, the proposed method converges to an $\\epsilon$-approximate\nconstrained Nash equilibrium within $\\mathcal{O}(\\epsilon^{-3})$ iterations.", "AI": {"tldr": "The paper investigates Nash equilibria in continuous static games with shared coupling constraints, establishing their existence and proposing a computational method using gradient ascent with adaptive stepsizes.", "motivation": "Prior results on Nash equilibria were limited by strong assumptions like joint convexity of the feasible set. The paper seeks to address games with playerwise concave utilities and constraints under weaker conditions.", "method": "Topological fixed point theory was used to prove the existence of equilibria. Computationally, log barrier regularized gradient ascent is employed to find approximate Nash equilibria under potential function assumptions.", "result": "The method converges to an $\n\\epsilon$-approximate constrained Nash equilibrium within $\n\\mathcal{O}(\\epsilon^{-3})$ iterations, accounting for nonconvex feasible sets.", "conclusion": "The work expands the scope of Nash equilibria studies to games with weaker structural assumptions, while offering computational techniques with provable convergence rates."}}
{"id": "2509.14054", "pdf": "https://arxiv.org/pdf/2509.14054", "abs": "https://arxiv.org/abs/2509.14054", "authors": ["Weihao Yan", "Christoph Brune", "Mengwu Guo"], "title": "Physics-based deep kernel learning for parameter estimation in high dimensional PDEs", "categories": ["cs.CE", "cs.LG", "cs.NA", "math.NA", "68T05", "I.2.6"], "comment": null, "summary": "Inferring parameters of high-dimensional partial differential equations\n(PDEs) poses significant computational and inferential challenges, primarily\ndue to the curse of dimensionality and the inherent limitations of traditional\nnumerical methods. This paper introduces a novel two-stage Bayesian framework\nthat synergistically integrates training, physics-based deep kernel learning\n(DKL) with Hamiltonian Monte Carlo (HMC) to robustly infer unknown PDE\nparameters and quantify their uncertainties from sparse, exact observations.\nThe first stage leverages physics-based DKL to train a surrogate model, which\njointly yields an optimized neural network feature extractor and robust initial\nestimates for the PDE parameters. In the second stage, with the neural network\nweights fixed, HMC is employed within a full Bayesian framework to efficiently\nsample the joint posterior distribution of the kernel hyperparameters and the\nPDE parameters. Numerical experiments on canonical and high-dimensional inverse\nPDE problems demonstrate that our framework accurately estimates parameters,\nprovides reliable uncertainty estimates, and effectively addresses challenges\nof data sparsity and model complexity, offering a robust and scalable tool for\ndiverse scientific and engineering applications.", "AI": {"tldr": "This paper introduces a novel two-stage Bayesian framework combining physics-based deep kernel learning (DKL) and Hamiltonian Monte Carlo (HMC) to infer parameters and quantify uncertainties in high-dimensional PDEs.", "motivation": "To tackle computational and inferential challenges in high-dimensional PDEs due to the curse of dimensionality and limitations of traditional numerical methods.", "method": "The framework consists of two stages: (1) physics-based deep kernel learning (DKL) to train a surrogate model and initially estimate PDE parameters, and (2) Hamiltonian Monte Carlo (HMC) to sample the joint posterior distribution for uncertainty quantification.", "result": "Numerical experiments validate the framework\u2019s accuracy in parameter estimation and uncertainty quantification, effectively addressing data sparsity and model complexity.", "conclusion": "This robust and scalable method facilitates parameter inference and uncertainty quantification for high-dimensional PDEs, with applications in scientific and engineering domains."}}
{"id": "2509.14163", "pdf": "https://arxiv.org/pdf/2509.14163", "abs": "https://arxiv.org/abs/2509.14163", "authors": ["Chi-Sheng Chen", "En-Jui Kuo"], "title": "Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Diffusion models typically employ static or heuristic classifier-free\nguidance (CFG) schedules, which often fail to adapt across timesteps and noise\nconditions. In this work, we introduce a quantum reinforcement learning (QRL)\ncontroller that dynamically adjusts CFG at each denoising step. The controller\nadopts a hybrid quantum--classical actor--critic architecture: a shallow\nvariational quantum circuit (VQC) with ring entanglement generates policy\nfeatures, which are mapped by a compact multilayer perceptron (MLP) into\nGaussian actions over $\\Delta$CFG, while a classical critic estimates value\nfunctions. The policy is optimized using Proximal Policy Optimization (PPO)\nwith Generalized Advantage Estimation (GAE), guided by a reward that balances\nclassification confidence, perceptual improvement, and action regularization.\nExperiments on CIFAR-10 demonstrate that our QRL policy improves perceptual\nquality (LPIPS, PSNR, SSIM) while reducing parameter count compared to\nclassical RL actors and fixed schedules. Ablation studies on qubit number and\ncircuit depth reveal trade-offs between accuracy and efficiency, and extended\nevaluations confirm robust generation under long diffusion schedules.", "AI": {"tldr": "This paper proposes a quantum reinforcement learning (QRL) approach to dynamically adjust classifier-free guidance (CFG) in diffusion models, showing improvements in perceptual quality and efficiency.", "motivation": "Current diffusion models often rely on static or heuristic CFG schedules, which fail to adapt to varying timesteps and noise conditions, limiting their performance.", "method": "The paper uses a hybrid quantum-classical actor-critic architecture. A shallow variational quantum circuit (VQC) generates policy features, while a multilayer perceptron (MLP) maps these features into actions for $\\\\Delta$CFG. The policy is optimized using Proximal Policy Optimization (PPO) with Generalized Advantage Estimation (GAE), and a reward system balances confidence, visual quality, and action efficiency.", "result": "Experiments on the CIFAR-10 dataset demonstrate that the proposed QRL approach improves perceptual metrics like LPIPS, PSNR, and SSIM while reducing parameter count when compared to classical RL approaches or static CFG schedules.", "conclusion": "The QRL-based CFG scheduling approach enhances the adaptability and perceptual quality of diffusion models, demonstrating robust performance under varying conditions and offering trade-offs between accuracy and efficiency when adjusting quantum circuit configurations."}}
{"id": "2509.14203", "pdf": "https://arxiv.org/pdf/2509.14203", "abs": "https://arxiv.org/abs/2509.14203", "authors": ["Shengbo Wang", "Nian Si"], "title": "Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Learning and optimal control under robust Markov decision processes (MDPs)\nhave received increasing attention, yet most existing theory, algorithms, and\napplications focus on finite-horizon or discounted models. The average-reward\nformulation, while natural in many operations research and management contexts,\nremains underexplored. This is primarily because the dynamic programming\nfoundations are technically challenging and only partially understood, with\nseveral fundamental questions remaining open. This paper steps toward a general\nframework for average-reward robust MDPs by analyzing the constant-gain\nsetting. We study the average-reward robust control problem with possible\ninformation asymmetries between the controller and an S-rectangular adversary.\nOur analysis centers on the constant-gain robust Bellman equation, examining\nboth the existence of solutions and their relationship to the optimal average\nreward. Specifically, we identify when solutions to the robust Bellman equation\ncharacterize the optimal average reward and stationary policies, and we provide\nsufficient conditions ensuring solutions' existence. These findings expand the\ndynamic programming theory for average-reward robust MDPs and lay a foundation\nfor robust dynamic decision making under long-run average criteria in\noperational environments.", "AI": {"tldr": "The paper explores average-reward robust Markov decision processes (MDPs), focusing on the constant-gain setting and solving related Bellman equations.", "motivation": "Existing work on robust MDPs has largely ignored the average-reward framework despite its relevance in operations research and management.", "method": "The study analyzes the robust Bellman equation in the constant-gain setting to determine solutions' existence and their relation to optimal average reward and policies.", "result": "The paper identifies conditions under which robust Bellman equations provide optimal solutions and stationary policies, expanding the theory for average-reward robust MDPs.", "conclusion": "Findings deepen understanding of robust dynamic programming under long-run average criteria and provide theoretical groundwork for applications in operational environments."}}
{"id": "2509.14229", "pdf": "https://arxiv.org/pdf/2509.14229", "abs": "https://arxiv.org/abs/2509.14229", "authors": ["Rieko Tasaka", "Tatsuya Kimura", "Joe Suzuki"], "title": "Spacing Test for Fused Lasso", "categories": ["math.ST", "cs.LG", "stat.TH"], "comment": null, "summary": "This study addresses the unresolved problem of selecting the regularization\nparameter in the fused lasso. In particular, we extend the framework of the\nSpacing Test proposed by Tibshirani et al. to the fused lasso, providing a\ntheoretical foundation for post-selection inference by characterizing the\nselection event as a polyhedral constraint. Based on the analysis of the\nsolution path of the fused lasso using a LARS-type algorithm, we derive exact\nconditional $p$-values for the selected change-points. Our method broadens the\napplicability of the Spacing Test from the standard lasso to fused penalty\nstructures. Furthermore, through numerical experiments comparing the proposed\nmethod with sequential versions of AIC and BIC as well as cross-validation, we\ndemonstrate that the proposed approach properly controls the type I error while\nachieving high detection power. This work offers a theoretically sound and\ncomputationally practical solution for parameter selection and post-selection\ninference in structured signal estimation problems. Keywords: Fused Lasso,\nRegularization parameter selection, Spacing Test for Lasso, Selective\ninference, Change-point detection", "AI": {"tldr": "The study enhances the Spacing Test to address the selection of regularization parameters in fused lasso, offering a theoretically grounded approach for change-point detection.", "motivation": "To resolve challenges in selecting regularization parameters for fused lasso and establish robust inference methods for identifying change-points.", "method": "The authors extend the Spacing Test framework to fused lasso and analyze its solution path using a LARS-type algorithm. They derive conditional $p$-values for change-points and carry out comparisons via numerical experiments.", "result": "The proposed method controls type I error effectively and shows high detection power, outperforming approaches like AIC, BIC, and cross-validation.", "conclusion": "This study provides a sound and computationally efficient solution for structured signal estimation, enhancing change-point detection capabilities in fused lasso applications."}}
