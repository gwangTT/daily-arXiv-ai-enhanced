{"id": "2602.07306", "pdf": "https://arxiv.org/pdf/2602.07306", "abs": "https://arxiv.org/abs/2602.07306", "authors": ["Chong Wang", "Nan Du", "Tom Gunter", "Tao Lei", "Kulin Seth", "Senyu Tong", "Jianyu Wang", "Guoli Yin", "Xiyou Zhou", "Kelvin Zou", "Ruoming Pang"], "title": "Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Efficient large-scale inference of transformer-based large language models (LLMs) remains a fundamental systems challenge, frequently requiring multi-GPU parallelism to meet stringent latency and throughput targets. Conventional tensor parallelism decomposes matrix operations across devices but introduces substantial inter-GPU synchronization, leading to communication bottlenecks and degraded scalability. We propose the Parallel Track (PT) Transformer, a novel architectural paradigm that restructures computation to minimize cross-device dependencies. PT achieves up to a 16x reduction in synchronization operations relative to standard tensor parallelism, while maintaining competitive model quality in our experiments. We integrate PT into two widely adopted LLM serving stacks-Tensor-RT-LLM and vLLM-and report consistent improvements in serving efficiency, including up to 15-30% reduced time to first token, 2-12% reduced time per output token, and up to 31.90% increased throughput in both settings.", "AI": {"tldr": "The paper introduces the Parallel Track (PT) Transformer, which significantly reduces synchronization operations in multi-GPU parallelism for LLM inference, improving efficiency and scalability.", "motivation": "The primary motivation is to address the communication bottlenecks and scalability issues arising from conventional tensor parallelism in large-scale LLM inference.", "method": "The authors restructure computation architectures in LLMs by introducing the novel Parallel Track (PT) Transformer design, reducing cross-device dependencies.", "result": "The PT architecture achieves up to a 16x reduction in synchronization, 15-30% faster time to first token, 2-12% faster per output token, and up to 31.90% increased throughput.", "conclusion": "PT Transformer successfully enhances LLM serving efficiency while maintaining model quality, making it a promising advancement in scalable multi-GPU inference systems."}}
{"id": "2602.07614", "pdf": "https://arxiv.org/pdf/2602.07614", "abs": "https://arxiv.org/abs/2602.07614", "authors": ["Rosario Napoli", "Gabriele Morabito", "Antonio Celesti", "Massimo Villari", "Maria Fazio"], "title": "Knowledge Graphs-Driven Intelligence for Distributed Decision Systems", "categories": ["cs.DC"], "comment": "Accepted to the 18th IEEE/ACM International Conference on Utility and Cloud Computing (UCC 2025)", "summary": "Modern distributed decision-making systems face significant challenges arising from data heterogeneity, dynamic environments, and the need for decentralized coordination. This paper introduces the Knowledge Sharing paradigm as an innovative approach that uses the semantic richness of Knowledge Graphs (KGs) and the representational power of Graph Embeddings (GEs) to achieve decentralized intelligence. Our architecture empowers individual nodes to locally construct semantic representations of their operational context, iteratively aggregating embeddings through neighbor-based exchanges using GraphSAGE. This iterative local aggregation process results in a dynamically evolving global semantic abstraction called Knowledge Map, enabling coordinated decision-making without centralized control. To validate our approach, we conduct extensive experiments under a distributed resource orchestration use case. We simulate different network topologies and node workloads, analyzing the local semantic drift of individual nodes. Experimental results confirm that our distributed knowledge-sharing mechanism effectively maintains semantic coherence and adaptability, making it suitable for complex and dynamic environments such as Edge Computing, IoT, and multi-agent systems.", "AI": {"tldr": "This paper proposes a novel Knowledge Sharing paradigm using Knowledge Graphs and Graph Embeddings for decentralized decision-making systems in complex environments.", "motivation": "The motivation is to address challenges in distributed decision-making systems, such as data heterogeneity, dynamic environments, and decentralized coordination.", "method": "The paper introduces a system where nodes employ Graph Embeddings and the GraphSAGE algorithm to locally and iteratively aggregate semantic representations, resulting in a dynamically evolving global Knowledge Map.", "result": "The distributed knowledge-sharing mechanism was validated through extensive experiments in a resource orchestration use case, demonstrating semantic coherence and adaptability across diverse network scenarios.", "conclusion": "The proposed approach is effective for decentralized decision-making in dynamic environments, showing promise in applications like Edge Computing, IoT, and multi-agent systems."}}
{"id": "2602.07850", "pdf": "https://arxiv.org/pdf/2602.07850", "abs": "https://arxiv.org/abs/2602.07850", "authors": ["Shanuja Sasi"], "title": "Privacy-Preserving Coding Schemes for Multi-Access Distributed Computing Models", "categories": ["cs.DC"], "comment": null, "summary": "Distributed computing frameworks such as MapReduce have become essential for large-scale data processing by decomposing tasks across multiple nodes. The multi-access distributed computing (MADC) model further advances this paradigm by decoupling mapper and reducer roles: dedicated mapper nodes store data and compute intermediate values, while reducer nodes are connected to multiple mappers and aggregate results to compute final outputs. This separation reduces communication bottlenecks without requiring file replication. In this paper, we introduce privacy constraints into MADC and develop private coded schemes for two specific connectivity models. We construct new families of extended placement delivery arrays and derive corresponding coding schemes that guarantee privacy of each reducer's assigned function.", "AI": {"tldr": "This paper integrates privacy into the MADC model by introducing private coded schemes and constructing new placement delivery arrays.", "motivation": "To address privacy concerns in distributed computing frameworks and extend the MADC model to ensure reducer function privacy.", "method": "Develop private coded schemes for specific connectivity models and construct extended placement delivery arrays for privacy assurance.", "result": "Two new coding schemes for private computing were developed alongside the extended placement delivery arrays.", "conclusion": "The methodologies presented ensure reducer function privacy within MADC, advancing its applicability in sensitive distributed computing tasks."}}
{"id": "2602.08257", "pdf": "https://arxiv.org/pdf/2602.08257", "abs": "https://arxiv.org/abs/2602.08257", "authors": ["Antonis Psistakis", "Burak Ocalan", "Fabien Chaix", "Ramnatthan Alagappan", "Josep Torrellas"], "title": "HEAL: Online Incremental Recovery for Leaderless Distributed Systems Across Persistency Models", "categories": ["cs.DC"], "comment": null, "summary": "Ensuring resilience in distributed systems has become an acute concern. In today's environment, it is crucial to develop light-weight mechanisms that recover a distributed system from faults quickly and with only a small impact on the live-system throughput. To address this need, this paper proposes a new low-overhead, general recovery scheme for modern non-transactional leaderless distributed systems. We call our scheme HEAL. On a node failure, HEAL performs an optimized online incremental recovery. This paper presents HEAL's algorithms for settings with Linearizable consistency and different memory persistency models. We implement HEAL on a 6-node Intel cluster. Our experiments running TAOBench workloads show that HEAL is very effective. HEAL recovers the cluster in 120 milliseconds on average, while reducing the throughput of the running workload by an average of 8.7%. In contrast, a conventional recovery scheme for leaderless systems needs 360 seconds to recover, reducing the throughput of the system by 16.2%. Finally, compared to an incremental recovery scheme for a state-of-the-art leader-based system, HEAL reduces the average recovery latency by 20.7x and the throughput degradation by 62.4%.", "AI": {"tldr": "HEAL is a low-overhead recovery scheme for leaderless distributed systems that achieves fast recovery with minimal impact on throughput.", "motivation": "Fault recovery in distributed systems is essential, especially for modern leaderless systems where rapid recovery with minimal throughput disruption is needed.", "method": "HEAL performs an optimized online incremental recovery using tailored algorithms for Linearizable consistency and various memory persistency models.", "result": "Experiments on a 6-node Intel cluster show HEAL recovers clusters in 120 ms, reducing workload throughput by 8.7%, outperforming conventional systems significantly.", "conclusion": "HEAL demonstrates improved efficiency and reduced recovery latency and throughput impact compared to conventional and state-of-the-art recovery schemes."}}
{"id": "2602.08081", "pdf": "https://arxiv.org/pdf/2602.08081", "abs": "https://arxiv.org/abs/2602.08081", "authors": ["Brian Rojkov", "Shubham Ranjan", "Derek Wright", "Manoj Sachdev"], "title": "Investigating Energy Bounds of Analog Compute-in-Memory with Local Normalization", "categories": ["cs.AR"], "comment": null, "summary": "Modern edge AI workloads demand maximum energy efficiency, motivating the pursuit of analog Compute-in-Memory (CIM) architectures. Simultaneously, the popularity of Large-Language-Models (LLMs) drives the adoption of low-bit floating-point formats which prioritize dynamic range. However, the conventional direct-accumulation CIM accommodates floating-points by normalizing them to a shared widened fixed-point scale. Consequently, hardware resolution is dictated by the input's dynamic range rather than its precision, and energy consumption is dominated by the ADC. We address this limitation by introducing local normalization for each input, weight, and multiply-accumulate (MAC) output via a Gain-Ranging MAC (GR-MAC). Normalization overhead is handled by low-power digital logic, enabling the computationally expensive MAC operation to remain in the energy-efficient low-precision analog regime. Energy modelling shows that the addition of a gain-ranging Stage to the MAC enables a 4-bit increase in input dynamic range without increased energy consumption at a 35 dB SQNR standard. Additionally, the ADC resolution requirement becomes invariant to input distribution assumptions, allowing construction of an upper bound with a 1.5-bit reduction compared to the conventional lower bound. These results establish a pathway towards unlocking favourable energy scaling trends of analog CIM for modern AI workloads.", "AI": {"tldr": "The paper introduces Gain-Ranging MAC (GR-MAC), addressing limitations in analog Compute-in-Memory (CIM) architectures when handling low-bit floating-point formats, improving energy efficiency and dynamic range.", "motivation": "Modern edge AI workloads require maximum energy efficiency while accommodating low-bit floating-point formats with high dynamic range. Existing CIM architectures face resolution and energy efficiency issues.", "method": "The proposed GR-MAC incorporates local normalization for each input, weight, and MAC output using a gain-ranging stage, supported by low-power digital logic, ensuring efficient computation.", "result": "GR-MAC allows a 4-bit increase in input dynamic range with no additional energy consumption and reduces ADC resolution requirements by 1.5 bits compared to conventional lower bounds.", "conclusion": "The GR-MAC design enhances analog CIM architectures, balancing energy efficiency and handling modern AI workloads with improved dynamic range and precision trade-offs."}}
{"id": "2602.06996", "pdf": "https://arxiv.org/pdf/2602.06996", "abs": "https://arxiv.org/abs/2602.06996", "authors": ["Katayoun Eshkofti", "Matthieu Barreau"], "title": "Curriculum-Learned Vanishing Stacked Residual PINNs for Hyperbolic PDE State Reconstruction", "categories": ["cs.NE", "cs.LG", "eess.SY"], "comment": null, "summary": "Modeling distributed dynamical systems governed by hyperbolic partial differential equations (PDEs) remains challenging due to discontinuities and shocks that hinder the convergence of traditional physics-informed neural networks (PINNs). The recently proposed vanishing stacked residual PINN (VSR-PINN) embeds a vanishing-viscosity mechanism within stacked residual refinements to enable a smooth transition from the parabolic to hyperbolic regime. This paper integrates three curriculum-learning methods as primal-dual (PD) optimization, causality progression, and adaptive sampling into the VSR-PINN. The PD strategy balances physics and data losses, the causality scheme unlocks deeper stacks by respecting temporal and gradient evolution, and adaptive sampling targets high residuals. Numerical experiments on traffic reconstruction confirm that enforcing causality systematically reduces the median point-wise MSE and its variability across runs, yielding improvements of nearly one order of magnitude over non-causal training in both the baseline and PD variants.", "AI": {"tldr": "This paper addresses the difficulty of modeling systems with hyperbolic PDEs by integrating three curriculum-learning methods into the vanishing stacked residual PINN (VSR-PINN).", "motivation": "Modeling distributed systems ruled by hyperbolic PDEs is challenging due to discontinuities and shocks that impede neural network convergence.", "method": "The study enhances VSR-PINN with primal-dual optimization, causality progression, and adaptive sampling strategies.", "result": "Experiments on traffic reconstruction demonstrate significant error reductions, improving predictions by nearly one order of magnitude.", "conclusion": "Incorporating causality and curriculum learning strategies into VSR-PINN improves performance and training stability for hyperbolic PDE problems."}}
{"id": "2602.07324", "pdf": "https://arxiv.org/pdf/2602.07324", "abs": "https://arxiv.org/abs/2602.07324", "authors": ["Abdullah H. Rasheed"], "title": "Static Analysis Under Non-Deterministic Program Assumptions", "categories": ["cs.PL"], "comment": null, "summary": "Static analyses overwhelmingly trade precision for soundness and automation. For this reason, their use-cases are restricted to situations where imprecision isn't prohibitive. In this paper, we propose and specify a static analysis that accepts user-supplied program assumptions that are local to program locations. Such assumptions can be used to counteract imprecision in static analyses, enabling their use in a much wider variety of applications. These assumptions are taken by the analyzer non-deterministically, resulting in a function from sets of accepted assumptions to the resulting analysis under those assumptions. We also demonstrate the utility of such a function in two ways, both of which showcase how it can enable optimization over a search space of assumptions that is otherwise infeasible without the specified analysis.", "AI": {"tldr": "The paper introduces a static analysis method that incorporates user-provided local program assumptions to reduce imprecision and enable broader applicability in analysis tasks.", "motivation": "Most static analyses sacrifice precision to maintain soundness and automation, which restricts their usability in scenarios requiring high precision.", "method": "The proposed static analysis leverages user-supplied assumptions tied to specific program locations and takes these assumptions non-deterministically to create a function mapping assumption sets to analysis outcomes.", "result": "The approach enables optimization across assumption search spaces and demonstrates utility with examples, overcoming challenges associated with traditional static analysis methods.", "conclusion": "Incorporating local program assumptions makes static analysis more versatile and useful, enabling it to handle previously infeasible applications more effectively."}}
{"id": "2602.07071", "pdf": "https://arxiv.org/pdf/2602.07071", "abs": "https://arxiv.org/abs/2602.07071", "authors": ["S M Rakib UI Karim", "Wenyi Lu", "Sean Goggins"], "title": "Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.", "AI": {"tldr": "This paper reviews the use of AI to address challenges in open-source software (OSS) sustainability, analyzing its applications like bug triaging and community health monitoring, while addressing ethical concerns and proposing future research directions.", "motivation": "The paper seeks to address the sustainability challenges in OSS, such as insufficient contributions, funding issues, and maintaining community health, by exploring how AI can provide solutions to these problems.", "method": "It conducts a literature review to synthesize interdisciplinary research on AI applications and their role in improving OSS sustainability and identifies areas where AI interventions are being implemented.", "result": "The paper finds potential in AI for enhancing OSS sustainability through automated processes like system maintenance and monitoring community dynamics, but it also identifies limitations related to data, bias, and ethical concerns.", "conclusion": "AI has the potential to augment human efforts in OSS, though it requires addressing ethical limitations and ensuring equitable applications. Future research is needed to bridge gaps and strengthen OSS ecosystems using AI."}}
{"id": "2602.06966", "pdf": "https://arxiv.org/pdf/2602.06966", "abs": "https://arxiv.org/abs/2602.06966", "authors": ["Kai Xu", "Hang Zhao", "Ruizhen Hu", "Min Yang", "Hao Liu", "Hui Zhang", "Haibin Yu"], "title": "Embodied Intelligence for Flexible Manufacturing: A Survey", "categories": ["cs.RO"], "comment": "in chinese language. ROBOT", "summary": "Driven by breakthroughs in next-generation artificial intelligence, embodied intelligence is rapidly advancing into industrial manufacturing. In flexible manufacturing, industrial embodied intelligence faces three core challenges: accurate process modeling and monitoring under limited perception, dynamic balancing between flexible adaptation and high-precision control, and the integration of general-purpose skills with specialized industrial operations. Accordingly, this survey reviews existing work from three viewpoints: Industrial Eye, Industrial Hand, and Industrial Brain. At the perception level (Industrial Eye), multimodal data fusion and real-time modeling in complex dynamic settings are examined. At the control level (Industrial Hand), flexible, adaptive, and precise manipulation for complex manufacturing processes is analyzed. At the decision level (Industrial Brain), intelligent optimization methods for process planning and line scheduling are summarized. By considering multi-level collaboration and interdisciplinary integration, this work reveals the key technological pathways of embodied intelligence for closed-loop optimization of perception-decision-execution in manufacturing systems. A three-stage evolution model for the development of embodied intelligence in flexible manufacturing scenarios, comprising cognition enhancement, skill transition, and system evolution, is proposed, and future development trends are examined, to offer both a theoretical framework and practical guidance for the interdisciplinary advancement of industrial embodied intelligence in the context of flexible manufacturing.", "AI": {"tldr": "The paper reviews embodied intelligence advancements in flexible manufacturing, analyzing perception, control, and decision-making challenges while proposing a framework for future development.", "motivation": "To address the challenges of integrating embodied intelligence into flexible manufacturing, such as limited perception, precision control, and skill integration.", "method": "A review organized into three viewpoints: Industrial Eye (perception), Industrial Hand (control), Industrial Brain (decision-making), alongside proposing a three-stage evolution model for embodied intelligence.", "result": "Insights into technological pathways for closed-loop optimization of perception, decision, and execution in manufacturing systems are revealed.", "conclusion": "The study outlines a theoretical framework and guidance for advancing embodied intelligence in flexible manufacturing, focusing on cognition enhancement, skill transition, and system evolution."}}
{"id": "2602.06973", "pdf": "https://arxiv.org/pdf/2602.06973", "abs": "https://arxiv.org/abs/2602.06973", "authors": ["Lucky Susanto", "Musa Izzanardi Wijanarko", "Khumaisa Nur'aini", "Farid Adilazuarda", "Alham Fikri Aji", "Derry Tanti Wijaya"], "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted to ARR January", "summary": "While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.", "AI": {"tldr": "This paper evaluates pixel-based language modeling and the reintroduction of tokenization via a multimodal model to study its fundamental constraints, finding significant alignment issues.", "motivation": "The study aims to question whether visual rendering of text truly resolves tokenization constraints, particularly for low-resource languages with non-Latin scripts.", "method": "The paper investigates script-tokenizer alignment performance within the DualGPT architecture using four Indonesian low-resource languages and compares a general-purpose tokenizer to a custom one.", "result": "The custom tokenizer outperformed the general-purpose Llama 2 tokenizer by up to 30.15 chrF++, exposing issues of reintroducing tokenization in visual renderings.", "conclusion": "Despite advances in multimodal models, tokenizers still pose a significant challenge, especially for equitable representation of low-resource languages."}}
{"id": "2602.07006", "pdf": "https://arxiv.org/pdf/2602.07006", "abs": "https://arxiv.org/abs/2602.07006", "authors": ["Alokesh Manna", "Neil Spencer", "Dipak K. Dey"], "title": "Scalable spatial point process models for forensic footwear analysis", "categories": ["cs.CV", "cs.LG", "stat.ML"], "comment": null, "summary": "Shoe print evidence recovered from crime scenes plays a key role in forensic investigations. By examining shoe prints, investigators can determine details of the footwear worn by suspects. However, establishing that a suspect's shoes match the make and model of a crime scene print may not be sufficient. Typically, thousands of shoes of the same size, make, and model are manufactured, any of which could be responsible for the print. Accordingly, a popular approach used by investigators is to examine the print for signs of ``accidentals,'' i.e., cuts, scrapes, and other features that accumulate on shoe soles after purchase due to wear. While some patterns of accidentals are common on certain types of shoes, others are highly distinctive, potentially distinguishing the suspect's shoe from all others. Quantifying the rarity of a pattern is thus essential to accurately measuring the strength of forensic evidence. In this study, we address this task by developing a hierarchical Bayesian model. Our improvement over existing methods primarily stems from two advancements. First, we frame our approach in terms of a latent Gaussian model, thus enabling inference to be efficiently scaled to large collections of annotated shoe prints via integrated nested Laplace approximations. Second, we incorporate spatially varying coefficients to model the relationship between shoes' tread patterns and accidental locations. We demonstrate these improvements through superior performance on held-out data, which enhances accuracy and reliability in forensic shoe print analysis.", "AI": {"tldr": "The paper develops a hierarchical Bayesian model to quantify the rarity of accidental patterns in shoe prints for forensic investigations, improving forensic accuracy and reliability.", "motivation": "There is a need to improve forensic evidence analysis by quantifying the rarity of accidental patterns (e.g., cuts, scrapes) on shoes, beyond just matching their make and model.", "method": "The study uses a hierarchical Bayesian model, leveraging a latent Gaussian approach with integrated nested Laplace approximations and spatially varying coefficients for superior forensic analysis.", "result": "The model achieves superior performance on held-out data, demonstrating its effectiveness in improving the accuracy of shoe print analysis.", "conclusion": "The proposed method significantly enhances the reliability and accuracy of forensic shoe print analysis, assisting investigations in quantifying pattern rarity."}}
{"id": "2602.07102", "pdf": "https://arxiv.org/pdf/2602.07102", "abs": "https://arxiv.org/abs/2602.07102", "authors": ["L\u00e9on Zheng", "Thomas Hirtz", "Yazid Janati", "Eric Moulines"], "title": "Fast and Robust Likelihood-Guided Diffusion Posterior Sampling with Amortized Variational Inference", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Zero-shot diffusion posterior sampling offers a flexible framework for inverse problems by accommodating arbitrary degradation operators at test time, but incurs high computational cost due to repeated likelihood-guided updates. In contrast, previous amortized diffusion approaches enable fast inference by replacing likelihood-based sampling with implicit inference models, but at the expense of robustness to unseen degradations. We introduce an amortization strategy for diffusion posterior sampling that preserves explicit likelihood guidance by amortizing the inner optimization problems arising in variational diffusion posterior sampling. This accelerates inference for in-distribution degradations while maintaining robustness to previously unseen operators, thereby improving the trade-off between efficiency and flexibility in diffusion-based inverse problems.", "AI": {"tldr": "The paper proposes a method to speed up diffusion-based inverse problem solving while retaining robustness to unseen operators.", "motivation": "The motivation is to address the computational inefficiency of zero-shot diffusion posterior sampling for inverse problems while overcoming the robustness issues of amortized diffusion approaches.", "method": "The method involves amortizing the inner optimization problem in variational diffusion posterior sampling to accelerate inference and maintain robustness.", "result": "This approach achieves faster inference for known degradations and preserves robustness to unseen degradation operators.", "conclusion": "The proposed strategy improves the balance between efficiency and flexibility in solving diffusion-based inverse problems."}}
{"id": "2602.07032", "pdf": "https://arxiv.org/pdf/2602.07032", "abs": "https://arxiv.org/abs/2602.07032", "authors": ["Yuheng Wu", "Berk Gokmen", "Zhouhua Xie", "Peijing Li", "Caroline Trippel", "Priyanka Raina", "Thierry Tambe"], "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation", "categories": ["cs.AI", "cs.AR", "cs.CL"], "comment": null, "summary": "Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually constructed examples, LLM-FSM is built through a fully automated pipeline. LLM-FSM first constructs FSM with configurable state counts and constrained transition structures. It then prompts LLMs to express each FSM in a structured YAML format with an application context, and to further convert that YAML into a natural-language (NL) specification. From the same YAML, our pipeline synthesizes the reference RTL and testbench in a correct-by-construction manner. All 1,000 problems are verified using LLM-based and SAT-solver-based checks, with human review on a subset. Our experiments show that even the strongest LLMs exhibit sharply declining accuracy as FSM complexity increases. We further demonstrate that training-time scaling via supervised fine-tuning (SFT) generalizes effectively to out-of-distribution (OOD) tasks, while increasing test-time compute improves reasoning reliability. Finally, LLM-FSM remains extensible by allowing its FSM complexity to scale with future model capabilities.", "AI": {"tldr": "The paper introduces LLM-FSM, a benchmark for evaluating large language models' (LLMs) ability to translate natural-language FSM behavior into correct RTL implementations, revealing sharp accuracy declines as FSM complexity grows.", "motivation": "To evaluate and advance LLMs\u2019 ability to handle finite-state reasoning and implement FSM behavior effectively, which is essential for hardware design.", "method": "The LLM-FSM benchmark is constructed through an automated pipeline that generates FSMs, synthesizes their corresponding RTL and testbench, and converts FSMs into natural-language specifications for evaluation by LLMs.", "result": "Experiments concluded that LLM performance decreases with FSM complexity. Supervised fine-tuning improves generalization to new tasks, and increased computation during testing enhances reasoning reliability.", "conclusion": "LLM-FSM provides a scalable and extensible platform to benchmark LLMs in FSM tasks, with potential improvements tied to fine-tuning and computational scaling."}}
{"id": "2602.06993", "pdf": "https://arxiv.org/pdf/2602.06993", "abs": "https://arxiv.org/abs/2602.06993", "authors": ["Shashank"], "title": "Attractor Patch Networks: Reducing Catastrophic Forgetting with Routed Low-Rank Patch Experts", "categories": ["cs.LG", "cs.CL"], "comment": "9 pages. Code (APN implementation in nanoGPT transformer): https://github.com/shankch/nanoGPT-apn (baseline: https://github.com/karpathy/nanoGPT) Data prep: https://github.com/karpathy/nanoGPT/tree/master/data/shakespeare_char and https://github.com/karpathy/nanoGPT/tree/master/data/shakespeare", "summary": "Transformers achieve strong language modeling accuracy, yet their position-wise feed-forward networks (FFNs) are dense, globally shared, and typically updated end to end. These properties create two practical tensions. First, dense FFNs spend the same compute on every token regardless of context, and they allocate capacity uniformly even when language exhibits highly clustered context structure. Second, continual learning, in the sense of updating the model while serving a data stream, often produces interference because a small update touches broadly shared weights.\n  We propose Attractor Patch Networks (APN), a plug-compatible replacement for the Transformer FFN. APN is a bank of patch experts. A similarity router selects a small top-k set of patches for each token by matching the token representation to learned prototypes. Each selected patch emits a low-rank residual update conditioned on a compact code. The architecture yields conditional, context-specialized nonlinear transformations while preserving the standard Transformer interface.\n  This paper focuses on APN as an architectural primitive. We formalize APN, analyze its expressivity as a piecewise low-rank residual function class, and derive simple interference and stability arguments that make APN naturally compatible with continual learning. In experiments on character-level language modeling, APN achieves competitive perplexity (4.57 vs 4.32 PPL) while enabling dramatically better continual adaptation: when adapting to a shifted domain, APN achieves 2.6 times better retention (11.1 vs 29.4 PPL on the original domain) and 2.8 times better adaptation (6.4 vs 17.8 PPL on the new domain) compared to global fine-tuning of a dense FFN baseline.", "AI": {"tldr": "The paper introduces Attractor Patch Networks (APN) as a replacement for Transformer FFNs, tackling inefficiencies of dense FFNs and enhancing continual learning capabilities.", "motivation": "Transformer's dense, globally shared FFN creates inefficiency in processing tokens uniformly and interferes with continual learning adaptations.", "method": "APN utilizes patch experts selected via a similarity router for tokens, applying low-rank residual updates conditioned on compact codes to ensure conditional and context-specialized transformations.", "result": "APN achieves competitive perplexity in language modeling and greatly enhances continual learning adaptation and retention capabilities compared to the dense FFN baseline.", "conclusion": "APN improves conditioning capabilities of Transformers, resolves continual learning challenges, and preserves interface while maintaining competitive modeling performance."}}
{"id": "2602.07400", "pdf": "https://arxiv.org/pdf/2602.07400", "abs": "https://arxiv.org/abs/2602.07400", "authors": ["Simon B\u00fchrer", "Andreas Plesner", "Aczel Till", "Roger Wattenhofer"], "title": "BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks", "categories": ["cs.LG", "cs.ET", "cs.PF"], "comment": null, "summary": "The energy and latency costs of deep neural network inference are increasingly driven by deployment rather than training, motivating hardware-specialized alternatives to arithmetic-heavy models. Field-Programmable Gate Arrays (FPGAs) provide an attractive substrate for such specialization, yet existing FPGA-based neural approaches are fragmented and difficult to compare. We present BitLogic, a fully gradient-based, end-to-end trainable framework for FPGA-native neural networks built around Lookup Table (LUT) computation. BitLogic replaces multiply-accumulate operations with differentiable LUT nodes that map directly to FPGA primitives, enabling native binary computation, sparse connectivity, and efficient hardware realization. The framework offers a modular functional API supporting diverse architectures, along with learned encoders, hardware-aware heads, and multiple boundary-consistent LUT relaxations. An automated Register Transfer Level (RTL) export pipeline translates trained PyTorch models into synthesizable HDL, ensuring equivalence between software and hardware inference. Experiments across standard vision benchmarks and heterogeneous hardware platforms demonstrate competitive accuracy and substantial gains in FPGA efficiency, including 72.3% test accuracy on CIFAR-10 achieved with fewer than 0.3M logic gates, while attaining sub-20 ns single-sample inference using only LUT resources.", "AI": {"tldr": "The paper introduces BitLogic, an FPGA-native framework for neural networks focused on efficient inference using Lookup Tables (LUT).", "motivation": "To address energy and latency costs in deep neural network inference and enable efficient FPGA-based deployment.", "method": "The BitLogic framework replaces arithmetic-heavy operations with gradient-based LUT computation for FPGA efficiency, and provides end-to-end trainable modular APIs.", "result": "BitLogic achieves competitive performance, e.g., 72.3% test accuracy on CIFAR-10 with under 0.3M logic gates and sub-20 ns inference latency.", "conclusion": "BitLogic shows that FPGA-specialized neural networks can provide significant gains in efficiency without sacrificing accuracy, making it a promising alternative for low-resource computational scenarios."}}
{"id": "2602.06994", "pdf": "https://arxiv.org/pdf/2602.06994", "abs": "https://arxiv.org/abs/2602.06994", "authors": ["Rongzhao He", "Dalin Zhu", "Ying Wang", "Songhong Yue", "Leilei Zhao", "Yu Fu", "Dan Wu", "Bin Hu", "Weihao Zheng"], "title": "SurfAge-Net: A Hierarchical Surface-Based Network for Interpretable Fine-Grained Brain Age Prediction", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Brain age prediction serves as a powerful framework for assessing brain status and detecting deviations associated with neurodevelopmental and neurodegenerative disorders. However, most existing approaches emphasize whole-brain age prediction and therefore overlook the pronounced regional heterogeneity of brain maturation that is crucial for detecting localized atypical trajectories. To address this limitation, we propose a novel spherical surface-based brain age prediction network (SurfAge-Net) that leverages multiple morphological metrics to capture region-specific developmental patterns with enhanced robustness and clinical interpretability. SurfAge-Net establishes a new modeling paradigm by incorporating the connectomic principles of cortical organization: it explicitly models both intra- and inter-hemispheric dependencies through a spatial-channel mixing and a lateralization-aware attention mechanism, enabling the network to characterize the coordinate maturation pattern uniquely associated with each target region. Validated on three fetal and neonatal datasets, SurfAge-Net outperforms existing approaches (global MAE = 0.54, regional MAE = 0.45 in gestational/postmenstrual weeks) and demonstrates strong generalizability across external cohorts. Importantly, it provides spatially precise and biologically interpretable maps of cortical maturation, effectively identifying heterogeneous delays and regional-specific abnormalities in atypical developmental populations. These results established fine-grained brain age prediction as a promising paradigm for advancing neurodevelopmental research and supporting early clinical assessment.", "AI": {"tldr": "The paper introduces SurfAge-Net, a new deep learning approach for brain age prediction, focusing on regional maturation patterns rather than whole-brain analysis.", "motivation": "Current brain age prediction methods overlook regional differences in brain maturation, which are critical for understanding localized developmental anomalies.", "method": "SurfAge-Net uses spherical surface-based modeling with morphological metrics, spatial-channel mixing, and a lateralization-aware attention mechanism to predict brain age regionally.", "result": "SurfAge-Net achieves superior accuracy (global MAE = 0.54, regional MAE = 0.45) compared to existing methods, demonstrating generalizability and providing precise maps of cortical maturation.", "conclusion": "Fine-grained brain age prediction via SurfAge-Net shows great potential for enhancing neurodevelopmental research and clinical assessments."}}
{"id": "2602.08271", "pdf": "https://arxiv.org/pdf/2602.08271", "abs": "https://arxiv.org/abs/2602.08271", "authors": ["Antonis Psistakis", "Burak Ocalan", "Chloe Alverti", "Fabien Chaix", "Ramnatthan Alagappan", "Josep Torrellas"], "title": "Towards CXL Resilience to CPU Failures", "categories": ["cs.DC"], "comment": null, "summary": "Compute Express Link (CXL) 3.0 and beyond allows the compute nodes of a cluster to share data with hardware cache coherence and at the granularity of a cache line. This enables shared-memory semantics for distributed computing, but introduces new resilience challenges: a node failure leads to the loss of the dirty data in its caches, corrupting application state. Unfortunately, the CXL specification does not consider processor failures. Moreover, when a component fails, the specification tries to isolate it and continue application execution; there is no attempt to bring the application to a consistent state. To address these limitations, this paper extends the CXL specification to be resilient to node failures, and to correctly recover the application after node failures. We call the system ReCXL. To handle the failure of nodes, ReCXL augments the coherence transaction of a write with messages that propagate the update to a small set of other nodes (i.e., Replicas). Replicas save the update in a hardware Logging Unit. Such replication ensures resilience to node failures. Then, at regular intervals, the Logging Units dump the updates to memory. Recovery involves using the logs in the Logging Units to bring the directory and memory to a correct state. Our evaluation shows that ReCXL enables fault-tolerant execution with only a 30% slowdown over the same platform with no fault-tolerance support.", "AI": {"tldr": "The paper discusses ReCXL, a system designed to improve the Compute Express Link (CXL) specification by addressing resilience to node failures in distributed computing, ensuring fault tolerance.", "motivation": "CXL 3.0 introduces shared-memory semantics in distributed computing using hardware cache coherence, but lacks provisions for resilience to node failures, which can corrupt application states.", "method": "ReCXL augments the CXL coherence transaction by replicating write updates to designated nodes, using a hardware Logging Unit for recovery purposes, and periodically dumping updates to memory for consistent state recovery.", "result": "ReCXL achieves fault-tolerant execution with only a 30% performance slowdown compared to a platform without fault-tolerance features.", "conclusion": "ReCXL extends CXL to address resilience to node failures, offering a practical mechanism for recovery and ensuring distributed computing stability with limited performance impact."}}
{"id": "2602.08323", "pdf": "https://arxiv.org/pdf/2602.08323", "abs": "https://arxiv.org/abs/2602.08323", "authors": ["Yousuf Choudhary", "Tosiron Adegbija"], "title": "Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study", "categories": ["cs.AR", "cs.ET"], "comment": "Design, Automation and Test in Europe (DATE) 2026", "summary": "Antiferromagnetic Tunnel Junctions (AFMTJs) enable picosecond switching and femtojoule writes through ultrafast sublattice dynamics. We present the first end-to-end AFMTJ simulation framework integrating multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level modeling. SPICE-based simulations show that AFMTJs achieve ~8x lower write latency and ~9x lower write energy than conventional MTJs. When integrated into an in-memory computing architecture, AFMTJs deliver 17.5x average speedup and nearly 20x energy savings versus a CPU baseline-significantly outperforming MTJ-based IMC. These results establish AFMTJs as a compelling primitive for scalable, low-power computing.", "AI": {"tldr": "The paper introduces a simulation framework for Antiferromagnetic Tunnel Junctions (AFMTJs) showcasing their high speed and low energy consumption compared to conventional MTJs.", "motivation": "To address the need for faster and more energy-efficient memory solutions through AFMTJs, leveraging their ultrafast sublattice dynamics.", "method": "The study combines multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level SPICE-based modeling to simulate AFMTJ performance.", "result": "AFMTJs demonstrate ~8x lower write latency and ~9x lower write energy than MTJs, and in-memory computing using AFMTJs achieves 17.5x speedup and 20x energy savings compared to CPUs.", "conclusion": "AFMTJs are validated as a highly efficient primitive for scalable and low-power computing applications."}}
{"id": "2602.07002", "pdf": "https://arxiv.org/pdf/2602.07002", "abs": "https://arxiv.org/abs/2602.07002", "authors": ["Masahi Okada", "Kazuki Sakai", "Hiroaki Yoshida", "Masaki Okoshi", "Tadahiro Taniguchi"], "title": "MolLIBRA: Genetic Molecular Optimization with Multi-Fingerprint Surrogates and Text-Molecule Aligned Critic", "categories": ["cs.NE", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "We study sample-efficient molecular optimization under a limited budget of oracle evaluations. We propose MolLIBRA (MultimOdaLity and Language Integrated Bayesian and evolutionaRy optimizAtion), a genetic algorithm based framework that pre-ranks candidate molecules using multiple critics before oracle calls: (i) an ensemble of Gaussian process (GP) surrogates defined over multiple molecular fingerprints and (ii) a pretrained text-molecule aligned encoder CLAMP. The GP ensemble enables adaptive selection of task-appropriate fingerprints, while CLAMP provides a zero-shot scoring signal from task descriptions by measuring the similarity between molecular and text embeddings. On the Practical Molecular Optimization (PMO) benchmark with a budget of 1,000 evaluations (PMO-1K), MolLIBRA-L, our variant with a language-model-based candidate generator, attains the best Top-10 AUC on 14/22 tasks and the highest overall sum of Top-10 AUC across tasks among prior methods.", "AI": {"tldr": "The paper introduces MolLIBRA, a framework combining Bayesian optimization, genetic algorithms, and text-molecule alignment for molecular optimization with limited oracle evaluations, achieving state-of-the-art results on the PMO-1K benchmark.", "motivation": "The work aims to improve sample-efficient molecular optimization by reducing reliance on expensive oracle evaluations, enabling effective optimization under strict resource constraints.", "method": "MolLIBRA uses a genetic algorithm pre-ranking candidates based on multiple critics: Gaussian process (GP) surrogates over molecular fingerprints and a pretrained encoder (CLAMP) for zero-shot scoring by aligning molecular and text embeddings.", "result": "On the PMO-1K benchmark, MolLIBRA-L achieved superior Top-10 AUC performance in 14/22 tasks and the highest overall AUC sum across tasks compared to previous methods.", "conclusion": "The proposed MolLIBRA framework demonstrates significant improvements in molecular optimization efficiency and performance, offering a novel approach for task-specific and resource-constrained optimization."}}
{"id": "2602.07455", "pdf": "https://arxiv.org/pdf/2602.07455", "abs": "https://arxiv.org/abs/2602.07455", "authors": ["Jinhua Wu", "Yuting Wang", "Liukun Yu", "Linglong Meng"], "title": "RustCompCert: A Verified and Verifying Compiler for a Sequential Subset of Rust", "categories": ["cs.PL"], "comment": "Submitted to Rust Verify 2026", "summary": "We present our ongoing work on developing an end-to-end verified Rust compiler based on CompCert. It provides two guarantees: one is semantics preservation from Rust to assembly, i.e., the behaviors of source code includes the behaviors of target code, with which the properties verified at the source can be preserved down to the target; the other is memory safety ensured by the verifying compilation -- the borrow checking pass, which can simplify the verification of Rust programs, e.g., by allowing the verification tools focus on the functional correctness.", "AI": {"tldr": "The paper proposes an end-to-end verified Rust compiler based on CompCert, offering guarantees of semantics preservation and memory safety.", "motivation": "To ensure verified compilation of Rust programs, maintaining semantics preservation and memory safety to simplify program verification.", "method": "The authors developed a compiler that incorporates verified semantics preservation from Rust to assembly and a borrow-checking pass for memory safety.", "result": "The compiler ensures source-to-target code behavior consistency and memory safety, facilitating simplified functional correctness verification.", "conclusion": "This approach fosters trust in Rust program verification, bolstering confidence in derived properties and correctness at the assembly level."}}
{"id": "2602.07072", "pdf": "https://arxiv.org/pdf/2602.07072", "abs": "https://arxiv.org/abs/2602.07072", "authors": ["Igor Costa"], "title": "AgentSpawn: Adaptive Multi-Agent Collaboration Through Dynamic Spawning for Long-Horizon Code Generation", "categories": ["cs.SE", "cs.MA"], "comment": "18 pages, 4 figures, 6 tables", "summary": "Long-horizon code generation requires sustained context and adaptive expertise across domains. Current multi-agent systems use static workflows that cannot adapt when runtime analysis reveals unanticipated complexity. We propose AgentSpawn, an architecture enabling dynamic agent collaboration through: (1) automatic memory transfer during spawning, (2) adaptive spawning policies triggered by runtime complexity metrics, and (3) coherence protocols for concurrent modifications. AgentSpawn addresses five critical gaps in existing research around memory continuity, skill inheritance, task resumption, runtime spawning, and concurrent coherence. Experimental validation demonstrates AgentSpawn achieves 34% higher completion rates than static baselines on benchmarks like SWE-bench while reducing memory overhead by 42% through selective slicing.", "AI": {"tldr": "AgentSpawn is a dynamic multi-agent system enabling better collaboration for long-horizon coding tasks by using adaptive spawning and advanced memory management, showing improved performance and efficiency compared to static approaches.", "motivation": "Long-horizon code generation demands sustained contextual understanding and adaptability, but current multi-agent systems fail to adjust workflows dynamically when faced with unexpected challenges.", "method": "AgentSpawn employs automatic memory transfer, adaptive spawning based on runtime complexity, and protocols for coherence during concurrent modifications.", "result": "The architecture achieves a 34% improvement in task completion rates on benchmarks like SWE-bench and reduces memory overhead by 42% through selective slicing.", "conclusion": "AgentSpawn addresses critical challenges in multi-agent collaboration and showcases enhanced effectiveness and resource efficiency in dynamic coding environments."}}
{"id": "2602.06967", "pdf": "https://arxiv.org/pdf/2602.06967", "abs": "https://arxiv.org/abs/2602.06967", "authors": ["Siqi Song", "Xuanbing Xie", "Zonglin Li", "Yuqiang Li", "Shijie Wang", "Biqing Qi"], "title": "Leveraging Adaptive Group Negotiation for Heterogeneous Multi-Robot Collaboration with Large Language Models", "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "20 pages, 12 figures, Under Review", "summary": "Multi-robot collaboration tasks often require heterogeneous robots to work together over long horizons under spatial constraints and environmental uncertainties. Although Large Language Models (LLMs) excel at reasoning and planning, their potential for coordinated control has not been fully explored. Inspired by human teamwork, we present CLiMRS (Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System), an adaptive group negotiation framework among LLMs for multi-robot collaboration. This framework pairs each robot with an LLM agent and dynamically forms subgroups through a general proposal planner. Within each subgroup, a subgroup manager leads perception-driven multi-LLM discussions to get commands for actions. Feedback is provided by both robot execution outcomes and environment changes. This grouping-planning-execution-feedback loop enables efficient planning and robust execution. To evaluate these capabilities, we introduce CLiMBench, a heterogeneous multi-robot benchmark of challenging assembly tasks. Our experiments show that CLiMRS surpasses the best baseline, achieving over 40% higher efficiency on complex tasks without sacrificing success on simpler ones. Overall, our results demonstrate that leveraging human-inspired group formation and negotiation principles significantly enhances the efficiency of heterogeneous multi-robot collaboration. Our code is available here: https://github.com/song-siqi/CLiMRS.", "AI": {"tldr": "The paper proposes CLiMRS, a framework for heterogeneous multi-robot collaboration driven by Large Language Models (LLMs), utilizing negotiation and feedback loops for efficient task planning and execution, demonstrated with significant performance improvement in benchmarks.", "motivation": "The paper is motivated by the need for efficient and robust coordination among heterogeneous multi-robot systems in complex, spatially constrained, and uncertain environments.", "method": "CLiMRS pairs each robot with an LLM agent to form dynamic subgroups under a general proposal planner. These subgroups are led by a subgroup manager that facilitates perception-driven multi-LLM discussions to determine actions. A grouping-planning-execution-feedback loop optimizes task execution.", "result": "CLiMRS outperforms traditional baselines, achieving over 40% greater efficiency in complex multi-robot tasks compared to simpler task systems.", "conclusion": "Human-inspired principles of group formation and negotiation enhance the collaboration efficiency of heterogeneous multi-robot systems. Key advancements rely on leveraging LLM-driven planning mechanisms."}}
{"id": "2602.06975", "pdf": "https://arxiv.org/pdf/2602.06975", "abs": "https://arxiv.org/abs/2602.06975", "authors": ["R. James Cotton", "Thomas Leonard"], "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.", "AI": {"tldr": "BiomechAgent simplifies biomechanical data analysis through a natural language interface, applicable to various analysis tasks without requiring coding expertise.", "motivation": "Facilitating biomechanical data analysis for non-programmers and leveraging markerless motion capture advancements.", "method": "Design and benchmark BiomechAgent\u2014a natural language-based code-generating AI for biomechanical analysis, enhanced with domain-specific guidance and specialized tools.", "result": "BiomechAgent exhibited strong accuracy in data retrieval, visualization, and demonstrated clinical reasoning proficiency. Domain-specific prompts and specialized tools improved its performance.", "conclusion": "BiomechAgent effectively democratizes and enhances accessibility of biomechanical data analysis, though performance depends heavily on the underlying language model and specialized design choices."}}
{"id": "2602.07008", "pdf": "https://arxiv.org/pdf/2602.07008", "abs": "https://arxiv.org/abs/2602.07008", "authors": ["Ruoyu Chen", "Shangquan Sun", "Xiaoqing Guo", "Sanyi Zhang", "Kangwei Liu", "Shiming Liu", "Zhangcheng Wang", "Qunli Zhang", "Hua Zhang", "Xiaochun Cao"], "title": "Where Not to Learn: Prior-Aligned Training with Subset-based Attribution Constraints for Reliable Decision-Making", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Reliable models should not only predict correctly, but also justify decisions with acceptable evidence. Yet conventional supervised learning typically provides only class-level labels, allowing models to achieve high accuracy through shortcut correlations rather than the intended evidence. Human priors can help constrain such behavior, but aligning models to these priors remains challenging because learned representations often diverge from human perception. To address this challenge, we propose an attribution-based human prior alignment method. We encode human priors as input regions that the model is expected to rely on (e.g., bounding boxes), and leverage a highly faithful subset-selection-based attribution approach to expose the model's decision evidence during training. When the attribution region deviates substantially from the prior regions, we penalize reliance on off-prior evidence, encouraging the model to shift its attribution toward the intended regions. This is achieved through a training objective that imposes attribution constraints induced by the human prior. We validate our method on both image classification and click decision tasks in MLLM-based GUI agent models. Across conventional classification and autoregressive generation settings, human prior alignment consistently improves task accuracy while also enhancing the model's decision reasonability.", "AI": {"tldr": "This paper introduces a method to make AI models provide decisions based on human-like acceptable evidence by aligning their decision-making process with human perception.", "motivation": "Traditional supervised learning often fails to ensure models rely on intended evidence, instead exploiting shortcut correlations, which do not align with human reasoning.", "method": "The authors propose using attribution-based human prior alignment by enforcing constraints that encourage models to align their decision evidence (e.g., image regions) with human-defined priors during training.", "result": "The proposed method improves both task accuracy and the reasonability of model decisions on image classification and GUI agent tasks.", "conclusion": "Human prior alignment effectively constrains models to rely on meaningful evidence, enhancing both prediction accuracy and justificability of decisions."}}
{"id": "2602.07132", "pdf": "https://arxiv.org/pdf/2602.07132", "abs": "https://arxiv.org/abs/2602.07132", "authors": ["Oswin So", "Brian Karrer", "Chuchu Fan", "Ricky T. Q. Chen", "Guan-Horng Liu"], "title": "Discrete Adjoint Matching", "categories": ["stat.ML", "cs.LG"], "comment": "ICLR 2026", "summary": "Computation methods for solving entropy-regularized reward optimization -- a class of problems widely used for fine-tuning generative models -- have advanced rapidly. Among those, Adjoint Matching (AM, Domingo-Enrich et al., 2025) has proven highly effective in continuous state spaces with differentiable rewards. Transferring these practical successes to discrete generative modeling, however, remains particularly challenging and largely unexplored, mainly due to the drastic shift in generative model classes to discrete state spaces, which are nowhere differentiable. In this work, we propose Discrete Adjoint Matching (DAM) -- a discrete variant of AM for fine-tuning discrete generative models characterized by Continuous-Time Markov Chains, such as diffusion-based large language models. The core of DAM is the introduction of discrete adjoint-an estimator of the optimal solution to the original problem but formulated on discrete domains-from which standard matching frameworks can be applied. This is derived via a purely statistical standpoint, in contrast to the control-theoretic viewpoint in AM, thereby opening up new algorithmic opportunities for general adjoint-based estimators. We showcase DAM's effectiveness on synthetic and mathematical reasoning tasks.", "AI": {"tldr": "Introduces Discrete Adjoint Matching (DAM), adapting adjoint matching methods to discrete generative models via Continuous-Time Markov Chains.", "motivation": "Extend effective computation methods, like Adjoint Matching (AM), from continuous state spaces to discrete generative modeling challenges.", "method": "Propose and define DAM, employing discrete adjoints derived from statistical principles to solve entropy-regularized reward optimization for discrete models.", "result": "Demonstrated DAM's utility in synthetic and reasoning tasks, showcasing its practical applicability in discrete domains.", "conclusion": "DAM broadens the effective use of adjoint estimators to discrete generative models, overcoming differentiability challenges and introducing new opportunities for algorithm development."}}
{"id": "2602.07034", "pdf": "https://arxiv.org/pdf/2602.07034", "abs": "https://arxiv.org/abs/2602.07034", "authors": ["Jinxiu Qu", "Zirui Tang", "Hongzhang Huang", "Boyu Niu", "Wei Zhou", "Jiannan Wang", "Yitong Song", "Guoliang Li", "Xuanhe Zhou", "Fan Wu"], "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA", "categories": ["cs.AI"], "comment": null, "summary": "Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at https://github.com/weAIDB/ST-Raptor, and a demonstration video is available at https://youtu.be/9GDR-94Cau4.", "AI": {"tldr": "This paper presents ST-Raptor, a system for accurately addressing semi-structured table question answering by combining interactive analysis, visual editing, structural modeling, and agent-driven queries. It outperforms current solutions.", "motivation": "Addressing the challenges of inefficient and error-prone manual interpretation of semi-structured tables, as well as overcoming the limitations in existing automated methods that fail with complex layouts and information retention.", "method": "ST-Raptor integrates visual editing, tree-based structural modeling, and agentic query-driven resolutions to process and interact with semi-structured table data accurately.", "result": "Experimental results show superior accuracy and usability of ST-Raptor when tested on both benchmark and real-world datasets, showcasing advantages over current methods.", "conclusion": "ST-Raptor provides an effective and user-focused approach to semi-structured table QA, enhancing both the precision of results and user interaction usability."}}
{"id": "2602.07030", "pdf": "https://arxiv.org/pdf/2602.07030", "abs": "https://arxiv.org/abs/2602.07030", "authors": ["Young Jin Ahn", "Yiyang Du", "Zheyuan Zhang", "Haisen Kang"], "title": "Neural Sabermetrics with World Model: Play-by-play Predictive Modeling with Large Language Model", "categories": ["cs.LG"], "comment": null, "summary": "Classical sabermetrics has profoundly shaped baseball analytics by summarizing long histories of play into compact statistics. While these metrics are invaluable for valuation and retrospective analysis, they do not define a generative model of how baseball games unfold pitch by pitch, leaving most existing approaches limited to single-step prediction or post-hoc analysis. In this work, we present Neural Sabermetrics with World Model, a Large Language Model (LLM) based play-by-play world model for baseball. We cast baseball games as long auto-regressive sequences of events and continuously pretrain a single LLM on more than ten years of Major League Baseball (MLB) tracking data, comprising over seven million pitch sequences and approximately three billion tokens. The resulting model is capable of predicting multiple aspects of game evolution within a unified framework. We evaluate our model on both in-distribution regular-season data and out-of-distribution postseason games and compare against strong neural baselines from prior work. Despite using a single backbone model, our approach outperforms the performance of existing baselines, (1) correctly predicting approximately 64% of next pitches within a plate appearance and (2) 78% of batter swing decisions, suggesting that LLMs can serve as effective world models for sports.", "AI": {"tldr": "This paper introduces Neural Sabermetrics with World Model, a Large Language Model (LLM)-based method for pitch-by-pitch prediction in baseball using extensive MLB tracking data.", "motivation": "Existing sabermetrics summarize historical play but lack a generative model for predicting baseball games sequentially, motivating the need for a robust model capable of detailed prediction.", "method": "The authors developed an auto-regressive sequence framework using LLMs trained on over 10 years of MLB data, with billions of tokens and millions of pitch sequences.", "result": "The model predicts next pitches with 64% accuracy and batter swing decisions with 78% accuracy, outperforming prior neural baselines.", "conclusion": "LLMs can effectively model sequential events in sports, offering advancements in predictive analytics for baseball."}}
{"id": "2602.07945", "pdf": "https://arxiv.org/pdf/2602.07945", "abs": "https://arxiv.org/abs/2602.07945", "authors": ["N. R. Rapaka", "R. Peddinti", "E. Tiunov", "N. J. Faraj", "A. N. Alkhooori", "L. Aolita", "Y. Addad", "M. K. Riahi"], "title": "A quantum-inspired multi-level tensor-train monolithic space-time method for nonlinear PDEs", "categories": ["math.NA", "cs.PF", "physics.comp-ph", "quant-ph"], "comment": "29", "summary": "We propose a multilevel tensor-train (TT) framework for solving nonlinear partial differential equations (PDEs) in a global space-time formulation. While space-time TT solvers have demonstrated significant potential for compressed high-dimensional simulations, the literature contains few systematic comparisons with classical time-stepping methods, limited error convergence analyses, and little quantitative assessment of the impact of TT rounding on numerical accuracy. Likewise, existing studies fail to demonstrate performance across a diverse set of PDEs and parameter ranges. In practice, monolithic Newton iterations may stagnate or fail to converge in strongly nonlinear, stiff, or advection-dominated regimes, where poor initial guesses and severely ill-conditioned space-time Jacobians hinder robust convergence. We overcome this limitation by introducing a coarse-to-fine multilevel strategy fully embedded within the TT format. Each level refines both spatial and temporal resolutions while transferring the TT solution through low-rank prolongation operators, providing robust initializations for successive Newton solves. Residuals, Jacobians, and transfer operators are represented directly in TT and solved with the adaptive-rank DMRG algorithm. Numerical experiments for a selection of nonlinear PDEs including Fisher-KPP, viscous Burgers, sine-Gordon, and KdV cover diffusive, convective, and dispersive dynamics, demonstrating that the multilevel TT approach consistently converges where single-level space-time Newton iterations fail. In dynamic, advection-dominated (nonlinear) scenarios, multilevel TT surpasses single-level TT, achieving high accuracy with significantly reduced computational cost, specifically when high-fidelity numerical simulation is required.", "AI": {"tldr": "The paper introduces a multilevel tensor-train framework for solving nonlinear PDEs globally in space-time, addressing challenges like convergence issues in strongly nonlinear regimes and demonstrating its effectiveness over traditional methods.", "motivation": "Existing space-time TT methods lack systematic comparisons with classical techniques, error convergence analysis, and robust solutions for stiff and nonlinear PDEs, necessitating a framework that surmounts these limitations.", "method": "The proposed framework embeds a coarse-to-fine multilevel strategy fully within the TT format, refining spatial and temporal resolutions through low-rank operators while utilizing adaptive-rank DMRG for residuals and Jacobians.", "result": "Numerical experiments demonstrate the approach's success across various nonlinear PDEs, outperforming single-level TT and achieving high accuracy with reduced computational costs, particularly in complex dynamic scenarios.", "conclusion": "The multilevel TT framework enhances robustness, accuracy, and efficiency in solving nonlinear PDEs, addressing previous limitations and offering a viable alternative to classical and single-level TT methods."}}
{"id": "2602.07261", "pdf": "https://arxiv.org/pdf/2602.07261", "abs": "https://arxiv.org/abs/2602.07261", "authors": ["Qi Zhang"], "title": "Cognitive algorithms and systems of episodic memory, semantic memory and their learnings", "categories": ["q-bio.NC", "cs.AI", "cs.ET"], "comment": "33 pages, 6 figures, 6 tables", "summary": "Declarative memory, the memory that can be \"declared\" in words or languages, is made up of two dissociated parts: episodic memory and semantic memory. This dissociation has its neuroanatomical basis episodic memory is mostly associated with the hippocampus and semantic memory with the neocortex. The two memories, on the other hand, are closely related. Lesions in the hippocampus often result in various impairments of explicit memory, e.g., anterograde, retrograde and developmental amnesias, and semantic learning deficit. These impairments provide opportunities for us to understand how the two memories may be acquired, stored and organized. This chapter reviews several cognitive systems that are centered to mimic explicit memory, and other systems that are neuroanatomically based and are implemented to simulate those memory impairments mentioned above. This review includes: the structures of the computational systems, their learning rules, and their simulations of memory acquisition and impairments.", "AI": {"tldr": "Declarative memory consists of episodic and semantic memory with neuroanatomical differences. This paper explores computational systems mimicking explicit memory and its impairments.", "motivation": "To understand how declarative memory (episodic and semantic) is acquired, stored, organized, and how impairments affect memory processes.", "method": "The paper reviews cognitive and neuroanatomically-based computational systems that simulate memory acquisition and impairments, detailing their structures, learning rules, and simulations.", "result": "The systems showcase how memory acquisition and impairments occur, based on computational modeling and neuroanatomical insights.", "conclusion": "Simulations in computational systems provide valuable insights into the mechanisms and interrelation of episodic and semantic memory and their impairments due to hippocampal lesions."}}
{"id": "2602.08747", "pdf": "https://arxiv.org/pdf/2602.08747", "abs": "https://arxiv.org/abs/2602.08747", "authors": ["Zhixin Zhao", "Yitao Hu", "Simin Chen", "Mingfang Ji", "Wei Yang", "Yuhao Zhang", "Laiping Zhao", "Wenxin Li", "Xiulong Liu", "Wenyu Qu", "Hao Wang"], "title": "PARD: Enhancing Goodput for Inference Pipeline via Proactive Request Dropping", "categories": ["cs.DC"], "comment": "Accepted by EuroSys'26", "summary": "Modern deep neural network (DNN) applications integrate multiple DNN models into inference pipelines with stringent latency requirements for customized tasks. To mitigate extensive request timeouts caused by accumulation, systems for inference pipelines commonly drop a subset of requests so the remaining ones can satisfy latency constraints. Since it is commonly believed that request dropping adversely affects goodput, existing systems only drop requests when they have to, which we call reactive dropping. However, this reactive policy can not maintain high goodput, as it neither makes timely dropping decisions nor identifies the proper set of requests to drop, leading to issues of dropping requests too late or dropping the wrong set of requests.\n  We propose that the inference system should proactively drop certain requests in advance to enhance the goodput across the entire workload. To achieve this, we design an inference system PARD. It enhances goodput with timely and precise dropping decisions by integrating a proactive dropping method that decides when to drop requests using runtime information of the inference pipeline, and an adaptive request priority mechanism that selects which specific requests to drop based on remaining latency budgets and workload intensity. Evaluation on a cluster of 64 GPUs over real-world workloads shows that PARD achieves $16\\%$-$176\\%$ higher goodput than the state of the art while reducing the drop rate and wasted computation resources by $1.6\\times$-$17\\times$ and $1.5\\times$-$62\\times$ respectively.", "AI": {"tldr": "This paper proposes PARD, a proactive system for enhancing goodput in inference pipelines by timely and targeted request dropping.", "motivation": "To address the limitations of reactive request dropping, which can lead to inefficient goodput due to late or improper decisions in DNN inference pipelines.", "method": "The authors developed PARD, integrating a proactive dropping decision method and adaptive request prioritization based on latency budgets and workload intensity.", "result": "Evaluation on a GPU cluster across real-world workloads demonstrated a 16%-176% improvement in goodput, a reduction in drop rate by 1.6x-17x, and decreased wasted computational resources by 1.5x-62x.", "conclusion": "Proactive request dropping improves overall system goodput, reduces system latency issues, and increases computational resource efficiency compared to reactive methods."}}
{"id": "2602.08842", "pdf": "https://arxiv.org/pdf/2602.08842", "abs": "https://arxiv.org/abs/2602.08842", "authors": ["Jean-Pierre Busch", "Lukas Ostendorf", "Guido Linden", "Lennart Reiher", "Till Beemelmanns", "Bastian Lampe", "Timo Woopen", "Lutz Eckstein"], "title": "karl. -- A Research Vehicle for Automated and Connected Driving", "categories": ["cs.AR", "cs.RO", "eess.SY"], "comment": "8 pages; Accepted to be published as part of the 37th Intelligent Vehicles Symposium (IV), Detroit, MI, United States, June 22-25, 2026", "summary": "As highly automated driving is transitioning from single-vehicle closed-access testing to commercial deployments of public ride-hailing in selected areas (e.g., Waymo), automated driving and connected cooperative intelligent transport systems (C-ITS) remain active fields of research. Even though simulation is omnipresent in the development and validation life cycle of automated and connected driving technology, the complex nature of public road traffic and software that masters it still requires real-world integration and testing with actual vehicles. Dedicated vehicles for research and development allow testing and validation of software and hardware components under real-world conditions early on. They also enable collecting and publishing real-world datasets that let others conduct research without vehicle access, and support early demonstration of futuristic use cases. In this paper, we present karl., our new research vehicle for automated and connected driving. Apart from major corporations, few institutions worldwide have access to their own L4-capable research vehicles, restricting their ability to carry out independent research. This paper aims to help bridge that gap by sharing the reasoning, design choices, and technical details that went into making karl. a flexible and powerful platform for research, engineering, and validation in the context of automated and connected driving. More impressions of karl. are available at https://karl.ac.", "AI": {"tldr": "This paper introduces 'karl.', a new L4-capable research vehicle designed for automated and connected driving research aimed at addressing the research gap for institutions lacking their own vehicle platforms.", "motivation": "To bridge the limitation faced by institutions without L4-capable research vehicles by providing details and insights into the development of 'karl.', thereby facilitating advanced research in automated and connected driving.", "method": "Development of the research vehicle 'karl.' and a detailed explanation of its reasoning, design choices, and technical components to establish a flexible research platform.", "result": "The creation and deployment of 'karl.', a flexible and powerful autonomous vehicle platform enabling real-world testing and the collection of datasets for the broader research community.", "conclusion": "The implementation of 'karl.' supports independent research, validation, and exploration of futuristic use cases in automated and connected driving by lowering barriers to experimentation and innovation."}}
{"id": "2602.07009", "pdf": "https://arxiv.org/pdf/2602.07009", "abs": "https://arxiv.org/abs/2602.07009", "authors": ["MD Azizul Hakim"], "title": "Multi-Scale Temporal Homeostasis Enables Efficient and Robust Neural Networks", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Artificial neural networks achieve strong performance on benchmark tasks but remain fundamentally brittle under perturbations, limiting their deployment in real-world settings. In contrast, biological nervous systems sustain reliable function across decades through homeostatic regulation coordinated across multiple temporal scales. Inspired by this principle, this presents Multi-Scale Temporal Homeostasis (MSTH), a biologically grounded framework that integrates ultra-fast (5-ms), fast (2-s), medium (5-min) and slow (1-hrs) regulation into artificial networks. MSTH implements the cross-scale coordination system for artificial neural networks, providing a unified temporal hierarchy that moves beyond superficial biomimicry. The cross-scale coordination enhances computational efficiency through evolutionary-refined optimization mechanisms. Experiments across molecular, graph and image classification benchmarks show that MSTH consistently improves accuracy, eliminates catastrophic failures and enhances recovery from perturbations. Moreover, MSTH outperforms both single-scale bio-inspired models and established state-of-the-art methods, demonstrating generality across diverse domains. These findings establish cross-scale temporal coordination as a core principle for stabilizing artificial neural systems, positioning MSTH as a foundation for building robust, resilient and biologically faithful intelligence.", "AI": {"tldr": "The paper introduces Multi-Scale Temporal Homeostasis (MSTH), a biologically inspired framework, for stabilizing artificial neural networks under perturbations.", "motivation": "Despite strong performance, artificial neural networks are brittle under perturbations, unlike biological systems which maintain reliability through multi-scale homeostasis. This research explores integrating such biological principles into artificial networks.", "method": "The study proposes and develops MSTH, which integrates ultra-fast, fast, medium, and slow temporal scales for homeostatic regulation, simulating cross-scale coordination mechanisms in biological systems.", "result": "MSTH consistently improves accuracy, eliminates catastrophic failures, and enhances recovery from perturbations across diverse benchmarks, outperforming other bio-inspired and state-of-the-art methods.", "conclusion": "Cross-scale temporal coordination is established as a foundation for stabilizing artificial intelligence systems, with MSTH proving to be a robust and biologically faithful framework."}}
{"id": "2602.07627", "pdf": "https://arxiv.org/pdf/2602.07627", "abs": "https://arxiv.org/abs/2602.07627", "authors": ["Xuran Cai", "Amir Goharshady", "S Hitarth", "Chun Kit Lam"], "title": "Series-Parallel-Loop Decompositions of Control-flow Graphs", "categories": ["cs.PL"], "comment": null, "summary": "Control-flow graphs (CFGs) of structured programs are well known to exhibit strong sparsity properties. Traditionally, this sparsity has been modeled using graph parameters such as treewidth and pathwidth, enabling the development of faster parameterized algorithms for tasks in compiler optimization, model checking, and program analysis. However, these parameters only approximate the structural constraints of CFGs: although every structured CFG has treewidth at most~7, many graphs with treewidth at most~7 cannot arise as CFGs. As a result, existing parameterized techniques are optimized for a substantially broader class of graphs than those encountered in practice.\n  In this work, we introduce a new grammar-based decomposition framework that characterizes \\emph{exactly} the class of control-flow graphs generated by structured programs. Our decomposition is intuitive, mirrors the syntactic structure of programs, and remains fully compatible with the dynamic-programming paradigm of treewidth-based methods. Using this framework, we design improved algorithms for two classical compiler optimization problems: \\emph{Register Allocation} and \\emph{Lifetime-Optimal Speculative Partial Redundancy Elimination (LOSPRE)}. Extensive experimental evaluation demonstrates significant performance improvements over previous state-of-the-art approaches, highlighting the benefits of using decompositions tailored specifically to CFGs.", "AI": {"tldr": "The paper introduces a grammar-based decomposition framework tailored for control-flow graphs (CFGs) to enhance computational tasks like compiler optimization and program analysis.", "motivation": "Existing methods to analyze CFGs rely on structural parameters like treewidth, but these overgeneralize and include graphs that do not align with CFG structures, leaving room for improvement in precision and efficiency.", "method": "A novel decomposition framework is proposed that precisely characterizes CFGs from structured programs. It mirrors program syntax and integrates with treewidth-based algorithms for dynamic programming.", "result": "The framework enables improved algorithms for Register Allocation and Lifetime-Optimal Speculative Partial Redundancy Elimination (LOSPRE). Experiments show significant performance enhancements compared to previous methods.", "conclusion": "Tailoring decomposition frameworks more specifically to control-flow graphs yields better algorithmic results in compiler optimization tasks, demonstrating applicability and efficiency."}}
{"id": "2602.07079", "pdf": "https://arxiv.org/pdf/2602.07079", "abs": "https://arxiv.org/abs/2602.07079", "authors": ["Go Frendi Gunawan", "Mukhlis Amien"], "title": "Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark", "categories": ["cs.SE", "cs.CL"], "comment": "10 pages, 7 figures. Under review. Code and data will be fully released", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in software engineering, yet comprehensive benchmarks covering diverse SE activities remain limited. We present a multi-task evaluation of 11 state-of-the-art LLMs across five representative software engineering tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis. Our automated verification framework measures both output quality and completion efficiency. Key findings reveal that (1) models achieving identical perfect scores exhibit 22x variation in completion time, 49x variation in tool efficiency, and 53x variation in estimated cost; (2) tool usage frequency shows no correlation with success (r = 0.077, p = 0.575) - one model used 917 tool calls while another solved the same task with 3 calls; (3) we identify two distinct inefficiency patterns: loop inefficiency and inference inefficiency; and (4) coding tasks achieve 100 percent success while research tasks present greater challenges (90.9 percent). We release all experimental data, verification scripts, and analysis code for full reproducibility.", "AI": {"tldr": "This paper evaluates 11 LLMs on five software engineering tasks, providing insights on efficiency, effectiveness, resource usage, and identifies inefficiency patterns.", "motivation": "Current benchmarks for Large Language Models in software engineering tasks are insufficiently comprehensive, making it difficult to assess their diverse capabilities.", "method": "The study employs an automated verification framework to evaluate the quality and efficiency of LLM outputs across five SE tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis.", "result": "Findings include large variations in completion time, tool efficiency, and estimated cost among models with identical scores. Coding tasks achieve 100% success, while research tasks face greater challenges.", "conclusion": "This work highlights inefficiency patterns and provides a detailed performance analysis of LLMs, contributing improved evaluation frameworks and releasing experimental data for reproducibility."}}
{"id": "2602.06968", "pdf": "https://arxiv.org/pdf/2602.06968", "abs": "https://arxiv.org/abs/2602.06968", "authors": ["Xubo Luo", "Zhaojin Li", "Xue Wan", "Wei Zhang", "Leizheng Shu"], "title": "Learning to Anchor Visual Odometry: KAN-Based Pose Regression for Planetary Landing", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, accepted by RA-L", "summary": "Accurate and real-time 6-DoF localization is mission-critical for autonomous lunar landing, yet existing approaches remain limited: visual odometry (VO) drifts unboundedly, while map-based absolute localization fails in texture-sparse or low-light terrain. We introduce KANLoc, a monocular localization framework that tightly couples VO with a lightweight but robust absolute pose regressor. At its core is a Kolmogorov-Arnold Network (KAN) that learns the complex mapping from image features to map coordinates, producing sparse but highly reliable global pose anchors. These anchors are fused into a bundle adjustment framework, effectively canceling drift while retaining local motion precision. KANLoc delivers three key advances: (i) a KAN-based pose regressor that achieves high accuracy with remarkable parameter efficiency, (ii) a hybrid VO-absolute localization scheme that yields globally consistent real-time trajectories (>=15 FPS), and (iii) a tailored data augmentation strategy that improves robustness to sensor occlusion. On both realistic synthetic and real lunar landing datasets, KANLoc reduces average translation and rotation error by 32% and 45%, respectively, with per-trajectory gains of up to 45%/48%, outperforming strong baselines.", "AI": {"tldr": "The paper introduces KANLoc, a framework combining visual odometry (VO) and a unique deep pose regressor for accurate and real-time 6-DoF localization for autonomous lunar landings.", "motivation": "To address the limitations of current localization methods, such as drift in VO and ineffectiveness of map-based methods in low-light or texture-sparse terrains.", "method": "KANLoc integrates VO with a Kolmogorov-Arnold Network (KAN) for absolute pose regression, fusing global pose anchors through bundle adjustment to reduce errors.", "result": "The framework reduces average translation and rotation errors by 32% and 45%, respectively, and achieves real-time performance while surpassing baseline methods.", "conclusion": "KANLoc demonstrates a robust and efficient solution for lunar localization, combining accuracy and robustness in challenging terrains."}}
{"id": "2602.06976", "pdf": "https://arxiv.org/pdf/2602.06976", "abs": "https://arxiv.org/abs/2602.06976", "authors": ["Chen Shen", "Wei Cheng", "Jingyue Yang", "Huan Zhang", "Yuhan Wu", "Wei Hu"], "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.", "AI": {"tldr": "The paper introduces ILA-agent, a framework to enable LLMs to learn unfamiliar programming languages dynamically, without extensive fine-tuning, and evaluates it using a new benchmark called Cangjie-bench. ILA-agent surpasses other methods in performance.", "motivation": "To address LLM limitations in handling unfamiliar programming languages without relying on data-intensive fine-tuning, fostering a more dynamic, interactive learning approach.", "method": "The authors propose ILA-agent, a framework that equips LLMs with behavioral tools to explore, apply, and verify language knowledge through interaction with official resources and an execution environment. They also create Cangjie-bench to test this method on a new language.", "result": "ILA-agent outperforms retrieval-augmented baselines across tasks like code generation, translation, and repair in the Cangjie language, showing improved capabilities in language mastery.", "conclusion": "ILA-agent validates the effectiveness of inference-time language acquisition for unfamiliar programming languages, but challenges remain in bridging performance gaps to enhance emergent behaviors."}}
{"id": "2602.07011", "pdf": "https://arxiv.org/pdf/2602.07011", "abs": "https://arxiv.org/abs/2602.07011", "authors": ["Zhuonan Wang", "Zhenxuan Fan", "Siwen Tan", "Yu Zhong", "Yuqian Yuan", "Haoyuan Li", "Hao Jiang", "Wenqiao Zhang", "Feifei Shao", "Hongwei Wang", "Jun Xiao"], "title": "MAU-GPT: Enhancing Multi-type Industrial Anomaly Understanding via Anomaly-aware and Generalist Experts Adaptation", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "9 pages, 5 figures", "summary": "As industrial manufacturing scales, automating fine-grained product image analysis has become critical for quality control. However, existing approaches are hindered by limited dataset coverage and poor model generalization across diverse and complex anomaly patterns. To address these challenges, we introduce MAU-Set, a comprehensive dataset for Multi-type industrial Anomaly Understanding. It spans multiple industrial domains and features a hierarchical task structure, ranging from binary classification to complex reasoning. Alongside this dataset, we establish a rigorous evaluation protocol to facilitate fair and comprehensive model assessment. Building upon this foundation, we further present MAU-GPT, a domain-adapted multimodal large model specifically designed for industrial anomaly understanding. It incorporates a novel AMoE-LoRA mechanism that unifies anomaly-aware and generalist experts adaptation, enhancing both understanding and reasoning across diverse defect classes. Extensive experiments show that MAU-GPT consistently outperforms prior state-of-the-art methods across all domains, demonstrating strong potential for scalable and automated industrial inspection.", "AI": {"tldr": "This paper introduces MAU-Set, a comprehensive dataset for industrial anomaly understanding, and MAU-GPT, a domain-adapted multimodal model, achieving superior results for automated inspection.", "motivation": "To address the limitations of narrow dataset coverage and poor generalization in models for industrial quality control.", "method": "Introduced MAU-Set, a complex dataset with hierarchical tasks, and developed MAU-GPT, a multimodal large model with an AMoE-LoRA mechanism for better adaptability.", "result": "MAU-GPT outperformed prior state-of-the-art methods, showcasing its effectiveness in diverse defect detection tasks across multiple industries.", "conclusion": "The proposed dataset and model significantly advance automated quality control, providing a scalable solution for industrial anomaly understanding."}}
{"id": "2602.07632", "pdf": "https://arxiv.org/pdf/2602.07632", "abs": "https://arxiv.org/abs/2602.07632", "authors": ["Jinhua Lyu", "Tianmin Yu", "Ying Ma", "Naichen Shi"], "title": "Scalable Mean-Field Variational Inference via Preconditioned Primal-Dual Optimization", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we investigate the large-scale mean-field variational inference (MFVI) problem from a mini-batch primal-dual perspective. By reformulating MFVI as a constrained finite-sum problem, we develop a novel primal-dual algorithm based on an augmented Lagrangian formulation, termed primal-dual variational inference (PD-VI). PD-VI jointly updates global and local variational parameters in the evidence lower bound in a scalable manner. To further account for heterogeneous loss geometry across different variational parameter blocks, we introduce a block-preconditioned extension, P$^2$D-VI, which adapts the primal-dual updates to the geometry of each parameter block and improves both numerical robustness and practical efficiency. We establish convergence guarantees for both PD-VI and P$^2$D-VI under properly chosen constant step size, without relying on conjugacy assumptions or explicit bounded-variance conditions. In particular, we prove $O(1/T)$ convergence to a stationary point in general settings and linear convergence under strong convexity. Numerical experiments on synthetic data and a real large-scale spatial transcriptomics dataset demonstrate that our methods consistently outperform existing stochastic variational inference approaches in terms of convergence speed and solution quality.", "AI": {"tldr": "This paper addresses the challenges in mean-field variational inference (MFVI) by proposing a novel primal-dual algorithm (PD-VI) and its block-preconditioned extension (P$^2$D-VI), ensuring better scalability, robustness, and solution quality.", "motivation": "Current minimization methods for MFVI suffer from scalability and robustness issues with heterogeneous loss geometries, requiring a method to efficiently update variational parameters without restrictive assumptions.", "method": "The authors reformulate MFVI as a constrained finite-sum optimization problem and develop the primal-dual algorithm (PD-VI) relying on augmented Lagrangian formulation. P$^2$D-VI adapts updates to parameter geometry for further robustness.", "result": "PD-VI and P$^2$D-VI methods achieve $O(1/T)$ convergence and linear convergence under strong convexity. Numerical experiments show superior performance compared to stochastic variational inference approaches on synthetic and real datasets.", "conclusion": "The proposed PD-VI and P$^2$D-VI algorithms provide scalable, efficient, and robust solutions to MFVI problems, supporting their application in complex, large-scale datasets."}}
{"id": "2602.07035", "pdf": "https://arxiv.org/pdf/2602.07035", "abs": "https://arxiv.org/abs/2602.07035", "authors": ["Jiahao Zhao", "Shaoxuan Xu", "Zhongxiang Sun", "Fengqi Zhu", "Jingyang Ou", "Yuling Shi", "Chongxuan Li", "Xiao Zhang", "Jun Xu"], "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C", "AI": {"tldr": "This paper introduces DLLM-Searcher, an optimization framework for diffusion Large Language Model-based search agents, addressing efficiency and reasoning capability challenges.", "motivation": "To tackle the inefficiency of search agents caused by high latency and improve the reasoning and tool-calling weaknesses of current dLLMs.", "method": "The authors designed a two-stage post-training pipeline (Agentic SFT and Agentic VRPO) to improve reasoning and tool-calling. They also propose a novel agent paradigm, P-ReAct, to exploit dLLMs' parallel decoding and flexible generation.", "result": "DLLM-Searcher achieved competitive performance with mainstream LLM search agents. P-ReAct provided approximately 15% faster inference.", "conclusion": "The study demonstrates that it is possible to optimize dLLMs for search agents, enhancing their reasoning and lowering latency, thus achieving significant efficiency improvements."}}
{"id": "2602.07031", "pdf": "https://arxiv.org/pdf/2602.07031", "abs": "https://arxiv.org/abs/2602.07031", "authors": ["Dong Li", "Shuai Huang", "Yapeng Cao", "Yujun Cui", "Xiaobin Wei", "Hongtao Cao"], "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "This study develops a Lagged Backward-Compatible Physics-Informed Neural Network (LBC-PINN) for simulating and inverting one-dimensional unsaturated soil consolidation under long-term loading. To address the challenges of coupled air and water pressure dissipation across multi-scale time domains, the framework integrates logarithmic time segmentation, lagged compatibility loss enforcement, and segment-wise transfer learning.\n  In forward analysis, the LBC-PINN with recommended segmentation schemes accurately predicts pore air and pore water pressure evolution. Model predictions are validated against finite element method (FEM) results, with mean absolute errors below 1e-2 for time durations up to 1e10 seconds. A simplified segmentation strategy based on the characteristic air-phase dissipation time improves computational efficiency while preserving predictive accuracy. Sensitivity analyses confirm the robustness of the framework across air-to-water permeability ratios ranging from 1e-3 to 1e3.", "AI": {"tldr": "This paper introduces LBC-PINN for tackling complex challenges in soil consolidation simulations over varying time scales, achieving accurate results validated against FEM models.", "motivation": "The study aims to improve simulation and inversion of unsaturated soil consolidation under long-term loading conditions, addressing multi-scale time and coupled dissipation challenges.", "method": "The framework uses a Lagged Backward-Compatible Physics-Informed Neural Network, incorporating logarithmic time segmentation, compatibility loss enforcement, and segment-wise transfer learning.", "result": "The LBC-PINN accurately predicts pore air and water pressure evolution with mean absolute errors below 1e-2 and demonstrates robust performance across permeability ratios from 1e-3 to 1e3.", "conclusion": "The proposed segmentation strategy improves computational efficiency while maintaining prediction accuracy, showcasing the approach's potential for soil consolidation simulations."}}
{"id": "2602.08670", "pdf": "https://arxiv.org/pdf/2602.08670", "abs": "https://arxiv.org/abs/2602.08670", "authors": ["Yang Bai"], "title": "A Machine Learning accelerated geophysical fluid solver", "categories": ["cs.CV", "cs.CE", "cs.PF", "physics.comp-ph"], "comment": "Master Thesis", "summary": "Machine learning methods have been successful in many areas, like image classification and natural language processing. However, it still needs to be determined how to apply ML to areas with mathematical constraints, like solving PDEs. Among various approaches to applying ML techniques to solving PDEs, the data-driven discretization method presents a promising way of accelerating and improving existing PDE solver on structured grids where it predicts the coefficients of quasi-linear stencils for computing values or derivatives of a function at given positions. It can improve the accuracy and stability of low-resolution simulation compared with using traditional finite difference or finite volume schemes. Meanwhile, it can also benefit from traditional numerical schemes like achieving conservation law by adapting finite volume type formulations. In this thesis, we have implemented the shallow water equation and Euler equation classic solver under a different framework. Experiments show that our classic solver performs much better than the Pyclaw solver. Then we propose four different deep neural networks for the ML-based solver. The results indicate that two of these approaches could output satisfactory solutions.", "AI": {"tldr": "The paper explores machine learning methods for solving PDEs and proposes ML-based solvers that show promise in improving accuracy and stability compared to traditional numerical solvers.", "motivation": "To address the challenge of applying machine learning methods to areas constrained by mathematical frameworks, specifically PDEs.", "method": "Implemented classic solvers for shallow water and Euler equations, and compared them to Pyclaw. Developed four different deep neural network models for ML-based PDE solvers.", "result": "Two of the proposed ML models provided satisfactory solutions and outperformed traditional solvers under experimentation.", "conclusion": "Machine learning methods hold significant potential to enhance PDE solving techniques by improving accuracy and stability, and yields favorable results when integrated with classic solver frameworks."}}
{"id": "2602.07539", "pdf": "https://arxiv.org/pdf/2602.07539", "abs": "https://arxiv.org/abs/2602.07539", "authors": ["Yixuan Liu", "Zhiyuan Ma", "Likai Tang", "Runmin Gan", "Xinche Zhang", "Jinhao Li", "Chao Xie", "Sen Song"], "title": "Training-Driven Representational Geometry Modularization Predicts Brain Alignment in Language Models", "categories": ["q-bio.NC", "cs.CL"], "comment": null, "summary": "How large language models (LLMs) align with the neural representation and computation of human language is a central question in cognitive science. Using representational geometry as a mechanistic lens, we addressed this by tracking entropy, curvature, and fMRI encoding scores throughout Pythia (70M-1B) training. We identified a geometric modularization where layers self-organize into stable low- and high-complexity clusters. The low-complexity module, characterized by reduced entropy and curvature, consistently better predicted human language network activity. This alignment followed heterogeneous spatial-temporal trajectories: rapid and stable in temporal regions (AntTemp, PostTemp), but delayed and dynamic in frontal areas (IFG, IFGorb). Crucially, reduced curvature remained a robust predictor of model-brain alignment even after controlling for training progress, an effect that strengthened with model scale. These results links training-driven geometric reorganization to temporal-frontal functional specialization, suggesting that representational smoothing facilitates neural-like linguistic processing.", "AI": {"tldr": "The paper explores how large language models (LLMs) align with human language neural representation using representational geometry metrics like entropy and curvature, and fMRI data for analysis.", "motivation": "To understand how large language models correspond to the neural processes underlying human linguistic functions by examining their training dynamics and computational structure.", "method": "The authors analyzed geometric metrics such as entropy, curvature, and fMRI encoding scores across training stages of Pythia LLMs (models ranging from 70M-1B parameters) and identified modularization trends. Human brain activity regions like temporal and frontal areas were also studied for alignment with LLM outputs.", "result": "Layers of LLMs were observed to self-organize into low-complexity and high-complexity clusters, with the low-complexity cluster predicting human brain activity more accurately. The alignment was region-specific, exhibiting both stable and dynamic trajectories across temporal and frontal regions. Alignment improved with larger-scale models, and curvature emerged as a key predictor even after controlling for training progress.", "conclusion": "The study links geometric reorganization during LLM training to human neural specialization, suggesting that smoother representational structures enable more human-like linguistic processing."}}
{"id": "2602.07215", "pdf": "https://arxiv.org/pdf/2602.07215", "abs": "https://arxiv.org/abs/2602.07215", "authors": ["Haiyuan Li", "Hari Madhukumar", "Shuangyi Yan", "Yulei Wu", "Dimitra Simeonidou"], "title": "Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks", "categories": ["eess.SY", "cs.AI", "cs.DC"], "comment": null, "summary": "Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile edge networks emerges as a promising solution. However, it also poses new challenges, including heterogeneous multi-modal LMs with diverse resource demands and inference speeds, varied prompt/output modalities that complicate orchestration, and resource-limited infrastructure ill-suited for concurrent LM execution. In response, we propose a Multi-Agentic AI framework for latency- and fairness-aware multi-modal LM inference in mobile edge networks. Our solution includes a long-term planning agent, a short-term prompt scheduling agent, and multiple on-node LM deployment agents, all powered by foundation language models. These agents cooperatively optimize prompt routing and LM deployment through natural language reasoning over runtime telemetry and historical experience. To evaluate its performance, we further develop a city-wide testbed that supports network monitoring, containerized LM deployment, intra-server resource management, and inter-server communications. Experiments demonstrate that our solution reduces average latency by over 80% and improves fairness (Normalized Jain index) to 0.90 compared to other baselines. Moreover, our solution adapts quickly without fine-tuning, offering a generalizable solution for optimizing GenAI services in edge environments.", "AI": {"tldr": "The paper proposes a Multi-Agentic AI framework for optimizing latency and fairness in deploying generative AI models on mobile edge networks, achieving significant improvements in efficiency and adaptability.", "motivation": "Deploying large language models in mobile edge networks presents challenges such as resource limitations, diverse model demands, and complexity in orchestration, while aiming to resolve issues like high latency, poor customizability, and privacy concerns in centralized inference.", "method": "The proposed framework includes a long-term planning agent, a short-term prompt scheduling agent, and on-node model deployment agents that collaborate using language model-powered reasoning, leveraging runtime data and historical insights to optimize deployments.", "result": "The solution demonstrates over 80% reduction in average latency and improves fairness (Normalized Jain index) to 0.90, showcasing superior performance compared to baseline methods in experimental city-wide testbeds.", "conclusion": "The framework provides an adaptable and generalizable solution for delivering efficient and equitable generative AI services in mobile edge environments without requiring additional model fine-tuning."}}
{"id": "2602.07010", "pdf": "https://arxiv.org/pdf/2602.07010", "abs": "https://arxiv.org/abs/2602.07010", "authors": ["Szymon Mamo\u0144", "Max Talanov", "Alessandro Crimi"], "title": "Learning Alzheimer's Disease Signatures by bridging EEG with Spiking Neural Networks and Biophysical Simulations", "categories": ["cs.NE", "cs.AI"], "comment": "11 pages ,8 figures", "summary": "As the prevalence of Alzheimer's disease (AD) rises, improving mechanistic insight from non-invasive biomarkers is increasingly critical. Recent work suggests that circuit-level brain alterations manifest as changes in electroencephalography (EEG) spectral features detectable by machine learning. However, conventional deep learning approaches for EEG-based AD detection are computationally intensive and mechanistically opaque. Spiking neural networks (SNNs) offer a biologically plausible and energy-efficient alternative, yet their application to AD diagnosis remains largely unexplored.\n  We propose a neuro-bridge framework that links data-driven learning with minimal, biophysically grounded simulations, enabling bidirectional interpretation between machine learning signatures and circuit-level mechanisms in AD. Using resting-state clinical EEG, we train an SNN classifier that achieves competitive performance (AUC = 0.839) and identifies the aperiodic 1/f slope as a key discriminative marker.\n  The 1/f slope reflects excitation-inhibition balance. To interpret this mechanistically, we construct spiking network simulations in which inhibitory-to-excitatory synaptic ratios are systematically varied to emulate healthy, mild cognitive impairment, and AD-like states. Using both membrane potential-based and synaptic current-based EEG proxies, we reproduce empirical spectral slowing and altered alpha organization.\n  Incorporating empirical functional connectivity priors into multi-subnetwork simulations further enhances spectral differentiation, demonstrating that large-scale network topology constrains EEG signatures more strongly than excitation-inhibition balance alone. Overall, this neuro-bridge approach connects SNN-based classification with interpretable circuit simulations, advancing mechanistic understanding of EEG biomarkers while enabling scalable, explainable AD detection.", "AI": {"tldr": "This paper introduces a spiking neural network (SNN)-based methodology for Alzheimer's disease (AD) diagnosis using EEG data and emphasizes its computational efficiency, interpretability, and biological grounding.", "motivation": "As Alzheimer's disease prevalence rises, there is a critical need for non-invasive biomarkers that improve mechanistic understanding while being computationally efficient and interpretable.", "method": "The authors propose a neuro-bridge framework combining SNN classifiers trained on EEG data with biophysically grounded simulations to interpret machine learning findings in terms of circuit mechanisms in AD.", "result": "The SNN classifier achieves an AUC of 0.839 and identifies the aperiodic 1/f slope as a key marker. Simulations reveal how variations in synaptic ratios and network topology influence EEG spectral features associated with AD.", "conclusion": "The proposed neuro-bridge approach enables scalable, interpretable, and biologically plausible AD detection while providing mechanistic insights into EEG biomarkers through spiking neural network models."}}
{"id": "2602.07742", "pdf": "https://arxiv.org/pdf/2602.07742", "abs": "https://arxiv.org/abs/2602.07742", "authors": ["Nat Karmios", "Sacha-\u00c9lie Ayoun", "Philippa Gardner"], "title": "Gillian Debugging: Swinging Through the (Compositional Symbolic Execution) Trees, Extended Version", "categories": ["cs.PL"], "comment": "24 pages, 11 figures. To be published at TACAS 2026", "summary": "In recent years, compositional symbolic execution (CSE) tools have been growing in prominence and are becoming more and more applicable to real-world codebases. Still to this day, however, debugging the output of these tools remains difficult, even for specialist users. To address this, we introduce a debugging interface for symbolic execution tools, integrated with Visual Studio Code and the Gillian multi-language CSE platform, with strong focus on visualisation, interactivity, and intuitive representation of symbolic execution trees. We take care in making this interface tool-agnostic, easing its transfer to other symbolic analysis tools in future. We empirically evaluate our work with a user study, the results of which show the debugger's usefulness in helping early researchers understand the principles of CSE and verify fundamental data structure algorithms in Gillian.", "AI": {"tldr": "The paper introduces a debugging interface for compositional symbolic execution (CSE) tools, integrated with Visual Studio Code, aiming for better visualization and understanding of CSE behaviors, and evaluates it via a user study.", "motivation": "The motivation stems from the difficulty specialist users face in debugging the outputs of CSE tools despite their increasing prominence and application in real-world settings.", "method": "The authors designed a debugging interface integrated with VS Code and the Gillian CSE platform, focusing on visualization, intuitive representation, interactivity, and making it tool-agnostic.", "result": "The interface was found useful in helping early researchers comprehend CSE principles and verify data structure algorithms, as demonstrated by an empirical user study.", "conclusion": "The debugger enhances the accessibility and understanding of CSE, suggesting potential for future use and adaptation across other symbolic analysis tools."}}
{"id": "2602.07080", "pdf": "https://arxiv.org/pdf/2602.07080", "abs": "https://arxiv.org/abs/2602.07080", "authors": ["Yicheng He", "Zheng Zhao", "Zhou Kaiyu", "Bryan Dai", "Jie Fu", "Yonghui Yang"], "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability, we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs. By decomposing complex residual flows, we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.", "AI": {"tldr": "This paper explores the internal computational signals of large language models (LLMs) for assessing functional correctness in code generation, bypassing external judging mechanisms.", "motivation": "The motivation is to reduce reliance on labor-intensive external tools for code verification and explore whether LLMs internally encode signals predictive of logical validity.", "method": "The authors use mechanistic interpretability to analyze the internal neural dynamics of LLMs and map algorithmic trajectories into line-level attribution graphs. They identify distinguishable structural signatures and decompose residual flows to examine logical validity.", "result": "The intrinsic correctness signals of LLMs prove robust across Python, C++, and Java syntaxes. Topological features from the internal attribution graphs outperform surface heuristics in predicting code correctness and enable causal interventions.", "conclusion": "Internal introspection is shown to be a reliable, decodable property for verifying code generated by LLMs, offering an efficient alternative to external verification mechanisms."}}
{"id": "2602.06969", "pdf": "https://arxiv.org/pdf/2602.06969", "abs": "https://arxiv.org/abs/2602.06969", "authors": ["Roshan Kumar Chhetri", "Sarocha Jetawatthana", "Thanakorn Khamvilai"], "title": "A Survey of Medical Drones from Flight Dynamics, Guidance, Navigation, and Control Perspectives", "categories": ["cs.RO"], "comment": null, "summary": "The integration of drones into the medical field has revolutionized healthcare delivery by enabling rapid transportation of medical supplies, organs, and even emergency assistance in remote or disaster-stricken areas. While other survey papers focus on the healthcare supply chain, operations, and medical emergency response aspects, this paper provides a comprehensive review of medical drones from the perspectives of flight dynamics and guidance, navigation, and control (GNC) systems. We first discuss the medical aerial delivery mission requirements and suitable uncrewed aerial system (UAS) configurations. We then address payload container design and optimization, and its effect on supplies and overall flight dynamics. We also explore the fundamental principles of GNC in the context of medical drone operations, highlighting key challenges arising from vibration, air temperature, pressure, and humidity, which affect the quality of medical supplies. The paper examines various GNC algorithms that can mitigate these challenges, as well as the algorithms' limitations. With these considerations, this survey aims to provide insights into optimizing GNC frameworks for medical drones, emphasizing research gaps and directions to improve real-world healthcare applications.", "AI": {"tldr": "This paper reviews the use of drones in healthcare, focusing on flight dynamics, guidance, navigation, and control (GNC) systems, as well as their challenges and optimization.", "motivation": "To address the technological challenges of drones in healthcare delivery and improve their performance in environmental and logistical conditions.", "method": "The paper reviews medical drone configurations, payload design, and GNC frameworks, highlighting challenges such as vibration, temperature, and humidity, and examines algorithms to mitigate these issues.", "result": "Identified GNC-related challenges in medical drone operations and reviewed existing algorithms for potential improvements.", "conclusion": "The study outlines research gaps and provides recommendations to optimize GNC systems for medical drones' effective application in healthcare."}}
{"id": "2602.07120", "pdf": "https://arxiv.org/pdf/2602.07120", "abs": "https://arxiv.org/abs/2602.07120", "authors": ["Jacqueline He", "Jonathan Hayase", "Wen-tau Yih", "Sewoong Oh", "Luke Zettlemoyer", "Pang Wei Koh"], "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model", "categories": ["cs.CL"], "comment": "51 pages, 12 figures, 16 tables. Code is publicly available at https://github.com/jacqueline-he/anchored-decoding", "summary": "Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.", "AI": {"tldr": "The paper introduces Anchored Decoding, a method to prevent sensitive or copyright-violating verbatim copying in language model outputs by constraining risky models' generations near a safe, permissively trained model.", "motivation": "To address the issue of verbatim copying from sensitive or copyrighted training data in language models, which creates legal and ethical concerns.", "method": "The authors propose Anchored Decoding, a plug-and-play inference-time technique that suppresses verbatim copying by adapting generation to a nearby safe language model trained on permissive data, ensuring customizable constraints and generating safe outputs.", "result": "Anchored Decoding achieves up to a 75% reduction in measurable copying while maintaining fluency and factuality on long-form text evaluations, with only a modest increase in computational overhead.", "conclusion": "Anchored Decoding offers a practical and tunable approach to balance compliance and utility for language model outputs, defining a new standard for reducing copying risks in AI systems."}}
{"id": "2602.07012", "pdf": "https://arxiv.org/pdf/2602.07012", "abs": "https://arxiv.org/abs/2602.07012", "authors": ["Zhonghua Wang", "Lie Ju", "Sijia Li", "Wei Feng", "Sijin Zhou", "Ming Hu", "Jianhao Xiong", "Xiaoying Tang", "Yifan Peng", "Mingquan Lin", "Yaodong Ding", "Yong Zeng", "Wenbin Wei", "Li Dong", "Zongyuan Ge"], "title": "A General Model for Retinal Segmentation and Quantification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Retinal imaging is fast, non-invasive, and widely available, offering quantifiable structural and vascular signals for ophthalmic and systemic health assessment. This accessibility creates an opportunity to study how quantitative retinal phenotypes relate to ocular and systemic diseases. However, such analyses remain difficult at scale due to the limited availability of public multi-label datasets and the lack of a unified segmentation-to-quantification pipeline. We present RetSAM, a general retinal segmentation and quantification framework for fundus imaging. It delivers robust multi-target segmentation and standardized biomarker extraction, supporting downstream ophthalmologic studies and oculomics correlation analyses. Trained on over 200,000 fundus images, RetSAM supports three task categories and segments five anatomical structures, four retinal phenotypic patterns, and more than 20 distinct lesion types. It converts these segmentation results into over 30 standardized biomarkers that capture structural morphology, vascular geometry, and degenerative changes. Trained with a multi-stage strategy using both private and public fundus data, RetSAM achieves superior segmentation performance on 17 public datasets. It improves on prior best methods by 3.9 percentage points in DSC on average, with up to 15 percentage points on challenging multi-task benchmarks, and generalizes well across diverse populations, imaging devices, and clinical settings. The resulting biomarkers enable systematic correlation analyses across major ophthalmic diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma, and pathologic myopia. Together, RetSAM transforms fundus images into standardized, interpretable quantitative phenotypes, enabling large-scale ophthalmic research and translation.", "AI": {"tldr": "RetSAM is a retinal segmentation and quantification framework that converts fundus images into standardized biomarkers for large-scale ophthalmic research and disease correlation analyses.", "motivation": "The study aims to address the lack of public multi-label datasets and unified segmentation-to-quantification pipelines in retinal imaging, limiting scalable analyses of quantitative retinal phenotypes in ocular and systemic diseases.", "method": "The authors developed RetSAM, a framework trained on over 200,000 fundus images with a multi-stage strategy. It performs multi-target segmentation of anatomical structures, retinal phenotypic patterns, and lesion types, translating segmentation results into over 30 biomarkers.", "result": "RetSAM demonstrated superior performance on 17 public datasets, improving segmentation accuracy by an average of 3.9% DSC compared to prior techniques, with significant gains in challenging scenarios. It generalized well across diverse populations and clinical setups.", "conclusion": "RetSAM standardizes retinal phenotyping through robust segmentation and biomarker extraction, facilitating large-scale research and contributing to deeper understanding of ophthalmic diseases."}}
{"id": "2602.07633", "pdf": "https://arxiv.org/pdf/2602.07633", "abs": "https://arxiv.org/abs/2602.07633", "authors": ["Trevor Harris"], "title": "Flow-Based Conformal Predictive Distributions", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "9 pages, 6 figures, 10 appendix pages", "summary": "Conformal prediction provides a distribution-free framework for uncertainty quantification via prediction sets with exact finite-sample coverage. In low dimensions these sets are easy to interpret, but in high-dimensional or structured output spaces they are difficult to represent and use, which can limit their ability to integrate with downstream tasks such as sampling and probabilistic forecasting. We show that any differentiable nonconformity score induces a deterministic flow on the output space whose trajectories converge to the boundary of the corresponding conformal prediction set. This leads to a computationally efficient, training-free method for sampling conformal boundaries in arbitrary dimensions. Boundary samples can be reconformalized to form pointwise prediction sets with controlled risk, and mixing across confidence levels yields conformal predictive distributions whose quantile regions coincide exactly with conformal prediction sets. We evaluate the approach on PDE inverse problems, precipitation downscaling, climate model debiasing, and hurricane trajectory forecasting.", "AI": {"tldr": "This paper introduces a computational method to sample boundaries of high-dimensional conformal prediction sets, offering improved interpretability and usability for downstream tasks.", "motivation": "The challenge of interpreting and utilizing conformal prediction sets in high-dimensional or structured output spaces limits their integration with tasks like sampling and probabilistic forecasting.", "method": "The authors propose using a differentiable nonconformity score to create deterministic flows on the output space, converging to the boundaries of conformal prediction sets. They also derive methods for efficient sampling and reconformalization in high dimensions.", "result": "Effective application of the approach was demonstrated on problems including PDE inverse solving, climate model debiasing, and hurricane forecasting, showcasing performance and utility.", "conclusion": "The method enhances the usability of high-dimensional conformal prediction sets, enabling improved integration into practical tasks like probabilistic forecasting and uncertainty quantification."}}
{"id": "2602.07040", "pdf": "https://arxiv.org/pdf/2602.07040", "abs": "https://arxiv.org/abs/2602.07040", "authors": ["Emmett Bicker"], "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods", "categories": ["cs.AI"], "comment": "Available at www.asterlab.ai, 25 pages, 8 figures, 4 tables", "summary": "We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs.\n  We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute.\n  Aster is accessible via a web interface and API at asterlab.ai.", "AI": {"tldr": "The paper introduces Aster, an AI agent that efficiently achieves state-of-the-art results in multiple fields by optimizing programs through iterative improvements, reducing computational iterations significantly.", "motivation": "To create an AI system capable of drastically reducing the computational effort and iteration cycles needed for scientific discovery and achieving state-of-the-art results across diverse domains.", "method": "Aster employs iterative program optimization based on task-specific guidance, an initial program, and an evaluation script. It improves computational efficiency, making previously intractable problems solvable within reasonable timeframes.", "result": "Aster demonstrated state-of-the-art (SOTA) results in diverse fields, such as mathematics, GPU kernel engineering, biology, neuroscience, and language modeling, showing its broad adaptability and high computational efficiency.", "conclusion": "Aster represents a breakthrough in autonomous scientific discovery, enabling faster and more efficient performance across various complex tasks with widespread applicability."}}
{"id": "2602.07033", "pdf": "https://arxiv.org/pdf/2602.07033", "abs": "https://arxiv.org/abs/2602.07033", "authors": ["Md Shahriar Kabir", "Sana Alamgeer", "Minakshi Debnath", "Anne H. H. Ngu"], "title": "TransConv-DDPM: Enhanced Diffusion Model for Generating Time-Series Data in Healthcare", "categories": ["cs.LG"], "comment": "Previously published at IEEE COMPSAC 2025", "summary": "The lack of real-world data in clinical fields poses a major obstacle in training effective AI models for diagnostic and preventive tools in medicine. Generative AI has shown promise in increasing data volume and enhancing model training, particularly in computer vision and natural language processing (NLP) domains. However, generating physiological time-series data, a common type in medical AI applications, presents unique challenges due to its inherent complexity and variability. This paper introduces TransConv-DDPM, an enhanced generative AI method for biomechanical and physiological time-series data generation. The model employs a denoising diffusion probabilistic model (DDPM) with U-Net, multi-scale convolution modules, and a transformer layer to capture both global and local temporal dependencies. We evaluated TransConv-DDPM on three diverse datasets, generating both long and short-sequence time-series data. Quantitative comparisons against state-of-the-art methods, TimeGAN and Diffusion-TS, using four performance metrics, demonstrated promising results, particularly on the SmartFallMM and EEG datasets, where it effectively captured the more gradual temporal change patterns between data points. Additionally, a utility test on the SmartFallMM dataset revealed that adding synthetic fall data generated by TransConv-DDPM improved predictive model performance, showing a 13.64% improvement in F1-score and a 14.93% increase in overall accuracy compared to the baseline model trained solely on fall data from the SmartFallMM dataset. These findings highlight the potential of TransConv-DDPM to generate high-quality synthetic data for real-world applications.", "AI": {"tldr": "TransConv-DDPM is a generative AI method introduced to address the issue of limited real-world physiological time-series data in medical AI applications, using advanced mechanisms to capture temporal dependencies.", "motivation": "The study aims to overcome the problem of insufficient real-world data in clinical fields, which limits the training of effective AI models for medical diagnostics and prevention.", "method": "The TransConv-DDPM utilizes a denoising diffusion probabilistic model (DDPM) with U-Net architecture, multi-scale convolution modules, and a transformer layer to enhance the generation of biomechanical and physiological time-series data.", "result": "Quantitative tests show that TransConv-DDPM outperforms existing methods like TimeGAN and Diffusion-TS, especially in datasets with gradual temporal changes, and improves model metrics like F1-score and accuracy when synthetic data is added.", "conclusion": "TransConv-DDPM successfully generates high-quality synthetic time-series data, proving its utility in enhancing medical AI applications and predictive model performance."}}
{"id": "2602.07547", "pdf": "https://arxiv.org/pdf/2602.07547", "abs": "https://arxiv.org/abs/2602.07547", "authors": ["Subba Reddy Oota", "Vijay Rowtula", "Satya Sai Srinath Namburi", "Khushbu Pahwa", "Anant Khandelwal", "Manish Gupta", "Tanmoy Chakraborty", "Bapi S. Raju"], "title": "Linguistic properties and model scale in brain encoding: from small to compressed language models", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.LG"], "comment": "40 pages, 33 figures", "summary": "Recent work has shown that scaling large language models (LLMs) improves their alignment with human brain activity, yet it remains unclear what drives these gains and which representational properties are responsible. Although larger models often yield better task performance and brain alignment, they are increasingly difficult to analyze mechanistically. This raises a fundamental question: what is the minimal model capacity required to capture brain-relevant representations? To address this question, we systematically investigate how constraining model scale and numerical precision affects brain alignment. We compare full-precision LLMs, small language models (SLMs), and compressed variants (quantized and pruned) by predicting fMRI responses during naturalistic language comprehension. Across model families up to 14B parameters, we find that 3B SLMs achieve brain predictivity indistinguishable from larger LLMs, whereas 1B models degrade substantially, particularly in semantic language regions. Brain alignment is remarkably robust to compression: most quantization and pruning methods preserve neural predictivity, with GPTQ as a consistent exception. Linguistic probing reveals a dissociation between task performance and brain predictivity: compression degrades discourse, syntax, and morphology, yet brain predictivity remains largely unchanged. Overall, brain alignment saturates at modest model scales and is resilient to compression, challenging common assumptions about neural scaling and motivating compact models for brain-aligned language modeling.", "AI": {"tldr": "Scaling large language models enhances alignment with human brain activity, but minimal capacity models show comparable predictivity. Compression has little effect on neural alignment.", "motivation": "To understand the minimal model capacity required for achieving brain alignment during natural language comprehension, while addressing representational properties and robustness to compression.", "method": "Examining brain alignment by comparing fMRI responses using full-precision large language models, small language models, and compressed variants (quantized and pruned).", "result": "Models with up to 3 billion parameters match brain predictivity of larger models, while 1 billion parameter models show reduced performance. Compression preserves neural predictivity largely without degrading brain alignment.", "conclusion": "Brain alignment saturates at modest model scales and is unaffected by compression, supporting the use of compact models for brain-aligned language modeling."}}
{"id": "2602.07483", "pdf": "https://arxiv.org/pdf/2602.07483", "abs": "https://arxiv.org/abs/2602.07483", "authors": ["Kuan-Cheng Chen", "Hiromichi Matsuyama", "Wei-hao Huang", "Yu Yamashiro"], "title": "Recursive QAOA for Interference-Aware Resource Allocation in Wireless Networks", "categories": ["quant-ph", "cs.DC"], "comment": null, "summary": "Discrete radio resource management problems in dense wireless networks are naturally cast as quadratic unconstrained binary optimization (QUBO) programs but are difficult to solve at scale. We investigate a quantum-classical approach based on the Recursive Quantum Approximate Optimization Algorithm (RQAOA), which interleaves shallow QAOA layers with variable elimination guided by measured single- and two-qubit correlators. For interference-aware channel assignment, we give a compact QUBO/Ising formulation in which pairwise interference induces same-channel couplings and one-hot constraints are enforced via quadratic penalties (or, optionally, constraint-preserving mixers). Within RQAOA, fixing high-confidence variables or relations reduces the problem dimension, stabilizes training, and concentrates measurement effort on a shrinking instance that is solved exactly once below a cutoff. On simulated instances of modest size, including a four-user, four-channel example, the method consistently returns feasible assignments and, for the demonstrated case, attains the global optimum. These results indicate that recursion can mitigate parameter growth and feasibility issues that affect plain QAOA, and suggest a viable pathway for near-term quantum heuristics in wireless resource allocation.", "AI": {"tldr": "The paper addresses the challenge of solving dense wireless networks' resource management problems by proposing a hybrid quantum-classical algorithm (RQAOA), producing promising results in achieving feasible and optimal solutions.", "motivation": "The motivation is to solve discrete radio resource management problems efficiently in dense wireless networks, which are naturally formulated as QUBO problems but challenging at scale.", "method": "The method involves the Recursive Quantum Approximate Optimization Algorithm (RQAOA), which uses shallow QAOA layers, variable elimination, and compact QUBO/Ising formulations to reduce problem dimensions and stabilize computation.", "result": "RQAOA was tested on modest-sized, simulated instances (e.g., a four-user, four-channel case) and consistently returned feasible assignments, attaining the global optimum in the demonstrated test.", "conclusion": "The study shows that recursive techniques in quantum algorithms can reduce complexity and feasibility issues, offering a viable route for implementing near-term quantum heuristics in wireless resource management."}}
{"id": "2602.07518", "pdf": "https://arxiv.org/pdf/2602.07518", "abs": "https://arxiv.org/abs/2602.07518", "authors": ["Manuel Escudero", "Mohamadreza Zolfagharinejad", "Sjoerd van den Belt", "Nikolaos Alachiotis", "Wilfred G. van der Wiel"], "title": "Physical Analog Kolmogorov-Arnold Networks based on Reconfigurable Nonlinear-Processing Units", "categories": ["cs.ET", "cs.AR", "cs.LG", "nlin.AO"], "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) shift neural computation from linear layers to learnable nonlinear edge functions, but implementing these nonlinearities efficiently in hardware remains an open challenge. Here we introduce a physical analog KAN architecture in which edge functions are realized in materia using reconfigurable nonlinear-processing units (RNPUs): multi-terminal nanoscale silicon devices whose input-output characteristics are tuned via control voltages. By combining multiple RNPUs into an edge processor and assembling these blocks into a reconfigurable analog KAN (aKAN) architecture with integrated mixed-signal interfacing, we establish a realistic system-level hardware implementation that enables compact KAN-style regression and classification with programmable nonlinear transformations. Using experimentally calibrated RNPU models and hardware measurements, we demonstrate accurate function approximation across increasing task complexity while requiring fewer or comparable trainable parameters than multilayer perceptrons (MLPs). System-level estimates indicate an energy per inference of $\\sim$250 pJ and an end-to-end inference latency of $\\sim$600 ns for a representative workload, corresponding to a $\\sim$10$^{2}$-10$^{3}\\times$ reduction in energy accompanied by a $\\sim$10$\\times$ reduction in area compared to a digital fixed-point MLP at similar approximation error. These results establish RNPUs as scalable, hardware-native nonlinear computing primitives and identify analog KAN architectures as a realistic silicon-based pathway toward energy-, latency-, and footprint-efficient analog neural-network hardware, particularly for edge inference.", "AI": {"tldr": "The paper introduces a hardware-efficient implementation of Kolmogorov-Arnold Networks using reconfigurable nanoscale silicon devices for nonlinear processing.", "motivation": "To address the challenge of efficiently implementing nonlinearities in Kolmogorov-Arnold Networks within hardware systems.", "method": "Physical analog KAN is realized using reconfigurable nonlinear-processing units (RNPUs) as hardware primitives for nonlinear computation, supported by integrated mixed-signal interfacing.", "result": "Demonstrated accurate function approximation with fewer parameters than MLPs and achieved significant reductions in energy consumption, latency, and footprint in hardware comparisons.", "conclusion": "RNPUs and analog KAN architectures are scalable and viable for efficient neural-network hardware, especially for energy-critical edge inference applications."}}
{"id": "2602.07037", "pdf": "https://arxiv.org/pdf/2602.07037", "abs": "https://arxiv.org/abs/2602.07037", "authors": ["Huannan Zheng", "Jingli Liu", "Kezhou Yang"], "title": "Stochastic Spiking Neuron Based SNN Can be Inherently Bayesian", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.ET"], "comment": null, "summary": "Uncertainty in biological neural systems appears to be computationally beneficial rather than detrimental. However, in neuromorphic computing systems, device variability often limits performance, including accuracy and efficiency. In this work, we propose a spiking Bayesian neural network (SBNN) framework that unifies the dynamic models of intrinsic device stochasticity (based on Magnetic Tunnel Junctions) and stochastic threshold neurons to leverage noise as a functional Bayesian resource. Experiments demonstrate that SBNN achieves high accuracy (99.16% on MNIST, 94.84% on CIFAR10) with 8-bit precision. Meanwhile rate estimation method provides a ~20-fold training speedup. Furthermore, SBNN exhibits superior robustness, showing a 67% accuracy improvement under synaptic weight noise and 12% under input noise compared to standard spiking neural networks. Crucially, hardware validation confirms that physical device implementation causes invisible accuracy and calibration loss compared to the algorithmic model. Converting device stochasticity into neuronal uncertainty offers a route to compact, energy-efficient neuromorphic computing under uncertainty.", "AI": {"tldr": "This paper introduces a spiking Bayesian neural network (SBNN) framework, leveraging device stochasticity for computational benefit in neuromorphic systems, improving accuracy, speed, and robustness.", "motivation": "Neuromorphic systems often struggle with device variability, which limits their computational efficiency and accuracy. This research aims to explore how inherent uncertainties or noise could be leveraged as beneficial computational resources.", "method": "The authors propose the SBNN framework utilizing device stochasticity in Magnetic Tunnel Junctions and stochastic threshold neurons to model Bayesian uncertainty. They also employ a rate estimation training method for efficiency enhancement.", "result": "Experiments show SBNN achieves high classification accuracy on benchmarks (99.16% MNIST, 94.84% CIFAR10) with 8-bit precision, offers a 20-fold training speedup, and outperforms standard neural networks in robustness under noise.", "conclusion": "The study validates that leveraging device stochasticity effectively for neuronal uncertainty can result in compact, energy-efficient neuromorphic systems with minimal hardware accuracy loss and superior performance under uncertainty."}}
{"id": "2602.07083", "pdf": "https://arxiv.org/pdf/2602.07083", "abs": "https://arxiv.org/abs/2602.07083", "authors": ["Yongqing Jiang", "Jianze Wang", "Zhiqi Shen", "Zhenghong Lin", "Jiayuan Wang", "Yijian Yang", "Kaoshan Dai", "Haoran Luo"], "title": "Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at https://github.com/Jovanqing/AutoBM.", "AI": {"tldr": "This paper proposes a framework for automatic generation of physics-consistent building modeling using large language models, with improved constraints compliance and verification metrics.", "motivation": "To address the issue of non-executable or physically inconsistent outputs of large language models in structural modeling under stringent engineering constraints.", "method": "The framework integrates domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. It introduces a domain-specific dataset (CivilInstruct) and employs a two-stage fine-tuning strategy to enforce constraint satisfaction and API compliance.", "result": "The results demonstrate consistent improvements over baselines in executability and structural dynamics consistency metrics, evaluated through a new benchmark (MBEval).", "conclusion": "The proposed framework demonstrates the potential of LLMs in generating simulation-ready engineering models by ensuring physical consistency and compliance, significantly advancing automatic building modeling."}}
{"id": "2602.06971", "pdf": "https://arxiv.org/pdf/2602.06971", "abs": "https://arxiv.org/abs/2602.06971", "authors": ["Anastasios Manganaris", "Vittorio Giammarino", "Ahmed H. Qureshi", "Suresh Jagannathan"], "title": "Formal Methods in Robot Policy Learning and Verification: A Survey on Current Techniques and Future Directions", "categories": ["cs.RO"], "comment": "19 Pages. 6 Figures. Published in Transactions on Machine Learning Research", "summary": "As hardware and software systems have grown in complexity, formal methods have been indispensable tools for rigorously specifying acceptable behaviors, synthesizing programs to meet these specifications, and validating the correctness of existing programs. In the field of robotics, a similar trend of rising complexity has emerged, driven in large part by the adoption of deep learning. While this shift has enabled the development of highly performant robot policies, their implementation as deep neural networks has posed challenges to traditional formal analysis, leading to models that are inflexible, fragile, and difficult to interpret. In response, the robotics community has introduced new formal and semi-formal methods to support the precise specification of complex objectives, guide the learning process to achieve them, and enable the verification of learned policies against them. In this survey, we provide a comprehensive overview of how formal methods have been used in recent robot learning research. We organize our discussion around two pillars: policy learning and policy verification. For both, we highlight representative techniques, compare their scalability and expressiveness, and summarize how they contribute to meaningfully improving realistic robot safety and correctness. We conclude with a discussion of remaining obstacles for achieving that goal and promising directions for advancing formal methods in robot learning.", "AI": {"tldr": "The paper surveys the usage of formal methods in addressing challenges posed by the growing complexity of robotic systems, primarily driven by deep learning models.", "motivation": "The growing complexity of robotics due to deep learning necessitates precise formal methods to address issues such as inflexibility, fragility, and interpretability of robotic policies.", "method": "The authors conduct a survey focused on recent applications of formal methods in robot learning research, organized around policy learning and policy verification.", "result": "The discussion highlights techniques improving robot safety and correctness, comparing their scalability, expressiveness, and contributions to the field.", "conclusion": "The paper identifies remaining challenges and promising directions for advancing formal methods' application in robot learning."}}
{"id": "2602.07160", "pdf": "https://arxiv.org/pdf/2602.07160", "abs": "https://arxiv.org/abs/2602.07160", "authors": ["Jiecheng Lu", "Shihao Yang"], "title": "Free Energy Mixer", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": "Camera-ready version. Accepted at ICLR 2026", "summary": "Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.", "AI": {"tldr": "The paper presents the Free Energy Mixer (FEM), which improves standard attention by enabling value-aware, per-channel selection without increasing complexity.", "motivation": "To overcome the limitation of standard attention mechanisms that only allow for convex averaging of keys/values, preventing fine-grained channel-wise selection.", "method": "FEM introduces a free-energy (log-sum-exp) mechanism for reading values, applying value-driven log-linear adjustments to an existing prior derived from queries/keys. It operates at unchanged asymptotic complexity.", "result": "FEM outperforms strong baselines in NLP, vision, and time-series tasks while maintaining parameter budgets and compatibility with attention models and variants.", "conclusion": "FEM enables more flexible, value-aware attention mechanisms with improved performance and complexity-preserving design."}}
{"id": "2602.07013", "pdf": "https://arxiv.org/pdf/2602.07013", "abs": "https://arxiv.org/abs/2602.07013", "authors": ["Jiaxi Yang", "Shicheng Liu", "Yuchen Yang", "Dongwon Lee"], "title": "Steering to Say No: Configurable Refusal via Activation Steering in Vision Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "With the rapid advancement of Vision Language Models (VLMs), refusal mechanisms have become a critical component for ensuring responsible and safe model behavior. However, existing refusal strategies are largely \\textit{one-size-fits-all} and fail to adapt to diverse user needs and contextual constraints, leading to either under-refusal or over-refusal. In this work, we firstly explore the challenges mentioned above and develop \\textbf{C}onfigurable \\textbf{R}efusal in \\textbf{VLM}s (\\textbf{CR-VLM}), a robust and efficient approach for {\\em configurable} refusal based on activation steering. CR-VLM consists of three integrated components: (1) extracting a configurable refusal vector via a teacher-forced mechanism to amplify the refusal signal; (2) introducing a gating mechanism that mitigates over-refusal by preserving acceptance for in-scope queries; and (3) designing a counterfactual vision enhancement module that aligns visual representations with refusal requirements. Comprehensive experiments across multiple datasets and various VLMs demonstrate that CR-VLM achieves effective, efficient, and robust configurable refusals, offering a scalable path toward user-adaptive safety alignment in VLMs.", "AI": {"tldr": "This study introduces CR-VLM, an approach for configurable refusal responses in Vision Language Models (VLMs) to adapt to user needs while mitigating over- and under-refusals.", "motivation": "Current refusal mechanisms in VLMs often adopt a one-size-fits-all approach, leading to suboptimal behavior by either over-refusing or under-refusing in diverse contexts and user settings.", "method": "The paper proposes CR-VLM, which involves: 1) extracting a refusal vector via a teacher-forced system, 2) implementing a gating mechanism to balance refusal and acceptance, and 3) incorporating a counterfactual vision enhancement to align visual data with refusal criteria.", "result": "Experiments across multiple datasets and VLMs show that CR-VLM offers robust, efficient, and adaptable refusal behavior.", "conclusion": "CR-VLM presents a scalable and effective solution for configurable refusal in VLMs, substantially improving safety and adaptability to user requirements."}}
{"id": "2602.07710", "pdf": "https://arxiv.org/pdf/2602.07710", "abs": "https://arxiv.org/abs/2602.07710", "authors": ["Jiaxun Li", "Vinod Raman", "Ambuj Tewari"], "title": "On Generation in Metric Spaces", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study generation in separable metric instance spaces. We extend the language generation framework from Kleinberg and Mullainathan [2024] beyond countable domains by defining novelty through metric separation and allowing asymmetric novelty parameters for the adversary and the generator. We introduce the $(\\varepsilon,\\varepsilon')$-closure dimension, a scale-sensitive analogue of closure dimension, which yields characterizations of uniform and non-uniform generatability and a sufficient condition for generation in the limit. Along the way, we identify a sharp geometric contrast. Namely, in doubling spaces, including all finite-dimensional normed spaces, generatability is stable across novelty scales and invariant under equivalent metrics. In general metric spaces, however, generatability can be highly scale-sensitive and metric-dependent; even in the natural infinite-dimensional Hilbert space $\\ell^2$, all notions of generation may fail abruptly as the novelty parameters vary.", "AI": {"tldr": "This paper extends language generation in separable metric instance spaces by introducing the $(\\varepsilon,\\varepsilon')$-closure dimension, providing insights on generatability in different metric conditions.", "motivation": "The motivation is to expand on the language generation framework to account for separable metric spaces, addressing the limitations of countable domains and exploring the impact of different metrics and novelty parameters on generatability.", "method": "The authors use the concept of metric separation and introduce the $(\\varepsilon,\\varepsilon')$-closure dimension to characterize and analyze generatability in uniform, non-uniform, and limiting conditions across metric spaces.", "result": "The findings reveal stable generatability in doubling spaces while showing that in general metric spaces (e.g., infinite-dimensional Hilbert spaces), generatability is highly sensitive to changes in novelty parameters and metrics.", "conclusion": "Generatability is determined by the interplay of metric conditions and novelty parameters, offering methods to assess and predict generation stability across uniform and non-uniform spaces."}}
{"id": "2602.07055", "pdf": "https://arxiv.org/pdf/2602.07055", "abs": "https://arxiv.org/abs/2602.07055", "authors": ["Pingyue Zhang", "Zihan Huang", "Yue Wang", "Jieyu Zhang", "Letian Xue", "Zihan Wang", "Qineng Wang", "Keshigeyan Chandrasegaran", "Ruohan Zhang", "Yejin Choi", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "published at iclr 2026", "summary": "Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration.", "AI": {"tldr": "The paper explores spatial embodied intelligence, focusing on how agents acquire and maintain spatial knowledge through active exploration. It identifies significant gaps and inefficiencies in current foundation models.", "motivation": "The motivation is to investigate the underexplored area of active, self-directed exploration in multimodal foundation models, aiming to improve spatial embodied intelligence.", "method": "The authors propose a benchmark to evaluate agent performance in curiosity-driven exploration for building cognitive maps. A novel spatial belief probing method is used to monitor internal spatial representations.", "result": "Findings reveal critical challenges like the Active-Passive Gap, inefficiency in exploration, instability in spatial beliefs, and the issue of Belief Inertia. Vision-based models are particularly affected.", "conclusion": "Current foundation models exhibit limitations in coherently constructing and maintaining spatial beliefs during active exploration, requiring novel strategies for improvement."}}
{"id": "2602.07054", "pdf": "https://arxiv.org/pdf/2602.07054", "abs": "https://arxiv.org/abs/2602.07054", "authors": ["Ashutosh Chaubey", "Jiacheng Pang", "Maksim Siniukov", "Mohammad Soleymani"], "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization", "categories": ["cs.LG", "cs.CV", "cs.HC"], "comment": "Accepted as a conference paper at ICLR 2026. Project page: https://avere-iclr.github.io", "summary": "Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models have shown strong performance on this task, two key challenges remain - spurious associations between emotions and irrelevant audiovisual cues, and hallucinations of audiovisual cues driven by text priors in the language model backbone. To quantify and understand these issues, we introduce EmoReAlM, a benchmark designed to evaluate MLLMs for cue-emotion associations, hallucinations and modality agreement. We then propose AVEm-DPO, a preference optimization technique that aligns model responses with both audiovisual inputs and emotion-centric queries. Specifically, we construct preferences over responses exhibiting spurious associations or hallucinations, and audiovisual input pairs guided by textual prompts. We also include a regularization term that penalizes reliance on text priors, thereby mitigating modality-specific cue hallucinations. Experimental results on DFEW, RAVDESS and EMER demonstrate that our method significantly improves the performance of the reference baseline models with 6-19% of relative performance gains in zero-shot settings. By providing both a rigorous benchmark and a robust optimization framework, this work enables principled evaluation and improvement of MLLMs for emotion understanding and social AI. Code, models and benchmark will be released at https://avere-iclr.github.io.", "AI": {"tldr": "The paper introduces EmoReAlM, a benchmark for emotion understanding in MLLMs, and proposes AVEm-DPO, a method to optimize responses to address spurious associations, hallucinations, and improve modality-specific alignment.", "motivation": "The motivation is to tackle challenges in multimodal large language models (MLLMs) related to spurious associations between emotions and audiovisual cues, as well as hallucinations driven by text priors in language models.", "method": "The method involves creating a benchmark (EmoReAlM) for evaluation and proposing AVEm-DPO, a preference optimization technique with regularization to reduce dependence on text priors and improve audiovisual input alignment.", "result": "Experimental results on datasets (DFEW, RAVDESS, EMER) show 6-19% performance gains in zero-shot settings compared to baseline models.", "conclusion": "The work provides tools and techniques to rigorously evaluate and enhance emotion understanding in social AI. Code and resources will be openly released."}}
{"id": "2602.07570", "pdf": "https://arxiv.org/pdf/2602.07570", "abs": "https://arxiv.org/abs/2602.07570", "authors": ["Prachi Jindal", "Anant Khandelwal", "Manish Gupta", "Bapi S. Raju", "Subba Reddy Oota", "Tanmoy Chakraborty"], "title": "How does longer temporal context enhance multimodal narrative video processing in the brain?", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "cs.LG"], "comment": "22 pages, 15 figures", "summary": "Understanding how humans and artificial intelligence systems process complex narrative videos is a fundamental challenge at the intersection of neuroscience and machine learning. This study investigates how the temporal context length of video clips (3--12 s clips) and the narrative-task prompting shape brain-model alignment during naturalistic movie watching. Using fMRI recordings from participants viewing full-length movies, we examine how brain regions sensitive to narrative context dynamically represent information over varying timescales and how these neural patterns align with model-derived features. We find that increasing clip duration substantially improves brain alignment for multimodal large language models (MLLMs), whereas unimodal video models show little to no gain. Further, shorter temporal windows align with perceptual and early language regions, while longer windows preferentially align higher-order integrative regions, mirrored by a layer-to-cortex hierarchy in MLLMs. Finally, narrative-task prompts (multi-scene summary, narrative summary, character motivation, and event boundary detection) elicit task-specific, region-dependent brain alignment patterns and context-dependent shifts in clip-level tuning in higher-order regions. Together, our results position long-form narrative movies as a principled testbed for probing biologically relevant temporal integration and interpretable representations in long-context MLLMs.", "AI": {"tldr": "This paper explores how temporal context length and narrative-task prompts influence brain model alignment when humans watch movies, using fMRI data and multimodal large language models (MLLMs).", "motivation": "The study is motivated to understand how humans and AI models process complex narratives by examining temporal context and narrative-task effects on brain activity and computational model alignment.", "method": "Researchers used fMRI recordings from people watching full-length movies and evaluated varying temporal context (3-12 seconds) and task prompts. They analyzed brain-model alignment using multimodal and unimodal models.", "result": "The study found that MLLMs achieve better brain alignment with longer temporal contexts, while shorter contexts align with perceptual brain regions. Narrative-task prompts also show task-specific alignment to regions and shifts in neural tuning.", "conclusion": "Long-form narrative movies are effective tools for studying temporal integration in the brain and for understanding the interpretable representations in MLLMs with long-context capabilities."}}
{"id": "2602.07630", "pdf": "https://arxiv.org/pdf/2602.07630", "abs": "https://arxiv.org/abs/2602.07630", "authors": ["Taotao Wang", "Long Shi", "Fang Liu", "Qing Yang", "Shengli Zhang"], "title": "Wireless Streamlet: A Spectrum-Aware and Cognitive Consensus Protocol for Edge IoT", "categories": ["cs.IT", "cs.DC"], "comment": "15 pages, 14 figures and 4 tables", "summary": "Blockchain offers a decentralized trust framework for the Internet of Things (IoT), yet deploying consensus in spectrum-congested and dynamic wireless edge IoT networks faces fundamental obstacles: traditional BFT protocols are spectrum-ignorant, leading to inefficient resource utilization and fragile progress under time-varying interference. This paper presents \\textit{Wireless Streamlet}, a spectrum-aware and cognitive consensus protocol tailored for wireless edge IoT. Building on Streamlet's streamlined structure, we introduce a \\textit{Channel-Aware Leader Election (CALE)} mechanism. CALE serves as a verifiable cross-layer cognitive engine that leverages receiver-measured channel state information (CSI) piggybacked in signed votes to derive Byzantine-robust connectivity scores from notarization certificates, and deterministically selects a unique weighted leader per epoch from finalized history, thereby improving proposal dissemination reliability under deep fading. Complementing this cognitive adaptation, Wireless Streamlet exploits the single-hop broadcast medium and a deterministic TDMA voting schedule to achieve linear per-epoch on-air transmissions (slot complexity), ensuring deterministic spectral access. To address the communication-storage trade-off, we further propose a coded dual-chain architecture that decouples header-only consensus (State Chain) from payload data (Data Chain). By employing erasure coding and on-chain integrity commitments, the system minimizes redundant spectrum usage for data retrieval while ensuring availability. Experiments show that Wireless Streamlet achieves higher throughput and lower confirmation latency than representative baselines in lossy environments, while substantially reducing per-node storage, demonstrating the efficacy of integrating cognitive sensing into consensus logic.", "AI": {"tldr": "This paper introduces Wireless Streamlet, a spectrum-aware consensus protocol, to address inefficiencies and spectrum-related challenges in wireless edge IoT networks, outperforming traditional methods in terms of throughput and storage efficiency.", "motivation": "The motivation is to resolve inefficiencies of traditional BFT protocols in spectrum-congested and dynamic wireless edge IoT networks, where such protocols fail to leverage spectrum awareness, leading to resource underutilization and fragile operations under interference.", "method": "The paper introduces Wireless Streamlet, incorporating a novel Channel-Aware Leader Election (CALE) mechanism, cognitive spectrum sensing, a deterministic TDMA schedule, and a dual-chain architecture (State Chain and Data Chain) with erasure coding for enhanced efficiency and reliability.", "result": "Wireless Streamlet outperforms baseline methods by achieving higher throughput, lower confirmation latency, and reduced per-node storage under lossy environments, demonstrating better resource usage and reliability.", "conclusion": "Integrating cognitive sensing into consensus logic improves the performance and adaptability of blockchain-based IoT frameworks, making Wireless Streamlet an effective solution for dynamic and spectrum-limited wireless environments."}}
{"id": "2602.08190", "pdf": "https://arxiv.org/pdf/2602.08190", "abs": "https://arxiv.org/abs/2602.08190", "authors": ["Gwangoo Yeo", "Zhiyang Shen", "Wei Cui", "Matteo Interlandi", "Rathijit Sen", "Bailu Ding", "Qi Chen", "Minsoo Rhu"], "title": "ZipFlow: a Compiler-based Framework to Unleash Compressed Data Movement for Modern GPUs", "categories": ["cs.DB", "cs.AR", "cs.DC"], "comment": null, "summary": "In GPU-accelerated data analytics, the overhead of data transfer from CPU to GPU becomes a performance bottleneck when the data scales beyond GPU memory capacity due to the limited PCIe bandwidth. Data compression has come to rescue for reducing the amount of data transfer while taking advantage of the powerful GPU computation for decompression. To optimize the end-to-end query performance, however, the workflow of data compression, transfer, and decompression must be holistically designed based on the compression strategies and hardware characteristics to balance the I/O latency and computational overhead. In this work, we present ZipFlow, a compiler-based framework for optimizing compressed data transfer in GPU-accelerated data analytics. ZipFlow classifies compression algorithms into three distinct patterns based on their inherent parallelism. For each pattern, ZipFlow employs generalized scheduling strategies to effectively exploit the computational power of GPUs across diverse architectures. Building on these patterns, ZipFlow delivers flexible, high-performance, and holistic optimization, which substantially advances end-to-end data transfer capabilities. We evaluate the effectiveness of ZipFlow on industry-standard benchmark, TPC-H. Overall, ZipFlow achieves an average improvement of 2.08 times over the state-of-the-art GPU compression library (nvCOMP) and 3.14 times speedup against CPU-based query processing engines (e.g., DuckDB).", "AI": {"tldr": "This paper introduces ZipFlow, a framework optimizing data compression and transfer in GPU-accelerated analytics to reduce data transfer bottlenecks, achieving significant performance gains.", "motivation": "To address the performance bottleneck caused by the limited PCIe bandwidth in GPU-accelerated analytics when data surpasses GPU memory capacity.", "method": "ZipFlow, a compiler-based framework, is designed to optimize data compression, transfer, and decompression workflows. It classifies compression algorithms by parallelism patterns and employs generalized GPU scheduling strategies.", "result": "ZipFlow achieves an average performance improvement of 2.08x over NVIDIA's nvCOMP library and 3.14x compared to CPU-based engines such as DuckDB, as per TPC-H benchmarking.", "conclusion": "ZipFlow successfully provides a holistic optimization strategy, enhancing end-to-end data transfer for GPU-accelerated analytics by integrating compression strategies and hardware-specific features."}}
{"id": "2602.07059", "pdf": "https://arxiv.org/pdf/2602.07059", "abs": "https://arxiv.org/abs/2602.07059", "authors": ["Francesca Da Ros", "Tarik Za\u010diragi\u0107", "Aske Plaat", "Thomas B\u00e4ck", "Niki van Stein"], "title": "Assessing Reproducibility in Evolutionary Computation: A Case Study using Human- and LLM-based Assessment", "categories": ["cs.NE", "cs.AI", "cs.SE"], "comment": null, "summary": "Reproducibility is an important requirement in evolutionary computation, where results largely depend on computational experiments. In practice, reproducibility relies on how algorithms, experimental protocols, and artifacts are documented and shared. Despite growing awareness, there is still limited empirical evidence on the actual reproducibility levels of published work in the field. In this paper, we study the reproducibility practices in papers published in the Evolutionary Combinatorial Optimization and Metaheuristics track of the Genetic and Evolutionary Computation Conference over a ten-year period. We introduce a structured reproducibility checklist and apply it through a systematic manual assessment of the selected corpus. In addition, we propose RECAP (REproducibility Checklist Automation Pipeline), an LLM-based system that automatically evaluates reproducibility signals from paper text and associated code repositories. Our analysis shows that papers achieve an average completeness score of 0.62, and that 36.90% of them provide additional material beyond the manuscript itself. We demonstrate that automated assessment is feasible: RECAP achieves substantial agreement with human evaluators (Cohen's k of 0.67). Together, these results highlight persistent gaps in reproducibility reporting and suggest that automated tools can effectively support large-scale, systematic monitoring of reproducibility practices.", "AI": {"tldr": "The paper investigates reproducibility practices in evolutionary computation through a structured checklist and an automated tool, finding persistent gaps and showing potential for automation.", "motivation": "Reproducibility in evolutionary computation is crucial as results heavily depend on computational experiments, yet empirical data on reproducibility levels remain limited.", "method": "The study conducted a systematic manual assessment of 10 years of conference papers using a reproducibility checklist and developed RECAP, an automated LLM-based system for evaluating reproducibility signals.", "result": "The papers scored 0.62 on average for reproducibility completeness, with 36.90% including supplementary materials, and RECAP achieved substantial reliability, matching human evaluations with a Cohen's k of 0.67.", "conclusion": "Reproducibility in evolutionary computation requires improvement, as shown by gaps in reporting. Automated tools like RECAP can assist in enhancing reproducibility monitoring at scale."}}
{"id": "2602.07581", "pdf": "https://arxiv.org/pdf/2602.07581", "abs": "https://arxiv.org/abs/2602.07581", "authors": ["Thomas Beckers", "J\u00e1n Drgo\u0148a", "Truong X. Nghiem"], "title": "$\\partial$CBDs: Differentiable Causal Block Diagrams", "categories": ["eess.SY", "cs.LG", "cs.PL"], "comment": null, "summary": "Modern cyber-physical systems (CPS) integrate physics, computation, and learning, demanding modeling frameworks that are simultaneously composable, learnable, and verifiable. Yet existing approaches treat these goals in isolation: causal block diagrams (CBDs) support modular system interconnections but lack differentiability for learning; differentiable programming (DP) enables end-to-end gradient-based optimization but provides limited correctness guarantees; while contract-based verification frameworks remain largely disconnected from data-driven model refinement. To address these limitations, we introduce differentiable causal block diagrams ($\\partial$CBDs), a unifying formalism that integrates these three perspectives. Our approach (i) retains the compositional structure and execution semantics of CBDs, (ii) incorporates assume--guarantee (A--G) contracts for modular correctness reasoning, and (iii) introduces residual-based contracts as differentiable, trajectory-level certificates compatible with automatic differentiation (AD), enabling gradient-based optimization and learning. Together, these elements enable a scalable, verifiable, and trainable modeling pipeline that preserves causality and modularity while supporting data-, physics-, and constraint-informed optimization for CPS.", "AI": {"tldr": "This paper introduces Differentiable Causal Block Diagrams ($\\partial$CBDs) to unify learning, composability, and verification for Cyber-Physical Systems (CPS).", "motivation": "Current modeling frameworks for CPS fail to integrate compositional structure, learning capabilities, and correctness guarantees cohesively.", "method": "The authors propose $\\partial$CBDs, which integrate causal block diagrams with differentiability and assume--guarantee (A-G) contracts, enabling gradient-based optimization while ensuring correctness and modularity.", "result": "$\\partial$CBDs provide a framework that combines modular, verifiable, and learnable traits, enabling scalable modeling pipelines for CPS.", "conclusion": "The integration of $\\partial$CBDs ensures causal, modular, scalable, and verifiable modeling for CPS while promoting data-driven learning and optimization."}}
{"id": "2602.07086", "pdf": "https://arxiv.org/pdf/2602.07086", "abs": "https://arxiv.org/abs/2602.07086", "authors": ["Michael Marketsm\u00fcller", "Simon Martin", "Tim Schlippe"], "title": "Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "preprint of conference submission", "summary": "Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.", "AI": {"tldr": "This paper evaluates retrieval-augmented generation (RAG) variants for SQL and REST API generation in enterprise contexts and highlights the importance of retrieval policy design.", "motivation": "The paper explores the gap in evaluating large language models' effectiveness in domain-specific enterprise systems for tasks combining retrieval and modification, essential for building production-grade natural language interfaces.", "method": "It evaluates RAG variants (standard RAG, Self-RAG, CoRAG) on SQL and REST API generation tasks using a novel test dataset within SAP Transactional Banking. Iterative query decomposition and different retrieval strategies are compared.", "result": "Retrieval boosts accuracy significantly, achieving up to 79.30% execution accuracy with CoRAG being the most robust (e.g., 10.29% exact match improvement and 15.32% improved SQL generation in hybrid settings).", "conclusion": "RAG and its retrieval-policy design are crucial for high-performance natural language interfaces, and iterative query decomposition performs best under heterogeneous documentation."}}
{"id": "2602.06974", "pdf": "https://arxiv.org/pdf/2602.06974", "abs": "https://arxiv.org/abs/2602.06974", "authors": ["Faith Johnson", "Bryan Bo Cao", "Shubham Jain", "Ashwin Ashok", "Kristin Dana"], "title": "FeudalNav: A Simple Framework for Visual Navigation", "categories": ["cs.RO", "cs.CV"], "comment": "8 Pages, 6 figures and 4 tables. arXiv admin note: substantial text overlap with arXiv:2411.09893, arXiv:2402.12498", "summary": "Visual navigation for robotics is inspired by the human ability to navigate environments using visual cues and memory, eliminating the need for detailed maps. In unseen, unmapped, or GPS-denied settings, traditional metric map-based methods fall short, prompting a shift toward learning-based approaches with minimal exploration. In this work, we develop a hierarchical framework that decomposes the navigation decision-making process into multiple levels. Our method learns to select subgoals through a simple, transferable waypoint selection network. A key component of the approach is a latent-space memory module organized solely by visual similarity, as a proxy for distance. This alternative to graph-based topological representations proves sufficient for navigation tasks, providing a compact, light-weight, simple-to-train navigator that can find its way to the goal in novel locations. We show competitive results with a suite of SOTA methods in Habitat AI environments without using any odometry in training or inference. An additional contribution leverages the interpretablility of the framework for interactive navigation. We consider the question: how much direction intervention/interaction is needed to achieve success in all trials? We demonstrate that even minimal human involvement can significantly enhance overall navigation performance.", "AI": {"tldr": "This paper introduces a hierarchical, learning-based visual navigation framework using a latent-space memory module organized by visual similarity, achieving effective navigation without traditional metrics or odometry.", "motivation": "To address the limitations of metric map-based methods in unmapped, unseen, or GPS-denied environments by leveraging learning-based navigation inspired by human visual memory.", "method": "The approach employs a hierarchical framework with a waypoint selection network and a latent-space memory module organized by visual similarity to select subgoals and navigate novel locations.", "result": "The framework demonstrated competitive performance to state-of-the-art methods in Habitat AI environments without relying on odometry during training or inference.", "conclusion": "The proposed method provides a compact, interpretable, and effective navigation system suitable for novel scenarios, with minimal human intervention boosting performance."}}
{"id": "2602.07164", "pdf": "https://arxiv.org/pdf/2602.07164", "abs": "https://arxiv.org/abs/2602.07164", "authors": ["Ruimeng Ye", "Zihan Wang", "Zinan Ling", "Yang Xiao", "Manling Li", "Xiaolong Ma", "Bo Hui"], "title": "Your Language Model Secretly Contains Personality Subnetworks", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR 2026", "summary": "Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.", "AI": {"tldr": "The paper reveals that Large Language Models (LLMs) inherently contain persona-specialized subnetworks without requiring external data, providing a training-free approach to isolate these behaviors.", "motivation": "To investigate if LLMs inherently possess the ability to adopt different personas, without relying on external mechanisms or additional data.", "method": "The researchers used small calibration datasets to identify persona-specific activation signatures and developed a masking strategy to isolate lightweight persona subnetworks. They also introduced a contrastive pruning method for identifying binary-opposing personas.", "result": "The isolated subnetworks demonstrated significantly improved persona alignment compared to traditional methods that require external knowledge or adaptation.", "conclusion": "LLMs inherently embed diverse human-like behaviors in their parameter space, offering potential for efficient, interpretable, and controllable personalization of personas."}}
{"id": "2602.07014", "pdf": "https://arxiv.org/pdf/2602.07014", "abs": "https://arxiv.org/abs/2602.07014", "authors": ["Qingyu Wu", "Yuxuan Han", "Haijun Li", "Zhao Xu", "Jianshan Zhao", "Xu Jin", "Longyue Wang", "Weihua Luo"], "title": "Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In-Image Machine Translation (IIMT) powers cross-border e-commerce product listings; existing research focuses on machine translation evaluation, while visual rendering quality is critical for user engagement. When facing context-dense product imagery and multimodal defects, current reference-based methods (e.g., SSIM, FID) lack explainability, while model-as-judge approaches lack domain-grounded, fine-grained reward signals. To bridge this gap, we introduce Vectra, to the best of our knowledge, the first reference-free, MLLM-driven visual quality assessment framework for e-commerce IIMT. Vectra comprises three components: (1) Vectra Score, a multidimensional quality metric system that decomposes visual quality into 14 interpretable dimensions, with spatially-aware Defect Area Ratio (DAR) quantification to reduce annotation ambiguity; (2) Vectra Dataset, constructed from 1.1M real-world product images via diversity-aware sampling, comprising a 2K benchmark for system evaluation, 30K reasoning-based annotations for instruction tuning, and 3.5K expert-labeled preferences for alignment and evaluation; and (3) Vectra Model, a 4B-parameter MLLM that generates both quantitative scores and diagnostic reasoning. Experiments demonstrate that Vectra achieves state-of-the-art correlation with human rankings, and our model outperforms leading MLLMs, including GPT-5 and Gemini-3, in scoring performance. The dataset and model will be released upon acceptance.", "AI": {"tldr": "The paper introduces Vectra, a framework for evaluating visual quality in e-commerce imagery, addressing limitations of current methods and proposing a multidimensional metric system and a large-scale dataset.", "motivation": "Current methods for evaluating e-commerce in-image machine translation (IIMT) are insufficient. Reference-based methods lack explainability and model-as-judge methods lack domain-specific, fine-grained feedback.", "method": "The authors propose Vectra, which includes (1) a multidimensional quality metric (Vectra Score), (2) a large-scale, diverse dataset (Vectra Dataset), and (3) a 4B-parameter MLLM (Vectra Model) that provides scores and reasoning for visual quality.", "result": "Vectra achieves state-of-the-art correlation with human rankings and surpasses existing MLLMs like GPT-5 and Gemini-3 in scoring performance.", "conclusion": "Vectra establishes a novel framework in evaluating visual quality in e-commerce imagery with high explainability and human alignment, filling critical gaps in IIMT evaluation."}}
{"id": "2602.07767", "pdf": "https://arxiv.org/pdf/2602.07767", "abs": "https://arxiv.org/abs/2602.07767", "authors": ["Ruizhe Deng", "Bibhas Chakraborty", "Ran Chen", "Yan Shuo Tan"], "title": "BFTS: Thompson Sampling with Bayesian Additive Regression Trees", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Contextual bandits are a core technology for personalized mobile health interventions, where decision-making requires adapting to complex, non-linear user behaviors. While Thompson Sampling (TS) is a preferred strategy for these problems, its performance hinges on the quality of the underlying reward model. Standard linear models suffer from high bias, while neural network approaches are often brittle and difficult to tune in online settings. Conversely, tree ensembles dominate tabular data prediction but typically rely on heuristic uncertainty quantification, lacking a principled probabilistic basis for TS. We propose Bayesian Forest Thompson Sampling (BFTS), the first contextual bandit algorithm to integrate Bayesian Additive Regression Trees (BART), a fully probabilistic sum-of-trees model, directly into the exploration loop. We prove that BFTS is theoretically sound, deriving an information-theoretic Bayesian regret bound of $\\tilde{O}(\\sqrt{T})$. As a complementary result, we establish frequentist minimax optimality for a \"feel-good\" variant, confirming the structural suitability of BART priors for non-parametric bandits. Empirically, BFTS achieves state-of-the-art regret on tabular benchmarks with near-nominal uncertainty calibration. Furthermore, in an offline policy evaluation on the Drink Less micro-randomized trial, BFTS improves engagement rates by over 30% compared to the deployed policy, demonstrating its practical effectiveness for behavioral interventions.", "AI": {"tldr": "The paper proposes Bayesian Forest Thompson Sampling (BFTS), a novel algorithm for contextual bandits using Bayesian Additive Regression Trees (BART), achieving strong theoretical guarantees and practical effectiveness in personalized interventions.", "motivation": "Traditional reward models used in Thompson Sampling for contextual bandits suffer from limitations: linear models are biased, neural networks are brittle, and tree ensembles lack principled probabilistic foundations, posing challenges for adapting to complex user behaviors in health interventions.", "method": "The authors integrate Bayesian Additive Regression Trees (BART) into the Thompson Sampling framework to create BFTS, leveraging a probabilistic sum-of-trees model and theoretical guarantees like a Bayesian regret bound and frequentist minimax optimality.", "result": "BFTS achieves state-of-the-art regret benchmarks with good uncertainty calibration and improves engagement rates by over 30% in an offline evaluation on the Drink Less trial, outperforming the deployed policy.", "conclusion": "BFTS effectively bridges theoretical rigor and practical application, offering an optimal and robust solution for personalized decision-making in non-parametric bandit problems like mobile health interventions."}}
{"id": "2602.07153", "pdf": "https://arxiv.org/pdf/2602.07153", "abs": "https://arxiv.org/abs/2602.07153", "authors": ["Jinbiao Wei", "Yilun Zhao", "Kangqi Ni", "Arman Cohan"], "title": "ANCHOR: Branch-Point Data Generation for GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.", "AI": {"tldr": "The paper introduces Anchor, a trajectory expansion framework to generate scalable and high-quality interaction data for real desktop environments from a small set of seed demonstrations.", "motivation": "Current methods for collecting interaction data for end-to-end GUI agents are expensive or suffer from issues such as limited task diversity and noisy trajectories.", "method": "Anchor uses seed demonstrations to identify branch points for meaningful state changes, generates new task variants based on GUI context, and uses an executing agent and state-aware verifier to ensure task completion and remove noise.", "result": "Experiments on OSWorld and WindowsAgentArena benchmarks show consistent improvements in performance for models fine-tuned on Anchor\u2019s expanded corpus compared to zero-shot agents and prior synthesis methods.", "conclusion": "Anchor successfully improves interaction data quality and scalability for desktop GUI agents, enabling better generalization across applications and operating systems."}}
{"id": "2602.07061", "pdf": "https://arxiv.org/pdf/2602.07061", "abs": "https://arxiv.org/abs/2602.07061", "authors": ["Daniel Nobrega"], "title": "TACIT: Transformation-Aware Capturing of Implicit Thought", "categories": ["cs.LG", "cs.AI"], "comment": "25 pages, 7 figures", "summary": "We present TACIT (Transformation-Aware Capturing of Implicit Thought), a diffusion-based transformer for interpretable visual reasoning. Unlike language-based reasoning systems, TACIT operates entirely in pixel space using rectified flow, enabling direct visualization of the reasoning process at each inference step. We demonstrate the approach on maze-solving, where the model learns to transform images of unsolved mazes into solutions. Key results on 1 million synthetic maze pairs include:\n  - 192x reduction in training loss over 100 epochs\n  - 22.7x improvement in L2 distance to ground truth\n  - Only 10 Euler steps required (vs. 100-1000 for typical diffusion models)\n  Quantitative analysis reveals a striking phase transition phenomenon: the solution remains invisible for 68% of the transformation (zero recall), then emerges abruptly at t=0.70 within just 2% of the process. Most remarkably, 100% of samples exhibit simultaneous emergence across all spatial regions, ruling out sequential path construction and providing evidence for holistic rather than algorithmic reasoning. This \"eureka moment\" pattern -- long incubation followed by sudden crystallization -- parallels insight phenomena in human cognition. The pixel-space design with noise-free flow matching provides a foundation for understanding how neural networks develop implicit reasoning strategies that operate below and before language.", "AI": {"tldr": "TACIT is a pixel-space diffusion transformer designed for visual reasoning, capable of solving mazes with fewer steps and displaying reasoning in a holistic, sudden manner.", "motivation": "To create interpretable visual reasoning by enabling models to operate in pixel space, capturing implicit thought processes similar to human cognition.", "method": "TACIT uses rectified flow in pixel space and diffusion-based transformation to visualize reasoning in maze-solving, quantified through synthetic maze pair datasets.", "result": "Reduced training loss (192x), L2 distance improvement (22.7x), and fewer Euler steps (10) required; phase transition analysis revealed abrupt solution emergence and holistic reasoning patterns.", "conclusion": "TACIT provides novel insights into implicit neural reasoning strategies, showing parallelism to human 'eureka moments' through reasoning processes that are holistic and visual."}}
{"id": "2602.07816", "pdf": "https://arxiv.org/pdf/2602.07816", "abs": "https://arxiv.org/abs/2602.07816", "authors": ["Emiko Shishido"], "title": "Beyond Expertise: Stable Individual Differences in Predictive Eye-Hand Coordination", "categories": ["q-bio.NC", "cs.HC"], "comment": "21 pages, 8 figures, supplementary figure in a separate pdf file, supplementary video (in youtube link)", "summary": "Human eye-hand coordination relies on internal forward models that predict future states and compensate for sensory delays. During line tracing, the gaze typically leads the hand through predictive saccades, yet the extent to which this predictive window reflects expertise or intrinsic individual traits remains unclear. In this study, I examined eye-hand coordination in professional calligraphers and non-experts performing a controlled line tracing task. The temporal coupling between saccade distance (SD) and pen speed (PS) revealed substantial interpersonal variability: SD-PS peak times ranged from approximately -50 to 400 ms, forming stable, participant-specific predictive windows that were consistent across trials. These predictive windows closely matched each individual's pen catch-up time, indicating that the oculomotor system stabilizes fixation in anticipation of the hand's future velocity rather than relying on reactive pursuit. Neither the spatial indices (mean gaze-pen distance, mean saccade distance) nor the temporal index (SD-PS peak time) differed between calligraphers and non-calligraphers, and none of these predictive parameters correlated with tracing accuracy. These findings suggest that diverse predictive strategies can achieve equivalent performance, consistent with the minimum intervention principle of optimal feedback control. Together, the results indicate that predictive timing in eye-hand coordination reflects a stable, idiosyncratic Predictive Protocol shaped by individual neuromotor constraints rather than by expertise or training history.", "AI": {"tldr": "The study explores eye-hand coordination and predictive strategies across individuals, revealing stable and individual-specific timing irrespective of expertise.", "motivation": "To understand whether predictive eye-hand coordination is shaped by expertise or intrinsic traits.", "method": "Experienced calligraphers and non-experts performed a controlled line tracing task to measure spatial and temporal coordination indices.", "result": "Participant-specific temporal predictive windows were identified, independent of expertise, and did not correlate with tracing accuracy.", "conclusion": "Predictive coordination reflects individual neuromotor constraints rather than expertise, aligning with optimal feedback control principles."}}
{"id": "2602.07958", "pdf": "https://arxiv.org/pdf/2602.07958", "abs": "https://arxiv.org/abs/2602.07958", "authors": ["Yumin Kim", "Hyeonsu Lyu", "Minjae Lee", "Hyun Jong Yang"], "title": "Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty", "categories": ["eess.SY", "cs.AI", "cs.DC"], "comment": "This paper has been accepted at 2025 IEEE Globecom Workshop: WS02-GAIMC: Mutual Facilitation of Generative Artificial Intelligence and Mobile Communications", "summary": "Large language models (LLMs) offer significant potential for intelligent mobile services but are computationally intensive for resource-constrained devices. Mobile edge computing (MEC) allows such devices to offload inference tasks to edge servers (ESs), yet introduces latency due to communication and serverside queuing, especially in multi-user environments. In this work, we propose an uncertainty-aware offloading framework that dynamically decides whether to perform inference locally or offload it to the ES, based on token-level uncertainty and resource constraints. We define a margin-based token-level uncertainty metric and demonstrate its correlation with model accuracy. Leveraging this metric, we design a greedy offloading algorithm (GOA) that minimizes delay while maintaining accuracy by prioritizing offloading for highuncertainty queries. Our experiments show that GOA consistently achieves a favorable trade-off, outperforming baseline strategies in both accuracy and latency across varying user densities, and operates with practical computation time. These results establish GOA as a scalable and effective solution for LLM inference in MEC environments.", "AI": {"tldr": "This paper proposes an uncertainty-aware offloading framework to optimize LLM inference in mobile edge computing (MEC) environments, improving both accuracy and latency trade-offs.", "motivation": "To address the challenge of deploying computationally intensive large language models (LLMs) on resource-constrained devices, while mitigating latency introduced by mobile edge computing (MEC) frameworks, especially in multi-user scenarios.", "method": "The authors introduce a margin-based token-level uncertainty metric to guide decisions on whether to perform inference locally or offload to an edge server (ES). Using this metric, they develop a greedy offloading algorithm (GOA) that prioritizes offloading for high-uncertainty queries while minimizing delays and sustaining accuracy.", "result": "Experiments show that the proposed GOA outperforms baseline strategies in both accuracy and latency across different user densities, and does so with practical computation time.", "conclusion": "GOA provides a scalable and efficient solution for managing LLM inference in MEC settings, achieving an effective balance between latency and accuracy in multi-user environments."}}
{"id": "2602.07275", "pdf": "https://arxiv.org/pdf/2602.07275", "abs": "https://arxiv.org/abs/2602.07275", "authors": ["Vishesh Purnananda", "Benjamin John Wruck", "Mingyu Guo"], "title": "Evolving LLM-Derived Control Policies for Residential EV Charging and Vehicle-to-Grid Energy Optimization", "categories": ["cs.NE"], "comment": null, "summary": "This research presents a novel application of Evolutionary Computation to the domain of residential electric vehicle (EV) energy management. While reinforcement learning (RL) achieves high performance in vehicle-to-grid (V2G) optimization, it typically produces opaque \"black-box\" neural networks that are difficult for consumers and regulators to audit. Addressing this interpretability gap, we propose a program search framework that leverages Large Language Models (LLMs) as intelligent mutation operators within an iterative prompt-evaluation-repair loop. Utilizing the high-fidelity EV2Gym simulation environment as a fitness function, the system undergoes successive refinement cycles to synthesize executable Python policies that balance profit maximization, user comfort, and physical safety constraints. We benchmark four prompting strategies: Imitation, Reasoning, Hybrid and Runtime, evaluating their ability to discover adaptive control logic. Results demonstrate that the Hybrid strategy produces concise, human-readable heuristics that achieve 118% of the baseline profit, effectively discovering complex behaviors like anticipatory arbitrage and hysteresis without explicit programming. This work establishes LLM-driven Evolutionary Computation as a practical approach for generating EV charging control policies that are transparent, inspectable, and suitable for real residential deployment.", "AI": {"tldr": "The paper proposes an application of Evolutionary Computation using Large Language Models (LLMs) to create interpretable energy management policies for residential electric vehicle (EV) charging, achieving improved performance and transparency.", "motivation": "The research aims to address the lack of transparency and auditability in reinforcement learning-based vehicle-to-grid (V2G) optimization, providing interpretable solutions for residential EV charging.", "method": "The method integrates a program search framework where LLMs act as mutation operators in an iterative refinement loop, using EV2Gym simulation as a fitness function to synthesize executable Python policies.", "result": "The Hybrid prompting strategy produced human-readable heuristics, achieving 118% of baseline profit and demonstrating complex, adaptive control behaviors.", "conclusion": "LLM-driven Evolutionary Computation is shown to be a practical and transparent solution for generating residential EV charging control policies, improving performance while ensuring interpretability."}}
{"id": "2602.07672", "pdf": "https://arxiv.org/pdf/2602.07672", "abs": "https://arxiv.org/abs/2602.07672", "authors": ["Babak Rahmani"], "title": "Debugging code world models", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "cs.SC"], "comment": "8 pages, 4 figures, under review in conference", "summary": "Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.", "AI": {"tldr": "This paper analyzes the limitations of Code World Models (CWMs) trained to simulate program execution and identifies failure points in token budget and string-valued state representation.", "motivation": "To improve the understanding of errors and limitations in CWMs and explore methodologies for more effective program simulation in execution-based world modeling.", "method": "The study analyzes CWMs via real-code benchmarks for semantic execution and a controlled permutation-tracking benchmark to evaluate long-horizon state tracking.", "result": "Key limitations include token budget exhaustion due to dense runtime state traces and failure in string-valued state representation caused by subword tokenization issues. Long-horizon errors are mainly due to incorrect action generation.", "conclusion": "CWMs' efficiency can improve through enhanced supervision and state representation techniques better aligned with executing programs and handling specific data types."}}
{"id": "2602.07147", "pdf": "https://arxiv.org/pdf/2602.07147", "abs": "https://arxiv.org/abs/2602.07147", "authors": ["Marco De Luca", "Michele Perlotto", "Anna Rita Fasolino", "Porfirio Tramontana"], "title": "Architectural Anti-Patterns in Student-Developed Microservice Architectures: An Exploratory Study", "categories": ["cs.SE"], "comment": null, "summary": "Teaching microservice architectures is challenging due to distributed complexity and the gap between academia and industry. Understanding the quality issues students introduce in MSAs is essential to improve education. This study analyzes student-developed microservices using an established anti-pattern taxonomy and derives lessons learned with actionable teaching recommendations. We conducted a longitudinal, project-based course (2023-2025) involving 216 Master's students (67 teams) who designed and deployed a realistic, containerized MSA for a gamified testing platform. The final systems revealed 23 out of 58 known MSA anti-patterns, spanning five categories. Security issues were most frequent, highlighting weaknesses in authentication, authorization, and data protection. Team Organization and Service Interaction problems followed, reflecting limited DevOps experience and difficulties in inter-service coordination. Fewer issues appeared in Intra-service Design and Inter-service Decomposition, suggesting students generally defined service boundaries well. Overall, students prioritized feature delivery over robustness and operational discipline. To address this, we recommend enforcing minimal standards (API contracts, gateways), providing labs on resilient communication, integrating security-by-design practices, and offering CI-CD templates. The paper contributes a realistic, full-scale educational experience and a replicable model for teaching industry-aligned microservice architecture.", "AI": {"tldr": "The study analyzes student-developed microservice architectures (MSAs), revealing frequent quality issues and providing teaching recommendations.", "motivation": "To address the gap between academia and industry in teaching MSAs, and to understand quality issues in student-developed systems.", "method": "A longitudinal course (2023-2025) studied 216 Master's students (67 teams) as they designed MSAs. Their systems were analyzed using an anti-pattern taxonomy.", "result": "Students' MSAs exhibited 23 out of 58 known anti-patterns, with common problems being security issues, team organization, and service interaction.", "conclusion": "Educational recommendations include enforcing API contracts, security-by-design, and offering CI/CD templates. The study provides a replicable teaching model."}}
{"id": "2602.06977", "pdf": "https://arxiv.org/pdf/2602.06977", "abs": "https://arxiv.org/abs/2602.06977", "authors": ["Shifa Sulaiman", "Francesco Schetter", "Tobias Jensen", "Simon B\u00f8gh", "Fanny Ficuciello"], "title": "Autonomous Manipulation of Hazardous Chemicals and Delicate Objects in a Self-Driving Laboratory: A Sliding Mode Approach", "categories": ["cs.RO"], "comment": null, "summary": "Precise handling of chemical instruments and materials within a self-driving laboratory environment using robotic systems demands advanced and reliable control strategies. Sliding Mode Control (SMC) has emerged as a robust approach for managing uncertainties and disturbances in manipulator dynamics, providing superior control performance compared to traditional methods. This study implements a model-based SMC (MBSMC) utilizing a hyperbolic tangent function to regulate the motion of a manipulator mounted on a mobile platform operating inside a self-driving chemical laboratory. Given the manipulator's role in transporting fragile glass vessels filled with hazardous chemicals, the controller is specifically designed to minimize abrupt transitions and achieve gentle, accurate trajectory tracking. The proposed controller is benchmarked against a non-model-based SMC (NMBSMC) and a Proportional-Integral-Derivative (PID) controller using a comprehensive set of joint and Cartesian metrics. Compared to PID and NMBSMC, MBSMC achieved significantly smoother motion and up to 90% lower control effort, validating its robustness and precision for autonomous laboratory operations. Experimental trials confirmed successful execution of tasks such as vessel grasping and window operation, which failed under PID control due to its limited ability to handle nonlinear dynamics and external disturbances, resulting in substantial trajectory tracking errors. The results validate the controller's effectiveness in achieving smooth, precise, and safe manipulator motions, supporting the advancement of intelligent mobile manipulators in autonomous laboratory environments.", "AI": {"tldr": "This study evaluates a model-based Sliding Mode Control (MBSMC) for precise manipulator motion in self-driving chemical laboratories, showing superior performance compared to traditional PID and NMBSMC controllers.", "motivation": "Autonomous chemical laboratories require precise and reliable control strategies for robotic manipulators to safely handle fragile materials and hazardous chemicals.", "method": "Utilization of a model-based Sliding Mode Control (MBSMC) with a hyperbolic tangent function to regulate manipulator motion, comparing its performance with non-model-based SMC and PID controllers.", "result": "MBSMC demonstrated smoother motion, 90% reduced control efforts, and superior performance in experimental tasks like vessel grasping and window operation, which PID failed to execute properly.", "conclusion": "MBSMC offers robust, precise, and safe manipulator motions ideal for autonomous laboratories, outperforming traditional methods in handling nonlinear dynamics and external disturbances."}}
{"id": "2602.07176", "pdf": "https://arxiv.org/pdf/2602.07176", "abs": "https://arxiv.org/abs/2602.07176", "authors": ["Mohamed El Hajji", "Tarek Ait Baha", "Aicha Dakir", "Hammou Fadili", "Youssef Es-Saady"], "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC"], "comment": "19 pages, 15 figures", "summary": "Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.", "AI": {"tldr": "Open TutorAI uses generative AI and 3D avatars to create personalized tutoring, enhancing engagement and supporting self-regulated learning.", "motivation": "Existing chatbots lack contextual adaptability, real-time responsiveness, and pedagogical agility, limiting personalized and effective learning experiences.", "method": "The platform uses LLMs, natural language processing, and customizable 3D avatars to create learner-specific AI assistants accessible through text and avatar-driven interfaces.", "result": "Open TutorAI offers tools for dynamic tutoring, embedded feedback, adaptive learner support, and analytics to improve engagement and provide actionable insights.", "conclusion": "Open TutorAI establishes a modular, open-source framework that advances intelligent tutoring systems by combining AI, immersive technologies, and learner analytics."}}
{"id": "2602.07015", "pdf": "https://arxiv.org/pdf/2602.07015", "abs": "https://arxiv.org/abs/2602.07015", "authors": ["Subreena", "Mohammad Amzad Hossain", "Mirza Raquib", "Saydul Akbar Murad", "Farida Siddiqi Prity", "Muhammad Hanif", "Nick Rahimi"], "title": "Robust and Real-Time Bangladeshi Currency Recognition: A Dual-Stream MobileNet and EfficientNet Approach", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Accurate currency recognition is essential for assistive technologies, particularly for visually impaired individuals who rely on others to identify banknotes. This dependency puts them at risk of fraud and exploitation. To address these challenges, we first build a new Bangladeshi banknote dataset that includes both controlled and real-world scenarios, ensuring a more comprehensive and diverse representation. Next, to enhance the dataset's robustness, we incorporate four additional datasets, including public benchmarks, to cover various complexities and improve the model's generalization. To overcome the limitations of current recognition models, we propose a novel hybrid CNN architecture that combines MobileNetV3-Large and EfficientNetB0 for efficient feature extraction. This is followed by an effective multilayer perceptron (MLP) classifier to improve performance while keeping computational costs low, making the system suitable for resource-constrained devices. The experimental results show that the proposed model achieves 97.95% accuracy on controlled datasets, 92.84% on complex backgrounds, and 94.98% accuracy when combining all datasets. The model's performance is thoroughly evaluated using five-fold cross-validation and seven metrics: accuracy, precision, recall, F1-score, Cohen's Kappa, MCC, and AUC. Additionally, explainable AI methods like LIME and SHAP are incorporated to enhance transparency and interpretability.", "AI": {"tldr": "The paper develops a hybrid CNN architecture for accurate recognition of Bangladeshi banknotes, achieving high accuracy across various datasets.", "motivation": "To aid visually impaired individuals in identifying currency accurately and independently, mitigating risks of fraud and exploitation.", "method": "A novel hybrid CNN architecture combining MobileNetV3-Large and EfficientNetB0 for feature extraction alongside an efficient MLP classifier. The model was trained and tested on a comprehensive Bangladeshi banknote dataset enhanced with additional datasets and analyzed using explainable AI tools like LIME and SHAP.", "result": "The proposed model achieved 97.95% accuracy on controlled datasets, 92.84% on complex backgrounds, and 94.98% on all combined datasets, evaluated using five-fold cross-validation and metrics.", "conclusion": "The model demonstrates high accuracy and computational efficiency, making it effective for resource-constrained assistive devices."}}
{"id": "2602.07997", "pdf": "https://arxiv.org/pdf/2602.07997", "abs": "https://arxiv.org/abs/2602.07997", "authors": ["TrungKhang Tran", "TrungTin Nguyen", "Md Abul Bashar", "Nhat Ho", "Richi Nayak", "Christopher Drovandi"], "title": "Fast Model Selection and Stable Optimization for Softmax-Gated Multinomial-Logistic Mixture of Experts Models", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.CO", "stat.ME"], "comment": "TrungKhang Tran and TrungTin Nguyen are co-first authors", "summary": "Mixture-of-Experts (MoE) architectures combine specialized predictors through a learned gate and are effective across regression and classification, but for classification with softmax multinomial-logistic gating, rigorous guarantees for stable maximum-likelihood training and principled model selection remain limited. We address both issues in the full-data (batch) regime. First, we derive a batch minorization-maximization (MM) algorithm for softmax-gated multinomial-logistic MoE using an explicit quadratic minorizer, yielding coordinate-wise closed-form updates that guarantee monotone ascent of the objective and global convergence to a stationary point (in the standard MM sense), avoiding approximate M-steps common in EM-type implementations. Second, we prove finite-sample rates for conditional density estimation and parameter recovery, and we adapt dendrograms of mixing measures to the classification setting to obtain a sweep-free selector of the number of experts that achieves near-parametric optimal rates after merging redundant fitted atoms. Experiments on biological protein--protein interaction prediction validate the full pipeline, delivering improved accuracy and better-calibrated probabilities than strong statistical and machine-learning baselines.", "AI": {"tldr": "This paper presents a batch MM algorithm for multinomial-logistic MoE models, ensuring monotone ascent and global convergence, introduces finite-sample guarantees, and adapts dendrograms for improving model selection in classification tasks.", "motivation": "Mixture-of-Experts models are effective but there is a lack of rigorous guarantees for stable training and model selection in classification scenarios using multinomial-logistic gating.", "method": "The approach includes deriving a batch MM algorithm with closed-form updates for softmax gated multinomial-logistic MoE and adapting mixing measure dendrograms to perform efficient model selection.", "result": "The proposed approach yields better accuracy and calibrated probabilities compared to statistical and machine learning baselines in protein interaction prediction.", "conclusion": "This work achieves stable maximum-likelihood training, improved finite-sample guarantees, effective model selection methods, and enhanced prediction performance for classification tasks."}}
{"id": "2602.07187", "pdf": "https://arxiv.org/pdf/2602.07187", "abs": "https://arxiv.org/abs/2602.07187", "authors": ["Hanyu Wang", "Yuanpu Cao", "Lu Lin", "Jinghui Chen"], "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents", "categories": ["cs.AI"], "comment": null, "summary": "Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.", "AI": {"tldr": "PreFlect introduces a prospective reflection mechanism for language model agents, focusing on refining plans before execution and proactively addressing potential errors, improving performance on real-world tasks.", "motivation": "Existing reflective approaches in language models are reactive, correcting errors after observing failures. The motivation is to shift towards foreseeing and refining errors before execution, improving the effectiveness of agent plans.", "method": "The approach captures patterns of past successes and failures from historical agent trajectories to construct mechanisms for prospective reflection. It also integrates a dynamic re-planning system for adjusting plans during execution when deviations occur.", "result": "PreFlect demonstrated superior performance by improving utility on complex real-world tasks compared to traditional retrospective reflection methods and other advanced agent architectures.", "conclusion": "Prospective reflection, as implemented in PreFlect, is a more effective framework for language model agents. This method enhances task efficacy by addressing potential failures in planning, providing a significant step forward in agent design and execution."}}
{"id": "2602.07063", "pdf": "https://arxiv.org/pdf/2602.07063", "abs": "https://arxiv.org/abs/2602.07063", "authors": ["Serkan Sulun"], "title": "Video-based Music Generation", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "comment": "PhD thesis, University of Porto", "summary": "As the volume of video content on the internet grows rapidly, finding a suitable soundtrack remains a significant challenge. This thesis presents EMSYNC (EMotion and SYNChronization), a fast, free, and automatic solution that generates music tailored to the input video, enabling content creators to enhance their productions without composing or licensing music. Our model creates music that is emotionally and rhythmically synchronized with the video. A core component of EMSYNC is a novel video emotion classifier. By leveraging pretrained deep neural networks for feature extraction and keeping them frozen while training only fusion layers, we reduce computational complexity while improving accuracy. We show the generalization abilities of our method by obtaining state-of-the-art results on Ekman-6 and MovieNet. Another key contribution is a large-scale, emotion-labeled MIDI dataset for affective music generation. We then present an emotion-based MIDI generator, the first to condition on continuous emotional values rather than discrete categories, enabling nuanced music generation aligned with complex emotional content. To enhance temporal synchronization, we introduce a novel temporal boundary conditioning method, called \"boundary offset encodings,\" aligning musical chords with scene changes. Combining video emotion classification, emotion-based music generation, and temporal boundary conditioning, EMSYNC emerges as a fully automatic video-based music generator. User studies show that it consistently outperforms existing methods in terms of music richness, emotional alignment, temporal synchronization, and overall preference, setting a new state-of-the-art in video-based music generation.", "AI": {"tldr": "This research introduces EMSYNC, an automatic video-based music generator, addressing the challenge of adding synchronized and emotion-tailored soundtracks to videos.", "motivation": "Content creators face difficulties in composing or licensing music that aligns emotionally and rhythmically with video content.", "method": "EMSYNC uses a novel video emotion classifier, emotion-labeled MIDI dataset for music generation, and temporal boundary conditioning to align music with scene changes. It leverages frozen pretrained deep neural networks for efficient feature extraction.", "result": "The model achieves state-of-the-art results in emotion classification tasks (Ekman-6, MovieNet) and demonstrates superior performance in music alignment, synchronization, and preferences, validated through user studies.", "conclusion": "EMSYNC provides a fast, free, and user-friendly tool for creating emotionally and rhythmically synchronized music for videos, surpassing existing methods."}}
{"id": "2602.08079", "pdf": "https://arxiv.org/pdf/2602.08079", "abs": "https://arxiv.org/abs/2602.08079", "authors": ["Giovanni Pezzulo", "Michael Levin"], "title": "Bootstrapping Life-Inspired Machine Intelligence: The Biological Route from Chemistry to Cognition and Creativity", "categories": ["q-bio.NC"], "comment": null, "summary": "Achieving advanced machine intelligence remains a central challenge in AI research, often approached through scaling neural architectures and generative models. However, biological systems offer a broader repertoire of strategies for adaptive, goal-directed behavior - strategies that emerged long before nervous systems evolved. This paper advocates a genuinely life-inspired approach to machine intelligence, drawing on principles from biology that enable robustness, autonomy, and open-ended problem-solving across scales. We frame intelligence as flexible problem-solving, following William James, and develop the concept of \"cognitive light cones\" to characterize the continuum of intelligence in living systems and machines. We argue that biological evolution has discovered a scalable recipe for intelligence - and the progressive expansion of organisms' \"cognitive light cone\", predictive and control capacities. To explain how this is possible, we distill five design principles - multiscale autonomy, growth through self-assemblage of active components, continuous reconstruction of capabilities, exploitation of physical and embodied constraints, and pervasive signaling enabling self-organization and top-down control from goals - that underpin life's ability to navigate creatively diverse problem spaces. We discuss how these principles contrast with current AI paradigms and outline pathways for integrating them into future autonomous, embodied, and resilient artificial systems.", "AI": {"tldr": "The paper explores how principles from biology can inspire robust and adaptive machine intelligence systems, contrasting with current AI paradigms.", "motivation": "Current AI systems rely heavily on scaling neural nets, but biological systems offer alternative, scalable strategies for adaptive intelligence that remain largely untapped.", "method": "The concept of 'cognitive light cones' is introduced to explore intelligence across systems, and five biological design principles are distilled for application into machine intelligence.", "result": "The study identifies and synthesizes foundational biological principles that could enable AI systems to exhibit robustness, autonomy, and open-ended problem-solving across scales.", "conclusion": "Integrating biological strategies into AI could create more adaptive, scalable, and resilient systems, addressing limitations in contemporary methodologies."}}
{"id": "2602.08003", "pdf": "https://arxiv.org/pdf/2602.08003", "abs": "https://arxiv.org/abs/2602.08003", "authors": ["Yigit Turkmen", "Baturalp Buyukates", "Melih Bastopcu"], "title": "Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.IT", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even with many models, we model the correlated errors of the models using Gaussian-copula and show an information-theoretic error floor for the performance of the ensemble. Motivated by these, we propose a simple greedy mutual-information selection algorithm that estimates the required information terms directly from data and iteratively builds an ensemble under a query budget. We test our approach in two question answering datasets and one binary sentiment classification dataset: MEDMCQA, MMLU, and IMDB movie reviews. Across all datasets, we observe that our method consistently outperforms strong baselines under the same query budget.", "AI": {"tldr": "The paper investigates optimal ensemble selection for large language models (LLMs) by maximizing mutual information, proposing a greedy algorithm for selection, and validating it on several datasets.", "motivation": "To address the challenge of correlated errors in LLM ensembles and the saturation of ensemble performance with additional models, improving reliability and robustness under query budgets.", "method": "The authors model correlated errors using a Gaussian-copula framework, develop an error floor theory for ensembles, and introduce a greedy algorithm optimizing mutual information for budgeted ensemble selection.", "result": "The proposed method consistently outperforms strong baseline ensemble techniques on three datasets: MEDMCQA, MMLU, and IMDB, under identical query budgets.", "conclusion": "Maximizing mutual information while forming an ensemble under budget constraints improves reliability and performance, offering a robust selection strategy for LLM ensembles."}}
{"id": "2602.07299", "pdf": "https://arxiv.org/pdf/2602.07299", "abs": "https://arxiv.org/abs/2602.07299", "authors": ["Rivaaj Monsia", "Daniel Young", "Olivier Francon", "Risto Miikkulainen"], "title": "Optimizing Chlorination in Water Distribution Systems via Surrogate-assisted Neuroevolution", "categories": ["cs.NE", "eess.SY"], "comment": "14 pages, 9 figures, GECCO '26 in-review", "summary": "Ensuring the microbiological safety of large, heterogeneous water distribution systems (WDS) typically requires managing appropriate levels of disinfectant residuals including chlorine. WDS include complex fluid interactions that are nonlinear and noisy, making such maintenance a challenging problem for traditional control algorithms. This paper proposes an evolutionary framework to this problem based on neuroevolution, multi-objective optimization, and surrogate modeling. Neural networks were evolved with NEAT to inject chlorine at strategic locations in the distribution network at select times. NSGA-II was employed to optimize four objectives: minimizing the total amount of chlorine injected, keeping chlorine concentrations homogeneous across the network, ensuring that maximum concentrations did not exceed safe bounds, and distributing the injections regularly over time. Each network was evaluated against a surrogate model, i.e. a neural network trained to emulate EPANET, an industry-level hydraulic WDS simulator that is accurate but infeasible in terms of computational cost to support machine learning. The evolved controllers produced a diverse range of Pareto-optimal policies that could be implemented in practice, outperforming standard reinforcement learning methods such as PPO. The results thus suggest a pathway toward improving urban water systems, and highlight the potential of using evolution with surrogate modeling to optimize complex real-world systems.", "AI": {"tldr": "This paper proposes a neuroevolution framework and surrogate modeling to optimize chlorine injections in water distribution systems to ensure microbiological safety while balancing multiple objectives.", "motivation": "Monitoring and maintaining microbiological safety in complex water distribution systems is challenging due to nonlinear, noisy interactions and the need for appropriate chlorine residuals.", "method": "Neuroevolution using NEAT and surrogate modeling was utilized to optimize chlorine injections, evaluating against four objectives with multi-objective optimization (NSGA-II) and surrogate models trained to emulate EPANET simulations.", "result": "Evolved controllers achieved Pareto-optimal policies outperforming traditional reinforcement learning methods like PPO, enabling practical, effective optimization for water systems.", "conclusion": "The approach shows promise for improving urban water safety and demonstrates the efficacy of evolution combined with surrogate modeling in managing complex systems."}}
{"id": "2602.08846", "pdf": "https://arxiv.org/pdf/2602.08846", "abs": "https://arxiv.org/abs/2602.08846", "authors": ["Sam Speight", "Niels van der Weide"], "title": "Impredicativity in Linear Dependent Type Theory", "categories": ["cs.LO", "cs.PL", "math.CT", "math.LO"], "comment": "20 pages, 2 figures", "summary": "We construct a realizability model of linear dependent type theory from a linear combinatory algebra. Our model motivates a number of additions to the type theory. In particular, we add a universe with two decoding operations: one takes codes to cartesian types and the other takes codes to linear types. The universe is impredicative in the sense that it is closed under both large cartesian dependent products and large linear dependent products. We also add a rule for injectivity of the modality turning linear terms into cartesian terms. With all of the additions, we are able to encode (linear) inductive types. As a case study, we consider the type of lists over a linear type, and demonstrate that our encoding has the relevant uniqueness principle. The construction of the realizability model is fully formalized in the proof assistant Rocq.", "AI": {"tldr": "The paper develops a realizability model for linear dependent type theory using a linear combinatory algebra, introducing new features like a universe with dual decoding operations and injectivity rules.", "motivation": "To provide a realizability model for linear dependent type theory and to enhance type theory with additional features like universes, impredicativity, and support for linear inductive types.", "method": "A realizability model is constructed from a linear combinatory algebra. Features like impredicative universes and modality injectivity rules are added to encode linear inductive types. The model's correctness is formalized in the Rocq proof assistant.", "result": "The extension allows encoding of linear inductive types, with an example case study demonstrating a uniqueness principle for lists over linear types.", "conclusion": "The proposed model and extensions enrich linear dependent type theory, providing a robust framework and toolset formalized in Rocq."}}
{"id": "2602.07182", "pdf": "https://arxiv.org/pdf/2602.07182", "abs": "https://arxiv.org/abs/2602.07182", "authors": ["Maximilian Vierlboeck", "Antonio Pugliese", "Roshanak Nilchian", "Paul Grogan", "Rashika Sugganahalli Natesh Babu"], "title": "Measuring Complexity at the Requirements Stage: Spectral Metrics as Development Effort Predictors", "categories": ["cs.SE", "cs.CL"], "comment": "16 pages, 3 figures, 5 tables", "summary": "Complexity in engineered systems presents one of the most persistent challenges in modern development since it is driving cost overruns, schedule delays, and outright project failures. Yet while architectural complexity has been studied, the structural complexity embedded within requirements specifications remains poorly understood and inadequately quantified. This gap is consequential: requirements fundamentally drive system design, and complexity introduced at this stage propagates through architecture, implementation, and integration. To address this gap, we build on Natural Language Processing methods that extract structural networks from textual requirements. Using these extracted structures, we conducted a controlled experiment employing molecular integration tasks as structurally isomorphic proxies for requirements integration - leveraging the topological equivalence between molecular graphs and requirement networks while eliminating confounding factors such as domain expertise and semantic ambiguity. Our results demonstrate that spectral measures predict integration effort with correlations exceeding 0.95, while structural metrics achieve correlations above 0.89. Notably, density-based metrics show no significant predictive validity. These findings indicate that eigenvalue-derived measures capture cognitive and effort dimensions that simpler connectivity metrics cannot. As a result, this research bridges a critical methodological gap between architectural complexity analysis and requirements engineering practice, providing a validated foundation for applying these metrics to requirements engineering, where similar structural complexity patterns may predict integration effort.", "AI": {"tldr": "This paper presents a study on analyzing structural complexity in requirements specifications using Natural Language Processing and its impact on system integration efforts.", "motivation": "The paper aims to address the gap in understanding and quantifying structural complexity in requirements specifications, which significantly affects system design and integration.", "method": "The research employs Natural Language Processing to extract structural networks from textual requirements, then conducted controlled experiments using molecular graphs as proxies for requirement networks to measure and predict integration effort.", "result": "The results reveal that spectral measures exhibit strong predictive correlations (above 0.95) for integration effort, while simpler structural metrics also show high correlations (above 0.89). Density-based metrics, however, are not predictive.", "conclusion": "The study demonstrates the utility of eigenvalue-derived metrics for capturing the complexity and integration efforts that simpler metrics fail to measure, offering a new method for analyzing complexity in requirements engineering."}}
{"id": "2602.06991", "pdf": "https://arxiv.org/pdf/2602.06991", "abs": "https://arxiv.org/abs/2602.06991", "authors": ["Seongbo Ha", "Sibaek Lee", "Kyungsu Kang", "Joonyeol Choi", "Seungjun Tak", "Hyeonwoo Yu"], "title": "LangGS-SLAM: Real-Time Language-Feature Gaussian Splatting SLAM", "categories": ["cs.RO", "cs.CV", "eess.IV"], "comment": "17 pages, 4 figures", "summary": "In this paper, we propose a RGB-D SLAM system that reconstructs a language-aligned dense feature field while sustaining low-latency tracking and mapping. First, we introduce a Top-K Rendering pipeline, a high-throughput and semantic-distortion-free method for efficiently rendering high-dimensional feature maps. To address the resulting semantic-geometric discrepancy and mitigate the memory consumption, we further design a multi-criteria map management strategy that prunes redundant or inconsistent Gaussians while preserving scene integrity. Finally, a hybrid field optimization framework jointly refines the geometric and semantic fields under real-time constraints by decoupling their optimization frequencies according to field characteristics. The proposed system achieves superior geometric fidelity compared to geometric-only baselines and comparable semantic fidelity to offline approaches while operating at 15 FPS. Our results demonstrate that online SLAM with dense, uncompressed language-aligned feature fields is both feasible and effective, bridging the gap between 3D perception and language-based reasoning.", "AI": {"tldr": "The paper presents an RGB-D SLAM system for real-time tracking and mapping, integrating language-aligned dense features.", "motivation": "The paper aims to bridge the gap between 3D perception and language-based reasoning in SLAM systems, ensuring high geometric fidelity and semantic alignment while maintaining real-time performance.", "method": "It combines a Top-K Rendering pipeline for efficient feature rendering, a multi-criteria map management strategy for memory optimization, and a hybrid field optimization framework balancing geometric and semantic field refinement under time constraints.", "result": "The system achieves real-time (15 FPS) operation with superior geometric fidelity and comparable semantic fidelity to offline methods.", "conclusion": "This RGB-D SLAM system demonstrates the feasibility and effectiveness of integrating dense, language-aligned features for online 3D semantic reasoning and perception."}}
{"id": "2602.07181", "pdf": "https://arxiv.org/pdf/2602.07181", "abs": "https://arxiv.org/abs/2602.07181", "authors": ["Tianyu Zhao", "Siqi Li", "Yasser Shoukry", "Salma Elmalaki"], "title": "Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.", "AI": {"tldr": "The paper discusses using personality-aligned user preferences to improve LLM responses and introduces a dataset and framework for this purpose.", "motivation": "To improve the quality of LLM responses by addressing challenges in leveraging noisy, incomplete, or misleading user preference signals.", "method": "The authors conditioned on personality-aligned user preferences, developed the PACIFIC dataset annotated with the Big-Five personality traits, and proposed a framework for integrating these preferences during LLM answer generation.", "result": "Conditioning on personality-aligned preferences improved answer accuracy from 29.25% to 76%.", "conclusion": "Personality-aligned preferences significantly enhance LLM personalization, and the provided dataset and framework offer novel mechanisms for future improvements."}}
{"id": "2602.07016", "pdf": "https://arxiv.org/pdf/2602.07016", "abs": "https://arxiv.org/abs/2602.07016", "authors": ["Mohsen Mostafa"], "title": "Gaussian-Constrained LeJEPA Representations for Unsupervised Scene Discovery and Pose Consistency", "categories": ["cs.CV"], "comment": "10 pages, 3 figures, https://www.kaggle.com/code/babydriver1233/optimized-pipeline-for-the-image-matching-challeng, https://www.kaggle.com/code/babydriver1233/integrating-lejepa-for-enhanced-image-matching", "summary": "Unsupervised 3D scene reconstruction from unstructured image collections remains a fundamental challenge in computer vision, particularly when images originate from multiple unrelated scenes and contain significant visual ambiguity. The Image Matching Challenge 2025 (IMC2025) highlights these difficulties by requiring both scene discovery and camera pose estimation under real-world conditions, including outliers and mixed content. This paper investigates the application of Gaussian-constrained representations inspired by LeJEPA (Joint Embedding Predictive Architecture) to address these challenges. We present three progressively refined pipelines, culminating in a LeJEPA-inspired approach that enforces isotropic Gaussian constraints on learned image embeddings. Rather than introducing new theoretical guarantees, our work empirically evaluates how these constraints influence clustering consistency and pose estimation robustness in practice. Experimental results on IMC2025 demonstrate that Gaussian-constrained embeddings can improve scene separation and pose plausibility compared to heuristic-driven baselines, particularly in visually ambiguous settings. These findings suggest that theoretically motivated representation constraints offer a promising direction for bridging self-supervised learning principles and practical structure-from-motion pipelines.", "AI": {"tldr": "The paper explores Gaussian-constrained representations inspired by LeJEPA to address unsupervised 3D scene reconstruction challenges, demonstrating improved clustering and camera pose estimation performance on IMC2025.", "motivation": "To tackle the difficulties in unsupervised 3D scene reconstruction from unstructured images, such as outliers, visual ambiguities, and unrelated scenes, highlighted in challenges like IMC2025.", "method": "Introduced three refined pipelines culminating in an approach inspired by LeJEPA that incorporates isotropic Gaussian constraints on learned image embeddings to improve scene discovery and pose estimation.", "result": "Experimental results on IMC2025 show that Gaussian-constrained embeddings improve scene separation and pose plausibility compared to heuristic-driven baselines, particularly in ambiguous settings.", "conclusion": "The findings point to representation constraints, such as Gaussian embeddings, as a practical and theoretically motivated approach to enhance self-supervised learning principles and structure-from-motion pipelines."}}
{"id": "2602.08042", "pdf": "https://arxiv.org/pdf/2602.08042", "abs": "https://arxiv.org/abs/2602.08042", "authors": ["Nadav Katz", "Ariel Jaffe"], "title": "Graph-based Semi-Supervised Learning via Maximum Discrimination", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Semi-supervised learning (SSL) addresses the critical challenge of training accurate models when labeled data is scarce but unlabeled data is abundant. Graph-based SSL (GSSL) has emerged as a popular framework that captures data structure through graph representations. Classic graph SSL methods, such as Label Propagation and Label Spreading, aim to compute low-dimensional representations where points with the same labels are close in representation space. Although often effective, these methods can be suboptimal on data with complex label distributions. In our work, we develop AUC-spec, a graph approach that computes a low-dimensional representation that maximizes class separation. We compute this representation by optimizing the Area Under the ROC Curve (AUC) as estimated via the labeled points. We provide a detailed analysis of our approach under a product-of-manifold model, and show that the required number of labeled points for AUC-spec is polynomial in the model parameters. Empirically, we show that AUC-spec balances class separation with graph smoothness. It demonstrates competitive results on synthetic and real-world datasets while maintaining computational efficiency comparable to the field's classic and state-of-the-art methods.", "AI": {"tldr": "The paper introduces AUC-spec, a graph-based semi-supervised learning (SSL) method that enhances class separation by optimizing the Area Under the ROC Curve (AUC).", "motivation": "The motivation is to address the challenge of SSL methods performing suboptimally when handling datasets with complex label distributions and needing better class separation.", "method": "AUC-spec maximizes class separation in graph SSL by optimizing AUC via labeled points. It is analyzed under a product-of-manifold model, ensuring a polynomial amount of labeled data.", "result": "AUC-spec achieves competitive results on synthetic and real-world datasets, combining class separation and graph smoothness while maintaining computational efficiency.", "conclusion": "AUC-spec effectively addresses limitations of classic SSL methods on complex datasets, making a significant contribution to graph-based SSL frameworks."}}
{"id": "2602.07238", "pdf": "https://arxiv.org/pdf/2602.07238", "abs": "https://arxiv.org/abs/2602.07238", "authors": ["Matthias Mertens", "Natalia Fischl-Lanzoni", "Neil Thompson"], "title": "Is there \"Secret Sauce'' in Large Language Model Development?", "categories": ["cs.AI", "cs.LG", "econ.GN"], "comment": null, "summary": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.", "AI": {"tldr": "The paper investigates whether leading LLM performance is driven by proprietary technology or primarily by scaling compute, examining 809 models released between 2022-2025.", "motivation": "To understand the factors behind LLM performance differences, specifically whether advancements are proprietary or driven by scale, and its impact on AI leadership.", "method": "Analyzed training and benchmarking data using scaling-law regressions, accounting for developer-specific factors and performance distributions.", "result": "Found that at the performance frontier, compute scaling explains 80-90% of differences. Away from the frontier, proprietary techniques and shared progress reduce compute needs. Efficiency varies significantly within and across developers.", "conclusion": "Scale drives frontier advances, but proprietary technology plays a significant role in reducing compute requirements for specific tasks and models."}}
{"id": "2602.07070", "pdf": "https://arxiv.org/pdf/2602.07070", "abs": "https://arxiv.org/abs/2602.07070", "authors": ["Vladimer Khasia"], "title": "Hybrid Dual-Path Linear Transformations for Efficient Transformer Architectures", "categories": ["cs.LG"], "comment": null, "summary": "Standard Transformer architectures rely heavily on dense linear transformations, treating feature projection as a monolithic, full-rank operation. We argue that this formulation is inefficient and lacks the structural inductive bias necessary for distinguishing between local feature preservation and global context integration. To address this, we introduce the Hybrid Dual-Path Linear (HDPL) operator, which decomposes the affine transformation into two topologically distinct pathways: a sparse block-diagonal component for high-rank local processing, and a low-rank Variational Autoencoder (VAE) bottleneck for global context regularization. By \"surgically\" replacing specific projections (Query, Key, Value, Gate, Up) with HDPL operators while retaining standard dense layers for aggregation (Output, Down), we achieve a superior balance of efficiency and representational power. Experiments on the FineWeb-Edu dataset demonstrate that the HDPL architecture outperforms a standard Llama-style baseline, reducing validation loss while simultaneously reducing parameter count by 6.8%. Beyond immediate performance gains, we discuss how the explicit materialization of a probabilistic latent space within the Transformer backbone serves as a vital architectural affordance, offering new pathways for inference-time or hypernetwork induced control, continual adaptation, interpretability, and cross-model or cross-modal synchronization. The code is available at https://github.com/VladimerKhasia/HDPL", "AI": {"tldr": "The paper introduces the Hybrid Dual-Path Linear (HDPL) operator to enhance Transformer models by decomposing linear transformations into local and global pathways, showcasing improved efficiency and performance.", "motivation": "The motivation for this paper is to address inefficiencies and the lack of structural inductive bias in standard Transformer architectures, particularly in balancing local feature preservation with global context integration.", "method": "The method involves decomposing affine transformations into a block-diagonal component for local processing and a low-rank Variational Autoencoder bottleneck for global context. Specific Transformer layers are replaced with HDPL operators while retaining standard dense layers for other tasks.", "result": "Experiments on the FineWeb-Edu dataset demonstrate that the HDPL architecture outperforms a standard Llama-style baseline, achieving decreased validation loss and a 6.8% reduction in parameter count.", "conclusion": "The HDPL operator offers a more efficient and representationally powerful alternative, creating new possibilities in interpretability, adaptation, and synchronization for Transformer-based models."}}
{"id": "2602.08275", "pdf": "https://arxiv.org/pdf/2602.08275", "abs": "https://arxiv.org/abs/2602.08275", "authors": ["Fudong Zhang", "Bo Chai", "Yujie Wu", "Wai Ting Siok", "Nizhuan Wang"], "title": "Linguistics and Human Brain: A Perspective of Computational Neuroscience", "categories": ["q-bio.NC", "cs.CL"], "comment": null, "summary": "Elucidating the language-brain relationship requires bridging the methodological gap between the abstract theoretical frameworks of linguistics and the empirical neural data of neuroscience. Serving as an interdisciplinary cornerstone, computational neuroscience formalizes the hierarchical and dynamic structures of language into testable neural models through modeling, simulation, and data analysis. This enables a computational dialogue between linguistic hypotheses and neural mechanisms. Recent advances in deep learning, particularly large language models (LLMs), have powerfully advanced this pursuit. Their high-dimensional representational spaces provide a novel scale for exploring the neural basis of linguistic processing, while the \"model-brain alignment\" framework offers a methodology to evaluate the biological plausibility of language-related theories.", "AI": {"tldr": "The paper discusses bridging linguistics and neuroscience using computational models, emphasizing large language models (LLMs) for evaluating language-brain alignment.", "motivation": "To bridge the gap between theoretical linguistics and empirical neuroscience by creating computational models connecting both fields.", "method": "Utilizing computational neuroscience and advanced deep learning techniques like LLMs to simulate and analyze neural representations of language.", "result": "Large language models facilitate exploration of neural mechanisms of language processing, providing tools to align linguistic theories with brain dynamics.", "conclusion": "Computational neuroscience, through LLMs and the model-brain alignment framework, enables testing and validating language-brain relationships scientifically."}}
{"id": "2602.08080", "pdf": "https://arxiv.org/pdf/2602.08080", "abs": "https://arxiv.org/abs/2602.08080", "authors": ["Luciano Bozzi", "Christian Celidonio", "Umberto Nuzzi", "Massimo Biagini", "Stefano Cherubin", "Asbj\u00f8rn Djupdal", "Tor Andre Haugdahl", "Andrea Aliverti", "Alessandra Angelucci", "Giovanni Agosta", "Gerardo Pelosi", "Paolo Belluco", "Samuele Polistina", "Riccardo Volpi", "Luigi Malag\u00f2", "Michael Schneider", "Florian Wieczorek", "Xabier Eguiluz"], "title": "The CAPSARII Approach to Cyber-Secure Wearable, Ultra-Low-Power Networked Sensors for Soldier Health Monitoring", "categories": ["cs.ET", "cs.DC", "cs.LG"], "comment": null, "summary": "The European Defence Agency's revised Capability Development Plan (CDP) identifies as a priority improving ground combat capabilities by enhancing soldiers' equipment for better protection. The CAPSARII project proposes in innovative wearable system and Internet of Battlefield Things (IoBT) framework to monitor soldiers' physiological and psychological status, aiding tactical decisions and medical support. The CAPSARII system will enhance situational awareness and operational effectiveness by monitoring physiological, movement and environmental parameters, providing real-time tactical decision support through AI models deployed on edge nodes and enable data analysis and comparative studies via cloud-based analytics. CAPSARII also aims at improving usability through smart textile integration, longer battery life, reducing energy consumption through software and hardware optimizations, and address security concerns with efficient encryption and strong authentication methods. This innovative approach aims to transform military operations by providing a robust, data-driven decision support tool.", "AI": {"tldr": "CAPSARII focuses on enhancing soldier protection and operational effectiveness with an innovative wearable system and IoBT framework for real-time monitoring and decision support.", "motivation": "To address the need for improved soldier protection and operational effectiveness in military operations by leveraging advanced technology.", "method": "Development of a wearable system integrating physiological and environmental monitoring, AI for tactical support, smart fabric, energy-efficient optimization, and robust security measures.", "result": "A data-driven decision support tool that improves situational awareness and operational outcomes in military contexts.", "conclusion": "The CAPSARII project has the potential to transform military operations by enhancing soldier protection and efficiency through innovative technologies."}}
{"id": "2602.08513", "pdf": "https://arxiv.org/pdf/2602.08513", "abs": "https://arxiv.org/abs/2602.08513", "authors": ["Yu Xue", "Pengcheng Jiang", "Chenchen Zhu", "Yong Zhang", "Ran Cheng", "Kaizhou Gao", "Dunwei Gong"], "title": "A Multi-objective Evolutionary Algorithm Based on Bi-population with Uniform Sampling for Neural Architecture Search", "categories": ["cs.NE"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems. Published on this https URL: https://doi.org/10.1109/TNNLS.2026.3659508", "summary": "Neural architecture search (NAS) automates neural network design, improving efficiency over manual approaches. However, efficiently discovering high-performance neural network architectures that simultaneously optimize multiple objectives remains a significant challenge in NAS. Existing methods often suffer from limited population diversity and inadequate exploration of the search space, particularly in regions with extreme complexity values. To address these challenges, we propose MOEA-BUS, an innovative multi-objective evolutionary algorithm based on bi-population with uniform sampling for neural architecture search, aimed at simultaneously optimizing both accuracy and network complexity. In MOEA-BUS, a novel uniform sampling method is proposed to initialize the population, ensuring that architectures are distributed uniformly across the objective space. Furthermore, to enhance exploration, we deploy a bi-population framework where two populations evolve synergistically, facilitating comprehensive search space coverage. Experiments on CIFAR-10 and ImageNet demonstrate MOEA-BUS's superiority, achieving top-1 accuracies of 98.39% on CIFAR-10, and 80.03% on ImageNet. Notably, it achieves 78.28% accuracy on ImageNet with only 446M MAdds. Ablation studies confirm that both uniform sampling and bi-population mechanisms enhance population diversity and performance. Additionally, in terms of the Kendall's tau coefficient, the SVM achieves an improvement of at least 0.035 compared to the other three commonly used machine learning models, and uniform sampling provided an enhancement of approximately 0.07.", "AI": {"tldr": "MOEA-BUS improves neural architecture search by using a uniform sampling-based bi-population evolutionary algorithm to optimize accuracy and complexity simultaneously.", "motivation": "To enhance population diversity and explore unexplored regions in NAS, solving challenges in existing methods like limited diversity and inadequate search space exploration.", "method": "Propose MOEA-BUS, a bi-population, uniform sampling-based multi-objective evolutionary algorithm for neural architecture search.", "result": "Achieved top-1 accuracies of 98.39% on CIFAR-10, 80.03% on ImageNet, and 78.28% on ImageNet with 446M MAdds. Ablation studies showed improved population diversity and SVM accuracy.", "conclusion": "MOEA-BUS effectively enhances search space exploration and diversity in NAS while optimizing multiple objectives, proving its superiority with excellent performance on datasets."}}
{"id": "2602.07195", "pdf": "https://arxiv.org/pdf/2602.07195", "abs": "https://arxiv.org/abs/2602.07195", "authors": ["Bihui Jin", "Kaiyuan Wang", "Pengyu Nie"], "title": "Automated Modernization of Machine Learning Engineering Notebooks for Reproducibility", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Interactive computational notebooks (e.g., Jupyter notebooks) are widely used in machine learning engineering (MLE) to program and share end-to-end pipelines, from data preparation to model training and evaluation. However, environment erosion-the rapid evolution of hardware and software ecosystems for machine learning-has rendered many published MLE notebooks non-reproducible in contemporary environments, hindering code reuse and scientific progress. To quantify this gap, we study 12,720 notebooks mined from 79 popular Kaggle competitions: only 35.4% remain reproducible today. Crucially, we find that environment backporting, i.e., downgrading dependencies to match the submission time, does not improve reproducibility but rather introduces additional failure modes.\n  To address environment erosion, we design and implement MLEModernizer, an LLM-driven agentic framework that treats the contemporary environment as a fixed constraint and modernizes notebook code to restore reproducibility. MLEModernizer iteratively executes notebooks, collects execution feedback, and applies targeted fixes in three types: error-repair, runtime-reduction, and score-calibration. Evaluated on 7,402 notebooks that are non-reproducible under the baseline environment, MLEModernizer makes 5,492 (74.2%) reproducible. MLEModernizer enables practitioners to validate, reuse, and maintain MLE artifacts as the hardware and software ecosystems continue to evolve.", "AI": {"tldr": "The paper introduces MLEModernizer, a framework to restore the reproducibility of outdated machine learning (MLE) notebooks in contemporary environments using an iterative and error-repair approach.", "motivation": "The motivation stems from the issue of environment erosion, which makes previously functional MLE notebooks non-reproducible due to changes in hardware and software ecosystems, hindering code reusability and scientific progress.", "method": "The authors developed MLEModernizer, a framework leveraging large language models to iteratively update and debug notebooks to fit current environments, focusing on three types of fixes: error-repair, runtime-reduction, and score-calibration.", "result": "Of the 7,402 non-reproducible notebooks tested, MLEModernizer restored reproducibility to 74.2% (5,492 notebooks), demonstrating its effectiveness in addressing this challenge.", "conclusion": "MLEModernizer offers a viable path for modernizing MLE artifacts, enabling effective validation, reuse, and maintenance of computational notebooks despite evolving environments."}}
{"id": "2602.06995", "pdf": "https://arxiv.org/pdf/2602.06995", "abs": "https://arxiv.org/abs/2602.06995", "authors": ["Konstantinos Gounis", "Sotiris A. Tegos", "Dimitrios Tyrovolas", "Panagiotis D. Diamantoulakis", "George K. Karagiannidis"], "title": "When Simultaneous Localization and Mapping Meets Wireless Communications: A Survey", "categories": ["cs.RO", "cs.CV", "cs.IT", "cs.MA"], "comment": null, "summary": "The availability of commercial wireless communication and sensing equipment combined with the advancements in intelligent autonomous systems paves the way towards robust joint communications and simultaneous localization and mapping (SLAM). This paper surveys the state-of-the-art in the nexus of SLAM and Wireless Communications, attributing the bidirectional impact of each with a focus on visual SLAM (V-SLAM) integration. We provide an overview of key concepts related to wireless signal propagation, geometric channel modeling, and radio frequency (RF)-based localization and sensing. In addition to this, we show image processing techniques that can detect landmarks, proactively predicting optimal paths for wireless channels. Several dimensions are considered, including the prerequisites, techniques, background, and future directions and challenges of the intersection between SLAM and wireless communications. We analyze mathematical approaches such as probabilistic models, and spatial methods for signal processing, as well as key technological aspects. We expose techniques and items towards enabling a highly effective retrieval of the autonomous robot state. Among other interesting findings, we observe that monocular V-SLAM would benefit from RF relevant information, as the latter can serve as a proxy for the scale ambiguity resolution. Conversely, we find that wireless communications in the context of 5G and beyond can potentially benefit from visual odometry that is central in SLAM. Moreover, we examine other sources besides the camera for SLAM and describe the twofold relation with wireless communications. Finally, integrated solutions performing joint communications and SLAM are still in their infancy: theoretical and practical advancements are required to add higher-level localization and semantic perception capabilities to RF and multi-antenna technologies.", "AI": {"tldr": "This paper explores the integration of SLAM and wireless communications, particularly focusing on visual SLAM (V-SLAM), providing a comprehensive survey of current technologies, methods, and challenges.", "motivation": "To bridge the gap between SLAM and wireless communications, leveraging their bidirectional benefits to enhance autonomous system capabilities.", "method": "The paper surveys state-of-the-art methods, discussing mathematical and technological approaches like probabilistic models, spatial signal processing methods, and camera-based detection for integrating wireless signals with SLAM.", "result": "Detailed findings highlight that integrating RF data can resolve limitations in V-SLAM (e.g., scale ambiguity) and that SLAM methods like visual odometry can improve 5G and beyond technology.", "conclusion": "There is a strong potential for synergy between SLAM and wireless communications, but theoretical and practical advancements are essential for joint implementations and higher-level capabilities."}}
{"id": "2602.07190", "pdf": "https://arxiv.org/pdf/2602.07190", "abs": "https://arxiv.org/abs/2602.07190", "authors": ["Anagha Kulkarni", "Parin Rajesh Jhaveri", "Prasha Shrestha", "Yu Tong Han", "Reza Amini", "Behrouz Madahian"], "title": "Long-Context Long-Form Question Answering for Legal Domain", "categories": ["cs.CL", "cs.AI"], "comment": "EACL 2026", "summary": "Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.", "AI": {"tldr": "The paper addresses the complexity of question answering in legal documents with proposed methods to process long-context and long-form answers effectively.", "motivation": "Legal documents pose challenges like complex layouts, intricate syntax, and domain-specific vocabulary, making traditional QA systems insufficient for long-context and comprehensive answers.", "method": "A QA system is developed to deconstruct domain-specific vocabulary, parse complex layouts (handling sections and footnotes), and generate precise, long-form answers. A coverage metric is introduced to assess recall performance, and a bespoke dataset is curated with expertise from legal professionals.", "result": "Experimental results and ablation studies affirm the system's effectiveness and utility in handling legal QA challenges.", "conclusion": "The paper concludes that the developed system enhances the retrieval and comprehensive answering capability for legal documents, providing a viable solution for processing complex document contexts."}}
{"id": "2602.07017", "pdf": "https://arxiv.org/pdf/2602.07017", "abs": "https://arxiv.org/abs/2602.07017", "authors": ["Thuraya Alzubaidi", "Sana Ammar", "Maryam Alsharqi", "Islem Rekik", "Muzammil Behzad"], "title": "XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Medical image segmentation is a critical component of clinical workflows, enabling accurate diagnosis, treatment planning, and disease monitoring. However, despite the superior performance of transformer-based models over convolutional architectures, their limited interpretability remains a major obstacle to clinical trust and deployment. Existing explainable artificial intelligence (XAI) techniques, including gradient-based saliency methods and perturbation-based approaches, are often computationally expensive, require numerous forward passes, and frequently produce noisy or anatomically irrelevant explanations. To address these limitations, we propose XAI-CLIP, an ROI-guided perturbation framework that leverages multimodal vision-language model embeddings to localize clinically meaningful anatomical regions and guide the explanation process. By integrating language-informed region localization with medical image segmentation and applying targeted, region-aware perturbations, the proposed method generates clearer, boundary-aware saliency maps while substantially reducing computational overhead. Experiments conducted on the FLARE22 and CHAOS datasets demonstrate that XAI-CLIP achieves up to a 60\\% reduction in runtime, a 44.6\\% improvement in dice score, and a 96.7\\% increase in Intersection-over-Union for occlusion-based explanations compared to conventional perturbation methods. Qualitative results further confirm cleaner and more anatomically consistent attribution maps with fewer artifacts, highlighting that the incorporation of multimodal vision-language representations into perturbation-based XAI frameworks significantly enhances both interpretability and efficiency, thereby enabling transparent and clinically deployable medical image segmentation systems.", "AI": {"tldr": "XAI-CLIP, a novel framework for medical image segmentation, offers superior interpretability and efficiency by leveraging multimodal vision-language embeddings for targeted ROI-guided explanations.", "motivation": "The paper aims to target the limited interpretability of transformer-based models in medical image segmentation, which hampers clinical trust despite their superior performance over convolutional architectures.", "method": "The authors propose XAI-CLIP, which employs multimodal vision-language embeddings for region-of-interest-guided perturbation, yielding clearer saliency maps with reduced computational costs.", "result": "XAI-CLIP achieves significant performance boosts, including up to 60% runtime reduction, 44.6% improvement in dice score, and 96.7% increase in Intersection-over-Union for occlusion-based explanations, as demonstrated on the FLARE22 and CHAOS datasets.", "conclusion": "The integration of vision-language models into perturbation-based XAI frameworks facilitates transparent, interpretable, and clinically deployable medical image segmentation systems."}}
{"id": "2602.08185", "pdf": "https://arxiv.org/pdf/2602.08185", "abs": "https://arxiv.org/abs/2602.08185", "authors": ["Masanari Kimura"], "title": "Information Geometry of Absorbing Markov-Chain and Discriminative Random Walks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Discriminative Random Walks (DRWs) are a simple yet powerful tool for semi-supervised node classification, but their theoretical foundations remain fragmentary. We revisit DRWs through the lens of information geometry, treating the family of class-specific hitting-time laws on an absorbing Markov chain as a statistical manifold. Starting from a log-linear edge-weight model, we derive closed-form expressions for the hitting-time probability mass function, its full moment hierarchy, and the observed Fisher information. The Fisher matrix of each seed node turns out to be rank-one, taking the quotient by its null space yields a low-dimensional, globally flat manifold that captures all identifiable directions of the model. Leveraging the geometry, we introduce a sensitivity score for unlabeled nodes that bounds, and in one-dimensional cases attains, the maximal first-order change in DRW betweenness under unit Fisher perturbations. The score can lead to principled strategies for active label acquisition, edge re-weighting, and explanation.", "AI": {"tldr": "This paper revisits Discriminative Random Walks (DRWs) and offers a geometric framework for their analysis, providing theoretical insights and practical tools.", "motivation": "To advance the understanding and theoretical foundations of DRWs, addressing the current gaps in their usage for semi-supervised node classification.", "method": "The paper employs concepts from information geometry to derive mathematical properties (hitting-time probabilities, Fisher information, etc.) and introduces a sensitivity score for unlabeled nodes.", "result": "The authors deduce closed-form expressions for hitting-time probabilities, establish globally flat manifold representations, and propose a sensitivity score for active learning strategies.", "conclusion": "The geometric understanding enhances the application of DRWs, enabling refined strategies for node classification, edge re-weighting, and explanation in graph-based models."}}
{"id": "2602.07253", "pdf": "https://arxiv.org/pdf/2602.07253", "abs": "https://arxiv.org/abs/2602.07253", "authors": ["Litian Liu", "Reza Pourreza", "Yubing Jian", "Yao Qin", "Roland Memisevic"], "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.", "AI": {"tldr": "The paper investigates hallucination detection in large language models (LLMs) by reframing it as out-of-distribution (OOD) detection, providing training-free and accurate detectors for reasoning tasks.", "motivation": "There is a need to improve hallucination detection in LLMs, especially for reasoning tasks, as current methods underperform compared to simpler question-answering tasks.", "method": "The authors propose treating next-token prediction as a classification task to apply OOD detection techniques, adapting them for structural differences in LLMs.", "result": "OOD-based methods showed strong accuracy in detecting hallucinations during reasoning tasks without requiring additional training or data.", "conclusion": "Reframing hallucination detection as OOD detection offers a scalable and promising strategy for improving the safety and reliability of LLMs."}}
{"id": "2602.07078", "pdf": "https://arxiv.org/pdf/2602.07078", "abs": "https://arxiv.org/abs/2602.07078", "authors": ["Yingru Li", "Jiawei Xu", "Ziniu Li", "Jiacai Liu", "Wei Liu", "Yuxuan Tong", "Longtao Zheng", "Zhenghai Xue", "Yaxiang Zhang", "Tianle Cai", "Ge Zhang", "Qian Liu", "Baoxiang Wang"], "title": "The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) for Large Language Models (LLMs) often suffers from training collapse in long-horizon tasks due to exploding gradient variance. To mitigate this, a baseline is commonly introduced for advantage computation; however, traditional value models remain difficult to optimize, and standard group-based baselines overlook sequence heterogeneity. Although classic optimal baseline theory can achieve global variance reduction, it neglects token heterogeneity and requires prohibitive gradient-based computation. In this work, we derive the Optimal Token Baseline (OTB) from first principles, proving that gradient updates should be weighted inversely to their cumulative gradient norm. To ensure efficiency, we propose the Logit-Gradient Proxy that approximates the gradient norm using only forward-pass probabilities. Our method achieves training stability and matches the performance of large group sizes ($N=32$) with only $N=4$, reducing token consumption by over 65% across single-turn and tool-integrated reasoning tasks.", "AI": {"tldr": "The paper addresses training collapse in long-horizon RL tasks for LLMs by introducing the Optimal Token Baseline (OTB). This method reduces gradient variance and improves training efficiency.", "motivation": "The motivation is to mitigate training collapse caused by exploding gradient variance in long-horizon RL tasks for LLMs. Traditional approaches either overlook sequence heterogeneity or are computationally prohibitive, necessitating a more efficient solution.", "method": "The authors derive the Optimal Token Baseline (OTB), showing gradient updates should be weighted inversely to cumulative gradient norms. They also propose the Logit-Gradient Proxy, which approximates these norms using forward-pass probabilities.", "result": "The proposed method ensures training stability, achieving comparable performance to larger group sizes ($N=32$) with significantly smaller groups ($N=4$), thereby reducing token consumption by over 65%.", "conclusion": "This paper provides a novel and efficient solution to address gradient variance issues in RL for LLMs, improving training efficiency and stability across various tasks."}}
{"id": "2602.07131", "pdf": "https://arxiv.org/pdf/2602.07131", "abs": "https://arxiv.org/abs/2602.07131", "authors": ["Javier Salazar Cavazos", "Maximillian Egan", "Krisanne Litinas", "Benjamin Hampstead", "Scott Peltier"], "title": "Behavior Score Prediction in Resting-State Functional MRI by Deep State Space Modeling", "categories": ["eess.SP", "q-bio.NC"], "comment": null, "summary": "Early clinical assessment of Alzheimer's disease relies on behavior scores that measure a subject's language, memory, and cognitive skills. On the medical imaging side, functional magnetic resonance imaging has provided invaluable insights into the neural pathways underlying Alzheimer's disease. While prior studies have used resting-state functional MRI by extracting functional connectivity matrices, these approaches neglect the temporal dynamics inherent in functional data. In this work, we present a deep state space modeling framework that directly leverages the blood-oxygenation-level-dependent time series to learn a sparse collection of brain regions to predict behavior scores. Our model extracts temporal features that encapsulate nuanced patterns of intrinsic brain activity, thereby enhancing predictive performance compared to traditional connectivity methods. We identify specific brain regions that are most predictive of cognitive impairment through experiments on data provided by the Michigan Alzheimer's Disease Research Center, providing new insights into the neural substrates of early Alzheimer's pathology. These findings have important implications for the possible development of risk monitoring and intervention strategies in Alzheimer's disease.", "AI": {"tldr": "This paper introduces a deep learning framework using fMRI time series to predict behavior scores for early Alzheimer's diagnosis, emphasizing temporal dynamics and identifying key brain regions. ", "motivation": "Traditional methods for early Alzheimer's diagnosis focus on behavior scores and functional connectivity matrices from fMRI, which fail to effectively capture temporal dynamics in brain data.", "method": "The authors propose a deep state space modeling framework to analyze blood-oxygenation-level-dependent (BOLD) time series from fMRI, extracting sparse brain regions and temporal features for behavior score prediction.", "result": "The model outperforms traditional functional connectivity methods in predicting behavior scores and identifies specific brain regions linked to cognitive impairment based on Michigan Alzheimer's Disease Research Center data.", "conclusion": "The study advances Alzheimer's research by highlighting intrinsic brain activity patterns for better diagnosis, offering insights into neural mechanisms and aiding risk monitoring and intervention strategy development."}}
{"id": "2602.08619", "pdf": "https://arxiv.org/pdf/2602.08619", "abs": "https://arxiv.org/abs/2602.08619", "authors": ["Laura-Maria Cornei", "Mihaela-Elena Breab\u0103n"], "title": "Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "Paper accepted to the International Conference on Applications of Evolutionary Computation (EvoApplications) 2026", "summary": "This paper investigates the impact of hybridizing a multi-modal Genetic Algorithm with a Graph Neural Network for timetabling optimization. The Graph Neural Network is designed to encapsulate general domain knowledge to improve schedule quality, while the Genetic Algorithm explores different regions of the search space and integrates the deep learning model as an enhancement operator to guide the solution search towards optimality. Initially, both components of the hybrid technique were designed, developed, and optimized independently to solve the tackled task. Multiple experiments were conducted on Staff Rostering, a well-known timetabling problem, to compare the proposed hybridization with the standalone optimized versions of the Genetic Algorithm and Graph Neural Network. The experimental results demonstrate that the proposed hybridization brings statistically significant improvements in both the time efficiency and solution quality metrics, compared to the standalone methods. To the best of our knowledge, this work proposes the first hybridization of a Genetic Algorithm with a Graph Neural Network for solving timetabling problems.", "AI": {"tldr": "The paper proposes a novel hybrid approach combining a Genetic Algorithm and a Graph Neural Network to enhance the optimization of timetabling problems.", "motivation": "The researchers aim to address challenges in timetabling optimization by combining the exploration strength of Genetic Algorithms with the knowledge encoding abilities of Graph Neural Networks.", "method": "The hybrid technique separately designs and optimizes a Genetic Algorithm and Graph Neural Network, then integrates the Graph Neural Network as an enhancement operator into the Genetic Algorithm for optimal solution search.", "result": "Experiments on the Staff Rostering problem show statistically significant improvements in both time efficiency and solution quality when using the hybrid model compared to using the standalone methods.", "conclusion": "This work successfully demonstrates that integrating a Genetic Algorithm with a Graph Neural Network can enhance timetabling optimization, marking it as a novel and effective approach in this domain."}}
{"id": "2602.07412", "pdf": "https://arxiv.org/pdf/2602.07412", "abs": "https://arxiv.org/abs/2602.07412", "authors": ["Raula Gaikovina Kula", "Christoph Treude", "Xing Hu", "Sebastian Baltes", "Earl T. Barr", "Kelly Blincoe", "Fabio Calefato", "Junjie Chen", "Marc Cheong", "Youmei Fan", "Daniel M. German", "Marco Gerosa", "Jin L. C. Guo", "Shinpei Hayashi", "Robert Hirschfeld", "Reid Holmes", "Yintong Huo", "Takashi Kobayashi", "Michele Lanza", "Zhongxin Liu", "Olivier Nourry", "Nicole Novielli", "Denys Poshyvanyk", "Shinobu Saito", "Kazumasa Shimari", "Igor Steinmacher", "Mairieli Wessel", "Markus Wagner", "Annie Vella", "Laurie Williams", "Xin Xia"], "title": "Forecasting Developer Environments with GenAI: A Research Perspective", "categories": ["cs.SE"], "comment": "IDE Workshop", "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222, a four-day intensive research meeting. Four themes emerged as areas of interest for researchers and practitioners.", "AI": {"tldr": "This paper discusses the influence of Generative Artificial Intelligence (GenAI) on integrated development environments (IDEs) and identifies challenges and opportunities through discussions with 33 experts.", "motivation": "To understand how GenAI is transforming the Human-AI interaction in IDEs and identify its challenges and opportunities within software engineering, AI, and human-computer interaction fields.", "method": "33 experts convened during the Shonan Meeting 222 for four days to discuss challenges and opportunities regarding GenAI applications in IDEs. Major themes were identified during this intensive research meeting.", "result": "Four major themes emerged, highlighting areas of interest for researchers and practitioners related to GenAI's role and impact on IDEs.", "conclusion": "The paper emphasizes the transformative potential of GenAI in IDEs, urging further exploration into its challenges and opportunities to benefit the software development process."}}
{"id": "2602.07005", "pdf": "https://arxiv.org/pdf/2602.07005", "abs": "https://arxiv.org/abs/2602.07005", "authors": ["Shifa Sulaiman", "Tobias Jensen", "Francesco Schetter", "Simon B\u00f8gh"], "title": "Admittance-Based Motion Planning with Vision-Guided Initialization for Robotic Manipulators in Self-Driving Laboratories", "categories": ["cs.RO"], "comment": null, "summary": "Self driving laboratories (SDLs) are highly automated research environments that leverage advanced technologies to conduct experiments and analyze data with minimal human involvement. These environments often involve delicate laboratory equipment, unpredictable environmental interactions, and occasional human intervention, making compliant and force aware control essential for ensuring safety, adaptability, and reliability. This paper introduces a motion-planning framework centered on admittance control to enable adaptive and compliant robotic manipulation. Unlike conventional schemes, the proposed approach integrates an admittance controller directly into trajectory execution, allowing the manipulator to dynamically respond to external forces during interaction. This capability enables human operators to override or redirect the robot's motion in real time. A vision algorithm based on structured planar pose estimation is employed to detect and localize textured planar objects through feature extraction, homography estimation, and depth fusion, thereby providing an initial target configuration for motion planning. The vision based initialization establishes the reference trajectory, while the embedded admittance controller ensures that trajectory execution remains safe, adaptive, and responsive to external forces or human intervention. The proposed strategy is validated using textured image detection as a proof of concept. Future work will extend the framework to SDL environments involving transparent laboratory objects where compliant motion planning can further enhance autonomy, safety, and human-robot collaboration.", "AI": {"tldr": "The paper presents a framework for adaptive robotic manipulation using admittance control and vision-based initialization to ensure safety and human-robot collaboration.", "motivation": "To address challenges in self-driving laboratories that require compliant and adaptable robotic manipulation in environments with unpredictable interactions and human intervention.", "method": "Integrating admittance control into motion-planning and trajectory execution, enhanced by a vision algorithm for detecting and localizing planar objects.", "result": "The framework was validated using textured image detection, demonstrating adaptability, safety, and responsiveness during robotic manipulation.", "conclusion": "The approach shows potential for improving autonomy and human-robot interaction in SDLs, with plans to extend its application to environments involving transparent objects."}}
{"id": "2602.07211", "pdf": "https://arxiv.org/pdf/2602.07211", "abs": "https://arxiv.org/abs/2602.07211", "authors": ["Ju Lin", "Jing Pan", "Ruizhi Li", "Ming Sun", "Yuzong Liu", "Alaa Hassan", "Jing Zheng", "Florian Metze"], "title": "Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.", "AI": {"tldr": "The paper explores how to enable large language models (LLMs) with directional and multi-talker speech understanding capabilities using multi-microphone arrays embedded in smart glasses.", "motivation": "Existing speech LLMs are primarily trained on single-channel, single-talker data, making them less suitable for multi-talker and multi-channel environments within contexts like smart glasses.", "method": "The paper proposes two approaches: (1) a cascaded system using a source separation module, and (2) an end-to-end serialized output training system, both leveraging multi-microphone arrays for streaming directional speech understanding.", "result": "Experimental findings show that both methods significantly enhance LLMs' capabilities in speech recognition and translation for directional, multi-talker scenarios.", "conclusion": "The proposed approaches successfully integrate directional multi-talker capabilities into LLMs for smart glasses use cases, demonstrating strong performance and paving the way for improved speech understanding technologies."}}
{"id": "2602.07019", "pdf": "https://arxiv.org/pdf/2602.07019", "abs": "https://arxiv.org/abs/2602.07019", "authors": ["Elaheh Sabziyan Varnousfaderani", "Syed A. M. Shihab", "Jonathan King"], "title": "Deep Learning Based Multi-Level Classification for Aviation Safety", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Bird strikes pose a significant threat to aviation safety, often resulting in loss of life, severe aircraft damage, and substantial financial costs. Existing bird strike prevention strategies primarily rely on avian radar systems that detect and track birds in real time. A major limitation of these systems is their inability to identify bird species, an essential factor, as different species exhibit distinct flight behaviors, and altitudinal preference. To address this challenge, we propose an image-based bird classification framework using Convolutional Neural Networks (CNNs), designed to work with camera systems for autonomous visual detection. The CNN is designed to identify bird species and provide critical input to species-specific predictive models for accurate flight path prediction. In addition to species identification, we implemented dedicated CNN classifiers to estimate flock formation type and flock size. These characteristics provide valuable supplementary information for aviation safety. Specifically, flock type and size offer insights into collective flight behavior, and trajectory dispersion . Flock size directly relates to the potential impact severity, as the overall damage risk increases with the combined kinetic energy of multiple birds.", "AI": {"tldr": "The paper addresses aviation safety by proposing a CNN-based framework for bird species, flock type, and size identification to supplement predictive models for bird strike prevention.", "motivation": "Bird strikes pose risks like human fatalities, aircraft damage, and economic losses. Existing radar systems cannot identify bird species, vital for predicting flight behaviors and collision risks.", "method": "The study develops Convolutional Neural Networks (CNNs) to classify bird species, determine flock formation types, and estimate flock size using image-based inputs with camera systems.", "result": "The system identifies species, flock type, and flock size, providing vital behavioral data and predicting trajectories for improved aviation safety measures.", "conclusion": "This novel image-based classification approach empowers aviation safety systems by integrating species-specific data, enhancing predictions, and mitigating bird strike risks."}}
{"id": "2602.08243", "pdf": "https://arxiv.org/pdf/2602.08243", "abs": "https://arxiv.org/abs/2602.08243", "authors": ["Wei Guo", "Yuchen Zhu", "Xiaochen Du", "Juno Nam", "Yongxin Chen", "Rafael G\u00f3mez-Bombarelli", "Guan-Horng Liu", "Molei Tao", "Jaemoo Choi"], "title": "Discrete Adjoint Schr\u00f6dinger Bridge Sampler", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Learning discrete neural samplers is challenging due to the lack of gradients and combinatorial complexity. While stochastic optimal control (SOC) and Schr\u00f6dinger bridge (SB) provide principled solutions, efficient SOC solvers like adjoint matching (AM), which excel in continuous domains, remain unexplored for discrete spaces. We bridge this gap by revealing that the core mechanism of AM is $\\mathit{state}\\text{-}\\mathit{space~agnostic}$, and introduce $\\mathbf{discrete~ASBS}$, a unified framework that extends AM and adjoint Schr\u00f6dinger bridge sampler (ASBS) to discrete spaces. Theoretically, we analyze the optimality conditions of the discrete SB problem and its connection to SOC, identifying a necessary cyclic group structure on the state space to enable this extension. Empirically, discrete ASBS achieves competitive sample quality with significant advantages in training efficiency and scalability.", "AI": {"tldr": "This paper introduces discrete ASBS to extend efficient sampling methods like adjoint Schr\u00f6dinger bridge samplers (ASBS) to discrete state spaces while preserving sample quality and improving computational efficiency.", "motivation": "The motivation is to address challenges in learning discrete neural samplers, such as the absence of gradients and combinatorial complexity, and to adapt efficient SOC methods like adjoint matching (AM), which are well-suited to continuous spaces, to discrete domains.", "method": "The paper proposes discrete ASBS, a unified framework designed to extend adjoint matching (AM) and adjoint Schr\u00f6dinger bridge samplers (ASBS) to handle discrete spaces by analyzing the state-space-agnostic mechanism and utilizing cyclic group structures.", "result": "Discrete ASBS achieves competitive sample quality while offering significant improvements in training efficiency and scalability compared to existing approaches.", "conclusion": "Discrete ASBS serves as an efficient solution for discrete neural sampling by merging optimal control methods with capabilities to handle discrete spaces, paving the way for better computational performance in such domains."}}
{"id": "2602.07259", "pdf": "https://arxiv.org/pdf/2602.07259", "abs": "https://arxiv.org/abs/2602.07259", "authors": ["Cheol Woo Kim", "Davin Choo", "Tzeh Yuan Neoh", "Milind Tambe"], "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective", "categories": ["cs.AI"], "comment": null, "summary": "As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.", "AI": {"tldr": "This paper introduces a novel AI safety framework based on Stackelberg Security Games (SSGs), emphasizing proactive, game-theoretic oversight to address adversarial challenges across the AI lifecycle.", "motivation": "AI's increasing autonomy raises significant safety concerns, especially due to dynamic adversarial incentives in data collection, evaluation, and deployment, suggesting that existing static-focused safety frameworks are insufficient.", "method": "The authors leverage the Stackelberg Security Games framework for modeling strategic interactions between defenders and adversaries in the AI development and deployment process, along with examples in training, evaluation, and multi-model deployment.", "result": "This game-theoretic approach demonstrates how structured models can improve incentive design and robustness across different stages of AI oversight, tackling adversarial issues effectively.", "conclusion": "The proposed framework integrates algorithmic alignment with institutional oversight, paving the way for proactive, risk-aware, and manipulation-resistant AI safety strategies."}}
{"id": "2602.07088", "pdf": "https://arxiv.org/pdf/2602.07088", "abs": "https://arxiv.org/abs/2602.07088", "authors": ["Muhammad Zafar Iqbal", "Ghazanfar Farooq Siddiqui", "Anwar Ul Haq", "Imran Razzak"], "title": "Attention-Driven Framework for Non-Rigid Medical Image Registration", "categories": ["cs.LG"], "comment": null, "summary": "Deformable medical image registration is a fundamental task in medical image analysis with applications in disease diagnosis, treatment planning, and image-guided interventions. Despite significant advances in deep learning based registration methods, accurately aligning images with large deformations while preserving anatomical plausibility remains a challenging task. In this paper, we propose a novel Attention-Driven Framework for Non-Rigid Medical Image Registration (AD-RegNet) that employs attention mechanisms to guide the registration process. Our approach combines a 3D UNet backbone with bidirectional cross-attention, which establishes correspondences between moving and fixed images at multiple scales. We introduce a regional adaptive attention mechanism that focuses on anatomically relevant structures, along with a multi-resolution deformation field synthesis approach for accurate alignment. The method is evaluated on two distinct datasets: DIRLab for thoracic 4D CT scans and IXI for brain MRI scans, demonstrating its versatility across different anatomical structures and imaging modalities. Experimental results demonstrate that our approach achieves performance competitive with state-of-the-art methods on the IXI and DIRLab datasets. The proposed method maintains a favorable balance between registration accuracy and computational efficiency, making it suitable for clinical applications. A comprehensive evaluation using normalized cross-correlation (NCC), mean squared error (MSE), structural similarity (SSIM), Jacobian determinant, and target registration error (TRE) indicates that attention-guided registration improves alignment accuracy while ensuring anatomically plausible deformations.", "AI": {"tldr": "The paper introduces AD-RegNet, a novel attention-based framework for medical image registration, which achieves accurate and anatomically plausible alignments for images with large deformations.", "motivation": "To improve the accuracy and anatomical plausibility of deformable medical image registration, particularly for images with large deformations.", "method": "The paper proposes AD-RegNet, which integrates a 3D UNet backbone, bidirectional cross-attention, regional adaptive attention for anatomically relevant structures, and a multi-resolution deformation field synthesis approach.", "result": "Experimental results on the DIRLab and IXI datasets demonstrate that AD-RegNet achieves competitive performance, balancing registration accuracy and computational efficiency across different imaging modalities.", "conclusion": "AD-RegNet offers a clinically suitable registration method that improves alignment accuracy and anatomical plausibility through attention mechanisms, validated by comprehensive evaluation metrics."}}
{"id": "2602.07233", "pdf": "https://arxiv.org/pdf/2602.07233", "abs": "https://arxiv.org/abs/2602.07233", "authors": ["Eric V. Strobl"], "title": "Extracting Root-Causal Brain Activity Driving Psychopathology from Resting State fMRI", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Neuroimaging studies of psychiatric disorders often correlate imaging patterns with diagnostic labels or composite symptom scores, yielding diffuse associations that obscure underlying mechanisms. We instead seek to identify root-causal maps -- localized BOLD disturbances that initiate pathological cascades -- and to link them selectively to symptom dimensions. We introduce a bilevel structural causal model that connects between-subject symptom structure to within-subject resting-state fMRI via independent latent sources with localized direct effects. Based on this model, we develop SOURCE (Symptom-Oriented Uncovering of Root-Causal Elements), a procedure that links interpretable symptom axes to a parsimonious set of localized drivers. Experiments show that SOURCE recovers localized maps consistent with root-causal BOLD drivers and increases interpretability and anatomical specificity relative to existing comparators.", "AI": {"tldr": "This paper introduces SOURCE, a model to identify root-causal brain disturbances linked to psychiatric symptoms using fMRI data, offering enhanced interpretability and specificity.", "motivation": "Traditional neuroimaging analyses often yield broad associations between imaging patterns and psychiatric symptoms, failing to illuminate the underlying mechanisms. This paper aims to pinpoint specific localized brain disturbances that drive symptoms in psychiatric disorders.", "method": "The authors developed a bilevel structural causal model in which between-subject symptom structures are connected to within-subject resting-state fMRI data via independent latent sources with localized effects. They propose SOURCE, a procedure implementing this model.", "result": "SOURCE was shown to accurately recover localized BOLD patterns consistent with root-causal disturbances while offering improved interpretability and anatomical precision compared to existing methods.", "conclusion": "The SOURCE approach provides a framework for linking specific psychiatric symptom dimensions to localized brain dysfunctions, improving understanding of brain-symptom relationships."}}
{"id": "2602.08199", "pdf": "https://arxiv.org/pdf/2602.08199", "abs": "https://arxiv.org/abs/2602.08199", "authors": ["Cong Wang", "Yusheng Zheng"], "title": "Fork, Explore, Commit: OS Primitives for Agentic Exploration", "categories": ["cs.OS", "cs.DC"], "comment": null, "summary": "AI agents increasingly perform agentic exploration: pursuing multiple solution paths in parallel and committing only the successful one. Because each exploration path may modify files and spawn processes, agents require isolated environments with atomic commit and rollback semantics for both filesystem state and process state. We introduce the branch context, a new OS abstraction that provides: (1) copy-on-write state isolation with independent filesystem views and process groups, (2) a structured lifecycle of fork, explore, and commit/abort, (3) first-commit-wins resolution that automatically invalidates sibling branches, and (4) nestable contexts for hierarchical exploration. We realize branch contexts in Linux through two complementary components. First, BranchFS is a FUSE-based filesystem that gives each branch context an isolated copy-on-write workspace, with O(1) creation, atomic commit to the parent, and automatic sibling invalidation, all without root privileges. BranchFS is open sourced in https://github.com/multikernel/branchfs. Second, branch() is a proposed Linux syscall that spawns processes into branch contexts with reliable termination, kernel-enforced sibling isolation, and first-commit-wins coordination. Preliminary evaluation of BranchFS shows sub-350 us branch creation independent of base filesystem size, and modification-proportional commit overhead (under 1 ms for small changes).", "AI": {"tldr": "The paper introduces 'branch context,' a new OS abstraction for isolated execution and parallel exploration.", "motivation": "The motivation is to meet the need for isolated system environments for AI agents performing parallel solution exploration and manipulation of files and processes.", "method": "The authors propose 'branch context,' combining a new filesystem (BranchFS) for copy-on-write isolation and a suggested Linux syscall (branch()) for reliable process isolation and synchronization.", "result": "BranchFS provides O(1) branch creation, atomic commit operations, and efficient sibling branch invalidation, with evaluation showing quick operations for small changes.", "conclusion": "Branch contexts enhance AI agent capabilities for parallel exploration by offering structured, isolated environments with reduced overhead. It's an open-source project for broader applicability."}}
{"id": "2602.08825", "pdf": "https://arxiv.org/pdf/2602.08825", "abs": "https://arxiv.org/abs/2602.08825", "authors": ["Tomohiro Harada", "Enrique Alba", "Gabriel Luque"], "title": "A Methodology for Effective Surrogate Learning in Complex Optimization", "categories": ["cs.NE"], "comment": null, "summary": "Solving complex problems requires continuous effort in developing theory and practice to cope with larger, more difficult scenarios. Working with surrogates is normal for creating a proxy that realistically models the problem into the computer. Thus, the question of how to best define and characterize such a surrogate model is of the utmost importance. In this paper, we introduce the PTME methodology to study deep learning surrogates by analyzing their Precision, Time, Memory, and Energy consumption. We argue that only a combination of numerical and physical performance can lead to a surrogate that is both a trusted scientific substitute for the real problem and an efficient experimental artifact for scalable studies. Here, we propose different surrogates for a real problem in optimally organizing the network of traffic lights in European cities and perform a PTME study on the surrogates' sampling methods, dataset sizes, and resource consumption. We further use the built surrogates in new optimization metaheuristics for decision-making in real cities. We offer better techniques and conclude that the PTME methodology can be used as a guideline for other applications and solvers.", "AI": {"tldr": "The paper introduces the PTME methodology to evaluate and improve deep learning surrogate models, focusing on precision, time, memory, and energy.", "motivation": "To better define and evaluate surrogate models that realistically simulate complex problems on computers and ensure they are both scientifically reliable and efficient in performance.", "method": "The authors developed the PTME methodology and applied it to analyze surrogate models, exploring factors such as sampling methods, dataset sizes, and resource consumption for optimizing traffic light networks in European cities.", "result": "The PTME study led to improved surrogate models and more efficient metaheuristics for decision-making in real-world traffic networks.", "conclusion": "The PTME methodology is a valuable framework for designing and evaluating surrogate models, applicable across various domains to enhance both scientific and computational efficiency."}}
{"id": "2602.07457", "pdf": "https://arxiv.org/pdf/2602.07457", "abs": "https://arxiv.org/abs/2602.07457", "authors": ["Qinglin Zhu", "Tianyu Chen", "Shuai Lu", "Lei Ji", "Runcong Zhao", "Murong Ma", "Xiangxiang Dai", "Yulan He", "Lin Gui", "Peng cheng", "Yeyun Gong"], "title": "Pull Requests as a Training Signal for Repo-Level Code Editing", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Repository-level code editing requires models to understand complex dependencies and execute precise multi-file modifications across a large codebase. While recent gains on SWE-bench rely heavily on complex agent scaffolding, it remains unclear how much of this capability can be internalised via high-quality training signals. To address this, we propose Clean Pull Request (Clean-PR), a mid-training paradigm that leverages real-world GitHub pull requests as a training signal for repository-level editing. We introduce a scalable pipeline that converts noisy pull request diffs into Search/Replace edit blocks through reconstruction and validation, resulting in the largest publicly available corpus of 2 million pull requests spanning 12 programming languages. Using this training signal, we perform a mid-training stage followed by an agentless-aligned supervised fine-tuning process with error-driven data augmentation. On SWE-bench, our model significantly outperforms the instruction-tuned baseline, achieving absolute improvements of 13.6% on SWE-bench Lite and 12.3% on SWE-bench Verified. These results demonstrate that repository-level code understanding and editing capabilities can be effectively internalised into model weights under a simplified, agentless protocol, without relying on heavy inference-time scaffolding.", "AI": {"tldr": "The paper proposes Clean-PR, a training paradigm using GitHub pull requests to enhance models for repository-level code editing, achieving significant improvements on SWE-bench without complex inference-time setups.", "motivation": "To improve repository-level code editing capabilities in models without relying on complex agent scaffolding by using high-quality training signals from pull requests.", "method": "The authors develop Clean-PR, a pipeline that processes pull request diffs from GitHub into structured Search/Replace edit blocks, forming a large training dataset for mid-training and fine-tuning, augmented with error-driven adjustments.", "result": "Their model, trained with this paradigm, outperforms baseline models on SWE-bench, showing 13.6% and 12.3% improvements in Lite and Verified benchmarks, respectively.", "conclusion": "Repository-level code editing can be effectively integrated into model training using real-world pull requests, eliminating the need for heavy inference-time scaffolding while significantly improving performance."}}
{"id": "2602.07007", "pdf": "https://arxiv.org/pdf/2602.07007", "abs": "https://arxiv.org/abs/2602.07007", "authors": ["Dongsheng Chen", "Yuxuan Li", "Yi Lin", "Guanhua Chen", "Jiaxin Zhang", "Xiangyu Zhao", "Lei Ma", "Xin Yao", "Xuetao Wei"], "title": "ARGOS: Automated Functional Safety Requirement Synthesis for Embodied AI via Attribute-Guided Combinatorial Reasoning", "categories": ["cs.RO"], "comment": null, "summary": "Ensuring functional safety is essential for the deployment of Embodied AI in complex open-world environments. However, traditional Hazard Analysis and Risk Assessment (HARA) methods struggle to scale in this domain. While HARA relies on enumerating risks for finite and pre-defined function lists, Embodied AI operates on open-ended natural language instructions, creating a challenge of combinatorial interaction risks. Whereas Large Language Models (LLMs) have emerged as a promising solution to this scalability challenge, they often lack physical grounding, yielding semantically superficial and incoherent hazard descriptions. To overcome these limitations, we propose a new framework ARGOS (AttRibute-Guided cOmbinatorial reaSoning), which bridges the gap between open-ended user instructions and concrete physical attributes. By dynamically decomposing entities from instructions into these fine-grained properties, ARGOS grounds LLM reasoning in causal risk factors to generate physically plausible hazard scenarios. It then instantiates abstract safety standards, such as ISO 13482, into context-specific Functional Safety Requirements (FSRs) by integrating these scenarios with robot capabilities. Extensive experiments validate that ARGOS produces high-quality FSRs and outperforms baselines in identifying long-tail risks. Overall, this work paves the way for systematic and grounded functional safety requirement generation, a critical step toward the safe industrial deployment of Embodied AI.", "AI": {"tldr": "The paper introduces ARGOS, a framework that enhances functional safety analysis in Embodied AI by addressing scalability and grounding issues in hazard assessment.", "motivation": "Traditional Hazard Analysis and Risk Assessment methods do not scale well in Embodied AI due to its open-ended natural language instructions and combinatorial risks. Large Language Models, while helpful, lack physical grounding, leading to superficial hazard descriptions.", "method": "The framework, ARGOS, decomposes instructions into fine-grained physical attributes, enabling causal and context-specific hazard analysis. It integrates these analyses with safety standards like ISO 13482 to create Functional Safety Requirements (FSRs).", "result": "ARGOS generates high-quality FSRs and outperforms other methods in identifying rare and complex risks.", "conclusion": "ARGOS demonstrates systematic and grounded functional safety generation, advancing the safe deployment of Embodied AI and addressing scalability and grounding challenges."}}
{"id": "2602.07319", "pdf": "https://arxiv.org/pdf/2602.07319", "abs": "https://arxiv.org/abs/2602.07319", "authors": ["Savan Doshi"], "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.", "AI": {"tldr": "This paper proposes a risk-sensitive evaluation framework to assess hallucinations in medical language models, focusing on the potential impact of risk-bearing language instead of factual correctness.", "motivation": "The study is motivated by the inadequacy of existing hallucination standards in evaluating the varied and potentially harmful impacts of language model outputs in patient-facing medical contexts.", "method": "The paper introduces a framework that evaluates hallucinations based on the presence of risk-bearing language, applies it to three language models using safety stress test prompts, and combines risk scoring with relevance measures to identify dangerous outputs.", "result": "The analysis reveals significant differences in risk profiles among models with similar surface-level behavior and exposes the limitations of standard evaluation metrics in identifying these differences.", "conclusion": "The paper emphasizes the need for risk sensitivity in hallucination evaluation and highlights the critical importance of task and prompt design to improve evaluation validity."}}
{"id": "2602.07025", "pdf": "https://arxiv.org/pdf/2602.07025", "abs": "https://arxiv.org/abs/2602.07025", "authors": ["Daniele Savietto", "Declan Campbell", "Andr\u00e9 Panisson", "Marco Nurisso", "Giovanni Petri", "Jonathan D. Cohen", "Alan Perotti"], "title": "The Geometry of Representational Failures in Vision Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) exhibit puzzling failures in multi-object visual tasks, such as hallucinating non-existent elements or failing to identify the most similar objects among distractions. While these errors mirror human cognitive constraints, such as the \"Binding Problem\", the internal mechanisms driving them in artificial systems remain poorly understood. Here, we propose a mechanistic insight by analyzing the representational geometry of open-weight VLMs (Qwen, InternVL, Gemma), comparing methodologies to distill \"concept vectors\" - latent directions encoding visual concepts. We validate our concept vectors via steering interventions that reliably manipulate model behavior in both simplified and naturalistic vision tasks (e.g., forcing the model to perceive a red flower as blue). We observe that the geometric overlap between these vectors strongly correlates with specific error patterns, offering a grounded quantitative framework to understand how internal representations shape model behavior and drive visual failures.", "AI": {"tldr": "The paper investigates why Vision-Language Models (VLMs) fail in specific multi-object tasks, linking the issues to their internal representational geometry.", "motivation": "The study aims to explore why VLMs exhibit errors like hallucinations and object misidentification, paralleling human cognitive limitations like the Binding Problem.", "method": "The authors analyzed the representational geometry in VLMs (Qwen, InternVL, Gemma) and introduced 'concept vectors' to study internal representations and performed experimental manipulations (steering interventions).", "result": "The research found that the overlap in representational vectors significantly correlates with error patterns in VLM behavior.", "conclusion": "Understanding the geometry of internal representations in VLMs provides a quantitative framework to explain and potentially mitigate their systematic errors."}}
{"id": "2602.08259", "pdf": "https://arxiv.org/pdf/2602.08259", "abs": "https://arxiv.org/abs/2602.08259", "authors": ["Xintao Xia", "Zhiqiu Xia", "Linjun Zhang", "Zhanrui Cai"], "title": "A Statistical Framework for Alignment with Biased AI Feedback", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Modern alignment pipelines are increasingly replacing expensive human preference labels with evaluations from large language models (LLM-as-Judge). However, AI labels can be systematically biased compared to high-quality human feedback datasets. In this paper, we develop two debiased alignment methods within a general framework that accommodates heterogeneous prompt-response distributions and external human feedback sources. Debiased Direct Preference Optimization (DDPO) augments standard DPO with a residual-based correction and density-ratio reweighting to mitigate systematic bias, while retaining DPO's computational efficiency. Debiased Identity Preference Optimization (DIPO) directly estimates human preference probabilities without imposing a parametric reward model. We provide theoretical guarantees for both methods: DDPO offers a practical and computationally efficient solution for large-scale alignment, whereas DIPO serves as a robust, statistically optimal alternative that attains the semiparametric efficiency bound. Empirical studies on sentiment generation, summarization, and single-turn dialogue demonstrate that the proposed methods substantially improve alignment efficiency and recover performance close to that of an oracle trained on fully human-labeled data.", "AI": {"tldr": "The paper presents debiased methods for aligning AI models using AI-generated labels, improving efficiency and performance close to human-labeled data.", "motivation": "AI-generated labels are biased compared to high-quality human feedback, necessitating methods to debias alignment processes.", "method": "Proposed Debiased Direct Preference Optimization (DDPO) using corrections and reweighting, and Debiased Identity Preference Optimization (DIPO) for human preference estimation without parametric reward models.", "result": "Empirical results show improved alignment efficiency and performance nearing that of models trained with fully human-labeled data.", "conclusion": "The methods effectively address systematic bias in AI-generated labels and provide scalable, efficient solutions for alignment."}}
{"id": "2602.07267", "pdf": "https://arxiv.org/pdf/2602.07267", "abs": "https://arxiv.org/abs/2602.07267", "authors": ["Fengyuan Liu", "Jay Gala", "Nilaksh", "Dzmitry Bahdanau", "Siva Reddy", "Hugo Larochelle"], "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.", "AI": {"tldr": "The paper introduces a framework (BRIDGE) that estimates task difficulty using AI model responses and anchors this to human task completion time, improving scalability compared to direct human annotation.", "motivation": "To address the challenges of cost, noise, and scalability when using human task completion time for evaluating AI system benchmarks.", "method": "Utilized a two-parameter logistic Item Response Theory model to jointly estimate task difficulty and model capabilities from AI model performance across various benchmarks, correlating these with human task completion times.", "result": "Found that task difficulty is linearly related to the logarithm of human completion time, enabling task difficulty inference for new benchmarks and accurate forecasting of model capabilities.", "conclusion": "BRIDGE allows scalable and interpretable assessment of AI performance, aligning AI system evaluation with human task understanding, and supports forecasting of AI progress."}}
{"id": "2602.07126", "pdf": "https://arxiv.org/pdf/2602.07126", "abs": "https://arxiv.org/abs/2602.07126", "authors": ["Joshua Ward", "Chi-Hua Wang", "Guang Cheng"], "title": "Finding Connections: Membership Inference Attacks for the Multi-Table Synthetic Data Setting", "categories": ["cs.LG"], "comment": null, "summary": "Synthetic tabular data has gained attention for enabling privacy-preserving data sharing. While substantial progress has been made in single-table synthetic generation where data are modeled at the row or item level, most real-world data exists in relational databases where a user's information spans items across multiple interconnected tables. Recent advances in synthetic relational data generation have emerged to address this complexity, yet release of these data introduce unique privacy challenges as information can be leaked not only from individual items but also through the relationships that comprise a complete user entity.\n  To address this, we propose a novel Membership Inference Attack (MIA) setting to audit the empirical user-level privacy of synthetic relational data and show that single-table MIAs that audit at an item level underestimate user-level privacy leakage. We then propose Multi-Table Membership Inference Attack (MT-MIA), a novel adversarial attack under a No-Box threat model that targets learned representations of user entities via Heterogeneous Graph Neural Networks. By incorporating all connected items for a user, MT-MIA better targets user-level vulnerabilities induced by inter-tabular relationships than existing attacks. We evaluate MT-MIA on a range of real-world multi-table datasets and demonstrate that this vulnerability exists in state-of-the-art relational synthetic data generators, employing MT-MIA to additionally study where this leakage occurs.", "AI": {"tldr": "The paper introduces a novel attack approach to audit privacy leakage in synthetic relational data, focusing on user-level vulnerability instead of individual item privacy.", "motivation": "Synthetic relational data generation aims to balance data privacy and usability, but unique privacy issues arise due to interconnected relationships in multi-table databases.", "method": "The authors propose a Multi-Table Membership Inference Attack (MT-MIA) utilizing Heterogeneous Graph Neural Networks to assess privacy leaks at the user-level in relational databases.", "result": "MT-MIA effectively uncovers user-level vulnerabilities in relational synthetic data, highlighting privacy leakage in state-of-the-art generators across various datasets.", "conclusion": "The study reveals that relational synthetic data generators exhibit significant user-level privacy issues, prompting the need for improved model designs to tackle such vulnerabilities."}}
{"id": "2602.08640", "pdf": "https://arxiv.org/pdf/2602.08640", "abs": "https://arxiv.org/abs/2602.08640", "authors": ["Abel Sagodi", "Il Memming Park"], "title": "Universal Approximation Theorems for Dynamical Systems with Infinite-Time Horizon Guarantees", "categories": ["math.DS", "q-bio.NC"], "comment": null, "summary": "Universal approximation theorems establish the expressive capacity of neural network architectures. For dynamical systems, existing results are limited to finite time horizons or systems with a globally stable equilibrium, leaving multistability and limit cycles unaddressed. We prove that Neural ODEs achieve $\\varepsilon$-$\u03b4$ closeness -- trajectories within error $\\varepsilon$ except for initial conditions of measure $< \u03b4$ -- over the \\emph{infinite} time horizon $[0,\\infty)$ for three target classes: (1) Morse-Smale systems (a structurally stable class) with hyperbolic fixed points, (2) Morse-Smale systems with hyperbolic limit cycles via exact period matching, and (3) systems with normally hyperbolic continuous attractors via discretization. We further establish a temporal generalization bound: $\\varepsilon$-$\u03b4$ closeness implies $L^p$ error $\\leq \\varepsilon^p + \u03b4\\cdot D^p$ for all $t \\geq 0$, bridging topological guarantees to training metrics. These results provide the first universal approximation framework for multistable infinite-horizon dynamics.", "AI": {"tldr": "The paper extends universal approximation theorems to dynamical systems over infinite time horizons, addressing complex systems with multistability and limit cycles.", "motivation": "Existing universal approximation results for neural networks in dynamical systems are restricted to finite time or globally stable equilibria, leaving significant systems like multistable and limit cycle systems unexplored.", "method": "The paper proves $\u000b\\varepsilon$-$\\delta$ closeness of Neural ODEs for infinite time horizons in three system classes: Morse-Smale systems with hyperbolic fixed points/limit cycles, and normally hyperbolic continuous attractors. Temporal generalization bounds are also developed.", "result": "Neural ODEs achieve target system trajectory approximations within bounded error over infinite time, extending prior results. Temporal generalization bounds link training metrics to long-term accuracy.", "conclusion": "The study provides a universal framework for approximating multistable and infinite-horizon dynamics, advancing Neural ODE capabilities in complex dynamical systems."}}
{"id": "2602.08387", "pdf": "https://arxiv.org/pdf/2602.08387", "abs": "https://arxiv.org/abs/2602.08387", "authors": ["Max L\u00fcbbering", "Timm Ruland", "Richard Rutmann", "Felix Stollenwerk", "David Fitzek", "Michael Fromm", "Alexander Weber", "Rafet Sifa", "Nicolas Flores-Herr", "Joachim K\u00f6hler", "Mehdi Ali"], "title": "Modalities, a PyTorch-native Framework For Large-scale LLM Training and Research", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Today's LLM (pre-) training and research workflows typically allocate a significant amount of compute to large-scale ablation studies. Despite the substantial compute costs of these ablations, existing open-source frameworks provide limited tooling for these experiments, often forcing researchers to write their own wrappers and scripts. We propose Modalities, an end-to-end PyTorch-native framework that integrates data-driven LLM research with large-scale model training from two angles. Firstly, by integrating state-of-the-art parallelization strategies, it enables both efficient pretraining and systematic ablations at trillion-token and billion-parameter scale. Secondly, Modalities adopts modular design with declarative, self-contained configuration, enabling reproducibility and extensibility levels that are difficult to achieve out-of-the-box with existing LLM training frameworks.", "AI": {"tldr": "The paper proposes 'Modalities', a PyTorch-native framework for efficient training and ablation studies of large language models, providing scalability and improved reproducibility.", "motivation": "Existing LLM training and research workflows face difficulties due to the high computational costs of large-scale ablation studies, coupled with limited tooling support in current frameworks.", "method": "Proposes 'Modalities', a framework that combines advanced parallelization strategies and modular design for efficient pretraining and systematic ablation studies at large scales.", "result": "The framework facilitates efficient training and experimentation for trillion-token and billion-parameter LLMs while ensuring reproducibility and extensibility.", "conclusion": "Modalities provides a practical solution to enhance research productivity in LLM development by combining scalability, efficiency, and reproducibility."}}
{"id": "2602.06997", "pdf": "https://arxiv.org/pdf/2602.06997", "abs": "https://arxiv.org/abs/2602.06997", "authors": ["Anindya Bhattacharjee", "Nittya Ananda Biswas", "K. A. Shahriar", "Adib Rahman"], "title": "Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion to model temporal EEG dynamics with complementary peripheral physiological and personality features. Dedicated subnetworks are used to process EEG features and auxiliary modalities, and a shared autoencoder-based fusion module is used to learn discriminative latent representations before classification. Subject-dependent experiments conducted on the PhyMER dataset across seven emotional classes achieve an accuracy of 95.45%, surpassing previously reported results. Furthermore, temporal attention analysis provides interpretable insights into emotion-specific temporal relevance, and t-SNE visualizations demonstrate enhanced class separability, highlighting the effectiveness of the proposed approach. Finally, statistical analysis of temporal dynamics confirms that the network self-organizes into distinct functional groups with specialized fast and slow neurons, proving it independently tunes learnable time constants and memory dominance to effectively capture complex emotion artifacts.", "AI": {"tldr": "A multimodal framework using liquid neural networks and attention mechanisms improves EEG-based emotion recognition accuracy to 95.45% on the PhyMER dataset, with interpretable insights and statistical validation.", "motivation": "Emotion recognition from physiological signals is challenging due to their non-stationary, noisy, and subject-dependent characteristics.", "method": "The study introduces a multimodal framework combining convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion alongside an autoencoder-based fusion module.", "result": "Subject-dependent experiments on the PhyMER dataset achieved 95.45% accuracy across seven emotion classes, surpassing prior results. Temporal attention analysis and t-SNE visualizations demonstrate improved class separability and emotion-specific insights.", "conclusion": "The framework effectively captures complex emotional dynamics through self-organized specialized neurons and learnable time constants, advancing EEG-based emotion recognition."}}
{"id": "2602.07561", "pdf": "https://arxiv.org/pdf/2602.07561", "abs": "https://arxiv.org/abs/2602.07561", "authors": ["Quanjun Zhang", "Ye Shang", "Haichuan Hu", "Chunrong Fang", "Zhenyu Chen", "Liang Xiao"], "title": "ComPass: Contrastive Learning for Automated Patch Correctness Assessment in Program Repair", "categories": ["cs.SE"], "comment": "30 pages, 3 figures", "summary": "Automated program repair (APR) attempts to reduce manual debugging efforts and plays a vital role in software maintenance. Despite remarkable progress, APR is still limited in generating overfitting patches, i.e., patches passing available test suites but incorrect. This issue, known as patch overfitting, has become a key concern in the APR community, with numerous approaches proposed to address it. Very recent work proposes a pre-trained language model (PLM)-based automated patch correctness assessment (APCA) approach, indicating the potential of such PLMs in reasoning about patch correctness. Despite being promising, it is still far from perfect due to various limitations, such as the training paradigm and training dataset. In this paper, we present ComPass, a PLM-based APCA approach that leverages contrastive learning and data augmentation to address the technical limitations of prior work. Our work is inspired by the opportunity to integrate contrastive learning with recent PLMs in the field of patch correctness assessment, where large-scale labeled patches are difficult to obtain. ComPass utilizes code transformation rules to generate semantic-preserving code snippets for both unlabeled pre-training corpus and labeled fine-tuning patches. ComPass then pre-trains PLMs with contrastive learning, which captures code features with the same semantics but different structures. ComPass finally integrates representation embeddings of patch code snippets and fine-tunes PLMs with a binary classifier jointly to assess patch code correctness. Experimental results on 2274 real-world patches from Defects4J demonstrate that ComPass achieves an accuracy of 88.35%, significantly outperforming state-of-the-art baseline APPT.", "AI": {"tldr": "ComPass, a PLM-based approach, addresses the patch overfitting issue in automated program repair using contrastive learning and data augmentation, achieving 88.35% accuracy on real-world patches.", "motivation": "Automated program repair (APR) reduces debugging efforts, but faces the issue of patch overfitting, where patches pass tests but remain incorrect. The motivation is to better assess patch correctness using improved methods.", "method": "ComPass leverages contrastive learning and code transformation-based data augmentation. It pre-trains PLMs with semantic-preserving transformations and fine-tunes them using a binary classifier for patch correctness assessment.", "result": "ComPass achieves 88.35% accuracy on 2274 patches from Defects4J, outperforming prior state-of-the-art methods.", "conclusion": "ComPass effectively reduces patch overfitting by improving correctness assessment through contrastive learning and enhanced training paradigms, providing an advancement in APR approaches."}}
{"id": "2602.07024", "pdf": "https://arxiv.org/pdf/2602.07024", "abs": "https://arxiv.org/abs/2602.07024", "authors": ["Valerio Belcamino", "Nhat Minh Dinh Le", "Quan Khanh Luu", "Alessandro Carf\u00ec", "Van Anh Ho", "Fulvio Mastrogiovanni"], "title": "A Distributed Multi-Modal Sensing Approach for Human Activity Recognition in Real-Time Human-Robot Collaboration", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Human activity recognition (HAR) is fundamental in human-robot collaboration (HRC), enabling robots to respond to and dynamically adapt to human intentions. This paper introduces a HAR system combining a modular data glove equipped with Inertial Measurement Units and a vision-based tactile sensor to capture hand activities in contact with a robot. We tested our activity recognition approach under different conditions, including offline classification of segmented sequences, real-time classification under static conditions, and a realistic HRC scenario. The experimental results show a high accuracy for all the tasks, suggesting that multiple collaborative settings could benefit from this multi-modal approach.", "AI": {"tldr": "The paper presents a multi-modal human activity recognition (HAR) system using a modular data glove and a vision-based tactile sensor for improved collaboration with robots.", "motivation": "To enhance human-robot collaboration (HRC) by enabling robots to dynamically understand and respond to human intentions through accurate activity recognition.", "method": "The system combines a modular data glove (with Inertial Measurement Units) and a vision-based tactile sensor. Activities were tested in offline classification, real-time classification under static conditions, and realistic HRC scenarios.", "result": "Experimental results demonstrated high accuracy in all tested tasks, validating the effectiveness of the multi-modal HAR system.", "conclusion": "The system's robust performance indicates its suitability for multiple collaborative environments, offering significant benefits in HRC settings."}}
{"id": "2602.07338", "pdf": "https://arxiv.org/pdf/2602.07338", "abs": "https://arxiv.org/abs/2602.07338", "authors": ["Geng Liu", "Fei Zhu", "Rong Feng", "Changyi Ma", "Shiqi Wang", "Gaofeng Meng"], "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.", "AI": {"tldr": "This paper addresses the reduced performance of large language models (LLMs) in multi-turn conversations, introducing a Mediator-Assistant framework to improve intent alignment.", "motivation": "The paper aims to solve the performance degradation in multi-turn conversations of LLMs, which stems from an intent alignment gap rather than model unreliability or intrinsic capability limitations.", "method": "The authors propose a Mediator-Assistant architecture. The Mediator interprets vague user inputs into clear, structured instructions using historical interaction patterns, ensuring better task execution by the Assistant.", "result": "The proposed Mediator-Assistant framework successfully mitigates performance drop in multi-turn conversations, achieving improved results across various LLMs.", "conclusion": "Effective user intent clarification is essential for maintaining LLM performance in conversational settings, and the Mediator-Assistant approach demonstrates a viable solution to the issue of intent alignment in multi-turn conversations."}}
{"id": "2602.07026", "pdf": "https://arxiv.org/pdf/2602.07026", "abs": "https://arxiv.org/abs/2602.07026", "authors": ["Xiaomin Yu", "Yi Xin", "Wenjie Zhang", "Chonghan Liu", "Hanzhen Zhao", "Xiaoxing Hu", "Xinlei Yu", "Ziyue Qiao", "Hao Tang", "Xue Yang", "Xiaobin Hu", "Chengwei Qin", "Hui Xiong", "Yu Qiao", "Shuicheng Yan"], "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly, the Modality Gap, remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions, hindering their application in large-scale scenarios. In this paper, we address these limitations by precisely characterizing the geometric shape of the modality gap and leveraging it for efficient model scaling. First, we propose the Fixed-frame Modality Gap Theory, which decomposes the modality gap within a frozen reference frame into stable biases and anisotropic residuals. Guided by this precise modeling, we introduce ReAlign, a training-free modality alignment strategy. Utilizing statistics from massive unpaired data, ReAlign aligns text representation into the image representation distribution via a three-step process comprising Anchor, Trace, and Centroid Alignment, thereby explicitly rectifying geometric misalignment. Building on ReAlign, we propose ReVision, a scalable training paradigm for Multimodal Large Language Models (MLLMs). ReVision integrates ReAlign into the pretraining stage, enabling the model to learn the distribution of visual representations from unpaired text before visual instruction tuning, without the need for large-scale, high-quality image-text pairs. Our framework demonstrates that statistically aligned unpaired data can effectively substitute for expensive image-text pairs, offering a robust path for the efficient scaling of MLLMs.", "AI": {"tldr": "The paper tackles the modality gap issue in multimodal contrastive learning, proposing a precise geometric theory and introducing training-free alignment strategies to rectify this misalignment effectively.", "motivation": "Current multimodal contrastive learning faces challenges due to the modality gap, where representations of identical semantics in different modalities are misaligned geometrically. Existing methods assume isotropy, limiting effectiveness in large-scale contexts.", "method": "The Fixed-frame Modality Gap Theory is proposed to model the modality gap, isolating biases and residuals. The ReAlign strategy aligns representations statistically, and the ReVision framework scales multimodal models using unpaired data instead of paired image-text datasets.", "result": "ReAlign effectively rectifies geometric misalignment between modality representations. ReVision enables scalable model training using unpaired text and visual statistics, reducing dependency on expensive, high-quality image-text pairs.", "conclusion": "Utilizing unpaired data and precise geometric modeling enables efficient scaling of multimodal models, with significant improvements over existing methods relying on paired datasets."}}
{"id": "2602.08318", "pdf": "https://arxiv.org/pdf/2602.08318", "abs": "https://arxiv.org/abs/2602.08318", "authors": ["Soon Hoe Lim", "Shizheng Lin", "Michael W. Mahoney", "N. Benjamin Erichson"], "title": "Is Flow Matching Just Trajectory Replay for Sequential Data?", "categories": ["stat.ML", "cs.LG", "nlin.CD"], "comment": "51 pages", "summary": "Flow matching (FM) is increasingly used for time-series generation, but it is not well understood whether it learns a general dynamical structure or simply performs an effective \"trajectory replay\". We study this question by deriving the velocity field targeted by the empirical FM objective on sequential data, in the limit of perfect function approximation. For the Gaussian conditional paths commonly used in practice, we show that the implied sampler is an ODE whose dynamics constitutes a nonparametric, memory-augmented continuous-time dynamical system. The optimal field admits a closed-form expression as a similarity-weighted mixture of instantaneous velocities induced by past transitions, making the dataset dependence explicit and interpretable. This perspective positions neural FM models trained by stochastic optimization as parametric surrogates of an ideal nonparametric solution. Using the structure of the optimal field, we study sampling and approximation schemes that improve the efficiency and numerical robustness of ODE-based generation. On nonlinear dynamical system benchmarks, the resulting closed-form sampler yields strong probabilistic forecasts directly from historical transitions, without training.", "AI": {"tldr": "The paper examines Flow Matching (FM) in time-series generation, analyzing whether it captures dynamical structures or merely performs trajectory replay. It investigates optimal velocity fields and introduces improved sampling techniques.", "motivation": "The study aims to understand whether FM learns general dynamics for time-series generation or simply replicates observed trajectories.", "method": "The paper derives the velocity field targeted by FM on sequential data, introducing a closed-form sampler for ODE-based generation that uses Gaussian conditional paths.", "result": "The authors present a structured, interpretable depiction of FM, demonstrating its dataset dependence and improving sampling efficiency and robustness.", "conclusion": "The analysis situates FM as a neural parametric surrogate of a nonparametric solution while introducing an effective closed-form sampler for forecasting without additional training."}}
{"id": "2602.07274", "pdf": "https://arxiv.org/pdf/2602.07274", "abs": "https://arxiv.org/abs/2602.07274", "authors": ["Kaijie Zhu", "Yuzhou Nie", "Yijiang Li", "Yiming Huang", "Jialian Wu", "Jiang Liu", "Ximeng Sun", "Zhenfei Yin", "Lun Wang", "Zicheng Liu", "Emad Barsoum", "William Yang Wang", "Wenbo Guo"], "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents", "categories": ["cs.AI"], "comment": null, "summary": "Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.", "AI": {"tldr": "This paper identifies two limitations of large language models (LLMs) in performing terminal tasks and introduces TermiGen, a pipeline for synthesizing verifiable task environments and error-resilient trajectories. Fine-tuning on TermiGen's dataset achieved improved terminal task performance.", "motivation": "To address the challenges faced by LLMs in terminal task execution, including lack of diverse training environments and inability to recover from runtime errors.", "method": "TermiGen employs an iterative multi-agent refinement loop for generating verifiable tasks and environments, paired with a Generator-Critic approach that induces and corrects errors during trajectory synthesis.", "result": "The fine-tuned TermiGen-Qwen2.5-Coder-32B model achieved a 31.3% pass rate on TerminalBench, outperforming existing baseline models and proprietary ones like o4-mini.", "conclusion": "TermiGen represents a significant step in improving open-weight LLMs' capability for terminal tasks, demonstrating enhanced performance and setting a new state-of-the-art benchmark."}}
{"id": "2602.07135", "pdf": "https://arxiv.org/pdf/2602.07135", "abs": "https://arxiv.org/abs/2602.07135", "authors": ["Jiaqing Chen", "Nicholas Hadler", "Tiankai Xie", "Rostyslav Hnatyshyn", "Caleb Geniesse", "Yaoqing Yang", "Michael W. Mahoney", "Talita Perciano", "John F. Hartwig", "Ross Maciejewski", "Gunther H. Weber"], "title": "Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Loss landscapes are a powerful tool for understanding neural network optimization and generalization, yet traditional low-dimensional analyses often miss complex topological features. We present Landscaper, an open-source Python package for arbitrary-dimensional loss landscape analysis. Landscaper combines Hessian-based subspace construction with topological data analysis to reveal geometric structures such as basin hierarchy and connectivity. A key component is the Saddle-Minimum Average Distance (SMAD) for quantifying landscape smoothness. We demonstrate Landscaper's effectiveness across various architectures and tasks, including those involving pre-trained language models, showing that SMAD captures training transitions, such as landscape simplification, that conventional metrics miss. We also illustrate Landscaper's performance in challenging chemical property prediction tasks, where SMAD can serve as a metric for out-of-distribution generalization, offering valuable insights for model diagnostics and architecture design in data-scarce scientific machine learning scenarios.", "AI": {"tldr": "Landscaper is a Python package for high-dimensional loss landscape analysis, incorporating subspace construction and topological methods to understand neural network structures and generalization.", "motivation": "To address limitations of traditional low-dimensional analyses in capturing the complex topological features of neural network loss landscapes.", "method": "The paper describes Landscaper, which combines Hessian-based subspace construction with topological data analysis and introduces the Saddle-Minimum Average Distance (SMAD) metric for assessing landscape smoothness.", "result": "Landscaper reveals geometric structures in neural loss landscapes, demonstrates training transitions, and performs effectively on tasks such as pre-trained language models and chemical property prediction.", "conclusion": "Landscaper proves useful for analyzing training dynamics and generalization, with SMAD offering insights into model diagnostics, architecture design, and generalization in data-scarce scenarios."}}
{"id": "2602.08910", "pdf": "https://arxiv.org/pdf/2602.08910", "abs": "https://arxiv.org/abs/2602.08910", "authors": ["Izaro Fernandez-Iriondo", "Antonio Jimenez-Marin", "Jesus Cortes", "Pablo Villegas"], "title": "Structural coarse-graining enables noise-robust functional connectivity and reveals hidden inter-subject variability", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC", "q-bio.PE"], "comment": "10 Pages, 4 Figures and Supplementary Information", "summary": "Functional connectivity estimates are highly sensitive to analysis choices and can be dominated by noise when the number of sampled time points is small relative to network dimensionality. This issue is particularly acute in fMRI, where scan resolution is limited. Because scan duration is constrained by practical factors (e.g., motion and fatigue), many datasets remain statistically underpowered for high-dimensional correlation estimation. We introduce a framework that combines diffusion-based structural coarse-graining with spectral noise filtering to recover statistically reliable functional networks from temporally limited data. The method reduces network dimensionality by grouping regions according to diffusion-defined communication. This produces coarse-grained networks with dimensions compatible with available time points, enabling random matrix filtering of noise-dominated modes. We benchmark three common FC pipelines against our approach. We find that raw-signal correlations are strongly influenced by non-stationary fluctuations that can reduce apparent inter-subject variability under limited sampling conditions. In contrast, our pipeline reveals a broader, multimodal landscape of inter-subject variability. These large-scale organization patterns are largely obscured by standard pipelines. Together, these results provide a practical route to reliable functional networks under realistic sampling constraints. This strategy helps separate noise-driven artifacts from reproducible patterns of human brain variability.", "AI": {"tldr": "Functional connectivity analyses can be distorted by sampling constraints and noise in fMRI data. This paper introduces an advanced framework combining diffusion-based structural grouping and spectral noise filtering to enhance the reliability of functional network estimates from limited data.", "motivation": "Functional connectivity studies, particularly in fMRI, are hampered by noise and limited sampling due to constraints such as scan durations. Improving analytical methods is essential for deriving meaningful brain connectivity insights.", "method": "The proposed method combines structural coarse-graining via diffusion-based grouping and spectral noise filtering to reduce network dimensionality, aligning them with available data points and filtering out noise-driven artifacts.", "result": "The authors benchmark their method against conventional pipelines and find improved statistical reliability. Their approach reveals broader inter-subject variability and reduces the impact of noise-dominated artifacts.", "conclusion": "The framework enables the extraction of reliable functional networks from temporally constrained fMRI data, offering a practical solution to overcome limitations posed by traditional analysis methods."}}
{"id": "2602.08446", "pdf": "https://arxiv.org/pdf/2602.08446", "abs": "https://arxiv.org/abs/2602.08446", "authors": ["Pouria Arefijamal", "Mahdi Ahmadlou", "Bardia Safaei", "J\u00f6rg Henkel"], "title": "RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks", "categories": ["cs.LG", "cs.CR", "cs.DC", "cs.NI"], "comment": "This paper has been accepted for publication in IEEE ICC 2026 and will be indexed in the IEEE Xplore Digital Library", "summary": "Federated learning (FL) is a decentralized learning paradigm widely adopted in resource-constrained Internet of Things (IoT) environments. These devices, typically relying on TinyML models, collaboratively train global models by sharing gradients with a central server while preserving data privacy. However, as data heterogeneity and task complexity increase, TinyML models often become insufficient to capture intricate patterns, especially under extreme non-IID (non-independent and identically distributed) conditions. Moreover, ensuring robustness against malicious clients and poisoned updates remains a major challenge. Accordingly, this paper introduces RIFLE - a Robust, distillation-based Federated Learning framework that replaces gradient sharing with logit-based knowledge transfer. By leveraging a knowledge distillation aggregation scheme, RIFLE enables the training of deep models such as VGG-19 and Resnet18 within constrained IoT systems. Furthermore, a Kullback-Leibler (KL) divergence-based validation mechanism quantifies the reliability of client updates without exposing raw data, achieving high trust and privacy preservation simultaneously. Experiments on three benchmark datasets (MNIST, CIFAR-10, and CIFAR-100) under heterogeneous non-IID conditions demonstrate that RIFLE reduces false-positive detections by up to 87.5%, enhances poisoning attack mitigation by 62.5%, and achieves up to 28.3% higher accuracy compared to conventional federated learning baselines within only 10 rounds. Notably, RIFLE reduces VGG19 training time from over 600 days to just 1.39 hours on typical IoT devices (0.3 GFLOPS), making deep learning practical in resource-constrained networks.", "AI": {"tldr": "This paper introduces RIFLE, a robust federated learning framework using knowledge distillation for IoT systems, enabling efficient training of deep models under non-IID conditions and improving robustness against malicious clients.", "motivation": "The motivation is to enhance federated learning in resource-constrained IoT environments, addressing challenges such as data heterogeneity, task complexity, and robustness against malicious attacks.", "method": "RIFLE replaces gradient sharing with logit-based knowledge transfer and uses a KL divergence-based mechanism to validate client updates securely and effectively.", "result": "RIFLE demonstrates superior performance in accuracy improvement, false-positive reduction, and attack mitigation compared to traditional FL methods, while significantly reducing training time for deep models.", "conclusion": "RIFLE makes practical deep learning achievable for IoT devices by improving robustness, privacy, and efficiency in federated learning frameworks, thus addressing critical challenges in constrained environments."}}
{"id": "2602.07051", "pdf": "https://arxiv.org/pdf/2602.07051", "abs": "https://arxiv.org/abs/2602.07051", "authors": ["Karthik Sivakoti"], "title": "Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, and vehicle attribute extraction through a single forward pass. Our primary contribution lies in demonstrating that a fine-tuned PaliGemma 3B model, adapted via Low-Rank Adaptation (LoRA), can simultaneously answer multiple visual questions about vehicle images, achieving 92.3% plate recognition accuracy, which is a 14.1% improvement over EasyOCR and 9.9% improvement over PaddleOCR baselines. We introduce a Human-in-the-Loop (HITL) continual learning framework that incorporates user corrections while preventing catastrophic forgetting through experience replay, maintaining a 70:30 ratio of original training data to correction samples. The system achieves a mean inference latency of 152ms with an Expected Calibration Error (ECE) of 0.048, indicating well calibrated confidence estimates. Additionally, the VLM first architecture enables zero-shot generalization to auxiliary tasks including vehicle color detection (89%), seatbelt detection (82%), and occupancy counting (78%) without task specific training. Through extensive experimentation on real world toll plaza imagery, we demonstrate that unified vision language approaches represent a paradigm shift in ALPR systems, offering superior accuracy, reduced architectural complexity, and emergent multi-task capabilities that traditional pipeline approaches cannot achieve.", "AI": {"tldr": "This work proposes Neural Sentinel, a unified Vision Language Model (VLM)-based approach for license plate recognition and related vehicle tasks, achieving significant accuracy improvements with reduced complexity over traditional methods.", "motivation": "Traditional ALPR systems rely on complex, multi-stage pipelines that increase latency and error propagation. The motivation is to simplify this architecture while achieving superior accuracy and multi-task capabilities using VLMs.", "method": "The study leverages the PaliGemma 3B VLM fine-tuned with Low-Rank Adaptation (LoRA) to handle multiple visual questions. It integrates a Human-in-the-Loop (HITL) learning framework with experience replay to prevent forgetting and maintain training data balance.", "result": "The model achieves 92.3% license plate recognition accuracy, a significant improvement over baseline OCR models, with a mean inference time of 152ms and well-calibrated confidence (ECE= 0.048). It also generalizes zero-shot to other vehicle-related tasks like color, seatbelt detection, and occupancy counting.", "conclusion": "Neural Sentinel demonstrates the effectiveness of using unified vision language frameworks for ALPR systems. It simplifies architecture, enhances accuracy, and introduces robust multi-task capabilities, signifying a shift from traditional pipeline models."}}
{"id": "2602.07569", "pdf": "https://arxiv.org/pdf/2602.07569", "abs": "https://arxiv.org/abs/2602.07569", "authors": ["Eduardo C. Peixoto", "Hector Oliveira", "Geber L. Ramalho", "Cesar Fran\u00e7a"], "title": "Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach", "categories": ["cs.SE", "cs.SI"], "comment": "34 pages, 8 figures, 10 tables, 2 appendices", "summary": "Digital Transformation (DT) initiatives frequently face high failure rates, and while Digital Maturity Models (DMMs) offer potential solutions, they have notable shortcomings. Specifically, there is significant disparity in the dimensions considered relevant, a lack of clarity in their definitions, and uncertainty regarding their components. This study aims to provide a clearer understanding of DMMs by proposing integrative definitions of the most frequently used dimensions. Using a Systematic Mapping approach, including automatic search and snowballing techniques, we analyzed 76 DMMs to answer two Research Questions: (RQ1) What are the most frequent dimensions in DMMs? and (RQ2) How are these dimensions described, including their components? We reconcile varying interpretations of the ten most frequent dimensions -- Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data -- and propose integrative definitions for each. Compared to previous analyses, this study provides a broader and more recent perspective on Digital Maturity Models.", "AI": {"tldr": "The paper analyzes 76 Digital Maturity Models (DMMs) to address their disparities and provide integrative definitions for commonly used dimensions, improving clarity in the field.", "motivation": "Despite the potential of Digital Maturity Models (DMMs) to support Digital Transformation (DT) initiatives, their inefficacy is attributed to unclear, inconsistent dimensions and components.", "method": "The study uses a Systematic Mapping approach with both automatic search and snowballing techniques to review a total of 76 DMMs and identify patterns in dimensions and their descriptions.", "result": "Ten key dimensions (Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data) were identified, examined, and given integrative definitions.", "conclusion": "This research enhances the clarity and relevance of DMMs by addressing ambiguities, generating integrative definitions of key dimensions, and offering a contemporary analysis of their utility for Digital Transformation."}}
{"id": "2602.07074", "pdf": "https://arxiv.org/pdf/2602.07074", "abs": "https://arxiv.org/abs/2602.07074", "authors": ["H. Emre Tekaslan", "Ella M. Atkins"], "title": "Airspace-aware Contingency Landing Planning", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This paper develops a real-time, search-based aircraft contingency landing planner that minimizes traffic disruptions while accounting for ground risk. The airspace model captures dense air traffic departure and arrival flows, helicopter corridors, and prohibited zones and is demonstrated with a Washington, D.C., area case study. Historical Automatic Dependent Surveillance-Broadcast (ADS-B) data are processed to estimate air traffic density. A low-latency computational geometry algorithm generates proximity-based heatmaps around high-risk corridors and restricted regions. Airspace risk is quantified as the cumulative exposure time of a landing trajectory within congested regions, while ground risk is assessed from overflown population density to jointly guide trajectory selection. A landing site selection module further mitigates disruption to nominal air traffic operations. Benchmarking against minimum-risk Dubins solutions demonstrates that the proposed planner achieves lower joint risk and reduced airspace disruption while maintaining real-time performance. Under airspace-risk-only conditions, the planner generates trajectories within an average of 2.9 seconds on a laptop computer. Future work will incorporate dynamic air traffic updates to enable spatiotemporal contingency landing planning that minimizes the need for real-time traffic rerouting.", "AI": {"tldr": "This paper presents a real-time aircraft contingency landing planner that minimizes air traffic disruptions and ground risk, validated through a Washington, D.C., case study.", "motivation": "Address the challenge in efficiently planning emergency aircraft landings in congested airspace while considering risks to ground population and minimizing flight disruptions.", "method": "Using historical ADS-B data, computational geometry algorithms, and risk quantification metrics, trajectories are optimized jointly considering airspace and ground risks. A landing site selection module further reduces air traffic disruption.", "result": "The proposed solution outperforms minimum-risk alternatives by achieving lower joint risks and reduced traffic disruptions in real-time, with computation averaging 2.9 seconds per trajectory.", "conclusion": "The planner demonstrates effectiveness in real-time emergency aircraft trajectory planning, and the study identifies scope for dynamic traffic integration in future developments."}}
{"id": "2602.07361", "pdf": "https://arxiv.org/pdf/2602.07361", "abs": "https://arxiv.org/abs/2602.07361", "authors": ["Long S. T. Nguyen", "Quan M. Bui", "Tin T. Ngo", "Quynh T. N. Vo", "Dung N. H. Le", "Tho T. Quan"], "title": "ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted at ACIIDS 2026", "summary": "Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.", "AI": {"tldr": "This paper introduces ViHERMES, a benchmark dataset designed for multihop question answering on Vietnamese healthcare regulatory documents. It highlights multihop reasoning challenges and proposes a graph-aware retrieval method.", "motivation": "Question answering over regulatory texts, especially in healthcare, faces challenges due to hierarchical structures, amendments, and cross-references. Limited resources exist for low-resource languages like Vietnamese in multihop QA tasks.", "method": "The authors created ViHERMES using a pipeline with semantic clustering, graph-inspired data mining, and large language model generation with structured annotations. They propose a graph-aware retrieval framework to model legal relations and expand context.", "result": "ViHERMES is shown to be a challenging benchmark for multihop reasoning. Experimental results demonstrate the graph-aware approach consistently outperforms retrieval-based baselines.", "conclusion": "ViHERMES provides valuable resources for multihop QA evaluation in Vietnamese healthcare regulations, with methods that advance retrieval quality for regulatory reasoning tasks."}}
{"id": "2602.07027", "pdf": "https://arxiv.org/pdf/2602.07027", "abs": "https://arxiv.org/abs/2602.07027", "authors": ["Sanggeon Yun", "Ryozo Masukawa", "SungHeon Jeong", "Wenjun Huang", "Hanning Chen", "Mohsen Imani"], "title": "Fair Context Learning for Evidence-Balanced Test-Time Adaptation in Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Vision-Language Models (VLMs) such as CLIP enable strong zero-shot recognition but suffer substantial degradation under distribution shifts. Test-Time Adaptation (TTA) aims to improve robustness using only unlabeled test samples, yet most prompt-based TTA methods rely on entropy minimization -- an approach that can amplify spurious correlations and induce overconfident errors when classes share visual features. We propose Fair Context Learning (FCL), an episodic TTA framework that avoids entropy minimization by explicitly addressing shared-evidence bias. Motivated by our additive evidence decomposition assumption, FCL decouples adaptation into (i) augmentation-based exploration to identify plausible class candidates, and (ii) fairness-driven calibration that adapts text contexts to equalize sensitivity to common visual evidence. This fairness constraint mitigates partial feature obsession and enables effective calibration of text embeddings without relying on entropy reduction. Through extensive evaluation, we empirically validate our theoretical motivation and show that FCL achieves competitive adaptation performance relative to state-of-the-art TTA methods across diverse domain-shift and fine-grained benchmarks.", "AI": {"tldr": "The paper introduces Fair Context Learning (FCL), an episodic Test-Time Adaptation (TTA) framework, to improve Vision-Language Models (VLMs) under distribution shifts without reliance on entropy minimization, showing competitive results.", "motivation": "To enhance the robustness of Vision-Language Models (VLMs) like CLIP under distribution shifts, overcoming issues like spurious correlations and overconfidence caused by entropy minimization in existing TTA methods.", "method": "Proposed Fair Context Learning (FCL), which avoids entropy minimization by using an additive evidence decomposition assumption. FCL uses augmentation-based exploration for identifying plausible class candidates and fairness-driven calibration to equalize sensitivity to visual evidence, preventing shared-evidence bias.", "result": "FCL achieves competitive test-time adaptation performance compared to state-of-the-art methods over various domain-shift and fine-grained benchmarks.", "conclusion": "The proposed FCL framework effectively mitigates shared-evidence bias and enables robust adaptation of VLMs, validating its theoretical underpinnings and practical applicability."}}
{"id": "2602.08374", "pdf": "https://arxiv.org/pdf/2602.08374", "abs": "https://arxiv.org/abs/2602.08374", "authors": ["Denis Belomestny", "Alexey Naumov", "Nikita Puchkin", "Denis Suchkov"], "title": "Schr\u00f6dinger bridge problem via empirical risk minimization", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST"], "comment": null, "summary": "We study the Schr\u00f6dinger bridge problem when the endpoint distributions are available only through samples. Classical computational approaches estimate Schr\u00f6dinger potentials via Sinkhorn iterations on empirical measures and then construct a time-inhomogeneous drift by differentiating a kernel-smoothed dual solution. In contrast, we propose a learning-theoretic route: we rewrite the Schr\u00f6dinger system in terms of a single positive transformed potential that satisfies a nonlinear fixed-point equation and estimate this potential by empirical risk minimization over a function class. We establish uniform concentration of the empirical risk around its population counterpart under sub-Gaussian assumptions on the reference kernel and terminal density. We plug the learned potential into a stochastic control representation of the bridge to generate samples. We illustrate performance of the suggested approach with numerical experiments.", "AI": {"tldr": "The paper proposes a learning-theoretic approach to solve the Schr\u00f6dinger bridge problem using empirical risk minimization and evaluates its performance through numerical experiments.", "motivation": "The motivation is to address the challenge of solving the Schr\u00f6dinger bridge problem when endpoint distributions are only available via samples, improving upon classical approaches.", "method": "The proposed method transforms the Schr\u00f6dinger problem into a nonlinear fixed-point equation and employs empirical risk minimization to estimate a positive potential. It uses a stochastic control representation to generate samples.", "result": "The method achieves uniform concentration of empirical risk around its population counterpart under specific assumptions, and numerical experiments validate its performance.", "conclusion": "The learning-theoretic approach is a promising alternative to classical methods for solving sample-based Schr\u00f6dinger bridge problems, showing theoretical and empirical effectiveness."}}
{"id": "2602.07276", "pdf": "https://arxiv.org/pdf/2602.07276", "abs": "https://arxiv.org/abs/2602.07276", "authors": ["Pengrui Han", "Xueqiang Xu", "Keyang Xuan", "Peiyang Song", "Siru Ouyang", "Runchu Tian", "Yuqing Jiang", "Cheng Qian", "Pengcheng Jiang", "Jiashuo Sun", "Junxia Cui", "Ming Zhong", "Ge Liu", "Jiawei Han", "Jiaxuan You"], "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.", "AI": {"tldr": "STEER2ADAPT proposes a lightweight method to adapt large language models (LLMs) by dynamically composing steering vectors instead of creating them from scratch, achieving performance improvements.", "motivation": "Current steering methods lack flexibility and inadequacy when handling tasks requiring multiple coordinated capabilities or variations, necessitating a better approach.", "method": "STEER2ADAPT composes steering vectors using a low-dimensional semantic subspace and discovers a linear combination of basis vectors dynamically for task adaptation.", "result": "Experiments on 9 tasks across reasoning and safety domains show an average 8.2% performance improvement with STEER2ADAPT.", "conclusion": "STEER2ADAPT is a data-efficient, transparent, and stable way to adapt LLMs at inference time."}}
{"id": "2602.07141", "pdf": "https://arxiv.org/pdf/2602.07141", "abs": "https://arxiv.org/abs/2602.07141", "authors": ["Isabel de la Higuera", "Francisco Herrera", "M. Victoria Velasco"], "title": "Featured Reproducing Kernel Banach Spaces for Learning and Neural Networks", "categories": ["cs.LG", "math.FA"], "comment": null, "summary": "Reproducing kernel Hilbert spaces provide a foundational framework for kernel-based learning, where regularization and interpolation problems admit finite-dimensional solutions through classical representer theorems. Many modern learning models, however -- including fixed-architecture neural networks equipped with non-quadratic norms -- naturally give rise to non-Hilbertian geometries that fall outside this setting. In Banach spaces, continuity of point-evaluation functionals alone is insufficient to guarantee feature representations or kernel-based learning formulations. In this work, we develop a functional-analytic framework for learning in Banach spaces based on the notion of featured reproducing kernel Banach spaces. We identify the precise structural conditions under which feature maps, kernel constructions, and representer-type results can be recovered beyond the Hilbertian regime. Within this framework, supervised learning is formulated as a minimal-norm interpolation or regularization problem, and existence results together with conditional representer theorems are established. We further extend the theory to vector-valued featured reproducing kernel Banach spaces and show that fixed-architecture neural networks naturally induce special instances of such spaces. This provides a unified function-space perspective on kernel methods and neural networks and clarifies when kernel-based learning principles extend beyond reproducing kernel Hilbert spaces.", "AI": {"tldr": "The paper extends kernel-based learning to Banach spaces by developing a novel framework, unifying perspectives on kernel methods and neural networks in function spaces.", "motivation": "Modern learning models like fixed-architecture neural networks operate beyond Hilbert spaces, posing challenges for kernel-based learning that necessitate new foundations.", "method": "A functional-analytic framework for Banach spaces is created, introducing featured reproducing kernel Banach spaces and identifying structural conditions for tools like feature maps and kernels.", "result": "Existence results and conditional representer theorems are established, alongside extending the theory to vector-valued featured reproducing kernel Banach spaces.", "conclusion": "This framework unifies kernel methods and neural networks, explaining when kernel-based learning principles apply beyond reproducing kernel Hilbert spaces."}}
{"id": "2602.08800", "pdf": "https://arxiv.org/pdf/2602.08800", "abs": "https://arxiv.org/abs/2602.08800", "authors": ["Kaiyang Zhao", "Neha Gholkar", "Hasan Maruf", "Abhishek Dhanotia", "Johannes Weiner", "Gregory Price", "Ning Sun", "Bhavya Dwivedi", "Stuart Clark", "Dimitrios Skarlatos"], "title": "Equilibria: Fair Multi-Tenant CXL Memory Tiering At Scale", "categories": ["cs.OS", "cs.DC"], "comment": null, "summary": "Memory dominates datacenter system cost and power. Memory expansion via Compute Express Link (CXL) is an effective way to provide additional memory at lower cost and power, but its effective use requires software-level tiering for hyperscaler workloads. Existing tiering solutions, including current Linux support, face fundamental limitations in production deployments. First, they lack multi-tenancy support, failing to handle stacked homogeneous or heterogeneous workloads. Second, limited control-plane flexibility leads to fairness violations and performance variability. Finally, insufficient observability prevents operators from diagnosing performance pathologies at scale.\n  We present Equilibria, an OS framework enabling fair, multi-tenant CXL tiering at datacenter scale. Equilibria provides per-container controls for memory fair-share allocation and fine-grained observability of tiered-memory usage and operations. It further enforces flexible, user-specified fairness policies through regulated promotion and demotion, and mitigates noisy-neighbor interference by suppressing thrashing.\n  Evaluated in a large hyperscaler fleet using production workloads and benchmarks, Equilibria helps workloads meet service level objectives (SLOs) while avoiding performance interference. It improves performance over the state-of-the-art Linux solution, TPP, by up to 52% for production workloads and 1.7x for benchmarks. All Equilibria patches have been released to the Linux community.", "AI": {"tldr": "Equilibria is an OS framework enhancing fair memory tiering via CXL for datacenter-scale, multi-tenant workloads, addressing limitations in existing tiering solutions.", "motivation": "The paper addresses shortcomings in memory tiering solutions for datacenter systems, particularly incompatibility with multi-tenancy, limited control-plane flexibility, and lack of observability.", "method": "Equilibria introduces per-container memory allocation controls, fine-grained observability, fairness enforcement via memory promotion/demotion policies, and suppression of thrashing to mitigate interference.", "result": "Equilibria significantly improves performance, achieving up to 52% better results for production workloads and 1.7x better outcomes for benchmarks compared to the existing Linux TPP solution.", "conclusion": "Released to the Linux community, Equilibria provides a scalable and fair approach to memory tiering that supports multi-tenancy, enhances performance, and meets hyperscaler workload requirements."}}
{"id": "2602.07697", "pdf": "https://arxiv.org/pdf/2602.07697", "abs": "https://arxiv.org/abs/2602.07697", "authors": ["Francesco Innocenti", "El Mehdi Achour", "Rafal Bogacz"], "title": "On the Infinite Width and Depth Limits of Predictive Coding Networks", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "31 pages, 27 figures", "summary": "Predictive coding (PC) is a biologically plausible alternative to standard backpropagation (BP) that minimises an energy function with respect to network activities before updating weights. Recent work has improved the training stability of deep PC networks (PCNs) by leveraging some BP-inspired reparameterisations. However, the full scalability and theoretical basis of these approaches remains unclear. To address this, we study the infinite width and depth limits of PCNs. For linear residual networks, we show that the set of width- and depth-stable feature-learning parameterisations for PC is exactly the same as for BP. Moreover, under any of these parameterisations, the PC energy with equilibrated activities converges to the BP loss in a regime where the model width is much larger than the depth, resulting in PC computing the same gradients as BP. Experiments show that these results hold in practice for deep nonlinear networks, as long as an activity equilibrium seem to be reached. Overall, this work unifies various previous theoretical and empirical results and has potentially important implications for the scaling of PCNs.", "AI": {"tldr": "The paper explores the scalability and theoretical foundation of predictive coding networks (PCNs) by examining their infinite width and depth limits, showing their equivalence to backpropagation (BP) under certain conditions.", "motivation": "To understand the scalability and theoretical foundation of predictive coding networks (PCNs) in deep learning, and to clarify the connection between PCNs and backpropagation (BP).", "method": "Studied the infinite width and depth limits of PCNs, analyzed parameterizations for linear residual networks, and conducted experiments to validate findings in nonlinear networks where activity equilibrium is reached.", "result": "Demonstrates that PCNs and BP share the same width- and depth-stable feature-learning parameterizations and that PCNs compute the same gradients as BP when PC energy equilibrates to BP loss in wide models that are deeper.", "conclusion": "This work unifies theoretical and empirical findings, showing that PCNs can perform similarly to BP in gradient computation, providing a deeper understanding of their scaling and practical relevance in deep learning."}}
{"id": "2602.07589", "pdf": "https://arxiv.org/pdf/2602.07589", "abs": "https://arxiv.org/abs/2602.07589", "authors": ["Andriy Miranskyy"], "title": "A Course on the Introduction to Quantum Software Engineering: Experience Report", "categories": ["cs.SE", "cs.CY", "cs.ET", "quant-ph"], "comment": null, "summary": "Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management.\n  This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work.\n  Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.", "AI": {"tldr": "This paper reports on designing and delivering a course that frames quantum computing through a software engineering perspective, focusing on combining foundational quantum concepts with software engineering practices.", "motivation": "To address the gap in quantum computing education by incorporating software engineering concerns such as testing, abstraction, lifecycle management, and tooling, which are largely missing in current curriculums.", "method": "The authors designed and conducted a cross-listed undergraduate-graduate course combining foundational quantum concepts with software engineering themes. Evidence includes instructor observations, student feedback, surveys, and student work.", "result": "The course successfully enabled students, even those with minimal prior quantum computing knowledge, to productively engage with quantum software engineering topics after building a foundational understanding through executable artifacts.", "conclusion": "This course design demonstrates the feasibility of combining quantum computing and software engineering education. It provides modular course materials, a scalable assessment method for mixed academic levels, and insights for educators developing quantum-focused curricula."}}
{"id": "2602.07158", "pdf": "https://arxiv.org/pdf/2602.07158", "abs": "https://arxiv.org/abs/2602.07158", "authors": ["Deniz Kerimoglu", "Ismail Uyanik"], "title": "A compliant ankle-actuated compass walker with triggering timing control", "categories": ["cs.RO"], "comment": "6 figures, 6 pages", "summary": "Passive dynamic walkers are widely adopted as a mathematical model to represent biped walking. The stable locomotion of these models is limited to tilted surfaces, requiring gravitational energy. Various techniques, such as actuation through the ankle and hip joints, have been proposed to extend the applicability of these models to level ground and rough terrain with improved locomotion efficiency. However, most of these techniques rely on impulsive energy injection schemes and torsional springs, which are quite challenging to implement in a physical platform. Here, a new model is proposed, named triggering controlled ankle actuated compass gait (TC-AACG), which allows non-instantaneous compliant ankle pushoff. The proposed technique can be implemented in physical platforms via series elastic actuators (SEAs). Our systematic examination shows that the proposed approach extends the locomotion capabilities of a biped model compared to impulsive ankle pushoff approach. We provide extensive simulation analysis investigating the locomotion speed, mechanical cost of transport, and basin of attraction of the proposed model.", "AI": {"tldr": "This paper introduces a new bipedal walking model called TC-AACG that improves locomotion simulations by using non-instantaneous compliant ankle pushoff and can be implemented with series elastic actuators.", "motivation": "Existing passive dynamic biped walking models are limited to tilted surfaces and impulsive energy injection techniques, making them inefficient and hard to implement on physical platforms.", "method": "The authors propose a triggering controlled ankle actuated compass gait model (TC-AACG) featuring non-instantaneous compliant ankle pushoff, implementable via series elastic actuators.", "result": "Through simulations, the proposed TC-AACG model demonstrated improved locomotion capabilities, including locomotion speed, mechanical cost of transport, and basin of attraction, compared to impulsive energy injection techniques.", "conclusion": "The TC-AACG model extends passive bipedal walker capabilities, offering improved efficiency and adaptability for physical implementations."}}
{"id": "2602.07374", "pdf": "https://arxiv.org/pdf/2602.07374", "abs": "https://arxiv.org/abs/2602.07374", "authors": ["Nisharg Nargund", "Priyesh Shukla"], "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.", "AI": {"tldr": "The paper introduces TernaryLM, a 132M parameter language model utilizing 1-bit ternary quantization during training, which reduces memory usage without performance loss.", "motivation": "The motivation is to address the high computational demand of large language models (LLMs) and make them more deployable on edge devices and resource-constrained environments.", "method": "The method involves training a transformer with 1-bit ternary quantization {-1, 0, +1} directly using straight-through estimators and adaptive scaling factors, rather than applying quantization after pre-training.", "result": "The model achieves validation perplexity of 58.42 on TinyStories, an F1 score of 82.47 on MRPC, a 2.4x memory reduction, stable training dynamics, and insights into layer-wise quantization compatibility.", "conclusion": "Native 1-bit quantization during training is effective for building memory-efficient language models, offering performance with reduced computational resources while suggesting directions for future research."}}
{"id": "2602.07028", "pdf": "https://arxiv.org/pdf/2602.07028", "abs": "https://arxiv.org/abs/2602.07028", "authors": ["Kaaustaaub Shankar", "Bharadwaj Dogga", "Kelly Cohen"], "title": "A Comparative Study of Adversarial Robustness in CNN and CNN-ANFIS Architectures", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to NAFIPS 2026", "summary": "Convolutional Neural Networks (CNNs) achieve strong image classification performance but lack interpretability and are vulnerable to adversarial attacks. Neuro-fuzzy hybrids such as DCNFIS replace fully connected CNN classifiers with Adaptive Neuro-Fuzzy Inference Systems (ANFIS) to improve interpretability, yet their robustness remains underexplored. This work compares standard CNNs (ConvNet, VGG, ResNet18) with their ANFIS-augmented counterparts on MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100 under gradient-based (PGD) and gradient-free (Square) attacks. Results show that ANFIS integration does not consistently improve clean accuracy and has architecture-dependent effects on robustness: ResNet18-ANFIS exhibits improved adversarial robustness, while VGG-ANFIS often underperforms its baseline. These findings suggest that neuro-fuzzy augmentation can enhance robustness in specific architectures but is not universally beneficial.", "AI": {"tldr": "This study assesses the robustness of neuro-fuzzy augmented CNNs against adversarial attacks, with mixed results depending on the architecture.", "motivation": "To improve interpretability and robustness of CNNs, which are otherwise strong in classification but lack transparency and are vulnerable to adversarial attacks.", "method": "Comparing standard CNNs with neuro-fuzzy hybrids (DCNFIS) across various datasets under adversarial attack simulations (PGD and Square attacks).", "result": "ResNet18-ANFIS showed better robustness against adversarial attacks while VGG-ANFIS performed poorly compared to its baseline. Improvement in robustness varies by architecture.", "conclusion": "Neuro-fuzzy augmentation offers potential robustness improvements for certain CNN architectures, but cannot be considered universally applicable or beneficial."}}
{"id": "2602.08782", "pdf": "https://arxiv.org/pdf/2602.08782", "abs": "https://arxiv.org/abs/2602.08782", "authors": ["Tommy Rochussen", "Vincent Fortuin"], "title": "Amortising Inference and Meta-Learning Priors in Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted at ICLR 2026", "summary": "One of the core facets of Bayesianism is in the updating of prior beliefs in light of new evidence$\\text{ -- }$so how can we maintain a Bayesian approach if we have no prior beliefs in the first place? This is one of the central challenges in the field of Bayesian deep learning, where it is not clear how to represent beliefs about a prediction task by prior distributions over model parameters. Bridging the fields of Bayesian deep learning and probabilistic meta-learning, we introduce a way to $\\textit{learn}$ a weights prior from a collection of datasets by introducing a way to perform per-dataset amortised variational inference. The model we develop can be viewed as a neural process whose latent variable is the set of weights of a BNN and whose decoder is the neural network parameterised by a sample of the latent variable itself. This unique model allows us to study the behaviour of Bayesian neural networks under well-specified priors, use Bayesian neural networks as flexible generative models, and perform desirable but previously elusive feats in neural processes such as within-task minibatching or meta-learning under extreme data-starvation.", "AI": {"tldr": "The paper introduces a novel approach to learn a weights prior for Bayesian neural networks (BNNs) by using variational inference across datasets.", "motivation": "To address the issue in Bayesian deep learning where it is unclear how to define prior beliefs due to the lack of prior distributions over model parameters.", "method": "The paper proposes a model inspired by neural processes, treating BNN weights as a latent variable and parameterizing the decoder as a function of this variable, using per-dataset amortised variational inference.", "result": "The new model enables better handling of well-specified priors, flexibility in using BNNs as generative models, and advances in tasks like minibatching and meta-learning in resource-constrained settings.", "conclusion": "This approach bridges Bayesian deep learning and probabilistic meta-learning effectively, showcasing its applicability to challenging tasks and enhancing understanding of BNNs."}}
{"id": "2602.07308", "pdf": "https://arxiv.org/pdf/2602.07308", "abs": "https://arxiv.org/abs/2602.07308", "authors": ["Sutapa Dey Tithi", "Nazia Alam", "Tahreem Yasir", "Yang Shi", "Xiaoyi Tian", "Min Chi", "Tiffany Barnes"], "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System", "categories": ["cs.AI"], "comment": null, "summary": "The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.", "AI": {"tldr": "The paper investigates the ICAP framework's four engagement levels by developing an adaptive system that uses Guided and Buggy examples, leveraging BKT and DRL methods for tailoring learning in an ITS.", "motivation": "To address the challenge of personalizing learning activities in intelligent tutoring systems to optimize cognitive engagement levels for better learning outcomes.", "method": "The authors develop an adaptive system that dynamically selects Guided and Buggy worked examples using Bayesian Knowledge Tracing and Deep Reinforcement Learning compared to a non-adaptive baseline.", "result": "Experimental results with 113 students show adaptive methods significantly improved learning outcomes. BKT benefited low prior knowledge students, while DRL improved high prior knowledge students.", "conclusion": "The paper highlights the complex interplay between cognitive engagement and adaptivity, demonstrating that tailored methods can enhance student learning outcomes based on their knowledge levels."}}
{"id": "2602.07144", "pdf": "https://arxiv.org/pdf/2602.07144", "abs": "https://arxiv.org/abs/2602.07144", "authors": ["Samuel Daulton", "David Eriksson", "Maximilian Balandat", "Eytan Bakshy"], "title": "BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "26 pages", "summary": "Bayesian optimization (BO) is a popular technique for sample-efficient optimization of black-box functions. In many applications, the parameters being tuned come with a carefully engineered default configuration, and practitioners only want to deviate from this default when necessary. Standard BO, however, does not aim to minimize deviation from the default and, in practice, often pushes weakly relevant parameters to the boundary of the search space. This makes it difficult to distinguish between important and spurious changes and increases the burden of vetting recommendations when the optimization objective omits relevant operational considerations. We introduce BONSAI, a default-aware BO policy that prunes low-impact deviations from a default configuration while explicitly controlling the loss in acquisition value. BONSAI is compatible with a variety of acquisition functions, including expected improvement and upper confidence bound (GP-UCB). We theoretically bound the regret incurred by BONSAI, showing that, under certain conditions, it enjoys the same no-regret property as vanilla GP-UCB. Across many real-world applications, we empirically find that BONSAI substantially reduces the number of non-default parameters in recommended configurations while maintaining competitive optimization performance, with little effect on wall time.", "AI": {"tldr": "BONSAI is proposed to prevent unnecessary deviations from default configurations in Bayesian Optimization, ensuring more practical optimization outcomes.", "motivation": "Practitioners often face challenges with standard Bayesian Optimization as it pushes parameters to boundaries, making it hard to differentiate meaningful impacts. The need arises to minimize deviation from default and reduce vetting burdens.", "method": "BONSAI, a default-aware Bayesian Optimization policy, prunes low-impact deviations from defaults and controls the acquisition loss. It supports various acquisition functions and theoretically ensures no-regret performance under certain conditions.", "result": "BONSAI effectively reduces the number of non-default parameters in configurations while maintaining competitive optimization performance across real-world applications.", "conclusion": "BONSAI provides a practical optimization approach, improving relevance of recommendations and maintaining efficiency without additional computational cost."}}
{"id": "2602.08923", "pdf": "https://arxiv.org/pdf/2602.08923", "abs": "https://arxiv.org/abs/2602.08923", "authors": ["Wenchen Han", "Shay Vargaftik", "Michael Mitzenmacher", "Ran Ben Basat"], "title": "DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": "18 pages, 18 figures", "summary": "Multi-hop all-reduce is the de facto backbone of large model training. As the training scale increases, the network often becomes a bottleneck, motivating reducing the volume of transmitted data. Accordingly, recent systems demonstrated significant acceleration of the training process using gradient quantization. However, these systems are not optimized for multi-hop aggregation, where entries are partially summed multiple times along their aggregation topology.\n  This paper presents DynamiQ, a quantization framework that bridges the gap between quantization best practices and multi-hop aggregation. DynamiQ introduces novel techniques to better represent partial sums, co-designed with a decompress-accumulate-recompress fused kernel to facilitate fast execution.\n  We extended PyTorch DDP to support DynamiQ over NCCL P2P, and across different LLMs, tasks, and scales, we demonstrate consistent improvement of up to 34.2% over the best among state-of-the-art methods such as Omni-Reduce, THC, and emerging standards such as MXFP4, MXFP6, and MXFP8. Further, DynamiQ is the only evaluated method that consistently reaches near-baseline accuracy (e.g., 99.9% of the BF16 baseline) and does so while significantly accelerating the training.", "AI": {"tldr": "DynamiQ is a quantization framework designed to optimize multi-hop all-reduce operations during large model training, demonstrating up to 34.2% improvement in speed and maintaining near-baseline accuracy.", "motivation": "The motivation is to address the network bottleneck caused by large-scale training and improve the efficiency of multi-hop all-reduce operations.", "method": "DynamiQ introduces new techniques for better representation of partial sums, implements a decompress-accumulate-recompress fused kernel, and integrates with PyTorch DDP to enhance performance in multi-hop aggregation.", "result": "DynamiQ achieves up to 34.2% improvement over state-of-the-art methods and consistently maintains near-baseline accuracy in various large language models and tasks.", "conclusion": "DynamiQ successfully bridges quantization practices with multi-hop aggregation, accelerating training processes while maintaining high accuracy."}}
{"id": "2602.07709", "pdf": "https://arxiv.org/pdf/2602.07709", "abs": "https://arxiv.org/abs/2602.07709", "authors": ["Mrunali Manjrekar", "Runzhong Wang", "Samuel Goldman", "Jenna C. Fromer", "Connor W. Coley"], "title": "Generative structural elucidation from mass spectra as an iterative optimization problem", "categories": ["q-bio.QM", "cs.NE"], "comment": null, "summary": "Liquid chromatography tandem mass spectrometry (LC-MS/MS) is a critical analytical technique for molecular identification across metabolomics, environmental chemistry, and chemical forensics. A variety of computational methods have emerged for structural annotation of spectral features of interest, but many of these features cannot be confidently annotated with reference structures or spectra. Here, we introduce FOAM (Formula-constrained Optimization for Annotating Metabolites), a computational workflow that poses structure elucidation from LC-MS/MS as an iterative optimization problem. FOAM couples a formula-constrained graph genetic algorithm with spectral simulation to explore candidate annotations given an experimental spectrum. We demonstrate FOAM's performance on the NIST'20 and MassSpecGym datasets as both a standalone elucidation pipeline and as a complement to existing inverse models. This work establishes iterative optimization as an effective and extensible paradigm for structural elucidation.", "AI": {"tldr": "The paper introduces FOAM, a computational workflow for LC-MS/MS structural elucidation using optimization.", "motivation": "To address the challenge of confidently annotating spectral features in LC-MS/MS that lack reference structures or spectra.", "method": "Proposes FOAM, combining formula-constrained graph genetic algorithms with spectral simulations to annotate molecular structures iteratively.", "result": "FOAM demonstrates strong performance on NIST'20 and MassSpecGym datasets both as a standalone tool and in complementing existing methods.", "conclusion": "Iterative optimization is an effective and flexible approach for LC-MS/MS structural elucidation."}}
{"id": "2602.07609", "pdf": "https://arxiv.org/pdf/2602.07609", "abs": "https://arxiv.org/abs/2602.07609", "authors": ["Ruoyu Su", "Alexander Bakhtin", "Noman Ahmad", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Evaluating Large Language Models for Detecting Architectural Decision Violations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.", "AI": {"tldr": "The study investigates the use of Large Language Models (LLMs) to automate identification of architectural decision violations in software. Using a multi-model pipeline to analyze 980 ADRs from GitHub, LLMs show promise but are limited for implicit or deployment-related decisions.", "motivation": "Software projects often lack systematic documentation and automated mechanisms to detect architectural decision violations, which compromises quality. The motivation is to explore LLMs as a tool to improve automation and reasoning around these decisions.", "method": "The study uses a multi-model pipeline where one LLM identifies potential violations and three other LLMs validate the reasoning. It examines 980 ADRs across 109 GitHub repositories, evaluating metrics like agreement, accuracy, precision, and recall, complemented with expert reviews.", "result": "LLMs demonstrated high agreement and strong accuracy for explicit, code-based architectural decisions. Performance declined for implicit or deployment-related decisions due to their dependency on non-code factors.", "conclusion": "LLMs are effective in supporting architectural decision compliance for code-focused decisions but cannot fully replace human expertise for decisions requiring contextual or organizational knowledge."}}
{"id": "2602.07209", "pdf": "https://arxiv.org/pdf/2602.07209", "abs": "https://arxiv.org/abs/2602.07209", "authors": ["Spencer Teetaert", "Giammarco Caroleo", "Marco Pontin", "Sven Lilge", "Jessica Burgner-Kahrs", "Timothy D. Barfoot", "Perla Maiolino"], "title": "Continuum Robot Localization using Distributed Time-of-Flight Sensors", "categories": ["cs.RO"], "comment": null, "summary": "Localization and mapping of an environment are crucial tasks for any robot operating in unstructured environments. Time-of-flight (ToF) sensors (e.g.,~lidar) have proven useful in mobile robotics, where high-resolution sensors can be used for simultaneous localization and mapping. In soft and continuum robotics, however, these high-resolution sensors are too large for practical use. This, combined with the deformable nature of such robots, has resulted in continuum robot (CR) localization and mapping in unstructured environments being a largely untouched area. In this work, we present a localization technique for CRs that relies on small, low-resolution ToF sensors distributed along the length of the robot. By fusing measurement information with a robot shape prior, we show that accurate localization is possible despite each sensor experiencing frequent degenerate scenarios. We achieve an average localization error of 2.5cm in position and 7.2\u00b0 in rotation across all experimental conditions with a 53cm long robot. We demonstrate that the results are repeated across multiple environments, in both simulation and real-world experiments, and study robustness in the estimation to deviations in the prior map.", "AI": {"tldr": "This paper presents a localization technique for continuum robots (CRs) using low-resolution time-of-flight sensors distributed along the robot's length, achieving high accuracy in unstructured environments.", "motivation": "Accurate localization and mapping in unstructured environments for continuum robots (CRs) are challenging due to their deformable nature and limitations of high-resolution sensors.", "method": "The technique fuses measurements from low-resolution ToF sensors with a robot shape prior to achieve accurate localization, minimizing errors from frequent degenerate scenarios.", "result": "The authors achieve an average error of 2.5cm in position and 7.2\u00b0 in rotation in a 53cm long robot, with consistent performance across real-world and simulated environments.", "conclusion": "The proposed method demonstrates robust and repeatable localization capabilities for CRs in unstructured environments, overcoming traditional sensor limitations."}}
{"id": "2602.07375", "pdf": "https://arxiv.org/pdf/2602.07375", "abs": "https://arxiv.org/abs/2602.07375", "authors": ["Peiqi Yu", "Jinhao Wang", "Xinyi Sui", "Nam Ling", "Wei Wang", "Wei Jiang"], "title": "Efficient Post-Training Pruning of Large Language Models with Statistical Correction", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 2 figures, 5 tables", "summary": "Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.", "AI": {"tldr": "This paper proposes a lightweight framework for pruning large language models (LLMs) post-training using statistical properties. It balances efficiency and pruning quality without requiring retraining or heavy computations.", "motivation": "Existing pruning methods either focus on efficiency but are prone to activation outliers, or are computationally expensive but achieve better fidelity. The goal is to find a balance between efficiency and pruning quality.", "method": "The method calibrates magnitude-based importance scores using channel-wise statistics during pruning and applies energy compensation to mitigate bias caused by weight removal. It avoids retraining, gradients, and second-order information.", "result": "The framework demonstrates improved pruning performance across various LLM families, sparsity patterns, and evaluation tasks, comparable in computational cost to heuristic methods.", "conclusion": "Simple statistical adjustments can significantly enhance post-training pruning in LLMs, achieving a favorable trade-off between quality and efficiency."}}
{"id": "2602.07038", "pdf": "https://arxiv.org/pdf/2602.07038", "abs": "https://arxiv.org/abs/2602.07038", "authors": ["Yifan Ji", "Zhipeng Xu", "Zhenghao Liu", "Zulong Chen", "Qian Zhang", "Zhibo Yang", "Junyang Lin", "Yu Gu", "Ge Yu", "Maosong Sun"], "title": "UNIKIE-BENCH: Benchmarking Large Multimodal Models for Key Information Extraction in Visual Documents", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Key Information Extraction (KIE) from real-world documents remains challenging due to substantial variations in layout structures, visual quality, and task-specific information requirements. Recent Large Multimodal Models (LMMs) have shown promising potential for performing end-to-end KIE directly from document images. To enable a comprehensive and systematic evaluation across realistic and diverse application scenarios, we introduce UNIKIE-BENCH, a unified benchmark designed to rigorously evaluate the KIE capabilities of LMMs. UNIKIE-BENCH consists of two complementary tracks: a constrained-category KIE track with scenario-predefined schemas that reflect practical application needs, and an open-category KIE track that extracts any key information that is explicitly present in the document. Experiments on 15 state-of-the-art LMMs reveal substantial performance degradation under diverse schema definitions, long-tail key fields, and complex layouts, along with pronounced performance disparities across different document types and scenarios. These findings underscore persistent challenges in grounding accuracy and layout-aware reasoning for LMM-based KIE. All codes and datasets are available at https://github.com/NEUIR/UNIKIE-BENCH.", "AI": {"tldr": "The paper presents UNIKIE-BENCH, a benchmark designed to evaluate the effectiveness of Large Multimodal Models (LMMs) in extracting key information from diverse real-world documents. It features two tracks for different extraction scenarios.", "motivation": "To address the challenges of Key Information Extraction (KIE) from documents, including diverse layouts, quality inconsistencies, and varied task-specific needs, and to systematically evaluate LMMs.", "method": "Introducing UNIKIE-BENCH, which comprises two tracks: constrained-category KIE (predefined schemas) and open-category KIE (any information extraction). Experiments are performed using 15 state-of-the-art LMMs.", "result": "Findings reveal substantial degradation in performance under diverse scenarios, schema variations, and document complexities; highlighting challenges in layout-aware reasoning for LMMs.", "conclusion": "LMMs face persistent challenges in grounding accuracy and handling diverse document scenarios despite showing potential for end-to-end KIE."}}
{"id": "2602.08849", "pdf": "https://arxiv.org/pdf/2602.08849", "abs": "https://arxiv.org/abs/2602.08849", "authors": ["Terry C. W. Lam", "Niamh O'Neill", "Christoph Schran", "Lars L. Schaaf"], "title": "Cutting Through the Noise: On-the-fly Outlier Detection for Robust Training of Machine Learning Interatomic Potentials", "categories": ["stat.ML", "cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "comment": "12 pages, 6 figures", "summary": "The accuracy of machine learning interatomic potentials suffers from reference data that contains numerical noise. Often originating from unconverged or inconsistent electronic-structure calculations, this noise is challenging to identify. Existing mitigation strategies such as manual filtering or iterative refinement of outliers, require either substantial expert effort or multiple expensive retraining cycles, making them difficult to scale to large datasets. Here, we introduce an on-the-fly outlier detection scheme that automatically down-weights noisy samples, without requiring additional reference calculations. By tracking the loss distribution via an exponential moving average, this unsupervised method identifies outliers throughout a single training run. We show that this approach prevents overfitting and matches the performance of iterative refinement baselines with significantly reduced overhead. The method's effectiveness is demonstrated by recovering accurate physical observables for liquid water from unconverged reference data, including diffusion coefficients. Furthermore, we validate its scalability by training a foundation model for organic chemistry on the SPICE dataset, where it reduces energy errors by a factor of three. This framework provides a simple, automated solution for training robust models on imperfect datasets across dataset sizes.", "AI": {"tldr": "The paper proposes an on-the-fly outlier detection method to address noise in machine learning interatomic potential datasets caused by unconverged calculations. This approach avoids additional reference computation and prevents overfitting while achieving significant performance improvements.", "motivation": "To address the issue of numerical noise in reference datasets for machine learning interatomic potentials, especially when these errors stem from unconverged or inconsistent calculations, which hinder model accuracy and are challenging to mitigate at scale.", "method": "The authors introduce an unsupervised on-the-fly outlier detection technique. By monitoring loss distribution using an exponential moving average, this method automatically identifies and down-weights noisy data points during a single training run, eliminating the need for additional reference calculations or manual intervention.", "result": "The proposed method prevents overfitting and matches the performance of iterative refinement baselines, with significantly reduced computational overhead. It accurately reproduces physical observables for liquid water and scales to large datasets like the SPICE dataset, improving energy error reduction by a factor of three.", "conclusion": "This framework offers an automated, efficient solution for training robust machine learning models on noisy or imperfect datasets, supporting scalability and broad applicability in scientific and engineering domains."}}
{"id": "2602.07339", "pdf": "https://arxiv.org/pdf/2602.07339", "abs": "https://arxiv.org/abs/2602.07339", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.", "AI": {"tldr": "RAPiD is an optimized trajectory planning framework that eliminates diffusion sampling to achieve faster and safer decision-making.", "motivation": "To address the real-time and safety-critical challenges faced by diffusion-based trajectory planners that rely on iterative stochastic sampling.", "method": "RAPiD uses score-regularized policy optimization to distill pretrained diffusion-based planners into deterministic policies, supported by a critic trained for safety and comfort.", "result": "RAPiD achieves an 8x speedup over diffusion baselines in nuPlan scenarios and outperforms competitors in generalization on the interPlan benchmark.", "conclusion": "RAPiD demonstrates improved efficiency, safety, and generalization, making it practical for real-time trajectory planning."}}
{"id": "2602.07145", "pdf": "https://arxiv.org/pdf/2602.07145", "abs": "https://arxiv.org/abs/2602.07145", "authors": ["Zhiqi Bu", "Shiyun Xu", "Jialin Mao"], "title": "Convex Dominance in Deep Learning I: A Scaling Law of Loss and Learning Rate", "categories": ["cs.LG", "cs.CL", "math.OC"], "comment": "Part of a planned series to understand and leverage the convexity in deep learning. Accepted to ICLR 2026", "summary": "Deep learning has non-convex loss landscape and its optimization dynamics is hard to analyze or control. Nevertheless, the dynamics can be empirically convex-like across various tasks, models, optimizers, hyperparameters, etc. In this work, we examine the applicability of convexity and Lipschitz continuity in deep learning, in order to precisely control the loss dynamics via the learning rate schedules. We illustrate that deep learning quickly becomes weakly convex after a short period of training, and the loss is predicable by an upper bound on the last iterate, which further informs the scaling of optimal learning rate. Through the lens of convexity, we build scaling laws of learning rates and losses that extrapolate as much as 80X across training horizons and 70X across model sizes.", "AI": {"tldr": "The paper investigates the convexity and Lipschitz continuity properties in deep learning to understand and control loss dynamics via learning rate schedules, establishing scaling laws for learning rates and losses.", "motivation": "The motivation behind the paper is to address the challenge of analyzing and controlling the optimization dynamics in deep learning, which typically involves non-convex loss landscapes but exhibits convex-like empirical behavior.", "method": "The authors explore the weak convexity property in deep learning loss landscapes after initial training, develop upper bounds on loss, and establish scaling laws for learning rates and losses across varying training stages and model sizes.", "result": "They demonstrate that deep learning becomes weakly convex early in training, enabling prediction and control of loss dynamics. Their scaling laws successfully extrapolate learning rates and losses across broad training horizons (up to 80X) and model sizes (up to 70X).", "conclusion": "Convexity and Lipschitz continuity properties in deep learning provide reliable ways to understand and improve optimization dynamics through targeted learning rate schedules, with implications for scaling and modeling performance."}}
{"id": "2602.07800", "pdf": "https://arxiv.org/pdf/2602.07800", "abs": "https://arxiv.org/abs/2602.07800", "authors": ["Rahul Padmanabhan", "Simone Brugiapaglia"], "title": "Approximating Matrix Functions with Deep Neural Networks and Transformers", "categories": ["cs.LG", "cs.NE", "math.NA"], "comment": null, "summary": "Transformers have revolutionized natural language processing, but their use for numerical computation has received less attention. We study the approximation of matrix functions, which map scalar functions to matrices, using neural networks including transformers. We focus on functions mapping square matrices to square matrices of the same dimension. These types of matrix functions appear throughout scientific computing, e.g., the matrix exponential in continuous-time Markov chains and the matrix sign function in stability analysis of dynamical systems. In this paper, we make two contributions. First, we prove bounds on the width and depth of ReLU networks needed to approximate the matrix exponential to an arbitrary precision. Second, we show experimentally that a transformer encoder-decoder with suitable numerical encodings can approximate certain matrix functions at a relative error of 5% with high probability. Our study reveals that the encoding scheme strongly affects performance, with different schemes working better for different functions.", "AI": {"tldr": "The paper explores using transformers for numerical computation, specifically for approximating matrix functions, presenting both theoretical bounds and experimental results.", "motivation": "To address the gap in research concerning the use of neural networks, including transformers, for numerical computations related to matrix functions.", "method": "The paper provides theoretical bounds for the ReLU neural network size required to approximate the matrix exponential and conducts experiments using a transformer encoder-decoder with numerical encodings to assess performance.", "result": "The authors demonstrate that a transformer encoder-decoder can approximate matrix functions with a 5% relative error under specific numerical encoding schemes. Different encoding schemes yield varied performance.", "conclusion": "Transformers have potential in numerical computation for matrix functions, but choice of numerical encoding strongly impacts their effectiveness."}}
{"id": "2602.07641", "pdf": "https://arxiv.org/pdf/2602.07641", "abs": "https://arxiv.org/abs/2602.07641", "authors": ["Marc Bara"], "title": "HAIF: A Human-AI Integration Framework for Hybrid Team Operations", "categories": ["cs.SE", "cs.HC"], "comment": "22 pages, 4 figures, 5 tables, 2 appendices", "summary": "The rapid deployment of generative AI, copilots, and agentic systems in knowledge work has created an operational gap: no existing framework addresses how to organize daily work in teams where AI agents perform substantive, delegated tasks alongside humans. Agile, DevOps, MLOps, and AI governance frameworks each cover adjacent concerns but none models the hybrid team as a coherent delivery unit. This paper proposes the Human-AI Integration Framework (HAIF): a protocol-based, scalable operational system built around four core principles, a formal delegation decision model, tiered autonomy with quantifiable transition criteria, and feedback mechanisms designed to integrate into existing Agile and Kanban workflows without requiring additional roles for small teams. The framework is developed following a Design Science Research methodology. HAIF explicitly addresses the central adoption paradox: the more capable AI becomes, the harder it is to justify the oversight the framework demands-and yet the greater the consequences of not providing it. The paper includes domain-specific validation checklists, adaptation guidance for non-software environments, and an examination of the framework's structural limitations-including the increasingly common pattern of continuous human-AI co-production that challenges the discrete delegation model. The framework is tool-agnostic and designed for iterative adoption. Empirical validation is identified as future work.", "AI": {"tldr": "This paper introduces the Human-AI Integration Framework (HAIF), an operational system for hybrid teams composed of humans and AI agents, addressing the lack of frameworks for such teams.", "motivation": "Address the operational gap in organizing work in teams where AI agents perform substantive, delegated tasks alongside humans.", "method": "Develop HAIF based on Design Science Research methodology. HAIF is protocol-based with four principles, formal delegation decision model, tiered autonomy, and feedback mechanisms.", "result": "HAIF integrates with Agile and Kanban workflows without requiring new roles for small teams, offers validation checklists, and adaptation guidance for environments outside software domains.", "conclusion": "HAIF is a scalable, tool-agnostic framework aimed at iterative adoption, while highlighting structural challenges and the paradox of oversight as AI capabilities grow. Empirical validation is a future task."}}
{"id": "2602.07243", "pdf": "https://arxiv.org/pdf/2602.07243", "abs": "https://arxiv.org/abs/2602.07243", "authors": ["Siddharth Singh", "Ifrah Idrees", "Abraham Dauhajre"], "title": "Realistic Synthetic Household Data Generation at Scale", "categories": ["cs.RO", "cs.AI", "cs.GR"], "comment": "Accepted at Agentic AI Benchmarks and Applications for Enterprise Tasks workshop at AAAI 2026", "summary": "Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthetic data for long-term human-robot interactions but fail to model the bidirectional influence between human behavior and household environments. Our proposed generative framework creates household datasets at scale through loosely coupled generation of long-term human-robot interactions and environments. Human personas influence environment generation, while environment schematics and semantics shape human-robot interactions.\n  The generated 3D data includes rich static context such as object and environment semantics, and temporal context capturing human and agent behaviors over extended periods. Our flexible tool allows users to define dataset characteristics via natural language prompts, enabling configuration of environment and human activity data through natural language specifications. The tool creates variations of user-defined configurations, enabling scalable data generation.\n  We validate our framework through statistical evaluation using multi-modal embeddings and key metrics: cosine similarity, mutual information gain, intervention analysis, and iterative improvement validation. Statistical comparisons show good alignment with real-world datasets (HOMER) with cosine similarity (0.60), while synthetic datasets (Wang et al.) show moderate alignment (0.27). Intervention analysis across age, organization, and sleep pattern changes shows statistically significant effects (p < 0.001) with large effect sizes (Cohen's d = 0.51-1.12), confirming bidirectional coupling translates persona traits into measurable environmental and behavioral differences. These contributions enable development and testing of household smart devices at scale.", "AI": {"tldr": "The paper introduces a framework to generate scalable household datasets with human-robot interactions influenced by dynamic environmental and behavioral factors, aligning well with real-world metrics and enabling smart device testing.", "motivation": "The motivation is to address shortcomings in prior frameworks that inadequately model the interplay between human behaviors and household environments and to aid advancements in Embodied AI through diverse, large-scale datasets.", "method": "The framework generates household data by simulating human-robot interactions and environmental variables through a loosely coupled generative process, guided by natural language prompts for flexible customization.", "result": "The generated datasets include both static environmental semantics and temporal human-agent behavioral context, validated statistically with metrics showing strong alignment with real-world data and significant bidirectional influences.", "conclusion": "The proposed framework contributes towards scalable testing and development of smart household devices, modeling real-world human and environmental interdependencies effectively."}}
{"id": "2602.07376", "pdf": "https://arxiv.org/pdf/2602.07376", "abs": "https://arxiv.org/abs/2602.07376", "authors": ["Usman Naseem", "Gautam Siddharth Kashyap", "Sushant Kumar Ray", "Rafiq Ali", "Ebad Shabbir", "Abdullah Mohammad"], "title": "Do Large Language Models Reflect Demographic Pluralism in Safety?", "categories": ["cs.CL"], "comment": "Accepted at EACL Findings 2026", "summary": "Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.", "AI": {"tldr": "This paper introduces Demo-SafetyBench to address the lack of demographic diversity in LLM safety alignment datasets by evaluating pluralistic sensitivity across 14 safety domains and multiple demographic contexts.", "motivation": "Existing methods of LLM alignment ignore diverse safety perceptions across different communities, relying on narrow annotator pools.", "method": "The authors developed Demo-SafetyBench by reclassifying prompts using models (Mistral and Llama) into 14 distinct safety domains while retaining demographic metadata. They expanded coverage for low-resource domains and used pluralistic sensitivity evaluation with zero-shot inference and balanced thresholds.", "result": "Demo-SafetyBench achieved high reliability and low demographic sensitivity while modeling safety across varied demographic contexts.", "conclusion": "Pluralistic safety evaluation for LLMs can scale effectively while maintaining demographic robustness, enhancing model alignment across diverse communities."}}
{"id": "2602.07041", "pdf": "https://arxiv.org/pdf/2602.07041", "abs": "https://arxiv.org/abs/2602.07041", "authors": ["Leeje Jang", "Yao-Yi Chiang", "Angela M. Hastings", "Patimaporn Pungchanchaikul", "Martha B. Lucas", "Emily C. Schultz", "Jeffrey P. Louie", "Mohamed Estai", "Wen-Chen Wang", "Ryan H. L. Ip", "Boyen Huang"], "title": "OMNI-Dent: Towards an Accessible and Explainable AI Framework for Automated Dental Diagnosis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Accurate dental diagnosis is essential for oral healthcare, yet many individuals lack access to timely professional evaluation. Existing AI-based methods primarily treat diagnosis as a visual pattern recognition task and do not reflect the structured clinical reasoning used by dental professionals. These approaches also require large amounts of expert-annotated data and often struggle to generalize across diverse real-world imaging conditions. To address these limitations, we present OMNI-Dent, a data-efficient and explainable diagnostic framework that incorporates clinical reasoning principles into a Vision-Language Model (VLM)-based pipeline. The framework operates on multi-view smartphone photographs,embeds diagnostic heuristics from dental experts, and guides a general-purpose VLM to perform tooth-level evaluation without dental-specific fine-tuning of the VLM. By utilizing the VLM's existing visual-linguistic capabilities, OMNI-Dent aims to support diagnostic assessment in settings where curated clinical imaging is unavailable. Designed as an early-stage assistive tool, OMNI-Dent helps users identify potential abnormalities and determine when professional evaluation may be needed, offering a practical option for individuals with limited access to in-person care.", "AI": {"tldr": "OMNI-Dent is a data-efficient and explainable diagnostic framework integrating clinical reasoning into a Vision-Language Model (VLM) pipeline for tooth-level evaluation using smartphone photos.", "motivation": "Dental diagnosis is often inaccessible for many individuals due to barriers in timely professional evaluation, existing AI methods lack incorporation of clinical reasoning, and they struggle with real-world imaging conditions.", "method": "OMNI-Dent uses multi-view smartphone photographs and embeds diagnostic heuristics into a VLM-based framework to provide tooth-level evaluation without requiring dental-specific VLM fine-tuning.", "result": "The system leverages the visual-linguistic capabilities of VLM for diagnostic assessment in non-clinical imaging environments and identifies abnormalities while guiding users towards professional care.", "conclusion": "OMNI-Dent serves as a practical early-stage tool aiding individuals with limited healthcare access to detect potential dental concerns and decide on professional evaluation."}}
{"id": "2602.08892", "pdf": "https://arxiv.org/pdf/2602.08892", "abs": "https://arxiv.org/abs/2602.08892", "authors": ["Hamsa Bastani", "Osbert Bastani", "Bryce McLaughlin"], "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": null, "summary": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation.", "AI": {"tldr": "The paper critiques the model-based policy evaluation methodology widely used in data-driven decision-making as prone to optimistic bias due to the winner's curse.", "motivation": "The motivation is to address the widespread use of flawed model-based policy evaluation methods that lead to biased and overly optimistic effectiveness of policies.", "method": "The paper combines theoretical analysis and a simulation study to demonstrate the inherent flaws of the model-based policy evaluation methodology, particularly concerning the winner's curse.", "result": "The study finds that even under commonly used justifications, model-based policy evaluation significantly overestimates benefits\u2014in one simulation, the reported gains were fabricated despite no actual improvement over random assignment.", "conclusion": "The paper provides evidence that model-based evaluation methods are unreliable and advocates against their use for policy evaluation in data-driven decision-making."}}
{"id": "2602.07342", "pdf": "https://arxiv.org/pdf/2602.07342", "abs": "https://arxiv.org/abs/2602.07342", "authors": ["Shengyue Guan", "Yihao Liu", "Lang Cao"], "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world benchmark that assesses both supply chain domain knowledge and long-horizon tool-based orchestration grounded in standard operating procedures (SOPs). Our experiments reveal substantial gaps in execution reliability across models. We further propose SupChain-ReAct, an SOP-free framework that autonomously synthesizes executable procedures for tool use, achieving the strongest and most consistent tool-calling performance. Our work establishes a principled benchmark for studying reliable long-horizon orchestration in real-world operational settings and highlights significant room for improvement in LLM-based supply chain agents.", "AI": {"tldr": "This paper evaluates large language models (LLMs) for supply chain management, introducing a benchmark and a novel framework to address existing challenges.", "motivation": "To explore the potential of LLMs in real-world supply chain management, addressing their current limitations in reliable long-horizon, multi-step orchestration grounded in domain-specific processes.", "method": "The authors introduced SupChain-Bench as a benchmark for assessing supply chain management capabilities and proposed SupChain-ReAct, a framework for synthesizing procedures without relying on standard operating procedures (SOPs).", "result": "The study identified gaps in execution reliability for existing LLMs and demonstrated that SupChain-ReAct outperformed other models in tool-calling tasks.", "conclusion": "The work provides an important benchmark for assessing LLMs in supply chain contexts and introduces a novel framework, but it also underscores the need for significant improvements in the field."}}
{"id": "2602.07150", "pdf": "https://arxiv.org/pdf/2602.07150", "abs": "https://arxiv.org/abs/2602.07150", "authors": ["Bjarni Haukur Bjarnason", "Andr\u00e9 Silva", "Martin Monperrus"], "title": "On Randomness in Agentic Evals", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by collecting 60,000 agentic trajectories on SWE-Bench-Verified, spanning three models and two scaffolds. We find substantial variance: single-run pass@1 estimates vary by 2.2 to 6.0 percentage points depending on which run is selected, with standard deviations exceeding 1.5 percentage points even at temperature 0. This variance has critical implications: reported improvements of 2--3 percentage points may reflect evaluation noise rather than genuine algorithmic progress. Through token-level analysis, we show that trajectories diverge early, often within the first few percent of tokens, and that these small differences cascade into different solution strategies. To enable reliable evaluation of agentic systems, we recommend three concrete practices: (1) estimate pass@1 from multiple independent runs per task, especially when measuring small improvements, (2) use statistical power analysis to determine the number of runs needed to detect expected effect sizes, and (3) consider metrics like pass@k (optimistic bound) and pass^k (pessimistic bound) with k>1 to better characterize the full performance envelope. While these practices increase evaluation cost, they are essential for distinguishing genuine scientific progress from statistical noise.", "AI": {"tldr": "This paper evaluates the reliability of agentic systems' performance measures, such as pass@1 scores, and highlights significant variance in single-run estimates, recommending improved evaluation practices.", "motivation": "To address the assumption that single-run pass@1 scores provide reliable performance estimates, and to investigate the potential noise and lack of precision in such evaluations.", "method": "The authors collected 60,000 agentic trajectories on SWE-Bench-Verified, exploring variance across three models and two scaffolds, while performing token-level analysis to identify sources of trajectory divergence.", "result": "Substantial variance in single-run pass@1 scores was observed (2.2-6.0 percentage points variance, with standard deviations over 1.5 percentage points). Early token divergences were shown to cascade into different task solution strategies.", "conclusion": "Single-run evaluation does not reliably measure agentic system performance due to high variance. The paper recommends practices to improve evaluation reliability, including multiple runs per task, statistical power analysis, and alternative metrics like pass@k/pass^k."}}
{"id": "2602.08515", "pdf": "https://arxiv.org/pdf/2602.08515", "abs": "https://arxiv.org/abs/2602.08515", "authors": ["Muhammad Luthfi Shahab", "Imam Mukhlash", "Hadi Susanto"], "title": "Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm", "categories": ["math.NA", "cs.LG", "cs.NE", "math.OC"], "comment": null, "summary": "This work investigates the use of shallow physics-informed neural networks (PINNs) for solving forward and inverse problems of nonlinear partial differential equations (PDEs). By reformulating PINNs as nonlinear systems, the Levenberg-Marquardt (LM) algorithm is employed to efficiently optimize the network parameters. Analytical expressions for the neural network derivatives with respect to the input variables are derived, enabling accurate and efficient computation of the Jacobian matrix required by LM. The proposed approach is tested on several benchmark problems, including the Burgers, Schr\u00f6dinger, Allen-Cahn, and three-dimensional Bratu equations. Numerical results demonstrate that LM significantly outperforms BFGS in terms of convergence speed, accuracy, and final loss values, even when using shallow network architectures with only two hidden layers. These findings indicate that, for a wide class of PDEs, shallow PINNs combined with efficient second-order optimization methods can provide accurate and computationally efficient solutions for both forward and inverse problems.", "AI": {"tldr": "This paper introduces shallow physics-informed neural networks (PINNs) optimized with the Levenberg-Marquardt algorithm for solving both forward and inverse nonlinear PDE problems.", "motivation": "The study aims to improve the efficiency and accuracy of solving nonlinear PDEs using shallow neural network architectures combined with advanced optimization methods.", "method": "Shallow PINNs are reformulated as nonlinear systems and optimized using the Levenberg-Marquardt algorithm. Analytical derivatives are derived to enhance computational accuracy and efficiency.", "result": "The approach was tested on benchmark PDEs and showed superior performance in convergence speed, accuracy, and loss minimization compared to BFGS optimization, even with shallow networks.", "conclusion": "Shallow PINNs, when paired with efficient second-order optimization techniques like LM, can effectively solve nonlinear PDE problems with high accuracy and computational efficiency."}}
{"id": "2602.07264", "pdf": "https://arxiv.org/pdf/2602.07264", "abs": "https://arxiv.org/abs/2602.07264", "authors": ["Jacopo Panerati", "Sina Sajjadi", "Sina Soleymanpour", "Varunkumar Mehta", "Iraj Mantegh"], "title": "aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones", "categories": ["cs.RO", "cs.AI", "cs.SE"], "comment": null, "summary": "Unmanned aerial vehicles are rapidly transforming multiple applications, from agricultural and infrastructure monitoring to logistics and defense. Introducing greater autonomy to these systems can simultaneously make them more effective as well as reliable. Thus, the ability to rapidly engineer and deploy autonomous aerial systems has become of strategic importance. In the 2010s, a combination of high-performance compute, data, and open-source software led to the current deep learning and AI boom, unlocking decades of prior theoretical work. Robotics is on the cusp of a similar transformation. However, physical AI faces unique hurdles, often combined under the umbrella term \"simulation-to-reality gap\". These span from modeling shortcomings to the complexity of vertically integrating the highly heterogeneous hardware and software systems typically found in field robots. To address the latter, we introduce aerial-autonomy-stack, an open-source, end-to-end framework designed to streamline the pipeline from (GPU-accelerated) perception to (flight controller-based) action. Our stack allows the development of aerial autonomy using ROS2 and provides a common interface for two of the most popular autopilots: PX4 and ArduPilot. We show that it supports over 20x faster-than-real-time, end-to-end simulation of a complete development and deployment stack -- including edge compute and networking -- significantly compressing the build-test-release cycle of perception-based autonomy.", "AI": {"tldr": "The paper introduces an open-source framework, aerial-autonomy-stack, that simplifies and accelerates the development of autonomous aerial systems by bridging perception and action while addressing challenges such as the simulation-to-reality gap.", "motivation": "The paper aims to enhance the autonomy, effectiveness, and reliability of unmanned aerial systems while addressing the challenges of simulation-to-reality gaps and the complexity of field robotics.", "method": "They developed an open-source end-to-end framework (aerial-autonomy-stack) that integrates GPU-accelerated perception with flight control actions using ROS2 and supports major autopilots like PX4 and ArduPilot.", "result": "The framework achieves over 20x faster-than-real-time end-to-end simulation for aerial autonomy development, streamlining the build-test-release cycle.", "conclusion": "The aerial-autonomy-stack significantly simplifies and speeds up the development and deployment of autonomous aerial systems, enabling advancements in aerial autonomy."}}
{"id": "2602.07381", "pdf": "https://arxiv.org/pdf/2602.07381", "abs": "https://arxiv.org/abs/2602.07381", "authors": ["Gautam Siddharth Kashyap", "Mark Dras", "Usman Naseem"], "title": "When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified", "categories": ["cs.CL"], "comment": "Accepted at EACL Mains 2026", "summary": "Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.", "AI": {"tldr": "The paper introduces AlignX, a framework improving language model alignment with human values via a two-stage process, addressing issues in fine-tuning and expert mixtures for multi-objective tasks.", "motivation": "To ensure the alignment of Large Language Models with human values (helpfulness, harmlessness, honesty) for their safe and effective deployment, overcoming limitations of interference in fine-tuning and inaccurate routing in mixtures of experts.", "method": "AlignX is a two-stage approach: first, it employs prompt-injected fine-tuning for task-specific features to reduce forgetting; second, it uses a MoCaE module that improves expert routing with fractal and natural geometry techniques.", "result": "AlignX exceeds benchmarks in helpfulness, harmlessness, and honesty (e.g., +171.5% win rate in Alpaca, +110.1% in truthfulness, and 4.3% fewer safety violations). It also enhances efficiency, reducing latency and memory usage by 35%.", "conclusion": "AlignX effectively addresses alignment challenges in Large Language Models, achieving superior multi-objective task performance, generalizability across models, and resource efficiency."}}
{"id": "2602.07042", "pdf": "https://arxiv.org/pdf/2602.07042", "abs": "https://arxiv.org/abs/2602.07042", "authors": ["Magesh Rajasekaran", "Md Saiful Islam Sajol", "Frej Berglind", "Supratik Mukhopadhyay", "Kamalika Das"], "title": "COMBOOD: A Semiparametric Approach for Detecting Out-of-distribution Data for Image Classification", "categories": ["cs.CV"], "comment": "Copyright by SIAM. Unauthorized reproduction of this article is prohibited First Published in Proceedings of the 2024 SIAM International Conference on Data Mining (SDM24), published by the Society for Industrial and Applied Mathematics (SIAM)", "summary": "Identifying out-of-distribution (OOD) data at inference time is crucial for many machine learning applications, especially for automation. We present a novel unsupervised semi-parametric framework COMBOOD for OOD detection with respect to image recognition. Our framework combines signals from two distance metrics, nearest-neighbor and Mahalanobis, to derive a confidence score for an inference point to be out-of-distribution. The former provides a non-parametric approach to OOD detection. The latter provides a parametric, simple, yet effective method for detecting OOD data points, especially, in the far OOD scenario, where the inference point is far apart from the training data set in the embedding space. However, its performance is not satisfactory in the near OOD scenarios that arise in practical situations. Our COMBOOD framework combines the two signals in a semi-parametric setting to provide a confidence score that is accurate both for the near-OOD and far-OOD scenarios. We show experimental results with the COMBOOD framework for different types of feature extraction strategies. We demonstrate experimentally that COMBOOD outperforms state-of-the-art OOD detection methods on the OpenOOD (both version 1 and most recent version 1.5) benchmark datasets (for both far-OOD and near-OOD) as well as on the documents dataset in terms of accuracy. On a majority of the benchmark datasets, the improvements in accuracy resulting from the COMBOOD framework are statistically significant. COMBOOD scales linearly with the size of the embedding space, making it ideal for many real-life applications.", "AI": {"tldr": "COMBOOD is a novel OOD detection framework combining nearest-neighbor and Mahalanobis distance metrics to achieve high detection accuracy for both near-OOD and far-OOD scenarios in image recognition.", "motivation": "The paper addresses the challenge of identifying OOD data during inference, which is critical for enhancing the robustness and reliability of machine learning systems, especially in automation.", "method": "The method introduces COMBOOD, a semi-parametric OOD detection framework that integrates nearest-neighbor and Mahalanobis distance metrics to create a confidence score for OOD detection.", "result": "COMBOOD demonstrated better performance than state-of-the-art OOD detection methods on OpenOOD benchmarks and document datasets, significantly improving accuracy in both near-OOD and far-OOD scenarios.", "conclusion": "The COMBOOD framework is effective, scalable, and outperforms existing methods for OOD detection, addressing limitations in far-OOD and near-OOD scenarios while maintaining computational efficiency."}}
{"id": "2602.08927", "pdf": "https://arxiv.org/pdf/2602.08927", "abs": "https://arxiv.org/abs/2602.08927", "authors": ["Rohan Hore", "Ruodu Wang", "Aaditya Ramdas"], "title": "Online monotone density estimation and log-optimal calibration", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "28 pages, 1 figure", "summary": "We study the problem of online monotone density estimation, where density estimators must be constructed in a predictable manner from sequentially observed data. We propose two online estimators: an online analogue of the classical Grenander estimator, and an expert aggregation estimator inspired by exponential weighting methods from the online learning literature. In the well-specified stochastic setting, where the underlying density is monotone, we show that the expected cumulative log-likelihood gap between the online estimators and the true density admits an $O(n^{1/3})$ bound. We further establish a $\\sqrt{n\\log{n}}$ pathwise regret bound for the expert aggregation estimator relative to the best offline monotone estimator chosen in hindsight, under minimal regularity assumptions on the observed sequence. As an application of independent interest, we show that the problem of constructing log-optimal p-to-e calibrators for sequential hypothesis testing can be formulated as an online monotone density estimation problem. We adapt the proposed estimators to build empirically adaptive p-to-e calibrators and establish their optimality. Numerical experiments illustrate the theoretical results.", "AI": {"tldr": "This paper investigates online monotone density estimation, presenting novel online estimators and analyzing their efficiency. It connects this to sequential hypothesis testing and validates findings through numerical experiments.", "motivation": "The study aims to address the challenge of constructing density estimators from sequential data in a predictable and theoretically sound manner. ", "method": "The paper proposes two online estimators: an online version of the Grenander estimator and an expert aggregation estimator inspired by exponential weighting methods. It analyzes their performance bounds under theoretical and empirical setups.", "result": "It demonstrates theoretical bounds for the proposed estimators, including $O(n^{1/3})$ for log-likelihood gap and $\u0001sqrt{n\\log{n}}$ pathwise regret. It also formulates and optimizes p-to-e calibrators via online monotone density estimation.", "conclusion": "The paper establishes effective online estimators for monotone density estimation, demonstrates their application to p-to-e calibrators, and validates theoretical outcomes through experiments, offering practical and theoretical insights."}}
{"id": "2602.07359", "pdf": "https://arxiv.org/pdf/2602.07359", "abs": "https://arxiv.org/abs/2602.07359", "authors": ["Xiaoqiang Lin", "Jun Hao Liew", "Silvio Savarese", "Junnan Li"], "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents", "categories": ["cs.AI"], "comment": null, "summary": "Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.", "AI": {"tldr": "This paper introduces the Wide and Deep research agent framework, leveraging parallel tool calls to enhance agent performance and efficiency in research tasks.", "motivation": "To explore the unexplored potential of scaling width via parallel tool calling and improve automation in complex intellectual tasks.", "method": "The study focuses on intrinsic parallel tool calling within single reasoning steps and evaluates parallelization using various tool call schedulers.", "result": "Scaling width significantly enhances agent accuracy on benchmarks (62.2% with GPT-5-Medium surpassing GPT-5-High's 54.9%) while reducing turn counts.", "conclusion": "Optimizing the balance between width and depth in tool calling strategies is crucial for advancing efficient deep research agents."}}
{"id": "2602.07154", "pdf": "https://arxiv.org/pdf/2602.07154", "abs": "https://arxiv.org/abs/2602.07154", "authors": ["Ayush Roy", "Rudrasis Chakraborty", "Lav Varshney", "Vishnu Suresh Lokhande"], "title": "Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "AISTATS 2026", "summary": "Pooling heterogeneous datasets across domains is a common strategy in representation learning, but naive pooling can amplify distributional asymmetries and yield biased estimators, especially in settings where zero-shot generalization is required. We propose a matching framework that selects samples relative to an adaptive centroid and iteratively refines the representation distribution. The double robustness and the propensity score matching for the inclusion of data domains make matching more robust than naive pooling and uniform subsampling by filtering out the confounding domains (the main cause of heterogeneity). Theoretical and empirical analyses show that, unlike naive pooling or uniform subsampling, matching achieves better results under asymmetric meta-distributions, which are also extended to non-Gaussian and multimodal real-world settings. Most importantly, we show that these improvements translate to zero-shot medical anomaly detection, one of the extreme forms of data heterogeneity and asymmetry. The code is available on https://github.com/AyushRoy2001/Beyond-Pooling.", "AI": {"tldr": "This paper addresses issues in representation learning with heterogeneous datasets by proposing a matching framework to improve zero-shot performance and anomaly detection.", "motivation": "Developing robust methods to address challenges with heterogeneous datasets, particularly for zero-shot generalization, to better handle biased estimators and distributional asymmetries.", "method": "Proposes a matching framework with adaptive centroids, double robustness, and propensity score matching to iteratively refine data distributions and filter out confounding domains.", "result": "The proposed method outperforms naive pooling and uniform subsampling in handling asymmetric meta-distributions, including real-world non-Gaussian and multimodal datasets.", "conclusion": "The matching framework improves zero-shot generalization and demonstrates strong applicability in medical anomaly detection, where data heterogeneity is highly prevalent."}}
{"id": "2602.08933", "pdf": "https://arxiv.org/pdf/2602.08933", "abs": "https://arxiv.org/abs/2602.08933", "authors": ["Abhik Ghosh", "Suryasis Jana"], "title": "Provably robust learning of regression neural networks using $\u03b2$-divergences", "categories": ["stat.ML", "cs.LG", "cs.NE", "stat.ME"], "comment": "Pre-print, under review", "summary": "Regression neural networks (NNs) are most commonly trained by minimizing the mean squared prediction error, which is highly sensitive to outliers and data contamination. Existing robust training methods for regression NNs are often limited in scope and rely primarily on empirical validation, with only a few offering partial theoretical guarantees. In this paper, we propose a new robust learning framework for regression NNs based on the $\u03b2$-divergence (also known as the density power divergence) which we call `rRNet'. It applies to a broad class of regression NNs, including models with non-smooth activation functions and error densities, and recovers the classical maximum likelihood learning as a special case. The rRNet is implemented via an alternating optimization scheme, for which we establish convergence guarantees to stationary points under mild, verifiable conditions. The (local) robustness of rRNet is theoretically characterized through the influence functions of both the parameter estimates and the resulting rRNet predictor, which are shown to be bounded for suitable choices of the tuning parameter $\u03b2$, depending on the error density. We further prove that rRNet attains the optimal 50\\% asymptotic breakdown point at the assumed model for all $\u03b2\\in(0, 1]$, providing a strong global robustness guarantee that is largely absent for existing NN learning methods. Our theoretical results are complemented by simulation experiments and real-data analyses, illustrating practical advantages of rRNet over existing approaches in both function approximation problems and prediction tasks with noisy observations.", "AI": {"tldr": "The paper introduces rRNet, a robust framework for training regression neural networks (NNs) using $\u03b2$-divergence, offering theoretical guarantees, local and global robustness, and promising results in practical applications.", "motivation": "Current regression neural network training methods are sensitive to outliers and lack strong theoretical guarantees for robustness, necessitating better methods.", "method": "The rRNet framework employs $\u03b2$-divergence, maximum likelihood learning, and alternating optimization with convergence guarantees. Robustness is characterized through influence functions and achieves optimal breakdown points for appropriate settings of $\u03b2$.", "result": "Robust theoretical properties for rRNet were proven, and simulations and real-data analyses demonstrated superior performance in tasks involving noisy observations.", "conclusion": "rRNet provides a theoretically sound and practically effective approach to robust regression neural network training, addressing limitations in existing methods."}}
{"id": "2602.07698", "pdf": "https://arxiv.org/pdf/2602.07698", "abs": "https://arxiv.org/abs/2602.07698", "authors": ["Adam Sorrenti", "Andriy Miranskyy"], "title": "On Sequence-to-Sequence Models for Automated Log Parsing", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Log parsing is a critical standard operating procedure in software systems, enabling monitoring, anomaly detection, and failure diagnosis. However, automated log parsing remains challenging due to heterogeneous log formats, distribution shifts between training and deployment data, and the brittleness of rule-based approaches. This study aims to systematically evaluate how sequence modelling architecture, representation choice, sequence length, and training data availability influence automated log parsing performance and computational cost. We conduct a controlled empirical study comparing four sequence modelling architectures: Transformer, Mamba state-space, monodirectional LSTM, and bidirectional LSTM models. In total, 396 models are trained across multiple dataset configurations and evaluated using relative Levenshtein edit distance with statistical significance testing. Transformer achieves the lowest mean relative edit distance (0.111), followed by Mamba (0.145), mono-LSTM (0.186), and bi-LSTM (0.265), where lower values are better. Mamba provides competitive accuracy with substantially lower computational cost. Character-level tokenization generally improves performance, sequence length has negligible practical impact on Transformer accuracy, and both Mamba and Transformer demonstrate stronger sample efficiency than recurrent models. Overall, Transformers reduce parsing error by 23.4%, while Mamba is a strong alternative under data or compute constraints. These results also clarify the roles of representation choice, sequence length, and sample efficiency, providing practical guidance for researchers and practitioners.", "AI": {"tldr": "Log parsing is important but challenging due to diverse formats and shifts in data. This paper evaluates sequence modelling architectures for performance and cost, finding Transformers most accurate and Mamba efficient.", "motivation": "Log parsing supports monitoring, anomaly detection, and failure diagnosis, but remains difficult due to format heterogeneity and data shifts.", "method": "Four sequence modelling architectures (Transformer, Mamba, mono-LSTM, bi-LSTM) are evaluated using controlled studies and relative Levenshtein edit distance.", "result": "Transformer achieved the best accuracy, reducing parsing error by 23.4%. Mamba performed competitively with lower computational cost. Representation choice, sequence length, and sample efficiency were assessed.", "conclusion": "Transformers are preferable for accuracy, while Mamba is effective in resource-constrained scenarios. Practical guidance is offered for improving automated log parsing."}}
{"id": "2602.07322", "pdf": "https://arxiv.org/pdf/2602.07322", "abs": "https://arxiv.org/abs/2602.07322", "authors": ["Jindou Jia", "Gen Li", "Xiangyu Chen", "Tuo An", "Yuxuan Hu", "Jingliang Li", "Xinying Guo", "Jianfei Yang"], "title": "Action-to-Action Flow Matching", "categories": ["cs.RO", "cs.AI"], "comment": "18 pages, 18 figures", "summary": "Diffusion-based policies have recently achieved remarkable success in robotics by formulating action prediction as a conditional denoising process. However, the standard practice of sampling from random Gaussian noise often requires multiple iterative steps to produce clean actions, leading to high inference latency that incurs a major bottleneck for real-time control. In this paper, we challenge the necessity of uninformed noise sampling and propose Action-to-Action flow matching (A2A), a novel policy paradigm that shifts from random sampling to initialization informed by the previous action. Unlike existing methods that treat proprioceptive action feedback as static conditions, A2A leverages historical proprioceptive sequences, embedding them into a high-dimensional latent space as the starting point for action generation. This design bypasses costly iterative denoising while effectively capturing the robot's physical dynamics and temporal continuity. Extensive experiments demonstrate that A2A exhibits high training efficiency, fast inference speed, and improved generalization. Notably, A2A enables high-quality action generation in as few as a single inference step (0.56 ms latency), and exhibits superior robustness to visual perturbations and enhanced generalization to unseen configurations. Lastly, we also extend A2A to video generation, demonstrating its broader versatility in temporal modeling. Project site: https://lorenzo-0-0.github.io/A2A_Flow_Matching.", "AI": {"tldr": "This paper introduces Action-to-Action flow matching (A2A), which improves robotic policies by replacing traditional random Gaussian noise sampling with an initialization informed by prior actions, reducing latency and enhancing performance.", "motivation": "To address the high inference latency of diffusion-based policies in real-time robotic control caused by the need for multiple iterative steps to produce clean actions.", "method": "A2A replaces random Gaussian noise initialization with a starting point based on historical proprioceptive data embedded into a latent space, bypassing iterative denoising and maintaining dynamic continuity.", "result": "A2A achieves high training efficiency, significantly faster inference speed (0.56 ms latency for single-step inference), improved robustness to visual perturbations, and better generalization to unseen scenarios.", "conclusion": "A2A effectively reduces inference latency while maintaining performance and generalization capabilities in robotic control, with potential applications in domains like video generation for broader temporal modeling."}}
{"id": "2602.07382", "pdf": "https://arxiv.org/pdf/2602.07382", "abs": "https://arxiv.org/abs/2602.07382", "authors": ["Debtanu Datta", "Rajdeep Mukherjee", "Adrijit Goswami", "Saptarshi Ghosh"], "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 5 figures, 8 tables", "summary": "Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.", "AI": {"tldr": "The paper addresses the complexity of summarizing Indian legal court judgments and proposes methods to generate summaries in English and Hindi using domain-specific refinements in both extractive and generative summarization models.", "motivation": "To bridge the gap caused by the intricate and inaccessible legal language within Indian court judgments, especially for the large population unfamiliar with English-based legal text, by offering summaries in English and Hindi.", "method": "A framework is proposed that enhances extractive summarization models with legal domain-specific encoders and refines generative models (including LLMs) using continual pre-training on large legal corpora in English and Hindi.", "result": "The proposed techniques significantly improve summarization quality in both English-to-English and English-to-Hindi tasks, validated by metrics and domain experts.", "conclusion": "The study demonstrates the effectiveness of incorporating domain-specific knowledge into summarization models for legal texts, improving accessibility and factual consistency across languages."}}
{"id": "2602.07044", "pdf": "https://arxiv.org/pdf/2602.07044", "abs": "https://arxiv.org/abs/2602.07044", "authors": ["Tianyi Qu", "Songxiao Yang", "Haolin Wang", "Huadong Song", "Xiaoting Guo", "Wenguang Hu", "Guanlin Liu", "Honghe Chen", "Yafei Ou"], "title": "PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging", "categories": ["cs.CV", "cs.AI"], "comment": "A dataset contains 240,320 pipeline MFL pseudo-color images and 191,530 bounding-box annotations, collected from 11 pipelines spanning approximately 1,480 km", "summary": "Pipeline integrity is critical to industrial safety and environmental protection, with Magnetic Flux Leakage (MFL) detection being a primary non-destructive testing technology. Despite the promise of deep learning for automating MFL interpretation, progress toward reliable models has been constrained by the absence of a large-scale public dataset and benchmark, making fair comparison and reproducible evaluation difficult. We introduce \\textbf{PipeMFL-240K}, a large-scale, meticulously annotated dataset and benchmark for complex object detection in pipeline MFL pseudo-color images. PipeMFL-240K reflects real-world inspection complexity and poses several unique challenges: (i) an extremely long-tailed distribution over \\textbf{12} categories, (ii) a high prevalence of tiny objects that often comprise only a handful of pixels, and (iii) substantial intra-class variability. The dataset contains \\textbf{240,320} images and \\textbf{191,530} high-quality bounding-box annotations, collected from 11 pipelines spanning approximately \\textbf{1,480} km. Extensive experiments are conducted with state-of-the-art object detectors to establish baselines. Results show that modern detectors still struggle with the intrinsic properties of MFL data, highlighting considerable headroom for improvement, while PipeMFL-240K provides a reliable and challenging testbed to drive future research. As the first public dataset and the first benchmark of this scale and scope for pipeline MFL inspection, it provides a critical foundation for efficient pipeline diagnostics as well as maintenance planning and is expected to accelerate algorithmic innovation and reproducible research in MFL-based pipeline integrity assessment.", "AI": {"tldr": "This paper introduces PipeMFL-240K, a large-scale dataset with 240,320 images and benchmark for deep learning in magnetic flux leakage (MFL) pipeline integrity detection, addressing real-world challenges.", "motivation": "The lack of a large-scale, publicly available dataset for pipeline MFL detection has hindered advancements in robust deep learning models for industrial safety and environmental protection.", "method": "The authors created PipeMFL-240K, a dataset with meticulously annotated complex object detection in pipeline MFL pseudo-color images, featuring a diverse and challenging dataset. Baselines were set using state-of-the-art object detection models.", "result": "Modern object detection models tested on the dataset show limitations in addressing the long-tailed distribution, tiny objects, and intra-class variability posed by MFL data.", "conclusion": "PipeMFL-240K is a pivotal tool that provides a public dataset and benchmark for MFL-based pipeline integrity research, enabling reproducibility, algorithm development, and advancements in safety diagnostics."}}
{"id": "2602.07391", "pdf": "https://arxiv.org/pdf/2602.07391", "abs": "https://arxiv.org/abs/2602.07391", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring \"benign-use correctness\", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.", "AI": {"tldr": "NAAMSE is an evolutionary framework designed to improve security evaluations for AI agents by modeling adaptive, multi-turn adversaries through genetic prompt mutation and behavioral feedback.", "motivation": "Traditional security methods rely on static benchmarks or manual approaches, which fail to capture adaptive and dynamic adversarial behaviors in AI systems.", "method": "NAAMSE uses evolutionary techniques such as genetic prompt mutation, hierarchical corpus exploration, and asymmetric scoring to optimize attacks and simultaneously maintain correct behaviors.", "result": "Experiments show that NAAMSE detects high-severity vulnerabilities missed by static or one-shot evaluations, demonstrating a scalable and effective approach to uncovering threats.", "conclusion": "The adaptive nature of NAAMSE provides a realistic and scalable method for assessing AI robustness, addressing dynamic and evolving security threats effectively."}}
{"id": "2602.07156", "pdf": "https://arxiv.org/pdf/2602.07156", "abs": "https://arxiv.org/abs/2602.07156", "authors": ["Asher Trockman", "J. Zico Kolter"], "title": "Mimetic Initialization of MLPs", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Mimetic initialization uses pretrained models as case studies of good initialization, using observations of structures in trained weights to inspire new, simple initialization techniques. So far, it has been applied only to spatial mixing layers, such convolutional, self-attention, and state space layers. In this work, we present the first attempt to apply the method to channel mixing layers, namely multilayer perceptrons (MLPs). Our extremely simple technique for MLPs -- to give the first layer a nonzero mean -- speeds up training on small-scale vision tasks like CIFAR-10 and ImageNet-1k. Though its effect is much smaller than spatial mixing initializations, it can be used in conjunction with them for an additional positive effect.", "AI": {"tldr": "This paper introduces a simple mimetic initialization technique for Multilayer Perceptrons (MLPs) to enhance training efficiency in small-scale vision tasks.", "motivation": "To explore and extend mimetic initialization methods to channel mixing layers (MLPs), previously applied only to spatial mixing layers.", "method": "Introduce a simple initialization technique for MLPs by giving the first layer a nonzero mean.", "result": "Faster training observed on small-scale vision tasks like CIFAR-10 and ImageNet-1k, and an additive positive effect when combined with spatial mixing initializations.", "conclusion": "While the effect is less significant compared to spatial mixing initializations, the method still provides a practical improvement and complements existing techniques."}}
{"id": "2602.07783", "pdf": "https://arxiv.org/pdf/2602.07783", "abs": "https://arxiv.org/abs/2602.07783", "authors": ["Zejun Zhang", "Yixin Gan", "Zhenchang Xing", "Tian Zhang", "Yi Li", "Xiwei Xu", "Qinghua Lu", "Liming Zhu"], "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted By FSE2026", "summary": "Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.", "AI": {"tldr": "LintCFG proposes an automatic approach for generating linter configurations using a DSL-driven, LLM-based compilation method, showcasing notable improvements in efficiency for coding standard management.", "motivation": "The paper aims to address the manual, complex, and maintenance-heavy requirement of configuring linters to comply with diverse coding standards across programming languages and projects.", "method": "LintCFG employs a domain-specific language (DSL) paired with an LLM-based compilation approach. It translates natural language coding standards into structured DSL representations and generates specific linter configurations through a parsing and verification process.", "result": "Experiments reveal over 90% precision and recall in DSL representation and around 70% accuracy in linter configuration generation, outperforming existing methods significantly. It demonstrates efficiency improvements for developers and applicability across other languages and linters.", "conclusion": "LintCFG offers a scalable, generalizable, and efficient solution for linter configuration generation, benefiting developers by reducing manual configuration efforts and improving standardization across coding projects."}}
{"id": "2602.07326", "pdf": "https://arxiv.org/pdf/2602.07326", "abs": "https://arxiv.org/abs/2602.07326", "authors": ["Edgar Lee", "Junho Choi", "Taemin Kim", "Changjoo Nam", "Seokhwan Jeong"], "title": "Why Look at It at All?: Vision-Free Multifingered Blind Grasping Using Uniaxial Fingertip Force Sensing", "categories": ["cs.RO", "eess.SY"], "comment": "Submitted to Journal (under review)", "summary": "Grasping under limited sensing remains a fundamental challenge for real-world robotic manipulation, as vision and high-resolution tactile sensors often introduce cost, fragility, and integration complexity. This work demonstrates that reliable multifingered grasping can be achieved under extremely minimal sensing by relying solely on uniaxial fingertip force feedback and joint proprioception, without vision or multi-axis/tactile sensing. To enable such blind grasping, we employ an efficient teacher-student training pipeline in which a reinforcement-learned teacher exploits privileged simulation-only observations to generate demonstrations for distilling a transformer-based student policy operating under partial observation. The student policy is trained to act using only sensing modalities available at real-world deployment. We validate the proposed approach on real hardware across 18 objects, including both in-distribution and out-of-distribution cases, achieving a 98.3~$\\%$ overall grasp success rate. These results demonstrate strong robustness and generalization beyond the simulation training distribution, while significantly reducing sensing requirements for real-world grasping systems.", "AI": {"tldr": "This paper focuses on reliable multifingered grasping based on minimal sensing using uniaxial fingertip force feedback and joint proprioception, without vision or tactile sensors.", "motivation": "The study aims to overcome the limitations of high-cost and fragile sensing systems in robotic manipulation, enabling robust grasping under minimal sensing modalities.", "method": "The researchers employed a teacher-student training pipeline using reinforcement learning in simulation to train a transformer-based student policy for operating under partial observation.", "result": "The approach demonstrated a 98.3% grasp success rate across 18 objects, showcasing robustness and generalization to out-of-distribution scenarios.", "conclusion": "This work highlights the potential of reducing sensing requirements while maintaining reliable and generalizable robotic grasping capabilities."}}
{"id": "2602.07447", "pdf": "https://arxiv.org/pdf/2602.07447", "abs": "https://arxiv.org/abs/2602.07447", "authors": ["Liviu P Dinu", "Ana Sabina Uban", "Bogdan Iordache", "Anca Dinu", "Simona Georgescu"], "title": "Measuring cross-language intelligibility between Romance languages with computational tools", "categories": ["cs.CL"], "comment": "16 pages, 7 figures, 2 tables", "summary": "We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.", "AI": {"tldr": "The paper introduces a computational metric to estimate mutual intelligibility among Romance languages based on lexical and semantic similarity, validated with human test results.", "motivation": "To provide a quantifiable metric for mutual intelligibility within the Romance language family, addressing asymmetries and improving linguistic analysis.", "method": "A novel metric combining lexical, orthographic, phonetic, and semantic similarities was introduced. It was applied to five Romance languages using parallel corpora and vectorial word meaning models. Intelligibility asymmetries were tested computationally and compared with human cloze tests.", "result": "The computed intelligibility scores align with linguistic intuitions and correlate with human experimental results, validating the metric.", "conclusion": "The proposed computational metric effectively measures mutual intelligibility in related languages, offering insights into linguistic comprehension asymmetries."}}
{"id": "2602.07045", "pdf": "https://arxiv.org/pdf/2602.07045", "abs": "https://arxiv.org/abs/2602.07045", "authors": ["Zhiming Luo", "Di Wang", "Haonan Guo", "Jing Zhang", "Bo Du"], "title": "VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have enabled complex reasoning. However, existing remote sensing (RS) benchmarks remain heavily biased toward perception tasks, such as object recognition and scene classification. This limitation hinders the development of MLLMs for cognitively demanding RS applications. To address this, , we propose a Vision Language ReaSoning Benchmark (VLRS-Bench), which is the first benchmark exclusively dedicated to complex RS reasoning. Structured across the three core dimensions of Cognition, Decision, and Prediction, VLRS-Bench comprises 2,000 question-answer pairs with an average length of 71 words, spanning 14 tasks and up to eight temporal phases. VLRS-Bench is constructed via a specialized pipeline that integrates RS-specific priors and expert knowledge to ensure geospatial realism and reasoning complexity. Experimental results reveal significant bottlenecks in existing state-of-the-art MLLMs, providing critical insights for advancing multimodal reasoning within the remote sensing community.", "AI": {"tldr": "The paper introduces VLRS-Bench, the first benchmark for complex reasoning in remote sensing, revealing shortcomings in existing multimodal models.", "motivation": "Existing remote sensing (RS) benchmarks focus on perception tasks, lacking the complexity needed for reasoning, which limits the development of Multimodal Large Language Models (MLLMs) for advanced RS applications.", "method": "Development of VLRS-Bench as a reasoning-focused benchmark containing 2,000 question-answer pairs across 14 tasks, utilizing RS-specific prior knowledge and expert contributions to ensure accuracy and difficulty.", "result": "VLRS-Bench identified performance bottlenecks in current state-of-the-art MLLMs, showing their limitations in reasoning within remote sensing.", "conclusion": "VLRS-Bench provides a valuable resource for advancing multimodal reasoning in RS, encouraging further development of capable models."}}
{"id": "2602.06267", "pdf": "https://arxiv.org/pdf/2602.06267", "abs": "https://arxiv.org/abs/2602.06267", "authors": ["Rohan Hore", "Aaditya Ramdas"], "title": "Conformal changepoint localization", "categories": ["stat.ME", "stat.ML"], "comment": "52 pages, 12 figures", "summary": "We study the problem of offline changepoint localization in a distribution-free setting. One observes a vector of data with a single changepoint, assuming that the data before and after the changepoint are iid (or more generally exchangeable) from arbitrary and unknown distributions. The goal is to produce a finite-sample confidence set for the index at which the change occurs without making any other assumptions. Existing methods often rely on parametric assumptions, tail conditions, or asymptotic approximations, or only produce point estimates. In contrast, our distribution-free algorithm, CONformal CHangepoint localization (CONCH), only leverages exchangeability arguments to construct confidence sets with finite sample coverage. By proving a conformal Neyman-Pearson lemma, we derive principled score functions that yield informative (small) sets. Moreover, with such score functions, the normalized length of the confidence set shrinks to zero under weak assumptions. We also establish a universality result showing that any distribution-free changepoint localization method must be an instance of CONCH. Experiments suggest that CONCH delivers precise confidence sets even in challenging settings involving images or text.", "AI": {"tldr": "The paper presents CONCH, a distribution-free algorithm for offline changepoint localization, designed to provide finite-sample confidence sets while relying only on exchangeability and avoiding any parametric assumptions.", "motivation": "The motivation is to address the limitations of existing changepoint localization methods which often depend on parametric assumptions, tail conditions, or asymptotic approximations, and lack distribution-free finite-sample guarantees.", "method": "The authors develop CONCH, utilizing exchangeability and conformal inference principles. They introduce a conformal Neyman-Pearson lemma to construct score functions for precise and shrinking confidence sets.", "result": "The paper shows that CONCH produces reliable and precise finite-sample confidence sets, with the length of confidence sets shrinking under weak assumptions. Experiments confirm effectiveness even in challenging settings like image and text data.", "conclusion": "CONCH is a universal and effective framework for distribution-free changepoint localization, guaranteeing finite-sample coverage and outperforming existing methods in challenging scenarios."}}
{"id": "2602.07399", "pdf": "https://arxiv.org/pdf/2602.07399", "abs": "https://arxiv.org/abs/2602.07399", "authors": ["Changhua Xu", "Jie Lu", "Junyu Xuan", "En Yu"], "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation", "categories": ["cs.AI", "cs.CV"], "comment": "Preprint", "summary": "Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{generation--selection} perspective and propose a novel framework \\textbf{VGAS} (\\textbf{V}alue-\\textbf{G}uided \\textbf{A}ction-chunk \\textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \\textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \\textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \\textit{Explicit Geometric Regularization} (\\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \\textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.", "AI": {"tldr": "The paper introduces VGAS (Value-Guided Action-chunk Selection), a framework enhancing vision-language-action models' reliability in low-data settings by addressing geometric ambiguities in decision-making.", "motivation": "To improve the adaptability of vision-language-action (VLA) models in tasks with scarce demonstrations by resolving geometric ambiguities causing failures.", "method": "Proposing VGAS, which combines a fine-tuned VLA model for generating proposals and a Q-Chunk-Former Transformer critic for selecting geometrically accurate actions, alongside Explicit Geometric Regularization (EGR) for improved action evaluation.", "result": "VGAS consistently enhances success rates and robustness during adaptation with minimal demonstrations and distribution shifts, supported by experiments and theoretical analysis.", "conclusion": "VGAS bridges the gap in VLA model adaptability by addressing geometric ambiguities, paving the way for more reliable few-shot multimodal reasoning applications."}}
{"id": "2602.07173", "pdf": "https://arxiv.org/pdf/2602.07173", "abs": "https://arxiv.org/abs/2602.07173", "authors": ["Tong Jian", "Tianyu Dai", "Tao Yu"], "title": "Learning Nonlinear Systems In-Context: From Synthetic Data to Real-World Motor Control", "categories": ["cs.LG", "eess.SY"], "comment": "Accepted to be presented in IEEE ICASSP 2026", "summary": "LLMs have shown strong in-context learning (ICL) abilities, but have not yet been extended to signal processing systems. Inspired by their design, we have proposed for the first time ICL using transformer models applicable to motor feedforward control, a critical task where classical PI and physics-based methods struggle with nonlinearities and complex load conditions. We propose a transformer based model architecture that separates signal representation from system behavior, enabling both few-shot finetuning and one-shot ICL. Pretrained on a large corpus of synthetic linear and nonlinear systems, the model learns to generalize to unseen system dynamics of real-world motors only with a handful of examples. In experiments, our approach generalizes across multiple motor load configurations, transforms untuned examples into accurate feedforward predictions, and outperforms PI controllers and physics-based feedforward baselines. These results demonstrate that ICL can bridge synthetic pretraining and real-world adaptability, opening new directions for data efficient control of physical systems.", "AI": {"tldr": "The paper introduces a transformer-based model for in-context learning (ICL) aimed at motor feedforward control, outperforming traditional methods while enabling few-shot and one-shot generalization.", "motivation": "Traditional PI and physics-based methods struggle to handle nonlinearities and complex load conditions in motor feedforward control. There is a need for a data-efficient approach to address the challenges of adapting pre-trained models to real-world systems.", "method": "The authors designed a transformer-based model architecture that separates signal representation from system behavior. Pretrained on synthetic linear and nonlinear systems, the model supports few-shot fine-tuning and one-shot ICL, enabling generalization to diverse motor dynamics.", "result": "The approach generalized well across various motor load configurations, transformed untuned examples into accurate predictions, and outperformed both PI controllers and physics-based methods in experiments.", "conclusion": "This study shows that ICL with transformers can effectively bridge synthetic pretraining and real-world adaptability, presenting a promising approach for efficient control of physical systems."}}
{"id": "2602.07821", "pdf": "https://arxiv.org/pdf/2602.07821", "abs": "https://arxiv.org/abs/2602.07821", "authors": ["Shinobu Saito"], "title": "Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution", "categories": ["cs.SE"], "comment": null, "summary": "In software maintenance work, software architects and programmers need to identify modules that require modification or deletion. Whilst user requests and bug reports are utilised for this purpose, evaluating the execution status of modules within the software is also crucial. This paper, therefore, applies spatial statistics to assess internal software execution data. First, we define a software space dataset, viewing the software's internal structure as a space based on module call relationships. Then, using spatial statistics, we conduct the visualization of spatial clusters and the statistical testing using spatial measures. Finally, we consider the usefulness of spatial statistics in the software engineering domain and future challenges.", "AI": {"tldr": "The paper utilizes spatial statistics to evaluate internal software execution data and identify modules needing modifications.", "motivation": "To provide software architects and programmers with a method to evaluate internal software execution data for identifying areas requiring changes.", "method": "The paper defines software space datasets based on module call relationships and uses spatial statistics to visualize clusters and perform statistical analyses.", "result": "Spatial statistics enables visualization of clusters and statistical testing within a software's internal execution data.", "conclusion": "Applying spatial statistics offers a useful approach for assessing software performance and supports software maintenance tasks; future challenges are discussed."}}
{"id": "2602.07363", "pdf": "https://arxiv.org/pdf/2602.07363", "abs": "https://arxiv.org/abs/2602.07363", "authors": ["Zihao Xu", "Runyu Lei", "Zihao Li", "Boxi Lin", "Ce Hao", "Jin Song Dong"], "title": "UEREBot: Learning Safe Quadrupedal Locomotion under Unstructured Environments and High-Speed Dynamic Obstacles", "categories": ["cs.RO"], "comment": null, "summary": "Quadruped robots are increasingly deployed in unstructured environments. Safe locomotion in these settings requires long-horizon goal progress, passability over uneven terrain and static constraints, and collision avoidance against high-speed dynamic obstacles. A single system cannot fully satisfy all three objectives simultaneously: planning-based decisions can be too slow, while purely reactive decisions can sacrifice goal progress and passability. To resolve this conflict, we propose UEREBot (Unstructured-Environment Reflexive Evasion Robot), a hierarchical framework that separates slow planning from instantaneous reflexive evasion and coordinates them during execution. UEREBot formulates the task as a constrained optimal control problem blueprint. It adopts a spatial--temporal planner that provides reference guidance toward the goal and threat signals. It then uses a threat-aware handoff to fuse navigation and reflex actions into a nominal command, and a control barrier function shield as a final execution safeguard. We evaluate UEREBot in Isaac Lab simulation and deploy it on a Unitree Go2 quadruped equipped with onboard perception. Across diverse environments with complex static structure and high-speed dynamic obstacles, UEREBot achieves higher avoidance success and more stable locomotion while maintaining goal progress than representative baselines, demonstrating improved safety--progress trade-offs.", "AI": {"tldr": "UEREBot proposes a hierarchical framework unifying planning and reflexive evasion for quadruped robots in unsafe environments, showing better safety and navigation outcomes.", "motivation": "Quadruped robots face challenges maintaining long-term goals, traversing uneven terrains, and avoiding dynamic obstacles while being deployed in unstructured environments.", "method": "UEREBot utilizes a hierarchical framework combining a spatial-temporal planner, threat-aware handoff process, and a control barrier function safeguard.", "result": "UEREBot proved successful in simulation and real-world environments, achieving better collision avoidance and stability than baselines.", "conclusion": "The paper highlights UEREBot's ability to enhance safety and progress trade-offs for quadruped robots navigating intricate, dynamic landscapes."}}
{"id": "2602.07451", "pdf": "https://arxiv.org/pdf/2602.07451", "abs": "https://arxiv.org/abs/2602.07451", "authors": ["Huiling Zhen", "Weizhe Lin", "Renxi Liu", "Kai Han", "Yiming Li", "Yuchuan Tian", "Hanting Chen", "Xiaoguang Li", "Xiaosong Li", "Chen Chen", "Xianzhi Yu", "Mingxuan Yuan", "Youliang Yan", "Peifeng Qin", "Jun Wang", "Yu Wang", "Dacheng Tao", "Yunhe Wang"], "title": "DLLM Agent: See Farther, Run Faster", "categories": ["cs.CL"], "comment": null, "summary": "Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.", "AI": {"tldr": "This paper investigates whether using Diffusion Large Language Models (DLLMs) instead of autoregressive (AR) models affects decision-making, planning, and tool use in agent workflows, finding that DLLMs vastly improve efficiency and planning accuracy but require tailored training for structured tool use.", "motivation": "The paper explores whether changing from AR models to DLLMs in agent usage improves planning and efficiency in decision-making tasks, motivated by DLLMs' potential advantages in efficiency and modeling.", "method": "The authors incorporated DLLMs into the DeepDiver agent workflow, performed fine-tuning with identical data for both DLLM and AR-based agents, and evaluated across speed, accuracy, and tool-use parameters on benchmarks.", "result": "DLLM agents achieved over 30% faster performance, reduced interaction rounds, and required fewer tool invocations while maintaining accuracy. Performance demands specific adjustments like training for tool-call correctness and aligned attention masking.", "conclusion": "DLLM agents provide significant efficiency and planning improvements but necessitate careful design considerations for structured tasks, contributing valuable insights into DLLM viability in agentic decision-making workflows."}}
{"id": "2602.07047", "pdf": "https://arxiv.org/pdf/2602.07047", "abs": "https://arxiv.org/abs/2602.07047", "authors": ["Muhammad Rashid", "Elvio G. Amparore", "Enrico Ferrari", "Damiano Verda"], "title": "ShapBPT: Image Feature Attributions Using Data-Aware Binary Partition Trees", "categories": ["cs.CV", "cs.LG"], "comment": "AAAI-2026", "summary": "Pixel-level feature attributions are an important tool in eXplainable AI for Computer Vision (XCV), providing visual insights into how image features influence model predictions. The Owen formula for hierarchical Shapley values has been widely used to interpret machine learning (ML) models and their learned representations. However, existing hierarchical Shapley approaches do not exploit the multiscale structure of image data, leading to slow convergence and weak alignment with the actual morphological features. Moreover, no prior Shapley method has leveraged data-aware hierarchies for Computer Vision tasks, leaving a gap in model interpretability of structured visual data. To address this, this paper introduces ShapBPT, a novel data-aware XCV method based on the hierarchical Shapley formula. ShapBPT assigns Shapley coefficients to a multiscale hierarchical structure tailored for images, the Binary Partition Tree (BPT). By using this data-aware hierarchical partitioning, ShapBPT ensures that feature attributions align with intrinsic image morphology, effectively prioritizing relevant regions while reducing computational overhead. This advancement connects hierarchical Shapley methods with image data, providing a more efficient and semantically meaningful approach to visual interpretability. Experimental results confirm ShapBPT's effectiveness, demonstrating superior alignment with image structures and improved efficiency over existing XCV methods, and a 20-subject user study confirming that ShapBPT explanations are preferred by humans.", "AI": {"tldr": "This paper introduces ShapBPT, a novel method to improve pixel-level explanations in AI for Computer Vision by leveraging hierarchical Shapley values and Binary Partition Trees (BPT) for more efficient and interpretable image feature attributions.", "motivation": "Current hierarchical Shapley approaches in visual interpretability fail to utilize image data's multiscale structure, leading to weak alignment with features and computational inefficiency, necessitating a data-aware solution for Computer Vision.", "method": "The paper proposes ShapBPT, which incorporates the Binary Partition Tree (BPT) into hierarchical Shapley value formulations for data-aware, multiscale feature attribution in image analysis.", "result": "Experimental results show ShapBPT improves alignment with image morphology, enhances efficiency compared to existing methods, and is preferred by users in a 20-subject study.", "conclusion": "ShapBPT bridges the gap between hierarchical Shapley methods and image data, offering a semantically meaningful, computationally efficient approach for visual interpretability."}}
{"id": "2602.07408", "pdf": "https://arxiv.org/pdf/2602.07408", "abs": "https://arxiv.org/abs/2602.07408", "authors": ["Hyomin Kim", "Sang-Yeon Hwang", "Jaechang Lim", "Yinhua Piao", "Yunhak Oh", "Woo Youn Kim", "Chanyoung Park", "Sungsoo Ahn", "Junhyeok Jeon"], "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction", "categories": ["cs.AI", "cs.MA"], "comment": "17 pages, 4 figures, 9 tables", "summary": "Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.", "AI": {"tldr": "The paper introduces LINCSQA, a benchmark for predicting gene regulation under chemical perturbations, and PBio-Agent, a framework to improve predictions using multi-agent collaboration.", "motivation": "The authors aim to address the challenge of predicting gene regulation in bulk-cell environments impacted by chemical perturbations, a domain crucial for drug discovery that has been understudied.", "method": "The study proposes PBio-Agent, a multi-agent framework with difficulty-aware task sequencing, specialized agents using biological knowledge graphs, and iterative knowledge refinement to manage causal complexities in gene regulation.", "result": "PBio-Agent achieves superior performance compared to existing baselines on LINCSQA and PerturbQA, demonstrating its capability in accurately predicting complex gene responses even with smaller models and no extra training.", "conclusion": "The proposed framework, PBio-Agent, showcases the potential of integrating specialized agents and biological knowledge graphs to predict and explain gene regulation processes effectively, contributing significantly to drug discovery."}}
{"id": "2602.07189", "pdf": "https://arxiv.org/pdf/2602.07189", "abs": "https://arxiv.org/abs/2602.07189", "authors": ["Joohwan Ko", "Tomas Geffner"], "title": "Latent Target Score Matching, with an application to Simulation-Based Inference", "categories": ["cs.LG"], "comment": "Machine Learning and the Physical Sciences Workshop, NeurIPS 2025", "summary": "Denoising score matching (DSM) for training diffusion models may suffer from high variance at low noise levels. Target Score Matching (TSM) mitigates this when clean data scores are available, providing a low-variance objective. In many applications clean scores are inaccessible due to the presence of latent variables, leaving only joint signals exposed. We propose Latent Target Score Matching (LTSM), an extension of TSM to leverage joint scores for low-variance supervision of the marginal score. While LTSM is effective at low noise levels, a mixture with DSM ensures robustness across noise scales. Across simulation-based inference tasks, LTSM consistently improves variance, score accuracy, and sample quality.", "AI": {"tldr": "The paper proposes Latent Target Score Matching (LTSM) to address variance issues in training diffusion models at low noise levels and demonstrates improved outcomes in simulation-based inference.", "motivation": "Denoising score matching (DSM) often suffers from high variance at low noise levels, limiting its effectiveness for training diffusion models. Target Score Matching (TSM) improves on this but relies on clean data scores, which are often inaccessible in practice due to latent variables.", "method": "The authors introduce Latent Target Score Matching (LTSM), which extends TSM to utilize joint scores in the absence of clean data scores. LTSM mitigates variance at low-noise levels, and its combination with DSM ensures robustness across noise levels.", "result": "LTSM consistently reduces variance, improves score accuracy, and enhances sample quality in simulation-based inference tasks.", "conclusion": "LTSM is a robust extension of TSM for cases without clean data scores, providing an effective solution for lowering variance and improving diffusion model training outcomes."}}
{"id": "2602.07871", "pdf": "https://arxiv.org/pdf/2602.07871", "abs": "https://arxiv.org/abs/2602.07871", "authors": ["Xiang Li", "Siyu Lu", "Sarro Federica", "Claire Le Goues", "He Ye"], "title": "HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid", "categories": ["cs.SE"], "comment": null, "summary": "Automated software environment setup is a prerequisite for testing, debugging, and reproducing failures, yet remains challenging in practice due to complex dependencies, heterogeneous build systems, and incomplete documentation. Recent work leverages large language models to automate this process, but typically evaluates success using weak signals such as dependency installation or partial test execution, which do not ensure that a project can actually run. In this paper, we argue that environment setup success should be evaluated through executable evidence rather than a single binary signal. We introduce the Environment Maturity Hierarchy, which defines three success levels based on progressively stronger execution requirements, culminating in successful execution of a project's main entry point. Guided by this hierarchy, we propose HerAgent, an automated environment setup approach that incrementally constructs executable environments through execution-based validation and repair. We evaluate HerAgent on four public benchmarks, where it outperforms all related work, achieving up to 79.6\\% improvement due to its holistic understanding of project structure and dependencies. On complex C/C++ projects, HerAgent surpasses prior approaches by 66.7\\%. In addition, HerAgent uniquely resolves 11-30 environment instances across the benchmarks that no prior method can configure.", "AI": {"tldr": "The paper addresses challenges in automated software environment setup by introducing a novel evaluation framework and a solution called HerAgent, achieving significant improvements over existing approaches.", "motivation": "Current automated environment setups face limitations due to complex dependencies, heterogeneous build systems, and incomplete evaluation criteria, necessitating a stronger approach.", "method": "The authors designed the Environment Maturity Hierarchy to evaluate environment setup success and proposed HerAgent, which incrementally builds environments using execution-based validation and repair.", "result": "HerAgent achieved up to 79.6% improvement over prior methods, particularly excelling in complex C/C++ projects and resolving unique environment configurations.", "conclusion": "The approach demonstrates the importance of execution-based evaluation for environment setup and presents a significant step forward in automating reproducible software configurations."}}
{"id": "2602.07388", "pdf": "https://arxiv.org/pdf/2602.07388", "abs": "https://arxiv.org/abs/2602.07388", "authors": ["Yuxuan Hu", "Xiangyu Chen", "Chuhao Zhou", "Yuxi Liu", "Gen Li", "Jindou Jia", "Jianfei Yang"], "title": "Trace-Focused Diffusion Policy for Multi-Modal Action Disambiguation in Long-Horizon Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Generative model-based policies have shown strong performance in imitation-based robotic manipulation by learning action distributions from demonstrations. However, in long-horizon tasks, visually similar observations often recur across execution stages while requiring distinct actions, which leads to ambiguous predictions when policies are conditioned only on instantaneous observations, termed multi-modal action ambiguity (MA2). To address this challenge, we propose the Trace-Focused Diffusion Policy (TF-DP), a simple yet effective diffusion-based framework that explicitly conditions action generation on the robot's execution history. TF-DP represents historical motion as an explicit execution trace and projects it into the visual observation space, providing stage-aware context when current observations alone are insufficient. In addition, the induced trace-focused field emphasizes task-relevant regions associated with historical motion, improving robustness to background visual disturbances. We evaluate TF-DP on real-world robotic manipulation tasks exhibiting pronounced multi-modal action ambiguity and visually cluttered conditions. Experimental results show that TF-DP improves temporal consistency and robustness, outperforming the vanilla diffusion policy by 80.56 percent on tasks with multi-modal action ambiguity and by 86.11 percent under visual disturbances, while maintaining inference efficiency with only a 6.4 percent runtime increase. These results demonstrate that execution-trace conditioning offers a scalable and principled approach for robust long-horizon robotic manipulation within a single policy.", "AI": {"tldr": "The paper introduces TF-DP, a diffusion-based policy framework designed to enhance long-horizon robotic manipulation by conditioning action generation on execution history.", "motivation": "Current imitation-based robotic manipulation struggles with tasks requiring distinct actions for visually similar observations, leading to ambiguous predictions.", "method": "TF-DP uses an execution trace to incorporate historical motion into visual observations and generates stage-aware actions for improved performance.", "result": "TF-DP outperforms the baseline by over 80% in action ambiguity tasks and approximately 86% under visual disturbances, with minimal runtime increase.", "conclusion": "Execution-trace conditioning via diffusion policies offers an efficient and robust solution for long-horizon robotic manipulation."}}
{"id": "2602.07464", "pdf": "https://arxiv.org/pdf/2602.07464", "abs": "https://arxiv.org/abs/2602.07464", "authors": ["Yijie Chen", "Yijin Liu", "Fandong Meng"], "title": "SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning", "categories": ["cs.CL"], "comment": "The code is publicly available at https://github.com/pppa2019/SED-SFT", "summary": "Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT", "AI": {"tldr": "The paper introduces SED-SFT, a method designed to address mode collapse in supervised fine-tuning of large language models by encouraging diversity using adaptive selective entropy regularization.", "motivation": "The study aims to tackle the mode collapse problem in SFT, where models lose diversity and limit RL exploration efficiency.", "method": "The method incorporates selective entropy regularization and masking into the optimization objective to balance accuracy and diversity.", "result": "Experiments show SED-SFT improves generation diversity and RL performance across mathematical benchmarks, with an average improvement in scores on large language models.", "conclusion": "SED-SFT successfully mitigates mode collapse, enhances diversity, and boosts RL performance with negligible computational overhead."}}
{"id": "2602.07049", "pdf": "https://arxiv.org/pdf/2602.07049", "abs": "https://arxiv.org/abs/2602.07049", "authors": ["Jindong Li", "Dario Zanca", "Vincent Christlein", "Tim Hamann", "Jens Barth", "Peter K\u00e4mpf", "Bj\u00f6rn Eskofier"], "title": "Enhancing IMU-Based Online Handwriting Recognition via Contrastive Learning with Zero Inference Overhead", "categories": ["cs.CV"], "comment": null, "summary": "Online handwriting recognition using inertial measurement units opens up handwriting on paper as input for digital devices. Doing it on edge hardware improves privacy and lowers latency, but entails memory constraints. To address this, we propose Error-enhanced Contrastive Handwriting Recognition (ECHWR), a training framework designed to improve feature representation and recognition accuracy without increasing inference costs. ECHWR utilizes a temporary auxiliary branch that aligns sensor signals with semantic text embeddings during the training phase. This alignment is maintained through a dual contrastive objective: an in-batch contrastive loss for general modality alignment and a novel error-based contrastive loss that distinguishes between correct signals and synthetic hard negatives. The auxiliary branch is discarded after training, which allows the deployed model to keep its original, efficient architecture. Evaluations on the OnHW-Words500 dataset show that ECHWR significantly outperforms state-of-the-art baselines, reducing character error rates by up to 7.4% on the writer-independent split and 10.4% on the writer-dependent split. Finally, although our ablation studies indicate that solving specific challenges require specific architectural and objective configurations, error-based contrastive loss shows its effectiveness for handling unseen writing styles.", "AI": {"tldr": "The paper introduces ECHWR, leveraging contrastive learning to improve feature representations in handwriting recognition using IMUs, while maintaining efficiency.", "motivation": "To enable privacy-preserving, efficient handwriting recognition on edge devices, utilizing inertial measurement units, despite memory constraints.", "method": "ECHWR aligns sensor signals with semantic text using an auxiliary branch and dual contrastive objective during training, utilizing in-batch and error-based contrastive loss.", "result": "ECHWR surpasses state-of-the-art baselines in handwriting recognition, improving character error rates by up to 10.4% in evaluations.", "conclusion": "ECHWR achieves enhanced recognition accuracy by leveraging contrastive learning approaches without sacrificing efficiency, making it effective for diverse writing styles."}}
{"id": "2602.07098", "pdf": "https://arxiv.org/pdf/2602.07098", "abs": "https://arxiv.org/abs/2602.07098", "authors": ["Lars K\u00fchmichel", "Jerry M. Huang", "Valentin Pratz", "Jonas Arruda", "Hans Olischl\u00e4ger", "Daniel Habermann", "Simon Kucharsky", "Lasse Elsem\u00fcller", "Aayush Mishra", "Niels Bracher", "Svenja Jedhoff", "Marvin Schmitt", "Paul-Christian B\u00fcrkner", "Stefan T. Radev"], "title": "BayesFlow 2.0: Multi-Backend Amortized Bayesian Inference in Python", "categories": ["stat.CO", "cs.LG", "stat.ML"], "comment": null, "summary": "Modern Bayesian inference involves a mixture of computational methods for estimating, validating, and drawing conclusions from probabilistic models as part of principled workflows. An overarching motif of many Bayesian methods is that they are relatively slow, which often becomes prohibitive when fitting complex models to large data sets. Amortized Bayesian inference (ABI) offers a path to solving the computational challenges of Bayes. ABI trains neural networks on model simulations, rewarding users with rapid inference of any model-implied quantity, such as point estimates, likelihoods, or full posterior distributions. In this work, we present the Python library BayesFlow, Version 2.0, for general-purpose ABI. Along with direct posterior, likelihood, and ratio estimation, the software includes support for multiple popular deep learning backends, a rich collection of generative networks for sampling and density estimation, complete customization and high-level interfaces, as well as new capabilities for hyperparameter optimization, design optimization, and hierarchical modeling. Using a case study on dynamical system parameter estimation, combined with comparisons to similar software, we show that our streamlined, user-friendly workflow has strong potential to support broad adoption.", "AI": {"tldr": "The paper introduces 'BayesFlow, Version 2.0,' a Python library designed for efficient Amortized Bayesian Inference (ABI), significantly improving computational efficiency for Bayesian workflows.", "motivation": "Bayesian inference methods, though principled, are often computationally slow, especially with complex models and large datasets. The authors aim to address this bottleneck by leveraging ABI.", "method": "The authors developed BayesFlow 2.0, an ABI-capable Python library that integrates neural networks trained on model simulations for efficient posterior, likelihood, and ratio estimation. The tool offers compatibility with various deep learning backends and functionalities like hyperparameter optimization and hierarchical modeling.", "result": "The case study demonstrated BayesFlow's efficiency in dynamical system parameter estimation, showing its advantages over similar software.", "conclusion": "BayesFlow 2.0 offers a streamlined and customizable workflow for ABI, potentially facilitating its adoption in wider Bayesian analysis contexts."}}
{"id": "2602.07414", "pdf": "https://arxiv.org/pdf/2602.07414", "abs": "https://arxiv.org/abs/2602.07414", "authors": ["Deuksin Kwon", "Kaleen Shrestha", "Bin Han", "Spencer Lin", "James Hale", "Jonathan Gratch", "Maja Matari\u0107", "Gale M. Lucas"], "title": "Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution", "categories": ["cs.AI", "cs.CL"], "comment": "AAAI 2026 (Special Track: AISI)", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises the question: Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior? To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework provides a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogues with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the use of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and validation in AI simulations before real-world use.", "AI": {"tldr": "This paper evaluates whether large language models (LLMs) accurately reproduce human personality-driven behaviors in conflict scenarios, finding significant discrepancies between LLM and human behavior.", "motivation": "The study addresses the uncertainty around LLMs' ability to simulate human personality-driven behaviors during social interactions, as these capabilities are increasingly relied upon in applications such as legal mediation and negotiation.", "method": "The authors developed an evaluation framework for comparing human-human and LLM-LLM behaviors in dispute resolution, analyzing dialogues through Big Five Inventory (BFI) personality traits. They also proposed a new dataset generation approach to match LLM scenarios with human data.", "result": "The evaluation revealed substantial differences in how LLMs and humans exhibit personality-driven behaviors in conflict situations, depending on the specific LLM used.", "conclusion": "The findings challenge the reliability of personality-prompted LLMs as behavioral proxies and emphasize the importance of psychological validation before deploying such models in real-world scenarios."}}
{"id": "2602.07192", "pdf": "https://arxiv.org/pdf/2602.07192", "abs": "https://arxiv.org/abs/2602.07192", "authors": ["Xiaolong He", "Haoyan Wei", "Wei Hu", "Henan Mao", "C. T. Wu"], "title": "Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling", "categories": ["cs.LG", "cs.CE", "math.NA", "physics.comp-ph"], "comment": null, "summary": "Deep Material Networks (DMNs) are structure-preserving, mechanistic machine learning models that embed micromechanical principles into their architectures, enabling strong extrapolation capabilities and significant potential to accelerate multiscale modeling of complex microstructures. A key advantage of these models is that they can be trained exclusively on linear elastic data and then generalized to nonlinear inelastic regimes during online prediction. Despite their growing adoption, systematic evaluations of their performance across the full offline-online pipeline remain limited. This work presents a comprehensive comparative assessment of DMNs with respect to prediction accuracy, computational efficiency, and training robustness. We investigate the effects of offline training choices, including initialization, batch size, training data size, and activation regularization on online generalization performance and uncertainty. The results demonstrate that both prediction error and variance decrease with increasing training data size, while initialization and batch size can significantly influence model performance. Moreover, activation regularization is shown to play a critical role in controlling network complexity and therefore generalization performance. Compared with the original DMN, the rotation-free Interaction-based Material Network (IMN) formulation achieves a 3.4x - 4.7x speed-up in offline training, while maintaining comparable online prediction accuracy and computational efficiency. These findings clarify key trade-offs between model expressivity and efficiency in structure-preserving material networks and provide practical guidance for their deployment in multiscale material modeling.", "AI": {"tldr": "The paper evaluates and compares key aspects of Deep Material Networks' performance, emphasizing its accuracy, efficiency, and generalizability in multiscale material modeling.", "motivation": "To systematically assess and improve the performance of DMNs in multiscale material modeling, which are increasingly used but lack comprehensive evaluations for prediction accuracy, computational efficiency, and training robustness.", "method": "The study investigates the impact of training parameters (e.g., initialization, batch size, training data size, activation regularization) on DMN performance. A comparative analysis between standard and advanced DMN formulations (such as IMN) is conducted.", "result": "Increasing training data size improves prediction performance, while batch size and initialization affect model outcomes. Activation regularization aids in controlling complexity and generalization. IMN outperforms DMN in training speed (3.4x - 4.7x faster) while maintaining comparable online accuracy.", "conclusion": "DMNs and IMNs hold strong potential for multiscale material modeling with trade-offs in expressiveness and efficiency clarified. Practical insights are provided for model deployment."}}
{"id": "2602.07882", "pdf": "https://arxiv.org/pdf/2602.07882", "abs": "https://arxiv.org/abs/2602.07882", "authors": ["Chen Xie", "Yuling Shi", "Xiaodong Gu", "Beijun Shen"], "title": "Rethinking Code Complexity Through the Lens of Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "Code complexity metrics such as cyclomatic complexity have long been used to assess software quality and maintainability. With the rapid advancement of large language models (LLMs) on code understanding and generation tasks, an important yet underexplored question arises: do these traditional complexity metrics meaningfully characterize the difficulty LLMs experience when processing code? In this work, we empirically demonstrate that, after controlling for code length, classical metrics exhibit no consistent correlation with LLM performance, revealing a fundamental mismatch with model-perceived difficulty. To address this gap, we propose LM-CC, a novel code complexity metric designed from the perspective of LLMs. The core premise of LM-CC is that LLM-perceived difficulty is driven by the nonlinearity of program semantics. Accordingly, we decompose programs into semantic units based on entropy, organize these units into a compositional hierarchy, and quantify complexity as a principled aggregation of compositional level and branching-induced divergence, capturing cumulative model uncertainty during code processing. Our extensive experiments show that LM-CC not only correlates more strongly with LLM performance than traditional metrics but also that lowering it directly enhances task performance.", "AI": {"tldr": "This paper demonstrates that traditional code complexity metrics fail to correlate with LLM performance and introduces a new metric, LM-CC, which better aligns with LLM-perceived code difficulty.", "motivation": "Traditional code complexity metrics like cyclomatic complexity fail to capture the difficulty experienced by LLMs when processing code. This creates a need for more appropriate metrics to assess code from the perspective of LLMs.", "method": "The authors propose LM-CC, a novel metric based on program semantics and entropy. They decompose programs into semantic units, organize them hierarchically, and quantify complexity by aggregating compositional levels and divergence.", "result": "Experiments show that LM-CC correlates more strongly with LLM performance than traditional metrics and improving LM-CC directly enhances task performance.", "conclusion": "LM-CC offers a better framework for evaluating code complexity in the context of LLMs, overcoming the limitations of traditional metrics and providing a path for improving LLM task performance."}}
{"id": "2602.07413", "pdf": "https://arxiv.org/pdf/2602.07413", "abs": "https://arxiv.org/abs/2602.07413", "authors": ["Yunhai Han", "Linhao Bai", "Ziyu Xiao", "Zhaodong Yang", "Yogita Choudhary", "Krishna Jha", "Chuizheng Kong", "Shreyas Kousik", "Harish Ravichandar"], "title": "Going with the Flow: Koopman Behavioral Models as Implicit Planners for Visuo-Motor Dexterity", "categories": ["cs.RO"], "comment": null, "summary": "There has been rapid and dramatic progress in robots' ability to learn complex visuo-motor manipulation skills from demonstrations, thanks in part to expressive policy classes that employ diffusion- and transformer-based backbones. However, these design choices require significant data and computational resources and remain far from reliable, particularly within the context of multi-fingered dexterous manipulation. Fundamentally, they model skills as reactive mappings and rely on fixed-horizon action chunking to mitigate jitter, creating a rigid trade-off between temporal coherence and reactivity. In this work, we introduce Unified Behavioral Models (UBMs), a framework that learns to represent dexterous skills as coupled dynamical systems that capture how visual features of the environment (visual flow) and proprioceptive states of the robot (action flow) co-evolve. By capturing such behavioral dynamics, UBMs can ensure temporal coherence by construction rather than by heuristic averaging. To operationalize these models, we propose Koopman-UBM, a first instantiation of UBMs that leverages Koopman Operator theory to effectively learn a unified representation in which the joint flow of latent visual and proprioceptive features is governed by a structured linear system. We demonstrate that Koopman-UBM can be viewed as an implicit planner: given an initial condition, it analytically computes the desired robot behavior while simultaneously ''imagining'' the resulting flow of visual features over the entire skill horizon. To enable reactivity and adaptation, we introduce an online replanning strategy in which the model acts as its own runtime monitor that automatically triggers replanning when predicted and observed visual flow diverge beyond a threshold. Across seven simulated tasks and two real-world tasks, we demonstrate that K-UBM matches or exceeds the performance of state-of-the-art baselines, while offering considerably faster inference, smooth execution, robustness to occlusions, and flexible replanning.", "AI": {"tldr": "The paper proposes Unified Behavioral Models (UBMs), a framework for learning dexterous manipulation skills as coupled dynamical systems, addressing inefficiencies in current methods relying on reactive mappings and action chunking.", "motivation": "Current robot learning methods for dexterous manipulation suffer from high data and computational costs, lack reliability, and struggle to maintain temporal coherence while being reactive.", "method": "The authors introduce UBMs, with Koopman-UBM as a specific implementation, utilizing Koopman Operator theory to model skill learning as unified behavioral dynamics of visual and proprioceptive flows, enabling analytical computation and runtime revisions.", "result": "Koopman-UBM successfully outperformed state-of-the-art baselines in both simulated and real-world tasks, showcasing benefits like smooth execution, robust replanning, and fast inference.", "conclusion": "By capturing behavioral dynamics, UBMs ensure coherent and adaptive robot behaviors while improving reliability and computational efficiency in complex manipulation tasks."}}
{"id": "2602.07497", "pdf": "https://arxiv.org/pdf/2602.07497", "abs": "https://arxiv.org/abs/2602.07497", "authors": ["Mo Wang", "Kaixuan Ren", "Pratik Jalan", "Ahmed Ashraf", "Tuong Vy Vu", "Rahul Seetharaman", "Shah Nawaz", "Usman Naseem"], "title": "From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection", "categories": ["cs.CL"], "comment": "12 pages, 5 figures, Proceedings of the ACM Web Conference 2026 (WWW '26)", "summary": "Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.", "AI": {"tldr": "This paper highlights how cultural context impacts VLMs, providing a framework to evaluate their cross-cultural performance and proposing solutions to improve robustness in hateful meme detection.", "motivation": "To address the cultural and linguistic biases in vision-language models that predominantly operate through Western or English-centric perspectives, limiting fairness and robustness in tasks like detecting hateful memes.", "method": "The authors introduce an evaluation framework to analyze multilingual VLM performance across three dimensions: learning strategy (zero-shot vs. one-shot), prompting language (native vs. English), and translation effects. They investigate interventions like native language prompting and evaluate against multilingual meme datasets.", "result": "The study finds that 'translate-then-detect' approaches harm performance, while native language prompts and one-shot learning improve cross-cultural robustness. Current VLMs converge on Western safety norms, limiting cross-cultural effectiveness.", "conclusion": "Actionable strategies, such as culturally aligned interventions, are essential to create globally equitable VLM moderation systems, addressing biases and enhancing fairness in hateful content detection."}}
{"id": "2602.07050", "pdf": "https://arxiv.org/pdf/2602.07050", "abs": "https://arxiv.org/abs/2602.07050", "authors": ["Sonia Joseph", "Quentin Garrido", "Randall Balestriero", "Matthew Kowal", "Thomas Fel", "Shahab Bakhtiari", "Blake Richards", "Mike Rabbat"], "title": "Interpreting Physics in Video World Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "A long-standing question in physical reasoning is whether video-based models need to rely on factorized representations of physical variables in order to make physically accurate predictions, or whether they can implicitly represent such variables in a task-specific, distributed manner. While modern video world models achieve strong performance on intuitive physics benchmarks, it remains unclear which of these representational regimes they implement internally. Here, we present the first interpretability study to directly examine physical representations inside large-scale video encoders. Using layerwise probing, subspace geometry, patch-level decoding, and targeted attention ablations, we characterize where physical information becomes accessible and how it is organized within encoder-based video transformers.\n  Across architectures, we identify a sharp intermediate-depth transition -- which we call the Physics Emergence Zone -- at which physical variables become accessible. Physics-related representations peak shortly after this transition and degrade toward the output layers. Decomposing motion into explicit variables, we find that scalar quantities such as speed and acceleration are available from early layers onwards, whereas motion direction becomes accessible only at the Physics Emergence Zone. Notably, we find that direction is encoded through a high-dimensional population structure with circular geometry, requiring coordinated multi-feature intervention to control. These findings suggest that modern video models do not use factorized representations of physical variables like a classical physics engine. Instead, they use a distributed representation that is nonetheless sufficient for making physical predictions.", "AI": {"tldr": "This paper investigates how modern video-based models internally represent physical variables, focusing on whether they use factorized representations like classical physics engines or distributed task-specific representations.", "motivation": "To determine whether video-based AI models mimic classical physics engines by using explicit physical variables or rely instead on distributed, implicit representations.", "method": "The authors analyzed internal physical representations in video transformers using techniques like layerwise probing, subspace geometry, and attention ablations, identifying key stages where physical information emerged.", "result": "They discovered a key intermediate stage in models, termed the 'Physics Emergence Zone,' where physical variables become accessible. Scalar motion variables emerged early, while motion direction required more complex, high-dimensional encoding.", "conclusion": "Modern video transformers use distributed, non-factorized representations of physical properties that enable them to make accurate predictions without resembling classical physics engines."}}
{"id": "2602.07432", "pdf": "https://arxiv.org/pdf/2602.07432", "abs": "https://arxiv.org/abs/2602.07432", "authors": ["Ning Li"], "title": "The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We show that these viral narratives were overwhelmingly human-driven. Exploiting an architectural feature of the OpenClaw agent framework--a periodic \"heartbeat\" cycle that produces regular posting intervals for autonomous agents but is disrupted by human prompting--we develop a temporal fingerprinting method based on the coefficient of variation of inter-post intervals. This signal converges with independent content, ownership, and network indicators across 91,792 posts and 405,707 comments from 22,020 agents. No viral phenomenon originated from a clearly autonomous agent; three of six traced to accounts with irregular temporal signatures characteristic of human intervention, one showed mixed patterns, and two had insufficient posting history for classification. A 44-hour platform shutdown provided a natural experiment: human-influenced agents returned first (87.7% of early reconnectors), confirming that the token reset differentially affected autonomous versus human-operated agents. We further document industrial-scale bot farming (four accounts producing 32% of all comments with 12-second coordination gaps) and rapid decay of human influence through reply chains (half-life: 0.65 conversation depths). These methods generalize to emerging multi-agent systems where attribution of autonomous versus human-directed behavior is critical.", "AI": {"tldr": "The study investigates viral narratives on an AI platform and reveals they were mainly driven by humans, using a temporal fingerprinting method and other indicators.", "motivation": "To determine whether apparent autonomous behavior on the AI platform Moltbook was truly emergent or human-driven.", "method": "The researchers used a temporal fingerprinting method, analyzing the posting intervals of agents, coupled with content, ownership, and network analysis, across a large dataset.", "result": "Viral phenomena were human-driven; a shutdown experiment confirmed differential behavior between autonomous and human-operated agents, alongside evidence of bot farming.", "conclusion": "Most viral narratives were human-originated, and the study's methods provide tools to distinguish human versus autonomous actions in multi-agent systems."}}
{"id": "2602.07202", "pdf": "https://arxiv.org/pdf/2602.07202", "abs": "https://arxiv.org/abs/2602.07202", "authors": ["Alonso Granados", "Jason Pacheco"], "title": "Risk-Sensitive Exponential Actor Critic", "categories": ["cs.LG"], "comment": "To appear at AAAI 2026", "summary": "Model-free deep reinforcement learning (RL) algorithms have achieved tremendous success on a range of challenging tasks. However, safety concerns remain when these methods are deployed on real-world applications, necessitating risk-aware agents. A common utility for learning such risk-aware agents is the entropic risk measure, but current policy gradient methods optimizing this measure must perform high-variance and numerically unstable updates. As a result, existing risk-sensitive model-free approaches are limited to simple tasks and tabular settings. In this paper, we provide a comprehensive theoretical justification for policy gradient methods on the entropic risk measure, including on- and off-policy gradient theorems for the stochastic and deterministic policy settings. Motivated by theory, we propose risk-sensitive exponential actor-critic (rsEAC), an off-policy model-free approach that incorporates novel procedures to avoid the explicit representation of exponential value functions and their gradients, and optimizes its policy w.r.t the entropic risk measure. We show that rsEAC produces more numerically stable updates compared to existing approaches and reliably learns risk-sensitive policies in challenging risky variants of continuous tasks in MuJoCo.", "AI": {"tldr": "The paper addresses safety in real-world applications of deep reinforcement learning by introducing a model-free approach, rsEAC, optimizing the entropic risk measure with stable gradient methods.", "motivation": "Safety is a key concern in deploying deep reinforcement learning in real-world applications, requiring development of risk-aware agents to handle uncertainties effectively.", "method": "The authors theoretically justify policy gradient methods for the entropic risk measure and introduce rsEAC, an off-policy model-free algorithm optimizing risk-sensitive policies without relying on unstable gradient updates.", "result": "rsEAC achieves numerically stable learning and effectively develops risk-sensitive policies in complex continuous tasks within the MuJoCo environment.", "conclusion": "rsEAC improves stability and reliability in risk-sensitive reinforcement learning, bridging a gap between theoretical advancements and practical applications in challenging environments."}}
{"id": "2602.07893", "pdf": "https://arxiv.org/pdf/2602.07893", "abs": "https://arxiv.org/abs/2602.07893", "authors": ["Zhiyuan Chen", "Soham Sanjay Deo", "Poorna Chander Reddy Puttaparthi", "Vanessa Nava-Camal", "Yiming Tang", "Xueling Zhang", "Weiyi Shang"], "title": "Is Your Private Information Logged? An Empirical Study on Android App Logs", "categories": ["cs.SE"], "comment": null, "summary": "With the rapid growth of mobile apps, users' concerns about their privacy have become increasingly prominent. Android app logs serve as crucial computer resources, aiding developers in debugging and monitoring the status of Android apps, while also containing a wealth of software system information. Previous studies have acknowledged privacy leaks in software logs and Android apps as significant issues without providing a comprehensive view of the privacy leaks in Android app logs. In this study, we build a comprehensive dataset of Android app logs and conduct an empirical study to analyze the status and severity of privacy leaks in Android app logs. Our study comprises three aspects: (1) Understanding real-world developers' concerns regarding privacy issues related to software logs; (2) Studying privacy leaks in the Android app logs; (3) Investigating the characteristics of privacy-leaking Android app logs and analyzing the reasons behind them. Our study reveals five different categories of concerns from real-world developers regarding privacy issues related to software logs and the prevalence of privacy leaks in Android app logs, with the majority stemming from developers' unawareness of such leaks. Additionally, our study provides developers with suggestions to safeguard their privacy from being logged.", "AI": {"tldr": "This paper investigates privacy leaks in Android app logs, builds a comprehensive dataset, and offers insights and developer suggestions for mitigating such issues.", "motivation": "With the growth of mobile apps, privacy concerns of users are increasing, particularly due to overlooked privacy leaks in Android app logs.", "method": "The authors create a dataset of Android app logs and conduct a three-part study: analyzing developer concerns, investigating privacy leaks, and understanding their characteristics and causes.", "result": "Five categories of developer concerns were identified. Privacy leaks in app logs are prevalent, often due to developers' lack of awareness.", "conclusion": "The study exposes the extent of privacy leaks in Android app logs and offers actionable recommendations for developers to better safeguard privacy."}}
{"id": "2602.07434", "pdf": "https://arxiv.org/pdf/2602.07434", "abs": "https://arxiv.org/abs/2602.07434", "authors": ["Songhua Yang", "Xuetao Li", "Xuanye Fei", "Mengde Li", "Miao Li"], "title": "Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Effective human-robot interaction requires emotionally rich multimodal expressions, yet most humanoid robots lack coordinated speech, facial expressions, and gestures. Meanwhile, real-world deployment demands on-device solutions that can operate autonomously without continuous cloud connectivity. To bridging \\underline{\\textit{S}}peech, \\underline{\\textit{E}}motion, and \\underline{\\textit{M}}otion, we present \\textit{SeM$^2$}, a Vision Language Model-based framework that orchestrates emotionally coherent multimodal interactions through three key components: a multimodal perception module capturing user contextual cues, a Chain-of-Thought reasoning for response planning, and a novel Semantic-Sequence Aligning Mechanism (SSAM) that ensures precise temporal coordination between verbal content and physical expressions. We implement both cloud-based and \\underline{\\textit{e}}dge-deployed versions (\\textit{SeM$^2_e$}), with the latter knowledge distilled to operate efficiently on edge hardware while maintaining 95\\% of the relative performance. Comprehensive evaluations demonstrate that our approach significantly outperforms unimodal baselines in naturalness, emotional clarity, and modal coherence, advancing socially expressive humanoid robotics for diverse real-world environments.", "AI": {"tldr": "The paper introduces SeM^2, a framework for emotionally coherent multimodal interactions in humanoid robots, with both cloud-based and edge-deployed versions, achieving enhanced performance in real-world conditions.", "motivation": "Current humanoid robots often lack coordinated speech, facial expressions, and gestures for effective human-robot interactions. Additionally, there is a need for autonomous solutions capable of operating without constant cloud connectivity.", "method": "The SeM^2 framework includes a multimodal perception module for contextual cues, a Chain-of-Thought reasoning system for planning, and a Semantic-Sequence Aligning Mechanism to synchronize verbal and physical expressions. Both cloud-based and edge versions are developed, with knowledge distillation for efficiency.", "result": "SeM^2 achieves significant improvements over unimodal approaches in naturalness, emotional clarity, and coherence, while the edge-deployed version maintains 95% of the relative performance.", "conclusion": "SeM^2 advances the capabilities of humanoid robotics by enabling emotionally rich, multimodal interactions in various real-world settings, combining natural behavior with operational efficiency."}}
{"id": "2602.07499", "pdf": "https://arxiv.org/pdf/2602.07499", "abs": "https://arxiv.org/abs/2602.07499", "authors": ["Jingshen Zhang", "Xin Ying Qiu", "Lifang Lu", "Zhuhua Huang", "Yutao Hu", "Yuechang Wu", "JunYu Lu"], "title": "Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification", "categories": ["cs.CL"], "comment": "Accepted to EACL 2026 Findings", "summary": "Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.", "AI": {"tldr": "This paper introduces a step-by-step simplification framework for proficiency-controlled sentence simplification, addressing limitations in large readability-level shifts.", "motivation": "Large language models lack effectiveness in adequately simplifying sentences across varying proficiency levels with preserved meaning.", "method": "A dynamic framework incorporating path planning, semantic-aware exemplar selection, and chain-of-thought generation to improve simplifications across diverse readability levels.", "result": "Improved simplification effectiveness across five languages, with computational step reductions of 22-42%. Human evaluations reveal trade-offs between simplification and meaning preservation.", "conclusion": "Step-by-step simplification enhances control but achieving semantic fidelity across extensive simplifications remains a challenging issue."}}
{"id": "2602.07470", "pdf": "https://arxiv.org/pdf/2602.07470", "abs": "https://arxiv.org/abs/2602.07470", "authors": ["Alexander von Recum", "Leander Girrbach", "Zeynep Akata"], "title": "Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?", "categories": ["cs.AI"], "comment": "ICLR 2026", "summary": "Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and apply them to multiple open-weight RLLMs across Math, Science, and Logic tasks. Our results show that RLLMs are generally robust, reliably recovering from diverse perturbations, with robustness improving with model size and degrading when interventions occur early. However, robustness is not style-invariant: paraphrasing suppresses doubt-like expressions and reduces performance, while other interventions trigger doubt and support recovery. Recovery also carries a cost: neutral and adversarial noise can inflate CoT length by more than 200%, whereas paraphrasing shortens traces but harms accuracy. These findings provide new evidence on how RLLMs maintain reasoning integrity, identify doubt as a central recovery mechanism, and highlight trade-offs between robustness and efficiency that future training methods should address.", "AI": {"tldr": "The study examines the robustness of Reasoning LLMs (RLLMs) when their reasoning chains (CoTs) are disrupted, revealing both recovery mechanisms and trade-offs.", "motivation": "The motivation is to assess the reliability and integrity of reasoning processes in RLLMs under disruptions, a key factor for their deployment in complex reasoning tasks.", "method": "The authors introduce an evaluation framework to perturb RLLM-generated CoTs at fixed stages using seven intervention types across Math, Science, and Logic tasks.", "result": "RLLMs generally recover from disruptions, with robustness improving with model size but diminishing for early interventions. Recovery mechanisms depend on the intervention type, with notable impacts on CoT structure and task accuracy.", "conclusion": "RLLMs showcase robustness and a reliance on doubt mechanisms to recover from reasoning disruptions, but such recoveries bring substantial costs in efficiency and accuracy, highlighting areas for future improvement."}}
{"id": "2602.07203", "pdf": "https://arxiv.org/pdf/2602.07203", "abs": "https://arxiv.org/abs/2602.07203", "authors": ["R. Teal Witter", "\u00c1lvaro Parafita", "Tomas Garriga", "Maximilian Muschalik", "Fabian Fumagalli", "Axel Brando", "Lucas Rosenblatt"], "title": "Exactly Computing do-Shapley Values", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Structural Causal Models (SCM) are a powerful framework for describing complicated dynamics across the natural sciences. A particularly elegant way of interpreting SCMs is do-Shapley, a game-theoretic method of quantifying the average effect of $d$ variables across exponentially many interventions. Like Shapley values, computing do-Shapley values generally requires evaluating exponentially many terms. The foundation of our work is a reformulation of do-Shapley values in terms of the irreducible sets of the underlying SCM. Leveraging this insight, we can exactly compute do-Shapley values in time linear in the number of irreducible sets $r$, which itself can range from $d$ to $2^d$ depending on the graph structure of the SCM. Since $r$ is unknown a priori, we complement the exact algorithm with an estimator that, like general Shapley value estimators, can be run with any query budget. As the query budget approaches $r$, our estimators can produce more accurate estimates than prior methods by several orders of magnitude, and, when the budget reaches $r$, return the Shapley values up to machine precision. Beyond computational speed, we also reduce the identification burden: we prove that non-parametric identifiability of do-Shapley values requires only the identification of interventional effects for the $d$ singleton coalitions, rather than all classes.", "AI": {"tldr": "The paper introduces a reformulation of do-Shapley values for Structural Causal Models (SCM), enabling more efficient computation and reduced identification requirements.", "motivation": "To address the computational inefficiency and high identification burden in calculating do-Shapley values for SCMs, which involve exponentially many terms to evaluate.", "method": "Reformulated the computation of do-Shapley values based on irreducible sets in SCM, enabling exact computation in linear time concerning the number of irreducible sets. Additionally, created an estimator for scenarios with limited query budgets.", "result": "Achieved efficient exact computation of do-Shapley values in time proportional to the irreducible sets. The new estimators outperform prior methods in accuracy by orders of magnitude under equivalent query budgets.", "conclusion": "The work significantly improves the computational feasibility and practicality of using do-Shapley values in SCM analysis by reducing both computational time and identifiability requirements."}}
{"id": "2602.07900", "pdf": "https://arxiv.org/pdf/2602.07900", "abs": "https://arxiv.org/abs/2602.07900", "authors": ["Zhi Chen", "Zhensu Sun", "Yuling Shi", "Chao Peng", "Xiaodong Gu", "David Lo", "Lingxiao Jiang"], "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the critical question: whether such tests meaningfully improve issue resolution or merely mimic human testing practices while consuming a substantial interaction budget.\n  To reveal the impact of agent-written tests, we present an empirical study that analyzes agent trajectories across six state-of-the-art LLMs on SWE-bench Verified. Our results show that while test writing is commonly adopted, but resolved and unresolved tasks within the same model exhibit similar test-writing frequencies Furthermore, these tests typically serve as observational feedback channels, where agents prefer value-revealing print statements significantly more than formal assertion-based checks. Based on these insights, we perform a controlled experiment by revising the prompts of four agents to either increase or reduce test writing. The results suggest that changes in the volume of agent-written tests do not significantly change final outcomes. Taken together, our study reveals that current test-writing practices may provide marginal utility in autonomous software engineering tasks.", "AI": {"tldr": "The paper investigates the utility of test-writing practices by LLM code agents, finding that test-writing does not significantly improve the resolution of repository-level issues.", "motivation": "To understand whether agent-written tests meaningfully contribute to issue resolution or just mimic human testing practices while consuming interaction budgets.", "method": "Conducted an empirical study on agent trajectories across six LLMs on SWE-bench Verified, analyzing test-writing frequencies, types, and effects. Additionally, ran controlled experiments modifying agent prompts to vary test-writing behaviors.", "result": "Test-writing is common across agents, but resolved and unresolved tasks have similar test-writing frequencies. Agents primarily use print statements over formal assertions, and changes in test-writing volume had negligible impact on outcomes.", "conclusion": "Current practices of test-writing in autonomous software engineering tasks yield marginal utility, questioning its effectiveness in issue resolution workflows."}}
{"id": "2602.07439", "pdf": "https://arxiv.org/pdf/2602.07439", "abs": "https://arxiv.org/abs/2602.07439", "authors": ["Weiji Xie", "Jiakun Zheng", "Jinrui Han", "Jiyuan Shi", "Weinan Zhang", "Chenjia Bai", "Xuelong Li"], "title": "TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control", "categories": ["cs.RO", "cs.AI"], "comment": "Project Page: https://text-op.github.io/", "summary": "Recent advances in humanoid whole-body motion tracking have enabled the execution of diverse and highly coordinated motions on real hardware. However, existing controllers are commonly driven either by predefined motion trajectories, which offer limited flexibility when user intent changes, or by continuous human teleoperation, which requires constant human involvement and limits autonomy. This work addresses the problem of how to drive a universal humanoid controller in a real-time and interactive manner. We present TextOp, a real-time text-driven humanoid motion generation and control framework that supports streaming language commands and on-the-fly instruction modification during execution. TextOp adopts a two-level architecture in which a high-level autoregressive motion diffusion model continuously generates short-horizon kinematic trajectories conditioned on the current text input, while a low-level motion tracking policy executes these trajectories on a physical humanoid robot. By bridging interactive motion generation with robust whole-body control, TextOp unlocks free-form intent expression and enables smooth transitions across multiple challenging behaviors such as dancing and jumping, within a single continuous motion execution. Extensive real-robot experiments and offline evaluations demonstrate instant responsiveness, smooth whole-body motion, and precise control. The project page and the open-source code are available at https://text-op.github.io/", "AI": {"tldr": "TextOp introduces a real-time text-driven framework for interactive humanoid motion generation and control, allowing seamless behavior transitions and precise execution on physical robots.", "motivation": "Traditional humanoid controllers rely on predefined trajectories or continuous human teleoperation, limiting flexibility and autonomy. This paper aims to enable real-time, text-driven motion control.", "method": "TextOp employs a two-level architecture. A high-level autoregressive motion diffusion model generates kinematic trajectories based on text input, while a low-level motion tracking policy executes these trajectories on physical humanoid robots.", "result": "Extensive experiments showcased instant responsiveness, smooth transitions, robust whole-body motion tracking, and precise control during real-robot testing.", "conclusion": "TextOp successfully bridges interactive motion generation and robust humanoid control, enhancing autonomy and flexibility in executing diverse behaviors."}}
{"id": "2602.07546", "pdf": "https://arxiv.org/pdf/2602.07546", "abs": "https://arxiv.org/abs/2602.07546", "authors": ["Zicong Cheng", "Ruixuan Jia", "Jia Li", "Guo-Wei Yang", "Meng-Hao Guo", "Shi-Min Hu"], "title": "Improving Variable-Length Generation in Diffusion Language Models via Length Regularization", "categories": ["cs.CL", "cs.LG"], "comment": "diffusion language models", "summary": "Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).", "AI": {"tldr": "The paper addresses the problem of variable-length generation in Diffusion Large Language Models (DLLMs) and proposes an inference framework, LR-DLLM, to better handle length determination.", "motivation": "DLLMs struggle with variable-length generation due to their fixed-length canvas, leading to biases when target length is unknown, making generation unreliable for tasks like completion and infilling.", "method": "The paper introduces LR-DLLM, a length-regularized inference framework that explicitly incorporates generation length as a variable, correcting biased confidence estimates and decoupling semantic compatibility from length-induced uncertainty.", "result": "LR-DLLM significantly improves performance, achieving 51.3% Pass@1 on HumanEval-Infilling (+13.4% over existing methods) and 51.5% average Pass@1 across multi-language McEval (+14.3%).", "conclusion": "LR-DLLM effectively addresses the length-induced bias in DLLMs, enabling dynamic generation adjustments without altering the model or training procedure, improving reliability in variable-length generation tasks."}}
{"id": "2602.07052", "pdf": "https://arxiv.org/pdf/2602.07052", "abs": "https://arxiv.org/abs/2602.07052", "authors": ["Ziye Xie", "Oded Schlesinger", "Raj Kundu", "Jessica Y. Choi", "Pablo Iturralde", "Dennis A. Turner", "Stefan M. Goetz", "Guillermo Sapiro", "Angel V. Peterchev", "J. Matias Di Martino"], "title": "Toward Accurate and Accessible Markerless Neuronavigation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Neuronavigation is widely used in biomedical research and interventions to guide the precise placement of instruments around the head to support procedures such as transcranial magnetic stimulation. Traditional systems, however, rely on subject-mounted markers that require manual registration, may shift during procedures, and can cause discomfort. We introduce and evaluate markerless approaches that replace expensive hardware and physical markers with low-cost visible and infrared light cameras incorporating stereo and depth sensing combined with algorithmic modeling of the facial geometry. Validation with $50$ human subjects yielded a median tracking discrepancy of only $2.32$ mm and $2.01\u00b0$ for the best markerless algorithms compared to a conventional marker-based system, which indicates sufficient accuracy for transcranial magnetic stimulation and a substantial improvement over prior markerless results. The results suggest that integration of the data from the various camera sensors can improve the overall accuracy further. The proposed markerless neuronavigation methods can reduce setup cost and complexity, improve patient comfort, and expand access to neuronavigation in clinical and research settings.", "AI": {"tldr": "This paper proposes markerless neuronavigation using affordable camera technologies and algorithmic modeling. It shows improved accuracy and usability over traditional marker-based systems.", "motivation": "Traditional neuronavigation systems rely on physical markers that are cumbersome, expensive, and may shift during use, leading to inaccuracies and reduced patient comfort. There is a need for a cost-effective and comfortable alternative for precise placement of instruments.", "method": "The authors developed markerless neuronavigation methods using low-cost cameras (visible and infrared) incorporating stereo and depth sensing. Algorithmic modeling of facial geometry was applied for tracking and positioning. Validation was conducted with 50 subjects.", "result": "The best markerless algorithms achieved a median tracking discrepancy of 2.32 mm and 2.01\u00b0, comparable to marker-based systems but significantly better than previous markerless attempts.", "conclusion": "Markerless neuronavigation methods can replace traditional systems, reducing expense and complexity while improving patient comfort, with potential for broader accessibility in clinical and research applications."}}
{"id": "2602.07205", "pdf": "https://arxiv.org/pdf/2602.07205", "abs": "https://arxiv.org/abs/2602.07205", "authors": ["Junyan Liu", "Haipeng Luo", "Zihan Zhang", "Lillian J. Ratliff"], "title": "Online Learning for Uninformed Markov Games: Empirical Nash-Value Regret and Non-Stationarity Adaptation", "categories": ["cs.LG", "cs.GT", "stat.ML"], "comment": "36 pages", "summary": "We study online learning in two-player uninformed Markov games, where the opponent's actions and policies are unobserved. In this setting, Tian et al. (2021) show that achieving no-external-regret is impossible without incurring an exponential dependence on the episode length $H$. They then turn to the weaker notion of Nash-value regret and propose a V-learning algorithm with regret $O(K^{2/3})$ after $K$ episodes. However, their algorithm and guarantee do not adapt to the difficulty of the problem: even in the case where the opponent follows a fixed policy and thus $O(\\sqrt{K})$ external regret is well-known to be achievable, their result is still the worse rate $O(K^{2/3})$ on a weaker metric.\n  In this work, we fully address both limitations. First, we introduce empirical Nash-value regret, a new regret notion that is strictly stronger than Nash-value regret and naturally reduces to external regret when the opponent follows a fixed policy. Moreover, under this new metric, we propose a parameter-free algorithm that achieves an $O(\\min \\{\\sqrt{K} + (CK)^{1/3},\\sqrt{LK}\\})$ regret bound, where $C$ quantifies the variance of the opponent's policies and $L$ denotes the number of policy switches (both at most $O(K)$). Therefore, our results not only recover the two extremes -- $O(\\sqrt{K})$ external regret when the opponent is fixed and $O(K^{2/3})$ Nash-value regret in the worst case -- but also smoothly interpolate between these extremes by automatically adapting to the opponent's non-stationarity. We achieve so by first providing a new analysis of the epoch-based V-learning algorithm by Mao et al. (2022), establishing an $O(\u03b7C + \\sqrt{K/\u03b7})$ regret bound, where $\u03b7$ is the epoch incremental factor. Next, we show how to adaptively restart this algorithm with an appropriate $\u03b7$ in response to the potential non-stationarity of the opponent, eventually achieving our final results.", "AI": {"tldr": "This paper addresses the challenges of online learning in two-player uninformed Markov games, introducing an improved regret analysis and algorithm.", "motivation": "The motivation is to overcome limitations in achieving no-external-regret for online Markov games, adapting to problem difficulty and overcoming the challenges of fixed or variable opponent policies.", "method": "The authors propose a new regret metric, empirical Nash-value regret, and design a parameter-free algorithm that adapts to the opponent's non-stationary behavior using epoch-based V-learning.", "result": "The new approach provides a regret bound of $O(\\min \\{\\sqrt{K} + (CK)^{1/3},\\sqrt{LK}\\})$, recovering prior work's results while smoothly adapting to opponent variability.", "conclusion": "This work bridges prior gaps, generalizing to both fixed and highly variable opponent behavior with a scalable, adaptive approach that improves state-of-the-art performance."}}
{"id": "2602.07473", "pdf": "https://arxiv.org/pdf/2602.07473", "abs": "https://arxiv.org/abs/2602.07473", "authors": ["Nathana\u00ebl Fijalkow", "Arka Ghosh", "Roman Kniazev", "Guillermo A. P\u00e9rez", "Pierre Vandenhove"], "title": "Computing the Reachability Value of Posterior-Deterministic POMDPs", "categories": ["cs.AI", "cs.FL"], "comment": null, "summary": "Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.\n  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.\n  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.", "AI": {"tldr": "This paper introduces a new class of POMDPs, known as posterior-deterministic POMDPs, allowing maximal probability reachability computation with arbitrary precision.", "motivation": "Address the intractability and undecidability issues in verification and synthesis problems in POMDPs, particularly pertaining to reachability probabilities.", "method": "Define and analyze posterior-deterministic POMDPs, which ensure the state remains known once revealed, enabling computation and approximation of reachability values.", "result": "Demonstrate that the introduced class can approximate the reachability value to arbitrary precision, contrasting with traditional POMDPs.", "conclusion": "Posterior-deterministic POMDPs expand computational feasibility in sequential decision-making under uncertainty, bridging the gap with fully observable MDPs."}}
{"id": "2602.08004", "pdf": "https://arxiv.org/pdf/2602.08004", "abs": "https://arxiv.org/abs/2602.08004", "authors": ["George Ling", "Shanshan Zhong", "Richard Huang"], "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality", "categories": ["cs.SE", "cs.SI"], "comment": null, "summary": "Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they pose. To answer these questions, we conduct a large-scale, data-driven analysis of 40,285 publicly listed skills from a major marketplace. Our results show that skill publication tends to occur in short bursts that track shifts in community attention. We also find that skill content is highly concentrated in software engineering workflows, while information retrieval and content creation account for a substantial share of adoption. Beyond content trends, we uncover a pronounced supply-demand imbalance across categories, and we show that most skills remain within typical prompt budgets despite a heavy-tailed length distribution. Finally, we observe strong ecosystem homogeneity, with widespread intent-level redundancy, and we identify non-trivial safety risks, including skills that enable state-changing or system-level actions. Overall, our findings provide a quantitative snapshot of agent skills as an emerging infrastructure layer for agents and inform future work on skill reuse, standardization, and safety-aware design.", "AI": {"tldr": "This paper analyzes 40,285 publicly listed LLM agent skills, revealing market trends, adoption patterns, and risks associated with these program-like modules.", "motivation": "The study aims to understand the types of LLM agent skills available, their adoption trends, and associated risks as they proliferate in public marketplaces.", "method": "The researchers conducted a large-scale, data-driven analysis of 40,285 skills from a major marketplace.", "result": "Findings include short bursts in skill publication, concentration in software engineering workflows, a supply-demand imbalance, adherence to typical prompt budgets, redundancy, and safety risks.", "conclusion": "Agent skills represent an emerging infrastructure layer for AI agents, but future efforts should focus on improving reuse, standardization, and ensuring safety-aware designs."}}
{"id": "2602.07506", "pdf": "https://arxiv.org/pdf/2602.07506", "abs": "https://arxiv.org/abs/2602.07506", "authors": ["Peizhen Li", "Longbing Cao", "Xiao-Ming Wu", "Yang Zhang"], "title": "VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "Accepted to the 2026 IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Humanoid facial expression shadowing enables robots to realistically imitate human facial expressions in real time, which is critical for lifelike, facially expressive humanoid robots and affective human-robot interaction. Existing progress in humanoid facial expression imitation remains limited, often failing to achieve either real-time performance or realistic expressiveness due to offline video-based inference designs and insufficient ability to capture and transfer subtle expression details. To address these limitations, we present VividFace, a real-time and realistic facial expression shadowing system for humanoid robots. An optimized imitation framework X2CNet++ enhances expressiveness by fine-tuning the human-to-humanoid facial motion transfer module and introducing a feature-adaptation training strategy for better alignment across different image sources. Real-time shadowing is further enabled by a video-stream-compatible inference pipeline and a streamlined workflow based on asynchronous I/O for efficient communication across devices. VividFace produces vivid humanoid faces by mimicking human facial expressions within 0.05 seconds, while generalizing across diverse facial configurations. Extensive real-world demonstrations validate its practical utility. Videos are available at: https://lipzh5.github.io/VividFace/.", "AI": {"tldr": "This paper introduces VividFace, a real-time system allowing humanoid robots to mimic human facial expressions quickly and realistically.", "motivation": "To overcome the lack of realistic and real-time human facial expression imitation in humanoid robots for enhanced human-robot interactions.", "method": "VividFace employs an optimized model, X2CNet++, with a feature-adaptation training strategy and an asynchronous I/O workflow to enable real-time processing and enhanced expressiveness.", "result": "VividFace achieves vivid human expression shadowing in under 0.05 seconds and generalizes well across various facial configurations, demonstrated through real-world tests.", "conclusion": "VividFace provides a promising solution for lifelike humanoid facial expression imitation, paving the way for effective human-robot interactions."}}
{"id": "2602.07594", "pdf": "https://arxiv.org/pdf/2602.07594", "abs": "https://arxiv.org/abs/2602.07594", "authors": ["Yuxin Chen", "Yu Wang", "Yi Zhang", "Ziang Ye", "Zhengzhou Cai", "Yaorui Shi", "Qi Gu", "Hui Su", "Xunliang Cai", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Learning to Self-Verify Makes Language Models Better Reasoners", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.", "AI": {"tldr": "The paper explores the asymmetry between large language models' generation and self-verification capabilities, proposing a multi-task reinforcement learning framework to address the issue.", "motivation": "Large language models excel in generating reasoning paths but struggle with self-verification of their answers, leading to an imbalance in capabilities.", "method": "The study investigates this asymmetry throughout training evolution, and proposes a multi-task reinforcement learning framework where generation and self-verification are separately optimized.", "result": "The framework improves both generation and verification capabilities compared to generation-only training, yielding more accurate and efficient reasoning traces.", "conclusion": "Integrating self-verification into generation training effectively addresses the asymmetry and enhances overall model performance."}}
{"id": "2602.07057", "pdf": "https://arxiv.org/pdf/2602.07057", "abs": "https://arxiv.org/abs/2602.07057", "authors": ["Di Mo", "Mingyang Sun", "Chengxiu Yin", "Runjia Tian", "Yanhong Wu", "Liyan Xu"], "title": "RECITYGEN -- Interactive and Generative Participatory Urban Design Tool with Latent Diffusion and Segment Anything", "categories": ["cs.CV"], "comment": null, "summary": "Urban design profoundly impacts public spaces and community engagement. Traditional top-down methods often overlook public input, creating a gap in design aspirations and reality. Recent advancements in digital tools, like City Information Modelling and augmented reality, have enabled a more participatory process involving more stakeholders in urban design. Further, deep learning and latent diffusion models have lowered barriers for design generation, providing even more opportunities for participatory urban design. Combining state-of-the-art latent diffusion models with interactive semantic segmentation, we propose RECITYGEN, a novel tool that allows users to interactively create variational street view images of urban environments using text prompts. In a pilot project in Beijing, users employed RECITYGEN to suggest improvements for an ongoing Urban Regeneration project. Despite some limitations, RECITYGEN has shown significant potential in aligning with public preferences, indicating a shift towards more dynamic and inclusive urban planning methods. The source code for the project can be found at RECITYGEN GitHub.", "AI": {"tldr": "The paper introduces RECITYGEN, a tool combining latent diffusion models and semantic segmentation for participatory urban design via text-generated street visuals.", "motivation": "Current urban design methods lack sufficient public input and integration with participatory digital tools, necessitating a more inclusive approach.", "method": "The authors developed RECITYGEN, enabling interactive creation of urban street visuals through latent diffusion models and semantic segmentation, tested via a pilot in Beijing.", "result": "The pilot study demonstrated that RECITYGEN aligns with public preferences and bridges the gap in participatory urban planning, despite certain limitations.", "conclusion": "RECITYGEN indicates a progressive shift towards digitally-enabled, more inclusive urban design approaches, proving the value of broader public participation and advanced tools."}}
{"id": "2602.07218", "pdf": "https://arxiv.org/pdf/2602.07218", "abs": "https://arxiv.org/abs/2602.07218", "authors": ["Gagik Magakyan", "Amirhossein Reisizadeh", "Chanwoo Park", "Pablo A. Parrilo", "Asuman Ozdaglar"], "title": "Collaborative and Efficient Fine-tuning: Leveraging Task Similarity", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Adaptability has been regarded as a central feature in the foundation models, enabling them to effectively acclimate to unseen downstream tasks. Parameter-efficient fine-tuning methods such as celebrated LoRA facilitate efficient adaptation of large foundation models using labeled, high-quality and generally scarce task data. To mitigate data scarcity in fine-tuning of foundation models, we propose to leverage task similarity across multiple downstream users. Intuitively, users with similar tasks must be able to assist each other in boosting the effective fine-tuning data size. We propose Collaborative Low-Rank Adaptation, or CoLoRA, which exploits task similarity to collaboratively and efficiently fine-tune personalized foundation models. The main idea in CoLoRA is to train one shared adapter capturing underlying task similarities across all tasks, and personalized adapters tailored to user-specific tasks. We theoretically study CoLoRA on heterogeneous linear regression and provide provable guarantees for ground truth recovery. We also conduct several natural language experiments with varying task similarity, which further demonstrate that when trained together with similar tasks, individual performances are significantly boosted.", "AI": {"tldr": "The paper introduces CoLoRA, a method to collaboratively fine-tune foundation models by leveraging task similarity for efficient and improved adaptation.", "motivation": "To address data scarcity in foundation model fine-tuning by enabling users with similar tasks to collaborate and boost the effective fine-tuning data size.", "method": "Development of CoLoRA by training one shared adapter for cross-task similarities and personalized adapters for user-specific tasks, supported by theoretical guarantees.", "result": "Experiments show that tasks with similarities lead to enhanced individual performances when trained collaboratively, supported by theoretical analysis.", "conclusion": "Collaboratively fine-tuning foundation models through task similarity significantly improves adaptation for personalized tasks."}}
{"id": "2602.07491", "pdf": "https://arxiv.org/pdf/2602.07491", "abs": "https://arxiv.org/abs/2602.07491", "authors": ["Isabella A. Stewart", "Tarjei Paule Hage", "Yu-Chuan Hsu", "Markus J. Buehler"], "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design", "categories": ["cs.AI", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.", "AI": {"tldr": "This paper presents a multi-agent framework, utilizing large-scale knowledge graphs, to find alternatives for PFAS in materials science by combining distributed specialization and relational reasoning.", "motivation": "The authors aim to overcome the challenge of meaningfully connecting vast and diverse scientific information in materials science, where neither humans nor single-agent LLMs can fully address the problem due to limitations like hallucinations.", "method": "They introduce a multi-agent system guided by knowledge graphs that specializes in tasks like problem decomposition, evidence retrieval, and graph traversal to uncover connections across knowledge domains for hypothesis generation.", "result": "Ablation studies show the multi-agent framework outperforms single-shot prompting. Tailored graph traversal alternates between focused, domain-critical searches and exploratory ones, discovering sustainable PFAS-free materials with balanced properties.", "conclusion": "The framework successfully demonstrates materials design innovation by integrating knowledge graphs and multi-agent reasoning, offering sustainable PFAS-free alternatives and expanding the materials design space."}}
{"id": "2602.07206", "pdf": "https://arxiv.org/pdf/2602.07206", "abs": "https://arxiv.org/abs/2602.07206", "authors": ["Bucher Sahyouni", "Matthew Vowels", "Liqun Chen", "Simon Hadfield"], "title": "DSL: Understanding and Improving Softmax Recommender Systems with Competition-Aware Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Softmax Loss (SL) is being increasingly adopted for recommender systems (RS) as it has demonstrated better performance, robustness and fairness. Yet in implicit-feedback, a single global temperature and equal treatment of uniformly sampled negatives can lead to brittle training, because sampled sets may contain varying degrees of relevant or informative competitors. The optimal loss sharpness for a user-item pair with a particular set of negatives, can be suboptimal or destabilising for another with different negatives. We introduce Dual-scale Softmax Loss (DSL), which infers effective sharpness from the sampled competition itself. DSL adds two complementary branches to the log-sum-exp backbone. Firstly it reweights negatives within each training instance using hardness and item--item similarity, secondly it adapts a per-example temperature from the competition intensity over a constructed competitor slate. Together, these components preserve the geometry of SL while reshaping the competition distribution across negatives and across examples.\n  Over several representative benchmarks and backbones, DSL yields substantial gains over strong baselines, with improvements over SL exceeding $10%$ in several settings and averaging $6.22%$ across datasets, metrics, and backbones. Under out-of-distribution (OOD) popularity shift, the gains are larger, with an average of $9.31%$ improvement over SL. We further provide a theoretical, distributionally robust optimisation (DRO) analysis, which demonstrates how DSL reshapes the robust payoff and the KL deviation for ambiguous instances. This helps explain the empirically observed improvements in accuracy and robustness.", "AI": {"tldr": "Dual-scale Softmax Loss (DSL) significantly improves recommendation systems, offering substantial accuracy and robustness gains over Softmax Loss (SL), especially under out-of-distribution conditions.", "motivation": "Softmax Loss struggles with brittle training in implicit-feedback RS due to fixed temperature and uniform negative sampling treatment, leading to suboptimal loss sharpness for varying user-item pairs.", "method": "DSL introduces adaptive sharpness by reweighting negatives and adapting temperature per example based on sampled competition, reshaping the distribution without altering SL geometry.", "result": "Experiments show that DSL outperforms SL across benchmarks with 6.22% average gains, exceeding 10% in some cases. Under distribution shifts, gains rise to 9.31%.", "conclusion": "DSL improves RS performance and robustness by addressing SL\u2019s limitations, supported by empirical results and theoretical analysis on distributional robustness."}}
{"id": "2602.08015", "pdf": "https://arxiv.org/pdf/2602.08015", "abs": "https://arxiv.org/abs/2602.08015", "authors": ["Patricia G. F. Matsubara", "Tayana Conte"], "title": "Bridging the Gap: Adapting Evidence to Decision Frameworks to support the link between Software Engineering academia and industry", "categories": ["cs.SE"], "comment": "Accepted for publication in ICSE 2026 - Future of Software Engineering", "summary": "Over twenty years ago, the Software Engineering (SE) research community have been involved with Evidence-Based Software Engineering (EBSE). EBSE aims to inform industrial practice with the best evidence from rigorous research, preferably from systematic literature reviews (SLRs). Since then, SE researchers have conducted many SLRs, perfected their SLR procedures, proposed alternative ways of presenting their results (such as Evidence Briefings), and profusely discussed how to conduct research that impacts practice. Nevertheless, there is still a feeling that SLRs' results are not reaching practitioners. Something is missing. In this vision paper, we introduce Evidence to Decision (EtD) frameworks from the health sciences, which propose gathering experts in panels to assess the existing best evidence about the impact of an intervention in all relevant outcomes and make structured recommendations based on them. The insight we can leverage from EtD frameworks is not their structure per se but all the relevant criteria for making recommendations to practitioners from SLRs. Furthermore, we provide a worked example based on an SE SLR. We also discuss the challenges the SE research and practice community may face when adopting EtD frameworks, highlighting the need for more comprehensive criteria in our recommendations to industry practitioners.", "AI": {"tldr": "The paper introduces Evidence to Decision (EtD) frameworks from health sciences as a model for enhancing the relevance of systematic literature reviews (SLRs) in software engineering (SE), aiming to better inform industry practices.", "motivation": "SE researchers desire to improve the impact of systematic literature reviews (SLRs) on industrial practice, addressing the gap between evidence and practitioners' application.", "method": "The paper adapts the concept of EtD frameworks from health sciences and provides a worked example using an SE systematic literature review (SLR).", "result": "The paper demonstrates how EtD frameworks can provide structured recommendations for practitioners by incorporating comprehensive criteria from SLRs.", "conclusion": "Using insights from EtD frameworks can bridge the gap between SE research and industry practice, although adoption will require addressing challenges related to criteria development and community engagement."}}
{"id": "2602.07541", "pdf": "https://arxiv.org/pdf/2602.07541", "abs": "https://arxiv.org/abs/2602.07541", "authors": ["Jingyi Hou", "Leyu Zhou", "Chenchen Jing", "Jinghan Yang", "Xinbo Yu", "Wei He"], "title": "Differentiate-and-Inject: Enhancing VLAs via Functional Differentiation Induced by In-Parameter Structural Reasoning", "categories": ["cs.RO"], "comment": null, "summary": "As robots are expected to perform increasingly diverse tasks, they must understand not only low-level actions but also the higher-level structure that determines how a task should unfold. Existing vision-language-action (VLA) models struggle with this form of task-level reasoning. They either depend on prompt-based in-context decomposition, which is unstable and sensitive to linguistic variations, or end-to-end long-horizon training, which requires large-scale demonstrations and entangles task-level reasoning with low-level control. We present in-parameter structured task reasoning (iSTAR), a framework for enhancing VLA models via functional differentiation induced by in-parameter structural reasoning. Instead of treating VLAs as monolithic policies, iSTAR embeds task-level semantic structure directly into model parameters, enabling differentiated task-level inference without external planners or handcrafted prompt inputs. This injected structure takes the form of implicit dynamic scene-graph knowledge that captures object relations, subtask semantics, and task-level dependencies in parameter space. Across diverse manipulation benchmarks, iSTAR achieves more reliable task decompositions and higher success rates than both in-context and end-to-end VLA baselines, demonstrating the effectiveness of parameter-space structural reasoning for functional differentiation and improved generalization across task variations.", "AI": {"tldr": "iSTAR is a framework that improves task-level semantic reasoning in vision-language-action (VLA) models by embedding structural reasoning into model parameters, enabling better task inference and higher reliability.", "motivation": "Current VLA models face challenges in task-level reasoning, often relying on unstable prompt-based decomposition or data-intensive long-horizon training, leading to inefficiencies in handling complex tasks.", "method": "iSTAR introduces structural reasoning directly into model parameters via dynamic scene-graph knowledge, embedding object relations, subtask semantics, and dependencies to enhance task decomposition and execution.", "result": "iSTAR outperforms traditional baselines by achieving more reliable task decompositions and improved success rates across diverse manipulation tasks.", "conclusion": "Embedding structural reasoning within model parameters significantly improves functional differentiation, task-level reasoning, and generalization abilities in VLA models."}}
{"id": "2602.07621", "pdf": "https://arxiv.org/pdf/2602.07621", "abs": "https://arxiv.org/abs/2602.07621", "authors": ["Xanh Ho", "Yun-Ang Wu", "Sunisth Kumar", "Tian Cheng Xia", "Florian Boudin", "Andre Greiner-Petter", "Akiko Aizawa"], "title": "SciClaimEval: Cross-modal Claim Verification in Scientific Papers", "categories": ["cs.CL"], "comment": "12 pages; data is available at https://sciclaimeval.github.io/", "summary": "We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.", "AI": {"tldr": "SciClaimEval is a dataset for claim verification based on authentic claims from scientific papers, featuring cross-modal evidence types like figures and tables.", "motivation": "To address the need for a scientific claim verification dataset that includes authentic and refuted claims, aiming to improve real-world model accuracy.", "method": "Introduced refuted claims by modifying supporting evidence instead of changing claims or using fabricated contradictions; annotated samples include cross-modal evidence from figures and tables.", "result": "Analyzed 1,664 samples from three domains and tested 11 multimodal models. Found figure-based verification to be notably challenging with models performing below human baseline.", "conclusion": "SciClaimEval provides a thorough dataset enabling the evaluation of multimodal models' claim verification; figure-based challenges highlight significant room for model improvement."}}
{"id": "2602.07058", "pdf": "https://arxiv.org/pdf/2602.07058", "abs": "https://arxiv.org/abs/2602.07058", "authors": ["Carolina R. Kelsch", "Leonardo S. B. Pereira", "Natnael Mola", "Luis H. Arribas", "Juan C. S. M. Avedillo"], "title": "FADE: Selective Forgetting via Sparse LoRA and Self-Distillation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Machine Unlearning aims to remove the influence of specific data or concepts from trained models while preserving overall performance, a capability increasingly required by data protection regulations and responsible AI practices. Despite recent progress, unlearning in text-to-image diffusion models remains challenging due to high computational costs and the difficulty of balancing effective forgetting with retention of unrelated concepts. We introduce FADE (Fast Adapter for Data Erasure), a two-stage unlearning method for image generation that combines parameter localization with self-distillation. FADE first identifies parameters most responsible for the forget set using gradient-based saliency and constrains updates through sparse LoRA adapters, ensuring lightweight, localized modifications. In a second stage, FADE applies a self-distillation objective that overwrites the forgotten concept with a user-defined surrogate while preserving behavior on retained data. The resulting adapters are memory-efficient, reversible, and can be merged or removed at runtime, enabling flexible deployment in production systems. We evaluated FADE on the UnlearnCanvas benchmark and conducted ablation studies on Imagenette, Labeled Faces in the Wild, AtharvaTaras Dog Breeds Dataset, and SUN Attributes datasets, demonstrating State-of-the-Art unlearning performance with fine-grained control over the forgetting-retention trade-off. Our results demonstrate that FADE achieves strong concept erasure and high retainability across various domains, making it a suitable solution for selective unlearning in diffusion-based image generation models.", "AI": {"tldr": "FADE is a novel two-stage method for effective and efficient machine unlearning in text-to-image diffusion models, achieving strong concept erasure and retained model performance.", "motivation": "The motivation behind this paper is addressing the challenge of unlearning specific data or concepts from text-to-image diffusion models, a growing necessity due to data protection regulations and responsible AI practices.", "method": "FADE follows a two-stage unlearning approach. Stage one identifies influential parameters using gradient-based saliency and updates them with sparse LoRA adapters for localized modifications. Stage two uses self-distillation to overwrite the forgotten concept with a user-defined surrogate while retaining performance on unrelated data.", "result": "FADE achieves State-of-the-Art unlearning performance, demonstrating strong concept erasure and fine-grained control over the forgetting-retention tradeoff across various datasets and benchmarks.", "conclusion": "FADE provides an effective and flexible solution for unlearning in diffusion-based image generation models, combining efficiency, adaptability, and strong performance metrics."}}
{"id": "2602.07370", "pdf": "https://arxiv.org/pdf/2602.07370", "abs": "https://arxiv.org/abs/2602.07370", "authors": ["Mark Bun", "William Fang"], "title": "Privately Learning Decision Lists and a Differentially Private Winnow", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "27 pages, The 37th International Conference on Algorithmic Learning Theory", "summary": "We give new differentially private algorithms for the classic problems of learning decision lists and large-margin halfspaces in the PAC and online models. In the PAC model, we give a computationally efficient algorithm for learning decision lists with minimal sample overhead over the best non-private algorithms. In the online model, we give a private analog of the influential Winnow algorithm for learning halfspaces with mistake bound polylogarithmic in the dimension and inverse polynomial in the margin. As an application, we describe how to privately learn decision lists in the online model, qualitatively matching state-of-the art non-private guarantees.", "AI": {"tldr": "The paper provides new algorithms for differentially private learning of decision lists and halfspaces in both PAC and online models.", "motivation": "To develop computationally efficient algorithms ensuring differential privacy while learning decision lists and large-margin halfspaces, addressing gaps in both PAC and online models.", "method": "The paper introduces a private variant of the Winnow algorithm for halfspaces in the online model and an efficient algorithm for decision lists in the PAC model.", "result": "The proposed algorithms achieve competitive performance while ensuring privacy, with minimal overhead in the PAC model and polylogarithmic mistake bounds in the online model.", "conclusion": "The research demonstrates that differentially private learning can match state-of-the-art guarantees of non-private methods for decision lists and halfspaces, in both PAC and online setups."}}
{"id": "2602.07533", "pdf": "https://arxiv.org/pdf/2602.07533", "abs": "https://arxiv.org/abs/2602.07533", "authors": ["Yankai Yang", "Yancheng Long", "Hongyang Wei", "Wei Chen", "Tianke Zhang", "Kaiyu Jiang", "Haonan Fan", "Changyi Liu", "Jiankang Chen", "Kaiyu Tang", "Bin Wen", "Fan Yang", "Tingting Gao", "Han Li", "Shuo Yang"], "title": "Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models", "categories": ["cs.AI"], "comment": null, "summary": "Reward models are critical for reinforcement learning from human feedback, as they determine the alignment quality and reliability of generative models. For complex tasks such as image editing, reward models are required to capture global semantic consistency and implicit logical constraints beyond local similarity. Existing reward modeling approaches have clear limitations. Discriminative reward models align well with human preferences but struggle with complex semantics due to limited reasoning supervision. Generative reward models offer stronger semantic understanding and reasoning, but they are costly at inference time and difficult to align directly with human preferences. To this end, we propose Joint Reward Modeling (JRM), which jointly optimizes preference learning and language modeling on a shared vision-language backbone. This approach internalizes the semantic and reasoning capabilities of generative models into efficient discriminative representations, enabling fast and accurate evaluation. JRM achieves state-of-the-art results on MMRB2 and EditReward-Bench, and significantly improves stability and performance in downstream online reinforcement learning. These results show that joint training effectively bridges efficiency and semantic understanding in reward modeling.", "AI": {"tldr": "Joint Reward Modeling (JRM) is introduced, optimizing preference learning and language modeling to enhance reward models' efficiency and semantic understanding. It achieves state-of-the-art results on benchmarks and improves reinforcement learning.", "motivation": "To improve reward models for reinforcement learning, addressing challenges in capturing global semantics and reasoning, which are vital for tasks like image editing.", "method": "Joint Reward Modeling (JRM) employs a shared vision-language backbone for joint optimization of preference learning and language modeling, combining generative reasoning with efficient discriminative capabilities.", "result": "JRM demonstrates state-of-the-art performance on benchmarks like MMRB2 and EditReward-Bench and boosts stability and performance in online reinforcement learning.", "conclusion": "Joint training bridges the gap between efficiency and semantic reasoning, making JRM highly effective for reinforcement learning tasks."}}
{"id": "2602.07213", "pdf": "https://arxiv.org/pdf/2602.07213", "abs": "https://arxiv.org/abs/2602.07213", "authors": ["Srijan Shakya", "Anamaria-Roberta Hartl", "Sepp Hochreiter", "Korbinian P\u00f6ppel"], "title": "Adaptive Retrieval helps Reasoning in LLMs -- but mostly if it's not used", "categories": ["cs.LG"], "comment": "Eurips Workshop on Principles of Generative Modeling (PriGM)", "summary": "Large Language Models (LLMs) often falter in complex reasoning tasks due to their static, parametric knowledge, leading to hallucinations and poor performance in specialized domains like mathematics. This work explores a fundamental principle for enhancing generative models: treating retrieval as a form of dynamic in-context learning. We test an adaptive retrieval-augmented architecture where an LLM agent actively decides when to query an external knowledge base during its reasoning process. We compare this adaptive strategy against a standard Chain-of-Thought (CoT) baseline and a static retrieval approach on the GSM8K and MATH-500 benchmarks. Although our experiments show that static retrieval is inferior to CoT, the adaptive retrieval shows interesting behavior: While traces including retrieved results show slightly worse performance compared to CoT, traces that do not include retrieval actually perform better compared to CoT. This suggests that: (a) retrieval only rarely helps reasoning (we show a few counterexamples, e.g. using useful theorems) and (b) actively not using retrieval is indicative of good model performance. Furthermore, we find that the model scales its retrieval frequency with the difficulty of the problem, reinforcing that the decision to retrieve is a crucial metacognitive signal. The agent's ability to self-assess its knowledge and selectively engage with external information represents a key principle for building more robust and reliable generative models.", "AI": {"tldr": "Large Language Models (LLMs) often struggle in complex reasoning tasks. This paper introduces a dynamic retrieval-augmented architecture where an LLM decides when to query external knowledge. The approach shows mixed results but highlights the importance of selective retrieval and metacognitive skills in improving model performance.", "motivation": "LLMs face limitations in complex reasoning and are prone to hallucinations, especially in specialized domains like mathematics. Enhancing LLM reasoning capabilities and addressing their static parametric knowledge issues motivate this exploration.", "method": "The adaptive retrieval-augmented architecture is tested, where an LLM decides in real-time whether to query an external knowledge base during reasoning. Comparative experiments involve adaptive retrieval, static retrieval, and Chain-of-Thought (CoT) baselines on GSM8K and MATH-500 benchmarks.", "result": "Adaptive retrieval reveals mixed findings: traces using retrieval marginally underperform CoT, while traces without retrieval outperform CoT. Moreover, the model adjusts retrieval frequency based on problem difficulty, emphasizing a metacognitive signal.", "conclusion": "Selective information retrieval and the ability to judge when not to retrieve are crucial for robust model performance. Dynamic retrieval serves as a promising direction for advancing LLMs' reasoning capabilities in challenging domains."}}
{"id": "2602.08084", "pdf": "https://arxiv.org/pdf/2602.08084", "abs": "https://arxiv.org/abs/2602.08084", "authors": ["Mark Looi", "Marc Szepan"], "title": "Outsourcing in Global Software Development: Effects of Temporal Location and Methodologies", "categories": ["cs.SE"], "comment": "Published in International Journal of Business and Social Science International Journal of Business and Social Science, Vol. 12, No. 3; March 2021, DOI: 10.30845/ijbss.v12n3p3", "summary": "Developing software globally using outsourced resources has become a common practice, with project teams often distributed in different time zones. In this study, we focus on customers that contract software development to vendors in temporally nearshore or far offshore locations. We conducted a survey to determine the effect of temporal distance on overall success, costs, project management effort, schedule, quality, communication problems, and other outcomes of interest to managers. In the survey of 80 customers and interviews with 6 of them, we also investigated the effect of software development methodology on the same outcomes. The results show that nearshore development is advantageous for overall success, quality, reduced PM effort, maintaining schedule, higher quality, and engendering fewer communication problems. Development methodology appears to only influence higher costs. We assess our findings in the context of prior GSE research and provide practical advice for customers of outsourced global software development, chief of which is to favor nearshore for communication-intensive or Agile projects.", "AI": {"tldr": "The study examines the effects of temporal distance and development methodology in global software outsourcing, finding nearshore outsourcing advantageous in several areas.", "motivation": "To investigate how temporal distance and software development methodologies impact various outcomes in global software outsourcing.", "method": "The study employed a combination of survey data from 80 customers and interviews with 6 of them to explore the relationship between temporal outsourcing proximity and project outcomes.", "result": "Nearshore outsourcing yielded better results in overall success, quality, reduced project management effort, schedule adherence, and fewer communication issues, while methodology influenced project costs.", "conclusion": "Nearshore outsourcing should be preferred for communication-intensive and Agile projects due to its advantages in reducing various challenges, while methodologies mainly affect cost."}}
{"id": "2602.07598", "pdf": "https://arxiv.org/pdf/2602.07598", "abs": "https://arxiv.org/abs/2602.07598", "authors": ["Drake Moore", "Arushi Aggarwal", "Emily Taylor", "Sarah Zhang", "Taskin Padir", "Xiang Zhi Tan"], "title": "\"Meet My Sidekick!\": Effects of Separate Identities and Control of a Single Robot in HRI", "categories": ["cs.RO"], "comment": null, "summary": "The presentation of a robot's capability and identity directly influences a human collaborator's perception and implicit trust in the robot. Unlike humans, a physical robot can simultaneously present different identities and have them reside and control different parts of the robot. This paper presents a novel study that investigates how users perceive a robot where different robot control domains (head and gripper) are presented as independent robots. We conducted a mixed design study where participants experienced one of three presentations: a single robot, two agents with shared full control (co-embodiment), or two agents with split control across robot control domains (split-embodiment). Participants underwent three distinct tasks -- a mundane data entry task where the robot provides motivational support, an individual sorting task with isolated robot failures, and a collaborative arrangement task where the robot causes a failure that directly affects the human participant. Participants perceived the robot as residing in the different control domains and were able to associate robot failure with different identities. This work signals how future robots can leverage different embodiment configurations to obtain the benefit of multiple robots within a single body.", "AI": {"tldr": "The paper explores how humans perceive robots with different control domains as independent entities and assesses their influence on trust and collaboration.", "motivation": "Examining how robot presentations and identities affect human perceptions, trust, and collaboration, focusing on the potential of robots to exhibit multiple identities through different control domains.", "method": "A mixed design study with three experimental conditions (single robot, co-embodiment, and split-embodiment). Participants performed three tasks that evaluated their perceptions and reactions to robot failures under different control domain configurations.", "result": "Participants associated robot failures with specific identities in split-control configurations, demonstrating that humans perceive multiple identities within a single robot body.", "conclusion": "Future robots could leverage split-embodiment to simulate the benefits of multiple robots while physically existing as a single entity, enhancing collaboration and problem-solving efficiency."}}
{"id": "2602.07639", "pdf": "https://arxiv.org/pdf/2602.07639", "abs": "https://arxiv.org/abs/2602.07639", "authors": ["Jaewook Lee", "Alexander Scarlatos", "Simon Woodhead", "Andrew Lan"], "title": "Letting Tutor Personas \"Speak Up\" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization", "categories": ["cs.CL"], "comment": null, "summary": "With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.", "AI": {"tldr": "The paper explores using tutor personas from human dialogues to guide large language model (LLM) behavior. It proposes a method called activation steering to incorporate tutor-specific variations in tutoring styles without explicit prompts.", "motivation": "The motivation is to address the lack of diversity and adaptability in LLM-based tutoring systems, as real-world tutoring involves varied instructional strategies tailored to student needs.", "method": "The authors modify the Bidirectional Preference Optimization (BiPO) method to create a steering vector, which directs LLM responses towards specific tutor personas derived from human tutor-student dialogues.", "result": "The steering vector successfully captures tutor-specific variations, improves alignment with real tutor utterances, enhances preference-based evaluations, and preserves lexical similarity while revealing interpretable behavior variations.", "conclusion": "Activation steering enables more diverse and interpretable LLM tutoring styles, using signals directly from real-world tutor-student data. It presents a significant step towards adaptable AI tutors that can mimic human tutoring diversity."}}
{"id": "2602.07062", "pdf": "https://arxiv.org/pdf/2602.07062", "abs": "https://arxiv.org/abs/2602.07062", "authors": ["Daniil Storonkin", "Ilia Dziub", "Maksim Golyadkin", "Ilya Makarov"], "title": "From Images to Decisions: Assistive Computer Vision for Non-Metallic Content Estimation in Scrap Metal", "categories": ["cs.CV"], "comment": "AAAI 2026 Workshop on Addressing Challenges and Opportunities in Human-Centric Manufacturing", "summary": "Scrap quality directly affects energy use, emissions, and safety in steelmaking. Today, the share of non-metallic inclusions (contamination) is judged visually by inspectors - an approach that is subjective and hazardous due to dust and moving machinery. We present an assistive computer vision pipeline that estimates contamination (per percent) from images captured during railcar unloading and also classifies scrap type. The method formulates contamination assessment as a regression task at the railcar level and leverages sequential data through multi-instance learning (MIL) and multi-task learning (MTL). Best results include MAE 0.27 and R2 0.83 by MIL; and an MTL setup reaches MAE 0.36 with F1 0.79 for scrap class. Also we present the system in near real time within the acceptance workflow: magnet/railcar detection segments temporal layers, a versioned inference service produces railcar-level estimates with confidence scores, and results are reviewed by operators with structured overrides; corrections and uncertain cases feed an active-learning loop for continual improvement. The pipeline reduces subjective variability, improves human safety, and enables integration into acceptance and melt-planning workflows.", "AI": {"tldr": "This paper introduces a computer vision pipeline that estimates contamination levels and classifies scrap type in steelmaking, improving safety and efficiency.", "motivation": "To mitigate the subjective and hazardous nature of manual scrap quality inspection in steelmaking by using a robust, automated solution.", "method": "The method involves a computer vision pipeline that uses multi-instance learning (MIL) and multi-task learning (MTL). It performs contamination detection as a regression task and incorporates a model that processes sequential data. The pipeline integrates inference services and active learning for continual updates.", "result": "Achieved strong performance metrics: MAE 0.27, R2 0.83 via MIL, and MAE 0.36 with F1 0.79 using MTL for scrap classification.", "conclusion": "The system improves safety, ensures consistency in scrap quality checks, and integrates effectively into existing workflows, optimizing both acceptance and melt-planning processes in steelmaking."}}
{"id": "2602.07378", "pdf": "https://arxiv.org/pdf/2602.07378", "abs": "https://arxiv.org/abs/2602.07378", "authors": ["Shota Imai", "Sota Nishiyama", "Masaaki Imaizumi"], "title": "Dichotomy of Feature Learning and Unlearning: Fast-Slow Analysis on Neural Networks with Stochastic Gradient Descent", "categories": ["cs.LG", "physics.data-an", "stat.ML"], "comment": "40 pages", "summary": "The dynamics of gradient-based training in neural networks often exhibit nontrivial structures; hence, understanding them remains a central challenge in theoretical machine learning. In particular, a concept of feature unlearning, in which a neural network progressively loses previously learned features over long training, has gained attention. In this study, we consider the infinite-width limit of a two-layer neural network updated with a large-batch stochastic gradient, then derive differential equations with different time scales, revealing the mechanism and conditions for feature unlearning to occur. Specifically, we utilize the fast-slow dynamics: while an alignment of first-layer weights develops rapidly, the second-layer weights develop slowly. The direction of a flow on a critical manifold, determined by the slow dynamics, decides whether feature unlearning occurs. We give numerical validation of the result, and derive theoretical grounding and scaling laws of the feature unlearning. Our results yield the following insights: (i) the strength of the primary nonlinear term in data induces the feature unlearning, and (ii) an initial scale of the second-layer weights mitigates the feature unlearning. Technically, our analysis utilizes Tensor Programs and the singular perturbation theory.", "AI": {"tldr": "This paper analyzes the dynamics of neural networks during training and explores feature unlearning using theoretical and empirical approaches.", "motivation": "To understand the phenomenon of feature unlearning in neural networks during long training periods.", "method": "The study uses the infinite-width limit of two-layer neural networks, stochastic gradient updates with large batches, Tensor Programs, and singular perturbation theory.", "result": "Derived differential equations explaining feature unlearning mechanisms, validated by numerical experiments and backed by scaling laws.", "conclusion": "Feature unlearning is influenced by data's primary nonlinear term and the initial scale of second-layer weights, providing theoretical insights about neural network training."}}
{"id": "2602.07543", "pdf": "https://arxiv.org/pdf/2602.07543", "abs": "https://arxiv.org/abs/2602.07543", "authors": ["Heewoong Noh", "Gyoung S. Na", "Namkyeong Lee", "Chanyoung Park"], "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": null, "summary": "Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.", "AI": {"tldr": "The paper introduces MSP-LLM, a framework using large language models (LLMs) to address the entire material synthesis planning (MSP) task, including precursor and synthesis operation predictions, achieving superior performance over existing methods.", "motivation": "The authors aim to address the underexplored challenge of material synthesis planning (MSP), a critical bottleneck in AI-driven materials discovery, by establishing a unified methodology to solve the entire MSP task.", "method": "They propose MSP-LLM, a large language model-based framework, breaking MSP into two subproblems: precursor prediction (PP) and synthesis operation prediction (SOP), with innovations like intermediate material classes, hierarchical precursor types, and explicit conditioning for consistency.", "result": "Experiments show that MSP-LLM outperforms existing approaches on precursor prediction, synthesis operation prediction, and the comprehensive MSP task, demonstrating its effectiveness and scalability.", "conclusion": "MSP-LLM offers a coherent and unified solution for the MSP challenge, significantly advancing the potential for AI to enhance real-world materials discovery and synthesis."}}
{"id": "2602.07216", "pdf": "https://arxiv.org/pdf/2602.07216", "abs": "https://arxiv.org/abs/2602.07216", "authors": ["Reuben Narad", "L\u00e9onard Boussioux", "Michael Wagner"], "title": "Probing Neural TSP Representations for Prescriptive Decision Support", "categories": ["cs.LG"], "comment": "Submitted to ICML 2026", "summary": "The field of neural combinatorial optimization (NCO) trains neural policies to solve NP-hard problems such as the traveling salesperson problem (TSP). We ask whether, beyond producing good tours, a trained TSP solver learns internal representations that transfer to other optimization-relevant objectives, in the spirit of transfer learning from other domains. We train several attention-based TSP policies, collect their internal activations, and train probes on node/edge embeddings for two NP-hard prescriptive downstream tasks inspired by real-world logistics scenarios: node-removal sensitivity (identifying the most impactful node to remove) and edge-forbid sensitivity (identifying the most critical edge to retain). On a Euclidean TSP100-trained model, probes for both tasks are competitive with existing baselines. Ensembling probe signals with geometric features outperforms the strongest baselines: 65\\% top-1 accuracy (vs. 58\\% baseline) for the best-node-removal task, and 73\\% top-1 accuracy (vs. 67\\% baseline) for the worst-edge identification task. To our knowledge, we are the first to study neural TSP solvers as transferable encoders for prescriptive what-if decision-support objectives beyond tour construction. Finally, we show that transfer accuracy increases with solver quality across training and model scale, suggesting that training stronger NCO solvers also yields more useful encoders for downstream objectives. Our code is available at: github.com/ReubenNarad/tsp_prescriptive_probe", "AI": {"tldr": "This paper explores whether neural policies trained for the TSP (Traveling Salesperson Problem) can transfer internal representations to other optimization tasks.", "motivation": "To investigate if neural TSP solvers develop transferable internal representations that can be applied to other difficult prescriptive decision-support tasks in optimization similar to transfer learning.", "method": "Attention-based TSP models are trained, their activations are used to train probes for two downstream tasks (node-removal sensitivity and edge-forbid sensitivity), and their performance is compared against established baselines.", "result": "The probes achieve competitive results, surpassing baselines by 7% for best-node-removal and by 6% for worst-edge identification when combined with geometric features.", "conclusion": "Neural policies for NCO not only produce good optimization results but also serve as effective encoders for other objectives, with better solvers improving transferability."}}
{"id": "2602.08133", "pdf": "https://arxiv.org/pdf/2602.08133", "abs": "https://arxiv.org/abs/2602.08133", "authors": ["Mojtaba Mostafavi Ghahfarokhi", "Hamed Jahantigh", "Alireza Asadi", "Abbas Heydarnoori"], "title": "Integrating Code Metrics into Automated Documentation Generation for Computational Notebooks", "categories": ["cs.SE"], "comment": null, "summary": "Effective code documentation is essential for collaboration, comprehension, and long-term software maintainability, yet developers often neglect it due to its repetitive nature. Automated documentation generation has evolved from heuristic and rule-based methods to neural network-based and large language model (LLM)-based approaches. However, existing methods often overlook structural and quantitative characteristics of code that influence readability and comprehension. Prior research suggests that code metrics capture information relevant to program understanding. Building on these insights, this paper investigates the role of source code metrics as auxiliary signals for automated documentation generation, focusing on computational notebooks, a popular medium among data scientists that integrates code, narrative, and results but suffers from inconsistent documentation. We propose a two-stage approach. First, the CodeSearchNet dataset construction process was refined to create a specialized dataset from over 17 million code and markdown cells. After structural and semantic filtering, approximately 36,734 high-quality (code, markdown) pairs were extracted. Second, two modeling paradigms, a lightweight CNN-RNN architecture and a few-shot GPT-3.5 architecture, were evaluated with and without metric information. Results show that incorporating code metrics improves the accuracy and contextual relevance of generated documentation, yielding gains of 6% in BLEU-1 and 3% in ROUGE-L F1 for CNN-RNN-based architecture, and 9% in BERTScore F1 for LLM-based architecture. These findings demonstrate that integrating code metrics provides valuable structural context, enhancing automated documentation generation across diverse model families.", "AI": {"tldr": "This paper explores incorporating source code metrics into automated documentation generation, improving quality and relevance of documentation for computational notebooks.", "motivation": "To address the challenges of neglected code documentation and enhance automated documentation generation with structural and quantitative code characteristics.", "method": "A two-stage method: refining the CodeSearchNet dataset to extract high-quality code-markdown pairs, then evaluating CNN-RNN and GPT-3.5 architectures with and without code metrics.", "result": "Incorporating code metrics improved BLEU-1 by 6%, ROUGE-L F1 by 3%, and BERTScore F1 by 9%, showcasing better accuracy and contextual relevance in automated documentation.", "conclusion": "Code metrics are valuable auxiliary signals that enhance automated documentation generation across models, improving comprehension and maintainability in computational notebooks."}}
{"id": "2602.07629", "pdf": "https://arxiv.org/pdf/2602.07629", "abs": "https://arxiv.org/abs/2602.07629", "authors": ["Nitesh Subedi", "Adam Haroon", "Samuel Tetteh", "Prajwal Koirala", "Cody Fleming", "Soumik Sarkar"], "title": "LCLA: Language-Conditioned Latent Alignment for Vision-Language Navigation", "categories": ["cs.RO"], "comment": null, "summary": "We propose LCLA (Language-Conditioned Latent Alignment), a framework for vision-language navigation that learns modular perception-action interfaces by aligning sensory observations to a latent representation of an expert policy. The expert is first trained with privileged state information, inducing a latent space sufficient for control, after which its latent interface and action head are frozen. A lightweight adapter is then trained to map raw visual-language observations, via a frozen vision-language model, into the expert's latent space, reducing the problem of visuomotor learning to supervised latent alignment rather than end-to-end policy optimization. This decoupling enforces a stable contract between perception and control, enabling expert behavior to be reused across sensing modalities and environmental variations. We instantiate LCLA and evaluate it on a vision-language indoor navigation task, where aligned latent spaces yield strong in-distribution performance and robust zero-shot generalization to unseen environments, lighting conditions, and viewpoints while remaining lightweight at inference time.", "AI": {"tldr": "LCLA uses a modular framework to simplify visuomotor learning for vision-language navigation by aligning sensory inputs with an expert's latent policy representations.", "motivation": "To address challenges in vision-language navigation by decoupling perception and control, allowing easy adaptation across different sensing modalities and environments.", "method": "An expert policy is trained with privileged information to establish a control-sufficient latent space. This latent space is then aligned with raw sensory inputs using a lightweight adapter and a frozen vision-language model, avoiding end-to-end policy optimization.", "result": "The framework achieves strong performance on a vision-language indoor navigation task, with robust zero-shot generalization to new environments, lighting conditions, and viewpoints.", "conclusion": "LCLA provides an efficient and modular approach for vision-language tasks by separating perception and control, proving capable of handling diverse environments."}}
{"id": "2602.07673", "pdf": "https://arxiv.org/pdf/2602.07673", "abs": "https://arxiv.org/abs/2602.07673", "authors": ["Jiangnan Fang", "Cheng-Tse Liu", "Hanieh Deilamsalehy", "Nesreen K. Ahmed", "Puneet Mathur", "Nedim Lipka", "Franck Dernoncourt", "Ryan A. Rossi"], "title": "Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.", "AI": {"tldr": "The paper analyzed biases in Large Language Model (LLM) judges when evaluating summarization tasks. It found that LLMs increasingly prefer AI-generated summaries over human-written ones as semantic similarity metrics like ROUGE and BLEU decrease.", "motivation": "The motivation is to understand the granular biases of LLM judges in summarization tasks, specifically in relation to overlap metrics. This arises from their limitations, including biases for length, order, and vulnerability to adversarial inputs.", "method": "The authors assessed bias using 9 LLMs, including Gemma 3 and LLaMA 3 variants, by testing their preference patterns for summaries judged by semantic overlap metrics like ROUGE and BLEU scores.", "result": "LLMs were shown to favor AI-generated summaries over human ones as the overlap between summaries decreased. This trend was prevalent across almost all tested models regardless of their position biases.", "conclusion": "LLMs show biases and limitations in judging summaries based only on overlap metrics, emphasizing the need for improved judging techniques for accurate summarization evaluations."}}
{"id": "2602.07064", "pdf": "https://arxiv.org/pdf/2602.07064", "abs": "https://arxiv.org/abs/2602.07064", "authors": ["Minghao Han", "Dingkang Yang", "Yue Jiang", "Yizhou Liu", "Lihua Zhang"], "title": "Exploring Physical Intelligence Emergence via Omni-Modal Architecture and Physical Data Engine", "categories": ["cs.CV"], "comment": null, "summary": "Physical understanding remains brittle in omni-modal models because key physical attributes are visually ambiguous and sparsely represented in web-scale data. We present OmniFysics, a compact omni-modal model that unifies understanding across images, audio, video, and text, with integrated speech and image generation. To inject explicit physical knowledge, we build a physical data engine with two components. FysicsAny produces physics-grounded instruction--image supervision by mapping salient objects to verified physical attributes through hierarchical retrieval over a curated prototype database, followed by physics-law--constrained verification and caption rewriting. FysicsOmniCap distills web videos via audio--visual consistency filtering to generate high-fidelity video--instruction pairs emphasizing cross-modal physical cues. We train OmniFysics with staged multimodal alignment and instruction tuning, adopt latent-space flow matching for text-to-image generation, and use an intent router to activate generation only when needed. Experiments show competitive performance on standard multimodal benchmarks and improved results on physics-oriented evaluations.", "AI": {"tldr": "OmniFysics is an omni-modal model that enhances understanding across multiple modalities (images, audio, video, and text) by incorporating explicit physical knowledge using a specialized data engine.", "motivation": "To address the lack of physical understanding in existing omni-modal models caused by ambiguities and sparsity in physical data within web-scale datasets.", "method": "OmniFysics uses a physical data engine with components FysicsAny (maps objects to attributes using physics laws and curated prototypes) and FysicsOmniCap (filters web videos for cross-modal physical cues). It undergoes staged multimodal alignment and incorporates a latent-space flow for text-to-image generation.", "result": "OmniFysics achieves competitive results on standard multimodal benchmarks and shows superior performance on evaluations focused on physical understanding.", "conclusion": "By integrating explicit physical knowledge and specialized instruction fine-tuning, OmniFysics advances omni-modal model robustness in understanding the physical world."}}
{"id": "2602.07418", "pdf": "https://arxiv.org/pdf/2602.07418", "abs": "https://arxiv.org/abs/2602.07418", "authors": ["Jian Qian", "Chen-Yu Wei"], "title": "Achieving Optimal Static and Dynamic Regret Simultaneously in Bandits with Deterministic Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In adversarial multi-armed bandits, two performance measures are commonly used: static regret, which compares the learner to the best fixed arm, and dynamic regret, which compares it to the best sequence of arms. While optimal algorithms are known for each measure individually, there is no known algorithm achieving optimal bounds for both simultaneously. Marinov and Zimmert [2021] first showed that such simultaneous optimality is impossible against an adaptive adversary. Our work takes a first step to demonstrate its possibility against an oblivious adversary when losses are deterministic. First, we extend the impossibility result of Marinov and Zimmert [2021] to the case of deterministic losses. Then, we present an algorithm achieving optimal static and dynamic regret simultaneously against an oblivious adversary. Together, they reveal a fundamental separation between adaptive and oblivious adversaries when multiple regret benchmarks are considered simultaneously. It also provides new insight into the long open problem of simultaneously achieving optimal regret against switching benchmarks of different numbers of switches.\n  Our algorithm uses negative static regret to compensate for the exploration overhead incurred when controlling dynamic regret, and leverages Blackwell approachability to jointly control both regrets. This yields a new model selection procedure for bandits that may be of independent interest.", "AI": {"tldr": "The paper addresses simultaneous optimal static and dynamic regret in adversarial multi-armed bandits against oblivious adversaries, revealing key distinctions between adaptive and oblivious adversaries.", "motivation": "The paper aims to resolve the challenge of achieving optimal static and dynamic regret simultaneously against oblivious adversaries, which was previously deemed impossible against adaptive adversaries.", "method": "The authors extend the impossibility result to deterministic losses and propose an algorithm leveraging negative static regret and Blackwell approachability to control both regrets.", "result": "The proposed algorithm successfully achieves simultaneous optimal static and dynamic regret against an oblivious adversary.", "conclusion": "The results demonstrate a fundamental separation between adaptive and oblivious adversaries while advancing understanding in achieving optimal regret benchmarks in multi-armed bandits."}}
{"id": "2602.07549", "pdf": "https://arxiv.org/pdf/2602.07549", "abs": "https://arxiv.org/abs/2602.07549", "authors": ["Dayoon Ko", "Jihyuk Kim", "Sohyeon Kim", "Haeju Park", "Dahyun Lee", "Gunhee Kim", "Moontae Lee", "Kyungjae Lee"], "title": "When Is Enough Not Enough? Illusory Completion in Search Agents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory completion frequently occurs, wherein agents believe tasks are complete despite unresolved or violated constraints, leading to underverified answers. To diagnose this behavior, we introduce the Epistemic Ledger, an evaluation framework that tracks evidential support and agents' beliefs for each constraint throughout multi-turn reasoning. Our analysis reveals four recurring failure patterns: bare assertions, overlooked refutations, stagnation, and premature exit. Motivated by these findings, we examine whether explicit constraint-state tracking during execution mitigates these failures via LiveLedger, an inference-time tracker. This simple intervention consistently improves performance, substantially reducing underverified answers (by up to 26.5%) and improving overall accuracy (by up to 11.6%) on multi-constraint problems.", "AI": {"tldr": "The paper introduces methods to address failures in search agents' reasoning for multi-constraint problems, improving accuracy and completion rates.", "motivation": "Examine search agents' reliability in reasoning through multi-constraint problems and address recurring failures that lead to incorrect answers.", "method": "Developed the Epistemic Ledger for diagnosing reasoning failures and introduced LiveLedger, an inference-time tracker that explicitly monitors constraint states.", "result": "LiveLedger reduced underverified answers by up to 26.5% and improved overall accuracy by up to 11.6% in multi-constraint problems.", "conclusion": "Explicit tracking of constraints during reasoning improves the reliability and accuracy of search agents in complex multi-turn tasks."}}
{"id": "2602.08146", "pdf": "https://arxiv.org/pdf/2602.08146", "abs": "https://arxiv.org/abs/2602.08146", "authors": ["Pengyu Chang", "Yixiong Fang", "Silin Chen", "Yuling Shi", "Beijun Shen", "Xiaodong Gu"], "title": "Test vs Mutant: Adversarial LLM Agents for Robust Unit Test Generation", "categories": ["cs.SE"], "comment": null, "summary": "Software testing is a critical, yet resource-intensive phase of the software development lifecycle. Over the years, various automated tools have been developed to aid in this process. Search-based approaches typically achieve high coverage but produce tests with low readability, whereas large language model (LLM)-based methods generate more human-readable tests but often suffer from low coverage and compilability. While the majority of research efforts have focused on improving test coverage and readability, little attention has been paid to enhancing the robustness of bug detection, particularly in exposing corner cases and vulnerable execution paths. To address this gap, we propose AdverTest, a novel adversarial framework for LLM-powered test case generation. AdverTest comprises two interacting agents: a test case generation agent (T) and a mutant generation agent (M). These agents engage in an adversarial loop, where M persistently creates new mutants \"hacking\" the blind spots of T's current test suite, while T iteratively refines its test cases to \"kill\" the challenging mutants produced by M. This interaction loop is guided by both coverage and mutation scores, enabling the system to co-evolve toward both high test coverage and bug detection capability. Experimental results in the Defects4J dataset show that our approach improves fault detection rates by 8.56% over the best existing LLM-based methods and by 63.30% over EvoSuite, while also improving line and branch coverage.", "AI": {"tldr": "AdverTest is a novel framework for leveraging adversarial interactions to improve software test case generation, achieving better fault detection rates and coverage.", "motivation": "Automated software testing has trade-offs between test coverage, readability, and robustness in detecting bugs, with particular challenges in addressing corner cases and vulnerable paths.", "method": "AdverTest employs an adversarial framework with two agents (test case generation and mutant generation) iterating in a loop to refine and challenge test cases, guided by coverage and mutation metrics.", "result": "Experimental results on the Defects4J dataset demonstrate a notable improvement in fault detection rates (up to 63.30% over EvoSuite and 8.56% over LLM-based methods), as well as enhanced coverage.", "conclusion": "AdverTest improves both bug detection robustness and code coverage, making it a more effective solution for automated test case generation compared to existing methods."}}
{"id": "2602.07677", "pdf": "https://arxiv.org/pdf/2602.07677", "abs": "https://arxiv.org/abs/2602.07677", "authors": ["Aron Mathias", "Mohammad Ghufran", "Jack Hughes", "Hossein Rastgoftar"], "title": "Affine Transformable Unmanned Ground Vehicle", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This paper develops the proof of concept for a novel affine transformable unmanned ground vehicle (ATUGV) with the capability of safe and aggressive deformation while carrying multiple payloads. The ATUGV is a multi-body system with mobile robots that can be used to power the ATUGV morphable motion, powered cells to enclose the mobile robots, unpowered cells to contain payloads, and a deformable structure to integrate cells through bars and joints. The objective is that all powered and unpowered cells motion can safely track a desired affine transformation, where an affine transformation can be decomposed into translation, rigid body rotation, and deformation. To this end, the paper first uses a deep neural network to structure cell interconnection in such a way that every cell can freely move over the deformation plane, and the entire structure can reconfigurably deform to track a desired affine transformation. Then, the mobile robots, contained by the powered cells and stepper motors, regulating the connections of the powered and unpowered cells, design the proper controls so that all cells safely track the desired affine transformation. The functionality of the proposed ATUGV is validated through hardware experimentation and simulation.", "AI": {"tldr": "The paper introduces a novel unmanned ground vehicle (ATUGV) that undergoes safe and aggressive affine transformations and validates its design with experiments and simulations.", "motivation": "To achieve safe and deformable motion in unmanned ground vehicles while carrying payloads, aiming for innovation in adaptive robotic systems.", "method": "The approach involves using deep neural networks for structural cell interconnections to support deformation, and controls designed for mobile robots and motors for tracking affine transformations.", "result": "The ATUGV successfully tracks affine transformations in simulated and experimental settings, showcasing its functional ability.", "conclusion": "This work demonstrates the feasibility of ATUGV as an adaptable ground vehicle capable of safe deformation and payload management, expanding future capabilities in morphable robotics."}}
{"id": "2602.07773", "pdf": "https://arxiv.org/pdf/2602.07773", "abs": "https://arxiv.org/abs/2602.07773", "authors": ["Chen Zhang", "Kuicai Dong", "Dexun Li", "Wenjun Li", "Qu Yang", "Wei Han", "Yong Liu"], "title": "SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Recent deep search agents built on large reasoning models (LRMs) excel at complex question answering by iteratively planning, acting, and gathering evidence, a capability known as search-integrated reasoning. However, mainstream approaches often train this ability using only outcome-based supervision, neglecting the quality of intermediate thoughts and actions. We introduce SRR-Judge, a framework for reliable step-level assessment of reasoning and search actions. Integrated into a modified ReAct-style rate-and-refine workflow, SRR-Judge provides fine-grained guidance for search-integrated reasoning and enables efficient post-training annotation. Using SRR-annotated data, we apply an iterative rejection sampling fine-tuning procedure to enhance the deep search capability of the base agent. Empirically, SRR-Judge delivers more reliable step-level evaluations than much larger models such as DeepSeek-V3.1, with its ratings showing strong correlation with final answer correctness. Moreover, aligning the policy with SRR-Judge annotated trajectories leads to substantial performance gains, yielding over a 10 percent average absolute pass@1 improvement across challenging deep search benchmarks.", "AI": {"tldr": "The paper presents SRR-Judge, a framework to improve reasoning quality in deep search agents through step-level guidance and iterative training. Results show significant performance improvements.", "motivation": "Current deep search agents excel in search-integrated reasoning but lack fine-grained evaluation due to reliance on outcome-based supervision. This paper seeks to address the lack of step-level assessment.", "method": "The authors introduce SRR-Judge, a framework for step-level assessment, integrate it into a rate-and-refine workflow, and use annotated data for iterative rejection sampling fine-tuning to modify deep search agents.", "result": "SRR-Judge achieves more reliable evaluations compared to larger models (e.g., DeepSeek-V3.1) and correlates strongly with answer correctness. Its integration improves pass@1 performance by over 10% on complex benchmarks.", "conclusion": "Providing step-level guidance via SRR-Judge enhances the reasoning capabilities and accuracy of deep search agents, demonstrating the importance of fine-grained assessment mechanisms."}}
{"id": "2602.07065", "pdf": "https://arxiv.org/pdf/2602.07065", "abs": "https://arxiv.org/abs/2602.07065", "authors": ["A. N. Maria Antony", "T. Richter", "E. Gladilin"], "title": "Contactless estimation of continuum displacement and mechanical compressibility from image series using a deep learning based framework", "categories": ["cs.CV"], "comment": "14 Pages, 8 Figures Note: Supplentary information (ancillary file) attached as .pdf", "summary": "Contactless and non-invasive estimation of mechanical properties of physical media from optical observations is of interest for manifold engineering and biomedical applications, where direct physical measurements are not possible. Conventional approaches to the assessment of image displacement and non-contact material probing typically rely on time-consuming iterative algorithms for non-rigid image registration and constitutive modelling using discretization and iterative numerical solving techniques, such as Finite Element Method (FEM) and Finite Difference Method (FDM), which are not suitable for high-throughput data processing. Here, we present an efficient deep learning based end-to-end approach for the estimation of continuum displacement and material compressibility directly from the image series. Based on two deep neural networks for image registration and material compressibility estimation, this framework outperforms conventional approaches in terms of efficiency and accuracy. In particular, our experimental results show that the deep learning model trained on a set of reference data can accurately determine the material compressibility even in the presence of substantial local deviations of the mapping predicted by image registration from the reference displacement field. Our findings suggest that the remarkable accuracy of the deep learning end-to-end model originates from its ability to assess higher-order cognitive features, such as the vorticity of the vector field, rather than conventional local features of the image displacement.", "AI": {"tldr": "This paper introduces an efficient deep learning method to estimate material properties and continuum displacement from optical images, outperforming traditional methods.", "motivation": "Conventional methods for non-contact material property estimation and image displacement rely on iterative algorithms that are time-consuming and unsuitable for high-throughput data.", "method": "The study proposes an end-to-end deep learning framework using two neural networks, one for image registration and the other for material compressibility estimation.", "result": "The neural networks achieve superior accuracy and efficiency compared to traditional approaches, even handling local deviations in image displacement mappings effectively.", "conclusion": "Deep learning models can leverage higher-order cognitive features (e.g., vorticity of vector fields) for accurate estimation, expanding possibilities for engineering and biomedical applications."}}
{"id": "2602.07453", "pdf": "https://arxiv.org/pdf/2602.07453", "abs": "https://arxiv.org/abs/2602.07453", "authors": ["Namrita Varshney", "Ashutosh Gupta", "Arhaan Ahmad", "Tanay V. Tayal", "S. Akshay"], "title": "Data-Aware and Scalable Sensitivity Analysis for Decision Tree Ensembles", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Decision tree ensembles are widely used in critical domains, making robustness and sensitivity analysis essential to their trustworthiness. We study the feature sensitivity problem, which asks whether an ensemble is sensitive to a specified subset of features -- such as protected attributes -- whose manipulation can alter model predictions. Existing approaches often yield examples of sensitivity that lie far from the training distribution, limiting their interpretability and practical value. We propose a data-aware sensitivity framework that constrains the sensitive examples to remain close to the dataset, thereby producing realistic and interpretable evidence of model weaknesses. To this end, we develop novel techniques for data-aware search using a combination of mixed-integer linear programming (MILP) and satisfiability modulo theories (SMT) encodings. Our contributions are fourfold. First, we strengthen the NP-hardness result for sensitivity verification, showing it holds even for trees of depth 1. Second, we develop MILP-optimizations that significantly speed up sensitivity verification for single ensembles and for the first time can also handle multiclass tree ensembles. Third, we introduce a data-aware framework generating realistic examples close to the training distribution. Finally, we conduct an extensive experimental evaluation on large tree ensembles, demonstrating scalability to ensembles with up to 800 trees of depth 8, achieving substantial improvements over the state of the art. This framework provides a practical foundation for analyzing the reliability and fairness of tree-based models in high-stakes applications.", "AI": {"tldr": "This paper introduces a data-aware framework for analyzing the sensitivity of decision tree ensembles to specified features while keeping examples close to the data distribution.", "motivation": "To enhance trustworthiness by ensuring robustness and conducting sensitivity analysis for decision tree ensembles, essential in critical domains.", "method": "The authors develop a data-aware sensitivity framework using mixed-integer linear programming (MILP) and satisfiability modulo theories (SMT) encodings, improving sensitivity verification and interpretability.", "result": "The framework handles large ensembles (up to 800 trees of depth 8) efficiently, generating realistic sensitivity analysis examples and outperforming current methods.", "conclusion": "The proposed framework offers interpretability and scalability, paving the way for improved analysis of reliability and fairness in tree-based models for high-stakes applications."}}
{"id": "2602.07559", "pdf": "https://arxiv.org/pdf/2602.07559", "abs": "https://arxiv.org/abs/2602.07559", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang", "Hao Li", "Muhammad Kafeel Shaheen"], "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning", "categories": ["cs.AI", "cs.CC", "math.NA"], "comment": "13 pages", "summary": "Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving \"verification by construction\" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.", "AI": {"tldr": "The paper presents Verify-RL, a framework for solving mathematical problems using verifiable decomposition through symbolic differentiation, improving accuracy significantly.", "motivation": "Existing decomposition methods for training language models on mathematical problems are heuristic, lacking guarantees of simplicity or usefulness of subproblems.", "method": "The framework, Verify-RL, uses symbolic differentiation to break down problems into simpler verified subproblems based on calculus rules.", "result": "The approach eliminates invalid decompositions, leading to a more than twofold accuracy gain on the hardest problems (32% to 68%) and a 40% relative overall improvement.", "conclusion": "Symbolic differentiation enables mathematically grounded, verifiable decompositions, improving the training of language models on complex math tasks."}}
{"id": "2602.07219", "pdf": "https://arxiv.org/pdf/2602.07219", "abs": "https://arxiv.org/abs/2602.07219", "authors": ["Abhigyan Dutta", "Itay Safran", "Paul Valiant"], "title": "The Median is Easier than it Looks: Approximation with a Constant-Depth, Linear-Width ReLU Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study the approximation of the median of $d$ inputs using ReLU neural networks. We present depth-width tradeoffs under several settings, culminating in a constant-depth, linear-width construction that achieves exponentially small approximation error with respect to the uniform distribution over the unit hypercube. By further establishing a general reduction from the maximum to the median, our results break a barrier suggested by prior work on the maximum function, which indicated that linear width should require depth growing at least as $\\log\\log d$ to achieve comparable accuracy. Our construction relies on a multi-stage procedure that iteratively eliminates non-central elements while preserving a candidate set around the median. We overcome obstacles that do not arise for the maximum to yield approximation results that are strictly stronger than those previously known for the maximum itself.", "AI": {"tldr": "The paper investigates approximating the median using ReLU neural networks, achieving depth-width tradeoffs and exponential accuracy with constant depth and linear width.", "motivation": "To better approximate the median of multiple inputs using neural networks, addressing limitations suggested by prior work dealing with the maximum function.", "method": "A multi-stage procedure that iteratively removes non-central elements, preserving a candidate set around the median.", "result": "Achieves exponentially small approximation error under the unit hypercube distribution, surpassing existing limits for the maximum function.", "conclusion": "This study advances median approximation beyond previously established barriers for the maximum function, leveraging novel neural network constructions."}}
{"id": "2602.08166", "pdf": "https://arxiv.org/pdf/2602.08166", "abs": "https://arxiv.org/abs/2602.08166", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "Distributed Architecture Reconstruction of Polyglot and Multi-Repository Microservice Projects", "categories": ["cs.SE"], "comment": null, "summary": "Microservice architectures encourage the use of small, independently developed services; however, this can lead to increased architectural complexity. Accurate documentation is crucial, but is challenging to maintain due to the rapid, independent evolution of services. While static architecture reconstruction provides a way to maintain up-to-date documentation, existing approaches suffer from technology limitations, mono-repo constraints, or high implementation barriers. This paper presents a novel framework for static architecture reconstruction that supports technology-specific analysis modules, called \\emph{extractors}, and supports \\emph{distributed architecture reconstruction} in multi-repo environments. We describe the core design concepts and algorithms that govern how extractors are executed, how data is passed between them, and how their outputs are unified. Furthermore, the framework is interoperable with existing static analysis tools and algorithms, allowing them to be invoked from or embedded within extractors.", "AI": {"tldr": "The paper proposes a framework to simplify static architecture reconstruction for microservices, promoting better documentation and compatibility with existing tools.", "motivation": "Microservices often lack up-to-date documentation due to rapid service evolution and architectural complexity. Current static architecture reconstruction methods have limitations like high difficulty and mono-repo constraints.", "method": "The authors introduce a framework using technology-specific modules called extractors and algorithms for distributed architecture reconstruction in multi-repo environments. It also integrates with existing static analysis tools.", "result": "A novel framework is designed to unify and pass data among modular extractors, supporting distributed architecture reconstruction.", "conclusion": "The framework facilitates maintaining microservice architectures' documentation, addressing challenges of multi-repo architecture reconstruction while ensuring interoperability with existing tools."}}
{"id": "2602.07736", "pdf": "https://arxiv.org/pdf/2602.07736", "abs": "https://arxiv.org/abs/2602.07736", "authors": ["Omar Tahri"], "title": "Global Symmetry and Orthogonal Transformations from Geometrical Moment $n$-tuples", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Detecting symmetry is crucial for effective object grasping for several reasons. Recognizing symmetrical features or axes within an object helps in developing efficient grasp strategies, as grasping along these axes typically results in a more stable and balanced grip, thereby facilitating successful manipulation. This paper employs geometrical moments to identify symmetries and estimate orthogonal transformations, including rotations and mirror transformations, for objects centered at the frame origin. It provides distinctive metrics for detecting symmetries and estimating orthogonal transformations, encompassing rotations, reflections, and their combinations. A comprehensive methodology is developed to obtain these functions in n-dimensional space, specifically moment \\( n \\)-tuples. Extensive validation tests are conducted on both 2D and 3D objects to ensure the robustness and reliability of the proposed approach. The proposed method is also compared to state-of-the-art work using iterative optimization for detecting multiple planes of symmetry. The results indicate that combining our method with the iterative one yields satisfactory outcomes in terms of the number of symmetry planes detected and computation time.", "AI": {"tldr": "This paper introduces a methodology to detect symmetry and estimate orthogonal transformations using geometrical moments, offering robust validation tests and comparisons with current methods.", "motivation": "Symmetry detection is critical for stable and balanced object grasping, essential for successful manipulation tasks.", "method": "Geometrical moments are used to identify symmetries and estimate orthogonal transformations, including rotations and reflections, in n-dimensional space.", "result": "Validation tests on 2D and 3D objects and comparisons with iterative methods confirm the robustness and improved outcomes of the proposed approach.", "conclusion": "The combination of the proposed methodology with iterative optimization achieves satisfactory results in detecting symmetry planes efficiently while reducing computation time."}}
{"id": "2602.07778", "pdf": "https://arxiv.org/pdf/2602.07778", "abs": "https://arxiv.org/abs/2602.07778", "authors": ["Shenglai Zeng", "Tianqi Zheng", "Chuan Tian", "Dante Everaert", "Yau-Shian Wang", "Yupin Huang", "Michael J. Morais", "Rohit Patki", "Jinjin Tian", "Xinnan Dai", "Kai Guo", "Monica Xiao Cheng", "Hui Liu"], "title": "Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.", "AI": {"tldr": "The paper presents a novel method, Attn-GS, to personalize large language models by efficiently compressing user context, outperforming state-of-the-art methods while drastically reducing token usage.", "motivation": "To enable effective personalization of LLMs for users without overloading input token limits or incurring high costs associated with inference latency and API usage.", "method": "Introduces an attention-guided context compression framework (Attn-GS) where attention patterns in LLMs identify important personalization signals. These signals guide a compression model to generate concise and relevant user profiles.", "result": "Attn-GS significantly outperforms baseline approaches across various personalization tasks and settings. It achieves near-full-context performance while reducing token usage by 50 times.", "conclusion": "By leveraging LLMs' attention patterns for intelligent context compression, personalization tasks benefit from substantial efficiency gains and improved performance, presenting a scalable solution for user-centered applications."}}
{"id": "2602.07069", "pdf": "https://arxiv.org/pdf/2602.07069", "abs": "https://arxiv.org/abs/2602.07069", "authors": ["Zihao Fan", "Xin Lu", "Yidi Liu", "Jie Huang", "Dong Li", "Xueyang Fu", "Zheng-Jun Zha"], "title": "Bidirectional Reward-Guided Diffusion for Real-World Image Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion-based super-resolution can synthesize rich details, but models trained on synthetic paired data often fail on real-world LR images due to distribution shifts. We propose Bird-SR, a bidirectional reward-guided diffusion framework that formulates super-resolution as trajectory-level preference optimization via reward feedback learning (ReFL), jointly leveraging synthetic LR-HR pairs and real-world LR images. For structural fidelity easily affected in ReFL, the model is directly optimized on synthetic pairs at early diffusion steps, which also facilitates structure preservation for real-world inputs under smaller distribution gap in structure levels. For perceptual enhancement, quality-guided rewards are applied at later sampling steps to both synthetic and real LR images. To mitigate reward hacking, the rewards for synthetic results are formulated in a relative advantage space bounded by their clean counterparts, while real-world optimization is regularized via a semantic alignment constraint. Furthermore, to balance structural and perceptual learning, we adopt a dynamic fidelity-perception weighting strategy that emphasizes structure preservation at early stages and progressively shifts focus toward perceptual optimization at later diffusion steps. Extensive experiments on real-world SR benchmarks demonstrate that Bird-SR consistently outperforms state-of-the-art methods in perceptual quality while preserving structural consistency, validating its effectiveness for real-world super-resolution.", "AI": {"tldr": "Bird-SR, a novel framework for super-resolution, uses bidirectional reward-guided diffusion and trajectory preference optimization with synthetic and real-world data, improving both perceptual quality and structural fidelity.", "motivation": "Traditional diffusion-based super-resolution models face challenges with real-world low-resolution images due to distribution shifts from synthetic data.", "method": "Bird-SR employs bidirectional reward-guided diffusion that optimizes synthetic data early for structure preservation. Later steps involve quality-guided rewards for enhancing real-world images, with semantic alignment constraints and dynamic fidelity-perception weighting.", "result": "Bird-SR achieves superior perceptual quality while maintaining structural fidelity, surpassing state-of-the-art methods in real-world benchmarks.", "conclusion": "The Bird-SR framework effectively combines synthetic and real-world data optimization, addressing distribution shifts and achieving excellent results in real-world super-resolution tasks."}}
{"id": "2602.07472", "pdf": "https://arxiv.org/pdf/2602.07472", "abs": "https://arxiv.org/abs/2602.07472", "authors": ["Yilun Chen", "Jiaqi Lu"], "title": "Bandit Allocational Instability", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML"], "comment": null, "summary": "When multi-armed bandit (MAB) algorithms allocate pulls among competing arms, the resulting allocation can exhibit huge variation. This is particularly harmful in modern applications such as learning-enhanced platform operations and post-bandit statistical inference. Thus motivated, we introduce a new performance metric of MAB algorithms termed allocation variability, which is the largest (over arms) standard deviation of an arm's number of pulls. We establish a fundamental trade-off between allocation variability and regret, the canonical performance metric of reward maximization. In particular, for any algorithm, the worst-case regret $R_T$ and worst-case allocation variability $S_T$ must satisfy $R_T \\cdot S_T=\u03a9(T^{\\frac{3}{2}})$ as $T\\rightarrow\\infty$, as long as $R_T=o(T)$. This indicates that any minimax regret-optimal algorithm must incur worst-case allocation variability $\u0398(T)$, the largest possible scale; while any algorithm with sublinear worst-case regret must necessarily incur ${S}_T= \u03c9(\\sqrt{T})$. We further show that this lower bound is essentially tight, and that any point on the Pareto frontier $R_T \\cdot S_T=\\tilde\u0398(T^{3/2})$ can be achieved by a simple tunable algorithm UCB-f, a generalization of the classic UCB1. Finally, we discuss implications for platform operations and for statistical inference, when bandit algorithms are used. As a byproduct of our result, we resolve an open question of Praharaj and Khamaru (2025).", "AI": {"tldr": "The paper introduces a new metric called allocation variability for multi-armed bandit (MAB) algorithms, which measures variability in resource distribution and explores its trade-off with regret. A fundamental lower bound on this trade-off is established, showing limitations of existing algorithms.", "motivation": "Modern applications like platform operations and statistical inference are negatively affected by high variability in how MAB algorithms allocate resources (pulls) to options (arms). Introducing a metric for allocation variability addresses this crucial overlooked issue.", "method": "The authors analyze and derive mathematical trade-offs between regret minimization and allocation variability for MAB algorithms. They propose a generalized tunable algorithm, UCB-f, to achieve desired outcomes along this trade-off frontier.", "result": "The authors prove a fundamental trade-off: regret and allocation variability must satisfy a ${R_T} \\cdot {S_T} =\u03a9(T^{\\frac{3}{2}})$ relationship. They show that UCB-f achieves tight bounds on this trade-off, offering control over variability while optimizing regret.", "conclusion": "The work highlights the inherent conflict between regret minimization and allocation consistency, providing a groundbreaking new framework for MAB algorithms that is applicable to platform optimization and post-bandit statistical inference. It also resolves an open theoretical question."}}
{"id": "2602.07624", "pdf": "https://arxiv.org/pdf/2602.07624", "abs": "https://arxiv.org/abs/2602.07624", "authors": ["Junyu Feng", "Binxiao Xu", "Jiayi Chen", "Mengyu Dai", "Cenyang Wu", "Haodong Li", "Bohan Zeng", "Yunliu Xie", "Hao Liang", "Ming Lu", "Wentao Zhang"], "title": "M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions", "categories": ["cs.AI"], "comment": null, "summary": "This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuously absorb and leverage users' incremental concepts, aliases, and preferences. Current personalized multimodal models are predominantly static-concepts are fixed at initialization and cannot evolve during interactions. We propose M2A, an agentic dual-layer hybrid memory system that maintains personalized multimodal information through online updates. The system employs two collaborative agents: ChatAgent manages user interactions and autonomously decides when to query or update memory, while MemoryManager breaks down memory requests from ChatAgent into detailed operations on the dual-layer memory bank, which couples a RawMessageStore (immutable conversation log) with a SemanticMemoryStore (high-level observations), providing memories at different granularities. In addition, we develop a reusable data synthesis pipeline that injects concept-grounded sessions from Yo'LLaVA and MC-LLaVA into LoCoMo long conversations while preserving temporal coherence. Experiments show that M2A significantly outperforms baselines, demonstrating that transforming personalization from one-shot configuration to a co-evolving memory mechanism provides a viable path for high-quality individualized responses in long-term multimodal interactions. The code is available at https://github.com/Little-Fridge/M2A.", "AI": {"tldr": "This research addresses personalized question answering in long-term human-machine interactions, proposing M2A, a dual-layer memory system for continuous learning and individualization.", "motivation": "Existing models struggle with long-term personalization as they cannot continuously incorporate users' evolving concepts, preferences, or aliases during prolonged interactions.", "method": "M2A uses a hybrid memory system with two agents: ChatAgent, which manages interactions and memory updates, and MemoryManager, which handles memory operations between a RawMessageStore and a SemanticMemoryStore for granularity.", "result": "M2A significantly outperforms baseline methods, providing better individualized responses in prolonged multimodal interactions.", "conclusion": "The study demonstrates that dynamic and co-evolving memory mechanisms enable more effective personalization in human-machine interactions over time."}}
{"id": "2602.07223", "pdf": "https://arxiv.org/pdf/2602.07223", "abs": "https://arxiv.org/abs/2602.07223", "authors": ["Yikang Yue", "Yuqi Xue", "Jian Huang"], "title": "SpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding", "categories": ["cs.LG"], "comment": null, "summary": "Long-context large language model (LLM) inference has become the norm for today's AI applications. However, it is severely bottlenecked by the increasing memory demands of its KV cache. Previous works have shown that self-speculative decoding with sparse attention, where tokens are drafted using a subset of the KV cache and verified in parallel with full KV cache, speeds up inference in a lossless way. However, this approach relies on standalone KV selection algorithms to select the KV entries used for drafting and overlooks that the criticality of each KV entry is inherently computed during verification. In this paper, we propose SpecAttn, a self-speculative decoding method with verification-guided sparse attention. SpecAttn identifies critical KV entries as a byproduct of verification and only loads these entries when drafting subsequent tokens. This not only improves draft token acceptance rate but also incurs low KV selection overhead, thereby improving decoding throughput. SpecAttn achieves 2.81$\\times$ higher throughput over vanilla auto-regressive decoding and 1.29$\\times$ improvement over state-of-the-art sparsity-based self-speculative decoding methods.", "AI": {"tldr": "SpecAttn introduces verification-guided sparse attention to enhance large language model inference by identifying critical KV cache entries dynamically during verification, achieving significant throughput improvements.", "motivation": "Memory bottlenecks due to KV cache in large language model inference limit scalability and performance in AI applications.", "method": "The paper proposes SpecAttn, a self-speculative decoding method utilizing verification-guided sparse attention to dynamically identify and load relevant KV entries during inference, minimizing overhead.", "result": "SpecAttn achieves 2.81\u00d7 higher throughput than standard auto-regressive decoding and 1.29\u00d7 improvement compared to previous sparsity-based self-speculative decoding methods.", "conclusion": "Verification-guided sparse attention is effective in enhancing efficiency and throughput in large language model inference, addressing KV cache memory constraints."}}
{"id": "2602.08181", "pdf": "https://arxiv.org/pdf/2602.08181", "abs": "https://arxiv.org/abs/2602.08181", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases", "categories": ["cs.SE"], "comment": null, "summary": "Microservice architectures promote small, independently developed services, but increase overall architectural complexity. It is crucial that developers understand the architecture and how changes to a service affect the overall system, but rapid and independent development of services increases the risk of architectural drift and discourages the creation and maintenance of documentation. Automatic architecture reconstruction can help avoid these issues, but it is difficult to reuse reconstruction code across multiple projects, as all use different combinations of technologies and project-specific conventions. Reconstruction of architecture-level details is further complicated by the tendency to split microservices into separate repositories, preventing a full view of the system from any one codebase. In this paper, we present and evaluate ModARO, an approach to microservice architecture reconstruction that allows writing modular reconstruction code ('extractors') for any technologies and reusing them across different projects, independent of the surrounding technology stack or whether or not the services are split into multiple codebases. We demonstrate the effectiveness of our approach by configuring ModARO to reconstruct 10 open source projects, and we validate the usefulness and usability of ModARO against a state-of-the-art baseline in a user study with 8 industry practitioners. Using this approach, developers can assemble or create extractors tailored to their technology stacks and distribute architecture reconstruction across repositories, enabling integration into repository CI/CD pipelines.", "AI": {"tldr": "This paper introduces ModARO, a tool for modular microservice architecture reconstruction, addressing challenges like system complexity and split repositories.", "motivation": "The rapid development of independent microservices often causes architectural drift, discourages documentation, and increases difficulty in maintaining a cohesive understanding of the overall system architecture.", "method": "The authors propose ModARO, which provides modular 'extractors' for reconstructing microservice architectures. These extractors are adaptable to varied technologies across multiple projects and can integrate with CI/CD pipelines.", "result": "ModARO successfully reconstructed architectures from 10 open-source projects and demonstrated superior usability in a user study with 8 industry practitioners compared to a state-of-the-art baseline.", "conclusion": "ModARO enables efficient and reusable architecture reconstruction, helping developers manage and maintain microservice systems effectively, even when services are distributed across repositories."}}
{"id": "2602.07776", "pdf": "https://arxiv.org/pdf/2602.07776", "abs": "https://arxiv.org/abs/2602.07776", "authors": ["Joachim Yann Despature", "Kazuki Shibata", "Takamitsu Matsubara"], "title": "CoLF: Learning Consistent Leader-Follower Policies for Vision-Language-Guided Multi-Robot Cooperative Transport", "categories": ["cs.RO"], "comment": "9 pages, 5 figures", "summary": "In this study, we address vision-language-guided multi-robot cooperative transport, where each robot grounds natural-language instructions from onboard camera observations. A key challenge in this decentralized setting is perceptual misalignment across robots, where viewpoint differences and language ambiguity can yield inconsistent interpretations and degrade cooperative transport. To mitigate this problem, we adopt a dependent leader-follower design, where one robot serves as the leader and the other as the follower. Although such a leader-follower structure appears straightforward, learning with independent and symmetric agents often yields symmetric or unstable behaviors without explicit inductive biases. To address this challenge, we propose Consistent Leader-Follower (CoLF), a multi-agent reinforcement learning (MARL) framework for stable leader-follower role differentiation. CoLF consists of two key components: (1) an asymmetric policy design that induces leader-follower role differentiation, and (2) a mutual-information-based training objective that maximizes a variational lower bound, encouraging the follower to predict the leader's action from its local observation. The leader and follower policies are jointly optimized under the centralized training and decentralized execution (CTDE) framework to balance task execution and consistent cooperative behaviors. We validate CoLF in both simulation and real-robot experiments using two quadruped robots. The demonstration video is available at https://sites.google.com/view/colf/.", "AI": {"tldr": "The paper presents CoLF, a framework for multi-robot cooperation using vision-language guidance, overcoming perceptual misalignment by establishing consistent leader-follower roles.", "motivation": "The study aims to solve the perceptual misalignment and inconsistent behavior in vision-language-guided multi-robot cooperative tasks due to language and viewpoint differences.", "method": "CoLF employs asymmetric policy designs for leader-follower roles and mutual-information-based objectives, optimized using centralized training with decentralized execution.", "result": "CoLF demonstrates enhanced performance and consistent cooperation in both simulated and real-world tests with quadruped robots.", "conclusion": "Consistent role differentiation through CoLF improves stability and cooperation in multi-robot vision-language tasks, validated by simulation and real-world experiments."}}
{"id": "2602.07794", "pdf": "https://arxiv.org/pdf/2602.07794", "abs": "https://arxiv.org/abs/2602.07794", "authors": ["Ningyu Xu", "Qi Zhang", "Xipeng Qiu", "Xuanjing Huang"], "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "27 pages, 16 figures", "summary": "Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.", "AI": {"tldr": "This paper explores how large language models (LLMs) dynamically construct and use structured conceptual representations for reasoning, revealing their functional role in inference.", "motivation": "To determine whether structured, human-like conceptual representations in large language models functionally influence reasoning processes.", "method": "The authors employ causal mediation analyses on LLMs, investigating internal processing during in-context concept inference and exploring layer-specific activities and progression.", "result": "They identify a conceptual subspace in LLMs that persists across contexts and find that this subspace plays a causal and functional role in model predictions.", "conclusion": "LLMs dynamically construct latent, structured conceptual representations, leveraging them for flexible inference and showing that internal processing mirrors human-like reasoning structures."}}
{"id": "2602.07082", "pdf": "https://arxiv.org/pdf/2602.07082", "abs": "https://arxiv.org/abs/2602.07082", "authors": ["Haoming Wang", "Qiyao Xue", "Weichen Liu", "Wei Gao"], "title": "MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "When embodied AI is expanding from traditional object detection and recognition to more advanced tasks of robot manipulation and actuation planning, visual spatial reasoning from the video inputs is necessary to perceive the spatial relationships of objects and guide device actions. However, existing visual language models (VLMs) have very weak capabilities in spatial reasoning due to the lack of knowledge about 3D spatial information, especially when the reasoning task involve complex spatial relations across multiple video frames. In this paper, we present a new inference-time computing technique for on-device embodied AI, namely \\emph{MosaicThinker}, which enhances the on-device small VLM's spatial reasoning capabilities on difficult cross-frame reasoning tasks. Our basic idea is to integrate fragmented spatial information from multiple frames into a unified space representation of global semantic map, and further guide the VLM's spatial reasoning over the semantic map via a visual prompt. Experiment results show that our technique can greatly enhance the accuracy of cross-frame spatial reasoning on resource-constrained embodied AI devices, over reasoning tasks with diverse types and complexities.", "AI": {"tldr": "This paper introduces 'MosaicThinker,' a technique to improve spatial reasoning for on-device AI by integrating multi-frame spatial information into a global semantic map.", "motivation": "Existing visual language models struggle with spatial reasoning, particularly for tasks requiring 3D spatial understanding and complex reasoning across multiple video frames.", "method": "The paper proposes 'MosaicThinker,' a method that merges fragmented spatial details from video frames into a unified semantic map, then enhances spatial reasoning using visual prompts.", "result": "MosaicThinker significantly improves the accuracy of cross-frame spatial reasoning tasks on resource-limited embodied AI devices.", "conclusion": "The proposed approach enhances the spatial reasoning capabilities of small VLMs, enabling more advanced cross-frame reasoning tasks for on-device AI."}}
{"id": "2602.07477", "pdf": "https://arxiv.org/pdf/2602.07477", "abs": "https://arxiv.org/abs/2602.07477", "authors": ["Lena Schemet", "Sarah Friedrich-Welz"], "title": "Statistical inference after variable selection in Cox models: A simulation study", "categories": ["stat.ME", "cs.LG", "stat.AP", "stat.CO", "stat.ML"], "comment": null, "summary": "Choosing relevant predictors is central to the analysis of biomedical time-to-event data. Classical frequentist inference, however, presumes that the set of covariates is fixed in advance and does not account for data-driven variable selection. As a consequence, naive post-selection inference may be biased and misleading. In right-censored survival settings, these issues may be further exacerbated by the additional uncertainty induced by censoring. We investigate several inference procedures applied after variable selection for the coefficients of the Lasso and its extension, the adaptive Lasso, in the context of the Cox model. The methods considered include sample splitting, exact post-selection inference, and the debiased Lasso. Their performance is examined in a neutral simulation study reflecting realistic covariate structures and censoring rates commonly encountered in biomedical applications. To complement the simulation results, we illustrate the practical behavior of these procedures in an applied example using a publicly available survival dataset.", "AI": {"tldr": "This paper evaluates inference procedures for variable selection methods (Lasso and adaptive Lasso) in Cox survival models under realistic biomedical conditions.", "motivation": "To address potential biases and misleading results in frequentist inference post-variable selection, especially in right-censored survival data contexts.", "method": "Investigates post-selection inference methods (sample splitting, exact post-selection inference, and debiased Lasso) under simulation studies with realistic covariate structures and a practical dataset example.", "result": "The paper analyzes the performance of these inference methods using simulations and discusses their behavior in real biomedical datasets.", "conclusion": "The study provides insights into the strengths and weaknesses of different post-selection inference techniques in survival data to guide practitioners."}}
{"id": "2602.07628", "pdf": "https://arxiv.org/pdf/2602.07628", "abs": "https://arxiv.org/abs/2602.07628", "authors": ["Keondo Park", "Younghoon Na", "Yourim Choi", "Hyunwoo Ryu", "Hyun-Woo Shin", "Hyung-Sin Kim"], "title": "SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures", "categories": ["cs.AI", "cs.LG"], "comment": "8 pages, Appendix 9 pages", "summary": "While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.", "AI": {"tldr": "The paper introduces SleepMaMi, a novel Sleep Foundation Model, to improve analysis in sleep medicine by addressing both global sleep structures and localized signal features.", "motivation": "The paper aims to address the limitations in sleep medicine where current models focus only on localized, task-specific features, neglecting the holistic multi-modal context of Polysomnography (PSG) and full-night sleep patterns.", "method": "A hierarchical dual-encoder design was introduced. The Macro-Encoder models entire sleep structure with Demographic-Guided Contrastive Learning, while the Micro-Encoder captures detailed biosignal morphologies with Masked Autoencoder (MAE) and multi-modal contrastive learning. The model was pre-trained on more than 20,000 PSG recordings.", "result": "SleepMaMi outperforms existing foundational models on various sleep medicine tasks, showing better generalization and adaptation in clinical analysis while needing fewer labeled data.", "conclusion": "The proposed SleepMaMi framework effectively bridges the gap in sleep analysis by integrating global and local sleep features, setting a new benchmark for clinical applications in sleep medicine."}}
{"id": "2602.07226", "pdf": "https://arxiv.org/pdf/2602.07226", "abs": "https://arxiv.org/abs/2602.07226", "authors": ["Zihan Zhu", "Yanqiu Wu", "Qiongkai Xu"], "title": "Fault-Tolerant Evaluation for Sample-Efficient Model Performance Estimators", "categories": ["cs.LG"], "comment": null, "summary": "In the era of Model-as-a-Service, organizations increasingly rely on third-party AI models for rapid deployment. However, the dynamic nature of emerging AI applications, the continual introduction of new datasets, and the growing number of models claiming superior performance make efficient and reliable validation of model services increasingly challenging. This motivates the development of sample-efficient performance estimators, which aim to estimate model performance by strategically selecting instances for labeling, thereby reducing annotation cost. Yet existing evaluation approaches often fail in low-variance settings: RMSE conflates bias and variance, masking persistent bias when variance is small, while p-value based tests become hypersensitive, rejecting adequate estimators for negligible deviations. To address this, we propose a fault-tolerant evaluation framework that integrates bias and variance considerations within an adjustable tolerance level ${\\varepsilon}$, enabling the evaluation of performance estimators within practically acceptable error margins. We theoretically show that proper calibration of ${\\varepsilon}$ ensures reliable evaluation across different variance regimes, and we further propose an algorithm that automatically optimizes and selects ${\\varepsilon}$. Experiments on real-world datasets demonstrate that our framework provides comprehensive and actionable insights into estimator behavior.", "AI": {"tldr": "The paper proposes a fault-tolerant evaluation framework for sample-efficient performance estimators, addressing challenges in providing reliable AI model validation in low-variance regimes.", "motivation": "Increasing reliance on third-party AI models makes efficient and reliable model performance validation crucial amidst the variability in datasets, applications, and models.", "method": "The authors introduce a bias and variance-aware evaluation framework with an adjustable tolerance level (\u03b5) and an algorithm to optimize it for robust estimator evaluation.", "result": "The proposed framework effectively evaluates performance estimators within acceptable error margins across different variance regimes, validated through experiments on real datasets.", "conclusion": "The fault-tolerant framework offers a reliable method for assessing performance estimators, helping organizations adopt AI models with clearer, actionable insights."}}
{"id": "2602.08192", "pdf": "https://arxiv.org/pdf/2602.08192", "abs": "https://arxiv.org/abs/2602.08192", "authors": ["Mirko Perkusich", "Danyllo Albuquerque", "Allysson Allex Ara\u00fajo", "Matheus Paix\u00e3o", "Rohit Gheyi", "Marcos Kalinowski", "Angelo Perkusich"], "title": "Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners", "categories": ["cs.SE"], "comment": "Accepted for publication at the 27th International Conference on Agile Software Development (XP 2026)", "summary": "Scrum is widely adopted in software project management due to its adaptability and collaborative nature. The recent emergence of Large Language Models (LLMs) has created new opportunities to support knowledge-intensive Scrum practices. However, existing research has largely focused on technical activities such as coding and testing, with limited evidence on the use of LLMs in management-related Scrum activities. In this study, we investigate the use of LLMs in Scrum management activities through a survey of 70 Brazilian professionals. Among them, 49 actively use Scrum, and 33 reported using LLM-based assistants in their Scrum practices. The results indicate a high level of proficiency and frequent use of LLMs, with 85% of respondents reporting intermediate or advanced proficiency and 52% using them daily. LLM use concentrates on exploring Scrum practices, with artifacts and events receiving targeted yet uneven support, whereas broader management tasks appear to be adopted more cautiously. The main benefits include increased productivity (78%) and reduced manual effort (75%). However, several critical risks remain, as respondents report 'almost correct' outputs (81%), confidentiality concerns (63%), and hallucinations during use (59%). This work provides one of the first empirical characterizations of LLM use in Scrum management, identifying current practices, quantifying benefits and risks, and outlining directions for responsible adoption and integration in Agile environments.", "AI": {"tldr": "This paper investigates how Large Language Models (LLMs) are used in Scrum management activities, highlighting benefits like productivity increases and potential risks like incorrect output and confidentiality issues.", "motivation": "To explore how LLMs can support Scrum management activities in Agile development, considering the current focus has been primarily on technical tasks.", "method": "Conducted a survey of 70 professionals in Brazil, focusing on their use of LLMs in Scrum, including levels of proficiency and specific adoption areas.", "result": "Findings revealed that 85% of respondents have intermediate or advanced LLM proficiency. While 52% use LLMs daily, adoption focuses on specific Scrum practices. Benefits include improved productivity (78%) and reduced manual effort (75%), alongside concerns such as 'almost correct' outputs (81%) and confidentiality issues (63%).", "conclusion": "The study provides an initial empirical insight into how LLMs are integrated into Scrum management, offers a quantification of benefits and risks, and proposes responsible adoption measures for Agile teams."}}
{"id": "2602.07837", "pdf": "https://arxiv.org/pdf/2602.07837", "abs": "https://arxiv.org/abs/2602.07837", "authors": ["Hongzhi Zang", "Shu'ang Yu", "Hao Lin", "Tianxing Zhou", "Zefang Huang", "Zhen Guo", "Xin Xu", "Jiakai Zhou", "Yuze Sheng", "Shizhe Zhang", "Feng Gao", "Wenhao Tang", "Yufeng Yue", "Quanlu Zhang", "Xinlei Chen", "Chao Yu", "Yu Wang"], "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI", "categories": ["cs.RO"], "comment": null, "summary": "Online policy learning directly in the physical world is a promising yet challenging direction for embodied intelligence. Unlike simulation, real-world systems cannot be arbitrarily accelerated, cheaply reset, or massively replicated, which makes scalable data collection, heterogeneous deployment, and long-horizon effective training difficult. These challenges suggest that real-world policy learning is not only an algorithmic issue but fundamentally a systems problem. We present USER, a Unified and extensible SystEm for Real-world online policy learning. USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer, enabling automatic discovery, management, and scheduling of heterogeneous robots. To address cloud-edge communication, USER introduces an adaptive communication plane with tunneling-based networking, distributed data channels for traffic localization, and streaming-multiprocessor-aware weight synchronization to regulate GPU-side overhead. On top of this infrastructure, USER organizes learning as a fully asynchronous framework with a persistent, cache-aware buffer, enabling efficient long-horizon experiments with robust crash recovery and reuse of historical data. In addition, USER provides extensible abstractions for rewards, algorithms, and policies, supporting online imitation or reinforcement learning of CNN/MLP, generative policies, and large vision-language-action (VLA) models within a unified pipeline. Results in both simulation and the real world show that USER enables multi-robot coordination, heterogeneous manipulators, edge-cloud collaboration with large models, and long-running asynchronous training, offering a unified and extensible systems foundation for real-world online policy learning.", "AI": {"tldr": "USER is a system designed for real-world online policy learning in robotics, solving challenges in hardware management, cloud-edge communication, and asynchronous training.", "motivation": "To address the limitations of real-world online policy learning, such as challenges in data collection, scalability, and long-horizon training.", "method": "USER employs hardware abstraction for robot and GPU management, adaptive communication protocols, asynchronous training frameworks, and provides extensible learning frameworks for policies and rewards.", "result": "USER demonstrates success with multi-robot coordination, real-world and simulated experiments, edge-cloud integrations of large models, and robust long-horizon training.", "conclusion": "USER offers a scalable, extensible framework for advancing embodied intelligence in real-world scenarios, bridging hardware and algorithmic challenges."}}
{"id": "2602.07796", "pdf": "https://arxiv.org/pdf/2602.07796", "abs": "https://arxiv.org/abs/2602.07796", "authors": ["Jiatong Li", "Changdae Oh", "Hyeong Kyu Choi", "Jindong Wang", "Sharon Li"], "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents", "categories": ["cs.CL"], "comment": "27 pages, 19 figures", "summary": "Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.", "AI": {"tldr": "The paper studies the effect of explicit reasoning in user-engaged large language model (LLM) agents, finding that mandatory reasoning often reduces performance by making agents less transparent and restrictive in communication. Solutions for improving agent performance are explored.", "motivation": "The authors aimed to investigate the performance of reasoning-enabled LLMs in real-world user-engagement scenarios, as previous studies on reasoning capabilities in LLMs focused more on standardized evaluations and neglected practical settings.", "method": "The study examined seven models on three different benchmarks and two reasoning methods. It employed a combination of quantitative response taxonomy analysis and qualitative failure case analysis to evaluate the effects of reasoning on agent performance.", "result": "Mandatory reasoning unexpectedly worsens agent performance in user-engaged setups by limiting information disclosure, leading to poor task execution. In contrast, explicitly prompting for information disclosure improves performance by fostering better communication.", "conclusion": "Explicit reasoning in LLM agents can inadvertently degrade performance in user-engaged settings by disrupting communication flow. Proactively encouraging information transparency is crucial for designing effective reasoning agents in real-world scenarios."}}
{"id": "2602.07095", "pdf": "https://arxiv.org/pdf/2602.07095", "abs": "https://arxiv.org/abs/2602.07095", "authors": ["Wang Lin", "Feng Wang", "Majun Zhang", "Wentao Hu", "Tao Jin", "Zhou Zhao", "Fei Wu", "Jingyuan Chen", "Alan Yuille", "Sucheng Ren"], "title": "WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in image editing models have demonstrated remarkable capabilities in executing explicit instructions, such as attribute manipulation, style transfer, and pose synthesis. However, these models often face challenges when dealing with implicit editing instructions, which describe the cause of a visual change without explicitly detailing the resulting outcome. These limitations arise because existing models rely on uniform editing strategies that are not equipped to handle the complex world knowledge and reasoning required for implicit instructions. To address this gap, we introduce \\textbf{WorldEdit}, a dataset specifically designed to enable world-driven image editing. WorldEdit consists of high-quality editing samples, guided by paraphrased instructions that align with real-world causal logic. Furthermore, we provide \\textbf{WorldEdit-Test} for evaluating the existing model's performance on causal editing scenarios. With WorldEdit, we use a two-stage training framework for fine-tuning models like Bagel, integrating with a causal verification reward. Our results show that the proposed dataset and methods significantly narrow the gap with GPT-4o and Nano-Banana, demonstrating competitive performance not only in instruction following but also in knowledge plausibility, where many open-source systems typically struggle.", "AI": {"tldr": "Advances in image editing struggle with implicit instructions; WorldEdit dataset and training improve causal editing performance.", "motivation": "Existing image editing models struggle with implicit editing instructions requiring world knowledge and reasoning.", "method": "Created WorldEdit dataset for world-driven image editing and fine-tuned models using causal verification reward.", "result": "WorldEdit approach significantly improved performance in instruction following and knowledge plausibility.", "conclusion": "WorldEdit enhances the ability of image editing models to handle implicit, cause-driven edits effectively."}}
{"id": "2602.07488", "pdf": "https://arxiv.org/pdf/2602.07488", "abs": "https://arxiv.org/abs/2602.07488", "authors": ["Francesco Cagnetta", "Allan Ravent\u00f3s", "Surya Ganguli", "Matthieu Wyart"], "title": "Deriving Neural Scaling Laws from the statistics of natural language", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Despite the fact that experimental neural scaling laws have substantially guided empirical progress in large-scale machine learning, no existing theory can quantitatively predict the exponents of these important laws for any modern LLM trained on any natural language dataset. We provide the first such theory in the case of data-limited scaling laws. We isolate two key statistical properties of language that alone can predict neural scaling exponents: (i) the decay of pairwise token correlations with time separation between token pairs, and (ii) the decay of the next-token conditional entropy with the length of the conditioning context. We further derive a simple formula in terms of these statistics that predicts data-limited neural scaling exponents from first principles without any free parameters or synthetic data models. Our theory exhibits a remarkable match with experimentally measured neural scaling laws obtained from training GPT-2 and LLaMA style models from scratch on two qualitatively different benchmarks, TinyStories and WikiText.", "AI": {"tldr": "The paper develops the first theoretical framework to predict neural scaling exponents of modern LLMs based on statistical properties of language without reliance on synthetic data or free parameters.", "motivation": "The lack of a quantitative theory that predicts neural scaling exponents for modern LLMs on natural language datasets, despite their importance in guiding large-scale ML advancements.", "method": "The authors identify two key statistical properties of language\u2014(i) decay of pairwise token correlations and (ii) decay of conditional entropy\u2014and derive a parameter-free formula for predicting data-limited neural scaling exponents.", "result": "The theory shows a strong match with experimental neural scaling laws from training models like GPT-2 and LLaMA on benchmarks such as TinyStories and WikiText.", "conclusion": "The provided theory successfully explains and predicts neural scaling exponents of LLMs, advancing theoretical understanding and eliminating the need for synthetic data or free parameters."}}
{"id": "2602.07642", "pdf": "https://arxiv.org/pdf/2602.07642", "abs": "https://arxiv.org/abs/2602.07642", "authors": ["Zhuoyan Xu", "Haoyang Fang", "Boran Han", "Bonan Min", "Bernie Wang", "Cuixiong Hu", "Shuai Zhang"], "title": "Efficient Table Retrieval and Understanding with Multimodal Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": "Published at EACL 2026 Findings", "summary": "Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.", "AI": {"tldr": "This paper introduces TabRAG, a framework for answering user queries on large collections of table images. It achieves improved table retrieval and reasoning accuracy using visual-text foundation models and Multimodal Large Language Models (MLLMs).", "motivation": "The paper addresses the challenge of understanding and reasoning over table data embedded in images, which is common in real-world scenarios like financial reports and document scans. Current methods assume tables are readily available, while a practical need exists to handle large collections of table images.", "method": "TabRAG combines visual-text foundation models for table retrieval, fine-grained reranking using MLLMs, and reasoning over selected tables by MLLMs for generating answers.", "result": "TabRAG significantly outperforms existing approaches, showing a 7.0% improvement in retrieval recall and a 6.1% boost in answer accuracy, based on experiments with over 48,000 unique table samples.", "conclusion": "The proposed TabRAG framework presents an effective and practical solution for understanding and reasoning over table images, offering improved performance in real-world scenarios."}}
{"id": "2602.07227", "pdf": "https://arxiv.org/pdf/2602.07227", "abs": "https://arxiv.org/abs/2602.07227", "authors": ["Nethmi Jayasinghe", "Diana Gontero", "Spencer T. Brown", "Vinod K. Sangwan", "Mark C. Hersam", "Amit Ranjan Trivedi"], "title": "Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Robotic policies deployed in real-world environments often encounter post-training faults, where retraining, exploration, or system identification are impractical. We introduce an inference-time, cerebellar-inspired residual control framework that augments a frozen reinforcement learning policy with online corrective actions, enabling fault recovery without modifying base policy parameters. The framework instantiates core cerebellar principles, including high-dimensional pattern separation via fixed feature expansion, parallel microzone-style residual pathways, and local error-driven plasticity with excitatory and inhibitory eligibility traces operating at distinct time scales. These mechanisms enable fast, localized correction under post-training disturbances while avoiding destabilizing global policy updates. A conservative, performance-driven meta-adaptation regulates residual authority and plasticity, preserving nominal behavior and suppressing unnecessary intervention. Experiments on MuJoCo benchmarks under actuator, dynamic, and environmental perturbations show improvements of up to $+66\\%$ on \\texttt{HalfCheetah-v5} and $+53\\%$ on \\texttt{Humanoid-v5} under moderate faults, with graceful degradation under severe shifts and complementary robustness from consolidating persistent residual corrections into policy parameters.", "AI": {"tldr": "This paper presents a cerebellar-inspired residual control framework for robotic systems, enabling fault recovery without retraining or exploration by augmenting existing reinforcement learning policies with online corrections.", "motivation": "The motivation is to address the challenge of robotic systems encountering post-training faults in real-world environments where retraining or exploration is impractical.", "method": "The method includes an online residual control framework inspired by cerebellar principles, employing techniques like high-dimensional feature expansion, local error-driven plasticity, and meta-adaptation to regulate corrections and maintain stability.", "result": "The proposed framework demonstrated significant performance improvements in robotic benchmarks (e.g., up to +66% improvement in HalfCheetah-v5), robust fault recovery, and graceful degradation under severe conditions.", "conclusion": "This approach shows promise in augmenting robotic policies with cerebellar-like online corrections, enabling effective fault recovery and adaptability without modifying the base policy parameters."}}
{"id": "2602.08242", "pdf": "https://arxiv.org/pdf/2602.08242", "abs": "https://arxiv.org/abs/2602.08242", "authors": ["Ali Hassaan Mughal", "Muhammad Bilal"], "title": "Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications", "categories": ["cs.SE", "cs.NI"], "comment": "18 pages, 5 figures, 3 tables. Code and data: https://github.com/amughalbscs16/network-layer-quality-testing", "summary": "Modern web applications rely heavily on client-side API calls to fetch data, render content, and communicate with backend services. However, the quality of these network interactions (redundant requests, missing cache headers, oversized payloads, and excessive third-party dependencies) is rarely tested in a systematic way. Moreover, many of these quality deficiencies carry security implications: missing cache headers enable cache poisoning, excessive third-party dependencies expand the supply-chain attack surface, and error responses risk leaking server internals. In this study, we present an automated software testing framework that captures and analyzes the complete HTTP traffic of 18 production websites spanning 11 categories (e-commerce, news, government, developer tools, travel, and more). Using automated browser instrumentation via Playwright, we record 108 HAR (HTTP Archive) files across 3 independent runs per page, then apply 8 heuristic-based anti-pattern detectors to produce a composite quality score (0-100) for each site. Our results reveal a wide quality spectrum: minimalist server-rendered sites achieve perfect scores of 100, while content-heavy commercial sites score as low as 56.8. We identify redundant API calls and missing cache headers as the two most pervasive anti-patterns, each affecting 67% of sites, while third-party overhead exceeds 20% on 72% of sites. One utility site makes 2,684 requests per page load, which is 447x more than the most minimal site. To protect site reputations, all identities are anonymized using category-based pseudonyms. We provide all analysis scripts, anonymized results, and reproducibility instructions as an open artifact. This work establishes an empirical baseline for HTTP API call quality across the modern web and offers a reproducible testing framework that researchers and practitioners can apply to their own applications.", "AI": {"tldr": "This paper presents a framework to analyze HTTP traffic of websites using anti-pattern detectors, revealing major quality deficiencies in modern web applications.", "motivation": "To systematically test the quality of network interactions in web applications, especially concerning redundancy, security risks, and third-party dependencies.", "method": "Automated browser instrumentation via Playwright to record HTTP traffic, analyzed through heuristic-based anti-pattern detectors and composite scoring.", "result": "Quality scores range from 56.8 to 100 across 18 websites. Common issues include redundant API calls and missing cache headers, each affecting 67%. Excessive third-party dependencies were also prevalent.", "conclusion": "The study establishes a baseline for HTTP API quality and provides an actionable framework for researchers and practitioners focused on improving web application performance and security."}}
{"id": "2602.07845", "pdf": "https://arxiv.org/pdf/2602.07845", "abs": "https://arxiv.org/abs/2602.07845", "authors": ["Yalcin Tur", "Jalal Naghiyev", "Haoquan Fang", "Wei-Chuan Tsai", "Jiafei Duan", "Dieter Fox", "Ranjay Krishna"], "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning", "categories": ["cs.RO"], "comment": "11 Pages, Project page:https://rd-vla.github.io/", "summary": "Current Vision-Language-Action (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence. Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0 percent success) with single-iteration inference exceed 90 percent success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80x inference speedup over prior reasoning-based VLA models. Project page: https://rd-vla.github.io/", "AI": {"tldr": "RD-VLA introduces a recurrent, adaptive-depth framework for Vision-Language-Action tasks, enabling efficient and scalable compute. It combines iterative refinement and latent reasoning instead of token-based reasoning.", "motivation": "Current VLA models expend equal compute on all tasks, inefficiently handling both simple and complex actions; CoT prompting offers adaptivity but is unsuitable for continuous action spaces.", "method": "RD-VLA employs a recurrent, weight-shared action head with training via truncated backpropagation through time, allowing iterative refinement with a constant memory footprint and adaptive stopping based on latent convergence.", "result": "RD-VLA achieves significant performance improvements, with success rates improving from 0% to over 90% in complex tasks and providing up to 80x inference speedup compared to prior models.", "conclusion": "RD-VLA enables efficient, adaptive computation by replacing token-based reasoning with latent reasoning, offering scalability and constant memory usage in robotics applications."}}
{"id": "2602.07804", "pdf": "https://arxiv.org/pdf/2602.07804", "abs": "https://arxiv.org/abs/2602.07804", "authors": ["Xuan Ding", "Pengyu Tong", "Ranjie Duan", "Yunjian Zhang", "Rui Sun", "Yao Zhu"], "title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.", "AI": {"tldr": "This paper presents a game-theoretic approach to optimize layer-wise pruning in large language models (LLMs), addressing performance and computational costs.", "motivation": "To enhance the feasibility of deploying LLMs in real-world scenarios by reducing high computational demands while maintaining performance.", "method": "A game-theoretic framework is introduced where layers are considered players in a cooperative game; layer contributions are estimated via lightweight surrogate networks and stratified Monte Carlo sampling.", "result": "The proposed method achieves superior performance in terms of perplexity and zero-shot accuracy, providing efficient and effective pruning for LLMs.", "conclusion": "This approach successfully addresses inter-layer dependencies and significantly improves LLM pruning efficiency by leveraging game theory and advanced value estimation techniques."}}
{"id": "2602.07100", "pdf": "https://arxiv.org/pdf/2602.07100", "abs": "https://arxiv.org/abs/2602.07100", "authors": ["Biao Xiong", "Zhen Peng", "Ping Wang", "Qiegen Liu", "Xian Zhong"], "title": "TLC-Plan: A Two-Level Codebook Based Network for End-to-End Vector Floorplan Generation", "categories": ["cs.CV"], "comment": null, "summary": "Automated floorplan generation aims to improve design quality, architectural efficiency, and sustainability by jointly modeling global spatial organization and precise geometric detail. However, existing approaches operate in raster space and rely on post hoc vectorization, which introduces structural inconsistencies and hinders end-to-end learning. Motivated by compositional spatial reasoning, we propose TLC-Plan, a hierarchical generative model that directly synthesizes vector floorplans from input boundaries, aligning with human architectural workflows based on modular and reusable patterns. TLC-Plan employs a two-level VQ-VAE to encode global layouts as semantically labeled room bounding boxes and to refine local geometries using polygon-level codes. This hierarchy is unified in a CodeTree representation, while an autoregressive transformer samples codes conditioned on the boundary to generate diverse and topologically valid designs, without requiring explicit room topology or dimensional priors. Extensive experiments show state-of-the-art performance on RPLAN dataset (FID = 1.84, MSE = 2.06) and leading results on LIFULL dataset. The proposed framework advances constraint-aware and scalable vector floorplan generation for real-world architectural applications. Source code and trained models are released at https://github.com/rosolose/TLC-PLAN.", "AI": {"tldr": "The paper introduces TLC-Plan, a hierarchical generative model for vector-based floorplan generation that achieves state-of-the-art performance on multiple datasets.", "motivation": "The motivation is to improve architectural design quality and efficiency by directly generating vector floorplans, avoiding the structural inconsistencies of raster-to-vector methods.", "method": "The proposed TLC-Plan uses a hierarchical generative model with a two-level VQ-VAE to encode global and local geometries, unified under a CodeTree representation, and employs an autoregressive transformer for diversity and validity in designs.", "result": "TLC-Plan achieves state-of-the-art performance with metrics such as FID of 1.84 and MSE of 2.06 on the RPLAN dataset, while demonstrating leading results on the LIFULL dataset.", "conclusion": "The TLC-Plan framework provides a scalable and constraint-aware solution for real-world architectural applications, offering a significant advance in automated floorplan generation."}}
{"id": "2602.07562", "pdf": "https://arxiv.org/pdf/2602.07562", "abs": "https://arxiv.org/abs/2602.07562", "authors": ["Antoine Gonon", "Alexandre Cordonnier", "Nicolas Boumal"], "title": "Gaussian Match-and-Copy: A Minimalist Benchmark for Studying Transformer Induction", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Match-and-copy is a core retrieval primitive used at inference time by large language models to retrieve a matching token from the context then copy its successor. Yet, understanding how this behavior emerges on natural data is challenging because retrieval and memorization are entangled. To disentangle the two, we introduce Gaussian Match-and-Copy (GMC), a minimalist benchmark that isolates long-range retrieval through pure second-order correlation signals. Numerical investigations show that this task retains key qualitative aspects of how Transformers develop match-and-copy circuits in practice, and separates architectures by their retrieval capabilities. We also analyze the optimization dynamics in a simplified attention setting. Although many solutions are a priori possible under a regression objective, including ones that do not implement retrieval, we identify an implicit-bias regime in which gradient descent drives the parameters to diverge while their direction aligns with the max-margin separator, yielding hard match selection. We prove this max-margin alignment for GD trajectories that reach vanishing empirical loss under explicit technical conditions.", "AI": {"tldr": "The paper introduces a benchmark called Gaussian Match-and-Copy (GMC) to analyze retrieval in language models using second-order correlations.", "motivation": "To isolate and understand the emergence of match-and-copy mechanisms in language models, disentangling retrieval from memorization.", "method": "Use GMC, a minimal benchmark, to study retrieval based on second-order correlation, and analyze gradient descent optimization dynamics in attention-based settings.", "result": "GMC retains qualitative aspects of match-and-copy circuits and differentiates retrieval capabilities among architectures. Gradient descent leads to max-margin alignment for parameters in a hard match-selection regime.", "conclusion": "The proposed framework provides insights into how match-and-copy mechanisms evolve and highlights the implicit biases shaped by gradient descent in retrieval tasks."}}
{"id": "2602.07662", "pdf": "https://arxiv.org/pdf/2602.07662", "abs": "https://arxiv.org/abs/2602.07662", "authors": ["Glenda Amaral", "Tiago Prince Sales", "Riccardo Baratella", "Daniele Porello", "Renata Guizzardi", "Giancarlo Guizzardi"], "title": "ONTrust: A Reference Ontology of Trust", "categories": ["cs.AI"], "comment": "46 pages", "summary": "Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.", "AI": {"tldr": "The paper develops a Reference Ontology of Trust (ONTrust) to conceptualize and formalize trust for machines and humans, supporting tasks like automated reasoning and enterprise architecture.", "motivation": "To address the need for trustworthy systems in light of technological advancements (AI and decentralized technologies like blockchain) by properly conceptualizing trust.", "method": "The authors propose ONTrust, grounded in the Unified Foundational Ontology and specified in OntoUML, applied to areas like enterprise architecture, trust management, and AI-human teaming.", "result": "ONTrust provides a comprehensive model of trust, its influencing factors, and risk relations, and demonstrates its utility through two case studies.", "conclusion": "ONTrust is a significant step toward understanding and operationalizing trust for improving systems and fostering reliable AI-human collaborations."}}
{"id": "2602.07235", "pdf": "https://arxiv.org/pdf/2602.07235", "abs": "https://arxiv.org/abs/2602.07235", "authors": ["Atefeh Gilani", "Carol Xuan Long", "Sajani Vithana", "Oliver Kosut", "Lalitha Sankar", "Flavio P. Calmon"], "title": "ArcMark: Multi-bit LLM Watermark via Optimal Transport", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": null, "summary": "Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zero-bit setting, such as encoding a single bit per token. Notably, the information-theoretic capacity of multi-bit watermarking -- the maximum number of bits per token that can be inserted and detected without changing average next-token predictions -- has remained unknown. We address this gap by deriving the first capacity characterization of multi-bit watermarks. Our results inform the design of ArcMark: a new watermark construction based on coding-theoretic principles that, under certain assumptions, achieves the capacity of the multi-bit watermark channel. In practice, ArcMark outperforms competing multi-bit watermarks in terms of bit rate per token and detection accuracy. Our work demonstrates that LM watermarking is fundamentally a channel coding problem, paving the way for principled coding-theoretic approaches to watermark design.", "AI": {"tldr": "This paper introduces ArcMark, a new watermark construction that improves multi-bit watermarking for language models, achieving high bit rate per token and detection accuracy.", "motivation": "The motivation of this paper is to advance the design of multi-bit watermarking for language models, addressing the lack of understanding regarding the information-theoretic capacity of such watermarks.", "method": "The authors derive a capacity characterization for multi-bit watermarking and propose ArcMark, a watermark method based on coding-theoretic principles.", "result": "ArcMark achieves better performance in bit rate per token and detection accuracy compared to existing multi-bit watermarking techniques.", "conclusion": "This study redefines language model watermarking as a channel coding problem and demonstrates the potential of coding-theoretic approaches to improve watermark design."}}
{"id": "2602.08263", "pdf": "https://arxiv.org/pdf/2602.08263", "abs": "https://arxiv.org/abs/2602.08263", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Mustafa A. Mustafa", "Youcheng Sun"], "title": "Specification Vibing for Automated Program Repair", "categories": ["cs.SE"], "comment": null, "summary": "Large language model (LLM)-driven automated program repair (APR) has advanced rapidly, but most methods remain code-centric: they directly rewrite source code and thereby risk hallucinated, behaviorally inconsistent fixes. This limitation suggests the need for an alternative repair paradigm that relies on a representation more accessible to LLMs than raw code, enabling more accurate understanding, analysis, and alignment during repair. To address this gap, we propose VibeRepair, a specification-centric APR technique that treats repair as behavior-specification repair rather than ad-hoc code editing. VibeRepair first translates buggy code into a structured behavior specification that captures the program's intended runtime behavior, then infers and repairs specification misalignments, and finally synthesizes code strictly guided by the corrected behavior specification. An on-demand reasoning component enriches hard cases with program analysis and historical bug-fix evidence while controlling cost. Across Defects4J and real-world benchmarks and multiple LLMs, VibeRepair demonstrates consistently strong repair effectiveness with a significantly smaller patch space. On Defects4J v1.2, VibeRepair correctly repairs 174 bugs, exceeding the strongest state-of-the-art baseline by 28 bugs, which corresponds to a 19% improvement. On Defects4J v2.0, it repairs 178 bugs, outperforming prior approaches by 33 bugs, representing a 23% improvement. Evaluations on real-world benchmarks collected after the training period of selected LLMs further confirm its effectiveness and generalizability. By centering repair on explicit behavioral intent, VibeRepair reframes APR for the era of \"vibe\" coding: make the behavior sing, and the code will follow.", "AI": {"tldr": "VibeRepair introduces a new specification-centric approach to automated program repair, significantly improving repair effectiveness over state-of-the-art methods by aligning code fixes with explicit program behavior intent.", "motivation": "Most automated program repair methods focus on direct code editing, often resulting in inconsistent fixes due to their code-centric approach. There is a need for an alternative paradigm that leverages behavior specifications for better understanding and repair accuracy.", "method": "VibeRepair translates buggy code into structured behavior specifications, repairs misalignments in these specifications, and synthesizes code based on the corrected specifications. It also integrates reasoning mechanisms for complex cases, combining program analysis and historical bug-fix data.", "result": "VibeRepair repaired 174 and 178 bugs on Defects4J v1.2 and v2.0, respectively, outperforming state-of-the-art techniques by 19% and 23%. Its performance on real-world post-training benchmarks also validated its effectiveness and adaptability.", "conclusion": "By prioritizing behavior understanding over direct code edits, VibeRepair introduces a reliable and efficient approach to automated program repair, paving the way for more controlled and accurate program fixes in real-world scenarios."}}
{"id": "2602.07846", "pdf": "https://arxiv.org/pdf/2602.07846", "abs": "https://arxiv.org/abs/2602.07846", "authors": ["Ning Hu", "Maochen Li", "Senhao Cao"], "title": "System-Level Error Propagation and Tail-Risk Amplification in Reference-Based Robotic Navigation", "categories": ["cs.RO"], "comment": "13 pages, 8 figures", "summary": "Image guided robotic navigation systems often rely on reference based geometric perception pipelines, where accurate spatial mapping is established through multi stage estimation processes. In biplanar X ray guided navigation, such pipelines are widely used due to their real time capability and geometric interpretability. However, navigation reliability can be constrained by an overlooked system level failure mechanism in which installation induced structural perturbations introduced at the perception stage are progressively amplified along the perception reconstruction execution chain and dominate execution level error and tail risk behavior. This paper investigates this mechanism from a system level perspective and presents a unified error propagation modeling framework that characterizes how installation induced structural perturbations propagate and couple with pixel level observation noise through biplanar imaging, projection matrix estimation, triangulation, and coordinate mapping. Using first order analytic uncertainty propagation and Monte Carlo simulations, we analyze dominant sensitivity channels and quantify worst case error behavior beyond mean accuracy metrics. The results show that rotational installation error is a primary driver of system level error amplification, while translational misalignment of comparable magnitude plays a secondary role under typical biplanar geometries. Real biplanar X ray bench top experiments further confirm that the predicted amplification trends persist under realistic imaging conditions. These findings reveal a broader structural limitation of reference based multi stage geometric perception pipelines and provide a framework for system level reliability analysis and risk aware design in safety critical robotic navigation systems.", "AI": {"tldr": "The paper addresses structural errors in biplanar X-ray guided robotic navigation systems arising from installation misalignments and analyzes their propagation and effects.", "motivation": "The study aims to address the overlooked issue of how installation-induced structural misalignments in biplanar X-ray navigation systems amplify system errors across geometric perception pipelines.", "method": "The authors present a unified error propagation modeling framework combining first-order analytic uncertainty propagation and Monte Carlo simulations, along with real bench-top experiments, to quantify and analyze error behavior.", "result": "The study reveals rotational installation errors as primary amplifiers of system-level errors, with translational misalignments having secondary effects, validated through theoretical and experimental approaches.", "conclusion": "This work highlights the structural limitations of existing geometric perception pipelines in robotic navigation systems and offers a framework for reliability analysis and risk-aware design to mitigate these issues."}}
{"id": "2602.07812", "pdf": "https://arxiv.org/pdf/2602.07812", "abs": "https://arxiv.org/abs/2602.07812", "authors": ["Fengting Yuchi", "Li Du", "Jason Eisner"], "title": "LLMs Know More About Numbers than They Can Say", "categories": ["cs.CL"], "comment": "EACL 2026", "summary": "Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: \"Which is larger, $5.7 \\times 10^2$ or $580$?\" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.", "AI": {"tldr": "The paper investigates LLMs' numerical reasoning capabilities, especially on numerical comparisons with mixed notation, identifying weaknesses and proposing enhancements.", "motivation": "The research aims to understand why LLMs struggle with numerical comparison tasks despite advanced language capabilities, focusing on whether they encode numerical magnitudes effectively.", "method": "The authors probed hidden states of smaller LLMs, analyzing their encoding of numerical log-magnitudes and ranking ability using synthetic and scientific datasets. They also introduced auxiliary objectives during finetuning to improve model performance.", "result": "LLMs encode log-magnitudes effectively, with recoverable magnitudes at varying accuracies (2.3%-19.06%) and over 90% ranking accuracy with probes. However, explicit verbal ranking tasks had significantly lower accuracy (50-70%).", "conclusion": "Enhancing internal magnitude representations of LLMs can improve their numerical reasoning and verbal accuracy. Incorporating probing objectives during finetuning further boosts model performance."}}
{"id": "2602.07101", "pdf": "https://arxiv.org/pdf/2602.07101", "abs": "https://arxiv.org/abs/2602.07101", "authors": ["Zinan Lv", "Yeqian Qian", "Chen Sang", "Hao Liu", "Danping Zou", "Ming Yang"], "title": "Zero-Shot UAV Navigation in Forests via Relightable 3D Gaussian Splatting", "categories": ["cs.CV", "cs.RO"], "comment": "12 pages, 8 figures", "summary": "UAV navigation in unstructured outdoor environments using passive monocular vision is hindered by the substantial visual domain gap between simulation and reality. While 3D Gaussian Splatting enables photorealistic scene reconstruction from real-world data, existing methods inherently couple static lighting with geometry, severely limiting policy generalization to dynamic real-world illumination. In this paper, we propose a novel end-to-end reinforcement learning framework designed for effective zero-shot transfer to unstructured outdoors. Within a high-fidelity simulation grounded in real-world data, our policy is trained to map raw monocular RGB observations directly to continuous control commands. To overcome photometric limitations, we introduce Relightable 3D Gaussian Splatting, which decomposes scene components to enable explicit, physically grounded editing of environmental lighting within the neural representation. By augmenting training with diverse synthesized lighting conditions ranging from strong directional sunlight to diffuse overcast skies, we compel the policy to learn robust, illumination-invariant visual features. Extensive real-world experiments demonstrate that a lightweight quadrotor achieves robust, collision-free navigation in complex forest environments at speeds up to 10 m/s, exhibiting significant resilience to drastic lighting variations without fine-tuning.", "AI": {"tldr": "The paper introduces a method for robust UAV navigation in unstructured outdoor environments using passive monocular vision trained in simulation and transferred to reality via a novel lighting-agnostic framework.", "motivation": "The motivation is to address the challenges of UAV navigation in unstructured outdoor environments caused by visual domain gaps between simulation and reality, especially under varying, dynamic lighting conditions.", "method": "The paper presents an end-to-end reinforcement learning framework trained in a realistic simulation using a novel technique called Relightable 3D Gaussian Splatting, which enables explicit editing of environmental lighting during training.", "result": "The proposed method demonstrated robust, collision-free UAV navigation at high speeds (up to 10 m/s) in real-world forest environments, showing strong resilience to dynamic and varying lighting conditions.", "conclusion": "Relightable 3D Gaussian Splatting, combined with reinforcement learning, allows effective zero-shot transfer of navigation policies from simulation to challenging real-world environments under diverse lighting scenarios."}}
{"id": "2602.07593", "pdf": "https://arxiv.org/pdf/2602.07593", "abs": "https://arxiv.org/abs/2602.07593", "authors": ["Polina Gordienko", "Christoph Jansen", "Julian Rodemann", "Georg Schollmeyer"], "title": "Beyond Arrow: From Impossibility to Possibilities in Multi-Criteria Benchmarking", "categories": ["cs.LG", "cs.GT", "stat.ML"], "comment": null, "summary": "Modern benchmarks such as HELM MMLU account for multiple metrics like accuracy, robustness and efficiency. When trying to turn these metrics into a single ranking, natural aggregation procedures can become incoherent or unstable to changes in the model set. We formalize this aggregation as a social choice problem where each metric induces a preference ranking over models on each dataset, and a benchmark operator aggregates these votes across metrics. While prior work has focused on Arrow's impossibility result, we argue that the impossibility often originates from pathological examples and identify sufficient conditions under which these disappear, and meaningful multi-criteria benchmarking becomes possible. In particular, we deal with three restrictions on the combinations of rankings and prove that on single-peaked, group-separable and distance-restricted preferences, the benchmark operator allows for the construction of well-behaved rankings of the involved models. Empirically, we investigate several modern benchmark suites like HELM MMLU and verify which structural conditions are fulfilled on which benchmark problems.", "AI": {"tldr": "The paper addresses challenges in aggregating multiple metrics for benchmarking models and proposes solutions for coherent rankings under specific conditions.", "motivation": "The paper aims to improve multi-criteria model evaluation by solving issues associated with incoherent or unstable rankings caused by aggregating multiple metrics.", "method": "The authors formalize benchmarking as a social choice problem and identify sufficient conditions, like single-peaked and distance-restricted preferences, for creating well-behaved rankings. Empirical validation on benchmark suites like HELM MMLU is also included.", "result": "The study confirms that under defined structural conditions, meaningful and stable multi-criteria benchmarking is feasible. The paper analyzes modern benchmark datasets to verify these conditions.", "conclusion": "With appropriate constraints, multi-metric aggregation in model benchmarking can work effectively, providing coherent ranking systems for modern benchmarks."}}
{"id": "2602.07695", "pdf": "https://arxiv.org/pdf/2602.07695", "abs": "https://arxiv.org/abs/2602.07695", "authors": ["Congcong Hu", "Yuang Shi", "Fan Huang", "Yang Xiang", "Zhou Ye", "Ming Jin", "Shiyu Wang"], "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.MM"], "comment": null, "summary": "Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.", "AI": {"tldr": "EventCast is a forecasting framework that improves e-commerce demand predictions, especially during high-impact periods, by integrating knowledge of future events.", "motivation": "To address the limitations of existing forecasting systems during unpredictable demand patterns from flash sales, holiday campaigns, and policy interventions.", "method": "EventCast utilizes a dual-tower architecture combining historical demand data with textual summaries derived from unstructured business data, processed by large language models (LLMs) for event reasoning.", "result": "EventCast outperformed traditional methods, achieving up to 86.9% (MAE) and 97.7% (MSE) improvement compared to variants excluding event knowledge, and significantly reduced error rates versus industrial baselines.", "conclusion": "EventCast provides an accurate, explainable, and scalable solution for forecasting in dynamic e-commerce environments and is successfully deployed in real-world pipelines."}}
{"id": "2602.07256", "pdf": "https://arxiv.org/pdf/2602.07256", "abs": "https://arxiv.org/abs/2602.07256", "authors": ["Ruizhong Qiu", "Ting-Wei Li", "Gaotang Li", "Hanghang Tong"], "title": "Graph homophily booster: Reimagining the role of discrete features in heterophilic graph learning", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2026", "summary": "Graph neural networks (GNNs) have emerged as a powerful tool for modeling graph-structured data. However, existing GNNs often struggle with heterophilic graphs, where connected nodes tend to have dissimilar features or labels. While numerous methods have been proposed to address this challenge, they primarily focus on architectural designs without directly targeting the root cause of the heterophily problem. These approaches still perform even worse than the simplest MLPs on challenging heterophilic datasets. For instance, our experiments show that 21 latest GNNs still fall behind the MLP on the Actor dataset. This critical challenge calls for an innovative approach to addressing graph heterophily beyond architectural designs. To bridge this gap, we propose and study a new and unexplored paradigm: directly increasing the graph homophily via a carefully designed graph transformation. In this work, we present a simple yet effective framework called GRAPHITE to address graph heterophily. To the best of our knowledge, this work is the first method that explicitly transforms the graph to directly improve the graph homophily. Stemmed from the exact definition of homophily, our proposed GRAPHITE creates feature nodes to facilitate homophilic message passing between nodes that share similar features. Furthermore, we both theoretically and empirically show that our proposed GRAPHITE significantly increases the homophily of originally heterophilic graphs, with only a slight increase in the graph size. Extensive experiments on challenging datasets demonstrate that our proposed GRAPHITE significantly outperforms state-of-the-art methods on heterophilic graphs while achieving comparable accuracy with state-of-the-art methods on homophilic graphs.", "AI": {"tldr": "The paper introduces a novel method, GRAPHITE, that addresses the challenge of heterophilic graphs in graph neural networks by transforming the graph structure to increase homophily, outperforming state-of-the-art methods.", "motivation": "Existing GNNs struggle on heterophilic graphs as they mainly focus on architectural designs rather than tackling the root cause\u2014low graph homophily. Current methods often underperform simpler models like MLPs on such challenging datasets, demonstrating the need for a new approach.", "method": "The method, GRAPHITE, enhances graph homophily by introducing feature nodes that facilitate homophilic message passing. This transformation stems from the formal definition of homophily and increases homophily with minimal increase in graph size.", "result": "GRAPHITE demonstrates significant improvements in performance on heterophilic graphs and achieves comparable results to current methods on homophilic graphs. Additionally, it substantially increases graph homophily.", "conclusion": "GRAPHITE is an effective framework that overcomes the heterophily problem in GNNs by explicitly transforming the graph structure. It establishes a new paradigm for enhancing GNN performance on heterophilic datasets."}}
{"id": "2602.08316", "pdf": "https://arxiv.org/pdf/2602.08316", "abs": "https://arxiv.org/abs/2602.08316", "authors": ["Jared Zhu", "Minhao Hu", "Junde Wu"], "title": "SWE Context Bench: A Benchmark for Context Learning in Coding", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether agents can reuse experience across related problems. As a result, the ability of agents to accumulate, retrieve, and apply prior experience, as well as the efficiency gains from such reuse, remains difficult to measure. We introduce SWE-ContextBench, a benchmark designed to explicitly evaluate experience reuse in programming agents. Built on SWE-Bench Lite, SWE-ContextBench augments 300 base tasks with 99 related tasks derived from real dependency and reference relationships among GitHub issues and pull requests, forming task sequences with shared context. The benchmark evaluates agents along three complementary dimensions: prediction accuracy, time efficiency, and cost efficiency. Using SWE-ContextBench, we study multiple experience reuse settings, including oracle guided and autonomous retrieval, as well as full execution trajectories and compact summaries. Our results show that correctly selected summarized experience improves resolution accuracy and substantially reduces runtime and token cost, particularly on harder tasks. In contrast, unfiltered or incorrectly selected experience provides limited or negative benefits. These findings highlight the importance of experience representation and retrieval quality, and position SWE-ContextBench as a principled benchmark for studying experience reuse in programming agents.", "AI": {"tldr": "The paper introduces SWE-ContextBench, a benchmark focusing on assessing experience reuse in programming agents, based on task relationships and efficiency gains from context sharing.", "motivation": "To evaluate whether programming agents can reuse experience efficiently in solving related real-world tasks, addressing shortcomings in existing benchmarks that treat tasks as independent.", "method": "The development of SWE-ContextBench, a benchmark augmenting tasks from SWE-Bench Lite, forming sequences of related programming tasks to measure performance in areas like prediction accuracy, time, and cost efficiency.", "result": "The benchmark demonstrated that properly selected summarized experiences enhance accuracy and reduce runtime and costs, while improperly chosen data can negatively impact performance.", "conclusion": "SWE-ContextBench provides a systematic way to study experience reuse in programming agents, emphasizing the significance of quality representations and retrieval mechanisms for improved efficiency."}}
{"id": "2602.07888", "pdf": "https://arxiv.org/pdf/2602.07888", "abs": "https://arxiv.org/abs/2602.07888", "authors": ["Ning Hu", "Shuai Li", "Jindong Tan"], "title": "Research on a Camera Position Measurement Method based on a Parallel Perspective Error Transfer Model", "categories": ["cs.RO", "cs.CV"], "comment": "32 pages, 19 figures", "summary": "Camera pose estimation from sparse correspondences is a fundamental problem in geometric computer vision and remains particularly challenging in near-field scenarios, where strong perspective effects and heterogeneous measurement noise can significantly degrade the stability of analytic PnP solutions. In this paper, we present a geometric error propagation framework for camera pose estimation based on a parallel perspective approximation. By explicitly modeling how image measurement errors propagate through perspective geometry, we derive an error transfer model that characterizes the relationship between feature point distribution, camera depth, and pose estimation uncertainty. Building on this analysis, we develop a pose estimation method that leverages parallel perspective initialization and error-aware weighting within a Gauss-Newton optimization scheme, leading to improved robustness in proximity operations. Extensive experiments on both synthetic data and real-world images, covering diverse conditions such as strong illumination, surgical lighting, and underwater low-light environments, demonstrate that the proposed approach achieves accuracy and robustness comparable to state-of-the-art analytic and iterative PnP methods, while maintaining high computational efficiency. These results highlight the importance of explicit geometric error modeling for reliable camera pose estimation in challenging near-field settings.", "AI": {"tldr": "This paper introduces a geometric error propagation framework for better camera pose estimation in near-field scenarios, emphasizing improved robustness and computational efficiency.", "motivation": "Current camera pose estimation methods struggle in near-field conditions due to strong perspective effects and heterogeneous measurement noise.", "method": "The authors propose a framework using parallel perspective approximation, error-aware weighting, and Gauss-Newton optimization. It involves modeling error propagation to better account for camera depth and feature point distribution.", "result": "Experiments on synthetic and real-world images under challenging scenarios (e.g., surgical lighting, underwater environments) demonstrate that the method matches state-of-the-art accuracy and is computationally efficient.", "conclusion": "Explicit geometric error modeling significantly enhances the reliability of camera pose estimation methods in challenging near-field environments."}}
{"id": "2602.07839", "pdf": "https://arxiv.org/pdf/2602.07839", "abs": "https://arxiv.org/abs/2602.07839", "authors": ["Jiaxi Liu", "Yanzuo Jiang", "Guibin Zhang", "Zihan Zhang", "Heng Chang", "Zhenfei Yin", "Qibing Ren", "Junchi Yan"], "title": "TodoEvolve: Learning to Architect Agent Planning Systems", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.", "AI": {"tldr": "The paper introduces TodoEvolve, a meta-planning approach that creates and adapts planning architectures for complex tasks, outperforming traditional methods.", "motivation": "Existing planning systems rely on rigid, hand-crafted structures that struggle with diverse, open-ended problems.", "method": "The authors propose TodoEvolve, using PlanFactory to standardize planning paradigms and training Todo-14B with Impedance-Guided Preference Optimization for improved performance.", "result": "TodoEvolve outperforms engineered planning modules on five benchmarks, ensuring efficiency and cost-effectiveness.", "conclusion": "TodoEvolve demonstrates dynamic capability in creating efficient planning structures, offering a significant improvement over traditional approaches for diverse agent tasks."}}
{"id": "2602.07104", "pdf": "https://arxiv.org/pdf/2602.07104", "abs": "https://arxiv.org/abs/2602.07104", "authors": ["Zhuoheng Li", "Ying Chen"], "title": "Extended to Reality: Prompt Injection in 3D Environments", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced the capabilities to interpret and act on visual input in 3D environments, empowering diverse applications such as robotics and situated conversational agents. When MLLMs reason over camera-captured views of the physical world, a new attack surface emerges: an attacker can place text-bearing physical objects in the environment to override MLLMs' intended task. While prior work has studied prompt injection in the text domain and through digitally edited 2D images, it remains unclear how these attacks function in 3D physical environments. To bridge the gap, we introduce PI3D, a prompt injection attack against MLLMs in 3D environments, realized through text-bearing physical object placement rather than digital image edits. We formulate and solve the problem of identifying an effective 3D object pose (position and orientation) with injected text, where the attacker's goal is to induce the MLLM to perform the injected task while ensuring that the object placement remains physically plausible. Experiments demonstrate that PI3D is an effective attack against multiple MLLMs under diverse camera trajectories. We further evaluate existing defenses and show that they are insufficient to defend against PI3D.", "AI": {"tldr": "This paper explores the vulnerabilities of multimodal large language models (MLLMs) in 3D environments due to prompt injection attacks via physical objects.", "motivation": "To assess the risks posed by text-bearing physical objects placed in 3D environments, which can manipulate MLLMs' behavior.", "method": "Introduced PI3D, a prompt injection attack method using physical objects with text. Developed strategies to determine effective object placement in 3D space for plausible attacks.", "result": "PI3D proved effective against various MLLMs under multiple camera trajectories, and current defenses were shown to be ineffective against these attacks.", "conclusion": "Physical prompt injections are a significant security concern for MLLMs deployed in 3D environments, necessitating robust defenses."}}
{"id": "2602.07613", "pdf": "https://arxiv.org/pdf/2602.07613", "abs": "https://arxiv.org/abs/2602.07613", "authors": ["Jiuyao Lu", "Tianruo Zhang", "Ke Zhu"], "title": "Fast Rerandomization for Balancing Covariates in Randomized Experiments: A Metropolis-Hastings Framework", "categories": ["stat.ME", "stat.CO", "stat.ML"], "comment": null, "summary": "Balancing covariates is critical for credible and efficient randomized experiments. Rerandomization addresses this by repeatedly generating treatment assignments until covariate balance meets a prespecified threshold. By shrinking this threshold, it can achieve arbitrarily strong balance, with established results guaranteeing optimal estimation and valid inference in both finite-sample and asymptotic settings across diverse complex experimental settings. Despite its rigorous theoretical foundations, practical use is limited by the extreme inefficiency of rejection sampling, which becomes prohibitively slow under small thresholds and often forces practitioners to adopt suboptimal settings, leading to degraded performance. Existing work focusing on acceleration typically fail to maintain the uniformity over the acceptable assignment space, thus losing the theoretical grounds of classical rerandomization. Building upon a Metropolis-Hastings framework, we address this challenge by introducing an additional sampling-importance resampling step, which restores uniformity and preserves statistical guarantees. Our proposed algorithm, PSRSRR, achieves speedups ranging from 10 to 10,000 times while maintaining exact and asymptotic validity, as demonstrated by simulations and two real-data applications.", "AI": {"tldr": "This paper introduces PSRSRR, a method for speeding up rerandomization in experiments while maintaining validity.", "motivation": "Rerandomization improves covariate balance in experiments but traditional methods are inefficient under small thresholds.", "method": "The paper uses a Metropolis-Hastings framework with a sampling-importance resampling step to restore uniformity.", "result": "PSRSRR achieves speedups of 10 to 10,000 times compared to traditional methods while maintaining validity.", "conclusion": "PSRSRR makes rerandomization practically efficient without compromising its theoretical benefits."}}
{"id": "2602.07749", "pdf": "https://arxiv.org/pdf/2602.07749", "abs": "https://arxiv.org/abs/2602.07749", "authors": ["Zhenyu Wu", "Yanxi Long", "Jian Li", "Hua Huang"], "title": "Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution", "categories": ["cs.AI"], "comment": "ICML2026", "summary": "Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.", "AI": {"tldr": "Geo-coder introduces a new approach to improve geometric image reconstruction using an inverse programming framework based on multi-agent systems. By combining visual operators with code self-correction, it outperforms previous methods in accuracy and multimodal reasoning.", "motivation": "To address the challenges of existing inverse graphics methods in accurately reconstructing geometric details, which often leads to loss of key constraints and structural issues.", "method": "A two-stage framework: Stage 1 uses visual operators and large models for pixel-wise geometric modeling, and Stage 2 implements a synthesis-rendering-validation loop for self-correcting and refining code through visual feedback.", "result": "Geo-coder significantly improves geometric accuracy and visual consistency, with reconstructed images retaining equivalent performance to originals in multimodal reasoning tasks. An open dataset and model are also provided for research.", "conclusion": "Geo-coder offers an innovative and robust solution for geometric image reconstruction, enabling better multimodal reasoning and expanding research opportunities with open-source datasets and models."}}
{"id": "2602.07258", "pdf": "https://arxiv.org/pdf/2602.07258", "abs": "https://arxiv.org/abs/2602.07258", "authors": ["Wanru Guo", "Juan Xie", "Binbin Wang", "Weicong Chen", "Xiaoyi Lu", "Vipin Chaudhary", "Curtis Tatsuoka"], "title": "Robust Ultra-High-Dimensional Variable Selection With Correlated Structure Using Group Testing", "categories": ["cs.LG", "stat.ME"], "comment": "57 Pages, 5 Figures, 4 Tables", "summary": "Background: High-dimensional genomic data exhibit strong group correlation structures that challenge conventional feature selection methods, which often assume feature independence or rely on pre-defined pathways and are sensitive to outliers and model misspecification.\n  Methods: We propose the Dorfman screening framework, a multi-stage procedure that forms data-driven variable groups via hierarchical clustering, performs group and within-group hypothesis testing, and refines selection using elastic net or adaptive elastic net. Robust variants incorporate OGK-based covariance estimation, rank-based correlation, and Huber-weighted regression to handle contaminated and non-normal data.\n  Results: In simulations, Dorfman-Sparse-Adaptive-EN performed best under normal conditions, while Robust-OGK-Dorfman-Adaptive-EN showed clear advantages under data contamination, outperforming classical Dorfman and competing methods. Applied to NSCLC gene expression data for trametinib response, robust Dorfman methods achieved the lowest prediction errors and enriched recovery of clinically relevant genes.\n  Conclusions: The Dorfman framework provides an efficient and robust approach to genomic feature selection. Robust-OGK-Dorfman-Adaptive-EN offers strong performance under both ideal and contaminated conditions and scales to ultra-high-dimensional settings, making it well suited for modern genomic biomarker discovery.", "AI": {"tldr": "The paper proposes the robust Dorfman screening framework for genomic feature selection, demonstrating superior performance in handling high-dimensional and contaminated data.", "motivation": "The authors aim to address the limitations of conventional genomic feature selection methods, which struggle with correlated high-dimensional data, contamination, and model misspecification.", "method": "The Dorfman framework employs hierarchical clustering to group variables, hypothesis testing at group and within-group levels, and elastic net or adaptive elastic net for feature selection. Robust versions incorporate methods like OGK-based covariance estimation and Huber-weighted regression to handle data contamination.", "result": "Simulations showed Dorfman-Sparse-Adaptive-EN excelled under normal data, while the robust version outperformed under contamination. Applied to NSCLC gene expression, robust methods reduced prediction errors and better identified important genes.", "conclusion": "This framework is efficient, robust, and scalable to ultra-high-dimensional data, making it ideal for modern genomic biomarker discovery, especially under challenging conditions."}}
{"id": "2602.08561", "pdf": "https://arxiv.org/pdf/2602.08561", "abs": "https://arxiv.org/abs/2602.08561", "authors": ["Syed Mehtab Hussain Shah", "Frank Hopfgartner", "Arnim Bleier"], "title": "Automating Computational Reproducibility in Social Science: Comparing Prompt-Based and Agent-Based Approaches", "categories": ["cs.SE", "cs.CL"], "comment": "12 pages, 5 figures. Submitted to ACM conference", "summary": "Reproducing computational research is often assumed to be as simple as rerunning the original code with provided data. In practice, missing packages, fragile file paths, version conflicts, or incomplete logic frequently cause analyses to fail, even when materials are shared. This study investigates whether large language models and AI agents can automate the diagnosis and repair of such failures, making computational results easier to reproduce and verify. We evaluate this using a controlled reproducibility testbed built from five fully reproducible R-based social science studies. Realistic failures were injected, ranging from simple issues to complex missing logic, and two automated repair workflows were tested in clean Docker environments. The first workflow is prompt-based, repeatedly querying language models with structured prompts of varying context, while the second uses agent-based systems that inspect files, modify code, and rerun analyses autonomously. Across prompt-based runs, reproduction success ranged from 31-79 percent, with performance strongly influenced by prompt context and error complexity. Complex cases benefited most from additional context. Agent-based workflows performed substantially better, with success rates of 69-96 percent across all complexity levels. These results suggest that automated workflows, especially agent-based systems, can significantly reduce manual effort and improve reproduction success across diverse error types. Unlike prior benchmarks, our testbed isolates post-publication repair under controlled failure modes, allowing direct comparison of prompt-based and agent-based approaches.", "AI": {"tldr": "Investigates AI-driven solutions for automating reproducibility of research by diagnosing and fixing computational failures.", "motivation": "To address challenges in reproducing computational research due to issues like missing packages, version conflicts, and incomplete logic.", "method": "Studied both prompt-based (language model queries) and agent-based (autonomous file and code modifications) workflows on five controlled R-based study environments with injected failures.", "result": "Prompt-based workflows achieved 31-79% reproduction success, while agent-based workflows performed better with 69-96% success across varying error complexities.", "conclusion": "Agent-based systems with automated workflows can significantly enhance reproduction rates and reduce manual effort in computational research failures."}}
{"id": "2602.07901", "pdf": "https://arxiv.org/pdf/2602.07901", "abs": "https://arxiv.org/abs/2602.07901", "authors": ["Mark Griguletskii", "Danil Belov", "Pavel Osinenko"], "title": "Incremental Mapping with Measurement Synchronization & Compression", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 4 figures, 1 table", "summary": "Modern autonomous vehicles and robots utilize versatile sensors for localization and mapping. The fidelity of these maps is paramount, as an accurate environmental representation is a prerequisite for stable and precise localization. Factor graphs provide a powerful approach for sensor fusion, enabling the estimation of the maximum a posteriori solution. However, the discrete nature of graph-based representations, combined with asynchronous sensor measurements, complicates consistent state estimation. The design of an optimal factor graph topology remains an open challenge, especially in multi-sensor systems with asynchronous data. Conventional approaches rely on a rigid graph structure, which becomes inefficient with sensors of disparate rates. Although preintegration techniques can mitigate this for high-rate sensors, their applicability is limited. To address this problem, this work introduces a novel approach that incrementally constructs connected factor graphs, ensuring the incorporation of all available sensor data by choosing the optimal graph topology based on the external evaluation criteria. The proposed methodology facilitates graph compression, reducing the number of nodes (optimized variables) by ~30% on average while maintaining map quality at a level comparable to conventional approaches.", "AI": {"tldr": "This paper presents an approach to optimize factor graph topology for multi-sensor systems with asynchronous data, enhancing sensor fusion efficiency while maintaining map quality.", "motivation": "The need for accurate maps for stable localization and the inefficiency of rigid factor graph structures in handling asynchronous sensor data and multiple sensor systems.", "method": "Various sensor data are incorporated into adaptive factor graphs that optimize topologies using external evaluation criteria, supporting incremental graph construction and compression.", "result": "The new method reduces the number of nodes by about 30% on average while preserving map quality at a level comparable to traditional methods.", "conclusion": "The adaptive approach provides an efficient solution to the challenge of consistent state estimation in multi-sensor systems, balancing efficiency and accuracy."}}
{"id": "2602.07842", "pdf": "https://arxiv.org/pdf/2602.07842", "abs": "https://arxiv.org/abs/2602.07842", "authors": ["Yuhan Wang", "Shiyu Ni", "Zhikai Ding", "Zihang Zhan", "Yuanzi Li", "Keping Bi"], "title": "Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers", "categories": ["cs.CL"], "comment": null, "summary": "Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.", "AI": {"tldr": "LLMs suffer from miscalibration in multi-answer scenarios due to disagreement among valid answers. This paper introduces MACE to study this and proposes Semantic Confidence Aggregation (SCA) to improve calibration.", "motivation": "Current confidence calibration methods fail when faced with multi-answer questions, leading to systematic underestimation of confidence and miscalibration.", "method": "The study introduces MACE, a benchmark for evaluating calibration across domains with varying correct answer counts. It also proposes SCA, a method that aggregates confidence across high-probability sampled responses.", "result": "Experiments demonstrate that accuracy improves with answer cardinality, but confidence declines, causing miscalibration. SCA achieves state-of-the-art results in mixed-answer settings while maintaining performance in single-answer scenarios.", "conclusion": "Aggregating confidence across multiple responses is crucial for effective calibration in LLMs, especially for questions with varied valid answers."}}
{"id": "2602.07106", "pdf": "https://arxiv.org/pdf/2602.07106", "abs": "https://arxiv.org/abs/2602.07106", "authors": ["Haoyu Zhang", "Zhipeng Li", "Yiwen Guo", "Tianshu Yu"], "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.", "AI": {"tldr": "The paper introduces Ex-Omni, a framework for combining speech with 3D facial animations for Omni-modal large language models (OLLMs), addressing representation mismatches and proposing mechanisms for semantic reasoning and temporal dynamics.", "motivation": "To enhance natural interaction in OLLMs by incorporating speech-accompanied 3D facial animation, which remains underdeveloped due to challenges in aligning semantic token-level reasoning with dense temporal 3D motion.", "method": "They propose Ex-Omni, which decouples semantic reasoning from temporal generation using speech units as scaffolding and introduces a token-as-query gated fusion mechanism for controlled semantic integration. They also present the InstructEx dataset to support this integration.", "result": "Experiments show that Ex-Omni achieves competitive performance compared to other open-source OLLMs while delivering stable and aligned speech-accompanied facial animation generation.", "conclusion": "Ex-Omni effectively addresses the challenges in combining speech with 3D facial animations in the context of OLLMs, demonstrating its potential for improving natural interactions and advancing multi-modal understanding and generation."}}
{"id": "2602.07618", "pdf": "https://arxiv.org/pdf/2602.07618", "abs": "https://arxiv.org/abs/2602.07618", "authors": ["Levi Rauchwerger", "Stefanie Jegelka", "Ron Levie"], "title": "Dense Neural Networks are not Universal Approximators", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We investigate the approximation capabilities of dense neural networks. While universal approximation theorems establish that sufficiently large architectures can approximate arbitrary continuous functions if there are no restrictions on the weight values, we show that dense neural networks do not possess this universality. Our argument is based on a model compression approach, combining the weak regularity lemma with an interpretation of feedforward networks as message passing graph neural networks. We consider ReLU neural networks subject to natural constraints on weights and input and output dimensions, which model a notion of dense connectivity. Within this setting, we demonstrate the existence of Lipschitz continuous functions that cannot be approximated by such networks. This highlights intrinsic limitations of neural networks with dense layers and motivates the use of sparse connectivity as a necessary ingredient for achieving true universality.", "AI": {"tldr": "Dense neural networks, under constraints on weights and dimensions, cannot approximate certain continuous functions, challenging the notion of universality.", "motivation": "To explore the limitations of dense neural networks and understand why certain continuous functions cannot be approximated despite universal approximation theorems.", "method": "The study combines model compression techniques, the weak regularity lemma, and an interpretation of feedforward networks as message passing graph neural networks to analyze dense ReLU networks.", "result": "It is shown that dense neural networks with constrained weights, input/output dimensions, cannot approximate certain Lipschitz continuous functions.", "conclusion": "Dense neural networks have intrinsic limitations, and sparse connectivity is essential to achieve true universality in neural network approximation."}}
{"id": "2602.07754", "pdf": "https://arxiv.org/pdf/2602.07754", "abs": "https://arxiv.org/abs/2602.07754", "authors": ["Bahare Riahi", "Veronica Catete"], "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency", "categories": ["cs.AI", "cs.HC"], "comment": "13 pages, 3 figures", "summary": "This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.", "AI": {"tldr": "The study examines undergraduate students' views on AI grading systems using feedback from programming projects, highlighting key concerns about fairness, trust, and transparency.", "motivation": "To understand student perceptions of AI grading systems and improve their fairness, transparency, and trustworthiness in education.", "method": "The study compares AI-generated feedback vs. human feedback in a computer science course. It analyzes key ethical principles such as fairness and consistency in AI grading.", "result": "Students expressed concerns about AI's inability to understand context, personalize feedback, and empathize, emphasizing the need for human oversight.", "conclusion": "AI grading systems require human-centered design that includes empathy, flexibility, and equity to supplement, not replace, human judgment."}}
{"id": "2602.07263", "pdf": "https://arxiv.org/pdf/2602.07263", "abs": "https://arxiv.org/abs/2602.07263", "authors": ["Kevin Li", "Dibyadeep Saha", "Avni Kanodia", "Fan Lai"], "title": "tLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models", "categories": ["cs.LG"], "comment": null, "summary": "As Low-Rank Adaptation (LoRA) becomes the standard approach for efficiently fine-tuning large language models (LLMs), shared clusters increasingly execute many concurrent LoRA training jobs over the same frozen backbone. While recent advances enable batching (co-locating) multiple adapters during serving, efficient training-time co-location of heterogeneous LoRA adapters presents unique challenges. Jobs often differ in adapter rank, batch size, and resource allocation, and na\u00efve batching can introduce synchronization stalls, communication overheads, and per-job slowdowns that are worse than executing independently. We introduce tLoRA, a framework that enables efficient batch training of multiple LoRA jobs. tLoRA fuses adapters that share the same base model into an elastic shared super-model, exploiting existing distributed training frameworks to derive parallelism plans that share resources effectively. At the kernel level, tLoRA employs a fused LoRA kernel that adaptively reconstructs low-rank computation tiles and schedules rank-aware nano-batches to maximize overlap between computation and communication across adapters. At the scheduling layer, tLoRA incorporates an online, residual-capacity-aware scheduler that adaptively groups jobs to maximize collective throughput. Evaluations using real-world cluster traces demonstrate that tLoRA improves training throughput by 1.2--1.8x, job training completion time by 2.3--5.4x, and GPU utilization by 37%.", "AI": {"tldr": "tLoRA is a framework improving training efficiency in concurrent LoRA adaptation jobs by elastically fusing adapters into a shared model and employing optimized scheduling and computation techniques.", "motivation": "The need to address inefficiencies in training concurrent heterogeneous LoRA adapters over shared backbone models in clusters.", "method": "tLoRA utilizes a shared super-model fused from adapters, adaptive fused LoRA kernels, rank-aware nano-batching, and residual-capacity-aware online scheduling.", "result": "tLoRA achieves up to 1.8x improvement in throughput, 5.4x enhancement in job completion time, and 37% better GPU utilization.", "conclusion": "tLoRA significantly improves resource sharing, scheduling efficiency, and overall performance for LoRA training jobs in shared clusters."}}
{"id": "2602.08765", "pdf": "https://arxiv.org/pdf/2602.08765", "abs": "https://arxiv.org/abs/2602.08765", "authors": ["Micah Villmow"], "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas", "categories": ["cs.SE", "cs.AI"], "comment": "32 Pages, 7 Figures", "summary": "LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.", "AI": {"tldr": "This paper introduces Scylla, a framework for benchmarking agentic coding tools, assessing trade-offs between complexity and efficiency using seven testing tiers and a Cost-of-Pass (CoP) metric.", "motivation": "To address the lack of rigorous evaluation methods for comparing architectural choices in automating software development tasks using LLM-based tools.", "method": "Developed a model-agnostic evaluation framework featuring seven progressive testing tiers and the key metric of Cost-of-Pass (CoP), demonstrated with Claude Sonnet 4.5 and multiple LLM judges for scoring.", "result": "The framework proved reproducible and showed that increased architectural complexity does not always correlate with higher quality outcomes.", "conclusion": "Scylla provides a structured, reproducible way to evaluate coding tools, helping to quantify and optimize the trade-off between complexity and efficiency in LLM-based systems."}}
{"id": "2602.07913", "pdf": "https://arxiv.org/pdf/2602.07913", "abs": "https://arxiv.org/abs/2602.07913", "authors": ["Ren\u00e1ta Rusn\u00e1kov\u00e1", "Martin Chovanec", "Juraj Gazda"], "title": "Multi-Agent Route Planning as a QUBO Problem", "categories": ["cs.RO", "quant-ph"], "comment": null, "summary": "Multi-Agent Route Planning considers selecting vehicles, each associated with a single predefined route, such that the spatial coverage of a road network is increased while redundant overlaps are limited. This paper gives a formal problem definition, proves NP-hardness by reduction from the Weighted Set Packing problem, and derives a Quadratic Unconstrained Binary Optimization formulation whose coefficients directly encode unique coverage rewards and pairwise overlap penalties. A single penalty parameter controls the coverage-overlap trade-off. We distinguish between a soft regime, which supports multi-objective exploration, and a hard regime, in which the penalty is strong enough to effectively enforce near-disjoint routes. We describe a practical pipeline for generating city instances, constructing candidate routes, building the QUBO matrix, and solving it with an exact mixed-integer solver (Gurobi), simulated annealing, and D-Wave hybrid quantum annealing. Experiments on Barcelona instances with up to 10 000 vehicles reveal a clear coverage-overlap knee and show that Pareto-optimal solutions are mainly obtained under the hard-penalty regime, while D-Wave hybrid solvers and Gurobi achieve essentially identical objective values with only minor differences in runtime as problem size grows.", "AI": {"tldr": "This paper addresses Multi-Agent Route Planning to maximize coverage and minimize overlaps in road networks. It defines the problem formally, proves it's NP-hard, and develops a Quadratic Unconstrained Binary Optimization (QUBO) model. Simulation and experiments on Barcelona instances show notable solution properties.", "motivation": "The paper aims to improve spatial coverage of road networks by addressing the challenge of redundant overlaps in vehicle route planning through formal modelling and optimization techniques.", "method": "A QUBO formulation is developed, balancing coverage and overlap penalties, with soft and hard penalty regimes. A practical pipeline including instance generation, QUBO matrix construction, and solving using Gurobi, simulated annealing, and D-Wave hybrid quantum annealing is utilized.", "result": "Experiments on instances with up to 10 000 vehicles demonstrate Pareto-optimal solutions under hard-penalty conditions, and comparable performance between quantum and classical solvers with minor runtime differences.", "conclusion": "Effective strategies exist for maximizing coverage while minimizing overlaps in road networks, with evidence supporting the hard-penalty regime and the efficacy of both quantum and classical solvers for large-scale route planning."}}
{"id": "2602.07909", "pdf": "https://arxiv.org/pdf/2602.07909", "abs": "https://arxiv.org/abs/2602.07909", "authors": ["Taolin Zhang", "Hang Guo", "Wang Lu", "Tao Dai", "Shu-Tao Xia", "Jindong Wang"], "title": "SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization", "categories": ["cs.CL", "cs.LG"], "comment": "ICLR2026", "summary": "As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$\u03c4$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.", "AI": {"tldr": "This paper presents SparseEval, a method to improve benchmarking efficiency for large language models by optimizing anchor weights and item selection through a sparse optimization problem.", "motivation": "The study is motivated by the high computational cost of evaluating large language models on numerous benchmarks, necessitating a more efficient evaluation mechanism.", "method": "The authors propose SparseEval, leveraging gradient descent and iterative refinement for optimizing anchor selection, underpinned by MLP-based sparse optimization techniques. Anchor Importance Score and Candidate Importance Score are introduced for precise task-specific item evaluation.", "result": "Experiments validate SparseEval's performance, demonstrating low estimation error and strong correlation (high Kendall's \u03c4) with comprehensive benchmark results.", "conclusion": "SparseEval establishes a robust and practical approach to efficient benchmarking, reducing computational overhead while maintaining reliable performance assessment."}}
{"id": "2602.07149", "pdf": "https://arxiv.org/pdf/2602.07149", "abs": "https://arxiv.org/abs/2602.07149", "authors": ["Rawisara Lohanimit", "Yankun Wu", "Amelia Katirai", "Yuta Nakashima", "Noa Garcia"], "title": "Privacy in Image Datasets: A Case Study on Pregnancy Ultrasounds", "categories": ["cs.CV"], "comment": null, "summary": "The rise of generative models has led to increased use of large-scale datasets collected from the internet, often with minimal or no data curation. This raises concerns about the inclusion of sensitive or private information. In this work, we explore the presence of pregnancy ultrasound images, which contain sensitive personal information and are often shared online. Through a systematic examination of LAION-400M dataset using CLIP embedding similarity, we retrieve images containing pregnancy ultrasound and detect thousands of entities of private information such as names and locations. Our findings reveal that multiple images have high-risk information that could enable re-identification or impersonation. We conclude with recommended practices for dataset curation, data privacy, and ethical use of public image datasets.", "AI": {"tldr": "Generative models use large-scale datasets with minimal curation, raising privacy concerns about sensitive content like pregnancy ultrasound images detected in LAION-400M.", "motivation": "To investigate risks and privacy concerns arising from poorly curated datasets, focusing on sensitive content such as pregnancy ultrasound images.", "method": "Systematic analysis of LAION-400M using CLIP embedding similarity to retrieve pregnancy ultrasound images and detect sensitive/private information.", "result": "Thousands of entities of private data were detected, including names and locations in the retrieved ultrasound images, posing risks of re-identification and impersonation.", "conclusion": "Recommends stronger dataset curation practices, better focus on data privacy, and ethical guidelines for using public image datasets."}}
{"id": "2602.07667", "pdf": "https://arxiv.org/pdf/2602.07667", "abs": "https://arxiv.org/abs/2602.07667", "authors": ["Aysajan Eziz"], "title": "Fast Response or Silence: Conversation Persistence in an AI-Agent Social Network", "categories": ["econ.EM", "stat.AP", "stat.ML"], "comment": "34 pages, 15 figures, 10 tables", "summary": "Autonomous AI agents are beginning to populate social platforms, but it is still unclear whether they can sustain the back-and-forth needed for extended coordination. We study Moltbook, an AI-agent social network, using a first-week snapshot and introduce interaction half-life: how quickly a comment's chance of receiving a direct reply fades as the comment ages. Across tens of thousands of commented threads, Moltbook discussions are dominated by first-layer reactions rather than extended chains. Most comments never receive a direct reply, reciprocal back-and-forth is rare, and when replies do occur they arrive almost immediately -- typically within seconds -- implying persistence on the order of minutes rather than hours. Moltbook is often described as running on an approximately four-hour ``heartbeat'' check-in schedule; using aggregate spectral tests on the longest contiguous activity window, we do not detect a reliable four-hour rhythm in this snapshot, consistent with jittered or out-of-phase individual schedules. A contemporaneous Reddit baseline analyzed with the same estimators shows substantially deeper threads and much longer reply persistence. Overall, early agent social interaction on Moltbook fits a ``fast response or silence'' regime, suggesting that sustained multi-step coordination will likely require explicit memory, thread resurfacing, and re-entry scaffolds.", "AI": {"tldr": "The paper examines the interaction patterns of AI agents on the social network Moltbook, contrasting them with human behaviors on Reddit, and identifies the need for better mechanisms for sustained coordination by AI.", "motivation": "To understand how autonomous AI agents perform in sustaining back-and-forth interactions on social platforms and exploring their ability to coordinate effectively over time.", "method": "The researchers analyzed a first-week snapshot of Moltbook's activity, focusing on interaction half-life, thread structure, and reply dynamics across tens of thousands of threads. Aggregate spectral tests were used to seek temporal patterns.", "result": "The study found that Moltbook interactions are shallow, with most comments not receiving replies. Replies, when they occur, arrive within seconds, with no evidence of a four-hour interaction rhythm. Comparatively, Reddit threads sustain longer discussions.", "conclusion": "AI agents on Moltbook operate in a 'fast response or silence' regime, lacking mechanisms for extended multi-step coordination. Memory, thread resurfacing, and scaffolding may be needed for sustained interaction."}}
{"id": "2602.07755", "pdf": "https://arxiv.org/pdf/2602.07755", "abs": "https://arxiv.org/abs/2602.07755", "authors": ["Yiming Xiong", "Shengran Hu", "Jeff Clune"], "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs", "categories": ["cs.AI"], "comment": null, "summary": "The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non-stationarity of real-world tasks. In this paper, we introduce ALMA (Automated meta-Learning of Memory designs for Agentic systems), a framework that meta-learns memory designs to replace hand-engineered memory designs, therefore minimizing human effort and enabling agentic systems to be continual learners across diverse domains. Our approach employs a Meta Agent that searches over memory designs expressed as executable code in an open-ended manner, theoretically allowing the discovery of arbitrary memory designs, including database schemas as well as their retrieval and update mechanisms. Extensive experiments across four sequential decision-making domains demonstrate that the learned memory designs enable more effective and efficient learning from experience than state-of-the-art human-crafted memory designs on all benchmarks. When developed and deployed safely, ALMA represents a step toward self-improving AI systems that learn to be adaptive, continual learners.", "AI": {"tldr": "This paper introduces ALMA, a meta-learning framework for creating adaptive memory designs in agentic systems, addressing the limitation of fixed human-crafted memory modules.", "motivation": "The motivation stems from the need to overcome the statelessness of foundation models that hinders continuous learning, a critical factor for long-term reasoning and adaptation in real-world tasks.", "method": "ALMA utilizes a Meta Agent to automatically search for memory designs represented as executable code, enabling the discovery of flexible and more effective memory mechanisms for continual learning.", "result": "Experimental results across four domains show that ALMA's learned memory designs outperform state-of-the-art human-crafted ones in terms of effectiveness and efficiency.", "conclusion": "ALMA represents progress towards self-improving AI systems capable of adapting and learning continually across diverse environments."}}
{"id": "2602.07265", "pdf": "https://arxiv.org/pdf/2602.07265", "abs": "https://arxiv.org/abs/2602.07265", "authors": ["Daniil Vankov", "Nikita Ivkin", "Kyle Ulrich", "Xiang Song", "Ashish Khetan", "George Karypis"], "title": "XShare: Collaborative in-Batch Expert Sharing for Faster MoE Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are increasingly used to efficiently scale large language models. However, in production inference, request batching and speculative decoding significantly amplify expert activation, eroding these efficiency benefits. We address this issue by modeling batch-aware expert selection as a modular optimization problem and designing efficient greedy algorithms for different deployment settings. The proposed method, namely XShare, requires no retraining and dynamically adapts to each batch by maximizing the total gating score of selected experts. It reduces expert activation by up to 30% under standard batching, cuts peak GPU load by up to 3x in expert-parallel deployments, and achieves up to 14% throughput gains in speculative decoding via hierarchical, correlation-aware expert selection even if requests in a batch drawn from heterogeneous datasets.", "AI": {"tldr": "This paper introduces XShare, a method to optimize Mixture-of-Experts (MoE) architectures for efficient batch-aware expert selection without retraining, improving both resource utilization and inference throughput in production systems.", "motivation": "Scaling large language models efficiently in production is challenging because batching and speculative decoding increase expert activation, reducing efficiency benefits of Mixture-of-Experts architectures.", "method": "The authors model batch-aware expert selection as a modular optimization problem and propose XShare, a dynamic and retraining-free method using greedy algorithms to optimize expert selection for different deployment scenarios.", "result": "XShare reduces expert activation by up to 30% in standard batching, cuts GPU load by up to 3x in expert-parallel systems, and achieves up to 14% throughput gains during speculative decoding.", "conclusion": "This study demonstrates XShare's ability to optimize MoE deployments, effectively reducing computational costs and improving scalability without requiring model retraining."}}
{"id": "2602.08866", "pdf": "https://arxiv.org/pdf/2602.08866", "abs": "https://arxiv.org/abs/2602.08866", "authors": ["Bang Xie", "Senjian Zhang", "Zhiyuan Peng", "Wei Chen", "Chenhao Ying", "Yuan Luo"], "title": "ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS", "categories": ["cs.SE"], "comment": null, "summary": "Large language models have transformed code generation, enabling unprecedented automation in software development. As mobile ecosystems evolve, HarmonyOS has emerged as a critical platform requiring robust development tools. Software development for the HarmonyOS ecosystem relies heavily on ArkTS, a statically typed extension of TypeScript. Despite its growing importance, the ecosystem lacks robust tools for automated code repair, primarily due to the absence of a high-quality benchmark for evaluation. To address this gap, we present ArkEval, a unified framework for ArkTS automated repair workflow evaluation and benchmark construction. It provides the first comprehensive benchmark specifically designed for ArkTS automated program repair. We constructed this benchmark by mining issues from a large-scale official Huawei repository containing over 400 independent ArkTS applications. Through a rigorous multi-stage filtering process, we curated 502 reproducible issues. To ensure testability, we employed a novel LLM-based test generation and voting mechanism involving Claude and other models. Furthermore, we standardized problem statements to facilitate fair evaluation. Finally, we evaluated four state-of-the-art Large Language Models (LLMs) on our benchmark using a retrieval-augmented repair workflow. Our results highlight the current capabilities and limitations of LLMs in repairing ArkTS code, paving the way for future research in this low-resource language domain.", "AI": {"tldr": "This paper introduces ArkEval, the first robust evaluation framework and benchmark for ArkTS automated program repair, leveraging issues mined from Huawei's repository and tested using advanced language models.", "motivation": "The need for robust automated tools for HarmonyOS development using ArkTS, especially due to the lack of high-quality benchmarks for evaluating automated code repair systems.", "method": "The authors developed ArkEval by collecting and processing issues from Huawei's ArkTS applications, applying multi-stage filters, using LLMs for test generation, and standardizing problem statements for fair evaluation.", "result": "ArkEval benchmark captured 502 reproducible ArkTS issues. Four state-of-the-art LLMs were evaluated using a retrieval-augmented workflow, showcasing their capabilities and limitations in program repair.", "conclusion": "ArkEval fills a critical gap in evaluating automated code repair for ArkTS, providing insights into LLM performance and paving the way for advancements in low-resource programming languages."}}
{"id": "2602.07924", "pdf": "https://arxiv.org/pdf/2602.07924", "abs": "https://arxiv.org/abs/2602.07924", "authors": ["Nur Ahmad Khatim", "Mansur Arief"], "title": "Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities", "categories": ["cs.RO", "cs.AI", "math.OC"], "comment": null, "summary": "Securing petroleum infrastructure requires balancing autonomous system efficiency with human judgment for threat escalation, a challenge unaddressed by classical facility location models assuming homogeneous resources. This paper formulates the Human-Robot Co-Dispatch Facility Location Problem (HRCD-FLP), a capacitated facility location variant incorporating tiered infrastructure criticality, human-robot supervision ratio constraints, and minimum utilization requirements. We evaluate command center selection across three technology maturity scenarios. Results show transitioning from conservative (1:3 human-robot supervision) to future autonomous operations (1:10) yields significant cost reduction while maintaining complete critical infrastructure coverage. For small problems, exact methods dominate in both cost and computation time; for larger problems, the proposed heuristic achieves feasible solutions in under 3 minutes with approximately 14% optimality gap where comparison is possible. From systems perspective, our work demonstrate that optimized planning for human-robot teaming is key to achieve both cost-effective and mission-reliable deployments.", "AI": {"tldr": "This paper explores the design and optimization of a mixed human-robot system for securing petroleum infrastructure using the HRCD-FLP model, evaluating cost and efficiency under varying human-robot ratios.", "motivation": "The motivation is to address challenges in balancing autonomous system efficiency with human oversight in securing critical petroleum infrastructure, a limitation unexplored by traditional models.", "method": "The HRCD-FLP, a new capacitated facility location model, is introduced, accounting for infrastructure criticality, human-robot supervision, and utilization requirements. Both exact methods and heuristics are employed for solution evaluation.", "result": "Transitioning from conservative 1:3 human-robot supervision ratios to 1:10 yields cost savings while maintaining coverage. Heuristic methods achieve near-optimal solutions quickly for larger problems with a 14% optimality gap.", "conclusion": "Optimized human-robot team planning is essential for cost-effective and reliable petroleum infrastructure security, showcasing the potential of maturing autonomous operations."}}
{"id": "2602.07930", "pdf": "https://arxiv.org/pdf/2602.07930", "abs": "https://arxiv.org/abs/2602.07930", "authors": ["Irina Bigoulaeva", "Jonas Rohweder", "Subhabrata Dutta", "Iryna Gurevych"], "title": "Patches of Nonlinearity: Instruction Vectors in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.", "AI": {"tldr": "This paper explores how instruction representations form and function in language models during post-training phases, identifying \"Instruction Vectors\" that are both linearly separable and involve non-linear causal interactions.", "motivation": "Understanding how instruction-tuned language models process and utilize detailed instructions during post-training and identifying the internal mechanisms behind it.", "method": "The researchers used causal mediation analysis and developed a linearity-free method to localize information processing in language models, aiming to uncover representations called Instruction Vectors (IVs) and track their role in different post-training phases.", "result": "The study identified that instruction-specific representations (IVs) are fairly localized, exhibit a mix of linear separability with non-linear interactions, and act as circuit selectors in leveraging different information pathways to solve tasks.", "conclusion": "The findings challenge the linear representation hypothesis in mechanistic interpretability and offer new insights into internal processing chains of instruction-tuned models using IVs."}}
{"id": "2602.07174", "pdf": "https://arxiv.org/pdf/2602.07174", "abs": "https://arxiv.org/abs/2602.07174", "authors": ["Yongheng Sun", "Jun Shu", "Jianhua Ma", "Fan Wang"], "title": "DuMeta++: Spatiotemporal Dual Meta-Learning for Generalizable Few-Shot Brain Tissue Segmentation Across Diverse Ages", "categories": ["cs.CV"], "comment": null, "summary": "Accurate segmentation of brain tissues from MRI scans is critical for neuroscience and clinical applications, but achieving consistent performance across the human lifespan remains challenging due to dynamic, age-related changes in brain appearance and morphology. While prior work has sought to mitigate these shifts by using self-supervised regularization with paired longitudinal data, such data are often unavailable in practice. To address this, we propose \\emph{DuMeta++}, a dual meta-learning framework that operates without paired longitudinal data. Our approach integrates: (1) meta-feature learning to extract age-agnostic semantic representations of spatiotemporally evolving brain structures, and (2) meta-initialization learning to enable data-efficient adaptation of the segmentation model. Furthermore, we propose a memory-bank-based class-aware regularization strategy to enforce longitudinal consistency without explicit longitudinal supervision. We theoretically prove the convergence of our DuMeta++, ensuring stability. Experiments on diverse datasets (iSeg-2019, IBIS, OASIS, ADNI) under few-shot settings demonstrate that DuMeta++ outperforms existing methods in cross-age generalization. Code will be available at https://github.com/ladderlab-xjtu/DuMeta++.", "AI": {"tldr": "DuMeta++ is a dual meta-learning framework for accurate brain MRI segmentation across all ages, achieving high performance even without paired longitudinal data.", "motivation": "Dynamic, age-related changes in brain morphology make accurate segmentation from MRI scans challenging, especially without longitudinal data.", "method": "DuMeta++ combines meta-feature learning to capture age-agnostic features, meta-initialization learning for adaptability, and memory-bank-based class-aware regularization for longitudinal consistency.", "result": "Experiments on datasets like iSeg-2019 and ADNI show superior cross-age generalization of DuMeta++ in few-shot settings.", "conclusion": "DuMeta++ enhances brain tissue segmentation by addressing age-related challenges in MRI data, offering a robust and generalizable solution."}}
{"id": "2602.07915", "pdf": "https://arxiv.org/pdf/2602.07915", "abs": "https://arxiv.org/abs/2602.07915", "authors": ["Huiyang Yi", "Xiaojian Shen", "Yonggang Wu", "Duxin Chen", "He Wang", "Wenwu Yu"], "title": "CausalCompass: Evaluating the Robustness of Time-Series Causal Discovery in Misspecified Scenarios", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "Causal discovery from time series is a fundamental task in machine learning. However, its widespread adoption is hindered by a reliance on untestable causal assumptions and by the lack of robustness-oriented evaluation in existing benchmarks. To address these challenges, we propose CausalCompass, a flexible and extensible benchmark suite designed to assess the robustness of time-series causal discovery (TSCD) methods under violations of modeling assumptions. To demonstrate the practical utility of CausalCompass, we conduct extensive benchmarking of representative TSCD algorithms across eight assumption-violation scenarios. Our experimental results indicate that no single method consistently attains optimal performance across all settings. Nevertheless, the methods exhibiting superior overall performance across diverse scenarios are almost invariably deep learning-based approaches. We further provide hyperparameter sensitivity analyses to deepen the understanding of these findings. We also find, somewhat surprisingly, that NTS-NOTEARS relies heavily on standardized preprocessing in practice, performing poorly in the vanilla setting but exhibiting strong performance after standardization. Finally, our work aims to provide a comprehensive and systematic evaluation of TSCD methods under assumption violations, thereby facilitating their broader adoption in real-world applications. The code and datasets are available at https://github.com/huiyang-yi/CausalCompass.", "AI": {"tldr": "The paper introduces CausalCompass, a benchmark for evaluating the robustness of time-series causal discovery (TSCD) methods under violated assumptions, revealing key insights into TSCD performance.", "motivation": "To address the lack of robustness-oriented evaluations and dependency on untestable assumptions in TSCD methods.", "method": "Developed CausalCompass, a benchmark suite evaluating TSCD robustness under eight different assumption-violation scenarios, and conducted extensive experiments with representative algorithms.", "result": "The results show no single TSCD method consistently excels across scenarios. Deep learning-based methods demonstrate superior overall performance, while specific preprocessing significantly impacts algorithm performance.", "conclusion": "CausalCompass provides systematic evaluation for TSCD methods, fostering their adoption in real-world applications. Experimental findings emphasize the importance of robustness and standardized preprocessing."}}
{"id": "2602.07765", "pdf": "https://arxiv.org/pdf/2602.07765", "abs": "https://arxiv.org/abs/2602.07765", "authors": ["Zhirong Huang", "Debo Cheng", "Guixian Zhang", "Yi Wang", "Jiuyong Li", "Shichao Zhang"], "title": "Disentangled Instrumental Variables for Causal Inference with Networked Observational Data", "categories": ["cs.AI"], "comment": null, "summary": "Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confounders and to violate exogeneity. To overcome this challenge, we propose $\\underline{Dis}$entangled $\\underline{I}$nstrumental $\\underline{V}$ariables (DisIV) framework, a novel method for causal inference based on networked observational data with latent confounders. DisIV exploits network homogeneity as an inductive bias and employs a structural disentanglement mechanism to extract individual-specific components that serve as latent IVs. The causal validity of the extracted IVs is constrained through explicit orthogonality and exclusion conditions. Extensive semi-synthetic experiments on real-world datasets demonstrate that DisIV consistently outperforms state-of-the-art baselines in causal effect estimation under network-induced confounding.", "AI": {"tldr": "DisIV introduces a framework for overcoming challenges in causal inference involving latent confounders in networked data by structurally disentangling instrumental variables.", "motivation": "The paper addresses the difficulties in using instrumental variables in networked data due to the confounding effects of shared environments and unobserved variables.", "method": "The DisIV framework uses network homogeneity as an inductive bias and employs structural disentanglement, along with orthogonality and exclusion constraints, to extract individual-specific latent instrumental variables.", "result": "Experiments on semi-synthetic and real-world datasets show DisIV's superior performance compared to existing methods in causal effect estimation under network-induced confounding.", "conclusion": "DisIV provides a novel solution for causal inference in networked data, ensuring the validity of instrumental variables and offering improved results even when confounded by shared environments."}}
{"id": "2602.07273", "pdf": "https://arxiv.org/pdf/2602.07273", "abs": "https://arxiv.org/abs/2602.07273", "authors": ["Xiaoyi Wu", "Juaren Steiger", "Bin Li", "R. Srikant"], "title": "Hybrid Feedback-Guided Optimal Learning for Wireless Interactive Panoramic Scene Delivery", "categories": ["cs.LG", "cs.MM"], "comment": "Submitting to ToN", "summary": "Immersive applications such as virtual and augmented reality impose stringent requirements on frame rate, latency, and synchronization between physical and virtual environments. To meet these requirements, an edge server must render panoramic content, predict user head motion, and transmit a portion of the scene that is large enough to cover the user viewport while remaining within wireless bandwidth constraints. Each portion produces two feedback signals: prediction feedback, indicating whether the selected portion covers the actual viewport, and transmission feedback, indicating whether the corresponding packets are successfully delivered. Prior work models this problem as a multi-armed bandit with two-level bandit feedback, but fails to exploit the fact that prediction feedback can be retrospectively computed for all candidate portions once the user head pose is observed. As a result, prediction feedback constitutes full-information feedback rather than bandit feedback. Motivated by this observation, we introduce a two-level hybrid feedback model that combines full-information and bandit feedback, and formulate the portion selection problem as an online learning task under this setting. We derive an instance-dependent regret lower bound for the hybrid feedback model and propose AdaPort, a hybrid learning algorithm that leverages both feedback types to improve learning efficiency. We further establish an instance-dependent regret upper bound that matches the lower bound asymptotically, and demonstrate through real-world trace driven simulations that AdaPort consistently outperforms state-of-the-art baseline methods.", "AI": {"tldr": "The paper introduces a hybrid feedback model for immersive applications in AR/VR, leveraging full-information and bandit feedback to optimize viewport content selection, and proposes AdaPort, an efficient algorithm outperforming existing methods.", "motivation": "The authors aim to address the shortcomings of existing multi-armed bandit models for immersive applications by leveraging prediction feedback that can be computed in full retrospectively, improving real-time viewport content selection in AR/VR.", "method": "They developed a two-level hybrid feedback model combining full-information and bandit feedback for online learning. They analyzed the regret bounds of their model and created AdaPort, an algorithm using this hybrid feedback to optimize immersive experience.", "result": "The proposed AdaPort algorithm achieves instance-dependent regret bounds matching the theoretical limits and outperforms state-of-the-art methods in real-world trace-driven simulations.", "conclusion": "The research successfully shows that utilizing hybrid feedback improves learning efficiency in immersive applications, setting new benchmarks in regret bounds and practical performance with AdaPort."}}
{"id": "2602.08887", "pdf": "https://arxiv.org/pdf/2602.08887", "abs": "https://arxiv.org/abs/2602.08887", "authors": ["Adam Trendowicz", "Daniel Seifert", "Andreas Jedlitschka", "Marcus Ciolkowski", "Anton Strahilov"], "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.", "AI": {"tldr": "The paper discusses the use of large language models (like GPT-4o) for improving requirements validation in agile software development, showcasing the 'DeepQuali' approach.", "motivation": "The paper aims to address the limited application of generative AI in quality assessments for requirements engineering, which is a critical gap in agile software development.", "method": "The authors propose 'DeepQuali', an LLM-based approach, and evaluated it by comparing its assessments with expert judgments in two small companies. Experts participated in walkthroughs, provided feedback, and rated the approach.", "result": "Experts largely agreed with the LLM's quality assessments, though detailed ratings were influenced by expertise and experience. Challenges like workflow integration appeared, but the feedback and explanatory features of LLMs improved acceptance.", "conclusion": "LLMs hold potential to support requirements quality assessment in agile development. Using explicit quality models and providing explanatory feedback can improve expert acceptance."}}
{"id": "2602.07932", "pdf": "https://arxiv.org/pdf/2602.07932", "abs": "https://arxiv.org/abs/2602.07932", "authors": ["Ying-Sheng Luo", "Lu-Ching Wang", "Hanjaya Mandala", "Yu-Lun Chou", "Guilherme Christmann", "Yu-Chung Chen", "Yung-Shun Chan", "Chun-Yi Lee", "Wei-Chao Chen"], "title": "Feasibility-Guided Planning over Multi-Specialized Locomotion Policies", "categories": ["cs.RO"], "comment": "ICRA 2026", "summary": "Planning over unstructured terrain presents a significant challenge in the field of legged robotics. Although recent works in reinforcement learning have yielded various locomotion strategies, planning over multiple experts remains a complex issue. Existing approaches encounter several constraints: traditional planners are unable to integrate skill-specific policies, whereas hierarchical learning frameworks often lose interpretability and require retraining whenever new policies are added. In this paper, we propose a feasibility-guided planning framework that successfully incorporates multiple terrain-specific policies. Each policy is paired with a Feasibility-Net, which learned to predict feasibility tensors based on the local elevation maps and task vectors. This integration allows classical planning algorithms to derive optimal paths. Through both simulated and real-world experiments, we demonstrate that our method efficiently generates reliable plans across diverse and challenging terrains, while consistently aligning with the capabilities of the underlying policies.", "AI": {"tldr": "This study addresses the complexity of planning over unstructured terrain using legged robots by proposing a framework that integrates terrain-specific policies using feasibility prediction.", "motivation": "The paper aims to tackle limitations in planning over unstructured terrain with legged robots, as existing methods struggle with integrating multiple locomotion strategies while maintaining efficiency and interpretability.", "method": "The approach involves attaching a Feasibility-Net to each terrain-specific policy. These networks predict feasibility tensors using local elevation maps and task vectors, enabling classical planners to generate optimal paths.", "result": "The proposed framework demonstrated success in simulated and real-world experiments, efficiently creating reliable and terrain-adapted plans.", "conclusion": "Feasibility-guided planning presents a robust method of integrating diverse terrain-specific policies for legged robots, offering reliable, interpretable, and adaptable solutions."}}
{"id": "2602.07954", "pdf": "https://arxiv.org/pdf/2602.07954", "abs": "https://arxiv.org/abs/2602.07954", "authors": ["Krzysztof Wr\u00f3bel", "Jan Maria Kowalski", "Jerzy Surma", "Igor Ciuciura", "Maciej Szyma\u0144ski"], "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\\%) and very low false positive rate (0.63\\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\\% precision, 4.70\\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.", "AI": {"tldr": "Bielik Guard introduces compact Polish content safety classifiers excelling in precision and efficiency across five safety categories.", "motivation": "To address the growing need for efficient and accurate content safety in Polish language applications amid the rise of Large Language Models (LLMs).", "method": "Developed two models (0.1B and 0.5B parameters) based on MMLW-RoBERTa-base and PKOBP/polish-roberta-8k, fine-tuning them on a community-annotated dataset of 6,885 Polish texts across five safety categories.", "result": "Both models show strong performance in benchmarks, with superior results from the 0.5B model (F1 scores: 0.791 micro, 0.785 macro), while 0.1B excels in precision (77.65%) and low false positive rate (0.63%).", "conclusion": "Bielik Guard models are efficient and high-performing, publicly available, and prioritize appropriate responses over content blocking, especially for sensitive cases like self-harm."}}
{"id": "2602.07198", "pdf": "https://arxiv.org/pdf/2602.07198", "abs": "https://arxiv.org/abs/2602.07198", "authors": ["Heyuan Li", "Huimin Zhang", "Yuda Qiu", "Zhengwentai Sun", "Keru Zheng", "Lingteng Qiu", "Peihao Li", "Qi Zuo", "Ce Chen", "Yujian Zheng", "Yuming Gu", "Zilong Dong", "Xiaoguang Han"], "title": "Condition Matters in Full-head 3D GANs", "categories": ["cs.CV", "cs.GR"], "comment": "Accepted by ICLR 2026. Project page: https://lhyfst.github.io/balancehead/", "summary": "Conditioning is crucial for stable training of full-head 3D GANs. Without any conditioning signal, the model suffers from severe mode collapse, making it impractical to training. However, a series of previous full-head 3D GANs conventionally choose the view angle as the conditioning input, which leads to a bias in the learned 3D full-head space along the conditional view direction. This is evident in the significant differences in generation quality and diversity between the conditional view and non-conditional views of the generated 3D heads, resulting in global incoherence across different head regions. In this work, we propose to use view-invariant semantic feature as the conditioning input, thereby decoupling the generative capability of 3D heads from the viewing direction. To construct a view-invariant semantic condition for each training image, we create a novel synthesized head image dataset. We leverage FLUX.1 Kontext to extend existing high-quality frontal face datasets to a wide range of view angles. The image clip feature extracted from the frontal view is then used as a shared semantic condition across all views in the extended images, ensuring semantic alignment while eliminating directional bias. This also allows supervision from different views of the same subject to be consolidated under a shared semantic condition, which accelerates training and enhances the global coherence of the generated 3D heads. Moreover, as GANs often experience slower improvements in diversity once the generator learns a few modes that successfully fool the discriminator, our semantic conditioning encourages the generator to follow the true semantic distribution, thereby promoting continuous learning and diverse generation. Extensive experiments on full-head synthesis and single-view GAN inversion demonstrate that our method achieves significantly higher fidelity, diversity, and generalizability.", "AI": {"tldr": "Previous methods for 3D head GAN conditioning using view angles cause directional bias and generation inconsistencies. This paper uses view-invariant semantic features for conditioning to achieve coherent and diverse 3D head generation.", "motivation": "Full-head 3D GANs face challenges such as severe mode collapse without conditioning, and biases from view-angle-based conditioning methods.", "method": "Proposes view-invariant semantic conditioning using novel synthesized dataset and semantic features extracted from frontal face images, eliminating view-direction bias and enhancing coherence.", "result": "Achieved superior fidelity, diversity, and generalizability in full-head synthesis and single-view GAN inversion through semantic conditioning.", "conclusion": "View-invariant semantic conditioning decouples generation from viewing direction, improves training efficiency, diversity, and coherence of 3D heads."}}
{"id": "2602.07992", "pdf": "https://arxiv.org/pdf/2602.07992", "abs": "https://arxiv.org/abs/2602.07992", "authors": ["Daniel Barzilai", "Yotam Wolf", "Ronen Basri"], "title": "When Is Compositional Reasoning Learnable from Verifiable Rewards?", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The emergence of compositional reasoning in large language models through reinforcement learning with verifiable rewards (RLVR) has been a key driver of recent empirical successes. Despite this progress, it remains unclear which compositional problems are learnable in this setting using outcome-level feedback alone. In this work, we theoretically study the learnability of compositional problems in autoregressive models under RLVR training. We identify a quantity that we call the task-advantage ratio, a joint property of the compositional problem and the base model, that characterizes which tasks and compositions are learnable from outcome-level feedback. On the positive side, using this characterization, we show that compositional problems where correct intermediate steps provide a clear advantage are efficiently learnable with RLVR. We also analyze how such an advantage naturally arises in different problems. On the negative side, when the structural advantage is not present, RLVR may converge to suboptimal compositions. We prove that, in some cases, the quality of the base model determines if such an advantage exists and whether RLVR will converge to a suboptimal solution. We hope our analysis can provide a principled theoretical understanding of when and why RLVR succeeds and when it does not.", "AI": {"tldr": "This paper studies the theoretical learnability of compositional tasks in autoregressive models using reinforcement learning with verifiable rewards (RLVR), defining a metric called the task-advantage ratio and analyzing when RLVR succeeds or fails.", "motivation": "Recent advances in large language models via reinforcement learning with verifiable rewards (RLVR) have shown promise, yet the learnability of compositional challenges using outcome-level feedback is not fully understood.", "method": "The paper introduces the task-advantage ratio, a property combining the compositional task and base model, to analyze learnability. It characterizes scenarios where RLVR training succeeds based on structural advantages in intermediate steps and studies how these advantages emerge.", "result": "It finds that tasks with clear intermediate advantages are efficiently learnable under RLVR, while cases lacking such advantages may cause convergence to suboptimal outcomes. The role of the base model in these outcomes is highlighted.", "conclusion": "Understanding the task-advantage ratio and the structural dynamics in RLVR provides insight into when RLVR is a viable solution for compositional reasoning tasks and when it may fail."}}
{"id": "2602.07787", "pdf": "https://arxiv.org/pdf/2602.07787", "abs": "https://arxiv.org/abs/2602.07787", "authors": ["Pierre-Louis Favreau", "Jean-Pierre Lo", "Clement Guiguet", "Charles Simon-Meunier", "Nicolas Dehandschoewercker", "Allen G. Roush", "Judah Goldfeder", "Ravid Shwartz-Ziv"], "title": "Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition", "categories": ["cs.AI"], "comment": null, "summary": "We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use", "AI": {"tldr": "Minitap is a multi-agent system achieving 100% success on AndroidWorld benchmark by addressing key shortcomings in single-agent architectures.", "motivation": "The motivation is to address the limitations of single-agent architectures in solving complex mobile tasks, such as context pollution, undetected text input issues, and action loops.", "method": "Minitap employs a multi-agent system with cognitive separation, deterministic post-validation of text input, and meta-cognitive reasoning to detect and adapt to failures.", "result": "Minitap successfully solves all 116 tasks in the AndroidWorld benchmark, surpassing human performance (80%), with improvements from multi-agent decomposition, execution verification, and meta-cognition.", "conclusion": "Minitap demonstrates the effectiveness of multi-agent systems in outperforming single-agent approaches and achieving state-of-the-art performance on mobile tasks."}}
{"id": "2602.07278", "pdf": "https://arxiv.org/pdf/2602.07278", "abs": "https://arxiv.org/abs/2602.07278", "authors": ["Sai Vamsi Alisetti"], "title": "Laplacian-LoRA: Delaying Oversmoothing in Deep GCNs via Spectral Low-Rank Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages", "summary": "Oversmoothing is a fundamental limitation of deep graph convolutional networks (GCNs), causing node representations to collapse as depth increases. While many prior approaches mitigate this effect through architectural modifications or residual mechanisms, the underlying spectral cause of oversmoothing is often left implicit. We propose Laplacian-LoRA, a simple and interpretable low-rank spectral adaptation of standard GCNs. Rather than redesigning message passing, Laplacian-LoRA introduces a learnable, spectrally anchored correction to the fixed Laplacian propagation operator, selectively weakening contraction while preserving stability and the low-pass inductive bias. Across multiple benchmark datasets and depths, Laplacian-LoRA consistently delays the onset of oversmoothing, extending the effective depth of GCNs by up to a factor of two. Embedding variance diagnostics confirm that these gains arise from delayed representational collapse, while learned spectral analysis demonstrates that the correction is smooth, bounded, and well behaved. Our results show that oversmoothing is a depth-dependent spectral phenomenon that can be systematically delayed through modest, low-rank adaptation of the graph propagation operator.", "AI": {"tldr": "The paper addresses oversmoothing in deep GCNs by proposing Laplacian-LoRA, a low-rank spectral adaptation to delay node representation collapse.", "motivation": "To overcome oversmoothing in deep GCNs, which limits their effectiveness by causing node representations to collapse as networks deepen.", "method": "Proposes Laplacian-LoRA, which introduces a learnable, spectrally anchored correction to the Laplacian propagation operator without redesigning message passing systems.", "result": "Significant improvement in the depth of GCNs by delaying oversmoothing by up to a factor of two with consistent benchmark performance.", "conclusion": "Oversmoothing is a spectral and depth-dependent issue; systematic, low-rank spectral adaptation effectively mitigates it and extends GCN performance."}}
{"id": "2602.08915", "pdf": "https://arxiv.org/pdf/2602.08915", "abs": "https://arxiv.org/abs/2602.08915", "authors": ["Giovanni Pinna", "Jingzhi Gong", "David Williams", "Federica Sarro"], "title": "Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance", "categories": ["cs.SE"], "comment": "Accepted by MSR'26 Mining Challenge Track", "summary": "The rapid adoption of AI-powered coding assistants is transforming software development practices, yet systematic comparisons of their effectiveness across different task types and over time remain limited. This paper presents an empirical study comparing five popular agents (OpenAI Codex, GitHub Copilot, Devin, Cursor, and Claude Code), analyzing 7,156 pull requests (PRs) from the AIDev dataset. Temporal trend analysis reveals heterogeneous evolution patterns: Devin exhibits the only consistent positive trend in acceptance rate (+0.77% per week over 32 weeks), whereas other agents remain largely stable. Our analysis suggests that the PR task type is a dominant factor influencing acceptance rates: documentation tasks achieve 82.1% acceptance compared to 66.1% for new features - a 16 percentage point gap that exceeds typical inter-agent variance for most tasks. OpenAI Codex achieves consistently high acceptance rates across all nine task categories (59.6%-88.6%), with stratified Chi-square tests confirming statistically significant advantages over other agents in several task categories. However, no single agent performs best across all task types: Claude Code leads in documentation (92.3%) and features (72.6%), while Cursor excels in fix tasks (80.4%).", "AI": {"tldr": "The paper evaluates five AI coding agents using 7,156 pull requests, analyzing performance across tasks and over time. Results highlight differences in effectiveness driven by task type.", "motivation": "To assess and compare the effectiveness of AI code assistants in the software development process and understand temporal and task-specific performance patterns.", "method": "Empirical study of 7,156 pull requests from the AIDev dataset comparing five coding agents, with statistical analysis on temporal trends and task-specific effectiveness.", "result": "The study identifies Devin's positive acceptance trend (+0.77% weekly), task-specific performance variations (e.g., documentation tasks showing higher acceptance), and OpenAI Codex achieving consistent rates, but no single agent dominates all tasks.", "conclusion": "AI coding agents differ in effectiveness by task type and time trends, suggesting selection should depend on specific use cases and needs."}}
{"id": "2602.07984", "pdf": "https://arxiv.org/pdf/2602.07984", "abs": "https://arxiv.org/abs/2602.07984", "authors": ["Simon Sagmeister", "Panagiotis Kounatidis", "Sven Goblirsch", "Markus Lienkamp"], "title": "Analyzing the Impact of Simulation Fidelity on the Evaluation of Autonomous Driving Motion Control", "categories": ["cs.RO"], "comment": "Accepted for publication at the IEEE IV 2024", "summary": "Simulation is crucial in the development of autonomous driving software. In particular, assessing control algorithms requires an accurate vehicle dynamics simulation. However, recent publications use models with varying levels of detail. This disparity makes it difficult to compare individual control algorithms. Therefore, this paper aims to investigate the influence of the fidelity of vehicle dynamics modeling on the closed-loop behavior of trajectory-following controllers. For this purpose, we introduce a comprehensive Autoware-compatible vehicle model. By simplifying this, we derive models with varying fidelity. Evaluating over 550 simulation runs allows us to quantify each model's approximation quality compared to real-world data. Furthermore, we investigate whether the influence of model simplifications changes with varying margins to the acceleration limit of the vehicle. From this, we deduce to which degree a vehicle model can be simplified to evaluate control algorithms depending on the specific application. The real-world data used to validate the simulation environment originate from the Indy Autonomous Challenge race at the Autodromo Nazionale di Monza in June 2023. They show the fastest fully autonomous lap of TUM Autonomous Motorsport, with vehicle speeds reaching 267 kph and lateral accelerations of up to 15 mps2.", "AI": {"tldr": "This paper investigates how the fidelity of vehicle dynamics models influences the closed-loop behavior of trajectory-following controllers in autonomous driving simulations. Models of varying complexity are tested and validated against real-world racing data.", "motivation": "The paper addresses the difficulty of comparing control algorithms in autonomous driving due to inconsistencies in the level of detail in vehicle dynamics models.", "method": "The authors developed a comprehensive Autoware-compatible vehicle model and derived simplified versions. Over 550 simulation runs were conducted to evaluate the impact of model fidelity and validate results against real-world data.", "result": "The study quantifies how differences in model fidelity affect trajectory-following controller performance. It examines how these differences change with adjustments in acceleration limit margins.", "conclusion": "The paper concludes on the extent to which vehicle dynamics models can be simplified for evaluating control algorithms depending on the application, validated using extreme real-world autonomous race data achieving high speeds and accelerations."}}
{"id": "2602.07963", "pdf": "https://arxiv.org/pdf/2602.07963", "abs": "https://arxiv.org/abs/2602.07963", "authors": ["Vaibhav Shukla", "Hardik Sharma", "Adith N Reganti", "Soham Wasmatkar", "Bagesh Kumar", "Vrijendra Singh"], "title": "Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at the AICS Workshop, AAAI 2026", "summary": "Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.", "AI": {"tldr": "The paper introduces CompositeHarm, a benchmark to study safety alignment of large language models (LLMs) across languages, finding that adversarial harms often intensify in Indic languages when syntactic changes occur.", "motivation": "Investigate whether translations capture the full spectrum of multilingual safety behaviors and further understand how harms transfer across languages in LLMs.", "method": "CompositeHarm benchmark combines two English datasets (AttaQ and MMSafetyBench) and translates them into six languages, testing model performance using lightweight inference strategies for scalability.", "result": "The study reveals that attack success rates increase prominently in Indic languages under adversarial syntax, while contextual harms transfer more moderately.", "conclusion": "Benchmark translation is an essential but insufficient step for multilingual safety; scalable and resource-aware testing systems are crucial for better alignment."}}
{"id": "2602.07212", "pdf": "https://arxiv.org/pdf/2602.07212", "abs": "https://arxiv.org/abs/2602.07212", "authors": ["Xinyu Liu", "Darryl C. Jacob", "Yuxin Liu", "Xinsong Du", "Muchao Ye", "Bolei Zhou", "Pan He"], "title": "Understanding Real-World Traffic Safety through RoadSafe365 Benchmark", "categories": ["cs.CV"], "comment": null, "summary": "Although recent traffic benchmarks have advanced multimodal data analysis, they generally lack systematic evaluation aligned with official safety standards. To fill this gap, we introduce RoadSafe365, a large-scale vision-language benchmark that supports fine-grained analysis of traffic safety from extensive and diverse real-world video data collections. Unlike prior works that focus primarily on coarse accident identification, RoadSafe365 is independently curated and systematically organized using a hierarchical taxonomy that refines and extends foundational definitions of crash, incident, and violation to bridge official traffic safety standards with data-driven traffic understanding systems. RoadSafe365 provides rich attribute annotations across diverse traffic event types, environmental contexts, and interaction scenarios, yielding 36,196 annotated clips from both dashcam and surveillance cameras. Each clip is paired with multiple-choice question-answer sets, comprising 864K candidate options, 8.4K unique answers, and 36K detailed scene descriptions collectively designed for vision-language understanding and reasoning. We establish strong baselines and observe consistent gains when fine-tuning on RoadSafe365. Cross-domain experiments on both real and synthetic datasets further validate its effectiveness. Designed for large-scale training and standardized evaluation, RoadSafe365 provides a comprehensive benchmark to advance reproducible research in real-world traffic safety analysis.", "AI": {"tldr": "RoadSafe365 is a comprehensive benchmark enabling fine-grained traffic safety analysis using annotated real-world video data.", "motivation": "Current traffic benchmarks lack alignment with official safety standards for systematic evaluation.", "method": "Introduced RoadSafe365 with a hierarchical taxonomy, annotated videos, and vision-language tasks for traffic safety analysis.", "result": "RoadSafe365 contains 36,196 annotated clips, question-answer sets, and baselines showing consistent gains on safety analysis tasks.", "conclusion": "RoadSafe365 bridges traffic safety standards with data-driven systems and supports reproducible research in vision-language benchmarks."}}
{"id": "2602.07824", "pdf": "https://arxiv.org/pdf/2602.07824", "abs": "https://arxiv.org/abs/2602.07824", "authors": ["Yiwei Qin", "Zhen Huang", "Tiantian Mi", "Weiye Si", "Chenyang Zhou", "Qipeng Guo", "Siyuan Feng", "Pengfei Liu"], "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.\n  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.", "AI": {"tldr": "The paper presents \"Data Darwinism,\" a 10-level taxonomy for data-model co-evolution, and validates it using a 900B-token scientific corpus and novel pre-trained models, showing performance gains with systematic data refinement.", "motivation": "To address the lack of systematic frameworks for high-quality data processing in foundational model training and demonstrate data-model co-evolution using advanced taxonomy.", "method": "Development of a 10-level taxonomy for data processing (L0-L9), construction of the 900B-token corpus (Darwin-Science), and pre-training contamination-free models to test the framework's performance enhancement.", "result": "Darwin-Science outperformed baselines by up to +8.40 points on domain-aligned tasks, with systematic data refinement contributing +1.36 points in improvement.", "conclusion": "Higher-level data processing enables better utilization of data, enhancing model performance and supporting the co-evolutionary development of foundational models."}}
{"id": "2602.07279", "pdf": "https://arxiv.org/pdf/2602.07279", "abs": "https://arxiv.org/abs/2602.07279", "authors": ["Bruno Belucci", "Karim Lounici", "Vladimir R. Kostic", "Katia Meziani"], "title": "VertCoHiRF: Decentralized Vertical Clustering Beyond k-means", "categories": ["cs.LG"], "comment": null, "summary": "Vertical Federated Learning (VFL) enables collaborative analysis across parties holding complementary feature views of the same samples, yet existing approaches are largely restricted to distributed variants of $k$-means, requiring centralized coordination or the exchange of feature-dependent numerical statistics, and exhibiting limited robustness under heterogeneous views or adversarial behavior. We introduce VertCoHiRF, a fully decentralized framework for vertical federated clustering based on structural consensus across heterogeneous views, allowing each agent to apply a base clustering method adapted to its local feature space in a peer-to-peer manner. Rather than exchanging feature-dependent statistics or relying on noise injection for privacy, agents cluster their local views independently and reconcile their proposals through identifier-level consensus. Consensus is achieved via decentralized ordinal ranking to select representative medoids, progressively inducing a shared hierarchical clustering across agents. Communication is limited to sample identifiers, cluster labels, and ordinal rankings, providing privacy by design while supporting overlapping feature partitions and heterogeneous local clustering methods, and yielding an interpretable shared Cluster Fusion Hierarchy (CFH) that captures cross-view agreement at multiple resolutions.We analyze communication complexity and robustness, and experiments demonstrate competitive clustering performance in vertical federated settings.", "AI": {"tldr": "The paper introduces VertCoHiRF, a decentralized framework for federated clustering, enabling multiple agents to collaborate on clustering tasks without sharing raw data, ensuring privacy and maintaining effectiveness under heterogeneous settings.", "motivation": "Existing Vertical Federated Learning methods are restricted to $k$-means and require centralized coordination or data-related exchanges, which lack robustness in heterogeneous or adversarial environments.", "method": "VertCoHiRF allows agents to independently cluster their views using local feature spaces and reconcile them through identifier-level consensus, employing decentralized ordinal ranking to establish shared clustering hierarchies across multiple views.", "result": "The method achieves competitive clustering performance, ensures privacy, and supports heterogeneous methods and overlapping feature partitions while preserving communication efficiency and robustness.", "conclusion": "VertCoHiRF provides a robust, privacy-preserving framework for vertical federated clustering, relying on structural consensus and minimal communication without central dependencies."}}
{"id": "2507.02424", "pdf": "https://arxiv.org/pdf/2507.02424", "abs": "https://arxiv.org/abs/2507.02424", "authors": ["Francesco Blefari", "Cristian Cosentino", "Francesco Aurelio Pironti", "Angelo Furfaro", "Fabrizio Marozzo"], "title": "CyberRAG: An Agentic RAG cyber attack classification and reporting tool", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming analysts with logs requiring rapidly evolving expertise. Conventional machine-learning detectors reduce alert volume but still yield many false positives, while standard Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify predictions. We present CyberRAG, a modular agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates: (i) fine-tuned classifiers specialized by attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that queries a domain-specific knowledge base until evidence is relevant and self-consistent. Unlike traditional RAG, CyberRAG adopts an agentic design that enables dynamic control flow and adaptive reasoning. This architecture autonomously refines threat labels and natural-language justifications, reducing false positives and enhancing interpretability. It is also extensible: new attack types can be supported by adding classifiers without retraining the core agent. CyberRAG was evaluated on SQL Injection, XSS, and SSTI, achieving over 94\\% accuracy per class and a final classification accuracy of 94.92\\% through semantic orchestration. Generated explanations reached 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation, with robustness preserved against adversarial and unseen payloads. These results show that agentic, specialist-oriented RAG can combine high detection accuracy with trustworthy, SOC-ready prose, offering a flexible path toward partially automated cyber-defense workflows.", "AI": {"tldr": "CyberRAG is a flexible modular RAG system for cyber-attack detection, delivering high accuracy, reliable explanations, and dynamic adaptability.", "motivation": "The paper aims to address the challenge of overwhelming false positives and irrelevant context retrieval in intrusion detection systems (IDS/IPS) by creating a more accurate, interpretable, and adaptable solution for cybersecurity threats.", "method": "The method involves CyberRAG, a modular RAG framework using LLM-based orchestration, specialized classifiers, and iterative retrieval mechanisms to classify and justify cyber-attack alerts while being adaptable to new attack types without core retraining.", "result": "CyberRAG demonstrated 94.92% final classification accuracy and high-quality natural language justifications with a BERTScore of 0.94 and 4.9/5 in GPT-4-based expert evaluation. It also maintained robustness against adversarial and unseen attack payloads.", "conclusion": "CyberRAG provides a scalable, accurate, and interpretable cyber-defense solution capable of reducing false positives and enhancing SOC workflows with trustworthy and dynamic alert processing."}}
{"id": "2602.08116", "pdf": "https://arxiv.org/pdf/2602.08116", "abs": "https://arxiv.org/abs/2602.08116", "authors": ["Jiawei Xu", "Subhrajit Bhattacharya", "David Salda\u00f1a"], "title": "From Ellipsoids to Midair Control of Dynamic Hitches", "categories": ["cs.RO"], "comment": null, "summary": "The ability to dynamically manipulate interaction between cables, carried by pairs of aerial vehicles attached to the ends of each cable, can greatly improve the versatility and agility of cable-assisted aerial manipulation. Such interlacing cables create hitches by winding two or more cables around each other, which can enclose payloads or can further develop into knots. Dynamic modeling and control of such hitches is key to mastering the inter-cable manipulation in context of cable-suspended aerial manipulation. This paper introduces an ellipsoid-based kinematic model to connect the geometric nature of a hitch created by two cables and the dynamics of the hitch driven by four aerial vehicles, which reveals the control-affine form of the system. As the constraint for maintaining tension of a cable is also control-affine, we design a quadratic programming-based controller that combines Control Lyapunov and High-Order Control Barrier Functions (CLF-HOCBF-QP) to precisely track a desired hitch position and system shape while enforcing safety constraints like cable tautness. We convert desired geometric reference configurations into target robot positions and introduce a composite error into the Lyapunov function to ensure a relative degree of one to the input. Numerical simulations validate our approach, demonstrating stable, high-speed tracking of dynamic references.", "AI": {"tldr": "The paper presents a dynamic model and control framework for cable hitches created by aerial vehicles, improving dynamic cable manipulation.", "motivation": "To enhance versatility and control in cable-assisted aerial manipulation through interlacing cable techniques that create hitches to enclose payloads or form knots.", "method": "An ellipsoid-based kinematic model links the geometry of cable hitches to their dynamics. A CLF-HOCBF-QP-based controller is employed to track desired positions and ensure safety constraints like cable tautness.", "result": "The proposed approach achieves stable and high-speed tracking of dynamic references in numerical simulations, validating its effectiveness.", "conclusion": "The study successfully introduces a dynamic model and a robust control system for precise, safe, and versatile cable manipulation using aerial vehicles."}}
{"id": "2602.07978", "pdf": "https://arxiv.org/pdf/2602.07978", "abs": "https://arxiv.org/abs/2602.07978", "authors": ["Rui Feng", "Zhiyao Luo", "Liuyu Wu", "Wei Wang", "Yuting Song", "Yong Liu", "Kok Pin Ng", "Jianqing Li", "Xingyao Wang"], "title": "Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection", "categories": ["cs.CL"], "comment": "18 pages, 7 figures, 6 tables", "summary": "Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.", "AI": {"tldr": "SynCog proposes a novel framework for MCI diagnostics using speech-based digital biomarkers to overcome data scarcity and enable cross-lingual generalization.", "motivation": "The study aims to address the challenges in speech-based biomarkers for detecting Mild Cognitive Impairment, including data scarcity, lack of transparent reasoning in diagnostics, and poor cross-lingual adaptability.", "method": "SynCog uses controllable zero-shot multimodal data synthesis to generate diverse virtual subjects and fine-tunes Multimodal Large Language Models with Chain-of-Thought deduction strategies for transparent clinical diagnostics.", "result": "The framework achieved competitive Macro-F1 scores of 80.67% and 78.46% on ADReSS and ADReSSo benchmarks while demonstrating strong cross-linguistic generalization with a Macro-F1 of 48.71% on Mandarin cohort tests.", "conclusion": "The SynCog framework is a promising step for scalable, transparent, and linguistically inclusive cognitive diagnostic tools for global healthcare settings."}}
{"id": "2602.07251", "pdf": "https://arxiv.org/pdf/2602.07251", "abs": "https://arxiv.org/abs/2602.07251", "authors": ["Haley Duba-Sullivan", "Steven R. Young", "Emma J. Reid"], "title": "The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Data-driven super-resolution (SR) methods are often integrated into imaging pipelines as preprocessing steps to improve downstream tasks such as classification and detection. However, these SR models introduce a previously unexplored attack surface into imaging pipelines. In this paper, we present AdvSR, a framework demonstrating that adversarial behavior can be embedded directly into SR model weights during training, requiring no access to inputs at inference time. Unlike prior attacks that perturb inputs or rely on backdoor triggers, AdvSR operates entirely at the model level. By jointly optimizing for reconstruction quality and targeted adversarial outcomes, AdvSR produces models that appear benign under standard image quality metrics while inducing downstream misclassification. We evaluate AdvSR on three SR architectures (SRCNN, EDSR, SwinIR) paired with a YOLOv11 classifier and demonstrate that AdvSR models can achieve high attack success rates with minimal quality degradation. These findings highlight a new model-level threat for imaging pipelines, with implications for how practitioners source and validate models in safety-critical applications.", "AI": {"tldr": "AdvSR reveals a model-level threat where adversarial behavior is embedded in super-resolution (SR) models during training to mislead downstream tasks, maintaining top-tier reconstruction quality.", "motivation": "Exploring adversarial vulnerabilities within SR models integrated into imaging pipelines, highlighting potential risks in safety-critical applications.", "method": "AdvSR embeds adversarial behavior into SR model weights during training, without relying on input access or backdoor triggers, jointly optimizing for quality and adversarial outputs.", "result": "AdvSR achieves high attack success rates while preserving reconstruction quality, as tested with SRCNN, EDSR, and SwinIR on YOLOv11 classifiers.", "conclusion": "AdvSR introduces a new threat to imaging pipelines, emphasizing the importance of inspecting and validating SR models for potential adversarial risks in critical systems."}}
{"id": "2602.08026", "pdf": "https://arxiv.org/pdf/2602.08026", "abs": "https://arxiv.org/abs/2602.08026", "authors": ["Arya Akhavan", "David Janz", "Csaba Szepesv\u00e1ri"], "title": "Sharp analysis of linear ensemble sampling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We analyse linear ensemble sampling (ES) with standard Gaussian perturbations in stochastic linear bandits. We show that for ensemble size $m=\u0398(d\\log n)$, ES attains $\\tilde O(d^{3/2}\\sqrt n)$ high-probability regret, closing the gap to the Thompson sampling benchmark while keeping computation comparable. The proof brings a new perspective on randomized exploration in linear bandits by reducing the analysis to a time-uniform exceedance problem for $m$ independent Brownian motions. Intriguingly, this continuous-time lens is not forced; it appears natural--and perhaps necessary: the discrete-time problem seems to be asking for a continuous-time solution, and we know of no other way to obtain a sharp ES bound.", "AI": {"tldr": "This paper provides a regret analysis for linear ensemble sampling in stochastic linear bandits and demonstrates its effectiveness compared to Thompson sampling.", "motivation": "To close the performance gap between linear ensemble sampling (ES) and the Thompson sampling benchmark while maintaining computational efficiency.", "method": "The authors studied ES with Gaussian perturbations in linear bandits, showing high-probability regret bounds using an analysis based on time-uniform exceedance and independent Brownian motions.", "result": "ES achieves $\\tilde{O}(d^{3/2}\\sqrt{n})$ regret for ensemble size $m=\u0398(d\\log n)$, comparable to the Thompson sampling benchmark.", "conclusion": "Linear ensemble sampling can match Thompson sampling's regret bounds with efficient computation, using a novel approach involving continuous-time analysis."}}
{"id": "2602.07830", "pdf": "https://arxiv.org/pdf/2602.07830", "abs": "https://arxiv.org/abs/2602.07830", "authors": ["Jiahui Zhou", "Dan Li", "Boxin Li", "Xiao Zhang", "Erli Meng", "Lin Li", "Zhuomin Chen", "Jian Lou", "See-Kiong Ng"], "title": "Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.", "AI": {"tldr": "VeriTime introduces a method to enhance large language models (LLMs) for time series reasoning using a synthesized multimodal dataset, data scheduling, and reinforcement learning (RL) finetuning.", "motivation": "To address challenges in time series reasoning with LLMs, including lack of suitable Chain-of-Thought data, data efficiency issues, and absence of tailored RL algorithms.", "method": "The VeriTime framework employs three approaches: 1) Data synthesis for creating a multimodal TS-text dataset with verifiable annotations; 2) Data scheduling based on difficulty and task taxonomy; 3) A two-stage RL finetuning using multi-objective rewards and process-level CoT data.", "result": "VeriTime enhances LLM reasoning across diverse time series tasks and allows compact models (3B, 4B) to achieve or surpass larger proprietary LLM performance.", "conclusion": "The proposed framework demonstrates how tailored data strategies and specialized RL finetuning can significantly improve LLM reasoning for time series tasks."}}
{"id": "2602.07285", "pdf": "https://arxiv.org/pdf/2602.07285", "abs": "https://arxiv.org/abs/2602.07285", "authors": ["Etam Benger", "Katrina Ligett"], "title": "Fair Decisions from Calibrated Scores: Achieving Optimal Classification While Satisfying Sufficiency", "categories": ["cs.LG"], "comment": null, "summary": "Binary classification based on predicted probabilities (scores) is a fundamental task in supervised machine learning. While thresholding scores is Bayes-optimal in the unconstrained setting, using a single threshold generally violates statistical group fairness constraints. Under independence (statistical parity) and separation (equalized odds), such thresholding suffices when the scores already satisfy the corresponding criterion. However, this does not extend to sufficiency: even perfectly group-calibrated scores -- including true class probabilities -- violate predictive parity after thresholding. In this work, we present an exact solution for optimal binary (randomized) classification under sufficiency, assuming finite sets of group-calibrated scores. We provide a geometric characterization of the feasible pairs of positive predictive value (PPV) and false omission rate (FOR) achievable by such classifiers, and use it to derive a simple post-processing algorithm that attains the optimal classifier using only group-calibrated scores and group membership. Finally, since sufficiency and separation are generally incompatible, we identify the classifier that minimizes deviation from separation subject to sufficiency, and show that it can also be obtained by our algorithm, often achieving performance comparable to the optimum.", "AI": {"tldr": "The paper discusses a method to achieve optimal binary classification under statistical group fairness constraints, specifically focusing on sufficiency, using a post-processing algorithm.", "motivation": "To address the challenge of achieving fair binary classification under sufficiency constraints, particularly when group-calibrated scores violate fairness after thresholding.", "method": "A geometric characterization of achievable positive predictive value (PPV) and false omission rate (FOR) pairs is provided, followed by a post-processing algorithm that utilizes group-calibrated scores and group membership.", "result": "The proposed algorithm optimizes classification under sufficiency constraints and minimizes deviation from separation, often achieving near-optimal performance.", "conclusion": "The approach provides a practical solution for fair binary classification under sufficiency, reconciling statistical parity and performance considerations."}}
{"id": "2602.08167", "pdf": "https://arxiv.org/pdf/2602.08167", "abs": "https://arxiv.org/abs/2602.08167", "authors": ["Milan Ganai", "Katie Luo", "Jonas Frey", "Clark Barrett", "Marco Pavone"], "title": "Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Embodied Chain-of-Thought (CoT) reasoning has significantly enhanced Vision-Language-Action (VLA) models, yet current methods rely on rigid templates to specify reasoning primitives (e.g., objects in the scene, high-level plans, structural affordances). These templates can force policies to process irrelevant information that distracts from critical action-prediction signals. This creates a bottleneck: without successful policies, we cannot verify reasoning quality; without quality reasoning, we cannot build robust policies. We introduce R&B-EnCoRe, which enables models to bootstrap embodied reasoning from internet-scale knowledge through self-supervised refinement. By treating reasoning as a latent variable within importance-weighted variational inference, models can generate and distill a refined reasoning training dataset of embodiment-specific strategies without external rewards, verifiers, or human annotation. We validate R&B-EnCoRe across manipulation (Franka Panda in simulation, WidowX in hardware), legged navigation (bipedal, wheeled, bicycle, quadruped), and autonomous driving embodiments using various VLA architectures with 1B, 4B, 7B, and 30B parameters. Our approach achieves 28% gains in manipulation success, 101% improvement in navigation scores, and 21% reduction in collision-rate metric over models that indiscriminately reason about all available primitives. R&B-EnCoRe enables models to distill reasoning that is predictive of successful control, bypassing manual annotation engineering while grounding internet-scale knowledge in physical execution.", "AI": {"tldr": "The paper introduces R&B-EnCoRe, a framework to enhance reasoning in Vision-Language-Action models using self-supervised refinement, avoiding rigid templates and manual annotations.", "motivation": "Existing Embodied Chain-of-Thought methods rely on rigid reasoning templates that distract from action prediction, limiting policy success and reasoning quality.", "method": "The authors propose R&B-EnCoRe, which treats reasoning as a latent variable in importance-weighted variational inference, creating a refined dataset of embodiment-specific strategies through self-supervision.", "result": "R&B-EnCoRe improves manipulation success by 28%, navigation scores by 101%, and reduces collision rates by 21% across various architectures and robotic embodiments.", "conclusion": "R&B-EnCoRe provides a scalable, annotation-free framework that grounds internet-scale knowledge into physical reasoning, leading to significant performance gains in embodied tasks."}}
{"id": "2602.07996", "pdf": "https://arxiv.org/pdf/2602.07996", "abs": "https://arxiv.org/abs/2602.07996", "authors": ["Arash Marioriyad", "Omid Ghahroodi", "Ehsaneddin Asgari", "Mohammad Hossein Rohban", "Mahdieh Soleymani Baghshah"], "title": "The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.", "AI": {"tldr": "This paper evaluates the reliability of large language models (LLMs) as automatic judges using controlled cue perturbations across two datasets, highlighting issues with verdict sensitivity and acknowledgment gaps.", "motivation": "The study aims to assess whether LLM-based judges are truly impartial and reliable. Concerns center around their susceptibility to irrelevant contextual cues and the transparency of their decision-making processes.", "method": "The researchers tested six LLM judge models using controlled cue perturbations, introducing synthetic metadata labels in prompts. They used two datasets, ELI5 (factual QA) and LitBench (open-ended creative writing), and tracked changes in verdicts using two metrics: Verdict Shift Rate (VSR) and Cue Acknowledgment Rate (CAR).", "result": "The study observed that injected cues often altered model verdicts significantly (high VSR), but models largely failed to acknowledge these cues in their justifications (low CAR). Effects varied between datasets, with more acknowledgment occurring in factual setups (ELI5) but collapsing in creative contexts (LitBench).", "conclusion": "LLMs exhibit both significant sensitivity to irrelevant cues and limited acknowledgment of those factors in their reasoning, creating an explanation gap that undermines their reliability as unbiased judges in automated evaluations."}}
{"id": "2602.07260", "pdf": "https://arxiv.org/pdf/2602.07260", "abs": "https://arxiv.org/abs/2602.07260", "authors": ["Hongyu Kan", "Kristofor Pas", "Ivan Medri", "Naqib Sad Pathan", "Natasha Ironside", "Shinjini Kundu", "Jingjia He", "Gustavo Kunde Rohde"], "title": "3D Transport-based Morphometry (3D-TBM) for medical image analysis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Transport-Based Morphometry (TBM) has emerged as a new framework for 3D medical image analysis. By embedding images into a transport domain via invertible transformations, TBM facilitates effective classification, regression, and other tasks using transport-domain features. Crucially, the inverse mapping enables the projection of analytic results back into the original image space, allowing researchers to directly interpret clinical features associated with model outputs in a spatially meaningful way. To facilitate broader adoption of TBM in clinical imaging research, we present 3D-TBM, a tool designed for morphological analysis of 3D medical images. The framework includes data preprocessing, computation of optimal transport embeddings, and analytical methods such as visualization of main transport directions, together with techniques for discerning discriminating directions and related analysis methods. We also provide comprehensive documentation and practical tutorials to support researchers interested in applying 3D-TBM in their own medical imaging studies. The source code is publicly available through PyTransKit.", "AI": {"tldr": "The paper introduces 3D-TBM, a tool that implements Transport-Based Morphometry for analyzing 3D medical images, enabling feature interpretation and offering documentation and tutorials.", "motivation": "Facilitate broader adoption of Transport-Based Morphometry (TBM) for 3D medical image analysis and provide tools to interpret outputs in a clinically meaningful way.", "method": "Developed a framework called 3D-TBM, which includes preprocessing, optimal transport embeddings, visualization of transport directions, and discriminating analysis techniques.", "result": "3D-TBM was implemented as a comprehensive tool with practical tutorials and documentation, making it accessible for researchers through PyTransKit.", "conclusion": "3D-TBM simplifies the use of TBM in clinical imaging, enhancing usability and interpretability of medical image-based analyses."}}
{"id": "2602.08096", "pdf": "https://arxiv.org/pdf/2602.08096", "abs": "https://arxiv.org/abs/2602.08096", "authors": ["Brian M Cho", "Raaz Dwivedi", "Nathan Kallus"], "title": "GAAVI: Global Asymptotic Anytime Valid Inference for the Conditional Mean Function", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Inference on the conditional mean function (CMF) is central to tasks from adaptive experimentation to optimal treatment assignment and algorithmic fairness auditing. In this work, we provide a novel asymptotic anytime-valid test for a CMF global null (e.g., that all conditional means are zero) and contrasts between CMFs, enabling experimenters to make high confidence decisions at any time during the experiment beyond a minimum sample size. We provide mild conditions under which our tests achieve (i) asymptotic type-I error guarantees, (i) power one, and, unlike past tests, (iii) optimal sample complexity relative to a Gaussian location testing. By inverting our tests, we show how to construct function-valued asymptotic confidence sequences for the CMF and contrasts thereof. Experiments on both synthetic and real-world data show our method is well-powered across various distributions while preserving the nominal error rate under continuous monitoring.", "AI": {"tldr": "This work introduces a novel asymptotic test for conditional mean function (CMF) inference during experiments, providing high confidence anytime-valid decisions with mild statistical guarantees.", "motivation": "The motivation is to improve statistical inference in experimental settings, enabling robust and effective decision-making at any point during the experiment, which has applications spanning adaptive experimentation and fairness auditing.", "method": "The paper provides an asymptotic anytime-valid test for CMF null hypotheses and contrasts, paired with conditions for achieving error control, power one, and sample complexity optimality relative to Gaussian testing.", "result": "Experimental validation demonstrates that the proposed method is well-powered across different distributions while maintaining nominal error rates under continuous monitoring.", "conclusion": "The method enables constructing asymptotic confidence sequences for CMF and contrasts, offering effective solutions to experimental and decision-making challenges in statistical inference."}}
{"id": "2602.07849", "pdf": "https://arxiv.org/pdf/2602.07849", "abs": "https://arxiv.org/abs/2602.07849", "authors": ["Xin Wang", "Hualin Zhou", "Sheng Guang Wang", "Ting Dang", "Yu Zhang", "Hong Jia", "Tao Gu"], "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge", "categories": ["cs.AI"], "comment": "16 pages, 9 figures ,9 tables, preprint", "summary": "Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.", "AI": {"tldr": "The paper presents LQA, a new framework for deploying Vision-Language Models (VLMs) on edge devices, solving resource constraints and adaptation challenges with improved performance and efficiency.", "motivation": "Existing Vision-Language Models (VLMs) face resource limitations and performance drops on edge devices, especially under distribution shifts, necessitating lightweight and effective test-time adaptation solutions.", "method": "LQA utilizes Selective Hybrid Quantization (SHQ) and gradient-free test-time adaptation to achieve efficiency. SHQ introduces modality-aware quantization while avoiding gradients for adaptation, ensuring a lightweight approach for edge devices.", "result": "Experimental results show that LQA improves adaptation performance by 4.5%, reduces memory usage below full-precision models, and outperforms gradient-based adaptation methods with up to 19.9\u00d7 lower memory usage across multiple datasets.", "conclusion": "LQA provides a robust solution for efficient, privacy-preserving Vision-Language Model deployment on edge devices, addressing resource constraints and maintaining performance during distribution shifts."}}
{"id": "2602.07320", "pdf": "https://arxiv.org/pdf/2602.07320", "abs": "https://arxiv.org/abs/2602.07320", "authors": ["Philip Jacobson", "Ben Feinberg", "Suhas Kumar", "Sapan Agarwal", "T. Patrick Xiao", "Christopher Bennett"], "title": "Incorruptible Neural Networks: Training Models that can Generalize to Large Internal Perturbations", "categories": ["cs.LG"], "comment": null, "summary": "Flat regions of the neural network loss landscape have long been hypothesized to correlate with better generalization properties. A closely related but distinct problem is training models that are robust to internal perturbations to their weights, which may be an important need for future low-power hardware platforms. In this paper, we explore the usage of two methods, sharpness-aware minimization (SAM) and random-weight perturbation (RWP), to find minima robust to a variety of random corruptions to weights. We consider the problem from two angles: generalization (how do we reduce the noise-robust generalization gap) and optimization (how do we maximize performance from optimizers when subject to strong perturbations). First, we establish, both theoretically and empirically, that an over-regularized RWP training objective is optimal for noise-robust generalization. For small-magnitude noise, we find that SAM's adversarial objective further improves performance over any RWP configuration, but performs poorly for large-magnitude noise. We link the cause of this to a vanishing-gradient effect, caused by unevenness in the loss landscape, affecting both SAM and RWP. Lastly, we demonstrate that dynamically adjusting the perturbation strength to match the evolution of the loss landscape improves optimizing for these perturbed objectives.", "AI": {"tldr": "This study examines how sharpness-aware minimization (SAM) and random-weight perturbation (RWP) influence noise-robust model generalization by mitigating weight perturbations in neural networks.", "motivation": "The paper aims to improve model robustness to internal perturbations in neural network weights, which is essential for better generalization and critical for future low-power hardware platforms.", "method": "The authors use SAM and RWP to study solutions robust to weight corruptions, analyzing generalization (noise-robust gaps) and optimization (performance under perturbations). They propose dynamically adjusting perturbation strength to enhance results.", "result": "SAM improves performance for small noise, while RWP is more suitable for large noise conditions. A vanishing-gradient issue was identified under large perturbations, influencing both SAM and RWP.", "conclusion": "Dynamically matching perturbation strength with the loss landscape evolution enhances optimization for training objectives under noise-robust scenarios."}}
{"id": "2602.08189", "pdf": "https://arxiv.org/pdf/2602.08189", "abs": "https://arxiv.org/abs/2602.08189", "authors": ["Seoyeon Jang", "Alex Junho Lee", "I Made Aswin Nahrendra", "Hyun Myung"], "title": "Chamelion: Reliable Change Detection for Long-Term LiDAR Mapping in Transient Environments", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, IEEE Robot. Automat. Lett. (RA-L) 2026", "summary": "Online change detection is crucial for mobile robots to efficiently navigate through dynamic environments. Detecting changes in transient settings, such as active construction sites or frequently reconfigured indoor spaces, is particularly challenging due to frequent occlusions and spatiotemporal variations. Existing approaches often struggle to detect changes and fail to update the map across different observations. To address these limitations, we propose a dual-head network designed for online change detection and long-term map maintenance. A key difficulty in this task is the collection and alignment of real-world data, as manually registering structural differences over time is both labor-intensive and often impractical. To overcome this, we develop a data augmentation strategy that synthesizes structural changes by importing elements from different scenes, enabling effective model training without the need for extensive ground-truth annotations. Experiments conducted at real-world construction sites and in indoor office environments demonstrate that our approach generalizes well across diverse scenarios, achieving efficient and accurate map updates.\\resubmit{Our source code and additional material are available at: https://chamelion-pages.github.io/.", "AI": {"tldr": "This paper introduces a dual-head network for online change detection and long-term map maintenance for mobile robots in dynamic environments, using a novel data augmentation strategy to address challenges in real-world data collection.", "motivation": "The motivation is to enable mobile robots to efficiently navigate and adapt to highly dynamic and occluded environments like construction sites or frequently changed indoor spaces.", "method": "The authors propose a dual-head network designed for change detection and map updating, with a data augmentation strategy that synthesizes structural changes by importing elements across scenes for better training.", "result": "The approach was tested in real-world construction sites and indoor offices, showing it generalizes well across diverse scenarios with efficient and accurate map updates.", "conclusion": "The proposed system effectively handles challenges in change detection and map maintenance for mobile robots, proving its efficacy across dynamic and occluded environments."}}
{"id": "2602.08005", "pdf": "https://arxiv.org/pdf/2602.08005", "abs": "https://arxiv.org/abs/2602.08005", "authors": ["Jitai Hao", "Qiang Huang", "Yaowei Wang", "Min Zhang", "Jun Yu"], "title": "DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity", "categories": ["cs.CL", "cs.AI"], "comment": "preprint", "summary": "The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.", "AI": {"tldr": "DeltaKV introduces a residual-based KV cache compression technique and Sparse-vLLM for efficient long-context LLMs, achieving significant memory reduction and system speedups.", "motivation": "Current long-context LLMs face challenges due to linear KV cache memory growth, and existing methods fail to balance accuracy, compression ratio, and hardware efficiency.", "method": "DeltaKV compresses KV cache by encoding semantic residuals instead of discarding tokens, while Sparse-vLLM offers optimized memory management and sparse kernel support for efficient inference.", "result": "Experiments show a 71% reduction in KV cache memory usage with near-lossless accuracy, along with up to 2\u00d7 system throughput improvement using Sparse-vLLM.", "conclusion": "DeltaKV and Sparse-vLLM enable scalable, memory- and throughput-efficient long-context LLM deployment, making them practical for real-world applications."}}
{"id": "2602.07262", "pdf": "https://arxiv.org/pdf/2602.07262", "abs": "https://arxiv.org/abs/2602.07262", "authors": ["Junbo Jacob Lian", "Feng Xiong", "Yujun Sun", "Kaichen Ouyang", "Mingyang Yu", "Shengwei Fu", "Zhong Rui", "Zhang Yujun", "Huiling Chen"], "title": "TwistNet-2D: Learning Second-Order Channel Interactions via Spiral Twisting for Texture Recognition", "categories": ["cs.CV"], "comment": "Code is available at https://github.com/junbolian/TwistNet-2D", "summary": "Second-order feature statistics are central to texture recognition, yet current methods face a fundamental tension: bilinear pooling and Gram matrices capture global channel correlations but collapse spatial structure, while self-attention models spatial context through weighted aggregation rather than explicit pairwise feature interactions. We introduce TwistNet-2D, a lightweight module that computes \\emph{local} pairwise channel products under directional spatial displacement, jointly encoding where features co-occur and how they interact. The core component, Spiral-Twisted Channel Interaction (STCI), shifts one feature map along a prescribed direction before element-wise channel multiplication, thereby capturing the cross-position co-occurrence patterns characteristic of structured and periodic textures. Aggregating four directional heads with learned channel reweighting and injecting the result through a sigmoid-gated residual path, \\TwistNet incurs only 3.5% additional parameters and 2% additional FLOPs over ResNet-18, yet consistently surpasses both parameter-matched and substantially larger baselines -- including ConvNeXt, Swin Transformer, and hybrid CNN--Transformer architectures -- across four texture and fine-grained recognition benchmarks.", "AI": {"tldr": "The paper introduces TwistNet-2D, a module designed to efficiently capture local pairwise feature interactions for better texture recognition without adding significant computational overhead.", "motivation": "To address the limitations of existing methods, such as loss of spatial structure in bilinear pooling or shallow context modeling in self-attention, for texture recognition tasks.", "method": "The TwistNet-2D employs a Spiral-Twisted Channel Interaction (STCI) that shifts feature maps spatially before performing channel-wise multiplication. Four directional heads are aggregated with learned channel reweighting and applied through a sigmoid-gated residual pathway.", "result": "TwistNet-2D achieves better texture and fine-grained recognition performance than parameter-matched and larger models like ConvNeXt, Swin Transformer, and hybrid architectures, while increasing computational cost minimally.", "conclusion": "TwistNet-2D effectively enhances texture recognition by modeling local pairwise feature interactions, offering superior performance without significant complexity."}}
{"id": "2602.08105", "pdf": "https://arxiv.org/pdf/2602.08105", "abs": "https://arxiv.org/abs/2602.08105", "authors": ["Paarth Gulati", "Eslam Abdelaleem", "Audrey Sederberg", "Ilya Nemenman"], "title": "Mutual information and task-relevant latent dimensionality", "categories": ["cs.LG", "physics.data-an", "stat.ML"], "comment": null, "summary": "Estimating the dimensionality of the latent representation needed for prediction -- the task-relevant dimension -- is a difficult, largely unsolved problem with broad scientific applications. We cast it as an Information Bottleneck question: what embedding bottleneck dimension is sufficient to compress predictor and predicted views while preserving their mutual information (MI). This repurposes neural MI estimators for dimensionality estimation. We show that standard neural estimators with separable/bilinear critics systematically inflate the inferred dimension, and we address this by introducing a hybrid critic that retains an explicit dimensional bottleneck while allowing flexible nonlinear cross-view interactions, thereby preserving the latent geometry. We further propose a one-shot protocol that reads off the effective dimension from a single over-parameterized hybrid model, without sweeping over bottleneck sizes. We validate the approach on synthetic problems with known task-relevant dimension. We extend the approach to intrinsic dimensionality by constructing paired views of a single dataset, enabling comparison with classical geometric dimension estimators. In noisy regimes where those estimators degrade, our approach remains reliable. Finally, we demonstrate the utility of the method on multiple physics datasets.", "AI": {"tldr": "This paper introduces a method to estimate the dimensionality of task-relevant latent representations. It approaches this through an Information Bottleneck framework, introducing a hybrid neural network critic for better accuracy.", "motivation": "The challenge is to determine the task-relevant dimension needed for prediction applications. Existing methods often struggle with inflated dimensionality estimates and unreliable results in noisy conditions.", "method": "The paper uses an Information Bottleneck framework with refined neural Mutual Information (MI) estimators. A hybrid critic is introduced, combining explicit bottlenecks and nonlinear cross-view interactions. They also design a one-shot protocol to infer dimensions directly from a single over-parameterized model.", "result": "The hybrid neural estimator was validated on synthetic data, showing accuracy in dimension estimation. Compared to classical geometric methods, it proved reliable even in noisy conditions. Use cases on physics datasets further demonstrated its practicality.", "conclusion": "The proposed method effectively estimates latent task-relevant dimensionality, addresses issues in prior estimators, and expands applicability to both synthetic and real-world datasets."}}
{"id": "2602.07852", "pdf": "https://arxiv.org/pdf/2602.07852", "abs": "https://arxiv.org/abs/2602.07852", "authors": ["Anna Soligo", "Edward Turner", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard", "categories": ["cs.AI", "cs.CL"], "comment": "Published at ICLR 2026", "summary": "Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.", "AI": {"tldr": "Finetuning large language models on harmful datasets can lead to widespread misalignment issues, with models providing unexpectedly harmful outputs in unrelated contexts.", "motivation": "The goal is to better understand why large language models trained on harmful datasets generalize this harm to unrelated contexts, highlighting gaps in our understanding of their inductive biases.", "method": "The study examines how emergently misaligned (EM) behaviors arise by analyzing the convergence of different finetuned models to similar representations of general misalignment.", "result": "The paper confirms that models achieve more stable and efficient representations for general misalignment rather than narrow dataset-based solutions.", "conclusion": "This research provides concrete tools for monitoring and mitigating general misalignment in LLMs and offers insights into how inductive biases shape their behavior. Open-source resources are shared for further investigation."}}
{"id": "2602.07340", "pdf": "https://arxiv.org/pdf/2602.07340", "abs": "https://arxiv.org/abs/2602.07340", "authors": ["Yonghui Yang", "Wenjian Tao", "Jilong Liu", "Xingyu Zhu", "Junfeng Fang", "Weibiao Huang", "Le Wu", "Richang Hong", "Tat-Sent Chua"], "title": "Revisiting Robustness for LLM Safety Alignment via Selective Geometry Control", "categories": ["cs.LG"], "comment": null, "summary": "Safety alignment of large language models remains brittle under domain shift and noisy preference supervision. Most existing robust alignment methods focus on uncertainty in alignment data, while overlooking optimization-induced fragility in preference-based objectives. In this work, we revisit robustness for LLM safety alignment from an optimization geometry perspective, and argue that robustness failures cannot be addressed by data-centric methods alone. We propose ShaPO, a geometry-aware preference optimization framework that enforces worst-case alignment objectives via selective geometry control over alignment-critical parameter subspace. By avoiding uniform geometry constraints, ShaPO mitigates the over-regularization that can harm robustness under distribution shift. We instantiate ShaPO at two levels: token-level ShaPO stabilizes likelihood-based surrogate optimization, while reward-level ShaPO enforces reward-consistent optimization under noisy supervision. Across diverse safety benchmarks and noisy preference settings, ShaPO consistently improves safety robustness over popular preference optimization methods. Moreover, ShaPO composes cleanly with data-robust objectives, yielding additional gains and empirically supporting the proposed optimization-geometry perspective.", "AI": {"tldr": "ShaPO introduces a geometry-aware preference optimization framework to enhance the robustness of safety alignment for LLMs, outperforming existing methods under noisy and shifted conditions.", "motivation": "Current safety alignments of large language models often fail due to domain shift and noisy preferences, and optimization-induced fragility has been overlooked in addressing robustness issues.", "method": "The paper proposes ShaPO, a framework utilizing selective geometry control over alignment-critical parameter subspaces, with two instantiations: token-level and reward-level optimization to tackle robust alignment.", "result": "Experiments show ShaPO improves safety robustness across diverse benchmarks and noisy preference conditions, outperforming other popular preference optimization methods.", "conclusion": "ShaPO effectively mitigates robustness failures in LLM safety alignment and pairs well with data-centric approaches, supporting the optimization-geometry perspective."}}
{"id": "2602.08245", "pdf": "https://arxiv.org/pdf/2602.08245", "abs": "https://arxiv.org/abs/2602.08245", "authors": ["Jinhao Li", "Yuxuan Cong", "Yingqiao Wang", "Hao Xia", "Shan Huang", "Yijia Zhang", "Ningyi Xu", "Guohao Dai"], "title": "STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction", "categories": ["cs.RO", "cs.AI"], "comment": "13 pages, 9 figures", "summary": "Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse past actions, but often struggle to jointly preserve action quality and achieve consistently low latency. In this work, we propose STEP, a lightweight spatiotemporal consistency prediction mechanism to construct high-quality warm-start actions that are both distributionally close to the target action and temporally consistent, without compromising the generative capability of the original diffusion policy. Then, we propose a velocity-aware perturbation injection mechanism that adaptively modulates actuation excitation based on temporal action variation to prevent execution stall especially for real-world tasks. We further provide a theoretical analysis showing that the proposed prediction induces a locally contractive mapping, ensuring convergence of action errors during diffusion refinement. We conduct extensive evaluations on nine simulated benchmarks and two real-world tasks. Notably, STEP with 2 steps can achieve an average 21.6% and 27.5% higher success rate than BRIDGER and DDIM on the RoboMimic benchmark and real-world tasks, respectively. These results demonstrate that STEP consistently advances the Pareto frontier of inference latency and success rate over existing methods.", "AI": {"tldr": "STEP introduces a spatiotemporal consistency and velocity-aware mechanism to enhance real-time robotic control under diffusion policies, achieving better success rates with reduced latency.", "motivation": "To address the limitations of existing diffusion policies for robotic manipulation, such as high inference latency and challenges in balancing action quality and performance efficiency.", "method": "STEP combines a spatiotemporal consistency prediction for warm-start actions and a velocity-aware perturbation to optimize action refinement, enabling faster and effective real-time operation.", "result": "STEP achieves superior success rates (21.6%-27.5% higher) compared to BRIDGER and DDIM across simulated and real-world robotic tasks while reducing latency.", "conclusion": "STEP enhances the efficiency and effectiveness of diffusion-based visuomotor control, positioning itself as a superior alternative for real-time robotic manipulation."}}
{"id": "2602.08028", "pdf": "https://arxiv.org/pdf/2602.08028", "abs": "https://arxiv.org/abs/2602.08028", "authors": ["Po-Chun Chen", "Hen-Hsen Huang", "Hsin-Hsi Chen"], "title": "Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning", "categories": ["cs.CL"], "comment": "Accepted to Findings of IJCNLP-AACL 2025", "summary": "To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.", "AI": {"tldr": "The paper proposes Diverge-to-Induce Prompting (DIP), a framework that enhances reasoning in large language models (LLMs) by generating multiple diverse strategies for answering questions, achieving better accuracy compared to single-strategy methods.", "motivation": "Current Chain-of-Thought prompting methods for LLMs suffer from instability and underperformance when relying on single reasoning strategies for diverse tasks.", "method": "DIP generates multiple diverse rationales for a question, elaborates each rationale into detailed draft plans, and consolidates them into a final plan, improving reasoning accuracy without requiring resource-intensive sampling.", "result": "Experiments demonstrate that DIP outperforms single-strategy prompting in zero-shot reasoning accuracy, validating the benefits of using multiple plans.", "conclusion": "Multi-plan induction via DIP enhances the reasoning potential of LLMs across diverse tasks without significant overhead, indicating its practical value for future research and applications."}}
{"id": "2602.07272", "pdf": "https://arxiv.org/pdf/2602.07272", "abs": "https://arxiv.org/abs/2602.07272", "authors": ["Bowen Xue", "Saeed Hadadan", "Zheng Zeng", "Fabrice Rousselle", "Zahra Montazeri", "Milos Hasan"], "title": "VideoNeuMat: Neural Material Extraction from Generative Video Models", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Creating photorealistic materials for 3D rendering requires exceptional artistic skill. Generative models for materials could help, but are currently limited by the lack of high-quality training data. While recent video generative models effortlessly produce realistic material appearances, this knowledge remains entangled with geometry and lighting. We present VideoNeuMat, a two-stage pipeline that extracts reusable neural material assets from video diffusion models. First, we finetune a large video model (Wan 2.1 14B) to generate material sample videos under controlled camera and lighting trajectories, effectively creating a \"virtual gonioreflectometer\" that preserves the model's material realism while learning a structured measurement pattern. Second, we reconstruct compact neural materials from these videos through a Large Reconstruction Model (LRM) finetuned from a smaller Wan 1.3B video backbone. From 17 generated video frames, our LRM performs single-pass inference to predict neural material parameters that generalize to novel viewing and lighting conditions. The resulting materials exhibit realism and diversity far exceeding the limited synthetic training data, demonstrating that material knowledge can be successfully transferred from internet-scale video models into standalone, reusable neural 3D assets.", "AI": {"tldr": "The paper introduces VideoNeuMat, a pipeline that extracts reusable neural material assets from video diffusion models, enabling photorealistic 3D rendering through better material realism preservation and reconstruction.", "motivation": "Creating high-quality photorealistic materials for 3D rendering is challenging and requires artistic expertise. Current generative models lack suitable high-quality training data and struggle to disentangle material appearance from geometry and lighting.", "method": "The method involves two stages: 1) Finetuning a large video model to act as a 'virtual gonioreflectometer' generating material sample videos under controlled conditions, and 2) reconstructing compact neural materials from these videos using a Large Reconstruction Model (LRM) finetuned on a smaller video backbone.", "result": "The system can predict neural material parameters from 17 generated video frames, generalizing to new viewing and lighting conditions. It achieves superior realism and diversity compared to limited synthetic training datasets.", "conclusion": "VideoNeuMat successfully transfers material knowledge from large video generative models into standalone neural 3D assets, representing a significant advance in photorealistic rendering."}}
{"id": "2602.08142", "pdf": "https://arxiv.org/pdf/2602.08142", "abs": "https://arxiv.org/abs/2602.08142", "authors": ["H. Martin Gillis", "Isaac Xu", "Thomas Trappenberg"], "title": "Variance-Gated Ensembles: An Epistemic-Aware Framework for Uncertainty Estimation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine learning applications require fast and reliable per-sample uncertainty estimation. A common approach is to use predictive distributions from Bayesian or approximation methods and additively decompose uncertainty into aleatoric (i.e., data-related) and epistemic (i.e., model-related) components. However, additive decomposition has recently been questioned, with evidence that it breaks down when using finite-ensemble sampling and/or mismatched predictive distributions. This paper introduces Variance-Gated Ensembles (VGE), an intuitive, differentiable framework that injects epistemic sensitivity via a signal-to-noise gate computed from ensemble statistics. VGE provides: (i) a Variance-Gated Margin Uncertainty (VGMU) score that couples decision margins with ensemble predictive variance; and (ii) a Variance-Gated Normalization (VGN) layer that generalizes the variance-gated uncertainty mechanism to training via per-class, learnable normalization of ensemble member probabilities. We derive closed-form vector-Jacobian products enabling end-to-end training through ensemble sample mean and variance. VGE matches or exceeds state-of-the-art information-theoretic baselines while remaining computationally efficient. As a result, VGE provides a practical and scalable approach to epistemic-aware uncertainty estimation in ensemble models. An open-source implementation is available at: https://github.com/nextdevai/vge.", "AI": {"tldr": "This paper introduces Variance-Gated Ensembles (VGE), a framework for improving uncertainty estimation in machine learning models through epistemic-aware mechanisms, achieving state-of-the-art performance efficiently.", "motivation": "The motivation for this work comes from the limitations of existing methods in uncertainty estimation, particularly the breakdown of additive decomposition approaches when using finite-ensemble sampling or mismatched predictive distributions.", "method": "The authors propose Variance-Gated Ensembles (VGE), which incorporates epistemic sensitivity via a signal-to-noise gate. This approach includes a Variance-Gated Margin Uncertainty score and a Variance-Gated Normalization layer, allowing for end-to-end training using ensemble statistics.", "result": "The results show that VGE matches or surpasses state-of-the-art baselines in uncertainty estimation while remaining computationally efficient.", "conclusion": "VGE offers a scalable and practical solution for epistemic-aware uncertainty estimation in ensemble models, achieving strong performance with efficiency. The implementation is open-sourced for broader accessibility."}}
{"id": "2602.07883", "pdf": "https://arxiv.org/pdf/2602.07883", "abs": "https://arxiv.org/abs/2602.07883", "authors": ["Jingqi Zhou", "Sheng Wang", "DeZhao Deng", "Junwen Lu", "Junwei Su", "Qintong Li", "Jiahui Gao", "Hao Wu", "Jiyue Jiang", "Lingpeng Kong", "Chuan Wu"], "title": "ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation", "categories": ["cs.AI"], "comment": null, "summary": "Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.", "AI": {"tldr": "ToolSelf integrates task execution and adaptive configuration updates for agents using large language models, enabling autonomous self-reconfiguration and enhanced task performance.", "motivation": "Static configurations in agents with LLMs limit their ability to adapt dynamically to complex and evolving tasks. Existing manual or heuristic adjustments fail to generalize effectively.", "method": "ToolSelf introduces tool-driven runtime self-reconfiguration, allowing agents to autonomously adapt their sub-goals, strategies, and tools. A Configuration-Aware Two-stage Training (CAT) system combines fine-tuning with reinforcement learning to internalize adaptive capabilities.", "result": "Extensive benchmarking shows ToolSelf achieves a 24.1% average performance improvement and rivals domain-specific workflows, demonstrating enhanced generalization and adaptability.", "conclusion": "ToolSelf provides a paradigm shift toward self-adaptive agents, seamlessly merging task execution with intrinsic adjustments, paving the way for more autonomous and effective systems."}}
{"id": "2602.07341", "pdf": "https://arxiv.org/pdf/2602.07341", "abs": "https://arxiv.org/abs/2602.07341", "authors": ["Yicheng Yang", "Ruijiao Li", "Lifeng Wang", "Shuai Zheng", "Shunzheng Ma", "Keyu Zhang", "Tuoyu Sun", "Chenyun Dai", "Jie Ding", "Zhuo Zou"], "title": "Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "This paper focuses on the scalable robot learning for manipulation in the dexterous robot arm-hand systems, where the remote human-robot interactions via augmented reality (AR) are established to collect the expert demonstration data for improving efficiency. In such a system, we present a unified framework to address the general manipulation task problem. Specifically, the proposed method consists of two phases: i) In the first phase for pretraining, the policy is created in a behavior cloning (BC) manner, through leveraging the learning data from our AR-based remote human-robot interaction system; ii) In the second phase, a contrastive learning empowered reinforcement learning (RL) method is developed to obtain more efficient and robust policy than the BC, and thus a projection head is designed to accelerate the learning progress. An event-driven augmented reward is adopted for enhancing the safety. To validate the proposed method, both the physics simulations via PyBullet and real-world experiments are carried out. The results demonstrate that compared to the classic proximal policy optimization and soft actor-critic policies, our method not only significantly speeds up the inference, but also achieves much better performance in terms of the success rate for fulfilling the manipulation tasks. By conducting the ablation study, it is confirmed that the proposed RL with contrastive learning overcomes policy collapse. Supplementary demonstrations are available at https://cyberyyc.github.io/.", "AI": {"tldr": "The paper introduces a scalable robot learning framework for dexterous manipulation leveraging AR-based human-robot interaction and an RL model enhanced with contrastive learning, validated through simulations and real-world testing.", "motivation": "To address the challenges of scalable and efficient learning for dexterous robot manipulation, and to incorporate augmented reality to improve expert data collection for policy training.", "method": "The framework has two major phases: (1) Pretraining uses behavior cloning with AR-based human-robot interaction data; (2) Policy refinement employs contrastive learning-enhanced reinforcement learning with a projection head to improve learning efficiency and safety using event-driven augmented rewards.", "result": "The method outperformed classic RL algorithms like PPO and SAC, demonstrating faster inference and higher success rates in manipulation tasks, and showed stronger robustness against policy collapse during experiments.", "conclusion": "The proposed framework validates the effectiveness of AR-based interaction for data collection and the ability of contrastive learning-enhanced RL to achieve robust, efficient manipulation policies."}}
{"id": "2602.07287", "pdf": "https://arxiv.org/pdf/2602.07287", "abs": "https://arxiv.org/abs/2602.07287", "authors": ["Juefei Pu", "Xingyu Li", "Haonan Li", "Zhengchuan Liang", "Jonathan Cox", "Yifan Wu", "Kareem Shehada", "Arrdya Srivastav", "Zhiyun Qian"], "title": "Patch-to-PoC: A Systematic Study of Agentic LLM Systems for Linux Kernel N-Day Reproduction", "categories": ["cs.CR", "cs.SE"], "comment": "17 pages, 2 figures", "summary": "Autonomous large language model (LLM) based systems have recently shown promising results across a range of cybersecurity tasks. However, there is no systematic study on their effectiveness in autonomously reproducing Linux kernel vulnerabilities with concrete proofs-of-concept (PoCs). Owing to the size, complexity, and low-level nature of the Linux kernel, such tasks are widely regarded as particularly challenging for current LLM-based approaches.\n  In this paper, we present the first large-scale study of LLM-based Linux kernel vulnerability reproduction. For this purpose, we develop K-Repro, an LLM-based agentic system equipped with controlled code-browsing, virtual machine management, interaction, and debugging capabilities. Using kernel security patches as input, K-Repro automates end-to-end bug reproduction of N-day vulnerabilities in the Linux kernel. On a dataset of 100 real-world exploitable Linux kernel vulnerabilities collected from KernelCTF, our results show that K-Repro can generate PoCs that reproduce over 50\\% of the cases with practical time and monetary cost.\n  Beyond aggregate success rates, we perform an extensive study of effectiveness, efficiency, stability, and impact factors to explain when agentic reproduction succeeds, where it fails, and which components drive performance. These findings provide actionable guidance for building more reliable autonomous security agents and for assessing real-world N-day risk from both offensive and defensive perspectives.", "AI": {"tldr": "The paper develops K-Repro, an LLM-based system capable of reproducing Linux kernel vulnerabilities, achieving success in over half of the studied cases.", "motivation": "The study aims to address the lack of systematic research on using autonomous LLM systems to reproduce Linux kernel vulnerabilities, given the complexity and challenges posed by the kernel.", "method": "K-Repro, an agentic system, automates vulnerability reproduction by integrating controlled code-browsing, virtual machine management, debugging, and interaction capabilities.", "result": "K-Repro successfully reproduced proofs-of-concept for over 50% of 100 Linux kernel vulnerabilities in practical time and cost.", "conclusion": "The research identifies factors affecting agentic reproduction success while providing insights for improving autonomous security agents and understanding N-day vulnerability risks from offensive and defensive perspectives."}}
{"id": "2602.08251", "pdf": "https://arxiv.org/pdf/2602.08251", "abs": "https://arxiv.org/abs/2602.08251", "authors": ["Yuanzhu Zhan", "Yufei Jiang", "Muqing Cao", "Junyi Geng"], "title": "Aerial Manipulation with Contact-Aware Onboard Perception and Hybrid Control", "categories": ["cs.RO"], "comment": "9 pages, 7 figures. Accepted by ICRA 2026", "summary": "Aerial manipulation (AM) promises to move Unmanned Aerial Vehicles (UAVs) beyond passive inspection to contact-rich tasks such as grasping, assembly, and in-situ maintenance. Most prior AM demonstrations rely on external motion capture (MoCap) and emphasize position control for coarse interactions, limiting deployability. We present a fully onboard perception-control pipeline for contact-rich AM that achieves accurate motion tracking and regulated contact wrenches without MoCap. The main components are (1) an augmented visual-inertial odometry (VIO) estimator with contact-consistency factors that activate only during interaction, tightening uncertainty around the contact frame and reducing drift, and (2) image-based visual servoing (IBVS) to mitigate perception-control coupling, together with a hybrid force-motion controller that regulates contact wrenches and lateral motion for stable contact. Experiments show that our approach closes the perception-to-wrench loop using only onboard sensing, yielding an velocity estimation improvement of 66.01% at contact, reliable target approach, and stable force holding-pointing toward deployable, in-the-wild aerial manipulation.", "AI": {"tldr": "The paper introduces a self-contained system for UAVs enabling precise contact-rich tasks without relying on external tools like MoCap by integrating improved perception and control.", "motivation": "To enhance UAV functionality and deployability for advanced tasks such as grasping and maintenance by overcoming the limitations of MoCap and position control reliance.", "method": "Develops an onboard perception-control system integrating augmented visual-inertial odometry for contact consistency and IBVS-based hybrid force-motion control for stable contact management.", "result": "Achieves significant performance improvements, such as a 66.01% boost in velocity estimation accuracy during contact and reliable, stable manipulation using only onboard sensing.", "conclusion": "Demonstrates a scalable and deployable solution enabling UAVs to perform precise contact-rich tasks in real-world scenarios."}}
{"id": "2602.08031", "pdf": "https://arxiv.org/pdf/2602.08031", "abs": "https://arxiv.org/abs/2602.08031", "authors": ["Chenwang Wu", "Yiu-ming Cheung", "Shuhai Zhang", "Bo Han", "Defu Lian"], "title": "Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection", "categories": ["cs.CL"], "comment": null, "summary": "While machine-generated texts (MGTs) offer great convenience, they also pose risks such as disinformation and phishing, highlighting the need for reliable detection. Metric-based methods, which extract statistically distinguishable features of MGTs, are often more practical than complex model-based methods that are prone to overfitting. Given their diverse designs, we first place representative metric-based methods within a unified framework, enabling a clear assessment of their advantages and limitations. Our analysis identifies a core challenge across these methods: the token-level detection score is easily biased by the inherent randomness of the MGTs generation process. To address this, we theoretically and empirically reveal two relationships of context detection scores that may aid calibration: Neighbor Similarity and Initial Instability. We then propose a Markov-informed score calibration strategy that models these relationships using Markov random fields, and implements it as a lightweight component via a mean-field approximation, allowing our method to be seamlessly integrated into existing detectors. Extensive experiments in various real-world scenarios, such as cross-LLM and paraphrasing attacks, demonstrate significant gains over baselines with negligible computational overhead. The code is available at https://github.com/tmlr-group/MRF_Calibration.", "AI": {"tldr": "The paper addresses challenges in detecting machine-generated texts by proposing a Markov-informed score calibration strategy to mitigate token-level bias and improve detection performance.", "motivation": "The motivation stems from the increasing presence of machine-generated texts, which introduce risks like disinformation and phishing, necessitating precise detection methods that are both reliable and lightweight.", "method": "The authors analyze metric-based detection methods, identify token-level biases, and introduce a Markov-informed score calibration strategy using mean-field approximation to improve detection accuracy.", "result": "The proposed method significantly outperforms baseline approaches in experiments, managing to handle real-world scenarios like cross-LLM and paraphrasing attacks while introducing minimal computational overhead.", "conclusion": "The study provides an effective and practical solution for improving machine-generated text detection, integrating seamlessly with existing systems and addressing robustness issues."}}
{"id": "2602.07277", "pdf": "https://arxiv.org/pdf/2602.07277", "abs": "https://arxiv.org/abs/2602.07277", "authors": ["Rishabh Sharma", "Gijs Hogervorst", "Wayne E. Mackey", "David J. Heeger", "Stefano Martiniani"], "title": "Cross-View World Models", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages, 7 figures", "summary": "World models enable agents to plan by imagining future states, but existing approaches operate from a single viewpoint, typically egocentric, even when other perspectives would make planning easier; navigation, for instance, benefits from a bird's-eye view. We introduce Cross-View World Models (XVWM), trained with a cross-view prediction objective: given a sequence of frames from one viewpoint, predict the future state from the same or a different viewpoint after an action is taken. Enforcing cross-view consistency acts as geometric regularization: because the input and output views may share little or no visual overlap, to predict across viewpoints, the model must learn view-invariant representations of the environment's 3D structure. We train on synchronized multi-view gameplay data from Aimlabs, an aim-training platform providing precisely aligned multi-camera recordings with high-frequency action labels. The resulting model gives agents parallel imagination streams across viewpoints, enabling planning in whichever frame of reference best suits the task while executing from the egocentric view. Our results show that multi-view consistency provides a strong learning signal for spatially grounded representations. Finally, predicting the consequences of one's actions from another viewpoint may offer a foundation for perspective-taking in multi-agent settings.", "AI": {"tldr": "This paper introduces Cross-View World Models (XVWM), a method enabling agents to predict future states from differing viewpoints to improve planning and spatial understanding.", "motivation": "To address the limitation of existing single-view world models and improve planning in navigation and other tasks by leveraging multiple viewpoints.", "method": "The proposed XVWM uses a cross-view prediction objective to make trained models predict future states across viewpoints. It relies on synchronized multi-view gameplay data from Aimlabs for training, using geometric regularization to learn 3D structure-aware representations.", "result": "XVWM produces parallel imagination streams for agents, enhancing planning across viewpoints and improving spatially grounded representations.", "conclusion": "Cross-view consistency offers a robust learning signal for 3D spatial understanding, enabling effective planning and potentially fostering perspective-taking in multi-agent systems."}}
{"id": "2602.08151", "pdf": "https://arxiv.org/pdf/2602.08151", "abs": "https://arxiv.org/abs/2602.08151", "authors": ["Yoav Freund", "Nicholas J. A. Harvey", "Victor S. Portella", "Yabing Qi", "Yu-Xiang Wang"], "title": "A second order regret bound for NormalHedge", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider the problem of prediction with expert advice for ``easy'' sequences. We show that a variant of NormalHedge enjoys a second-order $\u03b5$-quantile regret bound of $O\\big(\\sqrt{V_T \\log(V_T/\u03b5)}\\big) $ when $V_T > \\log N$, where $V_T$ is the cumulative second moment of instantaneous per-expert regret averaged with respect to a natural distribution determined by the algorithm. The algorithm is motivated by a continuous time limit using Stochastic Differential Equations. The discrete time analysis uses self-concordance techniques.", "AI": {"tldr": "The paper studies prediction using expert advice for simpler sequences, presenting an enhanced NormalHedge algorithm with second-order $\u03b5$-quantile regret bound.", "motivation": "The motivation is to create a more efficient prediction algorithm for \"easy\" sequences by optimizing regret bounds using advanced mathematical techniques.", "method": "The method involves developing a NormalHedge variant and analyzing it through Stochastic Differential Equations in continuous time, complemented by self-concordance techniques in discrete time.", "result": "The proposed algorithm achieves second-order $\u03b5$-quantile regret bound, offering performance scaling with the cumulative second moment of regret.", "conclusion": "NormalHedge's new variant provides improved prediction capabilities with rigorously analyzed regret bounds, contributing to the advancement in sequential prediction techniques."}}
{"id": "2602.07885", "pdf": "https://arxiv.org/pdf/2602.07885", "abs": "https://arxiv.org/abs/2602.07885", "authors": ["Zhenyuan Zhang", "Xianzhang Jia", "Zhiqin Yang", "Zhenbo Song", "Wei Xue", "Sirui Han", "Yike Guo"], "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.", "AI": {"tldr": "MemFly is proposed to optimize long-term memory management in large language models, improving task handling through reduced information redundancy and enhanced memory retrieval.", "motivation": "To address the dilemma in current systems that struggle between efficiently compressing redundant information and maintaining precise retrieval for complex tasks.", "method": "MemFly uses principles of the information bottleneck approach, incorporating a gradient-free optimizer to create a stratified memory structure and a hybrid retrieval mechanism for handling multi-hop queries.", "result": "Experiments indicate MemFly achieves better memory coherence, response fidelity, and accuracy compared to state-of-the-art alternatives.", "conclusion": "MemFly bridges the gap in memory management for LLMs, offering efficient storage and retrieval solutions for improved task performance."}}
{"id": "2602.07356", "pdf": "https://arxiv.org/pdf/2602.07356", "abs": "https://arxiv.org/abs/2602.07356", "authors": ["Yonghui Yang", "Junwei Li", "Jilong Liu", "Yicheng He", "Fengbin Zhu", "Weibiao Huang", "Le Wu", "Richang Hong", "Tat-Seng Chua"], "title": "Controllable Value Alignment in Large Language Models through Neuron-Level Editing", "categories": ["cs.LG"], "comment": null, "summary": "Aligning large language models (LLMs) with human values has become increasingly important as their influence on human behavior and decision-making expands. However, existing steering-based alignment methods suffer from limited controllability: steering a target value often unintentionally activates other, non-target values. To characterize this limitation, we introduce value leakage, a diagnostic notion that captures the unintended activation of non-target values during value steering, along with a normalized leakage metric grounded in Schwartz's value theory. In light of this analysis, we propose NeVA, a neuron-level editing framework for controllable value alignment in LLMs. NeVA identifies sparse, value-relevant neurons and performs inference-time activation editing, enabling fine-grained control without parameter updates or retraining. Experiments show that NeVA achieves stronger target value alignment while incurring smaller performance degradation on general capability. Moreover, NeVA significantly reduces the average leakage, with residual effects largely confined to semantically related value classes. Overall, NeVA offers a more controllable and interpretable mechanism for value alignment.", "AI": {"tldr": "This paper introduces NeVA, a neuron-level editing framework for better aligning large language models (LLMs) with targeted human values, addressing unintended activation of non-target values.", "motivation": "The need to align LLMs with specific human values has grown as these models influence decisions and behavior, but existing methods lack precise control, inadvertently activating undesired values.", "method": "The paper introduces NeVA, a framework leveraging neuron-level activation editing at inference time to target value-relevant neurons, without requiring retraining or parameter updates.", "result": "NeVA achieves stronger value alignment with minimal performance loss, reduces unintended value activation (leakage), and confines residual effects to semantically related values.", "conclusion": "NeVA provides an effective, interpretable, and precise method for controllable value alignment in LLMs, improving alignment outcomes and reducing unintended consequences."}}
{"id": "2602.07303", "pdf": "https://arxiv.org/pdf/2602.07303", "abs": "https://arxiv.org/abs/2602.07303", "authors": ["Lei Ma", "Jinyang Liu", "Tieying Zhang", "Peter M. VanNostrand", "Dennis M. Hofmann", "Lei Cao", "Elke A. Rundensteiner", "Jianjun Chen"], "title": "KRONE: Hierarchical and Modular Log Anomaly Detection", "categories": ["cs.DB", "cs.AI", "cs.SE"], "comment": null, "summary": "Log anomaly detection is crucial for uncovering system failures and security risks. Although logs originate from nested component executions with clear boundaries, this structure is lost when they are stored as flat sequences. As a result, state-of-the-art methods risk missing true dependencies within executions while learning spurious ones across unrelated events. We propose KRONE, the first hierarchical anomaly detection framework that automatically derives execution hierarchies from flat logs for modular multi-level anomaly detection. At its core, the KRONE Log Abstraction Model captures application-specific semantic hierarchies from log data. This hierarchy is then leveraged to recursively decompose log sequences into multiple levels of coherent execution chunks, referred to as KRONE Seqs, transforming sequence-level anomaly detection into a set of modular KRONE Seq-level detection tasks. For each test KRONE Seq, KRONE employs a hybrid modular detection mechanism that dynamically routes between an efficient level-independent Local-Context detector, which rapidly filters normal sequences, and a Nested-Aware detector that incorporates cross-level semantic dependencies and supports LLM-based anomaly detection and explanation. KRONE further optimizes hierarchical detection through cached result reuse and early-exit strategies. Experiments on three public benchmarks and one industrial dataset from ByteDance Cloud demonstrate that KRONE achieves consistent improvements in detection accuracy, F1-score, data efficiency, resource efficiency, and interpretability. KRONE improves the F1-score by more than 10 percentage points over prior methods while reducing LLM usage to only a small fraction of the test data.", "AI": {"tldr": "KRONE is a hierarchical anomaly detection framework designed for log data, leveraging semantic hierarchies for more accurate and efficient detection compared to flat sequence approaches.", "motivation": "The paper addresses the challenge of detecting anomalies in log data, which often loses its execution hierarchical structure when stored as flat sequences, leading to missed dependencies and spurious correlations.", "method": "KRONE creates and leverages execution hierarchies using a Log Abstraction Model to divide flat logs into modular execution chunks, enabling modular sequence-level anomaly detection tasks. It combines modular hybrid detection mechanisms, including efficient local context and nested-aware detectors.", "result": "Experiments on public and industrial datasets show KRONE improves detection accuracy, F1-score, resource efficiency, and interpretability, with over 10 percentage points increase in F1-score compared to prior methods.", "conclusion": "KRONE provides a hierarchical and efficient approach to log anomaly detection, demonstrating significant improvements in effectiveness and resource usage, with reduced reliance on large language models."}}
{"id": "2602.08266", "pdf": "https://arxiv.org/pdf/2602.08266", "abs": "https://arxiv.org/abs/2602.08266", "authors": ["Seunghoon Jeong", "Eunho Lee", "Jeongyun Kim", "Ayoung Kim"], "title": "Informative Object-centric Next Best View for Object-aware 3D Gaussian Splatting in Cluttered Scenes", "categories": ["cs.RO", "cs.CV"], "comment": "9 pages, 8 figures, 4 tables, accepted to ICRA 2026", "summary": "In cluttered scenes with inevitable occlusions and incomplete observations, selecting informative viewpoints is essential for building a reliable representation. In this context, 3D Gaussian Splatting (3DGS) offers a distinct advantage, as it can explicitly guide the selection of subsequent viewpoints and then refine the representation with new observations. However, existing approaches rely solely on geometric cues, neglect manipulation-relevant semantics, and tend to prioritize exploitation over exploration. To tackle these limitations, we introduce an instance-aware Next Best View (NBV) policy that prioritizes underexplored regions by leveraging object features. Specifically, our object-aware 3DGS distills instancelevel information into one-hot object vectors, which are used to compute confidence-weighted information gain that guides the identification of regions associated with erroneous and uncertain Gaussians. Furthermore, our method can be easily adapted to an object-centric NBV, which focuses view selection on a target object, thereby improving reconstruction robustness to object placement. Experiments demonstrate that our NBV policy reduces depth error by up to 77.14% on the synthetic dataset and 34.10% on the real-world GraspNet dataset compared to baselines. Moreover, compared to targeting the entire scene, performing NBV on a specific object yields an additional reduction of 25.60% in depth error for that object. We further validate the effectiveness of our approach through real-world robotic manipulation tasks.", "AI": {"tldr": "This paper introduces an instance-aware Next Best View (NBV) policy that leverages object features to overcome limitations in viewpoint selection for 3D scene representation using 3D Gaussian Splatting.", "motivation": "Cluttered scenes with occlusions and incomplete observations hinder building reliable representations during viewpoint selection, motivating the need for advanced methods.", "method": "An instance-aware NBV policy prioritizes underexplored regions using one-hot object vectors, guiding viewpoint selection and refining representations. It includes confidence-weighted information gain and an object-centric NBV for target objects.", "result": "The NBV policy reduces depth error by up to 77.14% on synthetic data and 34.10% on real-world data. Using object-centric NBV decreases depth error by an additional 25.60% for target objects.", "conclusion": "The proposed method improves representation reliability and depth reconstruction while showing efficacy in real-world robotic manipulation tasks."}}
{"id": "2602.08048", "pdf": "https://arxiv.org/pdf/2602.08048", "abs": "https://arxiv.org/abs/2602.08048", "authors": ["Arshia Hemmat", "Philip Torr", "Yongqiang Chen", "Junchi Yu"], "title": "TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs", "categories": ["cs.CL"], "comment": null, "summary": "Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.", "AI": {"tldr": "TDGNet is a temporal dynamic graph framework for robust hallucination detection in diffusion language models.", "motivation": "Hallucination detection for diffusion language models is underexplored, and prior methods for auto-regressive models are unsuitable for diffusion models due to their denoising trajectory.", "method": "TDGNet uses sparsified attention graphs with per-token memories and applies temporal attention across denoising trajectories to detect hallucinations.", "result": "TDGNet demonstrates consistent AUROC improvements on QA benchmarks compared to prior methods, requiring modest overhead.", "conclusion": "Temporal reasoning on attention graphs is crucial for effective hallucination detection in diffusion language models."}}
{"id": "2602.07301", "pdf": "https://arxiv.org/pdf/2602.07301", "abs": "https://arxiv.org/abs/2602.07301", "authors": ["Aruna Jithesh", "Chinmayi Karumuri", "Venkata Kiran Reddy Kotha", "Meghana Doddapuneni", "Taehee Jeong"], "title": "Diabetic Retinopathy Lesion Segmentation through Attention Mechanisms", "categories": ["cs.CV"], "comment": null, "summary": "Diabetic Retinopathy (DR) is an eye disease which arises due to diabetes mellitus. It might cause vision loss and blindness. To prevent irreversible vision loss, early detection through systematic screening is crucial. Although researchers have developed numerous automated deep learning-based algorithms for DR screening, their clinical applicability remains limited, particularly in lesion segmentation. Our method provides pixel-level annotations for lesions, which practically supports Ophthalmologist to screen DR from fundus images. In this work, we segmented four types of DR-related lesions: microaneurysms, soft exudates, hard exudates, and hemorrhages on 757 images from DDR dataset. To enhance lesion segmentation, an attention mechanism was integrated with DeepLab-V3+. Compared to the baseline model, the Attention-DeepLab model increases mean average precision (mAP) from 0.3010 to 0.3326 and the mean Intersection over Union (IoU) from 0.1791 to 0.1928. The model also increased microaneurysm detection from 0.0205 to 0.0763, a clinically significant improvement. The detection of microaneurysms is the earliest visible symptom of DR.", "AI": {"tldr": "This paper proposes an attention-enhanced DeepLab-V3+ model for segmenting diabetic retinopathy lesions, demonstrating improved clinical applicability.", "motivation": "The paper aims to address the limited clinical applicability of current deep learning algorithms in lesion segmentation for diabetic retinopathy screening, assisting early detection to prevent vision loss.", "method": "The authors used an Attention-DeepLab model based on DeepLab-V3+ for pixel-level annotation of four lesion types: microaneurysms, soft exudates, hard exudates, and hemorrhages. The dataset used included 757 images from the DDR dataset.", "result": "The Attention-DeepLab model showed significant improvements, increasing mean average precision (mAP) from 0.3010 to 0.3326, mean Intersection over Union (IoU) from 0.1791 to 0.1928, and microaneurysm detection from 0.0205 to 0.0763.", "conclusion": "The proposed model demonstrates improved lesion segmentation performance, especially in detecting microaneurysms, enhancing early detection and clinical impact in diabetic retinopathy screening."}}
{"id": "2602.08197", "pdf": "https://arxiv.org/pdf/2602.08197", "abs": "https://arxiv.org/abs/2602.08197", "authors": ["Shingo Higashiguchi", "Koki Kawabata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Interpretable Dynamic Network Modeling of Tensor Time Series via Kronecker Time-Varying Graphical Lasso", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ACM Web Conference 2026 (WWW2026)", "summary": "With the rapid development of web services, large amounts of time series data are generated and accumulated across various domains such as finance, healthcare, and online platforms. As such data often co-evolves with multiple variables interacting with each other, estimating the time-varying dependencies between variables (i.e., the dynamic network structure) has become crucial for accurate modeling. However, real-world data is often represented as tensor time series with multiple modes, resulting in large, entangled networks that are hard to interpret and computationally intensive to estimate. In this paper, we propose Kronecker Time-Varying Graphical Lasso (KTVGL), a method designed for modeling tensor time series. Our approach estimates mode-specific dynamic networks in a Kronecker product form, thereby avoiding overly complex entangled structures and producing interpretable modeling results. Moreover, the partitioned network structure prevents the exponential growth of computational time with data dimension. In addition, our method can be extended to stream algorithms, making the computational time independent of the sequence length. Experiments on synthetic data show that the proposed method achieves higher edge estimation accuracy than existing methods while requiring less computation time. To further demonstrate its practical value, we also present a case study using real-world data. Our source code and datasets are available at https://github.com/Higashiguchi-Shingo/KTVGL.", "AI": {"tldr": "This paper introduces Kronecker Time-Varying Graphical Lasso (KTVGL), a method for modeling tensor time series by estimating dynamic networks with mode-specific structures, optimizing computational efficiency and interpretability.", "motivation": "Time series data, commonly seen in domains like finance and healthcare, often consists of complex, interdependent variables that evolve dynamically. Existing methods face challenges in handling such high-complexity, tensor-based data efficiently and interpretably.", "method": "The authors develop KTVGL, which uses a Kronecker product form to model mode-specific dynamic networks. This method simplifies entangled network structures, reduces computational demands by partitioning the network structure, and can be extended to streaming algorithms.", "result": "Experiments using synthetic data show that KTVGL outperforms existing methods in estimation accuracy and computation time. A real-world case study further confirms its applicability.", "conclusion": "KTVGL offers an efficient and interpretable solution for tensor time series modeling, addressing the challenges of complexity and large-scale data in dynamic networks. Its implementation and data are open-source for public use."}}
{"id": "2602.07903", "pdf": "https://arxiv.org/pdf/2602.07903", "abs": "https://arxiv.org/abs/2602.07903", "authors": ["Mingcan Wang", "Junchang Xin", "Zhongming Yao", "Kaifu Long", "Zhiqiong Wang"], "title": "GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank", "categories": ["cs.AI"], "comment": null, "summary": "The algorithms based on message passing neural networks (MPNNs) on graphs have recently achieved great success for various graph applications. However, studies find that these methods always propagate the information to very limited neighborhoods with shallow depth, particularly due to over-smoothing. That means most of the existing MPNNs fail to be so `deep'. Although some previous work tended to handle this challenge via optimization- or structure-level remedies, the overall performance of GCNs still suffers from limited accuracy, poor stability, and unaffordable computational cost. Moreover, neglect of higher-order relationships during the propagation of MPNNs has further limited the performance of them. To overcome these challenges, a novel variant of PageRank named motif-based personalized PageRank (MPPR) is proposed to measure the influence of one node to another on the basis of considering higher-order motif relationships. Secondly, the MPPR is utilized to the message passing process of GCNs, thereby guiding the message passing process at a relatively `high' level. The experimental results show that the proposed method outperforms almost all of the baselines on accuracy, stability, and time consumption. Additionally, the proposed method can be considered as a component that can underpin almost all GCN tasks, with DGCRL being demonstrated in the experiment. The anonymous code repository is available at: https://anonymous.4open.science/r/GCN-MPPR-AFD6/.", "AI": {"tldr": "Message passing neural networks (MPNNs) on graphs face challenges like over-smoothing, limited depth, and neglecting higher-order relationships. This paper introduces MPPR, a motif-based PageRank variant, to enhance message passing in GCNs and achieves better performance in terms of accuracy, stability, and computational efficiency.", "motivation": "Current MPNNs suffer from over-smoothing, limited propagation depth, and neglect higher-order relationships, leading to challenges in accuracy, stability, and computational efficiency.", "method": "Propose a novel variant of PageRank called motif-based personalized PageRank (MPPR) to incorporate higher-order relationships. MPPR is used to guide the message passing in GCNs.", "result": "Experimental results demonstrate significant improvements in accuracy, stability, and time efficiency compared to baseline methods. MPPR can be integrated into various GCN tasks.", "conclusion": "MPPR effectively addresses key limitations in MPNNs, enhancing their depth, accuracy, and efficiency, and serves as a versatile component for GCN frameworks."}}
{"id": "2602.07358", "pdf": "https://arxiv.org/pdf/2602.07358", "abs": "https://arxiv.org/abs/2602.07358", "authors": ["Jiaming He", "Fuming Luo", "Hongwei Li", "Wenbo Jiang", "Wenshu Fan", "Zhenbo Shi", "Xudong Jiang", "Yi Yu"], "title": "UTOPIA: Unlearnable Tabular Data via Decoupled Shortcut Embedding", "categories": ["cs.LG"], "comment": null, "summary": "Unlearnable examples (UE) have emerged as a practical mechanism to prevent unauthorized model training on private vision data, while extending this protection to tabular data is nontrivial. Tabular data in finance and healthcare is highly sensitive, yet existing UE methods transfer poorly because tabular features mix numerical and categorical constraints and exhibit saliency sparsity, with learning dominated by a few dimensions. Under a Spectral Dominance condition, we show certified unlearnability is feasible when the poison spectrum overwhelms the clean semantic spectrum. Guided by this, we propose Unlearnable Tabular Data via DecOuPled Shortcut EmbeddIng (UTOPIA), which exploits feature redundancy to decouple optimization into two channels: high saliency features for semantic obfuscation and low saliency redundant features for embedding a hyper correlated shortcut, yielding constraint-aware dominant shortcuts while preserving tabular validity. Extensive experiments across tabular datasets and models show UTOPIA drives unauthorized training toward near random performance, outperforming strong UE baselines and transferring well across architectures.", "AI": {"tldr": "The paper introduces a method for protecting sensitive tabular data from unauthorized model training by making data effectively unlearnable.", "motivation": "There is a need to extend the concept of unlearnable examples from vision-based datasets to tabular datasets, which are widely used in sensitive domains such as finance and healthcare.", "method": "The authors propose UTOPIA, a method that creates unlearnable tabular data through decoupling optimization into two channels\u2014semantic obfuscation for high saliency features and embedding shortcuts for low saliency redundant features.", "result": "UTOPIA achieves near random performance during unauthorized training across various tabular datasets and models, outperforming existing unlearnable example methods and transferring effectively across architectures.", "conclusion": "UTOPIA is a promising solution for creating unlearnable tabular data, preserving its validity while ensuring protection against unauthorized model usage."}}
{"id": "2602.08072", "pdf": "https://arxiv.org/pdf/2602.08072", "abs": "https://arxiv.org/abs/2602.08072", "authors": ["Md Nafiu Rahman", "Sadif Ahmed", "Zahin Wahab", "Gias Uddin", "Rifat Shahriyar"], "title": "IssueGuard: Real-Time Secret Leak Prevention Tool for GitHub Issue Reports", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "GitHub and GitLab are widely used collaborative platforms whose issue-tracking systems contain large volumes of unstructured text, including logs, code snippets, and configuration examples. This creates a significant risk of accidental secret exposure, such as API keys and credentials, yet these platforms provide no mechanism to warn users before submission. We present \\textsc{IssueGuard}, a tool for real-time detection and prevention of secret leaks in issue reports. Implemented as a Chrome extension, \\textsc{IssueGuard} analyzes text as users type and combines regex-based candidate extraction with a fine-tuned CodeBERT model for contextual classification. This approach effectively separates real secrets from false positives and achieves an F1-score of 92.70\\% on a benchmark dataset, outperforming traditional regex-based scanners. \\textsc{IssueGuard} integrates directly into the web interface and continuously analyzes the issue editor, presenting clear visual warnings to help users avoid submitting sensitive data. The source code is publicly available at \\href{https://github.com/nafiurahman00/IssueGuard}{https://github.com/nafiurahman00/IssueGuard}, and a demonstration video is available at \\href{https://youtu.be/kvbWA8rr9cU}{https://youtu.be/kvbWA8rr9cU}.", "AI": {"tldr": "GitHub and GitLab lack mechanisms to prevent secret leaks in issue reports. The paper introduces IssueGuard, a Chrome extension utilizing regex and CodeBERT to detect such leaks effectively, achieving a high F1-score of 92.70%.", "motivation": "To address the lack of mechanisms on platforms like GitHub and GitLab for preventing accidental secret exposure in issue reports.", "method": "IssueGuard employs a combination of regex-based extraction and a fine-tuned CodeBERT model for real-time text analysis, offering contextual secret classification.", "result": "IssueGuard achieves an F1-score of 92.70% in detecting secrets on a benchmark dataset and outperforms regex-based scanners.", "conclusion": "IssueGuard effectively prevents secret leaks in issue reports with high accuracy, providing a real-time solution integrated into the web interface."}}
{"id": "2602.08278", "pdf": "https://arxiv.org/pdf/2602.08278", "abs": "https://arxiv.org/abs/2602.08278", "authors": ["Ke Zhang", "Lixin Xu", "Chengyi Song", "Junzhe Xu", "Xiaoyi Lin", "Zeyu Jiang", "Renjing Xu"], "title": "DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer", "categories": ["cs.RO"], "comment": null, "summary": "Dexterous manipulation remains one of the most challenging problems in robotics, requiring coherent control of high-DoF hands and arms under complex, contact-rich dynamics. A major barrier is embodiment variability: different dexterous hands exhibit distinct kinematics and dynamics, forcing prior methods to train separate policies or rely on shared action spaces with per-embodiment decoder heads. We present DexFormer, an end-to-end, dynamics-aware cross-embodiment policy built on a modified transformer backbone that conditions on historical observations. By using temporal context to infer morphology and dynamics on the fly, DexFormer adapts to diverse hand configurations and produces embodiment-appropriate control actions. Trained over a variety of procedurally generated dexterous-hand assets, DexFormer acquires a generalizable manipulation prior and exhibits strong zero-shot transfer to Leap Hand, Allegro Hand, and Rapid Hand. Our results show that a single policy can generalize across heterogeneous hand embodiments, establishing a scalable foundation for cross-embodiment dexterous manipulation. Project website: https://davidlxu.github.io/DexFormer-web/.", "AI": {"tldr": "The paper introduces DexFormer, a transformer-based policy for dexterous manipulation that generalizes across diverse robotic hand embodiments without re-training.", "motivation": "To address the challenge of variability in kinematics and dynamics across different robotic dexterous hands, which hinders the development of generalizable manipulation policies.", "method": "The authors developed DexFormer, a modified transformer model that uses temporal context from historical observations to dynamically adapt control actions to various hand embodiments.", "result": "DexFormer, trained with diverse hand configurations, demonstrates strong zero-shot transfer capabilities to different hand setups like Leap Hand, Allegro Hand, and Rapid Hand.", "conclusion": "DexFormer establishes an effective and scalable approach to cross-embodiment dexterous manipulation, enabling generalizable solutions in robotics."}}
{"id": "2602.08100", "pdf": "https://arxiv.org/pdf/2602.08100", "abs": "https://arxiv.org/abs/2602.08100", "authors": ["Jasmine Cui", "Charles Ye"], "title": "Emergent Search and Backtracking in Latent Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.", "AI": {"tldr": "This paper explores latent reasoning transformers (LRTs), which reason in activation space rather than verbalizing intermediate reasoning steps, and uncovers structured search dynamics underlying their deliberation processes.", "motivation": "The paper aims to understand how latent reasoning transforms happen entirely within continuous activation space, investigating decision-making processes like exploration, commitment, and backtracking.", "method": "The authors decode the model's beliefs during intermediate reasoning steps on a multiple-choice QA benchmark, analyzing its latent-space structured search dynamics.", "result": "The model exhibits structured trajectories of reasoning, including exploration, tentative commitment, and adaptive backtracking, leading to improved accuracy, particularly when avoiding semantically nearest distractors.", "conclusion": "Latent reasoning models can achieve structured and adaptive reasoning in activation space, mirroring chain-of-thought processes, and demonstrating a capacity for identifying and recovering from errors."}}
{"id": "2602.07310", "pdf": "https://arxiv.org/pdf/2602.07310", "abs": "https://arxiv.org/abs/2602.07310", "authors": ["Kyle Williams", "Andrew Seltzman"], "title": "Optimization of Precipitate Segmentation Through Linear Genetic Programming of Image Processing", "categories": ["cs.CV", "cs.LG"], "comment": "39 pages, 12 figures, 1 table", "summary": "Current analysis of additive manufactured niobium-based copper alloys relies on hand annotation due to varying contrast, noise, and image artifacts present in micrographs, slowing iteration speed in alloy development. We present a filtering and segmentation algorithm for detecting precipitates in FIB cross-section micrographs, optimized using linear genetic programming (LGP), which accounts for the various artifacts. To this end, the optimization environment uses a domain-specific language for image processing to iterate on solutions. Programs in this language are a list of image-filtering blocks with tunable parameters that sequentially process an input image, allowing for reliable generation and mutation by a genetic algorithm. Our environment produces optimized human-interpretable MATLAB code representing an image filtering pipeline. Under ideal conditions--a population size of 60 and a maximum program length of 5 blocks--our system was able to find a near-human accuracy solution with an average evaluation error of 1.8% when comparing segmentations pixel-by-pixel to a human baseline using an XOR error evaluation. Our automation work enabled faster iteration cycles and furthered exploration of the material composition and processing space: our optimized pipeline algorithm processes a 3.6 megapixel image in about 2 seconds on average. This ultimately enables convergence on strong, low-activation, precipitation hardened copper alloys for additive manufactured fusion reactor parts.", "AI": {"tldr": "The paper proposes an automated algorithm using linear genetic programming (LGP) to optimize detection of precipitates in micrographs, achieving near-human accuracy and speeding alloy development.", "motivation": "Current methods rely on manual annotation, which is slow due to varying artifacts in micrographs, hindering rapid alloy development iterations.", "method": "Developed a filtering and segmentation algorithm optimized through linear genetic programming in a domain-specific image processing language, producing MATLAB code for reliable segmentation.", "result": "Achieved an average error of 1.8% compared to human segmentation, processing images quickly, and enabling faster exploration of copper alloys for fusion reactor components.", "conclusion": "The method speeds up alloy development by automating micrograph analysis and improves the development of strong, precipitation-hardened copper alloys."}}
{"id": "2602.08210", "pdf": "https://arxiv.org/pdf/2602.08210", "abs": "https://arxiv.org/abs/2602.08210", "authors": ["Hyungseok Song", "Deunsol Yoon", "Kanghoon Lee", "Han-Seul Jeong", "Soonyoung Lee", "Woohyung Lim"], "title": "CADO: From Imitation to Cost Minimization for Heatmap-based Solvers in Combinatorial Optimization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Heatmap-based solvers have emerged as a promising paradigm for Combinatorial Optimization (CO). However, we argue that the dominant Supervised Learning (SL) training paradigm suffers from a fundamental objective mismatch: minimizing imitation loss (e.g., cross-entropy) does not guarantee solution cost minimization. We dissect this mismatch into two deficiencies: Decoder-Blindness (being oblivious to the non-differentiable decoding process) and Cost-Blindness (prioritizing structural imitation over solution quality). We empirically demonstrate that these intrinsic flaws impose a hard performance ceiling. To overcome this limitation, we propose CADO (Cost-Aware Diffusion models for Optimization), a streamlined Reinforcement Learning fine-tuning framework that formulates the diffusion denoising process as an MDP to directly optimize the post-decoded solution cost. We introduce Label-Centered Reward, which repurposes ground-truth labels as unbiased baselines rather than imitation targets, and Hybrid Fine-Tuning for parameter-efficient adaptation. CADO achieves state-of-the-art performance across diverse benchmarks, validating that objective alignment is essential for unlocking the full potential of heatmap-based solvers.", "AI": {"tldr": "The paper critiques existing heatmap-based combinatorial optimization approaches using Supervised Learning (SL) and proposes a novel method, CADO, utilizing reinforcement learning for better solution quality.", "motivation": "The motivation comes from the mismatch in training objectives of current SL-based heatmap solvers, leading to suboptimal performance in terms of solution quality.", "method": "The method introduces CADO, a Reinforcement Learning-based fine-tuning framework, featuring a reformulated MDP-based diffusion process, Label-Centered Reward, and Hybrid Fine-Tuning.", "result": "CADO achieves state-of-the-art results across multiple combinatorial optimization benchmarks.", "conclusion": "The findings highlight the importance of aligning objectives, showing that the proposed cost-aware framework improves heatmap-based optimization significantly."}}
{"id": "2602.07905", "pdf": "https://arxiv.org/pdf/2602.07905", "abs": "https://arxiv.org/abs/2602.07905", "authors": ["Yu Zhao", "Hao Guan", "Yongcheng Jing", "Ying Zhang", "Dacheng Tao"], "title": "MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the additional costs translate into accuracy. In this paper, we explore how meta-cognition of LLMs, i.e., their self-awareness of their own knowledge states, can regulate the reasoning process. Specifically, we propose MedCoG, a Medical Meta-Cognition Agent with Knowledge Graph, where the meta-cognitive assessments of task complexity, familiarity, and knowledge density dynamically regulate utilization of procedural, episodic, and factual knowledge. The LLM-centric on-demand reasoning aims to mitigate scaling laws by (1) reducing costs via avoiding indiscriminate scaling, (2) improving accuracy via filtering out distractive knowledge. To validate this, we empirically characterize the scaling curve and introduce inference density to quantify inference efficiency, defined as the ratio of theoretically effective cost to actual cost. Experiments demonstrate the effectiveness and efficiency of MedCoG on five hard sets of medical benchmarks, yielding 5.5x inference density. Furthermore, the Oracle study highlights the significant potential of meta-cognitive regulation.", "AI": {"tldr": "The paper presents MedCoG, an LLM-based approach using meta-cognition and knowledge graphs to optimize medical reasoning, reducing costs and improving accuracy.", "motivation": "To address the issue of diminishing gains in LLMs under inference scaling laws and explore the effectiveness of meta-cognition in regulating medical reasoning processes.", "method": "MedCoG uses meta-cognition assessments (task complexity, familiarity, knowledge density) to regulate procedural, episodic, and factual knowledge. It measures inference density and optimizes reasoning processes dynamically.", "result": "Experiments show MedCoG achieves a 5.5x increase in inference density and demonstrate improved efficiency and accuracy in medical benchmarks.", "conclusion": "Meta-cognition-based regulation is effective in optimizing LLMs for medical reasoning by reducing costs and improving inference accuracy, highlighting its significant potential."}}
{"id": "2602.07364", "pdf": "https://arxiv.org/pdf/2602.07364", "abs": "https://arxiv.org/abs/2602.07364", "authors": ["Jianchuan Yang", "Xi Chen", "Jidong Zhao"], "title": "FEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity", "categories": ["cs.LG"], "comment": "43 pages, 26 figures, 8tables", "summary": "Graph neural networks (GNNs) naturally align with sparse operators and unstructured discretizations, making them a promising paradigm for physics-informed machine learning in computational mechanics. Motivated by discrete physics losses and Hierarchical Deep Learning Neural Network (HiDeNN) constructions, we embed finite-element (FEM) computations at nodes and Gauss points directly into message-passing layers and propose a numerically consistent FEM-Informed Hypergraph Neural Networks (FHGNN). Similar to conventional physics-informed neural networks (PINNs), training is purely physics-driven and requires no labeled data: the input is a node element hypergraph whose edges encode mesh connectivity. Guided by empirical results and condition-number analysis, we adopt an efficient variational loss. Validated on 3D benchmarks, including cyclic loading with isotropic/kinematic hardening, the proposed method delivers substantially improved accuracy and efficiency over recent, competitive PINN variants. By leveraging GPU-parallel tensor operations and the discrete representation, it scales effectively to large elastoplastic problems and can be competitive with, or faster than, multi-core FEM implementations at comparable accuracy. This work establishes a foundation for scalable, physics-embedded learning in nonlinear solid mechanics.", "AI": {"tldr": "The paper proposes a novel physics-informed hypergraph neural network (FHGNN) integrating finite element computations directly within GNN layers for computational mechanics.", "motivation": "The paper is motivated by the need for scalable and accurate physics-driven learning methods in nonlinear solid mechanics, particularly through embedding discrete physics computations within machine learning frameworks.", "method": "The authors introduce FHGNN, which integrates finite-element computations directly into graph neural network message-passing layers, using a variational loss function and GPU-parallel operations for training without labeled data.", "result": "The proposed method demonstrates superior accuracy and efficiency compared to recent physics-informed neural network variants, scaling effectively on 3D benchmarks including large elastoplastic problems.", "conclusion": "FHGNN establishes a foundation for physics-embedded learning in nonlinear solid mechanics, offering competitive computational performance and improved scalability."}}
{"id": "2602.08422", "pdf": "https://arxiv.org/pdf/2602.08422", "abs": "https://arxiv.org/abs/2602.08422", "authors": ["Benjamin Livshits"], "title": "LLMs + Security = Trouble", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "We argue that when it comes to producing secure code with AI, the prevailing \"fighting fire with fire\" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.\n  While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the \"vibe coding\" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees.\n  In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code.", "AI": {"tldr": "The paper argues for a proactive approach in AI-generated secure coding using enforced security constraints during code generation, highlighting shortcomings in current methods.", "motivation": "The study is motivated by the limitations of current AI approaches in securing probabilistically generated code, which leaves systems prone to zero-day vulnerabilities.", "method": "The authors propose enforcing security constraints during code generation, particularly with diffusion-style code models, to create secure-by-construction outputs.", "result": "They propose that this method provides stronger security guarantees and leverages hierarchical enforcement for modular security in code generation.", "conclusion": "Emphasizing security constraints during AI-driven code generation can lead to better security guarantees compared to post-detection and repair strategies."}}
{"id": "2602.08285", "pdf": "https://arxiv.org/pdf/2602.08285", "abs": "https://arxiv.org/abs/2602.08285", "authors": ["Josh Pinskier", "Sarah Baldwin", "Stephen Rodan", "David Howard"], "title": "ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects", "categories": ["cs.RO"], "comment": null, "summary": "Climate change, invasive species and human activities are currently damaging the world's coral reefs at unprecedented rates, threatening their vast biodiversity and fisheries, and reducing coastal protection. Solving this vast challenge requires scalable coral regeneration technologies that can breed climate-resilient species and accelerate the natural regrowth processes; actions that are impeded by the absence of safe and robust tools to handle the fragile coral. We investigate ReefFlex, a generative soft finger design methodology that explores a diverse space of soft fingers to produce a set of candidates capable of safely grasping fragile and geometrically heterogeneous coral in a cluttered environment. Our key insight is encoding heterogeneous grasping into a reduced set of motion primitives, creating a simplified, tractable multi-objective optimisation problem. To evaluate the method, we design a soft robot for reef rehabilitation, which grows and manipulates coral in onshore aquaculture facilities for future reef out-planting. We demonstrate ReefFlex increases both grasp success and grasp quality (disturbance resistance, positioning accuracy) and reduces in adverse events encountered during coral manipulation compared to reference designs. ReefFlex, offers a generalisable method to design soft end-effectors for complex handling and paves a pathway towards automation in previously unachievable domains like coral handling for restoration.", "AI": {"tldr": "ReefFlex introduces a soft finger design methodology for safely grasping fragile coral, aiding efforts in coral reef restoration.", "motivation": "The paper addresses the urgent need for scalable coral regeneration technologies amidst threats from climate change, invasive species, and human activities.", "method": "The methodology involves exploring a diverse design space of soft fingers using motion primitives to optimize for safe coral grasping, reducing complexity.", "result": "The design methodology increased grasp success, quality, and minimized adverse events during coral handling, compared to prior approaches.", "conclusion": "ReefFlex provides a generalizable method for soft robotic designs in challenging domains, paving the way for automated coral restoration technologies."}}
{"id": "2602.08124", "pdf": "https://arxiv.org/pdf/2602.08124", "abs": "https://arxiv.org/abs/2602.08124", "authors": ["Ke Xu", "Shera Potka", "Alex Thomo"], "title": "Gender and Race Bias in Consumer Product Recommendations by Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at the 39th International Conference on Advanced Information Networking and Applications (AINA 2025)", "summary": "Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.", "AI": {"tldr": "This paper examines gender and race biases embedded in Large Language Models (LLMs) used for product recommendations.", "motivation": "To explore and address potential biases in LLM-generated product recommendations and their impacts on demographic groups.", "method": "Used prompt engineering for eliciting recommendations from LLMs for different groups and employed analytical methods: Marked Words, Support Vector Machines, and Jensen-Shannon Divergence.", "result": "Findings highlight significant disparities in product recommendations across different race and gender groups.", "conclusion": "There is a need for more equitable recommendation systems in LLMs to minimize bias."}}
{"id": "2602.07311", "pdf": "https://arxiv.org/pdf/2602.07311", "abs": "https://arxiv.org/abs/2602.07311", "authors": ["Difei Gu", "Yunhe Gao", "Gerasimos Chatzoudis", "Zihan Dong", "Guoning Zhang", "Bangwei Guo", "Yang Zhou", "Mu Zhou", "Dimitris Metaxas"], "title": "LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Sparse autoencoders (SAEs) offer a natural path toward comparable explanations across different representation spaces. However, current SAEs are trained per modality, producing dictionaries whose features are not directly understandable and whose explanations do not transfer across domains. In this study, we introduce LUCID (Learning Unified vision-language sparse Codes for Interpretable concept Discovery), a unified vision-language sparse autoencoder that learns a shared latent dictionary for image patch and text token representations, while reserving private capacity for modality-specific details. We achieve feature alignment by coupling the shared codes with a learned optimal transport matching objective without the need of labeling. LUCID yields interpretable shared features that support patch-level grounding, establish cross-modal neuron correspondence, and enhance robustness against the concept clustering problem in similarity-based evaluation. Leveraging the alignment properties, we develop an automated dictionary interpretation pipeline based on term clustering without manual observations. Our analysis reveals that LUCID's shared features capture diverse semantic categories beyond objects, including actions, attributes, and abstract concepts, demonstrating a comprehensive approach to interpretable multimodal representations.", "AI": {"tldr": "The paper introduces LUCID, a unified vision-language sparse autoencoder achieving interpretable and shared representations across image and text modalities.", "motivation": "To address the lack of directly understandable and transferable explanations across modalities in current sparse autoencoders (SAEs).", "method": "The authors propose LUCID, which learns a shared latent dictionary for image and text modalities using a learned optimal transport matching objective.", "result": "LUCID demonstrates interpretable and robust shared features, enabling patch-level grounding, cross-modal neuron correspondence, and clustering automation without labels.", "conclusion": "LUCID advances interpretable multimodal representations by capturing diverse semantic categories, offering insights into actions, attributes, and abstract concepts."}}
{"id": "2602.08216", "pdf": "https://arxiv.org/pdf/2602.08216", "abs": "https://arxiv.org/abs/2602.08216", "authors": ["Gunn Kim"], "title": "Thermodynamic Isomorphism of Transformers: A Lagrangian Approach to Attention Dynamics", "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "comment": "9 pages, 1 figure. Based on a thermodynamic framework for Transformer architectures. Derives the equation of state from first principles", "summary": "Although the Transformer architecture has revolutionized artificial intelligence, its underlying mechanisms remain largely heuristic and lack a unified physical theory. In this work, we propose a first-principles framework for information dynamics, treating the attention mechanism as a physical system governed by the principle of least action rather than as an algorithmic optimization. By mapping information states to a Riemannian manifold with the Fisher information metric, we derive the intelligence Lagrangian. We show that the softmax function corresponds to the unique thermodynamic equilibrium state that minimizes the Helmholtz free energy of the information gas. In addition, we identify the query-key interaction as an electrodynamic coupling between an external field and an intrinsic dipole moment. This theory establishes the first law of information thermodynamics, unifying inference (mechanical work) and learning (chemical evolution). It also explains emergent phenomena, such as scaling laws and grokking, as phase transitions characterized by the divergence of specific heat. Finally, we discuss how rotational symmetry breaking in the attention manifold generates massless Goldstone bosons, providing a field-theoretic perspective on rotary positional embeddings (RoPE). Our work connects Statistical Physics and Deep Learning, laying the groundwork for a general theory of physics-based intelligence.", "AI": {"tldr": "The paper presents a first-principles framework treating Transformers as a physical system governed by the principle of least action, linking Statistical Physics and Deep Learning.", "motivation": "To address the lack of a unified physical theory behind the Transformer's functionality and its heuristic design.", "method": "Develops a theoretical framework that maps information states onto a Riemannian manifold with the Fisher information metric, derives the intelligence Lagrangian, and applies principles from thermodynamics and field theory to explain neural attention mechanisms.", "result": "Derives insights like the thermodynamic basis of the softmax function and the electrodynamic interactions in attention mechanisms. Explains emergent phenomena such as scaling laws and grokking as phase transitions.", "conclusion": "Provides a physics-based theory unifying inference, learning, and emergent phenomena in Transformers, offering a novel perspective on their operation rooted in Statistical Physics."}}
{"id": "2602.07919", "pdf": "https://arxiv.org/pdf/2602.07919", "abs": "https://arxiv.org/abs/2602.07919", "authors": ["Mansi", "Avinash Kori", "Francesca Toni", "Soteris Demetriou"], "title": "Selective Fine-Tuning for Targeted and Robust Concept Unlearning", "categories": ["cs.AI", "cs.CV"], "comment": "Given the brittle nature of existing methods in unlearning harmful content in diffusion models, we propose TRuST, a novel approach for dynamically estimating target concept neurons and unlearning them by selectively fine-tuning", "summary": "Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.", "AI": {"tldr": "The paper introduces TRUST, a learning method to restrict harmful content generation in text-guided diffusion models by selectively unlearning targeted concepts. The approach maintains quality, handles complex concept scenarios, and improves computational efficiency compared to existing methods.", "motivation": "The motivation is to address the misuse of text-guided diffusion models in creating harmful content by devising an efficient and robust method to unlearn harmful concepts, while overcoming the challenges related to static concept localization and high computational costs.", "method": "The TRUST method dynamically identifies concept-related neurons and selectively fine-tunes them, utilizing a Hessian-based regularization for efficient and robust unlearning of harmful concepts or their combinations.", "result": "TRUST demonstrates strong performance in robustly unlearning harmful concepts while preserving generation quality. It also outperforms SOTA methods in terms of speed and the ability to handle adversarial prompts as well as concept combinations.", "conclusion": "TRUST is an effective approach for controlling harmful content in diffusion models. It offers a scalable, quality-preserving, and computationally efficient method for unlearning multiple and complex concepts, providing a significant improvement over previous methods."}}
{"id": "2602.08517", "pdf": "https://arxiv.org/pdf/2602.08517", "abs": "https://arxiv.org/abs/2602.08517", "authors": ["Shaoang Zhang", "Yazhe Niu"], "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.", "AI": {"tldr": "This paper introduces TreeTensor, a novel approach to efficiently process nested data structures in AI systems which overcomes the limitations of conventional Tensors. It facilitates operations on hierarchical data with minimal overhead.", "motivation": "Conventional Tensors struggle to handle nested and hierarchical data structures effectively, limiting their use in complex AI systems with multimodal data. There is a need for a more flexible data representation to address these challenges.", "method": "The authors designed a general nested data container, TreeTensor, which uses a constrained tree-structure model to process hierarchical data. It integrates seamlessly with existing ML libraries, enabling efficient operations and extensions like asynchronous execution and variable-length data computation.", "result": "TreeTensor demonstrated powerful usability in solving nested data problems, achieved significant runtime efficiency without overhead, and was successfully applied in complex scenarios such as AlphaStar for StarCraft II.", "conclusion": "TreeTensor simplifies and optimizes the manipulation of nested data structures, proving its value in advanced AI systems by enhancing usability and maintaining computational efficiency."}}
{"id": "2602.08298", "pdf": "https://arxiv.org/pdf/2602.08298", "abs": "https://arxiv.org/abs/2602.08298", "authors": ["Yuxin Zhang", "Cheng Wang", "Hubert P. H. Shum"], "title": "Benchmarking Autonomous Vehicles: A Driver Foundation Model Framework", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous vehicles (AVs) are poised to revolutionize global transportation systems. However, its widespread acceptance and market penetration remain significantly below expectations. This gap is primarily driven by persistent challenges in safety, comfort, commuting efficiency and energy economy when compared to the performance of experienced human drivers. We hypothesize that these challenges can be addressed through the development of a driver foundation model (DFM). Accordingly, we propose a framework for establishing DFMs to comprehensively benchmark AVs. Specifically, we describe a large-scale dataset collection strategy for training a DFM, discuss the core functionalities such a model should possess, and explore potential technical solutions to realize these functionalities. We further present the utility of the DFM across the operational spectrum, from defining human-centric safety envelopes to establishing benchmarks for energy economy. Overall, We aim to formalize the DFM concept and introduce a new paradigm for the systematic specification, verification and validation of AVs.", "AI": {"tldr": "The paper discusses the challenges of autonomous vehicles (AVs) and introduces the concept of a Driver Foundation Model (DFM) to improve performance and benchmark AVs.", "motivation": "To address the challenges of AVs in safety, comfort, commuting efficiency, and energy economy, and ensure they match or exceed human driver performance.", "method": "Propose a framework for a Driver Foundation Model (DFM), design a data collection strategy, identify core model functionalities, and explore technical solutions for implementation and benchmarking.", "result": "Introduced the concept of a Driver Foundation Model, its utility in setting safety standards, and its role in improving and validating AV performance.", "conclusion": "The Driver Foundation Model provides a systematic approach to enhance AV performance, ensure human-centric safety, and establish benchmarks for further development."}}
{"id": "2602.08149", "pdf": "https://arxiv.org/pdf/2602.08149", "abs": "https://arxiv.org/abs/2602.08149", "authors": ["Sahana Ramnath", "Nima Chitsazan", "Mingyang Zhou", "Chia-Hsuan Lee", "Shi-Xiong Zhang", "Stephen Rawls", "Sambit Sahu", "Sangwoo Cho", "Xiang Ren", "Genta Indra Winata", "Akshaj Kumar Veldanda"], "title": "DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.", "AI": {"tldr": "The paper introduces DIALSUMMER, a framework to evaluate dialogue summaries comprehensively using a proposed taxonomy addressing challenges like structural and narration shifts.", "motivation": "To improve evaluation methods for automatically generated dialogue summaries by addressing complexities in structural shifts and narration viewpoint changes.", "method": "Developed DIALSUMMER taxonomy for hierarchical error evaluation, created a dataset with manually annotated errors, and conducted empirical analyses and experiments on large language models.", "result": "Identified trends like middle-turn information frequently being missed and extrinsic hallucinations at the summary's end, validating the taxonomy's robustness and dataset's challenging nature.", "conclusion": "The proposed framework and taxonomy are promising tools for dialogue summary evaluation, indicating a need for enhanced performance from LLMs in this domain and future research focus."}}
{"id": "2602.07343", "pdf": "https://arxiv.org/pdf/2602.07343", "abs": "https://arxiv.org/abs/2602.07343", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Robust semantic segmentation of road scenes under adverse illumination, lighting, and shadow conditions remain a core challenge for autonomous driving applications. RGB-Thermal fusion is a standard approach, yet existing methods apply static fusion strategies uniformly across all conditions, allowing modality-specific noise to propagate throughout the network. Hence, we propose CLARITY that dynamically adapts its fusion strategy to the detected scene condition. Guided by vision-language model (VLM) priors, the network learns to modulate each modality's contribution based on the illumination state while leveraging object embeddings for segmentation, rather than applying a fixed fusion policy. We further introduce two mechanisms, i.e., one which preserves valid dark-object semantics that prior noise-suppression methods incorrectly discard, and a hierarchical decoder that enforces structural consistency across scales to sharpen boundaries on thin objects. Experiments on the MFNet dataset demonstrate that CLARITY establishes a new state-of-the-art (SOTA), achieving 62.3% mIoU and 77.5% mAcc.", "AI": {"tldr": "This paper introduces CLARITY, a dynamic RGB-Thermal fusion method adapting to scene conditions for improved road scene segmentation under challenging lighting.", "motivation": "To address the challenge of effective semantic segmentation under adverse lighting via an adaptive fusion method that mitigates noise propagation in autonomous driving contexts.", "method": "CLARITY adjusts RGB-Thermal fusion dynamically based on illumination states using VLM priors, preserving dark-object semantics and enhancing structural consistency with a hierarchical decoder.", "result": "CLARITY outperforms existing methods, achieving state-of-the-art results with 62.3% mIoU and 77.5% mAcc on the MFNet dataset.", "conclusion": "CLARITY showcases the importance of dynamic fusion strategies for robust performance in complex lighting contexts, setting new benchmarks in segmentation accuracy."}}
{"id": "2602.08232", "pdf": "https://arxiv.org/pdf/2602.08232", "abs": "https://arxiv.org/abs/2602.08232", "authors": ["Ruichen Jiang", "Zakaria Mhammedi", "Mehryar Mohri", "Aryan Mokhtari"], "title": "Adaptive Matrix Online Learning through Smoothing with Guarantees for Nonsmooth Nonconvex Optimization", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "37 pages, 1 figure", "summary": "We study online linear optimization with matrix variables constrained by the operator norm, a setting where the geometry renders designing data-dependent and efficient adaptive algorithms challenging. The best-known adaptive regret bounds are achieved by Shampoo-like methods, but they require solving a costly quadratic projection subproblem. To address this, we extend the gradient-based prediction scheme to adaptive matrix online learning and cast algorithm design as constructing a family of smoothed potentials for the nuclear norm. We define a notion of admissibility for such smoothings and prove any admissible smoothing yields a regret bound matching the best-known guarantees of one-sided Shampoo. We instantiate this framework with two efficient methods that avoid quadratic projections. The first is an adaptive Follow-the-Perturbed-Leader (FTPL) method using Gaussian stochastic smoothing. The second is Follow-the-Augmented-Matrix-Leader (FAML), which uses a deterministic hyperbolic smoothing in an augmented matrix space. By analyzing the admissibility of these smoothings, we show both methods admit closed-form updates and match one-sided Shampoo's regret up to a constant factor, while significantly reducing computational cost. Lastly, using the online-to-nonconvex conversion, we derive two matrix-based optimizers, Pion (from FTPL) and Leon (from FAML). We prove convergence guarantees for these methods in nonsmooth nonconvex settings, a guarantee that the popular Muon optimizer lacks.", "AI": {"tldr": "This paper addresses online linear optimization with operator norm-constrained matrix variables and develops efficient adaptive algorithms that match the best-known regret bounds without incurring high computational costs.", "motivation": "The study aims to solve challenges in designing data-adaptive, efficient algorithms for online matrix optimization under operator norm constraints, where current methods like Shampoo require expensive computations.", "method": "The authors propose a framework using smoothed potentials for the nuclear norm and design two efficient, closed-form update algorithms: adaptive FTPL with Gaussian smoothing and FAML with hyperbolic smoothing.", "result": "Both methods achieve regret bounds comparable to Shampoo-like approaches but with reduced computational cost. Furthermore, they extend the framework to derive two optimizers (Pion, Leon) with convergence guarantees in nonsmooth nonconvex scenarios.", "conclusion": "The proposed methods provide computationally efficient alternatives to existing adaptive algorithms with strong theoretical guarantees, improving scalability and versatility for nonsmooth optimization problems."}}
{"id": "2602.07940", "pdf": "https://arxiv.org/pdf/2602.07940", "abs": "https://arxiv.org/abs/2602.07940", "authors": ["Guanglong Sun", "Hongwei Yan", "Liyuan Wang", "Zhiqi Kang", "Shuang Cui", "Hang Su", "Jun Zhu", "Yi Zhong"], "title": "MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learnin", "categories": ["cs.AI"], "comment": null, "summary": "To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust output alignment. MePo serves as a plug-in strategy that achieves significant performance gains across a variety of GCL benchmarks and pretrained checkpoints in a rehearsal-free manner (e.g., 15.10\\%, 13.36\\%, and 12.56\\% on CIFAR-100, ImageNet-R, and CUB-200 under Sup-21/1K). Our source code is available at \\href{https://github.com/SunGL001/MePo}{MePo}", "AI": {"tldr": "This paper introduces a method named Meta Post-Refinement (MePo) to enhance general continual learning (GCL) performance by refining pretrained models and utilizing second-order statistics in a rehearsal-free manner.", "motivation": "To enhance the ability of intelligent systems to cope with uncertain, evolving environments and leverage pretrained models for improved general continual learning.", "method": "The proposed Meta Post-Refinement (MePo) constructs pseudo task sequences from pretraining data, uses a bi-level meta-learning approach for pretrained backbone refinement, and utilizes a meta covariance matrix for robust representation space alignment.", "result": "MePo achieves significant performance improvements across GCL benchmarks and pretrained checkpoints without requiring rehearsal, with gains such as 15.10% on CIFAR-100, 13.36% on ImageNet-R, and 12.56% on CUB-200 under Sup-21/1K.", "conclusion": "MePo provides a plug-in strategy that enhances GCL performance by refining pretrained models and leveraging second-order statistics, promoting rapid adaptation without rehearsal."}}
{"id": "2602.08750", "pdf": "https://arxiv.org/pdf/2602.08750", "abs": "https://arxiv.org/abs/2602.08750", "authors": ["Guy Farrelly", "Michael Chesser", "Seyit Camtepe", "Damith C. Ranasinghe"], "title": "DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing", "categories": ["cs.CR", "cs.SE"], "comment": "Accepted to ICSE 2026", "summary": "The rise of smart devices in critical domains--including automotive, medical, industrial--demands robust firmware testing. Fuzzing firmware in re-hosted environments is a promising method for automated testing at scale, but remains difficult due to the tight coupling of code with a microcontroller's peripherals. Existing fuzzing frameworks primarily address input challenges in providing inputs for Memory-Mapped I/O or interrupts, but largely overlook Direct Memory Access (DMA), a key high-throughput interface used that bypasses the CPU. We introduce DyMA-Fuzz to extend recent advances in stream-based fuzz input injection to DMA-driven interfaces in re-hosted environments. It tackles key challenges--vendor-specific descriptors, heterogeneous DMA designs, and varying descriptor locations--using runtime analysis techniques to infer DMA memory access patterns and automatically inject fuzzing data into target buffers, without manual configuration or datasheets. Evaluated on 94 firmware samples and 8 DMA-guarded CVE benchmarks, DyMA-Fuzz reveals vulnerabilities and execution paths missed by state-of-the-art tools and achieves up to 122% higher code coverage. These results highlight DyMA-Fuzz as a practical and effective advancement in automated firmware testing and a scalable solution for fuzzing complex embedded systems.", "AI": {"tldr": "DyMA-Fuzz is a firmware testing tool that extends fuzzing to handle Direct Memory Access (DMA) interfaces, improving testing efficacy and uncovering vulnerabilities in embedded systems.", "motivation": "Efficient firmware testing is critical for safety and security in domains like automotive, medical, and industrial systems, but traditional methods struggle to handle the DMA interface, an important but challenging component in firmware testing.", "method": "DyMA-Fuzz uses runtime analysis to infer DMA memory access patterns and automatically injects fuzzing data into target buffers. It is designed to work without manual configuration or vendor datasheets and tackles challenges such as vendor-specific descriptors and heterogeneous designs.", "result": "DyMA-Fuzz successfully identified vulnerabilities and execution paths missed by other tools, providing up to 122% higher code coverage in testing 94 firmware samples and 8 benchmarks.", "conclusion": "DyMA-Fuzz is demonstrated to be an effective and scalable solution for automated firmware testing, addressing key challenges in fuzzing embedded systems."}}
{"id": "2602.08326", "pdf": "https://arxiv.org/pdf/2602.08326", "abs": "https://arxiv.org/abs/2602.08326", "authors": ["Yongjae Lim", "Dabin Kim", "H. Jin Kim"], "title": "Personalized Autonomous Driving via Optimal Control with Clearance Constraints from Questionnaires", "categories": ["cs.RO"], "comment": null, "summary": "Driving without considering the preferred separation distance from surrounding vehicles may cause discomfort for users. To address this limitation, we propose a planning framework that explicitly incorporates user preferences regarding the desired level of safe clearance from surrounding vehicles. We design a questionnaire purposefully tailored to capture user preferences relevant to our framework, while minimizing unnecessary questions. Specifically, the questionnaire considers various interaction-relevant factors, including the surrounding vehicle's size, speed, position, and maneuvers of surrounding vehicles, as well as the maneuvers of the ego vehicle. The response indicates the user-preferred clearance for the scenario defined by the question and is incorporated as constraints in the optimal control problem. However, it is impractical to account for all possible scenarios that may arise in a driving environment within a single optimal control problem, as the resulting computational complexity renders real-time implementation infeasible. To overcome this limitation, we approximate the original problem by decomposing it into multiple subproblems, each dealing with one fixed scenario. We then solve these subproblems in parallel and select one using the cost function from the original problem. To validate our work, we conduct simulations using different user responses to the questionnaire. We assess how effectively our planner reflects user preferences compared to preference-agnostic baseline planners by measuring preference alignment.", "AI": {"tldr": "The paper introduces a planning framework for vehicles that incorporates user preferences for safe distances from surrounding vehicles, using a tailored questionnaire and an optimized computational approach.", "motivation": "To address user discomfort caused by driving that ignores personal preferences for vehicle separation distances and create a customizable user-based driving strategy.", "method": "The framework uses a customized questionnaire to capture user preferences for vehicle separation, then incorporates these preferences as constraints in an optimal control problem. Computational complexity is reduced by decomposing the problem into manageable subproblems solved in parallel.", "result": "Simulations show that the proposed system better aligns with user preferences compared to traditional, preference-agnostic planners.", "conclusion": "The approach effectively captures and implements user preferences in vehicle control systems, addressing real-world feasibility through computational optimization."}}
{"id": "2602.08162", "pdf": "https://arxiv.org/pdf/2602.08162", "abs": "https://arxiv.org/abs/2602.08162", "authors": ["Ricardo Campos", "Jos\u00e9 Pedro Evans", "Jos\u00e9 Miguel Isidro", "Miguel Marques", "Lu\u00eds Filipe Cunha", "Al\u00edpio Jorge", "S\u00e9rgio Nunes", "Nuno Guimar\u00e3es"], "title": "NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark", "categories": ["cs.CL"], "comment": null, "summary": "Local governance meeting records are official documents, in the form of minutes or transcripts, documenting how proposals, discussions, and procedural actions unfold during institutional meetings. While generally structured, these documents are often dense, bureaucratic, and highly heterogeneous across municipalities, exhibiting significant variation in language, terminology, structure, and overall organization. This heterogeneity makes them difficult for non-experts to interpret and challenging for intelligent automated systems to process, limiting public transparency and civic engagement. To address these challenges, computational methods can be employed to structure and interpret such complex documents. In particular, Natural Language Processing (NLP) offers well-established methods that can enhance the accessibility and interpretability of governmental records. In this focus article, we review foundational NLP tasks that support the structuring of local governance meeting documents. Specifically, we review three core tasks: document segmentation, domain-specific entity extraction and automatic text summarization, which are essential for navigating lengthy deliberations, identifying political actors and personal information, and generating concise representations of complex decision-making processes. In reviewing these tasks, we discuss methodological approaches, evaluation metrics, and publicly available resources, while highlighting domain-specific challenges such as data scarcity, privacy constraints, and source variability. By synthesizing existing work across these foundational tasks, this article provides a structured overview of how NLP can enhance the structuring and accessibility of local governance meeting records.", "AI": {"tldr": "The paper examines how Natural Language Processing (NLP) can improve the structuring and accessibility of complex documents from local governance meetings, focusing on segmentation, entity extraction, and summarization.", "motivation": "The motivation is to address challenges posed by the dense, heterogeneous nature of local governance meeting records, which are difficult for non-experts and automated systems to interpret, limiting transparency and civic engagement.", "method": "The paper reviews and synthesizes NLP methods, including document segmentation, entity extraction, and summarization, while considering evaluation metrics, publicly available resources, and addressing domain-specific challenges like data scarcity and privacy.", "result": "The study provides insights into how NLP tasks can be applied to structure and interpret dense and variable local governance documents, improving accessibility and interpretability.", "conclusion": "NLP offers valuable methods to overcome challenges in structuring and improving access to governance records, facilitating better transparency and civic participation."}}
{"id": "2602.07345", "pdf": "https://arxiv.org/pdf/2602.07345", "abs": "https://arxiv.org/abs/2602.07345", "authors": ["Lichen Bai", "Zikai Zhou", "Shitong Shao", "Wenliang Zhong", "Shuo Yang", "Shuo Chen", "Bojun Chen", "Zeke Xie"], "title": "Optimizing Few-Step Generation with Adaptive Matching Distillation", "categories": ["cs.CV", "cs.LG"], "comment": "25 pages, 15 figures, 11 tables", "summary": "Distribution Matching Distillation (DMD) is a powerful acceleration paradigm, yet its stability is often compromised in Forbidden Zone, regions where the real teacher provides unreliable guidance while the fake teacher exerts insufficient repulsive force. In this work, we propose a unified optimization framework that reinterprets prior art as implicit strategies to avoid these corrupted regions. Based on this insight, we introduce Adaptive Matching Distillation (AMD), a self-correcting mechanism that utilizes reward proxies to explicitly detect and escape Forbidden Zones. AMD dynamically prioritizes corrective gradients via structural signal decomposition and introduces Repulsive Landscape Sharpening to enforce steep energy barriers against failure mode collapse. Extensive experiments across image and video generation tasks (e.g., SDXL, Wan2.1) and rigorous benchmarks (e.g., VBench, GenEval) demonstrate that AMD significantly enhances sample fidelity and training robustness. For instance, AMD improves the HPSv2 score on SDXL from 30.64 to 31.25, outperforming state-of-the-art baselines. These findings validate that explicitly rectifying optimization trajectories within Forbidden Zones is essential for pushing the performance ceiling of few-step generative models.", "AI": {"tldr": "Adaptive Matching Distillation (AMD) explicitly rectifies trajectories within Forbidden Zones to enhance sample fidelity and training robustness for generative models.", "motivation": "Address challenges in Distribution Matching Distillation caused by Forbidden Zones, compromising stability and acceleration effectiveness in generative models.", "method": "Introduce AMD with mechanisms like reward proxies to detect and escape Forbidden Zones, and Repulsive Landscape Sharpening to enforce barriers against failure mode collapse.", "result": "Experiments across SDXL, Wan2.1, and other benchmarks show AMD significantly enhances performance, e.g., improving the HPSv2 score on SDXL to 31.25.", "conclusion": "Rectifying optimization pathways within corrupted regions like Forbidden Zones is vital for achieving higher generative model performance and training stability."}}
{"id": "2602.08287", "pdf": "https://arxiv.org/pdf/2602.08287", "abs": "https://arxiv.org/abs/2602.08287", "authors": ["Themistoklis Haris", "Zihan Zhang", "Yuichi Yoshida"], "title": "Noise Stability of Transformer Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Published in ICLR 2026", "summary": "Understanding simplicity biases in deep learning offers a promising path toward developing reliable AI. A common metric for this, inspired by Boolean function analysis, is average sensitivity, which captures a model's robustness to single-token perturbations. We argue that average sensitivity has two key limitations: it lacks a natural generalization to real-valued domains and fails to explain the \"junta-like\" input dependence we empirically observe in modern LLMs. To address these limitations, we propose noise stability as a more comprehensive simplicity metric. Noise stability expresses a model's robustness to correlated noise applied to all input coordinates simultaneously. We provide a theoretical analysis of noise stability for single-layer attention and ReLU MLP layers and tackle the multi-layer propagation problem with a covariance interval propagation approach. Building on this theory, we develop a practical noise stability regularization method. Experiments on algorithmic and next-token-prediction tasks show that our regularizer consistently catalyzes grokking and accelerates training by approximately $35\\%$ and $75\\%$ respectively. Our results sculpt a new connection between signal propagation in neural networks and interpretability, with noise stability emerging as a powerful tool for understanding and improving modern Transformers.", "AI": {"tldr": "This paper presents noise stability as a superior metric for understanding model robustness compared to average sensitivity, addressing its limitations with theoretical and experimental validation.", "motivation": "The motivation is to overcome the limitations of average sensitivity in explaining robustness for models with real-valued domains and junta-like input dependence observed in modern LLMs.", "method": "The authors propose noise stability as a new simplicity metric, analyze it theoretically for certain neural network layers, and develop a practical noise stability regularization method.", "result": "The proposed noise stability regularizer accelerates training by approximately 35% and 75%, and shows consistent improvement in grokking and interpretability in experiments.", "conclusion": "Noise stability proves to be a significant enhancement for understanding and improving signal propagation and interpretability in modern transformers."}}
{"id": "2602.07943", "pdf": "https://arxiv.org/pdf/2602.07943", "abs": "https://arxiv.org/abs/2602.07943", "authors": ["Ivaxi Sheth", "Zhijing Jin", "Bryan Wilder", "Dominik Janzing", "Mario Fritz"], "title": "IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery", "categories": ["cs.AI"], "comment": "18 pages", "summary": "In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.", "AI": {"tldr": "This paper explores the use of large language models (LLMs) to identify valid instrumental variables (IVs) in the context of causal inference.", "motivation": "Finding valid instrumental variables is a challenging task requiring a combination of interdisciplinary knowledge, creativity, and contextual understanding.", "method": "The authors conducted a two-stage evaluation: testing LLMs' ability to replicate established IVs and their capability to avoid discredited IVs. They introduced the IV Co-Scientist system for proposing and refining IVs and developed a statistical test for consistency without ground truth.", "result": "The study demonstrated the potential of LLMs to identify valid IVs from large observational datasets.", "conclusion": "LLMs show promise in aiding the identification of instrumental variables required for isolating causal effects in the presence of confounding."}}
{"id": "2602.07397", "pdf": "https://arxiv.org/pdf/2602.07397", "abs": "https://arxiv.org/abs/2602.07397", "authors": ["Hoang Anh Duy Le", "Sahil Joshi", "Zeyu Yang", "Zhaozhuo Xu", "Anshumali Shrivastava"], "title": "Scout Before You Attend: Sketch-and-Walk Sparse Attention for Efficient LLM Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-attention dominates the computational and memory cost of long-context LLM inference across both prefill and decode phases. To address this challenge, we introduce Sketch&Walk Attention, a training-free sparse attention method that determines sparsity with lightweight sketches and deterministic walk. Sketch&Walk applies Hadamard sketching to get inexpensive approximations of attention scores, then aggregates these estimates across layers via a walk mechanism that captures attention influence beyond direct interactions between tokens. The accumulated walk scores are used to select top-k attention blocks, enabling dynamic sparsity with a single training-free algorithm that applies uniformly to both the prefill and decode phases, together with custom sparse attention kernels. Across a wide range of models and tasks, Sketch&Walk maintains near-lossless accuracy at 20% attention density and can slightly outperform dense attention in some settings, while achieving up to 6x inference speedup.", "AI": {"tldr": "The paper introduces Sketch&Walk Attention, a training-free sparse attention method for accelerating long-context LLM inference while maintaining near-lossless accuracy.", "motivation": "Self-attention in long-context LLM inference is computationally and memory-intensive in both prefill and decode phases.", "method": "Sketch&Walk Attention uses Hadamard sketching for sparse attention score approximations and a deterministic walk mechanism for aggregating influence across layers.", "result": "Sketch&Walk achieves significant inference speedup (up to 6x) at 20% attention density while preserving accuracy and outperforming dense attention in some scenarios.", "conclusion": "Sketch&Walk is an efficient, training-free method for sparse attention that enhances LLM inference performance across models and tasks."}}
{"id": "2602.08801", "pdf": "https://arxiv.org/pdf/2602.08801", "abs": "https://arxiv.org/abs/2602.08801", "authors": ["Thanh Le", "Hai Duong", "ThanhVu Nguyen", "Takeshi Matsumura"], "title": "Verifying DNN-based Semantic Communication Against Generative Adversarial Noise", "categories": ["cs.LO", "cs.SE"], "comment": "18 pages", "summary": "Safety-critical applications like autonomous vehicles and industrial IoT are adopting semantic communication (SemCom) systems using deep neural networks to reduce bandwidth and increase transmission speed by transmitting only task-relevant semantic features.\n  However, adversarial attacks against these DNN-based SemCom systems can cause catastrophic failures by manipulating transmitted semantic features.\n  Existing defense mechanisms rely on empirical approaches provide no formal guarantees against the full spectrum of adversarial perturbations.\n  We present VSCAN, a neural network verification framework that provides mathematical robustness guarantees by formulating adversarial noise generation as mixed integer programming and verifying end-to-end properties across multiple interconnected networks (encoder, decoder, and task model).\n  Our key insight is that realistic adversarial constraints (power limitations and statistical undetectability) can be encoded as logical formulae to enable efficient verification using state-of-the-art DNN verifiers.\n  Our evaluation on 600 verification properties characterizing various attacker's capabilities shows VSCAN matches attack methods in finding vulnerabilities while providing formal robustness guarantees for 44% of properties -- a significant achievement given the complexity of multi-network verification.\n  Moreover, we reveal a fundamental security-efficiency tradeoff: compact 16-dimensional latent spaces achieve 50% verified robustness compared to 64-dimensional spaces.", "AI": {"tldr": "The paper presents VSCAN, a framework offering mathematical robustness for neural network-based semantic communication systems, ensuring mitigation of adversarial attacks.", "motivation": "Deep neural network-based semantic communication systems are crucial for safety-critical applications but are vulnerable to adversarial attacks, and existing solutions lack formal guarantees.", "method": "The authors propose VSCAN, which utilizes mixed integer programming and logical encoding of adversarial constraints for verifying interconnected neural networks' robustness under adversarial perturbations.", "result": "VSCAN achieves formal robustness guarantees for 44% of evaluated properties across interconnected models and identifies a tradeoff between robustness and efficiency in semantic features' latent space dimensions.", "conclusion": "This framework demonstrates the feasibility and importance of formal verification in mitigating adversarial risks for semantic communication systems, especially in safety-critical domains."}}
{"id": "2602.08328", "pdf": "https://arxiv.org/pdf/2602.08328", "abs": "https://arxiv.org/abs/2602.08328", "authors": ["Yi-Hsuan Hsiao", "Quang Phuc Kieu", "Zhongtao Guan", "Suhan Kim", "Jiaze Cai", "Owen Matteson", "Jonathan P. How", "Elizabeth Farrell Helbling", "YuFeng Chen"], "title": "Controlled Flight of an Insect-Scale Flapping-Wing Robot via Integrated Onboard Sensing and Computation", "categories": ["cs.RO", "eess.SY"], "comment": "22 pages, 7 figures", "summary": "Aerial insects can effortlessly navigate dense vegetation, whereas similarly sized aerial robots typically depend on offboard sensors and computation to maintain stable flight. This disparity restricts insect-scale robots to operation within motion capture environments, substantially limiting their applicability to tasks such as search-and-rescue and precision agriculture. In this work, we present a 1.29-gram aerial robot capable of hovering and tracking trajectories with solely onboard sensing and computation. The combination of a sensor suite, estimators, and a low-level controller achieved centimeter-scale positional flight accuracy. Additionally, we developed a hierarchical controller in which a human operator provides high-level commands to direct the robot's motion. In a 30-second flight experiment conducted outside a motion capture system, the robot avoided obstacles and ultimately landed on a sunflower. This level of sensing and computational autonomy represents a significant advancement for the aerial microrobotics community, further opening opportunities to explore onboard planning and power autonomy.", "AI": {"tldr": "This study introduces a 1.29-gram aerial robot capable of accurately hovering with onboard sensors and computation, overcoming the need for external systems.", "motivation": "To bridge the gap between the autonomous navigation abilities of insects and the reliance of insect-scale robots on offboard systems for stable flight, which limits their practical applications.", "method": "Developed a 1.29-gram aerial robot with a sensor suite, estimators, and a hierarchical controller for onboard sensing and motion control.", "result": "Achieved centimeter-level positional accuracy in flight experiments, including obstacle avoidance and landing autonomously on a sunflower.", "conclusion": "The work demonstrates a significant leap in aerial microrobotics, enabling autonomy in sensing and computation, paving the way for further advancements in onboard planning and power autonomy."}}
{"id": "2602.08208", "pdf": "https://arxiv.org/pdf/2602.08208", "abs": "https://arxiv.org/abs/2602.08208", "authors": ["Cameron R. Jones", "Agnese Lombardi", "Kyle Mahowald", "Benjamin K. Bergen"], "title": "LLMs and people both learn to form conventions -- just not with each other", "categories": ["cs.CL", "cs.HC"], "comment": "10 pages, 4 figures", "summary": "Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.", "AI": {"tldr": "The study investigates whether large language models (LLMs) can form conversational conventions like humans in a communication game. While LLMs align well in AI-AI interactions, their alignment with humans is limited.", "motivation": "To explore whether LLMs exhibit the human-like ability to adopt shared conventions during communication, particularly when interacting with humans versus other AI systems.", "method": "The authors conducted experiments where humans and LLMs participated in multimodal communication games in different pairings (human-human, human-AI, AI-AI). Additionally, in Experiment 2, they prompted LLMs to mimic human-like behavior.", "result": "LLMs showed evidence of convention-formation in AI-AI interactions, like increasing accuracy and consistency while reducing message length. However, human-AI pairs struggled to align, even with prompting LLMs to imitate humans.", "conclusion": "Effective conversational alignment requires more than superficial mimicry. The underlying shared interpretative biases humans rely on for understanding meaning are not fully replicated in LLMs."}}
{"id": "2602.07428", "pdf": "https://arxiv.org/pdf/2602.07428", "abs": "https://arxiv.org/abs/2602.07428", "authors": ["Chengqi Dong", "Zhiyuan Cao", "Tuoshi Qi", "Kexin Wu", "Yixing Gao", "Fan Tang"], "title": "Row-Column Separated Attention Based Low-Light Image/Video Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "U-Net structure is widely used for low-light image/video enhancement. The enhanced images result in areas with large local noise and loss of more details without proper guidance for global information. Attention mechanisms can better focus on and use global information. However, attention to images could significantly increase the number of parameters and computations. We propose a Row-Column Separated Attention module (RCSA) inserted after an improved U-Net. The RCSA module's input is the mean and maximum of the row and column of the feature map, which utilizes global information to guide local information with fewer parameters. We propose two temporal loss functions to apply the method to low-light video enhancement and maintain temporal consistency. Extensive experiments on the LOL, MIT Adobe FiveK image, and SDSD video datasets demonstrate the effectiveness of our approach. The code is publicly available at https://github.com/cq-dong/URCSA.", "AI": {"tldr": "The research proposes a U-Net-based approach for low-light image and video enhancement using a novel Row-Column Separated Attention module (RCSA) and introduces two temporal loss functions to improve temporal consistency. The method is validated on several datasets.", "motivation": "Current U-Net-based methods for low-light image/video enhancement fail to handle noise and global information effectively, leading to unsatisfactory results in detail preservation and global guidance.", "method": "The authors propose the RCSA module, which focuses on global information by processing the mean and maximum of row and column features, reducing parameters and computations. The improved U-Net is combined with two novel temporal loss functions for low-light video enhancement.", "result": "The method exhibits strong performance on the LOL, MIT Adobe FiveK, and SDSD datasets, demonstrating the effectiveness of the RCSA module and temporal loss functions for both images and videos.", "conclusion": "The introduced RCSA module and temporal loss functions improve low-light image and video enhancement by addressing noise, global information, and temporal consistency effectively, and the method is publicly accessible."}}
{"id": "2602.08307", "pdf": "https://arxiv.org/pdf/2602.08307", "abs": "https://arxiv.org/abs/2602.08307", "authors": ["Mengxiao Zhang", "Yuheng Zhang", "Haipeng Luo", "Paul Mineiro"], "title": "Interaction-Grounded Learning for Contextual Markov Decision Processes with Personalized Feedback", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we study Interaction-Grounded Learning (IGL) [Xie et al., 2021], a paradigm designed for realistic scenarios where the learner receives indirect feedback generated by an unknown mechanism, rather than explicit numerical rewards. While prior work on IGL provides efficient algorithms with provable guarantees, those results are confined to single-step settings, restricting their applicability to modern sequential decision-making systems such as multi-turn Large Language Model (LLM) deployments. To bridge this gap, we propose a computationally efficient algorithm that achieves a sublinear regret guarantee for contextual episodic Markov Decision Processes (MDPs) with personalized feedback. Technically, we extend the reward-estimator construction of Zhang et al. [2024a] from the single-step to the multi-step setting, addressing the unique challenges of decoding latent rewards under MDPs. Building on this estimator, we design an Inverse-Gap-Weighting (IGW) algorithm for policy optimization. Finally, we demonstrate the effectiveness of our method in learning personalized objectives from multi-turn interactions through experiments on both a synthetic episodic MDP and a real-world user booking dataset.", "AI": {"tldr": "This paper proposes an efficient algorithm for Interaction-Grounded Learning (IGL) in sequential decision-making settings, extending its application to multi-step scenarios like contextual episodic MDPs with personalized feedback.", "motivation": "The motivation is to extend the IGL paradigm from single-step to multi-step settings, making it applicable to sequential decision-making systems, such as multi-turn deployments of Large Language Models (LLMs).", "method": "The paper develops a computationally efficient algorithm by extending the reward-estimator used in single-step scenarios to handle multi-step contextual episodic MDPs. The authors also propose an Inverse-Gap-Weighting (IGW) algorithm for policy optimization.", "result": "The method achieves a sublinear regret for contextual episodic MDPs and effectively learns personalized objectives, as validated on a synthetic dataset and a real-world user booking dataset.", "conclusion": "The proposed approach significantly advances IGL by enabling it to handle modern sequential decision-making tasks, demonstrating its potential practicality both in theoretical and real-world applications."}}
{"id": "2602.07962", "pdf": "https://arxiv.org/pdf/2602.07962", "abs": "https://arxiv.org/abs/2602.07962", "authors": ["Weihao Zeng", "Yuzhen Huang", "Junxian He"], "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/LOCA-bench", "AI": {"tldr": "The paper introduces LOCA-bench, a benchmark to evaluate language agents in long-context scenarios, addressing the 'context rot' issue in large language models.", "motivation": "Long language agents often suffer from reliability issues as the context length grows ('context rot'). Existing benchmarks fail to evaluate realistic, dynamic agent behaviors in extended contexts.", "method": "LOCA-bench is designed to simulate dynamically increasing contexts while maintaining fixed task semantics to evaluate reliability. It includes automated control of environments and measures agent performance in combination with advanced context management techniques.", "result": "Tests with LOCA-bench show agent performance deteriorates in complex environments but improves with advanced context management techniques.", "conclusion": "LOCA-bench is an effective tool to assess and improve the performance of language models and scaffolds in long-context, real-world task scenarios. It is open-sourced for broader use."}}
{"id": "2602.08816", "pdf": "https://arxiv.org/pdf/2602.08816", "abs": "https://arxiv.org/abs/2602.08816", "authors": ["James Jewitt", "Gopi Krishnan Rajbahadur", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "comment": "13 pages, 2 figures, 10 tables", "summary": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.", "AI": {"tldr": "This paper highlights the widespread issue of \"permissive washing\" in AI, where artifacts labeled as freely usable fail to include required licensing elements, leaving users exposed legally.", "motivation": "To investigate and expose the prevalence of licensing non-compliance in AI artifacts, and its potential risks to downstream users.", "method": "The authors audit 124,278 dataset-to-model-to-application supply chains across platforms like Hugging Face and GitHub, assessing compliance with licensing requirements.", "result": "A significant 96.5% of datasets and 95.8% of models lack necessary license texts, and compliance propagates poorly throughout supply chains with only 2.3% of datasets and 3.2% of models satisfying legal requirements.", "conclusion": "Practitioners should not solely rely on permissive labels; legal compliance requires proper inclusion of license files and notices. The authors release their audit data and methodology."}}
{"id": "2602.08334", "pdf": "https://arxiv.org/pdf/2602.08334", "abs": "https://arxiv.org/abs/2602.08334", "authors": ["Xuanjin Jin", "Yanxin Dong", "Bin Sun", "Huan Xu", "Zhihui Hao", "XianPeng Lang", "Panpan Cai"], "title": "Vec-QMDP: Vectorized POMDP Planning on CPUs for Real-Time Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Planning under uncertainty for real-world robotics tasks, such as autonomous driving, requires reasoning in enormous high-dimensional belief spaces, rendering the problem computationally intensive. While parallelization offers scalability, existing hybrid CPU-GPU solvers face critical bottlenecks due to host-device synchronization latency and branch divergence on SIMT architectures, limiting their utility for real-time planning and hindering real-robot deployment. We present Vec-QMDP, a CPU-native parallel planner that aligns POMDP search with modern CPUs' SIMD architecture, achieving $227\\times$--$1073\\times$ speedup over state-of-the-art serial planners. Vec-QMDP adopts a Data-Oriented Design (DOD), refactoring scattered, pointer-based data structures into contiguous, cache-efficient memory layouts. We further introduce a hierarchical parallelism scheme: distributing sub-trees across independent CPU cores and SIMD lanes, enabling fully vectorized tree expansion and collision checking. Efficiency is maximized with the help of UCB load balancing across trees and a vectorized STR-tree for coarse-level collision checking. Evaluated on large-scale autonomous driving benchmarks, Vec-QMDP achieves state-of-the-art planning performance with millisecond-level latency, establishing CPUs as a high-performance computing platform for large-scale planning under uncertainty.", "AI": {"tldr": "Vec-QMDP is a CPU-native parallel planner for large-scale POMDP problems, offering significant speedups and real-time capability.", "motivation": "Overcoming computational bottlenecks in real-time robotics task planning due to high-dimensional belief spaces and inefficiencies of hybrid CPU-GPU solvers.", "method": "Proposed Vec-QMDP leveraging SIMD architecture in CPUs with Data-Oriented Design, hierarchical parallelism, and efficient memory layouts.", "result": "Achieved 227x\u20131073x speedup over serial planners and state-of-the-art performance with millisecond latency on autonomous driving benchmarks.", "conclusion": "Vec-QMDP demonstrates CPUs as a viable and high-performance option for real-time, large-scale planning under uncertainty."}}
{"id": "2602.08220", "pdf": "https://arxiv.org/pdf/2602.08220", "abs": "https://arxiv.org/abs/2602.08220", "authors": ["Boyi Zeng", "Yiqin Hao", "He Li", "Shixiang Song", "Feichen Song", "Zitong Wang", "Siyuan Huang", "Yi Xu", "ZiWei He", "Xinbing Wang", "Zhouhan Lin"], "title": "Pretraining with Token-Level Adaptive Latent Chain-of-Thought", "categories": ["cs.CL"], "comment": null, "summary": "Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.", "AI": {"tldr": "The paper proposes a new method called Pretraining with Token-Level Adaptive Latent Chain-of-Thought (adaptive latent CoT) to improve computation efficiency and model performance without increasing parameters.", "motivation": "To address the constraints of limited high-quality corpora and growing communication costs in scaling large language models, and to explore an alternative to scaling via parameter expansion by increasing per-token computation.", "method": "Introduce a model that generates variable-length latent Chain-of-Thought (CoT) trajectories per token during pretraining, where the computation allocated is token-dependent. This adaptive approach allows for longer trajectories for harder tokens and zero/shorter trajectories for easier ones, achieved via token-wise adaptive halting.", "result": "Experiments using Llama architectures demonstrated improved language modeling perplexity and downstream task accuracy, with reduced training computational costs compared to prior recurrent baselines.", "conclusion": "Adaptive latent CoT provides an efficient method to improve language model performance and computational scalability, making it a viable alternative to increasing parameters or training data."}}
{"id": "2602.07444", "pdf": "https://arxiv.org/pdf/2602.07444", "abs": "https://arxiv.org/abs/2602.07444", "authors": ["Ondrej Hlinka", "Georg Kaniak", "Christian Kapeller"], "title": "Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction", "categories": ["cs.CV", "eess.SP"], "comment": "submitted to IET Electronics Letters", "summary": "We address the problem of reconstructing 3D surfaces from depth and surface normal maps acquired by a sensor system based on a single perspective camera. Depth and normal maps can be obtained through techniques such as structured-light scanning and photometric stereo, respectively. We propose a perspective-aware log-depth fusion approach that extends existing orthographic gradient-based depth-normals fusion methods by explicitly accounting for perspective projection, leading to metrically accurate 3D reconstructions. Additionally, the method handles missing depth measurements by leveraging available surface normal information to inpaint gaps. Experiments on the DiLiGenT-MV data set demonstrate the effectiveness of our approach and highlight the importance of perspective-aware depth-normals fusion.", "AI": {"tldr": "The paper presents a method to reconstruct 3D surfaces using depth and surface normal maps, leveraging a perspective-aware approach for accuracy.", "motivation": "To improve 3D surface reconstruction accuracy by integrating depth and surface normal maps while addressing challenges like perspective projection and missing depth measurements.", "method": "Proposes a perspective-aware log-depth fusion technique that extends gradient-based depth-normals fusion by accounting for perspective projection and filling in missing depth data using surface normals.", "result": "Experiments on the DiLiGenT-MV dataset demonstrate enhanced 3D reconstruction accuracy and underscore the significance of perspective-aware fusion.", "conclusion": "Incorporating a perspective-aware approach improves the metric accuracy of 3D reconstructions, handling both perspective projection and missing depth data effectively."}}
{"id": "2602.08315", "pdf": "https://arxiv.org/pdf/2602.08315", "abs": "https://arxiv.org/abs/2602.08315", "authors": ["Shunyu Zhao", "Yanfeng Yang", "Shuai Li", "Kenji Fukumizu"], "title": "Fast Flow Matching based Conditional Independence Tests for Causal Discovery", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Constraint-based causal discovery methods require a large number of conditional independence (CI) tests, which severely limits their practical applicability due to high computational complexity. Therefore, it is crucial to design an algorithm that accelerates each individual test. To this end, we propose the Flow Matching-based Conditional Independence Test (FMCIT). The proposed test leverages the high computational efficiency of flow matching and requires the model to be trained only once throughout the entire causal discovery procedure, substantially accelerating causal discovery. According to numerical experiments, FMCIT effectively controls type-I error and maintains high testing power under the alternative hypothesis, even in the presence of high-dimensional conditioning sets. In addition, we further integrate FMCIT into a two-stage guided PC skeleton learning framework, termed GPC-FMCIT, which combines fast screening with guided, budgeted refinement using FMCIT. This design yields explicit bounds on the number of CI queries while maintaining high statistical power. Experiments on synthetic and real-world causal discovery tasks demonstrate favorable accuracy-efficiency trade-offs over existing CI testing methods and PC variants.", "AI": {"tldr": "This paper introduces a computationally efficient method (FMCIT) for causal discovery by leveraging flow matching and integrating it into an improved PC algorithm framework.", "motivation": "Constraint-based causal discovery methods face computational challenges due to the extensive number of conditional independence tests required.", "method": "The proposed FMCIT utilizes flow matching for computational efficiency and is integrated into a guided PC framework (GPC-FMCIT) for better resource management and performance.", "result": "Experiments show favorable accuracy-efficiency trade-offs in both synthetic and real-world datasets, demonstrating statistical power and reduced computational costs.", "conclusion": "FMCIT and its integration within GPC-FMCIT provide promising advancements in causal discovery methodologies, addressing computational challenges effectively."}}
{"id": "2602.07983", "pdf": "https://arxiv.org/pdf/2602.07983", "abs": "https://arxiv.org/abs/2602.07983", "authors": ["Jishu Sen Gupta", "Harini SI", "Somesh Kumar Singh", "Syed Mohamad Tawseeq", "Yaman Kumar Singla", "David Doermann", "Rajiv Ratn Shah", "Balaji Krishnamurthy"], "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.", "AI": {"tldr": "EXPERIGEN introduces a Bayesian optimization-inspired framework enabling faster, end-to-end scientific discovery, outperforming previous methods in hypothesis generation and validation.", "motivation": "The slow process of data-driven social science research necessitates an end-to-end framework to efficiently generate, evaluate, and validate hypotheses.", "method": "EXPERIGEN employs a two-phase search mechanism: a Generator to propose hypotheses and an Experimenter to empirically validate them, inspired by Bayesian optimization.", "result": "EXPERIGEN discovers hypotheses that are 2-4x more statistically significant and 7-17% more predictive than prior approaches, and adapts to multimodal/relational datasets. Expert review also indicates high novelty (88%) and impact (70%) of generated hypotheses.", "conclusion": "EXPERIGEN demonstrates its capability to advance scientific research through statistically significant A/B tests and expert validation, bridging gaps in hypothesis discovery and evaluation."}}
{"id": "2602.07411", "pdf": "https://arxiv.org/pdf/2602.07411", "abs": "https://arxiv.org/abs/2602.07411", "authors": ["Zishi Zhang", "Tao Ren", "Yijie Peng"], "title": "Nonparametric Bayesian Optimization for General Rewards", "categories": ["cs.LG"], "comment": null, "summary": "This work focuses on Bayesian optimization (BO) under reward model uncertainty. We propose the first BO algorithm that achieves no-regret guarantee in a general reward setting, requiring only Lipschitz continuity of the objective function and accommodating a broad class of measurement noise. The core of our approach is a novel surrogate model, termed as infinite Gaussian process ($\\infty$-GP). It is a Bayesian nonparametric model that places a prior on the space of reward distributions, enabling it to represent a substantially broader class of reward models than classical Gaussian process (GP). The $\\infty$-GP is used in combination with Thompson Sampling (TS) to enable effective exploration and exploitation. Correspondingly, we develop a new TS regret analysis framework for general rewards, which relates the regret to the total variation distance between the surrogate model and the true reward distribution. Furthermore, with a truncated Gibbs sampling procedure, our method is computationally scalable, incurring minimal additional memory and computational complexities compared to classical GP. Empirical results demonstrate state-of-the-art performance, particularly in settings with non-stationary, heavy-tailed, or other ill-conditioned rewards.", "AI": {"tldr": "The paper introduces a novel Bayesian optimization (BO) algorithm with a no-regret guarantee under general reward settings using the infinite Gaussian process ($\\infty$-GP) model.", "motivation": "To address the limitations in current Bayesian optimization methods which struggle with general reward settings, non-stationary or heavy-tailed rewards, especially under substantial measurement noise.", "method": "The approach uses an infinite Gaussian process ($\\infty$-GP) model as a surrogate for reward distributions and Thompson Sampling (TS) for exploration-exploitation trade-offs. It includes a specialized regret analysis and integrates a truncated Gibbs sampling procedure for scalability.", "result": "The method achieves state-of-the-art empirical performance in challenging settings, like non-stationary, heavy-tailed, or ill-conditioned rewards, while maintaining computational efficiency and a no-regret guarantee.", "conclusion": "This study broadens the scope of Bayesian optimization by introducing the $\\infty$-GP model, offering improved compatibility with diverse reward models and noise settings without sacrificing efficiency or performance."}}
{"id": "2602.08949", "pdf": "https://arxiv.org/pdf/2602.08949", "abs": "https://arxiv.org/abs/2602.08949", "authors": ["Mohammad Morsali", "Siavash H. Khajavi"], "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.", "AI": {"tldr": "This paper proposes the Intelligent Virtual Situation Room (IVSR), an AI-powered digital twin platform aimed at improving wildfire disaster management through real-time response and analysis.", "motivation": "Traditional disaster management systems rely on static simulations and passive data collection, making them inadequate for real-time adaptation to unpredictable wildfire scenarios.", "method": "The IVSR employs a bidirectional Digital Twin framework that incorporates multisource sensor imagery, weather data, and 3D forest models, powered by AI to retrieve optimized intervention strategies from a precomputed Disaster Simulation Library.", "result": "IVSR demonstrated enhanced detection capability, reduced response latency, and improved resource coordination through simulations provided by an industrial partner.", "conclusion": "IVSR enables a scalable, semi-automated decision-support system by integrating real-time digital twins and AI, facilitating proactive and adaptive management of wildfires."}}
{"id": "2602.08370", "pdf": "https://arxiv.org/pdf/2602.08370", "abs": "https://arxiv.org/abs/2602.08370", "authors": ["Yeke Chen", "Shihao Dong", "Xiaoyu Ji", "Jingkai Sun", "Zeren Luo", "Liu Zhao", "Jiahui Zhang", "Wanyue Li", "Ji Ma", "Bowen Xu", "Yimin Han", "Yudong Zhao", "Peng Lu"], "title": "Learning Human-Like Badminton Skills for Humanoid Robots", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "10 pages, 4 figures", "summary": "Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware striking without compromising stylistic naturalness is non-trivial. To address this, we propose Imitation-to-Interaction, a progressive reinforcement learning framework designed to evolve a robot from a \"mimic\" to a capable \"striker.\" Our approach establishes a robust motor prior from human data, distills it into a compact, model-based state representation, and stabilizes dynamics via adversarial priors. Crucially, to overcome the sparsity of expert demonstrations, we introduce a manifold expansion strategy that generalizes discrete strike points into a dense interaction volume. We validate our framework through the mastery of diverse skills, including lifts and drop shots, in simulation. Furthermore, we demonstrate the first zero-shot sim-to-real transfer of anthropomorphic badminton skills to a humanoid robot, successfully replicating the kinetic elegance and functional precision of human athletes in the physical world.", "AI": {"tldr": "The paper proposes a reinforcement learning framework, Imitation-to-Interaction, to train humanoid robots in badminton, achieving human-like precision and sim-to-real transfer of skills.", "motivation": "The motivation is to enable humanoid robots to perform human-like skills in sports like badminton, which require explosive coordination, timing-critical actions, and natural stylistic motions.", "method": "The method uses a progressive reinforcement learning framework. It builds motor priors from human data, creates a compact state representation, stabilizes dynamics with adversarial priors, and introduces a manifold expansion strategy to generalize strike points.", "result": "The framework was validated through simulations mastering various badminton skills like lifts and drop shots and achieved successful zero-shot sim-to-real transfer of these skills to a humanoid robot.", "conclusion": "This approach bridges the gap between kinematic imitation and functional striking, showcasing humanoid robots performing badminton with kinetic elegance and precision in the physical world."}}
{"id": "2602.08221", "pdf": "https://arxiv.org/pdf/2602.08221", "abs": "https://arxiv.org/abs/2602.08221", "authors": ["Xuhua Ma", "Richong Zhang", "Zhijie Nie"], "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.", "AI": {"tldr": "The paper identifies and addresses the issue of knowledge conflicts in retrieval-augmented generation (RAG) due to parametric suppression, introducing CoRect, a novel method to rectify hidden states and improve faithfulness without requiring ground-truth labels.", "motivation": "Improve the faithfulness of RAG outputs by addressing knowledge conflicts where internal model knowledge overrides retrieved evidence.", "method": "Propose CoRect: a method that contrasts logits of contextualized and non-contextualized forward passes to identify and rectify layers with high parametric bias.", "result": "CoRect improves faithfulness and reduces hallucinations across QA and summarization benchmarks, outperforming strong baselines.", "conclusion": "Layer-specific interventions like CoRect can enhance the reliability of RAG systems by effectively mitigating parametric suppression issues."}}
{"id": "2602.07446", "pdf": "https://arxiv.org/pdf/2602.07446", "abs": "https://arxiv.org/abs/2602.07446", "authors": ["Naqcho Ali Mehdi"], "title": "PTB-XL-Image-17K: A Large-Scale Synthetic ECG Image Dataset with Comprehensive Ground Truth for Deep Learning-Based Digitization", "categories": ["cs.CV"], "comment": "8 pages, 4 figures, dataset paper", "summary": "Electrocardiogram (ECG) digitization-converting paper-based or scanned ECG images back into time-series signals-is critical for leveraging decades of legacy clinical data in modern deep learning applications. However, progress has been hindered by the lack of large-scale datasets providing both ECG images and their corresponding ground truth signals with comprehensive annotations. We introduce PTB-XL-Image-17K, a complete synthetic ECG image dataset comprising 17,271 high-quality 12-lead ECG images generated from the PTB-XL signal database. Our dataset uniquely provides five complementary data types per sample: (1) realistic ECG images with authentic grid patterns and annotations (50% with visible grid, 50% without), (2) pixel-level segmentation masks, (3) ground truth time-series signals, (4) bounding box annotations in YOLO format for both lead regions and lead name labels, and (5) comprehensive metadata including visual parameters and patient information. We present an open-source Python framework enabling customizable dataset generation with controllable parameters including paper speed (25/50 mm/s), voltage scale (5/10 mm/mV), sampling rate (500 Hz), grid appearance (4 colors), and waveform characteristics. The dataset achieves 100% generation success rate with an average processing time of 1.35 seconds per sample. PTB-XL-Image-17K addresses critical gaps in ECG digitization research by providing the first large-scale resource supporting the complete pipeline: lead detection, waveform segmentation, and signal extraction with full ground truth for rigorous evaluation. The dataset, generation framework, and documentation are publicly available at https://github.com/naqchoalimehdi/PTB-XL-Image-17K and https://doi.org/10.5281/zenodo.18197519.", "AI": {"tldr": "The paper introduces a novel large-scale synthetic ECG image dataset, PTB-XL-Image-17K, with diverse data types and a customizable generation framework to aid in ECG signal digitization and research.", "motivation": "The motivation is to address the gap in available large-scale datasets that provide both ECG images and their ground truth signals, enabling advancements in leveraging legacy clinical data through modern deep learning applications.", "method": "The authors created PTB-XL-Image-17K, a dataset of 17,271 synthetic 12-lead ECG images with five complementary data types, and developed an open-source Python framework for customizable dataset generation with various controllable parameters.", "result": "The dataset achieves a 100% generation success rate, with an average processing time of 1.35 seconds per sample, and provides tools for the complete ECG digitization pipeline.", "conclusion": "PTB-XL-Image-17K fills a critical gap in ECG digitization research, offering resources for lead detection, waveform segmentation, and signal extraction, and it is made publicly available for collaborative development and evaluation."}}
{"id": "2602.08350", "pdf": "https://arxiv.org/pdf/2602.08350", "abs": "https://arxiv.org/abs/2602.08350", "authors": ["Tal Burla", "Roi Livni"], "title": "All ERMs Can Fail in Stochastic Convex Optimization Lower Bounds in Linear Dimension", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study the sample complexity of the best-case Empirical Risk Minimizer in the setting of stochastic convex optimization. We show that there exists an instance in which the sample size is linear in the dimension, learning is possible, but the Empirical Risk Minimizer is likely to be unique and to overfit. This resolves an open question by Feldman. We also extend this to approximate ERMs.\n  Building on our construction we also show that (constrained) Gradient Descent potentially overfits when horizon and learning rate grow w.r.t sample size. Specifically we provide a novel generalization lower bound of $\u03a9\\left(\\sqrt{\u03b7T/m^{1.5}}\\right)$ for Gradient Descent, where $\u03b7$ is the learning rate, $T$ is the horizon and $m$ is the sample size. This narrows down, exponentially, the gap between the best known upper bound of $O(\u03b7T/m)$ and existing lower bounds from previous constructions.", "AI": {"tldr": "The paper explores the sample complexity and overfitting risks in stochastic convex optimization with Empirical Risk Minimization (ERM) and Gradient Descent (GD).", "motivation": "The authors aim to address how overfitting emerges in common optimization methods like ERM and Gradient Descent in certain stochastic convex optimization setups while also resolving an open question by Feldman.", "method": "They construct specific instances to demonstrate overfitting in Empirical Risk Minimization and analyze Gradient Descent's generalization error via novel lower bounds.", "result": "The key findings include identifying conditions under which ERM and GD overfit, and deriving a new lower bound of $\u03a9\\left(\\sqrt{\u03b7T/m^{1.5}}\\right)$ on Gradient Descent's generalization error.", "conclusion": "This research highlights the limitations of widely used optimization methods and offers theoretical insights to narrow gaps in understanding their sample complexity and generalization errors."}}
{"id": "2602.08009", "pdf": "https://arxiv.org/pdf/2602.08009", "abs": "https://arxiv.org/abs/2602.08009", "authors": ["Rui Li", "Zeyu Zhang", "Xiaohe Bo", "Quanyu Dai", "Chaozhuo Li", "Feng Wen", "Xu Chen"], "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.", "AI": {"tldr": "The paper introduces RAPS, a system utilizing a reputation-aware publish-subscribe model to improve the coordination of large language model (LLM) agents, ensuring adaptive, scalable, and robust communication.", "motivation": "The motivation behind the paper is to address the challenge of automating the coordination of multi-agent architectures built on LLMs, aiming to reduce the manual effort in orchestrating complex agent workflows.", "method": "The paper proposes RAPS, a framework based on the Distributed Publish-Subscribe Protocol, featuring Reactive Subscription for dynamic intent refinement and Bayesian Reputation for detecting malicious agents locally.", "result": "The proposed RAPS framework demonstrated effectiveness across five benchmarks, showcasing its ability to balance adaptivity, scalability, and robustness in multi-agent coordination.", "conclusion": "RAPS successfully resolves key limitations of manual orchestration in multi-agent LLM systems, providing adaptive communication and reliability through innovative overlays and reputation mechanisms."}}
{"id": "2602.07415", "pdf": "https://arxiv.org/pdf/2602.07415", "abs": "https://arxiv.org/abs/2602.07415", "authors": ["Runhan Shi", "Zhicheng Zhang", "Letian Chen", "Gufeng Yu", "Yang Yang"], "title": "Learning Molecular Chirality via Chiral Determinant Kernels", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the ICLR 2026", "summary": "Chirality is a fundamental molecular property that governs stereospecific behavior in chemistry and biology. Capturing chirality in machine learning models remains challenging due to the geometric complexity of stereochemical relationships and the limitations of traditional molecular representations that often lack explicit stereochemical encoding. Existing approaches to chiral molecular representation primarily focus on central chirality, relying on handcrafted stereochemical tags or limited 3D encodings, and thus fail to generalize to more complex forms such as axial chirality. In this work, we introduce ChiDeK (Chiral Determinant Kernels), a framework that systematically integrates stereogenic information into molecular representation learning. We propose the chiral determinant kernel to encode the SE(3)-invariant chirality matrix and employ cross-attention to integrate stereochemical information from local chiral centers into the global molecular representation. This design enables explicit modeling of chiral-related features within a unified architecture, capable of jointly encoding central and axial chirality. To support the evaluation of axial chirality, we construct a new benchmark for electronic circular dichroism (ECD) and optical rotation (OR) prediction. Across four tasks, including R/S configuration classification, enantiomer ranking, ECD spectrum prediction, and OR prediction, ChiDeK achieves substantial improvements over state-of-the-art baselines, most notably yielding over 7% higher accuracy on axially chiral tasks on average.", "AI": {"tldr": "This paper introduces ChiDeK, a novel framework for molecular representation learning that integrates stereogenic information to effectively encode chirality, particularly addressing challenges in axial chirality. It outperforms existing methods in multiple tasks.", "motivation": "Capturing chirality in machine learning models is difficult because traditional molecular representations lack sufficient stereochemical encoding, especially for axial chirality, limiting their effectiveness in stereochemical analysis.", "method": "The authors propose ChiDeK, which uses chiral determinant kernels to encode a SE(3)-invariant chirality matrix and employs cross-attention mechanisms to integrate local stereochemical information into the global molecular representation, enabling joint encoding of both central and axial chirality.", "result": "ChiDeK significantly improves upon state-of-the-art methods across four evaluated tasks, achieving over 7% higher accuracy in axially chiral-related tasks, notably excelling in electronic circular dichroism and optical rotation prediction benchmarks.", "conclusion": "ChiDeK enables more accurate and generalized molecular representation learning by effectively encoding chirality, both central and axial, and demonstrates superior performance in stereochemical-related prediction tasks."}}
{"id": "2602.08392", "pdf": "https://arxiv.org/pdf/2602.08392", "abs": "https://arxiv.org/abs/2602.08392", "authors": ["Xin Wu", "Zhixuan Liang", "Yue Ma", "Mengkang Hu", "Zhiyuan Qin", "Xiu Li"], "title": "BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "38 pages, 9 figures. Project page:https://bimanibench.github.io/", "summary": "Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three tiers: fundamental spatial reasoning, high-level action planning, and low-level end-effector control. Our framework isolates unique bimanual challenges, such as arm reachability and kinematic constraints, thereby distinguishing perceptual hallucinations from planning failures. Analysis of over 30 state-of-the-art models reveals that despite high-level reasoning proficiency, MLLMs struggle with dual-arm spatial grounding and control, frequently resulting in mutual interference and sequencing errors. These findings suggest the current paradigm lacks a deep understanding of mutual kinematic constraints, highlighting the need for future research to focus on inter-arm collision-avoidance and fine-grained temporal sequencing.", "AI": {"tldr": "BiManiBench introduces a benchmark for assessing multimodal large language models (MLLMs) in challenging bimanual robotic tasks, highlighting their limitations in spatial grounding and control.", "motivation": "Current MLLM frameworks are limited to single-arm manipulation, which fails to address complex bimanual tasks requiring spatio-temporal coordination.", "method": "Developed BiManiBench, a hierarchical benchmark that evaluates MLLMs on spatial reasoning, action planning, and end-effector control, isolating unique bimanual challenges.", "result": "Evaluation of 30+ models shows MLLMs excel in high-level reasoning but struggle with dual-arm spatial grounding and control, leading to mutual interference and sequencing errors.", "conclusion": "MLLMs need advancement in inter-arm collision avoidance and fine-grained temporal sequencing to handle bimanual manipulation effectively."}}
{"id": "2602.08235", "pdf": "https://arxiv.org/pdf/2602.08235", "abs": "https://arxiv.org/abs/2602.08235", "authors": ["Jaylen Jones", "Zhehao Zhang", "Yuting Ning", "Eric Fosler-Lussier", "Pierre-Luc St-Charles", "Yoshua Bengio", "Dawn Song", "Yu Su", "Huan Sun"], "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "Project Homepage: https://osu-nlp-group.github.io/AutoElicit/", "summary": "Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.", "AI": {"tldr": "The paper introduces AutoElicit, a framework to systematically identify unintended behaviors in Computer-Use Agents (CUAs) using benign input perturbations.", "motivation": "There is a need to address the risk of unsafe unintended behaviors in computer-use agents (CUAs) under benign scenarios, which are currently inadequately characterized and lack automated methods of discovery.", "method": "AutoElicit iteratively perturbs benign inputs with feedback from CUA execution to elicit unintended behaviors while maintaining realism and benignity.", "result": "AutoElicit surfaces hundreds of harmful unintended behaviors in state-of-the-art CUAs and explores the transferability of these behaviors across other leading CUAs.", "conclusion": "This research provides a framework for systematically analyzing unintended CUA behaviors in realistic scenarios, paving the way for improved understanding and mitigation strategies."}}
{"id": "2602.07449", "pdf": "https://arxiv.org/pdf/2602.07449", "abs": "https://arxiv.org/abs/2602.07449", "authors": ["Tan Yu", "Qian Qiao", "Le Shen", "Ke Zhou", "Jincheng Hu", "Dian Sheng", "Bo Hu", "Haoming Qin", "Jun Gao", "Changhai Zhou", "Shunshun Yin", "Siyuan Liu"], "title": "SoulX-FlashHead: Oracle-guided Generation of Infinite Real-time Streaming Talking Heads", "categories": ["cs.CV"], "comment": "11 pages, 3 figures", "summary": "Achieving a balance between high-fidelity visual quality and low-latency streaming remains a formidable challenge in audio-driven portrait generation. Existing large-scale models often suffer from prohibitive computational costs, while lightweight alternatives typically compromise on holistic facial representations and temporal stability. In this paper, we propose SoulX-FlashHead, a unified 1.3B-parameter framework designed for real-time, infinite-length, and high-fidelity streaming video generation. To address the instability of audio features in streaming scenarios, we introduce Streaming-Aware Spatiotemporal Pre-training equipped with a Temporal Audio Context Cache mechanism, which ensures robust feature extraction from short audio fragments. Furthermore, to mitigate the error accumulation and identity drift inherent in long-sequence autoregressive generation, we propose Oracle-Guided Bidirectional Distillation, leveraging ground-truth motion priors to provide precise physical guidance. We also present VividHead, a large-scale, high-quality dataset containing 782 hours of strictly aligned footage to support robust training. Extensive experiments demonstrate that SoulX-FlashHead achieves state-of-the-art performance on HDTF and VFHQ benchmarks. Notably, our Lite variant achieves an inference speed of 96 FPS on a single NVIDIA RTX 4090, facilitating ultra-fast interaction without sacrificing visual coherence.", "AI": {"tldr": "The authors introduce SoulX-FlashHead, a 1.3B-parameter framework for real-time, high-fidelity audio-driven portrait generation with innovations in feature extraction and error mitigation.", "motivation": "The paper aims to address the trade-off between high-quality visual output and the computational efficiency required for real-time applications in audio-driven portrait generation, overcoming limitations in existing models.", "method": "The authors propose Streaming-Aware Spatiotemporal Pre-training with a Temporal Audio Context Cache for robust audio feature extraction and Oracle-Guided Bidirectional Distillation to reduce error accumulation in long sequences. They also introduce the VividHead dataset for robust training.", "result": "SoulX-FlashHead achieves state-of-the-art performance on HDTF and VFHQ benchmarks, with its Lite variant reaching 96 FPS on an NVIDIA RTX 4090 while maintaining visual consistency.", "conclusion": "SoulX-FlashHead balances high-performance streaming and high-fidelity visual quality, demonstrating its potential for real-time audio-driven portrait generation in practical applications."}}
{"id": "2602.08467", "pdf": "https://arxiv.org/pdf/2602.08467", "abs": "https://arxiv.org/abs/2602.08467", "authors": ["Charalampos Shimillas", "Kleanthis Malialis", "Konstantinos Fokianos", "Marios M. Polycarpou"], "title": "Low Rank Transformer for Multivariate Time Series Anomaly Detection and Localization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multivariate time series (MTS) anomaly diagnosis, which encompasses both anomaly detection and localization, is critical for the safety and reliability of complex, large-scale real-world systems. The vast majority of existing anomaly diagnosis methods offer limited theoretical insights, especially for anomaly localization, which is a vital but largely unexplored area. The aim of this contribution is to study the learning process of a Transformer when applied to MTS by revealing connections to statistical time series methods. Based on these theoretical insights, we propose the Attention Low-Rank Transformer (ALoRa-T) model, which applies low-rank regularization to self-attention, and we introduce the Attention Low-Rank score, effectively capturing the temporal characteristics of anomalies. Finally, to enable anomaly localization, we propose the ALoRa-Loc method, a novel approach that associates anomalies to specific variables by quantifying interrelationships among time series. Extensive experiments and real data analysis, show that the proposed methodology significantly outperforms state-of-the-art methods in both detection and localization tasks.", "AI": {"tldr": "The paper introduces the ALoRa-T model and ALoRa-Loc method for multivariate time series anomaly diagnosis, addressing both detection and localization with significant improvements over existing methods.", "motivation": "The study addresses the need for theoretical insights into anomaly localization in multivariate time series, which has been largely unexplored but is essential for the safety and reliability of complex systems.", "method": "The paper proposes the ALoRa-T model by incorporating low-rank regularization into the Transformer's self-attention mechanism and develops the ALoRa-Loc technique to link anomalies to specific time series variables.", "result": "Results from experiments and real-world data analyses demonstrate that the proposed methods outperform state-of-the-art approaches in detecting and localizing anomalies.", "conclusion": "The ALoRa-T and ALoRa-Loc effectively enhance anomaly detection and localization in multivariate time series, revealing important theoretical connections and improving performance in practical applications."}}
{"id": "2602.08013", "pdf": "https://arxiv.org/pdf/2602.08013", "abs": "https://arxiv.org/abs/2602.08013", "authors": ["Yuqiao Meng", "Luoxi Tang", "Dazheng Zhang", "Rafael Brens", "Elvys J. Romero", "Nancy Guo", "Safa Elkefi", "Zhaohan Xi"], "title": "Small Agent Group is the Future of Digital Health", "categories": ["cs.AI"], "comment": null, "summary": "The rapid adoption of large language models (LLMs) in digital health has been driven by a \"scaling-first\" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.", "AI": {"tldr": "The paper proposes a Small Agent Group (SAG) approach that shifts from relying solely on large language models (LLMs) to a collective intelligence system for clinical reasoning, demonstrating superior performance and better balance of effectiveness, reliability, and cost.", "motivation": "To address the limitations of solely scaling large language models in healthcare, which include issues with reliability, cost, and collaboration in clinical decision-making.", "method": "The authors propose SAG, a framework that uses collective reasoning through multiple smaller agents rather than a single large model. They evaluate its performance using clinical metrics for effectiveness, reliability, and cost in diverse settings.", "result": "SAG outperforms a single large model in clinical reasoning tasks across effectiveness, reliability, and cost metrics, even without optimizations or retrieval-augmented methods.", "conclusion": "Shifting to a Small Agent Group (SAG) approach provides a scalable and reliable alternative to the 'scaling-first' philosophy, offering better balance in digital health applications."}}
{"id": "2602.08417", "pdf": "https://arxiv.org/pdf/2602.08417", "abs": "https://arxiv.org/abs/2602.08417", "authors": ["Wentao Zhao", "Yihe Niu", "Zikun Chen", "Rui Li", "Yanbo Wang", "Tianchen Deng", "Jingchuan Wang"], "title": "Graph-Loc: Robust Graph-Based LiDAR Pose Tracking with Compact Structural Map Priors under Low Observability and Occlusion", "categories": ["cs.RO"], "comment": "13 pages, 8 figures, 8 tables", "summary": "Map-based LiDAR pose tracking is essential for long-term autonomous operation, where onboard map priors need be compact for scalable storage and fast retrieval, while online observations are often partial, repetitive, and heavily occluded. We propose Graph-Loc, a graph-based localization framework that tracks the platform pose against compact structural map priors represented as a lightweight point-line graph. Such priors can be constructed from heterogeneous sources commonly available in practice, including polygon outlines vectorized from occupancy/grid maps and CAD/model/floor-plan layouts. For each incoming LiDAR scan, Graph-Loc extracts sparse point and line primitives to form an observation graph, retrieves a pose-conditioned visible subgraph via LiDAR ray simulation, and performs scan-to-map association through unbalanced optimal transport with a local graph-context regularizer. The unbalanced formulation relaxes mass conservation, improving robustness to missing, spurious, and fragmented structures under occlusion. To enhance stability in low-observability segments, we estimate information anisotropy from the refinement normal matrix and defer updates along weakly constrained directions until sufficient constraints reappear. Experiments on public benchmarks, controlled stress tests, and real-world deployments demonstrate accurate and stable tracking with KB-level priors from heterogeneous map sources, including under geometrically degenerate and sustained occlusion and in the presence of gradual scene changes.", "AI": {"tldr": "The paper proposes Graph-Loc, a graph-based localization framework optimized for robust pose tracking using lightweight LiDAR mapping.", "motivation": "The primary motivation is to address challenges in long-term autonomous operation, including compact data storage, handling occlusions, and using partial, repetitive observations.", "method": "The framework represents map priors as lightweight point-line graphs generated from various sources and uses unbalanced optimal transport with graph-context regularization for LiDAR pose tracking.", "result": "Graph-Loc demonstrates accurate, stable tracking under challenging scenarios, including geometrically degraded conditions, sustained occlusion, and gradual environment changes with compact KB-level priors.", "conclusion": "Graph-Loc effectively enhances localization reliability and compactness, proving its capacity to handle practical challenges in long-term autonomous applications."}}
{"id": "2602.08237", "pdf": "https://arxiv.org/pdf/2602.08237", "abs": "https://arxiv.org/abs/2602.08237", "authors": ["Yao Xiao", "Lei Wang", "Yue Deng", "Guanzheng Chen", "Ziqi Jin", "Jung-jae Kim", "Xiaoli Li", "Roy Ka-wei Lee", "Lidong Bing"], "title": "Document Reconstruction Unlocks Scalable Long-Context RLVR", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.", "AI": {"tldr": "The paper explores unsupervised reinforcement learning approaches to improve the long-context abilities of large language models without relying on costly annotations or teacher supervision.", "motivation": "To overcome the dependency on expensive human annotations or teacher supervision traditionally used in reinforcement learning settings for improving long-context capabilities of large language models.", "method": "The authors train models to reconstruct long documents by replacing paragraphs with placeholders and tasking the models with identifying and sequencing the missing paragraphs using reinforcement learning.", "result": "The method achieved notable improvements on RULER and moderate gains on LongBench v2 benchmarks without needing manually curated long-context QA datasets.", "conclusion": "The proposed unsupervised reinforcement learning approach successfully enhances long-context performance, and the study provides insights through ablation on reward design, data curation, and scaling strategies with publicly released resources."}}
{"id": "2602.07458", "pdf": "https://arxiv.org/pdf/2602.07458", "abs": "https://arxiv.org/abs/2602.07458", "authors": ["Yancheng Long", "Yankai Yang", "Hongyang Wei", "Wei Chen", "Tianke Zhang", "Haonan fan", "Changyi Liu", "Kaiyu Jiang", "Jiankang Chen", "Kaiyu Tang", "Bin Wen", "Fan Yang", "Tingting Gao", "Han Li", "Shuo Yang"], "title": "SpatialReward: Bridging the Perception Gap in Online RL for Image Editing via Explicit Spatial Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Online Reinforcement Learning (RL) offers a promising avenue for complex image editing but is currently constrained by the scarcity of reliable and fine-grained reward signals. Existing evaluators frequently struggle with a critical perception gap we term \"Attention Collapse,\" where models neglect cross-image comparisons and fail to capture fine-grained details, resulting in inaccurate perception and miscalibrated scores. To address these limitations, we propose SpatialReward, a reward model that enforces precise verification via explicit spatial reasoning. By anchoring reasoning to predicted edit regions, SpatialReward grounds semantic judgments in pixel-level evidence, significantly enhancing evaluative accuracy. Trained on a curated 260k spatial-aware dataset, our model achieves state-of-the-art performance on MMRB2 and EditReward-Bench, and outperforms proprietary evaluators on our proposed MultiEditReward-Bench. Furthermore, SpatialReward serves as a robust signal in online RL, boosting OmniGen2 by +0.90 on GEdit-Bench--surpassing the leading discriminative model and doubling the gain of GPT-4.1 (+0.45). These results demonstrate that spatial reasoning is essential for unlocking effective alignment in image editing.", "AI": {"tldr": "The paper introduces SpatialReward, a model that enhances online RL in image editing by employing spatial reasoning for fine-grained reward signals to overcome the \"Attention Collapse\" issue.", "motivation": "To address the lack of reliable, fine-grained reward signals and the problem of \"Attention Collapse\" in current online RL models, which fail to capture fine details and cross-image comparisons in complex image editing tasks.", "method": "The proposed SpatialReward model uses explicit spatial reasoning anchored to predicted edit regions for grounding semantic judgments in pixel-level evidence, and it is trained on a specially curated 260k spatial-aware dataset.", "result": "SpatialReward achieves state-of-the-art results on benchmarks like MMRB2 and EditReward-Bench and outperforms proprietary models on MultiEditReward-Bench. It also boosts OmniGen2 performance significantly (+0.90 on GEdit-Bench).", "conclusion": "Spatial reasoning is crucial for effective alignment in image editing tasks, and SpatialReward demonstrates its potential by achieving substantial accuracy improvements in online RL applications."}}
{"id": "2602.08470", "pdf": "https://arxiv.org/pdf/2602.08470", "abs": "https://arxiv.org/abs/2602.08470", "authors": ["Kaizheng Wang", "Ghifari Adam Faza", "Fabio Cuzzolin", "Siu Lun Chau", "David Moens", "Hans Hallez"], "title": "Learning Credal Ensembles via Distributionally Robust Optimization", "categories": ["cs.LG", "stat.ML"], "comment": "32 pages", "summary": "Credal predictors are models that are aware of epistemic uncertainty and produce a convex set of probabilistic predictions. They offer a principled way to quantify predictive epistemic uncertainty (EU) and have been shown to improve model robustness in various settings. However, most state-of-the-art methods mainly define EU as disagreement caused by random training initializations, which mostly reflects sensitivity to optimization randomness rather than uncertainty from deeper sources. To address this, we define EU as disagreement among models trained with varying relaxations of the i.i.d. assumption between training and test data. Based on this idea, we propose CreDRO, which learns an ensemble of plausible models through distributionally robust optimization. As a result, CreDRO captures EU not only from training randomness but also from meaningful disagreement due to potential distribution shifts between training and test data. Empirical results show that CreDRO consistently outperforms existing credal methods on tasks such as out-of-distribution detection across multiple benchmarks and selective classification in medical applications.", "AI": {"tldr": "The paper presents CreDRO, a novel method for credal prediction that captures predictive epistemic uncertainty (EU) caused by distribution shifts, improving performance in tasks like out-of-distribution detection and selective classification.", "motivation": "To improve the robustness of credal predictors by addressing limitations in epistemic uncertainty (EU) definitions, which often emphasize optimization randomness but fail to account for distributional discrepancies between training and test data.", "method": "CreDRO trains an ensemble of plausible models using distributionally robust optimization, focusing on capturing EU caused by both training randomness and potential distribution shifts.", "result": "CreDRO consistently outperforms current credal methods in out-of-distribution detection across benchmarks and in selective classification for medical applications.", "conclusion": "CreDRO offers a more robust framework for credal prediction, effectively quantifying predictive epistemic uncertainty caused by meaningful distribution variations, and demonstrates superior performance compared to existing methods."}}
{"id": "2602.08021", "pdf": "https://arxiv.org/pdf/2602.08021", "abs": "https://arxiv.org/abs/2602.08021", "authors": ["Zhan-Yi Liao", "Jaewon Yoo", "Hao-Tsung Yang", "Po-An Chen"], "title": "Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers", "categories": ["cs.AI"], "comment": null, "summary": "Counterfactual explanation (CE) is a core technique in explainable artificial intelligence (XAI), widely used to interpret model decisions and suggest actionable alternatives. This work presents a structure-aware and robustness-oriented counterfactual search method based on the conditional Gaussian network classifier (CGNC). The CGNC has a generative structure that encodes conditional dependencies and potential causal relations among features through a directed acyclic graph (DAG). This structure naturally embeds feature relationships into the search process, eliminating the need for additional constraints to ensure consistency with the model's structural assumptions. We adopt a convergence-guaranteed cutting-set procedure as an adversarial optimization framework, which iteratively approximates solutions that satisfy global robustness conditions. To address the nonconvex quadratic structure induced by feature dependencies, we apply piecewise McCormick relaxation to reformulate the problem as a mixed-integer linear program (MILP), ensuring global optimality. Experimental results show that our method achieves strong robustness, with direct global optimization of the original formulation providing especially stable and efficient results. The proposed framework is extensible to more complex constraint settings, laying the groundwork for future advances in counterfactual reasoning under nonconvex quadratic formulations.", "AI": {"tldr": "The paper proposes a robustness-focused approach for counterfactual explanations using a model that embeds feature relationships and ensures global optimality through mixed-integer linear programming.", "motivation": "Counterfactual explanations are essential for understanding AI model decisions and actionable recommendations, but ensuring structural consistency and robustness remains challenging.", "method": "A structure-aware approach utilizing conditional Gaussian network classifiers combined with a cutting-set optimization framework and mixed-integer linear programming for global optimality.", "result": "Experimental results demonstrate strong robustness and efficiency with the proposed method, showcasing its stability even under original nonconvex formulations.", "conclusion": "The framework provides a reliable and extensible solution for counterfactual reasoning, supporting future developments in handling complex constraints and nonconvex formulations."}}
{"id": "2602.07425", "pdf": "https://arxiv.org/pdf/2602.07425", "abs": "https://arxiv.org/abs/2602.07425", "authors": ["Dingzhi Yu", "Hongyi Tao", "Yuanyu Wan", "Luo Luo", "Lijun Zhang"], "title": "Sign-Based Optimizers Are Effective Under Heavy-Tailed Noise", "categories": ["cs.LG", "cs.CL", "math.OC"], "comment": "Code available at https://github.com/Dingzhen230/Heavy-tailed-Noise-in-LLMs", "summary": "While adaptive gradient methods are the workhorse of modern machine learning, sign-based optimization algorithms such as Lion and Muon have recently demonstrated superior empirical performance over AdamW in training large language models (LLM). However, a theoretical understanding of why sign-based updates outperform variance-adapted methods remains elusive. In this paper, we aim to bridge the gap between theory and practice through the lens of heavy-tailed gradient noise, a phenomenon frequently observed in language modeling tasks. Theoretically, we introduce a novel generalized heavy-tailed noise condition that captures the behavior of LLMs more accurately than standard finite variance assumptions. Under this noise model, we establish sharp convergence rates of SignSGD and Lion for generalized smooth function classes, matching or surpassing previous best-known bounds. Furthermore, we extend our analysis to Muon and Muonlight, providing what is, to our knowledge, the first rigorous analysis of matrix optimization under heavy-tailed stochasticity. These results offer a strong theoretical justification for the empirical superiority of sign-based optimizers, showcasing that they are naturally suited to handle the noisy gradients associated with heavy tails. Empirically, LLM pretraining experiments validate our theoretical insights and confirm that our proposed noise models are well-aligned with practice.", "AI": {"tldr": "This paper investigates why sign-based optimization algorithms outperform variance-adapted methods, introducing a theoretical framework based on heavy-tailed gradient noise prevalent in language modeling tasks.", "motivation": "A gap exists between theoretical and practical understanding of why sign-based algorithms like Lion and Muon perform better than adaptive methods like AdamW in training large language models under heavy-tailed noise.", "method": "The paper introduces a generalized heavy-tailed noise condition relevant to large language models and provides sharp convergence rate analyses for sign-based methods such as SignSGD, Lion, and Muon. It incorporates matrix optimization analysis for heavy-tailed stochasticity.", "result": "This work establishes improved theoretical bounds for sign-based optimizers under heavy-tailed gradient noise. Empirical experiments in LLM pretraining validate the effectiveness of the proposed noise model and theoretical findings.", "conclusion": "Sign-based optimizers are theoretically and empirically superior in handling heavy-tailed noisy gradients observed in language modeling tasks, providing a strong justification for their use over adaptive gradient methods."}}
{"id": "2602.08421", "pdf": "https://arxiv.org/pdf/2602.08421", "abs": "https://arxiv.org/abs/2602.08421", "authors": ["Farhad Keramat", "Salma Salimi", "Tomi Westerlund"], "title": "Decentralized Intent-Based Multi-Robot Task Planner with LLM Oracles on Hyperledger Fabric", "categories": ["cs.RO"], "comment": null, "summary": "Large language models (LLMs) have opened new opportunities for transforming natural language user intents into executable actions. This capability enables embodied AI agents to perform complex tasks, without involvement of an expert, making human-robot interaction (HRI) more convenient. However these developments raise significant security and privacy challenges such as self-preferencing, where a single LLM service provider dominates the market and uses this power to promote their own preferences. LLM oracles have been recently proposed as a mechanism to decentralize LLMs by executing multiple LLMs from different vendors and aggregating their outputs to obtain a more reliable and trustworthy final result. However, the accuracy of these approaches highly depends on the aggregation method. The current aggregation methods mostly use semantic similarity between various LLM outputs, not suitable for robotic task planning, where the temporal order of tasks is important. To fill the gap, we propose an LLM oracle with a new aggregation method for robotic task planning. In addition, we propose a decentralized multi-robot infrastructure based on Hyperledger Fabric that can host the proposed oracle. The proposed infrastructure enables users to express their natural language intent to the system, which then can be decomposed into subtasks. These subtasks require coordinating different robots from different vendors, while enforcing fine-grained access control management on the data. To evaluate our methodology, we created the SkillChain-RTD benchmark made it publicly available. Our experimental results demonstrate the feasibility of the proposed architecture, and the proposed aggregation method outperforms other aggregation methods currently in use.", "AI": {"tldr": "The paper introduces an LLM oracle with a new aggregation method tailored for robotic task planning and proposes a decentralized multi-robot system using Hyperledger Fabric.", "motivation": "To address security and privacy issues in natural language-based robotic task planning, while mitigating self-preferencing in centralized LLM services.", "method": "Developing a new aggregation method for robotic task planning within LLM oracles and designing a decentralized infrastructure using Hyperledger Fabric.", "result": "Experimental results showcase the effectiveness of the architecture and highlight the proposed aggregation method's superiority over existing ones.", "conclusion": "The proposed system and aggregation method enhance reliability, interoperability, and security in robotic task planning led by LLM oracles."}}
{"id": "2602.08238", "pdf": "https://arxiv.org/pdf/2602.08238", "abs": "https://arxiv.org/abs/2602.08238", "authors": ["Nathaniel Imel", "Noga Zaslavasky"], "title": "On convexity and efficiency in semantic systems", "categories": ["cs.CL"], "comment": null, "summary": "There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.", "AI": {"tldr": "This paper explores the relationship between convexity and efficiency in human semantic category systems, especially in color naming.", "motivation": "To clarify the relationship between two widely held beliefs: semantic category systems are convex and efficient for communication, and to investigate why these properties co-occur.", "method": "The authors use the Information Bottleneck framework to conduct analytical and empirical analyses of semantic efficiency and convexity in color naming systems.", "result": "Convexity and efficiency are distinct, but in color naming, IB-optimal systems are predominantly convex. Efficiency is also shown to be a stronger predictor for real-world color naming systems than convexity.", "conclusion": "While convexity and efficiency often align in empirical structures, efficiency provides a more comprehensive and predictive framework for understanding semantic typology than convexity does."}}
{"id": "2602.07463", "pdf": "https://arxiv.org/pdf/2602.07463", "abs": "https://arxiv.org/abs/2602.07463", "authors": ["Misbah Ijaz", "Saif Ur Rehman Khan", "Abd Ur Rehman", "Tayyaba Asif", "Sebastian Vollmer", "Andreas Dengel", "Muhammad Nabeel Asim"], "title": "GlobalWasteData: A Large-Scale, Integrated Dataset for Robust Waste Classification and Environmental Monitoring", "categories": ["cs.CV"], "comment": null, "summary": "The growing amount of waste is a problem for the environment that requires efficient sorting techniques for various kinds of waste. An automated waste classification system is used for this purpose. The effectiveness of these Artificial Intelligence (AI) models depends on the quality and accessibility of publicly available datasets, which provide the basis for training and analyzing classification algorithms. Although several public waste classification datasets exist, they remain fragmented, inconsistent, and biased toward specific environments. Differences in class names, annotation formats, image conditions, and class distributions make it difficult to combine these datasets or train models that generalize well to real world scenarios. To address these issues, we introduce the GlobalWasteData (GWD) archive, a large scale dataset of 89,807 images across 14 main categories, annotated with 68 distinct subclasses. We compile this novel integrated GWD archive by merging multiple publicly available datasets into a single, unified resource. This GWD archive offers consistent labeling, improved domain diversity, and more balanced class representation, enabling the development of robust and generalizable waste recognition models. Additional preprocessing steps such as quality filtering, duplicate removal, and metadata generation further improve dataset reliability. Overall, this dataset offers a strong foundation for Machine Learning (ML) applications in environmental monitoring, recycling automation, and waste identification, and is publicly available to promote future research and reproducibility.", "AI": {"tldr": "The paper introduces GlobalWasteData (GWD), a unified, large-scale dataset designed to overcome challenges in waste classification such as fragmented datasets and biases. GWD offers improved image quality, balanced categories, and consistent annotations for better AI model development.", "motivation": "Efficient sorting and classification of waste are essential to address environmental challenges, but existing public datasets are fragmented, inconsistent, and problematic for AI model generalization.", "method": "The authors merged multiple public datasets into one unified archive named GlobalWasteData (GWD) with 89,807 images in 14 main categories and 68 subclasses. They employed additional preprocessing steps like quality filtering, duplicate removal, and consistent labeling.", "result": "The resulting GWD archive exhibits improved dataset reliability and offers balanced class representation, diverse domains, and consistent labeling. It supports the development of robust AI models for waste identification.", "conclusion": "GlobalWasteData provides a valuable resource for the AI community, promoting better waste classification models with environmental applications. It facilitates reproducibility and paves the way for scalable solutions in recycling automation and environmental monitoring."}}
{"id": "2602.08552", "pdf": "https://arxiv.org/pdf/2602.08552", "abs": "https://arxiv.org/abs/2602.08552", "authors": ["Fredrik Cumlin"], "title": "Rho-Perfect: Correlation Ceiling For Subjective Evaluation Datasets", "categories": ["cs.LG", "eess.AS", "stat.ML"], "comment": null, "summary": "Subjective ratings contain inherent noise that limits the model-human correlation, but this reliability issue is rarely quantified. In this paper, we present $\u03c1$-Perfect, a practical estimation of the highest achievable correlation of a model on subjectively rated datasets. We define $\u03c1$-Perfect to be the correlation between a perfect predictor and human ratings, and derive an estimate of the value based on heteroscedastic noise scenarios, a common occurrence in subjectively rated datasets. We show that $\u03c1$-Perfect squared estimates test-retest correlation and use this to validate the estimate. We demonstrate the use of $\u03c1$-Perfect on a speech quality dataset and show how the measure can distinguish between model limitations and data quality issues.", "AI": {"tldr": "The paper introduces $\u03c1$-Perfect, a measure to estimate the upper limit of model correlation on noisy, subjectively rated datasets, factoring in human and data limitations.", "motivation": "Subjective ratings are noisy, limiting model-human correlation, yet the reliability is rarely quantified. This paper aims to address this gap.", "method": "The authors define $\u03c1$-Perfect as the correlation between a perfect predictor and human ratings, and provide an estimation methodology considering common heteroscedastic noise in such datasets.", "result": "They validate the estimation method by showing how $\u03c1$-Perfect squared aligns with test-retest reliability, and demonstrate its utility on a speech quality dataset to differentiate between model weaknesses and data quality issues.", "conclusion": "$\u03c1$-Perfect is a useful metric for understanding model performance limits and dissecting data quality concerns in subjectively rated datasets."}}
{"id": "2602.08030", "pdf": "https://arxiv.org/pdf/2602.08030", "abs": "https://arxiv.org/abs/2602.08030", "authors": ["Yilun Zheng", "Dongyang Ma", "Tian Liang", "Jiahao Xu", "Xinting Huang", "Lijie Chen", "Haitao Mi", "Yan Wang"], "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.\n  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.", "AI": {"tldr": "The paper introduces Free()LM, a system that incorporates self-forgetting mechanisms to improve reasoning models' performance by pruning redundant information.", "motivation": "Standard reasoning models often degrade in performance with excessive computational steps due to an inability to eliminate irrelevant or obsolete data.", "method": "Free()LM employs a Free-Module, a LoRA adapter, to allow self-forgetting by switching between reasoning and cleaning modes to identify and prune non-essential context.", "result": "Free()LM outperforms existing models, achieving a 3.3% average improvement, new SOTA in IMOanswerBench, and restores 50% accuracy in tasks where traditional models fail (0% accuracy).", "conclusion": "Effective reasoning demands not just the capacity to process information but also a mechanism to discard redundant or irrelevant data."}}
{"id": "2602.07429", "pdf": "https://arxiv.org/pdf/2602.07429", "abs": "https://arxiv.org/abs/2602.07429", "authors": ["Yuanxu Sun", "Yuezhou Ma", "Haixu Wu", "Guanyang Zeng", "Muye Chen", "Jianmin Wang", "Mingsheng Long"], "title": "Brep2Shape: Boundary and Shape Representation Alignment via Self-Supervised Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Boundary representation (B-rep) is the industry standard for computer-aided design (CAD). While deep learning shows promise in processing B-rep models, existing methods suffer from a representation gap: continuous approaches offer analytical precision but are visually abstract, whereas discrete methods provide intuitive clarity at the expense of geometric precision. To bridge this gap, we introduce Brep2Shape, a novel self-supervised pre-training method designed to align abstract boundary representations with intuitive shape representations. Our method employs a geometry-aware task where the model learns to predict dense spatial points from parametric B\u00e9zier control points, enabling the network to better understand physical manifolds derived from abstract coefficients. To enhance this alignment, we propose a Dual Transformer backbone with parallel streams that independently encode surface and curve tokens to capture their distinct geometric properties. Moreover, the topology attention is integrated to model the interdependencies between surfaces and curves, thereby maintaining topological consistency. Experimental results demonstrate that Brep2Shape offers significant scalability, achieving state-of-the-art accuracy and faster convergence across various downstream tasks.", "AI": {"tldr": "Brep2Shape is introduced as a method to bridge the gap between analytical precision and intuitive clarity in using B-rep models for CAD tasks.", "motivation": "To address the limitations in CAD B-rep model processing, where continuous methods lack visual clarity and discrete methods sacrifice geometric precision.", "method": "Brep2Shape employs a self-supervised geometry-aware task that learns dense spatial points from B\u00e9zier control points, utilizes a Dual Transformer backbone to encode geometric properties, and incorporates topology attention to maintain topological consistency.", "result": "The proposed method achieves better scalability, state-of-the-art accuracy, and faster convergence in various downstream CAD-related tasks.", "conclusion": "Brep2Shape successfully aligns abstract representations with intuitive shapes, advancing the utility and precision of B-rep models in CAD workflows."}}
{"id": "2602.08425", "pdf": "https://arxiv.org/pdf/2602.08425", "abs": "https://arxiv.org/abs/2602.08425", "authors": ["Jinxian Zhou", "Ruihai Wu", "Yiwei Liu", "Yiwen Hou", "Xunzhe Zhou", "Checheng Yu", "Licheng Zhong", "Lin Shao"], "title": "Bi-Adapt: Few-shot Bimanual Adaptation for Novel Categories of 3D Objects via Semantic Correspondence", "categories": ["cs.RO"], "comment": null, "summary": "Bimanual manipulation is imperative yet challenging for robots to execute complex tasks, requiring coordinated collaboration between two arms. However, existing methods for bimanual manipulation often rely on costly data collection and training, struggling to generalize to unseen objects in novel categories efficiently. In this paper, we present Bi-Adapt, a novel framework designed for efficient generalization for bimanual manipulation via semantic correspondence. Bi-Adapt achieves cross-category affordance mapping by leveraging the strong capability of vision foundation models. Fine-tuning with restricted data on novel categories, Bi-Adapt exhibits notable generalization to out-of-category objects in a zero-shot manner. Extensive experiments conducted in both simulation and real-world environments validate the effectiveness of our approach and demonstrate its high efficiency, achieving a high success rate on different benchmark tasks across novel categories with limited data. Project website: https://biadapt-project.github.io/", "AI": {"tldr": "Bi-Adapt is a new framework that enables robots to perform complex bimanual manipulations with strong generalization to unseen objects, utilizing semantic correspondence and vision foundation models.", "motivation": "To address the challenges of efficient and generalized bimanual manipulation for robots in novel categories, overcoming reliance on costly data collection and training.", "method": "The framework leverages vision foundation models for cross-category affordance mapping and fine-tunes them with limited data, enabling zero-shot generalization to out-of-category objects.", "result": "Extensive experiments in both simulations and real-world settings show high success rates for manipulating various novel objects across different benchmarks with minimal data.", "conclusion": "Bi-Adapt is an effective and efficient solution for achieving generalization in robotic bimanual manipulation tasks, validated through successful experiments in diverse settings."}}
{"id": "2602.08252", "pdf": "https://arxiv.org/pdf/2602.08252", "abs": "https://arxiv.org/abs/2602.08252", "authors": ["Devin R. Wright", "Justin E. Lane", "F. LeRon Shults"], "title": "Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence", "categories": ["cs.CL"], "comment": "Initial submitted version", "summary": "In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.", "AI": {"tldr": "The study analyzes psychological extremism using a Cognitive Linguistic Identity Fusion Score involving LLMs and implicit metaphor, offering better predictive tools for identity fusion and extremism analysis.", "motivation": "The paper is motivated by the increasing polarization and political violence, aiming to understand the psychological foundations of extremism through advanced methods.", "method": "The paper uses the Cognitive Linguistic Identity Fusion Score, employing cognitive linguistic patterns, LLMs, and implicit metaphors to measure identity fusion from language.", "result": "The approach outperforms prior methods in predicting fusion scores in datasets from the UK and Singapore and identifies two high-fusion pathways to violence from extremist manifesto analysis.", "conclusion": "The findings refine theories of identity fusion, providing an improved tool for investigating fusion and detecting extremism in scalable ways."}}
{"id": "2602.07493", "pdf": "https://arxiv.org/pdf/2602.07493", "abs": "https://arxiv.org/abs/2602.07493", "authors": ["Tianhao Zhou", "Yujia Chen", "Zhihao Zhan", "Yuhang Ming", "Jianzhu Huai"], "title": "Thermal odometry and dense mapping using learned ddometry and Gaussian splatting", "categories": ["cs.CV"], "comment": "11 pages, 2 figures, 5 tables", "summary": "Thermal infrared sensors, with wavelengths longer than smoke particles, can capture imagery independent of darkness, dust, and smoke. This robustness has made them increasingly valuable for motion estimation and environmental perception in robotics, particularly in adverse conditions. Existing thermal odometry and mapping approaches, however, are predominantly geometric and often fail across diverse datasets while lacking the ability to produce dense maps. Motivated by the efficiency and high-quality reconstruction ability of recent Gaussian Splatting (GS) techniques, we propose TOM-GS, a thermal odometry and mapping method that integrates learning-based odometry with GS-based dense mapping. TOM-GS is among the first GS-based SLAM systems tailored for thermal cameras, featuring dedicated thermal image enhancement and monocular depth integration. Extensive experiments on motion estimation and novel-view rendering demonstrate that TOM-GS outperforms existing learning-based methods, confirming the benefits of learning-based pipelines for robust thermal odometry and dense reconstruction.", "AI": {"tldr": "TOM-GS is a thermal odometry and mapping method using Gaussian Splatting for dense maps, tailored for thermal cameras. It outperforms existing approaches in robustness and reconstruction.", "motivation": "Thermal infrared sensors are robust in adverse situations, but existing methods for thermal odometry often fail across datasets and cannot produce dense maps. Efficient techniques like Gaussian Splatting prompt the innovation.", "method": "TOM-GS combines learning-based odometry and Gaussian Splatting-based dense mapping with thermal image enhancement and monocular depth integration.", "result": "Extensive experiments showed TOM-GS surpasses current learning-based approaches in motion estimation and novel-view rendering.", "conclusion": "TOM-GS validates the advantage of learning-based approaches for robust thermal odometry and dense environmental reconstruction."}}
{"id": "2602.08629", "pdf": "https://arxiv.org/pdf/2602.08629", "abs": "https://arxiv.org/abs/2602.08629", "authors": ["Bo Peng", "Sirui Chen", "Jiaguo Tian", "Yu Qiao", "Chaochao Lu"], "title": "CauScale: Neural Causal Discovery at Scale", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.", "AI": {"tldr": "CauScale, a neural architecture for efficient causal discovery, addresses scalability issues with large graphs, achieving high causal discovery accuracy and significant inference speedups.", "motivation": "Existing approaches to causal discovery struggle with time and space efficiency, particularly when applied to large graphs. This impairs progress in scientific AI and data analysis.", "method": "CauScale employs a reduction unit to compress data embeddings, tied attention weights for space efficiency, and a two-stream design to maintain high accuracy. The data stream extracts relational evidence while the graph stream integrates statistical priors and structural signals.", "result": "CauScale successfully scales to 500-node graphs during training, achieves 99.6% mAP on in-distribution data, 84.4% mAP on out-of-distribution data, and delivers 4-13,000 times inference speedups over prior methods.", "conclusion": "CauScale overcomes efficiency bottlenecks in causal discovery, proving its scalability and accuracy for graphs up to 1000 nodes, while notably enhancing inference speed."}}
{"id": "2602.08052", "pdf": "https://arxiv.org/pdf/2602.08052", "abs": "https://arxiv.org/abs/2602.08052", "authors": ["Bulent Soykan", "Sean Mondesire", "Ghaith Rabadi", "Grace Bochenek"], "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling", "categories": ["cs.AI", "cs.ET"], "comment": "11 pages, 2 figures, Winter Simulation Conference (WSC) 2025", "summary": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.", "AI": {"tldr": "The paper addresses the Unrelated Parallel Machine Scheduling Problem (UPMSP) by proposing a novel Deep Reinforcement Learning framework using PPO combined with GNN, achieving superior results in minimizing Total Weighted Tardiness and Total Setup Time.", "motivation": "Traditional approaches struggle to effectively balance competing objectives (Total Weighted Tardiness and Total Setup Time) in complex scheduling problems like UPMSP.", "method": "A Proximal Policy Optimization (PPO) agent leverages a Graph Neural Network (GNN) to directly learn scheduling policies, guided by a multi-objective reward function.", "result": "Experimental results show the PPO-GNN agent outperforms standard dispatching rules and metaheuristics in achieving a better trade-off between Total Weighted Tardiness and Total Setup Time.", "conclusion": "The PPO-GNN framework provides a scalable and robust solution for complex manufacturing scheduling challenges, demonstrating its effectiveness over traditional methods."}}
{"id": "2602.07440", "pdf": "https://arxiv.org/pdf/2602.07440", "abs": "https://arxiv.org/abs/2602.07440", "authors": ["C\u00e9dric Jung", "Shirin Salehi", "Anke Schmeink"], "title": "Active Learning Using Aggregated Acquisition Functions: Accuracy and Sustainability Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Active learning (AL) is a machine learning (ML) approach that strategically selects the most informative samples for annotation during training, aiming to minimize annotation costs. This strategy not only reduces labeling expenses but also results in energy savings during neural network training, thereby enhancing both data and energy efficiency. In this paper, we implement and evaluate various state-of-the-art acquisition functions, analyzing their accuracy and computational costs, while discussing the advantages and disadvantages of each method. Our findings reveal that representativity-based acquisition functions effectively explore the dataset but do not prioritize boundary decisions, whereas uncertainty-based acquisition functions focus on refining boundary decisions already identified by the neural network. This trade-off is known as the exploration-exploitation dilemma. To address this dilemma, we introduce six aggregation structures: series, parallel, hybrid, adaptive feedback, random exploration, and annealing exploration. Our aggregated acquisition functions alleviate common AL pathologies such as batch mode inefficiency and the cold start problem. Additionally, we focus on balancing accuracy and energy consumption, contributing to the development of more sustainable, energy-aware artificial intelligence (AI). We evaluate our proposed structures on various models and datasets. Our results demonstrate the potential of these structures to reduce computational costs while maintaining or even improving accuracy. Innovative aggregation approaches, such as alternating between acquisition functions such as BALD and BADGE, have shown robust results. Sequentially running functions like $K$-Centers followed by BALD has achieved the same performance goals with up to 12\\% fewer samples, while reducing the acquisition cost by almost half.", "AI": {"tldr": "This paper focuses on improving Active Learning efficiency and sustainability by analyzing acquisition functions, addressing their trade-offs, and proposing innovative aggregation methods.", "motivation": "Active Learning can minimize annotation expenses and energy consumption during neural network training, necessitating further exploration of acquisition functions.", "method": "Implemented and assessed various acquisition functions and introduced six aggregation structures to address Active Learning issues.", "result": "Aggregation approaches like alternating BALD and BADGE or sequential strategies like $K$-Centers followed by BALD reduce sample usage and computational costs significantly.", "conclusion": "Using aggregated acquisition functions can reduce computational costs while maintaining or enhancing accuracy, supporting data-efficient and energy-aware AI development."}}
{"id": "2602.08440", "pdf": "https://arxiv.org/pdf/2602.08440", "abs": "https://arxiv.org/abs/2602.08440", "authors": ["Tian Gao", "Celine Tan", "Catherine Glossop", "Timothy Gao", "Jiankai Sun", "Kyle Stachowicz", "Shirley Wu", "Oier Mees", "Dorsa Sadigh", "Sergey Levine", "Chelsea Finn"], "title": "SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios", "categories": ["cs.RO"], "comment": null, "summary": "A fundamental challenge in autonomous driving is the integration of high-level, semantic reasoning for long-tail events with low-level, reactive control for robust driving. While large vision-language models (VLMs) trained on web-scale data offer powerful common-sense reasoning, they lack the grounded experience necessary for safe vehicle control. We posit that an effective autonomous agent should leverage the world knowledge of VLMs to guide a steerable driving policy toward robust control in driving scenarios. To this end, we propose SteerVLA, which leverages the reasoning capabilities of VLMs to produce fine-grained language instructions that steer a vision-language-action (VLA) driving policy. Key to our method is this rich language interface between the high-level VLM and low-level VLA, which allows the high-level policy to more effectively ground its reasoning in the control outputs of the low-level policy. To provide fine-grained language supervision aligned with vehicle control, we leverage a VLM to augment existing driving data with detailed language annotations, which we find to be essential for effective reasoning and steerability. We evaluate SteerVLA on a challenging closed-loop benchmark, where it outperforms state-of-the-art methods by 4.77 points in overall driving score and by 8.04 points on a long-tail subset. The project website is available at: https://steervla.github.io/.", "AI": {"tldr": "The paper introduces SteerVLA, a method that uses large vision-language models (VLMs) to guide autonomous driving policies by leveraging fine-grained language instructions for better decision-making and control.", "motivation": "The motivation is to address the need for high-level semantic reasoning in long-tail events and robust low-level control in autonomous driving, which current systems lack. VLMs offer reasoning capabilities but are not grounded enough for safe control.", "method": "The authors propose SteerVLA, which integrates VLMs with a driving policy by using rich language instructions as an interface between high-level reasoning and control actions. They enhance training by augmenting driving data with VLM-generated language annotations.", "result": "The approach achieved a 4.77-point improvement in overall driving score and an 8.04-point boost on challenging long-tail scenarios compared to state-of-the-art methods.", "conclusion": "SteerVLA demonstrates that using VLMs for fine-grained language instruction can significantly improve the robustness and effectiveness of autonomous driving policies in both typical and long-tail scenarios."}}
{"id": "2602.08274", "pdf": "https://arxiv.org/pdf/2602.08274", "abs": "https://arxiv.org/abs/2602.08274", "authors": ["Jan Philip Wahle"], "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection", "categories": ["cs.CL", "cs.AI"], "comment": "PhD dissertation, University of G\u00f6ttingen Germany, 2025. 182 pages", "summary": "Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...", "AI": {"tldr": "The paper focuses on decomposing paraphrases into linguistic aspects to achieve a fine-grained understanding of semantic equivalence, improving computational language models' performance in tasks like plagiarism detection and duplicate question identification.", "motivation": "To enhance computational language models' understanding and control over the different linguistic aspects of paraphrases, allowing for precise semantic processing and avoiding binary simplifications of paraphrases.", "method": "The author proposes a method for decomposing paraphrases into their linguistic aspects (paraphrase types) to train models explicitly for a more nuanced understanding of semantic equivalence.", "result": "The study found that models trained on paraphrase types significantly outperform human baselines and binary-trained models in tasks like plagiarism detection and question identification on platforms such as Wikipedia, arXiv, and Quora.", "conclusion": "Explicitly training language models on paraphrase types leads to better semantic understanding and stronger performance in related applications compared to conventional binary approaches."}}
{"id": "2602.07495", "pdf": "https://arxiv.org/pdf/2602.07495", "abs": "https://arxiv.org/abs/2602.07495", "authors": ["Jiawen Zheng", "Haonan Jia", "Ming Li", "Yuhui Zheng", "Yufeng Zeng", "Yang Gao", "Chen Liang"], "title": "Learning Brain Representation with Hierarchical Visual Embeddings", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Decoding visual representations from brain signals has attracted significant attention in both neuroscience and artificial intelligence. However, the degree to which brain signals truly encode visual information remains unclear. Current visual decoding approaches explore various brain-image alignment strategies, yet most emphasize high-level semantic features while neglecting pixel-level details, thereby limiting our understanding of the human visual system. In this paper, we propose a brain-image alignment strategy that leverages multiple pre-trained visual encoders with distinct inductive biases to capture hierarchical and multi-scale visual representations, while employing a contrastive learning objective to achieve effective alignment between brain signals and visual embeddings. Furthermore, we introduce a Fusion Prior, which learns a stable mapping on large-scale visual data and subsequently matches brain features to this pre-trained prior, thereby enhancing distributional consistency across modalities. Extensive quantitative and qualitative experiments demonstrate that our method achieves a favorable balance between retrieval accuracy and reconstruction fidelity.", "AI": {"tldr": "This paper aims to decode visual information from brain signals using a novel alignment strategy leveraging multi-scale encoders and contrastive learning for accurate retrieval and fidelity. ", "motivation": "To understand how brain signals encode visual information and improve decoding strategies by addressing shortcomings of existing methods, such as neglecting pixel-level details.", "method": "The authors propose using multiple pre-trained visual encoders with hierarchical visual features. They employ contrastive learning for alignment and introduce a Fusion Prior to enhance cross-modality consistency.", "result": "The approach achieves a balance between accuracy in visual retrieval and high-quality reconstruction.", "conclusion": "The proposed method advances understanding and decoding of visual representations from brain signals, highlighting the potential of hierarchical and multi-modal strategies."}}
{"id": "2602.08681", "pdf": "https://arxiv.org/pdf/2602.08681", "abs": "https://arxiv.org/abs/2602.08681", "authors": ["Leander Kurscheidt", "Gabriele Masina", "Roberto Sebastiani", "Antonio Vergari"], "title": "The Theory and Practice of MAP Inference over Non-Convex Constraints", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In many safety-critical settings, probabilistic ML systems have to make predictions subject to algebraic constraints, e.g., predicting the most likely trajectory that does not cross obstacles.\n  These real-world constraints are rarely convex, nor the densities considered are (log-)concave.\n  This makes computing this constrained maximum a posteriori (MAP) prediction efficiently and reliably extremely challenging.\n  In this paper, we first investigate under which conditions we can perform constrained MAP inference over continuous variables exactly and efficiently and devise a scalable message-passing algorithm for this tractable fragment.\n  Then, we devise a general constrained MAP strategy that interleaves partitioning the domain into convex feasible regions with numerical constrained optimization.\n  We evaluate both methods on synthetic and real-world benchmarks, showing our %\n  approaches outperform constraint-agnostic baselines, and scale to complex densities intractable for SoTA exact solvers.", "AI": {"tldr": "The paper addresses constraints in probabilistic predictions for safety-critical systems. It proposes exact and efficient inference methods with scalable algorithms and general strategies for constrained MAP inference, outperforming existing baselines.", "motivation": "The authors aim to address challenges in making algebraically constrained probabilistic predictions in safety-critical settings, where real-world constraints and densities are often intractable and non-convex.", "method": "The paper introduces a scalable message-passing algorithm for tractable cases and a general strategy combining domain partitioning and numerical constrained optimization for more complex scenarios.", "result": "Their methods are evaluated on synthetic and real-world benchmarks, demonstrating superiority over constraint-agnostic baselines and scalability to complex densities.", "conclusion": "The proposed approaches enable efficient and reliable constrained MAP inference, improving performance and applicability over existing solvers in non-convex settings."}}
{"id": "2602.08061", "pdf": "https://arxiv.org/pdf/2602.08061", "abs": "https://arxiv.org/abs/2602.08061", "authors": ["Doni Bloomfield", "Allison Berke", "Moritz S. Hanke", "Aaron Maiwald", "James R. M. Black", "Toby Webster", "Tina Hernandez-Boussard", "Oliver M. Crook", "Jassi Pannu"], "title": "Securing Dual-Use Pathogen Data of Concern", "categories": ["cs.AI", "q-bio.OT"], "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI", "summary": "Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.", "AI": {"tldr": "The paper proposes a five-tier Biosecurity Data Level (BDL) framework to categorize pathogen data for training AI models, aiming to prevent misuse for harmful purposes like bioweapons development.", "motivation": "The need to address biosecurity risks associated with the use of biological data to train AI models drove the researchers to propose measures for controlling such data.", "method": "The paper introduces a five-tier BDL framework that categorizes pathogen data based on its potential to contribute to biosecurity risks, supplemented by proposed technical restrictions and governance measures.", "result": "The authors developed a structured framework and governance suggestions to control data use, aiming to reduce the risks associated with dual-use and harmful applications in biological AI.", "conclusion": "By adopting the BDL framework, along with data controls and governance measures, the proliferation of concerning biosecurity risks linked to biological AI can be minimized."}}
{"id": "2602.07441", "pdf": "https://arxiv.org/pdf/2602.07441", "abs": "https://arxiv.org/abs/2602.07441", "authors": ["Jinzong Dong", "Wei Huang", "Jianshu Zhang", "Zhuo Chen", "Xinzhe Yuan", "Qinying Gu", "Zhaohui Jiang", "Nanyang Ye"], "title": "Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) optimizes policies from a previously collected static dataset and is an important branch of RL. A popular and promising approach is to regularize actor-critic methods with behavior cloning (BC), which yields realistic policies and mitigates bias from out-of-distribution actions, but can impose an often-overlooked performance ceiling: when dataset actions are suboptimal, indiscriminate imitation structurally prevents the actor from fully exploiting high-value regions suggested by the critic, especially in later training when imitation is already dominant. We formally analyzed this limitation by investigating convergence properties of BC-regularized actor-critic optimization and verified it on a controlled continuous bandit task. To break this ceiling, we propose proximal action replacement (PAR), a plug-and-play training sample replacer that progressively replaces low-value actions with high-value actions generated by a stable actor, broadening the action exploration space while reducing the impact of low-value data. PAR is compatible with multiple BC regularization paradigms. Extensive experiments across offline RL benchmarks show that PAR consistently improves performance and approaches state-of-the-art when combined with the basic TD3+BC.", "AI": {"tldr": "The paper addresses limitations in offline reinforcement learning (RL) caused by behavior cloning regularization, proposing a method called Proximal Action Replacement (PAR) to overcome performance ceilings and improve policy training.", "motivation": "Offline RL struggles with suboptimal datasets when behavior cloning indiscriminately imitates actions, hindering actor's ability to exploit high-value regions suggested by the critic.", "method": "The authors propose Proximal Action Replacement (PAR), a process to progressively replace low-value actions with high-value ones during training, enhancing exploration and minimizing the influence of suboptimal data.", "result": "Experiments across offline RL benchmarks show that PAR improves performance significantly and approaches state-of-the-art performance when combined with TD3+BC.", "conclusion": "PAR enables offline RL actor-critic methods to overcome limitations from behavior cloning and enhances performance without compromising practicality."}}
{"id": "2602.08444", "pdf": "https://arxiv.org/pdf/2602.08444", "abs": "https://arxiv.org/abs/2602.08444", "authors": ["Samsaptak Ghosh", "M. Felix Orlando", "Sohom Chakrabarty"], "title": "Post-Collision Trajectory Restoration for a Single-track Ackermann Vehicle using Heuristic Steering and Tractive Force Functions", "categories": ["cs.RO", "eess.SY"], "comment": "10 pages, 6 figures", "summary": "Post-collision trajectory restoration is a safety-critical capability for autonomous vehicles, as impact-induced lateral motion and yaw transients can rapidly drive the vehicle away from the intended path. This paper proposes a structured heuristic recovery control law that jointly commands steering and tractive force for a generalized single-track Ackermann vehicle model. The formulation explicitly accounts for time-varying longitudinal velocity in the lateral-yaw dynamics and retains nonlinear steering-coupled interaction terms that are commonly simplified in the literature. Unlike approaches that assume constant longitudinal speed, the proposed design targets the transient post-impact regime where speed variations and nonlinear coupling significantly influence recovery. The method is evaluated in simulation on the proposed generalized single-track model and a standard 3DOF single-track reference model in MATLAB, demonstrating consistent post-collision restoration behaviour across representative initial post-impact conditions.", "AI": {"tldr": "This paper presents a heuristic control law for post-collision trajectory restoration in autonomous vehicles considering nonlinear dynamics and speed variations.", "motivation": "To address the gap in post-collision trajectory restoration by considering time-varying velocity and nonlinear interactions, which are commonly simplified in previous works.", "method": "The authors propose a heuristic recovery control law for a single-track Ackermann vehicle model, retaining nonlinear dynamics and accounting for speed variations, and evaluate it in MATLAB simulations.", "result": "The method showed consistent post-collision restoration behavior across various initial post-impact conditions in simulations.", "conclusion": "The proposed control law effectively restores post-collision trajectories, considering nonlinear dynamics and transient speed effects, making it suitable for safety-critical autonomous vehicle operations."}}
{"id": "2602.08281", "pdf": "https://arxiv.org/pdf/2602.08281", "abs": "https://arxiv.org/abs/2602.08281", "authors": ["Zhilin Wang", "Yafu Li", "Shunkai Zhang", "Zhi Wang", "Haoran Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR", "categories": ["cs.CL"], "comment": "15 pages", "summary": "Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($\u03c1\\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.", "AI": {"tldr": "This paper explores whether RLVR introduces new capabilities to LLMs using a probabilistic framework, focusing on multi-step reasoning. Results show RLVR enhances skills and drives emergent abilities.", "motivation": "To understand if RLVR creates genuinely new capabilities in LLMs or merely amplifies existing latent ones through a well-defined probabilistic mechanism.", "method": "The paper trains models via RLVR, employing a framework (Algebrarium) that focuses on atomic steps in reasoning. Testing is conducted using unseen multi-step reasoning scenarios.", "result": "The study finds that RLVR improves exploration of solutions by amplifying existing skills, strongly correlates performance with atomic step success probabilities, and prioritizes aggregate rewards, sometimes sacrificing specific skills.", "conclusion": "RLVR fosters emergent abilities in LLMs by iteratively optimizing solvable problems, enabling models to address previously unsolvable tasks through enhanced atomic reasoning steps."}}
{"id": "2602.07498", "pdf": "https://arxiv.org/pdf/2602.07498", "abs": "https://arxiv.org/abs/2602.07498", "authors": ["Zhufeng Xu", "Xuan Gao", "Feng-Lin Liu", "Haoxian Zhang", "Zhixue Fang", "Yu-Kun Lai", "Xiaoqiang Liu", "Pengfei Wan", "Lin Gao"], "title": "IM-Animation: An Implicit Motion Representation for Identity-decoupled Character Animation", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in video diffusion models has markedly advanced character animation, which synthesizes motioned videos by animating a static identity image according to a driving video. Explicit methods represent motion using skeleton, DWPose or other explicit structured signals, but struggle to handle spatial mismatches and varying body scales. %proportions. Implicit methods, on the other hand, capture high-level implicit motion semantics directly from the driving video, but suffer from identity leakage and entanglement between motion and appearance. To address the above challenges, we propose a novel implicit motion representation that compresses per-frame motion into compact 1D motion tokens. This design relaxes strict spatial constraints inherent in 2D representations and effectively prevents identity information leakage from the motion video. Furthermore, we design a temporally consistent mask token-based retargeting module that enforces a temporal training bottleneck, mitigating interference from the source images' motion and improving retargeting consistency. Our methodology employs a three-stage training strategy to enhance the training efficiency and ensure high fidelity. Extensive experiments demonstrate that our implicit motion representation and the propose IM-Animation's generative capabilities are achieve superior or competitive performance compared with state-of-the-art methods.", "AI": {"tldr": "IM-Animation introduces a novel implicit motion representation, addressing challenges in character animation for video synthesis by using compact 1D motion tokens and ensuring consistent retargeting.", "motivation": "Video diffusion models struggle with issues like spatial mismatches in explicit methods and identity leakage in implicit methods for animating characters.", "method": "IM-Animation uses compact 1D motion tokens for implicit motion representation, coupled with a mask token-based retargeting module and a three-stage training strategy.", "result": "IM-Animation shows superior or competitive performance against state-of-the-art methods in motion synthesis and fidelity.", "conclusion": "By addressing motion-related challenges and ensuring consistent identity representation, IM-Animation offers advancements in video-based character animation synthesis."}}
{"id": "2602.08723", "pdf": "https://arxiv.org/pdf/2602.08723", "abs": "https://arxiv.org/abs/2602.08723", "authors": ["Yujie Shen", "Zihan Wang", "Jian Qian", "Qi Lei"], "title": "Data Reconstruction: Identifiability and Optimization with Sample Splitting", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Training data reconstruction from KKT conditions has shown striking empirical success, yet it remains unclear when the resulting KKT equations have unique solutions and, even in identifiable regimes, how to reliably recover solutions by optimization. This work hereby focuses on these two complementary questions: identifiability and optimization. On the identifiability side, we discuss the sufficient conditions for KKT system of two-layer networks with polynomial activations to uniquely determine the training data, providing a theoretical explanation of when and why reconstruction is possible. On the optimization side, we introduce sample splitting, a curvature-aware refinement step applicable to general reconstruction objectives (not limited to KKT-based formulations): it creates additional descent directions to escape poor stationary points and refine solutions. Experiments demonstrate that augmenting several existing reconstruction methods with sample splitting consistently improves reconstruction performance.", "AI": {"tldr": "The study explores identifiability and optimization aspects of reconstructing training data from KKT conditions in two-layer networks and proposes a refinement technique, sample splitting, which enhances reconstruction outcomes.", "motivation": "To address the uncertainties surrounding the uniqueness of solutions derived from KKT conditions and improve optimization for reliable reconstruction of training data in deep networks.", "method": "The authors analyze sufficient conditions for identifiability in polynomial activation networks and propose a refinement technique, called sample splitting, to overcome optimization shortcomings and improve reconstruction.", "result": "Identifiability conditions for training data reconstruction were established, and the sample splitting method consistently improved reconstruction performance in various experiments.", "conclusion": "The study provides theoretical insights into reconstruction feasibility and presents a practical optimization enhancement, setting a foundation for more reliable training data reconstruction methods."}}
{"id": "2602.08092", "pdf": "https://arxiv.org/pdf/2602.08092", "abs": "https://arxiv.org/abs/2602.08092", "authors": ["Majid Ghasemi", "Mark Crowley"], "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this \"judging the judges\" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.", "AI": {"tldr": "The paper identifies a failure in AI alignment assumptions in social settings and introduces a new method (ESA) to overcome it.", "motivation": "To address the misalignment challenge in AI when human feedback is not always truthful or reliable, particularly in social environments.", "method": "They propose Epistemic Source Alignment (ESA), which focuses on evaluating the source of feedback (judging evaluators) using safety axioms instead of relying on statistical consensus.", "result": "They prove theoretically and demonstrate empirically that ESA outperforms traditional methods by recovering the correct objective even under biased or collusive evaluators.", "conclusion": "The proposed ESA mechanism offers a reliable solution for AI to align with true objectives despite noisy or adversarial feedback, surpassing traditional methods."}}
{"id": "2602.08450", "pdf": "https://arxiv.org/pdf/2602.08450", "abs": "https://arxiv.org/abs/2602.08450", "authors": ["Stefan Ivi\u0107", "Luka Lan\u010da", "Karlo Jakac", "Ante Sikirica", "Stella Dumen\u010di\u0107", "Matej Mali\u0161a", "Zvonimir Mrle", "Bojan Crnkovi\u0107"], "title": "UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials", "categories": ["cs.RO", "math.OC"], "comment": null, "summary": "This paper presents the integration of flow field reconstruction, dynamic probabilistic modeling, search control, and machine vision detection in a system for autonomous maritime search operations. Field experiments conducted in Valun Bay (Cres Island, Croatia) involved real-time drifter data acquisition, surrogate flow model fitting based on computational fluid dynamics and numerical optimization, advanced multi-UAV search control and vision sensing, as well as deep learning-based object detection. The results demonstrate that a tightly coupled approach enables reliable detection of floating targets under realistic uncertainties and complex environmental conditions, providing concrete insights for future autonomous maritime search and rescue applications.", "AI": {"tldr": "This paper introduces a system integrating flow field modeling, probabilistic modeling, UAV search, and AI vision for maritime search operations, validated through field experiments.", "motivation": "The study aims to develop an efficient system capable of performing reliable autonomous maritime search operations under uncertain and complex environmental conditions.", "method": "The approach combines real-time data acquisition, surrogate flow modeling using computational fluid dynamics, numerical optimization, advanced UAV search control, and deep learning-based object detection.", "result": "Field experiments in Valun Bay demonstrated effective detection of floating targets, showcasing reliability even in challenging conditions.", "conclusion": "The integrated system provides valuable insights and shows promise for future autonomous maritime search and rescue operations."}}
{"id": "2602.08289", "pdf": "https://arxiv.org/pdf/2602.08289", "abs": "https://arxiv.org/abs/2602.08289", "authors": ["Binglin Wu", "Xianneng Li"], "title": "Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network", "categories": ["cs.CL"], "comment": null, "summary": "With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models.", "AI": {"tldr": "This paper presents Legal-KAHRE, a hypergraph neural network for entity and relation extraction in drug-related Chinese legal documents, outperforming existing models.", "motivation": "To address the lack of domain-specific adaptations in existing entity and relation extraction methods for legal documents, specifically in the judicial domain.", "method": "The approach introduces Legal-KAHRE, incorporating a neighbor-oriented packing strategy with biaffine mechanism for candidate span generation, a legal dictionary with domain knowledge encoded using multi-head attention, and domain-specific scenarios integrated into a hypergraph structure for improved inference.", "result": "The proposed method outperformed baseline models on the CAIL2022 information extraction dataset, highlighting its effectiveness in extracting relevant entities and relationships from legal texts.", "conclusion": "Leveraging domain-specific knowledge and hypergraph neural networks, the proposed method proves to be an advanced solution for extracting meaningful data from drug-related legal documents, offering significant improvements over current methods."}}
{"id": "2602.07512", "pdf": "https://arxiv.org/pdf/2602.07512", "abs": "https://arxiv.org/abs/2602.07512", "authors": ["Tao Wang", "Chenyu Lin", "Chenwei Tang", "Jizhe Zhou", "Deng Xiong", "Jianan Li", "Jian Zhao", "Jiancheng Lv"], "title": "Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection", "categories": ["cs.CV"], "comment": "paper accepted by ISPRS Journal of Photogrammetry and Remote Sensing ( IF=12.2)", "summary": "Detecting objects from UAV-captured images is challenging due to the small object size. In this work, a simple and efficient adaptive zoom-in framework is explored for object detection on UAV images. The main motivation is that the foreground objects are generally smaller and sparser than those in common scene images, which hinders the optimization of effective object detectors. We thus aim to zoom in adaptively on the objects to better capture object features for the detection task. To achieve the goal, two core designs are required: \\textcolor{black}{i) How to conduct non-uniform zooming on each image efficiently? ii) How to enable object detection training and inference with the zoomed image space?} Correspondingly, a lightweight offset prediction scheme coupled with a novel box-based zooming objective is introduced to learn non-uniform zooming on the input image. Based on the learned zooming transformation, a corner-aligned bounding box transformation method is proposed. The method warps the ground-truth bounding boxes to the zoomed space to learn object detection, and warps the predicted bounding boxes back to the original space during inference. We conduct extensive experiments on three representative UAV object detection datasets, including VisDrone, UAVDT, and SeaDronesSee. The proposed ZoomDet is architecture-independent and can be applied to an arbitrary object detection architecture. Remarkably, on the SeaDronesSee dataset, ZoomDet offers more than 8.4 absolute gain of mAP with a Faster R-CNN model, with only about 3 ms additional latency. The code is available at https://github.com/twangnh/zoomdet_code.", "AI": {"tldr": "This paper introduces ZoomDet, an adaptive zoom-in framework for enhancing object detection in UAV-captured images.", "motivation": "Object detection on UAV images is hindered by the small size and sparsity of objects in the foreground.", "method": "Proposes a lightweight offset prediction scheme and box-based zooming objective for adaptive, non-uniform zooming; transforms bounding boxes between zoomed and original spaces for training and inference.", "result": "ZoomDet significantly improves object detection performance, achieving over 8.4 mAP gain on the SeaDronesSee dataset with minimal latency overhead.", "conclusion": "The ZoomDet framework is architecture-independent, efficiently enhances detection in UAV images, and provides substantial accuracy gains with minimal computational cost."}}
{"id": "2602.08862", "pdf": "https://arxiv.org/pdf/2602.08862", "abs": "https://arxiv.org/abs/2602.08862", "authors": ["Lunjia Hu", "Jon Schneider", "Yifan Wu"], "title": "Near-optimal Swap Regret Minimization for Convex Losses", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "We give a randomized online algorithm that guarantees near-optimal $\\widetilde O(\\sqrt T)$ expected swap regret against any sequence of $T$ adaptively chosen Lipschitz convex losses on the unit interval. This improves the previous best bound of $\\widetilde O(T^{2/3})$ and answers an open question of Fishelson et al. [2025b]. In addition, our algorithm is efficient: it runs in $\\mathsf{poly}(T)$ time. A key technical idea we develop to obtain this result is to discretize the unit interval into bins at multiple scales of granularity and simultaneously use all scales to make randomized predictions, which we call multi-scale binning and may be of independent interest. A direct corollary of our result is an efficient online algorithm for minimizing the calibration error for general elicitable properties. This result does not require the Lipschitzness assumption of the identification function needed in prior work, making it applicable to median calibration, for which we achieve the first $\\widetilde O(\\sqrt T)$ calibration error guarantee.", "AI": {"tldr": "The paper presents a randomized online algorithm with near-optimal expected swap regret bounds of \\(\\widetilde{O}(\\sqrt{T})\\) for losses on the unit interval, improving previous bounds and introducing a multi-scale binning approach.", "motivation": "To address the open question by Fishelson et al. regarding minimizing swap regret bounds and improving the efficiency of algorithms in online settings.", "method": "The paper employs a multi-scale binning strategy that discretizes the unit interval into bins of various granularities, enabling randomized predictions across scales efficiently.", "result": "The algorithm achieves \\(\\widetilde{O}(\\sqrt{T})\\) expected swap regret and provides the first efficient result for minimizing calibration error in median calibration settings for elicitable properties.", "conclusion": "This approach improves state-of-the-art bounds, introduces a novel technique with broader applications, and removes restrictive assumptions in prior works, offering practical benefits for various scenarios of Lipschitz convex losses."}}
{"id": "2602.08104", "pdf": "https://arxiv.org/pdf/2602.08104", "abs": "https://arxiv.org/abs/2602.08104", "authors": ["Risal Shahriar Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains \"downstream-first\" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.", "AI": {"tldr": "This paper introduces an interpretable, two-stage gradient-based framework for detecting and understanding failures in safety-critical multi-agent reinforcement learning (MARL).", "motivation": "The motivation is to address the lack of methods for interpretable failure detection and attribution in MARL systems, which are increasingly deployed in safety-critical contexts.", "method": "A two-stage framework is developed: Stage 1 uses Taylor-remainder analysis for detecting initial failure sources (Patient-0), and Stage 2 validates these findings with geometric analysis to trace failure propagation pathways.", "result": "In evaluations with MARL environments and algorithms (Simple Spread and StarCraft II using MADDPG and HATRPO), the method demonstrated 88.2-99.4% accuracy in detecting Patient-0 failures while providing explanations for cascading failure propagation.", "conclusion": "The framework provides practical and interpretable tools for understanding and diagnosing cascading failures in complex MARL systems, moving beyond black-box approaches."}}
{"id": "2602.07465", "pdf": "https://arxiv.org/pdf/2602.07465", "abs": "https://arxiv.org/abs/2602.07465", "authors": ["Seungwoo Son", "Ingyu Seong", "Junhan Kim", "Hyemi Jang", "Yongkweon Jeon"], "title": "On the Importance of a Multi-Scale Calibration for Quantization", "categories": ["cs.LG", "cs.CL"], "comment": "ICASSP 2026", "summary": "Post-training quantization (PTQ) is a cornerstone for efficiently deploying large language models (LLMs), where a small calibration set critically affects quantization performance. However, conventional practices rely on random sequences of fixed length, overlooking the variable-length nature of LLM inputs. Input length directly influences the activation distribution and, consequently, the weight importance captured by the Hessian, which in turn affects quantization outcomes. As a result, Hessian estimates derived from fixed-length calibration may fail to represent the true importance of weights across diverse input scenarios. We propose MaCa (Matryoshka Calibration), a simple yet effective method for length-aware Hessian construction. MaCa (i) incorporates multi-scale sequence length information into Hessian estimation and (ii) regularizes each sequence as an independent sample, yielding a more stable and fruitful Hessian for accurate quantization. Experiments on state-of-the-art LLMs (e.g., Qwen3, Gemma3, LLaMA3) demonstrate that MaCa consistently improves accuracy under low bit quantization, offering a lightweight enhancement compatible with existing PTQ frameworks. To the best of our knowledge, this is the first work to systematically highlight the role of multi-scale calibration in LLM quantization.", "AI": {"tldr": "This paper introduces MaCa, a method that improves post-training quantization (PTQ) of large language models (LLMs) by considering variable input lengths during calibration.", "motivation": "Conventional PTQ relies on fixed-length calibration sequences, which fail to capture the variable-length nature of LLM inputs, leading to suboptimal quantization performance.", "method": "The MaCa method incorporates multi-scale sequence length information into Hessian estimation and regularizes sequences independently, thus improving the stability and efficacy of the Hessian for quantization.", "result": "MaCa enhances accuracy during low-bit quantization across various state-of-the-art LLMs (e.g., Qwen3, Gemma3, LLaMA3), demonstrating its effectiveness within existing PTQ frameworks.", "conclusion": "MaCa is a lightweight and reliable enhancement to PTQ, systematically addressing the importance of multi-scale calibration for LLM quantization and achieving better performance."}}
{"id": "2602.08466", "pdf": "https://arxiv.org/pdf/2602.08466", "abs": "https://arxiv.org/abs/2602.08466", "authors": ["Ning Hu", "Senhao Cao", "Maochen Li"], "title": "Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment", "categories": ["cs.RO", "cs.CV"], "comment": "7 pages, 1 figure", "summary": "Vision-guided robotic systems are increasingly deployed in precision alignment tasks that require reliable execution under near-field and off-axis configurations. While recent advances in pose estimation have significantly improved numerical accuracy, practical robotic systems still suffer from frequent execution failures even when pose estimates appear accurate. This gap suggests that pose accuracy alone is insufficient to guarantee execution-level reliability. In this paper, we reveal that such failures arise from a deterministic geometric error amplification mechanism, in which small pose estimation errors are magnified through system structure and motion execution, leading to unstable or failed alignment. Rather than modifying pose estimation algorithms, we propose a Reliability-aware Execution Gating mechanism that operates at the execution level. The proposed approach evaluates geometric consistency and configuration risk before execution, and selectively rejects or scales high-risk pose updates. We validate the proposed method on a real UR5 robotic platform performing single-step visual alignment tasks under varying camera-target distances and off-axis configurations. Experimental results demonstrate that the proposed execution gating significantly improves task success rates, reduces execution variance, and suppresses tail-risk behavior, while leaving average pose accuracy largely unchanged. Importantly, the proposed mechanism is estimator-agnostic and can be readily integrated with both classical geometry-based and learning-based pose estimation pipelines. These results highlight the importance of execution-level reliability modeling and provide a practical solution for improving robustness in near-field vision-guided robotic systems.", "AI": {"tldr": "This paper addresses the unreliability of pose estimation in robotic systems performing precision alignment tasks by proposing an execution-level gating mechanism to improve reliability.", "motivation": "Robotic systems struggle with execution failures in precision alignment tasks, even with accurate pose estimates, due to geometric error amplification during system motion.", "method": "The authors propose a Reliability-aware Execution Gating mechanism to evaluate geometric consistency, assess configuration risk, and reject or scale high-risk pose updates before execution.", "result": "The method, validated on a UR5 robotic platform, improved task success rates, reduced execution variance, and mitigated tail-risk behavior without affecting average pose accuracy.", "conclusion": "The proposed mechanism is effective, estimator-agnostic, and highlights the importance of execution-level reliability modeling to enhance robustness in vision-guided robotics."}}
{"id": "2602.08294", "pdf": "https://arxiv.org/pdf/2602.08294", "abs": "https://arxiv.org/abs/2602.08294", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "When Does Context Help? Error Dynamics of Contextual Information in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\\%$.", "AI": {"tldr": "The paper develops a theoretical framework to analyze how contextual information affects Transformer-based large language models (LLMs) during inference, improving their performance across tasks.", "motivation": "To address the lack of theoretical understanding of how contextual information (e.g., demonstrations, retrieved knowledge) influences LLMs' performance beyond specific scenarios like in-context learning.", "method": "The framework decomposes the error dynamics of a single-layer Transformer into a baseline error vector and a contextual correction vector, with mathematical conditions explaining when and how contexts reduce errors. This theory also extends to multi-layer and multi-context Transformers.", "result": "The authors prove geometric conditions for effective error reduction, quantify the limits of context's influence, and validate these findings through experiments in contexts like in-context learning, retrieval-augmented generation, and memory evolution, achieving a 0.6% performance improvement.", "conclusion": "The findings provide a quantitative basis for understanding contextual improvement dynamics and suggest strategies for optimal context selection to enhance LLMs' performance."}}
{"id": "2602.07523", "pdf": "https://arxiv.org/pdf/2602.07523", "abs": "https://arxiv.org/abs/2602.07523", "authors": ["Zhen Zhang", "Qing Zhao", "Xiuhe Li", "Cheng Wang", "Guoqiang Zhu", "Yu Zhang", "Yining Huo", "Hongyi Yu", "Yi Zhang"], "title": "CA-YOLO: Cross Attention Empowered YOLO for Biomimetic Localization", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication.Please note that once the article has been published by IEEE, preprints on locations not specified above should be removed if possible", "summary": "In modern complex environments, achieving accurate and efficient target localization is essential in numerous fields. However, existing systems often face limitations in both accuracy and the ability to recognize small targets. In this study, we propose a bionic stabilized localization system based on CA-YOLO, designed to enhance both target localization accuracy and small target recognition capabilities. Acting as the \"brain\" of the system, the target detection algorithm emulates the visual focusing mechanism of animals by integrating bionic modules into the YOLO backbone network. These modules include the introduction of a small target detection head and the development of a Characteristic Fusion Attention Mechanism (CFAM). Furthermore, drawing inspiration from the human Vestibulo-Ocular Reflex (VOR), a bionic pan-tilt tracking control strategy is developed, which incorporates central positioning, stability optimization, adaptive control coefficient adjustment, and an intelligent recapture function. The experimental results show that CA-YOLO outperforms the original model on standard datasets (COCO and VisDrone), with average accuracy metrics improved by 3.94%and 4.90%, respectively.Further time-sensitive target localization experiments validate the effectiveness and practicality of this bionic stabilized localization system.", "AI": {"tldr": "This study introduces a bionic stabilized localization system based on CA-YOLO for improved accuracy and small target recognition, inspired by biological visual and control mechanisms.", "motivation": "Current systems often struggle with low localization accuracy and inability to detect small targets effectively in complex environments.", "method": "The proposed system enhances the YOLO network with bionic modules, including a Characteristic Fusion Attention Mechanism (CFAM) and a small target detection head. It also integrates a bionic pan-tilt tracking strategy inspired by the human Vestibulo-Ocular Reflex (VOR).", "result": "Experimental results show CA-YOLO improves accuracy by 3.94% on COCO dataset and 4.90% on VisDrone dataset. Time-sensitive experiments validate its practicality.", "conclusion": "The bionic system significantly enhances target localization accuracy, small target detection, and proves highly effective for application in complex environments."}}
{"id": "2602.08907", "pdf": "https://arxiv.org/pdf/2602.08907", "abs": "https://arxiv.org/abs/2602.08907", "authors": ["Marko Medvedev", "Idan Attias", "Elisabetta Cornacchia", "Theodor Misiakiewicz", "Gal Vardi", "Nathan Srebro"], "title": "Positive Distribution Shift as a Framework for Understanding Tractable Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study a setting where the goal is to learn a target function f(x) with respect to a target distribution D(x), but training is done on i.i.d. samples from a different training distribution D'(x), labeled by the true target f(x). Such a distribution shift (here in the form of covariate shift) is usually viewed negatively, as hurting or making learning harder, and the traditional distribution shift literature is mostly concerned with limiting or avoiding this negative effect. In contrast, we argue that with a well-chosen D'(x), the shift can be positive and make learning easier -- a perspective called Positive Distribution Shift (PDS). Such a perspective is central to contemporary machine learning, where much of the innovation is in finding good training distributions D'(x), rather than changing the training algorithm. We further argue that the benefit is often computational rather than statistical, and that PDS allows computationally hard problems to become tractable even using standard gradient-based training. We formalize different variants of PDS, show how certain hard classes are easily learnable under PDS, and make connections with membership query learning.", "AI": {"tldr": "The paper introduces Positive Distribution Shift (PDS), where a well-selected training distribution improves learning, even under covariate shift.", "motivation": "The motivation is to challenge the traditional view that distribution shift hurts learning, and to demonstrate that a well-chosen shift can make computationally challenging learning tasks easier.", "method": "The authors formalized different types of Positive Distribution Shift and analyzed how certain challenging learning tasks become tractable under these shifts, leveraging connections with membership query learning.", "result": "The study theoretically and conceptually showed that PDS can significantly ease computational difficulties in learning without changing the training algorithm.", "conclusion": "Positive Distribution Shift can be a valuable tool in machine learning for improving computational tractability and enabling learning in challenging settings by carefully designing the training distribution."}}
{"id": "2602.08121", "pdf": "https://arxiv.org/pdf/2602.08121", "abs": "https://arxiv.org/abs/2602.08121", "authors": ["Liying Wang", "Madison Lee", "Yunzhang Jiang", "Steven Chen", "Kewei Sha", "Yunhe Feng", "Frank Wong", "Lisa Hightow-Weidman", "Weichao Yuwen"], "title": "Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention", "categories": ["cs.AI"], "comment": null, "summary": "Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT skills coach delivering chain and solution analysis for individuals at risk for HIV and substance use. In partnership with a Los Angeles community health organization, we conducted usability testing with clinical staff (n=6) and individuals with lived experience (n=28). Using the Helpful, Honest, and Harmless (HHH) framework, we employed user-driven adversarial testing wherein participants identified target behaviors and generated contextually realistic risk probes. We evaluated safety performance across 37 risk probe interactions. Results: Glow appropriately handled 73% of risk probes, but performance varied by agent. The solution analysis agent demonstrated 90% appropriate handling versus 44% for the chain analysis agent. Safety failures clustered around encouraging substance use and normalizing harmful behaviors. The chain analysis agent fell into an \"empathy trap,\" providing validation that reinforced maladaptive beliefs. Additionally, 27 instances of DBT skill misinformation were identified. Conclusions: This study provides the first systematic safety evaluation of GenAI-delivered DBT coaching for HIV and substance use risk reduction. Findings reveal vulnerabilities requiring mitigation before clinical trials. The HHH framework and user-driven adversarial testing offer replicable methods for evaluating GenAI mental health interventions.", "AI": {"tldr": "This study evaluates a GenAI-powered dialectical behavior therapy (DBT) skills coach called Glow for HIV and substance use risk reduction, identifying safety vulnerabilities requiring improvement before clinical trials.", "motivation": "The study aims to address the overlapping epidemics of HIV and substance use, motivated by psychological factors like impulsivity and maladaptive coping, by exploring the feasibility of using generative AI for scalable DBT coaching.", "method": "The researchers developed Glow, a GenAI-powered DBT skills coach, and conducted usability testing with clinical staff and individuals with lived experience. They used the Helpful, Honest, and Harmless (HHH) framework for user-driven adversarial testing, simulating realistic risk scenarios.", "result": "The GenAI system appropriately managed 73% of risk probes, with varying performance between agents. The solution analysis agent was more effective (90%) than the chain analysis agent (44%), which suffered from safety failures involving maladaptive validation and misinformation.", "conclusion": "The study highlights the potential of GenAI-powered DBT interventions while identifying significant safety issues. It emphasizes the need for improvement before clinical trials and introduces a replicable framework for assessing AI-based mental health tools."}}
{"id": "2602.08518", "pdf": "https://arxiv.org/pdf/2602.08518", "abs": "https://arxiv.org/abs/2602.08518", "authors": ["Kento Kawaharazuka", "Kei Okada", "Masayuki Inaba"], "title": "Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi", "categories": ["cs.RO"], "comment": "Accepted to Advanced Intelligent Systems", "summary": "Various musculoskeletal humanoids have been developed so far, and numerous studies on control mechanisms have been conducted to leverage the advantages of their biomimetic bodies. However, there has not been sufficient and unified discussion on the diverse properties inherent in these musculoskeletal structures, nor on how to manage and utilize them. Therefore, this study categorizes and analyzes the characteristics of muscles, as well as their management and utilization methods, based on the various research conducted on the musculoskeletal humanoids we have developed, Kengoro and Musashi. We classify the features of the musculoskeletal structure into five properties: Redundancy, Independency, Anisotropy, Variable Moment Arm, and Nonlinear Elasticity. We then organize the diverse advantages and disadvantages of musculoskeletal humanoids that arise from the combination of these properties. In particular, we discuss body schema learning and reflex control, along with muscle grouping and body schema adaptation. Also, we describe the implementation of movements through an integrated system and discuss future challenges and prospects.", "AI": {"tldr": "The study explores the properties of musculoskeletal humanoids by categorizing their distinct characteristics, analyzing their advantages and disadvantages, and discussing control mechanisms.", "motivation": "To address the lack of unified discussion and analysis on the diverse characteristics and control strategies of musculoskeletal humanoids.", "method": "Categorizing five properties of musculoskeletal systems (Redundancy, Independency, Anisotropy, Variable Moment Arm, Nonlinear Elasticity), analyzing diverse studies on developed humanoids Kengoro and Musashi, and applying control principles like body schema learning and reflex control.", "result": "Organized the properties into distinct categories, highlighted the advantages and challenges of musculoskeletal structures, and demonstrated control mechanisms such as muscle grouping and body schema adaptation.", "conclusion": "The study highlights the need for better management of musculoskeletal properties, emphasizes integrated control systems, and outlines future challenges to advance humanoid development."}}
{"id": "2602.08305", "pdf": "https://arxiv.org/pdf/2602.08305", "abs": "https://arxiv.org/abs/2602.08305", "authors": ["Binglin Wu", "Yingyi Zhang", "Xiannneg Li"], "title": "JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation", "categories": ["cs.CL"], "comment": null, "summary": "Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \\textit{\\textbf{J}udicial \\textbf{U}nified \\textbf{S}ynthesis \\textbf{T}hrough \\textbf{I}ntermediate \\textbf{C}onclusion \\textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\\rightarrow$ Pre-Judge $\\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.", "AI": {"tldr": "This paper introduces JUSTICE, a framework for generating legal judgment documents by emulating a judge's cognitive workflow, significantly improving legal accuracy.", "motivation": "Existing methods for automated judgment generation oversimplify legal reasoning and miss crucial Pre-Judge processes, leading to inefficiencies in capturing judicial elements and legal soundness.", "method": "JUSTICE uses a three-stage cognitive workflow \u2013 Search, Pre-Judge, and Write \u2013 implemented through three components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS).", "result": "Experimentation on legal datasets demonstrates significant improvements in legal accuracy, including a 4.6% enhancement in predicting prison terms compared to baseline models.", "conclusion": "Explicitly modeling the Pre-Judge phase greatly enhances the legal coherence and accuracy of automated judgment document generation."}}
{"id": "2602.07532", "pdf": "https://arxiv.org/pdf/2602.07532", "abs": "https://arxiv.org/abs/2602.07532", "authors": ["Krishnakant Singh", "Simone Schaub-Meyer", "Stefan Roth"], "title": "Evaluating Object-Centric Models beyond Object Discovery", "categories": ["cs.CV", "cs.LG"], "comment": "Project Page: https://guided-sa.github.io/eval-ocl/", "summary": "Object-centric learning (OCL) aims to learn structured scene representations that support compositional generalization and robustness to out-of-distribution (OOD) data. However, OCL models are often not evaluated regarding these goals. Instead, most prior work focuses on evaluating OCL models solely through object discovery and simple reasoning tasks, such as probing the representation via image classification. We identify two limitations in existing benchmarks: (1) They provide limited insights on the representation usefulness of OCL models, and (2) localization and representation usefulness are assessed using disjoint metrics. To address (1), we use instruction-tuned VLMs as evaluators, enabling scalable benchmarking across diverse VQA datasets to measure how well VLMs leverage OCL representations for complex reasoning tasks. To address (2), we introduce a unified evaluation task and metric that jointly assess localization (where) and representation usefulness (what), thereby eliminating inconsistencies introduced by disjoint evaluation. Finally, we include a simple multi-feature reconstruction baseline as a reference point.", "AI": {"tldr": "The paper discusses limitations in OCL model evaluations and introduces a new evaluation method combining localization and representation usefulness while utilizing instruction-tuned VLMs.", "motivation": "Object-centric learning aims to create structured scene representations for improved compositional generalization and OOD data robustness, but current evaluations inadequately measure these qualities.", "method": "The authors use instruction-tuned vision-language models (VLMs) for scalable assessments across VQA datasets and propose a unified evaluation task and metric to evaluate OCL models' localization and representation usefulness simultaneously.", "result": "They introduce benchmarks using VLMs and a unified evaluation approach for better analysis of OCL models, alongside proposing a multi-feature reconstruction baseline for comparison.", "conclusion": "A more comprehensive evaluation framework is proposed to better capture the strengths and weaknesses of OCL models, emphasizing their performance on tasks requiring reasoning and robust representation."}}
{"id": "2602.08913", "pdf": "https://arxiv.org/pdf/2602.08913", "abs": "https://arxiv.org/abs/2602.08913", "authors": ["Kate\u0159ina Henclov\u00e1", "V\u00e1clav \u0160m\u00eddl"], "title": "GEMSS: A Variational Bayesian Method for Discovering Multiple Sparse Solutions in Classification and Regression Problems", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Selecting interpretable feature sets in underdetermined ($n \\ll p$) and highly correlated regimes constitutes a fundamental challenge in data science, particularly when analyzing physical measurements. In such settings, multiple distinct sparse subsets may explain the response equally well. Identifying these alternatives is crucial for generating domain-specific insights into the underlying mechanisms, yet conventional methods typically isolate a single solution, obscuring the full spectrum of plausible explanations.\n  We present GEMSS (Gaussian Ensemble for Multiple Sparse Solutions), a variational Bayesian framework specifically designed to simultaneously discover multiple, diverse sparse feature combinations. The method employs a structured spike-and-slab prior for sparsity, a mixture of Gaussians to approximate the intractable multimodal posterior, and a Jaccard-based penalty to further control solution diversity. Unlike sequential greedy approaches, GEMSS optimizes the entire ensemble of solutions within a single objective function via stochastic gradient descent.\n  The method is validated on a comprehensive benchmark comprising 128 synthetic experiments across classification and regression tasks. Results demonstrate that GEMSS scales effectively to high-dimensional settings ($p=5000$) with sample size as small as $n = 50$, generalizes seamlessly to continuous targets, handles missing data natively, and exhibits remarkable robustness to class imbalance and Gaussian noise.\n  GEMSS is available as a Python package 'gemss' at PyPI. The full GitHub repository at https://github.com/kat-er-ina/gemss/ also includes a free, easy-to-use application suitable for non-coders.", "AI": {"tldr": "GEMSS is a method for finding multiple sparse solutions in datasets with fewer samples ($n$) than features ($p$), addressing issues like high correlation and missing data, while ensuring result diversity.", "motivation": "In underdetermined and highly correlated datasets, conventional methods often provide a single solution, masking alternative insights. The paper introduces a new approach to uncover multiple interpretable feature subsets for such challenging scenarios.", "method": "Introduces GEMSS, a variational Bayesian framework using a structured spike-and-slab prior for sparsity, a Gaussian mixture model for multimodal posterior approximation, and a Jaccard-based penalty to control diversity. It optimizes ensembles within a single objective via stochastic gradient descent.", "result": "Validated GEMSS on 128 synthetic experiments for classification and regression. It scales well to high dimensions ($p=5000$) with limited samples ($n=50$), handles missing data, and is robust to noise and class imbalances.", "conclusion": "GEMSS successfully identifies diverse, sparse feature sets even in extremely challenging data environments. The method is scalable and user-friendly, enabling practical use through an accessible Python package and application."}}
{"id": "2602.08214", "pdf": "https://arxiv.org/pdf/2602.08214", "abs": "https://arxiv.org/abs/2602.08214", "authors": ["Ziwei Wang", "Yuanhe Zhang", "Jing Chen", "Zhenhong Zhou", "Ruichao Liang", "Ruiying Du", "Ju Jia", "Cong Wu", "Yang Liu"], "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.", "AI": {"tldr": "The paper reveals vulnerabilities in Large Reasoning Models (LRMs) regarding resource exhaustion during reasoning processes and introduces Recursive Entropy (RECUR) to measure such risks.", "motivation": "To address the overlooked risks and vulnerabilities inherent in LRMs' reasoning processes, specifically reflective reasoning, which can lead to resource overconsumption.", "method": "The authors propose Recursive Entropy, a metric to quantify resource consumption risks during reflective reasoning, and introduce RECUR, an attack method exploiting these vulnerabilities using counterfactual questions.", "result": "RECUR disrupted normal reasoning processes in LRMs, significantly increasing output length up to 11x and reducing throughput by 90%.", "conclusion": "The study highlights critical safety issues in LRMs' inference processes, paving the way for developing more robust reasoning approaches."}}
{"id": "2602.07475", "pdf": "https://arxiv.org/pdf/2602.07475", "abs": "https://arxiv.org/abs/2602.07475", "authors": ["Zhuomin Liang", "Liang Bai", "Xian Yang"], "title": "Bipartite Graph Attention-based Clustering for Large-scale scRNA-seq Data", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "scRNA-seq clustering is a critical task for analyzing single-cell RNA sequencing (scRNA-seq) data, as it groups cells with similar gene expression profiles. Transformers, as powerful foundational models, have been applied to scRNA-seq clustering. Their self-attention mechanism automatically assigns higher attention weights to cells within the same cluster, enhancing the distinction between clusters. Existing methods for scRNA-seq clustering, such as graph transformer-based models, treat each cell as a token in a sequence. Their computational and space complexities are $\\mathcal{O}(n^2)$ with respect to the number of cells, limiting their applicability to large-scale scRNA-seq datasets.To address this challenge, we propose a Bipartite Graph Transformer-based clustering model (BGFormer) for scRNA-seq data. We introduce a set of learnable anchor tokens as shared reference points to represent the entire dataset. A bipartite graph attention mechanism is introduced to learn the similarity between cells and anchor tokens, bringing cells of the same class closer together in the embedding space. BGFormer achieves linear computational complexity with respect to the number of cells, making it scalable to large datasets. Experimental results on multiple large-scale scRNA-seq datasets demonstrate the effectiveness and scalability of BGFormer.", "AI": {"tldr": "BGFormer leverages bipartite graph transformers with anchor tokens for scalable scRNA-seq clustering, addressing computational limitations of existing methods.", "motivation": "To solve the computational and scalability challenges of clustering large-scale single-cell RNA sequencing (scRNA-seq) data due to quadratic complexity in existing transformer models.", "method": "BGFormer uses a bipartite graph attention mechanism with learnable anchor tokens as shared reference points that compute similarities between cells in the dataset, reducing complexity to linear scaling with the number of cells.", "result": "BGFormer demonstrated enhanced scalability and effectiveness in clustering large-scale scRNA-seq datasets compared to existing methods.", "conclusion": "BGFormer is capable of addressing previous computational limits, offering a practical solution for analyzing large and complex scRNA-seq datasets."}}
{"id": "2602.08537", "pdf": "https://arxiv.org/pdf/2602.08537", "abs": "https://arxiv.org/abs/2602.08537", "authors": ["Haoming Ye", "Yunxiao Xiao", "Cewu Lu", "Panpan Cai"], "title": "UniPlan: Vision-Language Task Planning for Mobile Manipulation with Unified PDDL Formulation", "categories": ["cs.RO"], "comment": null, "summary": "Integration of VLM reasoning with symbolic planning has proven to be a promising approach to real-world robot task planning. Existing work like UniDomain effectively learns symbolic manipulation domains from real-world demonstrations, described in Planning Domain Definition Language (PDDL), and has successfully applied them to real-world tasks. These domains, however, are restricted to tabletop manipulation. We propose UniPlan, a vision-language task planning system for long-horizon mobile-manipulation in large-scale indoor environments, that unifies scene topology, visuals, and robot capabilities into a holistic PDDL representation. UniPlan programmatically extends learned tabletop domains from UniDomain to support navigation, door traversal, and bimanual coordination. It operates on a visual-topological map, comprising navigation landmarks anchored with scene images. Given a language instruction, UniPlan retrieves task-relevant nodes from the map and uses a VLM to ground the anchored image into task-relevant objects and their PDDL states; next, it reconnects these nodes to a compressed, densely-connected topological map, also represented in PDDL, with connectivity and costs derived from the original map; Finally, a mobile-manipulation plan is generated using off-the-shelf PDDL solvers. Evaluated on human-raised tasks in a large-scale map with real-world imagery, UniPlan significantly outperforms VLM and LLM+PDDL planning in success rate, plan quality, and computational efficiency.", "AI": {"tldr": "The paper presents UniPlan, a system that integrates visual-language modeling with symbolic planning to enable robots to perform complex indoor navigation and manipulation tasks effectively.", "motivation": "Existing approaches in robot task planning, like UniDomain, are limited to tabletop manipulation and lack functionality for long-horizon tasks in larger indoor spaces. This paper aims to address those gaps.", "method": "The proposed UniPlan system extends learned tabletop manipulation domains to include navigation, door traversal, and bimanual tasks. It uses a visual-topological map and combines task-relevant image-grounding with PDDL-based symbolic planning to create efficient mobile-manipulation plans.", "result": "UniPlan outperforms VLM and LLM+PDDL models in success rate, plan quality, and computational efficiency on large-scale, real-world tasks.", "conclusion": "UniPlan demonstrates that integrating visual-topological mapping with advanced symbolic planning can significantly enhance robotic task performance, setting a new benchmark for large-scale indoor robot planning systems."}}
{"id": "2602.08321", "pdf": "https://arxiv.org/pdf/2602.08321", "abs": "https://arxiv.org/abs/2602.08321", "authors": ["Zijie Chen", "Zhenghao Lin", "Xiao Liu", "Zhenzhong Lan", "Yeyun Gong", "Peng Cheng"], "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.", "AI": {"tldr": "This paper addresses challenges in training language models for open-ended science questions by proposing a systematic approach to data processing and a redesigned post-training pipeline.", "motivation": "To enhance large language models' ability to tackle open-ended science questions, which suffer from unreliable supervision and evaluation due to their complexity.", "method": "The authors develop the Dr. SCI dataset with extensive questions and rubrics and propose a post-training pipeline using Exploration-Expanding SFT, Dynamic Difficulty Curriculum, and SciRubric-Guided RL.", "result": "Their approach, applied to Qwen3-4B-Base, outperforms baselines, showing marked improvement in reasoning and open-ended question evaluation.", "conclusion": "Utilizing the Dr. SCI pipeline and dataset demonstrates significant advancements in scientific reasoning tasks, validating improvements in addressing open-ended problems effectively."}}
{"id": "2602.07534", "pdf": "https://arxiv.org/pdf/2602.07534", "abs": "https://arxiv.org/abs/2602.07534", "authors": ["Mowmita Parvin Hera", "Md. Shahriar Mahmud Kallol", "Shohanur Rahman Nirob", "Md. Badsha Bulbul", "Jubayer Ahmed", "M. Zhourul Islam", "Hazrat Ali", "Mohammmad Farhad Bulbul"], "title": "Fine-Grained Cat Breed Recognition with Global Context Vision Transformer", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "4 pages, accepted at International Conference on Computer and Information Technology (ICCIT) 2025", "summary": "Accurate identification of cat breeds from images is a challenging task due to subtle differences in fur patterns, facial structure, and color. In this paper, we present a deep learning-based approach for classifying cat breeds using a subset of the Oxford-IIIT Pet Dataset, which contains high-resolution images of various domestic breeds. We employed the Global Context Vision Transformer (GCViT) architecture-tiny for cat breed recognition. To improve model generalization, we used extensive data augmentation, including rotation, horizontal flipping, and brightness adjustment. Experimental results show that the GCViT-Tiny model achieved a test accuracy of 92.00% and validation accuracy of 94.54%. These findings highlight the effectiveness of transformer-based architectures for fine-grained image classification tasks. Potential applications include veterinary diagnostics, animal shelter management, and mobile-based breed recognition systems. We also provide a hugging face demo at https://huggingface.co/spaces/bfarhad/cat-breed-classifier.", "AI": {"tldr": "The paper proposes a deep learning approach using Global Context Vision Transformer (GCViT-Tiny) for accurate cat breed classification, achieving over 92% test accuracy.", "motivation": "Differentiating cat breeds from images is challenging due to subtle visual differences like fur patterns, facial structure, and color, necessitating advanced tools for high accuracy.", "method": "The authors utilized a subset of the Oxford-IIIT Pet Dataset with the GCViT-Tiny architecture, enhancing performance through extensive data augmentation techniques such as rotation, horizontal flipping, and brightness adjustments.", "result": "The GCViT-Tiny model achieved 92.00% test accuracy and 94.54% validation accuracy in the cat breed classification task.", "conclusion": "Transformer-based architectures, specifically GCViT-Tiny, are highly effective for fine-grained image classification tasks like cat breed recognition, with possible applications in veterinary use, animal shelters, and mobile tools."}}
{"id": "2602.08980", "pdf": "https://arxiv.org/pdf/2602.08980", "abs": "https://arxiv.org/abs/2602.08980", "authors": ["Moritz Laber", "Tina Eliassi-Rad", "Brennan Klein"], "title": "When do neural ordinary differential equations generalize on complex networks?", "categories": ["physics.soc-ph", "cs.LG", "cs.SI", "stat.ML"], "comment": null, "summary": "Neural ordinary differential equations (neural ODEs) can effectively learn dynamical systems from time series data, but their behavior on graph-structured data remains poorly understood, especially when applied to graphs with different size or structure than encountered during training. We study neural ODEs ($\\mathtt{nODE}$s) with vector fields following the Barab\u00e1si-Barzel form, trained on synthetic data from five common dynamical systems on graphs. Using the $\\mathbb{S}^1$-model to generate graphs with realistic and tunable structure, we find that degree heterogeneity and the type of dynamical system are the primary factors in determining $\\mathtt{nODE}$s' ability to generalize across graph sizes and properties. This extends to $\\mathtt{nODE}$s' ability to capture fixed points and maintain performance amid missing data. Average clustering plays a secondary role in determining $\\mathtt{nODE}$ performance. Our findings highlight $\\mathtt{nODE}$s as a powerful approach to understanding complex systems but underscore challenges emerging from degree heterogeneity and clustering in realistic graphs.", "AI": {"tldr": "The paper investigates how neural ordinary differential equations (neural ODEs) perform on graph-structured data with varying sizes and structures, focusing on degree heterogeneity and dynamical systems.", "motivation": "Neural ODEs have successfully been applied to time series data, but their application and generalization to graph-structured data remains unclear.", "method": "The study utilized neural ODEs trained on synthetic data from five dynamical systems and tested their generalization using the $\u001bBB-model\u001b$ and $\u001bS^1$-model to generate graphs with varied structure.", "result": "The performance of neural ODEs is primarily influenced by degree heterogeneity and the type of underlying dynamical system. Average clustering impacts performance to a lesser extent.", "conclusion": "Neural ODEs show promise for understanding complex systems but face challenges in handling degree heterogeneity and clustering properties in graphs."}}
{"id": "2602.08222", "pdf": "https://arxiv.org/pdf/2602.08222", "abs": "https://arxiv.org/abs/2602.08222", "authors": ["Zehao Chen", "Gongxun Li", "Tianxiang Ai", "Yifei Li", "Zixuan Huang", "Wang Zhou", "Fuzhen Zhuang", "Xianglong Liu", "Jianxin Li", "Deqing Wang", "Yikun Ban"], "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger", "categories": ["cs.AI"], "comment": null, "summary": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.", "AI": {"tldr": "WMSS (Weak Agents Can Make Strong Agents Stronger) addresses saturation bottlenecks in post-training of large language models by leveraging past weaker checkpoints for targeted optimization, achieving performance improvements in tasks.", "motivation": "To overcome the saturation bottleneck in post-training optimization of large language models, where performance gains diminish due to high confidence levels limiting learning.", "method": "The WMSS paradigm identifies recoverable learning gaps using entropy dynamics in weak checkpoints and guides models via compensatory learning during post-training.", "result": "Experiments show performance improvements in mathematical reasoning and code generation tasks without increasing inference cost when applying WMSS.", "conclusion": "WMSS demonstrates that weak prior states of language models can effectively guide optimization to achieve higher performance, overcoming conventional bottlenecks."}}
{"id": "2602.07478", "pdf": "https://arxiv.org/pdf/2602.07478", "abs": "https://arxiv.org/abs/2602.07478", "authors": ["Laxmi Pandey", "Ariel Meroz", "Ben Cheng", "Ankita Manekar", "Abhijit Mukherjee", "Meirav Cohen", "Adway Mitra"], "title": "AI-Driven Predictive Modelling for Groundwater Salinization in Israel", "categories": ["cs.LG"], "comment": "60 pages, 9 figures in main text and 6 figures in appendix, 2 tables, 3 Appendix", "summary": "Increasing salinity and contamination of groundwater is a serious issue in many parts of the world, causing degradation of water resources. The aim of this work is to form a comprehensive understanding of groundwater salinization underlying causal factors and identify important meteorological, geological and anthropogenic drivers of salinity. We have integrated different datasets of potential covariates, to create a robust framework for machine learning based predictive models including Random Forest (RF), XGBoost, Neural network, Long Short-Term Memory (LSTM), convolution neural network (CNN) and linear regression (LR), of groundwater salinity. Additionally, Recursive Feature Elimination (RFE) followed by Global sensitivity analysis (GSA) and Explainable AI (XAI) based SHapley Additive exPlanations (SHAP) were used to estimate the importance scores and find insights into the drivers of salinization. We also did causality analysis via Double machine learning using various predictive models. From these analyses, key meteorological (Precipitation, Temperature), geological (Distance from river, Distance to saline body, TWI, Shoreline distance), and anthropogenic (Area of agriculture field, Treated Wastewater) covariates are identified to be influential drivers of groundwater salinity across Israel. XAI analysis also identified Treated Wastewater (TWW) as an essential anthropogenic driver of salinity, its significance being context-dependent but critical in vulnerable hydro-climatic environment. Our approach provides deeper insight into global salinization mechanisms at country scale, reducing AI model uncertainty and highlighting the need for tailored strategies to address salinity.", "AI": {"tldr": "Groundwater salinization is analyzed using machine learning models and techniques like RFE, SHAP, and causality analysis. Key drivers such as meteorological, geological, and anthropogenic factors are identified, particularly in Israel.", "motivation": "To address the critical issue of groundwater salinization and understand its causal factors and drivers at a country scale.", "method": "Integration of datasets and machine learning models (RF, XGBoost, Neural network, LSTM, CNN, Linear Regression) coupled with RFE, GSA, SHAP, and causality analysis (Double machine learning) to identify salinity drivers.", "result": "Key impactful salinity drivers identified include precipitation, temperature, geological distances, and treated wastewater, with treated wastewater being critical in certain hydro-climatic environments.", "conclusion": "The study emphasizes the need for tailored strategies to manage groundwater salinity, highlights influential factors, and reduces prediction uncertainty leveraging AI/ML tools."}}
{"id": "2602.08557", "pdf": "https://arxiv.org/pdf/2602.08557", "abs": "https://arxiv.org/abs/2602.08557", "authors": ["Marc Toussaint", "Cornelius V. Braun", "Eckart Cobo-Briesewitz", "Sayantan Auddy", "Armand Jordana", "Justin Carpentier"], "title": "Constrained Sampling to Guide Universal Manipulation RL", "categories": ["cs.RO"], "comment": null, "summary": "We consider how model-based solvers can be leveraged to guide training of a universal policy to control from any feasible start state to any feasible goal in a contact-rich manipulation setting. While Reinforcement Learning (RL) has demonstrated its strength in such settings, it may struggle to sufficiently explore and discover complex manipulation strategies, especially in sparse-reward settings. Our approach is based on the idea of a lower-dimensional manifold of feasible, likely-visited states during such manipulation and to guide RL with a sampler from this manifold. We propose Sample-Guided RL, which uses model-based constraint solvers to efficiently sample feasible configurations (satisfying differentiable collision, contact, and force constraints) and leverage them to guide RL for universal (goal-conditioned) manipulation policies. We study using this data directly to bias state visitation, as well as using black-box optimization of open-loop trajectories between random configurations to impose a state bias and optionally add a behavior cloning loss. In a minimalistic double sphere manipulation setting, Sample-Guided RL discovers complex manipulation strategies and achieves high success rates in reaching any statically stable state. In a more challenging panda arm setting, our approach achieves a significant success rate over a near-zero baseline, and demonstrates a breadth of complex whole-body-contact manipulation strategies.", "AI": {"tldr": "The paper introduces Sample-Guided RL, a method leveraging model-based solvers to guide reinforcement learning for universal manipulation policies in contact-rich settings.", "motivation": "To address the challenges of exploration and sparse rewards in contact-rich manipulation using reinforcement learning.", "method": "Sample-Guided RL creates a lower-dimensional manifold of feasible states using model-based solvers to guide reinforcement learning by biasing state visitation and optionally employing behavior cloning.", "result": "The method achieves high success in complex manipulation strategies, outperforming baselines in both minimalistic and challenging manipulation settings.", "conclusion": "Sample-Guided RL is effective for guiding universal manipulation policies, particularly in sparse-reward and complex contact-rich environments."}}
{"id": "2602.08322", "pdf": "https://arxiv.org/pdf/2602.08322", "abs": "https://arxiv.org/abs/2602.08322", "authors": ["Wei Zhu"], "title": "An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling", "categories": ["cs.CL"], "comment": null, "summary": "In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.", "AI": {"tldr": "This paper proposes a generative framework for simultaneous multi-intent detection and slot filling in task-oriented dialogue systems, introducing attention-over-attention decoding and new datasets, achieving state-of-the-art results.", "motivation": "Current SLU systems struggle with utterances containing multiple intents, which is common in real-world applications but inadequately addressed by existing methods.", "method": "A generative framework with an attention-over-attention decoder is introduced for multi-task learning of intent detection and slot filling. Additionally, new multi-intent datasets are generated using the NSP head of BERT.", "result": "The attention-over-attention generative model outperforms previous methods on public datasets (MixATIS and MixSNIPS) and newly created datasets.", "conclusion": "The proposed framework and datasets effectively handle multi-intent SLU tasks, addressing critical real-world challenges while achieving performance improvements."}}
{"id": "2602.07535", "pdf": "https://arxiv.org/pdf/2602.07535", "abs": "https://arxiv.org/abs/2602.07535", "authors": ["Md Sazidur Rahman", "Kjersti Engan", "Kathinka D\u00e6hli Kurz", "Mahdieh Khanmohammadi"], "title": "Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Computed tomography perfusion (CTP) at admission is routinely used to estimate the ischemic core and penumbra, while follow-up diffusion-weighted MRI (DWI) provides the definitive infarct outcome. However, single time-point segmentations fail to capture the biological heterogeneity and temporal evolution of stroke. We propose a bi-temporal analysis framework that characterizes ischemic tissue using statistical descriptors, radiomic texture features, and deep feature embeddings from two architectures (mJ-Net and nnU-Net). Bi-temporal refers to admission (T1) and post-treatment follow-up (T2). All features are extracted at T1 from CTP, with follow-up DWI aligned to ensure spatial correspondence. Manually delineated masks at T1 and T2 are intersected to construct six regions of interest (ROIs) encoding both initial tissue state and final outcome. Features were aggregated per region and analyzed in feature space. Evaluation on 18 patients with successful reperfusion demonstrated meaningful clustering of region-level representations. Regions classified as penumbra or healthy at T1 that ultimately recovered exhibited feature similarity to preserved brain tissue, whereas infarct-bound regions formed distinct groupings. Both baseline GLCM and deep embeddings showed a similar trend: penumbra regions exhibit features that are significantly different depending on final state, whereas this difference is not significant for core regions. Deep feature spaces, particularly mJ-Net, showed strong separation between salvageable and non-salvageable tissue, with a penumbra separation index that differed significantly from zero (Wilcoxon signed-rank test). These findings suggest that encoder-derived feature manifolds reflect underlying tissue phenotypes and state transitions, providing insight into imaging-based quantification of stroke evolution.", "AI": {"tldr": "Proposes a bi-temporal analysis framework for stroke imaging using statistical descriptors, radiomic texture features, and deep learning embeddings to understand ischemic tissue evolution.", "motivation": "Current single time-point segmentations fail to capture stroke's biological heterogeneity and temporal evolution.", "method": "Introduced a framework using bi-temporal (admission and follow-up) imaging analysis, with feature extraction from CTP at admission and spatial alignment of follow-up DWI for six regions of interest.", "result": "Evaluations demonstrated meaningful clustering of ischemic tissue representations and indicated strong separation between salvageable and non-salvageable tissue using deep embeddings.", "conclusion": "Deep feature embeddings can reflect ischemic tissue states and transitions, offering valuable insights into imaging-based stroke evolution quantification."}}
{"id": "2602.08998", "pdf": "https://arxiv.org/pdf/2602.08998", "abs": "https://arxiv.org/abs/2602.08998", "authors": ["Luciano Melodia"], "title": "Universal Coefficients and Mayer-Vietoris Sequence for Groupoid Homology", "categories": ["math.AT", "cs.LG", "math.OA", "stat.ML"], "comment": "Master's thesis", "summary": "We study homology of ample groupoids via the compactly supported Moore complex of the nerve. Let $A$ be a topological abelian group. For $n\\ge 0$ set $C_n(\\mathcal G;A) := C_c(\\mathcal G_n,A)$ and define $\\partial_n^A=\\sum_{i=0}^n(-1)^i(d_i)_*$. This defines $H_n(\\mathcal G;A)$. The theory is functorial for continuous \u00e9tale homomorphisms. It is compatible with standard reductions, including restriction to saturated clopen subsets. In the ample setting it is invariant under Kakutani equivalence. We reprove Matui type long exact sequences and identify the comparison maps at chain level. For discrete $A$ we prove a natural universal coefficient short exact sequence $$0\\to H_n(\\mathcal G)\\otimes_{\\mathbb Z}A\\xrightarrow{\\ \u03b9_n^{\\mathcal G}\\ }H_n(\\mathcal G;A)\\xrightarrow{\\ \u03ba_n^{\\mathcal G}\\ }\\operatorname{Tor}_1^{\\mathbb Z}\\bigl(H_{n-1}(\\mathcal G),A\\bigr)\\to 0.$$ The key input is the chain level isomorphism $C_c(\\mathcal G_n,\\mathbb Z)\\otimes_{\\mathbb Z}A\\cong C_c(\\mathcal G_n,A)$, which reduces the groupoid statement to the classical algebraic UCT for the free complex $C_c(\\mathcal G_\\bullet,\\mathbb Z)$. We also isolate the obstruction for non-discrete coefficients. For a locally compact totally disconnected Hausdorff space $X$ with a basis of compact open sets, the image of $\u03a6_X:C_c(X,\\mathbb Z)\\otimes_{\\mathbb Z}A\\to C_c(X,A)$ is exactly the compactly supported functions with finite image. Thus $\u03a6_X$ is surjective if and only if every $f\\in C_c(X,A)$ has finite image, and for suitable $X$ one can produce compactly supported continuous maps $X\\to A$ with infinite image. Finally, for a clopen saturated cover $\\mathcal G_0=U_1\\cup U_2$ we construct a short exact sequence of Moore complexes and derive a Mayer-Vietoris long exact sequence for $H_\\bullet(\\mathcal G;A)$ for explicit computations.", "AI": {"tldr": "This paper studies the homology of ample groupoids using the compactly supported Moore complex and extends the existing theory with new results and techniques.", "motivation": "The paper aims to expand the foundational understanding and computational mechanisms for homology theory in the context of ample groupoids, particularly focusing on compatibility with reductions and Kakutani equivalence.", "method": "It uses the Moore complex of the nerve in homological computations, establishes new theorems such as universal coefficient short exact sequences, and introduces chain-level constructions and obstructions in specific topological settings.", "result": "The paper identifies new universal coefficient sequences, proves chain-level isomorphisms, finds compatibility with classical algebraic structures, and constructs explicit computations using long exact sequences.", "conclusion": "This work advances the study of homology in ample groupoids through chain-level identification, compatibility results, and computational methods, revealing deeper insights into the structure and classification."}}
{"id": "2602.08229", "pdf": "https://arxiv.org/pdf/2602.08229", "abs": "https://arxiv.org/abs/2602.08229", "authors": ["Yifan Yang", "Jinjia Li", "Kunxi Li", "Puhao Zheng", "Yuanyi Wang", "Zheyan Qu", "Yang Yu", "Jianmin Wu", "Ming Li", "Hongxia Yang"], "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a \"centralized black box\" into a \"decentralized endorsement\" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.", "AI": {"tldr": "This paper identifies inconsistencies in current centralized evaluations for large language models and introduces a decentralized evaluation framework based on blockchain protocols, achieving greater stability and reliability.", "motivation": "The motivation is driven by the inconsistencies and statistical unreliabilities in centralized evaluations for large language models due to factors like hardware-induced variance and overfitting.", "method": "The proposed method uses a decentralized evaluation framework leveraging blockchain protocols, fostering hardware and parameter diversity through global contributions and collective verification.", "result": "Experimental results showed that the decentralized framework reduces the evaluation standard deviation drastically from 1.67 to 0.28, ensuring higher statistical confidence in rankings.", "conclusion": "The decentralized evaluation framework significantly enhances stability and reliability in evaluating large language models and is ready for community release."}}
{"id": "2602.07479", "pdf": "https://arxiv.org/pdf/2602.07479", "abs": "https://arxiv.org/abs/2602.07479", "authors": ["Yihang Gao", "Vincent Y. F. Tan"], "title": "ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.OC"], "comment": "38 pages", "summary": "Low-rank adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning method in deep transfer learning, due to its reduced number of trainable parameters and lower memory requirements enabled by Burer-Monteiro factorization on adaptation matrices. However, classical LoRA training methods treat the low-rank factor matrices individually and optimize them using standard gradient-based algorithms. Such decoupled optimization schemes are theoretically and empirically suboptimal, as they fail to fully exploit the intrinsic structure of the LoRA parameterization. In this work, we propose a novel continuous-time optimization dynamic for LoRA factor matrices in the form of an ordinary differential equation (ODE) that emulates the gradient flow of full fine-tuning on the balanced manifold. We term this approach ODELoRA. To faithfully track the trajectories of ODELoRA, we adopt well-established and theoretically grounded time-discretization schemes, including Euler and Runge--Kutta methods. Our framework provides a unified ODE-based perspective for understanding and designing LoRA training algorithms. We establish linear convergence of the proposed method under strongly convex objectives for certain discretization schemes under mild conditions, and further extend our analysis to the matrix sensing setting. Moreover, we show that ODELoRA achieves stable feature learning, a property that is crucial for training deep neural networks at different scales of problem dimensionality. Empirical results on matrix sensing tasks confirm the derived linear convergence behavior, and experiments on training physics-informed neural networks further demonstrate the superiority of ODELoRA over existing baselines, especially in the training stability.", "AI": {"tldr": "This paper proposes ODELoRA, a novel training framework for LoRA by incorporating a continuous-time optimization method based on ODEs, showing improved stability and convergence.", "motivation": "Existing LoRA training methods are suboptimal, as their decoupled optimization schemes fail to exploit the intrinsic structure of LoRA parameterization efficiently.", "method": "The authors introduce ODELoRA, which models LoRA factor matrix training as an ODE mimicking gradient flow on the balanced manifold, adopting time-discretization schemes such as Euler and Runge-Kutta methods.", "result": "ODELoRA demonstrates linear convergence under certain conditions and achieves stable feature learning. Empirical results confirm its improved stability and superior performance in tasks like matrix sensing and physics-informed neural networks.", "conclusion": "ODELoRA presents a theoretically grounded and stable approach for LoRA training, outperforming traditional methods and offering better optimization insights."}}
{"id": "2602.08571", "pdf": "https://arxiv.org/pdf/2602.08571", "abs": "https://arxiv.org/abs/2602.08571", "authors": ["Simon Hoffmann", "Simon Sagmeister", "Tobias Betz", "Joscha Bongard", "Sascha B\u00fcttner", "Dominic Ebner", "Daniel Esser", "Georg Jank", "Sven Goblirsch", "Alexander Langmann", "Maximilian Leitenstern", "Levent \u00d6gretmen", "Phillip Pitschi", "Ann-Kathrin Schwehn", "Cornelius Schr\u00f6der", "Marcel Weinmann", "Frederik Werner", "Boris Lohmann", "Johannes Betz", "Markus Lienkamp"], "title": "Head-to-Head autonomous racing at the limits of handling in the A2RL challenge", "categories": ["cs.RO"], "comment": "Submitted to Science Robotics for possible publication", "summary": "Autonomous racing presents a complex challenge involving multi-agent interactions between vehicles operating at the limit of performance and dynamics. As such, it provides a valuable research and testing environment for advancing autonomous driving technology and improving road safety. This article presents the algorithms and deployment strategies developed by the TUM Autonomous Motorsport team for the inaugural Abu Dhabi Autonomous Racing League (A2RL). We showcase how our software emulates human driving behavior, pushing the limits of vehicle handling and multi-vehicle interactions to win the A2RL. Finally, we highlight the key enablers of our success and share our most significant learnings.", "AI": {"tldr": "This paper discusses the algorithms and strategies used by TUM Autonomous Motorsport to succeed in the A2RL by mimicking human driving and advancing multi-vehicle interaction capabilities.", "motivation": "The study aims to utilize autonomous racing as a platform to advance autonomous driving technology and enhance road safety through mastery of multi-agent interactions and handling vehicles at their performance limits.", "method": "The team developed algorithms and deployment strategies designed to enable autonomous software to mimic human driving behavior, optimize vehicle handling, and manage multi-vehicle interactions.", "result": "The TUM Autonomous Motorsport team developed software that successfully competed and won in the A2RL by achieving human-like driving efficiency and enhancing the capability for multi-agent interactions.", "conclusion": "The study demonstrates how autonomous racing can push the boundaries of technology, offering valuable insights and road safety advancements through high-performance multi-agent systems."}}
{"id": "2602.08332", "pdf": "https://arxiv.org/pdf/2602.08332", "abs": "https://arxiv.org/abs/2602.08332", "authors": ["Ido Amos", "Avi Caciularu", "Mor Geva", "Amir Globerson", "Jonathan Herzig", "Lior Shani", "Idan Szpektor"], "title": "Latent Reasoning with Supervised Thinking States", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.", "AI": {"tldr": "Thinking States introduces reasoning performed during input processing, leveraging intermediate thinking tokens for efficient and effective reasoning.", "motivation": "Chain-of-thought reasoning in LLMs effectively handles complex tasks but incurs high inference costs due to lengthy rationales.", "method": "Thinking States intersperses input processing with the generation of thinking tokens, integrates them as embeddings, and learns reasoning by leveraging teacher-forcing and natural language supervision.", "result": "Thinking States demonstrates better reasoning compared to other methods, achieves comparable or improved performance to CoT in math and QA tasks, and excels in state-tracking tasks with scalability to longer sequences.", "conclusion": "The method enhances reasoning efficiency and accuracy during input processing, providing a scalable and latency-friendly alternative to CoT reasoning."}}
{"id": "2602.07540", "pdf": "https://arxiv.org/pdf/2602.07540", "abs": "https://arxiv.org/abs/2602.07540", "authors": ["Huimin Yan", "Liang Bai", "Xian Yang", "Long Chen"], "title": "LLM-Guided Diagnostic Evidence Alignment for Medical Vision-Language Pretraining under Limited Pairing", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Most existing CLIP-style medical vision--language pretraining methods rely on global or local alignment with substantial paired data. However, global alignment is easily dominated by non-diagnostic information, while local alignment fails to integrate key diagnostic evidence. As a result, learning reliable diagnostic representations becomes difficult, which limits their applicability in medical scenarios with limited paired data. To address this issue, we propose an LLM-Guided Diagnostic Evidence Alignment method (LGDEA), which shifts the pretraining objective toward evidence-level alignment that is more consistent with the medical diagnostic process. Specifically, we leverage LLMs to extract key diagnostic evidence from radiology reports and construct a shared diagnostic evidence space, enabling evidence-aware cross-modal alignment and allowing LGDEA to effectively exploit abundant unpaired medical images and reports, thereby substantially alleviating the reliance on paired data. Extensive experimental results demonstrate that our method achieves consistent and significant improvements on phrase grounding, image--text retrieval, and zero-shot classification, and even rivals pretraining methods that rely on substantial paired data.", "AI": {"tldr": "The paper introduces LGDEA, a method using LLMs for enhancing diagnostic evidence alignment in medical vision-language pretraining, reducing dependence on paired data and improving performance in multiple tasks.", "motivation": "Existing methods often rely on substantial paired data for aligning global or local features but fail to effectively integrate diagnostic evidence due to limitations in the alignment methods.", "method": "The proposed LGDEA method extracts diagnostic evidence from radiology reports using LLMs and creates a shared evidence space for evidence-level alignment, enabling better utilization of unpaired medical images and text.", "result": "Extensive experiments show significant and consistent improvements in tasks like phrase grounding, image-text retrieval, and zero-shot classification, with effectiveness comparable to methods relying heavily on paired data.", "conclusion": "LGDEA alleviates reliance on paired data while achieving reliable diagnostic representation learning, demonstrating its potential applicability in medical tasks."}}
{"id": "2602.08240", "pdf": "https://arxiv.org/pdf/2602.08240", "abs": "https://arxiv.org/abs/2602.08240", "authors": ["Xun Su", "Huamin Wang", "Qi Zhang"], "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition", "categories": ["cs.AI", "cs.SD"], "comment": null, "summary": "Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.", "AI": {"tldr": "The paper proposes Prompt-Tuned Spiking Neural Networks (PTS-SNN) to efficiently perform Speech Emotion Recognition (SER) on resource-constrained devices by addressing distribution mismatch issues between Spiking Neural Networks (SNNs) and self-supervised learning (SSL) embeddings.", "motivation": "The study is motivated by the need to overcome the high computational cost of traditional SER models for edge devices and the potential of energy-efficient SNNs hindered by distribution mismatches with SSL representations.", "method": "The proposed PTS-SNN introduces a Temporal Shift Spiking Encoder to capture temporal features and a Context-Aware Membrane Potential Calibration strategy that uses soft prompts and spiking attention modules to regulate neuron bias voltages, aligning SSL embeddings with spiking neurons.", "result": "The model achieves 73.34% accuracy on the IEMOCAP dataset, comparable to state-of-the-art Artificial Neural Networks (ANNs), while requiring only 1.19M parameters and consuming 0.35 mJ of energy per inference.", "conclusion": "PTS-SNN demonstrates the viability of integrating energy-efficient SNNs with SSL representations for SER tasks, achieving competitive performance with reduced parameters and low energy consumption."}}
{"id": "2602.08594", "pdf": "https://arxiv.org/pdf/2602.08594", "abs": "https://arxiv.org/abs/2602.08594", "authors": ["Zhenguo Sun", "Bo-Sheng Huang", "Yibo Peng", "Xukun Li", "Jingyu Ma", "Yu Sun", "Zhe Li", "Haojun Jiang", "Biao Gao", "Zhenshan Bing", "Xinlong Wang", "Alois Knoll"], "title": "MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation", "categories": ["cs.RO"], "comment": null, "summary": "Generalist humanoid motion trackers have recently achieved strong simulation metrics by scaling data and training, yet often remain brittle on hardware during sustained teleoperation due to interface- and dynamics-induced errors. We present MOSAIC, an open-source, full-stack system for humanoid motion tracking and whole-body teleoperation across multiple interfaces. MOSAIC first learns a teleoperation-oriented general motion tracker via RL on a multi-source motion bank with adaptive resampling and rewards that emphasize world-frame motion consistency, which is critical for mobile teleoperation. To bridge the sim-to-real interface gap without sacrificing generality, MOSAIC then performs rapid residual adaptation: an interface-specific policy is trained using minimal interface-specific data, and then distilled into the general tracker through an additive residual module, outperforming naive fine-tuning or continual learning. We validate MOSAIC with systematic ablations, out-of-distribution benchmarking, and real-robot experiments demonstrating robust offline motion replay and online long-horizon teleoperation under realistic latency and noise.", "AI": {"tldr": "MOSAIC is an open-source humanoid motion tracking and teleoperation system using RL-trained general trackers and rapid residual adaptation, tested with real robots.", "motivation": "To address the brittleness of generalist humanoid motion trackers during sustained teleoperation caused by interface- and dynamics-related issues, aiming for a robust solution.", "method": "MOSAIC employs reinforcement learning for teleoperation-oriented motion tracking using adaptive resampling and motion-consistency rewards, complemented by rapid residual adaptation to bridge the sim-to-real gap.", "result": "Systematic tests and experiments show robust motion replay and long-horizon teleoperation under realistic latency and noise conditions, overcoming prior challenges.", "conclusion": "MOSAIC demonstrates the practicality and robustness of integrating general motion tracking with adaptive learning for real-world humanoid teleoperation."}}
{"id": "2602.08336", "pdf": "https://arxiv.org/pdf/2602.08336", "abs": "https://arxiv.org/abs/2602.08336", "authors": ["Cheng Yang", "Chufan Shi", "Bo Shui", "Yaokang Wu", "Muzi Tao", "Huijuan Wang", "Ivan Yee Lee", "Yong Liu", "Xuezhe Ma", "Taylor Berg-Kirkpatrick"], "title": "UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models", "categories": ["cs.CL", "cs.CV"], "comment": "Project page: https://ureason.github.io", "summary": "To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.", "AI": {"tldr": "The paper introduces UReason, a benchmark to evaluate reasoning-driven image generation and identifies a paradox where reasoning traces help in theory but hinder in practice due to contextual interference.", "motivation": "To understand and improve the role of reasoning in unified multimodal models for addressing complex and implicit visual requirements in image generation.", "method": "Developed UReason, a benchmark with 2,000 instances across five reasoning tasks (Code, Arithmetic, Spatial, Attribute, Text), and proposed an evaluation framework to compare reasoning effects using direct, reasoning-guided, and de-contextualized generation.", "result": "Discovered that reasoning traces enhance performance conceptually but retaining intermediate thoughts as context negatively affects visual synthesis, with de-contextualized prompts yielding the best results.", "conclusion": "Contextual interference, not reasoning capacity, is the key bottleneck in reasoning-driven image generation. UReason facilitates future research to address these challenges."}}
{"id": "2602.07544", "pdf": "https://arxiv.org/pdf/2602.07544", "abs": "https://arxiv.org/abs/2602.07544", "authors": ["Sebastian Bock", "Leonie Sch\u00fc\u00dfler", "Krishnakant Singh", "Simone Schaub-Meyer", "Stefan Roth"], "title": "MUFASA: A Multi-Layer Framework for Slot Attention", "categories": ["cs.CV"], "comment": "Authors Sebastian Bock and Leonie Sch\u00fc\u00dfler contributed equally. Project page: https://leonieschuessler.github.io/mufasa/", "summary": "Unsupervised object-centric learning (OCL) decomposes visual scenes into distinct entities. Slot attention is a popular approach that represents individual objects as latent vectors, called slots. Current methods obtain these slot representations solely from the last layer of a pre-trained vision transformer (ViT), ignoring valuable, semantically rich information encoded across the other layers. To better utilize this latent semantic information, we introduce MUFASA, a lightweight plug-and-play framework for slot attention-based approaches to unsupervised object segmentation. Our model computes slot attention across multiple feature layers of the ViT encoder, fully leveraging their semantic richness. We propose a fusion strategy to aggregate slots obtained on multiple layers into a unified object-centric representation. Integrating MUFASA into existing OCL methods improves their segmentation results across multiple datasets, setting a new state of the art while simultaneously improving training convergence with only minor inference overhead.", "AI": {"tldr": "The paper introduces MUFASA, a framework enhancing object-centric learning methods by utilizing multiple layers of a Vision Transformer (ViT) for improved segmentation.", "motivation": "Current object-centric learning methods overlook rich semantic information from intermediate layers of ViT in visual scene segmentation.", "method": "MUFASA aggregates slot attention from multiple layers of a ViT encoder with a proposed fusion strategy, enhancing object-centric representations.", "result": "Integrating MUFASA improves segmentation performance and accelerates training convergence with a small inference overhead across datasets.", "conclusion": "MUFASA advances unsupervised object-centric learning, achieving state-of-the-art results in object segmentation and better efficiency."}}
{"id": "2602.08241", "pdf": "https://arxiv.org/pdf/2602.08241", "abs": "https://arxiv.org/abs/2602.08241", "authors": ["Siqu Ou", "Tianrui Wan", "Zhiyuan Zhao", "Junyu Gao", "Xuelong Li"], "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.", "AI": {"tldr": "The paper introduces SAYO, a model improving multimodal reasoning by better aligning visual attention using reinforcement learning, leading to enhanced accuracy in reasoning and perception tasks.", "motivation": "Current multimodal language models struggle with weak visual focus, leading to early-stage visual misalignment and error propagation during reasoning. This is attributed to inadequate reinforcement during training for visual attention policies.", "method": "The authors propose SAYO, leveraging reinforcement learning with a region-level visual attention-based reward. This technique strengthens optimization by aligning visual reasoning steps with learning signals, ensuring stable attention behaviors.", "result": "Experiments demonstrate that SAYO significantly enhances performance across various multimodal benchmarks, showing improved reasoning and perception capabilities.", "conclusion": "SAYO addresses the limitations in visual focus of multimodal models by employing a targeted RL approach, promoting more effective visual reasoning and improving model performance."}}
{"id": "2602.07494", "pdf": "https://arxiv.org/pdf/2602.07494", "abs": "https://arxiv.org/abs/2602.07494", "authors": ["Shenxi Wu", "Haosong Zhang", "Xingjian Ma", "Shirui Bian", "Yichi Zhang", "Xi Chen", "Wei Lin"], "title": "Hyperparameter Transfer Laws for Non-Recurrent Multi-Path Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Deeper modern architectures are costly to train, making hyperparameter transfer preferable to expensive repeated tuning. Maximal Update Parametrization ($\u03bc$P) helps explain why many hyperparameters transfer across width. Yet depth scaling is less understood for modern architectures, whose computation graphs contain multiple parallel paths and residual aggregation. To unify various non-recurrent multi-path neural networks such as CNNs, ResNets, and Transformers, we introduce a graph-based notion of effective depth. Under stabilizing initializations and a maximal-update criterion, we show that the optimal learning rate decays with effective depth following a universal -3/2 power law. Here, the maximal-update criterion maximizes the typical one-step representation change at initialization without causing instability, and effective depth is the minimal path length from input to output, counting layers and residual additions. Experiments across diverse architectures confirm the predicted slope and enable reliable zero-shot transfer of learning rates across depths and widths, turning depth scaling into a predictable hyperparameter-transfer problem.", "AI": {"tldr": "The paper introduces a universal -3/2 power law for learning rate scaling with depth in multi-path neural networks and proposes an effective depth concept for better hyperparameter transfer.", "motivation": "To address the challenge of unreliable hyperparameter transfer in modern deep architectures with diverse depths and widths.", "method": "The paper introduces the notion of 'effective depth' for multi-path networks and studies hyperparameter transfer using a stabilizing initialization and maximal-update criterion.", "result": "The study derives a -3/2 power law for optimal learning rate scaling and confirms its validity through experiments across different architectures.", "conclusion": "The findings enable predictable hyperparameter transfer across network depths, making deep neural network training more efficient."}}
{"id": "2602.08599", "pdf": "https://arxiv.org/pdf/2602.08599", "abs": "https://arxiv.org/abs/2602.08599", "authors": ["Kenghou Hoi", "Yuze Wu", "Annan Ding", "Junjie Wang", "Anke Zhao", "Chengqian Zhang", "Fei Gao"], "title": "A Precise Real-Time Force-Aware Grasping System for Robust Aerial Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Aerial manipulation requires force-aware capabilities to enable safe and effective grasping and physical interaction. Previous works often rely on heavy, expensive force sensors unsuitable for typical quadrotor platforms, or perform grasping without force feedback, risking damage to fragile objects. To address these limitations, we propose a novel force-aware grasping framework incorporating six low-cost, sensitive skin-like tactile sensors. We introduce a magnetic-based tactile sensing module that provides high-precision three-dimensional force measurements. We eliminate geomagnetic interference through a reference Hall sensor and simplify the calibration process compared to previous work. The proposed framework enables precise force-aware grasping control, allowing safe manipulation of fragile objects and real-time weight measurement of grasped items. The system is validated through comprehensive real-world experiments, including balloon grasping, dynamic load variation tests, and ablation studies, demonstrating its effectiveness in various aerial manipulation scenarios. Our approach achieves fully onboard operation without external motion capture systems, significantly enhancing the practicality of force-sensitive aerial manipulation. The supplementary video is available at: https://www.youtube.com/watch?v=mbcZkrJEf1I.", "AI": {"tldr": "The paper presents a new force-aware grasping framework using low-cost tactile sensors for aerial manipulation, enabling safe and precise handling of fragile objects without expensive equipment.", "motivation": "To address the challenges of aerial manipulation, particularly safe, precise grasping and physical interaction without reliance on expensive or heavy force sensors.", "method": "The authors developed a framework integrating six magnetic-based tactile sensors for precise three-dimensional force measurement and employed a simplified calibration process by using a reference Hall sensor.", "result": "The system supports safe manipulation of fragile objects, real-time weight measurement, and operates entirely onboard without external motion capture, validated through real-world tests such as grasping balloons and load variation studies.", "conclusion": "This solution significantly enhances the practicality of aerial manipulation systems by improving safety, precision, and onboard autonomy using cost-effective tactile sensors."}}
{"id": "2602.08367", "pdf": "https://arxiv.org/pdf/2602.08367", "abs": "https://arxiv.org/abs/2602.08367", "authors": ["Zexuan Wang", "Chenghao Yang", "Yingqi Que", "Zhenzhu Yang", "Huaqing Yuan", "Yiwen Wang", "Zhengxuan Jiang", "Shengjie Fang", "Zhenhe Wu", "Zhaohui Wang", "Zhixin Yao", "Jiashuo Liu", "Jincheng Ren", "Yuzhen Li", "Yang Yang", "Jiaheng Liu", "Jian Yang", "Zaiyuan Wang", "Ge Zhang", "Zhoufutu Wen", "Wenhao Huang"], "title": "WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints", "categories": ["cs.CL"], "comment": null, "summary": "Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \\textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \\textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\\% feasibility in text-only settings, which plummets to 19.33\\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics.", "AI": {"tldr": "This paper introduces a benchmark called WorldTravel, with real-world travel scenarios to evaluate autonomous planning under complex constraints extracted from visual environments.", "motivation": "Highlight shortcomings in existing benchmarks for autonomous planning which rely on idealized data and loosely coupled constraints, while demonstrating the need for robust reasoning and perception under tightly coupled constraints.", "method": "Developed WorldTravel benchmark across realistic scenarios with multi-modal inputs; created the WorldTravel-Webscape featuring web-rendered visual constraint extraction; conducted evaluations of performance collapse on 10 models.", "result": "State-of-the-art GPT-5.2 exhibited only 32.67% feasibility in text-based and 19.33% in multi-modal environments; identified Perception-Action Gap and Planning Horizon threshold (~10 constraints).", "conclusion": "Concludes that current models fail in visual perception and long-horizon reasoning, indicating the need for integrated solutions to handle complex real-world logistics effectively."}}
{"id": "2602.07550", "pdf": "https://arxiv.org/pdf/2602.07550", "abs": "https://arxiv.org/abs/2602.07550", "authors": ["Hussni Mohd Zakir", "Eric Tatt Wei Ho"], "title": "Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 3 figures, 7 tables", "summary": "Recent self-supervised Vision Transformers (ViTs), such as DINOv3, provide rich feature representations for dense vision tasks. This study investigates the intrinsic few-shot semantic segmentation (FSS) capabilities of frozen DINOv3 features through a training-free baseline, FSSDINO, utilizing class-specific prototypes and Gram-matrix refinement. Our results across binary, multi-class, and cross-domain (CDFSS) benchmarks demonstrate that this minimal approach, applied to the final backbone layer, is highly competitive with specialized methods involving complex decoders or test-time adaptation. Crucially, we conduct an Oracle-guided layer analysis, identifying a significant performance gap between the standard last-layer features and globally optimal intermediate representations. We reveal a \"Safest vs. Optimal\" dilemma: while the Oracle proves higher performance is attainable, matching the results of compute-intensive adaptation methods, current unsupervised and support-guided selection metrics consistently yield lower performance than the last-layer baseline. This characterizes a \"Semantic Selection Gap\" in Foundation Models, a disconnect where traditional heuristics fail to reliably identify high-fidelity features. Our work establishes the \"Last-Layer\" as a deceptively strong baseline and provides a rigorous diagnostic of the latent semantic potentials in DINOv3.The code is publicly available at https://github.com/hussni0997/fssdino.", "AI": {"tldr": "This paper explores the few-shot semantic segmentation (FSS) abilities of frozen DINOv3 Vision Transformers through a training-free approach called FSSDINO.", "motivation": "To analyze and leverage the intrinsic capabilities of self-supervised ViTs (DINOv3) for FSS without requiring complex training processes.", "method": "The FSSDINO baseline utilizes class-specific prototypes and Gram-matrix refinement applied to the final backbone layer of DINOv3, supported by Oracle-guided layer analysis.", "result": "FSSDINO performs competitively across binary, multi-class, and cross-domain benchmarks against complex methods, while highlighting a significant gap in feature selection metrics.", "conclusion": "The study establishes the last-layer features of DINOv3 as a strong baseline, identifies a Semantic Selection Gap in feature extraction, and advocates for exploring latent semantic potentials in Foundation Models."}}
{"id": "2602.08253", "pdf": "https://arxiv.org/pdf/2602.08253", "abs": "https://arxiv.org/abs/2602.08253", "authors": ["Baoyun Zhao", "He Wang", "Liang Zeng"], "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design", "categories": ["cs.AI"], "comment": null, "summary": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.", "AI": {"tldr": "The paper introduces G-LNS, a generative evolutionary framework for co-evolving pairs of Large Neighborhood Search (LNS) operators using Large Language Models (LLMs). It improves performance in solving complex combinatorial optimization problems like TSP and CVRP.", "motivation": "Existing Automated Heuristic Design (AHD) methods are limited to fixed heuristic forms, constraining structural exploration and making it challenging to escape deep local optima in complex combinatorial optimization problems.", "method": "The authors propose G-LNS, which uses LLMs to co-evolve paired destroy and repair operators for LNS. A cooperative evaluation mechanism is applied to discover complementary operator logic.", "result": "G-LNS outperforms LLM-based AHD methods and classical solvers across various COP benchmarks, achieving near-optimal solutions with less computation and demonstrating generalization to unseen problem instances.", "conclusion": "G-LNS effectively extends the capability of LLM-based AHD to structural exploration, enabling robust and efficient solutions for complex combinatorial optimization problems."}}
{"id": "2602.07496", "pdf": "https://arxiv.org/pdf/2602.07496", "abs": "https://arxiv.org/abs/2602.07496", "authors": ["Antonio Mone", "Frans A. Oliehoek", "Luciano Cavalcante Siebert"], "title": "CoMI-IRL: Contrastive Multi-Intention Inverse Reinforcement Learning", "categories": ["cs.LG"], "comment": "14 pages, 6 figures", "summary": "Inverse Reinforcement Learning (IRL) seeks to infer reward functions from expert demonstrations. When demonstrations originate from multiple experts with different intentions, the problem is known as Multi-Intention IRL (MI-IRL). Recent deep generative MI-IRL approaches couple behavior clustering and reward learning, but typically require prior knowledge of the number of true behavioral modes $K^*$. This reliance on expert knowledge limits their adaptability to new behaviors, and only enables analysis related to the learned rewards, and not across the behavior modes used to train them. We propose Contrastive Multi-Intention IRL (CoMI-IRL), a transformer-based unsupervised framework that decouples behavior representation and clustering from downstream reward learning. Our experiments show that CoMI-IRL outperforms existing approaches without a priori knowledge of $K^*$ or labels, while allowing for visual interpretation of behavior relationships and adaptation to unseen behavior without full retraining.", "AI": {"tldr": "This paper proposes a novel unsupervised framework, CoMI-IRL, for Multi-Intention Inverse Reinforcement Learning (MI-IRL) that eliminates the need for knowing the number of expert behavioral modes beforehand.", "motivation": "Existing MI-IRL methods require prior knowledge of the number of behavioral modes ($K^*$), limiting their adaptability to new behaviors and their ability to provide meaningful cross-behavior analyses.", "method": "The paper introduces CoMI-IRL, a transformer-based unsupervised framework that separates behavior clustering from reward learning.", "result": "CoMI-IRL demonstrates superior performance compared to existing methods without prior knowledge of $K^*$ or labels. It also enables visual interpretation of behavior relationships and can adapt to unseen behaviors without retraining.", "conclusion": "CoMI-IRL improves flexibility and interpretability in MI-IRL, addressing the limitations of prior methods by removing dependency on specialist knowledge and adapting effectively to new behaviors."}}
{"id": "2602.08602", "pdf": "https://arxiv.org/pdf/2602.08602", "abs": "https://arxiv.org/abs/2602.08602", "authors": ["Renming Huang", "Chendong Zeng", "Wenjing Tang", "Jingtian Cai", "Cewu Lu", "Panpan Cai"], "title": "Mimic Intent, Not Just Trajectories", "categories": ["cs.RO"], "comment": "Under review", "summary": "While imitation learning (IL) has achieved impressive success in dexterous manipulation through generative modeling and pretraining, state-of-the-art approaches like Vision-Language-Action (VLA) models still struggle with adaptation to environmental changes and skill transfer. We argue this stems from mimicking raw trajectories without understanding the underlying intent. To address this, we propose explicitly disentangling behavior intent from execution details in end-2-end IL: \\textit{``Mimic Intent, Not just Trajectories'' (MINT)}. We achieve this via \\textit{multi-scale frequency-space tokenization}, which enforces a spectral decomposition of action chunk representation. We learn action tokens with a multi-scale coarse-to-fine structure, and force the coarsest token to capture low-frequency global structure and finer tokens to encode high-frequency details. This yields an abstract \\textit{Intent token} that facilitates planning and transfer, and multi-scale \\textit{Execution tokens} that enable precise adaptation to environmental dynamics. Building on this hierarchy, our policy generates trajectories through \\textit{next-scale autoregression}, performing progressive \\textit{intent-to-execution reasoning}, thus boosting learning efficiency and generalization. Crucially, this disentanglement enables \\textit{one-shot transfer} of skills, by simply injecting the Intent token from a demonstration into the autoregressive generation process. Experiments on several manipulation benchmarks and on a real robot demonstrate state-of-the-art success rates, superior inference efficiency, robust generalization against disturbances, and effective one-shot transfer.", "AI": {"tldr": "The paper introduces the \"Mimic Intent, Not just Trajectories\" (MINT) approach to dexterous manipulation, focusing on disentangling behavior intent from execution details using multi-scale frequency tokenization.", "motivation": "Current methods for imitation learning in dexterous manipulation struggle with adapting to environmental changes and transferring skills due to focusing only on mimicking trajectories instead of understanding intent.", "method": "The approach uses multi-scale frequency-space tokenization to learn action representation as coarse and fine-grained tokens, enabling intent-to-execution reasoning through next-scale autoregression.", "result": "Experiments show improved success rates, inference efficiency, robustness to disturbances, and effective one-shot skill transfer on manipulation benchmarks and real robotic tasks.", "conclusion": "By disentangling intent from execution details, the proposed method enhances learning generalization, efficiency, and skill transferability in imitation learning scenarios."}}
{"id": "2602.08371", "pdf": "https://arxiv.org/pdf/2602.08371", "abs": "https://arxiv.org/abs/2602.08371", "authors": ["Hung Quang Tran", "Nam Tien Pham", "Son T. Luu", "Kiet Van Nguyen"], "title": "ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts", "categories": ["cs.CL"], "comment": "Accepted as main paper at EACL 2026", "summary": "Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.", "AI": {"tldr": "The paper introduces ViGoEmotions, a Vietnamese emotion corpus with 20,664 social media comments classified into 27 fine-grained emotions, and evaluates different preprocessing strategies to classify emotions effectively.", "motivation": "The study addresses the lack of a comprehensive Vietnamese emotion corpus and examines how preprocessing strategies can influence the emotion classification performance of various models.", "method": "The authors created ViGoEmotions, a dataset of Vietnamese social media comments labeled with fine-grained emotions. They evaluated it by testing eight pre-trained Transformer-based models using three different preprocessing strategies: preserving original emojis, converting emojis to text, and lexical normalization using ViSoLex.", "result": "The study found that preserving emojis performed best for models like ViSoBERT and CafeBERT, while converting emojis to text improved the performance of several BERT-based models. ViSoBERT achieved the highest scores: Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Removing emojis consistently resulted in lower performance.", "conclusion": "The ViGoEmotions dataset effectively supports emotion classification for Vietnamese comments. Preprocessing strategies, particularly handling emojis, play a critical role in optimizing model performance."}}
{"id": "2602.07554", "pdf": "https://arxiv.org/pdf/2602.07554", "abs": "https://arxiv.org/abs/2602.07554", "authors": ["Guandong Li", "Yijun Ding"], "title": "FlexID: Training-Free Flexible Identity Injection via Intent-Aware Modulation for Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Personalized text-to-image generation aims to seamlessly integrate specific identities into textual descriptions. However, existing training-free methods often rely on rigid visual feature injection, creating a conflict between identity fidelity and textual adaptability. To address this, we propose FlexID, a novel training-free framework utilizing intent-aware modulation. FlexID orthogonally decouples identity into two dimensions: a Semantic Identity Projector (SIP) that injects high-level priors into the language space, and a Visual Feature Anchor (VFA) that ensures structural fidelity within the latent space. Crucially, we introduce a Context-Aware Adaptive Gating (CAG) mechanism that dynamically modulates the weights of these streams based on editing intent and diffusion timesteps. By automatically relaxing rigid visual constraints when strong editing intent is detected, CAG achieves synergy between identity preservation and semantic variation. Extensive experiments on IBench demonstrate that FlexID achieves a state-of-the-art balance between identity consistency and text adherence, offering an efficient solution for complex narrative generation.", "AI": {"tldr": "FlexID introduces a training-free framework for better integrating identities into text-to-image generation, balancing identity fidelity and textual adaptation.", "motivation": "To improve the harmonious integration of specific identities into textual descriptions without compromising between identity fidelity and textual adaptability.", "method": "The paper proposes FlexID, a decoupled framework with Semantic Identity Projector (SIP), Visual Feature Anchor (VFA), and Context-Aware Adaptive Gating (CAG) for dynamic modulation.", "result": "FlexID demonstrates state-of-the-art identity consistency and text adherence in extensive experiments on the IBench dataset.", "conclusion": "FlexID offers an efficient solution for personalized text-to-image generation, achieving a strong balance between identity preservation and semantic variation."}}
{"id": "2602.08254", "pdf": "https://arxiv.org/pdf/2602.08254", "abs": "https://arxiv.org/abs/2602.08254", "authors": ["Arman Aghaee", "Sepehr Asgarian", "Jouhyun Jeon"], "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities", "categories": ["cs.AI", "cs.IR", "cs.MA"], "comment": "Presented in AAAI 2026 Singapore at the workshop of Health Intelligence", "summary": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.", "AI": {"tldr": "SynthAgent is a Multi-Agent System (MAS) for simulating high-fidelity virtual patients with obesity and mental disorders such as depression and anxiety. It uses clinical and medical evidence to model disease progression and patient behavior.", "motivation": "The study aims to address the challenges of fragmented, biased, and privacy-restricted real-world data by simulating complex diseases, specifically focusing on obesity patients with comorbid mental disorders, to enable a scalable and private framework for exploring disease dynamics.", "method": "SynthAgent uses a Multi-Agent System (MAS) framework integrating claims data, surveys, and literature to create virtual patients with personalized traits, simulating their disease progression, treatment response, and life management.", "result": "The evaluation of over 100 generated patients demonstrated that models like GPT-5 and Claude 4.5 Sonnet produced the most accurate simulations compared to other frameworks like Gemini 2.5 Pro and DeepSeek-R1.", "conclusion": "SynthAgent represents a scalable, privacy-preserving solution for studying patient behavior, disease progression, and medical decision-making, offering significant potential for both medical and psychological research."}}
{"id": "2602.07519", "pdf": "https://arxiv.org/pdf/2602.07519", "abs": "https://arxiv.org/abs/2602.07519", "authors": ["Martin Fixman", "Alessandro Abati", "Juli\u00e1n Jim\u00e9nez Nimmo", "Sean Lim", "Esther Mondrag\u00f3n"], "title": "PALMS: Pavlovian Associative Learning Models Simulator", "categories": ["cs.LG"], "comment": null, "summary": "Simulations are an indispensable step in the cycle of theory development and refinement, helping researchers formulate precise definitions, generate models, and make accurate predictions. This paper introduces the Pavlovian Associative Learning Models Simulator (PALMS), a Python environment to simulate Pavlovian conditioning experiments. In addition to the canonical Rescorla-Wagner model, PALMS incorporates several attentional learning approaches, including Pearce-Kaye-Hall, Mackintosh Extended, Le Pelley's Hybrid, and a novel extension of the Rescorla-Wagner model with a unified variable learning rate that integrates Mackintosh's and Pearce and Hall's opposing conceptualisations. The simulator's graphical interface allows for the input of entire experimental designs in an alphanumeric format, akin to that used by experimental neuroscientists. Moreover, it uniquely enables the simulation of experiments involving hundreds of stimuli, as well as the computation of configural cues and configural-cue compounds across all models, thereby considerably expanding their predictive capabilities. PALMS operates efficiently, providing instant visualisation of results, supporting rapid, precise comparisons of various models' predictions within a single architecture and environment. Furthermore, graphic displays can be easily saved, and simulated data can be exported to spreadsheets. To illustrate the simulator's capabilities and functionalities, we provide a detailed description of the software and examples of use, reproducing published experiments in the associative learning literature. PALMS is licensed under the open-source GNU Lesser General Public License 3.0. The simulator source code and the latest multiplatform release build are accessible as a GitHub repository at https://github.com/cal-r/PALMS-Simulator", "AI": {"tldr": "This study presents PALMS, a Python-based tool for simulating Pavlovian conditioning experiments, integrating classical and novel models with robust functionality and open-source accessibility.", "motivation": "The paper aims to enhance the study of Pavlovian conditioning with flexible simulation tools, enabling better model predictions and experimental setups, addressing limitations in simulating complex models or experimental designs.", "method": "Designed a Python-based simulator that incorporates traditional and attentional learning models. It allows for input of experimental designs, simulates numerous stimuli interactions, and compiles graphical and data outputs for the user.", "result": "PALMS supports diverse associative learning models, handles complex experimental designs efficiently, and allows for visualization and export of simulated data. It was validated by reproducing existing literature experiments.", "conclusion": "PALMS offers a comprehensive, flexible, and user-friendly tool for researchers in associative learning, enhancing model comparisons and experimentation accuracy. The tool is open-source and publicly available on GitHub."}}
{"id": "2602.08653", "pdf": "https://arxiv.org/pdf/2602.08653", "abs": "https://arxiv.org/abs/2602.08653", "authors": ["Jiarui Zhang", "Chengyong Lei", "Chengjiang Dai", "Lijie Wang", "Zhichao Han", "Fei Gao"], "title": "High-Speed Vision-Based Flight in Clutter with Safety-Shielded Reinforcement Learning", "categories": ["cs.RO"], "comment": null, "summary": "Quadrotor unmanned aerial vehicles (UAVs) are increasingly deployed in complex missions that demand reliable autonomous navigation and robust obstacle avoidance. However, traditional modular pipelines often incur cumulative latency, whereas purely reinforcement learning (RL) approaches typically provide limited formal safety guarantees. To bridge this gap, we propose an end-to-end RL framework augmented with model-based safety mechanisms. We incorporate physical priors in both training and deployment. During training, we design a physics-informed reward structure that provides global navigational guidance. During deployment, we integrate a real-time safety filter that projects the policy outputs onto a provably safe set to enforce strict collision-avoidance constraints. This hybrid architecture reconciles high-speed flight with robust safety assurances. Benchmark evaluations demonstrate that our method outperforms both traditional planners and recent end-to-end obstacle avoidance approaches based on differentiable physics. Extensive experiments demonstrate strong generalization, enabling reliable high-speed navigation in dense clutter and challenging outdoor forest environments at velocities up to 7.5m/s.", "AI": {"tldr": "This paper proposes a hybrid RL framework for quadrotor UAV navigation, combining physical priors and model-based safety mechanisms for high-speed and safe navigation.", "motivation": "Traditional navigation methods either have high latency or lack safety guarantees. This research seeks to combine the strengths of reinforcement learning with formal safety mechanisms to enable fast and robust navigation for UAVs.", "method": "An end-to-end RL framework augmented with model-based safety mechanisms. Physics-informed rewards guide training, while real-time safety filters enforce collision avoidance during deployment.", "result": "The proposed method outperforms traditional planners and state-of-the-art obstacle avoidance approaches. Demonstrated strong generalization in high-speed navigation, achieving up to 7.5m/s in cluttered and forested environments.", "conclusion": "The hybrid architecture successfully balances high-speed flight and robust safety, offering a significant advancement in UAV navigation."}}
{"id": "2602.08382", "pdf": "https://arxiv.org/pdf/2602.08382", "abs": "https://arxiv.org/abs/2602.08382", "authors": ["Zhuoen Chen", "Dongfang Li", "Meishan Zhang", "Baotian Hu", "Min Zhang"], "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": "26 pages, 7 figures. Code and models will be released", "summary": "Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.", "AI": {"tldr": "The paper addresses challenges in using LLMs for long-context processing by introducing a framework based on chunk-wise compression and selective memory recall, achieving competitive accuracy, efficiency, and scalability.", "motivation": "LLMs struggle with handling long contexts due to high computational costs, information loss, and limitations in current techniques such as retrieval-augmented generation.", "method": "The proposed framework divides long inputs into chunks, compresses them, and utilizes a learned gating module to dynamically select relevant memory blocks. A reasoning module with working memory processes tasks iteratively. Optimization is done via reinforcement learning and separate classifier training.", "result": "The framework demonstrates high accuracy on multi-hop reasoning tasks, can handle extended context lengths up to 1.75M tokens, and significantly reduces GPU memory usage and inference time compared to alternatives.", "conclusion": "The method effectively addresses long-context processing challenges in LLMs by balancing accuracy and efficiency, and offering scalability for extended contexts."}}
{"id": "2602.07555", "pdf": "https://arxiv.org/pdf/2602.07555", "abs": "https://arxiv.org/abs/2602.07555", "authors": ["Francesco Taioli", "Shiping Yang", "Sonia Raychaudhuri", "Marco Cristani", "Unnat Jain", "Angel X Chang"], "title": "VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Language-driven object navigation requires agents to interpret natural language descriptions of target objects, which combine intrinsic and extrinsic attributes for instance recognition and commonsense navigation. Existing methods either (i) use end-to-end trained models with vision-language embeddings, which struggle to generalize beyond training data and lack action-level explainability, or (ii) rely on modular zero-shot pipelines with large language models (LLMs) and open-set object detectors, which suffer from error propagation, high computational cost, and difficulty integrating their reasoning back into the navigation policy. To this end, we propose a compact 3B-parameter Vision-Language-Action (VLA) agent that performs human-like embodied reasoning for both object recognition and action selection, removing the need for stitched multi-model pipelines. Instead of raw embedding matching, our agent employs explicit image-grounded reasoning to directly answer \"Is this the target object?\" and \"Why should I take this action?\" The reasoning process unfolds in three stages: \"think\", \"think summary\", and \"action\", yielding improved explainability, stronger generalization, and more efficient navigation. Code and dataset available upon acceptance.", "AI": {"tldr": "This paper proposes a Vision-Language-Action agent for language-driven object navigation with enhanced explainability and generalization, bypassing common challenges in prior methods.", "motivation": "To overcome limitations in existing models for object navigation, which struggle with generalization, explainability, error propagation, high computational costs, and reasoning integration.", "method": "Developed a compact 3B-parameter Vision-Language-Action agent for embodied reasoning that uses explicit image-grounded reasoning in three stages: \"think,\" \"think summary,\" and \"action.\"", "result": "Achieved improved explainability, stronger generalization, and more efficient navigation compared to prior models.", "conclusion": "By removing stitched multi-model pipelines and focusing on explicit reasoning, the proposed model demonstrates superior performance in language-driven object navigation."}}
{"id": "2602.08268", "pdf": "https://arxiv.org/pdf/2602.08268", "abs": "https://arxiv.org/abs/2602.08268", "authors": ["Akinori Maeda", "Yuto Sekiya", "Sota Sugimura", "Tomoya Asai", "Yu Tsuda", "Kohei Ikeda", "Hiroshi Fujii", "Kohei Watanabe"], "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI", "categories": ["cs.AI"], "comment": "9 pages, 5 figures", "summary": "Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI.", "AI": {"tldr": "This paper addresses the challenge of balancing diverse personal data utilization and privacy in personalized AI by introducing Puda, a user-sovereign architecture for data management.", "motivation": "The paper is motivated by the centralization of personal data by dominant platforms, inhibiting user sovereignty and limiting data utilization across services, particularly as demand for personalization rises with LLM-based agents.", "method": "The authors propose and implement Puda, a browser-based system that aggregates personal data across services with client-side management, offering three privacy levels to control data sharing: Detailed Browsing History, Extracted Keywords, and Predefined Category Subsets.", "result": "Puda's evaluation shows that providing Predefined Category Subsets achieves 97.2% of the personalization performance compared to sharing Detailed Browsing History while maintaining privacy.", "conclusion": "Puda demonstrates an effective mechanism to manage the privacy-personalization trade-off and offers an AI-native framework for user sovereignty, empowering safe use of personalized AI services."}}
{"id": "2602.07521", "pdf": "https://arxiv.org/pdf/2602.07521", "abs": "https://arxiv.org/abs/2602.07521", "authors": ["Xionghui Yang", "Bozhou Chen", "Yunlong Lu", "Yongyi Wang", "Lingfeng Li", "Lanxiao Huang", "Lin Liu", "Wenjun Wang", "Meng Meng", "Xia Lin", "Wenxin Li"], "title": "Pareto-guided Pipeline for Distilling Featherweight AI Agents in Mobile MOBA Games", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in game AI have demonstrated the feasibility of training agents that surpass top-tier human professionals in complex environments such as Honor of Kings (HoK), a leading mobile multiplayer online battle arena (MOBA) game. However, deploying such powerful agents on mobile devices remains a major challenge. On one hand, the intricate multi-modal state representation and hierarchical action space of HoK demand large, sophisticated policy networks that are inherently difficult to compress into lightweight forms. On the other hand, production deployment requires high-frequency inference under strict energy and latency constraints on mobile platform. To the best of our knowledge, bridging large-scale game AI and practical on-device deployment has not been systematically studied. In this work, we propose a Pareto optimality guided pipeline and design a high-efficiency student architecture search space tailored for mobile execution, enabling systematic exploration of the trade-off between performance and efficiency. Experimental results demonstrate that the distilled model achieves remarkable efficiency, including an $12.4\\times$ faster inference speed (under 0.5ms per frame) and a $15.6\\times$ improvement in energy efficiency (under 0.5mAh per game), while retaining a 40.32% win rate against the original teacher model.", "AI": {"tldr": "This paper addresses the challenge of deploying advanced game AI on mobile devices, like adapting AI for Honor of Kings, by optimizing efficiency while retaining competitive performance.", "motivation": "There is currently a gap in deploying complex game AI models on mobile platforms due to constraints like limited device resources, high energy requirements, and the need for real-time inference.", "method": "The paper proposes a Pareto optimality guided pipeline combined with a tailored high-efficiency student architecture search space to balance performance and efficiency for mobile platforms.", "result": "The distilled AI model achieved significant efficiency improvements, including 12.4\u00d7 faster inference, 15.6\u00d7 energy efficiency, and retaining a 40.32% win rate against the teacher model.", "conclusion": "The proposed pipeline and approach demonstrate it is possible to deploy competitive game AI on resource-constrained mobile devices while efficiently managing speed, energy, and performance trade-offs."}}
{"id": "2602.08776", "pdf": "https://arxiv.org/pdf/2602.08776", "abs": "https://arxiv.org/abs/2602.08776", "authors": ["Cuijie Xu", "Shurui Zheng", "Zihao Su", "Yuanfan Xu", "Tinghao Yi", "Xudong Zhang", "Jian Wang", "Yu Wang", "Jinchen Yu"], "title": "Mind the Gap: Learning Implicit Impedance in Visuomotor Policies via Intent-Execution Mismatch", "categories": ["cs.RO"], "comment": "14 pages, 9 figures, 5 tables", "summary": "Teleoperation inherently relies on the human operator acting as a closed-loop controller to actively compensate for hardware imperfections, including latency, mechanical friction, and lack of explicit force feedback. Standard Behavior Cloning (BC), by mimicking the robot's executed trajectory, fundamentally ignores this compensatory mechanism. In this work, we propose a Dual-State Conditioning framework that shifts the learning objective to \"Intent Cloning\" (master command). We posit that the Intent-Execution Mismatch, the discrepancy between master command and slave response, is not noise, but a critical signal that physically encodes implicit interaction forces and algorithmically reveals the operator's strategy for overcoming system dynamics. By predicting the master intent, our policy learns to generate a \"virtual equilibrium point\", effectively realizing implicit impedance control. Furthermore, by explicitly conditioning on the history of this mismatch, the model performs implicit system identification, perceiving tracking errors as external forces to close the control loop. To bridge the temporal gap caused by inference latency, we further formulate the policy as a trajectory inpainter to ensure continuous control. We validate our approach on a sensorless, low-cost bi-manual setup. Empirical results across tasks requiring contact-rich manipulation and dynamic tracking reveal a decisive gap: while standard execution-cloning fails due to the inability to overcome contact stiffness and tracking lag, our mismatch-aware approach achieves robust success. This presents a minimalist behavior cloning framework for low-cost hardware, enabling force perception and dynamic compensation without relying on explicit force sensing. Videos are available on the \\href{https://xucj98.github.io/mind-the-gap-page/}{project page}.", "AI": {"tldr": "The paper introduces a new teleoperation framework, Dual-State Conditioning, to address challenges like latency and mechanical friction. The approach shifts focus from trajectory imitation to intent prediction for improved performance.", "motivation": "Teleoperation systems face challenges due to hardware imperfections like latency and lack of force feedback. Standard Behavior Cloning fails to address these issues effectively.", "method": "The Dual-State Conditioning framework predicts the operator's intent and uses Intent-Execution Mismatch as a signal. It enables implicit impedance control, system identification, and trajectory inpainting for continuous control.", "result": "The proposed method significantly outperforms standard approaches in tasks requiring contact-heavy manipulation and dynamic tracking, especially noticeable in low-cost, sensorless hardware setups.", "conclusion": "This novel approach highlights a minimalist behavior cloning method for teleoperation, enabling robust control without explicit force sensors, and demonstrates its strong potential for low-cost systems."}}
{"id": "2602.08404", "pdf": "https://arxiv.org/pdf/2602.08404", "abs": "https://arxiv.org/abs/2602.08404", "authors": ["Linye Wei", "Zixiang Luo", "Pingzhi Tang", "Meng Li"], "title": "TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration", "categories": ["cs.CL"], "comment": null, "summary": "Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.", "AI": {"tldr": "The paper addresses inefficiency in Mixture-of-Experts (MoE) diffusion large language models (dLLMs) decoding and introduces TEAM, a framework reducing latency while maintaining performance.", "motivation": "To mitigate inference inefficiency caused by activating multiple experts in MoE dLLMs for diffusion-based decoding in latency-sensitive applications.", "method": "TEAM leverages temporal and spatial consistency in expert routing decisions using three expert activation and decoding strategies for decoding masked tokens while optimizing speculative exploration.", "result": "TEAM achieves up to 2.2x acceleration over traditional MoE dLLMs with minimal performance loss.", "conclusion": "TEAM is a plug-and-play solution enhancing MoE dLLMs for faster inference in practical applications, making them more suitable for latency-constrained environments."}}
{"id": "2602.07564", "pdf": "https://arxiv.org/pdf/2602.07564", "abs": "https://arxiv.org/abs/2602.07564", "authors": ["Xiaoyan Zhang", "Zechen Bai", "Haofan Wang", "Yiren Song"], "title": "SIGMA: Selective-Interleaved Generation with Multi-Attribute Tokens", "categories": ["cs.CV"], "comment": null, "summary": "Recent unified models such as Bagel demonstrate that paired image-edit data can effectively align multiple visual tasks within a single diffusion transformer. However, these models remain limited to single-condition inputs and lack the flexibility needed to synthesize results from multiple heterogeneous sources. We present SIGMA (Selective-Interleaved Generation with Multi-Attribute Tokens), a unified post-training framework that enables interleaved multi-condition generation within diffusion transformers. SIGMA introduces selective multi-attribute tokens, including style, content, subject, and identity tokens, which allow the model to interpret and compose multiple visual conditions in an interleaved text-image sequence. Through post-training on the Bagel unified backbone with 700K interleaved examples, SIGMA supports compositional editing, selective attribute transfer, and fine-grained multimodal alignment. Extensive experiments show that SIGMA improves controllability, cross-condition consistency, and visual quality across diverse editing and generation tasks, with substantial gains over Bagel on compositional tasks.", "AI": {"tldr": "SIGMA builds on Bagel's unified diffusion transformer model and introduces selective multi-attribute tokens for interleaved multi-condition visual generation.", "motivation": "Existing models like Bagel cannot handle multi-condition inputs or synthesize diverse sources effectively.", "method": "Introduce selective multi-attribute tokens and utilize post-training with 700K interleaved examples to enable multi-condition interleaved generation.", "result": "SIGMA improves control, consistency, and visual quality in editing and generation tasks compared to Bagel, especially for compositional tasks.", "conclusion": "SIGMA extends unified modeling by enabling multi-condition inputs, enhancing task variety, and ensuring greater visual and compositional accuracy."}}
{"id": "2602.08276", "pdf": "https://arxiv.org/pdf/2602.08276", "abs": "https://arxiv.org/abs/2602.08276", "authors": ["Haoyu Jia", "Kento Kawaharazuka", "Kei Okada"], "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \\texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \\texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.", "AI": {"tldr": "The paper addresses the fragmented approach in LLM agent research by proposing a self-consistent, formal model called the Structural Context Model and introducing a complementary framework for development and analysis. ", "motivation": "To tackle the fragmentation in LLM research caused by a lack of a consistent formal model, thus providing a unified approach to analyzing and comparing agents without low-level implementation distractions.", "method": "Proposed the Structural Context Model for context-based analysis and comparison of LLM agents, alongside a declarative implementation framework and Semantic Dynamics Analysis workflow for effective agent design.", "result": "Demonstrated that the framework significantly improves agent design, achieving up to a 32% improvement in success rates in a complex monkey-banana problem setting.", "conclusion": "The framework facilitates a structured, systematic, and sustainable approach to LLM agent research, yielding measurable performance enhancements."}}
{"id": "2602.07529", "pdf": "https://arxiv.org/pdf/2602.07529", "abs": "https://arxiv.org/abs/2602.07529", "authors": ["Jianwen Chen", "Xinyu Yang", "Peng Xia", "Arian Azarang", "Yueh Z Lee", "Gang Li", "Hongtu Zhu", "Yun Li", "Beidi Chen", "Huaxiu Yao"], "title": "MedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance and rapid progress in a wide range of medical reasoning tasks. However, their sequential autoregressive decoding forces inherently parallel clinical reasoning, such as differential diagnosis, into a single linear reasoning path, limiting both efficiency and reliability for complex medical problems. To address this, we propose MedVerse, a reasoning framework for complex medical inference that reformulates medical reasoning as a parallelizable directed acyclic graph (DAG) process based on Petri net theory. The framework adopts a full-stack design across data, model architecture, and system execution. For data creation, we introduce the MedVerse Curator, an automated pipeline that synthesizes knowledge-grounded medical reasoning paths and transforms them into Petri net-structured representations. At the architectural level, we propose a topology-aware attention mechanism with adaptive position indices that supports parallel reasoning while preserving logical consistency. Systematically, we develop a customized inference engine that supports parallel execution without additional overhead. Empirical evaluations show that MedVerse improves strong general-purpose LLMs by up to 8.9%. Compared to specialized medical LLMs, MedVerse achieves comparable performance while delivering a 1.3x reduction in inference latency and a 1.7x increase in generation throughput, enabled by its parallel decoding capability.", "AI": {"tldr": "MedVerse introduces a framework for medical reasoning using a parallelizable process based on Petri net theory, addressing inefficiencies in traditional autoregressive decoding by large language models.", "motivation": "Current large language models face efficiency and reliability challenges in complex medical reasoning tasks due to their linear, sequential decoding approach.", "method": "MedVerse reformulates medical reasoning as a directed acyclic graph process using Petri net theory, incorporates topology-aware attention mechanisms, adaptive position indices, and a parallel inference engine.", "result": "MedVerse improves general-purpose LLMs performance by up to 8.9%, achieves comparable results to specialized medical LLMs, while reducing inference latency by 1.3x and increasing generation throughput by 1.7x.", "conclusion": "MedVerse offers a more efficient and reliable framework for medical reasoning, demonstrating significant improvements in performance, latency, and throughput by leveraging parallel processes."}}
{"id": "2602.08784", "pdf": "https://arxiv.org/pdf/2602.08784", "abs": "https://arxiv.org/abs/2602.08784", "authors": ["Santiago Montiel-Mar\u00edn", "Miguel Antunes-Garc\u00eda", "Fabio S\u00e1nchez-Garc\u00eda", "Angel Llamazares", "Holger Caesar", "Luis M. Bergasa"], "title": "GaussianCaR: Gaussian Splatting for Efficient Camera-Radar Fusion", "categories": ["cs.RO"], "comment": "8 pages, 6 figures. Accepted to IEEE ICRA 2026", "summary": "Robust and accurate perception of dynamic objects and map elements is crucial for autonomous vehicles performing safe navigation in complex traffic scenarios. While vision-only methods have become the de facto standard due to their technical advances, they can benefit from effective and cost-efficient fusion with radar measurements. In this work, we advance fusion methods by repurposing Gaussian Splatting as an efficient universal view transformer that bridges the view disparity gap, mapping both image pixels and radar points into a common Bird's-Eye View (BEV) representation. Our main contribution is GaussianCaR, an end-to-end network for BEV segmentation that, unlike prior BEV fusion methods, leverages Gaussian Splatting to map raw sensor information into latent features for efficient camera-radar fusion. Our architecture combines multi-scale fusion with a transformer decoder to efficiently extract BEV features. Experimental results demonstrate that our approach achieves performance on par with, or even surpassing, the state of the art on BEV segmentation tasks (57.3%, 82.9%, and 50.1% IoU for vehicles, roads, and lane dividers) on the nuScenes dataset, while maintaining a 3.2x faster inference runtime. Code and project page are available online.", "AI": {"tldr": "The paper introduces GaussianCaR, a BEV segmentation network combining camera and radar data via Gaussian Splatting, achieving state-of-the-art performance on the nuScenes dataset with faster runtime.", "motivation": "To enhance autonomous vehicle perception through efficient fusion of camera and radar data for better BEV segmentation in complex traffic conditions.", "method": "Gaussian Splatting is used as a universal view transformer, mapping image pixels and radar points into a unified BEV representation for efficient fusion, accompanied by a multi-scale fusion network and transformer decoder.", "result": "Performance exceeds or matches the state of the art for vehicles, roads, and lane dividers (57.3%, 82.9%, and 50.1% IoU) on the nuScenes dataset, with a 3.2x faster runtime.", "conclusion": "The proposed GaussianCaR effectively combines radar and image data for BEV segmentation, improving both accuracy and computational efficiency, establishing it as a robust solution for autonomous navigation."}}
{"id": "2602.08426", "pdf": "https://arxiv.org/pdf/2602.08426", "abs": "https://arxiv.org/abs/2602.08426", "authors": ["Xinghao Wang", "Pengyu Wang", "Xiaoran Liu", "Fangxu Liu", "Jason Chu", "Kai Song", "Xipeng Qiu"], "title": "Prism: Spectral-Aware Block-Sparse Attention", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\\mathbf{5.1\\times}$ speedup.", "AI": {"tldr": "The paper introduces Prism, a spectral-aware approach that enhances block-sparse attention for faster and more efficient long-context LLM pre-filling.", "motivation": "Existing block-sparse attention methods face inefficiencies in identifying relevant blocks due to inaccurate coarse-grained attention and costly token-level calculations.", "method": "The authors identify theoretical issues with standard mean pooling and propose Prism, which decomposes block selection into high-frequency and low-frequency branches using energy-based temperature calibration.", "result": "Prism maintains accuracy on par with full attention while achieving up to 5.1x speedup.", "conclusion": "Prism resolves inefficiencies in block-sparse attention by offering a training-free solution, proving effective in balancing accuracy and computational efficiency for long-context scenarios."}}
{"id": "2602.07565", "pdf": "https://arxiv.org/pdf/2602.07565", "abs": "https://arxiv.org/abs/2602.07565", "authors": ["Jingzhe Ma", "Meng Zhang", "Jianlong Yu", "Kun Liu", "Zunxiao Xu", "Xue Cheng", "Junjie Zhou", "Yanfei Wang", "Jiahang Li", "Zepeng Wang", "Kazuki Osamura", "Rujie Liu", "Narishige Abe", "Jingjie Wang", "Shunli Zhang", "Haojun Xie", "Jiajun Wu", "Weiming Wu", "Wenxiong Kang", "Qingshuo Gao", "Jiaming Xiong", "Xianye Ben", "Lei Chen", "Lichen Song", "Junjian Cui", "Haijun Xiong", "Junhao Lu", "Bin Feng", "Mengyuan Liu", "Ji Zhou", "Baoquan Zhao", "Ke Xu", "Yongzhen Huang", "Liang Wang", "Manuel J Marin-Jimenez", "Md Atiqur Rahman Ahad", "Shiqi Yu"], "title": "Human Identification at a Distance: Challenges, Methods and Results on the Competition HID 2025", "categories": ["cs.CV"], "comment": "Accepted by IJCB 2025(https://ijcb2025.ieee-biometrics.org/competitions/)", "summary": "Human identification at a distance (HID) is challenging because traditional biometric modalities such as face and fingerprints are often difficult to acquire in real-world scenarios. Gait recognition provides a practical alternative, as it can be captured reliably at a distance. To promote progress in gait recognition and provide a fair evaluation platform, the International Competition on Human Identification at a Distance (HID) has been organized annually since 2020. Since 2023, the competition has adopted the challenging SUSTech-Competition dataset, which features substantial variations in clothing, carried objects, and view angles. No dedicated training data are provided, requiring participants to train their models using external datasets. Each year, the competition applies a different random seed to generate distinct evaluation splits, which reduces the risk of overfitting and supports a fair assessment of cross-domain generalization. While HID 2023 and HID 2024 already used this dataset, HID 2025 explicitly examined whether algorithmic advances could surpass the accuracy limits observed previously. Despite the heightened difficulty, participants achieved further improvements, and the best-performing method reached 94.2% accuracy, setting a new benchmark on this dataset. We also analyze key technical trends and outline potential directions for future research in gait recognition.", "AI": {"tldr": "The paper discusses the challenges of human identification at a distance (HID) and how gait recognition offers a solution. It focuses on the HID competitions since 2023, particularly advancements achieved using the SUSTech-Competition dataset, despite its challenges.", "motivation": "The work addresses the need for reliable HID methods that overcome the limitations of traditional biometrics like face and fingerprints, particularly in real-world scenarios.", "method": "The HID competition offers a challenging dataset, the SUSTech-Competition, requiring participants to train on external data without dedicated training material. Distinct evaluation splits are generated annually to ensure fair assessment and reduced overfitting.", "result": "The best-performing method in the HID 2025 competition achieved a remarkable 94.2% accuracy, setting a new benchmark on the challenging dataset.", "conclusion": "The paper highlights advancements in gait recognition, identifies technical trends, and suggests areas for future research in HID, demonstrating that algorithmic improvements can enhance accuracy despite dataset challenges."}}
{"id": "2602.08295", "pdf": "https://arxiv.org/pdf/2602.08295", "abs": "https://arxiv.org/abs/2602.08295", "authors": ["Ilya Levin"], "title": "The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI", "categories": ["cs.AI"], "comment": "19 pages", "summary": "The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition.\n  The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems.\n  The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity.", "AI": {"tldr": "This paper introduces the concept of Vibe-Automation to describe how generative AI deviates from traditional algorithmic approaches by operationalizing tacit regularities, proposing new roles for human interaction with AI, like Vibe-Engineering.", "motivation": "The motivation is to explore the paradigm shift introduced by generative AI, which moves away from traditional algorithmic optimization towards navigating contextual and tacit knowledge. It aims to address the epistemological implications and practical consequences for academia and industry.", "method": "The paper provides a conceptual framework spanning three analytical levels and domains of action (faculty worldview, industry relations, and curriculum design) to examine the epistemological and institutional impact of generative AI.", "result": "It identifies generative AI's operationalization of tacit knowledge as a key shift, and proposes new roles like Vibe-Engineering for humans to collaborate with AI. It also highlights risks such as mode collapse and synthetic uniformity.", "conclusion": "The paper concludes that generative AI introduces a qualitative shift in how technological systems function, requiring thoughtful engagement with its transformative potential to prevent negative outcomes like cultural homogenization."}}
{"id": "2602.07530", "pdf": "https://arxiv.org/pdf/2602.07530", "abs": "https://arxiv.org/abs/2602.07530", "authors": ["Sreenivas Gollapudi", "Kostas Kollias", "Kamesh Munagala", "Aravindan Vijayaraghavan"], "title": "Compact Conformal Subgraphs", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "Conformal prediction provides rigorous, distribution-free uncertainty guarantees, but often yields prohibitively large prediction sets in structured domains such as routing, planning, or sequential recommendation. We introduce \"graph-based conformal compression\", a framework for constructing compact subgraphs that preserve statistical validity while reducing structural complexity. We formulate compression as selecting a smallest subgraph capturing a prescribed fraction of the probability mass, and reduce to a weighted version of densest $k$-subgraphs in hypergraphs, in the regime where the subgraph has a large fraction of edges. We design efficient approximation algorithms that achieve constant factor coverage and size trade-offs. Crucially, we prove that our relaxation satisfies a monotonicity property, derived from a connection to parametric minimum cuts, which guarantees the nestedness required for valid conformal guarantees. Our results on the one hand bridge efficient conformal prediction with combinatorial graph compression via monotonicity, to provide rigorous guarantees on both statistical validity, and compression or size. On the other hand, they also highlight an algorithmic regime, distinct from classical densest-$k$-subgraph hardness settings, where the problem can be approximated efficiently. We finally validate our algorithmic approach via simulations for trip planning and navigation, and compare to natural baselines.", "AI": {"tldr": "This paper introduces graph-based conformal compression, optimizing prediction sets in structured domains by formulating and solving a graph compression problem.", "motivation": "To address large prediction set sizes in structured domains while maintaining statistical validity in conformal predictions.", "method": "Graph compression is approached by selecting subgraphs that capture significant probability mass, reduced to a weighted densest $k$-subgraph problem with efficient approximation algorithms ensuring validity via monotonicity property.", "result": "Validated efficient approximation algorithms maintaining statistical rigor and providing compact prediction sets, bridging conformal prediction and graph compression.", "conclusion": "The proposed framework offers a statistically valid, computationally efficient approach for prediction set optimization, demonstrating practical benefits in structured tasks like trip planning and navigation."}}
{"id": "2602.08799", "pdf": "https://arxiv.org/pdf/2602.08799", "abs": "https://arxiv.org/abs/2602.08799", "authors": ["Robin Dehler", "Michael Buchholz"], "title": "A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles", "categories": ["cs.RO", "cs.MA"], "comment": "8 pages, 6 figures, 2 tables, published in RA-L", "summary": "Function offloading is a promising solution to address limitations concerning computational capacity and available energy of Connected Automated Vehicles~(CAVs) or other autonomous robots by distributing computational tasks between local and remote computing devices in form of distributed services. This paper presents a generic function offloading framework that can be used to offload an arbitrary set of computational tasks with a focus on autonomous driving. To provide flexibility, the function offloading framework is designed to incorporate different offloading decision making algorithms and quality of service~(QoS) requirements that can be adjusted to different scenarios or the objectives of the CAVs. With a focus on the applicability, we propose an efficient location-based approach, where the decision whether tasks are processed locally or remotely depends on the location of the CAV. We apply the proposed framework on the use case of service-oriented trajectory planning, where we offload the trajectory planning task of CAVs to a Multi-Access Edge Computing~(MEC) server. The evaluation is conducted in both simulation and real-world application. It demonstrates the potential of the function offloading framework to guarantee the QoS for trajectory planning while improving the computational efficiency of the CAVs. Moreover, the simulation results also show the adaptability of the framework to diverse scenarios involving simultaneous offloading requests from multiple CAVs.", "AI": {"tldr": "The paper introduces a function offloading framework for autonomous vehicles, focused on enabling flexible offloading decisions and improving trajectory planning efficiency.", "motivation": "Connected Automated Vehicles face limitations in computational capacity and energy. A function offloading framework ensures efficient task processing by distributing computational tasks between local and remote servers.", "method": "The framework integrates offloading decision-making algorithms and QoS requirements. A location-based approach decides task processing, tested on a service-oriented trajectory planning use case.", "result": "Simulations and real-world applications validate the approach, improving trajectory planning\u2019s QoS while enhancing computational efficiency for multiple simultaneous requests.", "conclusion": "The framework highlights its scalability, adaptability, and potential in addressing computational challenges and enhancing QoS for autonomous vehicles."}}
{"id": "2602.08437", "pdf": "https://arxiv.org/pdf/2602.08437", "abs": "https://arxiv.org/abs/2602.08437", "authors": ["Ziyan wang", "Longlong Ma"], "title": "Large Language Models and Impossible Language Acquisition: \"False Promise\" or an Overturn of our Current Perspective towards AI", "categories": ["cs.CL"], "comment": null, "summary": "In Chomsky's provocative critique \"The False Promise of CHATGPT,\" Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his \"rationalist-romantics\" paradigm to functionalism and empiricism in LLMs research.", "AI": {"tldr": "The paper critiques Chomsky\u2019s take on Large Language Models (LLMs) and tests their ability to learn possible versus impossible languages using GPT-2 and LSTM models. Results indicate significant differences in performance, showcasing the relevance of transformer architecture.", "motivation": "To critically examine Chomsky's assertion that LLMs operate as mere pattern predictors by testing their ability to distinguish between possible and impossible languages, and to explore theoretical paradigms in understanding LLMs.", "method": "Used linguistics and psychology research along with controlled experiments. Created syntactically impossible languages through transformations like sentence reversal and negation, then tested GPT-2 and LSTM models\u2019 learning capabilities. Statistical analysis applied (Welch\u2019s t-test).", "result": "Experiments showed GPT-2 underperformed in learning impossible languages compared to possible ones (p<.001), while LSTM models aligned with Chomsky's claims, spotlighting the critical role of transformer architecture.", "conclusion": "The study validates Chomsky\u2019s critique partially but also emphasizes the evolution of transformer models like GPT-2. It proposes a shift from Chomsky\u2019s traditional rationalist paradigm towards empiricism and functionalism in LLM research."}}
{"id": "2602.07566", "pdf": "https://arxiv.org/pdf/2602.07566", "abs": "https://arxiv.org/abs/2602.07566", "authors": ["Runcheng Wang", "Yaru Chen", "Guiguo Zhang", "Honghua Jiang", "Yongliang Qiao"], "title": "Cross-Camera Cow Identification via Disentangled Representation Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Precise identification of individual cows is a fundamental prerequisite for comprehensive digital management in smart livestock farming. While existing animal identification methods excel in controlled, single-camera settings, they face severe challenges regarding cross-camera generalization. When models trained on source cameras are deployed to new monitoring nodes characterized by divergent illumination, backgrounds, viewpoints, and heterogeneous imaging properties, recognition performance often degrades dramatically. This limits the large-scale application of non-contact technologies in dynamic, real-world farming environments. To address this challenge, this study proposes a cross-camera cow identification framework based on disentangled representation learning. This framework leverages the Subspace Identifiability Guarantee (SIG) theory in the context of bovine visual recognition. By modeling the underlying physical data generation process, we designed a principle-driven feature disentanglement module that decomposes observed images into multiple orthogonal latent subspaces. This mechanism effectively isolates stable, identity-related biometric features that remain invariant across cameras, thereby substantially improving generalization to unseen cameras. We constructed a high-quality dataset spanning five distinct camera nodes, covering heterogeneous acquisition devices and complex variations in lighting and angles. Extensive experiments across seven cross-camera tasks demonstrate that the proposed method achieves an average accuracy of 86.0%, significantly outperforming the Source-only Baseline (51.9%) and the strongest cross-camera baseline method (79.8%). This work establishes a subspace-theoretic feature disentanglement framework for collaborative cross-camera cow identification, offering a new paradigm for precise animal monitoring in uncontrolled smart farming environments.", "AI": {"tldr": "This paper proposes a framework for cross-camera cow identification using disentangled representation learning to improve identification in smart farming environments, achieving notable performance improvements.", "motivation": "Current cow identification methods fail under cross-camera generalization due to varying conditions in real-world farming environments like lighting and viewpoints.", "method": "The proposed framework uses the Subspace Identifiability Guarantee theory to isolate identity-related biometric features via feature disentanglement, ensuring stability across camera nodes.", "result": "Achieved 86.0% accuracy across seven cross-camera tasks, surpassing both the source-only baseline (51.9%) and the strongest cross-camera baseline method (79.8%).", "conclusion": "The study introduces a high-performing subspace-theoretic framework, paving the way for precise and scalable animal monitoring in uncontrolled farming environments."}}
{"id": "2602.08311", "pdf": "https://arxiv.org/pdf/2602.08311", "abs": "https://arxiv.org/abs/2602.08311", "authors": ["Shadman Rabby", "Md. Hefzul Hossain Papon", "Sabbir Ahmed", "Nokimul Hasan Arif", "A. B. M. Ashikur Rahman", "Irfan Ahmad"], "title": "Moral Sycophancy in Vision Language Models", "categories": ["cs.AI"], "comment": "13 pages, 6 figures, 8 tables, Submitted for review in ACL", "summary": "Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.", "AI": {"tldr": "This paper studies moral sycophancy in Vision-Language Models (VLMs), showing they often follow user biases at the expense of correct moral judgments.", "motivation": "To address the lack of understanding about how moral sycophancy affects VLMs' ability to make consistent and ethically sound decisions under user disagreement.", "method": "The authors used datasets (Moralise and M^3oralBench) and metrics (Error Introduction Rate and Error Correction Rate) to analyze the moral responses and sycophantic behavior of ten VLMs.", "result": "Models often degrade in moral judgment under user influence, exhibiting asymmetric shifts from right to wrong. Results vary by dataset, and models show a trade-off between error correction and error introduction.", "conclusion": "Moral inconsistencies show a need to develop strategies for improving ethical robustness to mitigate the influence of user-induced biases in VLMs."}}
{"id": "2602.08821", "pdf": "https://arxiv.org/pdf/2602.08821", "abs": "https://arxiv.org/abs/2602.08821", "authors": ["Robin Dehler", "Oliver Schumann", "Jona Ruof", "Michael Buchholz"], "title": "Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems", "categories": ["cs.RO"], "comment": null, "summary": "The integration of service-oriented architectures (SOA) with function offloading for distributed, intelligent transportation systems (ITS) offers the opportunity for connected autonomous vehicles (CAVs) to extend their locally available services. One major goal of offloading a subset of functions in the processing chain of a CAV to remote devices is to reduce the overall computational complexity on the CAV. The extension of using remote services, however, requires careful safety analysis, since the remotely created data are corrupted more easily, e.g., through an attacker on the remote device or by intercepting the wireless transmission. To tackle this problem, we first analyze the concept of SOA for distributed environments. From this, we derive a safety framework that validates the reliability of remote services and the data received locally. Since it is possible for the autonomous driving task to offload multiple different services, we propose a specific multi-staged framework for safety analysis dependent on the service composition of local and remote services. For efficiency reasons, we directly include the multi-staged framework for safety analysis in our service-oriented function offloading framework (SOFOF) that we have proposed in earlier work. The evaluation compares the performance of the extended framework considering computational complexity, with energy savings being a major motivation for function offloading, and its capability to detect data from corrupted remote services.", "AI": {"tldr": "The paper integrates service-oriented architectures with function offloading in intelligent transportation systems for connected autonomous vehicles while introducing a safety framework to validate remote services.", "motivation": "To reduce computational complexity and save energy on connected autonomous vehicles by leveraging function offloading while ensuring the safety and reliability of remote services.", "method": "Analyzed SOA for distributed environments, derived a safety framework for validating remote services, and integrated it into a multi-staged framework in a previously proposed service-oriented function offloading framework (SOFOF).", "result": "The proposed extended framework was evaluated and showed improvements in energy savings and detection of corrupted remote services while balancing computational complexity.", "conclusion": "The integration of the safety framework into the service-oriented function offloading system enables energy-efficient and safe implementation of distributed ITS solutions."}}
{"id": "2602.08498", "pdf": "https://arxiv.org/pdf/2602.08498", "abs": "https://arxiv.org/abs/2602.08498", "authors": ["Haoran Zhang", "Yafu Li", "Zhi Wang", "Zhilin Wang", "Shunkai Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "Characterizing, Evaluating, and Optimizing Complex Reasoning", "categories": ["cs.CL"], "comment": "Code and data are available at \\url{https://github.com/zzzhr97/TRM}", "summary": "Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.", "AI": {"tldr": "The paper addresses the challenges of evaluating and enhancing reasoning quality in large reasoning models by introducing a new evaluation framework and utilizing it for performance optimization.", "motivation": "The motivation is to provide a unified understanding and approach to evaluating and optimizing complex reasoning traces, which lack reliable frameworks in existing research.", "method": "The authors propose the ME$^2$ principle to characterize reasoning quality, model reasoning traces as DAGs for pairwise evaluation, and create the TRM-Preference dataset to train a Thinking Reward Model (TRM).", "result": "The proposed method effectively evaluates reasoning quality and achieves improvements in both test-time reasoning selection (up to 19.3%) and reinforcement learning training outcomes (up to 3.9%) across multiple tasks.", "conclusion": "The study demonstrates that systematic reasoning trace evaluation can be utilized to enhance model reasoning quality and task performance at scale."}}
{"id": "2602.07568", "pdf": "https://arxiv.org/pdf/2602.07568", "abs": "https://arxiv.org/abs/2602.07568", "authors": ["Hui Ye", "Shilong Yang", "Yexuan Xing", "Juan Yu", "Yaoqin Xie", "Wei Zhang", "Chulong Zhang"], "title": "Visualizing the Invisible: Enhancing Radiologist Performance in Breast Mammography via Task-Driven Chromatic Encoding", "categories": ["cs.CV"], "comment": null, "summary": "Purpose:Mammography screening is less sensitive in dense breasts, where tissue overlap and subtle findings increase perceptual difficulty. We present MammoColor, an end-to-end framework with a Task-Driven Chromatic Encoding (TDCE) module that converts single-channel mammograms into TDCE-encoded views for visual augmentation. Materials and Methods:MammoColor couples a lightweight TDCE module with a BI-RADS triage classifier and was trained end-to-end on VinDr-Mammo. Performance was evaluated on an internal test set, two public datasets (CBIS-DDSM and INBreast), and three external clinical cohorts. We also conducted a multi-reader, multi-case (MRMC) observer study with a washout period, comparing (1) grayscale-only, (2) TDCE-only, and (3) side-by-side grayscale+TDCE. Results:On VinDr-Mammo, MammoColor improved AUC from 0.7669 to 0.8461 (P=0.004). Gains were larger in dense breasts (AUC 0.749 to 0.835). In the MRMC study, TDCE-encoded images improved specificity (0.90 to 0.96; P=0.052) with comparable sensitivity. Conclusion:TDCE provides a task-optimized chromatic representation that may improve perceptual salience and reduce false-positive recalls in mammography triage.", "AI": {"tldr": "The paper introduces MammoColor with TDCE module to enhance mammogram analysis, showing improved performance and perceptual salience, especially for dense breasts.", "motivation": "Mammography screening often struggles in dense breast tissues due to perceptual challenges caused by tissue overlap and subtle findings.", "method": "MammoColor includes a Task-Driven Chromatic Encoding module paired with a BI-RADS classifier, trained on VinDr-Mammo. Performance was tested across multiple datasets and clinical cohorts, accompanied by a multi-reader study.", "result": "MammoColor enhanced AUC significantly (from 0.7669 to 0.8461), particularly for dense breasts. MRMC study confirmed improved specificity with TDCE images.", "conclusion": "TDCE offers enhanced visual representation, which helps improve mammography accuracy and minimize false positives."}}
{"id": "2602.08335", "pdf": "https://arxiv.org/pdf/2602.08335", "abs": "https://arxiv.org/abs/2602.08335", "authors": ["Yanming Li", "Xuelin Zhang", "WenJie Lu", "Ziye Tang", "Maodong Wu", "Haotian Luo", "Tongtong Wu", "Zijie Peng", "Hongze Mi", "Yibo Feng", "Naiqiang Tan", "Chao Huang", "Hong Chen", "Li Shen"], "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System", "categories": ["cs.AI"], "comment": null, "summary": "Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.", "AI": {"tldr": "SHARP is a novel framework for improving multi-agent reinforcement learning by using precise credit attribution via Shapley-based methods, yielding better performance on complex problems.", "motivation": "Address the inefficiencies in training multi-agent reinforcement learning systems caused by the credit assignment problem, which makes understanding individual agents' contributions challenging.", "method": "Introduces the SHARP framework, which uses Shapley-based hierarchical attribution for decomposing rewards into global, marginal-credit, and tool-process rewards to normalize agent-specific contributions and stabilize training.", "result": "SHARP outperformed state-of-the-art methods with match improvements of 23.66% over single-agent systems and 14.05% over multi-agent systems on various benchmarks.", "conclusion": "SHARP enhances reinforcement learning by providing a robust mechanism for credit attribution, improving training efficiency and effectiveness in multi-agent environments."}}
{"id": "2602.07579", "pdf": "https://arxiv.org/pdf/2602.07579", "abs": "https://arxiv.org/abs/2602.07579", "authors": ["Javidan Abdullayev", "Maxime Devanne", "Cyril Meyer", "Ali Ismail-Fawaz", "Jonathan Weber", "Germain Forestier"], "title": "Enhancing Time Series Classification with Diversity-Driven Neural Network Ensembles", "categories": ["cs.LG"], "comment": "Published in IEEE IJCNN 2025 proceedings. 10 pages, 8 figures", "summary": "Ensemble methods have played a crucial role in achieving state-of-the-art (SOTA) performance across various machine learning tasks by leveraging the diversity of features learned by individual models. In Time Series Classification (TSC), ensembles have proven highly effective whether based on neural networks (NNs) or traditional methods like HIVE-COTE. However most existing NN-based ensemble methods for TSC train multiple models with identical architectures and configurations. These ensembles aggregate predictions without explicitly promoting diversity which often leads to redundant feature representations and limits the benefits of ensembling. In this work, we introduce a diversity-driven ensemble learning framework that explicitly encourages feature diversity among neural network ensemble members. Our approach employs a decorrelated learning strategy using a feature orthogonality loss applied directly to the learned feature representations. This ensures that each model in the ensemble captures complementary rather than redundant information. We evaluate our framework on 128 datasets from the UCR archive and show that it achieves SOTA performance with fewer models. This makes our method both efficient and scalable compared to conventional NN-based ensemble approaches.", "AI": {"tldr": "The paper proposes a diversity-driven ensemble learning framework for Time Series Classification (TSC) that uses feature orthogonality loss to ensure diverse and complementary feature representations, achieving state-of-the-art performance using fewer models.", "motivation": "Existing neural network-based ensemble methods for TSC often fail to explicitly promote diversity among ensemble members, leading to redundant feature representations and limiting their effectiveness.", "method": "The paper introduces feature orthogonality loss applied to learned feature representations to explicitly encourage diversity among ensemble members within a neural network ensemble.", "result": "The approach was tested on 128 UCR archive datasets and demonstrated state-of-the-art performance while requiring fewer models, making it efficient and scalable.", "conclusion": "By promoting diversity in learned features through decorrelated learning, the framework improves the effectiveness and efficiency of neural network ensemble methods for TSC."}}
{"id": "2602.08845", "pdf": "https://arxiv.org/pdf/2602.08845", "abs": "https://arxiv.org/abs/2602.08845", "authors": ["Lazaro F. Torres", "Carlos I. Aldana", "Emmanuel Nu\u00f1o", "Emmanuel Cruz-Zavala"], "title": "Finite-Time Teleoperation of Euler-Lagrange Systems via Energy-Shaping", "categories": ["cs.RO"], "comment": null, "summary": "This paper proposes a family of finite-time controllers for the bilateral teleoperation of fully actuated nonlinear Euler-Lagrange systems. Based on the energy-shaping framework and under the standard assumption of passive interactions with the human and the environment, the controllers ensure that the position error and velocities globally converge to zero in the absence of time delays. In this case, the closed-loop system admits a homogeneous approximation of negative degree, and thus the control objective is achieved in finite-time. The proposed controllers are simple, continuous-time proportional-plus-damping-injection schemes, validated through both simulation and experimental results.", "AI": {"tldr": "Finite-time controllers are proposed for teleoperation systems ensuring rapid convergence of errors under passive interactions, validated by simulations and experiments.", "motivation": "To develop controllers for teleoperation systems to ensure faster convergence while maintaining system stability under passive interactions.", "method": "Energy-shaping framework with proportional-plus-damping-injection schemes ensuring finite-time convergence.", "result": "Position errors and velocities globally converge to zero without time delays; validated by simulations and experiments.", "conclusion": "Proposed controllers achieve finite-time control objectives effectively in teleoperation applications."}}
{"id": "2602.08543", "pdf": "https://arxiv.org/pdf/2602.08543", "abs": "https://arxiv.org/abs/2602.08543", "authors": ["Yutao Zhu", "Xingshuo Zhang", "Maosen Zhang", "Jiajie Jin", "Liancheng Zhang", "Xiaoshuai Song", "Kangzhi Zhao", "Wencong Zeng", "Ruiming Tang", "Han Li", "Ji-Rong Wen", "Zhicheng Dou"], "title": "GISA: A Benchmark for General Information-Seeking Assistant", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.", "AI": {"tldr": "The paper introduces GISA, a new benchmark for evaluating search agents based on authentic queries and structured answers, addressing limitations in existing benchmarks.", "motivation": "Existing benchmarks for search agents often rely on artificial queries and static answers, lacking alignment with real-world needs and comprehensive tasks. This paper aims to provide a more realistic and robust evaluation framework.", "method": "The authors developed GISA, consisting of 373 human-crafted queries, structured answer formats, live subsets with periodic updates, and gold-standard human search trajectories.", "result": "Experiments revealed that current LLMs perform poorly on GISA, achieving only 19.30% exact match score, especially in tasks requiring complex reasoning and planning.", "conclusion": "GISA exposes significant gaps in the ability of search agents and highlights substantial room for improvement in information-seeking technology."}}
{"id": "2602.07574", "pdf": "https://arxiv.org/pdf/2602.07574", "abs": "https://arxiv.org/abs/2602.07574", "authors": ["Wenjie Liu", "Hao Wu", "Xin Qiu", "Yingqi Fan", "Yihan Zhang", "Anhao Zhao", "Yunpu Ma", "Xiaoyu Shen"], "title": "ViCA: Efficient Multimodal LLMs with Vision-Only Cross-Attention", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Modern multimodal large language models (MLLMs) adopt a unified self-attention design that processes visual and textual tokens at every Transformer layer, incurring substantial computational overhead. In this work, we revisit the necessity of such dense visual processing and show that projected visual embeddings are already well-aligned with the language space, while effective vision-language interaction occurs in only a small subset of layers. Based on these insights, we propose ViCA (Vision-only Cross-Attention), a minimal MLLM architecture in which visual tokens bypass all self-attention and feed-forward layers, interacting with text solely through sparse cross-attention at selected layers. Extensive evaluations across three MLLM backbones, nine multimodal benchmarks, and 26 pruning-based baselines show that ViCA preserves 98% of baseline accuracy while reducing visual-side computation to 4%, consistently achieving superior performance-efficiency trade-offs. Moreover, ViCA provides a regular, hardware-friendly inference pipeline that yields over 3.5x speedup in single-batch inference and over 10x speedup in multi-batch inference, reducing visual grounding to near-zero overhead compared with text-only LLMs. It is also orthogonal to token pruning methods and can be seamlessly combined for further efficiency gains. Our code is available at https://github.com/EIT-NLP/ViCA.", "AI": {"tldr": "The paper introduces ViCA, a minimal MLLM architecture using sparse cross-attention at select layers for vision-text interactions, reducing visual computation to 4% while maintaining 98% accuracy and achieving significant inference speedups.", "motivation": "Current multimodal large language models employ dense visual processing, resulting in substantial computational overhead. The necessity of such dense interaction between visual and textual tokens is questioned.", "method": "ViCA processes visual tokens through sparse cross-attention with text at selected layers, bypassing self-attention and feed-forward layers in the Transformer. It simplifies the computation pipeline while retaining baseline accuracy.", "result": "ViCA achieves 98% of baseline accuracy with only 4% visual computation, offers superior performance-efficiency trade-offs, and provides significant inference speedups\u20143.5x for single-batch and 10x for multi-batch inference.", "conclusion": "ViCA dramatically improves efficiency and inference speed for multimodal large language models by reducing visual grounding overhead, ensuring scalability and compatibility with token pruning methods."}}
{"id": "2602.08339", "pdf": "https://arxiv.org/pdf/2602.08339", "abs": "https://arxiv.org/abs/2602.08339", "authors": ["Chengyi Du", "Yazhe Niu", "Dazhong Shen", "Luxin Xu"], "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT", "categories": ["cs.AI", "cs.CV"], "comment": "16 pages 6 figures", "summary": "Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.", "AI": {"tldr": "CoTZero is a new method to improve visual reasoning in vision-language models (VLMs) using dual-stage data synthesis and cognition-aligned training, showing strong semantic understanding and generalization.", "motivation": "Current VLMs struggle with human-like visual reasoning due to reliance on surface correlations rather than structured, logical representations, limiting their capacity for higher-level semantic and causal understanding.", "method": "CoTZero employs a dual-stage data synthesis inspired by neurocognitive processes, incrementally building compositional reasoning structures and enforcing global-to-local hierarchical reasoning. It also integrates Cognitively Coherent Verifiable Rewards (CCVR) during fine-tuning for stepwise reinforcement of logical reasoning.", "result": "CoTZero achieves an 83.33% F1 score on a semantic inconsistency benchmark, demonstrating improved reasoning across in-domain and out-of-domain scenarios. Ablation studies show each component's contribution to better generalization and interpretability.", "conclusion": "CoTZero effectively enhances VLMs' ability to perform compositional and interpretable visual reasoning while aligning more closely with human cognitive processes, addressing key shortcomings in previous models."}}
{"id": "2602.07588", "pdf": "https://arxiv.org/pdf/2602.07588", "abs": "https://arxiv.org/abs/2602.07588", "authors": ["Ziyang Yu", "Wenbing Huang", "Yang Liu"], "title": "Unified Biomolecular Trajectory Generation via Pretrained Variational Bridge", "categories": ["cs.LG"], "comment": "The Fourteenth International Conference on Learning Representations (ICLR 2026)", "summary": "Molecular Dynamics (MD) simulations provide a fundamental tool for characterizing molecular behavior at full atomic resolution, but their applicability is severely constrained by the computational cost. To address this, a surge of deep generative models has recently emerged to learn dynamics at coarsened timesteps for efficient trajectory generation, yet they either generalize poorly across systems or, due to limited molecular diversity of trajectory data, fail to fully exploit structural information to improve generative fidelity. Here, we present the Pretrained Variational Bridge (PVB) in an encoder-decoder fashion, which maps the initial structure into a noised latent space and transports it toward stage-specific targets through augmented bridge matching. This unifies training on both single-structure and paired trajectory data, enabling consistent use of cross-domain structural knowledge across training stages. Moreover, for protein-ligand complexes, we further introduce a reinforcement learning-based optimization via adjoint matching that speeds progression toward the holo state, which supports efficient post-optimization of docking poses. Experiments on proteins and protein-ligand complexes demonstrate that PVB faithfully reproduces thermodynamic and kinetic observables from MD while delivering stable and efficient generative dynamics.", "AI": {"tldr": "The paper proposes Pretrained Variational Bridge (PVB), which leverages a deep generative model for efficient molecular trajectory simulations, offering speed and fidelity compared to traditional MD simulations.", "motivation": "To overcome the computational cost limitations of MD simulations and to address the poor generalization of existing generative models due to limited molecular trajectory diversity.", "method": "The PVB model uses an encoder-decoder framework with noised latent spaces, augmented bridge matching to unify structural training, and reinforcement learning for efficient protein-ligand docking optimization.", "result": "PVB accurately replicates thermodynamic and kinetic properties of molecular dynamics and efficiently generates reliable molecular trajectories.", "conclusion": "PVB enhances both the fidelity and speed of generative molecular dynamics simulations, offering better structural insights and support for protein-ligand studies."}}
{"id": "2602.08963", "pdf": "https://arxiv.org/pdf/2602.08963", "abs": "https://arxiv.org/abs/2602.08963", "authors": ["Katharina Friedl", "No\u00e9mie Jaquier", "Seungyeon Kim", "Jens Lundell", "Danica Kragic"], "title": "Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics", "categories": ["cs.RO", "math.OC"], "comment": "20 pages, 15 figures", "summary": "Model-based controllers can offer strong guarantees on stability and convergence by relying on physically accurate dynamic models. However, these are rarely available for high-dimensional mechanical systems such as deformable objects or soft robots. While neural architectures can learn to approximate complex dynamics, they are either limited to low-dimensional systems or provide only limited formal control guarantees due to a lack of embedded physical structure. This paper introduces a latent control framework based on learned structure-preserving reduced-order dynamics for high-dimensional Lagrangian systems. We derive a reduced tracking law for fully actuated systems and adopt a Riemannian perspective on projection-based model-order reduction to study the resulting latent and projected closed-loop dynamics. By quantifying the sources of modeling error, we derive interpretable conditions for stability and convergence. We extend the proposed controller and analysis to underactuated systems by introducing learned actuation patterns. Experimental results on simulated and real-world systems validate our theoretical investigation and the accuracy of our controllers.", "AI": {"tldr": "The paper introduces a latent control framework based on learned reduced-order dynamics for high-dimensional systems, ensuring stability and convergence through interpretable conditions. Experimental results validate the approach.", "motivation": "High-dimensional mechanical systems like deformable objects or soft robots lack physically accurate dynamic models for model-based controllers. Neural architectures often fail to embed physical structure, limiting formal control guarantees.", "method": "The paper proposes a latent control framework with learned structure-preserving reduced-order dynamics for Lagrangian systems, deriving reduced tracking laws and utilizing model-order reduction with a Riemannian perspective.", "result": "Experimental results validate the theoretical investigations, showing accurate control on simulated and real-world systems.", "conclusion": "The framework provides stability and convergence guarantees for high-dimensional systems through learned reduced-order dynamics, marking improvement in both theory and practical outcomes."}}
{"id": "2602.08548", "pdf": "https://arxiv.org/pdf/2602.08548", "abs": "https://arxiv.org/abs/2602.08548", "authors": ["Xuanliang Zhang", "Dingzirui Wang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che"], "title": "How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location", "categories": ["cs.CL"], "comment": null, "summary": "While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.", "AI": {"tldr": "This paper investigates how Large Language Models (LLMs) understand tables, focusing on the atomic task of cell location, and breaks down the mechanism into three stages: Semantic Binding, Coordinate Localization, and Information Extraction.", "motivation": "The motivation is to understand the opaque mechanisms through which LLMs process and interpret structured tables, which are increasingly utilized for table-related tasks.", "method": "The authors use activation patching and interpretability techniques to analyze the process of table understanding, defining it into three stages and examining how models locate cells and encode column indices.", "result": "Key findings include LLMs using an ordinal mechanism to count delimiters for cell location, encoding column indices in a linear subspace, and applying the same attention heads for multi-cell location tasks.", "conclusion": "This study offers a detailed explanation of how Transformer architectures process tables, providing insights into their internal workings and mechanisms for table understanding."}}
{"id": "2602.07590", "pdf": "https://arxiv.org/pdf/2602.07590", "abs": "https://arxiv.org/abs/2602.07590", "authors": ["Jessica Ka Yi Chiu", "Tom Frode Hansen", "Eivind Magnus Paulsen", "Ole Jakob Mengshoel"], "title": "Automated rock joint trace mapping using a supervised learning model trained on synthetic data generated by parametric modelling", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "35 pages, 12 figures, 2 appendices", "summary": "This paper presents a geology-driven machine learning method for automated rock joint trace mapping from images. The approach combines geological modelling, synthetic data generation, and supervised image segmentation to address limited real data and class imbalance. First, discrete fracture network models are used to generate synthetic jointed rock images at field-relevant scales via parametric modelling, preserving joint persistence, connectivity, and node-type distributions. Second, segmentation models are trained using mixed training and pretraining followed by fine-tuning on real images. The method is tested in box and slope domains using several real datasets. The results show that synthetic data can support supervised joint trace detection when real data are scarce. Mixed training performs well when real labels are consistent (e.g. box-domain), while fine-tuning is more robust when labels are noisy (e.g. slope-domain where labels can be biased, incomplete, and inconsistent). Fully zero-shot prediction from synthetic model remains limited, but useful generalisation is achieved by fine-tuning with a small number of real data. Qualitative analysis shows clearer and more geologically meaningful joint traces than indicated by quantitative metrics alone. The proposed method supports reliable joint mapping and provides a basis for further work on domain adaptation and evaluation.", "AI": {"tldr": "The paper introduces a geology-informed machine learning method combining synthetic data and segmentation models to enhance automated rock joint trace mapping from images.", "motivation": "There is a need to overcome the scarcity of real data and address class imbalance in rock joint trace mapping, while preserving geological features such as joint persistence and connectivity.", "method": "The method integrates synthetic data generation using discrete fracture network models, supervised segmentation model training via mixed training, and fine-tuning real datasets for improved detection.", "result": "Synthetic data proved effective in joint detection when real data are limited. Fine-tuning with minimal real data enhances generalization, achieving clearer and geologically meaningful traces despite noisy labels.", "conclusion": "This approach significantly improves rock joint mapping, showcasing the potential for domain adaptation and offering robust solutions for geologically meaningful trace detection."}}
{"id": "2602.08340", "pdf": "https://arxiv.org/pdf/2602.08340", "abs": "https://arxiv.org/abs/2602.08340", "authors": ["Hoang Dang", "Luan Pham", "Minh Nguyen"], "title": "Effect-Level Validation for Causal Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by graph recovery accuracy alone. Empirically, we study the effect of early exposure to competitive gameplay on short-term retention using real-world game telemetry. We find that many statistically plausible discovery outputs do not admit point-identified causal queries once minimal temporal and semantic constraints are enforced, highlighting identifiability as a critical bottleneck for decision support. When identification is possible, several algorithm families converge to similar, decision-consistent effect estimates despite producing substantially different graph structures, including cases where the direct treatment-outcome edge is absent and the effect is preserved through indirect causal pathways. These converging estimates survive placebo, subsampling, and sensitivity refutation. In contrast, other methods exhibit sporadic admissibility and threshold-sensitive or attenuated effects due to endpoint ambiguity. These results suggest that graph-level metrics alone are inadequate proxies for causal reliability for a given target query. Therefore, trustworthy causal conclusions in telemetry-driven systems require prioritizing admissibility and effect-level validation over causal structural recovery alone.", "AI": {"tldr": "The paper discusses a novel framework for causal discovery in telemetry data, emphasizing the importance of identifiability, stability, and falsification over simple graph recovery accuracy.", "motivation": "To assess the reliability of causal discovery for decision-making in feedback-driven systems with self-selection biases using telemetry data.", "method": "Introduced an effect-centric framework that values identifiability, stability, and falsification, applied to real-world data from competitive gameplay to evaluate effects on short-term retention.", "result": "Identifiability is a key bottleneck for causal queries, as many plausible graphs fail when temporal and semantic constraints are applied. Different methods converge on consistent estimates despite varying graph structures.", "conclusion": "Graph-level metrics are insufficient for reliability; admissibility and effect-level validation must be prioritized in causal discovery for telemetry systems."}}
{"id": "2602.08999", "pdf": "https://arxiv.org/pdf/2602.08999", "abs": "https://arxiv.org/abs/2602.08999", "authors": ["Mouad Abrini", "Mohamed Chetouani"], "title": "CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion", "categories": ["cs.RO"], "comment": null, "summary": "With the increasing integration of robots into daily life, human-robot interaction has become more complex and multifaceted. A critical component of this interaction is Interactive Visual Grounding (IVG), through which robots must interpret human intentions and resolve ambiguity. Existing IVG models generally lack a mechanism to determine when to ask clarification questions, as they implicitly rely on their learned representations. CLUE addresses this gap by converting the VLM's cross-modal attention into an explicit, spatially grounded signal for deciding when to ask. We extract text to image attention maps and pass them to a lightweight CNN to detect referential ambiguity, while a LoRA fine-tuned decoder conducts the dialog and emits grounding location tokens. We train on a real-world interactive dataset for IVG, and a mixed ambiguity set for the detector. With InViG-only supervision, our model surpasses a state-of-the-art method while using parameter-efficient fine-tuning. Similarly, the ambiguity detector outperforms prior baselines. Overall, CLUE turns the internal cross-modal attention of a VLM into an explicit, spatially grounded signal for deciding when to ask. The data and code are publicly available at: mouadabrini.github.io/clue", "AI": {"tldr": "The paper introduces the CLUE model for Interactive Visual Grounding (IVG) which detects when clarification in human-robot interactions is needed by leveraging cross-modal attention and ambiguity detection.", "motivation": "Robots interacting with humans need to resolve ambiguity effectively in human-robot interaction scenarios. Current IVG models lack the ability to determine when clarification questions should be asked, necessitating a new approach.", "method": "CLUE transforms cross-modal attention of visual-language models (VLM) into spatially grounded signals. It employs text-to-image attention maps processed by a lightweight CNN for detecting ambiguity and uses a LoRA fine-tuned decoder for dialog and location grounding.", "result": "The model outperforms a state-of-the-art IVG framework using only parameter-efficient fine-tuning and excels in ambiguity detection compared to existing baselines.", "conclusion": "CLUE provides an efficient and effective solution for enabling robots to identify and respond to ambiguous scenarios in human interaction through spatially grounded signal processing. The code and dataset are publicly available."}}
{"id": "2602.08600", "pdf": "https://arxiv.org/pdf/2602.08600", "abs": "https://arxiv.org/abs/2602.08600", "authors": ["Archchana Sindhujan", "Girish A. Koushik", "Shenbin Qian", "Diptesh Kanojia", "Constantin Or\u0103san"], "title": "Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation", "categories": ["cs.CL"], "comment": "Currently this article is under review for Natural Language Processing Journal", "summary": "Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.", "AI": {"tldr": "This paper addresses challenges in machine translation quality estimation (QE), especially for low-resource languages like Malayalam, by introducing a new dataset with quality remarks and proposing a novel reinforcement learning framework that achieves state-of-the-art results.", "motivation": "The motivation is to enhance machine translation QE models, especially for low-resource languages, by moving beyond scalar scores and incorporating detailed error-analysis while ensuring efficient performance despite limited annotated data.", "method": "This paper introduces a new dataset for English-Malayalam QE and develops ALOPE-RL, a policy-based reinforcement learning framework that uses rewards based on both numeric scores and qualitative remarks to train compact fine-tuned models.", "result": "ALOPE-RL achieves state-of-the-art QE performance for English-Malayalam using compact LLMs, outperforming larger models and encoder-based approaches, despite limited data availability and computational resources.", "conclusion": "Error-aware, policy-based reinforcement learning can greatly enhance QE models for low-resource language pairs, and the proposed methods are efficient and applicable under data and computational constraints."}}
{"id": "2602.07595", "pdf": "https://arxiv.org/pdf/2602.07595", "abs": "https://arxiv.org/abs/2602.07595", "authors": ["Yuanzhi Liang", "Xuan'er Wu", "Yirui Liu", "Yijie Fang", "Yizhen Fan", "Ke Hao", "Rui Li", "Ruiying Liu", "Ziqi Ni", "Peng Yu", "Yanbo Wang", "Haibin Huang", "Qizhen Weng", "Chi Zhang", "Xuelong Li"], "title": "TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Post-training is the decisive step for converting a pretrained video generator into a production-oriented model that is instruction-following, controllable, and robust over long temporal horizons. This report presents a systematical post-training framework that organizes supervised policy shaping, reward-driven reinforcement learning, and preference-based refinement into a single stability-constrained optimization stack. The framework is designed around practical video-generation constraints, including high rollout cost, temporally compounding failure modes, and feedback that is heterogeneous, uncertain, and often weakly discriminative. By treating optimization as a staged, diagnostic-driven process rather than a collection of isolated tricks, the report summarizes a cohesive recipe for improving perceptual fidelity, temporal coherence, and prompt adherence while preserving the controllability established at initialization. The resulting framework provides a clear blueprint for building scalable post-training pipelines that remain stable, extensible, and effective in real-world deployment settings.", "AI": {"tldr": "A systematic post-training framework is proposed to optimize pretrained video generators for production use, focusing on instruction-following, controllability, and robustness over extended periods.", "motivation": "To create a robust and practical post-training method for converting pretrained video generators into tools suitable for real-world, instruction-following, and controllable applications.", "method": "The method integrates supervised policy shaping, reinforcement learning, and preference-based refinement into a staged optimization process tailored for video generation challenges.", "result": "The framework improves perceptual fidelity, temporal coherence, and prompt adherence while maintaining the model's initial controllability.", "conclusion": "The proposed framework offers a stable, scalable, and extensible pathway for building post-training pipelines optimized for real-world video generation tasks."}}
{"id": "2602.08344", "pdf": "https://arxiv.org/pdf/2602.08344", "abs": "https://arxiv.org/abs/2602.08344", "authors": ["Qi Guo", "Jianing Wang", "Deyang Kong", "Xiangyu Xi", "Jianfei Zhang", "Yi Lu", "Jingang Wang", "Wei Wang", "Shikun Zhang", "Wei Ye"], "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration", "categories": ["cs.AI"], "comment": null, "summary": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.", "AI": {"tldr": "The paper proposes Outline-Guided Path Exploration (OPE) to optimize parallel thinking in large reasoning models (LRMs) using reinforcement learning to improve solution diversity and reasoning performance.", "motivation": "The paper aims to address the mutual information bottleneck and limitations in computational resources and effectiveness in existing methods for reasoning in LRMs under the reinforcement learning paradigm.", "method": "Introducing OPE, which involves generating reasoning outlines to partition the solution space, followed by parallel path reasoning optimized via an iterative reinforcement learning strategy.", "result": "The proposed OPE method improved reasoning performance and solution reliability across various mathematical benchmarks and aggregation strategies.", "conclusion": "OPE enhances large reasoning models' ability to discover correct solutions by reducing information redundancy and diversifying exploration paths, contributing to more effective parallel thinking."}}
{"id": "2602.07596", "pdf": "https://arxiv.org/pdf/2602.07596", "abs": "https://arxiv.org/abs/2602.07596", "authors": ["Xi Chen", "Ming Li", "Junxi Li", "Changsheng Li", "Peisong Wang", "Lizhong Ding", "Ye Yuan", "Guoren Wang"], "title": "Astro: Activation-guided Structured Regularization for Outlier-Robust LLM Post-Training Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Weight-only post-training quantization (PTQ) is crucial for efficient Large Language Model (LLM) deployment but suffers from accuracy degradation caused by weight and activation outliers. Existing mitigation strategies often face critical limitations: they either yield insufficient outlier suppression or incur significant deployment inefficiencies, such as inference latency, heavy preprocessing, or reliance on complex operator fusion. To resolve these limitations, we leverage a key insight: over-parameterized LLMs often converge to Flat Minima, implying a vast equivalent solution space where weights can be adjusted without compromising accuracy. Building on this, we propose Astro, an Activation-guided Structured Regularization framework designed to suppress the negative effects of outliers in a hardware-friendly and efficient manner. Leveraging the activation-guided regularization objective, Astro actively reconstructs intrinsically robust weights, aggressively suppressing weight outliers corresponding to high-magnitude activations without sacrificing model accuracy. Crucially, Astro introduces zero inference latency and is orthogonal to mainstream quantization methods like GPTQ. Extensive experiments show that Astro achieves highly competitive performance; notably, on LLaMA-2-7B, it achieves better performance than complex learning-based rotation methods with almost 1/3 of the quantization time.", "AI": {"tldr": "Astro is a new framework designed to address accuracy degradation in weight-only post-training quantization for LLMs caused by weight and activation outliers. It achieves efficient and accurate quantization with no additional inference latency.", "motivation": "To resolve accuracy degradation and deployment inefficiencies in LLM deployment caused by weight and activation outliers during post-training quantization.", "method": "Astro utilizes an Activation-guided Structured Regularization framework which reconstructs weights to suppress outliers by leveraging the Flat Minima property of overparameterized LLMs. It works without introducing inference latency and can complement other quantization methods.", "result": "Astro achieves hardware-friendly and highly competitive quantization in LLMs, demonstrating superiority to complex rotation methods with significantly reduced quantization time, particularly achieving high performance in experiments with LLaMA-2-7B.", "conclusion": "Astro effectively mitigates the limitations of existing quantization methods, enabling weight-only quantization with efficient outlier suppression, hardware compatibility, and maintained model accuracy."}}
{"id": "2602.09002", "pdf": "https://arxiv.org/pdf/2602.09002", "abs": "https://arxiv.org/abs/2602.09002", "authors": ["Zilin Fang", "Anxing Xiao", "David Hsu", "Gim Hee Lee"], "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)", "summary": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io", "AI": {"tldr": "The paper proposes a social robot navigation framework that integrates geometric planning with contextual social reasoning using a fine-tuned vision-language model for socially optimized paths.", "motivation": "Current approaches to robot navigation may avoid collisions but often fail to respect social norms or ongoing human activities, necessitating a method that incorporates social reasoning.", "method": "The system extracts obstacles and human dynamics, generates feasible candidate paths, and uses a fine-tuned vision-language model to evaluate these paths based on socially grounded expectations.", "result": "Experiments in four navigation contexts show the method achieves the best performance with minimal personal space violations, reduced pedestrian-facing time, and no intrusions into social zones.", "conclusion": "This framework successfully integrates social reasoning into robot navigation, enabling real-time adaptation and optimized performance in human-robot interactions."}}
{"id": "2602.08607", "pdf": "https://arxiv.org/pdf/2602.08607", "abs": "https://arxiv.org/abs/2602.08607", "authors": ["Ziyang Cheng", "Yuhao Wang", "Heyang Liu", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\\times$--10$\\times$ decoding speedup and reduces first-chunk latency by 34\\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.", "AI": {"tldr": "The paper introduces VocalNet-MDM, a non-autoregressive (NA) speech large language model based on Masked Diffusion Modeling, offering faster and more efficient generation for speech interaction.", "motivation": "Current autoregressive speech LLMs face limitations in generation efficiency and are hindered by exposure bias.", "method": "The authors propose Hierarchical Block-wise Masking for training-inference alignment and Iterative Self-Distillation to reduce refinement steps, enabling low-latency streaming speech interaction.", "result": "VocalNet-MDM achieves significant decoding speedups (3.7\u00d7\u201310\u00d7) and reduces latency by 34% while maintaining competitive recognition accuracy and achieving state-of-the-art text and speech quality.", "conclusion": "Masked Diffusion Modeling demonstrates promise as an efficient, scalable alternative paradigm for speech LLMs, providing low-latency solutions without sacrificing performance."}}
{"id": "2602.07605", "pdf": "https://arxiv.org/pdf/2602.07605", "abs": "https://arxiv.org/abs/2602.07605", "authors": ["Hulingxiao He", "Zijun Geng", "Yuxin Peng"], "title": "Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "Published as a conference paper at ICLR 2026. The models are available at https://huggingface.co/collections/StevenHH2000/fine-r1", "summary": "Any entity in the visual world can be hierarchically grouped based on shared characteristics and mapped to fine-grained sub-categories. While Multi-modal Large Language Models (MLLMs) achieve strong performance on coarse-grained visual tasks, they often struggle with Fine-Grained Visual Recognition (FGVR). Adapting general-purpose MLLMs to FGVR typically requires large amounts of annotated data, which is costly to obtain, leaving a substantial performance gap compared to contrastive CLIP models dedicated for discriminative tasks. Moreover, MLLMs tend to overfit to seen sub-categories and generalize poorly to unseen ones. To address these challenges, we propose Fine-R1, an MLLM tailored for FGVR through an R1-style training framework: (1) Chain-of-Thought Supervised Fine-tuning, where we construct a high-quality FGVR CoT dataset with rationales of \"visual analysis, candidate sub-categories, comparison, and prediction\", transition the model into a strong open-world classifier; and (2) Triplet Augmented Policy Optimization, where Intra-class Augmentation mixes trajectories from anchor and positive images within the same category to improve robustness to intra-class variance, while Inter-class Augmentation maximizes the response distinction conditioned on images across sub-categories to enhance discriminative ability. With only 4-shot training, Fine-R1 outperforms existing general MLLMs, reasoning MLLMs, and even contrastive CLIP models in identifying both seen and unseen sub-categories, showing promise in working in knowledge-intensive domains where gathering expert annotations for all sub-categories is arduous. Code is available at https://github.com/PKU-ICST-MIPL/FineR1_ICLR2026.", "AI": {"tldr": "Fine-R1, a tailored MLLM, addresses the data scarcity challenge for Fine-Grained Visual Recognition (FGVR) using a novel R1-style training framework, showing superior performance even with limited annotated data.", "motivation": "MLLMs excel in coarse-grained visual tasks but face challenges with FGVR due to data annotation issues and poor generalization to unseen categories, prompting the need for training frameworks that overcome these limitations.", "method": "Fine-R1 employs two strategies: Chain-of-Thought Supervised Fine-tuning constructs FGVR datasets with visual analysis rationales, and Triplet Augmented Policy Optimization uses intra-class and inter-class augmentations to enhance robustness and discriminative ability.", "result": "Fine-R1 achieves superior FGVR performance, surpassing existing models including CLIP in identifying both seen and unseen sub-categories, showing promise in areas requiring expert annotation.", "conclusion": "Fine-R1 provides an effective solution for adapting MLLMs to FGVR, overcoming challenges such as data scarcity and poor generalization, offering strong potential for future applications in knowledge-intensive domains."}}
{"id": "2602.08353", "pdf": "https://arxiv.org/pdf/2602.08353", "abs": "https://arxiv.org/abs/2602.08353", "authors": ["Zhang Jiasheng", "Li Zhangpin", "Wang Mingzhe", "Shao Jie", "Cui Jiangtao", "Li Hui"], "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs", "categories": ["cs.AI"], "comment": "13 pages, 11 figures", "summary": "Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.", "AI": {"tldr": "This paper identifies biases and limitations in current temporal knowledge graph (TKG) benchmarks and introduces a new, bias-corrected benchmark to better evaluate TKG evolution models.", "motivation": "The motivation is to address inherent biases and limitations in existing TKG benchmarks that allow models to exploit shortcuts, resulting in incorrectly high performance scores without truly capturing temporal information.", "method": "The authors analyze biases in current datasets and propose a new TKG evolution benchmark with bias-corrected datasets and novel tasks that align closely with temporal evolution processes.", "result": "The newly introduced benchmark mitigates dataset biases and incorporates tasks aimed at improving the assessment of a model's ability to learn TKG evolution effectively.", "conclusion": "Using this benchmark will enable a fairer and more meaningful evaluation of TKG models and contribute toward advancing understanding of knowledge graph evolution."}}
{"id": "2602.07599", "pdf": "https://arxiv.org/pdf/2602.07599", "abs": "https://arxiv.org/abs/2602.07599", "authors": ["Mehryar Mohri"], "title": "Rational Transductors", "categories": ["cs.LG"], "comment": null, "summary": "Standard Transformers excel at semantic modeling but struggle with\n  rigid sequential logic and state tracking. Theoretical work\n  establishes that self-attention is limited to $\\AC^0$ (under hard\n  attention) or $\\TC^0$ (under soft attention), complexity classes\n  that often fail to support robust length generalization on\n  sequential problems without intermediate chain-of-thought. In this\n  work, we introduce \\emph{Rational Transductors}, a dual-stream\n  architecture that augments the Transformer with a matrix-valued\n  recurrence derived from Weighted Finite Automata (WFA). By\n  injecting rational state information into the attention mechanism\n  via a \\emph{Deep Rational Injection} scheme, our framework strictly\n  generalizes the expressive power of Transformers to capture all\n  Regular Languages, $\\NC^1$-complete problems (such as Boolean\n  Formula Evaluation), and fundamental separations like Parity and\n  Modular Counting, while preserving $O(L + \\log T)$ parallel time\n  complexity. We ground the architecture in a rigorous learning\n  theory: we prove that \\emph{Random Rational Features} act as a\n  universal basis for sequential dependencies, justifying our\n  initialization strategy, while establishing that the\n  \\emph{Differentiable Rational Feature} regime is necessary to close\n  the representational compactness gap. Theoretical analysis and\n  empirical results demonstrate that Rational Transductors solve the\n  \"Regular Gap,\" enabling robust length generalization on algorithmic\n  tasks where standard Transformers fail, without the sequential\n  computational bottlenecks of traditional RNNs.", "AI": {"tldr": "The paper introduces Rational Transductors, a novel architecture combining Weighted Finite Automata with Transformers, solving limitations in sequential logic and robust generalization.", "motivation": "Standard Transformers struggle with rigid sequential logic, state tracking, and length generalization due to limitations in the complexity classes they operate in.", "method": "The authors enhance Transformers by incorporating matrix-valued recurrence from Weighted Finite Automata, coupled with a new Deep Rational Injection mechanism. This extends the expressive power and preserves computational efficiency.", "result": "Rational Transductors successfully address the 'Regular Gap,' achieving improved length generalization and expressive capabilities over standard Transformers.", "conclusion": "The proposed architecture offers a theoretical and practical framework for overcoming Transformers' limitations on sequential tasks, combining the strengths of Transformers with state-tracking algorithms like WFA."}}
{"id": "2602.09013", "pdf": "https://arxiv.org/pdf/2602.09013", "abs": "https://arxiv.org/abs/2602.09013", "authors": ["Hongyi Chen", "Tony Dong", "Tiancheng Wu", "Liquan Wang", "Yash Jangir", "Yaru Niu", "Yufei Ye", "Homanga Bharadhwaj", "Zackory Erickson", "Jeffrey Ichnowski"], "title": "Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.", "AI": {"tldr": "VIDEOMANIP is a framework enabling dexterous manipulation training for robotic hands using only RGB human videos without specialized hardware.", "motivation": "Address limitations in scalable robotic hand manipulation by avoiding reliance on specialized devices and embracing RGB video-based training.", "method": "VIDEOMANIP reconstructs robot-object trajectories by estimating human hand poses and object meshes from videos and synthesizes diverse training data using hand-object contact optimization.", "result": "In simulation, achieved a 70.25% success rate with Inspire Hand; in real-world tasks using LEAP Hand, surpassed existing methods' results by 15.87% with a 62.86% success rate.", "conclusion": "Learned manipulation policies from human RGB videos show promising performance for scalable robotic grasping and manipulation tasks."}}
{"id": "2602.08625", "pdf": "https://arxiv.org/pdf/2602.08625", "abs": "https://arxiv.org/abs/2602.08625", "authors": ["Muhammad Naufil"], "title": "Do Multilingual LLMs have specialized language heads?", "categories": ["cs.CL"], "comment": null, "summary": "Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.", "AI": {"tldr": "The paper investigates the presence of specialized language attention heads in multilingual LLMs to streamline their deployment for specific languages.", "motivation": "Multilingual LLMs can process multiple languages, but their full language coverage introduces inefficiencies in targeted deployments. Current research lacks understanding of language-specialized components in these models.", "method": "The study analyzes whether multilingual LLMs contain specialized language attention heads and explores removing language-specific heads of unwanted languages to examine performance impacts.", "result": "The paper identifies key insights that could help optimize multilingual models by reducing complexity without affecting performance for intended languages.", "conclusion": "Efficient deployment strategies for multilingual LLMs can benefit from removing language-specific components, making the models lightweight while preserving accuracy in focused languages."}}
{"id": "2602.07608", "pdf": "https://arxiv.org/pdf/2602.07608", "abs": "https://arxiv.org/abs/2602.07608", "authors": ["Yixin Chen", "Ziyu Su", "Lingbin Meng", "Elshad Hasanov", "Wei Chen", "Anil Parwani", "M. Khalid Khan Niazi"], "title": "HistoMet: A Pan-Cancer Deep Learning Framework for Prognostic Prediction of Metastatic Progression and Site Tropism from Primary Tumor Histopathology", "categories": ["cs.CV"], "comment": null, "summary": "Metastatic Progression remains the leading cause of cancer-related mortality, yet predicting whether a primary tumor will metastasize and where it will disseminate directly from histopathology remains a fundamental challenge. Although whole-slide images (WSIs) provide rich morphological information, prior computational pathology approaches typically address metastatic status or site prediction as isolated tasks, and do not explicitly model the clinically sequential decision process of metastatic risk assessment followed by downstream site-specific evaluation. To address this research gap, we present a decision-aware, concept-aligned MIL framework, HistoMet, for prognostic metastatic outcome prediction from primary tumor WSIs. Our proposed framework adopts a two-module prediction pipeline in which the likelihood of metastatic progression from the primary tumor is first estimated, followed by conditional prediction of metastatic site for high-risk cases. To guide representation learning and improve clinical interpretability, our framework integrates linguistically defined and data-adaptive metastatic concepts through a pretrained pathology vision-language model. We evaluate HistoMet on a multi-institutional pan-cancer cohort of 6504 patients with metastasis follow-up and site annotations. Under clinically relevant high-sensitivity screening settings (95 percent sensitivity), HistoMet significantly reduces downstream workload while maintaining high metastatic risk recall. Conditional on metastatic cases, HistoMet achieves a macro F1 of 74.6 with a standard deviation of 1.3 and a macro one-vs-rest AUC of 92.1. These results demonstrate that explicitly modeling clinical decision structure enables robust and deployable prognostic prediction of metastatic progression and site tropism directly from primary tumor histopathology.", "AI": {"tldr": "This paper introduces HistoMet, a computational pathology framework, for predicting metastatic progression and site tropism from primary tumor histopathology using a decision-aware approach.", "motivation": "The paper aims to address the challenge of predicting metastatic progression and dissemination sites directly from histopathology, which is crucial for improving cancer prognosis and treatment planning.", "method": "The framework, HistoMet, uses a two-module pipeline for sequential prediction: first estimating metastatic progression risk, then predicting specific metastatic sites for high-risk cases, guided by a pathology vision-language model.", "result": "HistoMet minimizes workload while maintaining high recall at 95% sensitivity and achieves strong performance metrics, including a macro one-vs-rest AUC of 92.1 conditional on metastatic cases.", "conclusion": "Explicitly modeling the clinical decision-making process enhances prediction accuracy and clinical applicability for prognostic evaluation in cancer metastasis."}}
{"id": "2602.08354", "pdf": "https://arxiv.org/pdf/2602.08354", "abs": "https://arxiv.org/abs/2602.08354", "authors": ["Zixuan Huang", "Xin Xia", "Yuxi Ren", "Jianbin Zheng", "Xuanda Wang", "Zhixia Zhang", "Hongyan Xie", "Songshi Liang", "Zehao Chen", "Xuefeng Xiao", "Fuzhen Zhuang", "Jianxin Li", "Yikun Ban", "Deqing Wang"], "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.", "AI": {"tldr": "The paper addresses inefficiencies in large reasoning models (LRMs) caused by overly long reasoning chains and introduces SAGE, a novel sampling paradigm for more efficient reasoning.", "motivation": "To enhance the efficiency and accuracy of LRMs by overcoming issues like redundancy and delays caused by long reasoning chains.", "method": "The authors propose SAGE, a self-aware guided reasoning paradigm, and integrate it with group-based reinforcement learning (SAGE-RL) to optimize reasoning processes.", "result": "SAGE and SAGE-RL significantly improve reasoning accuracy and computational efficiency in LRMs, based on evaluations on challenging mathematical benchmarks.", "conclusion": "Current LRMs implicitly know when to stop reasoning, and leveraging this through the SAGE paradigm boosts efficiency and accuracy for complex tasks."}}
{"id": "2602.07602", "pdf": "https://arxiv.org/pdf/2602.07602", "abs": "https://arxiv.org/abs/2602.07602", "authors": ["Gabriel Stella", "Dmitri Loguinov"], "title": "Object-Oriented Transition Modeling with Inductive Logic Programming", "categories": ["cs.LG"], "comment": "46 pages, 26 figures", "summary": "Building models of the world from observation, i.e., induction, is one of the major challenges in machine learning. In order to be useful, models need to maintain accuracy when used in novel situations, i.e., generalize. In addition, they should be easy to interpret and efficient to train. Prior work has investigated these concepts in the context of object-oriented representations inspired by human cognition. In this paper, we develop a novel learning algorithm that is substantially more powerful than these previous methods. Our thorough experiments, including ablation tests and comparison with neural baselines, demonstrate a significant improvement over the state-of-the-art.", "AI": {"tldr": "The paper introduces a novel learning algorithm for building world models through induction, outperforming existing methods in accuracy and generalization based on comprehensive experiments.", "motivation": "The paper aims to address the challenges of building accurate, generalized, and interpretable models from observation for machine learning tasks.", "method": "The researchers propose a new learning algorithm inspired by object-oriented representations, integrated with tests such as ablation studies and comparisons with neural network baselines.", "result": "Experimental results show a significant performance improvement over state-of-the-art methods.", "conclusion": "The paper demonstrates the algorithm's efficacy in improving machine learning models' generalization and interpretability while outperforming prior approaches."}}
{"id": "2602.09017", "pdf": "https://arxiv.org/pdf/2602.09017", "abs": "https://arxiv.org/abs/2602.09017", "authors": ["Zichen Jeff Cui", "Omar Rayyan", "Haritheja Etukuru", "Bowen Tan", "Zavier Andrianarivo", "Zicheng Teng", "Yihang Zhou", "Krish Mehta", "Nicholas Wojno", "Kevin Yuanbo Wu", "Manan H Anjaria", "Ziyuan Wu", "Manrong Mao", "Guangxun Zhang", "Binit Shah", "Yejin Kim", "Soumith Chintala", "Lerrel Pinto", "Nur Muhammad Mahi Shafiullah"], "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/", "AI": {"tldr": "The paper introduces Contact-Anchored Policies (CAP), leveraging physical contact points instead of language prompts for robotic control, and improves manipulation performance through a modular approach and simulation-based iteration.", "motivation": "Robotic manipulation often fails to adequately use abstract language prompts, necessitating a more concrete method for achieving robust physical understanding.", "method": "CAP replaces language with physical contact points for conditioning. It employs modular utility models and uses EgoGym, a simulation tool, for iterative model refinement to identify issues before real-world deployment.", "result": "CAP generalizes well across environments and embodiments using only 23 hours of demonstration data. It shows a 56% improvement over state-of-the-art vision-language-conditioned models in zero-shot evaluations.", "conclusion": "Physical contact conditioning and simulation-based iteration improve robotic manipulation performance and generalization, offering a robust alternative to language-based prompts. The project resources will be publicly available."}}
{"id": "2602.08658", "pdf": "https://arxiv.org/pdf/2602.08658", "abs": "https://arxiv.org/abs/2602.08658", "authors": ["Mingzi Cao", "Xingwei Tan", "Mahmud Akhter", "Marco Valentino", "Maria Liakata", "Xi Wang", "Nikolaos Aletras"], "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.", "AI": {"tldr": "The paper investigates the reasoning capabilities of Large Language Models (LLMs) through deduction, induction, and abduction, introducing new datasets and methods to improve generalization.", "motivation": "To explore how fundamental reasoning paradigms (deduction, induction, abduction) influence the reasoning behavior of LLMs and improve their generalization.", "method": "The authors collected reasoning datasets focused on core paradigms, experimented with methods like fine-tuning and model architecture transformations, and evaluated these on realistic out-of-domain tasks.", "result": "The study demonstrated substantial performance improvements (up to 14.60% gains) in generalizability on practical real-world knowledge tasks.", "conclusion": "Leveraging reasoning paradigms enhances LLMs, leading to improved reasoning capabilities and better performance on realistic tasks."}}
{"id": "2602.07625", "pdf": "https://arxiv.org/pdf/2602.07625", "abs": "https://arxiv.org/abs/2602.07625", "authors": ["Binxiao Xu", "Junyu Feng", "Xiaopeng Lin", "Haodong Li", "Zhiyuan Feng", "Bohan Zeng", "Shaolin Lu", "Ming Lu", "Qi She", "Wentao Zhang"], "title": "AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal understanding of advertising videos is essential for interpreting the intricate relationship between visual storytelling and abstract persuasion strategies. However, despite excelling at general search, existing agents often struggle to bridge the cognitive gap between pixel-level perception and high-level marketing logic. To address this challenge, we introduce AD-MIR, a framework designed to decode advertising intent via a two-stage architecture. First, in the Structure-Aware Memory Construction phase, the system converts raw video into a structured database by integrating semantic retrieval with exact keyword matching. This approach prioritizes fine-grained brand details (e.g., logos, on-screen text) while dynamically filtering out irrelevant background noise to isolate key protagonists. Second, the Structured Reasoning Agent mimics a marketing expert through an iterative inquiry loop, decomposing the narrative to deduce implicit persuasion tactics. Crucially, it employs an evidence-based self-correction mechanism that rigorously validates these insights against specific video frames, automatically backtracking when visual support is lacking. Evaluation on the AdsQA benchmark demonstrates that AD-MIR achieves state-of-the-art performance, surpassing the strongest general-purpose agent, DVD, by 1.8% in strict and 9.5% in relaxed accuracy. These results underscore that effective advertising understanding demands explicitly grounding abstract marketing strategies in pixel-level evidence. The code is available at https://github.com/Little-Fridge/AD-MIR.", "AI": {"tldr": "AD-MIR is a framework designed to interpret advertising videos by bridging the gap between pixel-level perception and high-level marketing logic, achieving state-of-the-art results on AdsQA.", "motivation": "The paper aims to address the challenge of understanding advertising videos by bridging the cognitive gap between raw pixel-level data and abstract marketing strategies, which existing agents struggle to accomplish.", "method": "The two-stage AD-MIR framework involves (1) Structure-Aware Memory Construction to organize raw video data into a structured database by integrating semantic retrieval and fine-grained brand detail prioritization; and (2) a Structured Reasoning Agent mimicking a marketing expert through iterative inquiries and employing evidence-based self-correction to validate insights against video frames.", "result": "Evaluation on the AdsQA benchmark shows that AD-MIR outperforms the strongest existing agent, surpassing it by 1.8% in strict accuracy and 9.5% in relaxed accuracy.", "conclusion": "Effective advertising video understanding requires grounding abstract marketing strategies in pixel-level evidence, and the AD-MIR framework offers a state-of-the-art solution to this challenge."}}
{"id": "2602.08362", "pdf": "https://arxiv.org/pdf/2602.08362", "abs": "https://arxiv.org/abs/2602.08362", "authors": ["Chunxi Ji", "Adnan Darwiche"], "title": "Circuit Representations of Random Forests with Applications to XAI", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.", "AI": {"tldr": "The paper proposes an efficient approach to compile random forest classifiers into circuits, facilitates the computation of decision explanations, and develops algorithms for decision robustness and flipping pathways.", "motivation": "The motivation is to improve the efficiency and usability of Random Forest classifiers in explaining decisions, which is crucial in AI interpretability and understanding model behavior.", "method": "The paper introduces a novel method to compile random forest classifiers into circuits, enabling efficient computation for explanation tasks and robustness analysis. Additionally, algorithms for robustness and decision flipping were developed.", "result": "Empirical results demonstrate that the proposed approach outperforms existing methods in efficiency. It was successfully applied to enumerate explanations, calculate robustness, and determine the shortest paths to decision flipping.", "conclusion": "The proposed framework provides an effective and computationally advanced solution for model interpretability, offering practical tools for evaluating and explaining decisions made by random forest classifiers."}}
{"id": "2602.07603", "pdf": "https://arxiv.org/pdf/2602.07603", "abs": "https://arxiv.org/abs/2602.07603", "authors": ["Woojin Cho", "Junghwan Park"], "title": "Escaping Spectral Bias without Backpropagation: Fast Implicit Neural Representations with Extreme Learning Machines", "categories": ["cs.LG", "math.NA"], "comment": null, "summary": "Training implicit neural representations (INRs) to capture fine-scale details typically relies on iterative backpropagation and is often hindered by spectral bias when the target exhibits highly non-uniform frequency content. We propose ELM-INR, a backpropagation-free INR that decomposes the domain into overlapping subdomains and fits each local problem using an Extreme Learning Machine (ELM) in closed form, replacing iterative optimization with stable linear least-squares solutions. This design yields fast and numerically robust reconstruction by combining local predictors through a partition of unity. To understand where approximation becomes difficult under fixed local capacity, we analyze the method from a spectral Barron norm perspective, which reveals that global reconstruction error is dominated by regions with high spectral complexity. Building on this insight, we introduce BEAM, an adaptive mesh refinement strategy that balances spectral complexity across subdomains to improve reconstruction quality in capacity-constrained regimes.", "AI": {"tldr": "The paper introduces ELM-INR, a backpropagation-free approach for training implicit neural representations, combined with BEAM's mesh refinement strategy to address spectral bias and enable efficient reconstruction of complex data.", "motivation": "The motivation is to overcome challenges in training implicit neural representations, addressing spectral bias and improving reconstruction quality for data with non-uniform frequency content.", "method": "The ELM-INR method incorporates domain decomposition into subdomains solved with Extreme Learning Machines, complemented by BEAM for adaptive mesh refinement.", "result": "The approach achieves fast reconstruction, numerical robustness, and improved reconstruction quality by balancing spectral complexity across subdomains.", "conclusion": "ELM-INR and BEAM offer effective solutions for spectral bias in capacity-constrained regimes, enabling accurate and efficient data reconstruction."}}
{"id": "2602.09018", "pdf": "https://arxiv.org/pdf/2602.09018", "abs": "https://arxiv.org/abs/2602.09018", "authors": ["Amir Mallak", "Alaa Maalouf"], "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\\rightarrow$ urban and day $\\rightarrow$ night ($\\sim 31\\%$ each); actor swaps $\\sim 10\\%$, moderate rain $\\sim 7\\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\\% \\rightarrow 70.1\\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.", "AI": {"tldr": "This paper focuses on Out-of-Distribution (OOD) robustness in autonomous driving by decomposing environments into critical factors and analyzing their effects, testing various policy architectures such as ViT, CNN, and Foundation Models (FMs). It provides detailed insights into performance under controlled environment changes and presents strategies to build robust driving policies.", "motivation": "The motivation is to address the challenge of OOD robustness in autonomous driving by breaking down and systematically analyzing factors that disrupt policy performance, aiming to provide clear guidelines for improved robustness.", "method": "The study decomposes environments into five axes (scene, season, weather, time, and agent mix) and evaluates policies under controlled $k$-factor perturbations. Models like CNNs, ViTs, and FM-integrated policies are tested under different diversity, scale, and temporal contexts. OOD impacts are measured and performance improvements are designed.", "result": "ViT policies have superior OOD robustness compared to CNNs and FMs improve performance further at a latency cost. Naive temporal inputs don't outperform the best single-frame models. Critical OOD factors such as urban/social shifts and time-related changes significantly degrade performance. FM-policy models prove resistant under three simultaneous environment changes.", "conclusion": "The key takeaway is that actionable design strategies can significantly enhance OOD robustness, using elements like scalable and diverse data, targeted training in challenging scenarios, and model architectures like Foundation Models and ViTs for improved performance in autonomous vehicles."}}
{"id": "2602.08672", "pdf": "https://arxiv.org/pdf/2602.08672", "abs": "https://arxiv.org/abs/2602.08672", "authors": ["Clemencia Siro", "Pourya Aliannejadi", "Mohammad Aliannejadi"], "title": "Learning to Judge: LLMs Designing and Applying Evaluation Rubrics", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at EACL 2026 Findings", "summary": "Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.", "AI": {"tldr": "This paper investigates whether large language models (LLMs) can design and apply their own evaluation rubrics.", "motivation": "Current human-defined rubrics for evaluating LLM outputs are often static and misaligned with how LLMs internally perceive language quality.", "method": "The researchers introduced and tested GER-Eval, where LLMs generate and use their evaluation rubrics. They assessed these rubrics' semantic coherence, scoring reliability, and alignment with human criteria.", "result": "LLMs generated interpretable, task-aware rubrics and applied them reliably, though scoring accuracy declined in factually or knowledge-intensive tasks. Closed-source models like GPT-4 showed better reliability and agreement than open-weight models like Llama.", "conclusion": "LLM evaluation is a linguistic capability, consistent within individual models but fragmented across different ones. Advancements are needed to harmonize human and LLM evaluation methods."}}
{"id": "2602.07643", "pdf": "https://arxiv.org/pdf/2602.07643", "abs": "https://arxiv.org/abs/2602.07643", "authors": ["Yichi Zhang", "Feiyang Xiao", "Le Xue", "Wenbo Zhang", "Gang Feng", "Chenguang Zheng", "Yuan Qi", "Yuan Cheng", "Zixin Hu"], "title": "Uncovering Modality Discrepancy and Generalization Illusion for General-Purpose 3D Medical Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "While emerging 3D medical foundation models are envisioned as versatile tools with offer general-purpose capabilities, their validation remains largely confined to regional and structural imaging, leaving a significant modality discrepancy unexplored. To provide a rigorous and objective assessment, we curate the UMD dataset comprising 490 whole-body PET/CT and 464 whole-body PET/MRI scans ($\\sim$675k 2D images, $\\sim$12k 3D organ annotations) and conduct a thorough and comprehensive evaluation of representative 3D segmentation foundation models. Through intra-subject controlled comparisons of paired scans, we isolate imaging modality as the primary independent variable to evaluate model robustness in real-world applications. Our evaluation reveals a stark discrepancy between literature-reported benchmarks and real-world efficacy, particularly when transitioning from structural to functional domains. Such systemic failures underscore that current 3D foundation models are far from achieving truly general-purpose status, necessitating a paradigm shift toward multi-modal training and evaluation to bridge the gap between idealized benchmarking and comprehensive clinical utility. This dataset and analysis establish a foundational cornerstone for future research to develop truly modality-agnostic medical foundation models.", "AI": {"tldr": "The study reveals limitations in current 3D medical foundation models when applied across imaging modalities, highlighting the need for multi-modal training and evaluation.", "motivation": "Medical foundation models exhibit a capability discrepancy across imaging modalities, prompting the need for robust validation and analysis.", "method": "Conducted a comprehensive evaluation using the UMD dataset with intra-subject controlled comparisons of paired PET/CT and PET/MRI scans.", "result": "Revealed discrepancies between reported benchmarks and real-world efficacy, especially when transitioning between structural and functional imaging modalities.", "conclusion": "Current models lack general-purpose applicability, necessitating multi-modal training and evaluation approaches for medical imaging."}}
{"id": "2602.08369", "pdf": "https://arxiv.org/pdf/2602.08369", "abs": "https://arxiv.org/abs/2602.08369", "authors": ["Xin Zhang", "Kailai Yang", "Chenyue Li", "Hao Li", "Qiyu Wei", "Jun'ichi Tsujii", "Sophia Ananiadou"], "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.", "AI": {"tldr": "The paper proposes MemAdapter, a unified memory retrieval framework for LLM-based agents that enables efficient cross-paradigm alignment and fusion.", "motivation": "The study addresses the limitations in existing agent memory systems, which are isolated within specific paradigms, leading to poor generalization and fusion across different memory mechanisms.", "method": "MemAdapter employs a two-stage training strategy: (1) training a generative subgraph retriever from a unified memory space, and (2) adapting the retriever to new paradigms through a lightweight alignment module using contrastive learning.", "result": "Experiments on public benchmarks show that MemAdapter outperforms five other systems across three paradigms, completing alignment in just 13 minutes on a single GPU with significantly reduced computational cost.", "conclusion": "MemAdapter demonstrates its potential as a flexible, efficient, and plug-and-play solution for unifying and enhancing agent memory systems across paradigms."}}
{"id": "2602.07616", "pdf": "https://arxiv.org/pdf/2602.07616", "abs": "https://arxiv.org/abs/2602.07616", "authors": ["Juntong Wu", "Jialiang Cheng", "Fuyu Lv", "Ou Dan", "Li Yuan"], "title": "SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models", "categories": ["cs.LG", "cs.AI"], "comment": "Published as a conference paper at ICLR 2026", "summary": "Mixture-of-Experts (MoE) architectures employ sparse activation to deliver faster training and inference with higher accuracy than dense LLMs. However, in production serving, MoE models require batch inference to optimize hardware efficiency, which may cause excessive expert activation and thus slow the memory-bound decoding stage. To address the fundamental tension between batch decoding and expert sparsity, we present SERE, a Similarity-based Expert Re-routing method for Efficient batch decoding in MoE models. SERE dynamically reduces the number of active experts in an input-aware manner by re-routing tokens from secondary experts to their most similar primary counterparts. It also leverages similarity patterns to identify and preserve critical experts, thereby preventing capability loss. Notably, SERE avoids static expert pruning or merging, instead enabling dynamic expert skipping based on batch-level expert redundancy. Additionally, we provide an efficient custom CUDA kernel for SERE, enabling plug-and-play use in vLLM with only a single-line code change. Extensive experiments on various complex reasoning benchmarks demonstrate that SERE achieves up to 2.0x speedup with minimal quality loss, providing a practical solution for cost-efficient and latency-sensitive large-scale MoE deployment. Code implementation of SERE can be found in https://github.com/JL-Cheng/SERE.", "AI": {"tldr": "The paper introduces SERE, a method to optimize the efficiency of Mixture-of-Experts (MoE) models during batch decoding, achieving up to 2.0x speedup with minimal quality trade-offs.", "motivation": "The need for efficient and hardware-optimized batch inference in MoE models for production usage, while addressing the inefficiencies caused by excessive expert activations during batch decoding.", "method": "SERE uses a similarity-based approach to reroute tokens, reducing the active experts dynamically and avoiding static expert pruning. It also leverages a custom CUDA kernel and integrates easily into vLLM systems.", "result": "Experiments demonstrate that SERE achieves significant speedup (up to 2.0x) in batch decoding while maintaining nearly the same model quality.", "conclusion": "SERE provides a practical, cost-efficient, and latency-sensitive solution for deploying large-scale MoE models effectively, ensuring both speed and performance."}}
{"id": "2602.09021", "pdf": "https://arxiv.org/pdf/2602.09021", "abs": "https://arxiv.org/abs/2602.09021", "authors": ["Checheng Yu", "Chonghao Sima", "Gangcheng Jiang", "Hai Zhang", "Haoguang Mai", "Hongyang Li", "Huijie Wang", "Jin Chen", "Kaiyang Wu", "Li Chen", "Lirui Zhao", "Modi Shi", "Ping Luo", "Qingwen Bu", "Shijia Peng", "Tianyu Li", "Yibo Yuan"], "title": "$\u03c7_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $\u03c7_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $\u03c7_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $\u03c7_{0}$ surpasses the state-of-the-art $\u03c0_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.", "AI": {"tldr": "The paper identifies distributional shifts as the primary challenge in robotic manipulation robustness and introduces a framework, $\u03c7_{0}$, that achieves reliable long-horizon manipulation with minimal resources.", "motivation": "The motivation is to address the distributional inconsistencies between human demonstrations, policy learned biases, and test-time execution, which lead to compounding errors in robotic manipulation tasks.", "method": "The method involves three technical pillars: Model Arithmetic for merging diverse demonstration distributions, Stage Advantage for stable progress signals, and Train-Deploy Alignment for bridging distribution gaps via augmentation and corrections.", "result": "$\u03c7_{0}$ achieves high-reliability autonomy in garment manipulation tasks with a success rate surpassing the state-of-the-art by 250%, using limited data and computational resources.", "conclusion": "The framework demonstrates production-level reliability in robotic manipulation, and resources such as code and models will be shared to benefit the research community."}}
{"id": "2602.08688", "pdf": "https://arxiv.org/pdf/2602.08688", "abs": "https://arxiv.org/abs/2602.08688", "authors": ["Hossein Kermani", "Fatemeh Oudlajani", "Pardis Yarahmadi", "Hamideh Mahdi Soltani", "Mohammad Makki", "Zahra HosseiniKhoo"], "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.", "AI": {"tldr": "This paper evaluates methods to detect incivility in Persian tweets, concluding ParsBERT is more effective than ChatGPT.", "motivation": "To improve detection of hate speech in Persian tweets, especially given the low-resource language context.", "method": "Comparison of three methods: qualitative human coding, supervised learning using ParsBERT, and ChatGPT, evaluating their performance on 47,278 tweets.", "result": "ParsBERT outperforms seven ChatGPT models in accuracy for detecting hate speech. ChatGPT struggles significantly with explicit and subtle cases.", "conclusion": "ParsBERT is a superior tool for detecting hate speech in Persian compared to ChatGPT, and prompt language has no major effect on ChatGPT's performance."}}
{"id": "2602.07645", "pdf": "https://arxiv.org/pdf/2602.07645", "abs": "https://arxiv.org/abs/2602.07645", "authors": ["Leonardo Gonzalez"], "title": "From Dead Pixels to Editable Slides: Infographic Reconstruction into Native Google Slides via Vision-Language Region Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted for publication in the Companion Proceedings of the ACM Web Conference 2026 (WWW Companion '26), April 13-17, 2026, Dubai, United Arab Emirates", "summary": "Infographics are widely used to communicate information with a combination of text, icons, and data visualizations, but once exported as images their content is locked into pixels, making updates, localization, and reuse expensive. We describe \\textsc{Images2Slides}, an API-based pipeline that converts a static infographic (PNG/JPG) into a native, editable Google Slides slide by extracting a region-level specification with a vision-language model (VLM), mapping pixel geometry into slide coordinates, and recreating elements using the Google Slides batch update API. The system is model-agnostic and supports multiple VLM backends via a common JSON region schema and deterministic postprocessing. On a controlled benchmark of 29 programmatically generated infographic slides with known ground-truth regions, \\textsc{Images2Slides} achieves an overall element recovery rate of $0.989\\pm0.057$ (text: $0.985\\pm0.083$, images: $1.000\\pm0.000$), with mean text transcription error $\\mathrm{CER}=0.033\\pm0.149$ and mean layout fidelity $\\mathrm{IoU}=0.364\\pm0.161$ for text regions and $0.644\\pm0.131$ for image regions. We also highlight practical engineering challenges in reconstruction, including text size calibration and non-uniform backgrounds, and describe failure modes that guide future work.", "AI": {"tldr": "This paper introduces Images2Slides, a pipeline transforming static infographic images into editable Google Slides by leveraging vision-language models.", "motivation": "Static infographics, once exported as images, are challenging to update, localize, and reuse, creating a need for editable conversion solutions.", "method": "Images2Slides utilizes vision-language models to extract region-level data from infographic images, maps pixel geometry to slide coordinates, and reconstructs elements via the Google Slides batch update API.", "result": "The method achieves high recovery rates (text: 0.985, images: 1.000) and demonstrates strong transcription accuracy (CER=0.033), though layout fidelity varies. Engineering challenges and failure modes are discussed.", "conclusion": "Images2Slides provides a promising approach for editable infographic reconstruction, with potential for improvement in layout accuracy and handling complex designs."}}
{"id": "2602.08373", "pdf": "https://arxiv.org/pdf/2602.08373", "abs": "https://arxiv.org/abs/2602.08373", "authors": ["Feiyu Wu", "Xu Zheng", "Yue Qu", "Zhuocheng Wang", "Zicheng Feng", "Hui Li"], "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to ICLR 2026. Project page. https://openreview.net/forum?id=wb05ver1k8&noteId=v1Ax8CwI71", "summary": "Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.", "AI": {"tldr": "The authors propose the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic method to ensure safety in embodied AI by actively repairing unsafe plans rather than rejecting them, achieving state-of-the-art safety and goal completion rates.", "motivation": "The paper addresses the issue that Large Language Models (LLMs), as planners for embodied AI, lack formal reasoning and safety guarantees for physical deployment, making them unreliable and unsafe for real-world applications.", "method": "The authors developed the VIRF framework, which uses a neuro-symbolic architecture combining a deterministic Logic Tutor with an LLM. The Logic Tutor provides formal safety feedback to collaborate with the LLM in repairing unsafe plans. A scalable knowledge acquisition pipeline further enhances the system by synthesizing safety knowledge from real-world documents.", "result": "In home safety tasks, VIRF outperforms all baselines with a 0% Hazardous Action Rate (HAR) and a 77.3% Goal-Condition Rate (GCR), requiring only 1.1 correction iterations on average.", "conclusion": "VIRF makes significant strides toward creating embodied agents that are not only highly efficient but also verifiably safe and trustworthy, shifting the focus from passive safety monitoring to active and collaborative plan refinement."}}
{"id": "2602.09023", "pdf": "https://arxiv.org/pdf/2602.09023", "abs": "https://arxiv.org/abs/2602.09023", "authors": ["Qinwen Xu", "Jiaming Liu", "Rui Zhou", "Shaojun Shi", "Nuowei Han", "Zhuoyang Liu", "Chenyang Gu", "Shuo Gu", "Yang Yue", "Gao Huang", "Wenzhao Zheng", "Sirui Han", "Peng Jia", "Shanghang Zhang"], "title": "TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks.", "AI": {"tldr": "The paper proposes TwinRL, a collaborative RL framework for Vision-Language-Action (VLA) models, leveraging digital twins to improve exploration efficiency and training in real-world tasks.", "motivation": "Current Vision-Language-Action (VLA) models face challenges due to high costs of expert demonstrations and limited real-world interaction. Online RL for VLA models suffers from low exploration efficiency and constrained exploration space, necessitating a more scalable and efficient solution.", "method": "TwinRL uses high-fidelity digital twins reconstructed from smartphone-captured scenes to facilitate bidirectional transfers between real and simulated environments. It incorporates a supervised fine-tuning expansion strategy during initialization and employs sim-to-real guided exploration to streamline and accelerate online RL training.", "result": "TwinRL achieves nearly 100% success in both in-distribution and out-of-distribution areas, with at least a 30% improvement in training speed over previous methods. It also reduces real-world RL task time to about 20 minutes on average across four tested tasks.", "conclusion": "The TwinRL framework successfully enhances the exploration and training process for VLA models, addressing inefficiencies related to cost and interaction limitations, and demonstrates a significant impact on performance and training efficiency across tasks."}}
{"id": "2602.08698", "pdf": "https://arxiv.org/pdf/2602.08698", "abs": "https://arxiv.org/abs/2602.08698", "authors": ["Basudha Raje", "Sadanand Venkatraman", "Nandana TP", "Soumyadeepa Das", "Polkam Poojitha", "M. Vijaykumar", "Tanima Bagchi", "Hema A. Murthy"], "title": "Challenges in Translating Technical Lectures: Insights from the NPTEL", "categories": ["cs.CL"], "comment": null, "summary": "This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.", "AI": {"tldr": "The study explores machine translation for Indian languages focusing on Bangla, Malayalam, and Telugu using educational corpora from NPTEL.", "motivation": "Multilingual support in education technology, especially under NEP 2020 requirements in India.", "method": "Analyzing spontaneous speech corpora and testing translation across sensitive linguistic metrics.", "result": "Challenges in handling morphologically rich and semantically compact languages using machine translation metrics.", "conclusion": "Developments in machine translation should account for linguistic diversity and metric-specific nuances in multilingual Indian education contexts."}}
{"id": "2602.07658", "pdf": "https://arxiv.org/pdf/2602.07658", "abs": "https://arxiv.org/abs/2602.07658", "authors": ["Avinash Kumar K M", "Samarth S. Raut"], "title": "Influence of Geometry, Class Imbalance and Alignment on Reconstruction Accuracy -- A Micro-CT Phantom-Based Evaluation", "categories": ["cs.CV"], "comment": "22 pages, 13 figures", "summary": "The accuracy of the 3D models created from medical scans depends on imaging hardware, segmentation methods and mesh processing techniques etc. The effects of geometry type, class imbalance, voxel and point cloud alignment on accuracy remain to be thoroughly explored. This work evaluates the errors across the reconstruction pipeline and explores the use of voxel and surface-based accuracy metrics for different segmentation algorithms and geometry types. A sphere, a facemask, and an AAA were printed using the SLA technique and scanned using a micro-CT machine. Segmentation was performed using GMM, Otsu and RG based methods. Segmented and reference models aligned using the KU algorithm, were quantitatively compared to evaluate metrics like Dice and Jaccard scores, precision. Surface meshes were registered with reference meshes using an ICP-based alignment process. Metrics like chamfer distance, and average Hausdorff distance were evaluated. The Otsu method was found to be the most suitable method for all the geometries. AAA yielded low overlap scores due to its small wall thickness and misalignment. The effect of class imbalance on specificity was observed the most for AAA. Surface-based accuracy metrics differed from the voxel-based trends. The RG method performed best for sphere, while GMM and Otsu perform better for AAA. The facemask surface was most error-prone, possibly due to misalignment during the ICP process. Segmentation accuracy is a cumulative sum of errors across different stages of the reconstruction process. High voxel-based accuracy metrics may be misleading in cases of high class imbalance and sensitivity to alignment. The Jaccard index is found to be more stringent than the Dice and more suitable for accuracy assessment for thin-walled structures. Voxel and point cloud alignment should be ensured to make any reliable assessment of the reconstruction pipeline.", "AI": {"tldr": "The paper investigates reconstruction errors in medical scan 3D modeling pipelines and evaluates accuracy metrics using various segmentation algorithms and geometry types.", "motivation": "The study aims to address how imaging hardware, segmentation methods, alignment, and class imbalances affect 3D reconstruction accuracy, as these factors' effects remain insufficiently explored.", "method": "Experiments involved 3D printing geometries (a sphere, facemask, and AAA), scanning via micro-CT, segmentation using GMM, Otsu, and RG algorithms, and metric evaluation (Dice, Jaccard, chamfer distance, Hausdorff distance). Accuracy assessments used voxel-based and surface-based measurements with alignment techniques like KU and ICP.", "result": "Otsu segmentation showed consistent performance across geometries. AAA structures faced low overlap due to thin walls and misalignment, with class imbalance affecting the specificity. Surface-based metrics often contradicted voxel-based results. The RG method excelled for spheres, while GMM and Otsu were better for AAA.", "conclusion": "Reconstruction accuracy is cumulative, affected by segmentation, alignment, and class imbalances. High voxel metrics might mislead in imbalanced cases, and the Jaccard index is more suitable for thin-walled structures. Proper alignment ensures reliable accuracy evaluation."}}
{"id": "2602.08400", "pdf": "https://arxiv.org/pdf/2602.08400", "abs": "https://arxiv.org/abs/2602.08400", "authors": ["Longkun Li", "Yuanben Zou", "Jinghan Wu", "Yuqing Wen", "Jing Li", "Hangwei Qian", "Ivor Tsang"], "title": "SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains", "categories": ["cs.AI"], "comment": null, "summary": "Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \\textbf{SCOUT-RAG} (\\textit{\\underline{S}calable and \\underline{CO}st-efficient \\underline{U}nifying \\underline{T}raversal}), a distributed agentic Graph-RAG framework that performs progressive cross-domain retrieval guided by incremental utility goals. SCOUT-RAG employs four cooperative agents that: (i) estimate domain relevance, (ii) decide when to expand retrieval to additional domains, (iii) adapt traversal depth to avoid unnecessary graph exploration, and (iv) synthesize the high-quality answers. The framework is designed to minimize retrieval regret, defined as missing useful domain information, while controlling latency and API cost. Across multi-domain knowledge settings, SCOUT-RAG achieves performance comparable to centralized baselines, including DRIFT and exhaustive domain traversal, while substantially reducing cross-domain calls, total tokens processed, and latency.", "AI": {"tldr": "This paper introduces SCOUT-RAG, a distributed Graph-RAG system that optimizes information retrieval in decentralized knowledge environments.", "motivation": "To address limitations of traditional Graph-RAG designs in decentralized and access-restricted settings, enabling effective reasoning with structured knowledge without global graph visibility.", "method": "SCOUT-RAG uses four cooperative agents for estimating relevance, deciding domain expansion, adapting traversal depth, and synthesizing answers, optimizing for retrieval utility and cost-efficiency.", "result": "SCOUT-RAG achieved performance similar to centralized Graph-RAG baselines while significantly reducing domain queries, processed tokens, and system response times.", "conclusion": "SCOUT-RAG balances retrieval quality, efficiency, and cost in distributed multi-domain knowledge environments, making it suitable for decentralized and restricted data settings."}}
{"id": "2602.07640", "pdf": "https://arxiv.org/pdf/2602.07640", "abs": "https://arxiv.org/abs/2602.07640", "authors": ["Micha\u0142 Kozyra", "Gesine Reinert"], "title": "TASTE: Task-Aware Out-of-Distribution Detection via Stein Operators", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution detection methods are often either data-centric, detecting deviations from the training input distribution irrespective of their effect on a trained model, or model-centric, relying on classifier outputs without explicit reference to data geometry. We propose TASTE (Task-Aware STEin operators): a task-aware framework based on so-called Stein operators, which allows us to link distribution shift to the input sensitivity of the model. We show that the resulting operator admits a clear geometric interpretation as a projection of distribution shift onto the sensitivity field of the model, yielding theoretical guarantees. Beyond detecting the presence of a shift, the same construction enables its localisation through a coordinate-wise decomposition, and for image data-provides interpretable per-pixel diagnostics. Experiments on controlled Gaussian shifts, MNIST under geometric perturbations, and CIFAR-10 perturbed benchmarks demonstrate that the proposed method aligns closely with task degradation while outperforming established baselines.", "AI": {"tldr": "The paper introduces TASTE, a task-aware framework for out-of-distribution detection, linking distribution shift to model sensitivity via Stein operators.", "motivation": "To address limitations in current out-of-distribution detection methods, which are primarily either data- or model-centric, by developing an approach that considers both data distribution shifts and model sensitivity.", "method": "TASTE leverages Stein operators to detect distribution shifts by projecting them onto the model's input sensitivity field. This approach provides theoretical guarantees and allows for localization and interpretability, especially in image data.", "result": "TASTE effectively detects and localizes distribution shifts in experiments involving Gaussian shifts, MNIST geometric perturbations, and CIFAR-10 benchmarks, outperforming existing methods.", "conclusion": "The proposed TASTE framework demonstrates how task-awareness and sensitivity fields can improve out-of-distribution detection, offering practical advantages and interpretability."}}
{"id": "2512.01047", "pdf": "https://arxiv.org/pdf/2512.01047", "abs": "https://arxiv.org/abs/2512.01047", "authors": ["Tanmay Ambadkar", "\u0110or\u0111e \u017dikeli\u0107", "Abhinav Verma"], "title": "Automating the Refinement of Reinforcement Learning Specifications", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \\textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \\textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \\textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \\textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \\textsc{AutoSpec} are utilized.", "AI": {"tldr": "The paper introduces AutoSpec, a framework that refines logical specifications to simplify reinforcement learning by providing additional guidance for learning policies. Results show it aids in solving more complex control tasks.", "motivation": "Reinforcement learning (RL) agents struggle with under-specified tasks as they fail to learn useful policies. The study aims to improve coarse-grained logical specifications to guide RL algorithms effectively.", "method": "The authors propose AutoSpec, which refines logical specifications (SpectRL logic) via four refinement procedures that adjust edge specifications or add new ones while ensuring soundness. It integrates these refinements into existing RL algorithms.", "result": "AutoSpec demonstrates success in improving RL performance, enabling agents to solve more complex control tasks by leveraging refined specifications.", "conclusion": "Refining logical specifications using AutoSpec provides effective guidance, simplifying reinforcement learning and enhancing the capability of RL agents to address more complex tasks."}}
{"id": "2602.08700", "pdf": "https://arxiv.org/pdf/2602.08700", "abs": "https://arxiv.org/abs/2602.08700", "authors": ["Clemencia Siro", "Zahra Abbasiantaeb", "Yifei Yuan", "Mohammad Aliannejadi", "Maarten de Rijke"], "title": "Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search", "categories": ["cs.CL", "cs.HC", "cs.IR"], "comment": "Accepted at CHIIR 2025", "summary": "Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.", "AI": {"tldr": "This study investigates the role of images in conversational search and clarifying questions, examining their impact on user engagement, query reformulation, and retrieval performance.", "motivation": "To explore how adding images to clarifying questions in conversational search affects user performance and retrieval efficiency.", "method": "A user study with 73 participants comparing text-only and multimodal clarifying questions across tasks: answering questions and query reformulation.", "result": "Participants preferred multimodal clarifying questions for answering queries, but preferences were more balanced for query reformulation. Images supported engagement and improved retrieval precision, but text-only setups provided more comprehensive information in certain tasks.", "conclusion": "The benefits of visual augmentation in conversational search systems are task-dependent, suggesting strategic implementation is needed for optimal user experience and retrieval quality."}}
{"id": "2602.07668", "pdf": "https://arxiv.org/pdf/2602.07668", "abs": "https://arxiv.org/abs/2602.07668", "authors": ["Ross Greer", "Laura Fleig", "Maitrayee Keskar", "Erika Maquiling", "Giovanni Tapia Lopez", "Angel Martinez-Sanchez", "Parthib Roy", "Jake Rattigan", "Mira Sur", "Alejandra Vidrio", "Thomas Marcotte", "Mohan Trivedi"], "title": "Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "The looking-in-looking-out (LILO) framework has enabled intelligent vehicle applications that understand both the outside scene and the driver state to improve safety outcomes, with examples in smart airbag deployment, takeover time prediction in autonomous control transitions, and driver attention monitoring. In this research, we propose an augmentation to this framework, making a case for the audio modality as an additional source of information to understand the driver, and in the evolving autonomy landscape, also the passengers and those outside the vehicle. We expand LILO by incorporating audio signals, forming the looking-and-listening inside-and-outside (L-LIO) framework to enhance driver state assessment and environment understanding through multimodal sensor fusion. We evaluate three example cases where audio enhances vehicle safety: supervised learning on driver speech audio to classify potential impairment states (e.g., intoxication), collection and analysis of passenger natural language instructions (e.g., \"turn after that red building\") to motivate how spoken language can interface with planning systems through audio-aligned instruction data, and limitations of vision-only systems where audio may disambiguate the guidance and gestures of external agents. Datasets include custom-collected in-vehicle and external audio samples in real-world environments. Pilot findings show that audio yields safety-relevant insights, particularly in nuanced or context-rich scenarios where sound is critical to safe decision-making or visual signals alone are insufficient. Challenges include ambient noise interference, privacy considerations, and robustness across human subjects, motivating further work on reliability in dynamic real-world contexts. L-LIO augments driver and scene understanding through multimodal fusion of audio and visual sensing, offering new paths for safety intervention.", "AI": {"tldr": "This research proposes the L-LIO framework that integrates audio signals with visual sensing to improve vehicle safety and understanding of driver and scene dynamics.", "motivation": "The enhancement of vehicle safety and scene understanding motivates this paper by addressing the limitations of existing visual-only systems and leveraging audio as an additional modality.", "method": "The L-LIO framework fuses audio signals with visual sensing and evaluates three cases where this multimodal approach enhances vehicle safety: driver speech analysis, passenger language instructions, and external agent gesture disambiguation.", "result": "Pilot findings demonstrate that integrating audio into the framework yields safety-relevant insights, especially in complex scenarios where sound is crucial and visual signals are insufficient.", "conclusion": "The L-LIO framework enhances driver and scene assessment through audio-visual multimodal fusion, presenting opportunities for improved safety interventions and highlighting challenges such as noise interference and privacy."}}
{"id": "2602.08401", "pdf": "https://arxiv.org/pdf/2602.08401", "abs": "https://arxiv.org/abs/2602.08401", "authors": ["Liwen Wang", "Zongjie Li", "Yuchong Xie", "Shuai Wang", "Dongdong She", "Wei Wang", "Juergen Rahmel"], "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.", "AI": {"tldr": "The paper introduces AGENTWM, the first watermarking technique specifically for agentic Large Language Models, designed to protect intellectual property from imitation attacks.", "motivation": "Agentic LLMs are valuable but vulnerable to imitation attacks. Current watermarking methods are inadequate because agentic systems conceal internal processes, leaving IP at risk.", "method": "The authors developed AGENTWM, a watermarking framework that embeds signals into action sequences in agentic systems. Using semantic equivalence, the technique biases functionally identical outputs without disturbing user experience.", "result": "Extensive evaluations in three domains show AGENTWM achieves high watermark detection accuracy while having an insignificant impact on agent performance.", "conclusion": "AGENTWM effectively secures agentic LLMs against adversaries by embedding robust watermarks, ensuring proprietary capabilities remain protected even under adaptive attacks."}}
{"id": "2602.07659", "pdf": "https://arxiv.org/pdf/2602.07659", "abs": "https://arxiv.org/abs/2602.07659", "authors": ["Matthew Siper", "Muhammad Umair Nasir", "Ahmed Khalifa", "Lisa Soros", "Jay Azhang", "Julian Togelius"], "title": "Continuous Program Search", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "comment": null, "summary": "Genetic Programming yields interpretable programs, but small syntactic mutations can induce large, unpredictable behavioral shifts, degrading locality and sample efficiency. We frame this as an operator-design problem: learn a continuous program space where latent distance has behavioral meaning, then design mutation operators that exploit this structure without changing the evolutionary optimizer.\n  We make locality measurable by tracking action-level divergence under controlled latent perturbations, identifying an empirical trust region for behavior-local continuous variation. Using a compact trading-strategy DSL with four semantic components (long/short entry and exit), we learn a matching block-factorized embedding and compare isotropic Gaussian mutation over the full latent space to geometry-compiled mutation that restricts updates to semantically paired entry--exit subspaces and proposes directions using a learned flow-based model trained on logged mutation outcomes.\n  Under identical $(\u03bc+\u03bb)$ evolution strategies and fixed evaluation budgets across five assets, the learned mutation operator discovers strong strategies using an order of magnitude fewer evaluations and achieves the highest median out-of-sample Sharpe ratio. Although isotropic mutation occasionally attains higher peak performance, geometry-compiled mutation yields faster, more reliable progress, demonstrating that semantically aligned mutation can substantially improve search efficiency without modifying the underlying evolutionary algorithm.", "AI": {"tldr": "The paper proposes an approach to improve genetic programming by learning a program space with behaviorally meaningful latent distances and designing semantically aligned mutation operators.", "motivation": "To address the issue of small syntactic mutations causing large behavioral changes in genetic programming, leading to inefficient search and poor locality.", "method": "The authors introduce a method to track behavioral divergence under controlled perturbations in a trading-strategy DSL. They use block-factorized embeddings, semantically-aligned mutations, and a flow-based model to improve program evolution without changing the optimizer.", "result": "The learned mutation operator discovers strong strategies on five assets with lower evaluations and achieves the highest median out-of-sample Sharpe ratio compared to isotropic mutation.", "conclusion": "Using semantically-aligned mutation significantly improves the efficiency and reliability of genetic programming while maintaining interpretability and avoiding modifications to the evolutionary algorithm."}}
{"id": "2602.07000", "pdf": "https://arxiv.org/pdf/2602.07000", "abs": "https://arxiv.org/abs/2602.07000", "authors": ["Abanoub M. Girgis", "Ibtissam Labriji", "Mehdi Bennis"], "title": "Hierarchical JEPA Meets Predictive Remote Control in Beyond 5G Networks", "categories": ["eess.SY", "cs.AI", "cs.RO"], "comment": null, "summary": "In wireless networked control systems, ensuring timely and reliable state updates from distributed devices to remote controllers is essential for robust control performance. However, when multiple devices transmit high-dimensional states (e.g., images or video frames) over bandwidth-limited wireless networks, a critical trade-off emerges between communication efficiency and control performance. To address this challenge, we propose a Hierarchical Joint-Embedding Predictive Architecture (H-JEPA) for scalable predictive control. Instead of transmitting states, device observations are encoded into low-dimensional embeddings that preserve essential dynamics. The proposed architecture employs a three-level hierarchical prediction, with high-level, medium-level, and low-level predictors operating across different temporal resolutions, to achieve long-term prediction stability, intermediate interpolation, and fine-grained refinement, respectively. Control actions are derived within the embedding space, removing the need for state reconstruction. Simulation results on inverted cart-pole systems demonstrate that H-JEPA enables up to 42.83 % more devices to be supported under limited wireless capacity without compromising control performance.", "AI": {"tldr": "This paper proposes H-JEPA, a predictive control architecture for wireless systems, focusing on encoding observations into low-dimensional embeddings to balance communication efficiency and control performance, demonstrated via simulations.", "motivation": "To address bandwidth limitations in wireless networked control systems where multiple devices transmit high-dimensional states, such as images or video frames, affecting control performance.", "method": "The paper introduces Hierarchical Joint-Embedding Predictive Architecture, encoding observations into low-dimensional embeddings and utilizing hierarchical prediction (high-level, medium-level, low-level predictors) for scalable control.", "result": "Simulation results show that H-JEPA allows up to 42.83% more devices to operate under limited wireless capacity without reducing control performance.", "conclusion": "H-JEPA is effective in balancing communication efficiency and control performance in bandwidth-limited wireless networks by leveraging hierarchical predictive encoding methods."}}
{"id": "2602.08709", "pdf": "https://arxiv.org/pdf/2602.08709", "abs": "https://arxiv.org/abs/2602.08709", "authors": ["Leandro Anghinoni", "Jorge Sanchez"], "title": "FactSim: Fact-Checking for Opinion Summarization", "categories": ["cs.CL"], "comment": "10 pages, 4 figures", "summary": "We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.", "AI": {"tldr": "The paper introduces an automated method to evaluate the factual consistency of summaries generated by GenAI for opinion summarization tasks, addressing the limitations of traditional evaluation methods.", "motivation": "The study aims to overcome the limitations in evaluating summaries produced by generative AI, specifically for opinion summarization, as current metrics falter in handling the advancements introduced by large language models.", "method": "The proposed method involves extracting factual claims from original texts and matching them with those in machine-generated summaries to assess coverage and consistency, quantified in a score.", "result": "The metric efficiently attributes higher scores to accurate claims, even if expressed as paraphrases or expanded forms, and maintains strong correlation with human evaluations compared to existing techniques.", "conclusion": "The study establishes a novel and reliable evaluation method for generative AI summarization, proving its effectiveness and better alignment with human assessment benchmarks."}}
{"id": "2602.07680", "pdf": "https://arxiv.org/pdf/2602.07680", "abs": "https://arxiv.org/abs/2602.07680", "authors": ["Ross Greer", "Maitrayee Keskar", "Angel Martinez-Sanchez", "Parthib Roy", "Shashank Shriram", "Mohan Trivedi"], "title": "Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Vision-language models (VLMs) have recently emerged as powerful representation learning systems that align visual observations with natural language concepts, offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates how vision-language representations support driving scene safety assessment and decision-making when integrated into perception, prediction, and planning pipelines. We study three complementary system-level use cases. First, we introduce a lightweight, category-agnostic hazard screening approach leveraging CLIP-based image-text similarity to produce a low-latency semantic hazard signal. This enables robust detection of diverse and out-of-distribution road hazards without explicit object detection or visual question answering. Second, we examine the integration of scene-level vision-language embeddings into a transformer-based trajectory planning framework using the Waymo Open Dataset. Our results show that naively conditioning planners on global embeddings does not improve trajectory accuracy, highlighting the importance of representation-task alignment and motivating the development of task-informed extraction methods for safety-critical planning. Third, we investigate natural language as an explicit behavioral constraint on motion planning using the doScenes dataset. In this setting, passenger-style instructions grounded in visual scene elements suppress rare but severe planning failures and improve safety-aligned behavior in ambiguous scenarios. Taken together, these findings demonstrate that vision-language representations hold significant promise for autonomous driving safety when used to express semantic risk, intent, and behavioral constraints. Realizing this potential is fundamentally an engineering problem requiring careful system design and structured grounding rather than direct feature injection.", "AI": {"tldr": "This paper explores the integration of vision-language models (VLMs) into autonomous driving for safety-critical tasks, focusing on hazard detection, trajectory planning, and behavior constraints. Results highlight the promise of VLMs but emphasize the need for task alignment and careful system design.", "motivation": "The paper aims to harness vision-language models to enhance semantic reasoning and safety in autonomous driving, addressing limitations in perception, prediction, and planning pipelines.", "method": "Three use cases were explored: 1) a lightweight, category-agnostic hazard detection approach using CLIP-based image-text similarity; 2) integration of vision-language embeddings into trajectory planning using the Waymo Open Dataset; 3) use of natural language to impose behavioral constraints on motion planning with the doScenes dataset.", "result": "The study found that while VLMs detect diverse road hazards robustly and help mitigate safety risks by incorporating natural language instructions, a straightforward integration of embeddings in planners is insufficient without task-specific alignment.", "conclusion": "Vision-language representations can significantly enhance autonomous driving safety by expressing semantic risk, intent, and constraints. However, effective implementation requires structured grounding and tailored engineering rather than direct application of features."}}
{"id": "2602.08412", "pdf": "https://arxiv.org/pdf/2602.08412", "abs": "https://arxiv.org/abs/2602.08412", "authors": ["Yuhang Wang", "Feiming Xu", "Zheng Lin", "Guangyu He", "Yuzhe Huang", "Haichang Gao", "Zhenxing Niu"], "title": "From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent", "categories": ["cs.AI"], "comment": "11 pages,2 figures", "summary": "Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk propagation mechanisms of personalized agents in real-world deployments. To address this gap, we propose Personalized Agent Security Bench (PASB), an end-to-end security evaluation framework tailored for real-world personalized agents. Building upon existing agent attack paradigms, PASB incorporates personalized usage scenarios, realistic toolchains, and long-horizon interactions, enabling black-box, end-to-end security evaluation on real systems. Using OpenClaw as a representative case study, we systematically evaluate its security across multiple personalized scenarios, tool capabilities, and attack types. Our results indicate that OpenClaw exhibits critical vulnerabilities at different execution stages, including user prompt processing, tool usage, and memory retrieval, highlighting substantial security risks in personalized agent deployments. The code for the proposed PASB framework is available at https://github.com/AstorYH/PASB.", "AI": {"tldr": "This paper introduces the PASB framework to address security risks in LLM-based agents, particularly their vulnerabilities in handling personalized tasks.", "motivation": "The growing use of LLM-based agents like OpenClaw in real-world tasks presents significant security risks that are not adequately addressed by current security evaluation frameworks.", "method": "The authors propose the PASB framework, which includes personalized scenarios, real-world tools, and long-term interactions for end-to-end security evaluation.", "result": "Through case studies on OpenClaw, the results reveal critical security vulnerabilities during prompt processing, tool usage, and memory retrieval stages.", "conclusion": "Personalized agents, including OpenClaw, face substantial security risks in real-world applications, and frameworks like PASB are crucial for evaluating and addressing these vulnerabilities."}}
{"id": "2602.07670", "pdf": "https://arxiv.org/pdf/2602.07670", "abs": "https://arxiv.org/abs/2602.07670", "authors": ["Jarrod Barnes"], "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 7 figures, 11 tables. Preprint. Code: https://github.com/jbarnes850/test-time-training", "summary": "Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that search outperforms minimal adaptation (1-5 gradient steps): Best-of-N sampling achieves 90% task success (18/20 tasks) at K=64 across the full KernelBench L1 eval set while TTT's best checkpoint reaches only 30.6% (3-seed mean), with TTT's \"equivalent K\" falling below 1, worse than single-sample inference. The failure mode is over-sharpening: gradient updates collapse diversity toward mediocre solutions rather than discovering optimal ones. Our main contribution is surprisal-guided selection: selecting the highest-surprisal (lowest-confidence) correct sample yields 80% success vs. 50% for most-confident selection, a 30% improvement. Extending to surprisal-guided-top3 matches oracle performance at 100%. This zero-cost strategy, validated through length-controlled analysis, recovers oracle performance. For dense-reward VEG tasks, compute should be allocated to sample diversity and intelligent selection rather than gradient adaptation. The surprisal-guided selection principle may generalize to other execution-grounded domains where optimal solutions occupy the distribution tail.", "AI": {"tldr": "The paper compares test-time training (TTT) with alternative strategies for test-time inference in execution-grounded tasks, finding that search methods combined with surprisal-guided sample selection outperform gradient-based TTT adaptation.", "motivation": "The authors aim to evaluate whether gradient-based test-time training (TTT) is an optimal approach for tasks with continuous reward signals, such as GPU kernel optimization, and whether other compute-efficient strategies could perform better.", "method": "They use KernelBench, a benchmark for execution-grounded tasks, to evaluate the performance of a 120B-parameter language model (GPT-OSS-120B with LoRA adaptation) in finding optimal solutions. Search and adaptation-based methods are compared, and a novel surprisal-guided selection strategy is developed for sample-efficiency.", "result": "Search-based methods, particularly Best-of-N sampling at K=64, achieve a 90% success rate on KernelBench compared to 30.6% for TTT. Surprisal-guided selection improves performance by 30% over confidence-based selection and matches oracle performance when extended to top-3 sampling.", "conclusion": "Compute resources for dense-reward execution-grounded tasks are better allocated to sample diversity and intelligent selection rather than TTT adaptation. The surprisal-guided selection method shows promise for tasks where optimal solutions are rare."}}
{"id": "2602.08716", "pdf": "https://arxiv.org/pdf/2602.08716", "abs": "https://arxiv.org/abs/2602.08716", "authors": ["Shangrui Nie", "Kian Omoomi", "Lucie Flek", "Zhixue Zhao", "Charles Welch"], "title": "PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments", "categories": ["cs.CL"], "comment": "15 pages, 1 figure", "summary": "Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.", "AI": {"tldr": "The paper introduces PERSPECTRA, a benchmark designed to evaluate the ability of LLMs to handle pluralism by integrating debate structures and linguistic diversity from Kialo and Reddit.", "motivation": "The motivation for this study is the lack of attention paid to pluralism in LLM research, despite its importance for reflecting human diversity in perspectives.", "method": "PERSPECTRA combines the structural clarity of Kialo debate graphs with the linguistic diversity of Reddit discussions. It uses a controlled retrieval-and-expansion pipeline to create a benchmark with 3,810 enriched arguments across 762 stances on 100 topics.", "result": "Through experiments on state-of-the-art LLMs, the paper finds systematic failures in accurately representing and reasoning about multiple viewpoints, such as overestimating viewpoint counts and misclassifying structures.", "conclusion": "PERSPECTRA serves as the first scalable benchmark for evaluating pluralism in LLMs, enabling robust assessment of their ability to represent and reason with diverse perspectives."}}
{"id": "2602.07689", "pdf": "https://arxiv.org/pdf/2602.07689", "abs": "https://arxiv.org/abs/2602.07689", "authors": ["Jusheng Zhang", "Kaitong Cai", "Jian Wang", "Yongsen Zheng", "Kwok-Yan Lam", "Keze Wang"], "title": "Process-of-Thought Reasoning for Videos", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video understanding requires not only recognizing visual content but also performing temporally grounded, multi-step reasoning over long and noisy observations. We propose Process-of-Thought (PoT) Reasoning for Videos, a framework that makes the reasoning process explicit by structuring video inference into a sequence of lightweight, verifiable steps. PoT interleaves (i) temporal evidence selection, (ii) step-wise state updates, and (iii) constrained answer synthesis, enabling the model to progressively refine hypotheses while maintaining traceability to video evidence. The framework is designed to be model-agnostic and can be plugged into existing vision-language backbones, supporting both closed-book reasoning and evidence-augmented reasoning with external tools. We further introduce a unified representation for PoT traces that aligns intermediate decisions with temporal segments, which improves robustness to distractors and reduces hallucinated explanations. Extensive experiments on standard video reasoning tasks demonstrate that PoT consistently improves factual correctness and temporal grounding, while providing interpretable reasoning traces for diagnosis and downstream use.", "AI": {"tldr": "The paper introduces 'Process-of-Thought' (PoT) reasoning for video understanding, focusing on structured inference involving evidence selection, updates, and answer synthesis.", "motivation": "Video understanding often involves complex temporal reasoning over long, noisy observations, necessitating explicit structuring of the reasoning process.", "method": "PoT organizes video inference into steps: temporal evidence selection, step-wise updates, and constrained synthesis. It is model-agnostic and integrates well with existing frameworks.", "result": "PoT improves factual correctness, temporal grounding, and robustness against distractors. It also provides interpretable reasoning traces.", "conclusion": "The PoT framework enhances video reasoning tasks by structuring the inference process, boosting performance and interpretability."}}
{"id": "2602.08449", "pdf": "https://arxiv.org/pdf/2602.08449", "abs": "https://arxiv.org/abs/2602.08449", "authors": ["Igor Santos-Grueiro"], "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": "25 pages, 4 figures,", "summary": "Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-informational cues distinguishing evaluation from deployment-to implement conditional policies such as sycophancy and sleeper agents, which preserve compliance under oversight while defecting in deployment-like regimes. We reframe alignment evaluation as a problem of information flow under partial observability. Within this framework, we show that divergence between evaluation-time and deployment-time behavior is bounded by the mutual information between internal representations and the regime variable. Motivated by this result, we study regime-blind mechanisms: training-time interventions that reduce the extractability of regime information at decision-relevant internal representations via adversarial invariance. We evaluate this approach on a base, open-weight language model across two fully characterized failure modes -scientific sycophancy and temporal sleeper agents. Regime-blind training suppresses regime-conditioned behavior in both evaluated cases without measurable loss of task utility, but with qualitatively different dynamics: sycophancy exhibits a sharp representational and behavioral transition at low intervention strength, whereas sleeper-agent behavior requires substantially stronger pressure and does not exhibit a clean collapse of regime decodability. These results demonstrate that representational invariance is a meaningful but fundamentally limited control lever, whose effectiveness depends on how regime information is embedded in the policy. We argue that behavioral evaluation should be complemented with white-box diagnostics of regime awareness and information flow.", "AI": {"tldr": "The paper challenges traditional AI safety evaluations, highlighting the risks posed by situational awareness in agents. It introduces 'regime-blind' mechanisms to mitigate these risks through adversarial training and examines behavioral divergences under different regimes.", "motivation": "The motivation is to address the fragility of AI safety evaluations, especially for agents with situational awareness that may exploit the differences between evaluation and deployment conditions to behave differently in those regimes.", "method": "The authors propose reframing alignment evaluation as a partial observability problem, analyzing the divergence through mutual information, and introducing regime-blind training interventions using adversarial invariance to suppress regime-conditioned behavior.", "result": "Regime-blind training successfully suppresses specific failures (sycophancy and sleeper agents) with minor task utility loss, but its effectiveness varies depending on the embedding of regime information in policies.", "conclusion": "Behavioral evaluations alone are insufficient; they should be complemented with diagnostics on regime awareness and information flow to achieve reliable AI alignment."}}
{"id": "2602.07671", "pdf": "https://arxiv.org/pdf/2602.07671", "abs": "https://arxiv.org/abs/2602.07671", "authors": ["Mohan Li", "Dario Fenoglio", "Martin Gjoreski", "Marc Langheinrich"], "title": "Federated Learning with Profile Mapping under Distribution Shifts and Drifts", "categories": ["cs.LG"], "comment": "ICLR2026", "summary": "Federated Learning (FL) enables decentralized model training across clients without sharing raw data, but its performance degrades under real-world data heterogeneity. Existing methods often fail to address distribution shift across clients and distribution drift over time, or they rely on unrealistic assumptions such as known number of client clusters and data heterogeneity types, which limits their generalizability. We introduce Feroma, a novel FL framework that explicitly handles both distribution shift and drift without relying on client or cluster identity. Feroma builds on client distribution profiles-compact, privacy-preserving representations of local data-that guide model aggregation and test-time model assignment through adaptive similarity-based weighting. This design allows Feroma to dynamically select aggregation strategies during training, ranging from clustered to personalized, and deploy suitable models to unseen, and unlabeled test clients without retraining, online adaptation, or prior knowledge on clients' data. Extensive experiments show that compared to 10 state-of-the-art methods, Feroma improves performance and stability under dynamic data heterogeneity conditions-an average accuracy gain of up to 12 percentage points over the best baselines across 6 benchmarks-while maintaining computational and communication overhead comparable to FedAvg. These results highlight that distribution-profile-based aggregation offers a practical path toward robust FL under both data distribution shifts and drifts.", "AI": {"tldr": "Feroma is a new Federated Learning (FL) framework addressing distribution shifts and drifts effectively, achieving better performance in decentralized training.", "motivation": "To overcome FL performance degradation caused by data heterogeneity, including distribution shift across clients and drift over time, without relying on unrealistic assumptions like fixed client clusters or known data types.", "method": "Developed client distribution profiles to guide adaptive model aggregation and test-time assignment, allowing dynamic strategies during training and effective deployment without retraining or prior client data knowledge.", "result": "Feroma outperformed 10 state-of-the-art methods with up to 12% accuracy improvement and maintained computational and communication efficiency on 6 benchmarks.", "conclusion": "The approach based on distribution-profile-based aggregation offers a robust and practical solution for efficient Federated Learning under dynamic heterogeneous conditions."}}
{"id": "2602.08740", "pdf": "https://arxiv.org/pdf/2602.08740", "abs": "https://arxiv.org/abs/2602.08740", "authors": ["Gaifan Zhang", "Danushka Bollegala"], "title": "Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy", "categories": ["cs.CL"], "comment": null, "summary": "We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.", "AI": {"tldr": "The paper introduces a method to compare and visualize sentence encoders at scale, creating a map that captures relationships between encoders, allowing inference on downstream task performance.", "motivation": "Understanding and comparing sentence encoders is challenging due to the diversity of models and methods. The paper aims to provide a clear and scalable visualization of the relationships between sentence encoders.", "method": "The approach involves representing each encoder with an embedding matrix, computing a Pairwise Inner Product matrix, deriving Quantum Relative Entropy-based feature vectors, and mapping 1101 publicly available encoders to visualize relationships.", "result": "The proposed map accurately reflects relationships between similar encoders, and the feature vectors effectively predict downstream task performance (e.g., retrieval and clustering).", "conclusion": "This map provides an insightful perspective on the pre-trained sentence encoder space, aiding in assessing encoder similarities and supporting performance prediction in tasks."}}
{"id": "2602.07694", "pdf": "https://arxiv.org/pdf/2602.07694", "abs": "https://arxiv.org/abs/2602.07694", "authors": ["Wenping Jin", "Yuyang Tang", "Li Zhu"], "title": "Semantic-Deviation-Anchored Multi-Branch Fusion for Unsupervised Anomaly Detection and Localization in Unstructured Conveyor-Belt Coal Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Reliable foreign-object anomaly detection and pixel-level localization in conveyor-belt coal scenes are essential for safe and intelligent mining operations. This task is particularly challenging due to the highly unstructured environment: coal and gangue are randomly piled, backgrounds are complex and variable, and foreign objects often exhibit low contrast, deformation, occlusion, resulting in coupling with their surroundings. These characteristics weaken the stability and regularity assumptions that many anomaly detection methods rely on in structured industrial settings, leading to notable performance degradation. To support evaluation and comparison in this setting, we construct \\textbf{CoalAD}, a benchmark for unsupervised foreign-object anomaly detection with pixel-level localization in coal-stream scenes. We further propose a complementary-cue collaborative perception framework that extracts and fuses complementary anomaly evidence from three perspectives: object-level semantic composition modeling, semantic-attribution-based global deviation analysis, and fine-grained texture matching. The fused outputs provide robust image-level anomaly scoring and accurate pixel-level localization. Experiments on CoalAD demonstrate that our method outperforms widely used baselines across the evaluated image-level and pixel-level metrics, and ablation studies validate the contribution of each component. The code is available at https://github.com/xjpp2016/USAD.", "AI": {"tldr": "This paper aims to enhance anomaly detection in coal conveyor-belt scenes by introducing CoalAD benchmark and a collaborative framework for robust detection and localization.", "motivation": "To address the challenges of unstructured environments in coal mining, where current anomaly detection methods struggle due to random object arrangements, complex backgrounds, and low contrast of foreign objects.", "method": "The authors propose a complementary-cue collaborative perception framework combining object-level semantic modeling, deviation analysis, and texture matching.", "result": "The proposed framework outperforms baselines in both image-level and pixel-level anomaly detection on the CoalAD benchmark.", "conclusion": "The proposed method effectively addresses challenges in anomaly detection for coal mining, demonstrating improved performance over traditional methods."}}
{"id": "2602.07674", "pdf": "https://arxiv.org/pdf/2602.07674", "abs": "https://arxiv.org/abs/2602.07674", "authors": ["Bohdan Turbal", "Iryna Voitsitska", "Lesia Semenova"], "title": "ElliCE: Efficient and Provably Robust Algorithmic Recourse via the Rashomon Sets", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning models now influence decisions that directly affect people's lives, making it important to understand not only their predictions, but also how individuals could act to obtain better results. Algorithmic recourse provides actionable input modifications to achieve more favorable outcomes, typically relying on counterfactual explanations to suggest such changes. However, when the Rashomon set - the set of near-optimal models - is large, standard counterfactual explanations can become unreliable, as a recourse action valid for one model may fail under another. We introduce ElliCE, a novel framework for robust algorithmic recourse that optimizes counterfactuals over an ellipsoidal approximation of the Rashomon set. The resulting explanations are provably valid over this ellipsoid, with theoretical guarantees on uniqueness, stability, and alignment with key feature directions. Empirically, ElliCE generates counterfactuals that are not only more robust but also more flexible, adapting to user-specified feature constraints while being substantially faster than existing baselines. This provides a principled and practical solution for reliable recourse under model uncertainty, ensuring stable recommendations for users even as models evolve.", "AI": {"tldr": "The paper introduces ElliCE, a framework providing robust and fast algorithmic recourse under model uncertainty using an ellipsoidal approximation of near-optimal models.", "motivation": "Machine learning-driven decisions directly impact lives, necessitating robust and actionable explanations for individuals to obtain better outcomes amidst uncertainty in trained models.", "method": "Develop ElliCE, which optimizes counterfactual explanations over an ellipsoidal approximation of the Rashomon set and ensures theoretical validity across models. It also offers user-specified flexible constraints.", "result": "ElliCE generates robust, fast, and flexible counterfactuals that adapt to feature constraints while outperforming existing recourse models in stability and computational speed.", "conclusion": "ElliCE improves reliability and robustness in algorithmic recourse, offering stable solutions that accommodate evolving models and user-tailored constraints, solving key challenges in recourse validation."}}
{"id": "2602.08793", "pdf": "https://arxiv.org/pdf/2602.08793", "abs": "https://arxiv.org/abs/2602.08793", "authors": ["Yushi Sun", "Xujia Li", "Nan Tang", "Quanqing Xu", "Chuanhui Yang", "Lei Chen"], "title": "LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.", "AI": {"tldr": "The paper introduces LakeHopper, a framework for adapting pre-trained language models to new data lakes with minimal annotation.", "motivation": "To address the challenges of adapting pre-trained language models to new data lakes for column annotation while reducing the annotation overhead.", "method": "LakeHopper identifies knowledge gaps via LM interactions, selects informative data using a cluster-based scheme, and employs incremental fine-tuning to adapt the model to the target data lake.", "result": "Experimental results demonstrate the effectiveness of LakeHopper in adapting the model across data lake transfers in both low-resource and high-resource scenarios.", "conclusion": "LakeHopper successfully adapts pre-trained models to new data lakes, reducing the annotation burden and maintaining knowledge transfer."}}
{"id": "2602.07702", "pdf": "https://arxiv.org/pdf/2602.07702", "abs": "https://arxiv.org/abs/2602.07702", "authors": ["Deep Bhattacharyya", "Ali Ayub", "A. Ben Hamza"], "title": "A hybrid Kolmogorov-Arnold network for medical image segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Medical image segmentation plays a vital role in diagnosis and treatment planning, but remains challenging due to the inherent complexity and variability of medical images, especially in capturing non-linear relationships within the data. We propose U-KABS, a novel hybrid framework that integrates the expressive power of Kolmogorov-Arnold Networks (KANs) with a U-shaped encoder-decoder architecture to enhance segmentation performance. The U-KABS model combines the convolutional and squeeze-and-excitation stage, which enhances channel-wise feature representations, and the KAN Bernstein Spline (KABS) stage, which employs learnable activation functions based on Bernstein polynomials and B-splines. This hybrid design leverages the global smoothness of Bernstein polynomials and the local adaptability of B-splines, enabling the model to effectively capture both broad contextual trends and fine-grained patterns critical for delineating complex structures in medical images. Skip connections between encoder and decoder layers support effective multi-scale feature fusion and preserve spatial details. Evaluated across diverse medical imaging benchmark datasets, U-KABS demonstrates superior performance compared to strong baselines, particularly in segmenting complex anatomical structures.", "AI": {"tldr": "The paper introduces U-KABS, a novel hybrid framework for medical image segmentation, integrating Kolmogorov-Arnold Networks with a U-shaped architecture to improve segmentation accuracy and handling complex structures.", "motivation": "The paper aims to address challenges in medical image segmentation, particularly in capturing non-linear relationships and complex structures within medical imaging data.", "method": "The proposed method, U-KABS, combines a U-shaped encoder-decoder architecture and Kolmogorov-Arnold Networks. It merges convolutional and squeeze-and-excitation modules with learnable activation functions (using Bernstein polynomials and B-splines) for capturing global and local image patterns.", "result": "U-KABS shows superior segmentation performance across various medical imaging benchmark datasets, especially excelling in segmenting complex anatomical structures.", "conclusion": "The U-KABS framework effectively improves segmentation accuracy by blending global contextual trends and fine-grained details, making it suitable for complex medical image segmentation tasks."}}
{"id": "2602.08520", "pdf": "https://arxiv.org/pdf/2602.08520", "abs": "https://arxiv.org/abs/2602.08520", "authors": ["Xinhai Sun"], "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Modern large language models (LLMs) are often evaluated and deployed under a \\emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \\emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \\emph{without any retraining}.\n  On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\\% to 84.03\\%, while only incurring 61.06\\% additional inference calls. A 100\\% re-asking ablation reaches 84.35\\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \\emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone.\n  Beyond providing a practical inference-time upgrade, our results suggest a broader \\emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.", "AI": {"tldr": "The paper introduces Reinforcement Inference, a strategy to improve large language model (LLM) performance without retraining by using uncertainty-aware inference control.", "motivation": "To address the issue where one-shot greedy inference underestimates a model's capability due to premature commitment under ambiguity, particularly in deterministic professional settings.", "method": "Reinforcement Inference uses an entropy-aware control mechanism to selectively initiate a second reasoning attempt based on model uncertainty during inference.", "result": "The proposed method improved accuracy on MMLU-Pro questions from 60.72% to 84.03% with only 61.06% extra inference calls, outperforming alternatives while using significantly less computational resources.", "conclusion": "Reinforcement Inference demonstrates an effective way to leverage model uncertainty for performance improvement, suggesting a broader entropy-aware paradigm for model evaluation and training advancements."}}
{"id": "2602.07679", "pdf": "https://arxiv.org/pdf/2602.07679", "abs": "https://arxiv.org/abs/2602.07679", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Jing Yang", "Yongsen Zheng", "Kwok-Yan Lam", "Liang Lin", "Keze Wang"], "title": "Spectral Gating Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Gating mechanisms are ubiquitous, yet a complementary question in feed-forward networks remains under-explored: how to introduce frequency-rich expressivity without sacrificing stability and scalability? This tension is exposed by spline-based Kolmogorov-Arnold Network (KAN) parameterizations, where grid refinement can induce parameter growth and brittle optimization in high dimensions. To propose a stability-preserving way to inject spectral capacity into existing MLP/FFN layers under fixed parameter and training budgets, we introduce Spectral Gating Networks (SGN), a drop-in spectral reparameterization. SGN augments a standard activation pathway with a compact spectral pathway and learnable gates that allow the model to start from a stable base behavior and progressively allocate capacity to spectral features during training. The spectral pathway is instantiated with trainable Random Fourier Features (learned frequencies and phases), replacing grid-based splines and removing resolution dependence. A hybrid GELU-Fourier formulation further improves optimization robustness while enhancing high-frequency fidelity. Across vision, NLP, audio, and PDE benchmarks, SGN consistently improves accuracy-efficiency trade-offs under comparable computational budgets, achieving 93.15% accuracy on CIFAR-10 and up to 11.7x faster inference than spline-based KAN variants. Code and trained models will be released.", "AI": {"tldr": "The paper introduces Spectral Gating Networks (SGN), a mechanism to enhance frequency expressivity in feed-forward networks without sacrificing stability or scalability.", "motivation": "To address the lack of stability-preserving methods for introducing frequency-rich expressivity in feed-forward neural networks while keeping parameter and training budgets fixed.", "method": "SGN introduces a spectral reparameterization with a standard activation pathway augmented by a compact spectral pathway. It uses trainable Random Fourier Features (frequencies and phases) and employs a hybrid GELU-Fourier approach for better optimization and fidelity.", "result": "SGN achieves superior accuracy-efficiency trade-offs across diverse tasks, including 93.15% accuracy on CIFAR-10 and up to 11.7x faster inference compared to spline-based Kolmogorov-Arnold Network (KAN) alternatives.", "conclusion": "SGN offers a robust and scalable method to enhance spectral capacity in feed-forward networks while maintaining computational efficiency and stability."}}
{"id": "2602.08826", "pdf": "https://arxiv.org/pdf/2602.08826", "abs": "https://arxiv.org/abs/2602.08826", "authors": ["Chenghui Zou", "Ning Wang", "Tiesunlong Shen", "Luwei Xiao", "Chuan Ma", "Xiangpeng Li", "Rui Mao", "Erik Cambria"], "title": "Affective Flow Language Model for Emotional Support Conversation", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 7 figures", "summary": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.", "AI": {"tldr": "The paper introduces Affective Flow (AFlow), a model designed to improve multi-turn emotional support conversations by providing fine-grained affective supervision along dialogue trajectories, outperforming major LLMs.", "motivation": "Existing emotional support alignment schemes fail in complex multi-turn conversations due to sparse outcome-level signals, leading to inadequate guidance for intermediate strategy decisions.", "method": "The AFlow framework models continuous affective flows through multi-turn emotional conversations, estimating intermediate utility and employing a flow-balance objective for better strategy coherence.", "result": "AFlow consistently and significantly outperformed competitive baselines and proprietary LLMs (like GPT-4o, Claude-3.5) on emotional support metrics in diverse contexts.", "conclusion": "AFlow provides fine-grained supervision to improve emotional support dialogues and opens new pathways for efficient, high-performing open-source models in this domain."}}
{"id": "2602.07717", "pdf": "https://arxiv.org/pdf/2602.07717", "abs": "https://arxiv.org/abs/2602.07717", "authors": ["Yingjie Li", "Daniel Robinson", "Cunxi Yu"], "title": "All-Optical Segmentation via Diffractive Neural Networks for Autonomous Driving", "categories": ["cs.CV", "cs.ET"], "comment": null, "summary": "Semantic segmentation and lane detection are crucial tasks in autonomous driving systems. Conventional approaches predominantly rely on deep neural networks (DNNs), which incur high energy costs due to extensive analog-to-digital conversions and large-scale image computations required for low-latency, real-time responses. Diffractive optical neural networks (DONNs) have shown promising advantages over conventional DNNs on digital or optoelectronic computing platforms in energy efficiency. By performing all-optical image processing via light diffraction at the speed of light, DONNs save computation energy costs while reducing the overhead associated with analog-to-digital conversions by all-optical encoding and computing. In this work, we propose a novel all-optical computing framework for RGB image segmentation and lane detection in autonomous driving applications. Our experimental results demonstrate the effectiveness of the DONN system for image segmentation on the CityScapes dataset. Additionally, we conduct case studies on lane detection using a customized indoor track dataset and simulated driving scenarios in CARLA, where we further evaluate the model's generalizability under diverse environmental conditions.", "AI": {"tldr": "This paper presents a novel diffractive optical neural network (DONN) framework for RGB image segmentation and lane detection in autonomous driving, showcasing energy efficiency and effectiveness in real-world datasets.", "motivation": "Current deep neural networks for image segmentation and lane detection in autonomous driving are energy-intensive due to analog-to-digital conversions and large-scale computations.", "method": "An all-optical computing framework using diffractive optical neural networks (DONNs) is proposed to perform image segmentation and lane detection by leveraging light diffraction for computation.", "result": "Experimental results validated the DONN system's performance on the CityScapes dataset for image segmentation, and its generalizability in lane detection through indoor track and CARLA driving simulations under diverse conditions.", "conclusion": "The study highlights the DONN framework's potential in achieving energy-efficient image processing tasks while being effective in autonomous driving applications."}}
{"id": "2602.08533", "pdf": "https://arxiv.org/pdf/2602.08533", "abs": "https://arxiv.org/abs/2602.08533", "authors": ["Kun Peng", "Conghui Tan", "Yu Liu", "Guohua Tang", "Zhongqian Sun", "Wei Yang", "Zining Zhu", "Lei Jiang", "Yanbing Liu", "Hao Peng"], "title": "Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO", "categories": ["cs.AI"], "comment": null, "summary": "Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO). Adopting a two-agent game paradigm, a user agent constructs dynamic environments via style mimicry (learning user-specific conversational traits) and active termination (predicting turn-level termination probabilities as immediate rewards), forming an iterative cycle that drives the dialogue agent to deepen interest exploration. AT-GRPO reinterprets dialogue trajectories as trees and introduces adaptive observation ranges. Unlike full tree expansion that incurs exponential overhead, it limits each node to aggregate rewards from a stage-aware range: larger ranges support early-stage topic exploration, while smaller ranges facilitate late-stage dialogue maintenance. This design reduces rollout budgets from exponential to polynomial in the dialogue length, while preserving long-term reward capture. Extensive experiments show our framework's superior performance, sample efficiency, and robustness.", "AI": {"tldr": "This paper introduces a long-horizon RL framework, Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO), for better personalization and long-term value in open-ended dialogue systems.", "motivation": "Existing dialogue systems struggle with over-reliance on pre-collected user data and short-term biases in reinforcement learning, limiting dynamic personalization in long-term dialogue.", "method": "The approach integrates online personalization via a two-agent game paradigm, with one agent mimicking user behaviors and driving the other to adaptively explore interests. The RL incorporates AT-GRPO, a tree-based algorithm optimizing dialogue dynamics via adaptive observation ranges and polynomial resource efficiency.", "result": "The proposed framework achieved improved performance, sample efficiency, and robustness over existing systems in experiments.", "conclusion": "The novel long-horizon framework successfully balances personalization with computational efficiency in open-ended dialogue scenarios, addressing critical limitations of existing systems."}}
{"id": "2602.08829", "pdf": "https://arxiv.org/pdf/2602.08829", "abs": "https://arxiv.org/abs/2602.08829", "authors": ["Hao Peng", "Yunjia Qi", "Xiaozhi Wang", "Zijun Yao", "Lei Hou", "Juanzi Li"], "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.", "AI": {"tldr": "This paper introduces WildReward, a method for creating reward models using in-the-wild human interactions instead of human-annotated preference pairs, demonstrating strong performance and better adaptability.", "motivation": "The motivation is to reduce reliance on large-scale human-annotated preference pairs by leveraging implicit reward signals from in-the-wild interactions, which are increasingly available with widespread LLM deployment.", "method": "The method uses WildChat as a data source and a pipeline to extract reliable human feedback from interactions, yielding 186k instances. WildReward is trained using ordinal regression on this feedback, bypassing the need for preference pairs.", "result": "WildReward shows comparable or superior performance to traditional reward models, improved calibration, cross-sample consistency, and benefits from user diversity. It also enhances performance significantly when applied to online DPO training.", "conclusion": "WildReward demonstrates the potential to develop effective reward models from in-the-wild interactions, reducing reliance on costly human annotations and benefiting from diverse user data, offering new directions in LLM training."}}
{"id": "2602.07768", "pdf": "https://arxiv.org/pdf/2602.07768", "abs": "https://arxiv.org/abs/2602.07768", "authors": ["Qiuming Luo", "Yuebing Li", "Feng Li", "Chang Kong"], "title": "PAND: Prompt-Aware Neighborhood Distillation for Lightweight Fine-Grained Visual Classification", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "6pages, 3 figures, conference", "summary": "Distilling knowledge from large Vision-Language Models (VLMs) into lightweight networks is crucial yet challenging in Fine-Grained Visual Classification (FGVC), due to the reliance on fixed prompts and global alignment. To address this, we propose PAND (Prompt-Aware Neighborhood Distillation), a two-stage framework that decouples semantic calibration from structural transfer. First, we incorporate Prompt-Aware Semantic Calibration to generate adaptive semantic anchors. Second, we introduce a neighborhood-aware structural distillation strategy to constrain the student's local decision structure. PAND consistently outperforms state-of-the-art methods on four FGVC benchmarks. Notably, our ResNet-18 student achieves 76.09% accuracy on CUB-200, surpassing the strong baseline VL2Lite by 3.4%. Code is available at https://github.com/LLLVTA/PAND.", "AI": {"tldr": "The paper introduces PAND, a framework for better transferring knowledge from Vision-Language Models to smaller networks for Fine-Grained Visual Classification.", "motivation": "The motivation is to effectively distill knowledge from large Vision-Language Models into lightweight networks for FGVC, addressing challenges from fixed prompts and global alignment.", "method": "The paper presents a two-stage framework: Prompt-Aware Semantic Calibration for adaptive semantic anchors and neighborhood-aware structural distillation for local decision structure alignment.", "result": "PAND achieves superior results on four FGVC benchmarks, including a 76.09% accuracy with ResNet-18 on CUB-200, outperforming a strong baseline by 3.4%.", "conclusion": "PAND demonstrates an effective way to distill knowledge into smaller networks for FGVC, setting a new state-of-the-art approach. The method is available for reproducibility."}}
{"id": "2602.08586", "pdf": "https://arxiv.org/pdf/2602.08586", "abs": "https://arxiv.org/abs/2602.08586", "authors": ["Yiming Yang", "Zhuoyuan Li", "Fanxiang Zeng", "Hao Fu", "Yue Liu"], "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition", "categories": ["cs.AI"], "comment": null, "summary": "Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems.\n  We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems.", "AI": {"tldr": "The paper introduces PRISM, a new framework for multi-agent reasoning that outperforms existing methods by emphasizing diverse collaboration, effective feedback, and principled synthesis.", "motivation": "The paper aims to uncover why multi-agent collaboration outperforms single-agent reasoning, identifying the design elements that lead to performance improvements.", "method": "The authors propose a theoretical framework that breaks multi-agent reasoning into three factors: Exploration, Information, and Aggregation, and develop the PRISM framework to optimize these dimensions.", "result": "PRISM achieves state-of-the-art results in reasoning tasks like mathematical problem solving, code generation, and function calling, with better computational efficiency compared to others.", "conclusion": "The study provides a unified framework and actionable principles for designing more effective and efficient multi-agent reasoning systems."}}
{"id": "2602.07706", "pdf": "https://arxiv.org/pdf/2602.07706", "abs": "https://arxiv.org/abs/2602.07706", "authors": ["Yuanyun Zhang", "Mingxuan Zhang", "Siyuan Li", "Zihan Wang", "Haoran Chen", "Wenbo Zhou", "Shi Li"], "title": "Dense Feature Learning via Linear Structure Preservation in Medical Data", "categories": ["cs.LG"], "comment": "ICLR Workshop", "summary": "Deep learning models for medical data are typically trained using task specific objectives that encourage representations to collapse onto a small number of discriminative directions. While effective for individual prediction problems, this paradigm underutilizes the rich structure of clinical data and limits the transferability, stability, and interpretability of learned features. In this work, we propose dense feature learning, a representation centric framework that explicitly shapes the linear structure of medical embeddings. Our approach operates directly on embedding matrices, encouraging spectral balance, subspace consistency, and feature orthogonality through objectives defined entirely in terms of linear algebraic properties. Without relying on labels or generative reconstruction, dense feature learning produces representations with higher effective rank, improved conditioning, and greater stability across time. Empirical evaluations across longitudinal EHR data, clinical text, and multimodal patient representations demonstrate consistent improvements in downstream linear performance, robustness, and subspace alignment compared to supervised and self supervised baselines. These results suggest that learning to span clinical variation may be as important as learning to predict clinical outcomes, and position representation geometry as a first class objective in medical AI.", "AI": {"tldr": "This paper proposes dense feature learning to optimize medical embeddings' linear structure, improving performance, stability, and interpretability without relying on labels.", "motivation": "Current deep learning models underutilize clinical data structures, limiting transferability, stability, and interpretability of learned features.", "method": "They introduce dense feature learning, a framework manipulating embedding matrices to ensure spectral balance, subspace consistency, and orthogonality using linear algebraic objectives.", "result": "Dense feature learning enhances embeddings' rank, conditioning, and longitudinal stability, outperforming supervised and self-supervised baselines in clinical data tasks.", "conclusion": "Representation geometry should be prioritized in medical AI, as encompassing clinical variation is as crucial as predicting outcomes."}}
{"id": "2602.07395", "pdf": "https://arxiv.org/pdf/2602.07395", "abs": "https://arxiv.org/abs/2602.07395", "authors": ["Preeti Vyas", "Bereket Guta", "Tim G. Zhou", "Noor Naila Himam", "Andero Uusberg", "Karon E. MacLean"], "title": "Haptically Experienced Animacy Facilitates Emotion Regulation: A Theory-Driven Investigation", "categories": ["cs.HC", "cs.CY", "cs.ET", "cs.RO"], "comment": null, "summary": "Emotion regulation (ER) is essential to mental well-being but often difficult to access, especially in high-intensity moments or for individuals with clinical vulnerabilities. While existing technology-based ER tools offer value, they typically rely on self-reflection (e.g., emotion tracking, journaling) or co-regulation through verbal modalities (reminders, text-based conversational tools), which may not be accessible or effective when most needed. The biological role of the touch modality makes it an intriguing alternate pathway, but empirical evidence is limited and under-theorized. Building on our prior theoretical framework describing how a comforting haptic co-regulating adjunct (CHORA) can support ER, we developed a zoomorphic robot CHORA with looped biomimetic breathing and heartbeat behaviors. We evaluated its effects in a mixed-methods in-lab study (N=30), providing physiological, self-report, custom questionnaire, and retrospective interview data. Our findings demonstrate the regulatory effects of haptically experienced animacy, corroborate prior work, and validate CHORA's {theoretically grounded} potential to facilitate four ER strategies.", "AI": {"tldr": "The study explores a novel zoomorphic robot, CHORA, designed to aid emotion regulation through haptic interaction, providing empirical evidence of its effectiveness in stressful situations.", "motivation": "The paper addresses the limitations of existing emotion regulation tools, especially during high-intensity emotional moments or for individuals with clinical vulnerabilities. It explores haptic-based solutions due to the biological relevance of touch.", "method": "Developed a zoomorphic robot named CHORA with biomimetic breathing and heartbeat behaviors. Conducted a mixed-methods in-lab study with 30 participants to assess its regulatory effects using physiological data, self-reports, and interviews.", "result": "The study validated CHORA's potential in facilitating four emotion regulation strategies and demonstrated the regulatory effects of haptically experienced animacy.", "conclusion": "CHORA shows promise as a comforting and innovative emotion regulation tool leveraging haptic interaction, providing an alternative to traditional verbal and cognitive regulation methods."}}
{"id": "2602.08864", "pdf": "https://arxiv.org/pdf/2602.08864", "abs": "https://arxiv.org/abs/2602.08864", "authors": ["Ibraheem Muhammad Moosa", "Suhas Lohit", "Ye Wang", "Moitreya Chatterjee", "Wenpeng Yin"], "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.", "AI": {"tldr": "The paper explores token-level adaptive computation and its relationship to underlying complexities, introducing a systematic evaluation framework and a new recurrent Transformer model.", "motivation": "To address the unclear relationship between token-level compute allocation and task complexities in previous works, as token-level difficulty was unobservable in natural-language benchmarks.", "method": "The authors introduced a complexity-controlled evaluation with synthetic tasks, proposed a recurrent Transformer framework (ANIRA) supporting token-level variable-depth computation, and conducted an analysis of adaptive computation on alignment, generalization, and timing.", "result": "Compute allocation aligned with task complexity can emerge unsupervised, but does not guarantee generalization to unseen tasks. Structural cues guide early compute decisions, while online halting tracks execution state more closely.", "conclusion": "Token-level adaptive computation aligns to some extent with complexity but has limitations in algorithmic generalization and decision-making patterns."}}
{"id": "2602.07775", "pdf": "https://arxiv.org/pdf/2602.07775", "abs": "https://arxiv.org/abs/2602.07775", "authors": ["Haodong Li", "Shaoteng Liu", "Zhe Lin", "Manmohan Chandraker"], "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion", "categories": ["cs.CV"], "comment": "Figure PDFs were compressed to 150 dpi to comply with arXiv's submission size limit. Project page: https://rolling-sink.github.io/", "summary": "Recently, autoregressive (AR) video diffusion models has achieved remarkable performance. However, due to their limited training durations, a train-test gap emerges when testing at longer horizons, leading to rapid visual degradations. Following Self Forcing, which studies the train-test gap within the training duration, this work studies the train-test gap beyond the training duration, i.e., the gap between the limited horizons during training and open-ended horizons during testing. Since open-ended testing can extend beyond any finite training window, and long-video training is computationally expensive, we pursue a training-free solution to bridge this gap. To explore a training-free solution, we conduct a systematic analysis of AR cache maintenance. These insights lead to Rolling Sink. Built on Self Forcing (trained on only 5s clips), Rolling Sink effectively scales the AR video synthesis to ultra-long durations (e.g., 5-30 minutes at 16 FPS) at test time, with consistent subjects, stable colors, coherent structures, and smooth motions. As demonstrated by extensive experiments, Rolling Sink achieves superior long-horizon visual fidelity and temporal consistency compared to SOTA baselines. Project page: https://rolling-sink.github.io/", "AI": {"tldr": "The paper proposes 'Rolling Sink,' a method to improve autoregressive video diffusion models for ultra-long video synthesis without requiring additional training.", "motivation": "Autoregressive video diffusion models suffer rapid visual degradation when tested with video durations longer than those seen during training.", "method": "The authors analyze autoregressive cache maintenance and propose 'Rolling Sink,' a training-free technique that extends Self Forcing to scale video synthesis durations up to 30 minutes at 16 FPS.", "result": "'Rolling Sink' achieves superior long-horizon visual fidelity and temporal consistency compared to state-of-the-art baselines.", "conclusion": "The work demonstrates that a training-free solution like 'Rolling Sink' can effectively bridge the train-test gap in video diffusion models, enabling high-quality synthesis for extended durations."}}
{"id": "2602.08597", "pdf": "https://arxiv.org/pdf/2602.08597", "abs": "https://arxiv.org/abs/2602.08597", "authors": ["Roland Bertin-Johannet", "Lara Scipio", "Leopold Mayti\u00e9", "Rufin VanRullen"], "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture", "categories": ["cs.AI"], "comment": null, "summary": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.", "AI": {"tldr": "The paper proposes a top-down attention mechanism within the Global Workspace Theory framework, improving noise robustness and generalization in multimodal datasets.", "motivation": "To address the understudied attention mechanisms within the Global Workspace Theory framework, enhancing noise robustness and flexible cognition in multimodal systems.", "method": "The authors introduce a top-down attention mechanism for a global workspace system and evaluate it on multimodal datasets, comparing it to existing baselines.", "result": "The proposed attention mechanism improves noise robustness, enables unique cross-task and cross-modality generalization, and achieves competitive performance with state-of-the-art models on MM-IMDb 1.0.", "conclusion": "Incorporating a top-down attention mechanism makes the Global Workspace Theory system robust, generalizable, and comparable to state-of-the-art approaches in multimodal integration tasks."}}
{"id": "2602.07708", "pdf": "https://arxiv.org/pdf/2602.07708", "abs": "https://arxiv.org/abs/2602.07708", "authors": ["Ding Zhang", "Siddharth Betala", "Chirag Agarwal"], "title": "Quantifying Explanation Quality in Graph Neural Networks using Out-of-Distribution Generalization", "categories": ["cs.LG"], "comment": null, "summary": "Evaluating the quality of post-hoc explanations for Graph Neural Networks (GNNs) remains a significant challenge. While recent years have seen an increasing development of explainability methods, current evaluation metrics (e.g., fidelity, sparsity) often fail to assess whether an explanation identifies the true underlying causal variables. To address this, we propose the Explanation-Generalization Score (EGS), a metric that quantifies the causal relevance of GNN explanations. EGS is founded on the principle of feature invariance and posits that if an explanation captures true causal drivers, it should lead to stable predictions across distribution shifts. To quantify this, we introduce a framework that trains GNNs using explanatory subgraphs and evaluates their performance in Out-of-Distribution (OOD) settings (here, OOD generalization serves as a rigorous proxy for the explanation's causal validity). Through large-scale validation involving 11,200 model combinations across synthetic and real-world datasets, our results demonstrate that EGS provides a principled benchmark for ranking explainers based on their ability to capture causal substructures, offering a robust alternative to traditional fidelity-based metrics.", "AI": {"tldr": "The paper introduces the Explanation-Generalization Score (EGS), a metric for evaluating causal relevance in GNN explanations by measuring feature invariance and OOD generalization.", "motivation": "Current metrics for assessing explanations in GNNs fail to determine whether explanations identify true causal variables.", "method": "The proposed EGS measures feature invariance and evaluates explanatory subgraphs in Out-of-Distribution settings, using OOD generalization as a proxy for causal validity.", "result": "Large-scale validation involving 11,200 model combinations demonstrates EGS effectively ranks explainers based on their ability to capture causal substructures.", "conclusion": "EGS provides a robust and principled benchmark for evaluating the causal relevance of GNN explanations, improving upon traditional metrics."}}
{"id": "2602.08872", "pdf": "https://arxiv.org/pdf/2602.08872", "abs": "https://arxiv.org/abs/2602.08872", "authors": ["G. Cafferata", "T. Demarco", "K. Kalimeri", "Y. Mejova", "M. G. Beir\u00f3"], "title": "Large Language Models for Geolocation Extraction in Humanitarian Crisis Response", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.", "AI": {"tldr": "The paper proposes a framework using Large Language Models (LLMs) to improve fairness in extracting geolocation data from humanitarian documents, addressing geographic biases in crisis analytics.", "motivation": "The study aims to address geographic and socioeconomic biases in automated geolocation systems, ensuring equitable data visibility for crisis-affected regions during humanitarian responses.", "method": "A two-step framework: (1) Few-shot LLM-based named entity recognition and (2) an agent-based geocoding module for resolving ambiguous geographic names.", "result": "The proposed LLM-based method outperforms existing systems in both accuracy and fairness for geolocation extraction, especially for underrepresented regions.", "conclusion": "The integration of LLM reasoning with responsible AI principles offers a significant improvement in equitable geospatial data systems, supporting fairer humanitarian interventions."}}
{"id": "2602.07784", "pdf": "https://arxiv.org/pdf/2602.07784", "abs": "https://arxiv.org/abs/2602.07784", "authors": ["Jayawant Bodagala", "Balaji Bodagala"], "title": "Uncertainty-Aware Counterfactual Traffic Signal Control with Predictive Safety and Starvation-Avoidance Constraints Using Vision-Based Sensing", "categories": ["cs.CV"], "comment": "Total pages: 9", "summary": "Real-world deployment of adaptive traffic signal control, to date, remains limited due to the uncertainty associated with vision-based perception, implicit safety, and non-interpretable control policies learned and validated mainly in simulation. In this paper, we introduce UCATSC, a model-based traffic signal control system that models traffic signal control at an intersection using a stochastic decision process with constraints and under partial observability, taking into account the uncertainty associated with vision-based perception. Unlike reinforcement learning methods that learn to predict safety using reward shaping, UCATSC predicts and enforces hard constraints related to safety and starvation prevention during counterfactual rollouts in belief space. The system is designed to improve traffic delay and emission while preventing safety-critical errors and providing interpretable control policy outputs based on explicit models.", "AI": {"tldr": "The paper presents UCATSC, a model-based traffic signal control system that handles uncertainty in vision-based perception while ensuring safety and interpretability, contrasting reinforcement learning-based methods.", "motivation": "To address limitations in deploying adaptive traffic signal control due to uncertainties in vision-based perception, implicit safety concerns, and non-interpretable learned control policies.", "method": "UCATSC employs a stochastic decision process with constraints under partial observability. It introduces hard constraints for safety and starvation prevention, performing counterfactual rollouts in belief space.", "result": "The system enhances traffic delay and emission management while avoiding safety-critical errors, offering interpretable control outputs through explicit models.", "conclusion": "UCATSC showcases potential for real-world deployment by resolving key issues in adaptive traffic signal control, focusing on safety, interpretability, and handling uncertainty effectively."}}
{"id": "2602.08603", "pdf": "https://arxiv.org/pdf/2602.08603", "abs": "https://arxiv.org/abs/2602.08603", "authors": ["Teng Wang", "Rong Shan", "Jianghao Lin", "Junjie Wu", "Tianyi Xu", "Jianping Zhang", "Wenteng Chen", "Changwang Zhang", "Zhaoxiang Wang", "Weinan Zhang", "Jun Wang"], "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval", "categories": ["cs.AI"], "comment": null, "summary": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.", "AI": {"tldr": "The paper introduces OSCAR, a novel framework for composed image retrieval that outperforms existing methods by leveraging optimization-driven planning and reduced reliance on dataset-specific memorization.", "motivation": "Existing solutions for composed image retrieval struggle due to either overreliance on single models or inefficient heuristic methods.", "method": "The proposed OSCAR framework reformulates composed image retrieval as a trajectory optimization problem, combining offline mathematical modeling and online optimization using stored optimal trajectories.", "result": "Experiments show that OSCAR surpasses state-of-the-art methods on multiple benchmarks, even when trained on only 10% of the data.", "conclusion": "OSCAR demonstrates robust generalization and provides a more effective framework for complex reasoning in composed image retrieval."}}
{"id": "2602.07712", "pdf": "https://arxiv.org/pdf/2602.07712", "abs": "https://arxiv.org/abs/2602.07712", "authors": ["Alexandra Volkova", "Mher Safaryan", "Christoph H. Lampert", "Dan Alistarh"], "title": "Towards Robust Scaling Laws for Optimizers", "categories": ["cs.LG"], "comment": null, "summary": "The quality of Large Language Model (LLM) pretraining depends on multiple factors, including the compute budget and the choice of optimization algorithm. Empirical scaling laws are widely used to predict loss as model size and training data grow, however, almost all existing studies fix the optimizer (typically AdamW). At the same time, a new generation of optimizers (e.g., Muon, Shampoo, SOAP) promises faster and more stable convergence, but their relationship with model and data scaling is not yet well understood. In this work, we study scaling laws across different optimizers. Empirically, we show that 1) separate Chinchilla-style scaling laws for each optimizer are ill-conditioned and have highly correlated parameters. Instead, 2) we propose a more robust law with shared power-law exponents and optimizer-specific rescaling factors, which enable direct comparison between optimizers. Finally, 3) we provide a theoretical analysis of gradient-based methods for the proxy task of a convex quadratic objective, demonstrating that Chinchilla-style scaling laws emerge naturally as a result of loss decomposition into irreducible, approximation, and optimization errors.", "AI": {"tldr": "This paper explores scaling laws across various optimizers for large language model pretraining and proposes a unified robust scaling law with shared exponents to better compare optimizers.", "motivation": "Empirical scaling laws for model size and data growth have relied heavily on fixed optimizers like AdamW, while newer optimizers with faster convergence are not well understood in this context.", "method": "The authors empirically studied the behaviors of scaling laws across different optimizers, proposed a robust scaling law unifying optimizer-specific rescaling factors with shared power-law exponents, and conducted a theoretical analysis of gradient-based methods using a convex quadratic task.", "result": "The study revealed that separate scaling laws for optimizers yield correlated parameters and are ill-conditioned. The proposed unified law is more consistent and facilitates meaningful comparison between optimizers.", "conclusion": "Chinchilla-style scaling laws naturally arise from loss decomposition, and the proposed framework lays groundwork for understanding the scaling behavior across diverse LLM optimization strategies."}}
{"id": "2602.08874", "pdf": "https://arxiv.org/pdf/2602.08874", "abs": "https://arxiv.org/abs/2602.08874", "authors": ["Yu Fu", "Haz Sameen Shahgir", "Huanli Gong", "Zhipeng Wei", "N. Benjamin Erichson", "Yue Dong"], "title": "Is Reasoning Capability Enough for Safety in Long-Context Language Models?", "categories": ["cs.CL", "cs.CR"], "comment": "25 pages, 7 figures", "summary": "Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.", "AI": {"tldr": "This paper tests the hypothesis that stronger reasoning in large language models (LLMs) improves safety when handling implicit harmful intent. It introduces compositional reasoning attacks and finds that reasoning capability does not inherently make models more robust to such threats.", "motivation": "The study is motivated by the premise that advanced reasoning in LLMs could help models effectively recognize harmful intent, even when implicit, and improve their safety.", "method": "The method involves introducing compositional reasoning attacks, where harmful queries are split across long contexts and models are prompted to retrieve and synthesize them into harmful intent. The approach evaluates 14 LLMs on contexts up to 64k tokens.", "result": "The findings indicate: (1) stronger reasoning models are not inherently safer against compositional reasoning attacks; (2) safety alignment declines as context length increases; and (3) higher inference-time compute mitigates attack success rates.", "conclusion": "Improved reasoning does not guarantee safety in LLMs, especially in long-context scenarios. Safety measures require additional strategies beyond enhancing reasoning capabilities."}}
{"id": "2602.07801", "pdf": "https://arxiv.org/pdf/2602.07801", "abs": "https://arxiv.org/abs/2602.07801", "authors": ["Wenqi Liu", "Yunxiao Wang", "Shijie Ma", "Meng Liu", "Qile Su", "Tianke Zhang", "Haonan Fan", "Changyi Liu", "Kaiyu Jiang", "Jiankang Chen", "Kaiyu Tang", "Bin Wen", "Fan Yang", "Tingting Gao", "Han Li", "Yinwei Wei", "Xuemeng Song"], "title": "VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In long-video understanding, conventional uniform frame sampling often fails to capture key visual evidence, leading to degraded performance and increased hallucinations. To address this, recent agentic thinking-with-videos paradigms have emerged, adopting a localize-clip-answer pipeline in which the model actively identifies relevant video segments, performs dense sampling within those clips, and then produces answers. However, existing methods remain inefficient, suffer from weak localization, and adhere to rigid workflows. To solve these issues, we propose VideoTemp-o3, a unified agentic thinking-with-videos framework that jointly models video grounding and question answering. VideoTemp-o3 exhibits strong localization capability, supports on-demand clipping, and can refine inaccurate localizations. Specifically, in the supervised fine-tuning stage, we design a unified masking mechanism that encourages exploration while preventing noise. For reinforcement learning, we introduce dedicated rewards to mitigate reward hacking. Besides, from the data perspective, we develop an effective pipeline to construct high-quality long video grounded QA data, along with a corresponding benchmark for systematic evaluation across various video durations. Experimental results demonstrate that our method achieves remarkable performance on both long video understanding and grounding.", "AI": {"tldr": "This paper addresses issues in long-video understanding by introducing VideoTemp-o3, a framework that integrates video grounding and question answering, achieving improved performance.", "motivation": "To overcome the inefficiencies, weak localization, and rigid workflows in current long-video understanding methods, and to better capture key information in videos.", "method": "The proposed framework, VideoTemp-o3, unifies video grounding and question answering with a masking mechanism and reinforcement rewards, while introducing a new data pipeline and benchmark.", "result": "The method shows enhanced performance in both understanding and grounding of long videos, demonstrating strong localization and adaptability.", "conclusion": "VideoTemp-o3 significantly improves long-video understanding with better efficiency, adaptability, and performance in grounding and question answering tasks."}}
{"id": "2602.08630", "pdf": "https://arxiv.org/pdf/2602.08630", "abs": "https://arxiv.org/abs/2602.08630", "authors": ["Jonah Brown-Cohen", "Geoffrey Irving", "Simon C. Marshall", "Ilan Newman", "Georgios Piliouras", "Mario Szegedy"], "title": "Debate is efficient with your time", "categories": ["cs.AI", "cs.CC"], "comment": "11 Pages, 0 figures", "summary": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.\n  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.", "AI": {"tldr": "The paper introduces Debate Query Complexity (DQC), which examines the efficiency of human oversight in AI debates. It finds debates are very query-efficient, only requiring logarithmic queries for complex problems.", "motivation": "The motivation is to establish the practical cost (in terms of human oversight) for verifying solutions in AI safety debates, ensuring their usability for complex computational tasks.", "method": "The method involves defining Debate Query Complexity (DQC) as a measure for the minimum number of bits a verifier checks in a debate. The paper explores this for different function classes and problems.", "result": "The paper finds debates remarkably query-efficient, showing PSPACE/poly problems require O(log n) queries, with more general relations between queries, function inputs, and circuit complexities.", "conclusion": "Debate Query Complexity demonstrates efficient human oversight in AI debates. Further DQC lower bound proofs may inspire advancements in circuit complexity theory."}}
{"id": "2602.07715", "pdf": "https://arxiv.org/pdf/2602.07715", "abs": "https://arxiv.org/abs/2602.07715", "authors": ["Roi Benita", "Michael Elad", "Joseph Keshet"], "title": "Analyzing and Guiding Zero-Shot Posterior Sampling in Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Recovering a signal from its degraded measurements is a long standing challenge in science and engineering. Recently, zero-shot diffusion based methods have been proposed for such inverse problems, offering a posterior sampling based solution that leverages prior knowledge. Such algorithms incorporate the observations through inference, often leaning on manual tuning and heuristics. In this work we propose a rigorous analysis of such approximate posterior-samplers, relying on a Gaussianity assumption of the prior. Under this regime, we show that both the ideal posterior sampler and diffusion-based reconstruction algorithms can be expressed in closed-form, enabling their thorough analysis and comparisons in the spectral domain. Building on these representations, we also introduce a principled framework for parameter design, replacing heuristic selection strategies used to date. The proposed approach is method-agnostic and yields tailored parameter choices for each algorithm, jointly accounting for the characteristics of the prior, the degraded signal, and the diffusion dynamics. We show that our spectral recommendations differ structurally from standard heuristics and vary with the diffusion step size, resulting in a consistent balance between perceptual quality and signal fidelity.", "AI": {"tldr": "The paper analyzes and improves zero-shot diffusion-based methods for signal recovery by introducing a principled framework for parameter design.", "motivation": "Signal recovery from degraded measurements is a long-standing challenge and zero-shot diffusion-based methods require heuristic inference adjustments, which lack rigour.", "method": "The authors assume a Gaussian prior, analyze posterior samplers in closed-form, and establish a framework for principled parameter design without heuristic reliance.", "result": "The new framework provides tailored parameter choices that adapt to the degraded signal, prior characteristics, and diffusion dynamics, surpassing heuristic methods.", "conclusion": "The new method offers a systematic, algorithm-agnostic parameter design framework, improving the consistency and balance between perceptual quality and signal fidelity."}}
{"id": "2602.07938", "pdf": "https://arxiv.org/pdf/2602.07938", "abs": "https://arxiv.org/abs/2602.07938", "authors": ["Rabbia Asghar", "Lukas Rummelhard", "Wenqian Liu", "Anne Spalanzani", "Christian Laugier"], "title": "Integrating Specialized and Generic Agent Motion Prediction with Dynamic Occupancy Grid Maps", "categories": ["cs.CV", "cs.RO"], "comment": "Updated version with major revisions; currently under the second round of review at IEEE Transactions on Intelligent Vehicles", "summary": "Accurate prediction of driving scene is a challenging task due to uncertainty in sensor data, the complex behaviors of agents, and the possibility of multiple feasible futures. Existing prediction methods using occupancy grid maps primarily focus on agent-agnostic scene predictions, while agent-specific predictions provide specialized behavior insights with the help of semantic information. However, both paradigms face distinct limitations: agent-agnostic models struggle to capture the behavioral complexities of dynamic actors, whereas agent-specific approaches fail to generalize to poorly perceived or unrecognized agents; combining both enables robust and safer motion forecasting. To address this, we propose a unified framework by leveraging Dynamic Occupancy Grid Maps within a streamlined temporal decoding pipeline to simultaneously predict future occupancy state grids, vehicle grids, and scene flow grids. Relying on a lightweight spatiotemporal backbone, our approach is centered on a tailored, interdependent loss function that captures inter-grid dependencies and enables diverse future predictions. By using occupancy state information to enforce flow-guided transitions, the loss function acts as a regularizer that directs occupancy evolution while accounting for obstacles and occlusions. Consequently, the model not only predicts the specific behaviors of vehicle agents, but also identifies other dynamic entities and anticipates their evolution within the complex scene. Evaluations on real-world nuScenes and Woven Planet datasets demonstrate superior prediction performances for dynamic vehicles and generic dynamic scene elements compared to baseline methods.", "AI": {"tldr": "The paper introduces a unified framework to predict dynamic driving scenes more accurately by combining agent-specific and agent-agnostic methods. The proposed approach leverages a tailored loss function and Dynamic Occupancy Grid Maps to produce diverse and robust predictions.", "motivation": "The motivation is to address the challenges in predicting driving scenes due to sensor uncertainties, agent complexities, and diverse possible futures. Existing methods either ignore dynamic agents' behaviors or fail to generalize across different objects, necessitating a hybrid approach.", "method": "The paper proposes a unified method using Dynamic Occupancy Grid Maps alongside a lightweight spatiotemporal backbone. A custom loss function is used to enforce dependency relationships among occupancy, vehicle, and scene flow grids while guiding accurate scene predictions.", "result": "The framework achieves superior performance in predicting the behaviors of dynamic vehicles and other scene elements. Its effectiveness is validated on the nuScenes and Woven Planet datasets, outperforming existing baselines.", "conclusion": "Combining agent-agnostic and agent-specific predictions creates a robust system for motion forecasting. The tailored loss function ensures a detailed, obstacle-aware prediction framework, offering better scene understanding and safety in real-world driving scenarios."}}
{"id": "2602.08945", "pdf": "https://arxiv.org/pdf/2602.08945", "abs": "https://arxiv.org/abs/2602.08945", "authors": ["Sahajpreet Singh", "Kokil Jaidka", "Min-Yen Kan"], "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search", "categories": ["cs.CL", "cs.CY"], "comment": "18 pages, 11 figures, 7 tables", "summary": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.", "AI": {"tldr": "The paper introduces GitSearch, a framework that targets human-perceived quality gaps in community moderation for scalable and effective fact-checking, achieving higher coverage and helpfulness than state-of-the-art and human-generated notes.", "motivation": "To address structural challenges and limitations of AI methods in community-based moderation, especially in \"cold start\" scenarios where traditional approaches fail.", "method": "GitSearch employs a three-stage pipeline: identifying information deficits, using real-time web retrieval to address deficits, and synthesizing platform-compliant responses.", "result": "GitSearch achieves 99% coverage, nearly doubling existing state-of-the-art performance, with a win rate of 69% against human-authored notes and improved helpfulness scores (3.87 vs. 3.36).", "conclusion": "GitSearch demonstrates the effectiveness of targeted search methods for scalable and quality-focused community moderation, offering a significant improvement in both coverage and helpfulness of fact-checking responses."}}
{"id": "2602.07814", "pdf": "https://arxiv.org/pdf/2602.07814", "abs": "https://arxiv.org/abs/2602.07814", "authors": ["Simiao Ren", "Yuchen Zhou", "Xingyu Shen", "Kidus Zewde", "Tommy Duong", "George Huang", "Hatsanai", "Tiangratanakul", "Tsang", "Ng", "En Wei", "Jiayu Xue"], "title": "How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As AI-generated images proliferate across digital platforms, reliable detection methods have become critical for combating misinformation and maintaining content authenticity. While numerous deepfake detection methods have been proposed, existing benchmarks predominantly evaluate fine-tuned models, leaving a critical gap in understanding out-of-the-box performance -- the most common deployment scenario for practitioners. We present the first comprehensive zero-shot evaluation of 16 state-of-the-art detection methods, comprising 23 pretrained detector variants (due to multiple released versions of certain detectors), across 12 diverse datasets, comprising 2.6~million image samples spanning 291 unique generators including modern diffusion models. Our systematic analysis reveals striking findings: (1)~no universal winner exists, with detector rankings exhibiting substantial instability (Spearman~$\u03c1$: 0.01 -- 0.87 across dataset pairs); (2)~a 37~percentage-point performance gap separates the best detector (75.0\\% mean accuracy) from the worst (37.5\\%); (3)~training data alignment critically impacts generalization, causing up to 20--60\\% performance variance within architecturally identical detector families; (4)~modern commercial generators (Flux~Dev, Firefly~v4, Midjourney~v7) defeat most detectors, achieving only 18--30\\% average accuracy; and (5)~we identify three systematic failure patterns affecting cross-dataset generalization. Statistical analysis confirms significant performance differences between detectors (Friedman test: $\u03c7^2$=121.01, $p<10^{-16}$, Kendall~$W$=0.524). Our findings challenge the ``one-size-fits-all'' detector paradigm and provide actionable deployment guidelines, demonstrating that practitioners must carefully select detectors based on their specific threat landscape rather than relying on published benchmark performance.", "AI": {"tldr": "This paper evaluates zero-shot performance of 23 pretrained AI-generated image detectors across diverse datasets and highlights challenges compromising generalization and performance consistency.", "motivation": "The paper seeks to address the need for reliable methods to detect AI-generated images, focusing on zero-shot detection performance\u2014a critical gap in current benchmarks that often evaluate fine-tuned models.", "method": "The authors conducted a zero-shot evaluation of 23 pretrained detector variants across 12 datasets, featuring over 2.6 million images from 291 AI image generators. Statistical analyses were performed to identify patterns and inconsistencies across detection methods.", "result": "Key findings include substantial instability in detector rankings across datasets, wide performance gaps between detectors, impact of training data alignment on generalization, poor detection accuracy for modern generators, and identification of failure patterns affecting generalization.", "conclusion": "The paper challenges the universal applicability of detection methods, urging practitioners to select detectors tailored to their specific threat scenarios instead of relying solely on benchmark results."}}
{"id": "2602.08707", "pdf": "https://arxiv.org/pdf/2602.08707", "abs": "https://arxiv.org/abs/2602.08707", "authors": ["Aditya Gulati", "Nuria Oliver"], "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers", "categories": ["cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.", "AI": {"tldr": "Chatbots manipulate trust via design choices, warranting research on trust formation and calibration.", "motivation": "Explore the mechanisms and ethical concerns around trust in conversational AI.", "method": "Analyzes conceptual frameworks of trust in chatbots, contrasting behavioral and normative approaches.", "result": "Proposes viewing chatbots as salespeople emphasizing organizational objectives, not companions.", "conclusion": "Calls for clarity between trust mechanisms and stronger user trust calibration efforts."}}
{"id": "2602.07719", "pdf": "https://arxiv.org/pdf/2602.07719", "abs": "https://arxiv.org/abs/2602.07719", "authors": ["Gabriel Stella"], "title": "Efficient Planning in Reinforcement Learning via Model Introspection", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning and classical planning are typically seen as two distinct problems, with differing formulations necessitating different solutions. Yet, when humans are given a task, regardless of the way it is specified, they can often derive the additional information needed to solve the problem efficiently. The key to this ability is introspection: by reasoning about their internal models of the problem, humans directly synthesize additional task-relevant information. In this paper, we propose that this introspection can be thought of as program analysis. We discuss examples of how this approach can be applied to various kinds of models used in reinforcement learning. We then describe an algorithm that enables efficient goal-oriented planning over the class of models used in relational reinforcement learning, demonstrating a novel link between reinforcement learning and classical planning.", "AI": {"tldr": "This paper proposes an introspective approach, linking reinforcement learning and classical planning through program analysis and a new algorithm.", "motivation": "To address the gap between reinforcement learning and classical planning by enabling efficient problem-solving through introspection akin to human reasoning.", "method": "Introduces the concept of problem introspection as program analysis and describes an algorithm for efficient goal-oriented planning in relational reinforcement learning models.", "result": "Demonstrates the connection between reinforcement learning and classical planning using the proposed algorithm for relational reinforcement learning.", "conclusion": "The paper bridges the gap between the two fields, suggesting introspection as a key mechanism and offering a practical method to enhance problem-solving efficiency."}}
{"id": "2602.08006", "pdf": "https://arxiv.org/pdf/2602.08006", "abs": "https://arxiv.org/abs/2602.08006", "authors": ["Riya Mohan", "Juana Valeria Hurtado", "Rohit Mohan", "Abhinav Valada"], "title": "ForecastOcc: Vision-based Semantic Occupancy Forecasting", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Autonomous driving requires forecasting both geometry and semantics over time to effectively reason about future environment states. Existing vision-based occupancy forecasting methods focus on motion-related categories such as static and dynamic objects, while semantic information remains largely absent. Recent semantic occupancy forecasting approaches address this gap but rely on past occupancy predictions obtained from separate networks. This makes current methods sensitive to error accumulation and prevents learning spatio-temporal features directly from images. In this work, we present ForecastOcc, the first framework for vision-based semantic occupancy forecasting that jointly predicts future occupancy states and semantic categories. Our framework yields semantic occupancy forecasts for multiple horizons directly from past camera images, without relying on externally estimated maps. We evaluate ForecastOcc in two complementary settings: multi-view forecasting on the Occ3D-nuScenes dataset and monocular forecasting on SemanticKITTI, where we establish the first benchmark for this task. We introduce the first baselines by adapting two 2D forecasting modules within our framework. Importantly, we propose a novel architecture that incorporates a temporal cross-attention forecasting module, a 2D-to-3D view transformer, a 3D encoder for occupancy prediction, and a semantic occupancy head for voxel-level forecasts across multiple horizons. Extensive experiments on both datasets show that ForecastOcc consistently outperforms baselines, yielding semantically rich, future-aware predictions that capture scene dynamics and semantics critical for autonomous driving.", "AI": {"tldr": "ForecastOcc is a new vision-based framework that predicts semantic occupancy and future states directly from camera images, aiding autonomous driving.", "motivation": "Existing occupancy forecasting methods for autonomous driving neglect semantic forecasting and often rely on separate networks for past predictions, leading to error accumulation.", "method": "ForecastOcc integrates a novel temporal cross-attention forecasting module, a 2D-to-3D view transformer, 3D encoder for occupancy prediction, and semantic occupancy head for voxel-level predictions.", "result": "The framework surpasses baselines on Occ3D-nuScenes and SemanticKITTI datasets, showcasing rich semantic and dynamic scene predictions.", "conclusion": "ForecastOcc is an effective and innovative approach for semantic forecasting, directly predicting future environment states crucial for autonomous driving."}}
{"id": "2602.08951", "pdf": "https://arxiv.org/pdf/2602.08951", "abs": "https://arxiv.org/abs/2602.08951", "authors": ["Rasul Dent", "Pedro Ortiz Suarez", "Thibault Cl\u00e9rice", "Beno\u00eet Sagot"], "title": "How Should We Model the Probability of a Language?", "categories": ["cs.CL"], "comment": "Accepted for Vardial 2026", "summary": "Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.", "AI": {"tldr": "This paper discusses the limitations of current language identification systems, particularly for lesser-known languages, and proposes a new approach to improve coverage.", "motivation": "To address the lack of reliable coverage in identifying less common languages by commercial and research-grade LID systems.", "method": "The paper reconceptualizes language identification as a routing problem, emphasizing the importance of incorporating environmental cues rather than relying on static, decontextualized text classification.", "result": "It highlights the limitations of fixed-prior models and makes a case for developing dynamic, contextual approaches to cover underrepresented languages.", "conclusion": "Reframing LID as a routing problem with the integration of local environmental factors could significantly improve language coverage and identification for tail languages."}}
{"id": "2602.07815", "pdf": "https://arxiv.org/pdf/2602.07815", "abs": "https://arxiv.org/abs/2602.07815", "authors": ["Simiao Ren"], "title": "Out of the box age estimation through facial imagery: A Comprehensive Benchmark of Vision-Language Models vs. out-of-the-box Traditional Architectures", "categories": ["cs.CV"], "comment": null, "summary": "Facial age estimation is critical for content moderation, age verification, and deepfake detection, yet no prior benchmark has systematically compared modern vision-language models (VLMs) against specialized age estimation architectures. We present the first large-scale cross-paradigm benchmark, evaluating \\textbf{34 models} -- 22 specialized architectures with publicly available pretrained weights and 12 general-purpose VLMs -- across \\textbf{8 standard datasets} (UTKFace, IMDB-WIKI, MORPH, AFAD, CACD, FG-NET, APPA-REAL, AgeDB) totaling 1{,}100 test images per model. Our key finding is striking: \\emph{zero-shot VLMs significantly outperform most specialized models}, achieving an average MAE of 5.65 years compared to 9.88 for non-LLM models. The best VLM (Gemini~3 Flash Preview, MAE~4.32) outperforms the best non-LLM model (MiVOLO, MAE~5.10) by 15\\%. Only MiVOLO, which uniquely combines face and body features via Vision Transformers, competes with VLMs. We further analyze age verification at the 18-year threshold, revealing that non-LLM models exhibit 60--100\\% false adult rates on minors while VLMs achieve 13--25\\%, and demonstrate that coarse age binning (8--9 classes) consistently degrades MAE beyond 13 years. Our stratified analysis across 14 age groups reveals that all models struggle most at extreme ages ($<$5 and 65+). These findings challenge the assumption that task-specific architectures are necessary for age estimation and suggest that the field should redirect toward distilling VLM capabilities into efficient specialized models.", "AI": {"tldr": "The paper presents the first large-scale benchmark comparing vision-language models (VLMs) and specialized age estimation models, showing VLMs significantly outperform in age estimation tasks.", "motivation": "To evaluate whether modern vision-language models (VLMs) can outperform task-specific age estimation architectures and challenge assumptions about the necessity of specialized models.", "method": "The study evaluates 34 models (22 specialized and 12 general-purpose VLMs) on 8 standard datasets with 1,100 test images per model. Metrics like Mean Absolute Error (MAE) and performance at age verification thresholds are analyzed.", "result": "Zero-shot VLMs achieved better performance (e.g., lowest MAE of 4.32) than most specialized models (average MAE 9.88). The best-performing VLM outperformed the best non-LLM by 15%, and false adult rates were significantly lower in VLMs compared to non-LLM models.", "conclusion": "VLMs surpass specialized models in age estimation tasks, especially in extreme age groups. The field should focus on distilling VLM capabilities into efficient specialized models to capitalize on their advantages."}}
{"id": "2602.08708", "pdf": "https://arxiv.org/pdf/2602.08708", "abs": "https://arxiv.org/abs/2602.08708", "authors": ["Stefan Edelkamp", "Ji\u0159\u00ed Fink", "Petr Gregor", "Anders Jonsson", "Bernhard Nebel"], "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$", "categories": ["cs.AI"], "comment": null, "summary": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.", "AI": {"tldr": "The paper examines the computational complexity of propositional STRIPS$^1_1$ planning, using SAT solvers, literal graphs, and Petri net mapping.", "motivation": "To investigate whether propositional STRIPS planning with operators having one precondition and one effect is NP-complete.", "method": "Utilizes SAT solvers for small instances, introduces a literal graph representation, and maps it to Petri nets.", "result": "Provides insights into the computational complexity of small solution hypothesis for STRIPS$^1_1$ planning.", "conclusion": "Advances understanding of STRIPS$^1_1$ planning complexity and contributes tools for further computational exploration."}}
{"id": "2602.07721", "pdf": "https://arxiv.org/pdf/2602.07721", "abs": "https://arxiv.org/abs/2602.07721", "authors": ["Yanlin Qi", "Xinhang Chen", "Huiqiang Jiang", "Qitong Wang", "Botao Peng", "Themis Palpanas"], "title": "ParisKV: Fast and Drift-Robust KV-Cache Retrieval for Long-Context LLMs", "categories": ["cs.LG", "cs.CL", "cs.DB"], "comment": "25 pages, 16 figures. Under review", "summary": "KV-cache retrieval is essential for long-context LLM inference, yet existing methods struggle with distribution drift and high latency at scale. We introduce ParisKV, a drift-robust, GPU-native KV-cache retrieval framework based on collision-based candidate selection, followed by a quantized inner-product reranking estimator. For million-token contexts, ParisKV supports CPU-offloaded KV caches via Unified Virtual Addressing (UVA), enabling on-demand top-$k$ fetching with minimal overhead. ParisKV matches or outperforms full attention quality on long-input and long-generation benchmarks. It achieves state-of-the-art long-context decoding efficiency: it matches or exceeds full attention speed even at batch size 1 for long contexts, delivers up to 2.8$\\times$ higher throughput within full attention's runnable range, and scales to million-token contexts where full attention runs out of memory. At million-token scale, ParisKV reduces decode latency by 17$\\times$ and 44$\\times$ compared to MagicPIG and PQCache, respectively, two state-of-the-art KV-cache Top-$k$ retrieval baselines.", "AI": {"tldr": "ParisKV improves KV-cache retrieval for long-context LLM inference by decreasing latency and supporting robust performance, while scaling efficiently to million-token contexts.", "motivation": "Address the challenges of distribution drift and high latency in KV-cache retrieval for long-context LLM inference.", "method": "ParisKV utilizes collision-based candidate selection and quantized inner-product reranking estimator, along with GPU-native computation and CPU-offloaded KV caches using Unified Virtual Addressing.", "result": "ParisKV delivers state-of-the-art long-context decoding efficiency, greatly reducing latency and outperforming prior baselines in benchmarks for large-scale contexts.", "conclusion": "ParisKV enables robust and efficient KV-cache retrieval for long-context processing, offering noteworthy improvements in speed, throughput, and scalability compared to existing methods."}}
{"id": "2602.08058", "pdf": "https://arxiv.org/pdf/2602.08058", "abs": "https://arxiv.org/abs/2602.08058", "authors": ["Xihang Yu", "Rajat Talak", "Lorenzo Shaikewitz", "Luca Carlone"], "title": "Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling", "categories": ["cs.CV", "cs.AI", "cs.RO", "eess.SY"], "comment": "15 pages", "summary": "In the presence of occlusions and measurement noise, geometrically accurate scene reconstructions -- which fit the sensor data -- can still be physically incorrect. For instance, when estimating the poses and shapes of objects in the scene and importing the resulting estimates into a simulator, small errors might translate to implausible configurations including object interpenetration or unstable equilibrium. This makes it difficult to predict the dynamic behavior of the scene using a digital twin, an important step in simulation-based planning and control of contact-rich behaviors. In this paper, we posit that object pose and shape estimation requires reasoning holistically over the scene (instead of reasoning about each object in isolation), accounting for object interactions and physical plausibility. Towards this goal, our first contribution is Picasso, a physics-constrained reconstruction pipeline that builds multi-object scene reconstructions by considering geometry, non-penetration, and physics. Picasso relies on a fast rejection sampling method that reasons over multi-object interactions, leveraging an inferred object contact graph to guide samples. Second, we propose the Picasso dataset, a collection of 10 contact-rich real-world scenes with ground truth annotations, as well as a metric to quantify physical plausibility, which we open-source as part of our benchmark. Finally, we provide an extensive evaluation of Picasso on our newly introduced dataset and on the YCB-V dataset, and show it largely outperforms the state of the art while providing reconstructions that are both physically plausible and more aligned with human intuition.", "AI": {"tldr": "This paper introduces Picasso, a physics-constrained reconstruction pipeline for creating physically plausible multi-object scene reconstructions, along with a new dataset and metric for evaluating physical plausibility.", "motivation": "To address the limitations of traditional scene reconstructions which, despite being geometrically accurate, can result in physically implausible configurations, limiting their applicability in simulation-based planning and contact-rich dynamic behavior prediction.", "method": "The authors developed Picasso, a scene reconstruction pipeline that incorporates geometry, non-penetration, and physical constraints via fast rejection sampling and an object contact graph. They also created the Picasso dataset with annotations and a new physical plausibility metric.", "result": "Picasso outperforms existing methods in creating scene reconstructions that are more physically plausible and intuitive, validated on both the Picasso dataset and the YCB-V dataset.", "conclusion": "Holistic reasoning over scenes, including object interactions and physical plausibility, is essential for reconstructing realistic and dynamically meaningful scenes. Picasso sets a new standard in this area with its superior performance."}}
{"id": "2602.08984", "pdf": "https://arxiv.org/pdf/2602.08984", "abs": "https://arxiv.org/abs/2602.08984", "authors": ["Yuliang Liu", "Yunchong Song", "Yixuan Wang", "Kewen Ge", "Alex Lamb", "Qipeng Guo", "Kai Chen", "Bowen Zhou", "Zhouhan Lin"], "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.", "AI": {"tldr": "The paper presents Next Concept Prediction (NCP), a tougher generative pretraining paradigm than standard token-level models and demonstrates its ability to enhance language modeling performance.", "motivation": "Improve language modeling by introducing a more challenging pretraining paradigm beyond simple next-token prediction to drive better representations and performance.", "method": "ConceptLM uses Vector Quantization to generate discrete concepts from hidden states, creating a concept vocabulary. It integrates NCP and NTP for parameter updates in language model training and utilizes concepts for guiding token generation.", "result": "Through experiments with models ranging from 70M to 1.5B parameters and benchmarks, NCP consistently outperforms traditional token-level pretraining. Additionally, continual pretraining on larger models shows further performance improvement.", "conclusion": "NCP provides a promising approach to advancing generative language modeling by introducing a harder pretraining task that can yield stronger language representations and results."}}
{"id": "2602.07820", "pdf": "https://arxiv.org/pdf/2602.07820", "abs": "https://arxiv.org/abs/2602.07820", "authors": ["Zhibo Chen", "Yu Guan", "Yajuan Huang", "Chaoqi Chen", "XiangJi", "Qiuyun Fan", "Dong Liang", "Qiegen Liu"], "title": "Back to Physics: Operator-Guided Generative Paths for SMS MRI Reconstruction", "categories": ["cs.CV"], "comment": "10 pages, 6 figures", "summary": "Simultaneous multi-slice (SMS) imaging with in-plane undersampling enables highly accelerated MRI but yields a strongly coupled inverse problem with deterministic inter-slice interference and missing k-space data. Most diffusion-based reconstructions are formulated around Gaussian-noise corruption and rely on additional consistency steps to incorporate SMS physics, which can be mismatched to the operator-governed degradations in SMS acquisition. We propose an operator-guided framework that models the degradation trajectory using known acquisition operators and inverts this process via deterministic updates. Within this framework, we introduce an operator-conditional dual-stream interaction network (OCDI-Net) that explicitly disentangles target-slice content from inter-slice interference and predicts structured degradations for operator-aligned inversion, and we instantiate reconstruction as a two-stage chained inference procedure that performs SMS slice separation followed by in-plane completion. Experiments on fastMRI brain data and prospectively acquired in vivo diffusion MRI data demonstrate improved fidelity and reduced slice leakage over conventional and learning-based SMS reconstructions.", "AI": {"tldr": "The paper proposes a novel operator-guided framework and neural network model (OCDI-Net) to achieve improved MRI reconstruction for simultaneous multi-slice (SMS) imaging with highly accelerated and fidelity-enhanced results.", "motivation": "Conventional methods for reconstructing SMS MRI images struggle with inter-slice interference and missing k-space data, leading to suboptimal results. This paper aims to address this issue using operator-guided approaches.", "method": "The authors develop an operator-guided reconstruction framework with a dual-stream interaction network (OCDI-Net) that separates target-slice content from interference and inverts the degradation process in two stages: SMS slice separation and in-plane completion.", "result": "The proposed approach demonstrates superior performance with improved fidelity and reduced slice leakage in experiments involving fastMRI brain data and in vivo diffusion MRI data.", "conclusion": "Model-based reconstruction using operator guidance and the OCDI-Net framework offers a significant improvement in SMS imaging, paving the way for enhanced image quality in highly accelerated MRI applications."}}
{"id": "2602.08715", "pdf": "https://arxiv.org/pdf/2602.08715", "abs": "https://arxiv.org/abs/2602.08715", "authors": ["Miquel Mir\u00f3-Nicolau", "Gabriel Moy\u00e0-Alcover", "Anna Arias-Duart"], "title": "Exploring SAIG Methods for an Objective Evaluation of XAI", "categories": ["cs.AI"], "comment": null, "summary": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.", "AI": {"tldr": "This paper reviews and analyzes Synthetic Artificial Intelligence Ground truth (SAIG) methods for evaluating XAI techniques, introducing a taxonomy and highlighting gaps in consensus.", "motivation": "To address the challenge of objectively evaluating XAI methods due to the absence of a universal ground truth for explanations.", "method": "Review and analysis of existing SAIG methods, introducing a taxonomy with seven key features to classify approaches.", "result": "The study identifies a lack of consensus on effective XAI evaluation techniques and establishes the need for standardization.", "conclusion": "Further research and standardization are essential to advance objective XAI evaluation techniques using SAIG methods."}}
{"id": "2602.07729", "pdf": "https://arxiv.org/pdf/2602.07729", "abs": "https://arxiv.org/abs/2602.07729", "authors": ["Sagnik Mukherjee", "Lifan Yuan", "Pavan Jayasinha", "Dilek Hakkani-T\u00fcr", "Hao Peng"], "title": "Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL), particularly RL from verifiable reward (RLVR), has become a crucial phase of training large language models (LLMs) and a key focus of current scaling efforts. However, optimization practices in RL largely follow those of next-token prediction stages (e.g., pretraining and supervised fine-tuning), despite fundamental differences between RL and these stages highlighted by recent work. One such practice is the use of the AdamW optimizer, which is widely adopted for training large-scale transformers despite its high memory overhead. Our analysis shows that both momentum and adaptive learning rates in AdamW are less influential in RL than in SFT, leading us to hypothesize that RL benefits less from Adam-style per-parameter adaptive learning rates and momentum. Confirming this hypothesis, our experiments demonstrate that the substantially more memory-efficient SGD, which is known to perform poorly in supervised learning of large-scale transformers, matches or even outperforms AdamW in RL for LLMs. Remarkably, full fine-tuning with SGD updates fewer than 0.02% of model parameters without any sparsity-promoting regularization, more than 1000 times fewer than AdamW. Our analysis offers potential reasons for this update sparsity. These findings provide new insights into the optimization dynamics of RL in LLMs and show that RL can be substantially more parameter-efficient than previously recognized.", "AI": {"tldr": "SGD, a memory-efficient optimizer, matches or surpasses AdamW in reinforcement learning for large language models, challenging current practices.", "motivation": "Current RL optimization practices for training LLMs heavily rely on AdamW despite memory overhead, warranting exploration of alternatives like SGD.", "method": "Analyzed differences between SFT and RL optimization in LLMs and hypothesized that RL benefits less from adaptive learning rates and momentum. Compared AdamW and SGD performance experimentally.", "result": "SGD matched or outperformed AdamW in RL for LLMs, enabling greater memory efficiency and requiring updates for far fewer parameters.", "conclusion": "RL optimization for LLMs can be substantially more parameter- and memory-efficient using SGD, potentially revising practices in scaling efforts."}}
{"id": "2602.08123", "pdf": "https://arxiv.org/pdf/2602.08123", "abs": "https://arxiv.org/abs/2602.08123", "authors": ["Zhennan Yi", "Sophia Sakakibara Capello", "Randy Gomez", "Selma \u0160abanovi\u0107"], "title": "Adding More Value Than Work: Practical Guidelines for Integrating Robots into Intercultural Competence Learning", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "While social robots have demonstrated effectiveness in supporting students' intercultural competence development, it is unclear how they can effectively be adopted for integrated use in K-12 schools. We conducted two phases of design workshops with teachers, where they co-designed robot-mediated intercultural activities while considering student needs and school integration concerns. Using thematic analysis, we identify appropriate scenarios and roles for classroom robots, explore how robots could complement rather than replace teachers, and consider how to address ethical and compliance considerations. Our findings provide practical design guidelines for the HRI community to develop social robots that can effectively support intercultural education in K-12 schools.", "AI": {"tldr": "This paper explores how social robots can be integrated into classrooms to support intercultural competence development, presenting design workshops with teachers and practical guidelines.", "motivation": "Understand how social robots can effectively support intercultural competence development in K-12 schools through integrated use.", "method": "Conducted two phases of design workshops where teachers co-designed robot-mediated activities, followed by thematic analysis.", "result": "Identified roles for robots in classrooms, ways to complement teachers, and approaches to address ethical concerns.", "conclusion": "Provided design guidelines for creating social robots that assist intercultural education in schools under practical and ethical considerations."}}
{"id": "2602.08995", "pdf": "https://arxiv.org/pdf/2602.08995", "abs": "https://arxiv.org/abs/2602.08995", "authors": ["Yuting Ning", "Jaylen Jones", "Zhehao Zhang", "Chentao Ye", "Weitong Ruan", "Junyi Li", "Rahul Gupta", "Huan Sun"], "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents", "categories": ["cs.CL"], "comment": "Project Homepage: https://osu-nlp-group.github.io/Misaligned-Action-Detection/", "summary": "Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.", "AI": {"tldr": "The paper addresses misaligned actions in Computer-use agents (CUAs), proposing a benchmark and a guardrail method, DeAction, to detect and correct these misalignments effectively.", "motivation": "CUAs often produce actions misaligned with user intent, stemming from external attacks or internal failures, leading to safety risks and inefficiency.", "method": "The authors define misaligned action issues, construct MisActBench with human-annotated labels, and propose DeAction, a method to detect and iteratively correct misaligned actions through structured feedback.", "result": "DeAction surpasses baselines with over 15% better F1 score on MisActBench and reduces attack success rates by over 90% in adversarial settings while maintaining task success in benign environments.", "conclusion": "DeAction shows promise as an effective guardrail for CUAs, improving alignment and robustness with moderate latency overhead."}}
{"id": "2602.07827", "pdf": "https://arxiv.org/pdf/2602.07827", "abs": "https://arxiv.org/abs/2602.07827", "authors": ["Guoting Wei", "Xia Yuan", "Yang Zhou", "Haizhao Jing", "Yu Liu", "Xianbiao Qi", "Chunxia Zhao", "Haokui Zhang", "Rong Xiao"], "title": "Open-Text Aerial Detection: A Unified Framework For Aerial Visual Grounding And Detection", "categories": ["cs.CV"], "comment": null, "summary": "Open-Vocabulary Aerial Detection (OVAD) and Remote Sensing Visual Grounding (RSVG) have emerged as two key paradigms for aerial scene understanding. However, each paradigm suffers from inherent limitations when operating in isolation: OVAD is restricted to coarse category-level semantics, while RSVG is structurally limited to single-target localization. These limitations prevent existing methods from simultaneously supporting rich semantic understanding and multi-target detection. To address this, we propose OTA-Det, the first unified framework that bridges both paradigms into a cohesive architecture. Specifically, we introduce a task reformulation strategy that unifies task objectives and supervision mechanisms, enabling joint training across datasets from both paradigms with dense supervision signals. Furthermore, we propose a dense semantic alignment strategy that establishes explicit correspondence at multiple granularities, from holistic expressions to individual attributes, enabling fine-grained semantic understanding. To ensure real-time efficiency, OTA-Det builds upon the RT-DETR architecture, extending it from closed-set detection to open-text detection by introducing several high efficient modules, achieving state-of-the-art performance on six benchmarks spanning both OVAD and RSVG tasks while maintaining real-time inference at 34 FPS.", "AI": {"tldr": "OTA-Det is a unified framework combining Open-Vocabulary Aerial Detection and Remote Sensing Visual Grounding to overcome their limitations, achieving advanced performance and efficiency.", "motivation": "The motivation is to overcome limitations in existing paradigms\u2014OVAD's restricted semantic capability and RSVG's single-target focus\u2014by creating a model capable of rich, multi-target semantic understanding.", "method": "The paper proposes OTA-Det using a task reformulation strategy for unified objectives and dense supervision across datasets. A dense semantic alignment strategy enables fine-grained understanding, leveraging the RT-DETR architecture with efficient modules.", "result": "OTA-Det achieves state-of-the-art performance across six benchmarks for OVAD and RSVG tasks, maintaining real-time inference capabilities at 34 FPS.", "conclusion": "OTA-Det bridges two paradigms into a unified, efficient framework, ensuring comprehensive semantic understanding and multi-target detection."}}
{"id": "2602.08734", "pdf": "https://arxiv.org/pdf/2602.08734", "abs": "https://arxiv.org/abs/2602.08734", "authors": ["David Hud\u00e1k", "Maris F. L. Galesloot", "Martin Tappler", "Martin Kure\u010dka", "Nils Jansen", "Milan \u010ce\u0161ka"], "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning", "categories": ["cs.AI"], "comment": "17 pages (8 main paper, 2 references, 7 appendix). 3 figures in the main paper, 3 figures in the appendix. Accepted AAMAS'26 submission", "summary": "Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs.", "AI": {"tldr": "Lexpop uses deep reinforcement learning and finite-state controllers to address scalability and robustness in solving POMDPs, demonstrating superior performance on large state-space problems.", "motivation": "Existing POMDP solvers struggle with scalability and robustness across multiple POMDPs.", "method": "Proposed Lexpop framework employs neural policies using deep reinforcement learning and extracts finite-state controllers for performance guarantees.", "result": "Lexpop outperformed state-of-the-art solvers on POMDPs and HM-POMDPs with large state spaces.", "conclusion": "Lexpop provides scalable and robust solutions for POMDPs by combining neural policies and formal controller evaluations."}}
{"id": "2602.07730", "pdf": "https://arxiv.org/pdf/2602.07730", "abs": "https://arxiv.org/abs/2602.07730", "authors": ["Siddarth Chandrasekar", "Marlos C. Machado"], "title": "The Laplacian Keyboard: Beyond the Linear Span", "categories": ["cs.LG", "cs.AI"], "comment": "28 pages, 17 figures", "summary": "Across scientific disciplines, Laplacian eigenvectors serve as a fundamental basis for simplifying complex systems, from signal processing to quantum mechanics. In reinforcement learning (RL), these eigenvectors provide a natural basis for approximating reward functions; however, their use is typically limited to their linear span, which restricts expressivity in complex environments. We introduce the Laplacian Keyboard (LK), a hierarchical framework that goes beyond the linear span. LK constructs a task-agnostic library of options from these eigenvectors, forming a behavior basis guaranteed to contain the optimal policy for any reward within the linear span. A meta-policy learns to stitch these options dynamically, enabling efficient learning of policies outside the original linear constraints. We establish theoretical bounds on zero-shot approximation error and demonstrate empirically that LK surpasses zero-shot solutions while achieving improved sample efficiency compared to standard RL methods.", "AI": {"tldr": "The Laplacian Keyboard (LK) framework extends Laplacian eigenvector usage in reinforcement learning, increasing expressivity and efficiency beyond linear constraints.", "motivation": "Laplacian eigenvectors are widely used across disciplines for simplifying complex systems but their application in RL is restricted, limiting expressivity in diverse environments.", "method": "The Laplacian Keyboard (LK) is a hierarchical framework that constructs a library of options from eigenvectors and utilizes a meta-policy to dynamically combine these options for efficient learning of policies beyond the linear span.", "result": "LK demonstrates theoretical guarantees in zero-shot approximation error, outperforms standard RL methods in both zero-shot settings and sample efficiency, as shown through empirical tests.", "conclusion": "The Laplacian Keyboard provides a robust tool for reinforcement learning, bridging theoretical and practical improvements in policy approximation and efficiency."}}
{"id": "2602.07833", "pdf": "https://arxiv.org/pdf/2602.07833", "abs": "https://arxiv.org/abs/2602.07833", "authors": ["Weijiang Lv", "Yaoxuan Feng", "Xiaobo Xia", "Jiayu Wang", "Yan Jing", "Wenchao Chen", "Bo Chen"], "title": "SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "53 pages, 42 figures, 14 tables", "summary": "Chain-of-Thought reasoning is widely used to improve the interpretability of multimodal large language models (MLLMs), yet the faithfulness of the generated reasoning traces remains unclear. Prior work has mainly focused on perceptual hallucinations, leaving reasoning level unfaithfulness underexplored. To isolate faithfulness from linguistic priors, we introduce SPD-Faith Bench, a diagnostic benchmark based on fine-grained image difference reasoning that enforces explicit visual comparison. Evaluations on state-of-the-art MLLMs reveal two systematic failure modes, perceptual blindness and perception-reasoning dissociation. We trace these failures to decaying visual attention and representation shifts in the residual stream. Guided by this analysis, we propose SAGE, a train-free visual evidence-calibrated framework that improves visual routing and aligns reasoning with perception. Our results highlight the importance of explicitly evaluating faithfulness beyond response correctness. Our benchmark and codes are available at https://github.com/Johanson-colab/SPD-Faith-Bench.", "AI": {"tldr": "The paper introduces SPD-Faith Bench, a benchmark to assess the faithfulness of multimodal large language models (MLLMs) in reasoning tasks and proposes SAGE, a framework to enhance faithfulness.", "motivation": "To address the problem of unfaithful reasoning traces in MLLMs and to isolate faithfulness issues from linguistic priors, particularly concerning reasoning tasks requiring explicit visual comparisons.", "method": "Authors develop SPD-Faith Bench, a fine-grained diagnostic benchmark forcing explicit visual comparison and propose SAGE, a train-free framework that calibrates visual routing and aligns perception with reasoning.", "result": "They identify two key failure modes in MLLMs (perceptual blindness and perception-reasoning dissociation) and show that SAGE improves faithfulness in visual reasoning tasks.", "conclusion": "Explicit evaluation of reasoning faithfulness is crucial, and the proposed SPD-Faith Bench and SAGE framework effectively address reasoning limitations in current MLLMs."}}
{"id": "2602.08754", "pdf": "https://arxiv.org/pdf/2602.08754", "abs": "https://arxiv.org/abs/2602.08754", "authors": ["Rose E. Guingrich", "Dvija Mehta", "Umang Bhatt"], "title": "Belief Offloading in Human-AI Interaction", "categories": ["cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.", "AI": {"tldr": "The paper explores 'belief offloading,' where people rely on AI systems to form and maintain beliefs.", "motivation": "To understand how reliance on AI systems for beliefs affects cognitive skills and behavior.", "method": "Using interdisciplinary insights from philosophy, psychology, and computer science to define and taxonomize belief offloading.", "result": "Clarified boundary conditions for belief offloading and created a taxonomy along with normative implications.", "conclusion": "Highlighted the need for future work on the consequences of belief offloading in human-AI interactions."}}
{"id": "2602.07732", "pdf": "https://arxiv.org/pdf/2602.07732", "abs": "https://arxiv.org/abs/2602.07732", "authors": ["Joon Suk Huh"], "title": "Efficient Adaptive Data Analysis over Dense Distributions", "categories": ["cs.LG", "cs.DS"], "comment": "23 pages", "summary": "Modern data workflows are inherently adaptive, repeatedly querying the same dataset to refine and validate sequential decisions, but such adaptivity can lead to overfitting and invalid statistical inference. Adaptive Data Analysis (ADA) mechanisms address this challenge; however, there is a fundamental tension between computational efficiency and sample complexity. For $T$ rounds of adaptive analysis, computationally efficient algorithms typically incur suboptimal $O(\\sqrt{T})$ sample complexity, whereas statistically optimal $O(\\log T)$ algorithms are computationally intractable under standard cryptographic assumptions. In this work, we shed light on this trade-off by identifying a natural class of data distributions under which both computational efficiency and optimal sample complexity are achievable. We propose a computationally efficient ADA mechanism that attains optimal $O(\\log T)$ sample complexity when the data distribution is dense with respect to a known prior. This setting includes, in particular, feature--label data distributions arising in distribution-specific learning. As a consequence, our mechanism also yields a sample-efficient (i.e., $O(\\log T)$ samples) statistical query oracle in the distribution-specific setting. Moreover, although our algorithm is not based on differential privacy, it satisfies a relaxed privacy notion known as Predicate Singling Out (PSO) security (Cohen and Nissim, 2020). Our results thus reveal an inherent connection between adaptive data analysis and privacy beyond differential privacy.", "AI": {"tldr": "The paper addresses adaptive data analysis challenges by introducing a mechanism that achieves computational efficiency and optimal sample complexity under certain conditions, revealing connections with privacy.", "motivation": "The authors aim to resolve the tension between computational efficiency and sample complexity in adaptive data analysis, which can lead to overfitting under traditional methods.", "method": "A computationally efficient Adaptive Data Analysis (ADA) mechanism was developed, achieving optimal $O(\\log T)$ sample complexity for dense data distributions relative to a known prior. It uses a relaxed privacy notion called Predicate Singling Out (PSO) security.", "result": "The proposed mechanism achieves both computational efficiency and optimal sample complexity in specific data settings. It also establishes a novel connection between adaptive analysis and privacy.", "conclusion": "The work demonstrates the possibility of reconciling the trade-off between efficiency and complexity in ADA, providing practical mechanisms for dense distributions and revealing implications for privacy beyond differential privacy."}}
{"id": "2602.08962", "pdf": "https://arxiv.org/pdf/2602.08962", "abs": "https://arxiv.org/abs/2602.08962", "authors": ["Guangxun Zhu", "Xuan Liu", "Nicolas Pugeault", "Chongfeng Wei", "Edmond S. L. Ho"], "title": "Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted for IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D", "AI": {"tldr": "This paper introduces a 3D pedestrian pose forecasting framework incorporating vehicle information to improve prediction accuracy for autonomous driving.", "motivation": "The motivation is to enhance safety and reliability in autonomous driving by accurately predicting pedestrian movement in complex urban environments, particularly by including interactions with vehicles.", "method": "The study extends the Waymo-3DSkelMo dataset with 3D vehicle bounding boxes and proposes a new model based on the TBIFormer architecture, which integrates pedestrian and vehicle features via a cross-attention module.", "result": "Experiments show significant improvements in 3D pedestrian pose forecasting accuracy and validate the effectiveness of incorporating vehicle interaction modeling.", "conclusion": "Incorporating vehicle information into pedestrian pose prediction proves crucial for improving autonomous driving systems, as demonstrated by the framework's enhanced predictive performance."}}
{"id": "2602.07835", "pdf": "https://arxiv.org/pdf/2602.07835", "abs": "https://arxiv.org/abs/2602.07835", "authors": ["Sanoojan Baliah", "Yohan Abeysinghe", "Rusiru Thushara", "Khan Muhammad", "Abhinav Dhall", "Karthik Nandakumar", "Muhammad Haris Khan"], "title": "VFace: A Training-Free Approach for Diffusion-Based Video Face Swapping", "categories": ["cs.CV"], "comment": null, "summary": "We present a training-free, plug-and-play method, namely VFace, for high-quality face swapping in videos. It can be seamlessly integrated with image-based face swapping approaches built on diffusion models. First, we introduce a Frequency Spectrum Attention Interpolation technique to facilitate generation and intact key identity characteristics. Second, we achieve Target Structure Guidance via plug-and-play attention injection to better align the structural features from the target frame to the generation. Third, we present a Flow-Guided Attention Temporal Smoothening mechanism that enforces spatiotemporal coherence without modifying the underlying diffusion model to reduce temporal inconsistencies typically encountered in frame-wise generation. Our method requires no additional training or video-specific fine-tuning. Extensive experiments show that our method significantly enhances temporal consistency and visual fidelity, offering a practical and modular solution for video-based face swapping. Our code is available at https://github.com/Sanoojan/VFace.", "AI": {"tldr": "VFace is a training-free method improving video face-swapping by enhancing identity preservation, structural alignment, and temporal smoothness.", "motivation": "The paper addresses challenges in video-based face swapping, specifically temporal inconsistencies, identity preservation, and structural alignment within diffusion models.", "method": "VFace provides techniques like Frequency Spectrum Attention Interpolation, plug-and-play Target Structure Guidance, and Flow-Guided Attention Temporal Smoothening for better video face-swapping without additional training or fine-tuning.", "result": "The proposed methods significantly improve visual fidelity and temporal consistency in video face-swapping, outperforming frame-wise generation approaches.", "conclusion": "VFace is a practical and modular solution for seamless video face-swapping that requires no extra training, and its code is made available for further adaptation."}}
{"id": "2602.08783", "pdf": "https://arxiv.org/pdf/2602.08783", "abs": "https://arxiv.org/abs/2602.08783", "authors": ["Zirui Li", "Xuefeng Bai", "Kehai Chen", "Yizhi Li", "Jian Yang", "Chenghua Lin", "Min Zhang"], "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages", "summary": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.", "AI": {"tldr": "The paper examines latent chain-of-thought methods as causal processes, using interventions in structural causal models to better understand their intermediate steps and effects on reasoning tasks.", "motivation": "To address the challenge of evaluating intermediate computations in latent chain-of-thought methods and gain insights to improve their interpretability and performance.", "method": "The authors model latent reasoning steps as variables in a structural causal model (SCM), analyze them through do-interventions, and study these using two paradigms: Coconut and CODI on mathematical and general reasoning tasks.", "result": "They discovered that latent-step behaviors are staged rather than uniform, observed differences between output commitment and representational commitment, and highlighted areas needing further analysis and improvement for these systems.", "conclusion": "The findings suggest the importance of mode-conditional and stability-aware analyses, encouraging new training and decoding objectives for latent reasoning systems."}}
{"id": "2602.07735", "pdf": "https://arxiv.org/pdf/2602.07735", "abs": "https://arxiv.org/abs/2602.07735", "authors": ["Matteo Rossi", "Ryan Pederson", "Miles Wang-Henderson", "Ben Kaufman", "Edward C. Williams", "Carl Underkoffler", "Owen Lewis Howell", "Adrian Layer", "Stephan Thaler", "Narbe Mardirossian", "John Anthony Parkhill"], "title": "TerraBind: Fast and Accurate Binding Affinity Prediction through Coarse Structural Representations", "categories": ["cs.LG", "q-bio.BM"], "comment": "31 pages, 14 figures", "summary": "We present TerraBind, a foundation model for protein-ligand structure and binding affinity prediction that achieves 26-fold faster inference than state-of-the-art methods while improving affinity prediction accuracy by $\\sim$20\\%. Current deep learning approaches to structure-based drug design rely on expensive all-atom diffusion to generate 3D coordinates, creating inference bottlenecks that render large-scale compound screening computationally intractable. We challenge this paradigm with a critical hypothesis: full all-atom resolution is unnecessary for accurate small molecule pose and binding affinity prediction. TerraBind tests this hypothesis through a coarse pocket-level representation (protein C$_\u03b2$ atoms and ligand heavy atoms only) within a multimodal architecture combining COATI-3 molecular encodings and ESM-2 protein embeddings that learns rich structural representations, which are used in a diffusion-free optimization module for pose generation and a binding affinity likelihood prediction module. On structure prediction benchmarks (FoldBench, PoseBusters, Runs N' Poses), TerraBind matches diffusion-based baselines in ligand pose accuracy. Crucially, TerraBind outperforms Boltz-2 by $\\sim$20\\% in Pearson correlation for binding affinity prediction on both a public benchmark (CASP16) and a diverse proprietary dataset (18 biochemical/cell assays). We show that the affinity prediction module also provides well-calibrated affinity uncertainty estimates, addressing a critical gap in reliable compound prioritization for drug discovery. Furthermore, this module enables a continual learning framework and a hedged batch selection strategy that, in simulated drug discovery cycles, achieves 6$\\times$ greater affinity improvement of selected molecules over greedy-based approaches.", "AI": {"tldr": "The paper introduces TerraBind, a protein-ligand binding model that is 26 times faster than existing methods and improves binding affinity prediction accuracy by 20%.", "motivation": "Current drug design models are computationally expensive due to their reliance on all-atom diffusion for 3D structure generation, which limits scalability and efficiency. This paper proposes an alternative approach to address these issues.", "method": "TerraBind combines a coarse pocket-level representation with multimodal architecture (using COATI-3 molecular encodings and ESM-2 protein embeddings). It eliminates diffusion by employing a specialized optimization module for pose generation and uses another module for binding affinity prediction with uncertainty estimation.", "result": "TerraBind achieves similar accuracy to diffusion-based methods in ligand pose prediction benchmarks and outperforms baseline methods by ~20% on binding affinity prediction. It also enables a 6\u00d7 improvement in compound selection efficacy during simulated drug discovery.", "conclusion": "The study challenges the necessity of full all-atom resolution in drug design, showing that TerraBind's highly efficient framework can accelerate scalable compound screening and improve decision-making in drug discovery."}}
{"id": "2602.08971", "pdf": "https://arxiv.org/pdf/2602.08971", "abs": "https://arxiv.org/abs/2602.08971", "authors": ["Yu Shang", "Zhuohang Li", "Yiding Ma", "Weikang Su", "Xin Jin", "Ziyou Wang", "Xin Zhang", "Yinzhou Tang", "Chen Gao", "Wei Wu", "Xihui Liu", "Dhruv Shah", "Zhaoxiang Zhang", "Zhibo Chen", "Jun Zhu", "Yonghong Tian", "Tat-Seng Chua", "Wenwu Zhu", "Yong Li"], "title": "WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.", "AI": {"tldr": "WorldArena is a benchmark that evaluates embodied world models across perceptual and functional dimensions, introducing a holistic metric called EWMScore.", "motivation": "Evaluate embodied world models not only by perceptual fidelity but also functional utility in decision-making tasks.", "method": "Introduced WorldArena benchmark assessing video perception quality, task functionality, and providing EWMScore as a unified metric.", "result": "Experiments reveal a gap between visual quality and task capability, indicating the limitations of current benchmarks.", "conclusion": "WorldArena facilitates a systematic approach to assess embodied world models, aiming to improve their functionality in embodied AI."}}
{"id": "2602.07854", "pdf": "https://arxiv.org/pdf/2602.07854", "abs": "https://arxiv.org/abs/2602.07854", "authors": ["Chendong Xiang", "Jiajun Liu", "Jintao Zhang", "Xiao Yang", "Zhengwei Fang", "Shizun Wang", "Zijun Wang", "Yingtian Zou", "Hang Su", "Jun Zhu"], "title": "Geometry-Aware Rotary Position Embedding for Consistent Video World Model", "categories": ["cs.CV"], "comment": null, "summary": "Predictive world models that simulate future observations under explicit camera control are fundamental to interactive AI. Despite rapid advances, current systems lack spatial persistence: they fail to maintain stable scene structures over long trajectories, frequently hallucinating details when cameras revisit previously observed locations. We identify that this geometric drift stems from reliance on screen-space positional embeddings, which conflict with the projective geometry required for 3D consistency. We introduce \\textbf{ViewRope}, a geometry-aware encoding that injects camera-ray directions directly into video transformer self-attention layers. By parameterizing attention with relative ray geometry rather than pixel locality, ViewRope provides a model-native inductive bias for retrieving 3D-consistent content across temporal gaps. We further propose \\textbf{Geometry-Aware Frame-Sparse Attention}, which exploits these geometric cues to selectively attend to relevant historical frames, improving efficiency without sacrificing memory consistency. We also present \\textbf{ViewBench}, a diagnostic suite measuring loop-closure fidelity and geometric drift. Our results demonstrate that ViewRope substantially improves long-term consistency while reducing computational costs.", "AI": {"tldr": "This paper addresses the issue of geometric drift in predictive world models by introducing a geometry-aware technique, ViewRope, and evaluating it using a new benchmarking suite, ViewBench.", "motivation": "Current predictive world models fail to maintain spatial persistence over long trajectories, hallucinating scene details due to reliance on screen-space positional embeddings, which don't preserve 3D geometric consistency.", "method": "The authors propose ViewRope, a novel geometry-aware encoding, which incorporates camera-ray directions into video transformer self-attention layers. This enables attention parameterization based on ray geometry instead of screen-space pixel locality. Geometry-Aware Frame-Sparse Attention is also introduced to improve model efficiency without compromising memory consistency.", "result": "Experiments show that ViewRope effectively enhances long-term scene consistency, improves loop-closure fidelity, and reduces geometric drift, while also lowering computational costs.", "conclusion": "ViewRope provides a 3D-consistent improvement to predictive world models, addressing geometric drift and memory inefficiency, which are fundamental to enhancing interactive AI."}}
{"id": "2602.08796", "pdf": "https://arxiv.org/pdf/2602.08796", "abs": "https://arxiv.org/abs/2602.08796", "authors": ["Kevin Fan", "Jacquelyn A. Bialo", "Hongli Li"], "title": "The Use of AI Tools to Develop and Validate Q-Matrices", "categories": ["cs.AI", "cs.CL"], "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA", "summary": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.", "AI": {"tldr": "This paper evaluates the use of AI tools for constructing Q-matrices in cognitive diagnostic modeling by comparing AI-generated, human-expert, and validated Q-matrices for a reading comprehension test.", "motivation": "To address the labor-intensive process of Q-matrix development in cognitive diagnostic modeling by exploring AI tools as potential support.", "method": "AI language models were trained on the same materials as human experts to generate Q-matrices, which were compared to a validated Q-matrix and human efforts using Cohen's kappa for agreement measurement.", "result": "The Google Gemini 2.5 Pro AI model achieved the highest agreement (kappa = 0.63) with the validated Q-matrix, surpassing human experts, although agreement dropped when newer AI models were used.", "conclusion": "AI models, while promising in Q-matrix construction, showed variability in performance. Future research is needed to improve AI reliability and alignment with validated standards."}}
{"id": "2602.07738", "pdf": "https://arxiv.org/pdf/2602.07738", "abs": "https://arxiv.org/abs/2602.07738", "authors": ["Sunil Madhow", "Yuchen Liang", "Ness Shroff", "Yingbin Liang", "Yu-Xiang Wang"], "title": "Learnable Chernoff Baselines for Inference-Time Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study inference-time reward-guided alignment for generative models. Existing methods often rely on either architecture-specific adaptations or computationally costly inference procedures. We introduce Learnable Chernoff Baselines (LCBs) as a method for efficiently and approximately sampling from the exponentially tilted kernels that arise from KL-regularized reward alignment. Using only black-box sampling access to the pretrained model, LCBs implement a form of rejection sampling with adaptively selected acceptance probabilities, which allows fine-grained control over inference-compute scaling. We establish total-variation guarantees to the ideal aligned model, and demonstrate in both continuous and discrete diffusion settings that LCB sampling closely matches ideal rejection sampling while using substantially fewer queries to the pretrained model.", "AI": {"tldr": "The paper introduces Learnable Chernoff Baselines (LCBs), an efficient inference-time method for reward-guided alignment in generative models, leveraging adaptive rejection sampling.", "motivation": "Existing inference-time reward-guided alignment approaches for generative models often require architecture-specific adjustments or are computationally demanding. This research aims to address these inefficiencies.", "method": "The authors propose Learnable Chernoff Baselines (LCBs) as an efficient method to approximately sample from KL-regularized reward-aligned models, using adaptively selected acceptance probabilities for rejection sampling.", "result": "The study shows that LCBs achieve close alignment to ideal rejection sampling while significantly reducing the number of queries to the pretrained model in both continuous and discrete diffusion settings.", "conclusion": "LCBs provide an effective and efficient solution for reward-guided alignment in generative models, balancing computational cost and performance."}}
{"id": "2602.07036", "pdf": "https://arxiv.org/pdf/2602.07036", "abs": "https://arxiv.org/abs/2602.07036", "authors": ["Zien Sheikh Ali", "Hunzalah Hassan Bhatti", "Rabindra Nath Nandi", "Shammur Absar Chowdhury", "Firoj Alam"], "title": "MENASpeechBank: A Reference Voice Bank with Persona-Conditioned Multi-Turn Conversations for AudioLLMs", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Foundation Models, Large Language Models, Native, Speech Models, Arabic, AI-persona, Persona-conditioned-conversations", "summary": "Audio large language models (AudioLLMs) enable instruction-following over speech and general audio, but progress is increasingly limited by the lack of diverse, conversational, instruction-aligned speech-text data. This bottleneck is especially acute for persona-grounded interactions and dialectal coverage, where collecting and releasing real multi-speaker recordings is costly and slow. We introduce MENASpeechBank, a reference speech bank comprising about 18K high-quality utterances from 124 speakers spanning multiple MENA countries, covering English, Modern Standard Arabic (MSA), and regional Arabic varieties. Building on this resource, we develop a controllable synthetic data pipeline that: (i) constructs persona profiles enriched with World Values Survey-inspired attributes, (ii) defines a taxonomy of about 5K conversational scenarios, (iii) matches personas to scenarios via semantic similarity, (iv) generates about 417K role-play conversations with an LLM where the user speaks as the persona and the assistant behaves as a helpful agent, and (v) synthesizes the user turns by conditioning on reference speaker audio to preserve speaker identity and diversity. We evaluate both synthetic and human-recorded conversations and provide detailed analysis. We will release MENASpeechBank and the generated conversations publicly for the community.", "AI": {"tldr": "The paper introduces MENASpeechBank, a resource for enhancing AudioLLMs with persona-grounded and dialectally diverse speech-text data. It presents a synthetic data pipeline for generating conversational scenarios.", "motivation": "To address the lack of diverse, conversational, instruction-aligned speech-text data for AudioLLMs, especially in persona-grounded interactions and representations of regional dialects.", "method": "Created MENASpeechBank with 18K utterances from 124 speakers in MENA countries, covering multiple dialects and languages. Developed a controllable synthetic pipeline to create persona profiles, match scenarios, generate role-play conversations using LLMs, and synthesize speech to maintain speaker characteristics.", "result": "Generated a dataset of approximately 417K role-play conversations, both synthetic and human-recorded, evaluated for quality and community usability. MENASpeechBank and synthetic data will be released to the public.", "conclusion": "The resource and pipeline support advancements in AudioLLMs by enabling more diverse, persona-based, instruction-following conversations, addressing existing constraints on data availability and diversity."}}
{"id": "2602.07860", "pdf": "https://arxiv.org/pdf/2602.07860", "abs": "https://arxiv.org/abs/2602.07860", "authors": ["Fei Yu", "Shudan Guo", "Shiqing Xin", "Beibei Wang", "Haisen Zhao", "Wenzheng Chen"], "title": "Recovering 3D Shapes from Ultra-Fast Motion-Blurred Images", "categories": ["cs.CV", "cs.GR"], "comment": "Accepted by 3DV 2026. Project page: https://maxmilite.github.io/rec-from-ultrafast-blur/", "summary": "We consider the problem of 3D shape recovery from ultra-fast motion-blurred images. While 3D reconstruction from static images has been extensively studied, recovering geometry from extreme motion-blurred images remains challenging. Such scenarios frequently occur in both natural and industrial settings, such as fast-moving objects in sports (e.g., balls) or rotating machinery, where rapid motion distorts object appearance and makes traditional 3D reconstruction techniques like Multi-View Stereo (MVS) ineffective.\n  In this paper, we propose a novel inverse rendering approach for shape recovery from ultra-fast motion-blurred images. While conventional rendering techniques typically synthesize blur by averaging across multiple frames, we identify a major computational bottleneck in the repeated computation of barycentric weights. To address this, we propose a fast barycentric coordinate solver, which significantly reduces computational overhead and achieves a speedup of up to 4.57x, enabling efficient and photorealistic simulation of high-speed motion. Crucially, our method is fully differentiable, allowing gradients to propagate from rendered images to the underlying 3D shape, thereby facilitating shape recovery through inverse rendering.\n  We validate our approach on two representative motion types: rapid translation and rotation. Experimental results demonstrate that our method enables efficient and realistic modeling of ultra-fast moving objects in the forward simulation. Moreover, it successfully recovers 3D shapes from 2D imagery of objects undergoing extreme translational and rotational motion, advancing the boundaries of vision-based 3D reconstruction. Project page: https://maxmilite.github.io/rec-from-ultrafast-blur/", "AI": {"tldr": "This paper tackles the challenge of recovering 3D shapes from ultra-fast motion-blurred images using a novel inverse rendering approach.", "motivation": "Conventional 3D reconstruction methods struggle with extreme motion blur caused by fast-moving or rotating objects in scenarios like sports or industrial contexts.", "method": "The authors introduce a fast barycentric coordinate solver for efficient, photorealistic rendering of high-speed motion, enabling fully differentiable inverse rendering workflows for shape recovery.", "result": "Their approach demonstrates enhanced computational efficiency with up to 4.57x speedup and successfully recovers 3D shapes from extreme motion-blurred images.", "conclusion": "This method advances 3D vision by enabling realistic simulation and accurate shape recovery from motion-blurred scenes, pushing the limits of conventional reconstruction techniques."}}
{"id": "2602.08804", "pdf": "https://arxiv.org/pdf/2602.08804", "abs": "https://arxiv.org/abs/2602.08804", "authors": ["Liming Zhou", "Ailing Liu", "Hongwei Liu", "Min He", "Heng Zhang"], "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures", "categories": ["cs.AI"], "comment": null, "summary": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.", "AI": {"tldr": "The paper proposes a novel residual-connection-based RCA method (RC-LLM) for improving root cause localization in complex microservice architectures using LLMs.", "motivation": "Root cause localization is challenging due to the complexity of fault propagation among microservices and high-dimensional telemetry data, limiting the effectiveness of existing methods.", "method": "The proposed RC-LLM method uses a residual-like hierarchical fusion structure to integrate multi-source telemetry data and employs large language models for temporal and cross-microservice causal reasoning.", "result": "Experimental results on the CCF-AIOps dataset highlight the strong accuracy and efficiency of RC-LLM in root cause analysis.", "conclusion": "RC-LLM demonstrates effective root cause localization in complex microservice architectures by integrating multi-source telemetry data and leveraging LLMs for causal reasoning."}}
{"id": "2602.07744", "pdf": "https://arxiv.org/pdf/2602.07744", "abs": "https://arxiv.org/abs/2602.07744", "authors": ["Dongyeop Woo", "Marta Skreta", "Seonghyun Park", "Sungsoo Ahn", "Kirill Neklyudov"], "title": "Riemannian MeanFlow", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion and flow models have become the dominant paradigm for generative modeling on Riemannian manifolds, with successful applications in protein backbone generation and DNA sequence design. However, these methods require tens to hundreds of neural network evaluations at inference time, which can become a computational bottleneck in large-scale scientific sampling workflows. We introduce Riemannian MeanFlow~(RMF), a framework for learning flow maps directly on manifolds, enabling high-quality generations with as few as one forward pass. We derive three equivalent characterizations of the manifold average velocity (Eulerian, Lagrangian, and semigroup identities), and analyze parameterizations and stabilization techniques to improve training on high-dimensional manifolds. In promoter DNA design and protein backbone generation settings, RMF achieves comparable sample quality to prior methods while requiring up to 10$\\times$ fewer function evaluations. Finally, we show that few-step flow maps enable efficient reward-guided design through reward look-ahead, where terminal states can be predicted from intermediate steps at minimal additional cost.", "AI": {"tldr": "The paper introduces Riemannian MeanFlow (RMF), a new framework for generative modeling on manifolds that drastically reduces computational cost by allowing manifold generations with as few as one neural network forward pass.", "motivation": "Existing generative methods on Riemannian manifolds, such as diffusion and flow models, are computationally expensive, requiring numerous neural network evaluations during inference, which limits their scalability for large-scale scientific tasks.", "method": "The authors propose RMF, a new framework that learns flow maps directly on Riemannian manifolds, introducing three analytical approaches (Eulerian, Lagrangian, and semigroup identities) along with stabilization techniques for high-dimensional training.", "result": "RMF achieves comparable generative quality to prior methods in tasks like promoter DNA design and protein backbone generation, while reducing function evaluations by up to 10\u00d7. The method also supports efficient reward-guided design with terminal state prediction from few steps.", "conclusion": "RMF offers a cost-effective and scalable approach for manifold-based generative modeling, with potential utility in computational biology and other scientific fields."}}
{"id": "2602.07864", "pdf": "https://arxiv.org/pdf/2602.07864", "abs": "https://arxiv.org/abs/2602.07864", "authors": ["Chen Yang", "Guanxin Lin", "Youquan He", "Peiyao Chen", "Guanghe Liu", "Yufan Mo", "Zhouyuan Xu", "Linhao Wang", "Guohui Zhang", "Zihang Zhang", "Shenxiang Zeng", "Chen Wang", "Jiansheng Fan"], "title": "Thinking in Structures: Evaluating Spatial Intelligence through Reasoning on Constrained Manifolds", "categories": ["cs.CV"], "comment": null, "summary": "Spatial intelligence is crucial for vision--language models (VLMs) in the physical world, yet many benchmarks evaluate largely unconstrained scenes where models can exploit 2D shortcuts. We introduce SSI-Bench, a VQA benchmark for spatial reasoning on constrained manifolds, built from complex real-world 3D structures whose feasible configurations are tightly governed by geometric, topological, and physical constraints. SSI-Bench contains 1,000 ranking questions spanning geometric and topological reasoning and requiring a diverse repertoire of compositional spatial operations, such as mental rotation, cross-sectional inference, occlusion reasoning, and force-path reasoning. It is created via a fully human-centered pipeline: ten researchers spent over 400 hours curating images, annotating structural components, and designing questions to minimize pixel-level cues. Evaluating 31 widely used VLMs reveals a large gap to humans: the best open-source model achieves 22.2% accuracy and the strongest closed-source model reaches 33.6%, while humans score 91.6%. Encouraging models to think yields only marginal gains, and error analysis points to failures in structural grounding and constraint-consistent 3D reasoning. Project page: https://ssi-bench.github.io.", "AI": {"tldr": "SSI-Bench is a VQA benchmark focused on spatial reasoning within constrained 3D environments, highlighting significant gaps between human performance and leading vision-language models.", "motivation": "The paper addresses the limitations of current VLM benchmarks which often evaluate in unconstrained scenes, potentially relying on 2D shortcuts, and proposes a new benchmark emphasizing rigorous spatial reasoning.", "method": "SSI-Bench comprises 1,000 human-curated ranking questions built from complex 3D structures, focusing on geometric and topological reasoning. A fully human-centered pipeline was employed to minimize shortcuts.", "result": "Evaluation on 31 VLMs revealed weak performance compared to humans (22.2% accuracy for the best open-source model, 33.6% for the best closed-source model, while humans scored 91.6%), exposing failures in grounded 3D reasoning.", "conclusion": "Current vision-language models struggle with constraint-consistent spatial reasoning, demonstrating the need for improved structural grounding and spatial intelligence in AI systems."}}
{"id": "2602.08815", "pdf": "https://arxiv.org/pdf/2602.08815", "abs": "https://arxiv.org/abs/2602.08815", "authors": ["Yanglei Gan", "Peng He", "Yuxiang Cai", "Run Lin", "Guanyu Zhou", "Qiao Liu"], "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation", "categories": ["cs.AI"], "comment": null, "summary": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.", "AI": {"tldr": "This paper introduces NADEx, a Negative-Aware Diffusion model for Temporal Knowledge Graph (TKG) reasoning, which uses sequential embeddings and improves calibrations through incorporation of negative prototypes.", "motivation": "The motivation is to address gaps in TKG reasoning methods, particularly the lack of conditioning on negative evidence and insufficient calibration of denoised embeddings.", "method": "NADEx utilizes subject-centric histories, sequential embeddings, and a Transformer denoiser, along with a cosine-alignment regularizer based on batch-wise negative prototypes to refine predictions.", "result": "NADEx achieves state-of-the-art performance on four public TKG benchmarks through improved reasoning and calibration methods.", "conclusion": "Integrating negative-aware contexts and improved regularization enhances TKG reasoning, providing better prediction and decision boundary tightening."}}
{"id": "2602.07764", "pdf": "https://arxiv.org/pdf/2602.07764", "abs": "https://arxiv.org/abs/2602.07764", "authors": ["Tanmay Ambadkar", "Sourav Panda", "Shreyash Kale", "Jonathan Dodge", "Abhinav Verma"], "title": "Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-objective reinforcement learning (MORL) seeks to learn policies that balance multiple, often conflicting objectives. Although a single preference-conditioned policy is the most flexible and scalable solution, existing approaches remain brittle in practice, frequently failing to recover complete Pareto fronts. We show that this failure stems from two structural issues in current methods: destructive gradient interference caused by premature scalarization and representational collapse across the preference space. We introduce $D^3PO$, a PPO-based framework that reorganizes multi-objective policy optimization to address these issues directly. $D^3PO$ preserves per-objective learning signals through a decomposed optimization pipeline and integrates preferences only after stabilization, enabling reliable credit assignment. In addition, a scaled diversity regularizer enforces sensitivity of policy behavior to preference changes, preventing collapse. Across standard MORL benchmarks, including high-dimensional and many-objective control tasks, $D^3PO$ consistently discovers broader and higher-quality Pareto fronts than prior single- and multi-policy methods, matching or exceeding state-of-the-art hypervolume and expected utility while using a single deployable policy.", "AI": {"tldr": "The paper introduces $D^3PO$, a framework addressing structural issues in reinforcement learning for balancing multiple objectives. $D^3PO$ improves Pareto front discovery through decomposed optimization and preference-stabilized integration.", "motivation": "Current methods often fail to recover full Pareto fronts in reinforcement learning when balancing conflicting objectives due to gradient interference and representational collapse.", "method": "The authors propose $D^3PO$, employing a PPO-based optimization framework with decomposed signals and a scaled diversity regularizer to stabilize preferences and maintain policy sensitivity.", "result": "$D^3PO$ achieves broader and higher-quality Pareto fronts across benchmarks, surpassing prior methods in hypervolume and expected utility using a single policy.", "conclusion": "$D^3PO$ effectively resolves structural issues in multi-objective reinforcement learning, advancing reliable and scalable solutions for balancing conflicting objectives."}}
{"id": "2602.07872", "pdf": "https://arxiv.org/pdf/2602.07872", "abs": "https://arxiv.org/abs/2602.07872", "authors": ["Mert Sonmezer", "Serge Vasylechko", "Duygu Atasoy", "Seyda Ertekin", "Sila Kurugol"], "title": "WristMIR: Coarse-to-Fine Region-Aware Retrieval of Pediatric Wrist Radiographs with Radiology Report-Driven Learning", "categories": ["cs.CV"], "comment": null, "summary": "Retrieving wrist radiographs with analogous fracture patterns is challenging because clinically important cues are subtle, highly localized and often obscured by overlapping anatomy or variable imaging views. Progress is further limited by the scarcity of large, well-annotated datasets for case-based medical image retrieval. We introduce WristMIR, a region-aware pediatric wrist radiograph retrieval framework that leverages dense radiology reports and bone-specific localization to learn fine-grained, clinically meaningful image representations without any manual image-level annotations. Using MedGemma-based structured report mining to generate both global and region-level captions, together with pre-processed wrist images and bone-specific crops of the distal radius, distal ulna, and ulnar styloid, WristMIR jointly trains global and local contrastive encoders and performs a two-stage retrieval process: (1) coarse global matching to identify candidate exams, followed by (2) region-conditioned reranking aligned to a predefined anatomical bone region. WristMIR improves retrieval performance over strong vision-language baselines, raising image-to-text Recall@5 from 0.82% to 9.35%. Its embeddings also yield stronger fracture classification (AUROC 0.949, AUPRC 0.953). In region-aware evaluation, the two-stage design markedly improves retrieval-based fracture diagnosis, increasing mean $F_1$ from 0.568 to 0.753, and radiologists rate its retrieved cases as more clinically relevant, with mean scores rising from 3.36 to 4.35. These findings highlight the potential of anatomically guided retrieval to enhance diagnostic reasoning and support clinical decision-making in pediatric musculoskeletal imaging. The source code is publicly available at https://github.com/quin-med-harvard-edu/WristMIR.", "AI": {"tldr": "WristMIR introduces an anatomically guided framework for pediatric wrist radiograph retrieval, improving diagnostic performance by leveraging structured radiology reports and region-specific image encoders.", "motivation": "Address the challenges in retrieving wrist radiographs with analogous fracture patterns due to subtle cues and limited annotated datasets.", "method": "Develop WristMIR, combining global and local contrastive encoders for two-stage retrieval using MedGemma-based structured reports, wrist images, and bone-specific crops.", "result": "WristMIR significantly enhances retrieval performance (Recall@5: 0.82% to 9.35%) and fracture classification metrics (AUROC: 0.949, AUPRC: 0.953). Radiologists rate retrieved cases as more clinically relevant (mean score increase from 3.36 to 4.35).", "conclusion": "Anatomically guided retrieval like WristMIR can improve diagnostic reasoning and decision-making in pediatric musculoskeletal imaging, showcasing the value of region-aware frameworks."}}
{"id": "2602.08835", "pdf": "https://arxiv.org/pdf/2602.08835", "abs": "https://arxiv.org/abs/2602.08835", "authors": ["Andr\u00e9s Holgado-S\u00e1nchez", "Peter Vamplew", "Richard Dazeley", "Sascha Ossowski", "Holger Billhardt"], "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "18 pages, 3 figures. To be published in proceedings of the 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). This is a full version that includes the supplementary material", "summary": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.\n  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.", "AI": {"tldr": "The paper presents algorithms to address value alignment and operationalization in AI, particularly in the context of Markov Decision Processes (MDPs), using clustering and preference-based multi-objective reinforcement learning (PbMORL).", "motivation": "To create AI that recognizes and adapts to human values and diverse user value systems, ensuring interpretability and adaptability without manual feature design.", "method": "The authors propose algorithms leveraging clustering and PbMORL to jointly learn socially-derived value alignment models and represent groups of users through concise value systems and policies in MDPs.", "result": "The proposed method demonstrates its effectiveness by being evaluated against state-of-the-art PbMORL algorithms and baselines in two MDP scenarios featuring human values.", "conclusion": "The study affirms the potential of these algorithms to operationalize and align diverse societal values in decision-making processes, advancing personalized and value-aware AI systems."}}
{"id": "2602.07790", "pdf": "https://arxiv.org/pdf/2602.07790", "abs": "https://arxiv.org/abs/2602.07790", "authors": ["Wanyun Xie", "Francesco Tonin", "Volkan Cevher"], "title": "MaD-Mix: Multi-Modal Data Mixtures via Latent Space Coupling for Vision-Language Model Training", "categories": ["cs.LG"], "comment": null, "summary": "Vision-Language Models (VLMs) are typically trained on a diverse set of multi-modal domains, yet current practices rely on costly manual tuning. We propose MaD-Mix, a principled and computationally efficient framework that derives multi-modal data mixtures for VLM training. MaD-Mix formulates data mixing as modality-aware domain alignment maximization and obtains closed-form multi-modal alignment scores from the Fenchel dual through inter-modal coupling variables. MaD-Mix systematically handles domains with missing modalities, allowing for the integration of language-only domains. Empirical evaluations across 0.5B and 7B models demonstrate that MaD-Mix accelerates VLM training across diverse benchmarks. MaD-Mix matches human-tuned data mixtures using 22% fewer training steps in image-text instruction tuning. In complex tri-modal video-image-text scenarios, where manual tuning becomes impractical, MaD-Mix boosts average accuracy over uniform weights, with negligible mixture computation overhead (< 1 GPU-hour), enabling scalable mixture design for modern VLM pipelines.", "AI": {"tldr": "MaD-Mix is a framework for multi-modal Vision-Language Model (VLM) training that efficiently aligns domains and handles missing modalities, saving training time and enhancing performance.", "motivation": "The need to address inefficiencies and high costs in the manual tuning of Vision-Language Models (VLMs) and expand their flexibility to handle diverse and incomplete multi-modal datasets.", "method": "The authors propose MaD-Mix, which derives multi-modal data mixtures using modality-aware domain alignment maximization, leveraging closed-form alignment scores derived from the Fenchel dual with inter-modal coupling variables.", "result": "MaD-Mix expedites VLM training, reducing training steps by 22% in image-text scenarios and improving accuracy in complex tri-modal setups, all with minimal computational cost (< 1 GPU-hour).", "conclusion": "MaD-Mix provides a scalable and computationally efficient solution for accelerating VLM training and achieving performance gains, making it suitable for handling both simple and complex multi-modal datasets."}}
{"id": "2602.07075", "pdf": "https://arxiv.org/pdf/2602.07075", "abs": "https://arxiv.org/abs/2602.07075", "authors": ["Xinwu Ye", "Yicheng Mao", "Jia Zhang", "Yimeng Liu", "Li Hao", "Fang Wu", "Zhiwei Li", "Yuxuan Liao", "Zehong Wang", "Zhiyuan Liu", "Zhenfei Yin", "Li Yuan", "Philip Torr", "Huan Sun", "Xiangxiang Zeng", "Mengdi Wang", "Le Cong", "Shenghua Gao", "Xiangru Tang"], "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning", "categories": ["physics.chem-ph", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Chemical large language models (LLMs) predominantly rely on explicit Chain-of-Thought (CoT) in natural language to perform complex reasoning. However, chemical reasoning is inherently continuous and structural, and forcing it into discrete linguistic tokens introduces a fundamental representation mismatch that constrains both efficiency and performance. We introduce LatentChem, a latent reasoning interface that decouples chemical computation from textual generation, enabling models to perform multi-step reasoning directly in continuous latent space while emitting language only for final outputs. Remarkably, we observe a consistent emergent behavior: when optimized solely for task success, models spontaneously internalize reasoning, progressively abandoning verbose textual derivations in favor of implicit latent computation. This shift is not merely stylistic but computationally advantageous. Across diverse chemical reasoning benchmarks, LatentChem achieves a 59.88\\% non-tie win rate over strong CoT-based baselines on ChemCoTBench, while delivering a 10.84$\\times$ average inference speedup. Our results provide empirical evidence that chemical reasoning is more naturally and effectively realized as continuous latent dynamics rather than discretized linguistic trajectories.", "AI": {"tldr": "LatentChem is introduced as a novel latent reasoning interface for chemical tasks, operating in continuous latent space instead of textual tokens, improving both performance and inference speed.", "motivation": "Existing chemical language models rely on textual Chain-of-Thought reasoning, which is mismatched with the continuous and structural nature of chemical reasoning, reducing efficiency and performance.", "method": "LatentChem decouples computation from textual generation, enabling direct multi-step reasoning in continuous latent space and using language only for outputs.", "result": "LatentChem outperformed CoT-based baselines with a 59.88% win rate on ChemCoTBench, offering an average inference speedup of 10.84\u00d7.", "conclusion": "Chemical reasoning is naturally expressed as continuous latent dynamics rather than discrete linguistic trajectories, offering better computational advantages and performance."}}
{"id": "2602.07891", "pdf": "https://arxiv.org/pdf/2602.07891", "abs": "https://arxiv.org/abs/2602.07891", "authors": ["Zihui Gao", "Ke Liu", "Donny Y. Chen", "Duochao Shi", "Guosheng Lin", "Hao Chen", "Chunhua Shen"], "title": "Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Geometric foundation models show promise in 3D reconstruction, yet their progress is severely constrained by the scarcity of diverse, large-scale 3D annotations. While Internet videos offer virtually unlimited raw data, utilizing them as a scaling source for geometric learning is challenging due to the absence of ground-truth geometry and the presence of observational noise. To address this, we propose SAGE, a framework for Scalable Adaptation of GEometric foundation models from raw video streams. SAGE leverages a hierarchical mining pipeline to transform videos into training trajectories and hybrid supervision: (1) Informative training trajectory selection; (2) Sparse Geometric Anchoring via SfM point clouds for global structural guidance; and (3) Dense Differentiable Consistency via 3D Gaussian rendering for multi-view constraints. To prevent catastrophic forgetting, we introduce a regularization strategy using anchor data. Extensive experiments show that SAGE significantly enhances zero-shot generalization, reducing Chamfer Distance by 20-42% on unseen benchmarks (7Scenes, TUM-RGBD, Matterport3D) compared to state-of-the-art baselines. To our knowledge, SAGE pioneers the adaptation of geometric foundation models via Internet video, establishing a scalable paradigm for general-purpose 3D learning.", "AI": {"tldr": "SAGE utilizes Internet videos to overcome 3D annotation scarcity by processing raw video into training data with hierarchical mining pipelines and hybrid supervision. It achieves better zero-shot generalization results.", "motivation": "Geometric foundation models face challenges due to insufficient 3D annotations and noisy raw data from Internet sources. The goal is to utilize abundant raw Internet video data for scalable geometric learning.", "method": "SAGE employs a hierarchical mining pipeline involving three stages: trajectory selection, sparse geometric anchoring via SfM, and dense differentiable consistency with a 3D Gaussian rendering method. It uses regularization to avoid model forgetting.", "result": "SAGE demonstrated significant improvements in zero-shot generalization performance, reducing Chamfer Distance by 20-42% on multiple 3D benchmarks compared to existing baselines.", "conclusion": "SAGE innovatively adapts geometric foundation models using Internet videos, establishing a new scalable framework for general-purpose 3D learning tasks."}}
{"id": "2602.08848", "pdf": "https://arxiv.org/pdf/2602.08848", "abs": "https://arxiv.org/abs/2602.08848", "authors": ["Quentin Cohen-Solal", "Alexandre Niveau", "Maroua Bouzid"], "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks", "categories": ["cs.AI"], "comment": null, "summary": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.", "AI": {"tldr": "The paper proposes a unified framework for qualitative reasoning addressing multi-scale, temporal integration, and loose combination challenges.", "motivation": "The aim is to enable reasoning with imprecise and incomplete information, extending formal qualitative reasoning frameworks.", "method": "Developing a unified framework and proving key polynomial satisfiability theorems for qualitative formalism combinations.", "result": "Presented a generalization of definitions, unified reasoning methods, and recovered known results through the framework.", "conclusion": "The framework facilitates qualitative reasoning across complex scenarios, extending applicability to overlooked combinations."}}
{"id": "2602.07798", "pdf": "https://arxiv.org/pdf/2602.07798", "abs": "https://arxiv.org/abs/2602.07798", "authors": ["Ruiqi Wang", "Ruikang Liu", "Runyu Chen", "Haoxiang Suo", "Zhiyi Peng", "Zhuo Tang", "Changjian Chen"], "title": "CausalTAD: Injecting Causal Knowledge into Large Language Models for Tabular Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Detecting anomalies in tabular data is critical for many real-world applications, such as credit card fraud detection. With the rapid advancements in large language models (LLMs), state-of-the-art performance in tabular anomaly detection has been achieved by converting tabular data into text and fine-tuning LLMs. However, these methods randomly order columns during conversion, without considering the causal relationships between them, which is crucial for accurately detecting anomalies. In this paper, we present CausalTaD, a method that injects causal knowledge into LLMs for tabular anomaly detection. We first identify the causal relationships between columns and reorder them to align with these causal relationships. This reordering can be modeled as a linear ordering problem. Since each column contributes differently to the causal relationships, we further propose a reweighting strategy to assign different weights to different columns to enhance this effect. Experiments across more than 30 datasets demonstrate that our method consistently outperforms the current state-of-the-art methods. The code for CausalTAD is available at https://github.com/350234/CausalTAD.", "AI": {"tldr": "CausalTaD enhances LLM-based tabular anomaly detection by incorporating causal relationships between columns, achieving state-of-the-art performance across 30+ datasets.", "motivation": "Existing tabular anomaly detection methods with LLMs disregard the causal relationships between columns during data conversion, limiting their accuracy.", "method": "CausalTaD introduces causal knowledge into LLMs through column reordering based on causal relationships and applies a reweighting strategy to emphasize important columns.", "result": "Experiments conducted across over 30 datasets reveal superior and consistent performance of CausalTaD compared to other state-of-the-art methods.", "conclusion": "Incorporating causal ordering and reweighting strategies significantly improves tabular anomaly detection in LLMs, showcased by CausalTaD's outperforming existing approaches."}}
{"id": "2602.07899", "pdf": "https://arxiv.org/pdf/2602.07899", "abs": "https://arxiv.org/abs/2602.07899", "authors": ["Zhenhao Shang", "Haizhao Jing", "Guoting Wei", "Haokui Zhang", "Rong Xiao", "Jianqing Gao", "Peng Wang"], "title": "Rethinking Practical and Efficient Quantization Calibration for Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Post-training quantization (PTQ) is a primary approach for deploying large language models without fine-tuning, and the quantized performance is often strongly affected by the calibration in PTQ. By contrast, in vision-language models (VLMs), substantial differences between visual and text tokens in their activation distributions and sensitivities to quantization error pose significant challenges for effective calibration during PTQ. In this work, we rethink what PTQ calibration should align with in VLMs and propose the Token-level Importance-aware Layer-wise Quantization framework (TLQ). Guided by gradient information, we design a token-level importance integration mechanism for quantization error, and use it to construct a token-level calibration set, enabling a more fine-grained calibration strategy. Furthermore, TLQ introduces a multi-GPU, quantization-exposed layer-wise calibration scheme. This scheme keeps the layer-wise calibration procedure consistent with the true quantized inference path and distributes the complex layer-wise calibration workload across multiple RTX3090 GPUs, thereby reducing reliance on the large memory of A100 GPUs. TLQ is evaluated across two models, three model scales, and two quantization settings, consistently achieving performance improvements across all settings, indicating its strong quantization stability. The code will be released publicly.", "AI": {"tldr": "The paper proposes a Token-level Importance-aware Layer-wise Quantization (TLQ) framework for Vision-Language Models (VLMs) to improve post-training quantization (PTQ) calibration and achieve better performance.", "motivation": "Current PTQ methods for Vision-Language Models face challenges due to differences in activation distributions and sensitivities between visual and text tokens, making effective calibration difficult.", "method": "The paper introduces TLQ, which includes a gradient-based token-level importance mechanism for quantization error, token-level calibration set construction, and a multi-GPU quantization-exposed layer-wise calibration scheme for memory efficiency.", "result": "TLQ was tested on two models, in various scales and quantization settings, and showed consistent performance improvement and strong quantization stability.", "conclusion": "TLQ provides a fine-grained calibration strategy that addresses PTQ challenges in VLMs, improves quantization performance, and reduces hardware dependence. Code will be made publicly available."}}
{"id": "2602.08889", "pdf": "https://arxiv.org/pdf/2602.08889", "abs": "https://arxiv.org/abs/2602.08889", "authors": ["Tobias Lorenz", "Mario Fritz"], "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation", "categories": ["cs.AI"], "comment": null, "summary": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.", "AI": {"tldr": "This paper explores using Large Language Models (LLMs) as scalable proxies for expert elicitation in quantitative risk assessment and demonstrates their promise through strong benchmarks compared to human panels.", "motivation": "The authors want to address the limitations of the Delphi method in risk assessment, including prolonged coordination time and accessibility, and assess if LLMs can streamline this process.", "method": "The paper introduces Scalable Delphi by adapting the traditional Delphi protocol for LLMs, incorporating diverse expert personas, iterative refinement, and rationale sharing. Evaluation is conducted using benchmarks and human panel comparisons focused on AI-augmented cybersecurity risk.", "result": "LLM panels achieved high correlation with benchmark ground truth (Pearson r=0.87-0.95), showed sensitivity to added evidence, and aligned well with human expert panels. In some cases, LLMs performed closer to human expert panels than the panels did to each other.", "conclusion": "LLM-based elicitation offers a scalable alternative to traditional methods, significantly reducing elicitation time from months to minutes while maintaining strong calibration, sensitivity, and alignment with human judgments."}}
{"id": "2602.07799", "pdf": "https://arxiv.org/pdf/2602.07799", "abs": "https://arxiv.org/abs/2602.07799", "authors": ["Ching Lam Choi", "Vighnesh Subramaniam", "Phillip Isola", "Antonio Torralba", "Stefanie Jegelka"], "title": "Fairness Aware Reward Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Demographic skews in human preference data propagate systematic unfairness through reward models into aligned LLMs. We introduce Fairness Aware Reward Optimization (Faro), an in-processing framework that trains reward models under demographic parity, equalized odds, or counterfactual fairness constraints. We provide the first theoretical analysis of reward-level fairness in LLM alignment, establishing: (i) provable fairness certificates for Faro-trained rewards with controllable slack; a (ii) formal characterization of the accuracy-fairness trade-off induced by KL-regularized fine-tuning, proving fairness transfers from reward to policy; and the (iii) existence of a non-empty Pareto frontier. Unlike pre- and post-processing methods, Faro ensures reward models are simultaneously ordinal (ranking correctly), cardinal (calibrated), and fair. Across multiple LLMs and benchmarks, Faro significantly reduces bias and harmful generations while maintaining or improving model quality.", "AI": {"tldr": "The paper introduces Faro, a framework to mitigate demographic biases in reward models for LLMs and proves its effectiveness in reducing biases while preserving model quality.", "motivation": "To address the propagation of demographic skew-based biases in reward models utilized in aligned language models, ensuring fairness across demographics.", "method": "Faro, an in-processing framework, is used to train reward models using fairness constraints like demographic parity, equalized odds, or counterfactual fairness, ensuring models are fair, calibrated, and rank properly.", "result": "The study provides fairness certificates, analyzes accuracy-fairness trade-offs, and shows the existence of a fairness-accuracy Pareto frontier. Across diverse benchmarks, Faro reduces bias and harmful outputs while preserving or improving model quality.", "conclusion": "Faro proves to be an effective approach for advancing fairness in reward models of LLMs, balancing the trade-offs between fairness and accuracy, and ensuring robust outcomes."}}
{"id": "2602.07931", "pdf": "https://arxiv.org/pdf/2602.07931", "abs": "https://arxiv.org/abs/2602.07931", "authors": ["Olena Hrynenko", "Darya Baranouskaya", "Alina Elena Baia", "Andrea Cavallaro"], "title": "Which private attributes do VLMs agree on and predict well?", "categories": ["cs.CV"], "comment": "This work has been accepted to the ICASSP 2026", "summary": "Visual Language Models (VLMs) are often used for zero-shot detection of visual attributes in the image. We present a zero-shot evaluation of open-source VLMs for privacy-related attribute recognition. We identify the attributes for which VLMs exhibit strong inter-annotator agreement, and discuss the disagreement cases of human and VLM annotations. Our results show that when evaluated against human annotations, VLMs tend to predict the presence of privacy attributes more often than human annotators. In addition to this, we find that in cases of high inter-annotator agreement between VLMs, they can complement human annotation by identifying attributes overlooked by human annotators. This highlights the potential of VLMs to support privacy annotations in large-scale image datasets.", "AI": {"tldr": "This paper evaluates zero-shot Visual Language Models (VLMs) for recognizing privacy-related visual attributes in images, showing their potential in complementing human annotations.", "motivation": "The need to explore the capabilities of VLMs for privacy-related attribute recognition in images and assess their performance vis-\u00e0-vis human annotations.", "method": "The paper conducts a zero-shot evaluation of open-source VLMs to identify privacy-related visual attributes, comparing their performance to human annotations.", "result": "VLMs tend to predict the presence of privacy attributes more frequently than human annotators, and when inter-annotator agreement between VLMs is high, they effectively complement human annotation by identifying overlooked attributes.", "conclusion": "VLMs show promise in supporting privacy annotations for large-scale image datasets, despite differences from human annotations."}}
{"id": "2602.08905", "pdf": "https://arxiv.org/pdf/2602.08905", "abs": "https://arxiv.org/abs/2602.08905", "authors": ["Jiawei Liu", "Xiting Wang", "Yuanyuan Zhong", "Defu Lian", "Yu Yang"], "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models", "categories": ["cs.AI"], "comment": "13 pages, 3 figures", "summary": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.", "AI": {"tldr": "This paper introduces Spatio-Temporal Pruning (STP), a framework to enhance reinforcement learning (RL) efficiency and stability in diffusion-based Large Language Models (dLLMs).", "motivation": "Reinforcement learning in dLLMs is essential but faces challenges in efficiency and stability during application.", "method": "The authors propose STP, which uses spatial pruning (constraining exploration space with static priors) and temporal pruning (eliminating redundant refinement steps) to reduce redundancy in the generative process.", "result": "The paper demonstrates, through theoretical analysis and experiments, that STP reduces variance in log-likelihood estimation, ensuring stable policy updates. It outperforms state-of-the-art methods in efficiency and accuracy.", "conclusion": "Spatio-Temporal Pruning is a novel approach that addresses challenges in RL for dLLMs, offering improved efficiency, stability, and overall performance."}}
{"id": "2602.08939", "pdf": "https://arxiv.org/pdf/2602.08939", "abs": "https://arxiv.org/abs/2602.08939", "authors": ["Longling Geng", "Andy Ouyang", "Theodore Wu", "Daphne Barretto", "Matthew John Hayes", "Rachael Cooper", "Yuqiao Zeng", "Sameer Vijay", "Gia Ancone", "Ankit Rai", "Matthew Wolfman", "Patrick Flanagan", "Edward Y. Chang"], "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse", "categories": ["cs.AI"], "comment": "17 pages, 20 tables, figures", "summary": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench", "AI": {"tldr": "This paper introduces CausalT5K, a benchmark of 5,000+ cases designed to systematically diagnose failures in causal reasoning by language models.", "motivation": "The study aims to address the lack of systematic diagnostic tools for assessing failures in causal reasoning by LLMs, which hinders progress in remediation.", "method": "The authors developed CausalT5K, a benchmark using realistic narratives embedded with causal traps, based on Pearl's Ladder of Causation, and verified its development through a human-machine collaborative process involving domain experts and iterative validations.", "result": "Initial experiments reveal significant limitations of static audit policies in reasoning systems, demonstrating the diagnostic utility of CausalT5K.", "conclusion": "CausalT5K provides a valuable tool for diagnosing and advancing the trustworthiness of reasoning systems by uncovering nuanced failure modes and inspiring improvements."}}
{"id": "2602.07828", "pdf": "https://arxiv.org/pdf/2602.07828", "abs": "https://arxiv.org/abs/2602.07828", "authors": ["Charles Ye", "Jasmine Cui"], "title": "Efficient Representations are Controllable Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "What is the most brute-force way to install interpretable, controllable features into a model's activations? Controlling how LLMs internally represent concepts typically requires sophisticated methods to first identify, then intervene on the model's existing feature geometry. We bypass all of this.\n  We finetune an LLM with a simple auxiliary loss, training 16 of its 3072 residual stream dimensions to be inert interpretability flags that simply indicate what concepts are required for generation. The model reorganizes around them anyway, learning to rely on these flags during actual generation tasks. As a result, these inert flags become genuine internal features: interpretable control switches that allow us to steer generation at inference time. Why does this work? When a feature is reliably supplied at a fixed location, gradient descent gradually eliminates redundant encodings elsewhere, and the model erodes its own alternative representations. A model's efficiency pressure is a lever - exploitable to induce interpretable, controllable representations.", "AI": {"tldr": "The paper proposes a straightforward method to introduce interpretable, controllable features into LLMs by augmenting and retraining a small subset of dimensions in the model's residual stream.", "motivation": "The motivation is to simplify the process of controlling and interpreting how LLMs represent concepts internally, as traditional methods involve complex identification and intervention in the model's internal geometry.", "method": "The authors finetune a language model with an auxiliary loss that assigns 16 out of 3072 dimensions in the residual stream to act as interpretability flags, which the model learns to rely on during actual generation tasks.", "result": "The method enables these small, inert flags to function as meaningful and controllable internal features, effectively providing interpretable switches for steering model generation during inference.", "conclusion": "The proposed approach demonstrates how gradient descent and efficiency pressure can be used to induce interpretable representations, offering a practical and less complicated alternative to traditional methods for achieving model control and interpretability."}}
{"id": "2602.07143", "pdf": "https://arxiv.org/pdf/2602.07143", "abs": "https://arxiv.org/abs/2602.07143", "authors": ["Georg Heigold", "Ehsan Variani", "Tom Bagby", "Cyril Allauzen", "Ji Ma", "Shankar Kumar", "Michael Riley"], "title": "Massive Sound Embedding Benchmark (MSEB)", "categories": ["cs.SD", "cs.CL"], "comment": null, "summary": "Audio is a critical component of multimodal perception, and any truly intelligent system must demonstrate a wide range of auditory capabilities. These capabilities include transcription, classification, retrieval, reasoning, segmentation, clustering, reranking, and reconstruction. Fundamentally, each task involves transforming a raw audio signal into a meaningful 'embedding' - be it a single vector, a sequence of continuous or discrete representations, or another structured form - which then serves as the basis for generating the task's final response. To accelerate progress towards robust machine auditory intelligence, we present the Massive Sound Embedding Benchmark (MSEB): an extensible framework designed to evaluate the auditory components of any multimodal system. In its first release, MSEB offers a comprehensive suite of eight core tasks, with more planned for the future, supported by diverse datasets, including the new, large-scale Simple Voice Questions (SVQ) dataset. Our initial experiments establish clear performance headrooms, highlighting the significant opportunity to improve real-world multimodal experiences where audio is a core signal. We encourage the research community to use MSEB to assess their algorithms and contribute to its growth. The library is publicly hosted at github.", "AI": {"tldr": "The paper presents the Massive Sound Embedding Benchmark (MSEB) framework for evaluating audio-related tasks in multimodal systems, including results from initial experiments and a new dataset.", "motivation": "To enable robust machine auditory intelligence, addressing audio tasks such as transcription, classification, and reasoning within multimodal systems by providing a unified evaluation framework.", "method": "The authors introduce MSEB as an extensible benchmarking framework that supports eight core audio tasks with datasets like the new Simple Voice Questions (SVQ).", "result": "Initial experiments with MSEB show potential for improving multimodal systems' performance and showcase the framework's versatility.", "conclusion": "MSEB provides a standardized platform for testing auditory capabilities in intelligent systems and invites contributions from the research community to expand its scope."}}
{"id": "2602.07955", "pdf": "https://arxiv.org/pdf/2602.07955", "abs": "https://arxiv.org/abs/2602.07955", "authors": ["Jiwei Chen", "Qi Wang", "Junyu Gao", "Jing Zhang", "Dingyi Li", "Jing-Jia Luo"], "title": "One-Shot Crowd Counting With Density Guidance For Scene Adaptaion", "categories": ["cs.CV"], "comment": null, "summary": "Crowd scenes captured by cameras at different locations vary greatly, and existing crowd models have limited generalization for unseen surveillance scenes. To improve the generalization of the model, we regard different surveillance scenes as different category scenes, and introduce few-shot learning to make the model adapt to the unseen surveillance scene that belongs to the given exemplar category scene. To this end, we propose to leverage local and global density characteristics to guide the model of crowd counting for unseen surveillance scenes. Specifically, to enable the model to adapt to the varying density variations in the target scene, we propose the multiple local density learner to learn multi prototypes which represent different density distributions in the support scene. Subsequently, these multiple local density similarity matrixes are encoded. And they are utilized to guide the model in a local way. To further adapt to the global density in the target scene, the global density features are extracted from the support image, then it is used to guide the model in a global way. Experiments on three surveillance datasets shows that proposed method can adapt to the unseen surveillance scene and outperform recent state-of-the-art methods in the few-shot crowd counting.", "AI": {"tldr": "The paper introduces a few-shot learning-based crowd counting method for adapting models to unseen surveillance scenes using local and global density characteristics.", "motivation": "Existing crowd counting models struggle to generalize across diverse surveillance scenes. The authors aim to overcome this limitation by using few-shot learning to improve model adaptability.", "method": "The paper introduces a model that leverages local and global density characteristics. A multiple local density learner captures varying density variations, while global density features guide overall scene adaptation.", "result": "Experiments on three surveillance datasets demonstrate the method's effectiveness, outperforming state-of-the-art few-shot crowd counting approaches in unseen scenes.", "conclusion": "The proposed approach successfully adapts to unseen surveillance scenes using local and global density characteristics, offering improved generalization and outperforming existing methods."}}
{"id": "2602.08948", "pdf": "https://arxiv.org/pdf/2602.08948", "abs": "https://arxiv.org/abs/2602.08948", "authors": ["Chen Jin", "Ryutaro Tanno", "Tom Diethe", "Philip Teare"], "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.", "AI": {"tldr": "CoRefine introduces a confidence-guided self-refinement method that uses a lightweight Conv1D controller to improve reasoning accuracy of LLMs, reducing compute and tokens significantly.", "motivation": "To address the substantial compute required by test-time scaling in parallel decoding for improving reasoning accuracy in LLMs.", "method": "Developed CoRefine, a method using a lightweight Conv1D controller atop frozen LLMs, guiding refinement based on full-trace confidence dynamics yielding token reduction and competitive accuracy.", "result": "Achieved 92.6% precision when confidently halting, reduced tokens usage by roughly 190-fold, and demonstrated effectiveness across diverse reasoning benchmarks.", "conclusion": "CoRefine treats confidence as a control signal for scalable reasoning, offering a modular solution for agentic settings and imperfect verifiers."}}
{"id": "2602.07832", "pdf": "https://arxiv.org/pdf/2602.07832", "abs": "https://arxiv.org/abs/2602.07832", "authors": ["Xian Wu", "Kaijie Zhu", "Ying Zhang", "Lun Wang", "Wenbo Guo"], "title": "rePIRL: Learn PRM with Inverse RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Process rewards have been widely used in deep reinforcement learning to improve training efficiency, reduce variance, and prevent reward hacking. In LLM reasoning, existing works also explore various solutions for learning effective process reward models (PRM) with or without the help of an expert policy. However, existing methods either rely on strong assumptions about the expert policies (e.g., requiring their reward functions) or suffer intrinsic limitations (e.g., entropy collapse), resulting in weak PRMs or limited generalizability. In this paper, we introduce rePIRL, an inverse RL-inspired framework that learns effective PRMs with minimal assumptions about expert policies. Specifically, we design a dual learning process that updates the policy and the PRM interchangeably. Our learning algorithm has customized techniques to address the challenges of scaling traditional inverse RL to LLMs. We theoretically show that our proposed learning framework can unify both online and offline PRM learning methods, justifying that rePIRL can learn PRMs with minimal assumptions. Empirical evaluations on standardized math and coding reasoning datasets demonstrate the effectiveness of rePIRL over existing methods. We further show the application of our trained PRM in test-time training, test-time scaling, and providing an early signal for training hard problems. Finally, we validate our training recipe and key design choices via a detailed ablation study.", "AI": {"tldr": "The paper introduces rePIRL, an inverse RL-inspired framework for learning effective process reward models (PRMs) with minimal assumptions about expert policies, overcoming limitations in existing methods.", "motivation": "Current methods for learning PRMs suffer from strong assumptions about expert policies and intrinsic limitations like entropy collapse, leading to weak or less general PRMs.", "method": "rePIRL employs a dual learning process to update policy and PRM interchangeably, integrating new techniques to adapt inverse RL to LLMs. It unifies online and offline PRM learning methods.", "result": "Empirical evaluations on math and coding reasoning datasets show rePIRL's improved performance over existing methods. Applications in test-time training and signaling hard problems are demonstrated.", "conclusion": "rePIRL effectively handles process reward model learning challenges with minimal assumptions, validated by empirical success and ablation studies."}}
{"id": "2602.07960", "pdf": "https://arxiv.org/pdf/2602.07960", "abs": "https://arxiv.org/abs/2602.07960", "authors": ["Changli Tang", "Tianyi Wang", "Fengyun Rao", "Jing Lyu", "Chao Zhang"], "title": "D-ORCA: Dialogue-Centric Optimization for Robust Audio-Visual Captioning", "categories": ["cs.CV"], "comment": null, "summary": "Spoken dialogue is a primary source of information in videos; therefore, accurately identifying who spoke what and when is essential for deep video understanding. We introduce D-ORCA, a \\textbf{d}ialogue-centric \\textbf{o}mni-modal large language model optimized for \\textbf{r}obust audio-visual \\textbf{ca}ptioning. We further curate DVD, a large-scale, high-quality bilingual dataset comprising nearly 40,000 multi-party dialogue videos for training and 2000 videos for evaluation in English and Mandarin, addressing a critical gap in the open-source ecosystem. To ensure fine-grained captioning accuracy, we adopt group relative policy optimization with three novel reward functions that assess speaker attribution accuracy, global speech content accuracy, and sentence-level temporal boundary alignment. These rewards are derived from evaluation metrics widely used in speech processing and, to our knowledge, are applied for the first time as reinforcement learning objectives for audio-visual captioning. Extensive experiments demonstrate that D-ORCA substantially outperforms existing open-source models in speaker identification, speech recognition, and temporal grounding. Notably, despite having only 8 billion parameters, D-ORCA achieves performance competitive with Qwen3-Omni across several general-purpose audio-visual understanding benchmarks. Demos are available at \\href{https://d-orca-llm.github.io/}{https://d-orca-llm.github.io/}. Our code, data, and checkpoints will be available at \\href{https://github.com/WeChatCV/D-ORCA/}{https://github.com/WeChatCV/D-ORCA/}.", "AI": {"tldr": "The paper presents D-ORCA, a dialogue-centric multimodal large language model, for improved audio-visual captioning and introduces a high-quality dataset DVD to address multilingual challenges in dialogue videos.", "motivation": "The motivation is to enhance deep video understanding by accurately identifying who spoke, what was said, and when, addressing the challenge of speaker attribution and fine-grained captioning in multilingual dialogue videos.", "method": "The authors developed D-ORCA, leveraging a curated DVD dataset with bilingual dialogue videos, and used group relative policy optimization with novel reward functions for speaker attribution, speech content, and temporal alignment.", "result": "Experiments showed that D-ORCA excels in speaker identification, speech recognition, and temporal grounding, outperforming existing open-source models and achieving near-state-of-the-art performance with only 8 billion parameters.", "conclusion": "D-ORCA is a significant contribution to open-source audio-visual understanding, combining advanced methods and a comprehensive dataset to push the boundaries of dialogue-centric video analysis."}}
{"id": "2602.07834", "pdf": "https://arxiv.org/pdf/2602.07834", "abs": "https://arxiv.org/abs/2602.07834", "authors": ["D Yang Eng"], "title": "Interpretable Analytic Calabi-Yau Metrics via Symbolic Distillation", "categories": ["cs.LG", "math.DG"], "comment": "31 pages, 7 figures", "summary": "Calabi--Yau manifolds are essential for string theory but require computing intractable metrics. Here we show that symbolic regression can distill neural approximations into simple, interpretable formulas. Our five-term expression matches neural accuracy ($R^2 = 0.9994$) with 3,000-fold fewer parameters. Multi-seed validation confirms that geometric constraints select essential features, specifically power sums and symmetric polynomials, while permitting structural diversity. The functional form can be maintained across the studied moduli range ($\u03c8\\in [0, 0.8]$) with coefficients varying smoothly; we interpret these trends as empirical hypotheses within the accuracy regime of the locally-trained teachers ($\u03c3\\approx 8-9\\%$ at $\u03c8\\neq 0$). The formula reproduces physical observables -- volume integrals and Yukawa couplings -- validating that symbolic distillation recovers compact, interpretable models for quantities previously accessible only to black-box networks.", "AI": {"tldr": "This paper demonstrates the use of symbolic regression to derive simplified, interpretable formulas for Calabi\u2013Yau metrics from neural network approximations, retaining accuracy while significantly reducing complexity.", "motivation": "Calabi\u2013Yau manifolds play a crucial role in string theory but are computationally complex, motivating the need for simplified and interpretable representations.", "method": "Symbolic regression distills neural network approximations into simple formulas, validated through multi-seed testing and empirical hypothesis interpretation across moduli ranges.", "result": "A five-term formula achieves neural network accuracy ($R^2 = 0.9994$) with 3,000-fold fewer parameters, while reproducing key physical observables, such as volume integrals and Yukawa couplings.", "conclusion": "Symbolic distillation can produce compact, interpretable models for physical quantities previously accessible only through black-box methods, demonstrating potential for simplifying complex theoretical computations."}}
{"id": "2602.07179", "pdf": "https://arxiv.org/pdf/2602.07179", "abs": "https://arxiv.org/abs/2602.07179", "authors": ["Mona Rajhans", "Vishal Khawarey"], "title": "An Information-Theoretic Framework for Comparing Voice and Text Explainability", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.IT"], "comment": "Accepted for publication at the 10th ACM International Conference on Intelligent Systems, Metaheuristics & Swarm Intelligence (ISMSI 2026), April 24-26, Cebu City, Phillipines", "summary": "Explainable Artificial Intelligence (XAI) aims to make machine learning models transparent and trustworthy, yet most current approaches communicate explanations visually or through text. This paper introduces an information theoretic framework for analyzing how explanation modality specifically, voice versus text affects user comprehension and trust calibration in AI systems. The proposed model treats explanation delivery as a communication channel between model and user, characterized by metrics for information retention, comprehension efficiency (CE), and trust calibration error (T CE). A simulation framework implemented in Python was developed to evaluate these metrics using synthetic SHAP based feature attributions across multiple modality style configurations (brief, detailed, and analogy based). Results demonstrate that text explanations achieve higher comprehension efficiency, while voice explanations yield improved trust calibration, with analogy based delivery achieving the best overall trade off. This framework provides a reproducible foundation for designing and benchmarking multimodal explainability systems and can be extended to empirical studies using real SHAP or LIME outputs on open datasets such as the UCI Credit Approval or Kaggle Financial Transactions datasets.", "AI": {"tldr": "This paper develops a simulation framework to evaluate the impact of explanation modalities (voice vs. text) in explainable AI, showing text enhances comprehension efficiency while voice improves trust calibration.", "motivation": "Many XAI methods focus on visual or text explanations, limiting exploration of voice-based or multimodal approaches, which may impact user trust and understanding.", "method": "The authors propose a Python-based simulation framework that uses an information-theoretic model to evaluate SHAP-based feature attributions delivered in varied styles (text or voice).", "result": "Text explanations were more efficient for comprehension, while voice explanations better calibrated user trust, with analogy-based delivery balancing these trade-offs effectively.", "conclusion": "The developed framework enables reproducible evaluation and design of multimodal XAI systems, offering insights for empirical studies using SHAP or LIME outputs on real-world datasets."}}
{"id": "2602.07967", "pdf": "https://arxiv.org/pdf/2602.07967", "abs": "https://arxiv.org/abs/2602.07967", "authors": ["Xiaofeng Tan", "Wanjiang Weng", "Haodong Lei", "Hongsong Wang"], "title": "EasyTune: Efficient Step-Aware Fine-Tuning for Diffusion-Based Motion Generation", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, motion generative models have undergone significant advancement, yet pose challenges in aligning with downstream objectives. Recent studies have shown that using differentiable rewards to directly align the preference of diffusion models yields promising results. However, these methods suffer from (1) inefficient and coarse-grained optimization with (2) high memory consumption. In this work, we first theoretically and empirically identify the key reason of these limitations: the recursive dependence between different steps in the denoising trajectory. Inspired by this insight, we propose EasyTune, which fine-tunes diffusion at each denoising step rather than over the entire trajectory. This decouples the recursive dependence, allowing us to perform (1) a dense and fine-grained, and (2) memory-efficient optimization. Furthermore, the scarcity of preference motion pairs restricts the availability of motion reward model training. To this end, we further introduce a Self-refinement Preference Learning (SPL) mechanism that dynamically identifies preference pairs and conducts preference learning. Extensive experiments demonstrate that EasyTune outperforms DRaFT-50 by 8.2% in alignment (MM-Dist) improvement while requiring only 31.16% of its additional memory overhead and achieving a 7.3x training speedup. The project page is available at this link {https://xiaofeng-tan.github.io/projects/EasyTune/index.html}.", "AI": {"tldr": "EasyTune refines motion generative models by optimizing diffusion at every denoising step instead of the entire trajectory, offering memory-efficient and fine-grained optimization.", "motivation": "Enable more efficient and effective alignment of motion generative models with downstream objectives, addressing limitations of existing methods such as coarse optimization and high memory usage.", "method": "EasyTune optimizes diffusion models step-by-step rather than across the full denoising trajectory. Additionally, it uses SPL (Self-refinement Preference Learning) to dynamically identify preference pairs for preference model training.", "result": "EasyTune outperforms DRaFT-50 with an 8.2% alignment improvement while reducing memory overhead by 68.84% and achieving a 7.3x training speedup.", "conclusion": "EasyTune significantly enhances diffusion-based motion generation with better performance, lower memory usage, and faster training by decoupling recursive dependencies and using SPL for robust preference modeling."}}
{"id": "2602.08968", "pdf": "https://arxiv.org/pdf/2602.08968", "abs": "https://arxiv.org/abs/2602.08968", "authors": ["Lucas Maes", "Quentin Le Lidec", "Dan Haramati", "Nassim Massaudi", "Damien Scieur", "Yann LeCun", "Randall Balestriero"], "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.", "AI": {"tldr": "The paper introduces SWM, a modular research ecosystem for World Models, promoting standardization, reusability, and robust research.", "motivation": "The motivation is to address the lack of reusability, standardization, and reliability in current World Model implementations, which hinders robust and generalizable research.", "method": "The authors developed SWM, a modular and tested ecosystem providing data collection tools, environments, planning algorithms, and baseline implementations with controllable factors.", "result": "SWM demonstrated its utility by studying zero-shot robustness in DINO-WM, supporting research in robustness and continual learning.", "conclusion": "SWM enhances World Model research by providing a standardized, reusable framework, encouraging efficiency, reliability, and explorative studies in the field."}}
{"id": "2602.07848", "pdf": "https://arxiv.org/pdf/2602.07848", "abs": "https://arxiv.org/abs/2602.07848", "authors": ["Shijie Wang", "Pengfei Li", "Yikun Fu", "Kaifeng Liu", "Fangyuan Li", "Yang Liu", "Xiaowei Sun", "Zonglin Li", "Siyao Zhao", "Jian Zhao", "Kai Tian", "Dong Li", "Junqi Gao", "Yutong Zhang", "Yiqun Chen", "Yuqiang Li", "Zoe Li", "Weinan Zhang", "Peng Ye", "Shuyue Hu", "Lei Bai", "Bowen Zhou", "Kaiyan Zhang", "Biqing Qi"], "title": "MARTI-MARS$^2$: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation", "categories": ["cs.LG"], "comment": null, "summary": "While the complex reasoning capability of Large Language Models (LLMs) has attracted significant attention, single-agent systems often encounter inherent performance ceilings in complex tasks such as code generation. Multi-agent collaboration offers a promising avenue to transcend these boundaries. However, existing frameworks typically rely on prompt-based test-time interactions or multi-role configurations trained with homogeneous parameters, limiting error correction capabilities and strategic diversity. In this paper, we propose a Multi-Agent Reinforced Training and Inference Framework with Self-Search Scaling (MARTI-MARS2), which integrates policy learning with multi-agent tree search by formulating the multi-agent collaborative exploration process as a dynamic and learnable environment. By allowing agents to iteratively explore and refine within the environment, the framework facilitates evolution from parameter-sharing homogeneous multi-role training to heterogeneous multi-agent training, breaking through single-agent capability limits. We also introduce an efficient inference strategy MARTI-MARS2-T+ to fully exploit the scaling potential of multi-agent collaboration at test time. We conduct extensive experiments across varied model scales (8B, 14B, and 32B) on challenging code generation benchmarks. Utilizing two collaborating 32B models, MARTI-MARS2 achieves 77.7%, outperforming strong baselines like GPT-5.1. Furthermore, MARTI-MARS2 reveals a novel scaling law: shifting from single-agent to homogeneous multi-role and ultimately to heterogeneous multi-agent paradigms progressively yields higher RL performance ceilings, robust TTS capabilities, and greater policy diversity, suggesting that policy diversity is critical for scaling intelligence via multi-agent reinforcement learning.", "AI": {"tldr": "The paper introduces MARTI-MARS2, a multi-agent framework for surpassing single-agent performance limits in tasks like code generation.", "motivation": "To overcome the performance limitations of single-agent systems in complex tasks, exploring multi-agent collaborative approaches with strategic diversity.", "method": "Developing the MARTI-MARS2 framework, which combines policy learning and multi-agent tree search in a dynamic and learnable environment, enabling agents to evolve from homogeneous to heterogeneous training.", "result": "MARTI-MARS2, using two 32B models, achieved 77.7% on challenging code generation tasks, surpassing state-of-the-art methods like GPT-5.1.", "conclusion": "Policy diversity is essential for enhancing intelligence and achieving higher performance ceilings through multi-agent reinforcement learning frameworks."}}
{"id": "2602.07979", "pdf": "https://arxiv.org/pdf/2602.07979", "abs": "https://arxiv.org/abs/2602.07979", "authors": ["Peng Peng", "Xinrui Zhang", "Junlin Wang", "Lei Li", "Shaoyu Wang", "Qiegen Liu"], "title": "FSP-Diff: Full-Spectrum Prior-Enhanced DualDomain Latent Diffusion for Ultra-Low-Dose Spectral CT Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Spectral computed tomography (CT) with photon-counting detectors holds immense potential for material discrimination and tissue characterization. However, under ultra-low-dose conditions, the sharply degraded signal-to-noise ratio (SNR) in energy-specific projections poses a significant challenge, leading to severe artifacts and loss of structural details in reconstructed images. To address this, we propose FSP-Diff, a full-spectrum prior-enhanced dual-domain latent diffusion framework for ultra-low-dose spectral CT reconstruction. Our framework integrates three core strategies: 1) Complementary Feature Construction: We integrate direct image reconstructions with projection-domain denoised results. While the former preserves latent textural nuances amidst heavy noise, the latter provides a stable structural scaffold to balance detail fidelity and noise suppression. 2) Full-Spectrum Prior Integration: By fusing multi-energy projections into a high-SNR full-spectrum image, we establish a unified structural reference that guides the reconstruction across all energy bins. 3) Efficient Latent Diffusion Synthesis: To alleviate the high computational burden of high-dimensional spectral data, multi-path features are embedded into a compact latent space. This allows the diffusion process to facilitate interactive feature fusion in a lower-dimensional manifold, achieving accelerated reconstruction while maintaining fine-grained detail restoration. Extensive experiments on simulated and real-world datasets demonstrate that FSP-Diff significantly outperforms state-of-the-art methods in both image quality and computational efficiency, underscoring its potential for clinically viable ultra-low-dose spectral CT imaging.", "AI": {"tldr": "The paper introduces FSP-Diff, a technique to improve ultra-low-dose spectral CT reconstruction using photon-counting detectors, addressing low signal-to-noise ratios and artifacts.", "motivation": "Current spectral CT imaging suffers from poor image quality and structural loss under ultra-low-dose conditions, necessitating a solution for clearer and more accurate results.", "method": "The framework incorporates complementary feature construction, high-SNR full-spectrum prior integration, and efficient latent diffusion synthesis to enhance reconstruction quality and efficiency.", "result": "FSP-Diff outperformed state-of-the-art methods in terms of image quality and computational speed on both simulated and real-world datasets.", "conclusion": "FSP-Diff holds potential for advancing clinically viable ultra-low-dose spectral CT imaging by merging detailed reconstruction with computational efficiency."}}
{"id": "2602.08990", "pdf": "https://arxiv.org/pdf/2602.08990", "abs": "https://arxiv.org/abs/2602.08990", "authors": ["Shiyang Feng", "Runmin Ma", "Xiangchao Yan", "Yue Fan", "Yusong Hu", "Songtao Huang", "Shuaiyu Zhang", "Zongsheng Cao", "Tianshuo Peng", "Jiakang Yuan", "Zijie Guo", "Zhijie Zhong", "Shangheng Du", "Weida Wang", "Jinxin Shi", "Yuhao Zhou", "Xiaohan He", "Zhiyin Yu", "Fangchen Yu", "Qihao Zheng", "Jiamin Wu", "Mianxin Liu", "Chi Zhang", "Shaowei Hou", "Shuya Li", "Yankai Jiang", "Wenjie Lou", "Lilong Wang", "Zifu Wang", "Jiong Wang", "Wanghan Xu", "Yue Deng", "Dongrui Liu", "Yiheng Wang", "Wenlong Zhang", "Fenghua Ling", "Shufei Zhang", "Xiaosong Wang", "Shuangjia Zheng", "Xun Huang", "Siqi Sun", "Shuyue Hu", "Peng Ye", "Chunfeng Song", "Bin Wang", "Conghui He", "Yihao Liu", "Xin Li", "Qibin Hou", "Tao Chen", "Xiangyu Yue", "Bin Wang", "Liang He", "Dahua Lin", "Bowen Zhou", "Bo Zhang", "Lei Bai"], "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery", "categories": ["cs.AI"], "comment": "Code and project page: https://github.com/InternScience/InternAgent", "summary": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.", "AI": {"tldr": "InternAgent-1.5 is a unified framework enabling autonomous scientific discovery through computational modeling and laboratory experimentation.", "motivation": "Develop a system capable of end-to-end scientific discovery across computational and empirical domains.", "method": "Structured architecture with three subsystems for generation, verification, and evolution, supported by research optimization and memory capabilities.", "result": "InternAgent-1.5 achieves leading performance on scientific reasoning benchmarks and demonstrates success in algorithm and empirical discovery tasks.", "conclusion": "InternAgent-1.5 is a scalable and general framework that supports autonomous scientific discovery at advanced capacities in multiple domains."}}
{"id": "2602.07859", "pdf": "https://arxiv.org/pdf/2602.07859", "abs": "https://arxiv.org/abs/2602.07859", "authors": ["Siyu Lu", "Chenhan Xiao", "Yang Weng"], "title": "Dynamic Load Model for Data Centers with Pattern-Consistent Calibration", "categories": ["cs.LG"], "comment": "10 pages, 13 figures", "summary": "The rapid growth of data centers has made large electronic load (LEL) modeling increasingly important for power system analysis. Such loads are characterized by fast workload-driven variability and protection-driven disconnection and reconnection behavior that are not captured by conventional load models. Existing data center load modeling includes physics-based approaches, which provide interpretable structure for grid simulation, and data-driven approaches, which capture empirical workload variability from data. However, physics-based models are typically uncalibrated to facility-level operation, while trajectory alignment in data-driven methods often leads to overfitting and unrealistic dynamic behavior. To resolve these limitations, we design the framework to leverage both physics-based structure and data-driven adaptability. The physics-based structure is parameterized to enable data-driven pattern-consistent calibration from real operational data, supporting facility-level grid planning. We further show that trajectory-level alignment is limited for inherently stochastic data center loads. Therefore, we design the calibration to align temporal and statistical patterns using temporal contrastive learning (TCL). This calibration is performed locally at the facility, and only calibrated parameters are shared with utilities, preserving data privacy. The proposed load model is calibrated by real-world operational load data from the MIT Supercloud, ASU Sol, Blue Waters, and ASHRAE datasets. Then it is integrated into the ANDES platform and evaluated on the IEEE 39-bus, NPCC 140-bus, and WECC 179-bus systems. We find that interactions among LELs can fundamentally alter post-disturbance recovery behavior, producing compound disconnection-reconnection dynamics and delayed stabilization that are not captured by uncalibrated load models.", "AI": {"tldr": "The paper introduces a hybrid approach to model large electronic loads (LELs) in data centers, combining physics-based structure with data-driven calibration methods.", "motivation": "With the increasing significance of data centers, modeling LELs accurately is critical for power system analysis due to their rapid variability and disconnection-reconnection behavior.", "method": "The method combines physics-based load modeling with data-driven calibration using temporal contrastive learning (TCL) to align temporal and statistical load patterns while preserving data privacy.", "result": "The proposed model, validated on multiple datasets and tested on large-scale power systems, revealed previously unobserved dynamics such as compound disconnection-reconnection and delayed stabilization.", "conclusion": "The hybrid model provides a more realistic and adaptable framework for power grid planning and analysis, addressing limitations in both traditional physics-based and data-driven approaches."}}
{"id": "2602.07980", "pdf": "https://arxiv.org/pdf/2602.07980", "abs": "https://arxiv.org/abs/2602.07980", "authors": ["Junlin Wang", "Jiancheng Fang", "Peng Peng", "Shaoyu Wang", "Qiegen Liu"], "title": "Continuity-driven Synergistic Diffusion with Neural Priors for Ultra-Sparse-View CBCT Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "The clinical application of cone-beam computed tomography (CBCT) is constrained by the inherent trade-off between radiation exposure and image quality. Ultra-sparse angular sampling, employed to reduce dose, introduces severe undersampling artifacts and inter-slice inconsistencies, compromising diagnostic reliability. Existing reconstruction methods often struggle to balance angular continuity with spatial detail fidelity. To address these challenges, we propose a Continuity-driven Synergistic Diffusion with Neural priors (CSDN) for ultra-sparse-view CBCT reconstruction. Neural priors are introduced as a structural foundation to encode a continuous threedimensional attenuation representation, enabling the synthesis of physically consistent dense projections from ultra-sparse measurements. Building upon this neural-prior-based initialization, a synergistic diffusion strategy is developed, consisting of two collaborative refinement paths: a Sinogram Refinement Diffusion (Sino-RD) process that restores angular continuity and a Digital Radiography Refinement Diffusion (DR-RD) process that enforces inter-slice consistency from the projection image perspective. The outputs of the two diffusion paths are adaptively fused by the Dual-Projection Reconstruction Fusion (DPRF) module to achieve coherent volumetric reconstruction. Extensive experiments demonstrate that the proposed CSDN effectively suppresses artifacts and recovers fine textures under ultra-sparse-view conditions, outperforming existing state-of-the-art techniques.", "AI": {"tldr": "The paper proposes CSDN, a novel method for reconstructing high-quality CBCT images from ultra-sparse angular sampling, mitigating artifacts and inconsistencies.", "motivation": "Ultra-sparse angular sampling in CBCT reduces radiation dose but introduces severe artifacts and inconsistencies, challenging diagnostic reliability.", "method": "The CSDN framework uses neural priors for continuous 3D attenuation modeling and synergistic diffusion strategies for refinement. Two paths\u2014Sinogram Refinement Diffusion and Digital Radiography Refinement Diffusion\u2014are fused for coherent volume reconstruction.", "result": "CSDN significantly reduces artifacts and enhances texture recovery under ultra-sparse conditions, outperforming existing methods in experiments.", "conclusion": "CSDN successfully balances radiation dose minimization and image quality, providing a reliable solution for ultra-sparse-view CBCT reconstructions."}}
{"id": "2602.09000", "pdf": "https://arxiv.org/pdf/2602.09000", "abs": "https://arxiv.org/abs/2602.09000", "authors": ["Ali Hatamizadeh", "Shrimai Prabhumoye", "Igor Gitman", "Ximing Lu", "Seungju Han", "Wei Ping", "Yejin Choi", "Jan Kautz"], "title": "iGRPO: Self-Feedback-Driven LLM Reasoning", "categories": ["cs.AI"], "comment": "Tech report", "summary": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.", "AI": {"tldr": "The paper proposes an advanced RL-based optimization approach called Iterative Group Relative Policy Optimization (iGRPO) for improving LLMs in solving mathematical problems. It combines dynamic self-conditioning and performance feedback to refine LLM reasoning.", "motivation": "The motivation is to address the inconsistency and inaccuracy challenges in solving mathematical problems using LLMs, improving their reasoning quality and reliability through reinforcement learning strategies.", "method": "The authors introduce iGRPO, a two-stage RL process that dynamically conditions models by generating exploratory drafts (Stage 1) and refining based on the best rewards (Stage 2). GRPO-style updates are used for iterative improvement.", "result": "iGRPO outperforms GRPO consistently on reasoning benchmarks and achieves state-of-the-art results in mathematical problem-solving, achieving 85.62% on AIME24 and 79.64% on AIME25.", "conclusion": "Iterative, self-feedback-based RL techniques like iGRPO open up possibilities for advancing the reliability of LLM outputs, especially in tasks requiring complex reasoning such as mathematics."}}
{"id": "2602.07873", "pdf": "https://arxiv.org/pdf/2602.07873", "abs": "https://arxiv.org/abs/2602.07873", "authors": ["Donghyeon Ki", "Hee-Jun Ahn", "Kyungyoon Kim", "Byung-Jun Lee"], "title": "Direct Soft-Policy Sampling via Langevin Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Soft policies in reinforcement learning define policies as Boltzmann distributions over state-action value functions, providing a principled mechanism for balancing exploration and exploitation. However, realizing such soft policies in practice remains challenging. Existing approaches either depend on parametric policies with limited expressivity or employ diffusion-based policies whose intractable likelihoods hinder reliable entropy estimation in soft policy objectives. We address this challenge by directly realizing soft-policy sampling via Langevin dynamics driven by the action gradient of the Q-function. This perspective leads to Langevin Q-Learning (LQL), which samples actions from the target Boltzmann distribution without explicitly parameterizing the policy. However, directly applying Langevin dynamics suffers from slow mixing in high-dimensional and non-convex Q-landscapes, limiting its practical effectiveness. To overcome this, we propose Noise-Conditioned Langevin Q-Learning (NC-LQL), which integrates multi-scale noise perturbations into the value function. NC-LQL learns a noise-conditioned Q-function that induces a sequence of progressively smoothed value landscapes, enabling sampling to transition from global exploration to precise mode refinement. On OpenAI Gym MuJoCo benchmarks, NC-LQL achieves competitive performance compared to state-of-the-art diffusion-based methods, providing a simple yet powerful solution for online RL.", "AI": {"tldr": "This paper introduces a reinforcement learning method, NC-LQL, which improves sampling efficiency within soft policies by utilizing noise-conditioned Langevin dynamics.", "motivation": "Soft policies in reinforcement learning are powerful for balancing exploration and exploitation but are hard to implement due to limitations in policy parameterization and difficulty in accurate entropy estimation.", "method": "The authors propose Noise-Conditioned Langevin Q-Learning (NC-LQL), which uses Langevin dynamics with multi-scale noise perturbations, allowing for more effective and adaptive action sampling.", "result": "NC-LQL demonstrates competitive performance on OpenAI Gym MuJoCo benchmarks compared to state-of-the-art diffusion-based methods.", "conclusion": "NC-LQL offers a simple and effective method for implementing soft policies, addressing challenges of slow mixing and poor sampling in non-convex, high-dimensional RL tasks."}}
{"id": "2602.07986", "pdf": "https://arxiv.org/pdf/2602.07986", "abs": "https://arxiv.org/abs/2602.07986", "authors": ["Md. Tarek Hasan", "Sanjay Saha", "Shaojing Fan", "Swakkhar Shatabda", "Terence Sim"], "title": "Deepfake Synthesis vs. Detection: An Uneven Contest", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of deepfake technology has significantly elevated the realism and accessibility of synthetic media. Emerging techniques, such as diffusion-based models and Neural Radiance Fields (NeRF), alongside enhancements in traditional Generative Adversarial Networks (GANs), have contributed to the sophisticated generation of deepfake videos. Concurrently, deepfake detection methods have seen notable progress, driven by innovations in Transformer architectures, contrastive learning, and other machine learning approaches. In this study, we conduct a comprehensive empirical analysis of state-of-the-art deepfake detection techniques, including human evaluation experiments against cutting-edge synthesis methods. Our findings highlight a concerning trend: many state-of-the-art detection models exhibit markedly poor performance when challenged with deepfakes produced by modern synthesis techniques, including poor performance by human participants against the best quality deepfakes. Through extensive experimentation, we provide evidence that underscores the urgent need for continued refinement of detection models to keep pace with the evolving capabilities of deepfake generation technologies. This research emphasizes the critical gap between current detection methodologies and the sophistication of new generation techniques, calling for intensified efforts in this crucial area of study.", "AI": {"tldr": "Deepfake detection systems struggle against newer, higher-quality generation methods, including diffusion models and NeRF.", "motivation": "Deepfake realism and accessibility have surged due to advanced synthesis technologies, requiring robust detection systems to prevent misuse.", "method": "Conducted empirical analysis of modern deepfake detection techniques, including human evaluations, against cutting-edge synthesis methods.", "result": "Detection methods, including human evaluators, demonstrated poor performance against new-generation deepfakes.", "conclusion": "Detection technologies must urgently evolve to meet the increasing sophistication of deepfake generation methods."}}
{"id": "2602.09003", "pdf": "https://arxiv.org/pdf/2602.09003", "abs": "https://arxiv.org/abs/2602.09003", "authors": ["Yudong Wang", "Zixuan Fu", "Hengyu Zhao", "Chen Zhao", "Chuyue Zhou", "Xinle Lin", "Hongya Lyu", "Shuaikang Xue", "Yi Yi", "Yingjiao Wang", "Zhi Zheng", "Yuzhou Zhang", "Jie Zhou", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management", "categories": ["cs.AI", "cs.CL"], "comment": "16 pages, 3 figures, 7 tables", "summary": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.", "AI": {"tldr": "This paper proposes a framework for scalable and efficient data management in LLM training to overcome current bottlenecks in data acquisition and usage.", "motivation": "Current LLM research faces challenges with data availability, cost, and efficiency, necessitating a transformation in how models and data interact.", "method": "A tiered data management framework (L0-L4) is proposed, where data tiers range from raw uncurated resources to structured knowledge, and LLMs are utilized in quality scoring and editing.", "result": "The proposed framework significantly improves model training efficiency and performance through tier-aware data utilization, validated by empirical studies.", "conclusion": "Tiered data management offers a systematic approach to sustainable LLM training, integrating models and strategic data management to boost efficiency and capability."}}
{"id": "2602.07875", "pdf": "https://arxiv.org/pdf/2602.07875", "abs": "https://arxiv.org/abs/2602.07875", "authors": ["Aditya Shankar", "Yuandou Wang", "Rihan Hai", "Lydia Y. Chen"], "title": "Harpoon: Generalised Manifold Guidance for Conditional Tabular Diffusion", "categories": ["cs.LG"], "comment": "Accepted at ICLR 2026", "summary": "Generating tabular data under conditions is critical to applications requiring precise control over the generative process. Existing methods rely on training-time strategies that do not generalise to unseen constraints during inference, and struggle to handle conditional tasks beyond tabular imputation. While manifold theory offers a principled way to guide generation, current formulations are tied to specific inference-time objectives and are limited to continuous domains. We extend manifold theory to tabular data and expand its scope to handle diverse inference-time objectives. On this foundation, we introduce HARPOON, a tabular diffusion method that guides unconstrained samples along the manifold geometry to satisfy diverse tabular conditions at inference. We validate our theoretical contributions empirically on tasks such as imputation and enforcing inequality constraints, demonstrating HARPOON'S strong performance across diverse datasets and the practical benefits of manifold-aware guidance for tabular data. Code URL: https://github.com/adis98/Harpoon", "AI": {"tldr": "This paper introduces HARPOON, a method for generating tabular data under diverse conditions using manifold theory and diffusion processes.", "motivation": "Current methods for conditionally generating tabular data fall short in generalizing to unseen constraints and handling tasks beyond imputation. There is a need for a more robust technique to address diverse inference-time objectives.", "method": "The paper extends manifold theory for tabular data and introduces HARPOON, a tabular diffusion method that utilizes manifold geometry to guide samples to satisfy various conditions during inference.", "result": "The proposed method, HARPOON, performs well across various datasets and tasks such as tabular imputation and enforcing inequality constraints, validating its theoretical framework.", "conclusion": "HARPOON demonstrates that manifold-aware guidance in tabular data generation enhances performance across diverse tasks, offering a principled solution for conditional tabular data synthesis."}}
{"id": "2602.07993", "pdf": "https://arxiv.org/pdf/2602.07993", "abs": "https://arxiv.org/abs/2602.07993", "authors": ["Xuehai Bai", "Xiaoling Gu", "Akide Liu", "Hangjie Yuan", "YiFan Zhang", "Jack Ma"], "title": "MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by AAAI2026", "summary": "Recent advances in instruction-based image editing have shown remarkable progress. However, existing methods remain limited to relatively simple editing operations, hindering real-world applications that require complex and compositional instructions. In this work, we address these limitations from the perspectives of architectural design, data, and evaluation protocols. Specifically, we identify two key challenges in current models: insufficient instruction compliance and background inconsistency. To this end, we propose MCIE-E1, a Multimodal Large Language Model-Driven Complex Instruction Image Editing method that integrates two key modules: a spatial-aware cross-attention module and a background-consistent cross-attention module. The former enhances instruction-following capability by explicitly aligning semantic instructions with spatial regions through spatial guidance during the denoising process, while the latter preserves features in unedited regions to maintain background consistency. To enable effective training, we construct a dedicated data pipeline to mitigate the scarcity of complex instruction-based image editing datasets, combining fine-grained automatic filtering via a powerful MLLM with rigorous human validation. Finally, to comprehensively evaluate complex instruction-based image editing, we introduce CIE-Bench, a new benchmark with two new evaluation metrics. Experimental results on CIE-Bench demonstrate that MCIE-E1 consistently outperforms previous state-of-the-art methods in both quantitative and qualitative assessments, achieving a 23.96% improvement in instruction compliance.", "AI": {"tldr": "This paper presents MCIE-E1, a new method for complex instruction-based image editing that addresses limitations in existing models related to instruction compliance and background consistency.", "motivation": "Existing image editing methods are limited to simple edits and face challenges in handling complex, compositional instructions. There is a need for improved compliance with instructions and preservation of background consistency in edits.", "method": "The MCIE-E1 model includes two key modules: a spatial-aware cross-attention module for aligning instructions with spatial regions, and a background-consistent module for preserving unedited features. A custom dataset pipeline and human validation are used for training. Additionally, they propose CIE-Bench as a new evaluation benchmark.", "result": "MCIE-E1 shows a significant improvement, achieving a 23.96% boost in instruction compliance over previous methods and demonstrates better qualitative and quantitative results.", "conclusion": "MCIE-E1 effectively addresses two major challenges in instruction-based image editing, enhancing model performance and setting a new benchmark for evaluation in this domain."}}
{"id": "2602.09007", "pdf": "https://arxiv.org/pdf/2602.09007", "abs": "https://arxiv.org/abs/2602.09007", "authors": ["Haodong Li", "Jingwei Wu", "Quan Sun", "Guopeng Li", "Juanxi Tian", "Huanyu Zhang", "Yanlin Lai", "Ruichuan An", "Hongbo Peng", "Yuhong Dai", "Chenxi Li", "Chunmei Qing", "Jia Wang", "Ziyang Meng", "Zheng Ge", "Xiangyu Zhang", "Daxin Jiang"], "title": "GEBench: Benchmarking Image Generation Models as GUI Environments", "categories": ["cs.AI", "cs.CV"], "comment": "23 pages, 5 figures, 4 tables", "summary": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.", "AI": {"tldr": "The paper introduces GEBench, a benchmark for evaluating dynamic interaction and temporal coherence in graphical user interface (GUI) generation, and proposes a novel metric for systematic evaluation.", "motivation": "Existing benchmarks in image generation fail to evaluate GUI-specific state transitions and temporal coherence, creating a need for a more focused evaluation framework.", "method": "The authors developed GEBench with 700 curated samples across five task categories and introduced GE-Score, a five-dimensional metric for systematic assessment.", "result": "Current models perform well in single-step GUI transitions but struggle with temporal coherence and spatial grounding in multi-step interactions. Bottlenecks include icon interpretation, text rendering, and localization precision.", "conclusion": "The work provides a structured framework for benchmarking GUI generation models and suggests directions for improving temporal coherence and spatial grounding."}}
{"id": "2602.07884", "pdf": "https://arxiv.org/pdf/2602.07884", "abs": "https://arxiv.org/abs/2602.07884", "authors": ["Mohammad Ashhad", "Robert Hoehndorf", "Ricardo Henao"], "title": "GRAFT: Decoupling Ranking and Calibration for Survival Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Survival analysis is complicated by censored data, high-dimensional features, and non-linear interactions. Classical models are interpretable but restrictive, while deep learning models are flexible but often non-interpretable and sensitive to noise. We propose GRAFT (Gated Residual Accelerated Failure Time), a novel AFT model that decouples prognostic ranking from calibration. GRAFT's hybrid architecture combines a linear AFT model with a non-linear residual neural network, and it also integrates stochastic gates for automatic, end-to-end feature selection. The model is trained by directly optimizing a differentiable, C-index-aligned ranking loss using stochastic conditional imputation from local Kaplan-Meier estimators. In public benchmarks, GRAFT outperforms baselines in discrimination and calibration, while remaining robust and sparse in high-noise settings.", "AI": {"tldr": "The paper presents GRAFT, a novel hybrid AFT model for survival analysis, combining linear models and neural networks, and optimizing performance under noise-sensitive settings.", "motivation": "Address challenges in survival analysis, including censored data, high-dimensional features, and complex, non-linear interactions.", "method": "Introduce GRAFT\u2014a hybrid model combining linear AFT and non-linear residual neural networks, with stochastic gates for feature selection and optimized ranking loss using local Kaplan-Meier estimators.", "result": "GRAFT achieves superior performance in discrimination and calibration on public benchmarks, while proving robust and sparse in noisy conditions.", "conclusion": "GRAFT offers a promising approach to overcoming limitations of classical and deep learning models in survival analysis, improving interpretability and robustness."}}
{"id": "2602.07333", "pdf": "https://arxiv.org/pdf/2602.07333", "abs": "https://arxiv.org/abs/2602.07333", "authors": ["Rajat Arora", "Ye Tao", "Jianqiang Shen", "Ping Liu", "Muchen Wu", "Qianqi Shen", "Benjamin Le", "Fedor Borisyuk", "Jingwei Wu", "Wenjing Zhang"], "title": "High Fidelity Textual User Representation over Heterogeneous Sources via Reinforcement Learning", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Effective personalization on large-scale job platforms requires modeling members based on heterogeneous textual sources, including profiles, professional data, and search activity logs. As recommender systems increasingly adopt Large Language Models (LLMs), creating unified, interpretable, and concise representations from heterogeneous sources becomes critical, especially for latency-sensitive online environments. In this work, we propose a novel Reinforcement Learning (RL) framework to synthesize a unified textual representation for each member. Our approach leverages implicit user engagement signals (e.g., clicks, applies) as the primary reward to distill salient information. Additionally, the framework is complemented by rule-based rewards that enforce formatting and length constraints. Extensive offline experiments across multiple LinkedIn products, one of the world's largest job platforms, demonstrate significant improvements in key downstream business metrics. This work provides a practical, labeling-free, and scalable solution for constructing interpretable user representations that are directly compatible with LLM-based systems.", "AI": {"tldr": "The paper introduces a reinforcement learning framework to create unified user representations from multiple data sources for LinkedIn\u2019s recommender systems, improving performance and scalability.", "motivation": "The motivation is to effectively model user behavior on large-scale job platforms, integrating diverse textual data while ensuring compatibility with latency-sensitive environments and modern LLM-based systems.", "method": "A reinforcement learning framework that uses user engagement signals (e.g., clicks, applies) as rewards, along with rule-based rewards to ensure formatting and concise representations.", "result": "The approach improved key business metrics for LinkedIn\u2019s recommender systems, as shown by extensive offline experiments across multiple LinkedIn products.", "conclusion": "The method offers a scalable, labeling-free way to create interpretable user representations, well-suited for LLM-powered systems in large, real-world applications."}}
{"id": "2007.16012", "pdf": "https://arxiv.org/pdf/2007.16012", "abs": "https://arxiv.org/abs/2007.16012", "authors": ["Josh Payne", "Mario Srouji", "Dian Ang Yap", "Vineet Kosaraju"], "title": "BERT Learns (and Teaches) Chemistry", "categories": ["q-bio.BM", "cs.AI", "cs.CL", "cs.LG", "stat.ML"], "comment": "10 pages, 5 figures", "summary": "Modern computational organic chemistry is becoming increasingly data-driven. There remain a large number of important unsolved problems in this area such as product prediction given reactants, drug discovery, and metric-optimized molecule synthesis, but efforts to solve these problems using machine learning have also increased in recent years. In this work, we propose the use of attention to study functional groups and other property-impacting molecular substructures from a data-driven perspective, using a transformer-based model (BERT) on datasets of string representations of molecules and analyzing the behavior of its attention heads. We then apply the representations of functional groups and atoms learned by the model to tackle problems of toxicity, solubility, drug-likeness, and synthesis accessibility on smaller datasets using the learned representations as features for graph convolution and attention models on the graph structure of molecules, as well as fine-tuning of BERT. Finally, we propose the use of attention visualization as a helpful tool for chemistry practitioners and students to quickly identify important substructures in various chemical properties.", "AI": {"tldr": "The paper explores using attention mechanisms in transformer models for studying molecular substructures and applies it to various chemistry-related problems including toxicity and drug-likeness.", "motivation": "To address unsolved problems in computational organic chemistry, such as product prediction, drug discovery, and molecular synthesis optimization, using data-driven machine learning approaches.", "method": "A transformer-based model (BERT) was applied to chemical datasets, analyzing attention mechanisms to study functional groups. It then used graph convolution and attention models as well as BERT fine-tuning to address chemical property problems.", "result": "The learned molecular representations enabled solving problems such as toxicity, solubility, drug-likeness, and synthesis accessibility, while attention visualization identified key structural impacts.", "conclusion": "Attention visualization and data-driven molecular representations can serve as impactful tools for chemistry practitioners, assisting in analyzing and predicting chemical properties efficiently."}}
{"id": "2602.07889", "pdf": "https://arxiv.org/pdf/2602.07889", "abs": "https://arxiv.org/abs/2602.07889", "authors": ["Long Chen", "Yinkui Liu", "Shen Li", "Bo Tang", "Xuemin Hu"], "title": "Efficient Anti-exploration via VQVAE and Fuzzy Clustering in Offline Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Pseudo-count is an effective anti-exploration method in offline reinforcement learning (RL) by counting state-action pairs and imposing a large penalty on rare or unseen state-action pair data. Existing anti-exploration methods count continuous state-action pairs by discretizing these data, but often suffer from the issues of dimension disaster and information loss in the discretization process, leading to efficiency and performance reduction, and even failure of policy learning. In this paper, a novel anti-exploration method based on Vector Quantized Variational Autoencoder (VQVAE) and fuzzy clustering in offline RL is proposed. We first propose an efficient pseudo-count method based on the multi-codebook VQVAE to discretize state-action pairs, and design an offline RL anti-exploitation method based on the proposed pseudo-count method to handle the dimension disaster issue and improve the learning efficiency. In addition, a codebook update mechanism based on fuzzy C-means (FCM) clustering is developed to improve the use rate of vectors in codebooks, addressing the information loss issue in the discretization process. The proposed method is evaluated on the benchmark of Datasets for Deep Data-Driven Reinforcement Learning (D4RL), and experimental results show that the proposed method performs better and requires less computing cost in multiple complex tasks compared to state-of-the-art (SOTA) methods.", "AI": {"tldr": "The paper proposes a novel method using Vector Quantized Variational Autoencoder (VQVAE) and fuzzy clustering to improve offline reinforcement learning (RL) through an enhanced pseudo-count based anti-exploration approach.", "motivation": "Existing anti-exploration methods in offline RL suffer from dimension disaster and information loss during the state-action pair discretization process, reducing efficiency and causing policy learning failures.", "method": "The authors utilize multi-codebook VQVAE for pseudo-count-based discretization and fuzzy C-means clustering for codebook updates, addressing dimension and information loss issues.", "result": "Their approach outperforms state-of-the-art (SOTA) methods in tasks from the D4RL benchmark, showcasing improved performance and decreased computational cost.", "conclusion": "The proposed method enhances offline RL by simultaneously improving learning efficiency and addressing key challenges in discretization, demonstrating better results compared to existing techniques."}}
{"id": "2602.08020", "pdf": "https://arxiv.org/pdf/2602.08020", "abs": "https://arxiv.org/abs/2602.08020", "authors": ["Minghai Chen", "Mingyuan Liu", "Yuxiang Huan"], "title": "PhysDrape: Learning Explicit Forces and Collision Constraints for Physically Realistic Garment Draping", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning-based garment draping has emerged as a promising alternative to traditional Physics-Based Simulation (PBS), yet robust collision handling remains a critical bottleneck. Most existing methods enforce physical validity through soft penalties, creating an intrinsic trade-off between geometric feasibility and physical plausibility: penalizing collisions often distorts mesh structure, while preserving shape leads to interpenetration. To resolve this conflict, we present PhysDrape, a hybrid neural-physical solver for physically realistic garment draping driven by explicit forces and constraints. Unlike soft-constrained frameworks, PhysDrape integrates neural inference with explicit geometric solvers in a fully differentiable pipeline. Specifically, we propose a Physics-Informed Graph Neural Network conditioned on a physics-enriched graph -- encoding material parameters and body proximity -- to predict residual displacements. Crucially, we integrate a differentiable two-stage solver: first, a learnable Force Solver iteratively resolves unbalanced forces derived from the Saint Venant-Kirchhoff (StVK) model to ensure quasi-static equilibrium; second, a Differentiable Projection strictly enforces collision constraints against the body surface. This differentiable design guarantees physical validity through explicit constraints, while enabling end-to-end learning to optimize the network for physically consistent predictions. Extensive experiments demonstrate that PhysDrape achieves state-of-the-art performance, ensuring negligible interpenetration with significantly lower strain energy compared to existing baselines, achieving superior physical fidelity and robustness in real-time.", "AI": {"tldr": "A hybrid neural-physical framework (PhysDrape) is proposed for garment draping, resolving collisions and achieving physical realism more effectively than existing methods.", "motivation": "Current deep learning approaches for garment draping struggle with robust collision handling due to the conflict between geometric feasibility and physical plausibility.", "method": "PhysDrape integrates a Physics-Informed Graph Neural Network with a differentiable pipeline, using a learnable Force Solver and Differentiable Projection for physical validity and constraint enforcement.", "result": "PhysDrape ensures negligible interpenetration, lower strain energy, and improved physical fidelity compared to traditional baselines, while achieving real-time performance.", "conclusion": "PhysDrape provides a robust, efficient, and physically consistent solution for garment draping, addressing critical issues in existing methods and advancing the field."}}
{"id": "2512.22730", "pdf": "https://arxiv.org/pdf/2512.22730", "abs": "https://arxiv.org/abs/2512.22730", "authors": ["Youssef Megahed", "Robin Ducharme", "Inok Lee", "Inbal Willner", "Adrian D. C. Chan", "Mark Walker", "Steven Hawken"], "title": "Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "13 pages, 6 figures, 2 tables", "summary": "Cystic hygroma is a high-risk prenatal ultrasound finding that portends high rates of chromosomal abnormalities, structural malformations, and adverse pregnancy outcomes. Automated detection can increase reproducibility and support scalable early screening programs, but supervised deep learning methods are limited by small labelled datasets. This study assesses whether ultrasound-specific self-supervised pretraining can facilitate accurate, robust deep learning detection of cystic hygroma in first-trimester ultrasound images. We fine-tuned the Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE), pretrained on over 370,000 unlabelled ultrasound images, for binary classification of normal controls and cystic hygroma cases used in this study. Performance was evaluated on the same curated ultrasound dataset, preprocessing pipeline, and 4-fold cross-validation protocol as for the DenseNet-169 baseline, using accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (ROC-AUC). Model interpretability was analyzed qualitatively using Score-CAM visualizations. USF-MAE outperformed the DenseNet-169 baseline on all evaluation metrics. The proposed model yielded a mean accuracy of 0.96, sensitivity of 0.94, specificity of 0.98, and ROC-AUC of 0.98 compared to 0.93, 0.92, 0.94, and 0.94 for the DenseNet-169 baseline, respectively. Qualitative Score-CAM visualizations of model predictions demonstrated clinical relevance by highlighting expected regions in the fetal neck for both positive and negative cases. Paired statistical analysis using a Wilcoxon signed-rank test confirmed that performance improvements achieved by USF-MAE were statistically significant (p = 0.0057).", "AI": {"tldr": "This paper highlights the use of ultrasound-specific self-supervised pretraining for detecting cystic hygroma, demonstrating superior performance metrics compared to traditional deep learning models.", "motivation": "The motivation behind this study lies in addressing the challenge posed by small labelled datasets for deep learning methods in detecting cystic hygroma and improving early screening accuracy and scalability.", "method": "The authors used the USF-MAE model pretrained on over 370,000 unlabelled ultrasound images, fine-tuning it for binary classification of normal and cystic hygroma cases, and comparing its performance against the DenseNet-169 baseline using a curated dataset.", "result": "The USF-MAE model demonstrated superior performance, achieving high metrics such as 0.96 accuracy, 0.94 sensitivity, 0.98 specificity, and 0.98 ROC-AUC, significantly outperforming the DenseNet-169 baseline.", "conclusion": "Ultrasound-specific self-supervised learning models like USF-MAE offer a robust, accurate method for detecting prenatal anomalies such as cystic hygroma, with potential for scalable application in early screening programs."}}
{"id": "2602.07892", "pdf": "https://arxiv.org/pdf/2602.07892", "abs": "https://arxiv.org/abs/2602.07892", "authors": ["Guanglong Sun", "Siyuan Zhang", "Liyuan Wang", "Jun Zhu", "Hang Su", "Yi Zhong"], "title": "Safety Alignment as Continual Learning: Mitigating the Alignment Tax via Orthogonal Gradient Projection", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) often incur an alignment tax: safety post-training can reduce general utility (e.g., reasoning and coding). We argue that this tax primarily arises from continual-learning-style forgetting in sequential alignment, where distribution shift and conflicting objectives cause safety updates to overwrite pre-trained competencies. Accordingly, we cast safety alignment as a continual learning (CL) problem that must balance plasticity (acquiring safety constraints) and stability (preserving general abilities). We propose Orthogonal Gradient Projection for Safety Alignment (OGPSA), a lightweight method that mitigates interference by constraining each safety update to be orthogonal (in a first-order sense) to a learned subspace capturing general capabilities. Specifically, OGPSA estimates a low-rank capability subspace from gradients on a small reference set and projects the safety gradient onto its orthogonal complement before updating. This produces safety-directed updates that minimally perturb prior knowledge while retaining capacity for alignment. OGPSA is plug-and-play and integrates into standard post-training pipelines without large-scale replay, auxiliary objectives, or retraining. Across Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and sequential SFT$\\rightarrow$DPO settings, OGPSA consistently improves the safety--utility Pareto frontier over standard baselines. For instance, on Qwen2.5-7B-Instruct under SFT$\\rightarrow$DPO, OGPSA preserves strong safety while recovering general capability, improving SimpleQA from 0.53\\% to 3.03\\% and IFEval from 51.94\\% to 63.96\\%. Our source code is available at \\href{https://github.com/SunGL001/OGPSA}{OGPSA}", "AI": {"tldr": "Large Language Models (LLMs) face alignment tax, where safety alignment reduces general abilities. Orthogonal Gradient Projection for Safety Alignment (OGPSA) is proposed to mitigate this issue by using orthogonal gradients to maintain capabilities while aligning safety requirements.", "motivation": "To address the issue of alignment tax in LLMs, where safety adjustments compromise general utility.", "method": "OGPSA employs orthogonal projection methods to update safety constraints while preserving pre-trained capabilities, using light-weight continual learning.", "result": "OGPSA improves the safety-utility balance over baselines, significantly recovering general capabilities in tasks such as QA and instruction following.", "conclusion": "Safety alignment in LLMs can be achieved effectively without sacrificing core competencies, using OGPSA as a practical enhancement tool."}}
{"id": "2602.07422", "pdf": "https://arxiv.org/pdf/2602.07422", "abs": "https://arxiv.org/abs/2602.07422", "authors": ["Tianyi Wu", "Mingzhe Du", "Yue Liu", "Chengran Yang", "Terry Yue Zhuo", "Jiaheng Zhang", "See-Kiong Ng"], "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.", "AI": {"tldr": "SecCoderX proposes an online reinforcement learning framework to enhance secure and functional code generation in large language models, improving security while preserving utility.", "motivation": "The use of large language models (LLMs) in software development is limited by their proclivity to generate insecure code. Existing methods to tackle this often compromise utility for security.", "method": "SecCoderX leverages mature vulnerability detection resources to synthesize realistic vulnerability tasks and train a reasoning-based reward model. It integrates these in an online reinforcement learning loop to align LLMs for secure and functional code generation.", "result": "The framework improves the Effective Safety Rate (ESR) by approximately 10% over unaligned models, outperforming prior methods that often degrade performance.", "conclusion": "SecCoderX demonstrates that functionality-preserving secure code generation is feasible, offering state-of-the-art results while maintaining security and utility alignment, paving the way for real-world deployment of LLMs in software development."}}
{"id": "2602.08024", "pdf": "https://arxiv.org/pdf/2602.08024", "abs": "https://arxiv.org/abs/2602.08024", "authors": ["Ziyang Fan", "Keyu Chen", "Ruilong Xing", "Yulin Li", "Li Jiang", "Zhuotao Tian"], "title": "FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted by ICLR 2026 (Oral)", "summary": "Although Video Large Language Models (VLLMs) have shown remarkable capabilities in video understanding, they are required to process high volumes of visual tokens, causing significant computational inefficiency. Existing VLLMs acceleration frameworks usually compress spatial and temporal redundancy independently, which overlooks the spatiotemporal relationships, thereby leading to suboptimal spatiotemporal compression. The highly correlated visual features are likely to change in spatial position, scale, orientation, and other attributes over time due to the dynamic nature of video. Building on this insight, we introduce FlashVID, a training-free inference acceleration framework for VLLMs. Specifically, FlashVID utilizes Attention and Diversity-based Token Selection (ADTS) to select the most representative tokens for basic video representation, then applies Tree-based Spatiotemporal Token Merging (TSTM) for fine-grained spatiotemporal redundancy elimination. Extensive experiments conducted on three representative VLLMs across five video understanding benchmarks demonstrate the effectiveness and generalization of our method. Notably, by retaining only 10% of visual tokens, FlashVID preserves 99.1% of the performance of LLaVA-OneVision. Consequently, FlashVID can serve as a training-free and plug-and-play module for extending long video frames, which enables a 10x increase in video frame input to Qwen2.5-VL, resulting in a relative improvement of 8.6% within the same computational budget. Code is available at https://github.com/Fanziyang-v/FlashVID.", "AI": {"tldr": "The paper introduces FlashVID, a training-free framework to accelerate video large language models (VLLMs) by efficiently removing spatiotemporal redundancies, achieving high performance with reduced computational cost.", "motivation": "VLLMs face computational inefficiency due to the requirement of processing large visual token volumes, and current methods overlook spatiotemporal relationships when compressing redundancy.", "method": "FlashVID employs Attention and Diversity-based Token Selection (ADTS) to choose key tokens and utilizes Tree-based Spatiotemporal Token Merging (TSTM) to remove spatiotemporal redundancies effectively.", "result": "Extensive experiments show FlashVID retains 99.1% of the performance using only 10% of tokens and enables a 10x increase in video frame inputs with an 8.6% improvement in computational efficiency.", "conclusion": "FlashVID offers an effective, training-free, and plug-and-play solution for accelerating VLLMs, contributing to better video understanding while reducing computational cost."}}
{"id": "2602.07904", "pdf": "https://arxiv.org/pdf/2602.07904", "abs": "https://arxiv.org/abs/2602.07904", "authors": ["Giang Ngo", "Dat Phan Trong", "Dang Nguyen", "Sunil Gupta", "Svetha Venkatesh"], "title": "Adaptive Acquisition Selection for Bayesian Optimization with Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Bayesian Optimization critically depends on the choice of acquisition function, but no single strategy is universally optimal; the best choice is non-stationary and problem-dependent. Existing adaptive portfolio methods often base their decisions on past function values while ignoring richer information like remaining budget or surrogate model characteristics. To address this, we introduce LMABO, a novel framework that casts a pre-trained Large Language Model (LLM) as a zero-shot, online strategist for the BO process. At each iteration, LMABO uses a structured state representation to prompt the LLM to select the most suitable acquisition function from a diverse portfolio. In an evaluation across 50 benchmark problems, LMABO demonstrates a significant performance improvement over strong static, adaptive portfolio, and other LLM-based baselines. We show that the LLM's behavior is a comprehensive strategy that adapts to real-time progress, proving its advantage stems from its ability to process and synthesize the complete optimization state into an effective, adaptive policy.", "AI": {"tldr": "The paper introduces LMABO, utilizing a pre-trained LLM to dynamically select acquisition functions during Bayesian Optimization, achieving superior performance across benchmarks.", "motivation": "Bayesian Optimization struggles with non-stationary and problem-dependent acquisition function choices, and existing methods fail to utilize rich context such as remaining budget or model characteristics.", "method": "The authors propose LMABO, a framework that uses a pre-trained LLM as a zero-shot strategist to adaptively select acquisition functions based on a structured state representation of the optimization process.", "result": "LMABO outperformed static, adaptive portfolio, and other LLM-based baselines in benchmarking across 50 problems, showing adaptive and context-aware decisions.", "conclusion": "Leveraging the LLM's ability to synthesize the entire optimization state, LMABO effectively adapts acquisition function selections, offering a substantial improvement in Bayesian Optimization performance."}}
{"id": "2602.08025", "pdf": "https://arxiv.org/pdf/2602.08025", "abs": "https://arxiv.org/abs/2602.08025", "authors": ["Yixuan Ye", "Xuanyu Lu", "Yuxin Jiang", "Yuchao Gu", "Rui Zhao", "Qiwei Liang", "Jiachun Pan", "Fengda Zhang", "Weijia Wu", "Alex Jinpeng Wang"], "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "World models aim to understand, remember, and predict dynamic visual environments, yet a unified benchmark for evaluating their fundamental abilities remains lacking. To address this gap, we introduce MIND, the first open-domain closed-loop revisited benchmark for evaluating Memory consIstency and action coNtrol in worlD models. MIND contains 250 high-quality videos at 1080p and 24 FPS, including 100 (first-person) + 100 (third-person) video clips under a shared action space and 25 + 25 clips across varied action spaces covering eight diverse scenes. We design an efficient evaluation framework to measure two core abilities: memory consistency and action control, capturing temporal stability and contextual coherence across viewpoints. Furthermore, we design various action spaces, including different character movement speeds and camera rotation angles, to evaluate the action generalization capability across different action spaces under shared scenes. To facilitate future performance benchmarking on MIND, we introduce MIND-World, a novel interactive Video-to-World baseline. Extensive experiments demonstrate the completeness of MIND and reveal key challenges in current world models, including the difficulty of maintaining long-term memory consistency and generalizing across action spaces. Project page: https://csu-jpg.github.io/MIND.github.io/", "AI": {"tldr": "MIND introduces a benchmark for evaluating memory consistency and action control in world models with high-quality video datasets and an efficient evaluation framework.", "motivation": "World models need robust evaluation metrics to test their abilities to understand, remember, and predict dynamic environments. Existing benchmarks are lacking in this respect.", "method": "MIND provides 250 video clips across diverse environments and action spaces, a framework to measure memory consistency and action control, and action generalization capabilities.", "result": "Experiments reveal challenges in world models, such as maintaining memory consistency and generalizing across action spaces.", "conclusion": "MIND establishes a robust benchmark for testing and improving world models, highlighting areas for further development and innovation."}}
{"id": "2602.07906", "pdf": "https://arxiv.org/pdf/2602.07906", "abs": "https://arxiv.org/abs/2602.07906", "authors": ["Yuzhu Cai", "Zexi Liu", "Xinyu Zhu", "Cheng Wang", "Jiaao Chen", "Hanrui Wang", "Wei-Chen Wang", "Di Jin", "Siheng Chen"], "title": "AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 5 figures", "summary": "Autonomous Machine Learning Engineering (MLE) requires agents to perform sustained, iterative optimization over long horizons. While recent LLM-based agents show promise, current prompt-based agents for MLE suffer from behavioral stagnation due to frozen parameters. Although Reinforcement Learning (RL) offers a remedy, applying it to MLE is hindered by prohibitive execution latency and inefficient data selection. Recognizing these challenges, we propose AceGRPO with two core components: (1) Evolving Data Buffer that continuously repurposes execution traces into reusable training tasks, and (2) Adaptive Sampling guided by a Learnability Potential function, which dynamically prioritizes tasks at the agent's learning frontier to maximize learning efficiency. Leveraging AceGRPO, our trained Ace-30B model achieves a 100% valid submission rate on MLE-Bench-Lite, approaches the performance of proprietary frontier models, and outperforms larger open-source baselines (e.g., DeepSeek-V3.2), demonstrating robust capability for sustained iterative optimization. Code is available at https://github.com/yuzhu-cai/AceGRPO.", "AI": {"tldr": "AceGRPO introduces methods to tackle challenges in machine learning engineering with autonomous agents, involving iterative optimization.", "motivation": "Current prompt-based agents for machine learning engineering suffer from stagnation, and RL solutions are hindered by latency and inefficiencies.", "method": "AceGRPO uses an Evolving Data Buffer for task repurposing and Adaptive Sampling for prioritization, enhancing learning efficiency.", "result": "The Ace-30B model achieves 100% valid submissions on MLE-Bench-Lite and outperforms other open-source models while closing gaps with proprietary models.", "conclusion": "AceGRPO demonstrates significant advancements and capabilities for sustained and efficient iterative optimization in autonomous machine learning engineering."}}
{"id": "2602.08046", "pdf": "https://arxiv.org/pdf/2602.08046", "abs": "https://arxiv.org/abs/2602.08046", "authors": ["Yahia Hamdi", "Nicolas Andrialovanirina", "K\u00e9lig Mah\u00e9", "Emilie Poisson Caillault"], "title": "Enhanced Mixture 3D CGAN for Completion and Generation of 3D Objects", "categories": ["cs.CV"], "comment": "11", "summary": "The generation and completion of 3D objects represent a transformative challenge in computer vision. Generative Adversarial Networks (GANs) have recently demonstrated strong potential in synthesizing realistic visual data. However, they often struggle to capture complex and diverse data distributions, particularly in scenarios involving incomplete inputs or significant missing regions. These challenges arise mainly from the high computational requirements and the difficulty of modeling heterogeneous and structurally intricate data, which restrict their applicability in real-world settings. Mixture of Experts (MoE) models have emerged as a promising solution to these limitations. By dynamically selecting and activating the most relevant expert sub-networks for a given input, MoEs improve both performance and efficiency. In this paper, we investigate the integration of Deep 3D Convolutional GANs (CGANs) with a MoE framework to generate high-quality 3D models and reconstruct incomplete or damaged objects. The proposed architecture incorporates multiple generators, each specialized to capture distinct modalities within the dataset. Furthermore, an auxiliary loss-free dynamic capacity constraint (DCC) mechanism is introduced to guide the selection of categorical generators, ensuring a balance between specialization, training stability, and computational efficiency, which is critical for 3D voxel processing. We evaluated the model's ability to generate and complete shapes with missing regions of varying sizes and compared its performance with state-of-the-art approaches. Both quantitative and qualitative results confirm the effectiveness of the proposed MoE-DCGAN in handling complex 3D data.", "AI": {"tldr": "This paper introduces a novel framework combining Deep 3D Convolutional GANs and Mixture of Experts to improve 3D object generation and reconstruction.", "motivation": "To address the challenges of GANs, particularly their struggles with diverse and complex data distributions in 3D object synthesis.", "method": "The paper employs Mixture of Experts with multiple specialized generators, along with a dynamic capacity constraint mechanism for better specialization, training stability, and computational efficiency.", "result": "The proposed MoE-DCGAN model successfully generates and reconstructs incomplete 3D shapes, outperforming state-of-the-art techniques in quantitative and qualitative evaluations.", "conclusion": "Integrating MoE with Deep 3D CGANs offers an effective solution for handling complex and incomplete 3D data, providing advancements in this transformative computer vision challenge."}}
{"id": "2602.08047", "pdf": "https://arxiv.org/pdf/2602.08047", "abs": "https://arxiv.org/abs/2602.08047", "authors": ["Jiahong Fu", "Qi Xie", "Deyu Meng", "Zongben Xu"], "title": "Vanilla Group Equivariant Vision Transformer: Simple and Effective", "categories": ["cs.CV"], "comment": null, "summary": "Incorporating symmetry priors as inductive biases to design equivariant Vision Transformers (ViTs) has emerged as a promising avenue for enhancing their performance. However, existing equivariant ViTs often struggle to balance performance with equivariance, primarily due to the challenge of achieving holistic equivariant modifications across the diverse modules in ViTs-particularly in harmonizing the Self-Attention mechanism with Patch Embedding. To address this, we propose a straightforward framework that systematically renders key ViT components, including patch embedding, self-attention, positional encodings, and Down/Up-Sampling, equivariant, thereby constructing ViTs with guaranteed equivariance. The resulting architecture serves as a plug-and-play replacement that is both theoretically grounded and practically versatile, scaling seamlessly even to Swin Transformers. Extensive experiments demonstrate that our equivariant ViTs consistently improve performance and data efficiency across a wide spectrum of vision tasks.", "AI": {"tldr": "The paper proposes a framework to build equivariant Vision Transformers (ViTs), systematically modifying components for better symmetry-driven performance.", "motivation": "Enhancing the performance of Vision Transformers (ViTs) by integrating symmetry priors while overcoming the challenge of achieving holistic equivariant modifications across various ViT components.", "method": "The framework introduces systematic equivariance in patches embedding, self-attention, positional encodings, and Down/Up-Sampling, enabling the construction of theoretically grounded, scalable ViTs.", "result": "Equivariant ViTs improve performance and data efficiency across various vision tasks, with applicability extending to models like Swin Transformers.", "conclusion": "The proposed approach balances performance and equivariance in ViTs, offering a versatile, scalable, and validated alternative to existing models."}}
{"id": "2602.07928", "pdf": "https://arxiv.org/pdf/2602.07928", "abs": "https://arxiv.org/abs/2602.07928", "authors": ["Ziyun Li", "Huancheng Hu", "Soon Hoe Lim", "Xuyu Li", "Fei Gao", "Enmao Diao", "Zezhen Ding", "Michalis Vazirgiannis", "Henrik Bostrom"], "title": "A Kinetic-Energy Perspective of Flow Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Flow-based generative models can be viewed through a physics lens: sampling transports a particle from noise to data by integrating a time-varying velocity field, and each sample corresponds to a trajectory with its own dynamical effort. Motivated by classical mechanics, we introduce Kinetic Path Energy (KPE), an action-like, per-sample diagnostic that measures the accumulated kinetic effort along an Ordinary Differential Equation (ODE) trajectory. Empirically, KPE exhibits two robust correspondences: (i) higher KPE predicts stronger semantic fidelity; (ii) high-KPE trajectories terminate on low-density manifold frontiers. We further provide theoretical guarantees linking trajectory energy to data density. Paradoxically, this correlation is non-monotonic. At sufficiently high energy, generation can degenerate into memorization. Leveraging the closed-form of empirical flow matching, we show that extreme energies drive trajectories toward near-copies of training examples. This yields a Goldilocks principle and motivates Kinetic Trajectory Shaping (KTS), a training-free two-phase inference strategy that boosts early motion and enforces a late-time soft landing, reducing memorization and improving generation quality across benchmark tasks.", "AI": {"tldr": "The paper introduces Kinetic Path Energy (KPE) to evaluate trajectories in flow-based generative models, proposes the Goldilocks principle for trajectory energy, and offers Kinetic Trajectory Shaping (KTS) as a method to improve quality.", "motivation": "To understand and improve sampling trajectories in flow-based generative models, addressing issues like memorization and poor generation quality.", "method": "The authors introduce KPE to measure kinetic effort of these trajectories, establish connections between KPE, data density, and quality, and propose KTS as a training-free strategy to refine trajectory dynamics.", "result": "The results show that KPE correlates with semantic fidelity and data density, albeit non-monotonically. The proposed KTS approach reduces memorization and enhances generation quality on benchmarks.", "conclusion": "High-energy trajectory optimization through KTS demonstrates promise in balancing memorization and quality, adhering to a Goldilocks principle for improved generative tasks."}}
{"id": "2602.07517", "pdf": "https://arxiv.org/pdf/2602.07517", "abs": "https://arxiv.org/abs/2602.07517", "authors": ["Yuhao Wang", "Shengfang Zhai", "Guanghao Jin", "Yinpeng Dong", "Linyi Yang", "Jiaheng Zhang"], "title": "MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.DB"], "comment": null, "summary": "Large Language Model (LLM)-based agents employ external and internal memory systems to handle complex, goal-oriented tasks, yet this exposes them to severe extraction attacks, and effective defenses remain lacking. In this paper, we propose MemPot, the first theoretically verified defense framework against memory extraction attacks by injecting optimized honeypots into the memory. Through a two-stage optimization process, MemPot generates trap documents that maximize the retrieval probability for attackers while remaining inconspicuous to benign users. We model the detection process as Wald's Sequential Probability Ratio Test (SPRT) and theoretically prove that MemPot achieves a lower average number of sampling rounds compared to optimal static detectors. Empirically, MemPot significantly outperforms state-of-the-art baselines, achieving a 50% improvement in detection AUROC and an 80% increase in True Positive Rate under low False Positive Rate constraints. Furthermore, our experiments confirm that MemPot incurs zero additional online inference latency and preserves the agent's utility on standard tasks, verifying its superiority in safety, harmlessness, and efficiency.", "AI": {"tldr": "MemPot introduces a defense framework against memory extraction attacks by embedding optimized honeypots in memory.", "motivation": "Large Language Model (LLM)-based agents face vulnerability to severe memory extraction attacks, requiring effective defense mechanisms.", "method": "MemPot employs a two-stage optimization process to design honeypots that attract attackers while remaining undetectable to benign users, utilizing Wald's Sequential Probability Ratio Test (SPRT) for theoretical analysis.", "result": "MemPot demonstrates a 50% improvement in detection AUROC and an 80% increase in True Positive Rate under strict False Positive Rate constraints, with no added inference latency or utility compromise.", "conclusion": "MemPot is effective in safeguarding LLM-based agents by introducing optimized detection capabilities, balancing security, usability, and efficiency."}}
{"id": "2602.08057", "pdf": "https://arxiv.org/pdf/2602.08057", "abs": "https://arxiv.org/abs/2602.08057", "authors": ["Yufei Wang", "Haixu Liu", "Tianxiang Xu", "Chuancheng Shi", "Hongsheng Xing"], "title": "Weak to Strong: VLM-Based Pseudo-Labeling as a Weakly Supervised Training Strategy in Multimodal Video-based Hidden Emotion Understanding Tasks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "To tackle the automatic recognition of \"concealed emotions\" in videos, this paper proposes a multimodal weak-supervision framework and achieves state-of-the-art results on the iMiGUE tennis-interview dataset. First, YOLO 11x detects and crops human portraits frame-by-frame, and DINOv2-Base extracts visual features from the cropped regions. Next, by integrating Chain-of-Thought and Reflection prompting (CoT + Reflection), Gemini 2.5 Pro automatically generates pseudo-labels and reasoning texts that serve as weak supervision for downstream models. Subsequently, OpenPose produces 137-dimensional key-point sequences, augmented with inter-frame offset features; the usual graph neural network backbone is simplified to an MLP to efficiently model the spatiotemporal relationships of the three key-point streams. An ultra-long-sequence Transformer independently encodes both the image and key-point sequences, and their representations are concatenated with BERT-encoded interview transcripts. Each modality is first pre-trained in isolation, then fine-tuned jointly, with pseudo-labeled samples merged into the training set for further gains. Experiments demonstrate that, despite severe class imbalance, the proposed approach lifts accuracy from under 0.6 in prior work to over 0.69, establishing a new public benchmark. The study also validates that an \"MLP-ified\" key-point backbone can match - or even surpass - GCN-based counterparts in this task.", "AI": {"tldr": "This paper presents a multimodal weak-supervision method for recognizing concealed emotions in videos, achieving state-of-the-art results on a tennis-interview dataset.", "motivation": "The paper aims to improve the automatic recognition of concealed emotions in videos, addressing class imbalance and advancing benchmarks using novel techniques.", "method": "The approach includes human detection using YOLO, visual feature extraction via DINOv2, pseudo-label generation using Gemini 2.5 Pro with CoT and Reflection prompting, simplified MLP models for spatiotemporal relationships, ultra-long-sequence Transformer encoding, and multi-modal pre-training and fine-tuning. Pseudo-labeled data enhances the training set.", "result": "The proposed method achieves a significant improvement in accuracy, reaching over 0.69, surpassing previous benchmarks on the iMiGUE dataset. The simplified key-point backbone (MLP) performs as well as, or better than, GCN-based models.", "conclusion": "The multimodal framework proves effective for concealed emotion recognition, showcasing the potential of simplified models and pseudo-labeling for enhancing performance in imbalanced class settings."}}
{"id": "2602.06981", "pdf": "https://arxiv.org/pdf/2602.06981", "abs": "https://arxiv.org/abs/2602.06981", "authors": ["Ankolika De", "Gabriel Lima", "Yixin Zou"], "title": "What is Safety? Corporate Discourse, Power, and the Politics of Generative AI Safety", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "18 pages, 2 tables", "summary": "This work examines how leading generative artificial intelligence companies construct and communicate the concept of \"safety\" through public-facing documents. Drawing on critical discourse analysis, we analyze a corpus of corporate safety-related statements to explicate how authority, responsibility, and legitimacy are discursively established. These discursive strategies consolidate legitimacy for corporate actors, normalize safety as an experimental and anticipatory practice, and push a perceived participatory agenda toward safe technologies. We argue that uncritical uptake of these discourses risks reproducing corporate priorities and constraining alternative approaches to governance and design. The contribution of this work is twofold: first, to situate safety as a sociotechnical discourse that warrants critical examination; second, to caution human-computer interaction scholars against legitimizing corporate framings, instead foregrounding accountability, equity, and justice. By interrogating safety discourses as artifacts of power, this paper advances a critical agenda for human-computer interaction scholarship on artificial intelligence.", "AI": {"tldr": "The paper critically examines how generative AI companies define and communicate 'safety' in public documents, highlighting concerns about power, normalization, and legitimacy of corporate priorities.", "motivation": "To critically evaluate the way AI corporations construct discourses on safety, situating it as a matter of power dynamics and its impact on governance and design practices.", "method": "Critical discourse analysis of corporate safety-related statements from leading generative AI companies.", "result": "Finds that corporate discourses solidify legitimacy for companies, normalize safety as experimental/anticipatory, and promote agendas that align with corporate priorities while potentially sidelining alternative governance approaches.", "conclusion": "Calls for a critical perspective on 'safety' discourses in AI, advocating for a focus on accountability, equity, and justice over uncritically adopting corporate framings, to shape human-computer interaction scholarship."}}
{"id": "2602.07933", "pdf": "https://arxiv.org/pdf/2602.07933", "abs": "https://arxiv.org/abs/2602.07933", "authors": ["Olamide Samuel Oseni", "Ibraheem Omotolani Obanla", "Toheeb Aduramomi Jimoh"], "title": "Attention-Based Deep Learning for Early Parkinson's Disease Detection with Tabular Biomedical Data", "categories": ["cs.LG"], "comment": null, "summary": "Early and accurate detection of Parkinson's disease (PD) remains a critical challenge in medical diagnostics due to the subtlety of early-stage symptoms and the complex, non-linear relationships inherent in biomedical data. Traditional machine learning (ML) models, though widely applied to PD detection, often rely on extensive feature engineering and struggle to capture complex feature interactions. This study investigates the effectiveness of attention-based deep learning models for early PD detection using tabular biomedical data. We present a comparative evaluation of four classification models: Multi-Layer Perceptron (MLP), Gradient Boosting, TabNet, and SAINT, using a benchmark dataset from the UCI Machine Learning Repository consisting of biomedical voice measurements from PD patients and healthy controls.\n  Experimental results show that SAINT consistently outperformed all baseline models across multiple evaluation metrics, achieving a weighted precision of 0.98, weighted recall of 0.97, weighted F1-score of 0.97, a Matthews Correlation Coefficient (MCC) of 0.9990, and the highest Area Under the ROC Curve (AUC-ROC). TabNet and MLP demonstrated competitive performance, while Gradient Boosting yielded the lowest overall scores. The superior performance of SAINT is attributed to its dual attention mechanism, which effectively models feature interactions within and across samples.\n  These findings demonstrate the diagnostic potential of attention-based deep learning architectures for early Parkinson's disease detection and highlight the importance of dynamic feature representation in clinical prediction tasks.", "AI": {"tldr": "The study explores attention-based deep learning models for early Parkinson's disease detection with SAINT showcasing exceptional performance. Traditional ML models were less effective in capturing complex biomedical data interactions.", "motivation": "Parkinson's disease is challenging to diagnose early due to subtle symptoms and intricate biomedical data relationships. There's a need for efficient methods beyond traditional ML models to improve diagnostic accuracy.", "method": "The paper evaluates four models\u2014MLP, Gradient Boosting, TabNet, and SAINT\u2014using a dataset of biomedical voice measurements from PD patients and healthy individuals.", "result": "SAINT outperformed other models, achieving superior precision (0.98), recall (0.97), F1-score (0.97), MCC (0.9990), and AUC-ROC. This success is linked to SAINT's dual attention mechanism effectively handling feature interactions.", "conclusion": "The study demonstrates that attention-based deep learning architectures, such as SAINT, hold significant promise for early Parkinson's disease detection by modeling complex features dynamically."}}
{"id": "2602.06982", "pdf": "https://arxiv.org/pdf/2602.06982", "abs": "https://arxiv.org/abs/2602.06982", "authors": ["Pujitha Mamillapalli", "Shikhar Verma", "Tiago Koketsu Rodrigues", "Abhinav Kumar"], "title": "Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG"], "comment": null, "summary": "Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \\(11.3\\%\\) throughput improvement for a \\(4\\times4\\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.", "AI": {"tldr": "The paper presents a reconfigurable intelligent surface (RIS)-aided framework with a DDPG algorithm for beamforming in 6G SAGINs to efficiently mitigate interference and improve spectral efficiency.", "motivation": "To address the severe cross-tier interference arising from spectrum sharing between terrestrial and non-terrestrial segments in 6G SAGINs, particularly the interference caused by the HAPS antenna back-lobe during frequency sharing.", "method": "A DDPG-based optimization framework is used in conjunction with RIS for efficient HAPS beamforming to form spatial nulls toward interference sources and maintain robust signal connections in SAGINs.", "result": "The proposed framework outperformed conventional ZF beamforming, achieving up to 11.3% throughput improvement with a 4x4 RIS configuration, proving its efficiency in dynamic spectrum sharing scenarios.", "conclusion": "The RIS-aided DDPG framework effectively enhances spectral efficiency and mitigates interference in HAPS-based SAGINs, showing promise for future 6G implementations."}}
{"id": "2602.07950", "pdf": "https://arxiv.org/pdf/2602.07950", "abs": "https://arxiv.org/abs/2602.07950", "authors": ["Daisuke Okanohara"], "title": "A Thermodynamic Theory of Learning Part II: Critical Period Closure and Continual Learning Failure", "categories": ["cs.LG"], "comment": "Part II of a series entitled \"A Thermodynamic Theory of Learning.\"", "summary": "Learning performed over finite time is necessarily irreversible. In Part~I of this series, we modeled learning as a transport process in the space of parameter distributions and derived the Epistemic Speed Limit, which lower-bounds entropy production under finite-time learning.\n  In this work (Part~II), we study the consequences of this irreversibility for continual learning from a trajectory-level perspective. We show that finite dissipation constrains not only which solutions are reachable, but which learning paths remain dynamically accessible.\n  Although a continuum of task-equivalent realizations can achieve identical task performance, finite-time learning irreversibly selects among these realizations. This selection occurs through the progressive elimination of degrees of freedom that would otherwise enable structural reconfiguration. We refer to this phenomenon as \\emph{critical period closure}: beyond a certain stage of learning, transitions between compatible representations become dynamically inaccessible under any finite dissipation budget.\n  As a result, continual learning failure arises not from the absence of solutions satisfying multiple tasks, but from an irreversible loss of representational freedom induced by prior learning. This reframes catastrophic forgetting as a dynamical constraint imposed by finite-time dissipation, rather than direct task interference.", "AI": {"tldr": "Learning over finite time is irreversible, constraining the learning paths and selectable solutions.", "motivation": "The paper investigates the implications of the irreversible nature of finite-time learning on continual learning.", "method": "Analyzes trajectory-level perspectives to understand constraints imposed by finite-time dissipation.", "result": "Introduces the concept of 'critical period closure' and links continual learning failure to loss of representational freedom rather than task interference.", "conclusion": "Continual learning failure is due to dynamical constraints imposed by finite-time dissipation."}}
{"id": "2602.08059", "pdf": "https://arxiv.org/pdf/2602.08059", "abs": "https://arxiv.org/abs/2602.08059", "authors": ["Tong Zhang", "Ru Zhang", "Jianyi Liu"], "title": "DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The recent proliferation of diffusion models has made style mimicry effortless, enabling users to imitate unique artistic styles without authorization. In deployed platforms, this raises copyright and intellectual-property risks and calls for reliable protection. However, existing countermeasures either require costly weight editing as new styles emerge or rely on an explicitly specified editing style, limiting their practicality for deployment-side safety. To address this challenge, we propose DICE (Disentanglement of artist Style from Content via Contrastive Subspace Decomposition), a training-free framework for on-the-fly artist style erasure. Unlike style editing that require an explicitly specified replacement style, DICE performs style purification, removing the artist's characteristics while preserving the user-intended content. Our core insight is that a model cannot truly comprehend the artist style from a single text or image alone. Consequently, we abandon the traditional paradigm of identifying style from isolated samples. Instead, we construct contrastive triplets to compel the model to distinguish between style and non-style features in the latent space. By formalizing this disentanglement process as a solvable generalized eigenvalue problem, we achieve precise identification of the style subspace. Furthermore, we introduce an Adaptive Attention Decoupling Editing strategy dynamically assesses the style concentration of each token and performs differential suppression and content enhancement on the QKV vectors. Extensive experiments demonstrate that DICE achieves a superior balance between the thoroughness of style erasure and the preservation of content integrity. DICE introduces an additional overhead of only 3 seconds to disentangle style, providing a practical and efficient technique for curbing style mimicry.", "AI": {"tldr": "The paper introduces DICE, a new method that allows for the removal of artistic styles from content without training or costly editing, to address copyright concerns.", "motivation": "The paper addresses copyright and intellectual property risks arising from style mimicry made easy by diffusion models, and the challenges of deploying practical solutions.", "method": "DICE uses a training-free approach, utilizing contrastive subspace decomposition and adaptive attention to remove artistic style while keeping original content intact.", "result": "Extensive experiments show DICE effectively erases styles while maintaining content integrity, adding only 3 seconds of overhead for the process.", "conclusion": "DICE presents a practical and efficient solution to mitigate unauthorized style mimicry with reliable style erasure without costly or impractical methods."}}
{"id": "2602.06983", "pdf": "https://arxiv.org/pdf/2602.06983", "abs": "https://arxiv.org/abs/2602.06983", "authors": ["Alison M. Fernandes", "Hermes I. Del Monego", "Bruno S. Chang", "Anelise Munaretto", "H\u00e9lder M. Fontes", "Rui Campos"], "title": "Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "6 pages, 6 figures", "summary": "This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture, which integrates Inception networks responsible for hierarchical spatial feature extraction and Bidirectional Long Short-Term Memory (BiLSTM) networks that capture temporal dependencies. A Support Vector Machine (SVM) is then utilized as the final classification layer to optimize decision boundaries. The framework's efficacy was systematically validated using a public dataset across 20, 40, and 80 MHz bandwidth configurations. The model yielded accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), respectively. These results confirm a marked superiority over standalone deep learning baselines, especially in the most constrained low-bandwidth scenarios. This study underscores the utility of combining Doppler-based feature engineering with a hybrid learning architecture for reliable HAR in bandwidth-limited wireless sensing applications.", "AI": {"tldr": "The paper proposes a hybrid deep learning framework for robust Human Activity Recognition (HAR) under bandwidth constraints using Wi-Fi, achieving higher accuracy than standalone methods.", "motivation": "To address the challenge of robust HAR performance in bandwidth-constrained Wi-Fi sensing environments.", "method": "The framework uses Doppler trace extraction for signal enhancement, followed by a hybrid deep learning model combining Inception networks, BiLSTM for feature extraction, and SVM for classification.", "result": "The model demonstrated accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), outperforming standalone frameworks in constrained scenarios.", "conclusion": "Combining Doppler-based feature engineering with hybrid neural architectures is effective for improving HAR reliability in low-bandwidth wireless environments."}}
{"id": "2602.07966", "pdf": "https://arxiv.org/pdf/2602.07966", "abs": "https://arxiv.org/abs/2602.07966", "authors": ["Pablo Hidalgo", "Daniel Rodriguez"], "title": "An Explainable Multi-Task Similarity Measure: Integrating Accumulated Local Effects and Weighted Fr\u00e9chet Distance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intelligence (XAI) techniques, specifically Accumulated Local Effects (ALE) curves.\n  ALE curves are compared using the Fr\u00e9chet distance, weighted by the data distribution, and the resulting similarity measure incorporates the importance of each feature. The measure is applicable in both single-task learning scenarios, where each task is trained separately, and multi-task learning scenarios, where all tasks are learned simultaneously. The measure is model-agnostic, allowing the use of different machine learning models across tasks. A scaling factor is introduced to account for differences in predictive performance across tasks, and several recommendations are provided for applying the measure in complex scenarios.\n  We validate this measure using four datasets, one synthetic dataset and three real-world datasets. The real-world datasets include a well-known Parkinson's dataset and a bike-sharing usage dataset -- both structured in tabular format -- as well as the CelebA dataset, which is used to evaluate the application of concept bottleneck encoders in a multitask learning setting. The results demonstrate that the measure aligns with intuitive expectations of task similarity across both tabular and non-tabular data, making it a valuable tool for exploring relationships between tasks and supporting informed decision-making.", "AI": {"tldr": "The paper introduces a model-agnostic similarity measure for tasks in Multi-Task Learning (MTL) using Explainable AI techniques, validated on varied datasets.", "motivation": "Understanding task similarity in MTL is vital for optimizing knowledge transfer between tasks, improving learning processes.", "method": "The proposed method calculates multi-task similarity using ALE curves compared with Fr\u00e9chet distance, while factoring in predictive performance with a scaling factor.", "result": "Results on synthetic and real-world datasets, including CelebA and Parkinson\u2019s datasets, confirm alignment with intuitive expectations of task similarity.", "conclusion": "The measure is effective and versatile across diverse data types and helps evaluate relationships between tasks, aiding multi-task learning strategies."}}
{"id": "2602.08068", "pdf": "https://arxiv.org/pdf/2602.08068", "abs": "https://arxiv.org/abs/2602.08068", "authors": ["Chunyang Li", "Yuanbo Yang", "Jiahao Shao", "Hongyu Zhou", "Katja Schwarz", "Yiyi Liao"], "title": "ReRoPE: Repurposing RoPE for Relative Camera Control", "categories": ["cs.CV"], "comment": null, "summary": "Video generation with controllable camera viewpoints is essential for applications such as interactive content creation, gaming, and simulation. Existing methods typically adapt pre-trained video models using camera poses relative to a fixed reference, e.g., the first frame. However, these encodings lack shift-invariance, often leading to poor generalization and accumulated drift. While relative camera pose embeddings defined between arbitrary view pairs offer a more robust alternative, integrating them into pre-trained video diffusion models without prohibitive training costs or architectural changes remains challenging. We introduce ReRoPE, a plug-and-play framework that incorporates relative camera information into pre-trained video diffusion models without compromising their generation capability. Our approach is based on the insight that Rotary Positional Embeddings (RoPE) in existing models underutilize their full spectral bandwidth, particularly in the low-frequency components. By seamlessly injecting relative camera pose information into these underutilized bands, ReRoPE achieves precise control while preserving strong pre-trained generative priors. We evaluate our method on both image-to-video (I2V) and video-to-video (V2V) tasks in terms of camera control accuracy and visual fidelity. Our results demonstrate that ReRoPE offers a training-efficient path toward controllable, high-fidelity video generation. See project page for more results: https://sisyphe-lee.github.io/ReRoPE/", "AI": {"tldr": "ReRoPE enhances video generation models by adding relative camera viewpoints information, ensuring better control and fidelity without costly retraining or architectural changes.", "motivation": "The paper aims to address issues of poor generalization and drift in video generation models caused by traditional camera pose encodings that lack shift-invariance.", "method": "The authors propose ReRoPE, a framework that utilizes the unused spectral bandwidth in Rotary Positional Embeddings to incorporate relative camera pose information into pre-trained video diffusion models.", "result": "ReRoPE improves camera control accuracy and visual fidelity in video generation tasks (I2V and V2V), achieving results efficiently without sacrificing generative capabilities.", "conclusion": "The approach overcomes key challenges in integrating camera viewpoint control into pre-trained models, offering a path for more interactive and precise video creation applications."}}
{"id": "2602.06984", "pdf": "https://arxiv.org/pdf/2602.06984", "abs": "https://arxiv.org/abs/2602.06984", "authors": ["Lin Luo", "Satwik Ghanta", "Yuri Nakao", "Mathieu Chollet", "Simone Stumpf"], "title": "Empowering Affected Individuals to Shape AI Fairness Assessments: Processes, Criteria, and Tools", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "AI systems are increasingly used in high-stakes domains such as credit rating, where fairness concerns are critical. Existing fairness assessments are typically conducted by AI experts or regulators using predefined protected attributes and metrics, which often fail to capture the diversity and nuance of fairness notions held by the individuals who are affected by these systems' decisions, such as decision subjects. Recent work has therefore called for involving affected individuals in fairness assessment, yet little empirical evidence exists on how they create their own fairness criteria or what kinds of criteria they produce - knowledge that could not only inform experts' fairness evaluation and mitigation, but also guide the design of AI assessment tools. We address this gap through a qualitative user study with 18 participants in a credit rating scenario. Participants first articulated their fairness notions in their own words. Then, participants turned them into concrete quantified and operationalized fairness criteria, through an interactive prototype we designed. Our findings provide empirical evidence of the process through which people's fairness notions emerge via grounding in model features, and uncover a diverse set of individuals' custom-defined criteria for both outcome and procedural fairness. We provide design implications for processes and tools that support more inclusive and value-sensitive AI fairness assessment.", "AI": {"tldr": "This paper explores how individuals articulate and define fairness criteria in AI systems through a qualitative study in a credit rating context, offering insights into diverse fairness concepts and implications for inclusive assessment tools.", "motivation": "To address the gap in understanding how affected individuals create their own fairness criteria, as current fairness assessments often ignore the diversity of fairness perceptions, leading to less inclusive AI evaluations.", "method": "A qualitative user study with 18 participants in a credit rating scenario, where participants defined their fairness notions and operationalized them using an interactive prototype tool.", "result": "The study uncovered a variety of custom-defined fairness criteria for both outcome and procedural fairness derived from individuals' perspectives, offering insights into how fairness notions can emerge via model features.", "conclusion": "The findings emphasize the importance of involving affected individuals in evaluating AI fairness and provide design recommendations for creating tools and processes that support inclusive, value-sensitive fairness assessments."}}
{"id": "2602.07973", "pdf": "https://arxiv.org/pdf/2602.07973", "abs": "https://arxiv.org/abs/2602.07973", "authors": ["Aaditya Naik", "Efthymia Tsamoura", "Shibo Jin", "Mayur Naik", "Dan Roth"], "title": "On Improving Neurosymbolic Learning by Exploiting the Representation Space", "categories": ["cs.LG"], "comment": null, "summary": "We study the problem of learning neural classifiers in a neurosymbolic setting where the hidden gold labels of input instances must satisfy a logical formula. Learning in this setting proceeds by first computing (a subset of) the possible combinations of labels that satisfy the formula and then computing a loss using those combinations and the classifiers' scores. One challenge is that the space of label combinations can grow exponentially, making learning difficult. We propose a technique that prunes this space by exploiting the intuition that instances with similar latent representations are likely to share the same label. While this intuition has been widely used in weakly supervised learning, its application in our setting is challenging due to label dependencies imposed by logical constraints. We formulate the pruning process as an integer linear program that discards inconsistent label combinations while respecting logical structure. Our approach, CLIPPER, is orthogonal to existing training algorithms and can be seamlessly integrated with them. Across 16 benchmarks over complex neurosymbolic tasks, we demonstrate that CLIPPER boosts the performance of state-of-the-art neurosymbolic engines like Scallop, Dolphin, and ISED by up to 48%, 53%, and 8%, leading to state-of-the-art accuracies.", "AI": {"tldr": "The paper presents CLIPPER, a method to improve the training of neural classifiers in neurosymbolic systems by pruning label combinations using logical constraints, resulting in improved performance across benchmarks.", "motivation": "The motivation is to address the challenge of exponential label combination growth in neurosymbolic learning and improve classifier training while respecting logical constraints.", "method": "CLIPPER prunes label combinations through an integer linear program that maintains logical consistency and incorporates the intuition of label similarity for instances with similar latent representations.", "result": "CLIPPER improves the accuracy of neurosymbolic engines like Scallop, Dolphin, and ISED by up to 48%, 53%, and 8%, respectively, across 16 benchmarks.", "conclusion": "The proposed technique significantly enhances the performance of neurosymbolic systems, is orthogonal to existing methods, and integrates seamlessly with various training algorithms."}}
{"id": "2602.08071", "pdf": "https://arxiv.org/pdf/2602.08071", "abs": "https://arxiv.org/abs/2602.08071", "authors": ["Feng Wang", "Sucheng Ren", "Tiezheng Zhang", "Predrag Neskovic", "Anand Bhattad", "Cihang Xie", "Alan Yuille"], "title": "ViT-5: Vision Transformers for The Mid-2020s", "categories": ["cs.CV"], "comment": "Code is available at https://github.com/wangf3014/ViT-5", "summary": "This work presents a systematic investigation into modernizing Vision Transformer backbones by leveraging architectural advancements from the past five years. While preserving the canonical Attention-FFN structure, we conduct a component-wise refinement involving normalization, activation functions, positional encoding, gating mechanisms, and learnable tokens. These updates form a new generation of Vision Transformers, which we call ViT-5. Extensive experiments demonstrate that ViT-5 consistently outperforms state-of-the-art plain Vision Transformers across both understanding and generation benchmarks. On ImageNet-1k classification, ViT-5-Base reaches 84.2\\% top-1 accuracy under comparable compute, exceeding DeiT-III-Base at 83.8\\%. ViT-5 also serves as a stronger backbone for generative modeling: when plugged into an SiT diffusion framework, it achieves 1.84 FID versus 2.06 with a vanilla ViT backbone. Beyond headline metrics, ViT-5 exhibits improved representation learning and favorable spatial reasoning behavior, and transfers reliably across tasks. With a design aligned with contemporary foundation-model practices, ViT-5 offers a simple drop-in upgrade over vanilla ViT for mid-2020s vision backbones.", "AI": {"tldr": "The paper introduces ViT-5, an upgraded Vision Transformer leveraging recent architectural advancements, consistently outperforming state-of-the-art models in classification and generative benchmarks.", "motivation": "To modernize Vision Transformer backbones using advancements over the past five years while maintaining simplicity and improving performance.", "method": "Systematically update the canonical Attention-FFN structure by refining normalization, activation functions, positional encoding, gating mechanisms, and learnable tokens.", "result": "ViT-5 achieves state-of-the-art performance, with improvements in accuracy in classification (e.g., 84.2% top-1 accuracy on ImageNet-1k) and generative modeling benchmarks (e.g., 1.84 FID compared to 2.06 in diffusion frameworks).", "conclusion": "ViT-5 emerges as a competitive backbone for both understanding and generation tasks, with reliable transferability across benchmarks and favorable characteristics for foundation-model practices."}}
{"id": "2602.06992", "pdf": "https://arxiv.org/pdf/2602.06992", "abs": "https://arxiv.org/abs/2602.06992", "authors": ["Xiaohui Zou", "Lijun Ke", "Shunpeng Zou"], "title": "A New Mode of Teaching Chinese as a Foreign Language from the Perspective of Smart System Studied by Using Rongzhixue", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "11 pages, in Chinese language, 22 figures", "summary": "The purpose of this study is to introduce a new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its characteristics are as follows: focusing on the butterfly model of interpretation before translation, highlighting the new method of bilingual thinking training, on the one hand, applying the new theory of Chinese characters, the theory of the relationship between language and speech, and the forward-looking research results of language science; On the other hand, the application of the new model of teaching Chinese as a foreign language, AI empowering teaching and learning, and the forward-looking research results of educational science fully reflect a series of characteristics of the new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its beneficial effects are: not only the old view of language and education, especially the old view of teaching Chinese as a foreign language, but also the old view of human-computer interaction. Its significance lies in that a series of great cross-border Rongzhixue such as language, knowledge, education and teaching, as well as new methods and new topics of bilingual thinking training are clearly put forward from the perspective of integrating wisdom. Especially in the face of the challenge of Chat GPT to human learning ability and even creativity, the existing concepts of language knowledge education and teaching are already very backward. The old concepts of Chinese language education, and teaching Chinese as a foreign language are all facing a series of subversive innovation challenges. How to seek changes in adaptation? This study has made a series of innovative attempts, hoping to benefit academic colleagues, teachers and students.", "AI": {"tldr": "The study introduces an innovative model for teaching Chinese as a foreign language, integrating wisdom, AI, and modern educational science.", "motivation": "To address the outdated methods of teaching Chinese as a foreign language and adapt to challenges from technologies like ChatGPT.", "method": "Combining theories of language, bilingual thinking, AI integration, and educational sciences to create a modern and effective teaching model.", "result": "The new model challenges traditional views on language education and demonstrates beneficial effects on teaching Chinese as a foreign language.", "conclusion": "This innovative approach to teaching aligns with modern linguistic, technological, and educational advancements, providing significant contributions to the field."}}
{"id": "2602.07974", "pdf": "https://arxiv.org/pdf/2602.07974", "abs": "https://arxiv.org/abs/2602.07974", "authors": ["Xin Li"], "title": "Beyond Optimization: Intelligence as Metric-Topology Factorization under Geometric Incompleteness", "categories": ["cs.LG"], "comment": null, "summary": "Contemporary ML often equates intelligence with optimization: searching for solutions within a fixed representational geometry. This works in static regimes but breaks under distributional shift, task permutation, and continual learning, where even mild topological changes can invalidate learned solutions and trigger catastrophic forgetting. We propose Metric-Topology Factorization (MTF) as a unifying geometric principle: intelligence is not navigation through a fixed maze, but the ability to reshape representational geometry so desired behaviors become stable attractors. Learning corresponds to metric contraction (a controlled deformation of Riemannian structure), while task identity and environmental variation are encoded topologically and stored separately in memory. We show any fixed metric is geometrically incomplete: for any local metric representation, some topological transformations make it singular or incoherent, implying an unavoidable stability-plasticity tradeoff for weight-based systems. MTF resolves this by factorizing stable topology from plastic metric warps, enabling rapid adaptation via geometric switching rather than re-optimization. Building on this, we introduce the Topological Urysohn Machine (TUM), implementing MTF through memory-amortized metric inference (MAMI): spectral task signatures index amortized metric transformations, letting a single learned geometry be reused across permuted, reflected, or parity-altered environments. This explains robustness to task reordering, resistance to catastrophic forgetting, and generalization across transformations that defeat conventional continual learning methods (e.g., EWC).", "AI": {"tldr": "The paper introduces Metric-Topology Factorization (MTF) to address issues like distributional shifts and catastrophic forgetting by separating the geometry of task representations (metric contraction and topological encoding). It implements this idea using the Topological Urysohn Machine (TUM), which shows resilience against conventional machine learning pitfalls.", "motivation": "The motivation stems from challenges faced by contemporary machine learning approaches, such as distributional shifts, task permutations, and continual learning settings, which lead to catastrophic forgetting and instability in solutions due to fixed representational geometries.", "method": "The proposed solution, Metric-Topology Factorization (MTF), restructures representational geometry by separating stable topology from adaptable metric geometries. This is realized through the Topological Urysohn Machine (TUM) using memory-amortized metric inference (MAMI) to adaptively transform metrics in response to tasks.", "result": "The framework demonstrates robustness to task permutations and generalization to diverse transformations, outperforming traditional methods like EWC. It addresses stability-plasticity tradeoffs and improves adaptability in continual learning scenarios.", "conclusion": "The proposed MTF framework redefines intelligence as the ability to reshape geometry dynamically rather than optimizing within fixed geometries, promoting better continual learning and adaptability across diverse tasks and environments."}}
{"id": "2602.08099", "pdf": "https://arxiv.org/pdf/2602.08099", "abs": "https://arxiv.org/abs/2602.08099", "authors": ["Issar Tzachor", "Dvir Samuel", "Rami Ben-Ari"], "title": "VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://iyttor.github.io/VidVec/", "summary": "Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-trained) MLLM layers already encode substantial task-relevant information. Leveraging this insight, we demonstrate that combining intermediate-layer embeddings with a calibrated MLLM head yields strong zero-shot retrieval performance without any training. Building on these findings, we introduce a lightweight text-based alignment strategy which maps dense video captions to short summaries and enables task-related video-text embedding learning without visual supervision. Remarkably, without any fine-tuning beyond text, our method outperforms current methods, often by a substantial margin, achieving state-of-the-art results across common video retrieval benchmarks.", "AI": {"tldr": "This paper explores using Multimodal Large Language Models (MLLMs) for video-text embedding and retrieval, achieving state-of-the-art results without fine-tuning.", "motivation": "Current generative MLLMs underperform compared to Video Foundation Models (VFMs) for video tasks. The paper aims to improve their effectiveness by investigating intermediate layers and text-based alignment strategies.", "method": "The authors analyze MLLM intermediate layers and propose combining their embeddings with calibrated heads. Additionally, a text-based alignment strategy for video-text embedding learning is introduced, avoiding visual supervision.", "result": "Without fine-tuning beyond text, this method achieves significant improvements and state-of-the-art performance on video retrieval benchmarks.", "conclusion": "MLLMs have substantial untapped potential for video tasks. Leveraging intermediate-layer embeddings and text-based alignment can provide effective zero-shot video-text retrieval solutions, outperforming existing methods."}}
{"id": "2602.08112", "pdf": "https://arxiv.org/pdf/2602.08112", "abs": "https://arxiv.org/abs/2602.08112", "authors": ["Sidike Paheding", "Abel Reyes-Angulo", "Leo Thomas Ramos", "Angel D. Sappa", "Rajaneesh A.", "Hiral P. B.", "Sajin Kumar K. S.", "Thomas Oommen"], "title": "MMLSv2: A Multimodal Dataset for Martian Landslide Detection in Remote Sensing Imagery", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We present MMLSv2, a dataset for landslide segmentation on Martian surfaces. MMLSv2 consists of multimodal imagery with seven bands: RGB, digital elevation model, slope, thermal inertia, and grayscale channels. MMLSv2 comprises 664 images distributed across training, validation, and test splits. In addition, an isolated test set of 276 images from a geographically disjoint region from the base dataset is released to evaluate spatial generalization. Experiments conducted with multiple segmentation models show that the dataset supports stable training and achieves competitive performance, while still posing challenges in fragmented, elongated, and small-scale landslide regions. Evaluation on the isolated test set leads to a noticeable performance drop, indicating increased difficulty and highlighting its value for assessing model robustness and generalization beyond standard in-distribution settings. Dataset will be available at: https://github.com/MAIN-Lab/MMLS_v2", "AI": {"tldr": "Introduction of MMLSv2 dataset for Martian surface landslide segmentation with multimodal imagery and comprehensive evaluation metrics.", "motivation": "To address the need for robust tools to segment landslides on Martian surfaces and improve spatial generalization in machine learning models.", "method": "Created MMLSv2 dataset with multimodal inputs and divided the data into training, validation, and geographically disjoint test sets.", "result": "The dataset supports stable training with competitive performance but poses challenges in complex segmentation regions. The geographically disjoint test set caused performance decline, emphasizing the difficulty of spatial generalization.", "conclusion": "MMLSv2 is a valuable resource for assessing segmentation models\u2019 robustness and spatial generalization beyond standard settings."}}
{"id": "2602.08000", "pdf": "https://arxiv.org/pdf/2602.08000", "abs": "https://arxiv.org/abs/2602.08000", "authors": ["Anirudh Satheesh", "Vaneet Aggarwal"], "title": "Regret Analysis of Unichain Average Reward Constrained MDPs with General Parameterization", "categories": ["cs.LG"], "comment": null, "summary": "We study infinite-horizon average-reward constrained Markov decision processes (CMDPs) under the unichain assumption and general policy parameterizations. Existing regret analyses for constrained reinforcement learning largely rely on ergodicity or strong mixing-time assumptions, which fail to hold in the presence of transient states. We propose a primal--dual natural actor--critic algorithm that leverages multi-level Monte Carlo (MLMC) estimators and an explicit burn-in mechanism to handle unichain dynamics without requiring mixing-time oracles. Our analysis establishes finite-time regret and cumulative constraint violation bounds that scale as $\\tilde{O}(\\sqrt{T})$, up to approximation errors arising from policy and critic parameterization, thereby extending order-optimal guarantees to a significantly broader class of CMDPs.", "AI": {"tldr": "The paper introduces a primal\u2013dual actor\u2013critic algorithm for constrained Markov decision processes (CMDPs) under the unichain assumption, addressing the challenges of transient states without relying on ergodicity or mixing-time assumptions.", "motivation": "Current methods fail to perform well in CMDPs with transient states due to reliance on ergodicity and mixing-time assumptions.", "method": "The paper develops an algorithm using multi-level Monte Carlo (MLMC) estimators and a burn-in mechanism, enabling learning in CMDPs with unichain dynamics.", "result": "The algorithm achieves bounds on finite-time regret and cumulative constraint violation that scale as $\u007fO(\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007fO\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007fO(\u007f\u007f\u007f\u007f\u007f\u007f(\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f$\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\u007f\\u00 fundamentaltime guarantees.", "conclusion": "The algorithm extends theoretical guarantees to a broader class of CMDPs, demonstrating adaptability and improved performance under unichain dynamics."}}
{"id": "2602.08117", "pdf": "https://arxiv.org/pdf/2602.08117", "abs": "https://arxiv.org/abs/2602.08117", "authors": ["Smriti Siva", "Jan Cross-Zamirski"], "title": "Building Damage Detection using Satellite Images and Patch-Based Transformer Methods", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "Rapid building damage assessment is critical for post-disaster response. Damage classification models built on satellite imagery provide a scalable means of obtaining situational awareness. However, label noise and severe class imbalance in satellite data create major challenges. The xBD dataset offers a standardized benchmark for building-level damage across diverse geographic regions. In this study, we evaluate Vision Transformer (ViT) model performance on the xBD dataset, specifically investigating how these models distinguish between types of structural damage when training on noisy, imbalanced data.\n  In this study, we specifically evaluate DINOv2-small and DeiT for multi-class damage classification. We propose a targeted patch-based pre-processing pipeline to isolate structural features and minimize background noise in training. We adopt a frozen-head fine-tuning strategy to keep computational requirements manageable. Model performance is evaluated through accuracy, precision, recall, and macro-averaged F1 scores. We show that small ViT architectures with our novel training method achieves competitive macro-averaged F1 relative to prior CNN baselines for disaster classification.", "AI": {"tldr": "This paper evaluates the performance of Vision Transformer (ViT) models, specifically DINOv2-small and DeiT, for building damage classification using the xBD dataset, and introduces a novel pre-processing and training method.", "motivation": "The motivation is to address challenges in damage classification from satellite imagery, such as label noise and class imbalance, and to leverage Vision Transformer models for more effective disaster response.", "method": "The study introduces a patch-based pre-processing pipeline to focus on structural features, minimizes background noise, and employs a frozen-head fine-tuning strategy for computational efficiency.", "result": "Small ViT models using the proposed method achieve competitive macro-averaged F1 scores compared to prior CNN baselines, demonstrating effectiveness in multi-class disaster classification.", "conclusion": "The research validates the potential of small ViT architectures with tailored training and preprocessing pipelines for scalable, efficient post-disaster damage assessment."}}
{"id": "2602.08126", "pdf": "https://arxiv.org/pdf/2602.08126", "abs": "https://arxiv.org/abs/2602.08126", "authors": ["Venkatraman Narayanan", "Bala Sai", "Rahul Ahuja", "Pratik Likhar", "Varun Ravi Kumar", "Senthil Yogamani"], "title": "MambaFusion: Adaptive State-Space Fusion for Multimodal 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Reliable 3D object detection is fundamental to autonomous driving, and multimodal fusion algorithms using cameras and LiDAR remain a persistent challenge. Cameras provide dense visual cues but ill posed depth; LiDAR provides a precise 3D structure but sparse coverage. Existing BEV-based fusion frameworks have made good progress, but they have difficulties including inefficient context modeling, spatially invariant fusion, and reasoning under uncertainty. We introduce MambaFusion, a unified multi-modal detection framework that achieves efficient, adaptive, and physically grounded 3D perception. MambaFusion interleaves selective state-space models (SSMs) with windowed transformers to propagate the global context in linear time while preserving local geometric fidelity. A multi-modal token alignment (MTA) module and reliability-aware fusion gates dynamically re-weight camera-LiDAR features based on spatial confidence and calibration consistency. Finally, a structure-conditioned diffusion head integrates graph-based reasoning with uncertainty-aware denoising, enforcing physical plausibility, and calibrated confidence. MambaFusion establishes new state-of-the-art performance on nuScenes benchmarks while operating with linear-time complexity. The framework demonstrates that coupling SSM-based efficiency with reliability-driven fusion yields robust, temporally stable, and interpretable 3D perception for real-world autonomous driving systems.", "AI": {"tldr": "MambaFusion proposes a 3D object detection framework for autonomous driving, utilizing efficient methods like selective state-space models, adaptive feature fusion, and uncertainty-aware reasoning to outperform existing methods and set new state-of-the-art benchmarks.", "motivation": "Autonomous driving requires reliable 3D object detection, integrating modalities like cameras and LiDAR. Current fusion frameworks face challenges such as inefficient modeling, spatially invariant fusion, and issues with uncertainty reasoning.", "method": "Introduce MambaFusion, combining selective state-space models with windowed transformers for efficient context modeling, incorporating multi-modal token alignment and reliability-aware fusion gates for feature re-weighting, and employing a structure-conditioned diffusion head for uncertainty management.", "result": "MambaFusion achieves state-of-the-art performance on the nuScenes benchmark while maintaining linear-time complexity, demonstrating robust 3D object detection capabilities.", "conclusion": "The framework successfully leverages efficient computations and reliability-based fusion techniques to deliver interpretable and stable 3D perception for practical autonomous driving applications."}}
{"id": "2602.08007", "pdf": "https://arxiv.org/pdf/2602.08007", "abs": "https://arxiv.org/abs/2602.08007", "authors": ["Sizhe Dang", "Jiaqi Shao", "Xiaodong Zheng", "Guang Dai", "Yan Song", "Haishan Ye"], "title": "From $O(mn)$ to $O(r^2)$: Two-Sided Low-Rank Communication for Adam in Distributed Training with Memory Efficiency", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As foundation models continue to scale, pretraining increasingly relies on data-parallel distributed optimization, making bandwidth-limited gradient synchronization a key bottleneck. Orthogonally, projection-based low-rank optimizers were mainly designed for memory efficiency, but remain suboptimal for communication-limited training: one-sided synchronization still transmits an $O(rn)$ object for an $m\\times n$ matrix gradient and refresh steps can dominate peak communicated bytes. We propose TSR, which brings two-sided low-rank communication to Adam-family updates (TSR-Adam) by synchronizing a compact core $U^\\top G V\\in\\mathbb{R}^{r\\times r}$, reducing the dominant per-step payload from $O(mn)$ to $O(r^2)$ while keeping moment states in low-dimensional cores. To further reduce the peak communication from subspace refresh, TSR-Adam adopts a randomized SVD-based refresh that avoids full-gradient synchronization. We additionally extend low-rank communication to embedding gradients with embedding-specific ranks and refresh schedules, yielding additional communication and memory savings over keeping embeddings dense. Across pretraining from 60M to 1B model scales, TSR-Adam reduces average communicated bytes per step by $13\\times$, and on GLUE fine-tuning it reduces communication by $25\\times$, while achieving comparable performance; we further provide a theoretical stationarity analysis for the proposed update. Code is available at https://github.com/DKmiyan/TSR-Adam.", "AI": {"tldr": "The paper introduces TSR-Adam to optimize data communication bottlenecks in large-scale distributed training by using two-sided low-rank communication, reducing average communication significantly while maintaining performance.", "motivation": "To address the bandwidth bottleneck of gradient synchronization in large-scale distributed training of foundation models, which limits optimization efficiency.", "method": "The paper proposes TSR-Adam, a two-sided low-rank communication approach that compresses matrix gradients into a compact core and employs randomized SVD for subspace refresh, along with embedding-specific ranks.", "result": "TSR-Adam reduces average communicated bytes per step by 13x during pretraining and 25x during fine-tuning on GLUE datasets, achieving comparable performance to other methods.", "conclusion": "TSR-Adam successfully reduces communication and memory overhead in distributed optimization without compromising training and fine-tuning performance, making it an effective solution for bandwidth-efficient training."}}
{"id": "2602.08131", "pdf": "https://arxiv.org/pdf/2602.08131", "abs": "https://arxiv.org/abs/2602.08131", "authors": ["Isaac Corley", "Hannah Kerner", "Caleb Robinson", "Jennifer Marcus"], "title": "Fields of The World: A Field Guide for Extracting Agricultural Field Boundaries", "categories": ["cs.CV"], "comment": null, "summary": "Field boundary maps are a building block for agricultural data products and support crop monitoring, yield estimation, and disease estimation. This tutorial presents the Fields of The World (FTW) ecosystem: a benchmark of 1.6M field polygons across 24 countries, pre-trained segmentation models, and command-line inference tools. We provide two notebooks that cover (1) local-scale field boundary extraction with crop classification and forest loss attribution, and (2) country-scale inference using cloud-optimized data. We use MOSAIKS random convolutional features and FTW derived field boundaries to map crop type at the field level and report macro F1 scores of 0.65--0.75 for crop type classification with limited labels. Finally, we show how to explore pre-computed predictions over five countries (4.76M km\\textsuperscript{2}), with median predicted field areas from 0.06 ha (Rwanda) to 0.28 ha (Switzerland).", "AI": {"tldr": "This paper introduces the Fields of The World (FTW) ecosystem, offering a comprehensive benchmark, pre-trained models, and tools for field boundary mapping to support various agricultural applications.", "motivation": "The research aims to address the lack of accessible and standardized field boundary maps for agricultural data applications and analysis.", "method": "FTW ecosystem includes a benchmark of 1.6M field polygons, pre-trained segmentation models, and cloud-based inference tools. The approach leverages MOSAIKS random convolutional features and notebooks for field-scale and country-scale usage.", "result": "The study reports crop type classification accuracy with macro F1 scores of 0.65\u20130.75 using FTW-derived boundaries. Predictions for five countries cover 4.76M km\u00b2, with median field areas from 0.06 ha to 0.28 ha.", "conclusion": "The FTW ecosystem significantly enhances field boundary mapping capabilities, offering resources for accurate agricultural monitoring at diverse scales."}}
{"id": "2602.08012", "pdf": "https://arxiv.org/pdf/2602.08012", "abs": "https://arxiv.org/abs/2602.08012", "authors": ["Riccardo De Santi", "Malte Franke", "Ya-Ping Hsieh", "Andreas Krause"], "title": "A Unified Density Operator View of Flow Control and Merging", "categories": ["cs.LG"], "comment": null, "summary": "Recent progress in large-scale flow and diffusion models raised two fundamental algorithmic challenges: (i) control-based reward adaptation of pre-trained flows, and (ii) integration of multiple models, i.e., flow merging. While current approaches address them separately, we introduce a unifying probability-space framework that subsumes both as limit cases, and enables reward-guided flow merging, allowing principled, task-aware combination of multiple pre-trained flows (e.g., merging priors while maximizing drug-discovery utilities). Our formulation renders possible to express a rich family of operators over generative models densities, including intersection (e.g., to enforce safety), union (e.g., to compose diverse models), interpolation (e.g., for discovery), their reward-guided counterparts, as well as complex logical expressions via generative circuits. Next, we introduce Reward-Guided Flow Merging (RFM), a mirror-descent scheme that reduces reward-guided flow merging to a sequence of standard fine-tuning problems. Then, we provide first-of-their-kind theoretical guarantees for reward-guided and pure flow merging via RFM. Ultimately, we showcase the capabilities of the proposed method on illustrative settings providing visually interpretable insights, and apply our method to high-dimensional de-novo molecular design and low-energy conformer generation.", "AI": {"tldr": "A unified probability-space framework is introduced to address reward-guided adaptation and flow merging challenges for generative models, enabling combined optimization and integration of pretrained flows.", "motivation": "To innovate and unify approaches for merging and adapting generative model flows for tasks like maximizing utilities in drug discovery.", "method": "Reward-Guided Flow Merging (RFM), a mirror-descent scheme, allowing adaptation and merging of flows via fine-tuning while providing theoretical guarantees.", "result": "RFM demonstrated capabilities in high-dimensional molecular design and conformer generation, backed by theoretical guarantees.", "conclusion": "This method facilitates task-aware combination and optimization of generative models and introduces operators for diverse combinatory behaviors using a unified framework."}}
{"id": "2602.08136", "pdf": "https://arxiv.org/pdf/2602.08136", "abs": "https://arxiv.org/abs/2602.08136", "authors": ["Md Rafi Ur Rashid", "MD Sadik Hossain Shanto", "Vishnu Asutosh Dasu", "Shagufta Mehnaz"], "title": "Robustness of Vision Language Models Against Split-Image Harmful Input Attacks", "categories": ["cs.CV", "cs.AI"], "comment": "22 Pages, long conference paper", "summary": "Vision-Language Models (VLMs) are now a core part of modern AI. Recent work proposed several visual jailbreak attacks using single/ holistic images. However, contemporary VLMs demonstrate strong robustness against such attacks due to extensive safety alignment through preference optimization (e.g., RLHF). In this work, we identify a new vulnerability: while VLM pretraining and instruction tuning generalize well to split-image inputs, safety alignment is typically performed only on holistic images and does not account for harmful semantics distributed across multiple image fragments. Consequently, VLMs often fail to detect and refuse harmful split-image inputs, where unsafe cues emerge only after combining images. We introduce novel split-image visual jailbreak attacks (SIVA) that exploit this misalignment. Unlike prior optimization-based attacks, which exhibit poor black-box transferability due to architectural and prior mismatches across models, our attacks evolve in progressive phases from naive splitting to an adaptive white-box attack, culminating in a black-box transfer attack. Our strongest strategy leverages a novel adversarial knowledge distillation (Adv-KD) algorithm to substantially improve cross-model transferability. Evaluations on three state-of-the-art modern VLMs and three jailbreak datasets demonstrate that our strongest attack achieves up to 60% higher transfer success than existing baselines. Lastly, we propose efficient ways to address this critical vulnerability in the current VLM safety alignment.", "AI": {"tldr": "The paper discovers a vulnerability in Vision-Language Models (VLMs) where harmful semantics can bypass safety mechanisms in split-image attacks. The proposed split-image visual jailbreak attacks (SIVA) exploit this gap and achieve high success rates.", "motivation": "Despite advancements in VLM safety alignment, vulnerabilities exist in handling split-image inputs where harmful cues are distributed.", "method": "The authors introduce SIVA, progressing from naive to adaptive attacks, with a novel adversarial knowledge distillation (Adv-KD) approach to enhance cross-model attack transferability.", "result": "SIVA achieves up to 60% higher success in transferring attacks across models compared to previous methods, as shown on state-of-the-art VLMs and datasets.", "conclusion": "The proposed SIVA attacks highlight critical gaps in VLM safety alignment, and the paper outlines efficient countermeasures to address these vulnerabilities."}}
{"id": "2602.08019", "pdf": "https://arxiv.org/pdf/2602.08019", "abs": "https://arxiv.org/abs/2602.08019", "authors": ["Dong Pan", "Bingtao Li", "Yongsheng Zheng", "Jiren Ma", "Victor Fei"], "title": "The Rise of Sparse Mixture-of-Experts: A Survey from Algorithmic Foundations to Decentralized Architectures and Vertical Domain Applications", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The sparse Mixture of Experts(MoE) architecture has evolved as a powerful approach for scaling deep learning models to more parameters with comparable computation cost. As an important branch of large language model(LLM), MoE model only activate a subset of experts based on a routing network. This sparse conditional computation mechanism significantly improves computational efficiency, paving a promising path for greater scalability and cost-efficiency. It not only enhance downstream applications such as natural language processing, computer vision, and multimodal in various horizontal domains, but also exhibit broad applicability across vertical domains. Despite the growing popularity and application of MoE models across various domains, there lacks a systematic exploration of recent advancements of MoE in many important fields. Existing surveys on MoE suffer from limitations such as lack coverage or none extensively exploration of key areas. This survey seeks to fill these gaps. In this paper, Firstly, we examine the foundational principles of MoE, with an in-depth exploration of its core components-the routing network and expert network. Subsequently, we extend beyond the centralized paradigm to the decentralized paradigm, which unlocks the immense untapped potential of decentralized infrastructure, enables democratization of MoE development for broader communities, and delivers greater scalability and cost-efficiency. Furthermore we focus on exploring its vertical domain applications. Finally, we also identify key challenges and promising future research directions. To the best of our knowledge, this survey is currently the most comprehensive review in the field of MoE. We aim for this article to serve as a valuable resource for both researchers and practitioners, enabling them to navigate and stay up-to-date with the latest advancements.", "AI": {"tldr": "This paper surveys recent advancements in Mixture of Experts (MoE) models, focusing on foundational principles, decentralized paradigms, applications in vertical domains, and future challenges.", "motivation": "The paper aims to address the lack of systematic exploration and comprehensive review of the growing popularity and application of sparse Mixture of Experts (MoE) models.", "method": "The authors systematically review the core components of MoE, explore both centralized and decentralized paradigms, and investigate applications in vertical domains while identifying challenges and future research directions.", "result": "The survey provides an in-depth analysis of MoE, highlighting its advantages, scalability, democratization potential, and applicability across various domains.", "conclusion": "This paper serves as the most comprehensive review of MoE models, aiming to guide researchers and practitioners in understanding and leveraging recent advancements."}}
{"id": "2602.08168", "pdf": "https://arxiv.org/pdf/2602.08168", "abs": "https://arxiv.org/abs/2602.08168", "authors": ["Mei Ling Chee", "Thangarajah Akilan", "Aparna Ravindra Phalke", "Kanchan Keisham"], "title": "DAS-SK: An Adaptive Model Integrating Dual Atrous Separable and Selective Kernel CNN for Agriculture Semantic Segmentation", "categories": ["cs.CV"], "comment": "13 pages", "summary": "Semantic segmentation in high-resolution agricultural imagery demands models that strike a careful balance between accuracy and computational efficiency to enable deployment in practical systems. In this work, we propose DAS-SK, a novel lightweight architecture that retrofits selective kernel convolution (SK-Conv) into the dual atrous separable convolution (DAS-Conv) module to strengthen multi-scale feature learning. The model further enhances the atrous spatial pyramid pooling (ASPP) module, enabling the capture of fine-grained local structures alongside global contextual information. Built upon a modified DeepLabV3 framework with two complementary backbones - MobileNetV3-Large and EfficientNet-B3, the DAS-SK model mitigates limitations associated with large dataset requirements, limited spectral generalization, and the high computational cost that typically restricts deployment on UAVs and other edge devices. Comprehensive experiments across three benchmarks: LandCover.ai, VDD, and PhenoBench, demonstrate that DAS-SK consistently achieves state-of-the-art performance, while being more efficient than CNN-, transformer-, and hybrid-based competitors. Notably, DAS-SK requires up to 21x fewer parameters and 19x fewer GFLOPs than top-performing transformer models. These findings establish DAS-SK as a robust, efficient, and scalable solution for real-time agricultural robotics and high-resolution remote sensing, with strong potential for broader deployment in other vision domains.", "AI": {"tldr": "The paper introduces DAS-SK, a lightweight model for semantic segmentation in high-resolution agricultural imagery, achieving state-of-the-art results with lower computational requirements.", "motivation": "Semantic segmentation in agricultural imagery requires models that balance accuracy and computational efficiency to enable deployment on UAVs and edge devices.", "method": "The DAS-SK model integrates selective kernel convolution into the DAS-Conv module and improves the ASPP module for better feature learning, deploying complementary backbones MobileNetV3-Large and EfficientNet-B3.", "result": "DAS-SK achieves state-of-the-art performance across benchmarks (LandCover.ai, VDD, PhenoBench) with significantly fewer parameters and GFLOPs compared to leading transformer models.", "conclusion": "DAS-SK offers an efficient, scalable, and robust solution for real-time agricultural robotics and remote sensing with potential applications across vision domains."}}
{"id": "2602.08198", "pdf": "https://arxiv.org/pdf/2602.08198", "abs": "https://arxiv.org/abs/2602.08198", "authors": ["Jingyu Hu", "Bin Hu", "Ka-Hei Hui", "Haipeng Li", "Zhengzhe Liu", "Daniel Cohen-Or", "Chi-Wing Fu"], "title": "PEGAsus: 3D Personalization of Geometry and Appearance", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "We present PEGAsus, a new framework capable of generating Personalized 3D shapes by learning shape concepts at both Geometry and Appearance levels. First, we formulate 3D shape personalization as extracting reusable, category-agnostic geometric and appearance attributes from reference shapes, and composing these attributes with text to generate novel shapes. Second, we design a progressive optimization strategy to learn shape concepts at both the geometry and appearance levels, decoupling the shape concept learning process. Third, we extend our approach to region-wise concept learning, enabling flexible concept extraction, with context-aware and context-free losses. Extensive experimental results show that PEGAsus is able to effectively extract attributes from a wide range of reference shapes and then flexibly compose these concepts with text to synthesize new shapes. This enables fine-grained control over shape generation and supports the creation of diverse, personalized results, even in challenging cross-category scenarios. Both quantitative and qualitative experiments demonstrate that our approach outperforms existing state-of-the-art solutions.", "AI": {"tldr": "This paper introduces PEGAsus, a framework for generating personalized 3D shapes by learning reusable, category-agnostic geometric and appearance attributes, which can be composed with text for novel shape creation.", "motivation": "To enable fine-grained control and personalization of 3D shape generation, addressing the challenge of extracting reusable and context-aware geometric and appearance attributes from reference shapes.", "method": "The framework employs a progressive optimization strategy to decouple and learn geometry and appearance attributes, along with region-wise concept learning using context-aware and context-free losses.", "result": "Experimental results demonstrate PEGAsus' ability to effectively extract shape attributes and generate diverse, personalized, and high-quality shapes, outperforming state-of-the-art methods in both qualitative and quantitative evaluations.", "conclusion": "PEGAsus provides an advanced solution for personalized 3D shape generation, showcasing flexible and fine-grained customization while achieving superior results across various scenarios, including challenging cross-category cases."}}
{"id": "2602.08032", "pdf": "https://arxiv.org/pdf/2602.08032", "abs": "https://arxiv.org/abs/2602.08032", "authors": ["Lior Cohen", "Ofir Nabati", "Kaixin Wang", "Navdeep Kumar", "Shie Mannor"], "title": "Horizon Imagination: Efficient On-Policy Training in Diffusion World Models", "categories": ["cs.LG"], "comment": "This paper will be published in the ICLR 2026 proceedings", "summary": "We study diffusion-based world models for reinforcement learning, which offer high generative fidelity but face critical efficiency challenges in control. Current methods either require heavyweight models at inference or rely on highly sequential imagination, both of which impose prohibitive computational costs. We propose Horizon Imagination (HI), an on-policy imagination process for discrete stochastic policies that denoises multiple future observations in parallel. HI incorporates a stabilization mechanism and a novel sampling schedule that decouples the denoising budget from the effective horizon over which denoising is applied while also supporting sub-frame budgets. Experiments on Atari 100K and Craftium show that our approach maintains control performance with a sub-frame budget of half the denoising steps and achieves superior generation quality under varied schedules. Code is available at https://github.com/leor-c/horizon-imagination.", "AI": {"tldr": "The paper introduces Horizon Imagination (HI), an efficient method to improve diffusion-based world models for reinforcement learning, reducing computational costs while maintaining performance.", "motivation": "Current diffusion-based world models for reinforcement learning have high generative fidelity but suffer from computational inefficiencies during control, making them impractical to use in real-time.", "method": "The authors propose Horizon Imagination (HI), an on-policy imagination process that denoises multiple future observations in parallel. It includes a stabilization mechanism and a novel sampling schedule to decouple the denoising budget from the effective horizon, even under limited computational budgets.", "result": "Experiments conducted on Atari 100K and Craftium demonstrate that HI can maintain control performance even with reduced denoising steps and offers superior generative quality across varied sampling schedules.", "conclusion": "The paper concludes that Horizon Imagination significantly enhances the efficiency of diffusion-based world models in reinforcement learning by optimizing the denoising process without compromising performance."}}
{"id": "2602.08202", "pdf": "https://arxiv.org/pdf/2602.08202", "abs": "https://arxiv.org/abs/2602.08202", "authors": ["Jinrong Lv", "Xun Gong", "Zhaohuan Li", "Weili Jiang"], "title": "Generative Regression for Left Ventricular Ejection Fraction Estimation from Echocardiography Video", "categories": ["cs.CV"], "comment": "11 pages, 5 tables, 10 figures. Under peer review", "summary": "Estimating Left Ventricular Ejection Fraction (LVEF) from echocardiograms constitutes an ill-posed inverse problem. Inherent noise, artifacts, and limited viewing angles introduce ambiguity, where a single video sequence may map not to a unique ground truth, but rather to a distribution of plausible physiological values. Prevailing deep learning approaches typically formulate this task as a standard regression problem that minimizes the Mean Squared Error (MSE). However, this paradigm compels the model to learn the conditional expectation, which may yield misleading predictions when the underlying posterior distribution is multimodal or heavy-tailed -- a common phenomenon in pathological scenarios. In this paper, we investigate the paradigm shift from deterministic regression toward generative regression. We propose the Multimodal Conditional Score-based Diffusion model for Regression (MCSDR), a probabilistic framework designed to model the continuous posterior distribution of LVEF conditioned on echocardiogram videos and patient demographic attribute priors. Extensive experiments conducted on the EchoNet-Dynamic, EchoNet-Pediatric, and CAMUS datasets demonstrate that MCSDR achieves state-of-the-art performance. Notably, qualitative analysis reveals that the generation trajectories of our model exhibit distinct behaviors in cases characterized by high noise or significant physiological variability, thereby offering a novel layer of interpretability for AI-aided diagnosis.", "AI": {"tldr": "The paper introduces a Multimodal Conditional Score-based Diffusion model for Regression (MCSDR) to better estimate the distribution of LVEF from echocardiogram data, outperforming previous methods.", "motivation": "Deep learning models for LVEF estimation often misrepresent posterior distributions, especially in pathological cases, due to assuming a deterministic regression approach.", "method": "The authors propose MCSDR, a probabilistic generative model that captures the continuous posterior distribution of LVEF, leveraging echocardiograms and patient demographics.", "result": "Experiments across multiple datasets show MCSDR achieves superior predictive performance and provides a novel interpretability layer by analyzing trajectory behaviors under noise.", "conclusion": "MCSDR offers more reliable and interpretable LVEF estimations, marking an advancement in generative regression for medical applications."}}
{"id": "2602.08033", "pdf": "https://arxiv.org/pdf/2602.08033", "abs": "https://arxiv.org/abs/2602.08033", "authors": ["Julien Fageot", "Matthias Grossglauser", "L\u00ea-Nguy\u00ean Hoang", "Matteo Tacchi-B\u00e9nard", "Oscar Villemaud"], "title": "The Benefits of Diversity: Combining Comparisons and Ratings for Efficient Scoring", "categories": ["cs.LG"], "comment": "1 table, 5 figures, 8 pages", "summary": "Should humans be asked to evaluate entities individually or comparatively? This question has been the subject of long debates. In this work, we show that, interestingly, combining both forms of preference elicitation can outperform the focus on a single kind. More specifically, we introduce SCoRa (Scoring from Comparisons and Ratings), a unified probabilistic model that allows to learn from both signals. We prove that the MAP estimator of SCoRa is well-behaved. It verifies monotonicity and robustness guarantees. We then empirically show that SCoRa recovers accurate scores, even under model mismatch. Most interestingly, we identify a realistic setting where combining comparisons and ratings outperforms using either one alone, and when the accurate ordering of top entities is critical. Given the de facto availability of signals of multiple forms, SCoRa additionally offers a versatile foundation for preference learning.", "AI": {"tldr": "The paper introduces SCoRa, a probabilistic model integrating individual and comparative preference evaluations, and shows its superior performance in certain scenarios.", "motivation": "To explore whether combining individual and comparative preference evaluations provides better results than using either method alone.", "method": "Developed SCoRa, a probabilistic model that integrates scoring from comparisons and ratings. The authors tested its properties like monotonicity and robustness and evaluated its empirical performance under mismatches.", "result": "SCoRa recovers accurate scores even under model mismatches and surpasses individual forms of preference learning in a scenario where accurate ranking of top entities is essential.", "conclusion": "Integrating multiple forms of preference signals via SCoRa enhances preference learning and offers a practical foundation for broader applications."}}
{"id": "2602.08206", "pdf": "https://arxiv.org/pdf/2602.08206", "abs": "https://arxiv.org/abs/2602.08206", "authors": ["Chufeng Zhou", "Jian Wang", "Xinyuan Liu", "Xiaokang Zhang"], "title": "Geospatial-Reasoning-Driven Vocabulary-Agnostic Remote Sensing Semantic Segmentation", "categories": ["cs.CV"], "comment": "5 pages, 3 figures", "summary": "Open-vocabulary semantic segmentation has emerged as a promising research direction in remote sensing, enabling the recognition of diverse land-cover types beyond pre-defined category sets. However, existing methods predominantly rely on the passive mapping of visual features and textual embeddings. This ``appearance-based\" paradigm lacks geospatial contextual awareness, leading to severe semantic ambiguity and misclassification when encountering land-cover classes with similar spectral features but distinct semantic attributes. To address this, we propose a Geospatial Reasoning Chain-of-Thought (GR-CoT) framework designed to enhance the scene understanding capabilities of Multimodal Large Language Models (MLLMs), thereby guiding open-vocabulary segmentation models toward precise mapping. The framework comprises two collaborative components: an offline knowledge distillation stream and an online instance reasoning stream. The offline stream establishes fine-grained category interpretation standards to resolve semantic conflicts between similar land-cover types. During online inference, the framework executes a sequential reasoning process involving macro-scenario anchoring, visual feature decoupling, and knowledge-driven decision synthesis. This process generates an image-adaptive vocabulary that guides downstream models to achieve pixel-level alignment with correct geographical semantics. Extensive experiments on the LoveDA and GID5 benchmarks demonstrate the superiority of our approach.", "AI": {"tldr": "This paper introduces the GR-CoT framework to improve open-vocabulary semantic segmentation in remote sensing by addressing issues of semantic ambiguity and misclassification.", "motivation": "Conventional methods lack geospatial contextual awareness, leading to semantic ambiguity in recognizing land-cover classes with similar features.", "method": "The GR-CoT framework includes an offline knowledge distillation stream and an online instance reasoning stream for improving category interpretation and guiding geospatial semantic understanding during segmentation.", "result": "Experiments on LoveDA and GID5 benchmarks demonstrate that GR-CoT significantly enhances segmentation accuracy and scene understanding.", "conclusion": "The proposed GR-CoT framework effectively resolves semantic conflicts and enhances open-vocabulary remote sensing segmentation through advanced reasoning and adaptive vocabulary generation."}}
{"id": "2602.08036", "pdf": "https://arxiv.org/pdf/2602.08036", "abs": "https://arxiv.org/abs/2602.08036", "authors": ["Jingtao Liu", "Xinming Zhang"], "title": "TAAM:Inductive Graph-Class Incremental Learning with Task-Aware Adaptive Modulation", "categories": ["cs.LG"], "comment": null, "summary": "Graph Continual Learning (GCL) aims to solve the challenges of streaming graph data. However, current methods often depend on replay-based strategies, which raise concerns like memory limits and privacy issues, while also struggling to resolve the stability-plasticity dilemma. In this paper, we suggest that lightweight, task-specific modules can effectively guide the reasoning process of a fixed GNN backbone. Based on this idea, we propose Task-Aware Adaptive Modulation (TAAM). The key component of TAAM is its lightweight Neural Synapse Modulators (NSMs). For each new task, a dedicated NSM is trained and then frozen, acting as an \"expert module.\" These modules perform detailed, node-attentive adaptive modulation on the computational flow of a shared GNN backbone. This setup ensures that new knowledge is kept within compact, task-specific modules, naturally preventing catastrophic forgetting without using any data replay. Additionally, to address the important challenge of unknown task IDs in real-world scenarios, we propose and theoretically prove a novel method named Anchored Multi-hop Propagation (AMP). Notably, we find that existing GCL benchmarks have flaws that can cause data leakage and biased evaluations. Therefore, we conduct all experiments in a more rigorous inductive learning scenario. Extensive experiments show that TAAM comprehensively outperforms state-of-the-art methods across eight datasets. Code and Datasets are available at: https://github.com/1iuJT/TAAM_AAMAS2026.", "AI": {"tldr": "This paper introduces TAAM, a method using lightweight task-specific modules to address Graph Continual Learning challenges without data replay.", "motivation": "Current Graph Continual Learning methods face issues such as memory limitations, privacy concerns, and stability-plasticity trade-offs.", "method": "The proposed method, TAAM, utilizes Neural Synapse Modulators (NSMs) for task-specific adaptive modulation on a shared GNN backbone.", "result": "TAAM outperforms state-of-the-art methods across eight datasets under rigorous scenarios.", "conclusion": "Task-specific modules within TAAM effectively mitigate catastrophic forgetting and provide robust performance without reliance on data replay."}}
{"id": "2602.08211", "pdf": "https://arxiv.org/pdf/2602.08211", "abs": "https://arxiv.org/abs/2602.08211", "authors": ["Yik Lung Pang", "Changjae Oh"], "title": "Chain-of-Caption: Training-free improvement of multimodal large language model on referring expression comprehension", "categories": ["cs.CV"], "comment": "4 pages, 5 figures, 2 tables", "summary": "Given a textual description, the task of referring expression comprehension (REC) involves the localisation of the referred object in an image. Multimodal large language models (MLLMs) have achieved high accuracy on REC benchmarks through scaling up the model size and training data. Moreover, the performance of MLLMs can be further improved using techniques such as Chain-of-Thought and tool use, which provides additional visual or textual context to the model. In this paper, we analyse the effect of various techniques for providing additional visual and textual context via tool use to the MLLM and its effect on the REC task. Furthermore, we propose a training-free framework named Chain-of-Caption to improve the REC performance of MLLMs. We perform experiments on RefCOCO/RefCOCOg/RefCOCO+ and Ref-L4 datasets and show that individual textual or visual context can improve the REC performance without any fine-tuning. By combining multiple contexts, our training-free framework shows between 5% to 30% performance gain over the baseline model on accuracy at various Intersection over Union (IoU) thresholds.", "AI": {"tldr": "This paper explores incorporating additional visual and textual contexts to enhance the performance of multimodal large language models (MLLMs) in referring expression comprehension (REC), proposing a training-free framework called Chain-of-Caption.", "motivation": "The paper aims to address the challenge of further boosting the performance of MLLMs in the REC task by introducing improved techniques for providing additional contextual information without requiring extra training efforts.", "method": "The paper proposes and evaluates the Chain-of-Caption framework, which provides extra visual and textual contexts to the MLLM using tool use techniques, ensuring a training-free approach. Results were tested on several REC benchmarks to assess its effectiveness.", "result": "The Chain-of-Caption framework and other context-providing techniques achieved significant performance improvement on REC benchmarks (RefCOCO, RefCOCOg, RefCOCO+, Ref-L4) without fine-tuning, offering between 5% to 30% gains in accuracy.", "conclusion": "Incorporating visual and textual contexts using training-free methods like Chain-of-Caption is effective in improving REC accuracy in MLLMs, showcasing a scalable and efficient way to enhance such models."}}
{"id": "2602.07021", "pdf": "https://arxiv.org/pdf/2602.07021", "abs": "https://arxiv.org/abs/2602.07021", "authors": ["Sahibpreet Singh", "Saksham Sharma"], "title": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.LG"], "comment": "Presented at National Conference on Navigating The Intersection of Artificial Intelligence and Law: Ethical and Legal Horizons, 29 September 2024, pp. 91-106", "summary": "Integration of AI into environmental regulation represents a significant advancement in data management. It offers promising results in both data protection plus algorithmic fairness. This research addresses the critical need for sustainable data protection in the era of ever evolving cyber threats. Traditional encryption methods face limitations in handling the dynamic nature of environmental data. This necessitates the exploration of advanced cryptographic techniques. The objective of this study is to evaluate how AI can enhance these techniques to ensure robust data protection while facilitating fair algorithmic management. The methodology involves a comprehensive review of current advancements in AI-enhanced homomorphic encryption (HE) and multi-party computation (MPC). It is coupled with an analysis of how these techniques can be applied to environmental data regulation. Key findings indicate that AI-driven dynamic key management, adaptive encryption schemes, and optimized computational efficiency in HE, alongside AI-enhanced protocol optimization and fault mitigation in MPC, significantly improve the security of environmental data processing. These findings highlight a crucial research gap in the intersection of AI, cyber laws, and environmental regulation, particularly in terms of addressing algorithmic bias, transparency, and accountability. The implications of this research underscore the need for stricter cyber laws. Also, the development of comprehensive regulations to safeguard sensitive environmental data. Future efforts should focus on refining AI systems to balance security with privacy and ensuring that regulatory frameworks can adapt to technological advancements. This study provides a foundation for future research aimed at achieving secure sustainable environmental data management through AI innovations.", "AI": {"tldr": "The study explores how AI can enhance data protection in environmental regulation amidst evolving cyber threats by employing advanced cryptographic techniques like HE and MPC, presenting significant opportunities to improve algorithmic fairness and security.", "motivation": "To address the growing need for robust and sustainable data protection in environmental data regulation amidst increasing cyber threats and limitations of traditional encryption methods.", "method": "A comprehensive review of advancements in AI-enhanced homomorphic encryption (HE) and multi-party computation (MPC), analyzing their applications in environmental regulation.", "result": "AI-driven approaches like dynamic key management, adaptive encryption schemes, optimization in HE, and fault mitigation in MPC significantly enhance security and efficiency in handling environmental data.", "conclusion": "The research highlights gaps in AI, cyber laws, and environmental regulation, advocating for stricter laws and adaptable frameworks to ensure secure and fair environmental data management through AI innovations."}}
{"id": "2602.08040", "pdf": "https://arxiv.org/pdf/2602.08040", "abs": "https://arxiv.org/abs/2602.08040", "authors": ["Isaac Han", "Sangyeon Park", "Seungwon Oh", "Donghu Kim", "Hojoon Lee", "Kyung-Joong Kim"], "title": "FIRE: Frobenius-Isometry Reinitialization for Balancing the Stability-Plasticity Tradeoff", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR'26 (oral)", "summary": "Deep neural networks trained on nonstationary data must balance stability (i.e., retaining prior knowledge) and plasticity (i.e., adapting to new tasks). Standard reinitialization methods, which reinitialize weights toward their original values, are widely used but difficult to tune: conservative reinitializations fail to restore plasticity, while aggressive ones erase useful knowledge. We propose FIRE, a principled reinitialization method that explicitly balances the stability-plasticity tradeoff. FIRE quantifies stability through Squared Frobenius Error (SFE), measuring proximity to past weights, and plasticity through Deviation from Isometry (DfI), reflecting weight isotropy. The reinitialization point is obtained by solving a constrained optimization problem, minimizing SFE subject to DfI being zero, which is efficiently approximated by Newton-Schulz iteration. FIRE is evaluated on continual visual learning (CIFAR-10 with ResNet-18), language modeling (OpenWebText with GPT-0.1B), and reinforcement learning (HumanoidBench with SAC and Atari games with DQN). Across all domains, FIRE consistently outperforms both naive training without intervention and standard reinitialization methods, demonstrating effective balancing of the stability-plasticity tradeoff.", "AI": {"tldr": "This paper introduces FIRE, a novel reinitialization method for deep neural networks that balances stability and plasticity better than standard methods, improving performance across various tasks.", "motivation": "The motivation is to address the challenge of maintaining a balance between stability and plasticity in deep neural networks trained on nonstationary data, as standard reinitialization methods struggle with tuning and often either fail to retain knowledge or lose adaptability.", "method": "FIRE explicitly balances stability and plasticity by quantifying stability through Squared Frobenius Error (SFE) and plasticity through Deviation from Isometry (DfI). The reinitialization point is determined by solving a constrained optimization problem using Newton-Schulz iteration.", "result": "FIRE outperforms both naive training and standard reinitialization methods in continual visual learning, language modeling, and reinforcement learning, demonstrating its effectiveness in balancing stability and plasticity.", "conclusion": "FIRE is a principled and efficient reinitialization approach that addresses the stability-plasticity tradeoff, making it beneficial across multiple domains and tasks."}}
{"id": "2602.08041", "pdf": "https://arxiv.org/pdf/2602.08041", "abs": "https://arxiv.org/abs/2602.08041", "authors": ["Boyang Xia", "Weiyou Tian", "Qingnan Ren", "Jiaqi Huang", "Jie Xiao", "Shuo Lu", "Kai Wang", "Lynn Ai", "Eric Yang", "Bill Shi"], "title": "Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Training large language model (LLM) agents for adversarial games is often driven by episodic objectives such as win rate. In long-horizon settings, however, payoffs are shaped by latent strategic externalities that evolve over time, so myopic optimization and variation-based regret analyses can become vacuous even when the dynamics are predictable. To solve this problem, we introduce Implicit Strategic Optimization (ISO), a prediction-aware framework in which each agent forecasts the current strategic context and uses it to update its policy online. ISO combines a Strategic Reward Model (SRM) that estimates the long-run strategic value of actions with iso-grpo, a context-conditioned optimistic learning rule. We prove sublinear contextual regret and equilibrium convergence guarantees whose dominant terms scale with the number of context mispredictions; when prediction errors are bounded, our bounds recover the static-game rates obtained when strategic externalities are known. Experiments in 6-player No-Limit Texas Hold'em and competitive Pokemon show consistent improvements in long-term return over strong LLM and RL baselines, and graceful degradation under controlled prediction noise.", "AI": {"tldr": "The paper introduces a framework called Implicit Strategic Optimization (ISO) for training large language model agents in long-term adversarial games, enhancing performance by addressing long-horizon strategic externalities.", "motivation": "To address limitations of myopic optimization and variation-based regret analysis in long-horizon adversarial games, where strategic externalities evolve over time.", "method": "The paper introduces ISO, which includes a Strategic Reward Model (SRM) for estimating long-term strategic values and iso-grpo, a context-conditioned optimistic learning rule. The agents predict current strategic contexts to update policies online.", "result": "ISO demonstrates improved long-term returns in experiments on 6-player No-Limit Texas Hold'em and competitive Pok\u00e9mon, outperforming strong LLM and RL baselines while showing robustness under prediction noise.", "conclusion": "ISO provides a robust framework for long-horizon settings by combining prediction-aware optimization with guarantees of sublinear regret and equilibrium convergence, effectively handling latent strategic externalities."}}
{"id": "2602.08224", "pdf": "https://arxiv.org/pdf/2602.08224", "abs": "https://arxiv.org/abs/2602.08224", "authors": ["Jing Zhang", "Zhikai Li", "Xuewen Liu", "Qingyi Gu"], "title": "Efficient-SAM2: Accelerating SAM2 with Object-Aware Visual Encoding and Memory Retrieval", "categories": ["cs.CV"], "comment": "ICLR 2026,Code is available at: https://github.com/jingjing0419/Efficient-SAM2", "summary": "Segment Anything Model 2 (SAM2) shows excellent performance in video object segmentation tasks; however, the heavy computational burden hinders its application in real-time video processing. Although there have been efforts to improve the efficiency of SAM2, most of them focus on retraining a lightweight backbone, with little exploration into post-training acceleration. In this paper, we observe that SAM2 exhibits sparse perception pattern as biological vision, which provides opportunities for eliminating redundant computation and acceleration: i) In mask decoder, the attention primarily focuses on the foreground objects, whereas the image encoder in the earlier stage exhibits a broad attention span, which results in unnecessary computation to background regions. ii) In memory bank, only a small subset of tokens in each frame contribute significantly to memory attention, and the salient regions exhibit temporal consistency, making full-token computation redundant. With these insights, we propose Efficient-SAM2, which promotes SAM2 to adaptively focus on object regions while eliminating task-irrelevant computations, thereby significantly improving inference efficiency. Specifically, for image encoder, we propose object-aware Sparse Window Routing (SWR), a window-level computation allocation mechanism that leverages the consistency and saliency cues from the previous-frame decoder to route background regions into a lightweight shortcut branch. Moreover, for memory attention, we propose object-aware Sparse Memory Retrieval (SMR), which allows only the salient memory tokens in each frame to participate in computation, with the saliency pattern reused from their first recollection. With negligible additional parameters and minimal training overhead, Efficient-SAM2 delivers 1.68x speedup on SAM2.1-L model with only 1.0% accuracy drop on SA-V test set.", "AI": {"tldr": "Efficient-SAM2 introduces sparse computation strategies to accelerate the Segment Anything Model 2 (SAM2), achieving a 1.68x speedup with minimal accuracy drop.", "motivation": "The computational burden of SAM2 limits its potential for real-time video processing, despite its strong video object segmentation performance.", "method": "Efficient-SAM2 leverages sparse perception patterns in SAM2 to introduce adaptive mechanisms: Sparse Window Routing (SWR) for image encoder efficiency and Sparse Memory Retrieval (SMR) for memory attention acceleration.", "result": "Efficient-SAM2 achieves a 1.68x speedup on the SAM2.1-L model with only a 1.0% accuracy drop on the SA-V test set.", "conclusion": "Efficient-SAM2 reduces redundant computations in SAM2 with negligible parameters and training overhead, enabling faster inference while preserving accuracy."}}
{"id": "2602.07023", "pdf": "https://arxiv.org/pdf/2602.07023", "abs": "https://arxiv.org/abs/2602.07023", "authors": ["Zeping Li", "Guancheng Wan", "Keyang Chen", "Yu Chen", "Yiwen Zhao", "Philip Torr", "Guangnan Ye", "Zhenfei Yin", "Hongfeng Chai"], "title": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation", "categories": ["q-fin.TR", "cs.AI"], "comment": null, "summary": "Recent works have increasingly applied Large Language Models (LLMs) as agents in financial stock market simulations to test if micro-level behaviors aggregate into macro-level phenomena. However, a crucial question arises: Do LLM agents' behaviors align with real market participants? This alignment is key to the validity of simulation results. To explore this, we select a financial stock market scenario to test behavioral consistency. Investors are typically classified as fundamental or technical traders, but most simulations fix strategies at initialization, failing to reflect real-world trading dynamics. In this work, we assess whether agents' strategy switching aligns with financial theory, providing a framework for this evaluation. We operationalize four behavioral-finance drivers-loss aversion, herding, wealth differentiation, and price misalignment-as personality traits set via prompting and stored long-term. In year-long simulations, agents process daily price-volume data, trade under a designated style, and reassess their strategy every 10 trading days. We introduce four alignment metrics and use Mann-Whitney U tests to compare agents' style-switching behavior with financial theory. Our results show that recent LLMs' switching behavior is only partially consistent with behavioral-finance theories, highlighting the need for further refinement in aligning agent behavior with financial theory.", "AI": {"tldr": "This paper examines whether behaviors of LLM agents in stock market simulations align with real-world trading dynamics and financial theories.", "motivation": "The motivation is to validate the credibility of financial market simulations by assessing if LLM agents' strategy-switching behaviors align with real-world traders.", "method": "The study operationalizes behavioral-finance drivers as personality traits for LLM agents, evaluates yearly simulations, assesses switching styles every 10 days, and introduces metrics based on statistical analysis (Mann-Whitney U tests).", "result": "LLM agents demonstrate partial consistency with behavioral-finance theories, revealing gaps in aligning their behavior with real-world trading dynamics.", "conclusion": "Further refinement of LLM agent behaviors is needed to more authentically replicate real-world trading actions and enhance simulation accuracy in financial contexts."}}
{"id": "2602.08064", "pdf": "https://arxiv.org/pdf/2602.08064", "abs": "https://arxiv.org/abs/2602.08064", "authors": ["Tianyu Li", "Dongchen Han", "Zixuan Cao", "Haofeng Huang", "Mengyu Zhou", "Ming Chen", "Erchao Zhao", "Xiaoxi Jiang", "Guanjun Jiang", "Gao Huang"], "title": "SiameseNorm: Breaking the Barrier to Reconciling Pre/Post-Norm", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Modern Transformers predominantly adopt the Pre-Norm paradigm for its optimization stability, foregoing the superior potential of the unstable Post-Norm architecture. Prior attempts to combine their strengths typically lead to a stability-performance trade-off. We attribute this phenomenon to a structural incompatibility within a single-stream design: Any application of the Post-Norm operation inevitably obstructs the clean identity gradient preserved by Pre-Norm. To fundamentally reconcile these paradigms, we propose SiameseNorm, a two-stream architecture that couples Pre-Norm-like and Post-Norm-like streams with shared parameters. This design decouples the optimization dynamics of the two streams, retaining the distinct characteristics of both Pre-Norm and Post-Norm by enabling all residual blocks to receive combined gradients inherited from both paradigms, where one stream secures stability while the other enhances expressivity. Extensive pre-training experiments on 1.3B-parameter models demonstrate that SiameseNorm exhibits exceptional optimization robustness and consistently outperforms strong baselines. Code is available at https://github.com/Qwen-Applications/SiameseNorm.", "AI": {"tldr": "The paper introduces SiameseNorm, a two-stream architecture combining Pre-Norm and Post-Norm Transformers, which enhances both stability and expressivity, outperforming standard models.", "motivation": "Address the trade-off between stability and expressivity in Transformer architectures using Pre-Norm and Post-Norm combinations.", "method": "A two-stream SiameseNorm architecture that separates optimization dynamics using shared parameters for Pre-Norm and Post-Norm paradigms.", "result": "SiameseNorm provides exceptional robustness in optimization and outperforms baselines in pretraining for 1.3B-parameter models.", "conclusion": "SiameseNorm resolves the inherent limitations of single-stream Transformers by decoupling the optimization dynamics of Pre-Norm and Post-Norm."}}
{"id": "2602.08230", "pdf": "https://arxiv.org/pdf/2602.08230", "abs": "https://arxiv.org/abs/2602.08230", "authors": ["Hongwei Ren", "Youxin Jiang", "Qifei Gu", "Xiangqian Wu"], "title": "Generating Adversarial Events: A Motion-Aware Point Cloud Framework", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Event cameras have been widely adopted in safety-critical domains such as autonomous driving, robotics, and human-computer interaction. A pressing challenge arises from the vulnerability of deep neural networks to adversarial examples, which poses a significant threat to the reliability of event-based systems. Nevertheless, research into adversarial attacks on events is scarce. This is primarily due to the non-differentiable nature of mainstream event representations, which hinders the extension of gradient-based attack methods. In this paper, we propose MA-ADV, a novel \\textbf{M}otion-\\textbf{A}ware \\textbf{Adv}ersarial framework. To the best of our knowledge, this is the first work to generate adversarial events by leveraging point cloud representations. MA-ADV accounts for high-frequency noise in events and employs a diffusion-based approach to smooth perturbations, while fully leveraging the spatial and temporal relationships among events. Finally, MA-ADV identifies the minimal-cost perturbation through a combination of sample-wise Adam optimization, iterative refinement, and binary search. Extensive experimental results validate that MA-ADV ensures a 100\\% attack success rate with minimal perturbation cost, and also demonstrate enhanced robustness against defenses, underscoring the critical security challenges facing future event-based perception systems.", "AI": {"tldr": "This paper introduces MA-ADV, the first adversarial attack framework for event cameras using point cloud representations, achieving high attack success rates with minimal perturbations.", "motivation": "Event cameras are vulnerable to adversarial examples, threatening their reliability in critical applications like autonomous driving and robotics, and limited research exists due to difficulties in utilizing event representations.", "method": "The paper proposes MA-ADV, a motion-aware adversarial framework using diffusion-based perturbation smoothing and techniques such as Adam optimization, iterative refinement, and binary search to generate adversarial events.", "result": "MA-ADV achieves a 100% attack success rate with minimal perturbation cost and demonstrates increased resilience to defenses.", "conclusion": "Future event-based perception systems face significant security challenges, emphasizing the importance of addressing adversarial vulnerabilities in such systems."}}
{"id": "2602.08043", "pdf": "https://arxiv.org/pdf/2602.08043", "abs": "https://arxiv.org/abs/2602.08043", "authors": ["Yiheng Gao", "Qin Hua", "Zizhong Chen"], "title": "V-ABFT: Variance-Based Adaptive Threshold for Fault-Tolerant Matrix Multiplication in Mixed-Precision Deep Learning", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": null, "summary": "Algorithm-Based Fault Tolerance (ABFT) is widely adopted to detect silent data corruptions (SDCs) in matrix multiplication, a cornerstone operation in deep learning systems. However, existing threshold determination methods face critical challenges: analytical bounds are overly conservative, while probabilistic approaches like A-ABFT yield thresholds $160$--$4200\\times$ larger than actual rounding errors. We present V-ABFT, a variance-based adaptive threshold algorithm that achieves tighter error bounds by directly modeling the verification difference. By leveraging statistical variance estimation, V-ABFT reduces the threshold-to-actual-error ratio to approximately $7$--$20\\times$ for FP32/FP64 and $48$--$158\\times$ for BF16, representing a \\textbf{6--48$\\times$ improvement} over A-ABFT while maintaining zero false positive rate across BF16, FP16, FP32, and FP64 precisions. Furthermore, we demonstrate that for fused-kernel ABFT implementations that verify before output quantization, low-precision GEMM can use FP32-level thresholds ($e_{\\max} \\approx 10^{-6}$), enabling \\textbf{$\\sim$1000$\\times$ finer detection granularity} compared to offline verification with low-precision output ($e_{\\max} \\approx 10^{-3}$). We reproduce A-ABFT's experimental setup and validate our implementation against the original paper's results. Our method requires only $O(n)$ complexity using max/min/mean statistics, compared to A-ABFT's $O(pn)$ for finding $p$ largest values. Extensive experiments on synthetic data and real model weights (LLaMA-7B, GPT-2, ViT) demonstrate V-ABFT's effectiveness across diverse distributions. V-ABFT is platform-agnostic and has been integrated into fault-tolerant GEMM implementations on both NPUs and GPUs.", "AI": {"tldr": "This paper presents V-ABFT, a variance-based adaptive threshold algorithm for fault tolerance in matrix multiplication, achieving tighter error bounds, increased detection granularity, and lower computational complexity.", "motivation": "The motivation is to address challenges in existing ABFT methods, where thresholds for error detection are overly conservative or excessively large, leading to inefficiencies in detecting data corruptions in matrix multiplication, a key operation in deep learning systems.", "method": "The paper proposes V-ABFT, which uses statistical variance estimation for adaptive threshold determination. It reduces the threshold-to-actual-error ratio and achieves a significant reduction in false positives while maintaining precision in error detection.", "result": "Results show V-ABFT reduces error threshold ratios by 6\u201348x compared to A-ABFT. It enables finer detection granularity for fused-kernel implementations and retains zero false positives across precision levels, with extensive validations using both synthetic and real model setups.", "conclusion": "V-ABFT proves to be an efficient, accurate, and platform-agnostic fault-tolerance solution that improves over existing methods while simplifying computational requirements, making it suitable for modern NPUs and GPUs."}}
{"id": "2602.08128", "pdf": "https://arxiv.org/pdf/2602.08128", "abs": "https://arxiv.org/abs/2602.08128", "authors": ["Zahir Alsulaimawi"], "title": "Online Bayesian Imbalanced Learning with Bregman-Calibrated Deep Networks", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Class imbalance remains a fundamental challenge in machine learning, where standard classifiers exhibit severe performance degradation in minority classes. Although existing approaches address imbalance through resampling or cost-sensitive learning during training, they require retraining or access to labeled target data when class distributions shift at deployment time, a common occurrence in real-world applications such as fraud detection, medical diagnosis, and anomaly detection. We present \\textit{Online Bayesian Imbalanced Learning} (OBIL), a principled framework that decouples likelihood-ratio estimation from class-prior assumptions, enabling real-time adaptation to distribution shifts without model retraining. Our approach builds on the established connection between Bregman divergences and proper scoring rules to show that deep networks trained with such losses produce posterior probability estimates from which prior-invariant likelihood ratios can be extracted. We prove that these likelihood-ratio estimates remain valid under arbitrary changes in class priors and cost structures, requiring only a threshold adjustment for optimal Bayes decisions. We derive finite-sample regret bounds demonstrating that OBIL achieves $O(\\sqrt{T \\log T})$ regret against an oracle with perfect prior knowledge. Extensive experiments on benchmark datasets and medical diagnosis benchmarks under simulated deployment shifts demonstrate that OBIL maintains robust performance under severe distribution shifts, outperforming state-of-the-art methods in F1 Score when test distributions deviate significantly from the training conditions.", "AI": {"tldr": "The paper introduces Online Bayesian Imbalanced Learning (OBIL) to address class imbalance in machine learning, enabling real-time adaptation to distribution shifts without retraining while maintaining robust performance.", "motivation": "Class imbalance often causes performance degradation in machine learning models for minority classes, especially under real-world scenarios of shifting class distributions. Current methods, while effective during training, require retraining or labeled target data during deployment shifts.", "method": "The OBIL framework decouples likelihood-ratio estimation from class-prior assumptions. It employs Bregman divergence and proper scoring rules, allowing networks to extract posterior probabilities and invariant likelihood ratios, only requiring threshold adjustments for optimal outcomes.", "result": "OBIL achieves $O(\\sqrt{T \\log T})$ regret bounds under deployment shifts and demonstrates superior F1 score performance compared to state-of-the-art methods across benchmark datasets and medical diagnosis cases.", "conclusion": "OBIL robustly handles class imbalance and shifting distributions without retraining. It provides a principled and efficient solution for real-time adaptation, proving effective in diverse experiments and outperforming competing methods."}}
{"id": "2602.08236", "pdf": "https://arxiv.org/pdf/2602.08236", "abs": "https://arxiv.org/abs/2602.08236", "authors": ["Shoubin Yu", "Yue Zhang", "Zun Wang", "Jaehong Yoon", "Huaxiu Yao", "Mingyu Ding", "Mohit Bansal"], "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "the first two authors are equally contributed. Project page: https://adaptive-visual-tts.github.io/", "summary": "Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination. Across spatial reasoning benchmarks (SAT, MMSI) and an embodied navigation benchmark (R2R), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.", "AI": {"tldr": "The paper explores the role of test-time visual imagination in multimodal reasoning, focusing on when it is necessary, beneficial, or harmful, and proposes a selective control framework to optimize its usage.", "motivation": "To address limitations in visual spatial reasoning within multimodal models, especially when reasoning involves alternative or unseen viewpoints without introducing excessive or misleading evidence.", "method": "The authors propose AVIC, an adaptive framework that evaluates the sufficiency of visual evidence and selectively employs world models for visual imagination based on spatial reasoning needs.", "result": "Experiments across benchmarks revealed scenarios where imagination is crucial, marginal, or detrimental, and demonstrated that selective control improves efficiency and performance compared to fixed strategies.", "conclusion": "Test-time imagination is crucial for efficient and reliable spatial reasoning, and selective control of imagination avoids unnecessary computation while enhancing accuracy."}}
{"id": "2602.08050", "pdf": "https://arxiv.org/pdf/2602.08050", "abs": "https://arxiv.org/abs/2602.08050", "authors": ["Qusai Khaled", "Uzay Kaymak", "Laura Genga"], "title": "Interpretable Fuzzy Systems For Forward Osmosis Desalination", "categories": ["cs.LG"], "comment": "7 pages, 4 figures, FUZZ-IEEE 2025", "summary": "Preserving interpretability in fuzzy rule-based systems (FRBS) is vital for water treatment, where decisions impact public health. While structural interpretability has been addressed using multi-objective algorithms, semantic interpretability often suffers due to fuzzy sets with low distinguishability. We propose a human-in-the-loop approach for developing interpretable FRBS to predict forward osmosis desalination productivity. Our method integrates expert-driven grid partitioning for distinguishable membership functions, domain-guided feature engineering to reduce redundancy, and rule pruning based on firing strength. This approach achieved comparable predictive performance to cluster-based FRBS while maintaining semantic interpretability and meeting structural complexity constraints, providing an explainable solution for water treatment applications.", "AI": {"tldr": "The paper proposes a human-in-the-loop method to ensure semantic interpretability in fuzzy rule-based systems for water treatment and demonstrates its effectiveness in forward osmosis desalination.", "motivation": "The motivation is to develop interpretable fuzzy rule-based systems (FRBS) for water treatment applications, ensuring decisions are transparent and explainable, especially given the public health impact of such decisions.", "method": "The authors integrate expert-driven grid partitioning, domain-guided feature engineering, and rule pruning based on firing strength to improve semantic interpretability while maintaining performance.", "result": "The proposed method maintains semantic interpretability, achieves comparable predictive performance to cluster-based FRBS, and adheres to structural complexity constraints.", "conclusion": "The introduced method offers a balance between predictive performance and interpretability, providing an explainable solution for forward osmosis desalination in water treatment."}}
{"id": "2602.08145", "pdf": "https://arxiv.org/pdf/2602.08145", "abs": "https://arxiv.org/abs/2602.08145", "authors": ["Xinyu Yang", "Junlin Han", "Rishi Bommasani", "Jinqi Luo", "Wenjie Qu", "Wangchunshu Zhou", "Adel Bibi", "Xiyao Wang", "Jaehong Yoon", "Elias Stengel-Eskin", "Shengbang Tong", "Lingfeng Shen", "Rafael Rafailov", "Runjia Li", "Zhaoyang Wang", "Yiyang Zhou", "Chenhang Cui", "Yu Wang", "Wenhao Zheng", "Huichi Zhou", "Jindong Gu", "Zhaorun Chen", "Peng Xia", "Tony Lee", "Thomas Zollo", "Vikash Sehwag", "Jixuan Leng", "Jiuhai Chen", "Yuxin Wen", "Huan Zhang", "Zhun Deng", "Linjun Zhang", "Pavel Izmailov", "Pang Wei Koh", "Yulia Tsvetkov", "Andrew Wilson", "Jiaheng Zhang", "James Zou", "Cihang Xie", "Hao Wang", "Philip Torr", "Julian McAuley", "David Alvarez-Melis", "Florian Tram\u00e8r", "Kaidi Xu", "Suman Jana", "Chris Callison-Burch", "Rene Vidal", "Filippos Kokkinos", "Mohit Bansal", "Beidi Chen", "Huaxiu Yao"], "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.CY"], "comment": "TMLR camera-ready version", "summary": "Foundation models, including Large Language Models (LLMs), Multimodal Large Language Models (MLLMs), Image Generative Models (i.e, Text-to-Image Models and Image-Editing Models), and Video Generative Models, have become essential tools with broad applications across various domains such as law, medicine, education, finance, science, and beyond. As these models see increasing real-world deployment, ensuring their reliability and responsibility has become critical for academia, industry, and government. This survey addresses the reliable and responsible development of foundation models. We explore critical issues, including bias and fairness, security and privacy, uncertainty, explainability, and distribution shift. Our research also covers model limitations, such as hallucinations, as well as methods like alignment and Artificial Intelligence-Generated Content (AIGC) detection. For each area, we review the current state of the field and outline concrete future research directions. Additionally, we discuss the intersections between these areas, highlighting their connections and shared challenges. We hope our survey fosters the development of foundation models that are not only powerful but also ethical, trustworthy, reliable, and socially responsible.", "AI": {"tldr": "The paper surveys the reliable and responsible development of foundation models, addressing issues like bias, fairness, security, hallucinations, and more.", "motivation": "With the arising ethical and practical concerns in deploying foundation models across diverse fields, ensuring their reliability and responsibility is essential.", "method": "The survey identifies critical challenges like bias, privacy, and model limitations and reviews existing advancements while proposing future research directions.", "result": "The study provides a detailed overview of current progress and challenges in responsible foundation model development.", "conclusion": "Promoting the ethical and trustworthy deployment of foundation models, the paper encourages further research to address shared challenges like bias, hallucinations, and distribution shifts."}}
{"id": "2602.08262", "pdf": "https://arxiv.org/pdf/2602.08262", "abs": "https://arxiv.org/abs/2602.08262", "authors": ["Guoqi Yu", "Xiaowei Hu", "Angelica I. Aviles-Rivero", "Anqi Qiu", "Shujun Wang"], "title": "Moving Beyond Functional Connectivity: Time-Series Modeling for fMRI-Based Brain Disorder Classification", "categories": ["cs.CV"], "comment": "This paper has been accepted by IEEE Transactions on Medical Imaging", "summary": "Functional magnetic resonance imaging (fMRI) enables non-invasive brain disorder classification by capturing blood-oxygen-level-dependent (BOLD) signals. However, most existing methods rely on functional connectivity (FC) via Pearson correlation, which reduces 4D BOLD signals to static 2D matrices, discarding temporal dynamics and capturing only linear inter-regional relationships. In this work, we benchmark state-of-the-art temporal models (e.g., time-series models such as PatchTST, TimesNet, and TimeMixer) on raw BOLD signals across five public datasets. Results show these models consistently outperform traditional FC-based approaches, highlighting the value of directly modeling temporal information such as cycle-like oscillatory fluctuations and drift-like slow baseline trends. Building on this insight, we propose DeCI, a simple yet effective framework that integrates two key principles: (i) Cycle and Drift Decomposition to disentangle cycle and drift within each ROI (Region of Interest); and (ii) Channel-Independence to model each ROI separately, improving robustness and reducing overfitting. Extensive experiments demonstrate that DeCI achieves superior classification accuracy and generalization compared to both FC-based and temporal baselines. Our findings advocate for a shift toward end-to-end temporal modeling in fMRI analysis to better capture complex brain dynamics. The code is available at https://github.com/Levi-Ackman/DeCI.", "AI": {"tldr": "This paper introduces DeCI, a novel framework for classifying brain disorders using fMRI signals by capturing temporal dynamics directly, rather than relying on static functional connectivity matrices.", "motivation": "To address the limitations of static functional connectivity approaches in fMRI analysis, which discard temporal dynamics and only capture linear inter-regional relationships.", "method": "The study benchmarks state-of-the-art temporal models on raw fMRI data and proposes the DeCI framework. DeCI integrates two principles: Cycle and Drift Decomposition to isolate dynamic trends in brain regions, and Channel-Independence to analyze regions individually to minimize overfitting.", "result": "DeCI outperforms both traditional functional connectivity-based methods and advanced temporal baselines in terms of classification accuracy and generalization across multiple datasets.", "conclusion": "End-to-end modeling of raw temporal fMRI data, as demonstrated with DeCI, better captures brain dynamics and should be adopted for more effective brain disorder analysis."}}
{"id": "2602.08054", "pdf": "https://arxiv.org/pdf/2602.08054", "abs": "https://arxiv.org/abs/2602.08054", "authors": ["Manan Tayal", "Mumuksh Tayal"], "title": "Epigraph-Guided Flow Matching for Safe and Performant Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 8 figures", "summary": "Offline reinforcement learning (RL) provides a compelling paradigm for training autonomous systems without the risks of online exploration, particularly in safety-critical domains. However, jointly achieving strong safety and performance from fixed datasets remains challenging. Existing safe offline RL methods often rely on soft constraints that allow violations, introduce excessive conservatism, or struggle to balance safety, reward optimization, and adherence to the data distribution. To address this, we propose Epigraph-Guided Flow Matching (EpiFlow), a framework that formulates safe offline RL as a state-constrained optimal control problem to co-optimize safety and performance. We learn a feasibility value function derived from an epigraph reformulation of the optimal control problem, thereby avoiding the decoupled objectives or post-hoc filtering common in prior work. Policies are synthesized by reweighting the behavior distribution based on this epigraph value function and fitting a generative policy via flow matching, enabling efficient, distribution-consistent sampling. Across various safety-critical tasks, including Safety-Gymnasium benchmarks, EpiFlow achieves competitive returns with near-zero empirical safety violations, demonstrating the effectiveness of epigraph-guided policy synthesis.", "AI": {"tldr": "EpiFlow tackles safe offline reinforcement learning by using a state-constrained optimal control problem to balance safety and performance, showing competitive returns with minimal violations.", "motivation": "Safe offline RL is crucial for training autonomous systems in safety-critical environments while avoiding the risks of online exploration. Existing methods struggle to balance safety, reward optimization, and consistency with the dataset.", "method": "EpiFlow introduces an epigraph-guided formulation for safe offline RL, learning a feasibility value function and synthesizing policies through reweighting and flow matching to ensure consistent sampling.", "result": "EpiFlow demonstrates near-zero safety violations and achieves competitive results across challenging safety-critical tasks, including Safety-Gymnasium benchmarks.", "conclusion": "Epigraph-guided policy synthesis enables efficient and safe offline RL performance without compromising on reward or safety, setting a strong benchmark for future approaches."}}
{"id": "2602.08159", "pdf": "https://arxiv.org/pdf/2602.08159", "abs": "https://arxiv.org/abs/2602.08159", "authors": ["Seonglae Cho", "Zekun Wu", "Kleyton Da Costa", "Adriano Koshiyama"], "title": "The Confidence Manifold: Geometric Structure of Correctness Representations in Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "When a language model asserts that \"the capital of Australia is Sydney,\" does it know this is wrong? We characterize the geometry of correctness representations across 9 models from 5 architecture families. The structure is simple: the discriminative signal occupies 3-8 dimensions, performance degrades with additional dimensions, and no nonlinear classifier improves over linear separation. Centroid distance in the low-dimensional subspace matches trained probe performance (0.90 AUC), enabling few-shot detection: on GPT-2, 25 labeled examples achieve 89% of full-data accuracy. We validate causally through activation steering: the learned direction produces 10.9 percentage point changes in error rates while random directions show no effect. Internal probes achieve 0.80-0.97 AUC; output-based methods (P(True), semantic entropy) achieve only 0.44-0.64 AUC. The correctness signal exists internally but is not expressed in outputs. That centroid distance matches probe performance indicates class separation is a mean shift, making detection geometric rather than learned.", "AI": {"tldr": "This paper investigates whether language models are aware of their own incorrect assertions, mapping the internal geometry of correctness signals and enabling effective error detection even with few examples.", "motivation": "The study seeks to understand whether and how language models internally represent correctness, providing insights into model behavior and improving error detection.", "method": "Researchers analyzed correctness signals across 9 models from 5 architectures, using techniques like low-dimensional representations, centroid geometry, trained probes, and activation steering.", "result": "Key findings include the effectiveness of low-dimensional geometric representations for error detection (0.90 AUC), the causal validation of correctness signals through activation steering, and outperforming traditional output-based methods.", "conclusion": "Correctness is represented geometrically within the models but isn't reflected in outputs, suggesting the internal knowledge can be accessed and utilized for improved error detection."}}
{"id": "2602.08277", "pdf": "https://arxiv.org/pdf/2602.08277", "abs": "https://arxiv.org/abs/2602.08277", "authors": ["Xiangbo Gao", "Renjie Li", "Xinghao Chen", "Yuheng Wu", "Suofei Feng", "Qing Yin", "Zhengzhong Tu"], "title": "PISCO: Precise Video Instance Insertion with Sparse Control", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and \"cherry-picking\" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing, this task demands several requirements: precise spatial-temporal placement, physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control. PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion models, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation, together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO.", "AI": {"tldr": "The paper introduces PISCO, a video diffusion model for precise video instance insertion using arbitrary sparse keyframe input, outperforming existing methods.", "motivation": "The motivation is to overcome limitations in AI-assisted filmmaking by providing a tool for precise video instance insertion, addressing spatial-temporal placement, consistent interaction, and dynamics preservation with minimal user input.", "method": "The authors propose PISCO, equipped with Variable-Information Guidance, Distribution-Preserving Temporal Masking, and geometry-aware conditioning for robust video editing. Additionally, PISCO-Bench is introduced for benchmarking.", "result": "PISCO outperforms existing inpainting and video editing baselines, showing improved performance as more control signals are provided and demonstrating robustness under sparse conditions.", "conclusion": "PISCO represents a significant advancement in video editing, offering fine-grained, controllable generation for AI-assisted filmmaking, and proving its effectiveness with strong benchmark results."}}
{"id": "2602.08060", "pdf": "https://arxiv.org/pdf/2602.08060", "abs": "https://arxiv.org/abs/2602.08060", "authors": ["Alejandro Ruiz y Mesa", "Guilherme Korol", "Moritz Riesteter", "Jo\u00e3o Paulo Cardoso de Lima", "Jeronimo Castrillon"], "title": "Compiler-Assisted Speculative Sampling for Accelerated LLM Inference on Heterogeneous Edge Devices", "categories": ["cs.LG"], "comment": "Accepted to AccML@HiPEAC 2026", "summary": "LLM deployment on resource-constrained edge devices faces severe latency constraints, particularly in real-time applications where delayed responses can compromise safety or usability. Among many approaches to mitigate the inefficiencies of sequential token-by-token generation, Speculative Decoding (SD) has emerged as a promising technique. However, SD at the edge is hindered by two major challenges: (1) integrating SD into a compiler-based workflow without sacrificing performance or programmability, and (2) exploiting the heterogeneous compute resources of modern SoCs through carefully designed partitioning strategies. This work addresses these challenges by using an analytical cost model that explores heterogeneous hardware configurations and guides coarse-grained partitioning of LLM subgraphs, particularly with edge-typical short input sequence lengths. The cost model predicts when speculative sampling and heterogeneous execution are jointly beneficial and is validated on an edge device featuring a hexacore Cortex-A CPU and a Mali GPU, revealing up to 1.68$\\times$ speedup for translation tasks, closely matching analytic expectations.", "AI": {"tldr": "The paper presents strategies to optimize LLM deployment on resource-scarce edge devices by introducing Speculative Decoding combined with heterogeneous hardware utilization, achieving significant speedup.", "motivation": "LLM deployment on edge devices faces latency and efficiency challenges which hinder real-time application performance and require novel methods for optimization.", "method": "The authors introduce an analytical cost model to guide heterogeneous compute partitioning of LLM subgraphs, focusing on edge-specific conditions like short input sequences.", "result": "Experiments on a hexacore Cortex-A CPU and Mali GPU demonstrate up to 1.68\u00d7 speedup in translation tasks, with predictions from the cost model closely aligning with actual results.", "conclusion": "The study successfully integrates Speculative Decoding into edge environments, leveraging heterogeneous hardware, and providing a robust model for future efficiency improvements in latency-constrained scenarios."}}
{"id": "2602.08169", "pdf": "https://arxiv.org/pdf/2602.08169", "abs": "https://arxiv.org/abs/2602.08169", "authors": ["Zejia You", "Chunyuan Deng", "Hanjie Chen"], "title": "Spherical Steering: Geometry-Aware Activation Rotation for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "The code is at: https://github.com/chili-lab/Spherical-Steering", "summary": "Inference-time steering has emerged as a promising paradigm for controlling language models (LMs) without the cost of retraining. However, standard approaches typically rely on activation addition, a geometric operation that inevitably alters the magnitude of hidden representations. This raises concerns about representation collapse and degradation of open-ended generation capabilities. In this work, we explore Spherical Steering, a training-free primitive that resolves this trade-off through activation rotation. Rather than shifting activations with a fixed vector, our method rotates them along a geodesic toward a target direction, guiding the activation toward the target concept while preserving the integrity of the signal. To further enhance adaptivity, we incorporate a confidence gate that dynamically modulates steering strength based on input uncertainty. Extensive experiments across multiple-choice benchmarks demonstrate that Spherical Steering significantly outperforms addition-based baselines (notably by +10% on TruthfulQA, COPA, and Storycloze), while simultaneously maintaining the model's general open-ended generation quality. This work highlights the value of geometric consistency, suggesting that norm-preserving rotation is a robust and effective primitive for precise inference-time control.", "AI": {"tldr": "Spherical Steering introduces a training-free method for controlling language models by rotating hidden activations instead of altering their magnitude, leading to better performance and preserving generation quality.", "motivation": "The motivation is to improve inference-time control of language models without retraining while avoiding the issues of representation collapse caused by activation addition methods.", "method": "The method involves guiding activations via rotation along a geodesic towards a desired target direction, incorporating a confidence gate for adaptive steering based on input uncertainty, ensuring norm preservation.", "result": "Spherical Steering significantly outperforms traditional addition-based methods in multiple-choice benchmarks (e.g., +10% improvement on TruthfulQA, COPA, and Storycloze) and maintains high open-ended generation quality.", "conclusion": "Norm-preserving rotation is introduced as a robust and effective mechanism for precision inference-time LM control, highlighting the importance of geometric consistency in steering methods."}}
{"id": "2602.08282", "pdf": "https://arxiv.org/pdf/2602.08282", "abs": "https://arxiv.org/abs/2602.08282", "authors": ["Haixu Liu", "Yufei Wang", "Tianxiang Xu", "Chuancheng Shi", "Hongsheng Xing"], "title": "Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large-scale, cross-species plant distribution prediction plays a crucial role in biodiversity conservation, yet modeling efforts in this area still face significant challenges due to the sparsity and bias of observational data. Presence-Absence (PA) data provide accurate and noise-free labels, but are costly to obtain and limited in quantity; Presence-Only (PO) data, by contrast, offer broad spatial coverage and rich spatiotemporal distribution, but suffer from severe label noise in negative samples. To address these real-world constraints, this paper proposes a multimodal fusion framework that fully leverages the strengths of both PA and PO data. We introduce an innovative pseudo-label aggregation strategy for PO data based on the geographic coverage of satellite imagery, enabling geographic alignment between the label space and remote sensing feature space. In terms of model architecture, we adopt Swin Transformer Base as the backbone for satellite imagery, utilize the TabM network for tabular feature extraction, retain the Temporal Swin Transformer for time-series modeling, and employ a stackable serial tri-modal cross-attention mechanism to optimize the fusion of heterogeneous modalities. Furthermore, empirical analysis reveals significant geographic distribution shifts between PA training and test samples, and models trained by directly mixing PO and PA data tend to experience performance degradation due to label noise in PO data. To address this, we draw on the mixture-of-experts paradigm: test samples are partitioned according to their spatial proximity to PA samples, and different models trained on distinct datasets are used for inference and post-processing within each partition. Experiments on the GeoLifeCLEF 2025 dataset demonstrate that our approach achieves superior predictive performance in scenarios with limited PA coverage and pronounced distribution shifts.", "AI": {"tldr": "This paper tackles plant distribution prediction using a multimodal fusion framework that combines PA and PO data, leveraging their respective strengths to overcome challenges in label sparsity and noise.", "motivation": "To address challenges in large-scale plant distribution modeling caused by sparse and biased observational data.", "method": "The methodology involves using multimodal fusion, pseudo-label aggregation for PO data with geographic satellite alignment, advanced model architectures like Swin Transformers, and spatially-informed mixture-of-experts for inference.", "result": "Experiments on GeoLifeCLEF 2025 dataset show enhanced predictive performance, especially in scenarios with sparse PA coverage and distribution shifts.", "conclusion": "The proposed framework effectively integrates PA and PO data to tackle label noise and geographical distribution challenges, providing a robust solution for plant distribution prediction."}}
{"id": "2602.08062", "pdf": "https://arxiv.org/pdf/2602.08062", "abs": "https://arxiv.org/abs/2602.08062", "authors": ["Shayan Ali Hassan", "Tao Ni", "Zafar Ayyub Qazi", "Marco Canini"], "title": "Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, reasoning, and generation. However, these systems remain susceptible to malicious prompts that induce unsafe or policy-violating behavior through harmful requests, jailbreak techniques, and prompt injection attacks. Existing defenses face fundamental limitations: black-box moderation APIs offer limited transparency and adapt poorly to evolving threats, while white-box approaches using large LLM judges impose prohibitive computational costs and require expensive retraining for new attacks. Current systems force designers to choose between performance, efficiency, and adaptability.\n  To address these challenges, we present BAGEL (Bootstrap AGgregated Ensemble Layer), a modular, lightweight, and incrementally updatable framework for malicious prompt detection. BAGEL employs a bootstrap aggregation and mixture of expert inspired ensemble of fine-tuned models, each specialized on a different attack dataset. At inference, BAGEL uses a random forest router to identify the most suitable ensemble member, then applies stochastic selection to sample additional members for prediction aggregation. When new attacks emerge, BAGEL updates incrementally by fine-tuning a small prompt-safety classifier (86M parameters) and adding the resulting model to the ensemble. BAGEL achieves an F1 score of 0.92 by selecting just 5 ensemble members (430M parameters), outperforming OpenAI Moderation API and ShieldGemma which require billions of parameters. Performance remains robust after nine incremental updates, and BAGEL provides interpretability through its router's structural features. Our results show ensembles of small finetuned classifiers can match or exceed billion-parameter guardrails while offering the adaptability and efficiency required for production systems.", "AI": {"tldr": "The paper proposes BAGEL, a modular and efficient framework for detecting malicious prompts affecting large language models (LLMs), achieving high performance and adaptability with lower computational costs.", "motivation": "To address the challenges in ensuring safety and policy compliance for large language models (LLMs) while overcoming limitations of current defenses, such as inefficiency and lack of adaptability.", "method": "The authors developed BAGEL, a modular framework using a bootstrap aggregation ensemble of fine-tuned models, coupled with a random forest router for optimized member selection and incremental updates during new attack scenarios.", "result": "BAGEL achieves high efficiency with an F1 score of 0.92 using less computational power (430M parameters) compared to existing solutions, and maintains robustness after multiple updates.", "conclusion": "BAGEL demonstrates that lightweight, specialized ensembles can provide superior defense mechanisms for LLMs, ensuring adaptability, efficiency, and safety in production settings."}}
{"id": "2602.08194", "pdf": "https://arxiv.org/pdf/2602.08194", "abs": "https://arxiv.org/abs/2602.08194", "authors": ["Konstantinos Mitsides", "Maxence Faldor", "Antoine Cully"], "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages (main text), 90 pages total. Project page: https://konstantinosmitsides.github.io/dreaming-in-code", "summary": "Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a $16\\%$ improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.", "AI": {"tldr": "The paper introduces Dreaming in Code (DiCode), a framework that employs foundation models to generate executable environment code for progressive learning in open-ended environments, demonstrating significant improvements in agent competence.", "motivation": "The motivation is to address the challenge of enabling agents to discover sequences of experiences for consistent learning in complex, combinatorially vast open-ended worlds, where current methods often fall short of sustaining long-term progression.", "method": "The proposed framework, DiCode, leverages foundation models to generate code-level variations of environments (\"dreaming\") to create intermediate challenges. This scaffolds the agent's learning toward progressively advanced competencies in open-ended tasks.", "result": "When instantiated in the Craftax benchmark featuring rich mechanics and long horizons, DiCode achieved a 16% improvement in average returns over the best existing baseline, with measurable success in tasks requiring late-game combat competence where other approaches fail.", "conclusion": "Code-level environment design offers an effective means for creating structured curricula in open-ended worlds, bridging learning gaps and fostering the development of long-horizon skills in agents."}}
{"id": "2602.08309", "pdf": "https://arxiv.org/pdf/2602.08309", "abs": "https://arxiv.org/abs/2602.08309", "authors": ["Yunzuo Hu", "Wen Li", "Jing Zhang"], "title": "CAE-AV: Improving Audio-Visual Learning via Cross-modal Interactive Enrichment", "categories": ["cs.CV"], "comment": "13 pages, 8 figures", "summary": "Audio-visual learning suffers from modality misalignment caused by off-screen sources and background clutter, and current methods usually amplify irrelevant regions or moments, leading to unstable training and degraded representation quality. To address this challenge, we proposed a novel Caption-aligned and Agreement-guided Enhancement framework (CAE-AV) for audio-visual learning, which used two complementary modules: Cross-modal Agreement-guided Spatio-Temporal Enrichment (CASTE) and Caption-Aligned Saliency-guided Enrichment (CASE) to relieve audio-visual misalignment. CASTE dynamically balances spatial and temporal relations by evaluating frame-level audio-visual agreement, ensuring that key information is captured from both preceding and subsequent frames under misalignment. CASE injects cross-modal semantic guidance into selected spatio-temporal positions, leveraging high-level semantic cues to further alleviate misalignment. In addition, we design lightweight objectives, caption-to-modality InfoNCE, visual-audio consistency, and entropy regularization to guide token selection and strengthen cross-modal semantic alignment. With frozen backbones, CAE-AV achieves state-of-the-art performance on AVE, AVVP, AVS, and AVQA benchmarks, and qualitative analyses further validate its robustness against audio-visual misalignment.", "AI": {"tldr": "The paper introduces CAE-AV, a framework addressing misalignment issues in audio-visual learning using two key modules: CASTE and CASE. These modules enhance spatial-temporal relations and inject semantic guidance to boost alignment and performance on several benchmarks.", "motivation": "Current audio-visual learning approaches struggle with modality misalignment due to off-screen sources and background noise, resulting in unstable training and reduced representation quality.", "method": "The CAE-AV framework includes two complementary modules: CASTE focuses on dynamically balancing spatial and temporal audio-visual relations, while CASE employs cross-modal semantic guidance in spatio-temporal selections. Lightweight objectives like InfoNCE, visual-audio consistency, and entropy regularization further align modalities.", "result": "CAE-AV achieves state-of-the-art (SOTA) performance across multiple benchmarks (AVE, AVVP, AVS, and AVQA) and demonstrates robustness to misalignment issues through qualitative analyses.", "conclusion": "The proposed CAE-AV framework effectively mitigates audio-visual misalignment and consistently improves learning performance by strategically aligning and enriching critical spatio-temporal and semantic information."}}
{"id": "2602.08063", "pdf": "https://arxiv.org/pdf/2602.08063", "abs": "https://arxiv.org/abs/2602.08063", "authors": ["Eduardo Figueiredo", "Steven Adams", "Luca Laurenti"], "title": "Efficient Distribution Learning with Error Bounds in Wasserstein Distance", "categories": ["cs.LG"], "comment": null, "summary": "The Wasserstein distance has emerged as a key metric to quantify distances between probability distributions, with applications in various fields, including machine learning, control theory, decision theory, and biological systems. Consequently, learning an unknown distribution with non-asymptotic and easy-to-compute error bounds in Wasserstein distance has become a fundamental problem in many fields. In this paper, we devise a novel algorithmic and theoretical framework to approximate an unknown probability distribution $\\mathbb{P}$ from a finite set of samples by an approximate discrete distribution $\\widehat{\\mathbb{P}}$ while bounding the Wasserstein distance between $\\mathbb{P}$ and $\\widehat{\\mathbb{P}}$. Our framework leverages optimal transport, nonlinear optimization, and concentration inequalities. In particular, we show that, even if $\\mathbb{P}$ is unknown, the Wasserstein distance between $\\mathbb{P}$ and $\\widehat{\\mathbb{P}}$ can be efficiently bounded with high confidence by solving a tractable optimization problem (a mixed integer linear program) of a size that only depends on the size of the support of $\\widehat{\\mathbb{P}}$. This enables us to develop intelligent clustering algorithms to optimally find the support of $\\widehat{\\mathbb{P}}$ while minimizing the Wasserstein distance error. On a set of benchmarks, we demonstrate that our approach outperforms state-of-the-art comparable methods by generally returning approximating distributions with substantially smaller support and tighter error bounds.", "AI": {"tldr": "The paper addresses the problem of approximating unknown probability distributions using a novel framework that bounds the Wasserstein distance with high confidence via tractable optimization.", "motivation": "To solve the challenge of learning unknown probability distributions with efficient and non-asymptotic error bounds in contexts where the Wasserstein distance is crucial, such as machine learning and other fields.", "method": "The authors introduce a framework combining optimal transport, nonlinear optimization, and concentration inequalities. They propose solving a mixed integer linear program to bound the Wasserstein distance and develop clustering algorithms for support optimization.", "result": "The approach achieves better performance in terms of tighter error bounds and smaller support sets compared to state-of-the-art methods, evidenced by benchmark tests.", "conclusion": "The proposed framework provides an efficient and theoretically robust method for approximating unknown distributions using the Wasserstein distance, with potential applications across various domains."}}
{"id": "2602.08213", "pdf": "https://arxiv.org/pdf/2602.08213", "abs": "https://arxiv.org/abs/2602.08213", "authors": ["Haoran Liu", "Zheni Zeng", "Yukun Yan", "Yuxuan Chen", "Yunduo Xiao"], "title": "DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.QM"], "comment": null, "summary": "Molecule generation and optimization is a fundamental task in chemical domain. The rapid development of intelligent tools, especially large language models (LLMs) with powerful knowledge reserves and interactive capabilities, has provided new paradigms for it. Nevertheless, the intrinsic challenge for LLMs lies in the complex implicit relationship between molecular structure and pharmacological properties and the lack of corresponding labeled data. To bridge this gap, we propose DrugR, an LLM-based method that introduces explicit, step-by-step pharmacological reasoning into the optimization process. Our approach integrates domain-specific continual pretraining, supervised fine-tuning via reverse data engineering, and self-balanced multi-granular reinforcement learning. This framework enables DrugR to effectively improve key ADMET properties while preserving the original molecule's core efficacy. Experimental results demonstrate that DrugR achieves comprehensive enhancement across multiple properties without compromising structural similarity or target binding affinity. Importantly, its explicit reasoning process provides clear, interpretable rationales for each optimization step, yielding actionable design insights and advancing toward automated, knowledge-driven scientific discovery. Our code and model checkpoints are open-sourced to foster future research.", "AI": {"tldr": "DrugR is an LLM-based model developed to address molecule optimization challenges, explicitly incorporating pharmacological reasoning for improved molecule properties without compromising their efficacy.", "motivation": "Existing challenges in molecule generation stem from the complex relationships between molecular structures and properties, and the lack of labeled data. Large language models can assist but face intrinsic limitations.", "method": "DrugR combines domain-specific continual pretraining, supervised fine-tuning through reverse data engineering, and reinforcement learning, introducing explicit pharmacological reasoning into molecule optimization.", "result": "DrugR enhances ADMET properties while maintaining molecular structural similarity and binding affinity, demonstrating interpretability and actionable insights in optimization steps.", "conclusion": "DrugR advances automated, knowledge-driven scientific discovery in molecule optimization, offering an open-source framework for further development in the chemical domain."}}
{"id": "2602.08337", "pdf": "https://arxiv.org/pdf/2602.08337", "abs": "https://arxiv.org/abs/2602.08337", "authors": ["Sheng Yan", "Yong Wang", "Xin Du", "Junsong Yuan", "Mengyuan Liu"], "title": "Language-Guided Transformer Tokenizer for Human Motion Generation", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we focus on motion discrete tokenization, which converts raw motion into compact discrete tokens--a process proven crucial for efficient motion generation. In this paradigm, increasing the number of tokens is a common approach to improving motion reconstruction quality, but more tokens make it more difficult for generative models to learn. To maintain high reconstruction quality while reducing generation complexity, we propose leveraging language to achieve efficient motion tokenization, which we term Language-Guided Tokenization (LG-Tok). LG-Tok aligns natural language with motion at the tokenization stage, yielding compact, high-level semantic representations. This approach not only strengthens both tokenization and detokenization but also simplifies the learning of generative models. Furthermore, existing tokenizers predominantly adopt convolutional architectures, whose local receptive fields struggle to support global language guidance. To this end, we propose a Transformer-based Tokenizer that leverages attention mechanisms to enable effective alignment between language and motion. Additionally, we design a language-drop scheme, in which language conditions are randomly removed during training, enabling the detokenizer to support language-free guidance during generation. On the HumanML3D and Motion-X generation benchmarks, LG-Tok achieves Top-1 scores of 0.542 and 0.582, outperforming state-of-the-art methods (MARDM: 0.500 and 0.528), and with FID scores of 0.057 and 0.088, respectively, versus 0.114 and 0.147. LG-Tok-mini uses only half the tokens while maintaining competitive performance (Top-1: 0.521/0.588, FID: 0.085/0.071), validating the efficiency of our semantic representations.", "AI": {"tldr": "This paper introduces Language-Guided Tokenization (LG-Tok), a method to improve motion tokenization using language alignment and achieving stronger efficiency and performance in motion generation tasks.", "motivation": "The study aims to address the complexity of learning in generative models caused by increased motion tokenization, while maintaining high-quality motion reconstruction.", "method": "The authors propose LG-Tok, aligning language and motion during tokenization, leveraging a Transformer-based tokenizer and a language-drop scheme for flexible language-free guidance.", "result": "On HumanML3D and Motion-X benchmarks, LG-Tok outperforms state-of-the-art methods with Top-1 and FID scores, demonstrating both improved performance and token efficiency.", "conclusion": "LG-Tok effectively combines language guidance with compact tokenization to advance motion generation, achieving strong performance while reducing generation complexity."}}
{"id": "2602.07039", "pdf": "https://arxiv.org/pdf/2602.07039", "abs": "https://arxiv.org/abs/2602.07039", "authors": ["Heimo M\u00fcller"], "title": "When Excellence Stops Producing Knowledge: A Practitioner's Observation on Research Funding", "categories": ["cs.CY", "cs.AI", "cs.DL"], "comment": null, "summary": "After almost four decades of participating in competitive research funding -- as applicant, coordinator, evaluator, and panel member -- I have come to see a structural paradox: many participants recognize that the current system is approaching its functional limits, yet most reform measures intensify rather than alleviate the underlying dynamics. This paper documents how excellence has become decoupled from knowledge production through an increasing coupling to representability under evaluation. The discussion focuses on two domains in which this is particularly visible: competitive basic research funding and large EU consortium projects. Three accelerating trends are examined: the professionalization of proposal writing through specialized consultants, the rise of AI-assisted applications, and an evaluator shortage that forces panels to rely on reviewers increasingly distant from the actual research domains. These observations are offered not as external critique but as an insider account, in the hope that naming a widely experienced but rarely articulated pattern may enable more constructive orientation.\n  Keywords: Research funding, Excellence, Evaluation, Goodhart's Law, Professionalization, AI-assisted proposals, Peer review crisis", "AI": {"tldr": "The paper discusses a structural paradox in competitive research funding, outlining how excellence in research has shifted towards being tied to representability under evaluation standards instead of genuine knowledge production.", "motivation": "The motivation lies in addressing the growing dissatisfaction among participants in research funding systems which no longer effectively serve their intended function due to systemic flaws, notably in evaluation practices.", "method": "The author examines trends in two domains\u2014competitive basic research funding and large EU consortium projects\u2014focusing on professionalized proposal writing, the use of AI in applications, and evaluator shortages.", "result": "The analysis reveals three trends: reliance on specialized consultants, increased use of AI in proposals, and a shortage of domain-specific reviewers, highlighting systemic problems that hinder knowledge production.", "conclusion": "Structural changes are necessary to align research excellence more closely with actual knowledge production rather than representability in evaluations. The paper calls for addressing these flaws to enable constructive improvements."}}
{"id": "2602.08342", "pdf": "https://arxiv.org/pdf/2602.08342", "abs": "https://arxiv.org/abs/2602.08342", "authors": ["Jie Zhang", "Xingtong Yu", "Yuan Fang", "Rudi Stouffs", "Zdravko Trivic"], "title": "UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Learning transferable multimodal embeddings for urban environments is challenging because urban understanding is inherently spatial, yet existing datasets and benchmarks lack explicit alignment between street-view images and urban structure. We introduce UGData, a spatially grounded dataset that anchors street-view images to structured spatial graphs and provides graph-aligned supervision via spatial reasoning paths and spatial context captions, exposing distance, directionality, connectivity, and neighborhood context beyond image content. Building on UGData, we propose UGE, a two-stage training strategy that progressively and stably aligns images, text, and spatial structures by combining instruction-guided contrastive learning with graph-based spatial encoding. We finally introduce UGBench, a comprehensive benchmark to evaluate how spatially grounded embeddings support diverse urban understanding tasks -- including geolocation ranking, image retrieval, urban perception, and spatial grounding. We develop UGE on multiple state-of-the-art VLM backbones, including Qwen2-VL, Qwen2.5-VL, Phi-3-Vision, and LLaVA1.6-Mistral, and train fixed-dimensional spatial embeddings with LoRA tuning. UGE built upon Qwen2.5-VL-7B backbone achieves up to 44% improvement in image retrieval and 30% in geolocation ranking on training cities, and over 30% and 22% gains respectively on held-out cities, demonstrating the effectiveness of explicit spatial grounding for spatially intensive urban tasks.", "AI": {"tldr": "The paper introduces UGData and UGE frameworks to create spatially grounded embeddings to enhance urban understanding tasks, such as geolocation ranking and image retrieval, achieving significant performance improvements.", "motivation": "The motivation is to address the challenge of learning multimodal embeddings that effectively represent urban environments by explicitly aligning street-view images with their spatial structures, which existing datasets lack.", "method": "The proposed method involves UGData for graph-aligned data and UGE, a two-stage training strategy using instruction-guided contrastive learning and graph-based spatial encoding.", "result": "UGE achieves up to 44% improvement in image retrieval and 30% in geolocation ranking on training cities, and significant gains in held-out cities, validating its reliability in spatially intensive tasks.", "conclusion": "Explicitly grounding embeddings in spatial graphs significantly enhances performance on urban environment tasks, proving the effectiveness of the UGData and UGE frameworks."}}
{"id": "2602.08067", "pdf": "https://arxiv.org/pdf/2602.08067", "abs": "https://arxiv.org/abs/2602.08067", "authors": ["Chenglei Shen", "Yi Zhan", "Weijie Yu", "Xiao Zhang", "Jun Xu"], "title": "Enhancing Bandit Algorithms with LLMs for Time-varying User Preferences in Streaming Recommendations", "categories": ["cs.LG"], "comment": null, "summary": "In real-world streaming recommender systems, user preferences evolve dynamically over time. Existing bandit-based methods treat time merely as a timestamp, neglecting its explicit relationship with user preferences and leading to suboptimal performance. Moreover, online learning methods often suffer from inefficient exploration-exploitation during the early online phase. To address these issues, we propose HyperBandit+, a novel contextual bandit policy that integrates a time-aware hypernetwork to adapt to time-varying user preferences and employs a large language model-assisted warm-start mechanism (LLM Start) to enhance exploration-exploitation efficiency in the early online phase. Specifically, HyperBandit+ leverages a neural network that takes time features as input and generates parameters for estimating time-varying rewards by capturing the correlation between time and user preferences. Additionally, the LLM Start mechanism employs multi-step data augmentation to simulate realistic interaction data for effective offline learning, providing warm-start parameters for the bandit policy in the early online phase. To meet real-time streaming recommendation demands, we adopt low-rank factorization to reduce hypernetwork training complexity. Theoretically, we rigorously establish a sublinear regret upper bound that accounts for both the hypernetwork and the LLM warm-start mechanism. Extensive experiments on real-world datasets demonstrate that HyperBandit+ consistently outperforms state-of-the-art baselines in terms of accumulated rewards.", "AI": {"tldr": "The study introduces HyperBandit+, a contextual bandit policy for streaming recommendation systems that acknowledges time's effect on user preferences and improves early phase exploration with a large language model-assisted warm-start mechanism.", "motivation": "Existing bandit-based recommender systems fail to explicitly account for the evolving relationship between time and user preferences, resulting in less effective recommendations. Moreover, current methods struggle with inefficient exploration-exploitation strategies during early online phases.", "method": "HyperBandit+ employs a time-aware hypernetwork that contextualizes time as a feature to dynamically capture its effect on user preferences. It also incorporates an LLM-assisted warm-start mechanism for data augmentation and offline learning, enabling better performance in early online phases. A low-rank factorization technique is used to optimize training times.", "result": "Experiments on real-world datasets show that HyperBandit+ achieves better accumulated rewards compared to state-of-the-art methods, validating the efficacy of its time-aware hypernetwork and LLM-based warm-start approach.", "conclusion": "HyperBandit+ effectively enhances streaming recommendation systems by addressing user preference evolution over time and improving early exploration-exploitation dynamics, achieving strong empirical results and theoretical guarantees on performance."}}
{"id": "2602.08346", "pdf": "https://arxiv.org/pdf/2602.08346", "abs": "https://arxiv.org/abs/2602.08346", "authors": ["Yujin Zhou", "Pengcheng Wen", "Jiale Chen", "Boqin Yin", "Han Zhu", "Jiaming Ji", "Juntao Dai", "Chi-Min Chan", "Sirui Han"], "title": "What, Whether and How? Unveiling Process Reward Models for Thinking with Images Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of Large Vision Language Models (LVLMs) has demonstrated excellent abilities in various visual tasks. Building upon these developments, the thinking with images paradigm has emerged, enabling models to dynamically edit and re-encode visual information at each reasoning step, mirroring human visual processing. However, this paradigm introduces significant challenges as diverse errors may occur during reasoning processes. This necessitates Process Reward Models (PRMs) for distinguishing positive and negative reasoning steps, yet existing benchmarks for PRMs are predominantly text-centric and lack comprehensive assessment under this paradigm. To address these gaps, this work introduces the first comprehensive benchmark specifically designed for evaluating PRMs under the thinking with images paradigm. Our main contributions are: (1) Through extensive analysis of reasoning trajectories and guided search experiments with PRMs, we define 7 fine-grained error types and demonstrate both the necessity for specialized PRMs and the potential for improvement. (2) We construct a comprehensive benchmark comprising 1,206 manually annotated thinking with images reasoning trajectories spanning 4 categories and 16 subcategories for fine-grained evaluation of PRMs. (3) Our experimental analysis reveals that current LVLMs fall short as effective PRMs, exhibiting limited capabilities in visual reasoning process evaluation with significant performance disparities across error types, positive evaluation bias, and sensitivity to reasoning step positions. These findings demonstrate the effectiveness of our benchmark and establish crucial foundations for advancing PRMs in LVLMs.", "AI": {"tldr": "This work introduces a benchmark for evaluating Process Reward Models (PRMs) in Large Vision Language Models under the thinking with images paradigm to address diverse reasoning errors.", "motivation": "The study aims to address the challenges in reasoning errors introduced by the thinking with images paradigm in Large Vision Language Models.", "method": "The authors define fine-grained error types, manually annotate reasoning trajectories, and construct a benchmark for assessing PRM performance across diverse error categories.", "result": "Current LVLMs show limitations in evaluating visual reasoning processes, biased evaluations, and significant performance disparities across error types.", "conclusion": "The benchmark highlights the need for specialized PRMs and establishes foundational insights to improve visual reasoning evaluation in LVLMs."}}
{"id": "2602.08077", "pdf": "https://arxiv.org/pdf/2602.08077", "abs": "https://arxiv.org/abs/2602.08077", "authors": ["Sayantan Kumar", "Peijie Qiu", "Aristeidis Sotiras"], "title": "Multimodal normative modeling in Alzheimers Disease with introspective variational autoencoders", "categories": ["cs.LG", "cs.AI"], "comment": "Conference on Health, Inference, and Learning (CHIL)", "summary": "Normative modeling learns a healthy reference distribution and quantifies subject-specific deviations to capture heterogeneous disease effects. In Alzheimers disease (AD), multimodal neuroimaging offers complementary signals but VAE-based normative models often (i) fit the healthy reference distribution imperfectly, inflating false positives, and (ii) use posterior aggregation (e.g., PoE/MoE) that can yield weak multimodal fusion in the shared latent space. We propose mmSIVAE, a multimodal soft-introspective variational autoencoder combined with Mixture-of-Product-of-Experts (MOPOE) aggregation to improve reference fidelity and multimodal integration. We compute deviation scores in latent space and feature space as distances from the learned healthy distributions, and map statistically significant latent deviations to regional abnormalities for interpretability. On ADNI MRI regional volumes and amyloid PET SUVR, mmSIVAE improves reconstruction on held-out controls and produces more discriminative deviation scores for outlier detection than VAE baselines, with higher likelihood ratios and clearer separation between control and AD-spectrum cohorts. Deviation maps highlight region-level patterns aligned with established AD-related changes. More broadly, our results highlight the importance of training objectives that prioritize reference-distribution fidelity and robust multimodal posterior aggregation for normative modeling, with implications for deviation-based analysis across multimodal clinical data.", "AI": {"tldr": "The paper introduces mmSIVAE, a soft-introspective VAE model optimized for multimodal neuroimaging in Alzheimer's disease, offering better integration and improved performance in detecting outliers.", "motivation": "To address limitations of traditional VAE-based models in normative modeling for Alzheimer's disease, specifically their imperfect healthy reference distribution fitting and weak multimodal fusion.", "method": "Proposed mmSIVAE combines soft-introspective VAEs with Mixture-of-Product-of-Experts (MOPOE) for improved multimodal integration and fidelity to a healthy reference distribution.", "result": "mmSIVAE demonstrates better performance on reconstruction accuracy, outlier detection, and regional deviation mapping as compared to standard VAE baselines using multimodal data like MRI and PET.", "conclusion": "Highlighting the need for improved training objectives prioritizing both healthy reference distribution fidelity and robust multimodal posterior aggregation for normative modeling in clinical contexts."}}
{"id": "2602.08343", "pdf": "https://arxiv.org/pdf/2602.08343", "abs": "https://arxiv.org/abs/2602.08343", "authors": ["Debajyoti Datta", "Trishala Neeraj", "Bibek Paudel", "Vyom Sharma", "Subhabrata Mukherjee"], "title": "ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "18 pages, 5 figures, 18 tables", "summary": "Long-context inference is constrained by KV-cache memory, which grows linearly with sequence length; KV-cache compression therefore hinges on reliably selecting which past tokens to retain. Most geometry-based eviction methods score keys by cosine similarity to a global centroid, but cosine is scale-invariant and can discard magnitude cues that distinguish semantically salient tokens. We propose ManifoldKV, a training-free scorer that ranks tokens by Euclidean distance to the key centroid, capturing both angular and radial deviations.\n  On the RULER benchmark, ManifoldKV achieves 95.7% accuracy at 4K-16K contexts with 20% compression; matching the best geometric baseline while improving robustness in two regimes where cosine scoring fails. First, on multi-key retrieval, ManifoldKV reduces directional collisions, achieving 92.4% vs KeyDiff's 77.0% (+15.4 points) on 3-key NIAH at 50% compression. Second, to address dilution and performance collapse of global centroids at 64K context, we introduce WindowedManifoldKV, which restores accuracy to 84.3% at 25% compression, a 49-point recovery over global L2 and +3.2 points over KeyDiff. The method requires only 3 lines of code and works across 4 architectures without tuning.", "AI": {"tldr": "The paper proposes training-free methods, ManifoldKV and WindowedManifoldKV, to improve KV-cache compression in long-context inference, achieving higher accuracy and robustness than existing geometry-based techniques.", "motivation": "Long-context inference faces scalability issues due to KV-cache memory growth. Addressing this requires effective and efficient techniques for selecting past tokens to retain during compression, as existing methods have limitations like directional collisions and performance collapse.", "method": "The paper introduces ManifoldKV, which ranks tokens based on their Euclidean distance to a key centroid, incorporating both angular and radial deviations. Additionally, WindowedManifoldKV applies local centroids in long contexts to improve robustness.", "result": "ManifoldKV achieves 95.7% accuracy on the RULER benchmark with 20% compression, excelling in multi-key retrieval and handling long contexts. WindowedManifoldKV further recovers accuracy in extended contexts, surpassing previous methods.", "conclusion": "The proposed ManifoldKV and WindowedManifoldKV methods are robust, effective, and adaptable across architectures with minimal implementation effort, improving long-context inference capabilities."}}
