{"id": "2507.07683", "pdf": "https://arxiv.org/pdf/2507.07683", "abs": "https://arxiv.org/abs/2507.07683", "authors": ["Jude Haris", "Jos\u00e9 Cano"], "title": "Accelerating Transposed Convolutions on FPGA-based Edge Devices", "categories": ["cs.AR", "cs.DC", "cs.LG"], "comment": "Accepted to 35th International Conference on Field-Programmable Logic\n  and Applications (FPL) 2025", "summary": "Transposed Convolutions (TCONV) enable the up-scaling mechanism within\ngenerative Artificial Intelligence (AI) models. However, the predominant\nInput-Oriented Mapping (IOM) method for implementing TCONV has complex output\nmapping, overlapping sums, and ineffectual computations. These inefficiencies\nfurther exacerbate the performance bottleneck of TCONV and generative models on\nresource-constrained edge devices. To address this problem, in this paper we\npropose MM2IM, a hardware-software co-designed accelerator that combines Matrix\nMultiplication (MatMul) with col2IM to process TCONV layers on\nresource-constrained edge devices efficiently. Using the SECDA-TFLite design\ntoolkit, we implement MM2IM and evaluate its performance across 261 TCONV\nproblem configurations, achieving an average speedup of 1.9x against a\ndual-thread ARM Neon optimized CPU baseline. We then evaluate the performance\nof MM2IM on a range of TCONV layers from well-known generative models achieving\nup to 4.2x speedup, and compare it against similar resource-constrained TCONV\naccelerators, outperforming them by at least 2x GOPs/DSP. Finally, we evaluate\nMM2IM on the DCGAN and pix2pix GAN models, achieving up to 3x speedup and 2.4x\nenergy reduction against the CPU baseline.", "AI": {"tldr": "The paper proposes MM2IM, a hardware-software co-designed accelerator for optimizing Transposed Convolutions (TCONV) on edge devices, demonstrating substantial performance and energy efficiency improvements.", "motivation": "Current methods for implementing TCONV have inefficiencies like complex mapping, overlapping sums, and unused computations, causing a bottleneck in generative AI models, especially on resource-limited edge devices.", "method": "The authors propose MM2IM, which uses hardware-software co-design to combine Matrix Multiplication (MatMul) with col2IM for efficient TCONV processing. They implemented MM2IM using the SECDA-TFLite toolkit.", "result": "MM2IM achieved a 1.9x average speedup across 261 TCONV configurations, up to 4.2x speedup on TCONV layers from generative models, and outperformed similar accelerators by at least 2x GOPs/DSP. Additionally, it sped up DCGAN and pix2pix GAN models by up to 3x and reduced energy usage by 2.4x against a CPU baseline.", "conclusion": "MM2IM effectively addresses TCONV inefficiencies for edge devices, improving speed and energy efficiency, and outperforms existing solutions in resource-constrained settings."}}
{"id": "2507.07223", "pdf": "https://arxiv.org/pdf/2507.07223", "abs": "https://arxiv.org/abs/2507.07223", "authors": ["Myoungsoo Jung"], "title": "Compute Can't Handle the Truth: Why Communication Tax Prioritizes Memory and Interconnects in Modern AI Infrastructure", "categories": ["cs.DC", "cs.AR", "B.4.3; C.0; C.2.1; C.2.2"], "comment": null, "summary": "Modern AI workloads such as large language models (LLMs) and\nretrieval-augmented generation (RAG) impose severe demands on memory,\ncommunication bandwidth, and resource flexibility. Traditional GPU-centric\narchitectures struggle to scale due to growing inter-GPU communication\noverheads. This report introduces key AI concepts and explains how Transformers\nrevolutionized data representation in LLMs. We analyze large-scale AI hardware\nand data center designs, identifying scalability bottlenecks in hierarchical\nsystems. To address these, we propose a modular data center architecture based\non Compute Express Link (CXL) that enables disaggregated scaling of memory,\ncompute, and accelerators. We further explore accelerator-optimized\ninterconnects-collectively termed XLink (e.g., UALink, NVLink, NVLink\nFusion)-and introduce a hybrid CXL-over-XLink design to reduce long-distance\ndata transfers while preserving memory coherence. We also propose a\nhierarchical memory model that combines local and pooled memory, and evaluate\nlightweight CXL implementations, HBM, and silicon photonics for efficient\nscaling. Our evaluations demonstrate improved scalability, throughput, and\nflexibility in AI infrastructure.", "AI": {"tldr": "The paper identifies memory and communication bottlenecks in AI systems like LLMs and proposes a modular architecture using CXL and XLink for improved scalability, throughput, and flexibility.", "motivation": "AI models like LLMs and RAG demand high memory, bandwidth, and scalability, which current GPU-centric architectures fail to handle efficiently.", "method": "The authors propose a modular data center architecture utilizing Compute Express Link (CXL) with hybrid CXL-over-XLink interconnects, hierarchical memory models, and lightweight implementations for scalability.", "result": "The proposed architecture shows enhancements in scalability, throughput, and flexibility through evaluations.", "conclusion": "Addressing the demands of modern AI workloads requires innovative hardware solutions like modular architectures to overcome GPU-centric limitations and communication bottlenecks."}}
{"id": "2507.07284", "pdf": "https://arxiv.org/pdf/2507.07284", "abs": "https://arxiv.org/abs/2507.07284", "authors": ["Andrew Fan", "Simon D. Levy"], "title": "A Robust, Open-Source Framework for Spiking Neural Networks on Low-End FPGAs", "categories": ["cs.NE"], "comment": null, "summary": "As the demand for compute power in traditional neural networks has increased\nsignificantly, spiking neural networks (SNNs) have emerged as a potential\nsolution to increasingly power-hungry neural networks. By operating on 0/1\nspikes emitted by neurons instead of arithmetic multiply-and-accumulate\noperations, SNNs propagate information temporally and spatially, allowing for\nmore efficient compute power. To this end, many architectures for accelerating\nand simulating SNNs have been developed, including Loihi, TrueNorth, and\nSpiNNaker. However, these chips are largely inaccessible to the wider\ncommunity. Field programmable gate arrays (FPGAs) have been explored to serve\nas a middle ground between neuromorphic and non-neuromorphic hardware, but many\nproposed architectures require expensive high-end FPGAs or target a single SNN\ntopology. This paper presents a framework consisting of a robust SNN\nacceleration architecture and a Pytorch-based SNN model compiler. Targeting\nany-to-any and/or fully connected SNNs, the FPGA architecture features a\nsynaptic array that tiles across the SNN to propagate spikes. The architecture\ntargets low-end FPGAs and requires very little (6358 LUT, 40.5 BRAM) resources.\nThe framework, tested on a low-end Xilinx Artix-7 FPGA at 100 MHz, achieves\ncompetitive speed in recognizing MNIST digits (0.52 ms/img). Further\nexperiments also show accurate simulation of hand coded any-to-any spiking\nneural networks on toy problems. All code and setup instructions are available\nat\nhttps://github.com/im-afan/snn-fpga}{\\texttt{https://github.com/im-afan/snn-fpga.", "AI": {"tldr": "This paper introduces an efficient framework for accelerating Spiking Neural Networks (SNNs) on low-end FPGAs and demonstrates its competitive performance with minimal resource usage.", "motivation": "With the growing computational demands of traditional neural networks, SNNs offer an energy-efficient alternative. However, existing neuromorphic hardware is largely inaccessible, and FPGA-based implementations often require expensive hardware or restrict flexibility in network topology.", "method": "The paper presents a two-part framework: first, a robust SNN acceleration architecture targeting low-end FPGAs, featuring a scalable synaptic array; second, a Pytorch-based compiler for SNN models. The design minimizes resource usage (6358 LUT, 40.5 BRAM) and supports any-to-any and fully connected topologies.", "result": "The framework was implemented and tested on a low-end Xilinx Artix-7 FPGA running at 100 MHz. It achieved competitive performance in tasks like MNIST digit recognition (0.52 ms/img) and demonstrated accurate simulation for other toy SNN problems.", "conclusion": "The proposed framework offers an accessible, resource-efficient, and flexible solution for SNN acceleration on low-end FPGAs, enabling wider community adoption and practical applications. Code and setup instructions make the work easily reproducible."}}
{"id": "2507.07115", "pdf": "https://arxiv.org/pdf/2507.07115", "abs": "https://arxiv.org/abs/2507.07115", "authors": ["Javal Vyas", "Mehmet Mercangoz"], "title": "Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "The increasing complexity of modern chemical processes, coupled with\nworkforce shortages and intricate fault scenarios, demands novel automation\nparadigms that blend symbolic reasoning with adaptive control. In this work, we\nintroduce a unified agentic framework that leverages large language models\n(LLMs) for both discrete fault-recovery planning and continuous process control\nwithin a single architecture. We adopt Finite State Machines (FSMs) as\ninterpretable operating envelopes: an LLM-driven planning agent proposes\nrecovery sequences through the FSM, a Simulation Agent executes and checks each\ntransition, and a Validator-Reprompting loop iteratively refines invalid plans.\nIn Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25\nstates, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path\nsuccess within five reprompts-outperforming open-source LLMs in both accuracy\nand latency. In Case Study 2, the same framework modulates dual-heater inputs\non a laboratory TCLab platform (and its digital twin) to maintain a target\naverage temperature under persistent asymmetric disturbances. Compared to\nclassical PID control, our LLM-based controller attains similar performance,\nwhile ablation of the prompting loop reveals its critical role in handling\nnonlinear dynamics. We analyze key failure modes-such as instruction following\nlapses and coarse ODE approximations. Our results demonstrate that, with\nstructured feedback and modular agents, LLMs can unify high-level symbolic\nplanningand low-level continuous control, paving the way towards resilient,\nlanguage-driven automation in chemical engineering.", "AI": {"tldr": "This paper develops an LLM-based framework that integrates symbolic reasoning and adaptive control for fault recovery and process management in chemical processes.", "motivation": "Modern chemical processes are increasingly complex and face workforce shortages and intricate fault scenarios, necessitating advanced automation methods.", "method": "The authors propose an agentic framework using FSMs, where LLMs handle fault recovery planning and process control. The architecture includes planning agents, simulation agents, and a Validator-Reprompting loop to refine plans.", "result": "In tests with 180 randomly generated FSMs, GPT-4 variants outperformed other LLMs in accuracy and latency, achieving 100% valid-path success. Additionally, the framework performed competitively against PID controllers in modulating heater inputs under disturbances.", "conclusion": "Structured feedback and modular agents enable LLMs to unify high-level planning with low-level control, presenting a resilient automation approach for chemical engineering challenges."}}
{"id": "2507.07114", "pdf": "https://arxiv.org/pdf/2507.07114", "abs": "https://arxiv.org/abs/2507.07114", "authors": ["Erez Weintraub", "Ron Banner", "Ariel Orda"], "title": "Distributed Training under Packet Loss", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "State-of-the-art language and vision models are routinely trained across\nthousands of GPUs, often spanning multiple data-centers, yet today's\ndistributed frameworks still assume reliable connections (e.g., InfiniBand or\nRoCE). The resulting acknowledgment traffic and retransmissions inflate tail\nlatencies and limit scalability. Leveraging unreliable connections will reduce\nlatency but may sacrifice model accuracy and convergence once packets are\ndropped. A principled, end-to-end solution that preserves accuracy and\nconvergence guarantees under genuine packet loss has previously been missing.\nWe address this critical gap by introducing a novel distributed training\nframework capable of operating over unreliable connections, offering unbiased\ngradient aggregation and bounded parameter drift without modifying model code\nor optimizers. The key insight is a two-stage defense against missing messages:\n(i) Unbiased gradient aggregation: each worker reconstructs a consistent\ngradient estimate from whatever packets arrive, guaranteeing expectation-level\ncorrectness; and (ii) Bounded-drift parameter broadcasts: we prove the\ninter-worker model discrepancy remains O(1) even after arbitrarily many\niterations, preventing the unbounded divergence typical of asynchronous setups.\nAnalytical bounds are matched by experiments on the LLAMA2 7B model with 64\nGPUs: tolerating 10% random packet loss yields at most 0.8% perplexity change.\nThis work bridges the gap between communication-efficient datacenter protocols\nand the accuracy and generalization guarantees demanded by modern large-model\ntraining, enabling robust, high-throughput learning on commodity or wide-area\nnetworks.", "AI": {"tldr": "The paper introduces a distributed training framework for language and vision models that works over unreliable network connections while preserving model accuracy and convergence guarantees.", "motivation": "Distributed training frameworks often rely on reliable connections, but this assumption inflates latency and limits scalability. A need for a principled solution that handles genuine packet loss without compromising accuracy and convergence was not addressed in the existing frameworks.", "method": "The framework uses a two-stage approach: (1) unbiased gradient aggregation where each worker reconstructs consistent gradient estimates from available packets, and (2) bounded-drift parameter broadcasts that limit inter-worker model discrepancy to O(1) even after numerous iterations.", "result": "Tests on the LLAMA2 7B model with 64 GPUs showed that the framework could handle 10% random packet loss with only a 0.8% perplexity change, demonstrating analytical bounds' practical applicability.", "conclusion": "The proposed framework bridges the gap between datacenter communication efficiency and the accuracy demands of large-model training, facilitating robust learning on less reliable or commodity networks."}}
{"id": "2507.07480", "pdf": "https://arxiv.org/pdf/2507.07480", "abs": "https://arxiv.org/abs/2507.07480", "authors": ["Tobias Kapp\u00e9"], "title": "On Propositional Program Equivalence (extended abstract)", "categories": ["cs.PL"], "comment": null, "summary": "General program equivalence is undecidable. However, if we abstract away the\nsemantics of statements, then this problem becomes not just decidable, but\npractically feasible. For instance, a program of the form \"if $b$ then $e$ else\n$f$\" should be equivalent to \"if not $b$ then $f$ else $e$\" - no matter what\n$b$, $e$ and $f$ are. This kind of equivalence is known as propositional\nequivalence. In this extended abstract, we discuss recent developments in\npropositional program equivalence from the perspective of (Guarded) Kleene\nAlgebra with Tests, or (G)KAT.", "AI": {"tldr": "The paper discusses propositional equivalence in programming, focusing on recent advancements in Guarded Kleene Algebra with Tests (G-KAT).", "motivation": "General program equivalence is undecidable in its complete semantics, posing challenges in comparing programs effectively.", "method": "The study employs abstractions using Guarded Kleene Algebra with Tests (G-KAT) to analyze propositional equivalence in programs.", "result": "Propositional equivalence, which abstracts semantics, is shown to be decidable and feasible.", "conclusion": "By using G-KAT, propositional program equivalence becomes tractable, offering insights into program analysis independent of detailed semantics."}}
{"id": "2507.07325", "pdf": "https://arxiv.org/pdf/2507.07325", "abs": "https://arxiv.org/abs/2507.07325", "authors": ["Martin Obaidi", "Marc Herrmann", "Elisa Schmid", "Raymond Ochsner", "Kurt Schneider", "Jil Kl\u00fcnder"], "title": "A German Gold-Standard Dataset for Sentiment Analysis in Software Engineering", "categories": ["cs.SE"], "comment": "This paper has been accepted at the 33rd IEEE International\n  Requirements Engineering Workshop (REW 2025)", "summary": "Sentiment analysis is an essential technique for investigating the emotional\nclimate within developer teams, contributing to both team productivity and\nproject success. Existing sentiment analysis tools in software engineering\nprimarily rely on English or non-German gold-standard datasets. To address this\ngap, our work introduces a German dataset of 5,949 unique developer statements,\nextracted from the German developer forum Android-Hilfe.de. Each statement was\nannotated with one of six basic emotions, based on the emotion model by Shaver\net al., by four German-speaking computer science students. Evaluation of the\nannotation process showed high interrater agreement and reliability. These\nresults indicate that the dataset is sufficiently valid and robust to support\nsentiment analysis in the German-speaking software engineering community.\nEvaluation with existing German sentiment analysis tools confirms the lack of\ndomain-specific solutions for software engineering. We also discuss approaches\nto optimize annotation and present further use cases for the dataset.", "AI": {"tldr": "The paper introduces a robust German dataset for sentiment analysis tailored to software engineering, validated through high interrater agreement and domain-specific evaluations.", "motivation": "Existing sentiment analysis tools largely cater to English datasets, leaving a gap for German-speaking software engineering communities.", "method": "Developed a dataset of 5,949 unique statements from a German developer forum, annotated with one of six basic emotions by four linguistically compatible annotators to ensure high validity.", "result": "Achieved high interrater agreement in annotation, confirming the dataset\u2019s reliability. Evaluation with current tools highlighted the lack of domain-specific solutions for German sentiment analysis.", "conclusion": "The dataset robustly supports sentiment analysis in German-speaking software development, highlighting the need for optimized tools and broader application opportunities."}}
{"id": "2507.07142", "pdf": "https://arxiv.org/pdf/2507.07142", "abs": "https://arxiv.org/abs/2507.07142", "authors": ["Quanjie Qiu", "MengCheng Lau"], "title": "g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM", "categories": ["cs.RO"], "comment": null, "summary": "This article presents a comparative analysis of g2o and Ceres solvers in\nenhancing scan matching performance within the Cartographer framework.\nCartographer, a widely-used library for Simultaneous Localization and Mapping\n(SLAM), relies on optimization algorithms to refine pose estimates and improve\nmap accuracy. The research aims to evaluate the performance, efficiency, and\naccuracy of the g2o solver in comparison to the Ceres solver, which is the\ndefault in Cartographer. In our experiments comparing Ceres and g2o within\nCartographer, Ceres outperformed g2o in terms of speed, convergence efficiency,\nand overall map clarity. Ceres required fewer iterations and less time to\nconverge, producing more accurate and well-defined maps, especially in\nreal-world mapping scenarios with the AgileX LIMO robot. However, g2o excelled\nin localized obstacle detection, highlighting its value in specific situations.", "AI": {"tldr": "This paper evaluates and compares g2o and Ceres solvers for SLAM performance in the Cartographer framework, demonstrating Ceres as superior in speed and map accuracy, while g2o excels in obstacle detection.", "motivation": "The study aims to determine the relative strengths and weaknesses of g2o and Ceres solvers within the SLAM-focused Cartographer framework to improve mapping performance.", "method": "Comparative experiments were conducted using the AgileX LIMO robot in real-world environments, measuring the speed, convergence efficiency, and mapping clarity of g2o versus Ceres solvers.", "result": "Ceres outperformed g2o in speed, efficiency of convergence, and map accuracy. Conversely, g2o performed better in detecting localized obstacles.", "conclusion": "Despite g2o\u2019s strengths in specific tasks, Ceres is the more efficient and accurate choice for most SLAM mapping scenarios."}}
{"id": "2507.07186", "pdf": "https://arxiv.org/pdf/2507.07186", "abs": "https://arxiv.org/abs/2507.07186", "authors": ["Itay Itzhak", "Yonatan Belinkov", "Gabriel Stanovsky"], "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "CoLM 2025", "summary": "Large language models (LLMs) exhibit cognitive biases -- systematic\ntendencies of irrational decision-making, similar to those seen in humans.\nPrior work has found that these biases vary across models and can be amplified\nby instruction tuning. However, it remains unclear if these differences in\nbiases stem from pretraining, finetuning, or even random noise due to training\nstochasticity. We propose a two-step causal experimental approach to\ndisentangle these factors. First, we finetune models multiple times using\ndifferent random seeds to study how training randomness affects over $30$\ncognitive biases. Second, we introduce \\emph{cross-tuning} -- swapping\ninstruction datasets between models to isolate bias sources. This swap uses\ndatasets that led to different bias patterns, directly testing whether biases\nare dataset-dependent. Our findings reveal that while training randomness\nintroduces some variability, biases are mainly shaped by pretraining: models\nwith the same pretrained backbone exhibit more similar bias patterns than those\nsharing only finetuning data. These insights suggest that understanding biases\nin finetuned models requires considering their pretraining origins beyond\nfinetuning effects. This perspective can guide future efforts to develop\nprincipled strategies for evaluating and mitigating bias in LLMs.", "AI": {"tldr": "Large language models (LLMs) exhibit cognitive biases, influenced more by pretraining rather than finetuning or training randomness.", "motivation": "To understand the origin of cognitive biases in LLMs and disentangle contributions from pretraining, finetuning, and training randomness.", "method": "Two-step causal experimental approach: (1) Multiple finetunings with different random seeds to examine training stochasticity, and (2) cross-tuning by swapping instruction datasets between models to isolate bias sources.", "result": "Findings show training randomness introduces minimal variability, while biases are primarily shaped by pretraining; models sharing pretrained backbones have more similarity in bias patterns than those sharing finetuning data.", "conclusion": "Understanding and mitigating biases in finetuned models require insights into their pretraining mechanisms, emphasizing the need for principled evaluation strategies."}}
{"id": "2507.07150", "pdf": "https://arxiv.org/pdf/2507.07150", "abs": "https://arxiv.org/abs/2507.07150", "authors": ["Jean-Baptiste Fermanian", "Mohamed Hebiri", "Joseph Salmon"], "title": "Class conditional conformal prediction for multiple inputs by p-value aggregation", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Conformal prediction methods are statistical tools designed to quantify\nuncertainty and generate predictive sets with guaranteed coverage\nprobabilities. This work introduces an innovative refinement to these methods\nfor classification tasks, specifically tailored for scenarios where multiple\nobservations (multi-inputs) of a single instance are available at prediction\ntime. Our approach is particularly motivated by applications in citizen\nscience, where multiple images of the same plant or animal are captured by\nindividuals. Our method integrates the information from each observation into\nconformal prediction, enabling a reduction in the size of the predicted label\nset while preserving the required class-conditional coverage guarantee. The\napproach is based on the aggregation of conformal p-values computed from each\nobservation of a multi-input. By exploiting the exact distribution of these\np-values, we propose a general aggregation framework using an abstract scoring\nfunction, encompassing many classical statistical tools. Knowledge of this\ndistribution also enables refined versions of standard strategies, such as\nmajority voting. We evaluate our method on simulated and real data, with a\nparticular focus on Pl@ntNet, a prominent citizen science platform that\nfacilitates the collection and identification of plant species through\nuser-submitted images.", "AI": {"tldr": "This paper introduces an enhanced conformal prediction method for handling multiple observations of a single instance in classification tasks, preserving statistical guarantees while reducing predictive label set sizes.", "motivation": "The motivation is to improve uncertainty quantification in classification scenarios where multiple observations, such as images of the same plant or animal from citizen science platforms, are available.", "method": "The method aggregates conformal p-values from multiple inputs using an abstract scoring function and exploits the exact p-value distribution to refine standard prediction strategies.", "result": "The proposed method outperforms alternatives in preserving class-conditional coverage guarantees while reducing prediction set size, as shown via simulations and real data, including on Pl@ntNet.", "conclusion": "The paper presents a generalized framework for leveraging multiple inputs in conformal prediction, enhancing its applicability in real-world scenarios like citizen science imaging."}}
{"id": "2507.07129", "pdf": "https://arxiv.org/pdf/2507.07129", "abs": "https://arxiv.org/abs/2507.07129", "authors": ["A. Bochkov"], "title": "Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The prevailing paradigm for scaling large language models (LLMs) involves\nmonolithic, end-to-end training, a resource-intensive process that lacks\nflexibility. This paper explores an alternative, constructive approach to model\ndevelopment, built upon the foundation of non-trainable, deterministic input\nembeddings. In prior [1], we established that high-level semantic reasoning can\nemerge in Transformers using frozen embeddings derived from the visual\nstructure of Unicode glyphs. Here, we demonstrate that this fixed\nrepresentational substrate acts as a universal \"docking port,\" enabling two\npowerful and efficient scaling paradigms: seamless modular composition and\nprogressive layer-wise growth.\n  First, we show that specialist models trained on disparate datasets (e.g.,\nRussian and Chinese text) can be merged into a single, more capable\nMixture-of-Experts (MoE) model, post-training, with zero architectural\nmodification. This is achieved by simply averaging their output logits. The\nresulting MoE model exhibits immediate performance improvements on reasoning\nbenchmarks like MMLU, surpassing its constituent experts without catastrophic\nforgetting. Second, we introduce a layer-wise constructive training\nmethodology, where a deep Transformer is \"grown\" by progressively stacking and\ntraining one layer at a time. This method demonstrates stable convergence and a\nclear correlation between model depth and the emergence of complex reasoning\nabilities, such as those required for SQuAD.\n  Our findings suggest a paradigm shift from monolithic optimization towards a\nmore biological or constructive model of AI development, where complexity is\nbuilt incrementally and modules can be composed freely. This opens new avenues\nfor resource-efficient scaling, continual learning, and a more democratized\necosystem for building powerful AI systems. We release all code and models to\nfacilitate further research.", "AI": {"tldr": "The paper proposes a constructive approach to developing large language models (LLMs) using deterministic input embeddings, enabling innovative scaling through modular composition and layer-wise growth.", "motivation": "Existing large language model training methods are resource-heavy and inflexible, necessitating a more efficient and modular approach.", "method": "The authors use frozen Unicode glyph embeddings as universal docking ports for modular combination of specialist models and propose layer-wise, incremental training of Transformers.", "result": "Specialist models, when averaged post-training, outperform individual models on reasoning benchmarks. Layer-wise growth of Transformers shows stable convergence and better reasoning ability with increased depth.", "conclusion": "This approach shifts AI development towards modular and incremental methods, offering benefits like efficiency, continual learning, and easier democratization of AI system building."}}
{"id": "2507.07108", "pdf": "https://arxiv.org/pdf/2507.07108", "abs": "https://arxiv.org/abs/2507.07108", "authors": ["Zhiwei Hu", "V\u00edctor Guti\u00e9rrez-Basulto", "Zhiliang Xiang", "Ru Li", "Jeff Z. Pan"], "title": "Multi-level Mixture of Experts for Multimodal Entity Linking", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "Accepted at KDD 2025", "summary": "Multimodal Entity Linking (MEL) aims to link ambiguous mentions within\nmultimodal contexts to associated entities in a multimodal knowledge base.\nExisting approaches to MEL introduce multimodal interaction and fusion\nmechanisms to bridge the modality gap and enable multi-grained semantic\nmatching. However, they do not address two important problems: (i) mention\nambiguity, i.e., the lack of semantic content caused by the brevity and\nomission of key information in the mention's textual context; (ii) dynamic\nselection of modal content, i.e., to dynamically distinguish the importance of\ndifferent parts of modal information. To mitigate these issues, we propose a\nMulti-level Mixture of Experts (MMoE) model for MEL. MMoE has four components:\n(i) the description-aware mention enhancement module leverages large language\nmodels to identify the WikiData descriptions that best match a mention,\nconsidering the mention's textual context; (ii) the multimodal feature\nextraction module adopts multimodal feature encoders to obtain textual and\nvisual embeddings for both mentions and entities; (iii)-(iv) the intra-level\nmixture of experts and inter-level mixture of experts modules apply a switch\nmixture of experts mechanism to dynamically and adaptively select features from\nrelevant regions of information. Extensive experiments demonstrate the\noutstanding performance of MMoE compared to the state-of-the-art. MMoE's code\nis available at: https://github.com/zhiweihu1103/MEL-MMoE.", "AI": {"tldr": "The paper focuses on improving Multimodal Entity Linking (MEL) with a proposed Multi-level Mixture of Experts (MMoE) model, addressing mention ambiguity and dynamic modal content selection, and demonstrating superior performance over existing techniques.", "motivation": "To improve the performance of Multimodal Entity Linking by addressing the challenges of mention ambiguity and dynamic selection of significant modal content, shortcomings in existing approaches.", "method": "The proposed Multi-level Mixture of Experts (MMoE) model introduces four components: (i) a description-aware mention enhancement module using large language models, (ii) a multimodal feature extraction module, (iii) an intra-level mixture of experts, and (iv) an inter-level mixture of experts modules that dynamically select relevant features.", "result": "Experiments indicate the proposed MMoE model outperforms state-of-the-art methods in Multimodal Entity Linking tasks and demonstrates excellent adaptability and effectiveness.", "conclusion": "The MMoE model addresses key challenges in Multimodal Entity Linking and offers a robust, adaptive approach for improving matching accuracy, with publicly available code for reproducibility."}}
{"id": "2507.07693", "pdf": "https://arxiv.org/pdf/2507.07693", "abs": "https://arxiv.org/abs/2507.07693", "authors": ["Gustavo Menesse", "Ana P. Mill\u00e1n", "Joaqu\u00edn J. Torres"], "title": "Astrocyte-Mediated Higher-Order Control of Synaptic Plasticity", "categories": ["q-bio.NC", "cond-mat.dis-nn"], "comment": "22 pages, 9 figures", "summary": "The dynamics of higher-order topological signals are increasingly recognized\nas a key aspect of the activity of complex systems. A paradigmatic example are\nsynaptic dynamics: synaptic efficacy changes over time driven by different\nmechanisms. Beyond traditional node-driven short-term plasticity mechanisms,\nthe role of astrocyte modulation through higher-order interactions, in the\nso-called tripartite synapse, is increasingly recognized. However, the\ncompetition and interplay between node-driven and higher-order mechanisms have\nyet to be considered. Here, we introduce a simple higher-order model of the\ntripartite synapse accounting for astrocyte-synapse-neuron interactions in\nshort-term plasticity. In the model, astrocyte gliotransmission and\npre-synaptic intrinsic facilitation mechanisms jointly modulate the probability\nof neurotransmitter release at the synapse, generalizing previous short-term\nplasticity models. We investigate the implications of such mechanisms in a\nminimal recurrent motif -- a directed ring of three excitatory leaky\nintegrate-and-fire neurons -- where one neuron receives external stimulation\nthat propagates through the circuit. Due to its strong recurrence, the circuit\nis highly prone to self-sustained activity, which can make it insensitive to\nexternal input. By introducing higher-order interactions among different\nsynapses through astrocyte modulation, we show that higher-order modulation\nrobustly stabilizes circuit dynamics and expands the parameter space that\nsupports stimulus-driven activity. Our findings highlight a plausible mechanism\nby which astrocytes can reshape effective connectivity and enhance information\nprocessing through higher-order structural interactions -- even in the simplest\nrecurrent circuits.", "AI": {"tldr": "The paper introduces a model integrating astrocyte modulation in tripartite synapses to explore its role in stabilizing neural circuit dynamics.", "motivation": "Analyzing the role of astrocyte-driven higher-order interactions in synaptic dynamics and their interplay with traditional node-driven short-term plasticity.", "method": "Developed a higher-order model incorporating astrocyte-mediated mechanisms into the dynamics of neurotransmitter release; tested within a recurrent motif of leaky integrate-and-fire neurons.", "result": "Higher-order modulation by astrocyte mechanisms stabilized circuit dynamics and expanded parameter space for stimulus-driven neural activity.", "conclusion": "Astrocytes reshape effective connectivity, enhancing information processing and stabilizing neural circuits via higher-order interactions."}}
{"id": "2507.07874", "pdf": "https://arxiv.org/pdf/2507.07874", "abs": "https://arxiv.org/abs/2507.07874", "authors": ["Yi-Chun Hung", "Gregory Schwartz", "Emily A. Cooper", "Emma Alexander"], "title": "Homeostatic Adaptation of Optimal Population Codes under Metabolic Stress", "categories": ["cs.NE"], "comment": null, "summary": "Information processing in neural populations is inherently constrained by\nmetabolic resource limits and noise properties, with dynamics that are not\naccurately described by existing mathematical models. Recent data, for example,\nshows that neurons in mouse visual cortex go into a \"low power mode\" in which\nthey maintain firing rate homeostasis while expending less energy. This\nadaptation leads to increased neuronal noise and tuning curve flattening in\nresponse to metabolic stress. We have developed a theoretical population coding\nframework that captures this behavior using two novel, surprisingly simple\nconstraints: an approximation of firing rate homeostasis and an energy limit\ntied to noise levels via biophysical simulation. A key feature of our\ncontribution is an energy budget model directly connecting adenosine\ntriphosphate (ATP) use in cells to a fully explainable mathematical framework\nthat generalizes existing optimal population codes. Specifically, our\nsimulation provides an energy-dependent dispersed Poisson noise model, based on\nthe assumption that the cell will follow an optimal decay path to produce the\nleast-noisy spike rate that is possible at a given cellular energy budget. Each\nstate along this optimal path is associated with properties (resting potential\nand leak conductance) which can be measured in electrophysiology experiments\nand have been shown to change under prolonged caloric deprivation. We\nanalytically derive the optimal coding strategy for neurons under varying\nenergy budgets and coding goals, and show how our method uniquely captures how\npopulations of tuning curves adapt while maintaining homeostasis, as has been\nobserved empirically.", "AI": {"tldr": "This paper introduces a novel theoretical framework for population coding in neurons, considering energy limits and noise properties.", "motivation": "To explain how neurons maintain firing rate homeostasis and adapt their coding properties under metabolic stress, a phenomenon not well modeled by existing approaches.", "method": "Developing a theoretical framework using constraints approximating firing rate homeostasis and linking energy use to noise levels through biophysical simulations.", "result": "The framework reveals an energy-dependent Poisson noise model and derivation of optimal coding strategies, validated with properties measurable in experiments.", "conclusion": "The proposed model effectively explains how neurons adapt their tuning curves and maintain homeostasis under metabolic constraints, making it generalizable for studying optimal neural codes."}}
{"id": "2507.07134", "pdf": "https://arxiv.org/pdf/2507.07134", "abs": "https://arxiv.org/abs/2507.07134", "authors": ["Mridula Vijendran", "Shuang Chen", "Jingjing Deng", "Hubert P. H. Shum"], "title": "BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks", "categories": ["cs.AI", "cs.LG", "I.2.10"], "comment": "18 pages, 7 figures, 3 tables", "summary": "The pervasive issue of bias in AI presents a significant challenge to\npainting classification, and is getting more serious as these systems become\nincreasingly integrated into tasks like art curation and restoration. Biases,\noften arising from imbalanced datasets where certain artistic styles dominate,\ncompromise the fairness and accuracy of model predictions, i.e., classifiers\nare less accurate on rarely seen paintings. While prior research has made\nstrides in improving classification performance, it has largely overlooked the\ncritical need to address these underlying biases, that is, when dealing with\nout-of-distribution (OOD) data. Our insight highlights the necessity of a more\nrobust approach to bias mitigation in AI models for art classification on\nbiased training data. We propose a novel OOD-informed model bias adaptive\nsampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It\naddresses these challenges by dynamically adjusting temperature scaling and\nsampling probabilities, thereby promoting a more equitable representation of\nall classes. We evaluate our proposed approach to the KaoKore and PACS\ndatasets, focusing on the model's ability to reduce class-wise bias. We further\npropose a new metric, Same-Dataset OOD Detection Score (SODC), designed to\nassess class-wise separation and per-class bias reduction. Our method\ndemonstrates the ability to balance high performance with fairness, making it a\nrobust solution for unbiasing AI models in the art domain.", "AI": {"tldr": "The paper addresses bias in AI for painting classification by introducing BOOST, an OOD-informed bias-mitigation method, to improve fairness and performance.", "motivation": "The motivation of this paper is to address the pervasive bias present in painting classification AI models, which arises due to imbalanced training datasets and results in reduced accuracy for rarely seen painting styles. Existing research has failed to adequately address this issue, particularly in out-of-distribution (OOD) scenarios.", "method": "The paper proposes BOOST (Bias-Oriented OOD Sampling and Tuning), a novel approach that uses dynamic temperature scaling and sampling probabilities to mitigate bias by promoting a fairer representation of less-represented classes in the training dataset.", "result": "Experiments were conducted on KaoKore and PACS datasets. The results indicate that BOOST effectively reduces class-wise biases and achieves a balance between improving performance and fairness. Additionally, a new metric, Same-Dataset OOD Detection Score (SODC), was introduced to measure bias reduction.", "conclusion": "BOOST provides a robust solution for mitigating bias in art-based AI models by addressing data imbalances, ensuring fairness, and maintaining high classification performance."}}
{"id": "2507.07116", "pdf": "https://arxiv.org/pdf/2507.07116", "abs": "https://arxiv.org/abs/2507.07116", "authors": ["Juan Cano-Benito", "Andrea Cimmino", "Sven Hertling", "Heiko Paulheim", "Ra\u00fal Garc\u00eda-Castro"], "title": "Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces", "categories": ["cs.DC", "cs.AI", "cs.ET"], "comment": null, "summary": "Data spaces are emerging as decentralised infrastructures that enable\nsovereign, secure, and trustworthy data exchange among multiple participants.\nTo achieve semantic interoperability within these environments, the use of\nsemantic web technologies and knowledge graphs has been proposed. Although\ndistributed ledger technologies (DLT) fit as the underlying infrastructure for\ndata spaces, there remains a significant gap in terms of the efficient storage\nof semantic data on these platforms. This paper presents a systematic\nevaluation of semantic data storage across different types of DLT (public,\nprivate, and hybrid), using a real-world knowledge graph as an experimental\nbasis. The study compares performance, storage efficiency, resource\nconsumption, and the capabilities to update and query semantic data. The\nresults show that private DLTs are the most efficient for storing and managing\nsemantic content, while hybrid DLTs offer a balanced trade-off between public\nauditability and operational efficiency. This research leads to a discussion on\nthe selection of the most appropriate DLT infrastructure based on the data\nsovereignty requirements of decentralised data ecosystems.", "AI": {"tldr": "This paper evaluates how to efficiently store semantic data on different types of distributed ledger technologies, concluding that private DLTs are the most efficient and hybrids balance auditability and efficiency.", "motivation": "To address the challenges of efficiently storing semantic data on distributed ledger technologies (DLTs), which are crucial for enabling secure and trustworthy decentralized data exchanges in data spaces.", "method": "The authors conducted a systematic evaluation comparing different types of DLTs (public, private, and hybrid) using a real-world knowledge graph. They analyzed performance, storage efficiency, resource consumption, and capabilities to update and query semantic data.", "result": "The evaluation revealed that private DLTs are highly efficient for handling semantic data, while hybrid DLTs offer a balance between public auditability and operational efficiency.", "conclusion": "Private DLTs are optimal for semantic data storage and management in terms of efficiency, whereas hybrid DLTs provide a good compromise where both efficiency and auditability are needed."}}
{"id": "2507.07344", "pdf": "https://arxiv.org/pdf/2507.07344", "abs": "https://arxiv.org/abs/2507.07344", "authors": ["Martin Obaidi", "Jannik Fischbach", "Jakob Droste", "Hannah Deters", "Marc Herrmann", "Jil Kl\u00fcnder", "Steffen Kr\u00e4tzig", "Hugo Villamizar", "Kurt Schneider"], "title": "Automatic Generation of Explainability Requirements and Software Explanations From User Reviews", "categories": ["cs.SE"], "comment": "This paper has been accepted at the 33rd IEEE International\n  Requirements Engineering Workshop (REW 2025)", "summary": "Explainability has become a crucial non-functional requirement to enhance\ntransparency, build user trust, and ensure regulatory compliance. However,\ntranslating explanation needs expressed in user feedback into structured\nrequirements and corresponding explanations remains challenging. While existing\nmethods can identify explanation-related concerns in user reviews, there is no\nestablished approach for systematically deriving requirements and generating\naligned explanations. To contribute toward addressing this gap, we introduce a\ntool-supported approach that automates this process. To evaluate its\neffectiveness, we collaborated with an industrial automation manufacturer to\ncreate a dataset of 58 user reviews, each annotated with manually crafted\nexplainability requirements and explanations. Our evaluation shows that while\nAI-generated requirements often lack relevance and correctness compared to\nhuman-created ones, the AI-generated explanations are frequently preferred for\ntheir clarity and style. Nonetheless, correctness remains an issue,\nhighlighting the importance of human validation. This work contributes to the\nadvancement of explainability requirements in software systems by (1)\nintroducing an automated approach to derive requirements from user reviews and\ngenerate corresponding explanations, (2) providing empirical insights into the\nstrengths and limitations of automatically generated artifacts, and (3)\nreleasing a curated dataset to support future research on the automatic\ngeneration of explainability requirements.", "AI": {"tldr": "The paper presents a tool-supported approach to automate the derivation of explainability requirements and explanation generation from user reviews, evaluating it with an industrial dataset.", "motivation": "The motivation is to address the challenge of systematically deriving structured explainability requirements and explanations from user feedback, a gap in ensuring transparency, trust, and regulatory compliance in software systems.", "method": "The authors introduce an automated approach combined with an evaluation on 58 annotated user reviews from an industrial automation manufacturer, comparing AI and human outputs for relevance and style.", "result": "The evaluation reveals that AI-generated requirements lack human-level relevance and correctness, but AI explanations are often preferred for their clarity despite issues with correctness.", "conclusion": "The study underscores the potential of automated tools in generating explainability-related artifacts while emphasizing the necessity of human validation for correctness. It also provides a dataset to foster further research in this domain."}}
{"id": "2507.07221", "pdf": "https://arxiv.org/pdf/2507.07221", "abs": "https://arxiv.org/abs/2507.07221", "authors": ["Nam Gyun Kim", "William E. Heap", "Yimeng Qin", "Elvy B. Yao", "Jee-Hwan Ryu", "Allison M. Okamura"], "title": "Self-Wearing Adaptive Garments via Soft Robotic Unfurling", "categories": ["cs.RO"], "comment": null, "summary": "Robotic dressing assistance has the potential to improve the quality of life\nfor individuals with limited mobility. Existing solutions predominantly rely on\nrigid robotic manipulators, which have challenges in handling deformable\ngarments and ensuring safe physical interaction with the human body. Prior\nrobotic dressing methods require excessive operation times, complex control\nstrategies, and constrained user postures, limiting their practicality and\nadaptability. This paper proposes a novel soft robotic dressing system, the\nSelf-Wearing Adaptive Garment (SWAG), which uses an unfurling and growth\nmechanism to facilitate autonomous dressing. Unlike traditional approaches,the\nSWAG conforms to the human body through an unfurling based deployment method,\neliminating skin-garment friction and enabling a safer and more efficient\ndressing process. We present the working principles of the SWAG, introduce its\ndesign and fabrication, and demonstrate its performance in dressing assistance.\nThe proposed system demonstrates effective garment application across various\ngarment configurations, presenting a promising alternative to conventional\nrobotic dressing assistance.", "AI": {"tldr": "The paper introduces the Self-Wearing Adaptive Garment (SWAG), a soft robotic dressing system that improves safety and efficiency in dressing assistance for individuals with limited mobility.", "motivation": "To address challenges like excessive operation time, complex control strategies, and constrained user postures faced by existing robotic dressing systems using rigid manipulators.", "method": "Developed the SWAG system that utilizes an unfurling and growth mechanism for autonomous dressing, eliminating skin-garment friction and adapting to human body contours.", "result": "Demonstrated effective dressing assistance across various garment configurations, highlighting efficiency and adaptability in practice.", "conclusion": "SWAG offers a promising alternative to conventional robotic dressing systems with improved safety, efficiency, and adaptability."}}
{"id": "2507.07188", "pdf": "https://arxiv.org/pdf/2507.07188", "abs": "https://arxiv.org/abs/2507.07188", "authors": ["Jens Rupprecht", "Georg Ahnert", "Markus Strohmaier"], "title": "Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses", "categories": ["cs.CL", "cs.AI", "cs.CY", "J.4"], "comment": "18 pages, 17 figures", "summary": "Large Language Models (LLMs) are increasingly used as proxies for human\nsubjects in social science surveys, but their reliability and susceptibility to\nknown response biases are poorly understood. This paper investigates the\nresponse robustness of LLMs in normative survey contexts -- we test nine\ndiverse LLMs on questions from the World Values Survey (WVS), applying a\ncomprehensive set of 11 perturbations to both question phrasing and answer\noption structure, resulting in over 167,000 simulated interviews. In doing so,\nwe not only reveal LLMs' vulnerabilities to perturbations but also reveal that\nall tested models exhibit a consistent \\textit{recency bias} varying in\nintensity, disproportionately favoring the last-presented answer option. While\nlarger models are generally more robust, all models remain sensitive to\nsemantic variations like paraphrasing and to combined perturbations. By\napplying a set of perturbations, we reveal that LLMs partially align with\nsurvey response biases identified in humans. This underscores the critical\nimportance of prompt design and robustness testing when using LLMs to generate\nsynthetic survey data.", "AI": {"tldr": "This paper examines the robustness of large language models (LLMs) in social science surveys, finding that they are prone to biases, such as recency bias, and sensitive to question perturbations.", "motivation": "To assess whether LLMs can reliably act as proxies for human subjects in normative survey scenarios and understand their susceptibility to known response biases.", "method": "Tested nine LLMs on World Values Survey (WVS) questions with 11 types of perturbations (e.g., question phrasing changes, answer structure variations) and conducted 167,000 simulated interviews to analyze robustness.", "result": "LLMs are vulnerable to perturbations, exhibit consistent recency bias, and even larger models are sensitive to semantic variations and combined perturbations.", "conclusion": "Prompt design and robustness testing are essential when using LLMs to generate synthetic survey data, as they align partially with human survey response biases but remain fragile under variations."}}
{"id": "2507.07156", "pdf": "https://arxiv.org/pdf/2507.07156", "abs": "https://arxiv.org/abs/2507.07156", "authors": ["Nicole Abreu", "Parker B. Edwards", "Francis Motta"], "title": "Topological Machine Learning with Unreduced Persistence Diagrams", "categories": ["stat.ML", "cs.CG", "cs.LG", "math.AT", "55N31"], "comment": "10 figures, 2 tables, 8 pages(without appendix and references)", "summary": "Supervised machine learning pipelines trained on features derived from\npersistent homology have been experimentally observed to ignore much of the\ninformation contained in a persistence diagram. Computing persistence diagrams\nis often the most computationally demanding step in such a pipeline, however.\nTo explore this, we introduce several methods to generate topological feature\nvectors from unreduced boundary matrices. We compared the performance of\npipelines trained on vectorizations of unreduced PDs to vectorizations of\nfully-reduced PDs across several data and task types. Our results indicate that\nmodels trained on PDs built from unreduced diagrams can perform on par and even\noutperform those trained on fully-reduced diagrams on some tasks. This\nobservation suggests that machine learning pipelines which incorporate\ntopology-based features may benefit in terms of computational cost and\nperformance by utilizing information contained in unreduced boundary matrices.", "AI": {"tldr": "The paper finds that machine learning pipelines can utilize unreduced boundary matrices for training, potentially saving computational time while maintaining or improving performance.", "motivation": "Supervised machine learning pipelines using persistence diagrams ignore much of the contained information and require computationally expensive steps. Exploring alternative methods is necessary.", "method": "The authors generated topological feature vectors from unreduced boundary matrices in persistence diagrams and compared their performance with pipelines using fully-reduced diagrams across various tasks.", "result": "Pipelines trained on unreduced diagrams performed on par or better than those trained on fully-reduced diagrams for some tasks, indicating their potential usefulness.", "conclusion": "Topological machine learning pipelines could benefit in terms of efficiency and performance by leveraging unreduced boundary matrices instead of fully-reduced persistence diagrams."}}
{"id": "2507.07135", "pdf": "https://arxiv.org/pdf/2507.07135", "abs": "https://arxiv.org/abs/2507.07135", "authors": ["Fran\u00e7ois Gard\u00e8res", "Shizhe Chen", "Camille-Sovanneary Gauthier", "Jean Ponce"], "title": "FACap: A Large-scale Fashion Dataset for Fine-grained Composed Image Retrieval", "categories": ["cs.LG"], "comment": null, "summary": "The composed image retrieval (CIR) task is to retrieve target images given a\nreference image and a modification text. Recent methods for CIR leverage large\npretrained vision-language models (VLMs) and achieve good performance on\ngeneral-domain concepts like color and texture. However, they still struggle\nwith application domains like fashion, because the rich and diverse vocabulary\nused in fashion requires specific fine-grained vision and language\nunderstanding. An additional difficulty is the lack of large-scale fashion\ndatasets with detailed and relevant annotations, due to the expensive cost of\nmanual annotation by specialists. To address these challenges, we introduce\nFACap, a large-scale, automatically constructed fashion-domain CIR dataset. It\nleverages web-sourced fashion images and a two-stage annotation pipeline\npowered by a VLM and a large language model (LLM) to generate accurate and\ndetailed modification texts. Then, we propose a new CIR model FashionBLIP-2,\nwhich fine-tunes the general-domain BLIP-2 model on FACap with lightweight\nadapters and multi-head query-candidate matching to better account for\nfine-grained fashion-specific information. FashionBLIP-2 is evaluated with and\nwithout additional fine-tuning on the Fashion IQ benchmark and the enhanced\nevaluation dataset enhFashionIQ, leveraging our pipeline to obtain\nhigher-quality annotations. Experimental results show that the combination of\nFashionBLIP-2 and pretraining with FACap significantly improves the model's\nperformance in fashion CIR especially for retrieval with fine-grained\nmodification texts, demonstrating the value of our dataset and approach in a\nhighly demanding environment such as e-commerce websites. Code is available at\nhttps://fgxaos.github.io/facap-paper-website/.", "AI": {"tldr": "The paper introduces FACap, a large-scale fashion-domain dataset for composed image retrieval (CIR), and FashionBLIP-2, a model tailored for fine-grained fashion-specific retrieval tasks.", "motivation": "CIR methods face challenges in domains like fashion due to a rich vocabulary and lack of annotated datasets, limiting their capability to understand fine-grained details.", "method": "The authors automatically construct the FACap dataset using web-sourced images, vision-language models (VLMs), and large language models (LLMs) for text annotations. They also propose FashionBLIP-2, which fine-tunes BLIP-2 with adapters and multi-head query-candidate matching.", "result": "FashionBLIP-2, when trained on FACap, and fine-tuned further, outperforms existing fashion CIR methods, demonstrating superior performance on benchmarks and enhanced datasets like Fashion IQ and enhFashionIQ.", "conclusion": "FACap and FashionBLIP-2 collectively advance the CIR task in the fashion domain, particularly for e-commerce scenarios, by addressing dataset limitations and leveraging detailed text annotations for better retrieval performance."}}
{"id": "2507.07125", "pdf": "https://arxiv.org/pdf/2507.07125", "abs": "https://arxiv.org/abs/2507.07125", "authors": ["Cristina Mata", "Kanchana Ranasinghe", "Michael S. Ryoo"], "title": "CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings", "categories": ["cs.CV", "eess.IV"], "comment": "ECCV 2024", "summary": "Unsupervised domain adaptation (UDA) involves learning class semantics from\nlabeled data within a source domain that generalize to an unseen target domain.\nUDA methods are particularly impactful for semantic segmentation, where\nannotations are more difficult to collect than in image classification. Despite\nrecent advances in large-scale vision-language representation learning, UDA\nmethods for segmentation have not taken advantage of the domain-agnostic\nproperties of text. To address this, we present a novel Covariance-based\nPixel-Text loss, CoPT, that uses domain-agnostic text embeddings to learn\ndomain-invariant features in an image segmentation encoder. The text embeddings\nare generated through our LLM Domain Template process, where an LLM is used to\ngenerate source and target domain descriptions that are fed to a frozen CLIP\nmodel and combined. In experiments on four benchmarks we show that a model\ntrained using CoPT achieves the new state of the art performance on UDA for\nsegmentation. The code can be found at https://github.com/cfmata/CoPT.", "AI": {"tldr": "The paper introduces CoPT, a novel loss function leveraging domain-agnostic text embeddings for unsupervised domain adaptation (UDA) in semantic segmentation, achieving state-of-the-art performance.", "motivation": "The motivation is to address the gap in UDA for semantic segmentation by utilizing text embeddings, as recent advancements in vision-language learning have not yet been effectively applied in this area.", "method": "The method involves using the CoPT loss function, based on domain-agnostic text embeddings generated through a process called LLM Domain Template. A pre-trained CLIP model processes text descriptions of source and target domains generated by an LLM, which are then used to learn domain-invariant segmentation features.", "result": "The experiments on four benchmarks demonstrate that CoPT significantly outperforms existing methods, setting a new state-of-the-art for UDA in semantic segmentation.", "conclusion": "CoPT effectively leverages domain-agnostic text representations to overcome the domain adaptation challenge in semantic segmentation, advancing the field and providing a new standard for future research."}}
{"id": "2507.07858", "pdf": "https://arxiv.org/pdf/2507.07858", "abs": "https://arxiv.org/abs/2507.07858", "authors": ["Yuki Minai", "Joana Soldado-Magraner", "Byron M. Yu", "Matthew A. Smith"], "title": "OMiSO: Adaptive optimization of state-dependent brain stimulation to shape neural population states", "categories": ["q-bio.NC"], "comment": null, "summary": "The coordinated activity of neural populations underlies myriad brain\nfunctions. Manipulating this activity using brain stimulation techniques has\ngreat potential for scientific and clinical applications, as it provides a tool\nto causally influence brain function. The state of the brain affects how neural\npopulations respond to incoming sensory stimuli. Thus, taking into account\npre-stimulation neural population activity may be crucial to achieve a desired\ncausal manipulation using stimulation. In this work, we propose Online\nMicroStimulation Optimization (OMiSO), a brain stimulation framework that\nleverages brain state information to find stimulation parameters that can drive\nneural population activity toward specified states. OMiSO includes two key\nadvances: i) it leverages the pre-stimulation brain state to choose optimal\nstimulation parameters, and ii) it adaptively refines the choice of those\nparameters by considering newly-observed stimulation responses. We tested OMiSO\nby applying intracortical electrical microstimulation in a monkey and found\nthat it outperformed competing methods that do not incorporate these advances.\nTaken together, OMiSO provides greater accuracy in achieving specified activity\nstates, thereby advancing neuromodulation technologies for understanding the\nbrain and for treating brain disorders.", "AI": {"tldr": "The paper introduces Online MicroStimulation Optimization (OMiSO), a framework that uses pre-stimulation brain state data to improve the precision of brain stimulation techniques.", "motivation": "There is a need to enhance brain stimulation methods to achieve precise and causal manipulation of neural population activity for scientific and clinical advancements.", "method": "OMiSO leverages pre-stimulation brain state information to optimally select stimulation parameters and adaptively refines these choices based on observed responses during stimulation.", "result": "Experimental testing of OMiSO in monkeys demonstrated its superiority over existing methods by achieving more precise neural activity states.", "conclusion": "OMiSO enhances the accuracy of brain stimulation technologies, advancing tools for neuroscience research and potential treatments for brain disorders."}}
{"id": "2507.07207", "pdf": "https://arxiv.org/pdf/2507.07207", "abs": "https://arxiv.org/abs/2507.07207", "authors": ["Florian Redhardt", "Yassir Akram", "Simon Schug"], "title": "Scale leads to compositional generalization", "categories": ["cs.LG", "cs.NE"], "comment": "Code available at https://github.com/smonsays/scale-compositionality", "summary": "Can neural networks systematically capture discrete, compositional task\nstructure despite their continuous, distributed nature? The impressive\ncapabilities of large-scale neural networks suggest that the answer to this\nquestion is yes. However, even for the most capable models, there are still\nfrequent failure cases that raise doubts about their compositionality. Here, we\nseek to understand what it takes for a standard neural network to generalize\nover tasks that share compositional structure. We find that simply scaling data\nand model size leads to compositional generalization. We show that this holds\nacross different task encodings as long as the training distribution\nsufficiently covers the task space. In line with this finding, we prove that\nstandard multilayer perceptrons can approximate a general class of\ncompositional task families to arbitrary precision using only a linear number\nof neurons with respect to the number of task modules. Finally, we uncover that\nif networks successfully compositionally generalize, the constituents of a task\ncan be linearly decoded from their hidden activations. We show that this metric\ncorrelates with failures of text-to-image generation models to compose known\nconcepts.", "AI": {"tldr": "The study demonstrates that neural networks can achieve compositional generalization with data scaling and appropriate task coverage, and hidden activations can reflect compositional properties.", "motivation": "To investigate whether neural networks can effectively capture compositional task structure and identify the factors influencing this capability.", "method": "The authors examined standard neural networks on tasks with compositional structure, analyzed generalization through data/model scaling, and used mathematical proofs to establish performance bounds.", "result": "Scaling data/model size and covering task distribution enable compositional generalization. Hidden activations reveal linear decodability of task components, exposing coherence in failure cases of text-to-image models.", "conclusion": "Standard neural networks can generalize over compositional structures when datasets and tasks are sufficiently structured, and hidden layer analysis serves as an insightful diagnostic tool."}}
{"id": "2507.07203", "pdf": "https://arxiv.org/pdf/2507.07203", "abs": "https://arxiv.org/abs/2507.07203", "authors": ["Minkyung Kim", "Junsik Kim", "Hwidong Bae", "Woongcheol Yang", "Sangdon Park", "Sohee Bae"], "title": "State-Inference-Based Prompting for Natural Language Trading with Game NPCs", "categories": ["cs.AI"], "comment": "9 pages main content, 4 pages appendix, 3 figures. Accepted to the\n  KDD 2025 Workshop on Prompt Optimization", "summary": "Large Language Models enable dynamic game interactions but struggle with\nrule-governed trading systems. Current implementations suffer from rule\nviolations, such as item hallucinations and calculation errors, that erode\nplayer trust. Here, State-Inference-Based Prompting (SIBP) enables reliable\ntrading through autonomous dialogue state inference and context-specific rule\nadherence. The approach decomposes trading into six states within a unified\nprompt framework, implementing context-aware item referencing and\nplaceholder-based price calculations. Evaluation across 100 trading dialogues\ndemonstrates >97% state compliance, >95% referencing accuracy, and 99.7%\ncalculation precision. SIBP maintains computational efficiency while\noutperforming baseline approaches, establishing a practical foundation for\ntrustworthy NPC interactions in commercial games.", "AI": {"tldr": "This paper introduces State-Inference-Based Prompting (SIBP) to address rule violations in trading systems within dynamic game interactions, achieving high accuracy and computational efficiency.", "motivation": "Large Language Models struggle with implementing rule-governed trading systems in games due to errors like item hallucinations and calculation mistakes, undermining player trust.", "method": "The paper proposes a systematic framework (State-Inference-Based Prompting - SIBP), decomposing trading interactions into six distinct dialogue states for rule adherence through autonomous state inference, item referencing, and placeholder-based calculations.", "result": "The method showed excellent performance with >97% compliance to trading states, >95% accuracy in item referencing, and 99.7% precision in price calculations across 100 dialogues, outperforming baseline methods.", "conclusion": "SIBP is a reliable and efficient solution that enhances trust in NPC interactions for commercial games, offering a practical method to address trading system issues."}}
{"id": "2507.07117", "pdf": "https://arxiv.org/pdf/2507.07117", "abs": "https://arxiv.org/abs/2507.07117", "authors": ["Jit Gupta", "Andrew Li", "Tarun Banka", "Ariel Cohen", "T. Sridhar", "Raj Yavatkar"], "title": "Collective Communication Profiling of Modern-day Machine Learning Workloads", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": "Poser, USENIX NSDI 2025, April 2025, Philadelphia, PA, USA", "summary": "Machine Learning jobs, carried out on large number of distributed high\nperformance systems, involve periodic communication using operations like\nAllReduce, AllGather, and Broadcast. These operations may create high bandwidth\nand bursty traffic patterns, leading to network congestion and packet loss,\nthus impacting the performance of these jobs. Hence it is imperative to analyze\nthese patterns, which can be helpful in provisioning network resources\ndepending on the type of machine learning workloads. In this poster we carry\nout extensive analysis of the collective communication behavior seen in a wide\nvariety of models (ex. DeepSeek, GPT, Llama, etc.) To achieve this we\ninstrument Nvidia Collective Communication Library logging functionality for\nricher context about the collectives and workloads. We adjust configuration\nparameters that influence collective communication behavior, such as\nparallelism, number of nodes, and model type. This overview presents and\ndiscusses some of the results on the collective communication behavior for the\nopen source DeepSeek V3 inferencing model, which includes operation type and\ncount, transfer sizes per operation, and request size distribution. Our\nanalysis shows that it makes sense to rethink current collective communication\nframeworks and network topologies so as to accommodate the effect of network\nanomalies on the mentioned workloads.", "AI": {"tldr": "The paper analyzes collective communication behaviors in distributed machine learning workloads to address network congestion and packet loss issues.", "motivation": "Investigate traffic patterns of collective communication (e.g., AllReduce) in distributed machine learning to mitigate network performance impacts caused by congestion and packet loss.", "method": "Used Nvidia Collective Communication Library logging for detailed data collection and adjusted variables such as parallelism and node count to study their impact on communication behaviors.", "result": "The results provided insights into traffic types, transfer sizes, and behavior differences, particularly for the DeepSeek V3 model, highlighting the impact of network anomalies.", "conclusion": "Revisiting collective communication frameworks and network designs is necessary to better handle the analyzed workloads in light of network irregularities."}}
{"id": "2507.07468", "pdf": "https://arxiv.org/pdf/2507.07468", "abs": "https://arxiv.org/abs/2507.07468", "authors": ["Sten Gr\u00fcner", "Nafise Eskandani"], "title": "Towards an Engineering Workflow Management System for Asset Administration Shells using BPMN", "categories": ["cs.SE"], "comment": "7 pages, 7 figures, Accepted at IFAC EAAS 2025\n  (https://j3c.org/eaas.php)", "summary": "The integration of Industry 4.0 technologies into engineering workflows is an\nessential step toward automating and optimizing plant and process engineering\nprocesses. The Asset Administration Shell (AAS) serves as a key enabler for\ncreating interoperable Digital Twins that facilitate engineering data exchange\nand automation. This paper explores the use of AAS within engineering\nworkflows, particularly in combination with Business Process Model and Notation\n(BPMN) to define structured and automated processes. We propose a distributed\nAAS copy-on-write infrastructure that enhances security and scalability while\nenabling seamless cross organizational collaboration. We also introduce a\nworkflow management prototype automating AAS operations and engineering\nworkflows, improving efficiency and traceability.", "AI": {"tldr": "The paper introduces a novel approach for enhancing engineering workflows through Industry 4.0 technologies, employing AAS, BPMN, and a copy-on-write infrastructure.", "motivation": "To integrate Industry 4.0 technologies for automating plant and process engineering workflows effectively, leveraging interoperable Digital Twins and engineering automation.", "method": "The authors utilize Asset Administration Shell (AAS) combined with BPMN for structured workflow definition, proposing a distributed copy-on-write infrastructure for scalability and security.", "result": "A prototype of a workflow management system is introduced, capable of automating AAS operations and engineering processes while optimizing efficiency and traceability.", "conclusion": "The proposed infrastructure and management prototype facilitate cross-organizational collaboration, showcasing improved engineering automation and data exchange through Industry 4.0 integrations."}}
{"id": "2507.07225", "pdf": "https://arxiv.org/pdf/2507.07225", "abs": "https://arxiv.org/abs/2507.07225", "authors": ["Yimeng Qin", "Jared Grinberg", "William Heap", "Allison M. Okamura"], "title": "3D Steering and Localization in Pipes and Burrows using an Externally Steered Soft Growing Robot", "categories": ["cs.RO"], "comment": null, "summary": "Navigation and inspection in confined environments, such as tunnels and\npipes, pose significant challenges for existing robots due to limitations in\nmaneuverability and adaptability to varying geometries. Vine robots, which are\nsoft growing continuum robots that extend their length through soft material\neversion at their tip, offer unique advantages due to their ability to navigate\ntight spaces, adapt to complex paths, and minimize friction. However, existing\nvine robot designs struggle with navigation in manmade and natural passageways,\nwith branches and sharp 3D turns. In this letter, we introduce a steerable vine\nrobot specifically designed for pipe and burrow environments. The robot\nfeatures a simple tubular body and an external tip mount that steers the vine\nrobot in three degrees of freedom by changing the growth direction and, when\nnecessary, bracing against the wall of the pipe or burrow. Our external tip\nsteering approach enables: (1) active branch selection in 3D space with a\nmaximum steerable angle of 51.7{\\deg}, (2) navigation of pipe networks with\nradii as small as 2.5 cm, (3) a compliant tip enabling navigation of sharp\nturns, and (4) real-time 3D localization in GPS-denied environments using\ntip-mounted sensors and continuum body odometry. We describe the forward\nkinematics, characterize steerability, and demonstrate the system in a 3D pipe\nsystem as well as a natural animal burrow.", "AI": {"tldr": "This paper introduces a steerable vine robot capable of navigating confined environments, such as pipes and burrows, with adaptability to sharp turns and complex paths.", "motivation": "Existing robots struggle with navigating confined spaces like tunnels and pipes, especially those with sharp turns and branches, limiting their usability in such applications.", "method": "The paper proposes a vine robot equipped with a tubular body and an external tip mount for steering. This setup allows for 3 degrees of freedom in maneuverability, enabling real-time 3D localization and sharp turns.", "result": "The steerable vine robot achieved active branch selection in 3D space, navigation in pipes with radii as small as 2.5 cm, and sharp turns. It also featured real-time localization in GPS-denied environments.", "conclusion": "This steerable vine robot proves effective for confined spaces, offering significant advancements in adaptability and functionality compared to traditional robotic designs."}}
{"id": "2507.07229", "pdf": "https://arxiv.org/pdf/2507.07229", "abs": "https://arxiv.org/abs/2507.07229", "authors": ["Krithika Ramesh", "Daniel Smolyak", "Zihao Zhao", "Nupoor Gandhi", "Ritu Agarwal", "Margr\u00e9t Bjarnad\u00f3ttir", "Anjalie Field"], "title": "SynthTextEval: Synthetic Text Data Generation and Evaluation for High-Stakes Domains", "categories": ["cs.CL"], "comment": null, "summary": "We present SynthTextEval, a toolkit for conducting comprehensive evaluations\nof synthetic text. The fluency of large language model (LLM) outputs has made\nsynthetic text potentially viable for numerous applications, such as reducing\nthe risks of privacy violations in the development and deployment of AI systems\nin high-stakes domains. Realizing this potential, however, requires principled\nconsistent evaluations of synthetic data across multiple dimensions: its\nutility in downstream systems, the fairness of these systems, the risk of\nprivacy leakage, general distributional differences from the source text, and\nqualitative feedback from domain experts. SynthTextEval allows users to conduct\nevaluations along all of these dimensions over synthetic data that they upload\nor generate using the toolkit's generation module. While our toolkit can be run\nover any data, we highlight its functionality and effectiveness over datasets\nfrom two high-stakes domains: healthcare and law. By consolidating and\nstandardizing evaluation metrics, we aim to improve the viability of synthetic\ntext, and in-turn, privacy-preservation in AI development.", "AI": {"tldr": "SynthTextEval is a toolkit designed for holistic evaluation of synthetic text, focusing on dimensions like utility, fairness, privacy risks, and expert feedback.", "motivation": "The motivation is to address the need for consistent and principled evaluations of synthetic text, which is increasingly significant due to its potential in reducing privacy risks in sensitive domains like healthcare and law.", "method": "The paper introduces a toolkit, SynthTextEval, which enables evaluations on synthetic text across several dimensions, such as downstream utility, fairness, privacy leakage risks, distribution differences, and qualitative expert insights.", "result": "SynthTextEval demonstrates its capabilities effectively in evaluating synthetic data for high-stakes domains such as healthcare and law.", "conclusion": "By standardizing evaluation metrics and demonstrating their importance, the toolkit advances the viability of synthetic text while enhancing privacy-preserving AI development."}}
{"id": "2507.07338", "pdf": "https://arxiv.org/pdf/2507.07338", "abs": "https://arxiv.org/abs/2507.07338", "authors": ["Nick Polson", "Vadim Sokolov"], "title": "Bayesian Double Descent", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": null, "summary": "Double descent is a phenomenon of over-parameterized statistical models. Our\ngoal is to view double descent from a Bayesian perspective. Over-parameterized\nmodels such as deep neural networks have an interesting re-descending property\nin their risk characteristics. This is a recent phenomenon in machine learning\nand has been the subject of many studies. As the complexity of the model\nincreases, there is a U-shaped region corresponding to the traditional\nbias-variance trade-off, but then as the number of parameters equals the number\nof observations and the model becomes one of interpolation, the risk can become\ninfinite and then, in the over-parameterized region, it re-descends -- the\ndouble descent effect. We show that this has a natural Bayesian interpretation.\nMoreover, we show that it is not in conflict with the traditional Occam's razor\nthat Bayesian models possess, in that they tend to prefer simpler models when\npossible. We illustrate the approach with an example of Bayesian model\nselection in neural networks. Finally, we conclude with directions for future\nresearch.", "AI": {"tldr": "The paper examines the phenomenon of double descent in over-parameterized models from a Bayesian perspective, showing its alignment with Bayesian principles and Occam's razor.", "motivation": "Explore double descent in the context of Bayesian models to understand its implications and reconcile it with traditional statistical principles like Occam's razor.", "method": "Analyze double descent in over-parameterized models, interpret its characteristics with Bayesian principles, and provide an example using Bayesian model selection in neural networks.", "result": "Double descent has a natural Bayesian interpretation, showing compatibility with Occam\u2019s razor despite the complexity and over-parameterization of models.", "conclusion": "Double descent in over-parameterized models aligns with Bayesian principles and Occam's razor, opening new directions for research and extending our understanding of risk characteristics in machine learning."}}
{"id": "2507.07137", "pdf": "https://arxiv.org/pdf/2507.07137", "abs": "https://arxiv.org/abs/2507.07137", "authors": ["Eric Yeats", "Darryl Hannan", "Henry Kvinge", "Timothy Doster", "Scott Mahan"], "title": "Automating Evaluation of Diffusion Model Unlearning with (Vision-) Language Model World Knowledge", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Machine unlearning (MU) is a promising cost-effective method to cleanse\nundesired information (generated concepts, biases, or patterns) from\nfoundational diffusion models. While MU is orders of magnitude less costly than\nretraining a diffusion model without the undesired information, it can be\nchallenging and labor-intensive to prove that the information has been fully\nremoved from the model. Moreover, MU can damage diffusion model performance on\nsurrounding concepts that one would like to retain, making it unclear if the\ndiffusion model is still fit for deployment. We introduce autoeval-dmun, an\nautomated tool which leverages (vision-) language models to thoroughly assess\nunlearning in diffusion models. Given a target concept, autoeval-dmun extracts\nstructured, relevant world knowledge from the language model to identify nearby\nconcepts which are likely damaged by unlearning and to circumvent unlearning\nwith adversarial prompts. We use our automated tool to evaluate popular\ndiffusion model unlearning methods, revealing that language models (1) impose\nsemantic orderings of nearby concepts which correlate well with unlearning\ndamage and (2) effectively circumvent unlearning with synthetic adversarial\nprompts.", "AI": {"tldr": "The paper focuses on a tool called autoeval-dmun for evaluating the effectiveness and implications of machine unlearning (MU) in diffusion models.", "motivation": "To address challenges in proving the effectiveness of machine unlearning in diffusion models and to assess its impact on surrounding concepts while maintaining deployment readiness.", "method": "The authors propose autoeval-dmun, a tool that uses (vision-) language models to extract structured knowledge, identify nearby concepts affected by unlearning, and employ adversarial prompts to evaluate resilience.", "result": "Findings indicate that language models can identify semantic relationships correlated to unlearning damage and create synthetic prompts that circumvent unlearning, revealing flaws in existing unlearning methods.", "conclusion": "Autonomous evaluation tools like autoeval-dmun are essential for rigorously assessing the balance between successful unlearning and potential collateral performance damage in diffusion models."}}
{"id": "2507.07139", "pdf": "https://arxiv.org/pdf/2507.07139", "abs": "https://arxiv.org/abs/2507.07139", "authors": ["Renyang Liu", "Guanlin Li", "Tianwei Zhang", "See-Kiong Ng"], "title": "Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack against Image Generation Model Unlearning", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "Recent advances in image generation models (IGMs), particularly\ndiffusion-based architectures such as Stable Diffusion (SD), have markedly\nenhanced the quality and diversity of AI-generated visual content. However,\ntheir generative capability has also raised significant ethical, legal, and\nsocietal concerns, including the potential to produce harmful, misleading, or\ncopyright-infringing content. To mitigate these concerns, machine unlearning\n(MU) emerges as a promising solution by selectively removing undesirable\nconcepts from pretrained models. Nevertheless, the robustness and effectiveness\nof existing unlearning techniques remain largely unexplored, particularly in\nthe presence of multi-modal adversarial inputs.\n  To bridge this gap, we propose Recall, a novel adversarial framework\nexplicitly designed to compromise the robustness of unlearned IGMs. Unlike\nexisting approaches that predominantly rely on adversarial text prompts, Recall\nexploits the intrinsic multi-modal conditioning capabilities of diffusion\nmodels by efficiently optimizing adversarial image prompts with guidance from a\nsingle semantically relevant reference image. Extensive experiments across ten\nstate-of-the-art unlearning methods and diverse tasks show that Recall\nconsistently outperforms existing baselines in terms of adversarial\neffectiveness, computational efficiency, and semantic fidelity with the\noriginal textual prompt. These findings reveal critical vulnerabilities in\ncurrent unlearning mechanisms and underscore the need for more robust solutions\nto ensure the safety and reliability of generative models. Code and data are\npublicly available at \\textcolor{blue}{https://github.com/ryliu68/RECALL}.", "AI": {"tldr": "The paper introduces \"Recall,\" an adversarial framework aimed at testing the robustness of machine unlearning in image generation models by exploiting multi-modal adversarial inputs. The results show that current unlearning methods are vulnerable and need improvement.", "motivation": "The motivation is to address vulnerabilities and ethical concerns in image generation models, particularly focusing on how \"unlearning\" efforts can be compromised by multi-modal adversarial attacks.", "method": "The authors developed \"Recall,\" a framework that generates adversarial image prompts using the multi-modal conditioning abilities of diffusion models. It uses optimization guided by a single reference image to test the robustness of unlearning methods in IGMs.", "result": "Experiments conducted on ten state-of-the-art unlearning methods and multiple tasks showcased that Recall is more effective than existing baselines in terms of adversarial performance, efficiency, and maintaining semantic relevance.", "conclusion": "Current machine unlearning methods in IGMs have critical vulnerabilities when exposed to multi-modal adversarial inputs. The study stresses the urgent need to develop more robust strategies to enhance the safety and reliability of these models."}}
{"id": "2507.07227", "pdf": "https://arxiv.org/pdf/2507.07227", "abs": "https://arxiv.org/abs/2507.07227", "authors": ["Mohammad Mohammadi", "Sima Najafzadehkhoei", "George Vega Yon", "Yunshan Wang"], "title": "A novel approach for classifying Monoamine Neurotransmitters by applying Machine Learning on UV plasmonic-engineered Auto Fluorescence Time Decay Series (AFTDS)", "categories": ["q-bio.BM", "q-bio.NC"], "comment": null, "summary": "This study introduces a hybrid approach integrating advanced plasmonic\nnanomaterials and machine learning (ML) for high-precision biomolecule\ndetection. We leverage aluminum concave nanocubes (AlCNCs) as an innovative\nplasmonic substrate to enhance the native fluorescence of neurotransmitters,\nincluding dopamine (DA), norepinephrine (NE), and 3,4-Dihydroxyphenylacetic\nacid (DOPAC). AlCNCs amplify weak fluorescence signals, enabling probe-free,\nlabel-free detection and differentiation of these molecules with great\nsensitivity and specificity. To further improve classification accuracy, we\nemploy ML algorithms, with Long Short-Term Memory (LSTM) networks playing a\ncentral role in analyzing time-dependent fluorescence data. Comparative\nevaluations with k-Nearest Neighbors (KNN) and Random Forest (RF) demonstrate\nthe superior performance of LSTM in distinguishing neurotransmitters. The\nresults reveal that AlCNC substrates provide up to a 12-fold enhancement in\nfluorescence intensity for DA, 9-fold for NE, and 7-fold for DOPAC compared to\nsilicon substrates. At the same time, ML algorithms achieve classification\naccuracy exceeding 89%. This interdisciplinary methodology bridges the gap\nbetween nanotechnology and ML, showcasing the synergistic potential of\nAlCNC-enhanced native fluorescence and ML in biosensing. The framework paves\nthe way for probe-free, label-free biomolecule profiling, offering\ntransformative implications for biomedical diagnostics and neuroscience\nresearch.", "AI": {"tldr": "This paper integrates advanced plasmonic substrates and machine learning to achieve high-precision detection of neurotransmitters. Aluminum concave nanocubes (AlCNCs) amplify fluorescence signals, combined with ML algorithms like LSTM for improved classification.", "motivation": "The paper seeks to address limitations in detecting and differentiating biomolecules with high sensitivity and specificity, leveraging plasmonic nanomaterials and ML.", "method": "The study uses AlCNCs as plasmonic substrates to enhance fluorescence and employs ML algorithms, particularly Long Short-Term Memory networks, for time-dependent fluorescence data analysis.", "result": "The results include up to a 12-fold fluorescence amplification with AlCNCs and ML-driven classification accuracy surpassing 89%.", "conclusion": "This hybrid approach demonstrates the potential of combining AlCNC-enhanced fluorescence with ML algorithms for probe-free, label-free biomolecular detection. It can significantly impact biomedical diagnostics and neuroscience."}}
{"id": "2507.07247", "pdf": "https://arxiv.org/pdf/2507.07247", "abs": "https://arxiv.org/abs/2507.07247", "authors": ["Zhengyu Tian", "Anantha Padmanaban Krishna Kumar", "Hemant Krishnakumar", "Reza Rawassizadeh"], "title": "Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "6 pages, 8 figures", "summary": "As large language models (LLMs) and visual language models (VLMs) grow in\nscale and application, attention mechanisms have become a central computational\nbottleneck due to their high memory and time complexity. While many efficient\nattention variants have been proposed, there remains a lack of rigorous\nevaluation on their actual energy usage and hardware resource demands during\ntraining. In this work, we benchmark eight attention mechanisms in training\nGPT-2 architecture, measuring key metrics including training time, GPU memory\nusage, FLOPS, CPU usage, and power consumption. Our results reveal that\nattention mechanisms with optimized kernel implementations, including Flash\nAttention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent\nAttention (MLA), achieve the best energy efficiency. We further show that lower\nGPU power alone does not guarantee reduced energy use, as training time plays\nan equally important role. Our study highlights the importance of energy-aware\nbenchmarking in attention design and provides a practical insight for selecting\nresource-efficient mechanisms. All our codes are available at GitHub.", "AI": {"tldr": "The paper benchmarks eight attention mechanisms using key metrics during GPT-2 training, finding that optimized kernel implementations like Flash Attention are energy-efficient solutions while noting that training time significantly impacts overall energy use.", "motivation": "Efficient attention mechanisms are crucial due to resource-heavy demands in large language and visual models, and there is limited evaluation regarding their energy consumption and hardware resources.", "method": "The authors benchmark eight attention mechanisms by measuring training time, GPU memory usage, FLOPS, CPU usage, and power consumption during GPT-2 training.", "result": "Optimized attention implementations, such as Flash Attention, LSH Attention, and MLA, demonstrated the best energy efficiency. Training time and energy use are equally critical factors.", "conclusion": "Energy-aware benchmarking is vital for attention design. Optimized kernel implementations should be prioritized for resource efficiency in model training."}}
{"id": "2507.07217", "pdf": "https://arxiv.org/pdf/2507.07217", "abs": "https://arxiv.org/abs/2507.07217", "authors": ["Zili Wang", "Frank Montabon", "Kristin Yvonne Rozier"], "title": "Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains", "categories": ["cs.AI", "cs.LG", "cs.LO", "I.2.4; I.2.7; J.4"], "comment": null, "summary": "Supply chain networks are complex systems that are challenging to analyze;\nthis problem is exacerbated when there are illicit activities involved in the\nsupply chain, such as counterfeit parts, forced labor, or human trafficking.\nWhile machine learning (ML) can find patterns in complex systems like supply\nchains, traditional ML techniques require large training data sets. However,\nillicit supply chains are characterized by very sparse data, and the data that\nis available is often (purposely) corrupted or unreliable in order to hide the\nnature of the activities. We need to be able to automatically detect new\npatterns that correlate with such illegal activity over complex, even temporal\ndata, without requiring large training data sets. We explore neurosymbolic\nmethods for identifying instances of illicit activity in supply chains and\ncompare the effectiveness of manual and automated feature extraction from news\narticles accurately describing illicit activities uncovered by authorities. We\npropose a question tree approach for querying a large language model (LLM) to\nidentify and quantify the relevance of articles. This enables a systematic\nevaluation of the differences between human and machine classification of news\narticles related to forced labor in supply chains.", "AI": {"tldr": "The paper addresses illicit supply chain detection using neurosymbolic methods and a question-tree approach with language models for better activity identification.", "motivation": "Supply chains are complex, and identifying illicit activities like counterfeit parts, forced labor, or human trafficking is even harder due to sparse and unreliable data.", "method": "The study explores neurosymbolic methods and employs a question-tree approach with large language models to analyze and classify news articles describing illicit activities.", "result": "The approach provides insights into the comparison between manual and AI-driven classification of articles related to illicit supply chain activities.", "conclusion": "Neurosymbolic methods and the question-tree approach enhance the ability to detect and evaluate illicit patterns in supply chains, paving the way for intelligent solutions with limited data dependencies."}}
{"id": "2507.07120", "pdf": "https://arxiv.org/pdf/2507.07120", "abs": "https://arxiv.org/abs/2507.07120", "authors": ["Nidhi Bhatia", "Ankit More", "Ritika Borkar", "Tiyasa Mitra", "Ramon Matas", "Ritchie Zhao", "Maximilian Golub", "Dheevatsa Mudigere", "Brian Pharris", "Bita Darvish Rouhani"], "title": "Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "As LLMs scale to multi-million-token KV histories, real-time autoregressive\ndecoding under tight Token-to-Token Latency (TTL) constraints faces growing\npressure. Two core bottlenecks dominate: accessing Feed-Forward Network (FFN)\nweights and reading long KV caches. While Tensor Parallelism (TP) helps\nmitigate the cost of FFN weight reads, it does not scale well for attention.\nWhen TP width exceeds the number of KV heads, it leads to inefficient KV\nduplication, limits parallelism, and constrains batch size. Simultaneously,\nDRAM reads for long KV histories scale linearly with batch size, further\ncapping efficiency.\n  We introduce Helix Parallelism, a hybrid execution strategy that applies KV\nparallelism during attention to shard KV caches across GPUs, then reuses the\nsame GPUs for TP in dense LLMs or TPxExpert Parallel (EP) in MoEs during FFN\ncomputation. To preserve exact attention behavior, Helix includes a lightweight\ncommunication step. To minimize the exposed communication cost, we introduce\nHelix HOP-B. Helix HOP-B effectively minimizes communication overhead through\nbatchwise overlap, preserving low TTL while improving GPU efficiency. Compared\nto conventional parallelism approaches, Helix reduces TTL by up to 1.5x at\nfixed batch sizes and supports up to 32x larger batches under the same latency\nbudget for DeepSeek-R1, pushing forward the throughput-latency Pareto on\nBlackwell and making real-time inference with ultra-long-sequence practical.", "AI": {"tldr": "As LLMs require processing extremely long token sequences with real-time constraints, the researchers introduce Helix Parallelism to boost efficiency by combining KV and Tensor Parallelism with optimized GPU usage.", "motivation": "The motivation is to address inefficiency challenges in scaling LLMs to multi-million-token histories under tight Token-to-Token Latency constraints, particularly related to bottlenecks in FFN weight access and KV cache reads.", "method": "Helix Parallelism is proposed as a hybrid approach combining KV parallelism for attention and GPU reuse for TP or TPxEP during FFN computation, with additional lightweight communication (Helix HOP-B) to reduce inefficiencies.", "result": "Helix achieves up to 1.5x reduction in TTL for fixed batch sizes and supports extremely large batches (up to 32x larger) under the same latency budget, pushing the boundaries for real-time inference with ultra-long-sequence LLMs.", "conclusion": "The work showcases how Helix Parallelism addresses bottlenecks in scaling LLMs for long sequences, achieving improved GPU efficiency, lower latency, and significant batch size capabilities for practical real-time inference."}}
{"id": "2507.07548", "pdf": "https://arxiv.org/pdf/2507.07548", "abs": "https://arxiv.org/abs/2507.07548", "authors": ["Jonathan Ullrich", "Matthias Koch", "Andreas Vogelsang"], "title": "From Requirements to Code: Understanding Developer Practices in LLM-Assisted Software Engineering", "categories": ["cs.SE"], "comment": "This paper has been accepted for publication at the 33rd IEEE\n  International Requirements Engineering (RE) conference", "summary": "With the advent of generative LLMs and their advanced code generation\ncapabilities, some people already envision the end of traditional software\nengineering, as LLMs may be able to produce high-quality code based solely on\nthe requirements a domain expert feeds into the system. The feasibility of this\nvision can be assessed by understanding how developers currently incorporate\nrequirements when using LLMs for code generation-a topic that remains largely\nunexplored. We interviewed 18 practitioners from 14 companies to understand how\nthey (re)use information from requirements and other design artifacts to feed\nLLMs when generating code. Based on our findings, we propose a theory that\nexplains the processes developers employ and the artifacts they rely on. Our\ntheory suggests that requirements, as typically documented, are too abstract\nfor direct input into LLMs. Instead, they must first be manually decomposed\ninto programming tasks, which are then enriched with design decisions and\narchitectural constraints before being used in prompts. Our study highlights\nthat fundamental RE work is still necessary when LLMs are used to generate\ncode. Our theory is important for contextualizing scientific approaches to\nautomating requirements-centric SE tasks.", "AI": {"tldr": "The paper investigates how developers use requirements and design artifacts to generate code with large language models (LLMs), finding that requirements are too abstract and must be decomposed and enriched for effective use in prompts.", "motivation": "Examine the interplay between requirements engineering (RE) and code generation with the rise of LLMs, given the claim that LLMs could revolutionize traditional software engineering.", "method": "The researchers conducted interviews with 18 industry practitioners from 14 companies to explore how they utilize requirements and design data when prompting LLMs for code generation.", "result": "The study found that requirements are too abstract for direct use with LLMs. Developers need to manually break down and supplement requirements with design and architecture information to create effective prompts.", "conclusion": "Key RE tasks remain indispensable even when LLMs are employed for code generation, emphasizing that automated requirements-centric software engineering still requires human input."}}
{"id": "2507.07299", "pdf": "https://arxiv.org/pdf/2507.07299", "abs": "https://arxiv.org/abs/2507.07299", "authors": ["Sonia Raychaudhuri", "Enrico Cancelli", "Tommaso Campari", "Lamberto Ballan", "Manolis Savva", "Angel X. Chang"], "title": "LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Recent progress in large vision-language models has driven improvements in\nlanguage-based semantic navigation, where an embodied agent must reach a target\nobject described in natural language. Despite these advances, we still lack a\nclear, language-focused benchmark for testing how well such agents ground the\nwords in their instructions. We address this gap with LangNav, an open-set\ndataset specifically created to test an agent's ability to locate objects\ndescribed at different levels of detail, from broad category names to fine\nattributes and object-object relations. Every description in LangNav was\nmanually checked, yielding a lower error rate than existing lifelong- and\nsemantic-navigation datasets. On top of LangNav we build LangNavBench, a\nbenchmark that measures how well current semantic-navigation methods understand\nand act on these descriptions while moving toward their targets. LangNavBench\nallows us to systematically compare models on their handling of attributes,\nspatial and relational cues, and category hierarchies, offering the first\nthorough, language-centric evaluation of embodied navigation systems. We also\npresent Multi-Layered Feature Map (MLFM), a method that builds a queryable\nmulti-layered semantic map, particularly effective when dealing with small\nobjects or instructions involving spatial relations. MLFM outperforms\nstate-of-the-art mapping-based navigation baselines on the LangNav dataset.", "AI": {"tldr": "LangNav is a detailed benchmark dataset designed to evaluate how well vision-language models can navigate through semantic instructions involving object descriptions ranging from categories to spatial relations. A new method called Multi-Layered Feature Map (MLFM) is introduced, which outperforms existing navigation methods.", "motivation": "The paper aims to fill the gap in language-focused evaluation frameworks for assessing how well embodied navigation agents ground natural language instructions.", "method": "Introduced LangNav, an open-set dataset with manually checked descriptions for object identification, and LangNavBench, a corresponding benchmark for semantic navigation evaluation. Also proposed MLFM, a mapping-based navigation method designed to handle complex object descriptions and relations.", "result": "LangNavBench provides a rigorous language-centric evaluation, and MLFM surpasses state-of-the-art baselines, especially in tasks involving small objects and spatial relations.", "conclusion": "The work offers a comprehensive dataset and benchmark for evaluating language grounding in navigation tasks and proposes an effective method for improving navigation based on semantic instructions."}}
{"id": "2507.07248", "pdf": "https://arxiv.org/pdf/2507.07248", "abs": "https://arxiv.org/abs/2507.07248", "authors": ["Minseon Kim", "Jean-Philippe Corbeil", "Alessandro Sordoni", "Francois Beaulieu", "Paul Vozila"], "title": "Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings", "categories": ["cs.CL"], "comment": null, "summary": "As the performance of large language models (LLMs) continues to advance,\ntheir adoption is expanding across a wide range of domains, including the\nmedical field. The integration of LLMs into medical applications raises\ncritical safety concerns, particularly due to their use by users with diverse\nroles, e.g. patients and clinicians, and the potential for model's outputs to\ndirectly affect human health. Despite the domain-specific capabilities of\nmedical LLMs, prior safety evaluations have largely focused only on general\nsafety benchmarks. In this paper, we introduce a safety evaluation protocol\ntailored to the medical domain in both patient user and clinician user\nperspectives, alongside general safety assessments and quantitatively analyze\nthe safety of medical LLMs. We bridge a gap in the literature by building the\nPatientSafetyBench containing 466 samples over 5 critical categories to measure\nsafety from the perspective of the patient. We apply our red-teaming protocols\non the MediPhi model collection as a case study. To our knowledge, this is the\nfirst work to define safety evaluation criteria for medical LLMs through\ntargeted red-teaming taking three different points of view - patient,\nclinician, and general user - establishing a foundation for safer deployment in\nmedical domains.", "AI": {"tldr": "This paper introduces a safety evaluation protocol tailored for medical large language models (LLMs), focusing on patient, clinician, and general user perspectives, and presents a new dataset, PatientSafetyBench, to address critical safety concerns.", "motivation": "The motivation is to tackle the safety challenges of deploying medical LLMs, as their outputs can directly impact human health and are utilized by diverse users, necessitating domain-specific safety evaluations.", "method": "The authors proposed a tailored safety evaluation protocol specific to the medical domain, introduced a dataset (PatientSafetyBench) with 466 samples across five safety-critical categories, and applied red-teaming protocols on the MediPhi model as a case study.", "result": "The study quantitatively analyzed the safety of medical LLMs and demonstrated the utility of their red-teaming protocols and PatientSafetyBench dataset to evaluate safety from multiple user perspectives.", "conclusion": "This work establishes a foundational framework for assessing and improving the safety of medical LLMs in diverse user scenarios, paving the way for safer applications in healthcare."}}
{"id": "2507.07461", "pdf": "https://arxiv.org/pdf/2507.07461", "abs": "https://arxiv.org/abs/2507.07461", "authors": ["Joshua Murphy", "Conor Rosato", "Andrew Millard", "Lee Devlin", "Paul Horridge", "Simon Maskell"], "title": "Hess-MC2: Sequential Monte Carlo Squared using Hessian Information and Second Order Proposals", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "Accepted to IEEE Machine Learning Signal Processing conference 2025", "summary": "When performing Bayesian inference using Sequential Monte Carlo (SMC)\nmethods, two considerations arise: the accuracy of the posterior approximation\nand computational efficiency. To address computational demands, Sequential\nMonte Carlo Squared (SMC$^2$) is well-suited for high-performance computing\n(HPC) environments. The design of the proposal distribution within SMC$^2$ can\nimprove accuracy and exploration of the posterior as poor proposals may lead to\nhigh variance in importance weights and particle degeneracy. The\nMetropolis-Adjusted Langevin Algorithm (MALA) uses gradient information so that\nparticles preferentially explore regions of higher probability. In this paper,\nwe extend this idea by incorporating second-order information, specifically the\nHessian of the log-target. While second-order proposals have been explored\npreviously in particle Markov Chain Monte Carlo (p-MCMC) methods, we are the\nfirst to introduce them within the SMC$^2$ framework. Second-order proposals\nnot only use the gradient (first-order derivative), but also the curvature\n(second-order derivative) of the target distribution. Experimental results on\nsynthetic models highlight the benefits of our approach in terms of step-size\nselection and posterior approximation accuracy when compared to other\nproposals.", "AI": {"tldr": "This paper incorporates second-order derivative information to improve Sequential Monte Carlo Squared (SMC$^2$) methods for Bayesian inference, increasing efficiency and accuracy.", "motivation": "Address the computational efficiency and accuracy challenges in Bayesian inference using SMC$^2$, by improving proposal distributions with advanced gradient and curvature information.", "method": "Extend the SMC$^2$ framework by integrating second-order proposal distributions, leveraging both the gradient (first-order) and curvature (second-order).", "result": "Experimental results on synthetic models show improved step-size selection and more accurate posterior approximation compared to existing methods.", "conclusion": "Second-order proposals within SMC$^2$ enhance computational performance and posterior exploration, making it effective for HPC-based Bayesian inference."}}
{"id": "2507.07138", "pdf": "https://arxiv.org/pdf/2507.07138", "abs": "https://arxiv.org/abs/2507.07138", "authors": ["Francesco Ferrini", "Veronica Lachi", "Antonio Longa", "Bruno Lepri", "Andrea Passerini"], "title": "GNNs Meet Sequence Models Along the Shortest-Path: an Expressive Method for Link Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle to capture the link-specific\nstructural patterns crucial for accurate link prediction, as their node-centric\nmessage-passing schemes overlook the subgraph structures connecting a pair of\nnodes. Existing methods to inject such structural context either incur high\ncomputational cost or rely on simplistic heuristics (e.g., common neighbor\ncounts) that fail to model multi-hop dependencies. We introduce SP4LP (Shortest\nPath for Link Prediction), a novel framework that combines GNN-based node\nencodings with sequence modeling over shortest paths. Specifically, SP4LP first\napplies a GNN to compute representations for all nodes, then extracts the\nshortest path between each candidate node pair and processes the resulting\nsequence of node embeddings using a sequence model. This design enables SP4LP\nto capture expressive multi-hop relational patterns with computational\nefficiency. Empirically, SP4LP achieves state-of-the-art performance across\nlink prediction benchmarks. Theoretically, we prove that SP4LP is strictly more\nexpressive than standard message-passing GNNs and several state-of-the-art\nstructural features methods, establishing it as a general and principled\napproach for link prediction in graphs.", "AI": {"tldr": "SP4LP, a new framework, enhances link prediction by combining GNNs with sequence modeling over shortest paths to capture multi-hop relational patterns effectively.", "motivation": "Address the inability of GNNs to incorporate link-specific structural patterns for accurate link prediction due to their node-centric design.", "method": "SP4LP integrates GNN-based node encodings with a sequence model applied to shortest path structures between node pairs, emphasizing efficiency and multi-hop relational patterns.", "result": "SP4LP achieves state-of-the-art results across link prediction benchmarks, demonstrating higher expressiveness than standard GNNs and structural feature methods.", "conclusion": "SP4LP establishes itself as an efficient and principled approach for link prediction, enhancing both empirical results and theoretical expressiveness beyond other methods."}}
{"id": "2507.07148", "pdf": "https://arxiv.org/pdf/2507.07148", "abs": "https://arxiv.org/abs/2507.07148", "authors": ["Getamesay Haile Dagnaw", "Yanming Zhu", "Muhammad Hassan Maqsood", "Wencheng Yang", "Xingshuai Dong", "Xuefei Yin", "Alan Wee-Chung Liew"], "title": "Explainable Artificial Intelligence in Biomedical Image Analysis: A Comprehensive Survey", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Explainable artificial intelligence (XAI) has become increasingly important\nin biomedical image analysis to promote transparency, trust, and clinical\nadoption of DL models. While several surveys have reviewed XAI techniques, they\noften lack a modality-aware perspective, overlook recent advances in multimodal\nand vision-language paradigms, and provide limited practical guidance. This\nsurvey addresses this gap through a comprehensive and structured synthesis of\nXAI methods tailored to biomedical image analysis.We systematically categorize\nXAI methods, analyzing their underlying principles, strengths, and limitations\nwithin biomedical contexts. A modality-centered taxonomy is proposed to align\nXAI methods with specific imaging types, highlighting the distinct\ninterpretability challenges across modalities. We further examine the emerging\nrole of multimodal learning and vision-language models in explainable\nbiomedical AI, a topic largely underexplored in previous work. Our\ncontributions also include a summary of widely used evaluation metrics and\nopen-source frameworks, along with a critical discussion of persistent\nchallenges and future directions. This survey offers a timely and in-depth\nfoundation for advancing interpretable DL in biomedical image analysis.", "AI": {"tldr": "The paper surveys explainable AI (XAI) methods for biomedical image analysis, proposing a modality-focused taxonomy and exploring underexamined areas like multimodal learning and vision-language models.", "motivation": "The study aims to address gaps in XAI reviews, particularly in considering modality-specific challenges, multimodal paradigms, and practical guidance for biomedical image analysis.", "method": "The authors systematically categorize XAI approaches, propose a taxonomy for imaging modalities, review emerging multimodal and vision-language methods, and provide metrics and frameworks for evaluation.", "result": "The paper synthesizes XAI methods tailored to biomedical image analysis, highlights trends and challenges across modalities, and summarizes existing evaluation tools while identifying future directions.", "conclusion": "This survey sets a detailed foundation for improving interpretability in deep learning models for biomedical imaging and highlights the need for continued research in multimodal and vision-language-based XAI."}}
{"id": "2507.07907", "pdf": "https://arxiv.org/pdf/2507.07907", "abs": "https://arxiv.org/abs/2507.07907", "authors": ["Francesca Mignacco", "Francesco Mori"], "title": "A statistical physics framework for optimal learning", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "q-bio.NC"], "comment": "35 pages, 13 figures", "summary": "Learning is a complex dynamical process shaped by a range of interconnected\ndecisions. Careful design of hyperparameter schedules for artificial neural\nnetworks or efficient allocation of cognitive resources by biological learners\ncan dramatically affect performance. Yet, theoretical understanding of optimal\nlearning strategies remains sparse, especially due to the intricate interplay\nbetween evolving meta-parameters and nonlinear learning dynamics. The search\nfor optimal protocols is further hindered by the high dimensionality of the\nlearning space, often resulting in predominantly heuristic, difficult to\ninterpret, and computationally demanding solutions. Here, we combine\nstatistical physics with control theory in a unified theoretical framework to\nidentify optimal protocols in prototypical neural network models. In the\nhigh-dimensional limit, we derive closed-form ordinary differential equations\nthat track online stochastic gradient descent through low-dimensional order\nparameters. We formulate the design of learning protocols as an optimal control\nproblem directly on the dynamics of the order parameters with the goal of\nminimizing the generalization error at the end of training. This framework\nencompasses a variety of learning scenarios, optimization constraints, and\ncontrol budgets. We apply it to representative cases, including optimal\ncurricula, adaptive dropout regularization and noise schedules in denoising\nautoencoders. We find nontrivial yet interpretable strategies highlighting how\noptimal protocols mediate crucial learning tradeoffs, such as maximizing\nalignment with informative input directions while minimizing noise fitting.\nFinally, we show how to apply our framework to real datasets. Our results\nestablish a principled foundation for understanding and designing optimal\nlearning protocols and suggest a path toward a theory of meta-learning grounded\nin statistical physics.", "AI": {"tldr": "The paper combines statistical physics and control theory to derive optimal learning protocols, simplifying complex dynamics in neural network training.", "motivation": "To address the challenges in understanding and designing optimal learning strategies due to evolving meta-parameters and nonlinear dynamics.", "method": "A theoretical framework is introduced that leverages statistical physics and control theory, deriving ordinary differential equations to model high-dimensional neural learning processes.", "result": "Derivation of interpretable learning strategies for curriculum design, dropout regularization, and noise schedules that optimize generalization error.", "conclusion": "The framework provides a foundation for principled design of learning protocols and advances meta-learning theory using statistical physics."}}
{"id": "2507.07734", "pdf": "https://arxiv.org/pdf/2507.07734", "abs": "https://arxiv.org/abs/2507.07734", "authors": ["Michael Neumeier", "Jules Lecomte", "Nils Kazinski", "Soubarna Banik", "Bing Li", "Axel von Arnim"], "title": "EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream Spiking Neural Networks", "categories": ["cs.CV", "cs.NE"], "comment": "International Conference on Neuromorphic Systems (ICONS) 2025", "summary": "Recognizing human activities early is crucial for the safety and\nresponsiveness of human-robot and human-machine interfaces. Due to their high\ntemporal resolution and low latency, event-based vision sensors are a perfect\nmatch for this early recognition demand. However, most existing processing\napproaches accumulate events to low-rate frames or space-time voxels which\nlimits the early prediction capabilities. In contrast, spiking neural networks\n(SNNs) can process the events at a high-rate for early predictions, but most\nworks still fall short on final accuracy. In this work, we introduce a\nhigh-rate two-stream SNN which closes this gap by outperforming previous work\nby 2% in final accuracy on the large-scale THU EACT-50 dataset. We benchmark\nthe SNNs within a novel early event-based recognition framework by reporting\nTop-1 and Top-5 recognition scores for growing observation time. Finally, we\nexemplify the impact of these methods on a real-world task of early action\ntriggering for human motion capture in sports.", "AI": {"tldr": "The paper proposes a high-rate two-stream Spiking Neural Network (SNN) for early human activity recognition, achieving higher accuracy and demonstrating its application in sports motion capture.", "motivation": "Early human activity recognition is vital for safe and responsive interactions in human-robot and human-machine interfaces. Event-based vision sensors offer high temporal resolution and low latency, but existing approaches limit their early prediction potential.", "method": "The authors developed a high-rate two-stream Spiking Neural Network (SNN) and integrated it into an early event-based recognition framework to improve early prediction and evaluation accuracy.", "result": "The proposed SNN improves final recognition accuracy by 2% on the large-scale THU EACT-50 dataset and demonstrates better tracking for human motion capture in sports applications.", "conclusion": "This study highlights the advantages of high-rate SNNs for event-based human activity recognition, showing improvements in prediction accuracy as well as practical implications for real-world tasks like sports."}}
{"id": "2507.07257", "pdf": "https://arxiv.org/pdf/2507.07257", "abs": "https://arxiv.org/abs/2507.07257", "authors": ["Licong Xu", "Milind Sarkar", "Anto I. Lonappan", "\u00cd\u00f1igo Zubeldia", "Pablo Villanueva-Domingo", "Santiago Casas", "Christian Fidler", "Chetana Amancharla", "Ujjwal Tiwari", "Adrian Bayer", "Chadi Ait Ekiou", "Miles Cranmer", "Adrian Dimitrov", "James Fergusson", "Kahaan Gandhi", "Sven Krippendorf", "Andrew Laverick", "Julien Lesgourgues", "Antony Lewis", "Thomas Meier", "Blake Sherwin", "Kristen Surrao", "Francisco Villaescusa-Navarro", "Chi Wang", "Xueqing Xu", "Boris Bolliet"], "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "categories": ["cs.AI", "astro-ph.IM", "cs.CL", "cs.MA"], "comment": "Accepted contribution to the ICML 2025 Workshop on Machine Learning\n  for Astrophysics. Code: https://github.com/CMBAgents/cmbagent; Videos:\n  https://www.youtube.com/@cmbagent; HuggingFace:\n  https://huggingface.co/spaces/astropilot-ai/cmbagent; Cloud:\n  https://cmbagent.cloud", "summary": "We present a multi-agent system for automation of scientific research tasks,\ncmbagent. The system is formed by about 30 Large Language Model (LLM) agents\nand implements a Planning & Control strategy to orchestrate the agentic\nworkflow, with no human-in-the-loop at any point. Each agent specializes in a\ndifferent task (performing retrieval on scientific papers and codebases,\nwriting code, interpreting results, critiquing the output of other agents) and\nthe system is able to execute code locally. We successfully apply cmbagent to\ncarry out a PhD level cosmology task (the measurement of cosmological\nparameters using supernova data) and evaluate its performance on two benchmark\nsets, finding superior performance over state-of-the-art LLMs. The source code\nis available on GitHub, demonstration videos are also available, and the system\nis deployed on HuggingFace and will be available on the cloud.", "AI": {"tldr": "The paper introduces cmbagent, a multi-agent system of about 30 Large Language Model agents designed to automate scientific research tasks, achieving superior performance in cosmology research and benchmarks.", "motivation": "The paper aims to address the need for automating complex scientific research and workflows without human intervention, enhancing productivity and accuracy.", "method": "The system uses a Planning & Control strategy with 30 LLM agents, each specializing in tasks like retrieving scientific information, coding, interpreting results, and critiquing outputs. It fully automates workflows and executes code locally.", "result": "The system successfully completed a PhD-level cosmology task, measured cosmological parameters using supernova data, and outperformed state-of-the-art LLMs in two benchmark tests.", "conclusion": "cmbagent demonstrates significant potential for automating scientific research tasks efficiently and accurately, providing superior results, and is accessible for public use via multiple platforms."}}
{"id": "2507.07130", "pdf": "https://arxiv.org/pdf/2507.07130", "abs": "https://arxiv.org/abs/2507.07130", "authors": ["Zihan Zhang", "Leon Wong", "Blesson Varghese"], "title": "Ampere: Communication-Efficient and High-Accuracy Split Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "A Federated Learning (FL) system collaboratively trains neural networks\nacross devices and a server but is limited by significant on-device computation\ncosts. Split Federated Learning (SFL) systems mitigate this by offloading a\nblock of layers of the network from the device to a server. However, in doing\nso, it introduces large communication overheads due to frequent exchanges of\nintermediate activations and gradients between devices and the server and\nreduces model accuracy for non-IID data. We propose Ampere, a novel\ncollaborative training system that simultaneously minimizes on-device\ncomputation and device-server communication while improving model accuracy.\nUnlike SFL, which uses a global loss by iterative end-to-end training, Ampere\ndevelops unidirectional inter-block training to sequentially train the device\nand server block with a local loss, eliminating the transfer of gradients. A\nlightweight auxiliary network generation method decouples training between the\ndevice and server, reducing frequent intermediate exchanges to a single\ntransfer, which significantly reduces the communication overhead. Ampere\nmitigates the impact of data heterogeneity by consolidating activations\ngenerated by the trained device block to train the server block, in contrast to\nSFL, which trains on device-specific, non-IID activations. Extensive\nexperiments on multiple CNNs and transformers show that, compared to\nstate-of-the-art SFL baseline systems, Ampere (i) improves model accuracy by up\nto 13.26% while reducing training time by up to 94.6%, (ii) reduces\ndevice-server communication overhead by up to 99.1% and on-device computation\nby up to 93.13%, and (iii) reduces standard deviation of accuracy by 53.39% for\nvarious non-IID degrees highlighting superior performance when faced with\nheterogeneous data.", "AI": {"tldr": "Ampere proposes a method to reduce on-device computation, device-server communication, and improve model accuracy in federated learning systems.", "motivation": "Federated and Split Federated Learning systems face challenges like high on-device computation cost, communication overhead, and reduced accuracy on non-IID data.", "method": "Ampere employs unidirectional inter-block training and a lightweight auxiliary network to reduce gradient transfers and intermediate exchanges; it also consolidates activations for better handling of non-IID data.", "result": "Ampere showed up to 13.26% accuracy improvement, 94.6% reduction in training time, 99.1% reduction in communication overhead, and 93.13% reduction in on-device computation.", "conclusion": "Ampere effectively addresses major limitations of existing SFL systems, showcasing significant improvements in accuracy, efficiency, and handling of heterogeneity."}}
{"id": "2507.07682", "pdf": "https://arxiv.org/pdf/2507.07682", "abs": "https://arxiv.org/abs/2507.07682", "authors": ["Kaicheng Huang", "Fanyu Wang", "Yutan Huang", "Chetan Arora"], "title": "Prompt Engineering for Requirements Engineering: A Literature Review and Roadmap", "categories": ["cs.SE"], "comment": null, "summary": "Advancements in large language models (LLMs) have led to a surge of prompt\nengineering (PE) techniques that can enhance various requirements engineering\n(RE) tasks. However, current LLMs are often characterized by significant\nuncertainty and a lack of controllability. This absence of clear guidance on\nhow to effectively prompt LLMs acts as a barrier to their trustworthy\nimplementation in the RE field. We present the first roadmap-oriented\nsystematic literature review of Prompt Engineering for RE (PE4RE). Following\nKitchenham's and Petersen's secondary-study protocol, we searched six digital\nlibraries, screened 867 records, and analyzed 35 primary studies. To bring\norder to a fragmented landscape, we propose a hybrid taxonomy that links\ntechnique-oriented patterns (e.g., few-shot, Chain-of-Thought) to task-oriented\nRE roles (elicitation, validation, traceability). Two research questions, with\nfive sub-questions, map the tasks addressed, LLM families used, and prompt\ntypes adopted, and expose current limitations and research gaps. Finally, we\noutline a step-by-step roadmap showing how today's ad-hoc PE prototypes can\nevolve into reproducible, practitioner-friendly workflows.", "AI": {"tldr": "The paper conducts a systematic literature review on prompt engineering (PE) for requirements engineering (RE) aimed at addressing issues of LLM uncertainty and lack of control.", "motivation": "To address the uncertainty and lack of control in applying large language models (LLMs) for requirements engineering (RE) tasks, limiting their trustworthy implementation.", "method": "Conducted a systematic review of prompt engineering literature using secondary-study protocols, analyzing 35 out of 867 screened studies to create a taxonomy linking technique patterns and RE tasks.", "result": "Identified technique-task linkages, current limitations, and research gaps. Developed a roadmap for transitioning ad-hoc prototypes into reproducible workflows for practitioners.", "conclusion": "Prompt engineering can significantly enhance RE tasks if systematic, reproducible strategies are developed, addressing the fragmented nature of current methods."}}
{"id": "2507.07315", "pdf": "https://arxiv.org/pdf/2507.07315", "abs": "https://arxiv.org/abs/2507.07315", "authors": ["Ricardo Vega", "Cameron Nowzari"], "title": "Classifying Emergence in Robot Swarms: An Observer-Dependent Approach", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "25 pages, 3 tables, 8 figures", "summary": "Emergence and swarms are widely discussed topics, yet no consensus exists on\ntheir formal definitions. This lack of agreement makes it difficult not only\nfor new researchers to grasp these concepts, but also for experts who may use\nthe same terms to mean different things. Many attempts have been made to\nobjectively define 'swarm' or 'emergence,' with recent work highlighting the\nrole of the external observer. Still, several researchers argue that once an\nobserver's vantage point (e.g., scope, resolution, context) is established, the\nterms can be made objective or measured quantitatively. In this note, we\npropose a framework to discuss these ideas rigorously by separating externally\nobservable states from latent, unobservable ones. This allows us to compare and\ncontrast existing definitions of swarms and emergence on common ground. We\nargue that these concepts are ultimately subjective-shaped less by the system\nitself than by the perception and tacit knowledge of the observer.\nSpecifically, we suggest that a 'swarm' is not defined by its group behavior\nalone, but by the process generating that behavior. Our broader goal is to\nsupport the design and deployment of robotic swarm systems, highlighting the\ncritical distinction between multi-robot systems and true swarms.", "AI": {"tldr": "The paper examines the concepts of emergence and swarms, proposing a framework to discuss them rigorously by distinguishing observable and latent states, ultimately arguing these concepts are subjective and shaped by observers.", "motivation": "The lack of agreed-upon definitions for 'swarm' and 'emergence' creates confusion both for new researchers and for experts using these terms differently. A rigorous framework is needed to support understanding and robotic swarm system design.", "method": "The authors propose a framework that separates externally observable states from latent, unobservable ones to rigorously compare and review existing definitions of swarms and emergence.", "result": "The paper argues that swarms and emergence are subjective concepts shaped by the observer's perception rather than the intrinsic system properties. It highlights that a swarm's behavior is defined by the process generating it, not the behavior itself.", "conclusion": "The study underscores that clear differentiation is crucial for understanding swarms and emergence, supporting precise communication for the design and deployment of robotic swarm systems."}}
{"id": "2507.07280", "pdf": "https://arxiv.org/pdf/2507.07280", "abs": "https://arxiv.org/abs/2507.07280", "authors": ["Mariah Bradford", "Nikhil Krishnaswamy", "Nathaniel Blanchard"], "title": "The Impact of Background Speech on Interruption Detection in Collaborative Groups", "categories": ["cs.CL"], "comment": "Long Paper AIED 2025", "summary": "Interruption plays a crucial role in collaborative learning, shaping group\ninteractions and influencing knowledge construction. AI-driven support can\nassist teachers in monitoring these interactions. However, most previous work\non interruption detection and interpretation has been conducted in\nsingle-conversation environments with relatively clean audio. AI agents\ndeployed in classrooms for collaborative learning within small groups will need\nto contend with multiple concurrent conversations -- in this context,\noverlapping speech will be ubiquitous, and interruptions will need to be\nidentified in other ways. In this work, we analyze interruption detection in\nsingle-conversation and multi-group dialogue settings. We then create a\nstate-of-the-art method for interruption identification that is robust to\noverlapping speech, and thus could be deployed in classrooms. Further, our work\nhighlights meaningful linguistic and prosodic information about how\ninterruptions manifest in collaborative group interactions. Our investigation\nalso paves the way for future works to account for the influence of overlapping\nspeech from multiple groups when tracking group dialog.", "AI": {"tldr": "The paper develops a method to identify interruptions robustly in overlapping speech scenarios, especially in classroom settings with multiple concurrent group conversations.", "motivation": "The study aims to address the limitations of existing interruption detection systems, which primarily operate in single-conversation environments with clean audio, making them unsuitable for complex classroom settings where overlapping speech is widespread.", "method": "The researchers analyze interruption detection in both single-conversation and multi-group dialogue settings and develop a state-of-the-art method incorporating linguistic and prosodic features to handle overlapping speech effectively.", "result": "The proposed method is capable of reliably identifying interruptions in environments with overlapping speech, and it extracts meaningful linguistic and prosodic insights on interruptions in collaborative groups.", "conclusion": "The findings establish the groundwork for deploying AI systems in classrooms to monitor collaborative group interactions and underscore the importance of accounting for overlapping speech when tracking group dialogues."}}
{"id": "2507.07469", "pdf": "https://arxiv.org/pdf/2507.07469", "abs": "https://arxiv.org/abs/2507.07469", "authors": ["Haojie Liu", "Zihan Lin"], "title": "Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": null, "summary": "Time-series models like ARIMA remain widely used for forecasting but limited\nto linear assumptions and high computational cost in large and complex\ndatasets. We propose Galerkin-ARIMA that generalizes the AR component of ARIMA\nand replace it with a flexible spline-based function estimated by Galerkin\nprojection. This enables the model to capture nonlinear dependencies in lagged\nvalues and retain the MA component and Gaussian noise assumption. We derive a\nclosed-form OLS estimator for the Galerkin coefficients and show the model is\nasymptotically unbiased and consistent under standard conditions. Our method\nbridges classical time-series modeling and nonparametric regression, which\noffering improved forecasting performance and computational efficiency.", "AI": {"tldr": "The paper introduces Galerkin-ARIMA, a spline-based advancement over ARIMA, capturing nonlinear dependencies and improving forecasting efficiency.", "motivation": "ARIMA models are limited by linearity assumptions and inefficiencies with large, complex datasets.", "method": "The ARIMA's AR component is replaced with a spline-based function using Galerkin projection. The paper derives an OLS estimator for this new setup, ensuring unbiasedness and consistency.", "result": "The proposed method combines classical time-series modeling with nonparametric regression, achieving improved forecasting and computational efficiency.", "conclusion": "Galerkin-ARIMA enhances ARIMA by addressing nonlinearities while maintaining foundational elements, making it effective for complex forecasting tasks."}}
{"id": "2507.07140", "pdf": "https://arxiv.org/pdf/2507.07140", "abs": "https://arxiv.org/abs/2507.07140", "authors": ["Samin Yeasar Arnob", "Zhan Su", "Minseon Kim", "Oleksiy Ostapenko", "Riyasat Ohib", "Esra'a Saleh", "Doina Precup", "Lucas Caccia", "Alessandro Sordoni"], "title": "Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts", "categories": ["cs.LG"], "comment": null, "summary": "Merging parameter-efficient task experts has recently gained growing\nattention as a way to build modular architectures that can be rapidly adapted\non the fly for specific downstream tasks, without requiring additional\nfine-tuning. Typically, LoRA serves as the foundational building block of such\nparameter-efficient modular architectures, leveraging low-rank weight\nstructures to reduce the number of trainable parameters. In this paper, we\nstudy the properties of sparse adapters, which train only a subset of weights\nin the base neural network, as potential building blocks of modular\narchitectures. First, we propose a simple method for training highly effective\nsparse adapters, which is conceptually simpler than existing methods in the\nliterature and surprisingly outperforms both LoRA and full fine-tuning in our\nsetting. Next, we investigate the merging properties of these sparse adapters\nby merging adapters for up to 20 natural language processing tasks, thus\nscaling beyond what is usually studied in the literature. Our findings\ndemonstrate that sparse adapters yield superior in-distribution performance\npost-merging compared to LoRA or full model merging. Achieving strong held-out\nperformance remains a challenge for all methods considered.", "AI": {"tldr": "The study explores sparse adapters for modular architectures, showing these simple methods outperform LoRA and full fine-tuning in task merging.", "motivation": "To enable adaptable modular architectures capable of enhancing performance across diverse downstream NLP tasks without requiring further fine-tuning.", "method": "The paper introduces a simpler approach to training sparse adapters by selectively training subsets of weights and compares their performance against LoRA and full fine-tuning.", "result": "Sparse adapters demonstrate superior in-distribution performance post-merging across up to 20 NLP tasks compared to LoRA or full model merging.", "conclusion": "Sparse adapters are a promising alternative to LoRA for modular architectures despite challenges in achieving strong held-out performance."}}
{"id": "2507.07151", "pdf": "https://arxiv.org/pdf/2507.07151", "abs": "https://arxiv.org/abs/2507.07151", "authors": ["Zongmeng Zhang", "Wengang Zhou", "Jie Zhao", "Houqiang Li"], "title": "Robust Multimodal Large Language Models Against Modality Conflict", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ICML 2025", "summary": "Despite the impressive capabilities of multimodal large language models\n(MLLMs) in vision-language tasks, they are prone to hallucinations in\nreal-world scenarios. This paper investigates the hallucination phenomenon in\nMLLMs from the perspective of modality conflict. Unlike existing works focusing\non the conflicts between model responses and inputs, we study the inherent\nconflicts in inputs from different modalities that place MLLMs in a dilemma and\ndirectly lead to hallucinations. We formally define the modality conflict and\nconstruct a dataset named Multimodal Modality Conflict (MMMC) to simulate this\nphenomenon in vision-language tasks. Three methods based on prompt engineering,\nsupervised fine-tuning, and reinforcement learning are proposed to alleviate\nthe hallucination caused by modality conflict. Extensive experiments are\nconducted on the MMMC dataset to analyze the merits and demerits of these\nmethods. Our results show that the reinforcement learning method achieves the\nbest performance in mitigating the hallucination under modality conflict, while\nthe supervised fine-tuning method shows promising and stable performance. Our\nwork sheds light on the unnoticed modality conflict that leads to\nhallucinations and provides more insights into the robustness of MLLMs.", "AI": {"tldr": "This paper explores the hallucination issue in multimodal large language models (MLLMs), especially arising from conflicts between different input modalities.", "motivation": "The goal is to better understand and address hallucinations in MLLMs caused by inherent modality conflicts, which occur in real-world multi-modal inputs.", "method": "Researchers formally define modality conflict, introduce a new dataset (MMMC), and test three approaches (prompt engineering, supervised fine-tuning, reinforcement learning) to mitigate hallucinations.", "result": "The reinforcement learning method performs best, while supervised fine-tuning offers stable and promising results in reducing hallucinations.", "conclusion": "The study introduces a previously unnoticed issue of modality conflict causing hallucinations in MLLMs and provides solutions and insights for enhancing their robustness."}}
{"id": "2507.07993", "pdf": "https://arxiv.org/pdf/2507.07993", "abs": "https://arxiv.org/abs/2507.07993", "authors": ["Weihao Xia", "Cengiz Oztireli"], "title": "Multigranular Evaluation for Brain Visual Decoding", "categories": ["cs.CV", "cs.AI", "eess.IV", "q-bio.NC"], "comment": "Project: https://weihaox.github.io/BASIC", "summary": "Existing evaluation protocols for brain visual decoding predominantly rely on\ncoarse metrics that obscure inter-model differences, lack neuroscientific\nfoundation, and fail to capture fine-grained visual distinctions. To address\nthese limitations, we introduce BASIC, a unified, multigranular evaluation\nframework that jointly quantifies structural fidelity, inferential alignment,\nand contextual coherence between decoded and ground truth images. For the\nstructural level, we introduce a hierarchical suite of segmentation-based\nmetrics, including foreground, semantic, instance, and component masks,\nanchored in granularity-aware correspondence across mask structures. For the\nsemantic level, we extract structured scene representations encompassing\nobjects, attributes, and relationships using multimodal large language models,\nenabling detailed, scalable, and context-rich comparisons with ground-truth\nstimuli. We benchmark a diverse set of visual decoding methods across multiple\nstimulus-neuroimaging datasets within this unified evaluation framework.\nTogether, these criteria provide a more discriminative, interpretable, and\ncomprehensive foundation for measuring brain visual decoding methods.", "AI": {"tldr": "The paper introduces BASIC, a comprehensive framework for evaluating brain visual decoding methods with detailed structural, semantic, and contextual metrics.", "motivation": "Existing evaluation protocols for brain visual decoding lack precision, neuroscientific foundations, and the ability to capture fine-grained visual details.", "method": "The paper proposes BASIC, a unified evaluation system with multigranular metrics, including segmentation-based structural fidelity, semantic structure analysis using multimodal large language models, and contextual coherence.", "result": "BASIC provides a unified and comprehensive benchmarking tool applied to diverse visual decoding methods and datasets, revealing nuanced inter-model differences.", "conclusion": "BASIC establishes a discriminative and interpretable foundation for evaluating and advancing brain visual decoding techniques."}}
{"id": "2507.07302", "pdf": "https://arxiv.org/pdf/2507.07302", "abs": "https://arxiv.org/abs/2507.07302", "authors": ["Ashish Kumar"], "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Efficient exploration is a well known problem in deep reinforcement learning\nand this problem is exacerbated in multi-agent reinforcement learning due the\nintrinsic complexities of such algorithms. There are several approaches to\nefficiently explore an environment to learn to solve tasks by multi-agent\noperating in that environment, of which, the idea of expert exploration is\ninvestigated in this work. More specifically, this work investigates the\napplication of large-language models as expert planners for efficient\nexploration in planning based tasks for multiple agents.", "AI": {"tldr": "The paper explores using large-language models as expert planners to improve efficient exploration in multi-agent reinforcement learning for planning-based tasks.", "motivation": "Efficient exploration is a challenge in multi-agent reinforcement learning due to its inherent complexities and the need for better methods to solve tasks in environments involving multiple agents.", "method": "The study investigates leveraging large-language models as expert planners to guide efficient exploration in planning-based environments for multiple agents.", "result": "The application of large-language models demonstrates potential in improving exploration strategies in multi-agent settings for planning-based tasks.", "conclusion": "Large-language models can serve as effective expert planners, aiding in efficient exploration for multi-agent reinforcement learning problems."}}
{"id": "2507.07144", "pdf": "https://arxiv.org/pdf/2507.07144", "abs": "https://arxiv.org/abs/2507.07144", "authors": ["Hongyi Xie", "Min Zhou", "Qiao Yu", "Jialiang Yu", "Zhenli Sheng", "Hong Xie", "Defu Lian"], "title": "M$^2$-MFP: A Multi-Scale and Multi-Level Memory Failure Prediction Framework for Reliable Cloud Infrastructure", "categories": ["cs.DC"], "comment": null, "summary": "As cloud services become increasingly integral to modern IT infrastructure,\nensuring hardware reliability is essential to sustain high-quality service.\nMemory failures pose a significant threat to overall system stability, making\naccurate failure prediction through the analysis of memory error logs (i.e.,\nCorrectable Errors) imperative. Existing memory failure prediction approaches\nhave notable limitations: rule-based expert models suffer from limited\ngeneralizability and low recall rates, while automated feature extraction\nmethods exhibit suboptimal performance. To address these limitations, we\npropose M$^2$-MFP: a Multi-scale and hierarchical memory failure prediction\nframework designed to enhance the reliability and availability of cloud\ninfrastructure. M$^2$-MFP converts Correctable Errors (CEs) into multi-level\nbinary matrix representations and introduces a Binary Spatial Feature Extractor\n(BSFE) to automatically extract high-order features at both DIMM-level and\nbit-level. Building upon the BSFE outputs, we develop a dual-path temporal\nmodeling architecture: 1) a time-patch module that aggregates multi-level\nfeatures within observation windows, and 2) a time-point module that employs\ninterpretable rule-generation trees trained on bit-level patterns. Experiments\non both benchmark datasets and real-world deployment show the superiority of\nM$^2$-MFP as it outperforms existing state-of-the-art methods by significant\nmargins. Code and data are available at this repository:\nhttps://github.com/hwcloud-RAS/M2-MFP.", "AI": {"tldr": "The paper presents M$^2$-MFP, a framework designed to predict memory failures in cloud infrastructure by using a Binary Spatial Feature Extractor and dual-path temporal modeling.", "motivation": "To improve hardware reliability in modern IT infrastructure by addressing limitations in existing memory failure prediction methods, which have limited generalizability or suboptimal performance.", "method": "The framework converts memory error logs into multi-level binary matrices, extracts high-order features using a Binary Spatial Feature Extractor (BSFE), and applies a dual-path temporal model for prediction using both aggregation and interpretable rule-generation trees.", "result": "The proposed method outperforms state-of-the-art approaches on benchmark datasets and real-world applications, demonstrating increased accuracy and reliability.", "conclusion": "M$^2$-MFP significantly enhances memory failure prediction capabilities, improving the reliability and availability of cloud infrastructures."}}
{"id": "2507.07689", "pdf": "https://arxiv.org/pdf/2507.07689", "abs": "https://arxiv.org/abs/2507.07689", "authors": ["Chetan Arora", "Fanyu Wang", "Chakkrit Tantithamthavorn", "Aldeida Aleti", "Shaun Kenyon"], "title": "From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry", "categories": ["cs.SE"], "comment": null, "summary": "Requirements engineering (RE) in the space industry is inherently complex,\ndemanding high precision, alignment with rigorous standards, and adaptability\nto mission-specific constraints. Smaller space organisations and new entrants\noften struggle to derive actionable requirements from extensive, unstructured\ndocuments such as mission briefs, interface specifications, and regulatory\nstandards. In this innovation opportunity paper, we explore the potential of\nRetrieval-Augmented Generation (RAG) models to support and (semi-)automate\nrequirements generation in the space domain. We present a modular, AI-driven\napproach that preprocesses raw space mission documents, classifies them into\nsemantically meaningful categories, retrieves contextually relevant content\nfrom domain standards, and synthesises draft requirements using large language\nmodels (LLMs). We apply the approach to a real-world mission document from the\nspace domain to demonstrate feasibility and assess early outcomes in\ncollaboration with our industry partner, Starbound Space Solutions. Our\npreliminary results indicate that the approach can reduce manual effort,\nimprove coverage of relevant requirements, and support lightweight compliance\nalignment. We outline a roadmap toward broader integration of AI in RE\nworkflows, intending to lower barriers for smaller organisations to participate\nin large-scale, safety-critical missions.", "AI": {"tldr": "The paper investigates how Retrieval-Augmented Generation (RAG) models can semi-automate requirements engineering in the space industry by processing mission documents, categorizing them, retrieving relevant content, and generating requirements using large language models, showcasing potential benefits like reduced manual effort and better compliance.", "motivation": "Smaller space organizations face challenges in deriving actionable requirements from unstructured documents due to the complexity and rigor of the space industry's standards, creating a need for innovative approaches to requirements engineering.", "method": "The authors present a modular, AI-driven approach that preprocesses mission documents, classifies content into semantic categories, retrieves relevant standards-based information, and creates draft requirements using large language models (LLMs).", "result": "Applying the proposed approach to a real-world mission document showed that it reduced manual effort, enhanced the coverage of relevant requirements, and supported compliance alignment, as tested in collaboration with Starbound Space Solutions.", "conclusion": "This study demonstrates the feasibility of using AI to support requirements engineering in the space domain, potentially lowering barriers for smaller organizations and outlining a roadmap for broader AI integration in RE workflows."}}
{"id": "2507.07327", "pdf": "https://arxiv.org/pdf/2507.07327", "abs": "https://arxiv.org/abs/2507.07327", "authors": ["Brian B. Vuong", "Josie Davidson", "Sangheui Cheon", "Kyujin Cho", "Allison M. Okamura"], "title": "Effects of Wrist-Worn Haptic Feedback on Force Accuracy and Task Speed during a Teleoperated Robotic Surgery Task", "categories": ["cs.RO", "cs.HC"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Previous work has shown that the addition of haptic feedback to the hands can\nimprove awareness of tool-tissue interactions and enhance performance of\nteleoperated tasks in robot-assisted minimally invasive surgery. However,\nhand-based haptic feedback occludes direct interaction with the manipulanda of\nsurgeon console in teleoperated surgical robots. We propose relocating haptic\nfeedback to the wrist using a wearable haptic device so that haptic feedback\nmechanisms do not need to be integrated into the manipulanda. However, it is\nunknown if such feedback will be effective, given that it is not co-located\nwith the finger movements used for manipulation. To test if relocated haptic\nfeedback improves force application during teleoperated tasks using da Vinci\nResearch Kit (dVRK) surgical robot, participants learned to palpate a phantom\ntissue to desired forces. A soft pneumatic wrist-worn haptic device with an\nanchoring system renders tool-tissue interaction forces to the wrist of the\nuser. Participants performed the palpation task with and without wrist-worn\nhaptic feedback and were evaluated for the accuracy of applied forces.\nParticipants demonstrated statistically significant lower force error when\nwrist-worn haptic feedback was provided. Participants also performed the\npalpation task with longer movement times when provided wrist-worn haptic\nfeedback, indicating that the haptic feedback may have caused participants to\noperate at a different point in the speed-accuracy tradeoff curve.", "AI": {"tldr": "This study explored relocating haptic feedback to the wrist to improve force application in robotic surgeries, showing improved accuracy despite altered speed-accuracy tradeoffs.", "motivation": "To address the challenge of occlusion and interruption caused by hand-based haptic feedback mechanisms for improving teleoperation task accuracy and performance in robot-assisted surgeries.", "method": "Participants used the da Vinci Research Kit (dVRK) surgical robot to perform tissue palpation tasks under two conditions: with and without a wrist-worn haptic device. The device communicated tool-tissue interaction forces via soft pneumatic technology.", "result": "Statistically significant lower force errors were observed with wrist-worn haptic feedback, indicating improved accuracy. However, movement times increased, suggesting participants adjusted to a different speed-accuracy tradeoff to accomplish the tasks.", "conclusion": "Wrist-worn haptic feedback enhances accuracy in teleoperated surgical tasks, but it may influence speed as users shift along the speed-accuracy tradeoff curve. Relocating feedback to the wrist appears effective for improving surgical performance."}}
{"id": "2507.07307", "pdf": "https://arxiv.org/pdf/2507.07307", "abs": "https://arxiv.org/abs/2507.07307", "authors": ["Anirban Saha Anik", "Xiaoying Song", "Elliott Wang", "Bryan Wang", "Bengisu Yarimbas", "Lingzi Hong"], "title": "Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) incorporated with Retrieval-Augmented Generation\n(RAG) have demonstrated powerful capabilities in generating counterspeech\nagainst misinformation. However, current studies rely on limited evidence and\noffer less control over final outputs. To address these challenges, we propose\na Multi-agent Retrieval-Augmented Framework to generate counterspeech against\nhealth misinformation, incorporating multiple LLMs to optimize knowledge\nretrieval, evidence enhancement, and response refinement. Our approach\nintegrates both static and dynamic evidence, ensuring that the generated\ncounterspeech is relevant, well-grounded, and up-to-date. Our method\noutperforms baseline approaches in politeness, relevance, informativeness, and\nfactual accuracy, demonstrating its effectiveness in generating high-quality\ncounterspeech. To further validate our approach, we conduct ablation studies to\nverify the necessity of each component in our framework. Furthermore, human\nevaluations reveal that refinement significantly enhances counterspeech quality\nand obtains human preference.", "AI": {"tldr": "The paper proposes a Multi-agent Retrieval-Augmented Framework using multiple large language models to enhance the generation of counterspeech against health misinformation.", "motivation": "Existing methods for generating counterspeech suffer from limited evidence and lack control over the final output.", "method": "The framework utilizes multiple LLMs and incorporates static and dynamic evidence into three steps: knowledge retrieval, evidence enhancement, and response refinement.", "result": "The approach outperformed baseline methods in terms of politeness, relevance, informativeness, and factual accuracy, validated by both ablation studies and human evaluations.", "conclusion": "The proposed framework effectively produces high-quality counterspeech addressing health misinformation with improved refinement and human preference."}}
{"id": "2507.07771", "pdf": "https://arxiv.org/pdf/2507.07771", "abs": "https://arxiv.org/abs/2507.07771", "authors": ["Shuying Huang", "Junpeng Li", "Changchun Hua", "Yana Yang"], "title": "A Unified Empirical Risk Minimization Framework for Flexible N-Tuples Weak Supervision", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "To alleviate the annotation burden in supervised learning, N-tuples learning\nhas recently emerged as a powerful weakly-supervised method. While existing\nN-tuples learning approaches extend pairwise learning to higher-order\ncomparisons and accommodate various real-world scenarios, they often rely on\ntask-specific designs and lack a unified theoretical foundation. In this paper,\nwe propose a general N-tuples learning framework based on empirical risk\nminimization, which systematically integrates pointwise unlabeled data to\nenhance learning performance. This paper first unifies the data generation\nprocesses of N-tuples and pointwise unlabeled data under a shared probabilistic\nformulation. Based on this unified view, we derive an unbiased empirical risk\nestimator that generalizes a broad class of existing N-tuples models. We\nfurther establish a generalization error bound for theoretical support. To\ndemonstrate the flexibility of the framework, we instantiate it in four\nrepresentative weakly supervised scenarios, each recoverable as a special case\nof our general model. Additionally, to address overfitting issues arising from\nnegative risk terms, we adopt correction functions to adjust the empirical\nrisk. Extensive experiments on benchmark datasets validate the effectiveness of\nthe proposed framework and demonstrate that leveraging pointwise unlabeled data\nconsistently improves generalization across various N-tuples learning tasks.", "AI": {"tldr": "The paper proposes a general framework for N-tuples learning that unifies various weakly supervised scenarios and integrates pointwise unlabeled data to improve learning performance.", "motivation": "To reduce the dependency on labor-intensive annotations in supervised learning while extending the applicability and theoretical foundation of N-tuples learning.", "method": "The authors present a unified probabilistic formulation for N-tuples and pointwise unlabeled data, derive an unbiased empirical risk estimator, establish a generalization error bound, and implement correction functions to prevent overfitting.", "result": "The proposed framework demonstrates improved generalization and effectiveness across multiple weakly-supervised learning tasks, particularly when leveraging pointwise unlabeled data.", "conclusion": "This study provides a theoretical and practical foundation for N-tuples learning, allowing its application in diverse weakly supervised scenarios and improving performance through pointwise unlabeled data."}}
{"id": "2507.07141", "pdf": "https://arxiv.org/pdf/2507.07141", "abs": "https://arxiv.org/abs/2507.07141", "authors": ["Dongxiao He", "Yongqi Huang", "Jitao Zhao", "Xiaobao Wang", "Zhen Wang"], "title": "Str-GCL: Structural Commonsense Driven Graph Contrastive Learning", "categories": ["cs.LG"], "comment": "Accepted by WWW 2025", "summary": "Graph Contrastive Learning (GCL) is a widely adopted approach in\nself-supervised graph representation learning, applying contrastive objectives\nto produce effective representations. However, current GCL methods primarily\nfocus on capturing implicit semantic relationships, often overlooking the\nstructural commonsense embedded within the graph's structure and attributes,\nwhich contains underlying knowledge crucial for effective representation\nlearning. Due to the lack of explicit information and clear guidance in general\ngraph, identifying and integrating such structural commonsense in GCL poses a\nsignificant challenge. To address this gap, we propose a novel framework called\nStructural Commonsense Unveiling in Graph Contrastive Learning (Str-GCL).\nStr-GCL leverages first-order logic rules to represent structural commonsense\nand explicitly integrates them into the GCL framework. It introduces\ntopological and attribute-based rules without altering the original graph and\nemploys a representation alignment mechanism to guide the encoder in\neffectively capturing this commonsense. To the best of our knowledge, this is\nthe first attempt to directly incorporate structural commonsense into GCL.\nExtensive experiments demonstrate that Str-GCL outperforms existing GCL\nmethods, providing a new perspective on leveraging structural commonsense in\ngraph representation learning.", "AI": {"tldr": "The paper introduces Str-GCL, a framework that incorporates structural commonsense into Graph Contrastive Learning (GCL) using first-order logic rules, achieving superior performance over existing methods.", "motivation": "Current GCL methods overlook structural commonsense embedded in graphs, which is crucial for effective representation learning, due to the lack of explicit information and guidance in general graphs.", "method": "The paper proposes Str-GCL, which uses first-order logic rules to model structural commonsense through topological and attribute-based rules, alongside a representation alignment mechanism, without altering the original graph.", "result": "Str-GCL outperforms existing GCL methods in effectively capturing structural commonsense for graph representation learning based on extensive experiments.", "conclusion": "Explicitly integrating structural commonsense into GCL frameworks is viable and effective, as shown by the improved performance of Str-GCL, paving the way for new perspectives in graph representation learning."}}
{"id": "2507.07153", "pdf": "https://arxiv.org/pdf/2507.07153", "abs": "https://arxiv.org/abs/2507.07153", "authors": ["Antonella Barisic Kulas", "Frano Petric", "Stjepan Bogdan"], "title": "Aerial Maritime Vessel Detection and Identification", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Preprint. ICUAS 2025", "summary": "Autonomous maritime surveillance and target vessel identification in\nenvironments where Global Navigation Satellite Systems (GNSS) are not available\nis critical for a number of applications such as search and rescue and threat\ndetection. When the target vessel is only described by visual cues and its last\nknown position is not available, unmanned aerial vehicles (UAVs) must rely\nsolely on on-board vision to scan a large search area under strict\ncomputational constraints. To address this challenge, we leverage the YOLOv8\nobject detection model to detect all vessels in the field of view. We then\napply feature matching and hue histogram distance analysis to determine whether\nany detected vessel corresponds to the target. When found, we localize the\ntarget using simple geometric principles. We demonstrate the proposed method in\nreal-world experiments during the MBZIRC2023 competition, integrated into a\nfully autonomous system with GNSS-denied navigation. We also evaluate the\nimpact of perspective on detection accuracy and localization precision and\ncompare it with the oracle approach.", "AI": {"tldr": "The study develops a UAV-based maritime surveillance system for identifying target vessels in GNSS-denied environments, utilizing YOLOv8 object detection, feature matching, and hue histogram analysis.", "motivation": "To address the need for autonomous maritime surveillance in GNSS-denied environments for applications like search and rescue or threat detection.", "method": "The authors use YOLOv8 object detection to detect vessels, followed by feature matching and hue histogram distance analysis for target identification. Localization is achieved via simple geometric principles.", "result": "The system was demonstrated during MBZIRC2023 in real-world experiments, successfully integrating GNSS-denied navigation and showcasing its efficiency in target detection and localization.", "conclusion": "The approach offers an effective UAV-based solution for GNSS-denied target vessel identification, with high potential for practical applications in maritime operations."}}
{"id": "2507.07306", "pdf": "https://arxiv.org/pdf/2507.07306", "abs": "https://arxiv.org/abs/2507.07306", "authors": ["Yichen Lu", "Wei Dai", "Jiaen Liu", "Ching Wing Kwok", "Zongheng Wu", "Xudong Xiao", "Ao Sun", "Sheng Fu", "Jianyuan Zhan", "Yian Wang", "Takatomo Saito", "Sicheng Lai"], "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning", "categories": ["cs.AI", "cs.CL", "eess.AS"], "comment": null, "summary": "LLM-based translation agents have achieved highly human-like translation\nresults and are capable of handling longer and more complex contexts with\ngreater efficiency. However, they are typically limited to text-only inputs. In\nthis paper, we introduce ViDove, a translation agent system designed for\nmultimodal input. Inspired by the workflow of human translators, ViDove\nleverages visual and contextual background information to enhance the\ntranslation process. Additionally, we integrate a multimodal memory system and\nlong-short term memory modules enriched with domain-specific knowledge,\nenabling the agent to perform more accurately and adaptively in real-world\nscenarios. As a result, ViDove achieves significantly higher translation\nquality in both subtitle generation and general translation tasks, with a 28%\nimprovement in BLEU scores and a 15% improvement in SubER compared to previous\nstate-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark\nfor long-form automatic video subtitling and translation, featuring 17 hours of\nhigh-quality, human-annotated data. Our code is available here:\nhttps://github.com/pigeonai-org/ViDove", "AI": {"tldr": "The paper introduces ViDove, a multimodal translation agent leveraging visual and contextual information to outperform state-of-the-art models in translation quality.", "motivation": "Current translation agents struggle with integrating multimodal inputs like visual context, limiting their real-world applicability and human-like translation quality.", "method": "ViDove combines visual and contextual data, a multimodal memory system, and long-short-term memory modules enriched with domain-specific knowledge to enhance translation tasks.", "result": "ViDove achieves a 28% improvement in BLEU scores and 15% in SubER over prior state-of-the-art methods. Additionally, it introduces DoveBench, a benchmark with 17 hours of human-annotated data.", "conclusion": "ViDove sets a new standard for multimodal translation tasks and demonstrates the importance of integrating domain-specific and multimodal memory systems for advancing translation accuracy."}}
{"id": "2507.07448", "pdf": "https://arxiv.org/pdf/2507.07448", "abs": "https://arxiv.org/abs/2507.07448", "authors": ["Otso Kinanen", "Andr\u00e9s D. Mu\u00f1oz-Moller", "Vlad Stirbu", "Tommi Mikkonen"], "title": "Toolchain for Faster Iterations in Quantum Software Development", "categories": ["quant-ph", "cs.SE"], "comment": "arXiv admin note: text overlap with arXiv:2408.06756", "summary": "Quantum computing proposes a revolutionary paradigm that can radically\ntransform numerous scientific and industrial application domains. To realize\nthis promise, these new capabilities need software solutions that are able to\neffectively harness its power. However, developers may face significant\nchallenges when developing and executing quantum software due to the limited\navailability of quantum computer hardware, high computational demands of\nsimulating quantum computers on classical systems, and complicated technology\nstack to enable currently available accelerators into development environments.\nThese limitations make it difficult for the developer to create an efficient\nworkflow for quantum software development. In this paper, we investigate the\npotential of using remote computational capabilities in an efficient manner to\nimprove the workflow of quantum software developers, by lowering the barrier of\nmoving between local execution and computationally more efficient remote\nhardware and offering speedup in execution with simulator surroundings. The\ngoal is to allow the development of more complex circuits and to support an\niterative software development approach. In our experiment, with the solution\npresented in this paper, we have obtained up to 5 times faster circuit\nexecution runtime, and enabled qubit ranges from 21 to 29 qubits with a simple\nplug-and-play kernel for the Jupyter notebook.", "AI": {"tldr": "This paper explores a remote computational approach to optimize quantum software workflows, achieving execution speedups and better accessibility for developers.", "motivation": "Quantum computing has transformative potential but faces hurdles like limited hardware, intensive computational demands when simulating on classical systems, and complex technology stacks, creating inefficiencies for developers.", "method": "The approach leverages remote computational resources to streamline quantum software development by integrating an easy-to-use plug-and-play Jupyter notebook kernel, enabling faster execution and support for larger quantum circuits.", "result": "The proposed solution achieved up to 5\u00d7 faster execution runtime and supported qubit ranges from 21 to 29 qubits.", "conclusion": "Remote computational resources can significantly enhance quantum software development, simplifying workflows and enabling iterative development of complex quantum circuits."}}
{"id": "2507.07356", "pdf": "https://arxiv.org/pdf/2507.07356", "abs": "https://arxiv.org/abs/2507.07356", "authors": ["Kangning Yin", "Weishuai Zeng", "Ke Fan", "Zirui Wang", "Qiang Zhang", "Zheng Tian", "Jingbo Wang", "Jiangmiao Pang", "Weinan Zhang"], "title": "UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots", "categories": ["cs.RO"], "comment": "10 pages, 5 figures", "summary": "Humanoid robots must achieve diverse, robust, and generalizable whole-body\ncontrol to operate effectively in complex, human-centric environments. However,\nexisting methods, particularly those based on teacher-student frameworks often\nsuffer from a loss of motion diversity during policy distillation and exhibit\nlimited generalization to unseen behaviors. In this work, we present\nUniTracker, a simplified yet powerful framework that integrates a Conditional\nVariational Autoencoder (CVAE) into the student policy to explicitly model the\nlatent diversity of human motion. By leveraging a learned CVAE prior, our\nmethod enables the student to retain expressive motion characteristics while\nimproving robustness and adaptability under partial observations. The result is\na single policy capable of tracking a wide spectrum of whole-body motions with\nhigh fidelity and stability. Comprehensive experiments in both simulation and\nreal-world deployments demonstrate that UniTracker significantly outperforms\nMLP-based DAgger baselines in motion quality, generalization to unseen\nreferences, and deployment robustness, offering a practical and scalable\nsolution for expressive humanoid control.", "AI": {"tldr": "The paper introduces UniTracker, a new framework that uses a Conditional Variational Autoencoder (CVAE) to enhance whole-body control in humanoid robots.", "motivation": "To address the challenges of achieving diverse, robust, and generalizable control in humanoid robots for operation in complex environments, as existing methods lose motion diversity and have limited behavior generalization.", "method": "The authors integrate a CVAE into the student policy to model latent motion diversity, allowing expressive characteristics while maintaining robustness and adaptability even under partial observations.", "result": "UniTracker delivers high fidelity and stability in whole-body motion tracking, outperforming traditional MLP-based DAgger baselines in simulation and real-world settings.", "conclusion": "This framework offers a practical and scalable solution for expressive and generalizable humanoid robot control, with significant advancements over existing baselines."}}
{"id": "2507.07414", "pdf": "https://arxiv.org/pdf/2507.07414", "abs": "https://arxiv.org/abs/2507.07414", "authors": ["Fardin Rastakhiz"], "title": "GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": null, "summary": "Time, cost, and energy efficiency are critical considerations in\nDeep-Learning (DL), particularly when processing long texts. Transformers,\nwhich represent the current state of the art, exhibit quadratic computational\ncomplexity relative to input length, making them inefficient for extended\ndocuments. This study introduces a novel model architecture that combines Graph\nNeural Networks (GNNs) and Convolutional Neural Networks (CNNs), integrated\nwith a real-time, end-to-end graph generation mechanism. The model processes\ncompact batches of character-level inputs without requiring padding or\ntruncation. To enhance performance while maintaining high speed and efficiency,\nthe model incorporates information from Large Language Models (LLMs), such as\ntoken embeddings and sentiment polarities, through efficient dictionary\nlookups. It captures local contextual patterns using CNNs, expands local\nreceptive fields via lattice-based graph structures, and employs small-world\ngraphs to aggregate document-level information. The generated graphs exhibit\nstructural properties indicative of meaningful semantic organization, with an\naverage clustering coefficient of approximately 0.45 and an average shortest\npath length ranging between 4 and 5. The model is evaluated across multiple\ntext classification tasks, including sentiment analysis and\nnews-categorization, and is compared against state-of-the-art models.\nExperimental results confirm the proposed model's efficiency and competitive\nperformance.", "AI": {"tldr": "The paper introduces a model combining Graph Neural Networks and Convolutional Neural Networks for efficient long-text processing, reducing computational overhead.", "motivation": "Current state-of-the-art models like Transformers are computationally inefficient for long texts due to quadratic complexity; hence, there's a need for more efficient architectures.", "method": "A hybrid model utilizes character-level inputs, lattice-based graph structures, CNNs for local contexts, and information from Large Language Models, processed via real-time graph creation.", "result": "Generated graphs showed notable semantic organization, and the model performed competitively in sentiment analysis and news categorization tasks.", "conclusion": "The proposed architecture is efficient and effective for text classification, providing a viable alternative to Transformer-based models for processing extended documents."}}
{"id": "2507.07276", "pdf": "https://arxiv.org/pdf/2507.07276", "abs": "https://arxiv.org/abs/2507.07276", "authors": ["Aaron Foote", "Danny Krizanc"], "title": "TRIP: A Nonparametric Test to Diagnose Biased Feature Importance Scores", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "Accepted at the Workshop on Explainable Artificial Intelligence (XAI)\n  at IJCAI 2025", "summary": "Along with accurate prediction, understanding the contribution of each\nfeature to the making of the prediction, i.e., the importance of the feature,\nis a desirable and arguably necessary component of a machine learning model.\nFor a complex model such as a random forest, such importances are not innate --\nas they are, e.g., with linear regression. Efficient methods have been created\nto provide such capabilities, with one of the most popular among them being\npermutation feature importance due to its efficiency, model-agnostic nature,\nand perceived intuitiveness. However, permutation feature importance has been\nshown to be misleading in the presence of dependent features as a result of the\ncreation of unrealistic observations when permuting the dependent features. In\nthis work, we develop TRIP (Test for Reliable Interpretation via Permutation),\na test requiring minimal assumptions that is able to detect unreliable\npermutation feature importance scores that are the result of model\nextrapolation. To build on this, we demonstrate how the test can be\ncomplemented in order to allow its use in high dimensional settings. Through\ntesting on simulated data and applications, our results show that the test can\nbe used to reliably detect when permutation feature importance scores are\nunreliable.", "AI": {"tldr": "Permutation feature importance can be misleading with dependent features due to model extrapolation issues. The paper introduces TRIP, a test that detects unreliable importance scores.", "motivation": "Understanding feature importance in predictions is crucial for interpreting machine learning models. Existing methods, like permutation feature importance, struggle with dependent features.", "method": "The researchers propose TRIP, a minimal-assumption test that identifies unreliable feature importance scores caused by model extrapolation under feature dependency. Techniques are provided to extend its application to high-dimensional datasets.", "result": "TRIP reliably detects when permutation feature importance scores fail, validating its effectiveness on simulated and real-world data.", "conclusion": "TRIP enhances the reliability of feature importance interpretations, addressing shortcomings of permutation methods under feature dependency scenarios."}}
{"id": "2507.07143", "pdf": "https://arxiv.org/pdf/2507.07143", "abs": "https://arxiv.org/abs/2507.07143", "authors": ["Karthik Pappu", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Understanding Malware Propagation Dynamics through Scientific Machine Learning", "categories": ["cs.LG", "cs.CR"], "comment": "17 pages, 6 figures, 4 tables", "summary": "Accurately modeling malware propagation is essential for designing effective\ncybersecurity defenses, particularly against adaptive threats that evolve in\nreal time. While traditional epidemiological models and recent neural\napproaches offer useful foundations, they often fail to fully capture the\nnonlinear feedback mechanisms present in real-world networks. In this work, we\napply scientific machine learning to malware modeling by evaluating three\napproaches: classical Ordinary Differential Equations (ODEs), Universal\nDifferential Equations (UDEs), and Neural ODEs. Using data from the Code Red\nworm outbreak, we show that the UDE approach substantially reduces prediction\nerror compared to both traditional and neural baselines by 44%, while\npreserving interpretability. We introduce a symbolic recovery method that\ntransforms the learned neural feedback into explicit mathematical expressions,\nrevealing suppression mechanisms such as network saturation, security response,\nand malware variant evolution. Our results demonstrate that hybrid\nphysics-informed models can outperform both purely analytical and purely neural\napproaches, offering improved predictive accuracy and deeper insight into the\ndynamics of malware spread. These findings support the development of early\nwarning systems, efficient outbreak response strategies, and targeted cyber\ndefense interventions.", "AI": {"tldr": "The paper explores how hybrid physics-informed models improve malware propagation prediction, outperforming traditional and neural models.", "motivation": "To enhance the understanding and prediction of malware propagation dynamics, especially for adaptive threats, using improved modeling that captures nonlinear feedback mechanisms.", "method": "The study evaluates three approaches: traditional Ordinary Differential Equations (ODEs), Universal Differential Equations (UDEs), and Neural ODEs, using data from the Code Red worm outbreak.", "result": "The UDE approach reduced prediction error by 44% compared to traditional and neural baselines, while also preserving model interpretability.", "conclusion": "Hybrid physics-informed models offer superior prediction accuracy and deeper insights into malware dynamics, supporting better cybersecurity strategies and defenses."}}
{"id": "2507.07154", "pdf": "https://arxiv.org/pdf/2507.07154", "abs": "https://arxiv.org/abs/2507.07154", "authors": ["Desheng Li", "Chaoliang Liu", "Zhiyong Xiao"], "title": "CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate segmentation of polyps from colonoscopy images is crucial for the\nearly diagnosis and treatment of colorectal cancer. Most existing deep\nlearning-based polyp segmentation methods adopt an Encoder-Decoder\narchitecture, and some utilize multi-task frameworks that incorporate auxiliary\ntasks such as classification to enhance segmentation performance. However,\nthese approaches often require additional labeled data and rely on task\nsimilarity, which can limit their generalizability. To address these\nchallenges, we propose CL-Polyp, a contrastive learning-enhanced polyp\nsegmentation network. Our method leverages contrastive learning to improve the\nencoder's ability to extract discriminative features by contrasting positive\nand negative sample pairs derived from polyp images. This self-supervised\nstrategy enhances visual representation without requiring additional\nannotations. In addition, we introduce two lightweight and effective modules:\nthe Modified Atrous Spatial Pyramid Pooling (MASPP) module for better\nmulti-scale feature fusion, and the Channel Concatenate and Element Add (CA)\nmodule to fuse low-level and upsampled features for improved boundary\nreconstruction. Extensive experiments on five benchmark datasets-Kvasir-SEG,\nCVC-ClinicDB, CVC-ColonDB, CVC-300, and ETIS-demonstrate that CL-Polyp\nconsistently outperforms state-of-the-art methods. Specifically, it improves\nthe IoU metric by 0.011 and 0.020 on the Kvasir-SEG and CVC-ClinicDB datasets,\nrespectively, validating its effectiveness in clinical polyp segmentation\ntasks.", "AI": {"tldr": "CL-Polyp proposes a contrastive learning-enhanced framework for polyp segmentation, achieving superior segmentation accuracy using self-supervised techniques and lightweight modules, without needing extra labeled data.", "motivation": "Provide accurate polyp segmentation for early colorectal cancer diagnosis while overcoming limitations of existing deep learning methods that rely heavily on additional labeled data and task similarity.", "method": "The study introduces CL-Polyp, leveraging contrastive learning for feature enhancement and two modules: MASPP for multi-scale feature fusion and CA module for attaining better boundary reconstruction.", "result": "Experimental evaluations on five benchmark datasets demonstrate superior performance of CL-Polyp over existing methods, showing consistent IoU improvements, particularly 0.011 and 0.020 on Kvasir-SEG and CVC-ClinicDB, respectively.", "conclusion": "CL-Polyp enhances clinical polyp segmentation through innovative self-supervised learning and efficient module designs, offering a generalizable solution without dependency on extra labeled data."}}
{"id": "2507.07341", "pdf": "https://arxiv.org/pdf/2507.07341", "abs": "https://arxiv.org/abs/2507.07341", "authors": ["Sarah Ball", "Greg Gluch", "Shafi Goldwasser", "Frauke Kreuter", "Omer Reingold", "Guy N. Rothblum"], "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "With the increased deployment of large language models (LLMs), one concern is\ntheir potential misuse for generating harmful content. Our work studies the\nalignment challenge, with a focus on filters to prevent the generation of\nunsafe information. Two natural points of intervention are the filtering of the\ninput prompt before it reaches the model, and filtering the output after\ngeneration. Our main results demonstrate computational challenges in filtering\nboth prompts and outputs. First, we show that there exist LLMs for which there\nare no efficient prompt filters: adversarial prompts that elicit harmful\nbehavior can be easily constructed, which are computationally indistinguishable\nfrom benign prompts for any efficient filter. Our second main result identifies\na natural setting in which output filtering is computationally intractable. All\nof our separation results are under cryptographic hardness assumptions. In\naddition to these core findings, we also formalize and study relaxed mitigation\napproaches, demonstrating further computational barriers. We conclude that\nsafety cannot be achieved by designing filters external to the LLM internals\n(architecture and weights); in particular, black-box access to the LLM will not\nsuffice. Based on our technical results, we argue that an aligned AI system's\nintelligence cannot be separated from its judgment.", "AI": {"tldr": "The paper investigates alignment issues in LLMs with a focus on filtering methods for input prompts and outputs. It reveals computational obstacles that make prompt and output filtering ineffective under cryptographic hardness assumptions.", "motivation": "The motivation is to address the safety challenge in the deployment of LLMs, specifically preventing the generation of harmful information through various filtering techniques.", "method": "The study relies on theoretical computational arguments and cryptographic hardness assumptions to prove the inefficiency and intractability of filters for LLM prompts and outputs.", "result": "The results show that efficient filters cannot distinguish adversarial prompts from benign ones, and that computationally tractable output filtering is infeasible in certain settings.", "conclusion": "External filtering solutions are inadequate for LLM safety. Aligned AI systems must integrate intelligence with judgment, making filters insufficient without internal model adjustments."}}
{"id": "2507.07352", "pdf": "https://arxiv.org/pdf/2507.07352", "abs": "https://arxiv.org/abs/2507.07352", "authors": ["Lo\u00efc Pottier", "Konstantia Georgouli", "Timothy S. Carpenter", "Fikret Aydin", "Jeremy O. B. Tempkin", "Dwight V. Nissley", "Frederick H. Streitz", "Thomas R. W. Scogland", "Peer-Timo Bremer", "Felice C. Lightstone", "Helgi I. Ing\u00f3lfsson"], "title": "Machine Learning-driven Multiscale MD Workflows: The Mini-MuMMI Experience", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Computational models have become one of the prevalent methods to model\ncomplex phenomena. To accurately model complex interactions, such as detailed\nbiomolecular interactions, scientists often rely on multiscale models comprised\nof several internal models operating at difference scales, ranging from\nmicroscopic to macroscopic length and time scales. Bridging the gap between\ndifferent time and length scales has historically been challenging but the\nadvent of newer machine learning (ML) approaches has shown promise for tackling\nthat task. Multiscale models require massive amounts of computational power and\na powerful workflow management system. Orchestrating ML-driven multiscale\nstudies on parallel systems with thousands of nodes is challenging, the\nworkflow must schedule, allocate and control thousands of simulations operating\nat different scales. Here, we discuss the massively parallel Multiscale\nMachine-Learned Modeling Infrastructure (MuMMI), a multiscale workflow\nmanagement infrastructure, that can orchestrate thousands of molecular dynamics\n(MD) simulations operating at different timescales, spanning from millisecond\nto nanosecond. More specifically, we introduce a novel version of MuMMI called\n\"mini-MuMMI\". Mini-MuMMI is a curated version of MuMMI designed to run on\nmodest HPC systems or even laptops whereas MuMMI requires larger HPC systems.\nWe demonstrate mini-MuMMI utility by exploring RAS-RAF membrane interactions\nand discuss the different challenges behind the generalization of multiscale\nworkflows and how mini-MuMMI can be leveraged to target a broader range of\napplications outside of MD and RAS-RAF interactions.", "AI": {"tldr": "This paper introduces mini-MuMMI, a scaled-down version of a workflow management infrastructure for orchestrating machine learning-driven multiscale models. It allows such simulations to run on modest computational systems instead of requiring massive parallel computing setups.", "motivation": "The paper aims to address the complexity of modeling multiscale biomolecular interactions, which requires bridging time and length scales while managing overwhelming computational demands, traditionally achievable only on large HPC systems.", "method": "The authors developed and introduced mini-MuMMI, a curated and smaller-scale version of the larger MuMMI infrastructure. It is tailored to enable multiscale simulations on modest computational platforms, like smaller HPC systems or even laptops.", "result": "The authors successfully demonstrate the utility of mini-MuMMI by exploring specific molecular interactions, such as RAS-RAF membrane interactions. They also analyze its potential to generalize multiscale workflows beyond this particular domain.", "conclusion": "Mini-MuMMI expands the accessibility of multiscale machine learning-driven modeling by reducing the resource barrier. It holds potential for broader applications across various fields beyond molecular dynamics and biomolecular modeling."}}
{"id": "2507.07597", "pdf": "https://arxiv.org/pdf/2507.07597", "abs": "https://arxiv.org/abs/2507.07597", "authors": ["Giuseppe Bisicchia", "Alessandro Bocci", "Antonio Brogi"], "title": "Quantum Executor: A Unified Interface for Quantum Computing", "categories": ["quant-ph", "cs.ET", "cs.SE"], "comment": "11 pages, 1 figure", "summary": "As quantum computing evolves from theoretical promise to practical\ndeployment, the demand for robust, portable, and scalable tools for quantum\nsoftware experimentation is growing. This paper introduces Quantum Executor, a\nbackend-agnostic execution engine designed to orchestrate quantum experiments\nacross heterogeneous platforms. Quantum Executor provides a declarative and\nmodular interface that decouples experiment design from backend execution,\nenabling seamless interoperability and code reuse across diverse quantum and\nclassical resources. Key features include support for asynchronous and\ndistributed execution, customizable execution strategies and a unified API for\nmanaging quantum experiments. We illustrate its applicability through two\nlife-like usage scenarios such as automated benchmarking and hybrid validation,\ndiscussing its capacity to streamline quantum development. We conclude by\ndiscussing current limitations and outlining a roadmap for future enhancements.", "AI": {"tldr": "This paper presents Quantum Executor, a backend-agnostic engine facilitating seamless quantum software experimentation and deployment.", "motivation": "The motivation is to address the growing demand for robust, scalable, and versatile tools for quantum software experimentation across heterogeneous platforms.", "method": "The authors developed Quantum Executor, which uses a declarative and modular interface. It supports asynchronous, distributed execution, customizable strategies, and offers a unified API to manage quantum experiments.", "result": "The engine's applicability is demonstrated via two example scenarios: automated benchmarking and hybrid validation, showcasing its ability to streamline quantum software development.", "conclusion": "Quantum Executor enhances interoperability and quantum experiment management, but the paper acknowledges limitations and provides a roadmap for future improvements."}}
{"id": "2507.07370", "pdf": "https://arxiv.org/pdf/2507.07370", "abs": "https://arxiv.org/abs/2507.07370", "authors": ["Zhanhong Jiang", "Dylan Shah", "Hsin-Jung Yang", "Soumik Sarkar"], "title": "Data-driven Kinematic Modeling in Soft Robots: System Identification and Uncertainty Quantification", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages; 6 figures; accepted at the 5th Modeling, Estimation and\n  Control Conference (MECC 2025)", "summary": "Precise kinematic modeling is critical in calibration and controller design\nfor soft robots, yet remains a challenging issue due to their highly nonlinear\nand complex behaviors. To tackle the issue, numerous data-driven machine\nlearning approaches have been proposed for modeling nonlinear dynamics.\nHowever, these models suffer from prediction uncertainty that can negatively\naffect modeling accuracy, and uncertainty quantification for kinematic modeling\nin soft robots is underexplored. In this work, using limited simulation and\nreal-world data, we first investigate multiple linear and nonlinear machine\nlearning models commonly used for kinematic modeling of soft robots. The\nresults reveal that nonlinear ensemble methods exhibit the most robust\ngeneralization performance. We then develop a conformal kinematic modeling\nframework for soft robots by utilizing split conformal prediction to quantify\npredictive position uncertainty, ensuring distribution-free prediction\nintervals with a theoretical guarantee.", "AI": {"tldr": "The paper addresses the challenge of precise kinematic modeling for soft robots by exploring machine learning methods and introducing a conformal prediction framework for uncertainty quantification.", "motivation": "The motivation is to overcome the difficulty in precise kinematic modeling of soft robots, which arises from their nonlinear and complex behavior, and to address the lack of uncertainty quantification in current approaches.", "method": "The authors investigate various linear and nonlinear machine learning models for kinematic modeling, evaluate their generalization performance, and develop a conformal prediction framework to quantify uncertainty in predictive positions.", "result": "Nonlinear ensemble methods were found to perform most robustly, and the proposed conformal kinematic modeling framework provides theoretical guarantees for distribution-free prediction intervals.", "conclusion": "The study contributes to soft robotics by improving modeling accuracy and incorporating uncertainty quantification, which could aid in better calibration and controller design."}}
{"id": "2507.07419", "pdf": "https://arxiv.org/pdf/2507.07419", "abs": "https://arxiv.org/abs/2507.07419", "authors": ["Hieu Tran", "Zonghai Yao", "Won Seok Jang", "Sharmin Sultana", "Allen Chang", "Yuan Zhang", "Hong Yu"], "title": "MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning", "categories": ["cs.CL", "cs.AI"], "comment": "Equal contribution for the first two authors. arXiv admin note: text\n  overlap with arXiv:2406.09205", "summary": "Generative AI has demonstrated strong potential in healthcare, from clinical\ndecision support to patient-facing chatbots that improve outcomes. A critical\nchallenge for deployment is effective human-AI communication, where content\nmust be both personalized and understandable. We introduce MedReadCtrl, a\nreadability-controlled instruction tuning framework that enables LLMs to adjust\noutput complexity without compromising meaning. Evaluations of nine datasets\nand three tasks across medical and general domains show that MedReadCtrl\nachieves significantly lower readability instruction-following errors than\nGPT-4 (e.g., 1.39 vs. 1.59 on ReadMe, p<0.001) and delivers substantial gains\non unseen clinical tasks (e.g., +14.7 ROUGE-L, +6.18 SARI on MTSamples).\nExperts consistently preferred MedReadCtrl (71.7% vs. 23.3%), especially at low\nliteracy levels. These gains reflect MedReadCtrl's ability to restructure\nclinical content into accessible, readability-aligned language while preserving\nmedical intent, offering a scalable solution to support patient education and\nexpand equitable access to AI-enabled care.", "AI": {"tldr": "The paper introduces MedReadCtrl, a framework for making AI-generated medical content more readable and accessible without losing meaning.", "motivation": "Healthcare applications of generative AI require effective and personalized human-AI communication, especially for making medical content understandable to diverse audiences.", "method": "The researchers developed MedReadCtrl, a readability-controlled instruction tuning framework for Adjusting LLM (Large Language Model) output complexity while preserving the original meaning.", "result": "MedReadCtrl outperformed baseline models like GPT-4 across multiple metrics and domains, particularly excelling in readability, clinical task performance, and expert preference testing (71.7% preferred MedReadCtrl).", "conclusion": "MedReadCtrl offers a scalable tool to enhance patient education and improve equitable access to care by providing readability-tuned, medically accurate AI outputs."}}
{"id": "2507.07359", "pdf": "https://arxiv.org/pdf/2507.07359", "abs": "https://arxiv.org/abs/2507.07359", "authors": ["Zheyu Zhang", "Jiayuan Dong", "Jie Liu", "Xun Huan"], "title": "Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": "10 pages, 6 figures", "summary": "We present GO-CBED, a goal-oriented Bayesian framework for sequential causal\nexperimental design. Unlike conventional approaches that select interventions\naimed at inferring the full causal model, GO-CBED directly maximizes the\nexpected information gain (EIG) on user-specified causal quantities of\ninterest, enabling more targeted and efficient experimentation. The framework\nis both non-myopic, optimizing over entire intervention sequences, and\ngoal-oriented, targeting only model aspects relevant to the causal query. To\naddress the intractability of exact EIG computation, we introduce a variational\nlower bound estimator, optimized jointly through a transformer-based policy\nnetwork and normalizing flow-based variational posteriors. The resulting policy\nenables real-time decision-making via an amortized network. We demonstrate that\nGO-CBED consistently outperforms existing baselines across various causal\nreasoning and discovery tasks-including synthetic structural causal models and\nsemi-synthetic gene regulatory networks-particularly in settings with limited\nexperimental budgets and complex causal mechanisms. Our results highlight the\nbenefits of aligning experimental design objectives with specific research\ngoals and of forward-looking sequential planning.", "AI": {"tldr": "GO-CBED is a new Bayesian framework for experimental design targeting specific causal research goals. It employs a transformer-based network for efficient decision-making and outperforms existing methods.", "motivation": "Existing methods in causal experimental design aim to infer full causal models, which can be inefficient when only specific causal queries are of interest.", "method": "The paper introduces GO-CBED, which maximizes expected information gain for user-specified targets, combining a variational lower bound estimator, transformer-based policy network, and normalizing flow-based variational posteriors.", "result": "GO-CBED achieves superior performance in causal reasoning and discovery tasks, especially with limited experiments or in complex contexts.", "conclusion": "The approach successfully aligns experimental design with research-specific goals, demonstrating efficiency and effectiveness in a variety of tasks."}}
{"id": "2507.07145", "pdf": "https://arxiv.org/pdf/2507.07145", "abs": "https://arxiv.org/abs/2507.07145", "authors": ["Zhaojing Zhou", "Xunchao Li", "Minghao Li", "Handi Zhang", "Haoshuang Wang", "Wenbin Chang", "Yiqun Liu", "Qingqing Dang", "Dianhai Yu", "Yanjun Ma", "Haifeng Wang"], "title": "CCQ: Convolutional Code for Extreme Low-bit Quantization in LLMs", "categories": ["cs.LG"], "comment": "11 pages, 3 figures", "summary": "The rapid scaling of Large Language Models (LLMs) elevates inference costs\nand compounds substantial deployment barriers. While quantization to 8 or 4\nbits mitigates this, sub-3-bit methods face severe accuracy, scalability, and\nefficiency degradation. We propose Convolutional Code Quantization (CCQ), an\ninference-optimized quantization approach compressing LLMs to 2.0-2.75 bits\nwith minimal accuracy loss. Departing from error-prone scalar quantization or\nslow vector quantization, CCQ integrates a hardware-aware bit-shift encoding\nand decoding solution with Convolutional Code, Hybrid Encoding, and Code\nCluster, jointly overcoming accuracy-speed bottlenecks. We construct a\nlookup-free encoding space, enabling a linear mapping between the codebook and\nweight vectors, thereby optimizing inference performance. Meanwhile, by drawing\non the concept of data mapping from vector quantization, we minimize the\nperformance degradation of the model under extremely low-bit conditions.\nExperiments demonstrate that CCQ achieves outstanding performance on LLMs\nacross various benchmarks. We compress DeepSeek-V3 (671B total parameters) to\n184GB and ERNIE-4.5-300B-A47B to 89GB, enabling single-GPU deployment of ERNIE\n4.5 and eliminating inter-card communication. The 2-bit ERNIE-4.5-300B-A47B\nmodel and inference engine have been open-sourced.", "AI": {"tldr": "This paper introduces Convolutional Code Quantization (CCQ), an approach to compress LLMs to 2.0-2.75 bits while maintaining high accuracy and performance.", "motivation": "The scaling of Large Language Models significantly increases inference costs and deployment challenges. Existing quantization methods below 3-bit levels face issues like accuracy and efficiency degradation, necessitating a better solution.", "method": "CCQ employs a hardware-aware encoding/decoding strategy using Convolutional Code, Hybrid Encoding, and Code Cluster. It constructs a lookup-free codebook-to-weight mapping, optimizing inference.", "result": "The method compresses models like DeepSeek-V3 (671B parameters) to 184GB and ERNIE-4.5-300B-A47B to 89GB, enabling single-GPU deployment and eliminating inter-card communication.", "conclusion": "CCQ offers a practical and efficient approach for using LLMs at extremely low-bit quantization levels, balancing accuracy and computational resource requirements effectively."}}
{"id": "2507.07157", "pdf": "https://arxiv.org/pdf/2507.07157", "abs": "https://arxiv.org/abs/2507.07157", "authors": ["Arshak Rezvani", "Ali Akbari", "Kosar Sanjar Arani", "Maryam Mirian", "Emad Arasteh", "Martin J. McKeown"], "title": "Interpretable EEG-to-Image Generation with Semantic Prompts", "categories": ["cs.CV", "cs.LG", "eess.SP"], "comment": "Actionable Interpretability Workshop (non-archival) at the 42\n  International Conference on Machine Learning", "summary": "Decoding visual experience from brain signals offers exciting possibilities\nfor neuroscience and interpretable AI. While EEG is accessible and temporally\nprecise, its limitations in spatial detail hinder image reconstruction. Our\nmodel bypasses direct EEG-to-image generation by aligning EEG signals with\nmultilevel semantic captions -- ranging from object-level to abstract themes --\ngenerated by a large language model. A transformer-based EEG encoder maps brain\nactivity to these captions through contrastive learning. During inference,\ncaption embeddings retrieved via projection heads condition a pretrained latent\ndiffusion model for image generation. This text-mediated framework yields\nstate-of-the-art visual decoding on the EEGCVPR dataset, with interpretable\nalignment to known neurocognitive pathways. Dominant EEG-caption associations\nreflected the importance of different semantic levels extracted from perceived\nimages. Saliency maps and t-SNE projections reveal semantic topography across\nthe scalp. Our model demonstrates how structured semantic mediation enables\ncognitively aligned visual decoding from EEG.", "AI": {"tldr": "The paper presents a framework for decoding visual experiences from EEG by using semantic captions generated by a language model, which leads to state-of-the-art performance in visual decoding.", "motivation": "To utilize EEG, which is accessible and temporally precise, in decoding visual experiences despite its limitations in spatial information, and to improve interpretability in neuroscience and AI.", "method": "A transformer-based EEG encoder maps brain signals to multilevel semantic captions (generated by a language model) using contrastive learning, and these captions condition a latent diffusion model for image generation.", "result": "The framework achieved state-of-the-art results on the EEGCVPR dataset, demonstrated interpretable alignments with brain activity, and highlighted dominant EEG-caption associations.", "conclusion": "Using text-mediated frameworks enables cognitively aligned and interpretable visual decoding from EEG signals."}}
{"id": "2507.07355", "pdf": "https://arxiv.org/pdf/2507.07355", "abs": "https://arxiv.org/abs/2507.07355", "authors": ["Haoyue Bai", "Haoyu Wang", "Nanxu Gong", "Xinyuan Wang", "Wangyang Ying", "Haifeng Chen", "Yanjie Fu"], "title": "Supply Chain Optimization via Generative Simulation and Iterative Decision Policies", "categories": ["cs.AI"], "comment": null, "summary": "High responsiveness and economic efficiency are critical objectives in supply\nchain transportation, both of which are influenced by strategic decisions on\nshipping mode. An integrated framework combining an efficient simulator with an\nintelligent decision-making algorithm can provide an observable, low-risk\nenvironment for transportation strategy design. An ideal simulation-decision\nframework must (1) generalize effectively across various settings, (2) reflect\nfine-grained transportation dynamics, (3) integrate historical experience with\npredictive insights, and (4) maintain tight integration between simulation\nfeedback and policy refinement. We propose Sim-to-Dec framework to satisfy\nthese requirements. Specifically, Sim-to-Dec consists of a generative\nsimulation module, which leverages autoregressive modeling to simulate\ncontinuous state changes, reducing dependence on handcrafted domain-specific\nrules and enhancing robustness against data fluctuations; and a history-future\ndual-aware decision model, refined iteratively through end-to-end optimization\nwith simulator interactions. Extensive experiments conducted on three\nreal-world datasets demonstrate that Sim-to-Dec significantly improves timely\ndelivery rates and profit.", "AI": {"tldr": "This paper introduces Sim-to-Dec, an integrated simulation-decision framework designed to enhance supply chain transportation strategies for responsiveness and economic efficiency.", "motivation": "To address the challenges of designing low-risk, effective transportation strategies in supply chains, which require balancing responsiveness and economic objectives.", "method": "The authors propose Sim-to-Dec, combining a generative simulation module based on autoregressive modeling and a history-future dual-aware decision model iteratively optimized with simulation feedback.", "result": "Experiments with real-world datasets show that Sim-to-Dec improves timely delivery rates and profitability compared to existing methods.", "conclusion": "Sim-to-Dec offers a robust and adaptive approach to supply chain transportation strategy design, demonstrating generalization across settings and effectiveness in enhancing decision-making processes."}}
{"id": "2507.07400", "pdf": "https://arxiv.org/pdf/2507.07400", "abs": "https://arxiv.org/abs/2507.07400", "authors": ["Zaifeng Pan", "Ajjkumar Patel", "Zhengding Hu", "Yipeng Shen", "Yue Guan", "Wan-Lu Li", "Lianhui Qin", "Yida Wang", "Yufei Ding"], "title": "KVFlow: Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows", "categories": ["cs.DC", "cs.MA"], "comment": null, "summary": "Large language model (LLM) based agentic workflows have become a popular\nparadigm for coordinating multiple specialized agents to solve complex tasks.\nTo improve serving efficiency, existing LLM systems employ prefix caching to\nreuse key-value (KV) tensors corresponding to agents' fixed prompts, thereby\navoiding redundant computation across repeated invocations. However, current\nsystems typically evict KV caches using a Least Recently Used (LRU) policy,\nwhich fails to anticipate future agent usage and often discards KV caches\nshortly before their reuse. This leads to frequent cache misses and substantial\nrecomputation or swapping overhead. We present KVFlow, a workflow-aware KV\ncache management framework tailored for agentic workloads. KVFlow abstracts the\nagent execution schedule as an Agent Step Graph and assigns each agent a\nsteps-to-execution value that estimates its temporal proximity to future\nactivation. These values guide a fine-grained eviction policy at the KV node\nlevel, allowing KVFlow to preserve entries likely to be reused and efficiently\nmanage shared prefixes in tree-structured caches. Moreover, KVFlow introduces a\nfully overlapped KV prefetching mechanism, which proactively loads required\ntensors from CPU to GPU in background threads for agents scheduled in the next\nstep, thereby avoiding cache miss stalls during generation. Compared to SGLang\nwith hierarchical radix cache, KVFlow achieves up to 1.83$\\times$ speedup for\nsingle workflows with large prompts, and up to 2.19$\\times$ speedup for\nscenarios with many concurrent workflows.", "AI": {"tldr": "The paper introduces KVFlow, a workflow-aware KV cache management framework designed to improve efficiency in LLM agentic workflows by optimizing cache eviction and prefetching strategies.", "motivation": "Current LLM systems using prefix caching suffer from inefficiencies due to the simplistic Least Recently Used (LRU) cache eviction policy, which does not anticipate usage patterns, leading to frequent cache misses.", "method": "KVFlow uses an Agent Step Graph to estimate agents' execution timing and prioritizes KV cache retention based on temporal proximity to reuse. Additionally, it incorporates KV prefetching to proactively load tensors between CPU and GPU.", "result": "KVFlow demonstrates significant performance improvements, achieving up to 1.83x speedup for single workflows with large prompts and up to 2.19x speedup for concurrent workflows.", "conclusion": "KVFlow offers a robust cache management framework, significantly enhancing efficiency for agentic workloads and overcoming limitations of existing cache eviction policies."}}
{"id": "2507.07649", "pdf": "https://arxiv.org/pdf/2507.07649", "abs": "https://arxiv.org/abs/2507.07649", "authors": ["Domenik Eichhorn", "Nick Poser", "Maximilian Schweikart", "Ina Schaefer"], "title": "ProvideQ: A Quantum Optimization Toolbox", "categories": ["quant-ph", "cs.SE"], "comment": "This paper was submitted and accepted at the IEEE QCE 2025", "summary": "Hybrid solvers for combinatorial optimization problems combine the advantages\nof classical and quantum computing to overcome difficult computational\nchallenges. Although their theoretical performance seems promising, their\npractical applicability is challenging due to the lack of a technological stack\nthat can seamlessly integrate quantum solutions with existing classical\noptimization frameworks. We tackle this challenge by introducing the ProvideQ\ntoolbox, a software tool that enables users to easily adapt and configure\nhybrid solvers via Meta-Solver strategies. A Meta-Solver strategy implements\ndecomposition techniques, which splits problems into classical and quantum\nsubroutines. The ProvideQ toolbox enables the interactive creation of such\ndecompositions via a Meta-Solver configuration tool. It combines\nwell-established classical optimization techniques with quantum circuits that\nare seamlessly executable on multiple backends. This paper introduces the\ntechnical details of the ProvideQ toolbox, explains its architecture, and\ndemonstrates possible applications for several real-world use cases. Our proof\nof concept shows that Meta-Solver strategies already enable the application of\nquantum subroutines today, however, more sophisticated hardware is required to\nmake their performance competitive.", "AI": {"tldr": "Hybrid solvers merging classical and quantum computing show theoretical promise but face practical challenges due to missing integration frameworks. ProvideQ toolbox is introduced to enable adaptable Meta-Solver strategies that split problems effectively using both computation paradigms.", "motivation": "To overcome the challenges of integrating quantum computing with classical optimization frameworks for tackling combinatorial optimization problems.", "method": "ProvideQ toolbox utilizes Meta-Solver strategies, which split problems into classical and quantum subroutines. It features a configuration tool to facilitate interactive decomposition and seamless integration of quantum circuits with classical methods.", "result": "The paper demonstrates the toolbox's technical design and its application to various real-world problems, showing the viability of Meta-Solver strategies using current quantum computing hardware.", "conclusion": "While Meta-Solver strategies via ProvideQ prove effective even on existing hardware, improving quantum hardware is necessary to achieve competitive performance compared to classical solutions."}}
{"id": "2507.07376", "pdf": "https://arxiv.org/pdf/2507.07376", "abs": "https://arxiv.org/abs/2507.07376", "authors": ["Hengrui Liu", "Yi Feng", "Qilong Zhang"], "title": "PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster\nresponse, exploration, and reconnaissance. However, dynamic and unknown\nenvironments pose significant challenges due to target unpredictability and\nenvironmental uncertainty. To tackle these issues, we propose PILOC, a\nframework that operates without global prior knowledge, leveraging local\nperception and communication. It introduces a pheromone inverse guidance\nmechanism to enable efficient coordination and dynamic target localization.\nPILOC promotes decentralized cooperation through local communication,\nsignificantly reducing reliance on global channels. Unlike conventional\nheuristics, the pheromone mechanism is embedded into the observation space of\nDeep Reinforcement Learning (DRL), supporting indirect agent coordination based\non environmental cues. We further integrate this strategy into a DRL-based\nmulti-agent architecture and conduct extensive experiments. Results show that\ncombining local communication with pheromone-based guidance significantly\nboosts search efficiency, adaptability, and system robustness. Compared to\nexisting methods, PILOC performs better under dynamic and\ncommunication-constrained scenarios, offering promising directions for future\nMASAR applications.", "AI": {"tldr": "The paper introduces PILOC, a framework for multi-agent search and rescue (MASAR) that uses local perceptions, communication, and a novel pheromone inverse guidance mechanism to improve search efficiency and coordination.", "motivation": "Dynamic and unpredictable environments create challenges in multi-agent search and rescue operations, necessitating strategies adapted to uncertainty and limited knowledge.", "method": "The study introduces PILOC, which integrates deep reinforcement learning with a pheromone inverse guidance mechanism for indirect coordination and local communication to reduce reliance on global knowledge.", "result": "Extensive experiments demonstrate that PILOC improves search efficiency, adaptability, and robustness, outperforming existing methods in dynamic and communication-constrained scenarios.", "conclusion": "PILOC offers a promising approach for future MASAR applications by enhancing decentralized cooperation and dynamic target discovery using innovative coordination mechanisms."}}
{"id": "2507.07421", "pdf": "https://arxiv.org/pdf/2507.07421", "abs": "https://arxiv.org/abs/2507.07421", "authors": ["Zonghai Yao", "Youxia Zhao", "Avijit Mitra", "David A. Levy", "Emily Druhl", "Jack Tsai", "Hong Yu"], "title": "SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data", "categories": ["cs.CL", "cs.AI"], "comment": "Equal contribution for the first two authors", "summary": "Eviction is a significant yet understudied social determinants of health\n(SDoH), linked to housing instability, unemployment, and mental health. While\neviction appears in unstructured electronic health records (EHRs), it is rarely\ncoded in structured fields, limiting downstream applications. We introduce\nSynthEHR-Eviction, a scalable pipeline combining LLMs, human-in-the-loop\nannotation, and automated prompt optimization (APO) to extract eviction\nstatuses from clinical notes. Using this pipeline, we created the largest\npublic eviction-related SDoH dataset to date, comprising 14 fine-grained\ncategories. Fine-tuned LLMs (e.g., Qwen2.5, LLaMA3) trained on\nSynthEHR-Eviction achieved Macro-F1 scores of 88.8% (eviction) and 90.3% (other\nSDoH) on human validated data, outperforming GPT-4o-APO (87.8%, 87.3%),\nGPT-4o-mini-APO (69.1%, 78.1%), and BioBERT (60.7%, 68.3%), while enabling\ncost-effective deployment across various model sizes. The pipeline reduces\nannotation effort by over 80%, accelerates dataset creation, enables scalable\neviction detection, and generalizes to other information extraction tasks.", "AI": {"tldr": "The study presents a scalable pipeline using large language models (LLMs) for effectively extracting eviction statuses and creating a large eviction-related social determinants of health (SDoH) dataset from unstructured clinical notes.", "motivation": "Eviction, as an overlooked SDoH, has significant implications for health outcomes such as housing instability, unemployment, and mental health issues. However, eviction-related data is mostly uncoded in EHRs, which restricts its applications.", "method": "The researchers developed a pipeline named SynthEHR-Eviction, combining large language models (LLMs), human-in-the-loop annotation, automated prompt optimization (APO), and fine-tuning to extract eviction data from clinical notes.", "result": "Using the pipeline, the team created the largest eviction-related SDoH dataset comprising 14 categories, with fine-tuned LLMs achieving high Macro-F1 scores (88.8% for eviction and 90.3% for other SDoH). The pipeline improved annotation efficiency by over 80%.", "conclusion": "The SynthEHR-Eviction pipeline facilitates scalable eviction detection from clinical notes, significantly reduces data annotation workload, outperforms other methods, and generalizes to broader information extraction tasks."}}
{"id": "2507.07382", "pdf": "https://arxiv.org/pdf/2507.07382", "abs": "https://arxiv.org/abs/2507.07382", "authors": ["Peng Luo", "Yilong Wu", "Yongze Song"], "title": "Feature-free regression kriging", "categories": ["physics.soc-ph", "stat.ME", "stat.ML"], "comment": null, "summary": "Spatial interpolation is a crucial task in geography. As perhaps the most\nwidely used interpolation methods, geostatistical models -- such as Ordinary\nKriging (OK) -- assume spatial stationarity, which makes it difficult to\ncapture the nonstationary characteristics of geographic variables. A common\nsolution is trend surface modeling (e.g., Regression Kriging, RK), which relies\non external explanatory variables to model the trend and then applies\ngeostatistical interpolation to the residuals. However, this approach requires\nhigh-quality and readily available explanatory variables, which are often\nlacking in many spatial interpolation scenarios -- such as estimating heavy\nmetal concentrations underground. This study proposes a Feature-Free Regression\nKriging (FFRK) method, which automatically extracts geospatial features --\nincluding local dependence, local heterogeneity, and geosimilarity -- to\nconstruct a regression-based trend surface without requiring external\nexplanatory variables. We conducted experiments on the spatial distribution\nprediction of three heavy metals in a mining area in Australia. In comparison\nwith 17 classical interpolation methods, the results indicate that FFRK, which\ndoes not incorporate any explanatory variables and relies solely on extracted\ngeospatial features, consistently outperforms both conventional Kriging\ntechniques and machine learning models that depend on explanatory variables.\nThis approach effectively addresses spatial nonstationarity while reducing the\ncost of acquiring explanatory variables, improving both prediction accuracy and\ngeneralization ability. This finding suggests that an accurate characterization\nof geospatial features based on domain knowledge can significantly enhance\nspatial prediction performance -- potentially yielding greater improvements\nthan merely adopting more advanced statistical models.", "AI": {"tldr": "The paper introduces the Feature-Free Regression Kriging (FFRK) method, which uses geospatial features without external explanatory variables to improve spatial interpolation accuracy.", "motivation": "The motivation is to address challenges with conventional geostatistical methods like Ordinary Kriging and Regression Kriging, which struggle with spatial nonstationarity and rely on hard-to-acquire explanatory variables.", "method": "The proposed method, Feature-Free Regression Kriging (FFRK), extracts geospatial features like local dependence, heterogeneity, and geosimilarity to construct prediction models without external explanatory data.", "result": "Experiments on heavy metals prediction in Australia demonstrate that FFRK consistently outperforms traditional Kriging techniques and machine learning models relying on explanatory variables.", "conclusion": "FFRK enhances spatial interpolation accuracy and generalization by addressing spatial nonstationarity and eliminating reliance on external explanatory variables, showing the value of geospatial feature characterization."}}
{"id": "2507.07146", "pdf": "https://arxiv.org/pdf/2507.07146", "abs": "https://arxiv.org/abs/2507.07146", "authors": ["Zixuan Huang", "Kecheng Huang", "Lihao Yin", "Bowei He", "Huiling Zhen", "Mingxuan Yuan", "Zili Shao"], "title": "An attention-aware GNN-based input defender against multi-turn jailbreak on LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have gained widespread popularity and are\nincreasingly integrated into various applications. However, their capabilities\ncan be exploited for both benign and harmful purposes. Despite rigorous\ntraining and fine-tuning for safety, LLMs remain vulnerable to jailbreak\nattacks. Recently, multi-turn attacks have emerged, exacerbating the issue.\nUnlike single-turn attacks, multi-turn attacks gradually escalate the dialogue,\nmaking them more difficult to detect and mitigate, even after they are\nidentified.\n  In this study, we propose G-Guard, an innovative attention-aware GNN-based\ninput classifier designed to defend against multi-turn jailbreak attacks on\nLLMs. G-Guard constructs an entity graph for multi-turn queries, explicitly\ncapturing relationships between harmful keywords and queries even when those\nkeywords appear only in previous queries. Additionally, we introduce an\nattention-aware augmentation mechanism that retrieves the most similar\nsingle-turn query based on the multi-turn conversation. This retrieved query is\ntreated as a labeled node in the graph, enhancing the ability of GNN to\nclassify whether the current query is harmful. Evaluation results demonstrate\nthat G-Guard outperforms all baselines across all datasets and evaluation\nmetrics.", "AI": {"tldr": "The paper introduces G-Guard, an advanced graph-based model that defends against multi-turn jailbreak attacks on large language models by analyzing relationships in multi-turn conversations and harmful keywords.", "motivation": "As LLMs grow popular, they face security vulnerabilities like jailbreak attacks, particularly multi-turn ones, which are harder to detect and mitigate due to their escalating nature.", "method": "The study introduces G-Guard, an attention-aware input classifier using Graph Neural Networks (GNN). It builds an entity graph to link harmful keywords across multi-turn queries and employs an attention-aware mechanism for query augmentation, benefiting classification accuracy.", "result": "G-Guard demonstrated superior performance over baseline methods across multiple datasets, showing robust defense capabilities against multi-turn jailbreak attacks.", "conclusion": "G-Guard effectively enhances the security of LLMs by accurately classifying and defending against multi-turn jailbreak attacks through innovative graph-based analysis and attention-aware mechanisms."}}
{"id": "2507.07202", "pdf": "https://arxiv.org/pdf/2507.07202", "abs": "https://arxiv.org/abs/2507.07202", "authors": ["Mohamed Elmoghany", "Ryan Rossi", "Seunghyun Yoon", "Subhojyoti Mukherjee", "Eslam Bakr", "Puneet Mathur", "Gang Wu", "Viet Dac Lai", "Nedim Lipka", "Ruiyi Zhang", "Varun Manjunatha", "Chien Nguyen", "Daksh Dangi", "Abel Salinas", "Mohammad Taesiri", "Hongjie Chen", "Xiaolei Huang", "Joe Barrow", "Nesreen Ahmed", "Hoda Eldardiry", "Namyong Park", "Yu Wang", "Jaemin Cho", "Anh Totti Nguyen", "Zhengzhong Tu", "Thien Nguyen", "Dinesh Manocha", "Mohamed Elhoseiny", "Franck Dernoncourt"], "title": "A Survey on Long-Video Storytelling Generation: Architectures, Consistency, and Cinematic Quality", "categories": ["cs.CV"], "comment": null, "summary": "Despite the significant progress that has been made in video generative\nmodels, existing state-of-the-art methods can only produce videos lasting 5-16\nseconds, often labeled \"long-form videos\". Furthermore, videos exceeding 16\nseconds struggle to maintain consistent character appearances and scene layouts\nthroughout the narrative. In particular, multi-subject long videos still fail\nto preserve character consistency and motion coherence. While some methods can\ngenerate videos up to 150 seconds long, they often suffer from frame redundancy\nand low temporal diversity. Recent work has attempted to produce long-form\nvideos featuring multiple characters, narrative coherence, and high-fidelity\ndetail. We comprehensively studied 32 papers on video generation to identify\nkey architectural components and training strategies that consistently yield\nthese qualities. We also construct a comprehensive novel taxonomy of existing\nmethods and present comparative tables that categorize papers by their\narchitectural designs and performance characteristics.", "AI": {"tldr": "The paper addresses challenges in generating long-form videos, including consistency, coherence, and detail, by analyzing 32 existing papers and proposing a taxonomy.", "motivation": "Current video generative models struggle to maintain character consistency, motion coherence, and high temporal diversity in long-form videos.", "method": "The authors conducted a study of 32 papers, identifying effective architectural components, training strategies, and building a taxonomy categorizing these models.", "result": "The study yielded a taxonomy and comparative tables to classify and evaluate video generative methods by design and performance.", "conclusion": "Comprehensive analysis and taxonomy provide deeper insights into advancing long-form video generation addressing current limitations."}}
{"id": "2507.07426", "pdf": "https://arxiv.org/pdf/2507.07426", "abs": "https://arxiv.org/abs/2507.07426", "authors": ["Zerui Yang", "Yuwei Wan", "Yinqiao Li", "Yudai Matsuda", "Tong Xie", "Linqi Song"], "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models have demonstrated considerable\npotential in scientific domains such as drug discovery. However, their\neffectiveness remains constrained when reasoning extends beyond the knowledge\nacquired during pretraining. Conventional approaches, such as fine-tuning or\nretrieval-augmented generation, face limitations in either imposing high\ncomputational overhead or failing to fully exploit structured scientific data.\nTo overcome these challenges, we propose DrugMCTS, a novel framework that\nsynergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree\nSearch for drug repurposing. The framework employs five specialized agents\ntasked with retrieving and analyzing molecular and protein information, thereby\nenabling structured and iterative reasoning. Without requiring domain-specific\nfine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by\nover 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate\nthat DrugMCTS achieves substantially higher recall and robustness compared to\nboth general-purpose LLMs and deep learning baselines. Our results highlight\nthe importance of structured reasoning, agent-based collaboration, and\nfeedback-driven search mechanisms in advancing LLM applications for drug\ndiscovery.", "AI": {"tldr": "This paper introduces DrugMCTS, a novel framework combining multiple approaches to improve drug repurposing using large language models without fine-tuning.", "motivation": "The paper aims to address the limitations of large language models in scientific domains like drug discovery, particularly their inefficacy in extended reasoning beyond pretrained knowledge and the computational inefficiency of existing techniques.", "method": "DrugMCTS combines retrieval-augmented generation (RAG), multi-agent collaboration, and Monte Carlo Tree Search to structure and refine reasoning without the need for domain-specific fine-tuning.", "result": "DrugMCTS achieved over 20% improvement versus Deepseek-R1 on Qwen2.5-7B-Instruct and displayed higher recall and robustness on DrugBank and KIBA datasets compared to other LLMs and deep learning methods.", "conclusion": "Structured reasoning, agent collaboration, and feedback-driven search mechanisms are crucial for advancing drug discovery applications of large language models."}}
{"id": "2507.07671", "pdf": "https://arxiv.org/pdf/2507.07671", "abs": "https://arxiv.org/abs/2507.07671", "authors": ["Jovan Prodanov", "Bla\u017e Bertalani\u010d", "Carolina Fortuna", "Shih-Kai Chou", "Matja\u017e Branko Juri\u010d", "Ramon Sanchez-Iborra", "Jernej Hribar"], "title": "Multi-agent Reinforcement Learning-based In-place Scaling Engine for Edge-cloud Systems", "categories": ["cs.DC"], "comment": "Accepted at IEEE Cloud 2025", "summary": "Modern edge-cloud systems face challenges in efficiently scaling resources to\nhandle dynamic and unpredictable workloads. Traditional scaling approaches\ntypically rely on static thresholds and predefined rules, which are often\ninadequate for optimizing resource utilization and maintaining performance in\ndistributed and dynamic environments. This inefficiency hinders the\nadaptability and performance required in edge-cloud infrastructures, which can\nonly be achieved through the newly proposed in-place scaling. To address this\nproblem, we propose the Multi-Agent Reinforcement Learning-based In-place\nScaling Engine (MARLISE) that enables seamless, dynamic, reactive control with\nin-place resource scaling. We develop our solution using two Deep Reinforcement\nLearning algorithms: Deep Q-Network (DQN), and Proximal Policy Optimization\n(PPO). We analyze each version of the proposed MARLISE solution using dynamic\nworkloads, demonstrating their ability to ensure low response times of\nmicroservices and scalability. Our results show that MARLISE-based approaches\noutperform heuristic method in managing resource elasticity while maintaining\nmicroservice response times and achieving higher resource efficiency.", "AI": {"tldr": "The paper introduces MARLISE, a reinforcement learning-based approach for dynamic in-place scaling of resources in edge-cloud systems, outperforming traditional heuristic methods.", "motivation": "Traditional static scaling methods fail to efficiently handle the dynamic and unpredictable workloads in modern edge-cloud systems, leading to suboptimal resource utilization and performance.", "method": "The authors propose MARLISE, based on Multi-Agent Reinforcement Learning, utilizing Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms for dynamic, reactive control of in-place resource scaling.", "result": "MARLISE demonstrates superior performance in managing resource elasticity, ensuring low microservice response times, and achieving better resource efficiency compared to heuristic methods.", "conclusion": "The study validates MARLISE as an effective solution for enhancing resource utilization and performance in edge-cloud systems, addressing challenges of dynamic workload scaling."}}
{"id": "2507.07444", "pdf": "https://arxiv.org/pdf/2507.07444", "abs": "https://arxiv.org/abs/2507.07444", "authors": ["Korbinian Moller", "Rafael Neher", "Marvin Seegert", "Johannes Betz"], "title": "Towards Safe Autonomous Driving: A Real-Time Safeguarding Concept for Motion Planning Algorithms", "categories": ["cs.RO"], "comment": "7 pages, submitted to the IEEE ICVES 2025, Coventry, UK", "summary": "Ensuring the functional safety of motion planning modules in autonomous\nvehicles remains a critical challenge, especially when dealing with complex or\nlearning-based software. Online verification has emerged as a promising\napproach to monitor such systems at runtime, yet its integration into embedded\nreal-time environments remains limited. This work presents a safeguarding\nconcept for motion planning that extends prior approaches by introducing a time\nsafeguard. While existing methods focus on geometric and dynamic feasibility,\nour approach additionally monitors the temporal consistency of planning outputs\nto ensure timely system response. A prototypical implementation on a real-time\noperating system evaluates trajectory candidates using constraint-based\nfeasibility checks and cost-based plausibility metrics. Preliminary results\nshow that the safeguarding module operates within real-time bounds and\neffectively detects unsafe trajectories. However, the full integration of the\ntime safeguard logic and fallback strategies is ongoing. This study contributes\na modular and extensible framework for runtime trajectory verification and\nhighlights key aspects for deployment on automotive-grade hardware. Future work\nincludes completing the safeguarding logic and validating its effectiveness\nthrough hardware-in-the-loop simulations and vehicle-based testing. The code is\navailable at: https://github.com/TUM-AVS/motion-planning-supervisor", "AI": {"tldr": "This paper proposes a new safeguarding concept for autonomous vehicle motion planning that includes a time safeguard, enhancing temporal consistency and safety assurances.", "motivation": "To address challenges in ensuring functional safety of autonomous vehicle motion planning systems, especially in real-time embedded environments, and limited integration of online verification methods.", "method": "Introduced a time safeguard to monitor planning outputs' temporal consistency, implemented as a modular framework on a real-time operating system with feasibility checks and cost-based plausibility metrics.", "result": "The safeguarding module operates within real-time limits and detects unsafe trajectories effectively. Full integration and fallback strategies are still under development.", "conclusion": "This work advances runtime trajectory verification by adding temporal safeguards, providing a foundation for further system testing and deployment on automotive-grade hardware."}}
{"id": "2507.07439", "pdf": "https://arxiv.org/pdf/2507.07439", "abs": "https://arxiv.org/abs/2507.07439", "authors": ["Matthieu Boileau", "Philippe Helluy", "Jeremy Pawlus", "Svitlana Vyetrenko"], "title": "Towards Interpretable Time Series Foundation Models", "categories": ["cs.CL", "cs.AI"], "comment": "International Conference on Machine Leaning (ICML) 2025 Workshop on\n  Foundation Models for Structured Data", "summary": "In this paper, we investigate the distillation of time series reasoning\ncapabilities into small, instruction-tuned language models as a step toward\nbuilding interpretable time series foundation models. Leveraging a synthetic\ndataset of mean-reverting time series with systematically varied trends and\nnoise levels, we generate natural language annotations using a large multimodal\nmodel and use these to supervise the fine-tuning of compact Qwen models. We\nintroduce evaluation metrics that assess the quality of the distilled reasoning\n- focusing on trend direction, noise intensity, and extremum localization - and\nshow that the post-trained models acquire meaningful interpretive capabilities.\nOur results highlight the feasibility of compressing time series understanding\ninto lightweight, language-capable models suitable for on-device or\nprivacy-sensitive deployment. This work contributes a concrete foundation\ntoward developing small, interpretable models that explain temporal patterns in\nnatural language.", "AI": {"tldr": "The paper explores distilling time series reasoning into small language models using synthetic datasets and systematic fine-tuning.", "motivation": "Develop interpretable small models for analyzing and explaining time series data effectively in natural language.", "method": "Synthetic training datasets paired with multimodal annotations fine-tune compact models using evaluation metrics focused on specific properties like trend direction and extremum localization.", "result": "Post-trained models demonstrate improved interpretive capabilities for capturing trends, noise patterns, and extremums in time series.", "conclusion": "Successfully compressing time series understanding into lightweight models shows promise for interpretable and privacy-sensitive deployments."}}
{"id": "2507.07826", "pdf": "https://arxiv.org/pdf/2507.07826", "abs": "https://arxiv.org/abs/2507.07826", "authors": ["Erfan Mirzaei", "Andreas Maurer", "Vladimir R. Kostic", "Massimiliano Pontil"], "title": "An Empirical Bernstein Inequality for Dependent Data in Hilbert Spaces and Applications", "categories": ["cs.LG", "stat.ML"], "comment": "In The 28th International Conference on Artificial Intelligence and\n  Statistics (2025)", "summary": "Learning from non-independent and non-identically distributed data poses a\npersistent challenge in statistical learning. In this study, we introduce\ndata-dependent Bernstein inequalities tailored for vector-valued processes in\nHilbert space. Our inequalities apply to both stationary and non-stationary\nprocesses and exploit the potential rapid decay of correlations between\ntemporally separated variables to improve estimation. We demonstrate the\nutility of these bounds by applying them to covariance operator estimation in\nthe Hilbert-Schmidt norm and to operator learning in dynamical systems,\nachieving novel risk bounds. Finally, we perform numerical experiments to\nillustrate the practical implications of these bounds in both contexts.", "AI": {"tldr": "The paper introduces data-dependent Bernstein inequalities for vector-valued processes in Hilbert space, improving risk bounds for stationary and non-stationary processes.", "motivation": "Statistical learning often faces challenges with non-independent and non-identically distributed data. This paper aims to address such challenges using advanced mathematical techniques.", "method": "The authors derive data-dependent Bernstein inequalities for vector-valued processes in Hilbert space, focusing on correlation decay and applying the results to covariance operator estimation and operator learning.", "result": "The study achieves new risk bounds for covariance operator estimation in the Hilbert-Schmidt norm and for operator learning in dynamical systems.", "conclusion": "The results demonstrate improved estimation techniques for complex data dependencies, supported by both theoretical derivations and numerical experiments."}}
{"id": "2507.07147", "pdf": "https://arxiv.org/pdf/2507.07147", "abs": "https://arxiv.org/abs/2507.07147", "authors": ["Sua Lee", "Kyubum Shin", "Jung Ho Park"], "title": "Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Recent advances in pre-trained Vision Language Models (VLM) have shown\npromising potential for effectively adapting to downstream tasks through prompt\nlearning, without the need for additional annotated paired datasets. To\nsupplement the text information in VLM trained on correlations with vision\ndata, new approaches leveraging Large Language Models (LLM) in prompts have\nbeen proposed, enhancing robustness to unseen and diverse data. Existing\nmethods typically extract text-based responses (i.e., descriptions) from LLM to\nincorporate into prompts; however, this approach suffers from high variability\nand low reliability. In this work, we propose Description-free Multi-prompt\nLearning(DeMul), a novel method that eliminates the process of extracting\ndescriptions and instead directly distills knowledge from LLM into prompts. By\nadopting a description-free approach, prompts can encapsulate richer semantics\nwhile still being represented as continuous vectors for optimization, thereby\neliminating the need for discrete pre-defined templates. Additionally, in a\nmulti-prompt setting, we empirically demonstrate the potential of prompt\nweighting in reflecting the importance of different prompts during training.\nExperimental results show that our approach achieves superior performance\nacross 11 recognition datasets.", "AI": {"tldr": "This paper introduces DeMul, a description-free multi-prompt learning technique for adapting vision language models (VLMs) to downstream tasks, achieving improved performance on recognition datasets.", "motivation": "To address the limitations of variability and reliability in existing prompt learning methods that extract text-based descriptions from large language models (LLMs).", "method": "The proposed method, DeMul, eliminates the need for extracting text-based descriptions and instead directly integrates knowledge from LLMs into continuous vector prompts. Multi-prompt weighting is also utilized to reflect the importance of different prompts during training.", "result": "DeMul achieves superior performance across 11 recognition datasets, demonstrating its effectiveness in adapting VLMs to downstream tasks.", "conclusion": "DeMul enhances the adaptability of pre-trained VLMs by using robust, description-free, and weighted multi-prompt learning, proving its efficacy in handling diverse and unseen data."}}
{"id": "2507.07230", "pdf": "https://arxiv.org/pdf/2507.07230", "abs": "https://arxiv.org/abs/2507.07230", "authors": ["Priyank Pathak", "Yogesh S. Rawat"], "title": "Colors See Colors Ignore: Clothes Changing ReID with Color Disentanglement", "categories": ["cs.CV"], "comment": "ICCV'25 paper", "summary": "Clothes-Changing Re-Identification (CC-ReID) aims to recognize individuals\nacross different locations and times, irrespective of clothing. Existing\nmethods often rely on additional models or annotations to learn robust,\nclothing-invariant features, making them resource-intensive. In contrast, we\nexplore the use of color - specifically foreground and background colors - as a\nlightweight, annotation-free proxy for mitigating appearance bias in ReID\nmodels. We propose Colors See, Colors Ignore (CSCI), an RGB-only method that\nleverages color information directly from raw images or video frames. CSCI\nefficiently captures color-related appearance bias ('Color See') while\ndisentangling it from identity-relevant ReID features ('Color Ignore'). To\nachieve this, we introduce S2A self-attention, a novel self-attention to\nprevent information leak between color and identity cues within the feature\nspace. Our analysis shows a strong correspondence between learned color\nembeddings and clothing attributes, validating color as an effective proxy when\nexplicit clothing labels are unavailable. We demonstrate the effectiveness of\nCSCI on both image and video ReID with extensive experiments on four CC-ReID\ndatasets. We improve the baseline by Top-1 2.9% on LTCC and 5.0% on PRCC for\nimage-based ReID, and 1.0% on CCVID and 2.5% on MeVID for video-based ReID\nwithout relying on additional supervision. Our results highlight the potential\nof color as a cost-effective solution for addressing appearance bias in\nCC-ReID. Github: https://github.com/ppriyank/ICCV-CSCI-Person-ReID.", "AI": {"tldr": "The paper introduces CSCI, an RGB-only method leveraging color information for Clothes-Changing Re-Identification (CC-ReID), eliminating the need for additional annotations or models.", "motivation": "Current CC-ReID methods are resource-intensive, requiring additional models or annotations to learn clothing-invariant features. The authors aim to develop a lightweight and annotation-free alternative using color information.", "method": "The proposed method, Colors See, Colors Ignore (CSCI), uses raw RGB images to separate color-related biases from identity cues. It introduces S2A self-attention to avoid information leakage between color and identity cues.", "result": "CSCI achieved improvements of Top-1 2.9% (LTCC), 5.0% (PRCC) for image-based ReID, and 1.0% (CCVID), 2.5% (MeVID) for video-based ReID without additional supervision.", "conclusion": "The study demonstrates the effectiveness of using color as a proxy for mitigating appearance bias in CC-ReID, offering a resource-efficient alternative to existing methods."}}
{"id": "2507.07445", "pdf": "https://arxiv.org/pdf/2507.07445", "abs": "https://arxiv.org/abs/2507.07445", "authors": ["Weihao Tan", "Changjiu Jiang", "Yu Duan", "Mingcong Lei", "Jiageng Li", "Yitian Hong", "Xinrun Wang", "Bo An"], "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley", "categories": ["cs.AI"], "comment": "Project website: https://weihaotan.github.io/StarDojo", "summary": "Autonomous agents navigating human society must master both production\nactivities and social interactions, yet existing benchmarks rarely evaluate\nthese skills simultaneously. To bridge this gap, we introduce StarDojo, a novel\nbenchmark based on Stardew Valley, designed to assess AI agents in open-ended\nproduction-living simulations. In StarDojo, agents are tasked to perform\nessential livelihood activities such as farming and crafting, while\nsimultaneously engaging in social interactions to establish relationships\nwithin a vibrant community. StarDojo features 1,000 meticulously curated tasks\nacross five key domains: farming, crafting, exploration, combat, and social\ninteractions. Additionally, we provide a compact subset of 100 representative\ntasks for efficient model evaluation. The benchmark offers a unified,\nuser-friendly interface that eliminates the need for keyboard and mouse\ncontrol, supports all major operating systems, and enables the parallel\nexecution of multiple environment instances, making it particularly well-suited\nfor evaluating the most capable foundation agents, powered by multimodal large\nlanguage models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents\ndemonstrate substantial limitations, with the best-performing model, GPT-4.1,\nachieving only a 12.7% success rate, primarily due to challenges in visual\nunderstanding, multimodal reasoning and low-level manipulation. As a\nuser-friendly environment and benchmark, StarDojo aims to facilitate further\nresearch towards robust, open-ended agents in complex production-living\nenvironments.", "AI": {"tldr": "StarDojo is a benchmark designed for evaluating AI agents in open-ended production-living simulations, featuring 1,000 tasks across domains like farming, crafting, and social interactions.", "motivation": "To address the lack of benchmarks that simultaneously evaluate both production activities and social interactions of AI agents.", "method": "The benchmark uses Stardew Valley as the foundation to create 1,000 tasks across five domains and provides tools for parallel environment execution and multimodal model evaluation.", "result": "State-of-the-art models, like GPT-4.1, achieved only a 12.7% success rate, revealing significant deficits in multimodal reasoning and manipulation.", "conclusion": "StarDojo serves as a tool to advance research and development of AI agents capable of thriving in complex, open-ended environments."}}
{"id": "2507.07932", "pdf": "https://arxiv.org/pdf/2507.07932", "abs": "https://arxiv.org/abs/2507.07932", "authors": ["Guilin Zhang", "Wulan Guo", "Ziqi Tan", "Qiang Guan", "Hailong Jiang"], "title": "KIS-S: A GPU-Aware Kubernetes Inference Simulator with RL-Based Auto-Scaling", "categories": ["cs.DC"], "comment": "8 pages, 6 figures", "summary": "Autoscaling GPU inference workloads in Kubernetes remains challenging due to\nthe reactive and threshold-based nature of default mechanisms such as the\nHorizontal Pod Autoscaler (HPA), which struggle under dynamic and bursty\ntraffic patterns and lack integration with GPU-level metrics. We present KIS-S,\na unified framework that combines KISim, a GPU-aware Kubernetes Inference\nSimulator, with KIScaler, a Proximal Policy Optimization (PPO)-based\nautoscaler. KIScaler learns latency-aware and resource-efficient scaling\npolicies entirely in simulation, and is directly deployed without retraining.\nExperiments across four traffic patterns show that KIScaler improves average\nreward by 75.2%, reduces P95 latency up to 6.7x over CPU baselines, and\ngeneralizes without retraining. Our work bridges the gap between reactive\nautoscaling and intelligent orchestration for scalable GPU-accelerated\nenvironments.", "AI": {"tldr": "Reactive autoscaling in Kubernetes struggles with GPU workloads under dynamic traffic. KIS-S combines a GPU-aware simulator with a PPO-based autoscaler for latency-aware scaling, improving efficiency and reward metrics across diverse traffic patterns.", "motivation": "Address challenges in autoscaling GPU inference workloads in Kubernetes due to the shortcomings of default mechanisms, such as HPA's reactive and threshold-based scaling approaches.", "method": "Developed KIS-S, comprising KISim (a GPU-aware Kubernetes simulator) and KIScaler (a PPO-based autoscaler) that learns efficient policies via simulation without retraining.", "result": "KIScaler achieves a 75.2% increase in average reward, reduces P95 latency by up to 6.7x compared to CPU baseline, and generalizes across traffic patterns without requiring retraining.", "conclusion": "KIS-S bridges the gap between traditional reactive autoscaling and optimized GPU workload orchestration, achieving better latency and scalability in dynamic environments."}}
{"id": "2507.07467", "pdf": "https://arxiv.org/pdf/2507.07467", "abs": "https://arxiv.org/abs/2507.07467", "authors": ["Juyeop Han", "Lukas Lao Beyer", "Guilherme V. Cavalheiro", "Sertac Karaman"], "title": "SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation", "categories": ["cs.RO"], "comment": "8 pages, 7 figures, 3 tables", "summary": "Autonomous flight in GPS denied indoor spaces requires trajectories that keep\nvisual localization error tightly bounded across varied missions. Whereas\nvisual inertial odometry (VIO) accumulates drift over time, scene coordinate\nregression (SCR) yields drift-free, high accuracy absolute pose estimation. We\npresent a perception-aware framework that couples an evidential learning-based\nSCR pose estimator with a receding horizon trajectory optimizer. The optimizer\nsteers the onboard camera toward pixels whose uncertainty predicts reliable\nscene coordinates, while a fixed-lag smoother fuses the low rate SCR stream\nwith high rate IMU data to close the perception control loop in real time. In\nsimulation, our planner reduces translation (rotation) mean error by 54% / 15%\n(40% / 31%) relative to yaw fixed and forward-looking baselines, respectively.\nMoreover, hardware in the loop experiment validates the feasibility of our\nproposed framework.", "AI": {"tldr": "The paper introduces a framework combining scene coordinate regression (SCR) for high-accuracy pose estimation and trajectory optimization for perception-aware indoor autonomous flight.", "motivation": "To address drift issues in visual inertial odometry (VIO) and ensure bounded visual localization error for autonomous flight in GPS-denied indoor spaces.", "method": "Couples evidential learning-based SCR for pose estimation with receding horizon trajectory optimization steering a camera towards reliable pixels, supported by a fixed-lag smoother integrating SCR and IMU data.", "result": "Simulation results show significant error reduction in translation (54%, 15%) and rotation (40%, 31%) compared to baselines. Hardware-in-the-loop validates feasibility.", "conclusion": "The perception-aware framework reliably boosts localization accuracy and is feasible for real-time use in autonomous indoor navigation."}}
{"id": "2507.07441", "pdf": "https://arxiv.org/pdf/2507.07441", "abs": "https://arxiv.org/abs/2507.07441", "authors": ["Yu Xia", "Yiran Jenny Shen", "Junda Wu", "Tong Yu", "Sungchul Kim", "Ryan A. Rossi", "Lina Yao", "Julian McAuley"], "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Model (LLM) agents are commonly tuned with supervised\nfinetuning on ReAct-style expert trajectories or preference optimization over\npairwise rollouts. Most of these methods focus on imitating specific expert\nbehaviors or promoting chosen reasoning thoughts and actions over rejected\nones. However, without reasoning and comparing over alternatives actions, LLM\nagents finetuned with these methods may over-commit towards seemingly plausible\nbut suboptimal actions due to limited action space exploration. To address\nthis, in this paper we propose Self-taught ActioN Deliberation (SAND)\nframework, enabling LLM agents to explicitly deliberate over candidate actions\nbefore committing to one. To tackle the challenges of when and what to\ndeliberate given large action space and step-level action evaluation, we\nincorporate self-consistency action sampling and execution-guided action\ncritique to help synthesize step-wise action deliberation thoughts using the\nbase model of the LLM agent. In an iterative manner, the deliberation\ntrajectories are then used to finetune the LLM agent itself. Evaluating on two\nrepresentative interactive agent tasks, SAND achieves an average 20%\nimprovement over initial supervised finetuning and also outperforms\nstate-of-the-art agent tuning approaches.", "AI": {"tldr": "The paper introduces the SAND framework, enabling LLM agents to better deliberate over candidate actions before deciding, leading to improved performance in interactive tasks.", "motivation": "Traditional LLM tuning methods over-commit to plausible but suboptimal actions because of limited action space exploration, motivating the need for a framework that improves action deliberation.", "method": "The paper proposes SAND, which leverages self-consistency action sampling and execution-guided action critique for step-wise deliberation. This generates iterative trajectories to finetune LLM agents.", "result": "SAND achieves an average 20% improvement over initial supervised finetuning and outperforms state-of-the-art methods in representative interactive agent tasks.", "conclusion": "The SAND framework significantly enhances reasoning and decision-making in LLM agents, addressing the shortcomings of traditional finetuning approaches."}}
{"id": "2507.07852", "pdf": "https://arxiv.org/pdf/2507.07852", "abs": "https://arxiv.org/abs/2507.07852", "authors": ["Haichen Hu", "David Simchi-Levi"], "title": "Pre-Trained AI Model Assisted Online Decision-Making under Missing Covariates: A Theoretical Perspective", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study a sequential contextual decision-making problem in which certain\ncovariates are missing but can be imputed using a pre-trained AI model. From a\ntheoretical perspective, we analyze how the presence of such a model influences\nthe regret of the decision-making process. We introduce a novel notion called\n\"model elasticity\", which quantifies the sensitivity of the reward function to\nthe discrepancy between the true covariate and its imputed counterpart. This\nconcept provides a unified way to characterize the regret incurred due to model\nimputation, regardless of the underlying missingness mechanism. More\nsurprisingly, we show that under the missing at random (MAR) setting, it is\npossible to sequentially calibrate the pre-trained model using tools from\northogonal statistical learning and doubly robust regression. This calibration\nsignificantly improves the quality of the imputed covariates, leading to much\nbetter regret guarantees. Our analysis highlights the practical value of having\nan accurate pre-trained model in sequential decision-making tasks and suggests\nthat model elasticity may serve as a fundamental metric for understanding and\nimproving the integration of pre-trained models in a wide range of data-driven\ndecision-making problems.", "AI": {"tldr": "The paper examines how pre-trained AI models for imputing missing covariates affect regret in sequential decision-making tasks, proposing 'model elasticity' as a key metric.", "motivation": "The study aims to understand the impact of pre-trained AI models on decision-making when data is missing and to develop methods to mitigate the resulting regret.", "method": "Introduced 'model elasticity' to analyze sensitivity and utilized orthogonal statistical learning and doubly robust regression for sequential model calibration under a MAR setting.", "result": "Sequential calibration of pre-trained models significantly improves imputation quality and reduces regret.", "conclusion": "Model elasticity offers a unified framework to optimize the integration of pre-trained models, enhancing sequential decision-making across various domains."}}
{"id": "2507.07192", "pdf": "https://arxiv.org/pdf/2507.07192", "abs": "https://arxiv.org/abs/2507.07192", "authors": ["Huibo Xu", "Runlong Yu", "Likang Wu", "Xianquan Wang", "Qi Liu"], "title": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models, a type of generative model, have shown promise in time\nseries forecasting. But they face limitations like rigid source distributions\nand limited sampling paths, which hinder their performance. Flow matching\noffers faster generation, higher-quality outputs, and greater flexibility,\nwhile also possessing the ability to utilize valuable information from the\nprediction errors of prior models, which were previously inaccessible yet\ncritically important. To address these challenges and fully unlock the untapped\npotential of flow matching, we propose Conditional Guided Flow Matching (CGFM).\nCGFM extends flow matching by incorporating the outputs of an auxiliary model,\nenabling a previously unattainable capability in the field: learning from the\nerrors of the auxiliary model. For time series forecasting tasks, it integrates\nhistorical data as conditions and guidance, constructs two-sided conditional\nprobability paths, and uses a general affine path to expand the space of\nprobability paths, ultimately leading to improved predictions. Extensive\nexperiments show that CGFM consistently enhances and outperforms\nstate-of-the-art models, highlighting its effectiveness in advancing\nforecasting methods.", "AI": {"tldr": "Conditional Guided Flow Matching (CGFM) improves time series forecasting by leveraging error information from auxiliary models, surpassing state-of-the-art techniques.", "motivation": "Time series forecasting needs advancements to overcome limitations in rigid generative models and limited error utilization.", "method": "CGFM incorporates auxiliary model outputs, historical data conditions, and expands probability path space using two-sided conditional probability paths.", "result": "CGFM consistently outperforms state-of-the-art forecasting models in experimental evaluations.", "conclusion": "This approach effectively addresses existing challenges and significantly advances the capability and accuracy of forecasting methods."}}
{"id": "2507.07242", "pdf": "https://arxiv.org/pdf/2507.07242", "abs": "https://arxiv.org/abs/2507.07242", "authors": ["Johannes Merz", "Lucien Fostier"], "title": "Automated Video Segmentation Machine Learning Pipeline", "categories": ["cs.CV"], "comment": null, "summary": "Visual effects (VFX) production often struggles with slow, resource-intensive\nmask generation. This paper presents an automated video segmentation pipeline\nthat creates temporally consistent instance masks. It employs machine learning\nfor: (1) flexible object detection via text prompts, (2) refined per-frame\nimage segmentation and (3) robust video tracking to ensure temporal stability.\nDeployed using containerization and leveraging a structured output format, the\npipeline was quickly adopted by our artists. It significantly reduces manual\neffort, speeds up the creation of preliminary composites, and provides\ncomprehensive segmentation data, thereby enhancing overall VFX production\nefficiency.", "AI": {"tldr": "The paper introduces a machine learning-based automated pipeline for creating consistent masks in video segmentation to enhance VFX production efficiency.", "motivation": "Address the inefficiency and resource-intensive process of mask generation in VFX production.", "method": "Machine learning techniques are employed for text-prompt-based object detection, refined image segmentation per frame, and robust video tracking for temporal stability. The system is deployed via containerization with structured outputs.", "result": "Artists quickly adopted the pipeline, which reduced manual effort, accelerated composite creation, and provided detailed segmentation data.", "conclusion": "The automated pipeline improves manual labor efficiency, speeds up production processes, and introduces better segmentation for more efficient VFX workflows."}}
{"id": "2507.07544", "pdf": "https://arxiv.org/pdf/2507.07544", "abs": "https://arxiv.org/abs/2507.07544", "authors": ["Oliver Eberle", "Thomas McGee", "Hamza Giaffar", "Taylor Webb", "Ida Momennejad"], "title": "Position: We Need An Algorithmic Understanding of Generative AI", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at ICML 2025 as a Spotlight Position Paper", "summary": "What algorithms do LLMs actually learn and use to solve problems? Studies\naddressing this question are sparse, as research priorities are focused on\nimproving performance through scale, leaving a theoretical and empirical gap in\nunderstanding emergent algorithms. This position paper proposes AlgEval: a\nframework for systematic research into the algorithms that LLMs learn and use.\nAlgEval aims to uncover algorithmic primitives, reflected in latent\nrepresentations, attention, and inference-time compute, and their algorithmic\ncomposition to solve task-specific problems. We highlight potential\nmethodological paths and a case study toward this goal, focusing on emergent\nsearch algorithms. Our case study illustrates both the formation of top-down\nhypotheses about candidate algorithms, and bottom-up tests of these hypotheses\nvia circuit-level analysis of attention patterns and hidden states. The\nrigorous, systematic evaluation of how LLMs actually solve tasks provides an\nalternative to resource-intensive scaling, reorienting the field toward a\nprincipled understanding of underlying computations. Such algorithmic\nexplanations offer a pathway to human-understandable interpretability, enabling\ncomprehension of the model's internal reasoning performance measures. This can\nin turn lead to more sample-efficient methods for training and improving\nperformance, as well as novel architectures for end-to-end and multi-agent\nsystems.", "AI": {"tldr": "This paper proposes AlgEval, a systematic framework to investigate the algorithms learned and used by large language models (LLMs), with a focus on interpretability and algorithmic understanding.", "motivation": "To address the lack of research into the algorithms behind LLMs' problem-solving methods, countering the current focus on performance scaling without understanding emergent algorithms.", "method": "Introduces AlgEval, which identifies algorithmic primitives through analysis of LLM latent representations, attention, and inference-time compute, and tests algorithmic hypotheses via circuit-level analysis.", "result": "Presents a case study that illustrates hypotheses about emergent search algorithms and validates them through analysis of attention patterns and hidden states.", "conclusion": "Algorithmic explanations enable human-understandable interpretability, more efficient training, and novel architectures, offering a shift from resource-intensive scaling to principled computational understanding."}}
{"id": "1602.03104", "pdf": "https://arxiv.org/pdf/1602.03104", "abs": "https://arxiv.org/abs/1602.03104", "authors": ["Ayan Dutta", "Prithviraj Dasgupta", "Carl Nelson"], "title": "A Graph Isomorphism-based Decentralized Algorithm for Modular Robot Configuration Formation", "categories": ["cs.RO", "cs.DC", "cs.DS"], "comment": null, "summary": "We consider the problem of configuration formation in modular robot systems\nwhere a set of modules that are initially in different configurations and\nlocated at different locations are required to assume appropriate positions so\nthat they can get into a new, user-specified, target configuration. We propose\na novel algorithm based on graph isomorphism, where the modules select\nlocations or spots in the target configuration using a utility-based framework,\nwhile retaining their original configuration to the greatest extent possible,\nto reduce the time and energy required by the modules to assume the target\nconfiguration. We have shown analytically that our proposed algorithm is\ncomplete and guarantees a Pareto-optimal allocation. Experimental simulations\nof our algorithm with different number of modules in different initial\nconfigurations and located initially at different locations, show that the\nplanning time of our algorithm is nominal (order of msec. for 100 modules). We\nhave also compared our algorithm against a market-based allocation algorithm\nand shown that our proposed algorithm performs better in terms of time and\nnumber of messages exchanged.", "AI": {"tldr": "This paper proposes a graph-isomorphism-based algorithm to optimize modular robot system reconfiguration, emphasizing Pareto-optimal allocations and reduced time/energy.", "motivation": "The motivation is to address the challenge of efficiently reconfiguring modular robot systems into a user-specified target configuration, while minimizing time and energy utilization.", "method": "The authors propose a novel algorithm utilizing graph isomorphism and a utility-based framework that prioritizes modules retaining their original configuration as much as possible. Analytical proofs of completeness and Pareto-optimality are provided.", "result": "The algorithm performs quickly (milliseconds for 100 modules) and outperforms a market-based alternative in terms of planning time and message complexity under experimental conditions.", "conclusion": "The proposed algorithm offers an effective, efficient, and analytically sound solution for modular robot reconfiguration, outperforming existing approaches in key metrics."}}
{"id": "2507.07661", "pdf": "https://arxiv.org/pdf/2507.07661", "abs": "https://arxiv.org/abs/2507.07661", "authors": ["Daria Trinitatova", "Dzmitry Tsetserukou"], "title": "FiDTouch: A 3D Wearable Haptic Display for the Finger Pad", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted to the IEEE World Haptics Conference 2025 (IEEE WHC 2025), 7\n  pages, 8 figures, 3 tables", "summary": "The applications of fingertip haptic devices have spread to various fields\nfrom revolutionizing virtual reality and medical training simulations to\nfacilitating remote robotic operations, proposing great potential for enhancing\nuser experiences, improving training outcomes, and new forms of interaction. In\nthis work, we present FiDTouch, a 3D wearable haptic device that delivers\ncutaneous stimuli to the finger pad, such as contact, pressure, encounter, skin\nstretch, and vibrotactile feedback. The application of a tiny inverted Delta\nrobot in the mechanism design allows providing accurate contact and fast\nchanging dynamic stimuli to the finger pad surface. The performance of the\ndeveloped display was evaluated in a two-stage user study of the perception of\nstatic spatial contact stimuli and skin stretch stimuli generated on the finger\npad. The proposed display, by providing users with precise touch and force\nstimuli, can enhance user immersion and efficiency in the fields of\nhuman-computer and human-robot interactions.", "AI": {"tldr": "FiDTouch is a wearable haptic device designed to enhance tactile feedback on the fingertip, aimed at improving user interaction in various fields like virtual reality and robotics.", "motivation": "To improve tactile feedback and user experiences in diverse fields such as virtual reality, medical training, and human-robot interaction.", "method": "Development of FiDTouch, a 3D wearable haptic device utilizing an inverted Delta robot mechanism for delivering precise and dynamic feedback to the fingertip.", "result": "Evaluation of FiDTouch in a user study demonstrated its ability to deliver accurate and dynamic tactile stimuli like skin stretch and spatial contact.", "conclusion": "FiDTouch shows promise in enhancing user immersion and efficiency, benefiting applications in virtual reality, medical training, and human-computer interaction."}}
{"id": "2507.07451", "pdf": "https://arxiv.org/pdf/2507.07451", "abs": "https://arxiv.org/abs/2507.07451", "authors": ["Hongzhi Zhang", "Jia Fu", "Jingyuan Zhang", "Kai Fu", "Qi Wang", "Fuzheng Zhang", "Guorui Zhou"], "title": "RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning", "categories": ["cs.CL"], "comment": "https://github.com/Kwai-Klear/RLEP", "summary": "Reinforcement learning (RL) for large language models is an energy-intensive\nendeavor: training can be unstable, and the policy may gradually drift away\nfrom its pretrained weights. We present \\emph{RLEP}\\, -- \\,Reinforcement\nLearning with Experience rePlay\\, -- \\,a two-phase framework that first\ncollects verified trajectories and then replays them during subsequent\ntraining. At every update step, the policy is optimized on mini-batches that\nblend newly generated rollouts with these replayed successes. By replaying\nhigh-quality examples, RLEP steers the model away from fruitless exploration,\nfocuses learning on promising reasoning paths, and delivers both faster\nconvergence and stronger final performance. On the Qwen2.5-Math-7B base model,\nRLEP reaches baseline peak accuracy with substantially fewer updates and\nultimately surpasses it, improving accuracy on AIME-2024 from 38.2% to 39.9%,\non AIME-2025 from 19.8% to 22.3%, and on AMC-2023 from 77.0% to 82.2%. Our\ncode, datasets, and checkpoints are publicly available at\nhttps://github.com/Kwai-Klear/RLEP to facilitate reproducibility and further\nresearch.", "AI": {"tldr": "This paper introduces RLEP, a two-phase reinforcement learning framework for large language models. It focuses on verified trajectories and replaying successful ones to improve learning stability and performance.", "motivation": "The paper aims to address the instability and energy-intensive nature of reinforcement learning for large language models, as well as the issue of policy drifting from pretrained weights.", "method": "RLEP uses a two-phase framework where verified trajectories are collected first and then replayed during further training. It optimizes with mini-batches blending new rollouts and replayed high-quality examples to focus learning on relevant paths.", "result": "The paper reports faster convergence and improved accuracy on mathematical reasoning tasks compared to baselines, with performance gains ranging from 1.7% to 5.2% across different challenges.", "conclusion": "RLEP effectively enhances reinforcement learning for large language models by steering training towards high-quality reasoning trajectories, improving stability, convergence speed, and final accuracy."}}
{"id": "2507.07941", "pdf": "https://arxiv.org/pdf/2507.07941", "abs": "https://arxiv.org/abs/2507.07941", "authors": ["Sohom Bhattacharya", "Yongzhuo Chen", "Muxuan Liang"], "title": "Late Fusion Multi-task Learning for Semiparametric Inference with Nuisance Parameters", "categories": ["stat.ME", "stat.ML"], "comment": "21 pages, 3 figures", "summary": "In the age of large and heterogeneous datasets, the integration of\ninformation from diverse sources is essential to improve parameter estimation.\nMulti-task learning offers a powerful approach by enabling simultaneous\nlearning across related tasks. In this work, we introduce a late fusion\nframework for multi-task learning with semiparametric models that involve\ninfinite-dimensional nuisance parameters, focusing on applications such as\nheterogeneous treatment effect estimation across multiple data sources,\nincluding electronic health records from different hospitals or clinical trial\ndata. Our framework is two-step: first, initial double machine-learning\nestimators are obtained through individual task learning; second, these\nestimators are adaptively aggregated to exploit task similarities while\nremaining robust to task-specific differences. In particular, the framework\navoids individual level data sharing, preserving privacy. Additionally, we\npropose a novel multi-task learning method for nuisance parameter estimation,\nwhich further enhances parameter estimation when nuisance parameters exhibit\nsimilarity across tasks. We establish theoretical guarantees for the method,\ndemonstrating faster convergence rates compared to individual task learning\nwhen tasks share similar parametric components. Extensive simulations and real\ndata applications complement the theoretical findings of our work while\nhighlight the effectiveness of our framework even in moderate sample sizes.", "AI": {"tldr": "The paper presents a two-step late fusion framework for multi-task learning applied to semiparametric models, focusing on heterogeneous treatment effect estimation across datasets, demonstrating increased robustness, privacy preservation, and improved convergence rates.", "motivation": "With the rising prevalence of large and diverse datasets, the need arises to integrate information from multiple sources to enhance parameter estimation, particularly in applications like heterogeneous treatment effect estimation.", "method": "The framework uses a two-step approach: first by employing double machine-learning estimators for individual tasks, and then by adaptively aggregating them to utilize task similarities and address differences. It also introduces a multi-task learning method for estimating nuisance parameters.", "result": "This framework achieves faster convergence rates compared to individual task learning when tasks have shared parametric components. The approach also retains privacy by avoiding data sharing and is effective even with moderate sample sizes.", "conclusion": "The proposed method offers a robust, privacy-preserving, and theoretically grounded solution for multi-task learning across heterogeneous datasets, validated through simulations and real-world applications, showcasing its practicality and efficiency."}}
{"id": "2507.07197", "pdf": "https://arxiv.org/pdf/2507.07197", "abs": "https://arxiv.org/abs/2507.07197", "authors": ["Elia Piccoli", "Malio Li", "Giacomo Carf\u00ec", "Vincenzo Lomonaco", "Davide Bacciu"], "title": "Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Published at 4th Conference on Lifelong Learning Agents (CoLLAs),\n  2025", "summary": "The recent focus and release of pre-trained models have been a key components\nto several advancements in many fields (e.g. Natural Language Processing and\nComputer Vision), as a matter of fact, pre-trained models learn disparate\nlatent embeddings sharing insightful representations. On the other hand,\nReinforcement Learning (RL) focuses on maximizing the cumulative reward\nobtained via agent's interaction with the environment. RL agents do not have\nany prior knowledge about the world, and they either learn from scratch an\nend-to-end mapping between the observation and action spaces or, in more recent\nworks, are paired with monolithic and computationally expensive Foundational\nModels. How to effectively combine and leverage the hidden information of\ndifferent pre-trained models simultaneously in RL is still an open and\nunderstudied question. In this work, we propose Weight Sharing Attention (WSA),\na new architecture to combine embeddings of multiple pre-trained models to\nshape an enriched state representation, balancing the tradeoff between\nefficiency and performance. We run an extensive comparison between several\ncombination modes showing that WSA obtains comparable performance on multiple\nAtari games compared to end-to-end models. Furthermore, we study the\ngeneralization capabilities of this approach and analyze how scaling the number\nof models influences agents' performance during and after training.", "AI": {"tldr": "The paper introduces Weight Sharing Attention (WSA), a method to integrate embeddings from multiple pre-trained models for enhanced state representation in reinforcement learning (RL).", "motivation": "Although pre-trained models have shown promising representation capabilities in fields like NLP and vision, their integration with RL remains limited. RL agents typically lack prior knowledge and rely on either learning from scratch or being tied to large foundational models. A more flexible and efficient architecture for combining pre-trained embeddings in RL is needed.", "method": "The proposed Weight Sharing Attention (WSA) architecture combines embeddings from multiple pre-trained models into a unified and enriched state representation. It aims to achieve a balance between computational efficiency and model performance.", "result": "The WSA model demonstrates performance comparable to end-to-end models in several Atari games. Experiments also reveal its generalization abilities and how scaling the number of pre-trained models impacts the RL agent's performance.", "conclusion": "WSA offers a promising approach to leverage multiple pre-trained models in RL, showing both efficiency and competitive effectiveness in complex environments."}}
{"id": "2507.07262", "pdf": "https://arxiv.org/pdf/2507.07262", "abs": "https://arxiv.org/abs/2507.07262", "authors": ["Shehreen Azad", "Yogesh S Rawat"], "title": "DisenQ: Disentangling Q-Former for Activity-Biometrics", "categories": ["cs.CV"], "comment": "Accepted in ICCV 2025", "summary": "In this work, we address activity-biometrics, which involves identifying\nindividuals across diverse set of activities. Unlike traditional person\nidentification, this setting introduces additional challenges as identity cues\nbecome entangled with motion dynamics and appearance variations, making\nbiometrics feature learning more complex. While additional visual data like\npose and/or silhouette help, they often struggle from extraction inaccuracies.\nTo overcome this, we propose a multimodal language-guided framework that\nreplaces reliance on additional visual data with structured textual\nsupervision. At its core, we introduce \\textbf{DisenQ} (\\textbf{Disen}tangling\n\\textbf{Q}-Former), a unified querying transformer that disentangles\nbiometrics, motion, and non-biometrics features by leveraging structured\nlanguage guidance. This ensures identity cues remain independent of appearance\nand motion variations, preventing misidentifications. We evaluate our approach\non three activity-based video benchmarks, achieving state-of-the-art\nperformance. Additionally, we demonstrate strong generalization to complex\nreal-world scenario with competitive performance on a traditional video-based\nidentification benchmark, showing the effectiveness of our framework.", "AI": {"tldr": "The paper proposes a framework for identifying individuals across different activities using text-based guidance, achieving state-of-the-art results on several benchmarks.", "motivation": "Current biometric methods struggle with challenges like motion dynamics and appearance variations, making feature learning complex. Additional visual data like pose or silhouette is often unreliable.", "method": "The authors propose a multimodal language-guided framework named DisenQ (Disentangling Q-Former), which uses structured textual supervision to disentangle biometric, motion, and non-biometric features.", "result": "The framework achieves state-of-the-art performance on three activity-based video benchmarks and performs competitively in traditional video-based identification tasks.", "conclusion": "The proposed method effectively separates identity cues from motion and appearance variations, demonstrating strong generalization and improved accuracy in both controlled and real-world scenarios."}}
{"id": "2507.07576", "pdf": "https://arxiv.org/pdf/2507.07576", "abs": "https://arxiv.org/abs/2507.07576", "authors": ["Mohamed Siala", "Jordi Planes", "Joao Marques-Silva"], "title": "On Trustworthy Rule-Based Models and Explanations", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "A task of interest in machine learning (ML) is that of ascribing explanations\nto the predictions made by ML models. Furthermore, in domains deemed high risk,\nthe rigor of explanations is paramount. Indeed, incorrect explanations can and\nwill mislead human decision makers. As a result, and even if interpretability\nis acknowledged as an elusive concept, so-called interpretable models are\nemployed ubiquitously in high-risk uses of ML and data mining (DM). This is the\ncase for rule-based ML models, which encompass decision trees, diagrams, sets\nand lists. This paper relates explanations with well-known undesired facets of\nrule-based ML models, which include negative overlap and several forms of\nredundancy. The paper develops algorithms for the analysis of these undesired\nfacets of rule-based systems, and concludes that well-known and widely used\ntools for learning rule-based ML models will induce rule sets that exhibit one\nor more negative facets.", "AI": {"tldr": "This paper studies undesired facets in rule-based machine learning models and introduces algorithms to analyze them.", "motivation": "Explaining ML predictions is critical in high-risk domains as incorrect explanations can mislead human decision-makers.", "method": "The study develops algorithms to identify negative overlap and redundancies in rule-based ML models.", "result": "Popular rule-based ML tools are found to induce rule sets with negative aspects such as redundancy and negative overlap.", "conclusion": "Despite widespread usage, rule-based ML models designed to enhance interpretability often have intrinsic flaws that can impair explanation quality."}}
{"id": "2507.07589", "pdf": "https://arxiv.org/pdf/2507.07589", "abs": "https://arxiv.org/abs/2507.07589", "authors": ["Arpana Sinhal", "Anay Sinhal", "Amit Sinhal"], "title": "Stress Monitoring in Healthcare: An Ensemble Machine Learning Framework Using Wearable Sensor Data", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Healthcare professionals, particularly nurses, face elevated occupational\nstress, a concern amplified during the COVID-19 pandemic. While wearable\nsensors offer promising avenues for real-time stress monitoring, existing\nstudies often lack comprehensive datasets and robust analytical frameworks.\nThis study addresses these gaps by introducing a multimodal dataset comprising\nphysiological signals, electrodermal activity, heart rate and skin temperature.\nA systematic literature review identified limitations in prior stress-detection\nmethodologies, particularly in handling class imbalance and optimizing model\ngeneralizability. To overcome these challenges, the dataset underwent\npreprocessing with the Synthetic Minority Over sampling Technique (SMOTE),\nensuring balanced representation of stress states. Advanced machine learning\nmodels including Random Forest, XGBoost and a Multi-Layer Perceptron (MLP) were\nevaluated and combined into a Stacking Classifier to leverage their collective\npredictive strengths. By using a publicly accessible dataset and a reproducible\nanalytical pipeline, this work advances the development of deployable\nstress-monitoring systems, offering practical implications for safeguarding\nhealthcare workers' mental health. Future research directions include expanding\ndemographic diversity and exploring edge-computing implementations for low\nlatency stress alerts.", "AI": {"tldr": "This study addresses stress detection in healthcare professionals using a multimodal dataset, advanced machine learning, and a systematic approach.", "motivation": "High occupational stress in healthcare professionals, especially during the COVID-19 pandemic, necessitates effective and deployable real-time monitoring solutions.", "method": "Created and preprocessed a multimodal physiological dataset using SMOTE for balance, and implemented machine learning models (Random Forest, XGBoost, MLP) combined through a Stacking Classifier.", "result": "Developed a reproducible pipeline with improved stress-detection capabilities leveraging ensemble machine learning techniques.", "conclusion": "The research provides a framework for deployable stress-monitoring systems with future focus on demographic diversity and edge-computing integration."}}
{"id": "2507.07714", "pdf": "https://arxiv.org/pdf/2507.07714", "abs": "https://arxiv.org/abs/2507.07714", "authors": ["Julio Garrido", "Javier Vales", "Diego Silva-Mu\u00f1iz", "Enrique Riveiro", "Pablo L\u00f3pez-Matencio", "Josu\u00e9 Rivera-Andrade"], "title": "Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "14 pages, 8 figures, 1 table, to be submitted to Advanced Intelligent\n  Systems", "summary": "Cable-Driven Parallel Robots (CDPRs) are increasingly used for load\nmanipulation tasks involving predefined toolpaths with intermediate stops. At\neach stop, where the platform maintains a fixed pose and the motors keep the\ncables under tension, the system must evaluate whether it is safe to proceed by\ndetecting anomalies that could compromise performance (e.g., wind gusts or\ncable impacts). This paper investigates whether anomalies can be detected using\nonly motor torque data, without additional sensors. It introduces an adaptive,\nunsupervised outlier detection algorithm based on Gaussian Mixture Models\n(GMMs) to identify anomalies from torque signals. The method starts with a\nbrief calibration period, just a few seconds, during which a GMM is fit on\nknown anomaly-free data. Real-time torque measurements are then evaluated using\nMahalanobis distance from the GMM, with statistically derived thresholds\ntriggering anomaly flags. Model parameters are periodically updated using the\nlatest segments identified as anomaly-free to adapt to changing conditions.\nValidation includes 14 long-duration test sessions simulating varied wind\nintensities. The proposed method achieves a 100% true positive rate and 95.4%\naverage true negative rate, with 1-second detection latency. Comparative\nevaluation against power threshold and non-adaptive GMM methods indicates\nhigher robustness to drift and environmental variation.", "AI": {"tldr": "This paper focuses on using motor torque data and an adaptive Gaussian Mixture Model for real-time anomaly detection in Cable-Driven Parallel Robots (CDPRs), achieving high accuracy and robustness.", "motivation": "To ensure the safety and performance of CDPRs during load manipulation tasks by detecting anomalies such as wind gusts or cable impacts, using only motor torque data and avoiding additional sensors.", "method": "An adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) is used. A brief calibration period trains the model on anomaly-free data, after which real-time torque data is evaluated using Mahalanobis distance and statistically-derived thresholds. Periodic model updates adapt to changing conditions.", "result": "The method achieved a 100% true positive rate and a 95.4% true negative rate on 14 long-duration test sessions, with a 1-second detection latency. It showed higher robustness compared to power threshold and non-adaptive GMM methods.", "conclusion": "The proposed GMM-based anomaly detection method is effective, adaptive, and robust for detecting anomalies in CDPRs, providing a reliable solution without additional sensors."}}
{"id": "2507.07484", "pdf": "https://arxiv.org/pdf/2507.07484", "abs": "https://arxiv.org/abs/2507.07484", "authors": ["Kaiqu Liang", "Haimin Hu", "Xuandong Zhao", "Dawn Song", "Thomas L. Griffiths", "Jaime Fern\u00e1ndez Fisac"], "title": "Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Project page, code & data: https://machine-bullshit.github.io", "summary": "Bullshit, as conceptualized by philosopher Harry Frankfurt, refers to\nstatements made without regard to their truth value. While previous work has\nexplored large language model (LLM) hallucination and sycophancy, we propose\nmachine bullshit as an overarching conceptual framework that can allow\nresearchers to characterize the broader phenomenon of emergent loss of\ntruthfulness in LLMs and shed light on its underlying mechanisms. We introduce\nthe Bullshit Index, a novel metric quantifying LLMs' indifference to truth, and\npropose a complementary taxonomy analyzing four qualitative forms of bullshit:\nempty rhetoric, paltering, weasel words, and unverified claims. We conduct\nempirical evaluations on the Marketplace dataset, the Political Neutrality\ndataset, and our new BullshitEval benchmark (2,400 scenarios spanning 100 AI\nassistants) explicitly designed to evaluate machine bullshit. Our results\ndemonstrate that model fine-tuning with reinforcement learning from human\nfeedback (RLHF) significantly exacerbates bullshit and inference-time\nchain-of-thought (CoT) prompting notably amplify specific bullshit forms,\nparticularly empty rhetoric and paltering. We also observe prevalent machine\nbullshit in political contexts, with weasel words as the dominant strategy. Our\nfindings highlight systematic challenges in AI alignment and provide new\ninsights toward more truthful LLM behavior.", "AI": {"tldr": "The paper conceptualizes 'machine bullshit' as LLM-generated statements indifferent to truth, introduces the Bullshit Index for quantification, and proposes a taxonomy for its forms.", "motivation": "To address the emergent issue of large language models losing truthfulness and create a framework to understand and mitigate this behavior.", "method": "Empirical evaluations using datasets, including Marketplace, Political Neutrality, and newly introduced BullshitEval. Analysis of machine bullshit under different fine-tuning techniques and inference strategies such as RLHF and CoT prompting.", "result": "Results reveal that fine-tuning with RLHF intensifies machine bullshit, CoT prompting amplifies certain forms, and political contexts show dominance of specific bullshit strategies like weasel words.", "conclusion": "The paper highlights challenges in achieving AI alignment, proposes methods to better understand machine truthfulness, and stresses the need for systematic solutions to address bullshit behaviors in LLMs."}}
{"id": "2507.07965", "pdf": "https://arxiv.org/pdf/2507.07965", "abs": "https://arxiv.org/abs/2507.07965", "authors": ["Yuxin Bai", "Cecelia Shuai", "Ashwin De Silva", "Siyu Yu", "Pratik Chaudhari", "Joshua T. Vogelstein"], "title": "Prospective Learning in Retrospect", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted to AGI 2025", "summary": "In most real-world applications of artificial intelligence, the distributions\nof the data and the goals of the learners tend to change over time. The\nProbably Approximately Correct (PAC) learning framework, which underpins most\nmachine learning algorithms, fails to account for dynamic data distributions\nand evolving objectives, often resulting in suboptimal performance. Prospective\nlearning is a recently introduced mathematical framework that overcomes some of\nthese limitations. We build on this framework to present preliminary results\nthat improve the algorithm and numerical results, and extend prospective\nlearning to sequential decision-making scenarios, specifically foraging. Code\nis available at: https://github.com/neurodata/prolearn2.", "AI": {"tldr": "Current AI approaches struggle with changing data and evolving goals. This paper enhances prospective learning to better handle these shifts, including applications in sequential decision-making like foraging.", "motivation": "Traditional PAC learning fails to adapt to dynamic environments, limiting its effectiveness in real-world scenarios.", "method": "Authors build upon the prospective learning framework, improving algorithms and extending its applications to scenarios like sequential decision-making.", "result": "Preliminary results demonstrate improved algorithmic performance and applicability to tasks like foraging.", "conclusion": "Enhanced prospective learning offers a promising approach to address dynamic environments and is applicable beyond traditional domains."}}
{"id": "2507.07274", "pdf": "https://arxiv.org/pdf/2507.07274", "abs": "https://arxiv.org/abs/2507.07274", "authors": ["Ananya Raval", "Aravind Narayanan", "Vahid Reza Khazaie", "Shaina Raza"], "title": "LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted at ASONAM'25", "summary": "Large Multimodal Models (LMMs) are typically trained on vast corpora of\nimage-text data but are often limited in linguistic coverage, leading to biased\nand unfair outputs across languages. While prior work has explored multimodal\nevaluation, less emphasis has been placed on assessing multilingual\ncapabilities. In this work, we introduce LinguaMark, a benchmark designed to\nevaluate state-of-the-art LMMs on a multilingual Visual Question Answering\n(VQA) task. Our dataset comprises 6,875 image-text pairs spanning 11 languages\nand five social attributes. We evaluate models using three key metrics: Bias,\nAnswer Relevancy, and Faithfulness. Our findings reveal that closed-source\nmodels generally achieve the highest overall performance. Both closed-source\n(GPT-4o and Gemini2.5) and open-source models (Gemma3, Qwen2.5) perform\ncompetitively across social attributes, and Qwen2.5 demonstrates strong\ngeneralization across multiple languages. We release our benchmark and\nevaluation code to encourage reproducibility and further research.", "AI": {"tldr": "The paper introduces LinguaMark, a benchmark for evaluating multilingual Visual Question Answering capabilities of Large Multimodal Models, focusing on bias, relevancy, and faithfulness.", "motivation": "To address the lack of focus on assessing multilingual capabilities in Large Multimodal Models, which often yield biased outputs across languages.", "method": "The authors created LinguaMark, a benchmark consisting of 6,875 image-text pairs covering 11 languages and 5 social attributes, and evaluated models on Bias, Answer Relevancy, and Faithfulness.", "result": "Findings show closed-source models generally outperform open-source ones, with Qwen2.5 demonstrating noteworthy multilingual generalization.", "conclusion": "The release of the LinguaMark benchmark and evaluation code aims to advance research on multilingual evaluations in multimodal AI models."}}
{"id": "2507.07595", "pdf": "https://arxiv.org/pdf/2507.07595", "abs": "https://arxiv.org/abs/2507.07595", "authors": ["Zhixiang Su", "Di Wang", "Chunyan Miao"], "title": "Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Recent investigations on the effectiveness of Graph Neural Network\n(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that\nvanilla aggregation does not significantly impact the model performance. In\nthis paper, we introduce a novel method, named Context Pooling, to enhance\nGNN-based models' efficacy for link predictions in KGs. To our best of\nknowledge, Context Pooling is the first methodology that applies graph pooling\nin KGs. Additionally, Context Pooling is first-of-its-kind to enable the\ngeneration of query-specific graphs for inductive settings, where testing\nentities are unseen during training. Specifically, we devise two metrics,\nnamely neighborhood precision and neighborhood recall, to assess the neighbors'\nlogical relevance regarding the given queries, thereby enabling the subsequent\ncomprehensive identification of only the logically relevant neighbors for link\nprediction. Our method is generic and assessed by being applied to two\nstate-of-the-art (SOTA) models on three public transductive and inductive\ndatasets, achieving SOTA performance in 42 out of 48 settings.", "AI": {"tldr": "The paper introduces Context Pooling, a novel graph pooling method, to improve GNN-based models for link prediction in Knowledge Graphs, achieving state-of-the-art performance.", "motivation": "Recent studies reveal that standard graph aggregation methods do not significantly improve GNN-based models for link prediction in Knowledge Graphs.", "method": "The authors developed Context Pooling, a graph pooling technique that identifies logical neighbors and generates query-specific graphs for inductive settings. It includes metrics for neighborhood precision and recall.", "result": "The proposed method achieves state-of-the-art performance in 42 out of 48 experimental settings on three public datasets.", "conclusion": "Context Pooling is a pioneering and effective improvement for GNN-based link prediction models, applicable to both transductive and inductive settings."}}
{"id": "2507.07718", "pdf": "https://arxiv.org/pdf/2507.07718", "abs": "https://arxiv.org/abs/2507.07718", "authors": ["Alberto Rota", "Ke Fan", "Elena De Momi"], "title": "Implementation and Assessment of an Augmented Training Curriculum for Surgical Robotics", "categories": ["cs.RO"], "comment": null, "summary": "The integration of high-level assistance algorithms in surgical robotics\ntraining curricula may be beneficial in establishing a more comprehensive and\nrobust skillset for aspiring surgeons, improving their clinical performance as\na consequence. This work presents the development and validation of a\nhaptic-enhanced Virtual Reality simulator for surgical robotics training,\nfeaturing 8 surgical tasks that the trainee can interact with thanks to the\nembedded physics engine. This virtual simulated environment is augmented by the\nintroduction of high-level haptic interfaces for robotic assistance that aim at\nre-directing the motion of the trainee's hands and wrists toward targets or\naway from obstacles, and providing a quantitative performance score after the\nexecution of each training exercise.An experimental study shows that the\nintroduction of enhanced robotic assistance into a surgical robotics training\ncurriculum improves performance during the training process and, crucially,\npromotes the transfer of the acquired skills to an unassisted surgical\nscenario, like the clinical one.", "AI": {"tldr": "The study develops a haptic-based VR simulator for surgical robotics training, demonstrating its effectiveness in improving performance and skill transfer.", "motivation": "To improve the clinical performance of aspiring surgeons by creating a comprehensive and robust training approach through advancements in surgical robotics training.", "method": "A haptic-enhanced VR simulator was developed with 8 surgical tasks integrated with a physics engine. High-level haptic interfaces assist in guiding hand/wrist motions and provide performance scores.", "result": "The use of this advanced simulator in training showed improved performance in practice, with increased skill transfer to unassisted, real-world surgical scenarios.", "conclusion": "Integrating haptic-enhanced robotic assistance in surgical training fosters better skill acquisition and transition to clinical practice."}}
{"id": "2507.07495", "pdf": "https://arxiv.org/pdf/2507.07495", "abs": "https://arxiv.org/abs/2507.07495", "authors": ["Mihir Parmar", "Palash Goyal", "Xin Liu", "Yiwen Song", "Mingyang Ling", "Chitta Baral", "Hamid Palangi", "Tomas Pfister"], "title": "PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": "15 Pages", "summary": "Recently, decomposing complex problems into simple subtasks--a crucial part\nof human-like natural planning--to solve the given problem has significantly\nboosted the performance of large language models (LLMs). However, leveraging\nsuch planning structures during post-training to boost the performance of\nsmaller open-source LLMs remains underexplored. Motivated by this, we introduce\nPLAN-TUNING, a unified post-training framework that (i) distills synthetic task\ndecompositions (termed \"planning trajectories\") from large-scale LLMs and (ii)\nfine-tunes smaller models via supervised and reinforcement-learning objectives\ndesigned to mimic these planning processes to improve complex reasoning. On\nGSM8k and the MATH benchmarks, plan-tuned models outperform strong baselines by\nan average $\\sim7\\%$. Furthermore, plan-tuned models show better generalization\ncapabilities on out-of-domain datasets, with average $\\sim10\\%$ and $\\sim12\\%$\nperformance improvements on OlympiadBench and AIME 2024, respectively. Our\ndetailed analysis demonstrates how planning trajectories improves complex\nreasoning capabilities, showing that PLAN-TUNING is an effective strategy for\nimproving task-specific performance of smaller LLMs.", "AI": {"tldr": "The paper introduces PLAN-TUNING, a method to improve smaller language models' reasoning skills via planning strategies distilled from larger models.", "motivation": "To enhance smaller open-source LLMs' problem-solving and reasoning abilities using post-training techniques inspired by human-like planning.", "method": "PLAN-TUNING involves extracting synthetic 'planning trajectories' from large LLMs and fine-tuning smaller models using supervised and reinforcement learning objectives.", "result": "Plan-tuned models achieve approximately 7% improvement on GSM8k and MATH benchmarks, with even better generalization on out-of-domain datasets (10% on OlympiadBench, 12% on AIME 2024).", "conclusion": "PLAN-TUNING effectively improves smaller LLMs' reasoning performance by leveraging planning strategies, highlighting its potential for task-specific advancements."}}
{"id": "2507.07969", "pdf": "https://arxiv.org/pdf/2507.07969", "abs": "https://arxiv.org/abs/2507.07969", "authors": ["Qiyang Li", "Zhiyuan Zhou", "Sergey Levine"], "title": "Reinforcement Learning with Action Chunking", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": "25 pages, 15 figures", "summary": "We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.", "AI": {"tldr": "The paper introduces Q-chunking, an approach to improve reinforcement learning (RL) for long-horizon tasks by adopting action chunking to enable efficient exploration and learning.", "motivation": "Challenges like effective exploration and sample-efficient learning in offline-to-online RL make it necessary to explore how offline datasets can guide policies in sparse-reward environments.", "method": "Q-chunking incorporates action chunking into TD-based RL algorithms, allowing the agent to operate in a 'chunked' action space and apply $n$-step TD learning for stability and efficiency.", "result": "The method improves performance and efficiency, outperforming previous offline-to-online RL methods in long-horizon manipulation tasks with sparse rewards.", "conclusion": "Q-chunking successfully leverages offline datasets for better exploration and learning, marking it as a promising approach for RL in challenging settings."}}
{"id": "2507.07216", "pdf": "https://arxiv.org/pdf/2507.07216", "abs": "https://arxiv.org/abs/2507.07216", "authors": ["Yunyi Li", "Maria De-Arteaga", "Maytal Saar-Tsechansky"], "title": "Bias-Aware Mislabeling Detection via Decoupled Confident Learning", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.HC"], "comment": null, "summary": "Reliable data is a cornerstone of modern organizational systems. A notable\ndata integrity challenge stems from label bias, which refers to systematic\nerrors in a label, a covariate that is central to a quantitative analysis, such\nthat its quality differs across social groups. This type of bias has been\nconceptually and empirically explored and is widely recognized as a pressing\nissue across critical domains. However, effective methodologies for addressing\nit remain scarce. In this work, we propose Decoupled Confident Learning\n(DeCoLe), a principled machine learning based framework specifically designed\nto detect mislabeled instances in datasets affected by label bias, enabling\nbias aware mislabelling detection and facilitating data quality improvement. We\ntheoretically justify the effectiveness of DeCoLe and evaluate its performance\nin the impactful context of hate speech detection, a domain where label bias is\na well documented challenge. Empirical results demonstrate that DeCoLe excels\nat bias aware mislabeling detection, consistently outperforming alternative\napproaches for label error detection. Our work identifies and addresses the\nchallenge of bias aware mislabeling detection and offers guidance on how DeCoLe\ncan be integrated into organizational data management practices as a powerful\ntool to enhance data reliability.", "AI": {"tldr": "This paper introduces Decoupled Confident Learning (DeCoLe), a framework to detect mislabeled data, particularly addressing label bias in datasets.", "motivation": "Label bias, creating systematic errors in data labeling across social groups, undermines data quality and impacts critical domains like hate speech detection.", "method": "The proposed method, DeCoLe, leverages a machine learning framework to detect mislabeled instances in data impacted by label bias, with theoretical justification and empirical validation.", "result": "DeCoLe consistently outperforms other approaches in bias-aware mislabeling detection, with strong results in hate speech detection datasets.", "conclusion": "DeCoLe provides an effective and integrable solution for detecting and addressing label bias, enhancing data reliability in organizational practices."}}
{"id": "2507.07297", "pdf": "https://arxiv.org/pdf/2507.07297", "abs": "https://arxiv.org/abs/2507.07297", "authors": ["Chengfei Wu", "Ronald Seoh", "Bingxuan Li", "Liqiang Zhang", "Fengrong Han", "Dan Goldwasser"], "title": "MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in large vision-language models have led to impressive\nperformance in visual question answering and multimodal reasoning. However, it\nremains unclear whether these models genuinely perform grounded visual\nreasoning or rely on superficial patterns and dataset biases. In this work, we\nintroduce MagiC, a comprehensive benchmark designed to evaluate grounded\nmultimodal cognition, assessing not only answer accuracy but also the quality\nof step-by-step reasoning and its alignment with relevant visual evidence. Our\nbenchmark includes approximately 5,500 weakly supervised QA examples generated\nfrom strong model outputs and 900 human-curated examples with fine-grained\nannotations, including answers, rationales, and bounding box groundings. We\nevaluate 15 vision-language models ranging from 7B to 70B parameters across\nfour dimensions: final answer correctness, reasoning validity, grounding\nfidelity, and self-correction ability. MagiC further includes diagnostic\nsettings to probe model robustness under adversarial visual cues and assess\ntheir capacity for introspective error correction. We introduce new metrics\nsuch as MagiScore and StepSense, and provide comprehensive analyses that reveal\nkey limitations and opportunities in current approaches to grounded visual\nreasoning.", "AI": {"tldr": "The paper presents MagiC, a benchmark to test vision-language models' grounded reasoning, focusing on answer accuracy, reasoning quality, and alignment with visual evidence using unique metrics and evaluations.", "motivation": "Addressing the uncertainty about whether vision-language models perform genuine reasoning or rely on biases, by proposing a benchmark specifically evaluating grounded multimodal cognition.", "method": "The benchmark includes 5,500 weakly supervised and 900 human-curated QA examples with annotations (e.g., answers, rationales, bounding box groundings), evaluates 15 models across dimensions, and introduces new metrics like MagiScore and StepSense.", "result": "MagiC evaluates models for answer correctness, reasoning validity, grounding fidelity, and self-correction, highlighting their robustness against adversarial cues and introspective abilities.", "conclusion": "The approach identifies key limitations and opportunities for improving grounded reasoning in vision-language models, contributing new benchmarks and diagnostics to the field."}}
{"id": "2507.07599", "pdf": "https://arxiv.org/pdf/2507.07599", "abs": "https://arxiv.org/abs/2507.07599", "authors": ["Sedigh Khademi", "Jim Black", "Christopher Palmer", "Muhammad Javed", "Hazel Clothier", "Jim Buttery", "Gerardo Luis Dimaguila"], "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "5 pages", "summary": "This study evaluates fine-tuned Llama 3.2 models for extracting\nvaccine-related information from emergency department triage notes to support\nnear real-time vaccine safety surveillance. Prompt engineering was used to\ninitially create a labeled dataset, which was then confirmed by human\nannotators. The performance of prompt-engineered models, fine-tuned models, and\na rule-based approach was compared. The fine-tuned Llama 3 billion parameter\nmodel outperformed other models in its accuracy of extracting vaccine names.\nModel quantization enabled efficient deployment in resource-constrained\nenvironments. Findings demonstrate the potential of large language models in\nautomating data extraction from emergency department notes, supporting\nefficient vaccine safety surveillance and early detection of emerging adverse\nevents following immunization issues.", "AI": {"tldr": "The study evaluates fine-tuned Llama 3.2 models for extracting vaccine-related data from emergency department notes, demonstrating their superiority in accuracy and feasibility for real-time vaccine safety surveillance.", "motivation": "Developing efficient tools for real-time vaccine safety surveillance from clinical narratives, addressing challenges in automating data extraction.", "method": "Fine-tuned Llama 3.2 models were compared with prompt-engineered models and a rule-based approach, leveraging prompt engineering and human annotation for dataset creation.", "result": "The fine-tuned Llama 3 billion parameter model outperformed other models in accuracy of vaccine name extraction, with model quantization enabling efficient resource utilization.", "conclusion": "Large language models show promise in enhancing vaccine safety surveillance by automating clinical data extraction efficiently, supporting early detection of adverse events."}}
{"id": "2507.07724", "pdf": "https://arxiv.org/pdf/2507.07724", "abs": "https://arxiv.org/abs/2507.07724", "authors": ["Thiemen Siemensma", "Niels de Boer", "Bahar Haghighat"], "title": "Distributed Surface Inspection via Operational Modal Analysis by a Swarm of Miniaturized Vibration-Sensing Robots", "categories": ["cs.RO"], "comment": null, "summary": "Robot swarms offer the potential to serve a variety of distributed sensing\napplications. An interesting real-world application that stands to benefit\nsignificantly from deployment of swarms is structural monitoring, where\ntraditional sensor networks face challenges in structural coverage due to their\nstatic nature. This paper investigates the deployment of a swarm of\nminiaturized vibration sensing robots to inspect and localize structural\ndamages on a surface section within a high-fidelity simulation environment. In\nparticular, we consider a 1 m x 1 m x 3 mm steel surface section and utilize\nfinite element analysis using Abaqus to obtain realistic structural vibration\ndata. The resulting vibration data is imported into the physics-based robotic\nsimulator Webots, where we simulate the dynamics of our surface inspecting\nrobot swarm. We employ (i) Gaussian process estimators to guide the robots'\nexploration as they collect vibration samples across the surface and (ii)\noperational modal analysis to detect structural damages by estimating and\ncomparing existing and intact structural vibration patterns. We analyze the\ninfluence of exploration radii on estimation uncertainty and assess the\neffectiveness of our method across 10 randomized scenarios, where the number,\nlocations, surface area, and depth of structural damages vary. Our simulation\nstudies validate the efficacy of our miniaturized robot swarm for\nvibration-based structural inspection.", "AI": {"tldr": "This paper proposes using a swarm of mini vibration-sensing robots for structural inspection and damage localization, validated through simulations.", "motivation": "Traditional static sensor networks are limited in structural coverage for applications like structural monitoring. Deploying a swarm of mobile, vibration-sensing robots could overcome these limitations.", "method": "The study uses finite element analysis to simulate realistic vibration data of a steel surface and integrates it into a robotic simulator. It deploys Gaussian process estimators for guiding exploration and operational modal analysis for damage detection.", "result": "Simulation studies across 10 randomized scenarios demonstrate that the swarm is effective in gathering vibration samples and detecting structural damage across varied conditions.", "conclusion": "The approach validates the potential of miniaturized robot swarms for cost-effective and accurate vibration-based structural inspections."}}
{"id": "2507.07498", "pdf": "https://arxiv.org/pdf/2507.07498", "abs": "https://arxiv.org/abs/2507.07498", "authors": ["Keqin Bao", "Nuo Chen", "Xiaoyuan Li", "Binyuan Hui", "Bowen Yu", "Fuli Feng", "Junyang Lin", "Xiangnan He", "Dayiheng Liu"], "title": "Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Enhancing reasoning capabilities remains a central focus in the LLM reasearch\ncommunity. A promising direction involves requiring models to simulate code\nexecution step-by-step to derive outputs for given inputs. However, as code is\noften designed for large-scale systems, direct application leads to\nover-reliance on complex data structures and algorithms, even for simple cases,\nresulting in overfitting to algorithmic patterns rather than core reasoning\nstructures. To address this, we propose TeaR, which aims at teaching LLMs to\nreason better. TeaR leverages careful data curation and reinforcement learning\nto guide models in discovering optimal reasoning paths through code-related\ntasks, thereby improving general reasoning abilities. We conduct extensive\nexperiments using two base models and three long-CoT distillation models, with\nmodel sizes ranging from 1.5 billion to 32 billion parameters, and across 17\nbenchmarks spanning Math, Knowledge, Code, and Logical Reasoning. The results\nconsistently show significant performance improvements. Notably, TeaR achieves\na 35.9% improvement on Qwen2.5-7B and 5.9% on R1-Distilled-7B.", "AI": {"tldr": "TeaR is a system to enhance reasoning abilities of Language Models (LLMs) through optimized reasoning paths in code-related tasks, yielding substantial performance gains.", "motivation": "Current LLMs struggle with overfitting to algorithmic patterns in code simulation tasks, hindering core reasoning abilities.", "method": "TeaR utilizes meticulous data curation and reinforcement learning to teach optimized reasoning paths in code-related challenges.", "result": "Experiments using diverse models and benchmarks indicate up to 35.9% improvement on reasoning tasks for selected models.", "conclusion": "TeaR successfully refines reasoning abilities in LLMs by addressing inefficiencies in code simulation methodologies and leveraging improved reasoning pathways."}}
{"id": "2507.07981", "pdf": "https://arxiv.org/pdf/2507.07981", "abs": "https://arxiv.org/abs/2507.07981", "authors": ["Noam Razin", "Yong Lin", "Jiarui Yao", "Sanjeev Arora"], "title": "Why is Your Language Model a Poor Implicit Reward Model?", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Reward models are key to language model post-training and inference\npipelines. Conveniently, recent work showed that every language model defines\nan implicit reward model (IM-RM), without requiring any architectural changes.\nHowever, such IM-RMs tend to generalize worse, especially out-of-distribution,\ncompared to explicit reward models (EX-RMs) that apply a dedicated linear head\nover the hidden representations of a language model. The existence of a\ngeneralization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They\ncan be trained using the same data, loss function, and language model, and\ndiffer only in how the reward is computed. Towards a fundamental understanding\nof the implicit biases underlying different reward model types, we investigate\nthe root cause of this gap. Our main finding, backed by theory and experiments,\nis that IM-RMs rely more heavily on superficial token-level cues. Consequently,\nthey often generalize worse than EX-RMs under token-level distribution shifts,\nas well as in-distribution. Furthermore, we provide evidence against\nalternative hypotheses for the generalization gap. Most notably, we challenge\nthe intuitive claim that IM-RMs struggle in tasks where generation is harder\nthan verification because they can operate both as a verifier and a generator.\nTaken together, our results highlight that seemingly minor design choices can\nsubstantially impact the generalization behavior of reward models.", "AI": {"tldr": "This paper investigates the generalization gap between implicit reward models (IM-RMs) and explicit reward models (EX-RMs) in language models, finding that IM-RMs overly rely on superficial token-level cues.", "motivation": "The motivation is to understand why implicit reward models (IM-RMs) generalize worse out-of-distribution compared to explicit reward models (EX-RMs), despite their architectural similarity.", "method": "The authors employ theoretical analysis and experiments, comparing the behavior and generalization performance of IM-RMs and EX-RMs, while testing alternative hypotheses for the performance gap.", "result": "The study finds that IM-RMs rely more on superficial token-level cues, leading to poorer generalization under token-level distribution shifts, as well as in-distribution. Alternative explanations, such as task difficulty differences, are ruled out.", "conclusion": "Small design choices, such as how reward is computed, significantly influence the generalization behavior of reward models. IM-RMs are less robust due to their reliance on token-level cues."}}
{"id": "2507.07222", "pdf": "https://arxiv.org/pdf/2507.07222", "abs": "https://arxiv.org/abs/2507.07222", "authors": ["Minchan Jeong", "J. Jon Ryu", "Se-Young Yun", "Gregory W. Wornell"], "title": "Efficient Parametric SVD of Koopman Operator for Stochastic Dynamical Systems", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA"], "comment": "28 pages, 4 figures. Under review for NeurIPS 2025. The first two\n  authors contributed equally", "summary": "The Koopman operator provides a principled framework for analyzing nonlinear\ndynamical systems through linear operator theory. Recent advances in dynamic\nmode decomposition (DMD) have shown that trajectory data can be used to\nidentify dominant modes of a system in a data-driven manner. Building on this\nidea, deep learning methods such as VAMPnet and DPNet have been proposed to\nlearn the leading singular subspaces of the Koopman operator. However, these\nmethods require backpropagation through potentially numerically unstable\noperations on empirical second moment matrices, such as singular value\ndecomposition and matrix inversion, during objective computation, which can\nintroduce biased gradient estimates and hinder scalability to large systems. In\nthis work, we propose a scalable and conceptually simple method for learning\nthe top-k singular functions of the Koopman operator for stochastic dynamical\nsystems based on the idea of low-rank approximation. Our approach eliminates\nthe need for unstable linear algebraic operations and integrates easily into\nmodern deep learning pipelines. Empirical results demonstrate that the learned\nsingular subspaces are both reliable and effective for downstream tasks such as\neigen-analysis and multi-step prediction.", "AI": {"tldr": "This paper develops a scalable method for learning the leading singular functions of the Koopman operator, avoiding unstable linear operations and improving downstream tasks.", "motivation": "Existing deep learning methods for learning Koopman operator singular subspaces suffer from computational instability and scalability issues, particularly due to operations like SVD and matrix inversion.", "method": "The authors introduce a deep learning-compatible, low-rank approximation-based method to learn the top-k singular functions of the Koopman operator, avoiding numerically unstable operations.", "result": "The proposed method reliably and effectively learns singular subspaces, excelling in tasks such as eigen-analysis and multi-step prediction.", "conclusion": "The work presents a robust approach for Koopman operator analysis that aligns with modern deep learning practices while addressing scalability and stability challenges."}}
{"id": "2507.07317", "pdf": "https://arxiv.org/pdf/2507.07317", "abs": "https://arxiv.org/abs/2507.07317", "authors": ["Sherry X. Chen", "Yi Wei", "Luowei Zhou", "Suren Kumar"], "title": "ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation", "categories": ["cs.CV"], "comment": "International Conference on Computer Vision (ICCV) 2025", "summary": "Recent advances in instruction-guided image editing underscore the need for\neffective automated evaluation. While Vision-Language Models (VLMs) have been\nexplored as judges, open-source models struggle with alignment, and proprietary\nmodels lack transparency and cost efficiency. Additionally, no public training\ndatasets exist to fine-tune open-source VLMs, only small benchmarks with\ndiverse evaluation schemes. To address this, we introduce ADIEE, an automated\ndataset creation approach which is then used to train a scoring model for\ninstruction-guided image editing evaluation. We generate a large-scale dataset\nwith over 100K samples and use it to fine-tune a LLaVA-NeXT-8B model modified\nto decode a numeric score from a custom token. The resulting scorer outperforms\nall open-source VLMs and Gemini-Pro 1.5 across all benchmarks, achieving a\n0.0696 (+17.24%) gain in score correlation with human ratings on AURORA-Bench,\nand improving pair-wise comparison accuracy by 4.03% (+7.21%) on GenAI-Bench\nand 4.75% (+9.35%) on AURORA-Bench, respectively, compared to the\nstate-of-the-art. The scorer can act as a reward model, enabling automated best\nedit selection and model fine-tuning. Notably, the proposed scorer can boost\nMagicBrush model's average evaluation score on ImagenHub from 5.90 to 6.43\n(+8.98%).", "AI": {"tldr": "The paper introduces ADIEE for creating a large dataset for training a Vision-Language Model (VLM) scorer for instruction-guided image editing, achieving superior performance compared to existing open-source and proprietary models.", "motivation": "Current Vision-Language Models (VLMs) for evaluating instruction-guided image editing face alignment challenges, lack of transparency, high costs, and absence of substantial public training datasets.", "method": "ADIEE (Automated Dataset for Image Editing Evaluation) is proposed to systematically create a large training dataset of over 100K samples. A modified LLaVA-NeXT-8B model with numeric scoring capabilities is fine-tuned using this dataset.", "result": "The trained scorer surpasses all open-source and proprietary VLMs, showing a 17.24% improvement in correlation with human ratings and better pair-wise comparison accuracy on benchmarks like AURORA-Bench and GenAI-Bench.", "conclusion": "The ADIEE-based scorer emerges as a leading automated evaluation tool for instruction-guided image editing, enabling more efficient model fine-tuning and application in enhancing other image editing models."}}
{"id": "2507.07619", "pdf": "https://arxiv.org/pdf/2507.07619", "abs": "https://arxiv.org/abs/2507.07619", "authors": ["Marco Sangalli", "Thomas Krak", "Cassio de Campos"], "title": "Towards conservative inference in credal networks using belief functions: the case of credal chains", "categories": ["cs.AI", "math.PR"], "comment": null, "summary": "This paper explores belief inference in credal networks using Dempster-Shafer\ntheory. By building on previous work, we propose a novel framework for\npropagating uncertainty through a subclass of credal networks, namely chains.\nThe proposed approach efficiently yields conservative intervals through belief\nand plausibility functions, combining computational speed with robust\nuncertainty representation. Key contributions include formalizing belief-based\ninference methods and comparing belief-based inference against classical\nsensitivity analysis. Numerical results highlight the advantages and\nlimitations of applying belief inference within this framework, providing\ninsights into its practical utility for chains and for credal networks in\ngeneral.", "AI": {"tldr": "The paper proposes a framework for efficiently propagating uncertainty in credal networks, using Dempster-Shafer theory to compute belief and plausibility functions in chains.", "motivation": "The motivation is to improve uncertainty representation and computational efficiency when performing belief inference in a specialized class of credal networks using Dempster-Shafer theory.", "method": "The authors developed a framework based on the propagation of belief and plausibility functions to compute conservative intervals within credal networks, specifically focusing on chain structures.", "result": "The framework demonstrated computational efficiency and robust uncertainty representation, with a comparison to classical sensitivity analysis showing its advantages and limitations.", "conclusion": "The proposed belief inference framework is a practical, efficient method for uncertainty representation in credal networks, particularly chains."}}
{"id": "2507.07745", "pdf": "https://arxiv.org/pdf/2507.07745", "abs": "https://arxiv.org/abs/2507.07745", "authors": ["Eleni Konstantinidou", "Nikolaos Kounalakis", "Nikolaos Efstathopoulos", "Dimitrios Papageorgiou"], "title": "On the capabilities of LLMs for classifying and segmenting time series of fruit picking motions into primitive actions", "categories": ["cs.RO"], "comment": "This paper is a Late Breaking Results report and it will be presented\n  through a poster at the 34th IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN), 2025 at Eindhoven, the Netherlands", "summary": "Despite their recent introduction to human society, Large Language Models\n(LLMs) have significantly affected the way we tackle mental challenges in our\neveryday lives. From optimizing our linguistic communication to assisting us in\nmaking important decisions, LLMs, such as ChatGPT, are notably reducing our\ncognitive load by gradually taking on an increasing share of our mental\nactivities. In the context of Learning by Demonstration (LbD), classifying and\nsegmenting complex motions into primitive actions, such as pushing, pulling,\ntwisting etc, is considered to be a key-step towards encoding a task. In this\nwork, we investigate the capabilities of LLMs to undertake this task,\nconsidering a finite set of predefined primitive actions found in fruit picking\noperations. By utilizing LLMs instead of simple supervised learning or analytic\nmethods, we aim at making the method easily applicable and deployable in a\nreal-life scenario. Three different fine-tuning approaches are investigated,\ncompared on datasets captured kinesthetically, using a UR10e robot, during a\nfruit-picking scenario.", "AI": {"tldr": "This paper studies how Large Language Models (LLMs) can classify and segment complex motions into primitive actions, specifically in fruit-picking operations, using fine-tuned models.", "motivation": "To explore the potential of LLMs in simplifying Learning by Demonstration (LbD) by classifying complex motions for real-life applications, like fruit picking.", "method": "The authors use three fine-tuning approaches applied to datasets collected from a UR10e robot during a fruit-picking scenario to evaluate LLMs' capabilities.", "result": "The study compares the efficiency and applicability of different fine-tuned LLM approaches in segmenting and classifying primitive actions for fruit-picking.", "conclusion": "LLMs show potential for practical deployment in tasks requiring motion classification and segmentation, making them advantageous for real-world uses in areas like robotics."}}
{"id": "2507.07499", "pdf": "https://arxiv.org/pdf/2507.07499", "abs": "https://arxiv.org/abs/2507.07499", "authors": ["Hein Htet", "Amgad Ahmed Ali Ibrahim", "Yutaka Sasaki", "Ryoji Asahi"], "title": "Extracting ORR Catalyst Information for Fuel Cell from Scientific Literature", "categories": ["cs.CL", "physics.data-an"], "comment": "28 pages, 12 figures, 6 tables", "summary": "The oxygen reduction reaction (ORR) catalyst plays a critical role in\nenhancing fuel cell efficiency, making it a key focus in material science\nresearch. However, extracting structured information about ORR catalysts from\nvast scientific literature remains a significant challenge due to the\ncomplexity and diversity of textual data. In this study, we propose a named\nentity recognition (NER) and relation extraction (RE) approach using DyGIE++\nwith multiple pre-trained BERT variants, including MatSciBERT and PubMedBERT,\nto extract ORR catalyst-related information from the scientific literature,\nwhich is compiled into a fuel cell corpus for materials informatics\n(FC-CoMIcs). A comprehensive dataset was constructed manually by identifying 12\ncritical entities and two relationship types between pairs of the entities. Our\nmethodology involves data annotation, integration, and fine-tuning of\ntransformer-based models to enhance information extraction accuracy. We assess\nthe impact of different BERT variants on extraction performance and investigate\nthe effects of annotation consistency. Experimental evaluations demonstrate\nthat the fine-tuned PubMedBERT model achieves the highest NER F1-score of\n82.19% and the MatSciBERT model attains the best RE F1-score of 66.10%.\nFurthermore, the comparison with human annotators highlights the reliability of\nfine-tuned models for ORR catalyst extraction, demonstrating their potential\nfor scalable and automated literature analysis. The results indicate that\ndomain-specific BERT models outperform general scientific models like BlueBERT\nfor ORR catalyst extraction.", "AI": {"tldr": "This paper develops a method combining DyGIE++ and multiple pre-trained BERT models to extract structured information on ORR catalysts from scientific literature.", "motivation": "The authors aim to address the challenge of extracting structured information about ORR catalysts due to the complexity and diversity in scientific literature.", "method": "They propose using named entity recognition (NER) and relation extraction (RE) models, specifically DyGIE++ fine-tuned with domain-specific BERT variants, on a manually annotated dataset for enhanced information extraction accuracy.", "result": "The PubMedBERT model achieved the highest NER F1-score (82.19%) and the MatSciBERT attained the best RE F1-score (66.10%), demonstrating a high degree of reliability.", "conclusion": "Domain-specific BERT models are more effective than general ones for ORR catalyst data extraction, showing potential for scalable automated literature analysis."}}
{"id": "2507.07236", "pdf": "https://arxiv.org/pdf/2507.07236", "abs": "https://arxiv.org/abs/2507.07236", "authors": ["Maya Kruse", "Majid Afshar", "Saksham Khatwani", "Anoop Mayampurath", "Guanhua Chen", "Yanjun Gao"], "title": "An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Under review", "summary": "Large language models (LLMs) often behave inconsistently across inputs,\nindicating uncertainty and motivating the need for its quantification in\nhigh-stakes settings. Prior work on calibration and uncertainty quantification\noften focuses on individual models, overlooking the potential of model\ndiversity. We hypothesize that LLMs make complementary predictions due to\ndifferences in training and the Zipfian nature of language, and that\naggregating their outputs leads to more reliable uncertainty estimates. To\nleverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a\nsimple information-theoretic method that uses Jensen-Shannon Divergence to\nidentify and aggregate well-calibrated subsets of LLMs. Experiments on binary\nprediction tasks demonstrate improved calibration and predictive performance\ncompared to single-model and naive ensemble baselines.", "AI": {"tldr": "This paper proposes MUSE, a method using subset ensembles of diverse LLMs for better calibration and uncertainty quantification.", "motivation": "Uncertainty quantification is critical for high-stakes applications, and existing methods largely focus on single models, missing potential benefits of combining diverse models.", "method": "MUSE uses Jensen-Shannon Divergence to select and aggregate subsets of complementary LLMs, improving uncertainty estimates.", "result": "Experiments reveal better calibration and predictive performance compared to individual models or simple ensembles in binary prediction tasks.", "conclusion": "Aggregating outputs from subsets of diverse LLMs enhances reliable uncertainty estimation, demonstrating the advantage of model diversity."}}
{"id": "2507.07333", "pdf": "https://arxiv.org/pdf/2507.07333", "abs": "https://arxiv.org/abs/2507.07333", "authors": ["Hui Pang", "Sunil Hadap", "Violetta Shevchenko", "Rahul Suresh", "Amin Banitalebi-Dehkordi"], "title": "Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory", "categories": ["cs.CV", "I.4.9"], "comment": "Presented at the workshop Three questions about virtual try-on at\n  CVPR 2025", "summary": "Augmented reality is revolutionizing beauty industry with virtual try-on\n(VTO) applications, which empowers users to try a wide variety of products\nusing their phones without the hassle of physically putting on real products. A\ncritical technical challenge in foundation VTO applications is the accurate\nsynthesis of foundation-skin tone color blending while maintaining the\nscalability of the method across diverse product ranges. In this work, we\npropose a novel method to approximate well-established Kubelka-Munk (KM) theory\nfor faster image synthesis while preserving foundation-skin tone color blending\nrealism. Additionally, we build a scalable end-to-end framework for realistic\nfoundation makeup VTO solely depending on the product information available on\ne-commerce sites. We validate our method using real-world makeup images,\ndemonstrating that our framework outperforms other techniques.", "AI": {"tldr": "The paper presents a novel method to improve virtual try-on (VTO) applications for the beauty industry by facilitating realistic blending of foundation and skin tones through a fast and scalable system.", "motivation": "Addressing the challenge of realistic foundation-skin tone color blending in VTO applications while ensuring scalability across diverse product ranges.", "method": "A method approximating the Kubelka-Munk (KM) theory for efficient image synthesis and a framework that relies on e-commerce product information for scalability.", "result": "The proposed framework achieves realistic blending of foundation and skin tones, validated by real-world makeup images, and outperforms existing techniques.", "conclusion": "The proposed method enhances VTO applications with realistic and scalable foundation blending capabilities, advancing the beauty industry's digital innovation."}}
{"id": "2507.07644", "pdf": "https://arxiv.org/pdf/2507.07644", "abs": "https://arxiv.org/abs/2507.07644", "authors": ["Fedor Rodionov", "Abdelrahman Eldesokey", "Michael Birsak", "John Femiani", "Bernard Ghanem", "Peter Wonka"], "title": "PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations", "categories": ["cs.AI"], "comment": "25 pages, 18 figures. Diagnostic benchmark for spatial reasoning in\n  LLMs. Project page: https://OldDelorean.github.io/PlanQA/", "summary": "We introduce PlanQA, a diagnostic benchmark for evaluating geometric and\nspatial reasoning in large-language models (LLMs). PlanQA is grounded in\nstructured representations of indoor scenes, such as kitchens, living rooms,\nand bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The\nbenchmark includes diverse question types that test not only metric and\ntopological reasoning (e.g., distance, visibility, shortest paths) but also\ninterior design constraints such as affordance, clearance, balance, and\nusability. Our results across a variety of frontier open-source and commercial\nLLMs show that while models may succeed in shallow queries, they often fail to\nsimulate physical constraints, preserve spatial coherence, or generalize under\nlayout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they\ndo not consistently reason about real-world layouts. We hope that this\nbenchmark inspires new work on language models that can accurately infer and\nmanipulate spatial and geometric properties in practical settings.", "AI": {"tldr": "The paper introduces PlanQA, a benchmark for evaluating large-language models' geometric and spatial reasoning abilities using structured indoor scene representations. Results show LLMs struggle with physical constraints and layout coherence.", "motivation": "The authors aim to address the limitations of large-language models (LLMs) in geometric and spatial reasoning, particularly for real-world indoor scene layouts.", "method": "The benchmark evaluates LLMs using structured representations (e.g., JSON, XML) of indoor spaces and diverse spatial questions, covering metric, topological reasoning, and interior design constraints.", "result": "Findings reveal that while LLMs can handle basic queries, they are deficient in simulating physical constraints, maintaining spatial coherence, and adapting to layout changes.", "conclusion": "PlanQA highlights weaknesses in current LLMs' spatial reasoning abilities and calls for further development of models capable of handling real-world layout challenges."}}
{"id": "2507.07752", "pdf": "https://arxiv.org/pdf/2507.07752", "abs": "https://arxiv.org/abs/2507.07752", "authors": ["Thanh Nguyen Canh", "Bao Nguyen Quoc", "Haolan Zhang", "Bupesh Rethinam Veeraiah", "Xiem HoangVan", "Nak Young Chong"], "title": "IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments", "categories": ["cs.RO"], "comment": "In the European Conference on Mobile Robots 2025", "summary": "Robust Visual SLAM (vSLAM) is essential for autonomous systems operating in\nreal-world environments, where challenges such as dynamic objects, low texture,\nand critically, varying illumination conditions often degrade performance.\nExisting feature-based SLAM systems rely on fixed front-end parameters, making\nthem vulnerable to sudden lighting changes and unstable feature tracking. To\naddress these challenges, we propose ``IRAF-SLAM'', an Illumination-Robust and\nAdaptive Feature-Culling front-end designed to enhance vSLAM resilience in\ncomplex and challenging environments. Our approach introduces: (1) an image\nenhancement scheme to preprocess and adjust image quality under varying\nlighting conditions; (2) an adaptive feature extraction mechanism that\ndynamically adjusts detection sensitivity based on image entropy, pixel\nintensity, and gradient analysis; and (3) a feature culling strategy that\nfilters out unreliable feature points using density distribution analysis and a\nlighting impact factor. Comprehensive evaluations on the TUM-VI and European\nRobotics Challenge (EuRoC) datasets demonstrate that IRAF-SLAM significantly\nreduces tracking failures and achieves superior trajectory accuracy compared to\nstate-of-the-art vSLAM methods under adverse illumination conditions. These\nresults highlight the effectiveness of adaptive front-end strategies in\nimproving vSLAM robustness without incurring significant computational\noverhead. The implementation of IRAF-SLAM is publicly available at\nhttps://thanhnguyencanh. github.io/IRAF-SLAM/.", "AI": {"tldr": "IRAF-SLAM is a vSLAM system that enhances performance under challenging environmental conditions using adaptive front-end strategies.", "motivation": "vSLAM systems often fail in real-world scenarios with dynamic objects, low texture, and illumination changes. The authors aim to address the vulnerability of existing vSLAM methods to these challenges.", "method": "The paper introduces IRAF-SLAM, which combines image enhancement, adaptive feature extraction, and adaptive feature culling to optimize tracking and mapping under diverse and changing lighting conditions.", "result": "Experimental evaluations show that IRAF-SLAM significantly reduces tracking failures and achieves better trajectory accuracy than existing approaches across TUM-VI and EuRoC datasets.", "conclusion": "IRAF-SLAM improves vSLAM robustness to illumination changes without adding significant computational load, showing the value of its adaptive techniques for real-world scenarios."}}
{"id": "2507.07505", "pdf": "https://arxiv.org/pdf/2507.07505", "abs": "https://arxiv.org/abs/2507.07505", "authors": ["Varin Sikka", "Vishal Sikka"], "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages; to be submitted to AAAI-26 after reviews", "summary": "With widespread adoption of transformer-based language models in AI, there is\nsignificant interest in the limits of LLMs capabilities, specifically so-called\nhallucinations, occurrences in which LLMs provide spurious, factually incorrect\nor nonsensical information when prompted on certain subjects. Furthermore,\nthere is growing interest in agentic uses of LLMs - that is, using LLMs to\ncreate agents that act autonomously or semi-autonomously to carry out various\ntasks, including tasks with applications in the real world. This makes it\nimportant to understand the types of tasks LLMs can and cannot perform. We\nexplore this topic from the perspective of the computational complexity of LLM\ninference. We show that LLMs are incapable of carrying out computational and\nagentic tasks beyond a certain complexity, and further that LLMs are incapable\nof verifying the accuracy of tasks beyond a certain complexity. We present\nexamples of both, then discuss some consequences of this work.", "AI": {"tldr": "The paper investigates the limitations of transformer-based large language models (LLMs), particularly their inability to perform or verify computational and agentic tasks beyond a certain complexity.", "motivation": "To understand the limitations of LLMs in performing and verifying tasks, especially in the context of agentic uses and their susceptibility to hallucinations.", "method": "The authors analyze LLM capabilities through the lens of computational complexity, providing theoretical arguments and examples.", "result": "LLMs are proven to be incapable of executing or verifying tasks that surpass a certain level of complexity.", "conclusion": "The study highlights inherent limitations in LLMs, stressing the importance of recognizing their boundaries for real-world applications."}}
{"id": "2507.07237", "pdf": "https://arxiv.org/pdf/2507.07237", "abs": "https://arxiv.org/abs/2507.07237", "authors": ["Erfan Hamdi", "Emma Lejeune"], "title": "Towards Robust Surrogate Models: Benchmarking Machine Learning Approaches to Expediting Phase Field Simulations of Brittle Fracture", "categories": ["cs.LG", "physics.data-an", "74R10, 74B20, 74A40, 68T07", "J.2; I.6.3; I.6.5"], "comment": "29 pages, 13 figures", "summary": "Data driven approaches have the potential to make modeling complex, nonlinear\nphysical phenomena significantly more computationally tractable. For example,\ncomputational modeling of fracture is a core challenge where machine learning\ntechniques have the potential to provide a much needed speedup that would\nenable progress in areas such as mutli-scale modeling and uncertainty\nquantification. Currently, phase field modeling (PFM) of fracture is one such\napproach that offers a convenient variational formulation to model crack\nnucleation, branching and propagation. To date, machine learning techniques\nhave shown promise in approximating PFM simulations. However, most studies rely\non overly simple benchmarks that do not reflect the true complexity of the\nfracture processes where PFM excels as a method. To address this gap, we\nintroduce a challenging dataset based on PFM simulations designed to benchmark\nand advance ML methods for fracture modeling. This dataset includes three\nenergy decomposition methods, two boundary conditions, and 1,000 random initial\ncrack configurations for a total of 6,000 simulations. Each sample contains 100\ntime steps capturing the temporal evolution of the crack field. Alongside this\ndataset, we also implement and evaluate Physics Informed Neural Networks\n(PINN), Fourier Neural Operators (FNO) and UNet models as baselines, and\nexplore the impact of ensembling strategies on prediction accuracy. With this\ncombination of our dataset and baseline models drawn from the literature we aim\nto provide a standardized and challenging benchmark for evaluating machine\nlearning approaches to solid mechanics. Our results highlight both the promise\nand limitations of popular current models, and demonstrate the utility of this\ndataset as a testbed for advancing machine learning in fracture mechanics\nresearch.", "AI": {"tldr": "The paper introduces a challenging dataset based on Phase Field Modeling (PFM) simulations for fracture modeling to tackle complex benchmarks beyond simplistic cases. It evaluates baseline ML models like PINN, FNO, and UNet against the dataset, also analyzing the effect of ensembling strategies.", "motivation": "The authors aim to address the gap in fracture modeling benchmarks by introducing a more complex dataset suitable for advancing machine learning methods, which traditionally relied on overly simple cases that do not align with real-world fracture complexity. Modeling fracture efficiently is essential for multi-scale modeling and uncertainty quantification.", "method": "The authors develop a dataset based on PFM simulations incorporating three energy decomposition methods, two boundary conditions, and 1,000 random initial crack configurations, comprising 6,000 simulations. They apply baseline ML models like PINN, FNO, UNet, and ensemble approaches to this dataset to evaluate prediction performance.", "result": "The study demonstrates the strengths and shortcomings of popular machine learning models in approximating PFM, showing their potential as well as limitations. The dataset proves effective in serving as a challenging benchmark for ML modeling in fracture mechanics.", "conclusion": "The paper highlights the relevance of the dataset as a standardized tool for advancing ML techniques in fracture mechanics. It underscores how the dataset allows for more accurate evaluations of machine learning approaches, contributing to closing the gap between ML capabilities and complex fracture phenomena."}}
{"id": "2507.07340", "pdf": "https://arxiv.org/pdf/2507.07340", "abs": "https://arxiv.org/abs/2507.07340", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning", "categories": ["cs.CV", "I.2; I.4; I.5; I.7"], "comment": "7 pages", "summary": "Visual storytelling systems, particularly large vision-language models,\nstruggle to maintain character and object identity across frames,\n  often failing to recognize when entities in different images represent the\nsame individuals or objects,\n  leading to inconsistent references and referential hallucinations.\n  This occurs because models lack explicit training on when to establish entity\nconnections across frames.\n  We propose a contrastive reinforcement learning approach that trains models\nto discriminate between coherent image sequences\n  and stories from unrelated images.\n  We extend the Story Reasoning dataset with synthetic negative examples to\nteach appropriate entity connection behavior.\n  We employ Direct Preference Optimization with a dual-component reward\nfunction that promotes grounding and re-identification of entities\n  in real stories while penalizing incorrect entity connections in synthetic\ncontexts.\n  Using this contrastive framework, we fine-tune Qwen Storyteller (based on\nQwen2.5-VL 7B).\n  Evaluation shows improvements in grounding mAP from 0.27 to 0.31 (+14.8%), F1\nfrom 0.35 to 0.41 (+17.1%).\n  Pronoun grounding accuracy improved across all pronoun types except ``its'',\n  and cross-frame character and object persistence increased\n  across all frame counts, with entities appearing in 5 or more frames\nadvancing from 29.3% to 33.3% (+13.7%).\n  Well-structured stories, containing the chain-of-thought and grounded story,\nincreased from 79.1% to 97.5% (+23.3%).", "AI": {"tldr": "This paper addresses the issue of large vision-language models' inability to maintain consistent character and object identity in visual storytelling across frames, proposing a contrastive reinforcement learning method that significantly improves performance.", "motivation": "To resolve the issue of inconsistent references and referential hallucinations in visual storytelling systems, caused by a lack of explicit training on connecting entities across frames.", "method": "A contrastive reinforcement learning approach using synthetic negative examples to extend the Story Reasoning dataset, coupled with a dual-component reward function focusing on grounding and entity re-identification, was employed to fine-tune the Qwen Storyteller model.", "result": "The model achieved improvements in grounding mAP (+14.8%), F1 (+17.1%), pronoun grounding accuracy (except for 'its'), and increased cross-frame character/object persistence (+13.7%). The percentage of well-structured stories increased significantly (+23.3%).", "conclusion": "The proposed method effectively enhances the ability of visual storytelling models to maintain cross-frame consistency of entities, improving both referential accuracy and the overall coherence of generated stories."}}
{"id": "2507.07723", "pdf": "https://arxiv.org/pdf/2507.07723", "abs": "https://arxiv.org/abs/2507.07723", "authors": ["Chengtao Jian", "Kai Yang", "Ye Ouyang", "Xiaozhou Ye"], "title": "Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Direct Preference Optimization (DPO) has emerged as a popular and efficient\nalternative to reward modeling and reinforcement learning for aligning language\nmodels with human preferences. Despite its empirical success, the theoretical\nproperties and intrinsic limitations of DPO remain underexplored. In this work,\nwe first present a comprehensive analysis of DPO's dynamics from a probability\nevolution perspective. Our analysis reveals that DPO is highly sensitive to\ninitialization. It also tends to misallocate probability mass, which can\ninadvertently shift probability toward irrelevant or undesired responses. This\nmisallocation may unintentionally reinforce model bias, thereby compromising\nboth the stability of model alignment and the consistency with intended\npreferences. Motivated by these theoretical findings, we propose a\ntheoretically grounded bilevel optimization framework that tightly integrate\nsupervised fine-tuning with an enhanced DPO objective a.k.a. stable preference\noptimization. Our approach introduces a principled regularization scheme to\nexplicitly encourage absolute probability improvement for preferred outputs,\nwhile maintaining stable optimization dynamics. Experiments on challenging\nreasoning and summarization benchmarks elucidate that our method consistently\nimproves reasoning accuracy and better aligns output distributions with\nintended preferences, outperforming standard DPO. Stable preference\noptimization provides new insights into the design of preference-based\nalignment objectives and opens up new avenues towards more reliable and\ninterpretable language model alignment.", "AI": {"tldr": "Direct Preference Optimization (DPO) is sensitive to initialization and may misallocate probability mass, which can compromise model alignment and stability. To address these limitations, a bilevel optimization framework with regularization is proposed, achieving improved performance in reasoning and summarization benchmarks.", "motivation": "Understand the theoretical limitations of DPO and propose a more stable method to align language models with human preferences.", "method": "Introduce a bilevel optimization framework that combines supervised fine-tuning with a stable DPO objective, supported by a regularization scheme to improve preference alignment and stabilization.", "result": "The proposed method improves reasoning accuracy and aligns output distributions better with intended preferences, surpassing standard DPO in reasoning and summarization benchmarks.", "conclusion": "Stable preference optimization enhances reliability and interpretability in preference-based alignment, addressing DPO's theoretical limitations while enabling improved model alignment outcomes."}}
{"id": "2507.07794", "pdf": "https://arxiv.org/pdf/2507.07794", "abs": "https://arxiv.org/abs/2507.07794", "authors": ["Zhe Han", "Huanyu Tian", "Tom Vercauteren", "Da Liu", "Changsheng Li", "Xingguang Duan"], "title": "Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach", "categories": ["cs.RO"], "comment": null, "summary": "Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral\nand maxillofacial surgery. Despite advances in technique and instrumentation,\nits success still relies heavily on the surgeon's experience. In this work, a\nhuman-robot collaborative system is proposed to perform MASO according to a\npreoperative plan and under guidance of a surgeon. A task decomposition\nmethodology is used to divide the collaborative surgical procedure into three\nsubtasks: (1) positional control and (2) orientation control, both led by the\nrobot for precise alignment; and (3) force-control, managed by surgeon to\nensure safety. Additionally, to achieve patient tracking without the need for a\nskull clamp, an optical tracking system (OTS) is utilized. Movement of the\npatient mandibular is measured with an optical-based tracker mounted on a\ndental occlusal splint. A registration method and Robot-OTS calibration method\nare introduced to achieve reliable navigation within our framework. The\nexperiments of drilling were conducted on the realistic phantom model, which\ndemonstrated that the average error between the planned and actual drilling\npoints is 1.85mm.", "AI": {"tldr": "The paper proposes a human-robot collaborative system for performing Mandibular Angle Split Osteotomy (MASO) with high precision.", "motivation": "To enhance the precision and safety of MASO while reducing dependence on surgeon experience and the need for invasive stabilization methods like skull clamps.", "method": "The approach combines task decomposition (robot-led positional and orientation control, and surgeon-led force control) with an optical tracking system that uses a dental occlusal splint for non-invasive patient movement tracking. A calibration and registration method ensures precise surgical navigation.", "result": "Drilling experiments on a realistic phantom model achieved an average error of 1.85mm between the planned and actual points, demonstrating high precision.", "conclusion": "The proposed system shows promise in enhancing surgical accuracy in MASO while addressing limitations of traditional techniques, making it safer and more reliable."}}
{"id": "2507.07509", "pdf": "https://arxiv.org/pdf/2507.07509", "abs": "https://arxiv.org/abs/2507.07509", "authors": ["Yuanchen Shi", "Longyin Zhang", "Fang Kong"], "title": "Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "10pages,8 figures", "summary": "The growing need for psychological support due to increasing pressures has\nexposed the scarcity of relevant datasets, particularly in non-English\nlanguages. To address this, we propose a framework that leverages limited\nreal-world data and expert knowledge to fine-tune two large language models:\nDialog Generator and Dialog Modifier. The Generator creates large-scale\npsychological counseling dialogues based on predefined paths, which guide\nsystem response strategies and user interactions, forming the basis for\neffective support. The Modifier refines these dialogues to align with\nreal-world data quality. Through both automated and manual review, we construct\nthe Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K\ndialogues across 13 groups, 16 psychological problems, 13 causes, and 12\nsupport focuses. Additionally, we introduce the Comprehensive Agent Dialogue\nSupport System (CADSS), where a Profiler analyzes user characteristics, a\nSummarizer condenses dialogue history, a Planner selects strategies, and a\nSupporter generates empathetic responses. The experimental results of the\nStrategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate\nthat CADSS achieves state-of-the-art performance on both CPsDD and ESConv\ndatasets.", "AI": {"tldr": "The paper introduces a framework to improve psychological counseling support by creating and refining a Chinese Psychological Support Dialogue Dataset (CPsDD), and a Comprehensive Agent Dialogue Support System (CADSS).", "motivation": "There is a scarcity of psychological support datasets, especially in non-English languages, making it challenging to develop effective counseling systems.", "method": "The authors fine-tuned large language models using limited real-world data and expert knowledge to generate and refine psychological counseling dialogues. They created CPsDD using predefined paths for strategy and expert refinement. CADSS was built with components like a Profiler, Summarizer, Planner, and Supporter.", "result": "Their CADSS system demonstrated state-of-the-art results in Strategy Prediction and Emotional Support Conversation tasks on CPsDD and ESConv datasets.", "conclusion": "The framework effectively addresses the lack of non-English psychological support datasets and provides a robust system for delivering empathetic responses and scalable support strategies."}}
{"id": "2507.07374", "pdf": "https://arxiv.org/pdf/2507.07374", "abs": "https://arxiv.org/abs/2507.07374", "authors": ["Haotian Wang", "Aoran Xiao", "Xiaoqin Zhang", "Meng Yang", "Shijian Lu"], "title": "PacGDC: Label-Efficient Generalizable Depth Completion with Projection Ambiguity and Consistency", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Generalizable depth completion enables the acquisition of dense metric depth\nmaps for unseen environments, offering robust perception capabilities for\nvarious downstream tasks. However, training such models typically requires\nlarge-scale datasets with metric depth labels, which are often labor-intensive\nto collect. This paper presents PacGDC, a label-efficient technique that\nenhances data diversity with minimal annotation effort for generalizable depth\ncompletion. PacGDC builds on novel insights into inherent ambiguities and\nconsistencies in object shapes and positions during 2D-to-3D projection,\nallowing the synthesis of numerous pseudo geometries for the same visual scene.\nThis process greatly broadens available geometries by manipulating scene scales\nof the corresponding depth maps. To leverage this property, we propose a new\ndata synthesis pipeline that uses multiple depth foundation models as scale\nmanipulators. These models robustly provide pseudo depth labels with varied\nscene scales, affecting both local objects and global layouts, while ensuring\nprojection consistency that supports generalization. To further diversify\ngeometries, we incorporate interpolation and relocation strategies, as well as\nunlabeled images, extending the data coverage beyond the individual use of\nfoundation models. Extensive experiments show that PacGDC achieves remarkable\ngeneralizability across multiple benchmarks, excelling in diverse scene\nsemantics/scales and depth sparsity/patterns under both zero-shot and few-shot\nsettings. Code: https://github.com/Wang-xjtu/PacGDC.", "AI": {"tldr": "PacGDC is a label-efficient method for generalizable depth completion that uses depth foundation models and data synthesis to create pseudo labels with varied scene scales, achieving strong performance with minimal annotations.", "motivation": "To reduce the labor-intensive process of collecting large-scale metric depth labels, enabling robust perception for unseen environments using a generalizable depth completion approach.", "method": "PacGDC uses a data synthesis pipeline with multiple depth foundation models to manipulate scene scales, create pseudo depth labels, and ensure projection consistency. It further employs interpolation, relocation strategies, and unlabeled images to diversify data coverage.", "result": "Experiments demonstrate that PacGDC achieves notable generalizability across diverse benchmarks and scenarios, excelling under zero-shot and few-shot settings in various scene semantics, scales, and depth sparsity patterns.", "conclusion": "PacGDC provides an efficient solution to expand data diversity for depth completion tasks with reduced annotation effort, leveraging foundation models to achieve robust generalization in unseen environments."}}
{"id": "2507.07743", "pdf": "https://arxiv.org/pdf/2507.07743", "abs": "https://arxiv.org/abs/2507.07743", "authors": ["Phil\u00e9mon Beghin", "Anne-Emmanuelle Ceulemans", "Fran\u00e7ois Glineur"], "title": "Identification of Violin Reduction via Contour Lines Classification", "categories": ["cs.AI"], "comment": null, "summary": "The first violins appeared in late 16th-century Italy. Over the next 200\nyears, they spread across Europe and luthiers of various royal courts, eager to\nexperiment with new techniques, created a highly diverse family of instruments.\nAround 1750, size standards were introduced to unify violin making for\norchestras and conservatories. Instruments that fell between two standards were\nthen reduced to a smaller size by luthiers. These reductions have an impact on\nseveral characteristics of violins, in particular on the contour lines, i.e.\nlines of constant altitude, which look more like a U for non reduced\ninstruments and a V for reduced ones. While such differences are observed by\nexperts, they have not been studied quantitatively.\n  This paper presents a method for classifying violins as reduced or\nnon-reduced based on their contour lines. We study a corpus of 25 instruments\nwhose 3D geometric meshes were acquired via photogrammetry. For each\ninstrument, we extract 10-20 contour lines regularly spaced every millimetre.\nEach line is fitted with a parabola-like curve (with an equation of the type y\n= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)\nand how vertically stretched (alpha) the curve is. We compute additional\nfeatures from those parameters, using regressions and counting how many values\nfall under some threshold. We also deal with outliers and non equal numbers of\nlevels, and eventually obtain a numerical profile for each instrument.\n  We then apply classification methods to assess whether geometry alone can\npredict size reduction. We find that distinguishing between reduced and non\nreduced instruments is feasible to some degree, taking into account that a\nwhole spectrum of more or less transformed violins exists, for which it is more\ndifficult to quantify the reduction. We also find the opening parameter beta to\nbe the most predictive.", "AI": {"tldr": "The paper develops a method to classify violins as reduced or non-reduced based on their contour lines, using parameters extracted from 3D geometric data.", "motivation": "While experts observe differences in contour lines between reduced and non-reduced violins, these differences have not been studied quantitatively.", "method": "Using 3D geometric meshes of 25 violins, the authors extract contour lines and fit them to parabola-like equations to derive parameters. These parameters are then analyzed and used for classification.", "result": "The study shows geometry can predict size reduction to some degree, with the opening parameter beta being the most predictive.", "conclusion": "Quantitative analysis of contour lines offers a feasible way to classify reduced versus non-reduced violins, despite challenges with borderline cases."}}
{"id": "2507.07825", "pdf": "https://arxiv.org/pdf/2507.07825", "abs": "https://arxiv.org/abs/2507.07825", "authors": ["Leixin Chang", "Yuxuan Nai", "Hua Chen", "Liangjing Yang"], "title": "Beyond Robustness: Learning Unknown Dynamic Load Adaptation for Quadruped Locomotion on Rough Terrain", "categories": ["cs.RO"], "comment": "Accepted to the 2025 IEEE International Conference on Robotics &\n  Automation (ICRA). 8 pages, 8 figures", "summary": "Unknown dynamic load carrying is one important practical application for\nquadruped robots. Such a problem is non-trivial, posing three major challenges\nin quadruped locomotion control. First, how to model or represent the dynamics\nof the load in a generic manner. Second, how to make the robot capture the\ndynamics without any external sensing. Third, how to enable the robot to\ninteract with load handling the mutual effect and stabilizing the load. In this\nwork, we propose a general load modeling approach called load characteristics\nmodeling to capture the dynamics of the load. We integrate this proposed\nmodeling technique and leverage recent advances in Reinforcement Learning (RL)\nbased locomotion control to enable the robot to infer the dynamics of load\nmovement and interact with the load indirectly to stabilize it and realize the\nsim-to-real deployment to verify its effectiveness in real scenarios. We\nconduct extensive comparative simulation experiments to validate the\neffectiveness and superiority of our proposed method. Results show that our\nmethod outperforms other methods in sudden load resistance, load stabilizing\nand locomotion with heavy load on rough terrain.\n\\href{https://leixinjonaschang.github.io/leggedloadadapt.github.io/}{Project\nPage}.", "AI": {"tldr": "The paper focuses on enabling quadruped robots to handle unknown dynamic loads effectively by addressing challenges in modeling, sensing, and stabilizing. The authors propose an RL-based control system and validate it through simulations.", "motivation": "Address challenges posed by unknown dynamic loads in quadruped robots, requiring solutions for modeling, sensing, and stabilizing loads.", "method": "Introduced load characteristics modeling and integrated it with Reinforcement Learning (RL) to infer and interact with load dynamics.", "result": "Demonstrated effectiveness in comparative simulations, showcasing better load resistance, stabilization, and performance on rough terrains than other methods.", "conclusion": "The proposed method is an effective solution for quadruped robots handling dynamic loads, verified through sim-to-real applications and outperforming alternatives."}}
{"id": "2507.07518", "pdf": "https://arxiv.org/pdf/2507.07518", "abs": "https://arxiv.org/abs/2507.07518", "authors": ["Mikey Elmers", "Koji Inoue", "Divesh Lala", "Tatsuya Kawahara"], "title": "Triadic Multi-party Voice Activity Projection for Turn-taking in Spoken Dialogue Systems", "categories": ["cs.CL"], "comment": "Accepted to Interspeech 2025", "summary": "Turn-taking is a fundamental component of spoken dialogue, however\nconventional studies mostly involve dyadic settings. This work focuses on\napplying voice activity projection (VAP) to predict upcoming turn-taking in\ntriadic multi-party scenarios. The goal of VAP models is to predict the future\nvoice activity for each speaker utilizing only acoustic data. This is the first\nstudy to extend VAP into triadic conversation. We trained multiple models on a\nJapanese triadic dataset where participants discussed a variety of topics. We\nfound that the VAP trained on triadic conversation outperformed the baseline\nfor all models but that the type of conversation affected the accuracy. This\nstudy establishes that VAP can be used for turn-taking in triadic dialogue\nscenarios. Future work will incorporate this triadic VAP turn-taking model into\nspoken dialogue systems.", "AI": {"tldr": "This paper adapts voice activity projection (VAP) for triadic (three-person) conversations, demonstrating its effectiveness in predicting turn-taking using acoustic data.", "motivation": "The study aims to address the gap in turn-taking prediction research, expanding it from dyadic to triadic multi-party conversations.", "method": "VAP models were developed and trained on a Japanese dataset of triadic conversations across multiple topics to forecast voice activity for each speaker.", "result": "VAP models trained on triadic conversations exceeded baseline performance, though accuracy varied depending on the type of conversation.", "conclusion": "VAP is a viable tool for turn-taking prediction in triadic dialogues, with potential for integrating into spoken dialogue systems in future research."}}
{"id": "2507.07259", "pdf": "https://arxiv.org/pdf/2507.07259", "abs": "https://arxiv.org/abs/2507.07259", "authors": ["Giulio Rossolini", "Fabio Brau", "Alessandro Biondi", "Battista Biggio", "Giorgio Buttazzo"], "title": "Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning", "categories": ["cs.LG", "cs.AI"], "comment": "under review", "summary": "As machine learning models become increasingly deployed across the edge of\ninternet of things environments, a partitioned deep learning paradigm in which\nmodels are split across multiple computational nodes introduces a new dimension\nof security risk. Unlike traditional inference setups, these distributed\npipelines span the model computation across heterogeneous nodes and\ncommunication layers, thereby exposing a broader attack surface to potential\nadversaries. Building on these motivations, this work explores a previously\noverlooked vulnerability: even when both the edge and cloud components of the\nmodel are inaccessible (i.e., black-box), an adversary who intercepts the\nintermediate features transmitted between them can still pose a serious threat.\nWe demonstrate that, under these mild and realistic assumptions, an attacker\ncan craft highly transferable proxy models, making the entire deep learning\nsystem significantly more vulnerable to evasion attacks. In particular, the\nintercepted features can be effectively analyzed and leveraged to distill\nsurrogate models capable of crafting highly transferable adversarial examples\nagainst the target model. To this end, we propose an exploitation strategy\nspecifically designed for distributed settings, which involves reconstructing\nthe original tensor shape from vectorized transmitted features using simple\nstatistical analysis, and adapting surrogate architectures accordingly to\nenable effective feature distillation. A comprehensive and systematic\nexperimental evaluation has been conducted to demonstrate that surrogate models\ntrained with the proposed strategy, i.e., leveraging intermediate features,\ntremendously improve the transferability of adversarial attacks. These findings\nunderscore the urgent need to account for intermediate feature leakage in the\ndesign of secure distributed deep learning systems.", "AI": {"tldr": "This paper identifies a security vulnerability in distributed deep learning systems by showing that intercepted intermediate features can be exploited to create highly transferable adversarial attacks.", "motivation": "The motivation is to explore vulnerabilities in partitioned deep learning models deployed in distributed environments, specifically focusing on the risks of intermediate feature leakage.", "method": "The proposed method involves analyzing intercepted intermediate features to reconstruct tensor shapes, then crafting surrogate architectures for feature distillation and generating effective adversarial attacks.", "result": "Experimental results reveal that leveraging intermediate features significantly improves the transferability of adversarial attacks crafted by proxy models.", "conclusion": "The study highlights the critical security risks posed by intermediate feature leakage in distributed deep learning systems and stresses the importance of designing more secure frameworks."}}
{"id": "2507.07379", "pdf": "https://arxiv.org/pdf/2507.07379", "abs": "https://arxiv.org/abs/2507.07379", "authors": ["Hong Xu", "Shireen Y. Elhabian"], "title": "Adaptive Particle-Based Shape Modeling for Anatomical Surface Correspondence", "categories": ["cs.CV"], "comment": null, "summary": "Particle-based shape modeling (PSM) is a family of approaches that\nautomatically quantifies shape variability across anatomical cohorts by\npositioning particles (pseudo landmarks) on shape surfaces in a consistent\nconfiguration. Recent advances incorporate implicit radial basis function\nrepresentations as self-supervised signals to better capture the complex\ngeometric properties of anatomical structures. However, these methods still\nlack self-adaptivity -- that is, the ability to automatically adjust particle\nconfigurations to local geometric features of each surface, which is essential\nfor accurately representing complex anatomical variability. This paper\nintroduces two mechanisms to increase surface adaptivity while maintaining\nconsistent particle configurations: (1) a novel neighborhood correspondence\nloss to enable high adaptivity and (2) a geodesic correspondence algorithm that\nregularizes optimization to enforce geodesic neighborhood consistency. We\nevaluate the efficacy and scalability of our approach on challenging datasets,\nproviding a detailed analysis of the adaptivity-correspondence trade-off and\nbenchmarking against existing methods on surface representation accuracy and\ncorrespondence metrics.", "AI": {"tldr": "This paper enhances particle-based shape modeling by introducing adaptive mechanisms using a novel neighborhood correspondence loss and a geodesic correspondence algorithm, improving representation of anatomical variability.", "motivation": "To address the lack of self-adaptivity in particle-based shape modeling methods, which hinders accurate representation of complex anatomical structures.", "method": "Proposed two mechanisms: a novel neighborhood correspondence loss for adaptivity and a geodesic correspondence algorithm to regularize and ensure consistency of particle configurations.", "result": "Evaluated on challenging datasets, the proposed approach improves surface representation accuracy and correspondence metrics, while offering a detailed adaptivity-correspondence trade-off analysis.", "conclusion": "The new methods enable more accurate and adaptive modeling of anatomical shape variability, outperforming existing methods in terms of accuracy and consistency."}}
{"id": "2507.07787", "pdf": "https://arxiv.org/pdf/2507.07787", "abs": "https://arxiv.org/abs/2507.07787", "authors": ["Elizabeth Hilliard", "Akshaya Jagadeesh", "Alex Cook", "Steele Billings", "Nicholas Skytland", "Alicia Llewellyn", "Jackson Paull", "Nathan Paull", "Nolan Kurylo", "Keatra Nesbitt", "Robert Gruenewald", "Anthony Jantzi", "Omar Chavez"], "title": "Measuring AI Alignment with Human Flourishing", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel\nevaluation framework that assesses AI alignment with human flourishing across\nseven dimensions: Character and Virtue, Close Social Relationships, Happiness\nand Life Satisfaction, Meaning and Purpose, Mental and Physical Health,\nFinancial and Material Stability, and Faith and Spirituality. Unlike\ntraditional benchmarks that focus on technical capabilities or harm prevention,\nthe FAI Benchmark measures AI performance on how effectively models contribute\nto the flourishing of a person across these dimensions. The benchmark evaluates\nhow effectively LLM AI systems align with current research models of holistic\nhuman well-being through a comprehensive methodology that incorporates 1,229\nobjective and subjective questions. Using specialized judge Large Language\nModels (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs\ngeometric mean scoring to ensure balanced performance across all flourishing\ndimensions. Initial testing of 28 leading language models reveals that while\nsome models approach holistic alignment (with the highest-scoring models\nachieving 72/100), none are acceptably aligned across all dimensions,\nparticularly in Faith and Spirituality, Character and Virtue, and Meaning and\nPurpose. This research establishes a framework for developing AI systems that\nactively support human flourishing rather than merely avoiding harm, offering\nsignificant implications for AI development, ethics, and evaluation.", "AI": {"tldr": "The paper presents the Flourishing AI Benchmark (FAI Benchmark) to evaluate AI alignment with human well-being across seven dimensions, revealing substantial gaps in alignment among leading language models.", "motivation": "Traditional AI benchmarks focus on technical proficiency or harm prevention, but there's a gap in evaluating AI's alignment with holistic human well-being. This paper addresses the need for a framework to assess AI's contribution to human flourishing.", "method": "The FAI Benchmark uses 1,229 objective and subjective questions, specialized judge LLMs, cross-dimensional evaluation, and geometric mean scoring to measure AI alignment with seven dimensions of human flourishing.", "result": "Testing 28 leading language models showed that while some achieved a score of 72/100, none were fully aligned in all seven dimensions, especially in Faith and Spirituality, Character and Virtue, and Meaning and Purpose.", "conclusion": "The research highlights the need to develop AI systems that actively promote human flourishing, providing a new evaluation framework with critical ethical and developmental implications for AI technology."}}
{"id": "2507.07845", "pdf": "https://arxiv.org/pdf/2507.07845", "abs": "https://arxiv.org/abs/2507.07845", "authors": ["David Warutumo", "Ciira wa Maina"], "title": "Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System", "categories": ["cs.RO"], "comment": "2 authors, 23 pages, 11 figures", "summary": "Autonomous agents, particularly in the field of robotics, rely on sensory\ninformation to perceive and navigate their environment. However, these sensory\ninputs are often imperfect, leading to distortions in the agent's internal\nrepresentation of the world. This paper investigates the nature of these\nperceptual distortions and how they influence autonomous representation\nlearning using a minimal robotic system. We utilize a simulated two-wheeled\nrobot equipped with distance sensors and a compass, operating within a simple\nsquare environment. Through analysis of the robot's sensor data during random\nexploration, we demonstrate how a distorted perceptual space emerges. Despite\nthese distortions, we identify emergent structures within the perceptual space\nthat correlate with the physical environment, revealing how the robot\nautonomously learns a structured representation for navigation without explicit\nspatial information. This work contributes to the understanding of embodied\ncognition, minimal agency, and the role of perception in self-generated\nnavigation strategies in artificial life.", "AI": {"tldr": "This paper explores how sensory distortions impact autonomous representation learning using a minimal robotic system, showing the emergence of structured perceptual spaces aiding navigation.", "motivation": "Understanding how sensory imperfections impact perception and navigation in autonomous agents, and uncovering emergent representational structures, improves knowledge in robotics and artificial life domains.", "method": "A simulated two-wheeled robot with distance sensors and a compass navigates a square environment. Perceptual distortions are analyzed based on sensor data during random exploration.", "result": "Despite distorted sensory data, emergent structures in perceptual space correlated with the physical environment, facilitating autonomous navigation.", "conclusion": "Autonomous agents can develop structured representations that aid their navigation despite perceptual distortions, advancing embodied cognition and artificial life research."}}
{"id": "2507.07539", "pdf": "https://arxiv.org/pdf/2507.07539", "abs": "https://arxiv.org/abs/2507.07539", "authors": ["Akram Elbouanani", "Evan Dufraisse", "Aboubacar Tuo", "Adrian Popescu"], "title": "CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text", "categories": ["cs.CL", "cs.AI"], "comment": "Notebook for the CheckThat! Lab at CLEF 2025", "summary": "This paper presents a competitive approach to multilingual subjectivity\ndetection using large language models (LLMs) with few-shot prompting. We\nparticipated in Task 1: Subjectivity of the CheckThat! 2025 evaluation\ncampaign. We show that LLMs, when paired with carefully designed prompts, can\nmatch or outperform fine-tuned smaller language models (SLMs), particularly in\nnoisy or low-quality data settings. Despite experimenting with advanced prompt\nengineering techniques, such as debating LLMs and various example selection\nstrategies, we found limited benefit beyond well-crafted standard few-shot\nprompts. Our system achieved top rankings across multiple languages in the\nCheckThat! 2025 subjectivity detection task, including first place in Arabic\nand Polish, and top-four finishes in Italian, English, German, and multilingual\ntracks. Notably, our method proved especially robust on the Arabic dataset,\nlikely due to its resilience to annotation inconsistencies. These findings\nhighlight the effectiveness and adaptability of LLM-based few-shot learning for\nmultilingual sentiment tasks, offering a strong alternative to traditional\nfine-tuning, particularly when labeled data is scarce or inconsistent.", "AI": {"tldr": "This paper demonstrates the success of large language models (LLMs) in multilingual subjectivity detection through few-shot learning, achieving top rankings in the CheckThat! 2025 campaign.", "motivation": "To explore robust methods for multilingual subjectivity detection, particularly addressing challenges posed by noisy data and inconsistent annotations.", "method": "Using few-shot prompting with large language models (LLMs) and experimenting with advanced prompt engineering techniques like debating LLMs and particular example selection strategies.", "result": "LLMs with carefully crafted prompts outperformed fine-tuned smaller language models (SLMs), achieving first place in Arabic and Polish and top rankings in other languages.", "conclusion": "LLMs paired with few-shot learning provide an effective, adaptable approach for multilingual sentiment tasks, especially in settings with limited or inconsistent labeled data."}}
{"id": "2507.07261", "pdf": "https://arxiv.org/pdf/2507.07261", "abs": "https://arxiv.org/abs/2507.07261", "authors": ["Chunzhuo Wang", "Hans Hallez", "Bart Vanrumste"], "title": "Robust Multimodal Learning Framework For Intake Gesture Detection Using Contactless Radar and Wearable IMU Sensors", "categories": ["cs.LG", "eess.SP"], "comment": "This manuscript has been submitted to a peer-reviewed journal and is\n  currently under review", "summary": "Automated food intake gesture detection plays a vital role in dietary\nmonitoring, enabling objective and continuous tracking of eating behaviors to\nsupport better health outcomes. Wrist-worn inertial measurement units (IMUs)\nhave been widely used for this task with promising results. More recently,\ncontactless radar sensors have also shown potential. This study explores\nwhether combining wearable and contactless sensing modalities through\nmultimodal learning can further improve detection performance. We also address\na major challenge in multimodal learning: reduced robustness when one modality\nis missing. To this end, we propose a robust multimodal temporal convolutional\nnetwork with cross-modal attention (MM-TCN-CMA), designed to integrate IMU and\nradar data, enhance gesture detection, and maintain performance under missing\nmodality conditions. A new dataset comprising 52 meal sessions (3,050 eating\ngestures and 797 drinking gestures) from 52 participants is developed and made\npublicly available. Experimental results show that the proposed framework\nimproves the segmental F1-score by 4.3% and 5.2% over unimodal Radar and IMU\nmodels, respectively. Under missing modality scenarios, the framework still\nachieves gains of 1.3% and 2.4% for missing radar and missing IMU inputs. This\nis the first study to demonstrate a robust multimodal learning framework that\neffectively fuses IMU and radar data for food intake gesture detection.", "AI": {"tldr": "This paper proposes a new multimodal learning framework for food intake gesture detection using both IMU and radar sensors, achieving higher performance even with missing modality inputs.", "motivation": "To improve food intake gesture detection for dietary monitoring and address the challenge of reduced robustness in multimodal learning when one sensing modality is unavailable.", "method": "A robust multimodal temporal convolutional network with cross-modal attention (MM-TCN-CMA) was developed to integrate IMU and radar data, with evaluations on a newly created dataset showcasing 3,847 eating and drinking gestures.", "result": "The proposed MM-TCN-CMA framework improved detection performance with a segmental F1-score increase of 4.3% and 5.2% over unimodal radar and IMU models, and maintained robustness with gains of 1.3% and 2.4% under missing modality inputs.", "conclusion": "The MM-TCN-CMA framework effectively demonstrates that combining wearable IMU sensors and radar data enhances food intake gesture detection, paving the way for more robust dietary monitoring systems."}}
{"id": "2507.07381", "pdf": "https://arxiv.org/pdf/2507.07381", "abs": "https://arxiv.org/abs/2507.07381", "authors": ["Hao Xu", "Arbind Agrahari Baniya", "Sam Wells", "Mohamed Reda Bouadjenek", "Richard Dazeley", "Sunil Aryal"], "title": "Multi-Scale Attention and Gated Shifting for Fine-Grained Event Spotting in Videos", "categories": ["cs.CV"], "comment": null, "summary": "Precise Event Spotting (PES) in sports videos requires frame-level\nrecognition of fine-grained actions from single-camera footage. Existing PES\nmodels typically incorporate lightweight temporal modules such as Gate Shift\nModule (GSM) or Gate Shift Fuse (GSF) to enrich 2D CNN feature extractors with\ntemporal context. However, these modules are limited in both temporal receptive\nfield and spatial adaptability. We propose a Multi-Scale Attention Gate Shift\nModule (MSAGSM) that enhances GSM with multi-scale temporal dilations and\nmulti-head spatial attention, enabling efficient modeling of both short- and\nlong-term dependencies while focusing on salient regions. MSAGSM is a\nlightweight plug-and-play module that can be easily integrated with various 2D\nbackbones. To further advance the field, we introduce the Table Tennis\nAustralia (TTA) dataset-the first PES benchmark for table tennis-containing\nover 4800 precisely annotated events. Extensive experiments across five PES\nbenchmarks demonstrate that MSAGSM consistently improves performance with\nminimal overhead, setting new state-of-the-art results.", "AI": {"tldr": "This paper introduces a new lightweight module, MSAGSM, for event spotting in sports videos and presents a new dataset for table tennis, the TTA dataset, achieving state-of-the-art results.", "motivation": "The motivation is to address the limitations of existing PES models, which have restricted temporal receptive fields and spatial adaptability, and to improve the performance of recognizing fine-grained actions in sports videos.", "method": "The authors propose MSAGSM, which combines multi-scale temporal dilations with multi-head spatial attention, providing better modeling of short- and long-term dependencies. They also introduce the TTA dataset for table tennis event recognition.", "result": "MSAGSM achieves consistent performance improvements across five PES benchmarks, setting new state-of-the-art results while maintaining minimal computational overhead.", "conclusion": "The proposed MSAGSM module and the introduction of the TTA dataset mark a significant advancement in PES, improving both methodology and benchmark resources for the community."}}
{"id": "2507.07818", "pdf": "https://arxiv.org/pdf/2507.07818", "abs": "https://arxiv.org/abs/2507.07818", "authors": ["Lu Xu", "Jiaqian Yu", "Xiongfeng Peng", "Yiwei Chen", "Weiming Li", "Jaewook Yoo", "Sunghyun Chunag", "Dongwook Lee", "Daehyun Ji", "Chao Zhang"], "title": "MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Recent studies show large language models (LLMs) and vision language models\n(VLMs) trained using web-scale data can empower end-to-end autonomous driving\nsystems for a better generalization and interpretation. Specifically, by\ndynamically routing inputs to specialized subsets of parameters, the\nMixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve\nsubstantial performance improvements while maintaining computational\nefficiency. However, general MoE models usually demands extensive training data\nand complex optimization. In this work, inspired by the learning process of\nhuman drivers, we propose a skill-oriented MoE, called MoSE, which mimics human\ndrivers' learning process and reasoning process, skill-by-skill and\nstep-by-step. We propose a skill-oriented routing mechanism that begins with\ndefining and annotating specific skills, enabling experts to identify the\nnecessary driving competencies for various scenarios and reasoning tasks,\nthereby facilitating skill-by-skill learning. Further align the driving process\nto multi-step planning in human reasoning and end-to-end driving models, we\nbuild a hierarchical skill dataset and pretrain the router to encourage the\nmodel to think step-by-step. Unlike multi-round dialogs, MoSE integrates\nvaluable auxiliary tasks (e.g.\\ description, reasoning, planning) in one single\nforward process without introducing any extra computational cost. With less\nthan 3B sparsely activated parameters, our model outperforms several 8B+\nparameters on CODA AD corner case reasoning task. Compared to existing methods\nbased on open-source models and data, our approach achieves state-of-the-art\nperformance with significantly reduced activated model size (at least by\n$62.5\\%$) with a single-turn conversation.", "AI": {"tldr": "The paper introduces MoSE, a skill-focused Mixture-of-Experts model, aimed at improving end-to-end autonomous driving by mimicking human learning and reasoning processes.", "motivation": "To overcome limitations in generalization and optimization faced by autonomous driving systems using general Mixture-of-Experts models, and to mimic human drivers' dynamic learning.", "method": "The paper proposes MoSE, which employs a skill-oriented routing mechanism and hierarchical skill datasets to enable step-by-step learning and reasoning akin to human drivers.", "result": "MoSE demonstrates state-of-the-art performance on CODA AD corner case reasoning tasks, surpassing larger models (8B+ parameters) with less computational demand (by at least 62.5%).", "conclusion": "MoSE efficiently achieves better performance by streamlining computational resources and integrating auxiliary tasks into a single forward process, offering a novel approach to autonomous driving systems."}}
{"id": "2507.07846", "pdf": "https://arxiv.org/pdf/2507.07846", "abs": "https://arxiv.org/abs/2507.07846", "authors": ["Kavindie Katuwandeniya", "Samith Rajapaksha Jayasekara Widhanapathirana"], "title": "ROS Help Desk: GenAI Powered, User-Centric Framework for ROS Error Diagnosis and Debugging", "categories": ["cs.RO"], "comment": null, "summary": "As the robotics systems increasingly integrate into daily life, from smart\nhome assistants to the new-wave of industrial automation systems (Industry\n4.0), there's an increasing need to bridge the gap between complex robotic\nsystems and everyday users. The Robot Operating System (ROS) is a flexible\nframework often utilised in writing robot software, providing tools and\nlibraries for building complex robotic systems. However, ROS's distributed\narchitecture and technical messaging system create barriers for understanding\nrobot status and diagnosing errors. This gap can lead to extended maintenance\ndowntimes, as users with limited ROS knowledge may struggle to quickly diagnose\nand resolve system issues. Moreover, this deficit in expertise often delays\nproactive maintenance and troubleshooting, further increasing the frequency and\nduration of system interruptions. ROS Help Desk provides intuitive error\nexplanations and debugging support, dynamically customized to users of varying\nexpertise levels. It features user-centric debugging tools that simplify error\ndiagnosis, implements proactive error detection capabilities to reduce\ndowntime, and integrates multimodal data processing for comprehensive system\nstate understanding across multi-sensor data (e.g., lidar, RGB). Testing\nqualitatively and quantitatively with artificially induced errors demonstrates\nthe system's ability to proactively and accurately diagnose problems,\nultimately reducing maintenance time and fostering more effective human-robot\ncollaboration.", "AI": {"tldr": "A tool, ROS Help Desk, is introduced to simplify error diagnosis in robotics systems, catering to users of varying expertise.", "motivation": "Robotics systems are increasingly integrated into daily life, but the complexity of robotic system frameworks like ROS poses challenges for users in understanding system status and diagnosing errors.", "method": "The approach includes ROS Help Desk's user-centric debugging tools, proactive error detection capabilities, and multimodal data processing for system state understanding across multi-sensor data like lidar and RGB.", "result": "Tests with artificially induced errors show the system accurately and proactively diagnoses issues, thereby reducing maintenance downtime.", "conclusion": "ROS Help Desk aids in reducing maintenance time and fostering improved human-robot collaboration by simplifying and expediting error diagnosis and resolution."}}
{"id": "2507.07543", "pdf": "https://arxiv.org/pdf/2507.07543", "abs": "https://arxiv.org/abs/2507.07543", "authors": ["Chen Amiraz", "Yaroslav Fyodorov", "Elad Haramaty", "Zohar Karnin", "Liane Lewin-Eytan"], "title": "The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Cross-lingual retrieval-augmented generation (RAG) is a critical capability\nfor retrieving and generating answers across languages. Prior work in this\ncontext has mostly focused on generation and relied on benchmarks derived from\nopen-domain sources, most notably Wikipedia. In such settings, retrieval\nchallenges often remain hidden due to language imbalances, overlap with\npretraining data, and memorized content. To address this gap, we study\nArabic-English RAG in a domain-specific setting using benchmarks derived from\nreal-world corporate datasets. Our benchmarks include all combinations of\nlanguages for the user query and the supporting document, drawn independently\nand uniformly at random. This enables a systematic study of multilingual\nretrieval behavior.\n  Our findings reveal that retrieval is a critical bottleneck in cross-lingual\ndomain-specific scenarios, with significant performance drops occurring when\nthe user query and supporting document languages differ. A key insight is that\nthese failures stem primarily from the retriever's difficulty in ranking\ndocuments across languages. Finally, we propose a simple retrieval strategy\nthat addresses this source of failure by enforcing equal retrieval from both\nlanguages, resulting in substantial improvements in cross-lingual and overall\nperformance. These results highlight meaningful opportunities for improving\nmultilingual retrieval, particularly in practical, real-world RAG applications.", "AI": {"tldr": "The paper studies Arabic-English retrieval-augmented generation (RAG) in domain-specific settings, finding that retrieval is a bottleneck when user query and document languages differ, and proposes a simple strategy to improve multilingual retrieval.", "motivation": "To address the gap in cross-lingual RAG research within domain-specific contexts, especially considering the limitations of existing benchmarks that hide retrieval challenges due to language imbalances and pretraining data overlaps.", "method": "The study involves developing benchmarks from real-world corporate datasets, examining query-document language combinations systematically, and proposing a retrieval strategy that enforces equal document retrieval from both languages.", "result": "The study finds that retrieval is the main weakness in cross-lingual domain-specific RAG, particularly with language mismatches between queries and documents. The proposed strategy significantly improves retrieval performance across languages.", "conclusion": "The research underscores the importance of focusing on retrieval improvements for effective domain-specific cross-lingual RAG and demonstrates that simple strategies can yield substantial practical benefits."}}
{"id": "2507.07271", "pdf": "https://arxiv.org/pdf/2507.07271", "abs": "https://arxiv.org/abs/2507.07271", "authors": ["Julianna Piskorz", "Krzysztof Kacprzyk", "Mihaela van der Schaar"], "title": "Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time", "categories": ["cs.LG"], "comment": "Presented at the Actionable Interpretability Workshop at ICML 2025", "summary": "The Average Treatment Effect (ATE) is a foundational metric in causal\ninference, widely used to assess intervention efficacy in randomized controlled\ntrials (RCTs). However, in many applications -- particularly in healthcare --\nthis static summary fails to capture the nuanced dynamics of treatment effects\nthat vary with both dose and time. We propose a framework for modelling\ntreatment effect trajectories as smooth surfaces over dose and time, enabling\nthe extraction of clinically actionable insights such as onset time, peak\neffect, and duration of benefit. To ensure interpretability, robustness, and\nverifiability -- key requirements in high-stakes domains -- we adapt\nSemanticODE, a recent framework for interpretable trajectory modelling, to the\ncausal setting where treatment effects are never directly observed. Our\napproach decouples the estimation of trajectory shape from the specification of\nclinically relevant properties (e.g., maxima, inflection points), supporting\ndomain-informed priors, post-hoc editing, and transparent analysis. We show\nthat our method yields accurate, interpretable, and editable models of\ntreatment dynamics, facilitating both rigorous causal analysis and practical\ndecision-making.", "AI": {"tldr": "The paper introduces a novel framework to model treatment effects over dose and time, moving beyond static metrics like ATE, by using interpretable trajectory modeling to enable actionable clinical insights.", "motivation": "Traditional metrics like ATE in causal inference fail to capture the dynamic nature of treatment effects across dose and time, limiting insights particularly in fields like healthcare.", "method": "The proposed method adapts SemanticODE for modeling treatment dynamics, decoupling trajectory estimation from defining clinically relevant properties, allowing for interpretability and flexible analysis.", "result": "The approach demonstrates the ability to accurately and transparently model the dynamics of treatment effects, offering robust and editable models for practical and clinical use.", "conclusion": "The framework enhances the understanding of treatment effects by providing actionable models and insights for causal analysis and decision-making in high-stakes domains."}}
{"id": "2507.07393", "pdf": "https://arxiv.org/pdf/2507.07393", "abs": "https://arxiv.org/abs/2507.07393", "authors": ["Jinseong Kim", "Junghoon Song", "Gyeongseon Baek", "Byeongjoon Noh"], "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 2 figures,", "summary": "We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person\nre-identification framework consisting of global and local branches that\nleverage human keypoints for enhanced spatiotemporal representation learning.\nThe global branch captures holistic identity semantics through\nTransformer-based temporal aggregation, while the local branch dynamically\nsegments body regions based on keypoints to generate fine-grained, part-aware\nfeatures. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate\nstate-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy\non MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code\nfor this work will be publicly available on GitHub upon publication.", "AI": {"tldr": "KeyRe-ID improves video-based person re-identification using keypoints and achieves state-of-the-art results on standard benchmarks.", "motivation": "To enhance the accuracy of video-based person re-identification by leveraging human keypoints for better representation learning.", "method": "KeyRe-ID utilizes a global branch with Transformer-based temporal aggregation for holistic representation and a local branch for part-aware features based on dynamically segmented body regions from keypoints.", "result": "The framework achieves 91.73% mAP and 97.32% Rank-1 accuracy on MARS, 96.00% Rank-1 and 100.0% Rank-5 accuracy on iLIDS-VID benchmarks.", "conclusion": "KeyRe-ID advances person re-identification by combining global and local spatiotemporal features, and its performance sets a new benchmark in the domain."}}
{"id": "2507.07820", "pdf": "https://arxiv.org/pdf/2507.07820", "abs": "https://arxiv.org/abs/2507.07820", "authors": ["Eunsu Baek", "Keondo Park", "Jeonggil Ko", "Min-hwan Oh", "Taesik Gong", "Hyung-Sin Kim"], "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Current AI advances largely rely on scaling neural models and expanding\ntraining datasets to achieve generalization and robustness. Despite notable\nsuccesses, this paradigm incurs significant environmental, economic, and\nethical costs, limiting sustainability and equitable access. Inspired by\nbiological sensory systems, where adaptation occurs dynamically at the input\n(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive\nsensing as a necessary and foundational shift. Adaptive sensing proactively\nmodulates sensor parameters (e.g., exposure, sensitivity, multimodal\nconfigurations) at the input level, significantly mitigating covariate shifts\nand improving efficiency. Empirical evidence from recent studies demonstrates\nthat adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass\nsubstantially larger models (e.g., OpenCLIP-H) trained with significantly more\ndata and compute. We (i) outline a roadmap for broadly integrating adaptive\nsensing into real-world applications spanning humanoid, healthcare, autonomous\nsystems, agriculture, and environmental monitoring, (ii) critically assess\ntechnical and ethical integration challenges, and (iii) propose targeted\nresearch directions, such as standardized benchmarks, real-time adaptive\nalgorithms, multimodal integration, and privacy-preserving methods.\nCollectively, these efforts aim to transition the AI community toward\nsustainable, robust, and equitable artificial intelligence systems.", "AI": {"tldr": "This paper proposes adopting adaptive sensing methods in AI to mimic biological sensory adjustments, improving model efficiency while reducing environmental, economic, and ethical costs.", "motivation": "The paper is motivated by the significant environmental, economic, and ethical concerns associated with scaling neural models and datasets, as well as a desire for equitable access and sustainable AI.", "method": "The authors advocate for adaptive sensing, where input sensor parameters are dynamically modulated to mitigate covariate shifts and enhance efficiency. They provide empirical evidence demonstrating that small models with adaptive sensing outperform larger ones. Additionally, they propose a roadmap for incorporating this approach into diverse real-world domains.", "result": "Empirical data shows smaller models employing adaptive sensing outperform larger, computationally intensive models. Furthermore, the paper identifies new pathways for adaptive sensing integration and future research.", "conclusion": "Adaptive sensing offers a sustainable and efficient alternative for advancing AI systems, with potential for widespread application across industries. It also represents a step toward equitable and responsible AI development."}}
{"id": "2507.07872", "pdf": "https://arxiv.org/pdf/2507.07872", "abs": "https://arxiv.org/abs/2507.07872", "authors": ["Daniel Betschinske", "Steven Peters"], "title": "Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle", "categories": ["cs.RO", "cs.LG"], "comment": "This work has been accepted for publication at the 2025 IEEE\n  International Automated Vehicle Validation Conference (IAVVC)", "summary": "The safety validation of automatic emergency braking system (AEBS) requires\naccurately distinguishing between false positive (FP) and true positive (TP)\nsystem activations. While simulations allow straightforward differentiation by\ncomparing scenarios with and without interventions, analyzing activations from\nopen-loop resimulations - such as those from field operational testing (FOT) -\nis more complex. This complexity arises from scenario parameter uncertainty and\nthe influence of driver interventions in the recorded data. Human labeling is\nfrequently used to address these challenges, relying on subjective assessments\nof intervention necessity or situational criticality, potentially introducing\nbiases and limitations. This work proposes a rule-based classification approach\nleveraging the Prediction Divergence Principle (PDP) to address those issues.\nApplied to a simplified AEBS, the proposed method reveals key strengths,\nlimitations, and system requirements for effective implementation. The findings\nsuggest that combining this approach with human labeling may enhance the\ntransparency and consistency of classification, thereby improving the overall\nvalidation process. While the rule set for classification derived in this work\nadopts a conservative approach, the paper outlines future directions for\nrefinement and broader applicability. Finally, this work highlights the\npotential of such methods to complement existing practices, paving the way for\nmore reliable and reproducible AEBS validation frameworks.", "AI": {"tldr": "The paper introduces a rule-based approach using the Prediction Divergence Principle (PDP) to enhance classification in the safety validation of automatic emergency braking systems (AEBS), addressing challenges associated with human labeling and uncertainty in open-loop resimulations.", "motivation": "Safety validation of AEBS has challenges in distinguishing false positives from true positives due to uncertainties in simulations and driver interventions, leading to reliance on subjective and potentially biased human labeling.", "method": "The study proposes a rule-based classification method based on the Prediction Divergence Principle (PDP) and applies it to a simplified AEBS to evaluate its effectiveness.", "result": "The proposed PDP-based method demonstrates strengths, limitations, and system requirements for implementation, and combining it with human labeling shows potential for improved transparency and consistency in classification.", "conclusion": "The paper concludes that the proposed method can complement human labeling practices, paving the way for more reliable and reproducible AEBS validation while outlining future improvements."}}
{"id": "2507.07562", "pdf": "https://arxiv.org/pdf/2507.07562", "abs": "https://arxiv.org/abs/2507.07562", "authors": ["Jierun Chen", "Tiezheng Yu", "Haoli Bai", "Lewei Yao", "Jiannan Wu", "Kaican Li", "Fei Mi", "Chaofan Tao", "Lei Zhu", "Manyi Zhang", "Xiaohui Li", "Lu Hou", "Lifeng Shang", "Qun Liu"], "title": "The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large vision-language models (VLMs) increasingly adopt post-training\ntechniques such as long chain-of-thought (CoT) supervised fine-tuning (SFT) and\nreinforcement learning (RL) to elicit sophisticated reasoning. While these\nmethods exhibit synergy in language-only models, their joint effectiveness in\nVLMs remains uncertain. We present a systematic investigation into the distinct\nroles and interplay of long-CoT SFT and RL across multiple multimodal reasoning\nbenchmarks. We find that SFT improves performance on difficult questions by\nin-depth, structured reasoning, but introduces verbosity and degrades\nperformance on simpler ones. In contrast, RL promotes generalization and\nbrevity, yielding consistent improvements across all difficulty levels, though\nthe improvements on the hardest questions are less prominent compared to SFT.\nSurprisingly, combining them through two-staged, interleaved, or progressive\ntraining strategies, as well as data mixing and model merging, all fails to\nproduce additive benefits, instead leading to trade-offs in accuracy, reasoning\nstyle, and response length. This ``synergy dilemma'' highlights the need for\nmore seamless and adaptive approaches to unlock the full potential of combined\npost-training techniques for reasoning VLMs.", "AI": {"tldr": "This paper investigates the impact of combining post-training techniques, supervised fine-tuning (SFT) and reinforcement learning (RL), in large vision-language models and finds no additive benefits despite their individual strengths.", "motivation": "The authors seek to understand whether combining post-training techniques like SFT and RL can enhance the reasoning capabilities of vision-language models (VLMs) and overcome their individual limitations.", "method": "The study rigorously evaluates multiple multimodal reasoning benchmarks using distinct and combined approaches to long chain-of-thought supervised fine-tuning (SFT) and reinforcement learning (RL). It assesses performance using varying training strategies.", "result": "SFT excels in tackling difficult reasoning tasks but causes verbosity, while RL enhances generalization and brevity across task difficulty levels. However, their combination fails to yield additive performance benefits, creating trade-offs in accuracy and reasoning style.", "conclusion": "The findings emphasize the need for more adaptive and integrated methods to effectively combine SFT and RL for improved reasoning in VLMs. Current approaches do not synergistically elevate performance."}}
{"id": "2507.07394", "pdf": "https://arxiv.org/pdf/2507.07394", "abs": "https://arxiv.org/abs/2507.07394", "authors": ["Zhimin Zhang", "Bi'an Du", "Caoyuan Ma", "Zheng Wang", "Wei Hu"], "title": "Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Animal motion embodies species-specific behavioral habits, making the\ntransfer of motion across categories a critical yet complex task for\napplications in animation and virtual reality. Existing motion transfer\nmethods, primarily focused on human motion, emphasize skeletal alignment\n(motion retargeting) or stylistic consistency (motion style transfer), often\nneglecting the preservation of distinct habitual behaviors in animals. To\nbridge this gap, we propose a novel habit-preserved motion transfer framework\nfor cross-category animal motion. Built upon a generative framework, our model\nintroduces a habit-preservation module with category-specific habit encoder,\nallowing it to learn motion priors that capture distinctive habitual\ncharacteristics. Furthermore, we integrate a large language model (LLM) to\nfacilitate the motion transfer to previously unobserved species. To evaluate\nthe effectiveness of our approach, we introduce the DeformingThings4D-skl\ndataset, a quadruped dataset with skeletal bindings, and conduct extensive\nexperiments and quantitative analyses, which validate the superiority of our\nproposed model.", "AI": {"tldr": "The paper proposes a motion transfer framework preserving animal-specific habitual behaviors using generative models and category-specific encoders, also incorporating large language models for unseen species.", "motivation": "Current motion transfer methods fail to preserve unique habitual behaviors in animals when transferring motion across species categories.", "method": "The paper introduces a habit-preservation module and a category-specific habit encoder within a generative framework. It leverages large language models (LLMs) for motion transfer to unobserved species.", "result": "Experiments on the newly introduced DeformingThings4D-skl dataset demonstrate that the proposed model outperforms existing methods.", "conclusion": "The framework successfully bridges the gap in habit-preserved motion transfer across animal categories and accommodates unseen species."}}
{"id": "2507.07857", "pdf": "https://arxiv.org/pdf/2507.07857", "abs": "https://arxiv.org/abs/2507.07857", "authors": ["Samuel Reyd", "Ada Diaconescu", "Jean-Louis Dessalles"], "title": "Searching for actual causes: Approximate algorithms with adjustable precision", "categories": ["cs.AI"], "comment": null, "summary": "Causality has gained popularity in recent years. It has helped improve the\nperformance, reliability, and interpretability of machine learning models.\nHowever, recent literature on explainable artificial intelligence (XAI) has\nfaced criticism. The classical XAI and causality literature focuses on\nunderstanding which factors contribute to which consequences. While such\nknowledge is valuable for researchers and engineers, it is not what non-expert\nusers expect as explanations. Instead, these users often await facts that cause\nthe target consequences, i.e., actual causes. Formalizing this notion is still\nan open problem. Additionally, identifying actual causes is reportedly an\nNP-complete problem, and there are too few practical solutions to approximate\nformal definitions. We propose a set of algorithms to identify actual causes\nwith a polynomial complexity and an adjustable level of precision and\nexhaustiveness. Our experiments indicate that the algorithms (1) identify\ncauses for different categories of systems that are not handled by existing\napproaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be\nadjusted to gain more precision and exhaustiveness with more computation time.", "AI": {"tldr": "This paper introduces algorithms with polynomial complexity to identify actual causes for better interpretability in machine learning, overcoming limitations of existing approaches in non-boolean, black-box, and stochastic systems.", "motivation": "To address the limitations in current XAI and causality frameworks, which fail to provide explanations in terms of 'actual causes' that non-expert users expect, and to overcome the computational issues in identifying such causes.", "method": "Proposed a set of algorithms capable of identifying actual causes with polynomial complexity and tunable precision and exhaustiveness.", "result": "The algorithms effectively identify causes in various system types (non-boolean, black-box, stochastic) and offer adjustable precision and computational trade-offs.", "conclusion": "The proposed approach advances causal explanation in machine learning, addressing computational and practical challenges in identifying actual causes."}}
{"id": "2507.07980", "pdf": "https://arxiv.org/pdf/2507.07980", "abs": "https://arxiv.org/abs/2507.07980", "authors": ["Wanjia Fu", "Hongyu Li", "Ivy X. He", "Stefanie Tellex", "Srinath Sridhar"], "title": "UniTac: Whole-Robot Touch Sensing Without Tactile Sensors", "categories": ["cs.RO"], "comment": null, "summary": "Robots can better interact with humans and unstructured environments through\ntouch sensing. However, most commercial robots are not equipped with tactile\nskins, making it challenging to achieve even basic touch-sensing functions,\nsuch as contact localization. We present UniTac, a data-driven whole-body\ntouch-sensing approach that uses only proprioceptive joint sensors and does not\nrequire the installation of additional sensors. Our approach enables a robot\nequipped solely with joint sensors to localize contacts. Our goal is to\ndemocratize touch sensing and provide an off-the-shelf tool for HRI researchers\nto provide their robots with touch-sensing capabilities. We validate our\napproach on two platforms: the Franka robot arm and the Spot quadruped. On\nFranka, we can localize contact to within 8.0 centimeters, and on Spot, we can\nlocalize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU\nwithout adding any additional sensors to the robot. Project website:\nhttps://ivl.cs.brown.edu/research/unitac.", "AI": {"tldr": "UniTac introduces a touch-sensing approach for robots using only their proprioceptive joint sensors, allowing contact localization without any additional sensors.", "motivation": "Most commercial robots lack tactile skins, making tasks like contact localization difficult. This paper aims to democratize touch sensing for robots.", "method": "The approach utilizes data-driven models and the robot's proprioceptive joint sensors for whole-body touch-sensing. No extra sensors are added.", "result": "UniTac achieves contact localization on the Franka robot arm (8.0 cm accuracy) and the Spot quadruped (7.2 cm accuracy) at high-frequency rates (~2,000 Hz).", "conclusion": "UniTac enables affordable, effective touch-sensing capabilities for robots, benefiting HRI researchers by providing a scalable solution using existing hardware."}}
{"id": "2507.07572", "pdf": "https://arxiv.org/pdf/2507.07572", "abs": "https://arxiv.org/abs/2507.07572", "authors": ["Yupu Liang", "Yaping Zhang", "Zhiyang Zhang", "Yang Zhao", "Lu Xiang", "Chengqing Zong", "Yu Zhou"], "title": "Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted by ACL 2025 Main", "summary": "Document Image Machine Translation (DIMT) aims to translate text within\ndocument images, facing generalization challenges due to limited training data\nand the complex interplay between visual and textual information. To address\nthese challenges, we introduce M4Doc, a novel single-to-mix modality alignment\nframework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an\nimage-only encoder with the multimodal representations of an MLLM, pre-trained\non large-scale document image datasets. This alignment enables a lightweight\nDIMT model to learn crucial visual-textual correlations during training. During\ninference, M4Doc bypasses the MLLM, maintaining computational efficiency while\nbenefiting from its multimodal knowledge. Comprehensive experiments demonstrate\nsubstantial improvements in translation quality, especially in cross-domain\ngeneralization and challenging document image scenarios.", "AI": {"tldr": "This paper introduces M4Doc, a framework enhancing Document Image Machine Translation (DIMT) by aligning an image-only encoder with Multimodal Large Language Models (MLLMs) for better visual-textual understanding.", "motivation": "The paper addresses challenges in DIMT, particularly the lack of training data and the complex interplay of visual and textual information in document images.", "method": "The proposed framework, M4Doc, aligns an image-only encoder with multimodal representations from pre-trained MLLMs, enabling lightweight DIMT models to learn visual-textual correlations efficiently. During inference, MLLMs are bypassed for computational efficiency.", "result": "Comprehensive experiments showcase improved translation quality, enhanced cross-domain generalization, and better performance in handling challenging document image scenarios.", "conclusion": "M4Doc represents significant progress in DIMT by effectively combining visual-textual knowledge, offering improved generalization and efficiency without relying on MLLMs during inference."}}
{"id": "2507.07288", "pdf": "https://arxiv.org/pdf/2507.07288", "abs": "https://arxiv.org/abs/2507.07288", "authors": ["Pierre Osselin", "Masaki Adachi", "Xiaowen Dong", "Michael A. Osborne"], "title": "Natural Evolutionary Search meets Probabilistic Numerics", "categories": ["cs.LG", "cs.NE"], "comment": "8 pages, 5 figures (24 pages, 11 figures including references and\n  appendices)", "summary": "Zeroth-order local optimisation algorithms are essential for solving\nreal-valued black-box optimisation problems. Among these, Natural Evolution\nStrategies (NES) represent a prominent class, particularly well-suited for\nscenarios where prior distributions are available. By optimising the objective\nfunction in the space of search distributions, NES algorithms naturally\nintegrate prior knowledge during initialisation, making them effective in\nsettings such as semi-supervised learning and user-prior belief frameworks.\nHowever, due to their reliance on random sampling and Monte Carlo estimates,\nNES algorithms can suffer from limited sample efficiency. In this paper, we\nintroduce a novel class of algorithms, termed Probabilistic Natural\nEvolutionary Strategy Algorithms (ProbNES), which enhance the NES framework\nwith Bayesian quadrature. We show that ProbNES algorithms consistently\noutperforms their non-probabilistic counterparts as well as global sample\nefficient methods such as Bayesian Optimisation (BO) or $\\pi$BO across a wide\nrange of tasks, including benchmark test functions, data-driven optimisation\ntasks, user-informed hyperparameter tuning tasks and locomotion tasks.", "AI": {"tldr": "The paper introduces Probabilistic Natural Evolutionary Strategy (ProbNES) algorithms, combining NES with Bayesian quadrature to enhance sample efficiency.", "motivation": "To improve the sample efficiency of Natural Evolution Strategies (NES), which are limited due to their reliance on random sampling and Monte Carlo estimates.", "method": "Proposes ProbNES algorithms, integrating Bayesian quadrature into the NES framework to enhance optimization in black-box settings.", "result": "ProbNES outperforms traditional NES, Bayesian Optimization (BO), and \u03c0BO in various optimization tasks, including benchmark problems, data-driven, hyperparameter tuning, and locomotion tasks.", "conclusion": "ProbNES improves on NES by leveraging Bayesian quadrature, demonstrating superior performance and sample efficiency in several application domains."}}
{"id": "2507.07395", "pdf": "https://arxiv.org/pdf/2507.07395", "abs": "https://arxiv.org/abs/2507.07395", "authors": ["Yongtang Bao", "Chengjie Tang", "Yuze Wang", "Haojie Li"], "title": "Seg-Wild: Interactive Segmentation based on 3D Gaussian Splatting for Unconstrained Image Collections", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing and segmenting scenes from unconstrained photo collections\nobtained from the Internet is a novel but challenging task. Unconstrained photo\ncollections are easier to get than well-captured photo collections. These\nunconstrained images suffer from inconsistent lighting and transient\nocclusions, which makes segmentation challenging. Previous segmentation methods\ncannot address transient occlusions or accurately restore the scene's lighting\nconditions. Therefore, we propose Seg-Wild, an interactive segmentation method\nbased on 3D Gaussian Splatting for unconstrained image collections, suitable\nfor in-the-wild scenes. We integrate multi-dimensional feature embeddings for\neach 3D Gaussian and calculate the feature similarity between the feature\nembeddings and the segmentation target to achieve interactive segmentation in\nthe 3D scene. Additionally, we introduce the Spiky 3D Gaussian Cutter (SGC) to\nsmooth abnormal 3D Gaussians. We project the 3D Gaussians onto a 2D plane and\ncalculate the ratio of 3D Gaussians that need to be cut using the SAM mask. We\nalso designed a benchmark to evaluate segmentation quality in in-the-wild\nscenes. Experimental results demonstrate that compared to previous methods,\nSeg-Wild achieves better segmentation results and reconstruction quality. Our\ncode will be available at https://github.com/Sugar0725/Seg-Wild.", "AI": {"tldr": "The paper introduces Seg-Wild, a method leveraging 3D Gaussian Splatting for enhanced scene reconstruction and segmentation of unconstrained photo collections, addressing issues like transient occlusions and inconsistent lighting.", "motivation": "The authors aim to address the challenges involved in reconstructing and segmenting scenes from readily accessible unconstrained photo collections, which suffer from factors like inconsistent lighting and transient occlusions that hinder segmentation quality.", "method": "The proposed approach, Seg-Wild, uses interactive segmentation based on 3D Gaussian Splatting. Each 3D Gaussian has multi-dimensional feature embeddings, and a Spiky 3D Gaussian Cutter (SGC) is introduced to refine segmentation by removing abnormal projections.", "result": "Experimental evaluations demonstrate that Seg-Wild outperforms previous methods in segmentation accuracy and reconstruction quality for unconstrained photo collections.", "conclusion": "Seg-Wild effectively handles challenges such as transient occlusions and inconsistent lighting, improving segmentation and reconstruction of in-the-wild scenes gathered from the Internet. The method is validated through a newly designed benchmark and experimental comparisons."}}
{"id": "2507.07893", "pdf": "https://arxiv.org/pdf/2507.07893", "abs": "https://arxiv.org/abs/2507.07893", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qing", "Qing xu", "Kaiwen Pan", "Ting luo"], "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis", "categories": ["cs.AI"], "comment": "15 pages,3 figures", "summary": "The rapid development of artificial intelligence has positioned large\nlanguage models as fundamental components of intelligent legal systems.\nHowever, these models face significant limitations in legal dispute analysis,\nincluding insufficient legal knowledge representation, limited concept\nunderstanding, and reasoning deficiencies. This research proposes an enhanced\nframework integrating prompt engineering with multidimensional knowledge\ngraphs. The framework introduces a three-stage hierarchical prompt structure\ncomprising task definition, knowledge background, and reasoning guidance,\nsupplemented by legal-specific reasoning templates and dynamic optimization\nmechanisms. A three-layer knowledge graph architecture is constructed with\nlegal classification ontology, representation, and instance layers. Four\ncomplementary methods enable precise legal concept retrieval: direct legal norm\ncode matching, domain-specific semantic vector similarity, ontology-based path\nreasoning, and specialized lexical segmentation. These components integrate\nwith web search technology to establish a knowledge-enhanced framework for\nlegal decision-making. Experimental results demonstrate significant performance\nimprovements in legal dispute analysis, enabling accurate legal application\nanalysis for complex cases while exhibiting nuanced understanding of judicial\ndecision-making logic, providing a novel technical approach for implementing\nintelligent legal assistance systems.", "AI": {"tldr": "This paper introduces a novel framework combining prompt engineering and knowledge graphs to address limitations in legal dispute analysis by large language models, demonstrating improved performance.", "motivation": "The study aims to overcome the limitations of large language models in analyzing legal disputes, such as inadequate legal knowledge representation, shallow concept understanding, and weak reasoning capabilities.", "method": "The approach includes a three-stage hierarchical prompt structure (task definition, knowledge background, reasoning guidance) and a three-layer knowledge graph (classification ontology, representation, instance layers). It uses legal reasoning templates, dynamic optimization, and semantic retrieval methods combined with web search technologies.", "result": "Experimental results show significant improvements in analyzing legal disputes and a deeper comprehension of judicial decision-making logic for complex cases.", "conclusion": "The framework provides a breakthrough in integrating AI with legal systems, offering a robust technical pathway for developing intelligent legal assistance systems."}}
{"id": "2507.07007", "pdf": "https://arxiv.org/pdf/2507.07007", "abs": "https://arxiv.org/abs/2507.07007", "authors": ["Aral Kose", "Daniel Liberzon"], "title": "Robust signal decompositions on the circle", "categories": ["math.OC", "cs.RO"], "comment": null, "summary": "We consider the problem of decomposing a piecewise constant function on the\ncircle into a sum of indicator functions of closed circular disks in the plane,\nwhose number and location are not a priori known. This represents a situation\nwhere an agent moving on the circle is able to sense its proximity to some\nlandmarks, and the goal is to estimate the number of these landmarks and their\npossible locations -- which can in turn enable control tasks such as motion\nplanning and obstacle avoidance. Moreover, the exact values of the function at\nits discontinuities (which correspond to disk boundaries for the individual\nindicator functions) are not assumed to be known to the agent. We introduce\nsuitable notions of robustness and degrees of freedom to single out those\ndecompositions that are more desirable, or more likely, given this non-precise\ndata collected by the agent. We provide a characterization of robust\ndecompositions and give a procedure for generating all such decompositions.\nWhen the given function admits a robust decomposition, we compute the number of\npossible robust decompositions and derive bounds for the number of\ndecompositions maximizing the degrees of freedom.", "AI": {"tldr": "This paper explores decomposing a piecewise constant function into a sum of indicator functions for circular disks, addressing challenges like unknown landmark locations and robustness.", "motivation": "To enable agents on a circular path to estimate the number and location of landmarks, facilitating tasks like motion planning and obstacle avoidance.", "method": "The authors introduce concepts of robustness and degrees of freedom to analyze decompositions and provide a method for generating and characterizing robust decompositions.", "result": "The study presents a framework to characterize and compute robust decompositions, including bounds for decompositions with maximum degrees of freedom.", "conclusion": "The method provides a systematic way to handle uncertain data and compute robust decompositions, improving functionality in proximity sensing and landmark estimation."}}
{"id": "2507.07586", "pdf": "https://arxiv.org/pdf/2507.07586", "abs": "https://arxiv.org/abs/2507.07586", "authors": ["Cooper Doyle"], "title": "Bayesian Discrete Diffusion Beats Autoregressive Perplexity", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "12 pages, 2 figures, 2 tables", "summary": "We reveal a hidden Bayesian core of discrete-diffusion language models by\nshowing that the expected denoiser output under the forward masking\ndistribution recovers the exact posterior over clean tokens. Under minimal\nassumptions, Monte Carlo marginalization over K independent corruptions\nconverges to this posterior at rate O(1/sqrt(K)), yielding a simple proof of\nconsistency and finite-sample error bounds. Building on this insight, we\nintroduce a lightweight inference-time ensemble that averages K\nmask-and-denoise passes to obtain posterior-aware token probabilities and\nuncertainty estimates at no extra training cost. On WikiText-2, our method\nachieves test perplexity 8.8 with K=8, versus 20.3 for GPT-2 Small, despite\nusing a model of comparable size. Code is available at\nhttps://github.com/mercury0100/bayesradd.", "AI": {"tldr": "This paper demonstrates a Bayesian framework for discrete-diffusion language models, achieving state-of-the-art performance using an ensemble inference approach.", "motivation": "The motivation is to uncover a Bayesian interpretation of discrete-diffusion language models, enabling better token probability estimation and uncertainty quantification.", "method": "The method involves showing that the expected denoiser output under the forward masking distribution recovers the posterior over clean tokens, with Monte Carlo marginalization converging to this posterior. The authors propose an ensemble of K mask-and-denoise passes for enhanced inference.", "result": "The method achieves test perplexity of 8.8 on WikiText-2 with K=8, significantly outperforming GPT-2 Small (20.3 perplexity) using models of comparable size.", "conclusion": "The proposed Bayesian-based technique offers a lightweight, training-free refinement enabling accurate token probabilities and uncertainty estimates, resulting in improved language model performance."}}
{"id": "2507.07291", "pdf": "https://arxiv.org/pdf/2507.07291", "abs": "https://arxiv.org/abs/2507.07291", "authors": ["Paola Causin", "Alessio Marta"], "title": "Estimating Dataset Dimension via Singular Metrics under the Manifold Hypothesis: Application to Inverse Problems", "categories": ["cs.LG"], "comment": null, "summary": "High-dimensional datasets often exhibit low-dimensional geometric structures,\nas suggested by the manifold hypothesis, which implies that data lie on a\nsmooth manifold embedded in a higher-dimensional ambient space. While this\ninsight underpins many advances in machine learning and inverse problems, fully\nleveraging it requires to deal with three key tasks: estimating the intrinsic\ndimension (ID) of the manifold, constructing appropriate local coordinates, and\nlearning mappings between ambient and manifold spaces. In this work, we propose\na framework that addresses all these challenges using a Mixture of Variational\nAutoencoders (VAEs) and tools from Riemannian geometry. We specifically focus\non estimating the ID of datasets by analyzing the numerical rank of the VAE\ndecoder pullback metric. The estimated ID guides the construction of an atlas\nof local charts using a mixture of invertible VAEs, enabling accurate manifold\nparameterization and efficient inference. We how this approach enhances\nsolutions to ill-posed inverse problems, particularly in biomedical imaging, by\nenforcing that reconstructions lie on the learned manifold. Lastly, we explore\nthe impact of network pruning on manifold geometry and reconstruction quality,\nshowing that the intrinsic dimension serves as an effective proxy for\nmonitoring model capacity.", "AI": {"tldr": "The paper presents a framework using Mixture of Variational Autoencoders (VAEs) and Riemannian geometry tools to address intrinsic dimension estimation, local coordinate construction, and learning mappings in high-dimensional manifold datasets.", "motivation": "To fully exploit the low-dimensional manifolds in high-dimensional data and address intrinsic dimension estimation, local coordinate construction, and mappings, improving solutions for machine learning and inverse problems.", "method": "The framework uses Mixture of Variational Autoencoders (VAEs) to estimate intrinsic dimensions, construct local coordinates via atlas creation, and incorporate the Riemannian pullback metric for analysis.", "result": "Estimates of intrinsic dimensions via the pullback metric improve manifold parameterization, solutions to inverse problems (e.g., biomedical imaging), and enable efficient inference.", "conclusion": "The method leverages intrinsic dimensionality for better manifold learning, improving reconstruction and inference efficiency while demonstrating utility in monitor model capacity through intrinsic dimensionality."}}
{"id": "2507.07410", "pdf": "https://arxiv.org/pdf/2507.07410", "abs": "https://arxiv.org/abs/2507.07410", "authors": ["Xinan Zhang", "Muhammad Zubair Irshad", "Anthony Yezzi", "Yi-Chang Tsai", "Zsolt Kira"], "title": "EscherNet++: Simultaneous Amodal Completion and Scalable View Synthesis through Masked Fine-Tuning and Enhanced Feed-Forward 3D Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "We propose EscherNet++, a masked fine-tuned diffusion model that can\nsynthesize novel views of objects in a zero-shot manner with amodal completion\nability. Existing approaches utilize multiple stages and complex pipelines to\nfirst hallucinate missing parts of the image and then perform novel view\nsynthesis, which fail to consider cross-view dependencies and require redundant\nstorage and computing for separate stages. Instead, we apply masked fine-tuning\nincluding input-level and feature-level masking to enable an end-to-end model\nwith the improved ability to synthesize novel views and conduct amodal\ncompletion. In addition, we empirically integrate our model with other\nfeed-forward image-to-mesh models without extra training and achieve\ncompetitive results with reconstruction time decreased by 95%, thanks to its\nability to synthesize arbitrary query views. Our method's scalable nature\nfurther enhances fast 3D reconstruction. Despite fine-tuning on a smaller\ndataset and batch size, our method achieves state-of-the-art results, improving\nPSNR by 3.9 and Volume IoU by 0.28 on occluded tasks in 10-input settings,\nwhile also generalizing to real-world occluded reconstruction.", "AI": {"tldr": "EscherNet++ is a novel masked fine-tuned diffusion model designed for zero-shot novel view synthesis and amodal image completion, outperforming traditional multi-stage methods.", "motivation": "Address limitations of existing novel view synthesis approaches, such as complex pipelines and inefficient cross-view dependencies.", "method": "Apply input-level and feature-level masking for an end-to-end fine-tuned diffusion model with generalization to arbitrary query views.", "result": "Achieves state-of-the-art results, increasing PSNR by 3.9 and Volume IoU by 0.28 in occlusion tasks, while reducing reconstruction time by 95%.", "conclusion": "EscherNet++ offers a scalable and efficient solution for novel view synthesis and 3D reconstruction, enhancing practicality in real-world applications."}}
{"id": "2507.07931", "pdf": "https://arxiv.org/pdf/2507.07931", "abs": "https://arxiv.org/abs/2507.07931", "authors": ["Hans Gundlach", "Jayson Lynch", "Neil Thompson"], "title": "Meek Models Shall Inherit the Earth", "categories": ["cs.AI", "cs.CY", "I.2.0; K.4.1"], "comment": "13 pages, 9 figures, longer version of the paper presented at TAIG\n  ICML 2025", "summary": "The past decade has seen incredible scaling of AI systems by a few companies,\nleading to inequality in AI model performance. This paper argues that, contrary\nto prevailing intuition, the diminishing returns to compute scaling will lead\nto a convergence of AI model capabilities. In other words, meek models (those\nwith limited computation budget) shall inherit the earth, approaching the\nperformance level of the best models overall. We develop a model illustrating\nthat under a fixed-distribution next-token objective, the marginal capability\nreturns to raw compute shrink substantially. Given current scaling practices,\nwe argue that these diminishing returns are strong enough that even companies\nthat can scale their models exponentially faster than other organizations will\neventually have little advantage in capabilities. As part of our argument, we\ngive several reasons that proxies like training loss differences capture\nimportant capability measures using evidence from benchmark data and\ntheoretical performance models. In addition, we analyze empirical data on the\ncapability difference of AI models over time. Finally, in light of the\nincreasing ability of meek models, we argue that AI strategy and policy require\nreexamination, and we outline the areas this shift will affect.", "AI": {"tldr": "The paper argues that diminishing returns in compute scaling will lead to smaller AI models achieving similar performance as larger, resource-intensive models, with important implications for AI strategy and policy.", "motivation": "Address inequalities in AI model performance caused by the dominance of a few large companies scaling AI systems with immense computational resources.", "method": "Developed a theoretical model to show diminishing returns of compute scaling, analyzed training loss proxies, and studied benchmark and empirical data on AI capability differences over time.", "result": "Demonstrated that diminishing computational returns will diminish the performance gap between large and smaller AI models, with meek (resource-limited) models approaching the capabilities of top-tier models.", "conclusion": "Suggests a closer performance parity among AI models in the future and calls for a reevaluation of AI strategy and policy to account for these changes."}}
{"id": "2507.07630", "pdf": "https://arxiv.org/pdf/2507.07630", "abs": "https://arxiv.org/abs/2507.07630", "authors": ["Joyeeta Datta", "Niclas Doll", "Qusai Ramadan", "Zeyd Boukhers"], "title": "Exploring the Limits of Model Compression in LLMs: A Knowledge Distillation Study on QA Tasks", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted four publication at the 26th Meeting of the Special Interest\n  on Discourse and Dialogue", "summary": "Large Language Models (LLMs) have demonstrated outstanding performance across\na range of NLP tasks, however, their computational demands hinder their\ndeployment in real-world, resource-constrained environments. This work\ninvestigates the extent to which LLMs can be compressed using Knowledge\nDistillation (KD) while maintaining strong performance on Question Answering\n(QA) tasks. We evaluate student models distilled from the Pythia and Qwen2.5\nfamilies on two QA benchmarks, SQuAD and MLQA, under zero-shot and one-shot\nprompting conditions. Results show that student models retain over 90% of their\nteacher models' performance while reducing parameter counts by up to 57.1%.\nFurthermore, one-shot prompting yields additional performance gains over\nzero-shot setups for both model families. These findings underscore the\ntrade-off between model efficiency and task performance, demonstrating that KD,\ncombined with minimal prompting, can yield compact yet capable QA systems\nsuitable for resource-constrained applications.", "AI": {"tldr": "LLMs can be compressed using Knowledge Distillation (KD) while maintaining over 90% performance on QA tasks, reducing parameter counts significantly.", "motivation": "To address the computational demands of LLMs and make them deployable in resource-constrained environments.", "method": "The study applies Knowledge Distillation to compress LLMs and evaluates their performance on QA benchmarks (SQuAD and MLQA) under zero-shot and one-shot prompting.", "result": "Student models achieve over 90% performance retention and reduce parameters by up to 57.1%, with one-shot prompting showing additional performance improvements.", "conclusion": "KD is effective for creating compact and capable QA systems, demonstrating a balance between efficiency and performance for restricted-resource environments."}}
{"id": "2507.07292", "pdf": "https://arxiv.org/pdf/2507.07292", "abs": "https://arxiv.org/abs/2507.07292", "authors": ["Jacob Hauck", "Yanzhi Zhang"], "title": "Discretization-independent multifidelity operator learning for partial differential equations", "categories": ["cs.LG"], "comment": "33 pages, 9 figures, submitted to the Journal of Machine Learning\n  Research", "summary": "We develop a new and general encode-approximate-reconstruct operator learning\nmodel that leverages learned neural representations of bases for input and\noutput function distributions. We introduce the concepts of \\textit{numerical\noperator learning} and \\textit{discretization independence}, which clarify the\nrelationship between theoretical formulations and practical realizations of\noperator learning models. Our model is discretization-independent, making it\nparticularly effective for multifidelity learning. We establish theoretical\napproximation guarantees, demonstrating uniform universal approximation under\nstrong assumptions on the input functions and statistical approximation under\nweaker conditions. To our knowledge, this is the first comprehensive study that\ninvestigates how discretization independence enables robust and efficient\nmultifidelity operator learning. We validate our method through extensive\nnumerical experiments involving both local and nonlocal PDEs, including\ntime-independent and time-dependent problems. The results show that\nmultifidelity training significantly improves accuracy and computational\nefficiency. Moreover, multifidelity training further enhances empirical\ndiscretization independence.", "AI": {"tldr": "The paper introduces a discretization-independent operator learning model to improve multifidelity learning, validated by theoretical and numerical experiments.", "motivation": "Address challenges in operator learning models, aiming for robust and efficient multifidelity approaches by achieving discretization independence.", "method": "Develop a model with numerical operator learning techniques leveraging neural representations, providing theories for approximation and validation through numerical PDE experiments.", "result": "Demonstrated improved accuracy, computational efficiency, and enhanced discretization independence through multifidelity training.", "conclusion": "The proposed approach establishes a strong foundation for robust multifidelity operator learning models, suitable for diverse computational scenarios."}}
{"id": "2507.07415", "pdf": "https://arxiv.org/pdf/2507.07415", "abs": "https://arxiv.org/abs/2507.07415", "authors": ["Xinyao Yu", "Hao Sun", "Zeyu Ling", "Ziwei Niu", "Zhenjia Bai", "Rui Qin", "Yen-Wei Chen", "Lanfen Lin"], "title": "EPIC: Efficient Prompt Interaction for Text-Image Classification", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2401.14856", "summary": "In recent years, large-scale pre-trained multimodal models (LMMs) generally\nemerge to integrate the vision and language modalities, achieving considerable\nsuccess in multimodal tasks, such as text-image classification. The growing\nsize of LMMs, however, results in a significant computational cost for\nfine-tuning these models for downstream tasks. Hence, prompt-based interaction\nstrategy is studied to align modalities more efficiently. In this context, we\npropose a novel efficient prompt-based multimodal interaction strategy, namely\nEfficient Prompt Interaction for text-image Classification (EPIC).\nSpecifically, we utilize temporal prompts on intermediate layers, and integrate\ndifferent modalities with similarity-based prompt interaction, to leverage\nsufficient information exchange between modalities. Utilizing this approach,\nour method achieves reduced computational resource consumption and fewer\ntrainable parameters (about 1\\% of the foundation model) compared to other\nfine-tuning strategies. Furthermore, it demonstrates superior performance on\nthe UPMC-Food101 and SNLI-VE datasets, while achieving comparable performance\non the MM-IMDB dataset.", "AI": {"tldr": "A new prompt-based strategy, EPIC, is introduced for text-image classification, improving efficiency and reducing computational costs.", "motivation": "The rising computational cost of fine-tuning large-scale pre-trained multimodal models requires more efficient methods for aligning vision and language modalities.", "method": "EPIC employs temporal prompts on intermediate layers and utilizes similarity-based interaction to enable effective information exchange between modalities.", "result": "EPIC achieves reduced cost with only 1% of trainable parameters of the foundation model, while showing strong performance on UPMC-Food101 and SNLI-VE datasets, and comparable results on MM-IMDB.", "conclusion": "EPIC is an efficient and effective prompt-based method for addressing computational challenges in multimodal tasks."}}
{"id": "2507.07935", "pdf": "https://arxiv.org/pdf/2507.07935", "abs": "https://arxiv.org/abs/2507.07935", "authors": ["Kiran Tomlinson", "Sonia Jaffe", "Will Wang", "Scott Counts", "Siddharth Suri"], "title": "Working with AI: Measuring the Occupational Implications of Generative AI", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "comment": "40 pages", "summary": "Given the rapid adoption of generative AI and its potential to impact a wide\nrange of tasks, understanding the effects of AI on the economy is one of\nsociety's most important questions. In this work, we take a step toward that\ngoal by analyzing the work activities people do with AI, how successfully and\nbroadly those activities are done, and combine that with data on what\noccupations do those activities. We analyze a dataset of 200k anonymized and\nprivacy-scrubbed conversations between users and Microsoft Bing Copilot, a\npublicly available generative AI system. We find the most common work\nactivities people seek AI assistance for involve gathering information and\nwriting, while the most common activities that AI itself is performing are\nproviding information and assistance, writing, teaching, and advising.\nCombining these activity classifications with measurements of task success and\nscope of impact, we compute an AI applicability score for each occupation. We\nfind the highest AI applicability scores for knowledge work occupation groups\nsuch as computer and mathematical, and office and administrative support, as\nwell as occupations such as sales whose work activities involve providing and\ncommunicating information. Additionally, we characterize the types of work\nactivities performed most successfully, how wage and education correlate with\nAI applicability, and how real-world usage compares to predictions of\noccupational AI impact.", "AI": {"tldr": "This paper analyzes how generative AI assists in work activities across various occupations using data from anonymized interactions with Microsoft Bing Copilot, proposing an AI applicability score based on activity success and impact.", "motivation": "To understand the effect of generative AI on economic activities, given its widespread adoption and transformative potential across diverse tasks.", "method": "An analysis of 200k anonymized conversations with Bing Copilot to identify performed work activities, measure task success, and compute AI applicability scores for various occupations.", "result": "The study found that information gathering, writing, teaching, and advising are commonly performed AI-assisted activities, and high AI applicability scores are linked to knowledge work occupations and sales.", "conclusion": "Generative AI is most effective in assisting with knowledge-intensive and communicative tasks, with its impact varying across occupations based on task type and success."}}
{"id": "2507.07634", "pdf": "https://arxiv.org/pdf/2507.07634", "abs": "https://arxiv.org/abs/2507.07634", "authors": ["Abhinav Java", "Srivathsan Koundinyan", "Nagarajan Natarajan", "Amit Sharma"], "title": "FrugalRAG: Learning to retrieve and reason for multi-hop QA", "categories": ["cs.CL"], "comment": "Accepted at ICML Workshop: Efficient Systems for Foundation Models", "summary": "We consider the problem of answering complex questions, given access to a\nlarge unstructured document corpus. The de facto approach to solving the\nproblem is to leverage language models that (iteratively) retrieve and reason\nthrough the retrieved documents, until the model has sufficient information to\ngenerate an answer. Attempts at improving this approach focus on\nretrieval-augmented generation (RAG) metrics such as accuracy and recall and\ncan be categorized into two types: (a) fine-tuning on large question answering\n(QA) datasets augmented with chain-of-thought traces, and (b) leveraging\nRL-based fine-tuning techniques that rely on question-document relevance\nsignals. However, efficiency in the number of retrieval searches is an equally\nimportant metric, which has received less attention. In this work, we show\nthat: (1) Large-scale fine-tuning is not needed to improve RAG metrics,\ncontrary to popular claims in recent literature. Specifically, a standard ReAct\npipeline with improved prompts can outperform state-of-the-art methods on\nbenchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can help\nRAG from the perspective of frugality, i.e., the latency due to number of\nsearches at inference time. For example, we show that we can achieve\ncompetitive RAG metrics at nearly half the cost (in terms of number of\nsearches) on popular RAG benchmarks, using the same base model, and at a small\ntraining cost (1000 examples).", "AI": {"tldr": "The paper explores efficient methods of answering complex questions using retrieval-augmented generation (RAG) models, emphasizing that improved prompting can outperform more resource-intensive state-of-the-art techniques.", "motivation": "Improve the efficiency of retrieval and reasoning processes for answering complex questions using large language models, while challenging existing claims about the necessity of large-scale fine-tuning.", "method": "The authors utilized a standard ReAct pipeline with enhanced prompts and incorporated minimal supervised and RL-based fine-tuning to evaluate gains in both RAG accuracy and computational frugality.", "result": "Improved prompts outperformed state-of-the-art methods in benchmarks like HotPotQA, and the proposed approach achieved competitive RAG metrics while reducing retrieval search costs by nearly half.", "conclusion": "Large-scale fine-tuning is unnecessary for improving RAG metrics; enhanced prompts and minimal fine-tuning achieve high performance with lower computational costs."}}
{"id": "2507.07316", "pdf": "https://arxiv.org/pdf/2507.07316", "abs": "https://arxiv.org/abs/2507.07316", "authors": ["Md Abrar Jahin", "Taufikur Rahman Fuad", "M. F. Mridha", "Nafiz Fahad", "Md. Jakir Hossen"], "title": "AdeptHEQ-FL: Adaptive Homomorphic Encryption for Federated Learning of Hybrid Classical-Quantum Models with Dynamic Layer Sparing", "categories": ["cs.LG", "cs.CR"], "comment": "Accepted in 1st International Workshop on ICCV'25 BISCUIT (Biomedical\n  Image and Signal Computing for Unbiasedness, Interpretability, and\n  Trustworthiness)", "summary": "Federated Learning (FL) faces inherent challenges in balancing model\nperformance, privacy preservation, and communication efficiency, especially in\nnon-IID decentralized environments. Recent approaches either sacrifice formal\nprivacy guarantees, incur high overheads, or overlook quantum-enhanced\nexpressivity. We introduce AdeptHEQ-FL, a unified hybrid classical-quantum FL\nframework that integrates (i) a hybrid CNN-PQC architecture for expressive\ndecentralized learning, (ii) an adaptive accuracy-weighted aggregation scheme\nleveraging differentially private validation accuracies, (iii) selective\nhomomorphic encryption (HE) for secure aggregation of sensitive model layers,\nand (iv) dynamic layer-wise adaptive freezing to minimize communication\noverhead while preserving quantum adaptability. We establish formal privacy\nguarantees, provide convergence analysis, and conduct extensive experiments on\nthe CIFAR-10, SVHN, and Fashion-MNIST datasets. AdeptHEQ-FL achieves a $\\approx\n25.43\\%$ and $\\approx 14.17\\%$ accuracy improvement over Standard-FedQNN and\nFHE-FedQNN, respectively, on the CIFAR-10 dataset. Additionally, it reduces\ncommunication overhead by freezing less important layers, demonstrating the\nefficiency and practicality of our privacy-preserving, resource-aware design\nfor FL.", "AI": {"tldr": "The paper introduces AdeptHEQ-FL, a hybrid classical-quantum federated learning (FL) framework tackling challenges such as model performance, privacy, and communication efficiency.", "motivation": "To address key challenges in FL like balancing model performance, privacy, and communication efficiency, especially in non-IID decentralized setups, and integrate quantum computing capabilities.", "method": "The framework combines hybrid CNN-PQC architecture, adaptive accuracy-weighted aggregation using differentially private techniques, selective homomorphic encryption for sensitive layers, and dynamic layer-wise adaptive freezing.", "result": "Achieved 25.43% and 14.17% accuracy improvements compared to Standard-FedQNN and FHE-FedQNN on CIFAR-10. It also reduced communication overhead through layer-freezing strategies.", "conclusion": "AdeptHEQ-FL showcases efficiency in balancing performance, privacy, and resource utilization, making it a versatile and practical approach for FL."}}
{"id": "2507.07424", "pdf": "https://arxiv.org/pdf/2507.07424", "abs": "https://arxiv.org/abs/2507.07424", "authors": ["Jingjing Jiang", "Chao Ma", "Xurui Song", "Hanwang Zhang", "Jun Luo"], "title": "Corvid: Improving Multimodal Large Language Models Towards Chain-of-Thought Reasoning", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "Recent advancements in multimodal large language models (MLLMs) have\ndemonstrated exceptional performance in multimodal perception and\nunderstanding. However, leading open-source MLLMs exhibit significant\nlimitations in complex and structured reasoning, particularly in tasks\nrequiring deep reasoning for decision-making and problem-solving. In this work,\nwe present Corvid, an MLLM with enhanced chain-of-thought (CoT) reasoning\ncapabilities. Architecturally, Corvid incorporates a hybrid vision encoder for\ninformative visual representation and a meticulously designed connector\n(GateMixer) to facilitate cross-modal alignment. To enhance Corvid's CoT\nreasoning capabilities, we introduce MCoT-Instruct-287K, a high-quality\nmultimodal CoT instruction-following dataset, refined and standardized from\ndiverse public reasoning sources. Leveraging this dataset, we fine-tune Corvid\nwith a two-stage CoT-formatted training approach to progressively enhance its\nstep-by-step reasoning abilities. Furthermore, we propose an effective\ninference-time scaling strategy that enables Corvid to mitigate over-reasoning\nand under-reasoning through self-verification. Extensive experiments\ndemonstrate that Corvid outperforms existing o1-like MLLMs and state-of-the-art\nMLLMs with similar parameter scales, with notable strengths in mathematical\nreasoning and science problem-solving. Project page:\nhttps://mm-vl.github.io/corvid.", "AI": {"tldr": "This paper introduces Corvid, an MLLM designed to address limitations in complex reasoning by integrating a hybrid vision encoder and an advanced CoT training method, achieving superior performance in reasoning tasks.", "motivation": "Current MLLMs face challenges in complex reasoning, especially in decision-making and problem-solving tasks; the study aims to enhance these reasoning capabilities.", "method": "The authors developed Corvid by incorporating a hybrid vision encoder, a GateMixer for cross-modal alignment, a new CoT instruction-following dataset (MCoT-Instruct-287K), and a two-stage training process to boost reasoning. They also introduced an inference-time scaling strategy to balance reasoning levels.", "result": "Corvid outperforms existing open-source MLLMs and state-of-the-art models with similar parameter scales, particularly excelling in mathematical reasoning and science problem-solving.", "conclusion": "Corvid represents a significant advancement in MLLMs by improving structured reasoning capabilities through architectural innovations, enhanced datasets, and fine-tuned training approaches, potentially broadening the applicability of MLLMs in complex multimodal tasks."}}
{"id": "2506.13201", "pdf": "https://arxiv.org/pdf/2506.13201", "abs": "https://arxiv.org/abs/2506.13201", "authors": ["Wenfeng Jia", "Bin Liang", "Yuxi Liu", "Muhammad Arif Khan", "Lihong Zheng"], "title": "A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Flooding remains a major global challenge, worsened by climate change and\nurbanization, demanding advanced solutions for effective disaster management.\nWhile traditional 2D flood mapping techniques provide limited insights, 3D\nflood mapping, powered by deep learning (DL), offers enhanced capabilities by\nintegrating flood extent and depth. This paper presents a comprehensive survey\nof deep learning-based 3D flood mapping, emphasizing its advancements over 2D\nmaps by integrating flood extent and depth for effective disaster management\nand urban planning. The survey categorizes deep learning techniques into task\ndecomposition and end-to-end approaches, applicable to both static and dynamic\nflood features. We compare key DL architectures, highlighting their respective\nroles in enhancing prediction accuracy and computational efficiency.\nAdditionally, this work explores diverse data sources such as digital elevation\nmodels, satellite imagery, rainfall, and simulated data, outlining their roles\nin 3D flood mapping. The applications reviewed range from real-time flood\nprediction to long-term urban planning and risk assessment. However,\nsignificant challenges persist, including data scarcity, model\ninterpretability, and integration with traditional hydrodynamic models. This\nsurvey concludes by suggesting future directions to address these limitations,\nfocusing on enhanced datasets, improved models, and policy implications for\nflood management. This survey aims to guide researchers and practitioners in\nleveraging DL techniques for more robust and reliable 3D flood mapping,\nfostering improved flood management strategies.", "AI": {"tldr": "This paper surveys deep learning-based 3D flood mapping, contrasting it with traditional 2D approaches, and emphasizes advancements in accuracy and applications for disaster management.", "motivation": "Flooding is a worsening global issue due to climate change and urbanization, necessitating advanced solutions such as 3D flood mapping to enhance disaster management.", "method": "The paper categorizes deep learning techniques into task decomposition and end-to-end approaches, evaluates architectures for accuracy and efficiency, and examines diverse data sources like DEMs, satellite imagery, and rainfall for 3D flood mapping.", "result": "Key progress and challenges are reviewed, demonstrating how deep learning improves prediction accuracy and computational efficiency but faces issues like data scarcity and model interpretability.", "conclusion": "The paper suggests future directions, such as developing better datasets and models, and emphasizes how deep learning in 3D flood mapping can contribute to improved policy and flood management strategies."}}
{"id": "2507.07550", "pdf": "https://arxiv.org/pdf/2507.07550", "abs": "https://arxiv.org/abs/2507.07550", "authors": ["Marianne Bossema", "Rob Saunders", "Aske Plaat", "Somaya Ben Allouch"], "title": "Pluri-perspectivism in Human-robot Co-creativity with Older Adults", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "This position paper explores pluriperspectivism as a core element of human\ncreative experience and its relevance to humanrobot cocreativity We propose a\nlayered fivedimensional model to guide the design of cocreative behaviors and\nthe analysis of interaction dynamics This model is based on literature and\nresults from an interview study we conducted with 10 visual artists and 8 arts\neducators examining how pluriperspectivism supports creative practice The\nfindings of this study provide insight in how robots could enhance human\ncreativity through adaptive contextsensitive behavior demonstrating the\npotential of pluriperspectivism This paper outlines future directions for\nintegrating pluriperspectivism with visionlanguage models VLMs to support\ncontext sensitivity in cocreative robots", "AI": {"tldr": "The paper investigates how the concept of pluriperspectivism can enhance human-robot cocreation, presenting a five-dimensional model informed by artist interviews.", "motivation": "To explore how the principle of pluriperspectivism\u2014a core aspect of human creativity\u2014can inform and improve human-robot cocreation.", "method": "A five-dimensional model was proposed based on literature review and interviews with 10 visual artists and 8 art educators, analyzing how pluriperspectivism aids creative practice.", "result": "The study revealed ways robots could potentially enhance human creativity through adaptive, context-sensitive behavior informed by pluriperspectivism.", "conclusion": "Pluriperspectivism holds promise for enhancing cocreative experiences between humans and robots, and future integration with vision-language models (VLMs) could further support this goal."}}
