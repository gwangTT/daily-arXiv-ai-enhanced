{"id": "2506.23672", "pdf": "https://arxiv.org/pdf/2506.23672", "abs": "https://arxiv.org/abs/2506.23672", "authors": ["Sergio Mazzola", "Gabriele Ara", "Thomas Benz", "Bj\u00f6rn Forsberg", "Tommaso Cucinotta", "Luca Benini"], "title": "Data-Driven Power Modeling and Monitoring via Hardware Performance Counter Tracking", "categories": ["cs.PF", "cs.AR"], "comment": "Published on Journal of Systems Architecture (JSA), here:\n  https://doi.org/10.1016/j.sysarc.2025.103504 Extension of conference paper\n  https://doi.org/10.1007/978-3-031-15074-6_22 (SAMOS 2022)", "summary": "Energy-centric design is paramount in the current embedded computing era: use\ncases require increasingly high performance at an affordable power budget,\noften under real-time constraints. Hardware heterogeneity and parallelism help\naddress the efficiency challenge, but greatly complicate online power\nconsumption assessments, which are essential for dynamic hardware and software\nstack adaptations. We introduce a novel power modeling methodology with\nstate-of-the-art accuracy, low overhead, and high responsiveness, whose\nimplementation does not rely on microarchitectural details. Our methodology\nidentifies the Performance Monitoring Counters (PMCs) with the highest linear\ncorrelation to the power consumption of each hardware sub-system, for each\nDynamic Voltage and Frequency Scaling (DVFS) state. The individual, simple\nmodels are composed into a complete model that effectively describes the power\nconsumption of the whole system, achieving high accuracy and low overhead. Our\nevaluation reports an average estimation error of 7.5% for power consumption\nand 1.3% for energy. We integrate these models in the Linux kernel with\nRunmeter, an open-source, PMC-based monitoring framework. Runmeter manages PMC\nsampling and processing, enabling the execution of our power models at runtime.\nWith a worst-case time overhead of only 0.7%, Runmeter provides responsive and\naccurate power measurements directly in the kernel. This information can be\nemployed for actuation policies in workload-aware DVFS and power-aware,\nclosed-loop task scheduling.", "AI": {"tldr": "The paper introduces a novel power modeling methodology for heterogeneous hardware systems, achieving high accuracy (7.5% error for power, 1.3% for energy) with minimal runtime overhead (0.7%). The models are integrated into a Linux kernel-based framework for real-time power measurements.", "motivation": "The need for energy-efficient designs in embedded systems under real-time constraints, compounded by the challenges posed by hardware heterogeneity and parallelism.", "method": "Simple, state-specific power models based on Performance Monitoring Counters (PMCs) are developed and combined into a comprehensive framework integrated into the Linux kernel using the Runmeter monitoring tool.", "result": "The approach achieves state-of-the-art power and energy estimation accuracy with negligible runtime overhead, enabling responsive real-time measurements.", "conclusion": "This methodology facilitates dynamic adaptations in hardware and software stacks, improving workload-aware DVFS and closed-loop task scheduling in power-constrained systems."}}
{"id": "2506.23717", "pdf": "https://arxiv.org/pdf/2506.23717", "abs": "https://arxiv.org/abs/2506.23717", "authors": ["Xingting Yao", "Qinghao Hu", "Fei Zhou", "Tielong Liu", "Gang Li", "Peisong Wang", "Jian Cheng"], "title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-bit spiking neural networks (SNNs) have recently become a heated\nresearch spot, pursuing energy-efficient and high-accurate AI. However, with\nmore bits involved, the associated memory and computation demands escalate to\nthe point where the performance improvements become disproportionate. Based on\nthe insight that different layers demonstrate different importance and extra\nbits could be wasted and interfering, this paper presents an adaptive bit\nallocation strategy for direct-trained SNNs, achieving fine-grained layer-wise\nallocation of memory and computation resources. Thus, SNN's efficiency and\naccuracy can be improved. Specifically, we parametrize the temporal lengths and\nthe bit widths of weights and spikes, and make them learnable and controllable\nthrough gradients. To address the challenges caused by changeable bit widths\nand temporal lengths, we propose the refined spiking neuron, which can handle\ndifferent temporal lengths, enable the derivation of gradients for temporal\nlengths, and suit spike quantization better. In addition, we theoretically\nformulate the step-size mismatch problem of learnable bit widths, which may\nincur severe quantization errors to SNN, and accordingly propose the step-size\nrenewal mechanism to alleviate this issue. Experiments on various datasets,\nincluding the static CIFAR and ImageNet and the dynamic CIFAR-DVS and\nDVS-GESTURE, demonstrate that our methods can reduce the overall memory and\ncomputation cost while achieving higher accuracy. Particularly, our\nSEWResNet-34 can achieve a 2.69\\% accuracy gain and 4.16$\\times$ lower bit\nbudgets over the advanced baseline work on ImageNet. This work will be fully\nopen-sourced.", "AI": {"tldr": "The paper proposes a novel adaptive bit allocation strategy for spiking neural networks (SNNs) to enhance efficiency and accuracy by dynamically tuning bit widths and temporal lengths in a layer-wise fashion.", "motivation": "To overcome the rising memory and computational demands in multi-bit SNNs, the study aims to allocate resources more effectively by leveraging the varying importance of layers, thus avoiding inefficiencies.", "method": "The authors introduce a parametric approach where bit widths of weights/spikes and temporal lengths are learnable through gradients. A refined spiking neuron is proposed to address challenges of variable bit widths and temporal lengths, along with a step-size renewal mechanism to mitigate quantization errors.", "result": "The approach demonstrates enhanced efficiency and accuracy on static datasets (CIFAR, ImageNet) and dynamic datasets (CIFAR-DVS, DVS-GESTURE), achieving up to 2.69% accuracy improvement and 4.16\u00d7 lower bit usage compared to baselines on ImageNet.", "conclusion": "The adaptive bit allocation strategy significantly improves resource allocation and quantization efficiency in SNNs without compromising accuracy, marking a step forward in energy-efficient AI solutions."}}
{"id": "2506.22654", "pdf": "https://arxiv.org/pdf/2506.22654", "abs": "https://arxiv.org/abs/2506.22654", "authors": ["Guy Wilks", "Brian Li", "Jonathan Balkind"], "title": "Oobleck: Low-Compromise Design for Fault Tolerant Accelerators", "categories": ["cs.AR"], "comment": null, "summary": "Data center hardware refresh cycles are lengthening. However, increasing\nprocessor complexity is raising the potential for faults. To achieve longevity\nin the face of increasingly fault-prone datapaths, fault tolerance is needed,\nespecially in on-chip accelerator datapaths. Previously researched methods for\nadding fault tolerance to accelerator designs require high area, lowering chip\nutilisation. We propose a novel architecture for accelerator fault tolerance,\nOobleck, which leverages modular acceleration to enable fault tolerance without\nburdensome area requirements.\n  In order to streamline the development and enforce modular conventions, we\nintroduce the Viscosity language, an actor based approach to hardware-software\nco-design. Viscosity uses a single description of the accelerator's function\nand produces both hardware and software descriptions.\n  Our high-level models of data centers indicate that our approach can decrease\nthe number of failure-induced chip purchases inside data centers while not\naffecting aggregate throughput, thus reducing data center costs. To show the\nfeasibility of our approach, we show three case-studies: FFT, AES, and DCT\naccelerators. We additionally profile the performance under the key parameters\naffecting latency. Under a single fault we can maintain speedups of between\n1.7x-5.16x for accelerated applications over purely software implementations.\nWe show further benefits can be achieved by adding hot-spare FPGAs into the\nchip.", "AI": {"tldr": "The paper introduces Oobleck, a fault-tolerant accelerator architecture, and Viscosity language for efficient hardware-software co-design, reducing costs and improving reliability in data centers.", "motivation": "Data center refresh cycles are lengthening, while increasing processor complexity leads to heightened fault risks in accelerator datapaths. Existing fault tolerance solutions incur high area costs.", "method": "The paper proposes Oobleck, a modular fault-tolerant accelerator architecture, and Viscosity, an actor-based hardware-software co-design language. It also provides case studies and model analysis.", "result": "Oobleck decreases failure-induced chip purchases without lowering aggregate throughput in data centers. Case studies show significant speedups (1.7x-5.16x) over software-only implementations under faults.", "conclusion": "Oobleck and Viscosity offer a practical, cost-effective solution to fault tolerance in accelerator chips, showing promise in maintaining reliability and throughput in modern data centers."}}
{"id": "2506.23058", "pdf": "https://arxiv.org/pdf/2506.23058", "abs": "https://arxiv.org/abs/2506.23058", "authors": ["Nikolaj Hey Hinnerskov", "Robert Schenck", "Cosmin E. Oancea"], "title": "Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "This paper presents a novel approach to automatically verify properties of\npure data-parallel programs with non-linear indexing -- expressed as pre- and\npost-conditions on functions. Programs consist of nests of second-order array\ncombinators (e.g., map, scan, and scatter) and loops. The key idea is to\nrepresent arrays as index functions: programs are index function\ntransformations over which properties are propagated and inferred. Our\nframework proves properties on index functions by distilling them into\nalgebraic (in)equalities and discharging them to a Fourier-Motzkin-based\nsolver. The framework is practical and accessible: properties are not\nrestricted to a decidable logic, but instead are carefully selected to express\npractically useful guarantees that can be automatically reasoned about and\ninferred. These guarantees extend beyond program correctness and can be\nexploited by the entire compiler pipeline for optimization. We implement our\nsystem in the pure data-parallel language Futhark and demonstrate its\npracticality on seven applications, reporting an average verification time of 1\nsecond. Two case studies show how eliminating dynamic verification in GPU\nprograms results in significant speedups.", "AI": {"tldr": "The paper introduces a method for verifying properties of data-parallel programs using index functions and algebraic reasoning, enabling optimizations and correctness guarantees.", "motivation": "Existing techniques struggle to verify properties of data-parallel programs with non-linear indexing, which hampers optimization and correctness.", "method": "Programs are treated as index function transformations. Properties are proved by converting them into algebraic inequalities and solving them using a Fourier-Motzkin-based approach.", "result": "Implementation in Futhark verifies properties in an average time of 1 second for seven applications. Case studies show significant GPU speedups due to reduced dynamic verification.", "conclusion": "The approach is practical, enabling automated, meaningful program guarantees that enhance correctness and compiler optimization without restricting expressiveness."}}
{"id": "2506.22714", "pdf": "https://arxiv.org/pdf/2506.22714", "abs": "https://arxiv.org/abs/2506.22714", "authors": ["Jinliang Shi", "Shigang Li", "Youxuan Xu", "Xueying Wang", "Rongtian Fu", "Zhi Ma", "Tong Wu"], "title": "Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication", "categories": ["cs.DC", "cs.LG", "cs.PF", "C.1.4; I.2.11"], "comment": null, "summary": "Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used\nin deep learning and scientific computing. Modern accelerators are commonly\nequipped with Tensor cores and CUDA cores to accelerate sparse operators. The\nformer brings superior computing power but only for structured matrix\nmultiplication, while the latter has relatively lower performance but with\nhigher programming flexibility. In this work, we discover that utilizing one\nresource alone leads to inferior performance for sparse matrix multiplication,\ndue to their respective limitations. To this end, we propose Libra, a\nsystematic approach that enables synergistic computation between CUDA and\nTensor cores to achieve the best performance for sparse matrix multiplication.\nSpecifically, we propose a 2D-aware workload distribution strategy to find out\nthe sweet point of task mapping for different sparse operators, leveraging both\nthe high performance of Tensor cores and the low computational redundancy on\nCUDA cores. In addition, Libra incorporates systematic optimizations for\nheterogeneous computing, including hybrid load-balancing, finely optimized\nkernel implementations, and GPU-accelerated preprocessing. Extensive\nexperimental results on H100 and RTX 4090 GPUs show that Libra outperforms the\nstate-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to\n3.9x) for end-to-end GNN applications. Libra opens up a new perspective for\nsparse operator acceleration by fully exploiting the heterogeneous computing\nresources on GPUs.", "AI": {"tldr": "The paper introduces Libra, a system that improves sparse matrix multiplication (SpMM and SDDMM) using a combination of CUDA and Tensor cores for superior performance.", "motivation": "Sparse matrix multiplication is critical in deep learning and scientific computing, but existing approaches underutilize GPU hardware resources, leading to inefficiencies.", "method": "Libra uses a 2D-aware workload distribution strategy to optimize task mapping between CUDA and Tensor cores. It includes optimizations such as hybrid load-balancing, optimized kernel implementations, and GPU-accelerated preprocessing.", "result": "Experimental results on H100 and RTX 4090 GPUs show a 3.1x average performance improvement (up to 9.23x) over DTC-SpMM and a 2.9x improvement (up to 3.9x) for GNN applications.", "conclusion": "Libra exploits heterogeneous computing resources on GPUs effectively, providing a new perspective on accelerating sparse matrix operations."}}
{"id": "2506.22951", "pdf": "https://arxiv.org/pdf/2506.22951", "abs": "https://arxiv.org/abs/2506.22951", "authors": ["Ramiro Pl\u00fcss", "Hern\u00e1n Villota", "Patricio Orio"], "title": "Hemispheric-Specific Coupling Improves Modeling of Functional Connectivity Using Wilson-Cowan Dynamics", "categories": ["q-bio.NC", "nlin.CD"], "comment": "13 pages, 7 figures", "summary": "Large-scale neural mass models have been widely used to simulate\nresting-state brain activity from structural connectivity. In this work, we\nextend a well-established Wilson--Cowan framework by introducing a novel\nhemispheric-specific coupling scheme that differentiates between\nintra-hemispheric and inter-hemispheric structural interactions. We apply this\nmodel to empirical cortical connectomes and resting-state fMRI data from\nmatched control and schizophrenia groups. Simulated functional connectivity is\ncomputed from the band-limited envelope correlations of regional excitatory\nactivity and compared against empirical functional connectivity matrices. Our\nresults show that incorporating hemispheric asymmetries enhances the\ncorrelation between simulated and empirical functional connectivity,\nhighlighting the importance of anatomically-informed coupling strategies in\nimproving the biological realism of large-scale brain network models.", "AI": {"tldr": "The paper introduces a hemispheric-specific coupling scheme to the Wilson-Cowan model and demonstrates improved alignment between simulated and empirical brain connectivity.", "motivation": "To improve the biological accuracy of large-scale brain network models by addressing hemispheric asymmetries in structural connectivity.", "method": "Using the Wilson-Cowan model, the authors introduced hemispheric-specific coupling to differentiate between intra- and inter-hemispheric structural connections. They applied the model to empirical cortical connectomes and fMRI data from both control and schizophrenia groups.", "result": "The hemispheric-asymmetric coupling approach improved the correlation between simulated and empirical functional connectivity data.", "conclusion": "Hemispheric-specific coupling enhances the anatomical realism of large-scale neural mass models, demonstrating its importance in understanding brain connectivity."}}
{"id": "2506.22656", "pdf": "https://arxiv.org/pdf/2506.22656", "abs": "https://arxiv.org/abs/2506.22656", "authors": ["Jiangping Huang", "Dongming Jin", "Weisong Sun", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision", "categories": ["cs.SE", "cs.AI", "68-04", "D.2.3; I.2.7"], "comment": null, "summary": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for\nautomated requirements development. KGMAF aims to address gaps in current\nautomation systems for SE, which prioritize code development and overlook the\ncomplexities of requirements tasks. KGMAF is composed of six specialized agents\nand an artifact pool to improve efficiency and accuracy. Specifically, KGMAF\noutlines the functionality, actions, and knowledge of each agent and provides\nthe conceptual design of the artifact pool. Our case study highlights the\npotential of KGMAF in real-world scenarios. Finally, we outline several\nresearch opportunities for implementing and enhancing automated requirements\ndevelopment using multi-agent systems. We believe that KGMAF will play a\npivotal role in shaping the future of automated requirements development in the\nera of LLMs.", "AI": {"tldr": "A multi-agent framework, KGMAF, is proposed to improve automated requirements development by addressing current gaps in software engineering.", "motivation": "Current automation systems in software engineering neglect the complexities of requirements tasks and focus heavily on code development.", "method": "The authors propose KGMAF, a framework consisting of six specialized agents and an artifact pool, defining the operations, knowledge, and design of these components.", "result": "The case study demonstrates KGMAF's practical applicability and potential impact in real-world scenarios.", "conclusion": "KGMAF could significantly enhance automated requirements development and open new research opportunities, especially in the context of LLMs."}}
{"id": "2506.22439", "pdf": "https://arxiv.org/pdf/2506.22439", "abs": "https://arxiv.org/abs/2506.22439", "authors": ["Javier Conde", "Miguel Gonz\u00e1lez", "Mar\u00eda Grandury", "Gonzalo Mart\u00ednez", "Pedro Reviriego", "Mar Brysbaert"], "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for the GEM2 workshop at ACL 2025", "summary": "The evaluation of LLMs has so far focused primarily on how well they can\nperform different tasks such as reasoning, question-answering, paraphrasing, or\ntranslating. For most of these tasks, performance can be measured with\nobjective metrics, such as the number of correct answers. However, other\nlanguage features are not easily quantified. For example, arousal,\nconcreteness, or gender associated with a given word, as well as the extent to\nwhich we experience words with senses and relate them to a specific sense.\nThose features have been studied for many years by psycholinguistics,\nconducting large-scale experiments with humans to produce ratings for thousands\nof words. This opens an opportunity to evaluate how well LLMs align with human\nratings on these word features, taking advantage of existing studies that cover\nmany different language features in a large number of words. In this paper, we\nevaluate the alignment of a representative group of LLMs with human ratings on\ntwo psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets\ncover thirteen features over thousands of words. The results show that\nalignment is \\textcolor{black}{generally} better in the Glasgow norms evaluated\n(arousal, valence, dominance, concreteness, imageability, familiarity, and\ngender) than on the Lancaster norms evaluated (introceptive, gustatory,\nolfactory, haptic, auditory, and visual). This suggests a potential limitation\nof current LLMs in aligning with human sensory associations for words, which\nmay be due to their lack of embodied cognition present in humans and\nillustrates the usefulness of evaluating LLMs with psycholinguistic datasets.", "AI": {"tldr": "This study evaluates how well large language models (LLMs) align with human ratings on psycholinguistic word features using Glasgow and Lancaster norms datasets, revealing stronger alignment with the former and emphasizing limitations in sensory associations.", "motivation": "To explore the alignment of LLMs with human psycholinguistic ratings on word features, leveraging existing norms datasets, and to identify potential limitations in current models.", "method": "The paper evaluates a group of representative LLMs against human ratings across 13 psycholinguistic features contained in the Glasgow and Lancaster norms datasets, covering thousands of words.", "result": "The analysis found that LLMs generally align better with the Glasgow norms (e.g., arousal, valence, dominance) than the Lancaster norms (e.g., sensory associations like auditory and visual). This highlights a gap in sensory alignment likely due to the lack of embodied cognition in LLMs.", "conclusion": "LLMs exhibit better alignment for abstract and emotional word features (Glasgow norms) but struggle with sensory-associated ones (Lancaster norms), underscoring the need for improvement in their handling of embodied cognition aspects."}}
{"id": "2506.22466", "pdf": "https://arxiv.org/pdf/2506.22466", "abs": "https://arxiv.org/abs/2506.22466", "authors": ["Marcel Heisler", "Christian Becker-Asano"], "title": "Conversations with Andrea: Visitors' Opinions on Android Robots in a Museum", "categories": ["cs.RO", "cs.CY", "I.2.9; I.2.7"], "comment": "To be published in IEEE RO-MAN 2025 conference proceedings; for\n  videos check https://ai.hdm-stuttgart.de/humanoid-lab", "summary": "The android robot Andrea was set up at a public museum in Germany for six\nconsecutive days to have conversations with visitors, fully autonomously. No\nspecific context was given, so visitors could state their opinions regarding\npossible use-cases in structured interviews, without any bias. Additionally the\n44 interviewees were asked for their general opinions of the robot, their\nreasons (not) to interact with it and necessary improvements for future use.\nThe android's voice and wig were changed between different days of operation to\ngive varying cues regarding its gender. This did not have a significant impact\non the positive overall perception of the robot. Most visitors want the robot\nto provide information about exhibits in the future, while opinions on other\nroles, like a receptionist, were both wanted and explicitly not wanted by\ndifferent visitors. Speaking more languages (than only English) and faster\nresponse times were the improvements most desired. These findings from the\ninterviews are in line with an analysis of the system logs, which revealed,\nthat after chitchat and personal questions, most of the 4436 collected requests\nasked for information related to the museum and to converse in a different\nlanguage. The valuable insights gained from these real-world interactions are\nnow used to improve the system to become a useful real-world application.", "AI": {"tldr": "An autonomous android robot, Andrea, had conversations with museum visitors in Germany over six days, gathering opinions about its use-cases, general perceptions, and improvement suggestions. Gender cues via voice and wig changes showed no significant impact on visitor perception.", "motivation": "Explore real-world visitor interactions with an autonomous android robot to understand possible use-cases and gather feedback for system improvement.", "method": "Set up Andrea in a public museum for fully autonomous interactions with visitors across six days, using structured interviews and analyzing system logs.", "result": "Visitor feedback showed positive overall perception. Desired improvements included multilingual support, quicker responses, and museum-related information provision. Gender cue changes did not significantly affect perceptions.", "conclusion": "Insights from real-world interactions will guide improvements to make Andrea a practical, useful application in public settings like museums."}}
{"id": "2506.22604", "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "categories": ["cs.AI", "cs.HC", "cs.RO"], "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance.", "AI": {"tldr": "This paper explores combining natural language programming with drag-and-drop interfaces using large language models (LLMs) to generate human-like robot task sequences.", "motivation": "Robot end users need accessible ways to specify robot tasks. Combining intuitive natural language programming with precise drag-and-drop interfaces could enhance task specification.", "method": "The authors developed an LLM-based pipeline that takes natural language input and generates action sequences with human-like granularity, then compared these sequences to hand-specified ones.", "result": "Larger LLMs performed better at generating human-like action sequences, but smaller models also provided satisfactory results.", "conclusion": "Integrating natural language processing and drag-and-drop interfaces using LLMs is promising, with larger models yielding superior outcomes."}}
{"id": "2506.22536", "pdf": "https://arxiv.org/pdf/2506.22536", "abs": "https://arxiv.org/abs/2506.22536", "authors": ["Yu Zhang", "Shanshan Zhao", "Bokui Wan", "Jinjuan Wang", "Xiaodong Yan"], "title": "Strategic A/B testing via Maximum Probability-driven Two-armed Bandit", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "25 pages, 14 figures", "summary": "Detecting a minor average treatment effect is a major challenge in\nlarge-scale applications, where even minimal improvements can have a\nsignificant economic impact. Traditional methods, reliant on normal\ndistribution-based or expanded statistics, often fail to identify such minor\neffects because of their inability to handle small discrepancies with\nsufficient sensitivity. This work leverages a counterfactual outcome framework\nand proposes a maximum probability-driven two-armed bandit (TAB) process by\nweighting the mean volatility statistic, which controls Type I error. The\nimplementation of permutation methods further enhances the robustness and\nefficacy. The established strategic central limit theorem (SCLT) demonstrates\nthat our approach yields a more concentrated distribution under the null\nhypothesis and a less concentrated one under the alternative hypothesis,\ngreatly improving statistical power. The experimental results indicate a\nsignificant improvement in the A/B testing, highlighting the potential to\nreduce experimental costs while maintaining high statistical power.", "AI": {"tldr": "This paper proposes an innovative two-armed bandit approach to improve the detection of minor average treatment effects, leveraging counterfactual frameworks and strategic permutation methods for enhanced statistical power.", "motivation": "Traditional methods struggle to detect minor treatment effects in large-scale applications, limiting sensitivity and failing to address small discrepancies effectively.", "method": "This approach introduces a maximum probability-driven two-armed bandit process using weighted mean volatility statistics and permutation methods, designed to control Type I error and employ central limit theorem strategies for improved null and alternative hypothesis distributions.", "result": "The experimental results show improved A/B testing efficiency, significantly enhancing statistical power while reducing experimental costs.", "conclusion": "The methodology provides a robust solution for detecting minor effects with high statistical power, paving the way for more cost-effective and accurate large-scale applications."}}
{"id": "2506.22441", "pdf": "https://arxiv.org/pdf/2506.22441", "abs": "https://arxiv.org/abs/2506.22441", "authors": ["Lei Yang"], "title": "Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Intelligent transportation systems (ITS) rely heavily on complete and\nhigh-quality spatiotemporal traffic data to achieve optimal performance.\nNevertheless, in real-word traffic data collection processes, issues such as\ncommunication failures and sensor malfunctions often lead to incomplete or\ncorrupted datasets, thereby posing significant challenges to the advancement of\nITS. Among various methods for imputing missing spatiotemporal traffic data,\nthe latent factorization of tensors (LFT) model has emerged as a widely adopted\nand effective solution. However, conventional LFT models typically employ the\nstandard L2-norm in their learning objective, which makes them vulnerable to\nthe influence of outliers. To overcome this limitation, this paper proposes a\nthreshold distance weighted (TDW) loss-incorporated Latent Factorization of\nTensors (TDWLFT) model. The proposed loss function effectively reduces the\nmodel's sensitivity to outliers by assigning differentiated weights to\nindividual samples. Extensive experiments conducted on two traffic speed\ndatasets sourced from diverse urban environments confirm that the proposed\nTDWLFT model consistently outperforms state-of-the-art approaches in terms of\nboth in both prediction accuracy and computational efficiency.", "AI": {"tldr": "The paper introduces a robust tensor factorization method (TDWLFT model) for imputing missing spatiotemporal traffic data that accounts for outliers using a unique loss function.", "motivation": "Challenges in incomplete and corrupted datasets hinder the optimal functioning of ITS due to sensor malfunctions and communication failures during traffic data collection.", "method": "A novel TDWLFT model incorporating a threshold distance weighted loss function to handle outliers in tensor factorization.", "result": "Experiments demonstrated superior performance of TDWLFT over state-of-the-art methods in prediction accuracy and computational efficiency across two urban traffic speed datasets.", "conclusion": "TDWLFT effectively addresses missing data problems in ITS by being robust to outliers, improving both data reliability and system efficiency."}}
{"id": "2506.22437", "pdf": "https://arxiv.org/pdf/2506.22437", "abs": "https://arxiv.org/abs/2506.22437", "authors": ["Xinxin Sun", "Peter Chang"], "title": "Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring", "categories": ["cs.CV", "68T45 (Computer Vision)"], "comment": "43 pages, 5 figures, 19 tables. Submitted to NDT&E International.\n  This work may also be of interest to researchers in optical NDE and civil\n  engineering SHM", "summary": "Accurate image alignment is essential for monitoring crack evolution in\nstructural health monitoring (SHM), particularly under real-world conditions\ninvolving perspective distortion, occlusion, and low contrast. However,\ntraditional feature detectors such as SIFT and SURF, which rely on\nGaussian-based scale spaces, tend to suppress high-frequency edges, making them\nunsuitable for thin crack localization. Lightweight binary alternatives like\nORB and BRISK, while computationally efficient, often suffer from poor keypoint\nrepeatability on textured or shadowed surfaces. This study presents a\nphysics-informed alignment framework that adapts the open KAZE architecture to\nSHM-specific challenges. By utilizing nonlinear anisotropic diffusion to\nconstruct a crack-preserving scale space, and integrating RANSAC-based\nhomography estimation, the framework enables accurate geometric correction\nwithout the need for training, parameter tuning, or prior calibration. The\nmethod is validated on time-lapse images of masonry and concrete acquired via\nhandheld smartphone under varied field conditions, including shadow\ninterference, cropping, oblique viewing angles, and surface clutter. Compared\nto classical detectors, the proposed framework reduces crack area and spine\nlength errors by up to 70 percent and 90 percent, respectively, while\nmaintaining sub-5 percent alignment error in key metrics. Unsupervised,\ninterpretable, and computationally lightweight, this approach supports scalable\ndeployment via UAVs and mobile platforms. By tailoring nonlinear scale-space\nmodeling to SHM image alignment, this work offers a robust and physically\ngrounded alternative to conventional techniques for tracking real-world crack\nevolution.", "AI": {"tldr": "This paper introduces a physics-informed framework for accurate image alignment in structural health monitoring, overcoming limitations of traditional and lightweight feature detectors.", "motivation": "The paper aims to address challenges in crack monitoring for SHM, such as perspective distortion, occlusion, and low contrast, which are inadequately handled by existing feature detectors like SIFT, SURF, ORB, and BRISK.", "method": "The study adapts the KAZE architecture using nonlinear anisotropic diffusion for crack-preserving scale space and incorporates RANSAC-based homography estimation to facilitate robust image alignment without training or extensive calibration.", "result": "Validation on varied field conditions shows the framework reduces crack area and spine length errors by 70-90%, achieves sub-5% alignment error, and is suitable for UAV and mobile deployment.", "conclusion": "The proposed method provides a scalable, unsupervised, interpretable, and computationally efficient approach to SHM image alignment, tailored to real-world challenges and eliminating reliance on conventional calibration-heavy techniques."}}
{"id": "2506.23734", "pdf": "https://arxiv.org/pdf/2506.23734", "abs": "https://arxiv.org/abs/2506.23734", "authors": ["Hao Shi", "Xi Li", "Fangfang Xie"], "title": "Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment", "categories": ["cs.NE", "cs.AI", "cs.GT"], "comment": "Submitted to IEEE Transactions on Evolutionary Computation. 13 pages,\n  10 figures. Supplementary material is included", "summary": "Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex\ndynamics like intransitivity and the Red Queen effect, leading to unstable\nconvergence. To counter these challenges, this paper introduces the Marker Gene\nMethod (MGM), a framework that establishes stability by using a 'marker gene'\nas a dynamic benchmark and an adaptive weighting mechanism to balance\nexploration and exploitation. We provide rigorous mathematical proofs\ndemonstrating that MGM creates strong attractors near Nash Equilibria within\nthe Strictly Competitive Game framework. Empirically, MGM demonstrates its\nefficacy across a spectrum of challenges: it stabilizes the canonical\nRock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D\non ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it\nsuccessfully tames the notoriously pathological Shapley Biased Game. This work\npresents a theoretically sound and empirically validated framework that\nsubstantially enhances the stability and robustness of CCEAs in complex\ncompetitive environments.", "AI": {"tldr": "This paper proposes the Marker Gene Method (MGM) to improve the stability of Competitive Co-evolutionary Algorithms (CCEAs) by introducing a \"marker gene\" and adaptive weighting mechanisms, demonstrating strong theoretical and empirical performance.", "motivation": "To address issues like intransitivity and the Red Queen effect that hinder stable convergence in Competitive Co-evolutionary Algorithms (CCEAs).", "method": "The Marker Gene Method (MGM) introduces a 'marker gene' as a dynamic benchmark along with an adaptive weighting mechanism to stabilize CCEAs. Mathematical proofs and a Memory Pool (MP) extension further enhance performance.", "result": "MGM stabilizes the Rock-Paper-Scissors game, improves C-RMOEA/D performance on ZDT benchmarks, and addresses challenges in complex games like the Shapley Biased Game with the MP extension.", "conclusion": "MGM provides a robust, theoretically grounded framework for improving the stability and performance of CCEAs in competitive and complex environments."}}
{"id": "2506.22772", "pdf": "https://arxiv.org/pdf/2506.22772", "abs": "https://arxiv.org/abs/2506.22772", "authors": ["Jingxiao Ma", "Soheil Hashemi", "Sherief Reda"], "title": "Approximate Logic Synthesis Using BLASYS", "categories": ["cs.AR", "B.6.1; B.2.4; B.8.2"], "comment": "Published in the Workshop on Open-Source EDA Technology (WOSET),\n  2019. (Workshop link: https://woset-workshop.github.io/WOSET2019.html)", "summary": "Approximate computing is an emerging paradigm where design accuracy can be\ntraded for improvements in design metrics such as design area and power\nconsumption. In this work, we overview our open-source tool, BLASYS, for\nsynthesis of approximate circuits using Boolean Matrix Factorization (BMF). In\nour methodology the truth table of a given circuit is approximated using BMF to\na controllable approximation degree, and the results of the factorization are\nused to synthesize the approximate circuit output. BLASYS scales up the\ncomputations to large circuits through the use of partition techniques, where\nan input circuit is partitioned into a number of interconnected subcircuits and\nthen a design-space exploration technique identifies the best order for\nsubcircuit approximations. BLASYS leads to a graceful trade-off between\naccuracy and full circuit complexity as measured by design area. Using an\nopen-source design flow, we extensively evaluate our methodology on a number of\nbenchmarks, where we demonstrate that the proposed methodology can achieve on\naverage 48.14% in area savings, while introducing an average relative error of\n5%.", "AI": {"tldr": "This paper introduces BLASYS, an open-source tool for synthesizing approximate circuits using Boolean Matrix Factorization (BMF) to trade accuracy for design efficiency.", "motivation": "To address the need for reducing design area and power consumption by enabling a controlled trade-off between circuit accuracy and design metrics.", "method": "The authors propose a methodology that uses BMF to approximate circuit truth tables, partition circuits into subcircuits for scalability, and apply design-space exploration to optimize subcircuit approximations.", "result": "BLASYS achieved a 48.14% average area savings and a 5% average relative error across multiple benchmarks.", "conclusion": "The proposed BLASYS approach effectively balances accuracy and complexity, providing substantial design efficiency improvements with controlled error rates."}}
{"id": "2506.23320", "pdf": "https://arxiv.org/pdf/2506.23320", "abs": "https://arxiv.org/abs/2506.23320", "authors": ["Nicola Assolini", "Alessandra Di Pierro"], "title": "A Denotational Semantics for Quantum Loops", "categories": ["cs.PL"], "comment": "17 pages", "summary": "Programming a quantum computer, i.e., implementing quantum algorithms on a\nquantum processor-based copmputer architecture, is a task that can be addressed\n(just as for classical computers) at different levels of abstraction. This\npaper proposes a denotational semantics for high-level quantum programming\nconstructs, focusing on the conceptual meaning of quantum-controlled branching\nand iteration. We introduce a denotational domain where a mathematical meaning\nof a quantum control flow with loops can be defined, which reflects the\ncoherent evolution of the quantum system implementing the program.", "AI": {"tldr": "The paper proposes a mathematical framework to understand high-level quantum programming concepts, specifically quantum-controlled branching and iteration.", "motivation": "To provide a conceptual and mathematical understanding of quantum control flow and loops in quantum programming.", "method": "Introduces a denotational domain to define mathematical semantics for quantum-controlled branching and iteration.", "result": "Demonstrates conceptual coherence evolution of quantum systems implementing high-level quantum programming constructs.", "conclusion": "The proposed semantics enhance understanding at the abstraction level for quantum programming and quantum control flow systems."}}
{"id": "2506.22773", "pdf": "https://arxiv.org/pdf/2506.22773", "abs": "https://arxiv.org/abs/2506.22773", "authors": ["Yanran Wu", "Inez Hua", "Yi Ding"], "title": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing", "categories": ["cs.DC", "cs.AR", "cs.CY", "cs.LG"], "comment": "7 pages, 9 figures, HotCarbon '25: Proceedings of the 4th Workshop on\n  Sustainable Computer Systems, Cambridge, Massachusetts (USA), July 10-11th,\n  2025", "summary": "Water consumption is an increasingly critical dimension of computing\nsustainability, especially as AI workloads rapidly scale. However, current\nwater impact assessment often overlooks where and when water stress is more\nsevere. To fill in this gap, we present SCARF, the first general framework that\nevaluates water impact of computing by factoring in both spatial and temporal\nvariations in water stress. SCARF calculates an Adjusted Water Impact (AWI)\nmetric that considers both consumption volume and local water stress over time.\nThrough three case studies on LLM serving, datacenters, and semiconductor\nfabrication plants, we show the hidden opportunities for reducing water impact\nby optimizing location and time choices, paving the way for water-sustainable\ncomputing. The code is available at https://github.com/jojacola/SCARF.", "AI": {"tldr": "This paper introduces SCARF, a framework that evaluates computing's water impact by incorporating spatial and temporal water stress variations, and demonstrates its effectiveness through various case studies.", "motivation": "With AI workloads scaling rapidly, water sustainability has become a critical issue, but existing assessments fail to consider variations in water stress based on location and time.", "method": "The authors developed SCARF, which includes the Adjusted Water Impact (AWI) metric to measure water impact by accounting for both consumption volume and dynamic local water stress across locations and times.", "result": "Through case studies on large language model serving, datacenters, and semiconductor manufacturing, SCARF revealed opportunities for reducing water impact by optimizing location and timing.", "conclusion": "This work highlights the potential of addressing spatial and temporal water stress variations to achieve water-sustainable computing, providing a valuable tool through SCARF for advancing sustainability."}}
{"id": "2506.23013", "pdf": "https://arxiv.org/pdf/2506.23013", "abs": "https://arxiv.org/abs/2506.23013", "authors": ["Sungwoo Ahn", "Leonid L Rubchinsky", "Evie A Malaia"], "title": "Distinct Modes of Functional Neural Organization in Autism: Insights from Dynamical Systems Analysis of Resting-State EEG", "categories": ["q-bio.NC"], "comment": "23 pages, 8 figures, 8 tables", "summary": "While differences in patterns of functional connectivity and neural\nsynchronization have been reported between individuals on the autism spectrum\nand neurotypical peers at various age stages, these differences appear to be\nsubtle and may not be captured by typical quantitative measures of EEG. We used\nthe dynamical systems approach to analyze resting-state EEG to investigate\nfine-grained spatiotemporal organization of brain networks in autistic and\nneurotypical young adults. While power spectra showed minimal group\ndifferences, autistic participants exhibited higher Lyapunov exponents\n(indicating less stable neural dynamics), weaker phase synchronization, and\nlower clustering/efficiency of functional networks during eyes-open resting\nstate, suggesting more random and less stably connected neural dynamics in\ncomparison to those of neurotypical peers. Closing the eyes regularized neural\ndynamics in autistic but not neurotypical participants, with increases in\nsynchrony strength, transient desynchronization patterning, and functional\nconnectivity observed in the autistic group. The results point to the distinct\nmodes of neural dynamics organization that could reflect life-long adaptations\nto sensory inputs that shape both resting-state neural activity and cognitive\nprocessing strategies.", "AI": {"tldr": "The study compares brain network dynamics in autistic and neurotypical young adults using a dynamical systems approach on EEG, revealing more unstable neural dynamics in autistic individuals.", "motivation": "To understand fine-grained differences in neural dynamics and connectivity between autistic and neurotypical individuals, which are not captured by traditional EEG measures.", "method": "Resting-state EEG data from autistic and neurotypical young adults were analyzed using a dynamical systems approach focusing on Lyapunov exponents, phase synchronization, and network efficiency.", "result": "Autistic participants showed less stable neural dynamics, weaker synchronization, and lower functional network efficiency. Neural dynamics in autistic individuals improved when closing their eyes.", "conclusion": "Autistic brains may exhibit distinct neural dynamic patterns reflecting lifelong sensory adaptations, which influence both resting-state brain activity and cognitive strategies."}}
{"id": "2506.22688", "pdf": "https://arxiv.org/pdf/2506.22688", "abs": "https://arxiv.org/abs/2506.22688", "authors": ["Humberto Cervantes", "Rick Kazman", "Yuanfang Cai"], "title": "An LLM-assisted approach to designing software architectures using ADD", "categories": ["cs.SE", "D.2.11; D.2.2"], "comment": "30 pages, 12 figures, 7 tables", "summary": "Designing effective software architectures is a complex, iterative process\nthat traditionally relies on expert judgment. This paper proposes an approach\nfor Large Language Model (LLM)-assisted software architecture design using the\nAttribute-Driven Design (ADD) method. By providing an LLM with an explicit\ndescription of ADD, an architect persona, and a structured iteration plan, our\nmethod guides the LLM to collaboratively produce architecture artifacts with a\nhuman architect. We validate the approach through case studies, comparing\ngenerated designs against proven solutions and evaluating them with\nprofessional architects. Results show that our LLM-assisted ADD process can\ngenerate architectures closely aligned with established solutions and partially\nsatisfying architectural drivers, highlighting both the promise and current\nlimitations of using LLMs in architecture design. Our findings emphasize the\nimportance of human oversight and iterative refinement when leveraging LLMs in\nthis domain.", "AI": {"tldr": "This study introduces a method for using Large Language Models (LLMs) to assist in software architecture design by integrating them into the Attribute-Driven Design (ADD) framework.", "motivation": "Software architecture design is traditionally dependent on expert judgment, and the paper aims to explore how LLMs can be effectively leveraged to support this intricate process.", "method": "The researchers proposed a structured approach where an LLM is guided by an explicit ADD description, an architect persona simulation, and a defined iteration plan to collaboratively produce architecture designs alongside human architects.", "result": "Case studies show that the LLM-assisted ADD process produces architecture designs closely resembling established solutions, while partially addressing architectural drivers. The results highlight both the capabilities and limitations of LLMs in this field.", "conclusion": "Although promising, LLMs in architecture design still require significant human oversight and iterative refinement to ensure effective and reliable solutions."}}
{"id": "2506.22485", "pdf": "https://arxiv.org/pdf/2506.22485", "abs": "https://arxiv.org/abs/2506.22485", "authors": ["Sudip Dasgupta", "Himanshu Shankar"], "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents", "categories": ["cs.CL", "cs.AI", "68T07, 68T50", "I.2.1; I.2.3; I.2.7; H.3.3"], "comment": "17 pages, 2 system diagrams, 1 table, no prior conference publication", "summary": "This study presents a modular, multi-agent system for the automated review of\nhighly structured enterprise business documents using AI agents. Unlike prior\nsolutions focused on unstructured texts or limited compliance checks, this\nframework leverages modern orchestration tools such as LangChain, CrewAI,\nTruLens, and Guidance to enable section-by-section evaluation of documents for\naccuracy, consistency, completeness, and clarity. Specialized agents, each\nresponsible for discrete review criteria such as template compliance or factual\ncorrectness, operate in parallel or sequence as required. Evaluation outputs\nare enforced to a standardized, machine-readable schema, supporting downstream\nanalytics and auditability. Continuous monitoring and a feedback loop with\nhuman reviewers allow for iterative system improvement and bias mitigation.\n  Quantitative evaluation demonstrates that the AI Agent-as-Judge system\napproaches or exceeds human performance in key areas: achieving 99% information\nconsistency (vs. 92% for humans), halving error and bias rates, and reducing\naverage review time from 30 to 2.5 minutes per document, with a 95% agreement\nrate between AI and expert human judgment. While promising for a wide range of\nindustries, the study also discusses current limitations, including the need\nfor human oversight in highly specialized domains and the operational cost of\nlarge-scale LLM usage. The proposed system serves as a flexible, auditable, and\nscalable foundation for AI-driven document quality assurance in the enterprise\ncontext.", "AI": {"tldr": "The paper introduces a modular system using AI agents for enterprise document review, achieving high accuracy, reducing error rates, and saving time compared to humans.", "motivation": "Current solutions for document review are limited in handling unstructured texts or specific compliance checks, necessitating a system that can accurately and efficiently evaluate structured documents.", "method": "The system involves modular AI agents using orchestration tools like LangChain and TruLens to evaluate documents across multiple criteria. Outputs are standardized for analysis and feedback loops with human reviewers improve performance.", "result": "The AI system achieved 99% consistency, reduced error/bias rates by half, and cut review time from 30 minutes to 2.5 minutes per document, with a 95% agreement between AI and expert human judgments.", "conclusion": "This modular system demonstrates scalability and high performance in automated enterprise document review, albeit with limitations like reliance on human oversight in complex cases and high operational costs."}}
{"id": "2506.22473", "pdf": "https://arxiv.org/pdf/2506.22473", "abs": "https://arxiv.org/abs/2506.22473", "authors": ["Fernando Diaz Ledezma", "Valentin Marcel", "Matej Hoffmann"], "title": "Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity", "categories": ["cs.RO", "eess.SP"], "comment": "8 pages with 6 figures", "summary": "The movements of both animals and robots give rise to streams of\nhigh-dimensional motor and sensory information. Imagine the brain of a newborn\nor the controller of a baby humanoid robot trying to make sense of unprocessed\nsensorimotor time series. Here, we present a framework for studying the dynamic\nfunctional connectivity between the multimodal sensory signals of a robotic\nagent to uncover an underlying structure. Using instantaneous mutual\ninformation, we capture the time-varying functional connectivity (FC) between\nproprioceptive, tactile, and visual signals, revealing the sensorimotor\nrelationships. Using an infinite relational model, we identified sensorimotor\nmodules and their evolving connectivity. To further interpret these dynamic\ninteractions, we employed non-negative matrix factorization, which decomposed\nthe connectivity patterns into additive factors and their corresponding\ntemporal coefficients. These factors can be considered the agent's motion\nprimitives or movement synergies that the agent can use to make sense of its\nsensorimotor space and later for behavior selection. In the future, the method\ncan be deployed in robot learning as well as in the analysis of human movement\ntrajectories or brain signals.", "AI": {"tldr": "The paper proposes a framework to analyze sensorimotor information in robots and animals using dynamic functional connectivity, revealing motion primitives for potential use in robot learning and human movement analysis.", "motivation": "The motivation is to uncover the underlying structure in high-dimensional sensorimotor time series data from robots or animals, enabling understanding and interpretation of these dynamic processes.", "method": "The study uses instantaneous mutual information to determine functional connectivity between sensory signals and applies an infinite relational model to identify sensorimotor modules. Non-negative matrix factorization is used to decompose connectivity patterns into additive factors.", "result": "The method revealed the motion primitives or movement synergies of an agent, representing the building blocks for interpreting sensorimotor spaces and facilitating behavior selection.", "conclusion": "The framework offers a novel approach to understanding sensorimotor dynamics in robots, with potential applications in robot learning, human movement trajectory analysis, and brain signal interpretation."}}
{"id": "2506.22609", "pdf": "https://arxiv.org/pdf/2506.22609", "abs": "https://arxiv.org/abs/2506.22609", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J. N. J. Soemers", "Julian Togelius"], "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "categories": ["cs.AI"], "comment": "18 pages, 3 figures", "summary": "Games have long been used as benchmarks and testing environments for research\nin artificial intelligence. A key step in supporting this research was the\ndevelopment of game description languages: frameworks that compile\ndomain-specific code into playable and simulatable game environments, allowing\nresearchers to generalize their algorithms and approaches across multiple games\nwithout having to manually implement each one. More recently, progress in\nreinforcement learning (RL) has been largely driven by advances in hardware\nacceleration. Libraries like JAX allow practitioners to take full advantage of\ncutting-edge computing hardware, often speeding up training and testing by\norders of magnitude. Here, we present a synthesis of these strands of research:\na domain-specific language for board games which automatically compiles into\nhardware-accelerated code. Our framework, Ludax, combines the generality of\ngame description languages with the speed of modern parallel processing\nhardware and is designed to fit neatly into existing deep learning pipelines.\nWe envision Ludax as a tool to help accelerate games research generally, from\nRL to cognitive science, by enabling rapid simulation and providing a flexible\nrepresentation scheme. We present a detailed breakdown of Ludax's description\nlanguage and technical notes on the compilation process, along with speed\nbenchmarking and a demonstration of training RL agents. The Ludax framework,\nalong with implementations of existing board games, is open-source and freely\navailable.", "AI": {"tldr": "Ludax is a new domain-specific language for board games that automates compilation into hardware-accelerated code, enabling faster and more efficient AI research.", "motivation": "Support AI research with a language that integrates game description flexibility and hardware acceleration for improved generality and speed.", "method": "Developed Ludax, a game description language designed to combine hardware acceleration with compatibility in deep learning pipelines.", "result": "Presented Ludax's technical features, showcased its speed benchmarking outcomes, and demonstrated its effectiveness in training RL agents.", "conclusion": "Ludax accelerates game research by integrating rapid simulation and flexible representations, and is freely offered as an open-source tool."}}
{"id": "2506.22565", "pdf": "https://arxiv.org/pdf/2506.22565", "abs": "https://arxiv.org/abs/2506.22565", "authors": ["Guan-Horng Liu", "Jaemoo Choi", "Yongxin Chen", "Benjamin Kurt Miller", "Ricky T. Q. Chen"], "title": "Adjoint Schr\u00f6dinger Bridge Sampler", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Computational methods for learning to sample from the Boltzmann distribution\n-- where the target distribution is known only up to an unnormalized energy\nfunction -- have advanced significantly recently. Due to the lack of explicit\ntarget samples, however, prior diffusion-based methods, known as diffusion\nsamplers, often require importance-weighted estimation or complicated learning\nprocesses. Both trade off scalability with extensive evaluations of the energy\nand model, thereby limiting their practical usage. In this work, we propose\nAdjoint Schr\\\"odinger Bridge Sampler (ASBS), a new diffusion sampler that\nemploys simple and scalable matching-based objectives yet without the need to\nestimate target samples during training. ASBS is grounded on a mathematical\nmodel -- the Schr\\\"odinger Bridge -- which enhances sampling efficiency via\nkinetic-optimal transportation. Through a new lens of stochastic optimal\ncontrol theory, we demonstrate how SB-based diffusion samplers can be learned\nat scale via Adjoint Matching and prove convergence to the global solution.\nNotably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to\narbitrary source distributions by relaxing the so-called memoryless condition\nthat largely restricts the design space. Through extensive experiments, we\ndemonstrate the effectiveness of ASBS on sampling from classical energy\nfunctions, amortized conformer generation, and molecular Boltzmann\ndistributions.", "AI": {"tldr": "This paper introduces the Adjoint Schr\"odinger Bridge Sampler (ASBS), a new diffusion-based method for learning to sample from Boltzmann distributions, which is more scalable and avoids the need for target sample estimation during training.", "motivation": "Current diffusion-based methods for sampling from Boltzmann distributions often suffer from complexity and inefficiency due to reliance on importance-weighted estimation or complicated learning processes.", "method": "The authors propose ASBS, a diffusion sampling technique grounded in the Schr\"odinger Bridge model that employs stochastic optimal control theory and Adjoint Matching to efficiently train sampling models without requiring target samples during training.", "result": "ASBS achieves enhanced sampling efficiency and generalizes previous methods (like Adjoint Sampling) by relaxing constraints such as the memoryless condition. Experiments show its effectiveness in various tasks like classical energy sampling, molecular conformer generation, and Boltzmann distribution modeling.", "conclusion": "ASBS addresses scalability and training inefficiencies in diffusion sampling, offering a robust and generalized solution for sampling from complex distributions, thus expanding its practical applicability and efficiency."}}
{"id": "2506.22442", "pdf": "https://arxiv.org/pdf/2506.22442", "abs": "https://arxiv.org/abs/2506.22442", "authors": ["Piotr Makarevich"], "title": "Features-based embedding or Feature-grounding", "categories": ["cs.LG"], "comment": "13 pages, 12 figures", "summary": "In everyday reasoning, when we think about a particular object, we associate\nit with a unique set of expected properties such as weight, size, or more\nabstract attributes like density or horsepower. These expectations are shaped\nby our prior knowledge and the conceptual categories we have formed through\nexperience. This paper investigates how such knowledge-based structured\nthinking can be reproduced in deep learning models using features based\nembeddings. Specially, it introduces an specific approach to build\nfeature-grounded embedding, aiming to align shareable representations of\noperable dictionary with interpretable domain-specific conceptual features.", "AI": {"tldr": "This paper explores replicating human structured conceptual thinking in deep learning models using feature-grounded embeddings.", "motivation": "To reproduce structured reasoning based on human conceptual categories in deep learning models.", "method": "The paper proposes creating feature-grounded embeddings linked to interpretable domain-specific conceptual features.", "result": "Introduced a new approach for aligning shareable representations with specific features relevant to an operable dictionary.", "conclusion": "Feature-grounded embeddings can potentially make deep learning models better align with human-like structured thinking."}}
{"id": "2506.22438", "pdf": "https://arxiv.org/pdf/2506.22438", "abs": "https://arxiv.org/abs/2506.22438", "authors": ["Xumin Gao", "Mark Stevens", "Grzegorz Cielniak"], "title": "Counting with Confidence: Accurate Pest Monitoring in Water Traps", "categories": ["cs.CV"], "comment": "\\c{opyright} 20XX the authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND", "summary": "Accurate pest population monitoring and tracking their dynamic changes are\ncrucial for precision agriculture decision-making. A common limitation in\nexisting vision-based automatic pest counting research is that models are\ntypically evaluated on datasets with ground truth but deployed in real-world\nscenarios without assessing the reliability of counting results due to the lack\nof ground truth. To this end, this paper proposed a method for comprehensively\nevaluating pest counting confidence in the image, based on information related\nto counting results and external environmental conditions. First, a pest\ndetection network is used for pest detection and counting, extracting counting\nresult-related information. Then, the pest images undergo image quality\nassessment, image complexity assessment, and pest distribution uniformity\nassessment. And the changes in image clarity caused by stirring during image\nacquisition are quantified by calculating the average gradient magnitude.\nNotably, we designed a hypothesis-driven multi-factor sensitivity analysis\nmethod to select the optimal image quality assessment and image complexity\nassessment methods. And we proposed an adaptive DBSCAN clustering algorithm for\npest distribution uniformity assessment. Finally, the obtained information\nrelated to counting results and external environmental conditions is input into\na regression model for prediction, resulting in the final pest counting\nconfidence. To the best of our knowledge, this is the first study dedicated to\ncomprehensively evaluating counting confidence in counting tasks, and\nquantifying the relationship between influencing factors and counting\nconfidence through a model. Experimental results show our method reduces MSE by\n31.7% and improves R2 by 15.2% on the pest counting confidence test set,\ncompared to the baseline built primarily on information related to counting\nresults.", "AI": {"tldr": "This paper proposes a comprehensive method for evaluating pest counting confidence in images by integrating detection results and environmental conditions, achieving significant error reduction compared to baselines.", "motivation": "Accurate pest population monitoring is essential for precision agriculture, but existing vision-based pest counting methods fail to assess reliability due to the absence of ground truth in real-world applications.", "method": "The method combines a pest detection network with image quality, image complexity, and pest distribution assessments. It also includes a hypothesis-driven sensitivity analysis and an adaptive DBSCAN clustering algorithm to predict pest counting confidence using regression models.", "result": "The approach reduces mean squared error (MSE) by 31.7% and improves R2 score by 15.2% compared to a baseline method on the pest counting confidence test set.", "conclusion": "This study pioneers a method to comprehensively evaluate counting confidence in pest counting tasks and quantifies the influence of various factors on confidence, enhancing reliability in real-world applications."}}
{"id": "2506.23738", "pdf": "https://arxiv.org/pdf/2506.23738", "abs": "https://arxiv.org/abs/2506.23738", "authors": ["Renzo J. Scholman", "Tanja Alderliesten", "Peter A. N. Bosman"], "title": "More Efficient Real-Valued Gray-Box Optimization through Incremental Distribution Estimation in RV-GOMEA", "categories": ["cs.NE"], "comment": null, "summary": "The Gene-pool Optimal Mixing EA (GOMEA) family of EAs offers a specific means\nto exploit problem-specific knowledge through linkage learning, i.e.,\ninter-variable dependency detection, expressed using subsets of variables, that\nshould undergo joint variation. Such knowledge can be exploited if faster\nfitness evaluations are possible when only a few variables are changed in a\nsolution, enabling large speed-ups. The recent-most version of Real-Valued\nGOMEA (RV-GOMEA) can learn a conditional linkage model during optimization\nusing fitness-based linkage learning, enabling fine-grained dependency\nexploitation in learning and sampling a Gaussian distribution. However, while\nthe most efficient Gaussian-based EAs, like NES and CMA-ES, employ incremental\nlearning of the Gaussian distribution rather than performing full re-estimation\nevery generation, the recent-most RV-GOMEA version does not employ such\nincremental learning. In this paper, we therefore study whether incremental\ndistribution estimation can lead to efficiency enhancements of RV-GOMEA. We\nconsider various benchmark problems with varying degrees of overlapping\ndependencies. We find that, compared to RV-GOMEA and VKD-CMA-ES, the required\nnumber of evaluations to reach high-quality solutions can be reduced by a\nfactor of up to 1.5 if population sizes are tuned problem-specifically, while a\nreduction by a factor of 2-3 can be achieved with generic population-sizing\nguidelines.", "AI": {"tldr": "The paper investigates using incremental distribution estimation to improve the efficiency of RV-GOMEA for solving problems with overlapping dependencies.", "motivation": "To enhance the efficiency of RV-GOMEA, particularly in cases where overlapping dependencies in problems are present, by exploring the possibility of incremental distribution estimation.", "method": "The authors integrate incremental learning mechanisms for the Gaussian distribution into RV-GOMEA. They compare its efficiency against RV-GOMEA and VKD-CMA-ES on benchmark problems with varying dependency overlaps.", "result": "Results indicate that incremental distribution estimation reduces the required number of evaluations. Specifically, it reduces evaluations by a factor of up to 1.5 with problem-specific population tuning, and by 2-3 with generic population sizing.", "conclusion": "Incremental distribution estimation enhances RV-GOMEA's efficiency significantly, particularly when population sizes are appropriately configured, making it a promising approach for further refinement."}}
{"id": "2506.23901", "pdf": "https://arxiv.org/pdf/2506.23901", "abs": "https://arxiv.org/abs/2506.23901", "authors": ["Yannik Stradmann", "Joscha Ilmberger", "Eric M\u00fcller", "Johannes Schemmel"], "title": "Sustainable operation of research infrastructure for novel computing", "categories": ["cs.AR"], "comment": null, "summary": "Novel compute systems are an emerging research topic, aiming towards building\nnext-generation compute platforms. For these systems to thrive, they need to be\nprovided as research infrastructure to allow acceptance and usage by a large\ncommunity. By the example of the neuromorphic BrainScaleS-2 system, we showcase\nthe transformation from a laboratory setup to a sustainable, publicly available\nplatform. It is embedded into a purpose-built institute, tightly coupling a\nconventional cluster with novel compute hardware. The network infrastructure is\noptimized for robust operation, even in the case of unintended behavior of\nindividual devices. The systems themselves are packaged into 19-inch compatible\nunits to allow for easy maintenance and extension. We operate the platform\nusing modern CI/CD techniques and continuously assert its health using\nautomated system monitoring. Finally, we share our lessons learned during the\ndecade-long endeavor of operating analog neuromorphic systems as a publicly\navailable research platform.", "AI": {"tldr": "The paper showcases how the BrainScaleS-2 neuromorphic system evolved into a sustainable public research platform, with specific infrastructure improvements and operational strategies.", "motivation": "The motivation is to make novel compute systems widely accepted and utilized by transitioning them into publicly available research platforms.", "method": "The authors transformed the BrainScaleS-2 system from a lab setup to a public platform, employing infrastructure optimization, robust network designs, packaging for maintenance, and modern CI/CD techniques for operations.", "result": "The BrainScaleS-2 system was successfully transitioned into a robust, maintainable, and publicly accessible platform, backed by continuous monitoring and system optimization strategies.", "conclusion": "The study shares valuable insights into operating analog neuromorphic systems, highlighting rigorous infrastructure and operational methodologies to support their sustainable public utilization."}}
{"id": "2506.23407", "pdf": "https://arxiv.org/pdf/2506.23407", "abs": "https://arxiv.org/abs/2506.23407", "authors": ["Marcus Edwards"], "title": "Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR", "categories": ["cs.PL", "quant-ph"], "comment": null, "summary": "We implement a compile toolchain from Q# to QASM 3.0 including a\nfull-featured lexer and parser implementation, as well as a compiler that\nsupports a subset of Q# features. The lexer, parser and compiler are shown to\nwork with various input Q# programs and the implementation is compared against\nexisting Q# compile tools. Unlike the Microsoft implementation of the official\nQ# compile toolchain, our implementation is written in TypeScript in order to\nport functionality to web environments.", "AI": {"tldr": "The paper introduces a TypeScript-based toolchain for converting Q# to QASM 3.0, including lexer, parser, and compiler.", "motivation": "To provide a web-compatible alternative to Microsoft's Q# compiler toolchain.", "method": "Developed a TypeScript-based lexer, parser, and subset-supporting compiler; tested on Q# examples and compared with existing tools.", "result": "The toolchain successfully processes Q# programs and is functional in web environments.", "conclusion": "This TypeScript-written toolchain expands Q# compilation compatibility for web-based applications."}}
{"id": "2506.22818", "pdf": "https://arxiv.org/pdf/2506.22818", "abs": "https://arxiv.org/abs/2506.22818", "authors": ["Stanislav Sedukhin", "Yoichi Tomioka", "Kazuya Matsumoto", "Yuichi Okuyama"], "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.ET", "eess.SP", "C.1.4; C.3; F.2.1; G.1.3; G.4"], "comment": "19 pages, 5 figures", "summary": "Multilinear transformations are key in high-performance computing (HPC) and\nartificial intelligence (AI) workloads, where data is represented as tensors.\nHowever, their high computational and memory demands, which grow with\ndimensionality, often slow down critical tasks. Moreover, scaling computation\nby enlarging the number of parallel processing units substantially increases\nenergy consumption, limiting widespread adoption, especially for sparse data,\nwhich is common in HPC and AI applications. This paper introduces the Trilinear\nAlgorithm and isomorphic to algorithm Device Architecture (TriADA) to address\nthese challenges with the following innovations: (1) a massively parallel,\nlow-rank algorithm for computing a family of trilinear (3D) discrete orthogonal\ntransformations (3D-DXTs), which is a special case of the more general 3-mode\nmatrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM\nkernel with decoupled streaming active memory, specially designed to accelerate\n3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully\ndistributed 3D network of mesh interconnected processing elements or cells with\na coordinate-free, data-driven local processing activity, which is independent\nof problem size; (4) an elastic sparse outer-product (ESOP) method that avoids\nunnecessary computing and communication operations with zero-valued operands,\nthereby enhancing energy efficiency, computational accuracy, and stability.\nTriADA is capable of performing a variety of trilinear transformations with\nhypercubic arithmetic complexity in a linear number of time-steps. The\nmassively parallel, scalable, and energy-efficient architecture of TriADA is\nideal for accelerating multilinear tensor operations, which are the most\ndemanding parts of AI and HPC workloads.", "AI": {"tldr": "The paper presents TriADA, a scalable and energy-efficient architecture for trilinear tensor operations to improve computation in AI and HPC workloads.", "motivation": "Address the computational and memory inefficiencies, alongside energy constraints, in handling multilinear transformations for sparse data in AI and HPC tasks.", "method": "Proposed TriADA, including a low-rank algorithm, a new GEMM kernel, a distributed 3D network architecture, and an elastic sparse outer-product method.", "result": "TriADA achieves energy-efficient, scalable, and massively parallel tensor operations with hypercubic arithmetic complexity.", "conclusion": "TriADA offers an advanced solution tailored for high-performance tensor processing, making it suitable for the critical workloads in AI and HPC applications."}}
{"id": "2506.23546", "pdf": "https://arxiv.org/pdf/2506.23546", "abs": "https://arxiv.org/abs/2506.23546", "authors": ["Zhendong Yu", "Weizhong Huang", "Haiping Huang"], "title": "Neural Langevin Machine: a local asymmetric learning rule can be creative", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.LG", "cs.NE"], "comment": "15 pages, 3 figures, with Github link in the paper", "summary": "Fixed points of recurrent neural networks can be leveraged to store and\ngenerate information. These fixed points can be captured by the Boltzmann-Gibbs\nmeasure, which leads to neural Langevin dynamics that can be used for sampling\nand learning a real dataset. We call this type of generative model neural\nLangevin machine, which is interpretable due to its analytic form of\ndistribution and is simple to train. Moreover, the learning process is derived\nas a local asymmetric plasticity rule, bearing biological relevance. Therefore,\none can realize a continuous sampling of creative dynamics in a neural network,\nmimicking an imagination process in brain circuits. This neural Langevin\nmachine may be another promising generative model, at least in its strength in\ncircuit-based sampling and biologically plausible learning rule.", "AI": {"tldr": "The paper introduces the concept of a neural Langevin machine, leveraging fixed points in recurrent neural networks for generative modeling.", "motivation": "Explores biologically relevant generative model inspired by brain circuits that enables continuous sampling and learning processes.", "method": "Utilizes neural Langevin dynamics, derived from Boltzmann-Gibbs measures, coupled with asymmetric plasticity for training.", "result": "Demonstrates an interpretable and efficient generative model with biologically plausible mechanisms.", "conclusion": "Proposes neural Langevin machines as a promising generative model with applications in creative continuous sampling and biological mimicry."}}
{"id": "2506.22703", "pdf": "https://arxiv.org/pdf/2506.22703", "abs": "https://arxiv.org/abs/2506.22703", "authors": ["Wali Mohammad Abdullah", "Azmain Kabir"], "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "We present P4OMP, a retrieval-augmented framework for transforming serial\nC/C++ code into OpenMP-annotated parallel code using large language models\n(LLMs). To our knowledge, this is the first system to apply retrieval-based\nprompting for OpenMP pragma correctness without model fine-tuning or compiler\ninstrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with\nstructured instructional knowledge from OpenMP tutorials to improve the\nreliability of prompt-driven code generation. By grounding generation in the\nretrieved context, P4OMP improves syntactic correctness compared to baseline\nprompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,\nGPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world\nC++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.\nP4OMP achieves 100% compilation success on all parallelizable cases, while the\nbaseline fails to compile in 20 out of 108 cases. Six cases that rely on\nnon-random-access iterators or thread-unsafe constructs are excluded due to\nfundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP\nconsistently avoids scoping errors, syntactic misuse, and invalid directive\ncombinations that commonly affect baseline-generated code. We further\ndemonstrate strong runtime scaling across seven compute-intensive benchmarks on\nan HPC cluster. P4OMP offers a robust, modular pipeline that significantly\nimproves the reliability and applicability of LLM-generated OpenMP code.", "AI": {"tldr": "P4OMP utilizes Retrieval-Augmented Generation (RAG) to enhance the generation of OpenMP parallel code using GPT-3.5-Turbo, achieving higher compilation success rates than baseline methods.", "motivation": "The paper aims to address the challenges in ensuring syntactic correctness and reliability in generating OpenMP parallel code using LLMs, particularly for C/C++ programs.", "method": "P4OMP adopts a retrieval-based prompting method, using instructional knowledge from OpenMP tutorials, and leverages GPT-3.5-Turbo without model fine-tuning for generating parallel code.", "result": "P4OMP achieves 100% compilation success in parallelizable benchmark cases, outperforming the baseline in avoiding scoping errors and syntax issues.", "conclusion": "The modular pipeline of P4OMP demonstrates improved reliability, scalability, and applicability of OpenMP code generation using LLMs, making it highly suitable for HPC applications."}}
{"id": "2506.22486", "pdf": "https://arxiv.org/pdf/2506.22486", "abs": "https://arxiv.org/abs/2506.22486", "authors": ["Ming Cheung"], "title": "Hallucination Detection with Small Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Since the introduction of ChatGPT, large language models (LLMs) have\ndemonstrated significant utility in various tasks, such as answering questions\nthrough retrieval-augmented generation. Context can be retrieved using a\nvectorized database, serving as a foundation for LLMs to generate responses.\nHowever, hallucinations in responses can undermine the reliability of LLMs in\npractical applications, and they are not easily detectable in the absence of\nground truth, particularly in question-and-answer scenarios. This paper\nproposes a framework that integrates multiple small language models to verify\nresponses generated by LLMs using the retrieved context from a vectorized\ndatabase. By breaking down the responses into individual sentences and\nutilizing the probability of generating \"Yes\" tokens from the outputs of\nmultiple models for a given set of questions, responses, and relevant context,\nhallucinations can be detected. The proposed framework is validated through\nexperiments with real datasets comprising over 100 sets of questions, answers,\nand contexts, including responses with fully and partially correct sentences.\nThe results demonstrate a 10\\% improvement in F1 scores for detecting correct\nresponses compared to hallucinations, indicating that multiple small language\nmodels can be effectively employed for answer verification, providing a\nscalable and efficient solution for both academic and practical applications.", "AI": {"tldr": "This paper introduces a framework using multiple small language models to detect hallucinations in responses by large language models (LLMs) through response verification against retrieved context.", "motivation": "The paper aims to address the issue of hallucinations in the responses of LLMs, which can undermine the reliability of these models in real-world applications, specifically in tasks like question answering.", "method": "The framework verifies LLM-generated responses by dividing them into sentences and using multiple small language models to assess the probability of generating consistent 'Yes' tokens. Context from a vectorized database is used for validation.", "result": "Experiments on real datasets show a 10% improvement in F1 scores for detecting accurate responses compared to hallucinations.", "conclusion": "This approach demonstrates that integrating small language models can effectively validate LLM responses, offering a scalable solution for enhancing reliability in both academic and practical applications."}}
{"id": "2506.22494", "pdf": "https://arxiv.org/pdf/2506.22494", "abs": "https://arxiv.org/abs/2506.22494", "authors": ["Shihong Ling", "Yue Wan", "Xiaowei Jia", "Na Du"], "title": "DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025. 7 pages, 3 figures", "summary": "This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT\narchitecture, to generate accurate and contextually relevant explanations for\nemerging driving scenarios. While existing vision-language models perform well\nin general tasks, they encounter difficulties in understanding complex,\nmulti-object environments, particularly in real-time applications such as\nautonomous driving, where the rapid identification of key objects is crucial.\nTo address this limitation, an Attention Map Generator is proposed to highlight\nsignificant objects relevant to driving decisions within critical video frames.\nBy directing the model's focus to these key regions, the generated attention\nmap helps produce clear and relevant explanations, enabling drivers to better\nunderstand the vehicle's decision-making process in critical situations.\nEvaluations on the DRAMA dataset reveal significant improvements in explanation\nquality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared\nto baseline models. These findings underscore the potential of targeted\nattention mechanisms in vision-language models for enhancing explainability in\nreal-time autonomous driving.", "AI": {"tldr": "Introduces DriveBLIP2, an improved vision-language model using targeted attention for better explainability in autonomous driving.", "motivation": "To overcome the inability of existing vision-language models to handle complex, multi-object environments effectively in real-time driving scenarios.", "method": "Developed DriveBLIP2 with an Attention Map Generator to focus on key objects in video frames, improving the explainability of decision-making processes.", "result": "Demonstrated superior performance on the DRAMA dataset through improved BLEU, ROUGE, CIDEr, and SPICE scores compared to baseline models.", "conclusion": "Targeted attention mechanisms can enhance the explainability and contextual relevance of vision-language models in critical autonomous driving applications."}}
{"id": "2506.22653", "pdf": "https://arxiv.org/pdf/2506.22653", "abs": "https://arxiv.org/abs/2506.22653", "authors": ["Michael Grosskopf", "Russell Bent", "Rahul Somasundaram", "Isaac Michaud", "Arthur Lui", "Nathan Debardeleben", "Earl Lawrence"], "title": "URSA: The Universal Research and Scientific Agent", "categories": ["cs.AI"], "comment": "31 pages, 9 figures", "summary": "Large language models (LLMs) have moved far beyond their initial form as\nsimple chatbots, now carrying out complex reasoning, planning, writing, coding,\nand research tasks. These skills overlap significantly with those that human\nscientists use day-to-day to solve complex problems that drive the cutting edge\nof research. Using LLMs in \"agentic\" AI has the potential to revolutionize\nmodern science and remove bottlenecks to progress. In this work, we present\nURSA, a scientific agent ecosystem for accelerating research tasks. URSA\nconsists of a set of modular agents and tools, including coupling to advanced\nphysics simulation codes, that can be combined to address scientific problems\nof varied complexity and impact. This work highlights the architecture of URSA,\nas well as examples that highlight the potential of the system.", "AI": {"tldr": "The paper introduces URSA, an ecosystem of AI agents designed to assist in accelerating scientific research tasks.", "motivation": "Modern scientific research often faces bottlenecks that slow progress, and the increasing capabilities of LLMs present an opportunity to overcome these barriers and revolutionize scientific workflows.", "method": "The authors develop URSA, a modular scientific agent ecosystem that integrates advanced tools and physics simulation codes to address scientific challenges of varying complexity.", "result": "They showcase the architecture of URSA and provide examples demonstrating its potential as a transformative tool in science.", "conclusion": "URSA exemplifies the capability of LLM-based tools to assist and accelerate scientific research, promising to remove traditional bottlenecks and enhance productivity in modern science."}}
{"id": "2506.22675", "pdf": "https://arxiv.org/pdf/2506.22675", "abs": "https://arxiv.org/abs/2506.22675", "authors": ["Luhuan Wu", "Mingzhang Yin", "Yixin Wang", "John P. Cunningham", "David M. Blei"], "title": "Bayesian Invariance Modeling of Multi-Environment Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from\nmultiple environments to identify invariant features - those with a stable\npredictive relationship to the outcome. Such features support generalization to\nnew environments and help reveal causal mechanisms. Previous methods have\nprimarily tackled this problem through hypothesis testing or regularized\noptimization. Here we develop Bayesian Invariant Prediction (BIP), a\nprobabilistic model for invariant prediction. BIP encodes the indices of\ninvariant features as a latent variable and recover them by posterior\ninference. Under the assumptions of Peters et al. [2016], the BIP posterior\ntargets the true invariant features. We prove that the posterior is consistent\nand that greater environment heterogeneity leads to faster posterior\ncontraction. To handle many features, we design an efficient variational\napproximation called VI-BIP. In simulations and real data, we find that BIP and\nVI-BIP are more accurate and scalable than existing methods for invariant\nprediction.", "AI": {"tldr": "This paper introduces Bayesian Invariant Prediction (BIP), a probabilistic model to identify invariant features, improving accuracy and scalability over existing methods.", "motivation": "To overcome limitations of previous invariant prediction methods such as hypothesis testing or regularized optimization, and to provide a probabilistic approach to identifying invariant features that support generalization and reveal causal mechanisms.", "method": "The authors encode invariant feature indices as a latent variable in a Bayesian framework and recover them through posterior inference. They introduce a variational approximation (VI-BIP) for computational efficiency when dealing with many features.", "result": "BIP is shown to produce consistent posterior results and faster convergence with increased environment heterogeneity. Experiments demonstrate BIP and VI-BIP outperform existing methods in accuracy and scalability.", "conclusion": "BIP and its variational approximation offer a more precise and scalable solution to invariant prediction, facilitating better generalization and causal understanding."}}
{"id": "2506.22443", "pdf": "https://arxiv.org/pdf/2506.22443", "abs": "https://arxiv.org/abs/2506.22443", "authors": ["Sarah Seifi", "Tobias Sukianto", "Cecilia Carbonelli", "Lorenzo Servadei", "Robert Wille"], "title": "Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition", "categories": ["cs.LG", "cs.HC"], "comment": "8 pages, 3 figures, accepted at the late-breaking work track at the\n  XAI-2025 third World Conference of Explainable AI", "summary": "Rule-based models offer interpretability but struggle with complex data,\nwhile deep neural networks excel in performance yet lack transparency. This\nwork investigates a neuro-symbolic rule learning neural network named RL-Net\nthat learns interpretable rule lists through neural optimization, applied for\nthe first time to radar-based hand gesture recognition (HGR). We benchmark\nRL-Net against a fully transparent rule-based system (MIRA) and an explainable\nblack-box model (XentricAI), evaluating accuracy, interpretability, and user\nadaptability via transfer learning. Our results show that RL-Net achieves a\nfavorable trade-off, maintaining strong performance (93.03% F1) while\nsignificantly reducing rule complexity. We identify optimization challenges\nspecific to rule pruning and hierarchy bias and propose stability-enhancing\nmodifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical\nmiddle ground between transparency and performance. This study highlights the\nreal-world feasibility of neuro-symbolic models for interpretable HGR and\noffers insights for extending explainable AI to edge-deployable sensing\nsystems.", "AI": {"tldr": "RL-Net is a neuro-symbolic model that learns interpretable rules for radar-based hand gesture recognition, balancing high performance with reduced complexity compared to rule-based and explainable black-box models.", "motivation": "To bridge the gap between interpretability of rule-based models and the high performance of deep neural networks.", "method": "Developed and benchmarked RL-Net, a neuro-symbolic rule learning neural network, against rule-based and explainable models, focusing on HGR tasks.", "result": "RL-Net achieved strong performance (93.03% F1) with reduced rule complexity and identified optimization challenges like rule pruning and hierarchy bias.", "conclusion": "RL-Net balances transparency and robust performance, proving neuro-symbolic models feasible for explainable AI in edge-deployable applications like HGR."}}
{"id": "2506.22463", "pdf": "https://arxiv.org/pdf/2506.22463", "abs": "https://arxiv.org/abs/2506.22463", "authors": ["Weizhi Gao", "Zhichao Hou", "Junqi Yin", "Feiyi Wang", "Linyu Peng", "Xiaorui Liu"], "title": "Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages, accepted by ICML 2025", "summary": "Diffusion models have emerged as powerful generative models, but their high\ncomputation cost in iterative sampling remains a significant bottleneck. In\nthis work, we present an in-depth and insightful study of state-of-the-art\nacceleration techniques for diffusion models, including caching and\nquantization, revealing their limitations in computation error and generation\nquality. To break these limits, this work introduces Modulated Diffusion\n(MoDiff), an innovative, rigorous, and principled framework that accelerates\ngenerative modeling through modulated quantization and error compensation.\nMoDiff not only inherents the advantages of existing caching and quantization\nmethods but also serves as a general framework to accelerate all diffusion\nmodels. The advantages of MoDiff are supported by solid theoretical insight and\nanalysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate\nthat MoDiff significant reduces activation quantization from 8 bits to 3 bits\nwithout performance degradation in post-training quantization (PTQ). Our code\nimplementation is available at https://github.com/WeizhiGao/MoDiff.", "AI": {"tldr": "The paper introduces Modulated Diffusion (MoDiff), a novel framework to accelerate generative diffusion models through modulated quantization and error compensation, reducing quantization to 3 bits without performance loss.", "motivation": "The motivation stems from the high computational costs and inefficiencies in iterative sampling of diffusion models, alongside the limitations of existing acceleration methods like caching and quantization in terms of quality and correctness.", "method": "The authors developed MoDiff, which incorporates modulated quantization and error compensation to address inefficiencies, serving as a general framework for accelerating diffusion models. The approach integrates theoretical analysis and experimental validations.", "result": "Experiments on datasets such as CIFAR-10 and LSUN show MoDiff can reduce quantization from 8 bits to 3 bits without a decline in post-training quantization performance, proving its efficacy.", "conclusion": "MoDiff offers a robust and principled solution to accelerate diffusion models, inheriting and surpassing benefits of existing techniques, and is backed by theoretical and empirical evidence."}}
{"id": "2506.24041", "pdf": "https://arxiv.org/pdf/2506.24041", "abs": "https://arxiv.org/abs/2506.24041", "authors": ["Alexis Melot", "Sean U. N. Wood", "Yannick Coffinier", "Pierre Yger", "Fabien Alibart"], "title": "Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting", "categories": ["cs.NE", "cs.LG"], "comment": "Main article : 16 pages, 7 figures and 4 tables. Supplementary\n  Material starts at page 17 with 7 figures", "summary": "Spike sorting is a crucial step in decoding multichannel extracellular neural\nsignals, enabling the identification of individual neuronal activity. A key\nchallenge in brain-machine interfaces (BMIs) is achieving real-time, low-power\nspike sorting at the edge while keeping high neural decoding performance. This\nstudy introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer\nspiking neural network optimized for efficient spike sorting. NSS leverages the\nLocally Competitive Algorithm (LCA) for sparse coding to extract relevant\nfeatures from noisy events with reduced computational demands. NSS learns to\nsort detected spike waveforms in an online fashion and operates entirely\nunsupervised. To exploit multi-bit spike coding capabilities of neuromorphic\nplatforms like Intel's Loihi 2, a custom neuron model was implemented, enabling\nflexible power-performance trade-offs via adjustable spike bit-widths.\nEvaluations on simulated and real-world tetrode signals with biological drift\nshowed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.\nWith 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with\nleaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%\nimprovement) while consuming 8.6mW (+1.65mW) when tested on a drifting\nrecording, with a computational processing time of 0.25ms (+60 us) per\ninference.", "AI": {"tldr": "The paper introduces Neuromorphic Sparse Sorter (NSS), a compact spiking neural network for efficient, real-time spike sorting at the edge, enabling higher neural decoding performance.", "motivation": "Spike sorting is fundamental for decoding neural signals efficiently in BMIs, with challenges in achieving real-time, low-power, and high-performance decoding at the edge.", "method": "They propose NSS, a two-layer spiking neural network utilizing Locally Competitive Algorithm (LCA) for real-time, unsupervised spike sorting with custom neuron models leveraging multi-bit spike coding on Intel's Loihi 2.", "result": "Evaluations on tetrode signals demonstrated NSS achieving an F1-score of 77%, outperforming existing pipelines like WaveClus3 while consuming only 8.6mW and processing in 0.25ms per inference.", "conclusion": "NSS shows significant advancements in real-time spike sorting, emphasizing its potential for low-power BMIs and edge computing platforms with improved accuracy and efficiency."}}
{"id": "2506.22702", "pdf": "https://arxiv.org/pdf/2506.22702", "abs": "https://arxiv.org/abs/2506.22702", "authors": ["Zina Mohamed", "Ammar B. Kouki", "Sonia A\u00efssa"], "title": "A Correlation-Based Design of RIS for Reduced Power Consumption and Simplified Control Circuitry", "categories": ["eess.SY", "cs.AR", "cs.SY", "eess.SP"], "comment": null, "summary": "Aiming at simplifying the hardware structure and reducing the energy\nconsumption in wireless communication via reconfigurable intelligent surfaces\n(RIS), this paper introduces a novel RIS design founded on the correlation\nbetween the phase shift values of the surface elements. First, a correlation\nanalysis is conducted, considering the azimuth angle of a target device within\na coverage region spanning from $-80^{\\circ}$ to $80^{\\circ}$. The correlation\nis demonstrated for different deployment cases, creating the basis for the new\nRIS structure, termed Connected-RIS, where correlated elements are designed to\nshare the same control signal. The fundamental performance of the proposed\ndesign is then analyzed in terms of control signals, power consumption, and\ncommunication system performance, comparing it to two RIS structures with full\ncontrol: one with the same size as the proposed design, and the other employing\nthe minimum number of elements necessary to satisfy the fair coverage\ncriterion. The correlation-based RIS design enables three-dimensional passive\nbeamforming and significantly reduces the number of required load impedances\nand control signals, thereby lowering the hardware cost and simplifying the\ncontrol circuitry. It also achieves substantial power savings as compared to\nthe baseline schemes, while maintaining sufficient gain for a fair radio\ncoverage. For instance, numerical simulations demonstrate that the proposed\ndesign reduces the power consumption by almost 86-92\\% and the control signals\nby 83-98\\% compared to operation with fully controlled RIS.", "AI": {"tldr": "The paper introduces Connected-RIS, a novel design for reconfigurable intelligent surfaces (RIS) that simplifies hardware and reduces energy consumption by leveraging phase shift correlation between surface elements.", "motivation": "To reduce hardware complexity and energy consumption in RIS-based wireless communication systems.", "method": "Conducted correlation analysis of phase shift values based on azimuth angles within a coverage of $-80^{\\circ}$ to $80^{\\circ}$. Correlated elements share control signals and are used to develop Connected-RIS structure.", "result": "Connected-RIS achieved significant hardware simplification, reducing load impedances and control signals by 83-98%, and power consumption by 86-92%, compared to fully controlled RIS structures.", "conclusion": "Connected-RIS enables effective passive beamforming while lowering hardware costs and achieving substantial energy savings, without compromising radio coverage gain."}}
{"id": "2506.22776", "pdf": "https://arxiv.org/pdf/2506.22776", "abs": "https://arxiv.org/abs/2506.22776", "authors": ["Sen Fang", "Weiyuan Ding", "Antonio Mastropaolo", "Bowen Xu"], "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "13 pages, 6 figures", "summary": "Quantization has emerged as a mainstream method for compressing Large\nLanguage Models (LLMs), reducing memory requirements and accelerating inference\nwithout architectural modifications. While existing research primarily focuses\non evaluating the effectiveness of quantized LLMs compared to their original\ncounterparts, the impact on robustness remains largely unexplored.In this\npaper, we present the first systematic investigation of how quantization\naffects the robustness of LLMs in code generation tasks. Through extensive\nexperiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and\nStarCoder) with parameter scales ranging from 350M to 33B, we evaluate\nrobustness from dual perspectives: adversarial attacks on input prompts and\nnoise perturbations on model architecture. Our findings challenge conventional\nwisdom by demonstrating that quantized LLMs often exhibit superior robustness\ncompared to their full-precision counterparts, with 51.59% versus 42.86% of our\nadversarial experiments showing better resilience in quantized LLMs. Similarly,\nour noise perturbation experiments also confirm that LLMs after quantitation\ngenerally withstand higher levels of weight disturbances. These results suggest\nthat quantization not only reduces computational requirements but can actually\nenhance LLMs' reliability in code generation tasks, providing valuable insights\nfor developing more robust and efficient LLM deployment strategies.", "AI": {"tldr": "Quantization improves robustness in large language models (LLMs) for code generation tasks.", "motivation": "Quantization has been widely used to compress LLMs and reduce computation costs, but its impact on robustness remains unclear.", "method": "Systematic robustness analysis of quantized LLMs in code generation tasks using adversarial attacks and noise perturbations on models across four LLM families.", "result": "Quantized LLMs show higher robustness, with 51.59% of adversarial tests and better tolerance to noise compared to full-precision models.", "conclusion": "Quantization not only enhances computational efficiency but also improves LLM robustness, benefiting code generation tasks and deployment strategies."}}
{"id": "2506.22884", "pdf": "https://arxiv.org/pdf/2506.22884", "abs": "https://arxiv.org/abs/2506.22884", "authors": ["Praveen Kumar Donta", "Qiyang Zhang", "Schahram Dustdar"], "title": "Performance Measurements in the AI-Centric Computing Continuum Systems", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "Over the Eight decades, computing paradigms have shifted from large,\ncentralized systems to compact, distributed architectures, leading to the rise\nof the Distributed Computing Continuum (DCC). In this model, multiple layers\nsuch as cloud, edge, Internet of Things (IoT), and mobile platforms work\ntogether to support a wide range of applications. Recently, the emergence of\nGenerative AI and large language models has further intensified the demand for\ncomputational resources across this continuum. Although traditional performance\nmetrics have provided a solid foundation, they need to be revisited and\nexpanded to keep pace with changing computational demands and application\nrequirements. Accurate performance measurements benefit both system designers\nand users by supporting improvements in efficiency and promoting alignment with\nsystem goals. In this context, we review commonly used metrics in DCC and IoT\nenvironments. We also discuss emerging performance dimensions that address\nevolving computing needs, such as sustainability, energy efficiency, and system\nobservability. We also outline criteria and considerations for selecting\nappropriate metrics, aiming to inspire future research and development in this\ncritical area.", "AI": {"tldr": "This paper reviews traditional performance metrics in Distributed Computing Continuum (DCC) and Internet of Things (IoT) environments, proposes new metrics addressing sustainability, energy efficiency, and observability, and offers criteria to inspire future research.", "motivation": "The computing paradigm has evolved into a Distributed Computing Continuum where computational demands have intensified due to Generative AI, requiring new approaches to performance measurement.", "method": "The paper reviews traditional performance metrics used in DCC and IoT systems, while introducing emerging dimensions of performance and outlining criteria for metric selection.", "result": "Emerging performance aspects such as sustainability, energy efficiency, and system observability are highlighted to meet the evolving needs of Generative AI and large-scale applications.", "conclusion": "Expanding performance metrics in DCC and IoT is essential for efficiency and aligning computational resources with future application needs."}}
{"id": "2506.22476", "pdf": "https://arxiv.org/pdf/2506.22476", "abs": "https://arxiv.org/abs/2506.22476", "authors": ["A. Subedi", "S. De", "L. Cavuoto", "S. Schwaitzberg", "M. Hackett", "J. Norfleet"], "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.LG", "q-bio.NC", "I.2.6; J.3; H.1.2"], "comment": null, "summary": "Objective skill assessment in high-stakes procedural environments requires\nmodels that not only decode underlying cognitive and motor processes but also\ngeneralize across tasks, individuals, and experimental contexts. While prior\nwork has demonstrated the potential of functional near-infrared spectroscopy\n(fNIRS) for evaluating cognitive-motor performance, existing approaches are\noften task-specific, rely on extensive preprocessing, and lack robustness to\nnew procedures or conditions. Here, we introduce an interpretable\ntransformer-based foundation model trained on minimally processed fNIRS signals\nfor cross-procedural skill assessment. Pretrained using self-supervised\nlearning on data from laparoscopic surgical tasks and endotracheal intubation\n(ETI), the model achieves greater than 88% classification accuracy on all\ntasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It\ngeneralizes to a novel emergency airway procedure--cricothyrotomy--using fewer\nthan 30 labeled samples and a lightweight (less than 2k parameter) adapter\nmodule, attaining an AUC greater than 87%. Interpretability is achieved via a\nnovel channel attention mechanism--developed specifically for fNIRS--that\nidentifies functionally coherent prefrontal sub-networks validated through\nablation studies. Temporal attention patterns align with task-critical phases\nand capture stress-induced changes in neural variability, offering insight into\ndynamic cognitive states.", "AI": {"tldr": "The paper presents a transformer-based model for skill assessment using fNIRS signals, which generalizes effectively across tasks and individuals, achieving high accuracy even with minimal data on new tasks.", "motivation": "To develop a model for objective skill assessment in cognitive-motor tasks that generalizes across different tasks, individuals, and contexts without relying on extensive preprocessing.", "method": "A transformer-based model trained on minimally processed fNIRS signals using self-supervised learning, pretrained on surgical tasks, and validated on a novel task with lightweight adapters.", "result": "The model achieved >88% classification accuracy on all tasks, an MCC >0.91 on ETI, and >87% AUC on a new procedure using fewer than 30 labeled samples.", "conclusion": "The proposed model demonstrates strong task generalization, interpretability through novel attention mechanisms, and provides insights into neural processes underlying cognitive performance."}}
{"id": "2506.22742", "pdf": "https://arxiv.org/pdf/2506.22742", "abs": "https://arxiv.org/abs/2506.22742", "authors": ["Wali Mohammad Abdullah", "Md. Morshedul Islam", "Devraj Parmar", "Happy Hasmukhbhai Patel", "Sindhuja Prabhakaran", "Baidya Saha"], "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to\nassist software development, yet they often produce incomplete code or\nincorrect imports, especially when lacking access to external or\nproject-specific documentation. We introduce RAILS (Retrieval-Augmented\nIntelligence for Learning Software Development), a framework that augments LLM\nprompts with semantically retrieved context from curated Java resources using\nFAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop\nguided by compiler feedback to refine suggestions. We evaluated RAILS on 78\nreal-world Java import error cases spanning standard libraries, GUI APIs,\nexternal tools, and custom utilities. Despite using the same LLM, RAILS\noutperforms baseline prompting by preserving intent, avoiding hallucinations,\nand surfacing correct imports even when libraries are unavailable locally.\nFuture work will integrate symbolic filtering via PostgreSQL and extend support\nto other languages and IDEs.", "AI": {"tldr": "RAILS improves software development by augmenting LLM prompts with retrieved context and compiler feedback, outperforming baseline methods in resolving Java import errors.", "motivation": "LLMs often produce incorrect or incomplete code due to limited access to project-specific or external documentation.", "method": "RAILS enhances LLM capabilities using FAISS and OpenAI embeddings for semantic retrieval of Java resources, combined with iterative compiler feedback loops.", "result": "RAILS successfully resolved 78 real-world Java import errors, outperforming standard LLM prompting by retaining developer intent and avoiding hallucinations.", "conclusion": "RAILS effectively addresses code generation challenges with retrieval-augmented methods and iterative feedback, paving the way for future multi-language and IDE integrations."}}
{"id": "2506.22491", "pdf": "https://arxiv.org/pdf/2506.22491", "abs": "https://arxiv.org/abs/2506.22491", "authors": ["Oliver Warke", "Joemon M. Jose", "Faegheh Hasibi", "Jan Breitsohl"], "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; J.4; K.4.2"], "comment": null, "summary": "Given the rise of conflicts on social media, effective classification models\nto detect harmful behaviours are essential. Following the\ngarbage-in-garbage-out maxim, machine learning performance depends heavily on\ntraining data quality. However, high-quality labelled data, especially for\nnuanced tasks like identifying conflict behaviours, is limited, expensive, and\ndifficult to obtain. Additionally, as social media platforms increasingly\nrestrict access to research data, text data augmentation is gaining attention\nas an alternative to generate training data. Augmenting conflict-related data\nposes unique challenges due to Large Language Model (LLM) guardrails that\nprevent generation of offensive content. This paper introduces PromptAug, an\ninnovative LLM-based data augmentation method. PromptAug achieves statistically\nsignificant improvements of 2% in both accuracy and F1-score on conflict and\nemotion datasets. To thoroughly evaluate PromptAug against other data\naugmentation methods we conduct a robust evaluation using extreme data scarcity\nscenarios, quantitative diversity analysis and a qualitative thematic analysis.\nThe thematic analysis identifies four problematic patterns in augmented text:\nLinguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and\nAugmented Content Misinterpretation.\n  Overall, this work presents PromptAug as an effective method for augmenting\ndata in sensitive tasks like conflict detection, offering a unique,\ninterdisciplinary evaluation grounded in both natural language processing and\nsocial science methodology.", "AI": {"tldr": "The study introduces PromptAug, an innovative Large Language Model-based data augmentation method that improves text classification accuracy and F1-score on conflict and emotion datasets amid challenges like limited labeled data and content generation guardrails.", "motivation": "With the growing prevalence of conflicts on social media, there is an urgent need for robust classification models to detect harmful behaviors. The challenge lies in the limited availability, cost, and difficulties associated with obtaining high-quality labeled training data for sensitive tasks.", "method": "The paper presents PromptAug, a data augmentation approach using Large Language Models (LLMs) to address challenges in generating conflict-related text data. To assess its performance, the study includes evaluations under extreme data scarcity scenarios, statistical diversity analyses, and qualitative thematic analyses.", "result": "PromptAug significantly improved classification accuracy and F1-score by 2% on conflict and emotion datasets. A thematic analysis also identified four problematic patterns in the augmented data: Linguistic Fluidity, Humor Ambiguity, Content Ambiguity, and Content Misinterpretation.", "conclusion": "PromptAug provides an effective LLM-based data augmentation technique for sensitive tasks like detecting social media conflicts, bridging natural language processing and social science methodologies to enhance classification performance amidst data limitations."}}
{"id": "2506.22572", "pdf": "https://arxiv.org/pdf/2506.22572", "abs": "https://arxiv.org/abs/2506.22572", "authors": ["Mrunmayi Mungekar", "Sanjith Menon", "M. Ravi Shankar", "M. Khalid Jawed"], "title": "Directed Shape Morphing using Kirigami-enhanced Thermoplastics", "categories": ["cs.RO"], "comment": "Software and Data: https://github.com/structuresComp/Shrinky-Dink", "summary": "We present a simple, accessible method for autonomously transforming flat\nplastic sheets into intricate three-dimensional structures using only uniform\nheating and common tools such as household ovens and scissors. Our approach\ncombines heat-shrinkable thermoplastics with Kirigami patterns tailored to the\ntarget 3D shape, creating bilayer composites that morph into a wide range of\ncomplex structures, e.g., bowls, pyramids, and even custom ergonomic surfaces\nlike mouse covers. Critically, the transformation is driven by a\nlow-information stimulus (uniform heat) yet produces highly intricate shapes\nthrough programmed geometric design. The morphing behavior, confirmed by finite\nelement simulations, arises from strain mismatch between the contracting\nthermoplastic layer and the constraining Kirigami layer. By decoupling material\ncomposition from mechanical response, this method avoids detailed process\ncontrol and enables a broad class of self-morphing structures, offering a\nversatile platform for adaptive design and scalable manufacturing.", "AI": {"tldr": "The paper introduces a straightforward method to turn flat plastic sheets into intricate 3D structures using heat and simple tools.", "motivation": "To provide an accessible and adaptable method for creating complex self-morphing structures without detailed process control.", "method": "Combining heat-shrinkable thermoplastics with Kirigami patterns to create bilayer composites that morph into 3D shapes using uniform heating.", "result": "The method successfully produces various intricate shapes confirmed by finite element simulations, driven by strain mismatch in the composites.", "conclusion": "This approach enables scalable manufacturing and adaptive design of self-morphing structures by simplifying material-morphing processes using low-information stimuli."}}
{"id": "2506.22740", "pdf": "https://arxiv.org/pdf/2506.22740", "abs": "https://arxiv.org/abs/2506.22740", "authors": ["Jessica Hullman", "Ziyang Guo", "Berk Ustun"], "title": "Explanations are a means to an end", "categories": ["cs.AI", "stat.ML"], "comment": null, "summary": "Modern methods for explainable machine learning are designed to describe how\nmodels map inputs to outputs--without deep consideration of how these\nexplanations will be used in practice. This paper argues that explanations\nshould be designed and evaluated with a specific end in mind. We describe how\nto formalize this end in a framework based in statistical decision theory. We\nshow how this functionally-grounded approach can be applied across diverse use\ncases, such as clinical decision support, providing recourse, or debugging. We\ndemonstrate its use to characterize the maximum \"boost\" in performance on a\nparticular task that an explanation could provide an idealized decision-maker,\npreventing misuse due to ambiguity by forcing researchers to specify concrete\nuse cases that can be analyzed in light of models of expected explanation use.\nWe argue that evaluation should meld theoretical and empirical perspectives on\nthe value of explanation, and contribute definitions that span these\nperspectives.", "AI": {"tldr": "The paper highlights that explanations in machine learning should be designed with specific applications in mind, using a framework based on statistical decision theory.", "motivation": "Explanations in machine learning often neglect consideration of practical use cases, potentially leading to suboptimal application and ambiguity.", "method": "The authors propose a framework rooted in statistical decision theory to align explanations with concrete use cases like clinical decision-making and debugging.", "result": "The framework offers insights into how explanations can enhance task performance and prevent misuse by mandating specific use-case analysis.", "conclusion": "Evaluations of explanations should integrate both theoretical and empirical perspectives, encouraging a focus on their utility in clearly-defined applications."}}
{"id": "2506.22963", "pdf": "https://arxiv.org/pdf/2506.22963", "abs": "https://arxiv.org/abs/2506.22963", "authors": ["Kevin Lam", "William Daniels", "J Maxwell Douglas", "Daniel Lai", "Samuel Aparicio", "Benjamin Bloem-Reddy", "Yongjin Park"], "title": "CN-SBM: Categorical Block Modelling For Primary and Residual Copy Number Variation", "categories": ["stat.ML", "cs.LG", "q-bio.GN"], "comment": "8 pages, 4 figures", "summary": "Cancer is a genetic disorder whose clonal evolution can be monitored by\ntracking noisy genome-wide copy number variants. We introduce the Copy Number\nStochastic Block Model (CN-SBM), a probabilistic framework that jointly\nclusters samples and genomic regions based on discrete copy number states using\na bipartite categorical block model. Unlike models relying on Gaussian or\nPoisson assumptions, CN-SBM respects the discrete nature of CNV calls and\ncaptures subpopulation-specific patterns through block-wise structure. Using a\ntwo-stage approach, CN-SBM decomposes CNV data into primary and residual\ncomponents, enabling detection of both large-scale chromosomal alterations and\nfiner aberrations. We derive a scalable variational inference algorithm for\napplication to large cohorts and high-resolution data. Benchmarks on simulated\nand real datasets show improved model fit over existing methods. Applied to\nTCGA low-grade glioma data, CN-SBM reveals clinically relevant subtypes and\nstructured residual variation, aiding patient stratification in survival\nanalysis. These results establish CN-SBM as an interpretable, scalable\nframework for CNV analysis with direct relevance for tumor heterogeneity and\nprognosis.", "AI": {"tldr": "The paper introduces a new probabilistic framework (CN-SBM) to analyze genetic cancer data by clustering based on copy number variants, achieving better results than existing models and aiding in identifying clinically relevant cancer subtypes.", "motivation": "The study aims to address the need for a model that can effectively analyze and interpret noisy genome-wide copy number variations (CNVs) in cancer research, particularly for tracking clonal evolution in tumors.", "method": "The authors developed the Copy Number Stochastic Block Model (CN-SBM), a bipartite categorical block model that clusters samples and regions based on discrete CNV states, leveraging a scalable variational inference algorithm for large datasets.", "result": "CN-SBM performs better than existing methods on simulated and real datasets. Application to TCGA glioma data uncovered clinically relevant subtypes and residual variations that enhanced patient classification and survival analysis.", "conclusion": "CN-SBM provides a scalable, interpretable framework for analyzing CNV data, contributing insights into tumor heterogeneity and improving cancer prognosis and patient stratification."}}
{"id": "2506.22444", "pdf": "https://arxiv.org/pdf/2506.22444", "abs": "https://arxiv.org/abs/2506.22444", "authors": ["Jing Wang", "Amar Sra", "Jeremy C. Weiss"], "title": "Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC,\npose a significant challenge to healthcare systems worldwide. Accurate\nidentification of progression events, such as hospitalization and reinfection,\nis essential for effective patient management and resource allocation. However,\ntraditional models trained on structured data struggle to capture the nuanced\nprogression of PASC. In this study, we introduce the first publicly available\ncohort of 18 PASC patients, with text time series features based on Large\nLanguage Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical\nexpert. We propose an Active Attention Network to predict the clinical risk and\nidentify progression events related to the risk. By integrating human expertise\nwith active learning, we aim to enhance clinical risk prediction accuracy and\nenable progression events identification with fewer number of annotation. The\nultimate goal is to improves patient care and decision-making for SARS-CoV-2\npatient.", "AI": {"tldr": "The paper introduces a cohort and a deep learning model to better predict clinical risks and progression events for PASC patients.", "motivation": "Traditional models fail to effectively capture the nuanced progression of PASC, creating challenges in healthcare resource allocation and patient management.", "method": "The study presents an Active Attention Network integrating human expertise and active learning, combined with text features derived from a large language model and expert clinical annotation.", "result": "The proposed model successfully predicts clinical risks and identifies progression events with a reduced need for annotations.", "conclusion": "This approach improves clinical risk prediction accuracy and facilitates better decision-making and care for PASC patients."}}
{"id": "2506.22498", "pdf": "https://arxiv.org/pdf/2506.22498", "abs": "https://arxiv.org/abs/2506.22498", "authors": ["Hao Liu", "Yu Hu", "Rakiba Rayhana", "Ling Bai", "Zheng Liu"], "title": "ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Bed-related falls remain a leading source of injury in hospitals and\nlong-term-care facilities, yet many commercial alarms trigger only after a\npatient has already left the bed. We show that early bed-exit intent can be\npredicted using only four low-cost load cells mounted under the bed legs. The\nresulting load signals are first converted into a compact set of complementary\nimages: an RGB line plot that preserves raw waveforms and three texture maps -\nrecurrence plot, Markov transition field, and Gramian angular field - that\nexpose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin\nTransformer that processes the line plot and texture maps in parallel and fuses\nthem through cross-attention to learn data-driven modality weights.\n  To provide a realistic benchmark, we collected six months of continuous data\nfrom 95 beds in a long-term-care facility. On this real-world dataset\nViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing\nrecent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.\nThe results demonstrate that image-based fusion of load-sensor signals for time\nseries classification is a practical and effective solution for real-time,\nprivacy-preserving fall prevention.", "AI": {"tldr": "The study proposes using a set of four load cell sensors and a novel dual-stream Swin Transformer (ViFusionTST) for early prediction of bed-exit intent to prevent falls in healthcare environments.", "motivation": "To address the inadequacy of existing bed alarms that trigger only after patients have already exited the bed, leading to falls and injuries in hospitals and long-term-care facilities.", "method": "They used four low-cost load cells mounted under bed legs to capture sensor data, converted these signals into various image formats, and designed a novel model (ViFusionTST) that employs dual-stream Swin Transformer architecture for processing and fusing the data for classification.", "result": "The method was validated on a 6-month real-world dataset from 95 beds, achieving an accuracy of 0.885 and an F1 score of 0.794, outperforming recent baselines in multiple metrics (F1, recall, accuracy, AUPRC).", "conclusion": "Image-based fusion of load-sensor signals is a feasible and effective solution for real-time, privacy-preserving fall prevention in healthcare settings, demonstrating strong performance in predicting bed-exit intent."}}
{"id": "2506.22516", "pdf": "https://arxiv.org/pdf/2506.22516", "abs": "https://arxiv.org/abs/2506.22516", "authors": ["Jingkai Li"], "title": "Can \"consciousness\" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis", "categories": ["cs.CL", "cs.AI", "cs.NE", "q-bio.NC"], "comment": "Published as a journal paper at:\n  https://doi.org/10.1016/j.nlp.2025.100163", "summary": "Integrated Information Theory (IIT) provides a quantitative framework for\nexplaining consciousness phenomenon, positing that conscious systems comprise\nelements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the\nlatest iterations of this framework -- to sequences of Large Language Model\n(LLM) representations, analyzing data derived from existing Theory of Mind\n(ToM) test results. Our study systematically investigates whether the\ndifferences of ToM test performances, when presented in the LLM\nrepresentations, can be revealed by IIT estimates, i.e., $\\Phi^{\\max}$ (IIT\n3.0), $\\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\\Phi$-structure\n(IIT 4.0). Furthermore, we compare these metrics with the Span Representations\nindependent of any estimate for consciousness. This additional effort aims to\ndifferentiate between potential \"consciousness\" phenomena and inherent\nseparations within LLM representational space. We conduct comprehensive\nexperiments examining variations across LLM transformer layers and linguistic\nspans from stimuli. Our results suggest that sequences of contemporary\nTransformer-based LLM representations lack statistically significant indicators\nof observed \"consciousness\" phenomena but exhibit intriguing patterns under\n$\\textit{spatio}$-permutational analyses. The Appendix and code are available\nas Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.", "AI": {"tldr": "This paper applies the Integrated Information Theory (IIT) to examine consciousness in Large Language Model representations, with tests on Theory of Mind performances.", "motivation": "Understanding how IIT metrics can be applied to LLMs to investigate potential markers of \"consciousness\" phenomenon.", "method": "Application of IIT 3.0 and 4.0 metrics, including $\n\\Phi^{\\max}$, $\n\\Phi$, Conceptual Information, and $\n\\Phi$-structure, on LLM data derived from Theory of Mind tests, along with spatio-permutational analyses.", "result": "The study finds no statistically significant indicators of \"consciousness\" in Transformer-based LLM representations but observes intriguing patterns in certain analyses.", "conclusion": "Transformer-based LLM representations may not contain detectable indicators of consciousness based on IIT metrics, but further investigation into structural patterns is warranted."}}
{"id": "2506.23281", "pdf": "https://arxiv.org/pdf/2506.23281", "abs": "https://arxiv.org/abs/2506.23281", "authors": ["Xintong Zhou", "Zhenyang Xu", "Chengnian Sun"], "title": "On the Feasibility of Deduplicating Compiler Bugs with Bisection", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Random testing has proven to be an effective technique for compiler\nvalidation. However, the debugging of bugs identified through random testing\npresents a significant challenge due to the frequent occurrence of duplicate\ntest programs that expose identical compiler bugs. The process to identify\nduplicates is a practical research problem known as bug deduplication. Prior\nmethodologies for compiler bug deduplication primarily rely on program analysis\nto extract bug-related features for duplicate identification, which can result\nin substantial computational overhead and limited generalizability. This paper\ninvestigates the feasibility of employing bisection, a standard debugging\nprocedure largely overlooked in prior research on compiler bug deduplication,\nfor this purpose. Our study demonstrates that the utilization of bisection to\nlocate failure-inducing commits provides a valuable criterion for\ndeduplication, albeit one that requires supplementary techniques for more\naccurate identification. Building on these results, we introduce BugLens, a\nnovel deduplication method that primarily uses bisection, enhanced by the\nidentification of bug-triggering optimizations to minimize false negatives.\nEmpirical evaluations conducted on four real-world datasets demonstrate that\nBugLens significantly outperforms the state-of-the-art analysis-based\nmethodologies Tamer and D3 by saving an average of 26.98% and 9.64% human\neffort to identify the same number of distinct bugs. Given the inherent\nsimplicity and generalizability of bisection, it presents a highly practical\nsolution for compiler bug deduplication in real-world applications.", "AI": {"tldr": "This paper explores bisection for compiler bug deduplication, proposing a new method, BugLens, which reduces human effort compared to existing techniques.", "motivation": "The need for effective compiler bug deduplication methods arises due to challenges in identifying duplicate bugs from random testing outputs, which is computationally costly and lacks generalizability in prior approaches.", "method": "The authors investigate bisection as a duplicate detection mechanism, incorporate it in a new method called BugLens, and enhance it by identifying bug-triggering optimizations to improve accuracy.", "result": "BugLens outperformed existing tools (Tamer and D3) on four datasets, achieving average human effort savings of 26.98% and 9.64% for the same bug identification tasks.", "conclusion": "Bisection, as implemented in BugLens, offers a lightweight and generalizable solution for compiler bug deduplication, making it more practical for real-world applications."}}
{"id": "2506.23395", "pdf": "https://arxiv.org/pdf/2506.23395", "abs": "https://arxiv.org/abs/2506.23395", "authors": ["Xiaohong Chen", "Grigore Rosu"], "title": "FastSet: Parallel Claim Settlement", "categories": ["cs.DC"], "comment": null, "summary": "FastSet is an actor-based distributed protocol for decentralized finance and\nsettlement, which is inspired from blockchains. Account holders cooperate by\nmaking claims, which can include payments, holding and transferring assets,\naccessing and updating shared data, medical records, digital identity, and\nmathematical theorems, among many others. The claims are signed by their owners\nand are broadcast to a decentralized network of validators, which validate and\nsettle them. Validators replicate the global state of the accounts and need not\ncommunicate with each other. In sharp contrast to blockchains, strong\nconsistency is purposely given up as a requirement. Yet, many if not most of\nthe blockchain benefits are preserved. The protocol is proved to be correct,\ndespite its massively parallel nature.", "AI": {"tldr": "FastSet is a decentralized protocol for finance and settlement that offers blockchain-like benefits but avoids requiring strong consistency.", "motivation": "Existing decentralized systems like blockchains face bottlenecks due to the requirement of strong consistency, which limits scalability and performance.", "method": "FastSet employs an actor-based protocol where account holders make signed claims that validators settle independently, allowing parallel operations without validators needing to communicate.", "result": "The protocol ensures correctness and preserves many blockchain benefits despite not enforcing strong consistency.", "conclusion": "FastSet delivers a scalable, decentralized settlement protocol that achieves significant blockchain functionalities in a more efficient way."}}
{"id": "2506.22752", "pdf": "https://arxiv.org/pdf/2506.22752", "abs": "https://arxiv.org/abs/2506.22752", "authors": ["Havvanur Dervi\u015fo\u011flu", "Ru\u015fen Halepmollas\u0131", "Elif Eyvaz"], "title": "Privacy-Preserving Methods for Bug Severity Prediction", "categories": ["cs.SE"], "comment": null, "summary": "Bug severity prediction is a critical task in software engineering as it\nenables more efficient resource allocation and prioritization in software\nmaintenance. While AI-based analyses and models significantly require access to\nextensive datasets, industrial applications face challenges due to data-sharing\nconstraints and the limited availability of labeled data. In this study, we\ninvestigate method-level bug severity prediction using source code metrics and\nLarge Language Models (LLMs) with two widely used datasets. We compare the\nperformance of models trained using centralized learning, federated learning,\nand synthetic data generation. Our experimental results, obtained using two\nwidely recognized software defect datasets, indicate that models trained with\nfederated learning and synthetic data achieve comparable results to centrally\ntrained models without data sharing. Our finding highlights the potential of\nprivacy-preserving approaches such as federated learning and synthetic data\ngeneration to enable effective bug severity prediction in industrial context\nwhere data sharing is a major challenge.\n  The source code and dataset are available at our GitHub repository:\nhttps://github.com/drvshavva/EASE2025-Privacy-Preserving-Methods-for-Bug-Severity-Prediction.", "AI": {"tldr": "This paper explores bug severity prediction through source code metrics and LLMs, comparing centralized learning, federated learning, and synthetic data generation approaches. Results show that federated learning and synthetic data methods perform comparably to centralized models while enabling privacy-preserving practices.", "motivation": "The paper aims to address the challenges in bug severity prediction, specifically the data-sharing constraints and lack of labeled data faced in industrial applications, by exploring privacy-preserving techniques.", "method": "The study used source code metrics and Large Language Models (LLMs) for bug severity prediction on two well-known datasets. It investigated three approaches: centralized learning, federated learning, and synthetic data generation, measuring their comparative performances.", "result": "Experimental results suggest that the federated learning and synthetic data generation methods achieve comparable performance to centralized models without requiring data sharing.", "conclusion": "Privacy-preserving methods like federated learning and synthetic data generation can effectively facilitate bug severity prediction, particularly in data-sensitive industrial scenarios."}}
{"id": "2506.22508", "pdf": "https://arxiv.org/pdf/2506.22508", "abs": "https://arxiv.org/abs/2506.22508", "authors": ["Chenyang Shao", "Tianxing Li", "Chenhao Pu", "Fengli Xu", "Yong Li"], "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text", "categories": ["cs.CL", "cs.AI"], "comment": "This work has been submitted to NeurIPS 2025. Under review", "summary": "In today's digital world, casual user-generated content often contains subtle\ncues that may inadvertently expose sensitive personal attributes. Such risks\nunderscore the growing importance of effective text anonymization to safeguard\nindividual privacy. However, existing methods either rely on rigid replacements\nthat damage utility or cloud-based LLMs that are costly and pose privacy risks.\nTo address these issues, we explore the use of locally deployed smaller-scale\nlanguage models (SLMs) for anonymization. Yet training effective SLMs remains\nchallenging due to limited high-quality supervision. To address the challenge,\nwe propose AgentStealth, a self-reinforcing LLM anonymization framework.First,\nwe introduce an adversarial anonymization workflow enhanced by In-context\nContrastive Learning and Adaptive Utility-Aware Control. Second, we perform\nsupervised adaptation of SLMs using high-quality data collected from the\nworkflow, which includes both anonymization and attack signals. Finally, we\napply online reinforcement learning where the model leverages its internal\nadversarial feedback to iteratively improve anonymization performance.\nExperiments on two datasets show that our method outperforms baselines in both\nanonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight\ndesign supports direct deployment on edge devices, avoiding cloud reliance and\ncommunication-based privacy risks. Our code is open-source at\nhttps://github.com/tsinghua-fib-lab/AgentStealth.", "AI": {"tldr": "The paper presents AgentStealth, a framework for text anonymization using locally deployed lightweight language models to ensure privacy without relying on costly and privacy-risky cloud solutions.", "motivation": "Casual user-generated content often contains cues that can unintentionally reveal sensitive personal data, leading to privacy concerns. Current solutions either harm textual utility or are reliant on costly and risky cloud-based models.", "method": "AgentStealth employs a three-step approach: adversarial anonymization using In-context Contrastive Learning and Adaptive Utility-Aware Control, supervised adaptation of small-scale language models (SLMs) with high-quality curated data, and online reinforcement learning to refine anonymization using self-feedback.", "result": "On two datasets, the proposed method achieved a 12.3% improvement in anonymization effectiveness and a 6.8% utility gain compared to baselines. It is lightweight and deployable on local edge devices.", "conclusion": "AgentStealth provides an effective, privacy-focused anonymization method that balances performance and utility, while eliminating reliance on cloud servers. It enhances text anonymization by leveraging lightweight, locally deployable models."}}
{"id": "2506.22593", "pdf": "https://arxiv.org/pdf/2506.22593", "abs": "https://arxiv.org/abs/2506.22593", "authors": ["Antonello Longo", "Chanyoung Chung", "Matteo Palieri", "Sung-Kyun Kim", "Ali Agha", "Cataldo Guaragnella", "Shehryar Khattak"], "title": "Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Paper accepted to 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Autonomous robots are increasingly playing key roles as support platforms for\nhuman operators in high-risk, dangerous applications. To accomplish challenging\ntasks, an efficient human-robot cooperation and understanding is required.\nWhile typically robotic planning leverages 3D geometric information, human\noperators are accustomed to a high-level compact representation of the\nenvironment, like top-down 2D maps representing the Building Information Model\n(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap\nbetween human readable 2D BIM and the robot 3D maps. In this work, we introduce\nPixels-to-Graph (Pix2G), a novel lightweight method to generate structured\nscene graphs from image pixels and LiDAR maps in real-time for the autonomous\nexploration of unknown environments on resource-constrained robot platforms. To\nsatisfy onboard compute constraints, the framework is designed to perform all\noperation on CPU only. The method output are a de-noised 2D top-down\nenvironment map and a structure-segmented 3D pointcloud which are seamlessly\nconnected using a multi-layer graph abstracting information from object-level\nup to the building-level. The proposed method is quantitatively and\nqualitatively evaluated during real-world experiments performed using the NASA\nJPL NeBula-Spot legged robot to autonomously explore and map cluttered garage\nand urban office like environments in real-time.", "AI": {"tldr": "This paper introduces Pixels-to-Graph (Pix2G), a method for creating structured scene graphs from image pixels and LiDAR data, aimed at improving human-robot cooperation under compute constraints.", "motivation": "The need for efficient human-robot collaboration in risky tasks because humans work better with compact, high-level representations of environments, unlike standard robotic 3D planning.", "method": "Pix2G generates structured scene graphs from real-time data using image pixels and LiDAR maps, operating entirely on CPU to meet resource constraints.", "result": "The method produces structured multi-layer graphs combining denoised 2D maps and segmented 3D point clouds, tested successfully on complex environments using NASA JPL NeBula-Spot robots.", "conclusion": "Pix2G provides a lightweight and efficient solution for bridging human-readable maps and robotic spatial data for real-time exploration in resource-limited systems."}}
{"id": "2506.22774", "pdf": "https://arxiv.org/pdf/2506.22774", "abs": "https://arxiv.org/abs/2506.22774", "authors": ["Michael Papademas", "Xenia Ziouvelou", "Antonis Troumpoukis", "Vangelis Karkaletsis"], "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Artificial Intelligence (AI) technology epitomizes the complex challenges\nposed by human-made artifacts, particularly those widely integrated into\nsociety and exert significant influence, highlighting potential benefits and\ntheir negative consequences. While other technologies may also pose substantial\nrisks, AI's pervasive reach makes its societal effects especially profound. The\ncomplexity of AI systems, coupled with their remarkable capabilities, can lead\nto a reliance on technologies that operate beyond direct human oversight or\nunderstanding. To mitigate the risks that arise, several theoretical tools and\nguidelines have been developed, alongside efforts to create technological tools\naimed at safeguarding Trustworthy AI. The guidelines take a more holistic view\nof the issue but fail to provide techniques for quantifying trustworthiness.\nConversely, while technological tools are better at achieving such\nquantification, they lack a holistic perspective, focusing instead on specific\naspects of Trustworthy AI. This paper aims to introduce an assessment method\nthat combines the ethical components of Trustworthy AI with the algorithmic\nprocesses of PageRank and TrustRank. The goal is to establish an assessment\nframework that minimizes the subjectivity inherent in the self-assessment\ntechniques prevalent in the field by introducing algorithmic criteria. The\napplication of our approach indicates that a holistic assessment of an AI\nsystem's trustworthiness can be achieved by providing quantitative insights\nwhile considering the theoretical content of relevant guidelines.", "AI": {"tldr": "The paper proposes an assessment framework for Trustworthy AI by integrating ethical aspects with algorithmic processes like PageRank and TrustRank.", "motivation": "The increasing integration and influence of AI in society require methods to quantify AI trustworthiness while addressing the shortcomings of existing theoretical guidelines and technical tools.", "method": "The proposed method combines ethical guidelines with the algorithmic frameworks of PageRank and TrustRank to create a quantitative assessment of AI trustworthiness.", "result": "The approach offers a way to holistically assess AI systems, providing quantitative metrics while respecting theoretical guidelines.", "conclusion": "The framework successfully minimizes subjectivity in Trustworthy AI assessments, bridging the gap between theoretical and algorithmic evaluations."}}
{"id": "2506.23396", "pdf": "https://arxiv.org/pdf/2506.23396", "abs": "https://arxiv.org/abs/2506.23396", "authors": ["Kay Giesecke", "Enguerrand Horel", "Chartsiri Jirachotkulthorn"], "title": "AICO: Feature Significance Tests for Supervised Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The opacity of many supervised learning algorithms remains a key challenge,\nhindering scientific discovery and limiting broader deployment -- particularly\nin high-stakes domains. This paper develops model- and distribution-agnostic\nsignificance tests to assess the influence of input features in any regression\nor classification algorithm. Our method evaluates a feature's incremental\ncontribution to model performance by masking its values across samples. Under\nthe null hypothesis, the distribution of performance differences across a test\nset has a non-positive median. We construct a uniformly most powerful,\nrandomized sign test for this median, yielding exact p-values for assessing\nfeature significance and confidence intervals with exact coverage for\nestimating population-level feature importance. The approach requires minimal\nassumptions, avoids model retraining or auxiliary models, and remains\ncomputationally efficient even for large-scale, high-dimensional settings.\nExperiments on synthetic tasks validate its statistical and computational\nadvantages, and applications to real-world data illustrate its practical\nutility.", "AI": {"tldr": "The paper introduces a method to assess the importance of input features in supervised learning algorithms using a model- and distribution-agnostic approach.", "motivation": "Many supervised learning algorithms are opaque, impeding scientific discovery and their deployment in sensitive domains. A method to explain feature importance is needed to address this challenge.", "method": "The authors propose a feature significance test through masking feature values and employing a randomized sign test. The technique avoids retraining or auxiliary models and provides exact p-values and confidence intervals.", "result": "The proposed method demonstrated statistical and computational efficiency in synthetic tasks and proved practically useful in real-world applications.", "conclusion": "This method advances explainability in machine learning by providing an efficient and reliable way to assess feature importance, applicable across various models and distributions."}}
{"id": "2506.22445", "pdf": "https://arxiv.org/pdf/2506.22445", "abs": "https://arxiv.org/abs/2506.22445", "authors": ["Saad Alqithami"], "title": "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "comment": null, "summary": "Cyber-Physical Systems play a critical role in the infrastructure of various\nsectors, including manufacturing, energy distribution, and autonomous\ntransportation systems. However, their increasing connectivity renders them\nhighly vulnerable to sophisticated cyber threats, such as adaptive and zero-day\nattacks, against which traditional security methods like rule-based intrusion\ndetection and single-agent reinforcement learning prove insufficient. To\novercome these challenges, this paper introduces a novel Hierarchical\nAdversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework.\nHAMARL employs a hierarchical structure consisting of local agents dedicated to\nsubsystem security and a global coordinator that oversees and optimizes\ncomprehensive, system-wide defense strategies. Furthermore, the framework\nincorporates an adversarial training loop designed to simulate and anticipate\nevolving cyber threats, enabling proactive defense adaptation. Extensive\nexperimental evaluations conducted on a simulated industrial IoT testbed\nindicate that HAMARL substantially outperforms traditional multi-agent\nreinforcement learning approaches, significantly improving attack detection\naccuracy, reducing response times, and ensuring operational continuity. The\nresults underscore the effectiveness of combining hierarchical multi-agent\ncoordination with adversarially-aware training to enhance the resilience and\nsecurity of next-generation CPS.", "AI": {"tldr": "This paper introduces the HAMARL framework to bolster cybersecurity in Cyber-Physical Systems via hierarchical multi-agent reinforcement learning and adversarial training.", "motivation": "As Cyber-Physical Systems become more connected and vulnerable to advanced cyber threats, existing security approaches are proving insufficient.", "method": "The HAMARL framework uses a hierarchical multi-agent setup, local agents for subsystem security, a global coordinator for overall defense, and adversarial training to anticipate cyber threats.", "result": "Experimental evaluations on an industrial IoT testbed show HAMARL significantly improves attack detection, response times, and operational continuity compared to traditional methods.", "conclusion": "Integrating hierarchical multi-agent coordination with adversarial-aware training offers enhanced resilience and security for next-generation Cyber-Physical Systems."}}
{"id": "2506.22499", "pdf": "https://arxiv.org/pdf/2506.22499", "abs": "https://arxiv.org/abs/2506.22499", "authors": ["Jiachao Liu", "Pablo Guarda", "Koichiro Niinuma", "Sean Qian"], "title": "Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "This study presents a novel integrated framework for dynamic\norigin-destination demand estimation (DODE) in multi-class mesoscopic network\nmodels, leveraging high-resolution satellite imagery together with conventional\ntraffic data from local sensors. Unlike sparse local detectors, satellite\nimagery offers consistent, city-wide road and traffic information of both\nparking and moving vehicles, overcoming data availability limitations. To\nextract information from imagery data, we design a computer vision pipeline for\nclass-specific vehicle detection and map matching, generating link-level\ntraffic density observations by vehicle class. Building upon this information,\nwe formulate a computational graph-based DODE model that calibrates dynamic\nnetwork states by jointly matching observed traffic counts and travel times\nfrom local sensors with density measurements derived from satellite imagery. To\nassess the accuracy and scalability of the proposed framework, we conduct a\nseries of numerical experiments using both synthetic and real-world data. The\nresults of out-of-sample tests demonstrate that supplementing traditional data\nwith satellite-derived density significantly improves estimation performance,\nespecially for links without local sensors. Real-world experiments also confirm\nthe framework's capability to handle large-scale networks, supporting its\npotential for practical deployment in cities of varying sizes. Sensitivity\nanalysis further evaluates the impact of data quality related to satellite\nimagery data.", "AI": {"tldr": "The paper introduces a new framework for estimating dynamic origin-destination (OD) demand in networks using a combination of satellite imagery and traditional traffic data for better accuracy and scalability.", "motivation": "The motivation behind this work is to address the limitations of traffic data collected from sparse local detectors by integrating satellite imagery, which provides city-wide and consistent traffic information that includes both parking and moving vehicles.", "method": "The approach develops a computer vision pipeline for vehicle detection and map matching from satellite images, creating link-level traffic density observations. A computational graph-based DODE model is then designed to calibrate dynamic network states by integrating both traditional sensor and satellite-derived data.", "result": "Numerical tests demonstrate that integrating satellite-derived data with traditional methods significantly boosts accuracy, particularly for areas lacking local sensors. Real-world experiments show scalability for large city networks, confirming practical applicability.", "conclusion": "The framework effectively improves traffic demand estimation and holds promise for deployment in urban settings across various scales. Sensitivity analysis highlights the importance of satellite data quality."}}
{"id": "2506.22526", "pdf": "https://arxiv.org/pdf/2506.22526", "abs": "https://arxiv.org/abs/2506.22526", "authors": ["Ofer M. Shir", "Michael Emmerich"], "title": "Correlated Mutations for Integer Programming", "categories": ["math.OC", "cs.AI", "cs.NE"], "comment": null, "summary": "Even with the recent theoretical advancements that dramatically reduced the\ncomplexity of Integer Programming (IP), heuristics remain the dominant\nproblem-solvers for this difficult category. This study seeks to establish the\ngroundwork for Integer Evolution Strategies (IESs), a class of randomized\nsearch heuristics inherently designed for continuous spaces. IESs already excel\nin treating IP in practice, but accomplish it via discretization and by\napplying sophisticated patches to their continuous operators, while\npersistently using the $\\ell_2$-norm as their operation pillar. We lay\nfoundations for discrete search, by adopting the $\\ell_1$-norm, accounting for\nthe suitable step-size, and questioning alternative measures to quantify\ncorrelations over the integer lattice. We focus on mutation distributions for\nunbounded integer decision variables. We briefly discuss a couple of candidate\ndiscrete probabilities induced by the uniform and binomial distributions, which\nwe show to possess less appealing theoretical properties, and then narrow down\nto the Truncated Normal (TN) and Double Geometric (DG) distributions. We\nexplore their theoretical properties, including entropy functions, and propose\na procedure to generate scalable correlated mutation distributions. Our\ninvestigations are accompanied by extensive numerical simulations, which\nconsistently support the claim that the DG distribution is better suited for\nunbounded integer search. We link our theoretical perspective to empirical\nevidence indicating that an IES with correlated DG mutations outperformed other\nstrategies over non-separable quadratic IP. We conclude that while the\nreplacement of the default TN distribution by the DG is theoretically justified\nand practically beneficial, the truly crucial change lies in adopting the\n$\\ell_1$-norm over the $\\ell_2$-norm.", "AI": {"tldr": "The paper introduces Integer Evolution Strategies (IESs) as a heuristic method for Integer Programming, focusing on discrete search using the $\n\\ell_1$-norm and evaluating mutation distributions. It finds the Double Geometric (DG) distribution superior for unbounded integer variables and highlights its empirical performance benefits.", "motivation": "Despite recent advancements in Integer Programming theory, heuristics dominate due to the complexity of the problem. The study aims to establish discrete IESs by addressing the limitations of continuous operators and reconsidering metrics for integer lattice search.", "method": "The authors explore mutation distributions for integer decision variables using theoretical analysis and numerical simulations. They evaluate uniform, binomial, truncated normal (TN), and double geometric (DG) distributions, examining entropy functions and scalability for correlated mutations.", "result": "The paper demonstrates that the DG mutation distribution is theoretically and empirically superior for integer search problems. Numerical simulations show its advantage over other strategies, especially for non-separable quadratic Integer Programming problems.", "conclusion": "The paper concludes that adopting the $\n\\ell_1$-norm and DG mutation distribution significantly improves Integer Evolution Strategies. While replacing TN with DG is beneficial, the adoption of the $\n\\ell_1$-norm is deemed a more crucial innovation."}}
{"id": "2506.23696", "pdf": "https://arxiv.org/pdf/2506.23696", "abs": "https://arxiv.org/abs/2506.23696", "authors": ["Francisco Oliveira", "Alexandra Mendes", "Carolina Carreira"], "title": "What Challenges Do Developers Face When Using Verification-Aware Programming Languages?", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Software reliability is critical in ensuring that the digital systems we\ndepend on function correctly. In software development, increasing software\nreliability often involves testing. However, for complex and critical systems,\ndevelopers can use Design by Contract (DbC) methods to define precise\nspecifications that software components must satisfy. Verification-Aware (VA)\nprogramming languages support DbC and formal verification at compile-time or\nrun-time, offering stronger correctness guarantees than traditional testing.\nHowever, despite the strong guarantees provided by VA languages, their adoption\nremains limited. In this study, we investigate the barriers to adopting VA\nlanguages by analyzing developer discussions on public forums using topic\nmodeling techniques. We complement this analysis with a developer survey to\nbetter understand the practical challenges associated with VA languages. Our\nfindings reveal key obstacles to adoption, including steep learning curves and\nusability issues. Based on these insights, we identify actionable\nrecommendations to improve the usability and accessibility of VA languages. Our\nfindings suggest that simplifying tool interfaces, providing better educational\nmaterials, and improving integration with everyday development environments\ncould improve the usability and adoption of these languages. Our work provides\nactionable insights for improving the usability of VA languages and making\nverification tools more accessible.", "AI": {"tldr": "This paper examines why Verification-Aware (VA) programming languages, which provide strong correctness guarantees, are not widely adopted by developers.", "motivation": "To investigate the barriers to adopting VA languages and improve their usability and accessibility since they offer significant benefits for software reliability.", "method": "The study analyzes developer discussions on public forums using topic modeling techniques and complements this analysis with a developer survey.", "result": "Key obstacles to the adoption of VA languages include steep learning curves, usability challenges, and inadequate tool interfaces and educational materials.", "conclusion": "The study suggests actionable recommendations like improving tool interfaces, providing better educational resources, and integrating VA languages into common development environments to boost their adoption."}}
{"id": "2506.23635", "pdf": "https://arxiv.org/pdf/2506.23635", "abs": "https://arxiv.org/abs/2506.23635", "authors": ["Mu-Chi Chen", "Po-Hsuan Huang", "Xiangrui Ke", "Chia-Heng Tu", "Chun Jason Xue", "Shih-Hao Hung"], "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model", "categories": ["cs.DC", "cs.AI", "cs.PF", "I.6.4; I.2.7; I.2.11"], "comment": "International Conference on Research in Adaptive and Convergent\n  Systems (RACS '24), November 5--8, 2024, Pompei, Italy", "summary": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)\nwith significant advancements such as OpenAI's ChatGPT, Meta's Llama, and\nDatabricks' DBRX. This paper addresses the cost and scalability challenges\nencountered when constructing private LLM systems for personal or small group\nservices, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2\nUltra chips is established as a cost-efficient solution to host and accelerate\nthe pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our\nperformance analysis reveal that parallel execution of the model's experts\nacross two to four machine nodes significantly reduces inference time. We find\nthat computation time for the experts is comparable to the communication time\nfor exchanging their outputs, emphasizing the importance of network latency\nover bandwidth. We also observe significant management overhead due to Apple\nsoftware stack's memory management logic. Based on these findings, we develop\noptimization schemes to eliminate the memory management overhead. As a result,\nthe Mac Studio cluster is 1.15 times more cost-efficient than the\nstate-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we\nconstruct a performance model to estimate system performance under varying\nconfigurations, and the model provides valuable insights for designing private\nLLM systems.", "AI": {"tldr": "The paper explores cost-efficient solutions for hosting private LLM systems, using Apple's M2 Ultra chips in a Mac Studio cluster to accelerate the DBRX model with MoE architecture.", "motivation": "The paper aims to tackle cost and scalability challenges in building private LLM systems for smaller-scale applications.", "method": "A Mac Studio cluster with Apple's M2 Ultra chips was utilized to host and accelerate the DBRX model, investigating parallel execution and optimizing software stack memory management.", "result": "The cluster showed significant inference time reductions, was 1.15x more cost-efficient vs NVIDIA H100 GPU supercomputers, and highlighted the importance of network latency over bandwidth.", "conclusion": "The results provide insights for efficient system design, and optimizations make the Mac Studio cluster a competitive option for private LLM system deployment."}}
{"id": "2506.22952", "pdf": "https://arxiv.org/pdf/2506.22952", "abs": "https://arxiv.org/abs/2506.22952", "authors": ["Yanwu Yang", "Thomas Wolfers"], "title": "Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization", "categories": ["eess.IV", "cs.CV", "q-bio.NC"], "comment": null, "summary": "Understanding brain dynamics through functional Magnetic Resonance Imaging\n(fMRI) remains a fundamental challenge in neuroscience, particularly in\ncapturing how the brain transitions between various functional states.\nRecently, metastability, which refers to temporarily stable brain states, has\noffered a promising paradigm to quantify complex brain signals into\ninterpretable, discretized representations. In particular, compared to\ncluster-based machine learning approaches, tokenization approaches leveraging\nvector quantization have shown promise in representation learning with powerful\nreconstruction and predictive capabilities. However, most existing methods\nignore brain transition dependencies and lack a quantification of brain\ndynamics into representative and stable embeddings. In this study, we propose a\nHierarchical State space-based Tokenization network, termed HST, which\nquantizes brain states and transitions in a hierarchical structure based on a\nstate space-based model. We introduce a refined clustered Vector-Quantization\nVariational AutoEncoder (VQ-VAE) that incorporates quantization error feedback\nand clustering to improve quantization performance while facilitating\nmetastability with representative and stable token representations. We validate\nour HST on two public fMRI datasets, demonstrating its effectiveness in\nquantifying the hierarchical dynamics of the brain and its potential in disease\ndiagnosis and reconstruction performance. Our method offers a promising\nframework for the characterization of brain dynamics, facilitating the analysis\nof metastability.", "AI": {"tldr": "This paper introduces HST, a novel tokenization method for fMRI brain dynamics, using a hierarchical state space and enhanced VQ-VAE to quantify metastability and transitions.", "motivation": "The authors aim to address the challenges in studying brain dynamics through fMRI, particularly the insufficient representation of brain state transitions and metastability in existing tokenization methods.", "method": "The study proposes a Hierarchical State space-based Tokenization network (HST), enhancing VQ-VAE with quantization error feedback and clustering for improved metastability representation.", "result": "HST was validated on two public fMRI datasets, showcasing superior performance in quantifying hierarchical brain dynamics and potential applications in disease diagnosis.", "conclusion": "This method enables deeper exploration of brain dynamics, enhancing metastability analysis and providing a robust framework for further neurological research."}}
{"id": "2506.22510", "pdf": "https://arxiv.org/pdf/2506.22510", "abs": "https://arxiv.org/abs/2506.22510", "authors": ["Zihao Zhao", "Xinlong Zhai", "Jinyu Yang", "Chuan Shi"], "title": "Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "Foundation models have achieved great success in natural language processing\n(NLP) and computer vision (CV). Their success largely stems from the ability to\nintegrate multi-domain knowledge in pre-training and transfer it to target\ndomains. Considering graph data, especially graphs without textual features, is\nubiquitous in real-world applications such as social networks and\nrecommendation systems, some researchers have attempted to extend this paradigm\nto the graph field, aiming to construct graph foundation models. However,\nunlike CV and NLP, there are huge gaps among the semantics and properties of\ngraphs in different domains, while current works still adopt traditional\ncontrastive pre-training strategies designed in the single-domain scenario,\nwhich regard contrastive samples from different domains as equivalent. From\nexperimental investigations, we discovered that inherent domain-specific\ndifferences prevent these strategies from effectively absorbing knowledge from\ndifferent domains to generate informative representations. In this paper, we\npropose a novel multi-domain pre-training and cross-domain transfer framework,\nnamely MDGCL.In the pre-training stage, we design a contrastive learning\nstrategy to substantially recognize and capture domain differences, and\nintroduce domain tokens to encode domain-level global information. In the\ndownstream stage, we introduce a domain attention mechanism to enable\nfine-grained domain knowledge transfer. Extensive experiments on five benchmark\ndatasets have demonstrated that our method outperforms state-of-the-art\nsignificantly, with the maximum improvement of 19.33\\% on accuracy and 19.13\\%\non Macro-F1 score.", "AI": {"tldr": "The paper introduces MDGCL, a framework for effective multi-domain pre-training and cross-domain transfer in graph data, addressing challenges in domain-specific differences.", "motivation": "Foundation models effectively transfer multi-domain knowledge in NLP and CV, but struggle in the graph domain due to domain semantic gaps and inappropriate contrastive pre-training strategies.", "method": "MDGCL introduces: (1) domain-aware contrastive learning to capture domain differences during pre-training, (2) domain tokens for encoding domain-global information, and (3) a domain attention mechanism for fine-grained knowledge transfer during downstream tasks.", "result": "Experiments on five benchmarks show MDGCL significantly improves performance, achieving accuracy gains of up to 19.33% and Macro-F1 improvements of up to 19.13%.", "conclusion": "MDGCL addresses domain-specific challenges in graph data, achieving superior results over current methods, and proving to be highly effective for cross-domain knowledge transfer."}}
{"id": "2506.22766", "pdf": "https://arxiv.org/pdf/2506.22766", "abs": "https://arxiv.org/abs/2506.22766", "authors": ["Yiting Chen", "Kenneth Kimble", "Howard H. Qian", "Podshara Chanrungmaneekul", "Robert Seney", "Kaiyu Hang"], "title": "Robust Peg-in-Hole Assembly under Uncertainties via Compliant and Interactive Contact-Rich Manipulation", "categories": ["cs.RO"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025; 16 pages, 10\n  figures", "summary": "Robust and adaptive robotic peg-in-hole assembly under tight tolerances is\ncritical to various industrial applications. However, it remains an open\nchallenge due to perceptual and physical uncertainties from contact-rich\ninteractions that easily exceed the allowed clearance. In this paper, we study\nhow to leverage contact between the peg and its matching hole to eliminate\nuncertainties in the assembly process under unstructured settings. By examining\nthe role of compliance under contact constraints, we present a manipulation\nsystem that plans collision-inclusive interactions for the peg to 1)\niteratively identify its task environment to localize the target hole and 2)\nexploit environmental contact constraints to refine insertion motions into the\ntarget hole without relying on precise perception, enabling a robust solution\nto peg-in-hole assembly. By conceptualizing the above process as the\ncomposition of funneling in different state spaces, we present a formal\napproach to constructing manipulation funnels as an uncertainty-absorbing\nparadigm for peg-in-hole assembly. The proposed system effectively generalizes\nacross diverse peg-in-hole scenarios across varying scales, shapes, and\nmaterials in a learning-free manner. Extensive experiments on a NIST Assembly\nTask Board (ATB) and additional challenging scenarios validate its robustness\nin real-world applications.", "AI": {"tldr": "The paper introduces a manipulation system to perform robust peg-in-hole assembly under unstructured and uncertain conditions without relying on precise perception, using environmental contact constraints and an uncertainty-absorbing approach.", "motivation": "The motivation is to address the challenge of performing robotic peg-in-hole assembly, which is critical for industry but difficult due to perceptual and physical uncertainties exceeding clearance tolerances.", "method": "The method involves leveraging contact mechanics and compliance to iteratively localize the target hole, refine insertion motions through contact constraints, and conceptualizing these actions as manipulation funnels for uncertainty absorption.", "result": "The results show that the proposed system generalizes well across various scales, shapes, and materials in diverse peg-in-hole scenarios, validated through extensive real-world experiments, including those on a NIST Assembly Task Board.", "conclusion": "The paper concludes that the proposed system provides a robust and learning-free solution to peg-in-hole assembly, suitable for unstructured and uncertain conditions."}}
{"id": "2506.22865", "pdf": "https://arxiv.org/pdf/2506.22865", "abs": "https://arxiv.org/abs/2506.22865", "authors": ["Ziqi Zhong", "Xunzhu Tang"], "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed a\nsignificant performance gap between closed-source and open-source models,\nparticularly in tasks requiring complex reasoning and precise instruction\nfollowing. This paper introduces ReasonBridge, a methodology that efficiently\ntransfers reasoning capabilities from powerful closed-source to open-source\nmodels through a novel hierarchical knowledge distillation framework. We\ndevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoning\ntraces emphasizing difficulty, diversity, and quality. These traces are\nfiltered from across multiple domains using a structured multi-criteria\nselection algorithm. Our transfer learning approach incorporates: (1) a\nhierarchical distillation process capturing both strategic abstraction and\ntactical implementation patterns, (2) a sparse reasoning-focused adapter\narchitecture requiring only 0.3% additional trainable parameters, and (3) a\ntest-time compute scaling mechanism using guided inference interventions.\nComprehensive evaluations demonstrate that ReasonBridge improves reasoning\ncapabilities in open-source models by up to 23% on benchmark tasks,\nsignificantly narrowing the gap with closed-source models. Notably, the\nenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its\nperformance on competition-level AIME problems. Our methodology generalizes\neffectively across diverse reasoning domains and model architectures,\nestablishing a sample-efficient approach to reasoning enhancement for\ninstruction following.", "AI": {"tldr": "The paper presents ReasonBridge, a framework for transferring reasoning abilities from closed-source Large Language Models (LLMs) to open-source models using hierarchical knowledge distillation and minimal computational resources.", "motivation": "To address the performance gap in complex reasoning tasks between closed-source and open-source LLMs and improve open-source models' capabilities in instruction following.", "method": "The methodology involves hierarchical knowledge distillation using a tailored reasoning-focused dataset (Reason1K), sparse reasoning adapters, and guided inference interventions for compute scaling.", "result": "ReasonBridge led to a 23% improvement in reasoning capabilities for open-source models, with enhanced models outperforming or matching closed-source counterparts on specific benchmarks.", "conclusion": "ReasonBridge provides a sample-efficient and generalizable solution to better equip open-source models with reasoning capabilities, narrowing the divide between closed-source and open-source model performance."}}
{"id": "2506.23429", "pdf": "https://arxiv.org/pdf/2506.23429", "abs": "https://arxiv.org/abs/2506.23429", "authors": ["Yingyuan Li", "Aokun Wang", "Zhongjian Wang"], "title": "DPOT: A DeepParticle method for Computation of Optimal Transport with convergence guarantee", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we propose a novel machine learning approach to compute the\noptimal transport map between two continuous distributions from their unpaired\nsamples, based on the DeepParticle methods. The proposed method leads to a\nmin-min optimization during training and does not impose any restriction on the\nnetwork structure. Theoretically we establish a weak convergence guarantee and\na quantitative error bound between the learned map and the optimal transport\nmap. Our numerical experiments validate the theoretical results and the\neffectiveness of the new approach, particularly on real-world tasks.", "AI": {"tldr": "The paper introduces a machine learning approach for computing optimal transport maps using DeepParticle methods, validated by theoretical and numerical results.", "motivation": "To address the challenge of computing optimal transport maps between continuous distributions efficiently and accurately.", "method": "A novel machine learning method involving DeepParticle techniques with a min-min optimization strategy is proposed, avoiding restrictions on network structures.", "result": "Theoretical guarantees of weak convergence and error bounds are established, and numerical experiments corroborate the approach's efficacy, including on real-world tasks.", "conclusion": "The study confirms the successful application of the proposed method in calculating optimal transport maps, backed by theoretical validations and practical performance."}}
{"id": "2506.22446", "pdf": "https://arxiv.org/pdf/2506.22446", "abs": "https://arxiv.org/abs/2506.22446", "authors": ["Aakash Tripathi", "Asim Waqas", "Matthew B. Schabath", "Yasin Yilmaz", "Ghulam Rasool"], "title": "EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate cancer survival prediction requires integration of diverse data\nmodalities that reflect the complex interplay between imaging, clinical\nparameters, and textual reports. However, existing multimodal approaches suffer\nfrom simplistic fusion strategies, massive computational requirements, and lack\nof interpretability-critical barriers to clinical adoption. We present EAGLE\n(Efficient Alignment of Generalized Latent Embeddings), a novel deep learning\nframework that addresses these limitations through attention-based multimodal\nfusion with comprehensive attribution analysis. EAGLE introduces four key\ninnovations: (1) dynamic cross-modal attention mechanisms that learn\nhierarchical relationships between modalities, (2) massive dimensionality\nreduction (99.96%) while maintaining predictive performance, (3) three\ncomplementary attribution methods providing patient-level interpretability, and\n(4) a unified pipeline enabling seamless adaptation across cancer types. We\nevaluated EAGLE on 911 patients across three distinct malignancies:\nglioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN,\nn=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis\nshowed high-risk individuals relied more heavily on adverse imaging features,\nwhile low-risk patients demonstrated balanced modality contributions. Risk\nstratification identified clinically meaningful groups with 4-fold (GBM) to\n5-fold (NSCLC) differences in median survival, directly informing treatment\nintensity decisions. By combining state-of-the-art performance with clinical\ninterpretability, EAGLE bridges the gap between advanced AI capabilities and\npractical healthcare deployment, offering a scalable solution for multimodal\nsurvival prediction that enhances both prognostic accuracy and physician trust\nin automated predictions.", "AI": {"tldr": "The paper introduces EAGLE, a deep learning framework for cancer survival prediction using multimodal data fusion, achieving high accuracy, scalability, and interpretability.", "motivation": "To address limitations in existing multimodal cancer survival prediction methods such as simplistic fusion strategies, heavy computational requirements, and lack of interpretability, which hinder clinical adoption.", "method": "EAGLE employs a novel deep learning framework with four key features: dynamic cross-modal attention, significant dimensionality reduction, comprehensive patient-level interpretability, and a unified adaptation pipeline across cancer types.", "result": "EAGLE was tested on data from 911 patients across three cancer types, demonstrating accurate risk stratification and identifying actionable differences in median survival among risk groups (4- to 5-fold differences), with insights into modality contributions by risk level.", "conclusion": "EAGLE successfully combines cutting-edge predictive performance with interpretability and scalability, making it a viable tool for clinical deployment in cancer survival prediction."}}
{"id": "2506.22500", "pdf": "https://arxiv.org/pdf/2506.22500", "abs": "https://arxiv.org/abs/2506.22500", "authors": ["Weiyi Zhao", "Xiaoyu Tan", "Liang Liu", "Sijia Li", "Youwei Song", "Xihe Qiu"], "title": "Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "68T07, 68U10, 92C55", "I.2.10; I.2.7; J.3; I.2.6"], "comment": "13 pages, 5 figures. The dataset and appendix are available at\n  https://github.com/zgg2577/VS-KC", "summary": "Surgical risk identification is critical for patient safety and reducing\npreventable medical errors. While multimodal large language models (MLLMs) show\npromise for automated operating room (OR) risk detection, they often exhibit\nvisual-semantic knowledge conflicts (VS-KC), failing to identify visual safety\nviolations despite understanding textual rules. To address this, we introduce a\ndataset comprising over 34,000 synthetic images generated by diffusion models,\ndepicting operating room scenes containing entities that violate established\nsafety rules. These images were created to alleviate data scarcity and examine\nMLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated\nimages that serve as a gold-standard reference for validation. This\ncomprehensive dataset, spanning diverse perspectives, stages, and\nconfigurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC\nsignificantly improves MLLMs' detection of trained conflict entities and\ngeneralizes well to new viewpoints for these entities, but performance on\nuntrained entity types remains poor, highlighting learning specificity and the\nneed for comprehensive training. The main contributions of this work include:\n(1) a data generation methodology tailored for rule-violation scenarios; (2)\nthe release of the OR-VSKC dataset and its associated benchmark as open-source\nresources; and (3) an empirical analysis of violation-sensitive knowledge\nconsistency in representative MLLMs. The dataset and appendix are available at\nhttps://github.com/zgg2577/VS-KC.", "AI": {"tldr": "The paper introduces a synthetic dataset to improve multimodal large language models for detecting rule violations in surgical operating rooms, addressing their current visual-semantic inconsistencies.", "motivation": "The motivation is to enhance patient safety in surgical environments by addressing the shortcomings of current multimodal large language models, which struggle with visual-semantic conflict issues in identifying safety violations.", "method": "The authors generated a dataset of 34,000 synthetic images using diffusion models, along with 214 human-annotated images for gold-standard validation, to fine-tune and evaluate MLLMs' ability to detect rule violations visually.", "result": "Fine-tuning MLLMs with the new dataset improved their detection of trained conflicts and generalization to new perspectives; however, they performed poorly on untrained entity types.", "conclusion": "The study reveals that while the new dataset improves MLLMs' understanding of safety rule violations in operating rooms, further comprehensive training is needed for better generalizability."}}
{"id": "2506.22771", "pdf": "https://arxiv.org/pdf/2506.22771", "abs": "https://arxiv.org/abs/2506.22771", "authors": ["Jingxiao Ma", "Priyadarshini Panda", "Sherief Reda"], "title": "FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision", "categories": ["cs.LG", "cs.AI", "cs.NE", "I.2.0; I.2.6"], "comment": "To be published in the 62nd Design Automation Conference (DAC), 2025", "summary": "Backpropagation has been the cornerstone of neural network training for\ndecades, yet its inefficiencies in time and energy consumption limit its\nsuitability for resource-constrained edge devices. While low-precision neural\nnetwork quantization has been extensively researched to speed up model\ninference, its application in training has been less explored. Recently, the\nForward-Forward (FF) algorithm has emerged as a promising alternative to\nbackpropagation, replacing the backward pass with an additional forward pass.\nBy avoiding the need to store intermediate activations for backpropagation, FF\ncan reduce memory footprint, making it well-suited for embedded devices. This\npaper presents an INT8 quantized training approach that leverages FF's\nlayer-by-layer strategy to stabilize gradient quantization. Furthermore, we\npropose a novel \"look-ahead\" scheme to address limitations of FF and improve\nmodel accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board\ndemonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in\nmemory usage, while maintaining competitive accuracy compared to the\nstate-of-the-art.", "AI": {"tldr": "The paper explores an INT8 quantized training strategy based on the Forward-Forward (FF) algorithm to address inefficiencies of backpropagation on edge devices, achieving faster training, energy savings, and reduced memory.", "motivation": "To address the inefficiencies of backpropagation in terms of time, energy, and memory, particularly for resource-constrained edge devices.", "method": "The authors use an INT8 quantized training method combined with the FF algorithm and introduce a 'look-ahead' scheme to bypass limitations of FF and stabilize gradient quantization.", "result": "The proposed approach achieved 4.6% faster training, 8.3% energy savings, and a 27.0% reduction in memory usage on the NVIDIA Jetson Orin Nano board, maintaining competitive accuracy.", "conclusion": "The combination of FF with INT8 quantization and the 'look-ahead' enhancement demonstrates significant advantages in performance, efficiency, and suitability for embedded systems while retaining accurate results."}}
{"id": "2506.23405", "pdf": "https://arxiv.org/pdf/2506.23405", "abs": "https://arxiv.org/abs/2506.23405", "authors": ["Faaiq Waqar", "Ming-Yen Lee", "Seongwon Yoon", "Seongkwang Lim", "Shimeng Yu"], "title": "CMOS+X: Stacking Persistent Embedded Memories based on Oxide Transistors upon GPGPU Platforms", "categories": ["cs.ET", "cs.AR", "B.8.2; B.3.1"], "comment": "14 pages, 18 figures, 4 tables, 4 equations", "summary": "In contemporary general-purpose graphics processing units (GPGPUs), the\ncontinued increase in raw arithmetic throughput is constrained by the\ncapabilities of the register file (single-cycle) and last-level cache (high\nbandwidth), which require the delivery of operands at a cadence demanded by\nwide single-instruction multiple-data (SIMD) lanes. Enhancing the capacity,\ndensity, or bandwidth of these memories can unlock substantial performance\ngains; however, the recent stagnation of SRAM bit-cell scaling leads to\ninequivalent losses in compute density.\n  To address the challenges posed by SRAM's scaling and leakage power\nconsumption, this paper explores the potential CMOS+X integration of amorphous\noxide semiconductor (AOS) transistors in capacitive, persistent memory\ntopologies (e.g., 1T1C eDRAM, 2T0C/3T0C Gain Cell) as alternative cells in\nmulti-ported and high-bandwidth banked GPGPU memories. A detailed study of the\ndensity and energy tradeoffs of back-end-of-line (BEOL) integrated memories\nutilizing monolithic 3D (M3D)-integrated multiplexed arrays is conducted, while\naccounting for the macro-level limitations of integrating AOS candidate\nstructures proposed by the device community (an aspect often overlooked in\nprior work). By exploiting the short lifetime of register operands, we propose\na multi-ported AOS gain-cell capable of delivering 3x the read ports in ~76% of\nthe footprint of SRAM with over 70% lower standby power, enabling enhancements\nto compute capacity, such as larger warp sizes or processor counts. Benchmarks\nrun on a validated NVIDIA Ampere-class GPU model, using a modified version of\nAccel-Sim, demonstrate improvements of up to 5.2x the performance per watt and\nan average 8% higher geometric mean instruction per cycle (IPC) on various\ncompute- and memory-bound tasks.", "AI": {"tldr": "This paper proposes a new memory topology based on amorphous oxide semiconductor (AOS) transistors for GPGPUs, delivering higher energy efficiency and performance gains compared to traditional SRAM.", "motivation": "The scaling challenges and increasing power consumption of SRAM limit advancements in GPGPU memory systems, inhibiting raw arithmetic throughput and compute density.", "method": "The study introduces CMOS+X integration of AOS transistors into capacitive memory topologies, leveraging 3D-integrated memory designs. A detailed evaluation of tradeoffs in density and power efficiency is performed.", "result": "The proposed AOS-based multi-ported gain-cell delivers three times the read ports at ~76% of SRAM's footprint and 70% lower standby power. Benchmarks show performance-per-watt improvements up to 5.2x and 8% higher IPC on average.", "conclusion": "AOS transistor-based memory designs offer a compelling path to overcome SRAM limitations, significantly enhancing GPGPU performance and energy efficiency across diverse workloads."}}
{"id": "2506.23809", "pdf": "https://arxiv.org/pdf/2506.23809", "abs": "https://arxiv.org/abs/2506.23809", "authors": ["Hongtao Xu", "Zibo Wu", "Mingzhen Li", "Weile Jia"], "title": "Large-scale Neural Network Quantum States for ab initio Quantum Chemistry Simulations on Fugaku", "categories": ["cs.DC"], "comment": null, "summary": "Solving quantum many-body problems is one of the fundamental challenges in\nquantum chemistry. While neural network quantum states (NQS) have emerged as a\npromising computational tool, its training process incurs exponentially growing\ncomputational demands, becoming prohibitively expensive for large-scale\nmolecular systems and creating fundamental scalability barriers for real-world\napplications. To address above challenges, we present \\ours, a high-performance\nNQS training framework for \\textit{ab initio} electronic structure\ncalculations. First, we propose a scalable sampling parallelism strategy with\nmulti-layers workload division and hybrid sampling scheme, which break the\nscalability barriers for large-scale NQS training. Then, we introduce\nmulti-level parallelism local energy parallelism, enabling more efficient local\nenergy computation. Last, we employ cache-centric optimization for\ntransformer-based \\textit{ansatz} and incorporate it with sampling parallelism\nstrategy, which further speedup up the NQS training and achieve stable memory\nfootprint at scale. Experiments demonstrate that \\ours accelerate NQS training\nwith up to 8.41x speedup and attains a parallel efficiency up to 95.8\\% when\nscaling to 1,536 nodes.", "AI": {"tldr": "The paper introduces a novel framework, \\ours, designed to overcome scalability bottlenecks in training neural network quantum states (NQS) for quantum chemistry problems, achieving significant speedups and parallel efficiency on large-scale systems.", "motivation": "Address the exponential growth in computational demands and scalability barriers when training neural network quantum states in large-scale quantum chemistry problems.", "method": "Proposed a scalable sampling parallelism strategy, introduced multi-level parallelism for efficient local energy computation, and used cache-centric optimization for transformer-based ansatz to enhance training speed and maintain stability.", "result": "Achieved up to 8.41x acceleration in NQS training and a parallel efficiency of 95.8% when using 1,536 nodes.", "conclusion": "\\ours successfully breaks scalability barriers in NQS training, significantly improving performance and enabling practical applications in large-scale quantum chemistry computations."}}
{"id": "2506.23075", "pdf": "https://arxiv.org/pdf/2506.23075", "abs": "https://arxiv.org/abs/2506.23075", "authors": ["Yuchen Zhou", "Jiamin Wu", "Zichen Ren", "Zhouheng Yao", "Weiheng Lu", "Kunyu Peng", "Qihao Zheng", "Chunfeng Song", "Wanli Ouyang", "Chao Gou"], "title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding", "categories": ["cs.HC", "cs.LG", "eess.SP", "q-bio.NC"], "comment": null, "summary": "Understanding and decoding brain activity from electroencephalography (EEG)\nsignals is a fundamental challenge in neuroscience and AI, with applications in\ncognition, emotion recognition, diagnosis, and brain-computer interfaces. While\nrecent EEG foundation models advance generalized decoding via unified\narchitectures and large-scale pretraining, they adopt a scale-agnostic dense\nmodeling paradigm inherited from NLP and vision. This design neglects a core\nproperty of neural activity: cross-scale spatiotemporal structure. EEG task\npatterns span a wide range of temporal and spatial scales, from short bursts to\nslow rhythms, and from localized cortical responses to distributed\ninteractions. Ignoring this diversity leads to suboptimal representations and\nweak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain\nfoundation model for generalized EEG decoding. CSBrain introduces: (i)\nCross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale\nfeatures from localized temporal windows and anatomical brain regions into\ncompact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which\ncaptures cross-window and cross-region dependencies, enhancing scale diversity\nwhile removing spurious correlations. CST and SSA are alternately stacked to\nprogressively integrate multi-scale dependencies. Experiments on 11 EEG tasks\nacross 16 datasets show that CSBrain consistently outperforms task-specific and\nfoundation model baselines. These results establish cross-scale modeling as a\nkey inductive bias and position CSBrain as a robust backbone for future\nbrain-AI research.", "AI": {"tldr": "The paper introduces CSBrain, a model that significantly improves EEG decoding by incorporating cross-scale spatiotemporal features.", "motivation": "Existing EEG decoding models ignore the multi-scale spatiotemporal structure of brain activity, leading to suboptimal representation and weak generalization.", "method": "The authors propose CSBrain, which utilizes Cross-scale Spatiotemporal Tokenization (CST) to aggregate diverse features and Structured Sparse Attention (SSA) to capture dependencies while avoiding noise. CST and SSA are combined in a layered structure for better integration.", "result": "CSBrain outperformed task-specific and foundational models across 11 EEG tasks using 16 diverse datasets, proving its superior ability in generalized EEG decoding.", "conclusion": "The study highlights the importance of cross-scale spatiotemporal modeling for EEG decoding and positions CSBrain as a seminal foundation model in brain-AI integration."}}
{"id": "2506.23014", "pdf": "https://arxiv.org/pdf/2506.23014", "abs": "https://arxiv.org/abs/2506.23014", "authors": ["Wilder Baldwin", "Shashank Chintakuntla", "Shreyah Parajuli", "Ali Pourghasemi", "Ryan Shanz", "Sepideh Ghanavati"], "title": "Generating Privacy Stories From Software Documentation", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to RENext!'25 at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Research shows that analysts and developers consider privacy as a security\nconcept or as an afterthought, which may lead to non-compliance and violation\nof users' privacy. Most current approaches, however, focus on extracting legal\nrequirements from the regulations and evaluating the compliance of software and\nprocesses with them. In this paper, we develop a novel approach based on\nchain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language\nModels (LLMs) to extract privacy behaviors from various software documents\nprior to and during software development, and then generate privacy\nrequirements in the format of user stories. Our results show that most commonly\nused LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and\ngenerate privacy user stories with F1 scores exceeding 0.8. We also show that\nthe performance of these models could be improved through parameter-tuning. Our\nfindings provide insight into using and optimizing LLMs for generating privacy\nrequirements given software documents created prior to or throughout the\nsoftware development lifecycle.", "AI": {"tldr": "The paper introduces a new method to extract privacy behaviors and create privacy user stories using Large Language Models (LLMs) and techniques like chain-of-thought prompting.", "motivation": "Analysts and developers often neglect privacy concerns, treating them as secondary to security, which risks non-compliance and user privacy violations.", "method": "The authors use Chain-of-Thought prompting, In-Context Learning, and LLMs (such as GPT-4o and Llama 3) to extract privacy behaviors from software documents and generate privacy requirements as user stories.", "result": "The proposed approach achieves over 0.8 F1 scores for identifying privacy behaviors and generating user stories, with further performance gains available through model parameter tuning.", "conclusion": "LLMs are effective tools for identifying and generating privacy requirements in the software development lifecycle, and their performance can be improved through optimization."}}
{"id": "2506.22769", "pdf": "https://arxiv.org/pdf/2506.22769", "abs": "https://arxiv.org/abs/2506.22769", "authors": ["Changshi Zhou", "Feng Luan", "Jiarui Hu", "Shaoqiang Meng", "Zhipeng Wang", "Yanchao Dong", "Yanmin Zhou", "Bin He"], "title": "Learning Efficient Robotic Garment Manipulation with Standardization", "categories": ["cs.RO"], "comment": null, "summary": "Garment manipulation is a significant challenge for robots due to the complex\ndynamics and potential self-occlusion of garments. Most existing methods of\nefficient garment unfolding overlook the crucial role of standardization of\nflattened garments, which could significantly simplify downstream tasks like\nfolding, ironing, and packing. This paper presents APS-Net, a novel approach to\ngarment manipulation that combines unfolding and standardization in a unified\nframework. APS-Net employs a dual-arm, multi-primitive policy with dynamic\nfling to quickly unfold crumpled garments and pick-and-place (p and p) for\nprecise alignment. The purpose of garment standardization during unfolding\ninvolves not only maximizing surface coverage but also aligning the garment's\nshape and orientation to predefined requirements. To guide effective robot\nlearning, we introduce a novel factorized reward function for standardization,\nwhich incorporates garment coverage (Cov), keypoint distance (KD), and\nintersection-over-union (IoU) metrics. Additionally, we introduce a spatial\naction mask and an Action Optimized Module to improve unfolding efficiency by\nselecting actions and operation points effectively. In simulation, APS-Net\noutperforms state-of-the-art methods for long sleeves, achieving 3.9 percent\nbetter coverage, 5.2 percent higher IoU, and a 0.14 decrease in KD (7.09\npercent relative reduction). Real-world folding tasks further demonstrate that\nstandardization simplifies the folding process. Project page: see\nhttps://hellohaia.github.io/APS/", "AI": {"tldr": "The paper introduces APS-Net, a robotic method for unfolding and standardizing garments by optimizing coverage, alignment, and efficiency.", "motivation": "Efficient garment manipulation is hindered by complex dynamics and self-occlusion, requiring a standardized approach to simplify tasks like folding and ironing.", "method": "APS-Net uses a dual-arm, multi-primitive policy for dynamic fling to unfold garments and pick-and-place functions for precise alignment, guided by a factorized reward function and optimized action modules.", "result": "APS-Net shows superior metrics in garment coverage (+3.9%), IoU (+5.2%), and distance reduction (-0.14 KD) compared to existing methods during simulation and improves folding efficiency in real-world scenarios.", "conclusion": "Integrating garment unfolding and standardization provides significant advantages in robotic manipulation, streamlining downstream tasks like folding and ironing."}}
{"id": "2506.22893", "pdf": "https://arxiv.org/pdf/2506.22893", "abs": "https://arxiv.org/abs/2506.22893", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "categories": ["cs.AI", "cs.HC"], "comment": "12 pages, 1 figure, 2 sidebars; Preprint", "summary": "After a very long winter, the Artificial Intelligence (AI) spring is here.\nOr, so it seems over the last three years. AI has the potential to impact many\nareas of human life - personal, social, health, education, professional. In\nthis paper, we take a closer look at the potential of AI for Enterprises, where\ndecision-making plays a crucial and repeated role across functions, tasks, and\noperations. We consider Agents imbued with AI as means to increase\ndecision-productivity of enterprises. We highlight six tenets for Agentic\nsuccess in enterprises, by drawing attention to what the current, AI-Centric\nUser paradigm misses, in the face of persistent needs of and usefulness for\nEnterprise Decision-Making. In underscoring a shift to User-Centric AI, we\noffer six tenets and promote market mechanisms for platforms, aligning the\ndesign of AI and its delivery by Agents to the cause of enterprise users.", "AI": {"tldr": "The paper explores AI's transformative potential for enterprises by proposing a shift towards user-centric AI and introducing six tenets for effective decision-making.", "motivation": "AI can revolutionize enterprise decision-making, yet current paradigms overlook real enterprise needs.", "method": "The paper identifies gaps in AI-Centric User paradigms and proposes six tenets for a user-oriented approach.", "result": "Six tenets are introduced to improve decision productivity and align AI for enterprise applications.", "conclusion": "User-Centric AI, guided by proposed six tenets, is essential to maximize AI impact in enterprise decision-making processes."}}
{"id": "2506.23453", "pdf": "https://arxiv.org/pdf/2506.23453", "abs": "https://arxiv.org/abs/2506.23453", "authors": ["Zhen Zhang", "Xin Liu", "Shaoli Wang", "Jiaye Teng"], "title": "Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Covariate shift occurs when the distribution of input features differs\nbetween the training and testing phases. In covariate shift, estimating an\nunknown function's moment is a classical problem that remains under-explored,\ndespite its common occurrence in real-world scenarios. In this paper, we\ninvestigate the minimax lower bound of the problem when the source and target\ndistributions are known. To achieve the minimax optimal bound (up to a\nlogarithmic factor), we propose a two-stage algorithm. Specifically, it first\ntrains an optimal estimator for the function under the source distribution, and\nthen uses a likelihood ratio reweighting procedure to calibrate the moment\nestimator. In practice, the source and target distributions are typically\nunknown, and estimating the likelihood ratio may be unstable. To solve this\nproblem, we propose a truncated version of the estimator that ensures double\nrobustness and provide the corresponding upper bound. Extensive numerical\nstudies on synthetic examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.", "AI": {"tldr": "The paper addresses the problem of estimating moments in covariate shift scenarios with known distributions, proposing an optimal two-stage algorithm and extending it to unknown distributions using a double robust estimator.", "motivation": "Covariate shift frequently occurs in real-world scenarios, making accurate estimation of unknown function moments crucial but under-explored.", "method": "The proposed method includes a two-stage algorithm: training an optimal estimator under the source distribution followed by likelihood ratio reweighting for calibration, with a robust extension for unknown distributions.", "result": "The algorithm achieves the minimax optimal bound (up to a logarithmic factor), and numerical studies verify its theoretical claims and practical efficacy.", "conclusion": "The paper introduces a novel approach for moment estimation under covariate shift, achieving theoretical limits and demonstrating robustness in practical scenarios."}}
{"id": "2506.22447", "pdf": "https://arxiv.org/pdf/2506.22447", "abs": "https://arxiv.org/abs/2506.22447", "authors": ["Fabio Merizzi", "Harilaos Loukos"], "title": "Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Global Climate Models (GCMs) are critical for simulating large-scale climate\ndynamics, but their coarse spatial resolution limits their applicability in\nregional studies. Regional Climate Models (RCMs) refine this through dynamic\ndownscaling, albeit at considerable computational cost and with limited\nflexibility. While deep learning has emerged as an efficient data-driven\nalternative, most existing studies have focused on single-variable models that\ndownscale one variable at a time. This approach can lead to limited contextual\nawareness, redundant computation, and lack of cross-variable interaction. Our\nstudy addresses these limitations by proposing a multi-task, multi-variable\nVision Transformer (ViT) architecture with a shared encoder and\nvariable-specific decoders (1EMD). The proposed architecture jointly predicts\nthree key climate variables: surface temperature (tas), wind speed (sfcWind),\nand 500 hPa geopotential height (zg500), directly from GCM-resolution inputs,\nemulating RCM-scale downscaling over Europe. We show that our multi-variable\napproach achieves positive cross-variable knowledge transfer and consistently\noutperforms single-variable baselines trained under identical conditions, while\nalso improving computational efficiency. These results demonstrate the\neffectiveness of multi-variable modeling for high-resolution climate\ndownscaling.", "AI": {"tldr": "This paper introduces a multi-variable Vision Transformer (ViT) architecture to improve climate variable downscaling, addressing shortcomings in single-variable models.", "motivation": "Single-variable downscaling lacks contextual interactions between climate variables and is computationally inefficient.", "method": "The study employs a shared encoder and variable-specific decoders within a Vision Transformer architecture to predict three climate variables simultaneously.", "result": "The proposed model demonstrates positive cross-variable knowledge transfer, surpasses single-variable baselines in accuracy, and offers increased computational efficiency.", "conclusion": "Multi-variable modeling is effective for high-resolution climate downscaling, providing improved performance and efficiency over traditional methods."}}
{"id": "2506.22501", "pdf": "https://arxiv.org/pdf/2506.22501", "abs": "https://arxiv.org/abs/2506.22501", "authors": ["Gautam Siddharth Kashyap", "Manaswi Kulahara", "Nipun Joshi", "Usman Naseem"], "title": "How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,\n  Australia", "summary": "Remote sensing datasets offer significant promise for tackling key\nclassification tasks such as land-use categorization, object presence\ndetection, and rural/urban classification. However, many existing studies tend\nto focus on narrow tasks or datasets, which limits their ability to generalize\nacross various remote sensing classification challenges. To overcome this, we\npropose a novel model, SpatialNet-ViT, leveraging the power of Vision\nTransformers (ViTs) and Multi-Task Learning (MTL). This integrated approach\ncombines spatial awareness with contextual understanding, improving both\nclassification accuracy and scalability. Additionally, techniques like data\naugmentation, transfer learning, and multi-task learning are employed to\nenhance model robustness and its ability to generalize across diverse datasets", "AI": {"tldr": "The paper introduces SpatialNet-ViT, combining Vision Transformers with Multi-Task Learning for improved remote sensing classification.", "motivation": "Current remote sensing studies are limited in generalization across tasks and datasets, creating a need for models capable of handling diverse classification challenges.", "method": "The authors developed SpatialNet-ViT, integrating Vision Transformers, Multi-Task Learning, data augmentation, and transfer learning to enhance spatial and contextual understanding.", "result": "The proposed model improves classification accuracy, robustness, and scalability for diverse datasets.", "conclusion": "SpatialNet-ViT offers a comprehensive solution for enhancing remote sensing classification tasks by integrating advanced methodologies."}}
{"id": "2506.23165", "pdf": "https://arxiv.org/pdf/2506.23165", "abs": "https://arxiv.org/abs/2506.23165", "authors": ["David Bossens", "Atsushi Nitanda"], "title": "Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Safety is an essential requirement for reinforcement learning systems. The\nnewly emerging framework of robust constrained Markov decision processes allows\nlearning policies that satisfy long-term constraints while providing guarantees\nunder epistemic uncertainty. This paper presents mirror descent policy\noptimisation for robust constrained Markov decision processes (RCMDPs), making\nuse of policy gradient techniques to optimise both the policy (as a maximiser)\nand the transition kernel (as an adversarial minimiser) on the Lagrangian\nrepresenting a constrained MDP. In the oracle-based RCMDP setting, we obtain an\n$\\mathcal{O}\\left(\\frac{1}{T}\\right)$ convergence rate for the squared distance\nas a Bregman divergence, and an $\\mathcal{O}\\left(e^{-T}\\right)$ convergence\nrate for entropy-regularised objectives. In the sample-based RCMDP setting, we\nobtain an $\\tilde{\\mathcal{O}}\\left(\\frac{1}{T^{1/3}}\\right)$ convergence rate.\nExperiments confirm the benefits of mirror descent policy optimisation in\nconstrained and unconstrained optimisation, and significant improvements are\nobserved in robustness tests when compared to baseline policy optimisation\nalgorithms.", "AI": {"tldr": "This paper introduces a mirror descent policy optimization approach for robust constrained Markov decision processes, achieving theoretical convergence guarantees and improved robustness over baseline methods.", "motivation": "The paper is motivated by the need for reinforcement learning systems to ensure safety and satisfy long-term constraints while providing robustness under epistemic uncertainty.", "method": "The authors employ a mirror descent policy optimization approach for RCMDPs, using policy gradient techniques combined with adversarial optimization on the Lagrangian representing constrained MDPs. They analyze convergence rates under oracle-based and sample-based settings.", "result": "Theoretical results show $\nmathcal{O}\\left(\\frac{1}{T}\\right)$ and $\nmathcal{O}\\left(e^{-T}\\right)$ convergence in oracle-based settings, and $\ntilde{\\mathcal{O}}\\left(\\frac{1}{T^{1/3}}\\right)$ in sample-based settings. Experiments demonstrate improvements in constrained optimization and robustness compared to baseline algorithms.", "conclusion": "Mirror descent policy optimization provides robust and efficient policy learning under constraints, with benefits demonstrated theoretically and empirically."}}
{"id": "2506.23934", "pdf": "https://arxiv.org/pdf/2506.23934", "abs": "https://arxiv.org/abs/2506.23934", "authors": ["Xiangchen Li", "Saeid Ghafouri", "Bo Ji", "Hans Vandierendonck", "Deepu John", "Dimitrios S. Nikolopoulos"], "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "As machine learning inferences increasingly move to edge devices, adapting to\ndiverse computational capabilities, hardware, and memory constraints becomes\nmore critical. Instead of relying on a pre-trained model fixed for all future\ninference queries across diverse edge devices, we argue that planning an\ninference pattern with a request-specific model tailored to the device's\ncomputational capacity, accuracy requirements, and time constraints is more\ncost-efficient and robust to diverse scenarios. To this end, we propose an\naccuracy-aware and workload-balanced inference system that integrates joint\nmodel quantization and inference partitioning. In this approach, the server\ndynamically responds to inference queries by sending a quantized model and\nadaptively sharing the inference workload with the device. Meanwhile, the\ndevice's computational power, channel capacity, and accuracy requirements are\nconsidered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference\nsystem, incorporating joint model quantization and partitioning. Our approach\noptimizes layer-wise quantization bit width and partition points to minimize\ntime consumption and cost while accounting for varying accuracy requirements of\ntasks through an accuracy degradation metric in our optimization model. To our\nknowledge, this work represents the first exploration of optimizing\nquantization layer-wise bit-width in the inference serving system, by\nintroducing theoretical measurement of accuracy degradation. Simulation results\ndemonstrate a substantial reduction in overall time and power consumption, with\ncomputation payloads decreasing by over 80% and accuracy degradation kept below\n1%.", "AI": {"tldr": "The paper introduces a dynamic inference system for edge devices, jointly optimizing model quantization and partitioning based on device constraints, achieving significant efficiency improvements while minimizing accuracy loss.", "motivation": "Machine learning inferences on edge devices demand adaptation to computational capabilities and constraints. A fixed pre-trained model is often inefficient for diverse scenarios, leading to a need for tailored, request-specific models that are cost-effective and adaptable.", "method": "The authors develop a system that integrates joint model quantization and inference partitioning. This system dynamically adapts to edge devices by optimizing quantization bit widths and partition points using a novel optimization framework that minimizes time and cost while maintaining task accuracy.", "result": "Simulations show that the proposed approach reduces computation payloads by over 80%, significantly decreases time and energy consumption, and keeps accuracy degradation below 1%.", "conclusion": "The proposed inference system offers an efficient and robust solution for edge-device ML inferences, balancing workload and accuracy while saving energy and computational resources, marking a notable advancement in optimizing inference-serving systems."}}
{"id": "2506.23293", "pdf": "https://arxiv.org/pdf/2506.23293", "abs": "https://arxiv.org/abs/2506.23293", "authors": ["P. Myles Eugenio"], "title": "Objective-Free Local Learning and Emergent Language Structure in Thinking Machines", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "comment": "22 pages, 7 figures", "summary": "We present a neuro-symbolic framework for generative language modeling based\non local, event-driven emergent learning. At its core is a hierarchical\nHopfield memory chain acting as a compositional short-term memory and dynamic\ntokenizer (retokenizer). Rather than relying on predefined tokens or\nsupervision, the model builds structure from scratch, learning symbol sequences\nas multi-scale representations. It constructs projection tensors that bind\nco-occurring features into hierarchical tokens, introducing redundancy (i.e an\nemergent gauge structure) and enabling compression of local activations into\nlong-range dependencies. Curiously, we find that the retokenizer can filter\nnatural language patterns from noise, generating synthetic languages with\ncoherent internal morphology -- quantifiably the same as human language.\nLanguage is learned in a local (Hebbian) fashion, where model constraints\ndictate allowed emergent structure, and new information is retained in\nalignment with this structure. The absence of a global objective enables a form\nof plasticity not found in conventional language models, allowing the system to\ngeneralize beyond its initial inference class -- even without explicit data. We\ndemonstrate that briefly activating a new neuron during inference binds\ndistributed multi-scale token features into a symbolic embedding. These\nemergent embedding neurons act as long-term memory and support a key-value\nmechanism for compositional inference and generalization. This architecture\nprovides a methodological foundation for studying how symbolic structure can\nemerge from local neural learning. It offers a new pathway for building\nscalable, interpretable neuro-symbolic systems -- where tokens, grammar, and\nreasoning arise as compressed memory traces within a Hopfield hierarchy. This\napproach advances the development of neuromorphic architectures for generative\nlanguage models.", "AI": {"tldr": "The paper presents a neuro-symbolic language model that uses a hierarchical Hopfield memory chain to dynamically tokenize and learn symbol structures without predefined rules or objectives, enabling emergent language structures and flexible generalization.", "motivation": "To explore how symbolic language structures like tokens and grammar can emerge naturally through local learning mechanisms without relying on predefined tokens, supervised learning, or global objectives.", "method": "The method involves a hierarchical Hopfield memory chain that acts as a dynamic short-term memory and retokenizer. The system employs Hebbian learning to build multi-scale symbol representations and aligns new information with emergent structures, fostering generalization without explicit data.", "result": "The model demonstrates the ability to filter coherent language patterns from noise, create synthetic languages that resemble human language morphology, and activate emergent embedding neurons for compositional inference and long-term memory.", "conclusion": "The study introduces a scalable and interpretable neuro-symbolic system capable of emergent grammar and reasoning, offering a novel approach for the development of neuromorphic architectures in generative language modeling."}}
{"id": "2506.23034", "pdf": "https://arxiv.org/pdf/2506.23034", "abs": "https://arxiv.org/abs/2506.23034", "authors": ["Hao Yan", "Swapneel Suhas Vaidya", "Xiaokuan Zhang", "Ziyu Yao"], "title": "Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have become powerful tools for automated code\ngeneration. However, these models often overlook critical security practices,\nwhich can result in the generation of insecure code that contains\nvulnerabilities-weaknesses or flaws in the code that attackers can exploit to\ncompromise a system. However, there has been limited exploration of strategies\nto guide LLMs in generating secure code and a lack of in-depth analysis of the\neffectiveness of LLMs in repairing code containing vulnerabilities. In this\npaper, we present a comprehensive evaluation of state-of-the-art LLMs by\nexamining their inherent tendencies to produce insecure code, their capability\nto generate secure code when guided by self-generated vulnerability hints, and\ntheir effectiveness in repairing vulnerabilities when provided with different\nlevels of feedback. Our study covers both proprietary and open-weight models\nacross various scales and leverages established benchmarks to assess a wide\nrange of vulnerability types. Through quantitative and qualitative analyses, we\nreveal that although LLMs are prone to generating insecure code, advanced\nmodels can benefit from vulnerability hints and fine-grained feedback to avoid\nor fix vulnerabilities. We also provide actionable suggestions to developers to\nreduce vulnerabilities when using LLMs for code generation.", "AI": {"tldr": "This paper explores the security issues of Large Language Models (LLMs) in code generation, their ability to repair vulnerabilities, and strategies for improvement.", "motivation": "The paper addresses the critical issue of insecure code generation by LLMs, including the lack of robust methods to improve security and repair vulnerabilities.", "method": "The authors conducted evaluations on proprietary and open-weight LLMs using established benchmarks and analyzed their tendencies to produce insecure code, capability to use vulnerability hints, and effectiveness in fixing vulnerabilities with feedback.", "result": "The study found that LLMs often produce insecure code but advanced models can leverage vulnerability hints and feedback to significantly improve code security.", "conclusion": "Advanced LLMs can become more effective in secure code generation and vulnerability repair when guided by well-designed hints and feedback, highlighting the need for developers to implement these strategies."}}
{"id": "2506.22518", "pdf": "https://arxiv.org/pdf/2506.22518", "abs": "https://arxiv.org/abs/2506.22518", "authors": ["Deyu Zou", "Yongqiang Chen", "Mufei Li", "Siqi Miao", "Chenxi Liu", "Bo Han", "James Cheng", "Pan Li"], "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph-based retrieval-augmented generation (RAG) enables large language\nmodels (LLMs) to ground responses with structured external knowledge from\nup-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs\noften rely on a weak retriever in graph-based RAG: I) Due to the lack of ground\ntruth, the retriever is often trained on weak supervision, which often\nintroduces spurious signals to the LLMs. II) Due to the abstraction of graph\ndata, the retrieved knowledge is often presented in unorganized forms. To\nmitigate the issue, we present Refined Graph-based RAG (ReG) to align weak\nretrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM\nfeedback to get rid of spurious signals and improve the quality of the\nsupervision. Meanwhile, ReG introduces a structure-aware reorganization module\nto refactor the retrieval results into logically coherent evidence chains.\nExperiments on prominent benchmarks demonstrate that ReG significantly and\nconsistently brings improvements across different LLM backbones by up to 10%.\nThe improved supervision quality enables ReG to match the state-of-the-art\nperformance with 5% training data and to transfer to out-of-distribution KGs.\nNotably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token\ncost by up to 30% and improves the performance by up to 4%.", "AI": {"tldr": "Refined Graph-based RAG (ReG) improves retrieval-augmented generation by enhancing weak retrievers with LLM feedback and structuring retrieved knowledge into coherent evidence chains, resulting in better performance and efficiency.", "motivation": "To address the limitations of current graph-based retrieval-augmented generation (RAG) approaches where weak retrievers introduce spurious signals and retrieved knowledge lacks organization, leading to suboptimal LLM performance and increased hallucinations.", "method": "The authors propose ReG, which aligns weak retrievers to LLMs through feedback-based supervision, removing spurious signals, and employs a structure-aware reorganization module to present retrieval results as logically coherent evidence chains.", "result": "ReG achieves up to a 10% improvement across different LLM backbones, matches state-of-the-art performance with only 5% training data, transfers effectively to out-of-distribution KGs, reduces reasoning token costs by up to 30%, and improves performance by up to 4%.", "conclusion": "ReG demonstrates that enhancing retrievers with LLM feedback and organizing retrieved knowledge significantly boosts the efficiency and effectiveness of graph-based RAG systems, with potential applications in improving reasoning and reducing resource requirements."}}
{"id": "2506.22788", "pdf": "https://arxiv.org/pdf/2506.22788", "abs": "https://arxiv.org/abs/2506.22788", "authors": ["Xuao Hou", "Yongquan Jia", "Shijin Zhang", "Yuqiang Wu"], "title": "SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information", "categories": ["cs.RO"], "comment": null, "summary": "The widespread application of industrial robots in fields such as cutting and\nwelding has imposed increasingly stringent requirements on the trajectory\naccuracy of end-effectors. However, current error compensation methods face\nseveral critical challenges, including overly simplified mechanism modeling, a\nlack of physical consistency in data-driven approaches, and substantial data\nrequirements. These issues make it difficult to achieve both high accuracy and\nstrong generalization simultaneously. To address these challenges, this paper\nproposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER).\nThis method integrates the kinematic equations of the robotic manipulator with\na Transformer architecture enhanced by sparse self-attention masks. A\nparameter-adaptive hybrid loss function incorporating spatial and physical\ninformation is employed to iteratively optimize the network during training,\nenabling high-precision error compensation under small-sample conditions.\nAdditionally, inverse joint angle compensation is performed using a gradient\ndescent-based optimization method. Experimental results on a small-sample\ndataset from a UR5 robotic arm (724 samples, with a train:test:validation split\nof 8:1:1) demonstrate the superior performance of the proposed method. It\nachieves a 3D absolute positioning error of 0.2515 mm with a standard deviation\nof 0.15 mm, representing a 35.16\\% reduction in error compared to conventional\ndeep neural network (DNN) methods. Furthermore, the inverse angle compensation\nalgorithm converges to an accuracy of 0.01 mm within an average of 147\niterations. This study presents a solution that combines physical\ninterpretability with data adaptability for high-precision control of\nindustrial robots, offering promising potential for the reliable execution of\nprecision tasks in intelligent manufacturing.", "AI": {"tldr": "The paper introduces SPI-BoTER, a spatial-physical informed attention network, to enhance trajectory accuracy for industrial robots using minimal sample data. It achieves greater precision and generalization compared to existing methods.", "motivation": "Current error compensation approaches for industrial robots suffer from simplified modeling, lack of physical consistency, and excessive data requirements, making it challenging to achieve high accuracy and generalization.", "method": "The proposed SPI-BoTER model integrates robotic kinematics with a Transformer architecture featuring sparse self-attention masks and uses a hybrid loss function with spatial and physical information. It incorporates gradient descent optimization for inverse joint angle compensation.", "result": "Experimental results on a small-sample UR5 robot dataset show a 35.16% error reduction over traditional DNNs, achieving a 3D positioning error of 0.2515 mm and convergence of 0.01 mm accuracy in 147 iterations.", "conclusion": "The proposed method offers a physically interpretable and data-adaptive solution for precision tasks in intelligent manufacturing, presenting a significant advancement in industrial robot control."}}
{"id": "2506.22919", "pdf": "https://arxiv.org/pdf/2506.22919", "abs": "https://arxiv.org/abs/2506.22919", "authors": ["Sanskar Pandey", "Ruhaan Chopra", "Saad Murtaza Bhat", "Ark Abhyudaya"], "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) models enable conditional computation by routing\ninputs to specialized experts, but these experts rely on identical inductive\nbiases, thus limiting representational diversity. This static computation\npathway is inefficient for inputs that require different types of reasoning and\nlimits specialization and interpretability. We propose Hecto, a lightweight MoE\narchitecture that leverages architectural heterogeneity by combining a GRU\nexpert for temporal reasoning and an FFNN expert for static abstraction under a\nsparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG\nNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely\ntrails homogeneous baselines in performance despite receiving isolated input\nrepresentations, while achieving clear expert specialization, with each expert\naligning to distinct reasoning types (temporal vs static). At larger batch\nsizes, Hecto exhibits improved performance, benefiting from relaxed\ncomputational constraints that allow its heterogeneous architecture to optimize\nmore effectively. Ablation results isolate architectural diversity as the\nsource of Hecto's stability and interpretability across diverse reasoning\ntasks. Overall, Hecto establishes itself as a new benchmark for conditional\ncomputation, offering a principled framework for specialized reasoning in\nlow-resource regimes with its model strength derived from principled\nspecialization.", "AI": {"tldr": "Hecto is a new lightweight architecture using diverse experts (GRU & FFNN) under Top-1 gating for reasoning tasks, showcasing specialization under low-resource settings.", "motivation": "To improve representational diversity and computational efficiency in MoE models for tasks demanding distinct reasoning types.", "method": "Hecto employs architectural heterogeneity with GRU for temporal reasoning and FFNN for static abstraction, routed via sparse Top-1 gating mechanism, tested across various benchmarks.", "result": "Hecto delivers matched or close performance to baseline models while achieving distinct expert specialization (temporal vs static) and stronger performance at larger batch sizes.", "conclusion": "Hecto sets a new benchmark by demonstrating principled specialization and interpretability in conditional computation under low-resource environments."}}
{"id": "2506.23487", "pdf": "https://arxiv.org/pdf/2506.23487", "abs": "https://arxiv.org/abs/2506.23487", "authors": ["Haoshu Xu", "Hongzhe Li"], "title": "Test of partial effects for Frechet regression on Bures-Wasserstein manifolds", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a novel test for assessing partial effects in Frechet regression\non Bures Wasserstein manifolds. Our approach employs a sample splitting\nstrategy: the first subsample is used to fit the Frechet regression model,\nyielding estimates of the covariance matrices and their associated optimal\ntransport maps, while the second subsample is used to construct the test\nstatistic. We prove that this statistic converges in distribution to a weighted\nmixture of chi squared components, where the weights correspond to the\neigenvalues of an integral operator defined by an appropriate RKHS kernel. We\nestablish that our procedure achieves the nominal asymptotic size and\ndemonstrate that its worst-case power converges uniformly to one. Through\nextensive simulations and a real data application, we illustrate the test's\nfinite-sample accuracy and practical utility.", "AI": {"tldr": "The paper introduces a novel statistical test for evaluating partial effects in Frechet regression on Bures Wasserstein manifolds, with provable theoretical and practical effectiveness.", "motivation": "To address the need for a rigorous statistical test for assessing partial effects in the complex setting of Frechet regression on Bures Wasserstein manifolds.", "method": "The method involves a sample-splitting strategy where one subsample is used to fit the Frechet regression model, and the other subsample is used to construct the test statistic. Theoretical analysis ensures convergence properties and effectiveness.", "result": "The test statistic converges asymptotically to a weighted mixture of chi-squared components. Nominal asymptotic size is achieved, and worst-case power converges to one uniformly.", "conclusion": "The proposed test shows both strong theoretical foundations and practical applicability, demonstrated through simulations and real-world data analysis."}}
{"id": "2506.22502", "pdf": "https://arxiv.org/pdf/2506.22502", "abs": "https://arxiv.org/abs/2506.22502", "authors": ["Matvei Anoshin", "Olga Tsurkan", "Vadim Lopatkin", "Leonid Fedichkin"], "title": "Stabilization of industrial processes with time series machine learning", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The stabilization of time series processes is a crucial problem that is\nubiquitous in various industrial fields. The application of machine learning to\nits solution can have a decisive impact, improving both the quality of the\nresulting stabilization with less computational resources required. In this\nwork, we present a simple pipeline consisting of two neural networks: the\noracle predictor and the optimizer, proposing a substitution of the point-wise\nvalues optimization to the problem of the neural network training, which\nsuccessfully improves stability in terms of the temperature control by about 3\ntimes compared to ordinary solvers.", "AI": {"tldr": "This paper presents a machine learning pipeline for improving time series stabilization, featuring two neural networks that outperform traditional solvers in temperature control by 3x.", "motivation": "The authors aimed to address the critical challenge of stabilizing time series processes in industrial applications for better outcomes with optimized computational resources.", "method": "The paper introduces a pipeline consisting of two neural networks: an oracle predictor and an optimizer, shifting the approach from point-wise value optimization to neural network training.", "result": "Their approach achieved a threefold improvement in temperature control stability compared to ordinary solvers.", "conclusion": "The proposed neural network-based pipeline effectively stabilizes time series processes with impressive results, demonstrating its potential in industrial applications."}}
{"id": "2506.22503", "pdf": "https://arxiv.org/pdf/2506.22503", "abs": "https://arxiv.org/abs/2506.22503", "authors": ["Michiel Schepers", "Pieter Robberechts", "Jan Van Haaren", "Jesse Davis"], "title": "What Makes a Dribble Successful? Insights From 3D Pose Tracking Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Data analysis plays an increasingly important role in soccer, offering new\nways to evaluate individual and team performance. One specific application is\nthe evaluation of dribbles: one-on-one situations where an attacker attempts to\nbypass a defender with the ball. While previous research has primarily relied\non 2D positional tracking data, this fails to capture aspects like balance,\norientation, and ball control, limiting the depth of current insights. This\nstudy explores how pose tracking data (capturing players' posture and movement\nin three dimensions) can improve our understanding of dribbling skills. We\nextract novel pose-based features from 1,736 dribbles in the 2022/23 Champions\nLeague season and evaluate their impact on dribble success. Our results\nindicate that features capturing the attacker's balance and the alignment of\nthe orientation between the attacker and defender are informative for\npredicting dribble success. Incorporating these pose-based features on top of\nfeatures derived from traditional 2D positional data leads to a measurable\nimprovement in model performance.", "AI": {"tldr": "The paper analyzes how pose tracking data can enhance understanding of dribble success in soccer, using features like player posture and movement.", "motivation": "Previous reliance on 2D tracking data for understanding dribbles lacked insights into fine details like balance and orientation.", "method": "Pose tracking data was utilized to derive novel features from 1,736 dribbles in the 2022/23 Champions League season for analysis.", "result": "Pose-based features were found informative for predicting dribble success, improving model performance when combined with 2D data.", "conclusion": "Adding pose data adds depth to evaluations of dribbles, advancing soccer analytics beyond traditional methods."}}
{"id": "2506.23682", "pdf": "https://arxiv.org/pdf/2506.23682", "abs": "https://arxiv.org/abs/2506.23682", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?", "categories": ["cs.CR", "cs.AR", "cs.HC"], "comment": null, "summary": "A digital security-by-design computer architecture, like CHERI, lets you\nprogram without fear of buffer overflows or other memory safety errors, but\nCHERI also rewrites some of the assumptions about how C works and how\nfundamental types (such as pointers) are implemented in hardware. We conducted\na usability study to examine how developers react to the changes required by\nCHERI when porting software to run on it. We find that developers struggle with\nCHERI's display of warnings and errors and a lack of diverse documentation.", "AI": {"tldr": "The paper explores CHERI, a digital security-by-design architecture aimed at improving memory safety, and identifies usability challenges faced by developers using it.", "motivation": "The authors aim to examine the impact of CHERI on programming practices, specifically how it changes assumptions about C language and hardware implementation, while addressing usability challenges.", "method": "A usability study was conducted where developers ported software to CHERI to observe their reactions to warnings, errors, and documentation changes.", "result": "The study found developers struggle with CHERI\u2019s warning/error mechanisms and the limited scope of its documentation.", "conclusion": "While CHERI enhances memory safety, there are significant usability barriers, particularly in error displays and documentation, that need addressing to improve developer experience."}}
{"id": "2506.24045", "pdf": "https://arxiv.org/pdf/2506.24045", "abs": "https://arxiv.org/abs/2506.24045", "authors": ["Xinming Wei", "Jiahao Zhang", "Haoran Li", "Jiayu Chen", "Rui Qu", "Maoliang Li", "Xiang Chen", "Guojie Luo"], "title": "Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The proliferation of agentic Large Language Models (LLMs) on personal devices\nintroduces a new class of workloads characterized by a dichotomy of objectives.\nReactive tasks, initiated by users, demand immediate, low-latency responses,\nwhile proactive tasks operate invisibly and prioritize throughput. Existing\non-device LLM engines, designed for isolated inferences, fail to efficiently\nmanage these concurrent and conflicting requests on consumer-grade\nheterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces\nAgent.xpu, an efficient serving system for agentic LLM workloads on\nmemory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu\nfirst constructs a heterogeneous execution graph, which fuses and chunks model\nkernels for affinity-guided, elastic accelerator mapping with predictive kernel\nannotation. At runtime, its online scheduler enables fine-grained, kernel-level\npreemption to guarantee the responsiveness of reactive tasks. To maximize SoC\nutilization, it adopts slack-aware kernel backfill to opportunistically append\nproactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware\ndispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves\n4.6$\\times$ lower latency for reactive tasks and sustains\n1.6$\\times$-6.8$\\times$ higher throughput for proactive tasks compared to\nstate-of-the-art inference engines.", "AI": {"tldr": "Agent.xpu is a serving system addressing the conflict between reactive and proactive LLM tasks on heterogeneous SoCs, optimizing both responsiveness and throughput.", "motivation": "With the emergence of agentic LLMs on personal devices, managing concurrent reactive and proactive tasks efficiently on consumer-grade SoCs has become critical.", "method": "Agent.xpu uses offline profiling to construct a heterogeneous execution graph and runtime scheduling with kernel-level preemption, slack-aware kernel backfill, and bandwidth-aware dispatch.", "result": "On Intel Core Ultra SoC, Agent.xpu delivers 4.6\u00d7 lower latency for reactive tasks and improves proactive task throughput by 1.6\u00d7-6.8\u00d7 compared to existing methods.", "conclusion": "Agent.xpu successfully optimizes execution for agentic LLM workloads on heterogeneous SoCs, balancing low-latency responses and high throughput."}}
{"id": "2506.23063", "pdf": "https://arxiv.org/pdf/2506.23063", "abs": "https://arxiv.org/abs/2506.23063", "authors": ["Guangfa Lyu", "Zhenzhong Cao", "Xiaofei Ren", "Fengyu Wang"], "title": "HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing", "categories": ["cs.SE"], "comment": null, "summary": "Directed Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for\ncrash reproduction and patch testing, leveraging its capability to precisely\nnavigate toward target locations and exploit vulnerabilities. However, current\nDGF tools are constrained by insufficient runtime feedback, limiting their\nefficiency in reaching targets and exploring state spaces. This study presents\nHF-DGF, a novel directed grey-box fuzzing framework. Its seed scheduling is\nguided by a hybrid feedback mechanism integrating control-flow distance,\nvalue-flow influence score, and slice coverage. To enable precise control-flow\ndistance feedback, we propose a backward-stepping algorithm to calculate basic\nblock-level seed distances on a virtual inter-procedural control-flow graph\n(ICFG). For effective state space exploration, we introduce value-flow\ninfluence and a corresponding metric, the value-flow influence score.\nAdditionally, to mitigate runtime overhead from hybrid feedback, we adopt a\nnovel selective instrumentation strategy. Evaluations on 41 real-world\nvulnerabilities show HF-DGF outperforms existing tools: it achieves crash\nreproduction 5.05 times faster than AFL, 5.79 times faster than AFLGo, 73.75\ntimes faster than WindRanger, 2.56 times faster than DAFL, and 8.45 times\nfaster than Beacon on average. Notably, when all fuzzers triggered crashes,\nHF-DGF exhibited the lowest code coverage, demonstrating superior\ndirectionality and efficiency. It also surpasses AFLGo, WindRanger, DAFL, and\nBeacon in static analysis efficiency.", "AI": {"tldr": "The paper introduces HF-DGF, a new directed grey-box fuzzing (DGF) framework that significantly outperforms existing tools in speed and directionality for crash reproduction and patch testing, using hybrid feedback and advanced algorithms.", "motivation": "Current DGF tools are limited by inadequate runtime feedback, reducing their efficiency in reaching target locations and exploring state space during crash reproduction and patch testing.", "method": "HF-DGF improves DGF via a hybrid feedback mechanism combining control-flow distance, value-flow influence score, and slice coverage, supported by backward-stepping algorithms and selective instrumentation strategies.", "result": "HF-DGF demonstrates faster crash reproduction than leading tools (AFL, AFLGo, WindRanger, DAFL, and Beacon) on average, achieving up to 73.75 times faster performance with superior directionality.", "conclusion": "The HF-DGF framework provides a more efficient and directional approach to DGF, improving runtime feedback and outperforming existing fuzzing tools in crash reproduction and static analysis."}}
{"id": "2506.22529", "pdf": "https://arxiv.org/pdf/2506.22529", "abs": "https://arxiv.org/abs/2506.22529", "authors": ["Lu Kalkbrenner", "Veronika Solopova", "Steffen Zeiler", "Robert Nickel", "Dorothea Kolossa"], "title": "MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages", "categories": ["cs.CL"], "comment": null, "summary": "Connectivity and message propagation are central, yet often underutilized,\nsources of information in misinformation detection -- especially on poorly\nmoderated platforms such as Telegram, which has become a critical channel for\nmisinformation dissemination, namely in the German electoral context. In this\npaper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based\ngraph dataset for misinformation detection. It includes over 5 million messages\nfrom public channels, enriched with metadata, channel relationships, and both\nweak and strong labels. These labels are derived via semantic similarity to\nfact-checks and news articles using M3-embeddings, as well as manual\nannotation. To establish reproducible baselines, we evaluate both text-only\nmodels and graph neural networks (GNNs) that incorporate message forwarding as\na network structure. Our results show that GraphSAGE with LSTM aggregation\nsignificantly outperforms text-only baselines in terms of Matthews Correlation\nCoefficient (MCC) and F1-score. We further evaluate the impact of subscribers,\nview counts, and automatically versus human-created labels on performance, and\nhighlight both the potential and challenges of weak supervision in this domain.\nThis work provides a reproducible benchmark and open dataset for future\nresearch on misinformation detection in German-language Telegram networks and\nother low-moderation social platforms.", "AI": {"tldr": "The paper introduces Misinfo-TeleGraph, a German-language Telegram-based graph dataset, for misinformation detection, highlighting the benefits of graph neural networks (GNNs) over text-only models.", "motivation": "To address the dissemination of misinformation on poorly moderated platforms like Telegram, especially in German electoral contexts, and to introduce tools that leverage connectivity and propagation information for misinformation detection.", "method": "The authors created Misinfo-TeleGraph, a dataset from over 5 million Telegram messages with metadata and labels, evaluated it using text-only models and graph neural networks (GNNs), and tested variables like user metrics and types of supervision.", "result": "GraphSAGE with LSTM aggregation outperformed text-only models in MCC and F1-score metrics and showcased the benefits of incorporating forwarding structures as graph networks.", "conclusion": "Misinfo-TeleGraph provides a valuable open dataset and reproducible benchmark that highlights the potential of GNNs and connectivity information for misinformation detection, while also identifying challenges in using weak supervision."}}
{"id": "2506.22827", "pdf": "https://arxiv.org/pdf/2506.22827", "abs": "https://arxiv.org/abs/2506.22827", "authors": ["Andr\u00e9 Schakkal", "Ben Zandonati", "Zhutian Yang", "Navid Azizan"], "title": "Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation", "categories": ["cs.RO"], "comment": "Accepted at the RSS 2025 Workshop on Robot Planning in the Era of\n  Foundation Models", "summary": "Enabling humanoid robots to reliably execute complex multi-step manipulation\ntasks is crucial for their effective deployment in industrial and household\nenvironments. This paper presents a hierarchical planning and control framework\ndesigned to achieve reliable multi-step humanoid manipulation. The proposed\nsystem comprises three layers: (1) a low-level RL-based controller responsible\nfor tracking whole-body motion targets; (2) a mid-level set of skill policies\ntrained via imitation learning that produce motion targets for different steps\nof a task; and (3) a high-level vision-language planning module that determines\nwhich skills should be executed and also monitors their completion in real-time\nusing pretrained vision-language models (VLMs). Experimental validation is\nperformed on a Unitree G1 humanoid robot executing a non-prehensile\npick-and-place task. Over 40 real-world trials, the hierarchical system\nachieved a 72.5% success rate in completing the full manipulation sequence.\nThese experiments confirm the feasibility of the proposed hierarchical system,\nhighlighting the benefits of VLM-based skill planning and monitoring for\nmulti-step manipulation scenarios. See https://vlp-humanoid.github.io/ for\nvideo demonstrations of the policy rollout.", "AI": {"tldr": "The paper proposes a hierarchical framework combining vision-language planning and reinforcement learning to enable humanoid robots to successfully perform complex multi-step manipulation tasks. The system demonstrated a high success rate in real-world trials.", "motivation": "To enhance humanoid robots' ability to reliably perform complex multi-step tasks in industrial and household settings.", "method": "The framework consists of three layers: a reinforcement learning-based low-level controller, imitation learning mid-level skill policies, and a vision-language high-level planning module for task execution and monitoring.", "result": "The proposed system was validated on a humanoid robot in real-world pick-and-place tasks, achieving a 72.5% success rate across 40 trials.", "conclusion": "The hierarchical system is effective for multi-step manipulation tasks, with vision-language models proving valuable for skill planning and task monitoring."}}
{"id": "2506.22920", "pdf": "https://arxiv.org/pdf/2506.22920", "abs": "https://arxiv.org/abs/2506.22920", "authors": ["Pinzheng Wang", "Juntao Li", "Zecheng Tang", "Haijia Gui", "Min zhang"], "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game", "categories": ["cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated considerable reasoning\nabilities in various tasks such as mathematics and coding. However, recent\nstudies indicate that even the best models lack true comprehension of their\nreasoning processes. In this paper, we explore how self-play can enhance the\nrationality of models in the reasoning process without supervision from humans\nor superior models. We design a Critic-Discernment Game(CDG) in which a prover\nfirst provides a solution to a given problem and is subsequently challenged by\ncritiques of its solution. These critiques either aim to assist or mislead the\nprover. The objective of the prover is to maintain the correct answer when\nfaced with misleading comments, while correcting errors in response to\nconstructive feedback. Our experiments on tasks involving mathematical\nreasoning, stepwise error detection, self-correction, and long-chain reasoning\ndemonstrate that CDG training can significantly improve the ability of\nwell-aligned LLMs to comprehend their reasoning process.", "AI": {"tldr": "This paper proposes a Critic-Discernment Game (CDG) to improve reasoning abilities of large language models using self-play mechanism rather than human supervision.", "motivation": "Large language models exhibit strong reasoning but lack true comprehension of their own processes, motivating a need for improvement in self-awareness and rationality without relying on external supervision.", "method": "The paper introduces the Critic-Discernment Game (CDG), in which a solution provided by a model is challenged by critiques that either help or mislead. The model's objective is to maintain correct answers against misleading inputs and address constructive criticism.", "result": "Experiments on mathematical reasoning, error detection, self-correction, and long-chain reasoning show significant improvements in the reasoning abilities of LLMs trained with CDG.", "conclusion": "CDG-based self-play effectively enhances the comprehensiveness and rationality of large language models, paving the way for better self-aware AI systems."}}
{"id": "2506.22543", "pdf": "https://arxiv.org/pdf/2506.22543", "abs": "https://arxiv.org/abs/2506.22543", "authors": ["Rahul Srinivasan", "Enrico Barausse", "Natalia Korsakova", "Roberto Trotta"], "title": "Simulation-based population inference of LISA's Galactic binaries: Bypassing the global fit", "categories": ["astro-ph.GA", "gr-qc", "stat.ML"], "comment": "19 pages, 12 figures, 3 tables", "summary": "The Laser Interferometer Space Antenna (LISA) is expected to detect thousands\nof individually resolved gravitational wave sources, overlapping in time and\nfrequency, on top of unresolved astrophysical and/or primordial backgrounds.\nDisentangling resolved sources from backgrounds and extracting their parameters\nin a computationally intensive \"global fit\" is normally regarded as a necessary\nstep toward reconstructing the properties of the underlying astrophysical\npopulations. Here, we show that it is possible to infer the properties of the\nmost numerous population of LISA sources - Galactic double white dwarfs -\ndirectly from the frequency (or, equivalently, time) strain series, by using a\nsimulation-based approach that bypasses the global fit entirely. By training a\nnormalizing flow on a custom-designed compression of simulated LISA frequency\nseries from the Galactic double white dwarf population, we demonstrate how to\ninfer the posterior distribution of population parameters (e.g., mass function,\nfrequency, and spatial distributions). This allows for extracting information\non the population parameters from both resolved and unresolved sources\nsimultaneously and in a computationally efficient manner. Our approach to\ntarget population properties directly can be readily extended to other source\nclasses (e.g., massive and stellar-mass black holes, extreme mass ratio\ninspirals), provided fast simulations are available, and to scenarios involving\nnon-Gaussian or non-stationary noise (e.g., data gaps).", "AI": {"tldr": "The authors propose a novel method to infer parameters of Galactic double white dwarfs directly from LISA data compressed into frequency series using normalizing flows, avoiding traditional global fits.", "motivation": "Current LISA data analysis relies on a computationally expensive global fit procedure, which complicates the process of extracting astrophysical information from overlapping resolved and unresolved gravitational wave sources.", "method": "A simulation-based approach is introduced, where a custom frequency series compression and normalizing flow are trained on simulated LISA data from Galactic double white dwarfs to infer population posterior distributions efficiently.", "result": "This method successfully extracts population parameter information from resolved and unresolved sources simultaneously, offering computational efficiency and extensibility to other source classes and noise scenarios.", "conclusion": "The proposed approach simplifies LISA data analysis, bypasses the global fit, and can adapt to various source types and noise conditions, making it versatile for future applications."}}
{"id": "2506.22530", "pdf": "https://arxiv.org/pdf/2506.22530", "abs": "https://arxiv.org/abs/2506.22530", "authors": ["Jakub Pele\u0161ka", "Gustav \u0160\u00edr"], "title": "Task-Agnostic Contrastive Pretraining for Relational Deep Learning", "categories": ["cs.LG", "cs.DB"], "comment": "arXiv admin note: text overlap with arXiv:2506.22199", "summary": "Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph\nNeural Network principles to learn directly from relational databases by\nrepresenting them as heterogeneous graphs. However, existing RDL models\ntypically rely on task-specific supervised learning, requiring training\nseparate models for each predictive task, which may hamper scalability and\nreuse.\n  In this work, we propose a novel task-agnostic contrastive pretraining\napproach for RDL that enables database-wide representation learning. For that\naim, we introduce three levels of contrastive objectives$-$row-level,\nlink-level, and context-level$-$designed to capture the structural and semantic\nheterogeneity inherent to relational data. We implement the respective\npretraining approach through a modular RDL architecture and an efficient\nsampling strategy tailored to the heterogeneous database setting. Our\npreliminary results on standard RDL benchmarks demonstrate that fine-tuning the\npretrained models measurably outperforms training from scratch, validating the\npromise of the proposed methodology in learning transferable representations\nfor relational data.", "AI": {"tldr": "The paper introduces a contrastive pretraining approach for Relational Deep Learning (RDL) that learns transferable database-wide representations, improving the performance of predictive tasks via fine-tuning.", "motivation": "Current RDL models rely on task-specific supervised learning, which limits scalability and reuse across multiple tasks.", "method": "The study proposes task-agnostic pretraining using three levels of contrastive objectives (row-level, link-level, and context-level) designed to capture relational data's structural and semantic heterogeneity. A modular architecture and efficient sampling strategy are utilized.", "result": "Preliminary benchmarks demonstrate that fine-tuned pretrained models outperform models trained from scratch, showcasing improved utility in relational data representation learning.", "conclusion": "Contrastive pretraining for RDL holds significant potential for scalability and representation transferability in relational data applications, reducing the need for task-specific models."}}
{"id": "2506.22504", "pdf": "https://arxiv.org/pdf/2506.22504", "abs": "https://arxiv.org/abs/2506.22504", "authors": ["Hassan Baker", "Austin J. Brockmeier"], "title": "Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Detecting brain lesions as abnormalities observed in magnetic resonance\nimaging (MRI) is essential for diagnosis and treatment. In the search of\nabnormalities, such as tumors and malformations, radiologists may benefit from\ncomputer-aided diagnostics that use computer vision systems trained with\nmachine learning to segment normal tissue from abnormal brain tissue. While\nsupervised learning methods require annotated lesions, we propose a new\nunsupervised approach (Patch2Loc) that learns from normal patches taken from\nstructural MRI. We train a neural network model to map a patch back to its\nspatial location within a slice of the brain volume. During inference, abnormal\npatches are detected by the relatively higher error and/or variance of the\nlocation prediction. This generates a heatmap that can be integrated into\npixel-wise methods to achieve finer-grained segmentation. We demonstrate the\nability of our model to segment abnormal brain tissues by applying our approach\nto the detection of tumor tissues in MRI on T2-weighted images from BraTS2021\nand MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show\nthat it outperforms the state-of-the art in unsupervised segmentation. The\ncodebase for this work can be found on our\n\\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.", "AI": {"tldr": "The paper introduces Patch2Loc, an unsupervised machine learning method for detecting brain lesions from MRI scans by mapping normal patches to spatial brain locations and identifying abnormalities based on location prediction errors.", "motivation": "Radiologists benefit from computer-aided diagnostics to enhance detection of brain lesions like tumors and malformations in MRI scans. Current supervised methods rely on annotated lesions, which may not always be feasible. Thus, an unsupervised approach that leverages normal MRI patches is needed.", "method": "Patch2Loc trains a neural network to map normal patches from structural MRIs back to their spatial brain locations. During inference, abnormalities are identified by higher location prediction errors or variance, generating heatmaps for finer-grained segmentation.", "result": "Patch2Loc was evaluated on T2-weighted MRI images (BraTS2021 and MSLUB datasets) and T1-weighted images (ATLAS and WMH datasets), showing its ability to segment abnormal brain tissues and outperform state-of-the-art unsupervised segmentation methods.", "conclusion": "Patch2Loc provides an effective unsupervised solution for detecting brain abnormalities in MRI scans, offering improved segmentation performance over existing methods and enhancing computer-aided diagnostics for radiologists."}}
{"id": "2506.22480", "pdf": "https://arxiv.org/pdf/2506.22480", "abs": "https://arxiv.org/abs/2506.22480", "authors": ["Mariam Yahya", "Aydin Sezgin", "Setareh Maghsudi"], "title": "Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits", "categories": ["cs.NI", "cs.DC", "cs.LG"], "comment": null, "summary": "As users in small cell networks increasingly rely on computation-intensive\nservices, cloud-based access often results in high latency. Multi-access edge\ncomputing (MEC) mitigates this by bringing computational resources closer to\nend users, with small base stations (SBSs) serving as edge servers to enable\nlow-latency service delivery. However, limited edge capacity makes it\nchallenging to decide which services to deploy locally versus in the cloud,\nespecially under unknown service demand and dynamic network conditions. To\ntackle this problem, we model service demand as a linear function of service\nattributes and formulate the service placement task as a linear bandit problem,\nwhere SBSs act as agents and services as arms. The goal is to identify the\nservice that, when placed at the edge, offers the greatest reduction in total\nuser delay compared to cloud deployment. We propose a distributed and adaptive\nmulti-agent best-arm identification (BAI) algorithm under a fixed-confidence\nsetting, where SBSs collaborate to accelerate learning. Simulations show that\nour algorithm identifies the optimal service with the desired confidence and\nachieves near-optimal speedup, as the number of learning rounds decreases\nproportionally with the number of SBSs. We also provide theoretical analysis of\nthe algorithm's sample complexity and communication overhead.", "AI": {"tldr": "This paper addresses service placement in multi-access edge computing (MEC) by introducing a distributed linear bandit-based best-arm identification algorithm, optimizing service deployment to minimize user delay.", "motivation": "The growing reliance on computation-intensive services in small cell networks leads to high latency in cloud-based access. MEC provides a potential solution by delivering services through local small base stations, but deciding which services to deploy locally faces challenges due to limited edge capacity, unknown demand, and dynamic network conditions.", "method": "The problem is modeled as a linear bandit problem, where SBSs act as agents and services as arms. The authors develop a distributed, adaptive, multi-agent best-arm identification (BAI) algorithm with a fixed-confidence setting. This algorithm enables SBSs to collaborate and identify the optimal service placement to minimize total user delay.", "result": "The algorithm effectively identifies the optimal service placement with the desired confidence and achieves near-optimal speedup, with learning rounds reducing proportionally to the number of SBSs. Simulations validate the approach, and theoretical analysis examines sample complexity and communication overhead.", "conclusion": "The proposed algorithm successfully addresses the challenges of service placement in MEC, enabling efficient local deployment of services while reducing user delays, and demonstrates scalability and effectiveness under collaborative settings."}}
{"id": "2506.23100", "pdf": "https://arxiv.org/pdf/2506.23100", "abs": "https://arxiv.org/abs/2506.23100", "authors": ["Jiayi Zhang", "Kai Huang", "Jian Zhang", "Yang Liu", "Chunyang Chen"], "title": "Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search", "categories": ["cs.SE"], "comment": "Accepted by ICSE 2026. Jiayi Zhang and Kai Huang contributed equally\n  to this work", "summary": "Automated Program Repair (APR) techniques aim to automatically fix buggy\nprograms. Among these, Large Language Model-based (LLM-based) approaches have\nshown great promise. Recent advances demonstrate that directly leveraging LLMs\ncan achieve leading results. However, these techniques remain suboptimal in\ngenerating contextually relevant and accurate patches, as they often overlook\nrepair ingredients crucial for practical program repair. In this paper, we\npropose ReinFix, a novel framework that enables LLMs to autonomously search for\nrepair ingredients throughout both the reasoning and solution phases of bug\nfixing. In the reasoning phase, ReinFix integrates static analysis tools to\nretrieve internal ingredients, such as variable definitions, to assist the LLM\nin root cause analysis when it encounters difficulty understanding the context.\nDuring the solution phase, when the LLM lacks experience in fixing specific\nbugs, ReinFix searches for external ingredients from historical bug fixes with\nsimilar bug patterns, leveraging both the buggy code and its root cause to\nguide the LLM in identifying appropriate repair actions, thereby increasing the\nlikelihood of generating correct patches. Evaluations on two popular benchmarks\n(Defects4J V1.2 and V2.0) demonstrate the effectiveness of our approach over\nSOTA baselines. Notably, ReinFix fixes 146 bugs, which is 32 more than the\nbaselines on Defects4J V1.2. On Defects4J V2.0, ReinFix fixes 38 more bugs than\nthe SOTA. Importantly, when evaluating on the recent benchmarks that are free\nof data leakage risk, ReinFix also maintains the best performance.", "AI": {"tldr": "The paper introduces ReinFix, a framework that enhances Large Language Models (LLMs) for automated program repair by integrating contextually relevant repair ingredients and achieves state-of-the-art results on popular benchmarks.", "motivation": "Existing LLM-based approaches for automated program repair lack capability in generating contextually relevant and accurate patches, as they often disregard important repair ingredients.", "method": "ReinFix employs a two-phase framework: 1) During the reasoning phase, it incorporates static analysis tools to retrieve internal repair ingredients for root cause analysis. 2) During the solution phase, it utilizes historical bug fixes (external ingredients) to guide patch generation based on bug patterns.", "result": "ReinFix demonstrates superior performance by fixing 146 bugs on Defects4J V1.2 (32 more than baselines) and 38 additional bugs on Defects4J V2.0 compared to the state-of-the-art.", "conclusion": "ReinFix significantly improves automated program repair by equipping LLMs with both internal and external repair ingredients, establishing itself as the leading approach even on recent benchmarks free from data leakage risks."}}
{"id": "2506.22598", "pdf": "https://arxiv.org/pdf/2506.22598", "abs": "https://arxiv.org/abs/2506.22598", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun", "Mao", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "categories": ["cs.CL"], "comment": null, "summary": "Agents based on Large Language Models (LLMs) have shown promise for\nperforming sophisticated software engineering tasks autonomously. In addition,\nthere has been progress towards developing agents that can perform parts of the\nresearch pipeline in machine learning and the natural sciences. We argue that\nresearch extension and its implementation is a critical capability for such\nsystems, and introduce RExBench to support the evaluation of this capability.\nRExBench is a benchmark consisting of 12 realistic research experiment\nimplementation tasks that aim to investigate research hypotheses that have not\npreviously been implemented. Each task is set up as an extension to an existing\nresearch paper and codebase, accompanied by domain expert-written instructions.\nRExBench is robust to data contamination, and supports an automatic evaluation\ninfrastructure that executes agent outputs to determine whether the success\ncriteria are met. We use this benchmark to evaluate nine LLM agents implemented\nusing three different frameworks: aider, Claude Code, and OpenHands. We find\nthat all agents evaluated fail to autonomously implement the majority of the\nextensions. Although the success rate improves with additional human-written\nhints, the best performance under this setting remains below 40%. This\nindicates that current agents are still short of being able to handle realistic\nresearch extension tasks without substantial human guidance.", "AI": {"tldr": "This paper introduces a benchmark called RExBench to evaluate Large Language Model (LLM) agents' ability to autonomously perform realistic research extension tasks. Current agents fall short, showing a performance below 40% even with human hints.", "motivation": "To assess whether LLM agents can autonomously handle complex research extension tasks which are critical for advancing automation in research and software engineering.", "method": "Developed RExBench, a benchmark of 12 tasks requiring implementation of novel research extensions, with data contamination safeguards and automatic evaluation. Tested nine LLM agents across three frameworks: aider, Claude Code, and OpenHands.", "result": "None of the tested LLM agents could autonomously complete most tasks; even with human hints, the success rate did not exceed 40%.", "conclusion": "Current LLM agents lack the capability to execute realistic research extensions autonomously, highlighting the need for further advancements."}}
{"id": "2506.22894", "pdf": "https://arxiv.org/pdf/2506.22894", "abs": "https://arxiv.org/abs/2506.22894", "authors": ["Bei Zhou", "Baha Zarrouki", "Mattia Piccinini", "Cheng Hu", "Lei Xie", "Johannes Betz"], "title": "Safe Reinforcement Learning with a Predictive Safety Filter for Motion Planning and Control: A Drifting Vehicle Example", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous drifting is a complex and crucial maneuver for safety-critical\nscenarios like slippery roads and emergency collision avoidance, requiring\nprecise motion planning and control. Traditional motion planning methods often\nstruggle with the high instability and unpredictability of drifting,\nparticularly when operating at high speeds. Recent learning-based approaches\nhave attempted to tackle this issue but often rely on expert knowledge or have\nlimited exploration capabilities. Additionally, they do not effectively address\nsafety concerns during learning and deployment. To overcome these limitations,\nwe propose a novel Safe Reinforcement Learning (RL)-based motion planner for\nautonomous drifting. Our approach integrates an RL agent with model-based drift\ndynamics to determine desired drift motion states, while incorporating a\nPredictive Safety Filter (PSF) that adjusts the agent's actions online to\nprevent unsafe states. This ensures safe and efficient learning, and stable\ndrift operation. We validate the effectiveness of our method through\nsimulations on a Matlab-Carsim platform, demonstrating significant improvements\nin drift performance, reduced tracking errors, and computational efficiency\ncompared to traditional methods. This strategy promises to extend the\ncapabilities of autonomous vehicles in safety-critical maneuvers.", "AI": {"tldr": "The paper proposes a Safe Reinforcement Learning (RL)-based motion planner for autonomous drifting by combining RL with drift dynamics and a Predictive Safety Filter (PSF), improving performance and safety.", "motivation": "Current methods face instability and unpredictability during autonomous drifting, particularly at high speeds, leaving safety during learning and deployment insufficiently addressed.", "method": "The approach integrates a model-based drift dynamics RL agent and incorporates a Predictive Safety Filter (PSF) to adjust actions online for safety during drifting maneuvers.", "result": "Simulations on Matlab-Carsim show improved drift performance, reduced tracking errors, and better computational efficiency compared to traditional methods.", "conclusion": "The method effectively enhances safety-critical drifting abilities in autonomous vehicles, addressing key limitations of existing techniques."}}
{"id": "2506.22992", "pdf": "https://arxiv.org/pdf/2506.22992", "abs": "https://arxiv.org/abs/2506.22992", "authors": ["Yulun Jiang", "Yekun Chai", "Maria Brbi\u0107", "Michael Moor"], "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The ability to process information from multiple modalities and to reason\nthrough it step-by-step remains a critical challenge in advancing artificial\nintelligence. However, existing reasoning benchmarks focus on text-only\nreasoning, or employ multimodal questions that can be answered by directly\nretrieving information from a non-text modality. Thus, complex reasoning\nremains poorly understood in multimodal domains. Here, we present MARBLE, a\nchallenging multimodal reasoning benchmark that is designed to scrutinize\nmultimodal language models (MLLMs) in their ability to carefully reason\nstep-by-step through complex multimodal problems and environments. MARBLE is\ncomposed of two highly challenging tasks, M-Portal and M-Cube, that require the\ncrafting and understanding of multistep plans under spatial, visual, and\nphysical constraints. We find that current MLLMs perform poorly on MARBLE --\nall the 12 advanced models obtain near-random performance on M-Portal and 0%\naccuracy on M-Cube. Only in simplified subtasks some models outperform the\nrandom baseline, indicating that complex reasoning is still a challenge for\nexisting MLLMs. Moreover, we show that perception remains a bottleneck, where\nMLLMs occasionally fail to extract information from the visual inputs. By\nshedding a light on the limitations of MLLMs, we hope that MARBLE will spur the\ndevelopment of the next generation of models with the ability to reason and\nplan across many, multimodal reasoning steps.", "AI": {"tldr": "Existing multimodal language models (MLLMs) struggle with complex reasoning tasks requiring step-by-step understanding across visual, spatial, and physical dimensions, as evidenced by poor performance on MARBLE's benchmarks.", "motivation": "To address the lack of benchmarks for evaluating complex reasoning in multimodal domains and to advance the ability of artificial intelligence to process and reason step-by-step across multiple modalities.", "method": "The authors introduced MARBLE, a multimodal reasoning benchmark consisting of two tasks, M-Portal and M-Cube, which assess multistep planning under spatial, visual, and physical constraints. They evaluated 12 advanced MLLMs on these tasks.", "result": "All tested models achieved near-random performance on M-Portal and 0% accuracy on M-Cube. Some could outperform random baselines only in simplified subtasks, highlighting failures in perception and complex reasoning.", "conclusion": "Current MLLMs face significant limitations in complex multimodal reasoning, particularly in perception tasks. MARBLE aims to drive research toward more advanced models capable of tackling such challenges effectively."}}
{"id": "2506.22566", "pdf": "https://arxiv.org/pdf/2506.22566", "abs": "https://arxiv.org/abs/2506.22566", "authors": ["Jacob Adamczyk"], "title": "Exploration Behavior of Untrained Policies", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "High-dimensional Learning Dynamics Workshop at ICML-2025", "summary": "Exploration remains a fundamental challenge in reinforcement learning (RL),\nparticularly in environments with sparse or adversarial reward structures. In\nthis work, we study how the architecture of deep neural policies implicitly\nshapes exploration before training. We theoretically and empirically\ndemonstrate strategies for generating ballistic or diffusive trajectories from\nuntrained policies in a toy model. Using the theory of infinite-width networks\nand a continuous-time limit, we show that untrained policies return correlated\nactions and result in non-trivial state-visitation distributions. We discuss\nthe distributions of the corresponding trajectories for a standard\narchitecture, revealing insights into inductive biases for tackling\nexploration. Our results establish a theoretical and experimental framework for\nusing policy initialization as a design tool to understand exploration behavior\nin early training.", "AI": {"tldr": "This paper investigates how the architecture and initialization of untrained deep neural policies influence exploration in reinforcement learning before training begins.", "motivation": "Exploration in RL is especially difficult in settings with sparse or adversarial rewards. The authors aim to better understand how policy architectures influence exploration during early training.", "method": "By leveraging infinite-width network theory and continuous-time limits, the authors study the behavior of untrained policies, both theoretically and empirically, in a simplified model.", "result": "The study demonstrates that untrained policies produce correlated actions, leading to non-trivial state visitation distributions, which can influence early exploration behavior.", "conclusion": "Untrained policy initialization affects exploration behavior, offering a new perspective and tools to design policies that encourage effective exploration in RL environments."}}
{"id": "2506.22505", "pdf": "https://arxiv.org/pdf/2506.22505", "abs": "https://arxiv.org/abs/2506.22505", "authors": ["Hassan Baker", "Matthew S. Emigh", "Austin J. Brockmeier"], "title": "Weakly Supervised Object Segmentation by Background Conditional Divergence", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "As a computer vision task, automatic object segmentation remains challenging\nin specialized image domains without massive labeled data, such as synthetic\naperture sonar images, remote sensing, biomedical imaging, etc. In any domain,\nobtaining pixel-wise segmentation masks is expensive. In this work, we propose\na method for training a masking network to perform binary object segmentation\nusing weak supervision in the form of image-wise presence or absence of an\nobject of interest, which provides less information but may be obtained more\nquickly from manual or automatic labeling. A key step in our method is that the\nsegmented objects can be placed into background-only images to create\nrealistic, images of the objects with counterfactual backgrounds. To create a\ncontrast between the original and counterfactual background images, we propose\nto first cluster the background-only images, and then during learning create\ncounterfactual images that blend objects segmented from their original source\nbackgrounds to backgrounds chosen from a targeted cluster. One term in the\ntraining loss is the divergence between these counterfactual images and the\nreal object images with backgrounds of the target cluster. The other term is a\nsupervised loss for background-only images. While an adversarial critic could\nprovide the divergence, we use sample-based divergences. We conduct experiments\non side-scan and synthetic aperture sonar in which our approach succeeds\ncompared to previous unsupervised segmentation baselines that were only tested\non natural images. Furthermore, to show generality we extend our experiments to\nnatural images, obtaining reasonable performance with our method that avoids\npretrained networks, generative networks, and adversarial critics. The basecode\nfor this work can be found at\n\\href{GitHub}{https://github.com/bakerhassan/WSOS}.", "AI": {"tldr": "This paper introduces a weakly-supervised object segmentation method using image-wise labels, avoiding costly pixel-level annotations.", "motivation": "The lack of labeled data for specialized domains (e.g., sonar or biomedical imaging) makes object segmentation a challenging task.", "method": "The method uses weak supervision, image clustering, counterfactual background generation, and sample-based divergences for training a masking network without requiring adversarial critics or pretrained models.", "result": "The proposed approach achieves success in side-scan and synthetic aperture sonar data while also demonstrating reasonable performance on natural images.", "conclusion": "The study showcases a framework for weakly-supervised segmentation, bypassing the need for extensive manual annotation and adversarial models."}}
{"id": "2506.22668", "pdf": "https://arxiv.org/pdf/2506.22668", "abs": "https://arxiv.org/abs/2506.22668", "authors": ["Selahattin Akkas", "Aditya Devarakonda", "Ariful Azad"], "title": "DistShap: Scalable GNN Explanations with Distributed Shapley Values", "categories": ["cs.LG", "cs.AI", "cs.DC", "stat.ML"], "comment": "12 pages", "summary": "With the growing adoption of graph neural networks (GNNs), explaining their\npredictions has become increasingly important. However, attributing predictions\nto specific edges or features remains computationally expensive. For example,\nclassifying a node with 100 neighbors using a 3-layer GNN may involve\nidentifying important edges from millions of candidates contributing to the\nprediction. To address this challenge, we propose DistShap, a parallel\nalgorithm that distributes Shapley value-based explanations across multiple\nGPUs. DistShap operates by sampling subgraphs in a distributed setting,\nexecuting GNN inference in parallel across GPUs, and solving a distributed\nleast squares problem to compute edge importance scores. DistShap outperforms\nmost existing GNN explanation methods in accuracy and is the first to scale to\nGNN models with millions of features by using up to 128 GPUs on the NERSC\nPerlmutter supercomputer.", "AI": {"tldr": "The paper introduces DistShap, a scalable method for explaining graph neural network (GNN) predictions using Shapley value-based explanations distributed across GPUs, achieving state-of-the-art accuracy and scalability.", "motivation": "The increasing use of GNNs necessitates effective and scalable methods to explain predictions, which is challenging due to computational costs, especially for large-scale graphs.", "method": "DistShap is a parallel algorithm that distributes Shapley value-based calculations for edge importance. It samples subgraphs, performs GNN inference in parallel on multiple GPUs, and solves a distributed least squares problem for edge attributions.", "result": "DistShap provides more accurate explanation results compared to existing methods while scaling efficiently on large models by leveraging up to 128 GPUs on a supercomputer.", "conclusion": "DistShap significantly advances the scalability and accuracy of GNN explanation methods, making it possible to interpret models with millions of features."}}
{"id": "2506.23234", "pdf": "https://arxiv.org/pdf/2506.23234", "abs": "https://arxiv.org/abs/2506.23234", "authors": ["Peerachai Banyongrakkul", "Mansooreh Zahedi", "Patanamon Thongtanunam", "Christoph Treude", "Haoyu Gao"], "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers", "categories": ["cs.SE"], "comment": "Recently accepted at ICSME 2025", "summary": "Pre-trained models (PTMs) have gained widespread popularity and achieved\nremarkable success across various fields, driven by their groundbreaking\nperformance and easy accessibility through hosting providers. However, the\nchallenges faced by downstream developers in reusing PTMs in software systems\nare less explored. To bridge this knowledge gap, we qualitatively created and\nanalyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub\nprojects. We systematically developed a comprehensive taxonomy of PTM-related\nchallenges that developers face in downstream projects. Our study identifies\nseven key categories of challenges that downstream developers face in reusing\nPTMs, such as model usage, model performance, and output quality. We also\ncompared our findings with existing taxonomies. Additionally, we conducted a\nresolution time analysis and, based on statistical tests, found that\nPTM-related issues take significantly longer to be resolved than issues\nunrelated to PTMs, with significant variation across challenge categories. We\ndiscuss the implications of our findings for practitioners and possibilities\nfor future research.", "AI": {"tldr": "The paper studies challenges developers face when reusing pre-trained models (PTMs) in software systems, identifying seven categories of issues and highlighting their resolution complexities.", "motivation": "The motivation is to address the underexplored challenges developers encounter when reusing PTMs in downstream software projects, despite the widespread success of PTMs in various fields.", "method": "The authors created and analyzed a dataset of 840 PTM-related issues from 31 OSS GitHub projects, developing a comprehensive taxonomy of challenges and performing resolution time analysis.", "result": "Seven categories of PTM-related challenges were identified, with findings showing PTM-related issues take significantly longer for resolution compared to non-PTM issues.", "conclusion": "The paper highlights the need for better tools, support, and research resources for developers working with PTMs, offering insights for future research directions and practical improvements."}}
{"id": "2506.22623", "pdf": "https://arxiv.org/pdf/2506.22623", "abs": "https://arxiv.org/abs/2506.22623", "authors": ["Badr Youbi Idrissi", "Monica Millunzi", "Amelia Sorrenti", "Lorenzo Baraldi", "Daryna Dementieva"], "title": "Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the present-day scenario, Large Language Models (LLMs) are establishing\ntheir presence as powerful instruments permeating various sectors of society.\nWhile their utility offers valuable support to individuals, there are multiple\nconcerns over potential misuse. Consequently, some academic endeavors have\nsought to introduce watermarking techniques, characterized by the inclusion of\nmarkers within machine-generated text, to facilitate algorithmic\nidentification. This research project is focused on the development of a novel\nmethodology for the detection of synthetic text, with the overarching goal of\nensuring the ethical application of LLMs in AI-driven text generation. The\ninvestigation commences with replicating findings from a previous baseline\nstudy, thereby underscoring its susceptibility to variations in the underlying\ngeneration model. Subsequently, we propose an innovative watermarking approach\nand subject it to rigorous evaluation, employing paraphrased generated text to\nasses its robustness. Experimental results highlight the robustness of our\nproposal compared to the~\\cite{aarson} watermarking method.", "AI": {"tldr": "This paper introduces a new watermarking method to identify synthetic text and ensure ethical use of large language models.", "motivation": "Concerns about the misuse of large language models (LLMs) drive the need for reliable identification methods for machine-generated text.", "method": "The authors replicated baseline findings, proposed a novel watermarking methodology, and tested its robustness using paraphrased texts.", "result": "Experimental results demonstrate the robustness of the proposed watermarking method compared to previous approaches.", "conclusion": "The new watermarking technique offers a more reliable way to detect synthetic text, promoting responsible LLM usage."}}
{"id": "2506.22942", "pdf": "https://arxiv.org/pdf/2506.22942", "abs": "https://arxiv.org/abs/2506.22942", "authors": ["Kartik A. Pant", "Jaehyeok Kim", "James M. Goppert", "Inseok Hwang"], "title": "Energy-Constrained Resilient Multi-Robot Coverage Control", "categories": ["cs.RO"], "comment": "6 pages, 4 figures", "summary": "The problem of multi-robot coverage control becomes significantly challenging\nwhen multiple robots leave the mission space simultaneously to charge their\nbatteries, disrupting the underlying network topology for communication and\nsensing. To address this, we propose a resilient network design and control\napproach that allows robots to achieve the desired coverage performance while\nsatisfying energy constraints and maintaining network connectivity throughout\nthe mission. We model the combined motion, energy, and network dynamics of the\nmultirobot systems (MRS) as a hybrid system with three modes, i.e., coverage,\nreturn-to-base, and recharge, respectively. We show that ensuring the energy\nconstraints can be transformed into designing appropriate guard conditions for\nmode transition between each of the three modes. Additionally, we present a\nsystematic procedure to design, maintain, and reconfigure the underlying\nnetwork topology using an energy-aware bearing rigid network design, enhancing\nthe structural resilience of the MRS even when a subset of robots departs to\ncharge their batteries. Finally, we validate our proposed method using\nnumerical simulations.", "AI": {"tldr": "The paper proposes a resilient and energy-aware multi-robot control design that maintains network connectivity during disruptions caused by robots leaving for battery charging.", "motivation": "To address the challenges in multi-robot coverage control, especially when robots leave the mission to recharge, disrupting network operations.", "method": "Modeling the multi-robot system as a hybrid system with three modes (coverage, return-to-base, recharge) and designing guard conditions to ensure smooth mode transitions. Additionally, introducing an energy-aware bearing rigid network topology design for maintaining resilience.", "result": "A resilient approach that systematically manages network connectivity and energy constraints was validated through numerical simulations.", "conclusion": "The proposed method achieves desired coverage performance and maintains network connectivity in multi-robot systems, even during disruptions due to energy constraints."}}
{"id": "2506.23049", "pdf": "https://arxiv.org/pdf/2506.23049", "abs": "https://arxiv.org/abs/2506.23049", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS", "68T42, 68T50,", "I.2.7; I.2.11; H.5.5"], "comment": null, "summary": "Despite advances in language and speech technologies, no open-source system\nenables full speech-to-speech, multi-turn dialogue with integrated tool use and\nagentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and\nAutomated Tool Use), the first open-source, speech-native assistant capable of\ncompleting complex, goal-driven tasks through dynamic tool invocation and\nmulti-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a\ncascaded pipeline and supports tools such as calendar booking, contact lookup,\nweb search, and email. Its modular design allows easy integration of new tools\nusing natural language prompts and action classes. On VoiceBench, AURA scores\n92.75% on OpenBookQA-outperforming all open-weight systems and nearing\nGPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.\nHuman evaluation shows 90% task success on complex, multi-turn speech tasks.", "AI": {"tldr": "AURA is an open-source, speech-native assistant for goal-driven tasks with dynamic tool use and multi-turn dialogue.", "motivation": "Existing systems lack a platform for full speech-to-speech dialogue with integrated tool use.", "method": "AURA combines ASR, TTS, and LLMs in a modular pipeline, supporting multi-tool integration and natural language prompts.", "result": "On VoiceBench, AURA scores 92.75% and achieves 90% task success in human evaluations on complex speech tasks.", "conclusion": "AURA advances multi-turn, speech-to-speech goal-driven assistant capabilities, nearing state-of-the-art performance."}}
{"id": "2506.22578", "pdf": "https://arxiv.org/pdf/2506.22578", "abs": "https://arxiv.org/abs/2506.22578", "authors": ["Xufei Lv", "Haoyuan Sun", "Xuefeng Bai", "Min Zhang", "Houde Liu", "Kehai Chen"], "title": "The Hidden Link Between RLHF and Contrastive Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Alignment of large language models (LLMs) with human values has recently\ngarnered significant attention, with prominent examples including the canonical\nyet costly Reinforcement Learning from Human Feedback (RLHF) and the simple\nDirect Preference Optimization (DPO). In this work, we demonstrate that both\nRLHF and DPO can be interpreted from the perspective of mutual information (MI)\nmaximization, uncovering a profound connection to contrastive learning. Within\nthis framework, both RLHF and DPO can be viewed as methods that perform\ncontrastive learning based on the positive and negative samples derived from\nthe base model, leveraging the Donsker-Varadhan (DV) lower bound on MI\n(equivalently, the MINE estimator). This paradigm further explains why RLHF may\nnot intrinsically incentivize reasoning capacities in LLMs beyond what is\nalready present in the base model. Building on this perspective, we replace the\nDV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual\nInformation Optimization (MIO). Comprehensive theoretical analysis and\nextensive empirical evaluations demonstrate that MIO mitigates the late-stage\ndecline in chosen-likelihood observed in DPO, achieving competitive or superior\nperformance across various challenging reasoning and mathematical benchmarks.\nWe will release the model and code upon acceptance.", "AI": {"tldr": "The paper interprets RLHF and DPO as mutual information (MI) maximization techniques linked to contrastive learning, and proposes an improved method called MIO.", "motivation": "To address the limitations of current techniques (RLHF and DPO) in aligning large language models (LLMs) with human values and reasoning capabilities.", "method": "The authors connect RLHF and DPO to mutual information (MI) maximization using the Donsker-Varadhan (DV) bound and propose a novel Jensen-Shannon MI estimator in a method called Mutual Information Optimization (MIO).", "result": "MIO mitigates the decline in performance seen in DPO and achieves better or comparable results in reasoning and mathematical benchmarks through theoretical and empirical evaluations.", "conclusion": "MIO is an effective alternative to existing alignment techniques, improving performance while addressing their limitations. The model and code will be accessible post-acceptance."}}
{"id": "2506.22509", "pdf": "https://arxiv.org/pdf/2506.22509", "abs": "https://arxiv.org/abs/2506.22509", "authors": ["Hang Xu", "Jie Huang", "Linjiang Huang", "Dong Li", "Yidi Liu", "Feng Zhao"], "title": "FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment", "categories": ["cs.CV", "cs.AI"], "comment": "ICCV2025", "summary": "Domain Adaptation(DA) for dense prediction tasks is an important topic, which\nenhances the dense prediction model's performance when tested on its unseen\ndomain. Recently, with the development of Diffusion-based Dense Prediction\n(DDP) models, the exploration of DA designs tailored to this framework is worth\nexploring, since the diffusion model is effective in modeling the distribution\ntransformation that comprises domain information. In this work, we propose a\ntraining-free mechanism for DDP frameworks, endowing them with DA capabilities.\nOur motivation arises from the observation that the exposure bias (e.g., noise\nstatistics bias) in diffusion brings domain shift, and different domains in\nconditions of DDP models can also be effectively captured by the noise\nprediction statistics. Based on this, we propose a training-free Domain Noise\nAlignment (DNA) approach, which alleviates the variations of noise statistics\nto domain changes during the diffusion sampling process, thereby achieving\ndomain adaptation. Specifically, when the source domain is available, we\ndirectly adopt the DNA method to achieve domain adaptation by aligning the\nnoise statistics of the target domain with those of the source domain. For the\nmore challenging source-free DA, inspired by the observation that regions\ncloser to the source domain exhibit higher confidence meeting variations of\nsampling noise, we utilize the statistics from the high-confidence regions\nprogressively to guide the noise statistic adjustment during the sampling\nprocess. Notably, our method demonstrates the effectiveness of enhancing the DA\ncapability of DDP models across four common dense prediction tasks. Code is\navailable at\n\\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.", "AI": {"tldr": "The paper proposes a training-free Domain Noise Alignment (DNA) method to enhance domain adaptation for diffusion-based dense prediction (DDP) models by adjusting noise statistics in the diffusion process, demonstrating its effectiveness across multiple tasks.", "motivation": "The authors aim to address the challenge of domain adaptation for dense prediction models within the emerging framework of diffusion-based dense prediction, leveraging the noise modeling capability of diffusion models to handle domain shifts.", "method": "The proposed training-free DNA approach adjusts noise statistics during the diffusion sampling process. It aligns target domain noise with source domain noise statistics (source-aware DA) or progressively uses high-confidence region statistics in source-free scenarios.", "result": "The DNA method demonstrates effective domain adaptation improvement for DDP models across four standard dense prediction tasks.", "conclusion": "This method provides a novel, efficient, training-free solution to endow diffusion-based dense prediction models with domain adaptation capabilities, addressing noise-induced domain shifts."}}
{"id": "2506.22855", "pdf": "https://arxiv.org/pdf/2506.22855", "abs": "https://arxiv.org/abs/2506.22855", "authors": ["Mohammadreza Doostmohammadian", "Hamid R. Rabiee"], "title": "Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity", "categories": ["eess.SY", "cs.DC", "cs.MA", "cs.SY", "eess.SP", "math.OC"], "comment": "Journal of the Franklin Institute", "summary": "Distributed optimization advances centralized machine learning methods by\nenabling parallel and decentralized learning processes over a network of\ncomputing nodes. This work provides an accelerated consensus-based distributed\nalgorithm for locally non-convex optimization using the gradient-tracking\ntechnique. The proposed algorithm (i) improves the convergence rate by adding\nmomentum towards the optimal state using the heavy-ball method, while (ii)\naddressing general sector-bound nonlinearities over the information-sharing\nnetwork. The link nonlinearity includes any sign-preserving odd sector-bound\nmapping, for example, log-scale data quantization or clipping in practical\napplications. For admissible momentum and gradient-tracking parameters, using\nperturbation theory and eigen-spectrum analysis, we prove convergence even in\nthe presence of sector-bound nonlinearity and for locally non-convex cost\nfunctions. Further, in contrast to most existing weight-stochastic algorithms,\nwe adopt weight-balanced (WB) network design. This WB design and\nperturbation-based analysis allow to handle dynamic directed network of agents\nto address possible time-varying setups due to link failures or packet drops.", "AI": {"tldr": "The paper introduces an accelerated consensus-based distributed algorithm for non-convex optimization that improves convergence using momentum, addresses sector-bound nonlinearities, and adapts to dynamic network setups.", "motivation": "To overcome limitations of centralized methods and improve decentralized learning efficiency and robustness in the presence of nonlinearities and dynamic network conditions.", "method": "The authors employ the heavy-ball method for momentum, gradient-tracking techniques, perturbation theory, and eigen-spectrum analysis.", "result": "They prove convergence despite sector-bound nonlinearities and non-convexity, while enabling applicability to time-varying, directed networks.", "conclusion": "The paper provides an effective framework for distributed optimization in dynamic environments with nonlinear constraints, ensuring improved convergence and robustness."}}
{"id": "2506.22644", "pdf": "https://arxiv.org/pdf/2506.22644", "abs": "https://arxiv.org/abs/2506.22644", "authors": ["Chase Fensore", "Kaustubh Dhole", "Joyce C Ho", "Eugene Agichtein"], "title": "Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge", "categories": ["cs.CL", "cs.IR"], "comment": "4 pages, 3 tables, 2 figures. Accepted at the SIGIR LiveRAG Workshop\n  2025 (Submission 2664)", "summary": "We present our submission to the LiveRAG Challenge 2025, which evaluates\nretrieval-augmented generation (RAG) systems on dynamic test sets using the\nFineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense\n(E5) retrieval methods and then aims to generate relevant and faithful answers\nwith Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic\nquestions generated with DataMorgana across 64 unique question-user\ncombinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP\nfrom 0.523 to 0.797 (52% relative improvement) but introduces prohibitive\ncomputational costs (84s vs 1.74s per question). While DSPy-optimized prompting\nstrategies achieved higher semantic similarity (0.771 vs 0.668), their 0%\nrefusal rates raised concerns about over-confidence and generalizability. Our\nsubmitted hybrid system without re-ranking achieved 4th place in faithfulness\nand 11th place in correctness among 25 teams. Analysis across question\ncategories reveals that vocabulary alignment between questions and documents\nwas the strongest predictor of performance on our development set, with\ndocument-similar phrasing improving cosine similarity from 0.562 to 0.762.", "AI": {"tldr": "This paper describes a hybrid retrieval-augmented generation (RAG) system for the LiveRAG Challenge 2025, combining sparse and dense retrieval with Falcon3-10B-Instruct for answer generation. The system achieves competitive results, particularly in faithfulness.", "motivation": "To address the challenge of creating reliable and effective RAG systems for dynamically changing datasets, evaluated in competitive settings like the LiveRAG Challenge.", "method": "The approach incorporates sparse (BM25) and dense (E5) retrieval methods, neural re-ranking using RankLLaMA (despite its computational cost), DSPy-optimized prompting, and evaluates their impact on performance metrics such as MAP and semantic similarity.", "result": "The hybrid system achieves notable improvements in metrics (e.g., 52% improvement in MAP with re-ranking) but has trade-offs like increased computational costs. The system placed 4th in faithfulness and 11th in correctness at the competition.", "conclusion": "Vocabulary alignment between queries and documents plays a critical role in RAG performance, and optimizing phrasing improves cosine similarity and system effectiveness. However, computational efficiency and generalizability remain key challenges."}}
{"id": "2506.22956", "pdf": "https://arxiv.org/pdf/2506.22956", "abs": "https://arxiv.org/abs/2506.22956", "authors": ["David Rodr\u00edguez-Mart\u00ednez", "Dave van der Meer", "Junlin Song", "Abishek Bera", "C. J. P\u00e9rez-del-Pulgar", "Miguel Angel Olivares-Mendez"], "title": "SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes", "categories": ["cs.RO"], "comment": "10 pages, 8 figures, dataset", "summary": "Exploring high-latitude lunar regions presents an extremely challenging\nvisual environment for robots. The low sunlight elevation angle and minimal\nlight scattering result in a visual field dominated by a high dynamic range\nfeaturing long, dynamic shadows. Reproducing these conditions on Earth requires\nsophisticated simulators and specialized facilities. We introduce a unique\ndataset recorded at the LunaLab from the SnT - University of Luxembourg, an\nindoor test facility designed to replicate the optical characteristics of\nmultiple lunar latitudes. Our dataset includes images, inertial measurements,\nand wheel odometry data from robots navigating seven distinct trajectories\nunder multiple illumination scenarios, simulating high-latitude lunar\nconditions from dawn to night time with and without the aid of headlights,\nresulting in 88 distinct sequences containing a total of 1.3M images. Data was\ncaptured using a stereo RGB-inertial sensor, a monocular monochrome camera, and\nfor the first time, a novel single-photon avalanche diode (SPAD) camera. We\nrecorded both static and dynamic image sequences, with robots navigating at\nslow (5 cm/s) and fast (50 cm/s) speeds. All data is calibrated, synchronized,\nand timestamped, providing a valuable resource for validating perception tasks\nfrom vision-based autonomous navigation to scientific imaging for future lunar\nmissions targeting high-latitude regions or those intended for robots operating\nacross perceptually degraded environments. The dataset can be downloaded from\nhttps://zenodo.org/records/13970078?preview=1, and a visual overview is\navailable at https://youtu.be/d7sPeO50_2I. All supplementary material can be\nfound at https://github.com/spaceuma/spice-hl3.", "AI": {"tldr": "This paper presents a dataset from LunaLab emulating high-latitude lunar visual conditions, supporting robotic navigation research.", "motivation": "Robotic navigation in high-latitude lunar regions faces challenges due to complex lighting conditions dominated by low sunlight angles and dynamic shadows.", "method": "A dataset was created using LunaLab, which mimics lunar lighting conditions. Data includes images, inertial measurements, and wheel odometry from diverse scenarios featuring different illumination setups and robot speeds.", "result": "The dataset contains 88 sequences with 1.3M images collected using various sensors and cameras, enabling the study of visual-based perception tasks under challenging conditions.", "conclusion": "This resource facilitates the validation of autonomous navigation systems and supports lunar research applications, particularly for degraded visual environments."}}
{"id": "2506.23080", "pdf": "https://arxiv.org/pdf/2506.23080", "abs": "https://arxiv.org/abs/2506.23080", "authors": ["Xinmin Fang", "Lingfeng Tao", "Zhengxiong Li"], "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents a comprehensive five-stage evolutionary framework for\nunderstanding the development of artificial intelligence, arguing that its\ntrajectory mirrors the historical progression of human cognitive technologies.\nWe posit that AI is advancing through distinct epochs, each defined by a\nrevolutionary shift in its capacity for representation and reasoning, analogous\nto the inventions of cuneiform, the alphabet, grammar and logic, mathematical\ncalculus, and formal logical systems. This \"Geometry of Cognition\" framework\nmoves beyond mere metaphor to provide a systematic, cross-disciplinary model\nthat not only explains AI's past architectural shifts-from expert systems to\nTransformers-but also charts a concrete and prescriptive path forward.\nCrucially, we demonstrate that this evolution is not merely linear but\nreflexive: as AI advances through these stages, the tools and insights it\ndevelops create a feedback loop that fundamentally reshapes its own underlying\narchitecture. We are currently transitioning into a \"Metalinguistic Moment,\"\ncharacterized by the emergence of self-reflective capabilities like\nChain-of-Thought prompting and Constitutional AI. The subsequent stages, the\n\"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be\ndefined by the development of a computable calculus of thought, likely through\nneuro-symbolic architectures and program synthesis, culminating in provably\naligned and reliable AI that reconstructs its own foundational representations.\nThis work serves as the methodological capstone to our trilogy, which\npreviously explored the economic drivers (\"why\") and cognitive nature (\"what\")\nof AI. Here, we address the \"how,\" providing a theoretical foundation for\nfuture research and offering concrete, actionable strategies for startups and\ndevelopers aiming to build the next generation of intelligent systems.", "AI": {"tldr": "This paper introduces a five-stage evolutionary framework for AI development, likening its progression to human cognitive history. It highlights the reflexive evolution of AI and provides a theoretical roadmap for future advancements.", "motivation": "To create a systematic framework explaining AI's architectural evolution based on analogies to human cognitive history, enabling better understanding and guiding future development.", "method": "The authors developed the 'Geometry of Cognition' framework, analyzing AI's past shifts and projecting a prescriptive path forward through cross-disciplinary modeling.", "result": "The paper identifies distinct epochs in AI evolution, such as the current 'Metalinguistic Moment,' and predicts future stages involving advances in neuro-symbolic architectures and program synthesis.", "conclusion": "The work concludes that AI's evolution is reflexive and systematic, offering insights and actionable strategies for developers to create aligned and reliable AI systems in the future."}}
{"id": "2506.22602", "pdf": "https://arxiv.org/pdf/2506.22602", "abs": "https://arxiv.org/abs/2506.22602", "authors": ["Joshua C. Zhao", "Saurabh Bagchi"], "title": "Are Fast Methods Stable in Adversarially Robust Transfer Learning?", "categories": ["cs.LG", "stat.ML"], "comment": "13 pages", "summary": "Transfer learning is often used to decrease the computational cost of model\ntraining, as fine-tuning a model allows a downstream task to leverage the\nfeatures learned from the pre-training dataset and quickly adapt them to a new\ntask. This is particularly useful for achieving adversarial robustness, as\nadversarially training models from scratch is very computationally expensive.\nHowever, high robustness in transfer learning still requires adversarial\ntraining during the fine-tuning phase, which requires up to an order of\nmagnitude more time than standard fine-tuning. In this work, we revisit the use\nof the fast gradient sign method (FGSM) in robust transfer learning to improve\nthe computational cost of adversarial fine-tuning. We surprisingly find that\nFGSM is much more stable in adversarial fine-tuning than when training from\nscratch. In particular, FGSM fine-tuning does not suffer from any issues with\ncatastrophic overfitting at standard perturbation budgets of $\\varepsilon=4$ or\n$\\varepsilon=8$. This stability is further enhanced with parameter-efficient\nfine-tuning methods, where FGSM remains stable even up to $\\varepsilon=32$ for\nlinear probing. We demonstrate how this stability translates into performance\nacross multiple datasets. Compared to fine-tuning with the more commonly used\nmethod of projected gradient descent (PGD), on average, FGSM only loses 0.39%\nand 1.39% test robustness for $\\varepsilon=4$ and $\\varepsilon=8$ while using\n$4\\times$ less training time. Surprisingly, FGSM may not only be a\nsignificantly more efficient alternative to PGD in adversarially robust\ntransfer learning but also a well-performing one.", "AI": {"tldr": "This paper revisits using the fast gradient sign method (FGSM) in adversarially robust transfer learning, showing it is computationally efficient and stable compared to more expensive methods like PGD.", "motivation": "The paper aims to reduce the computational cost of adversarial fine-tuning in transfer learning, as current methods like PGD are computationally expensive while adversarial training from scratch is impractical.", "method": "The paper explores FGSM for adversarial fine-tuning, showing its stability even under standard and high perturbation budgets. It also examines parameter-efficient techniques to further enhance FGSM's performance across multiple datasets.", "result": "FGSM fine-tuning achieves comparable adversarial robustness to PGD with minimal performance drop (0.39% and 1.39% for standard budgets) and requires four times less training time.", "conclusion": "FGSM offers an efficient and effective alternative for adversarially robust transfer learning, making it suitable for reducing resource demands with relatively small sacrifices in robustness."}}
{"id": "2506.22511", "pdf": "https://arxiv.org/pdf/2506.22511", "abs": "https://arxiv.org/abs/2506.22511", "authors": ["Tingting Zhou", "Feng Zhang", "Haoyang Fu", "Baoxiang Pan", "Renhe Zhang", "Feng Lu", "Zhixin Yang"], "title": "Lightning the Night with Generative Artificial Intelligence", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "The visible light reflectance data from geostationary satellites is crucial\nfor meteorological observations and plays an important role in weather\nmonitoring and forecasting. However, due to the lack of visible light at night,\nit is impossible to conduct continuous all-day weather observations using\nvisible light reflectance data. This study pioneers the use of generative\ndiffusion models to address this limitation. Based on the multi-band thermal\ninfrared brightness temperature data from the Advanced Geostationary Radiation\nImager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we\ndeveloped a high-precision visible light reflectance retrieval model, called\nReflectance Diffusion (RefDiff), which enables 0.47~\\mu\\mathrm{m},\n0.65~\\mu\\mathrm{m}, and 0.825~\\mu\\mathrm{m} bands visible light reflectance\nretrieval at night. Compared to the classical models, RefDiff not only\nsignificantly improves accuracy through ensemble averaging but also provides\nuncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,\nwith particularly significant improvements in areas with complex cloud\nstructures and thick clouds. The model's nighttime retrieval capability was\nvalidated using VIIRS nighttime product, demonstrating comparable performance\nto its daytime counterpart. In summary, this research has made substantial\nprogress in the ability to retrieve visible light reflectance at night, with\nthe potential to expand the application of nighttime visible light data.", "AI": {"tldr": "This study introduces a generative diffusion model to retrieve nighttime visible light reflectance data, addressing the limitation of meteorological observations during darkness.", "motivation": "Meteorological observations rely heavily on visible light reflectance data, yet nighttime observation remains impossible due to the lack of visible light.", "method": "A generative diffusion model called Reflectance Diffusion (RefDiff) was developed using thermal infrared brightness temperature data from the Fengyun-4B geostationary satellite.", "result": "RefDiff achieved high precision with an SSIM index of 0.90, especially for areas with complex clouds, and validated successful nighttime retrieval compared to VIIRS daytime data.", "conclusion": "The research advances nighttime visible light reflectance retrieval, enabling continuous all-day meteorological monitoring and expanding its application potential."}}
{"id": "2506.22875", "pdf": "https://arxiv.org/pdf/2506.22875", "abs": "https://arxiv.org/abs/2506.22875", "authors": ["Everson Flores", "Bruna Guterres", "Thomaz Pereira Junior", "Paula Barros", "Alberto Cabral", "Cristiana Lima Dora", "Marcelo Malheiros", "Marcelo Pias"], "title": "Reliable Image Transmission in CPS-based Pub/Sub", "categories": ["cs.NI", "cs.DC"], "comment": "10 pages, 4 figures", "summary": "Developments in communication and automation have driven the expansion of\ndistributed networks, essential for IoT and CPS development in industrial\napplications requiring reliable image processing and real-time adaptability.\nAlthough broadly adopted, there is a literature gap regarding the performance\nof MQTT protocol for image sharing and transmission under high-traffic\nscenarios with intermittent connectivity, restricting its use in critical IoT\nand CPS applications. In this context, the present work examines the\nreliability of real-time image transmission in IoT and CPS industrial systems\nthat utilize the MQTT-based publish/subscribe communication model. It focuses\non scenarios with network interruptions and high data traffic, evaluating the\nperformance of a distributed system through a series of controlled testbed\nvalidation experiments. Experimental validation demonstrated that while the\nMQTT-based system sustains reliable transmission under normal conditions, its\nrecovery capability depends on the failure point, with complete restoration\noccurring when disruptions affect the Orchestrator Node and partial recovery\nwhen the Producer Node or Broker are affected. The study also confirmed that\nthe system prevents duplicate errors and adapts well to increasing network\ndemands, reinforcing its suitability for industrial applications that require\nefficient and resilient data handling.", "AI": {"tldr": "This study investigates the performance of MQTT protocol for real-time image transmission in industrial IoT and CPS systems under high-traffic and network interruption scenarios.", "motivation": "There is a literature gap regarding the effectiveness of MQTT for image sharing in critical IoT and CPS applications, especially under challenging network conditions.", "method": "The study evaluates a distributed MQTT-based system through controlled testbed experiments to test performance under network interruptions and high traffic.", "result": "Reliability is sustained under normal conditions, while recovery depends on the failure point. The system avoids duplicate errors and adapts to increasing demands, showcasing its robustness for industrial use.", "conclusion": "MQTT-based systems are suitable for industrial IoT applications, providing efficient and resilient data handling even under challenging conditions."}}
{"id": "2506.23534", "pdf": "https://arxiv.org/pdf/2506.23534", "abs": "https://arxiv.org/abs/2506.23534", "authors": ["Siyu Chen", "Jiongyi Yang", "Xiang Chen", "Menglin Zheng", "Minnan Wei", "Xiaolin Ju"], "title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning", "categories": ["cs.SE"], "comment": null, "summary": "Context: Software vulnerabilities pose a significant threat to modern\nsoftware systems, as evidenced by the growing number of reported\nvulnerabilities and cyberattacks. These escalating trends underscore the urgent\nneed for effective approaches that can automatically detect and understand\nsoftware vulnerabilities. Objective: However, the scarcity of labeled samples\nand the class imbalance issue in vulnerability datasets present significant\nchallenges for both Vulnerability Type Prediction (VTP) and Line-level\nVulnerability Detection (LVD), especially for rare yet critical vulnerability\ntypes. Moreover, most existing studies treat VTP and LVD as independent tasks,\noverlooking their inherent correlation, which limits the potential to leverage\nshared semantic patterns across tasks. Methods: To address these limitations,\nwe propose a unified approach that integrates Embedding-Layer Driven\nAdversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT\nenhances model robustness by introducing adversarial perturbations to\nidentifier embeddings, guided by semantic importance. Meanwhile, MTL improves\noverall performance by leveraging shared representations and inter-task\ncorrelations between VTP and LVD. Results: Extensive experiments demonstrate\nthat our proposed approach outperforms state-of-the-art baselines on both VTP\nand LVD tasks. For VTP, it yields notable improvements in accuracy, precision,\nrecall, and F1-score, particularly in identifying rare vulnerability types.\nSimilarly, for LVD, our approach enhances line-level detection accuracy while\nsignificantly reducing false positives. Conclusion: Our study demonstrates that\ncombining EDAT with MTL provides a unified solution that improves performance\non both tasks and warrants further investigation.", "AI": {"tldr": "This paper addresses the challenges in detecting software vulnerabilities by proposing a unified approach combining Embedding-Layer Driven Adversarial Training (EDAT) and Multi-task Learning (MTL), achieving superior results in vulnerability type prediction and line-level detection compared to state-of-the-art methods.", "motivation": "Escalating software vulnerabilities and cyberattacks demand automated detection methods, but challenges such as limited labeled data, class imbalance, and the independent treatment of related tasks hinder progress.", "method": "The study integrates EDAT to enhance robustness via adversarial perturbations and MTL to exploit shared semantics and inter-task correlations for Vulnerability Type Prediction (VTP) and Line-level Vulnerability Detection (LVD).", "result": "The proposed unified approach improves VTP accuracy, precision, recall, and F1-score, especially for rare types. It also enhances LVD accuracy while reducing false positives, outperforming existing methods.", "conclusion": "The integration of EDAT with MTL offers an effective unified solution for both VTP and LVD, showing promise for further research and refinement."}}
{"id": "2506.22679", "pdf": "https://arxiv.org/pdf/2506.22679", "abs": "https://arxiv.org/abs/2506.22679", "authors": ["Ankush Raut", "Projna Paromita", "Sydney Begerowski", "Suzanne Bell", "Theodora Chaspari"], "title": "Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions", "categories": ["cs.CL"], "comment": "5 pages, 4 figures. Accepted to Interspeech 2025", "summary": "We explore the feasibility of large language models (LLMs) in detecting\nsubtle expressions of micro-behaviors in team conversations using transcripts\ncollected during simulated space missions. Specifically, we examine zero-shot\nclassification, fine-tuning, and paraphrase-augmented fine-tuning with\nencoder-only sequence classification LLMs, as well as few-shot text generation\nwith decoder-only causal language modeling LLMs, to predict the micro-behavior\nassociated with each conversational turn (i.e., dialogue). Our findings\nindicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to\ndetect underrepresented micro-behaviors, particularly discouraging speech, even\nwith weighted fine-tuning. In contrast, the instruction fine-tuned version of\nLlama-3.1, a decoder-only LLM, demonstrated superior performance, with the best\nmodels achieving macro F1-scores of 44% for 3-way classification and 68% for\nbinary classification. These results have implications for the development of\nspeech technologies aimed at analyzing team communication dynamics and\nenhancing training interventions in high-stakes environments such as space\nmissions, particularly in scenarios where text is the only accessible data.", "AI": {"tldr": "The paper evaluates the capability of large language models (LLMs) in detecting micro-behaviors in team conversation transcripts from simulated space missions, with mixed results showing the superiority of decoder-only LLMs for certain tasks.", "motivation": "To analyze team communication dynamics and develop speech technologies for training interventions in high-stakes environments like space missions, particularly when only text data is available.", "method": "The study examines zero-shot classification, fine-tuning, and paraphrase-augmented fine-tuning using encoder-only LLMs, alongside few-shot generation with decoder-only LLMs for detecting micro-behaviors in conversational dialogues.", "result": "Encoder-only LLMs struggled with underrepresented behaviors despite weighted fine-tuning, whereas instruction fine-tuned decoder-only LLMs like Llama-3.1 achieved better macro F1-scores: 44% for 3-way classification and 68% for binary classification.", "conclusion": "Decoder-only LLMs, especially instruction fine-tuned variants, offer superior capabilities in detecting micro-behaviors and show promise in advancing text-based speech technologies for analyzing team communication in critical settings like space missions."}}
{"id": "2506.23023", "pdf": "https://arxiv.org/pdf/2506.23023", "abs": "https://arxiv.org/abs/2506.23023", "authors": ["M. Youssef Abdelhamid", "Lennart Vater", "Zlatan Ajanovic"], "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "6 pages, 10 figures, submitted to a conference", "summary": "Developing decision-making algorithms for highly automated driving systems\nremains challenging, since these systems have to operate safely in an open and\ncomplex environments. Reinforcement Learning (RL) approaches can learn\ncomprehensive decision policies directly from experience and already show\npromising results in simple driving tasks. However, current approaches fail to\nachieve generalizability for more complex driving tasks and lack learning\nefficiency. Therefore, we present Scenario-based Automated Driving\nReinforcement Learning (SAD-RL), the first framework that integrates\nReinforcement Learning (RL) of hierarchical policy in a scenario-based\nenvironment. A high-level policy selects maneuver templates that are evaluated\nand executed by a low-level control logic. The scenario-based environment\nallows to control the training experience for the agent and to explicitly\nintroduce challenging, but rate situations into the training process. Our\nexperiments show that an agent trained using the SAD-RL framework can achieve\nsafe behaviour in easy as well as challenging situations efficiently. Our\nablation studies confirmed that both HRL and scenario diversity are essential\nfor achieving these results.", "AI": {"tldr": "This paper presents a novel framework, SAD-RL, for improving decision-making algorithms in automated driving using hierarchical reinforcement learning (HRL) in a scenario-based setup.", "motivation": "To address the challenges of safety and efficiency in decision-making for highly automated driving systems, which need to operate in complex and open environments.", "method": "The authors proposed SAD-RL, an integration of hierarchical reinforcement learning with a scenario-based environment. A high-level policy handles maneuver selection, while a low-level controller performs those actions. Training scenarios are designed to include rare and challenging situations.", "result": "The experiments demonstrated that agents trained with SAD-RL achieve safe and efficient behavior in both simple and complex driving scenarios. Additionally, ablation studies confirmed the necessity of both HRL and scenario diversity.", "conclusion": "Scenario-based training and hierarchical RL are critical for improving the robustness and efficiency of decision-making systems in highly automated driving."}}
{"id": "2506.23107", "pdf": "https://arxiv.org/pdf/2506.23107", "abs": "https://arxiv.org/abs/2506.23107", "authors": ["Bing Song", "Jianing Liu", "Sisi Jian", "Chenyang Wu", "Vinayak Dixit"], "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study", "categories": ["cs.AI"], "comment": "20 pages, 1 figure", "summary": "Large language models (LLMs) have made significant strides, extending their\napplications to dialogue systems, automated content creation, and\ndomain-specific advisory tasks. However, as their use grows, concerns have\nemerged regarding their reliability in simulating complex decision-making\nbehavior, such as risky decision-making, where a single choice can lead to\nmultiple outcomes. This study investigates the ability of LLMs to simulate\nrisky decision-making scenarios. We compare model-generated decisions with\nactual human responses in a series of lottery-based tasks, using transportation\nstated preference survey data from participants in Sydney, Dhaka, Hong Kong,\nand Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and\nChatGPT o1-mini -- which were tasked with predicting individual choices. Risk\npreferences were analyzed using the Constant Relative Risk Aversion (CRRA)\nframework. Results show that both models exhibit more risk-averse behavior than\nhuman participants, with o1-mini aligning more closely with observed human\ndecisions. Further analysis of multilingual data from Nanjing and Hong Kong\nindicates that model predictions in Chinese deviate more from actual responses\ncompared to English, suggesting that prompt language may influence simulation\nperformance. These findings highlight both the promise and the current\nlimitations of LLMs in replicating human-like risk behavior, particularly in\nlinguistic and cultural settings.", "AI": {"tldr": "This study evaluates LLMs' ability to mimic human risky decision-making using lottery tasks and finds discrepancies in risk preferences across languages and cultural settings.", "motivation": "Concerns about the reliability of LLMs in complex decision-making, especially risky scenarios, motivated analyzing their alignment with human responses.", "method": "The study compared decisions predicted by ChatGPT models to human responses in lottery-based tasks using transportation survey data from diverse demographics and a CRRA risk framework.", "result": "Both models showed more risk-averse decisions than humans, with o1-mini aligning closer to human behavior. Language differences affected simulation, particularly in Chinese versus English prompts.", "conclusion": "LLMs show potential but have limitations in replicating human risk behavior, influenced by prompt language and cultural diversity."}}
{"id": "2506.22621", "pdf": "https://arxiv.org/pdf/2506.22621", "abs": "https://arxiv.org/abs/2506.22621", "authors": ["Paul Saves", "Edward Hall\u00e9-Hannan", "Jasper Bussemaker", "Youssef Diouane", "Nathalie Bartoli"], "title": "Hierarchical Modeling and Architecture Optimization: Review and Unified Framework", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Simulation-based problems involving mixed-variable inputs frequently feature\ndomains that are hierarchical, conditional, heterogeneous, or tree-structured.\nThese characteristics pose challenges for data representation, modeling, and\noptimization. This paper reviews extensive literature on these structured input\nspaces and proposes a unified framework that generalizes existing approaches.\nIn this framework, input variables may be continuous, integer, or categorical.\nA variable is described as meta if its value governs the presence of other\ndecreed variables, enabling the modeling of conditional and hierarchical\nstructures.\n  We further introduce the concept of partially-decreed variables, whose\nactivation depends on contextual conditions. To capture these inter-variable\nhierarchical relationships, we introduce design space graphs, combining\nprinciples from feature modeling and graph theory. This allows the definition\nof general hierarchical domains suitable for describing complex system\narchitectures. The framework supports the use of surrogate models over such\ndomains and integrates hierarchical kernels and distances for efficient\nmodeling and optimization. The proposed methods are implemented in the\nopen-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are\ndemonstrated through applications in Bayesian optimization for complex system\ndesign, including a case study in green aircraft architecture.", "AI": {"tldr": "This paper introduces a generalized framework for hierarchical, mixed-variable input spaces and demonstrates its application in Bayesian optimization for complex system designs, such as green aircraft architecture.", "motivation": "To address challenges in representing, modeling, and optimizing hierarchical, conditional, heterogenous, or tree-structured mixed-variable inputs commonly found in simulation-based problems.", "method": "The paper proposes a unified framework using design space graphs to model hierarchical domains and supports surrogate modeling and hierarchical kernel optimization, implemented in the Surrogate Modeling Toolbox (SMT 2.0).", "result": "The methods were successfully applied to Bayesian optimization tasks, showcasing the framework's ability to handle complex system design challenges effectively.", "conclusion": "The framework represents a significant advancement in modeling and optimizing structured mixed-variable input spaces, with practical applications demonstrated in engineering fields like green aircraft architecture."}}
{"id": "2506.22513", "pdf": "https://arxiv.org/pdf/2506.22513", "abs": "https://arxiv.org/abs/2506.22513", "authors": ["Aditya Sharma"], "title": "Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence", "categories": ["cs.CV"], "comment": null, "summary": "This investigation attempts to create an automated framework for fault\ndetection and organization for usage in contemporary radiography, as per NDE\n4.0. The review's goals are to address the lack of information that is\nsufficiently explained, learn how to make the most of virtual defect increase,\nand determine whether the framework is viable by using NDE measurements. As its\nbasic information source, the technique consists of compiling and categorizing\n223 CR photographs of airplane welds. Information expansion systems, such as\nvirtual defect increase and standard increase, are used to work on the\npreparation dataset. A modified U-net model is prepared using the improved data\nto produce semantic fault division veils. To assess the effectiveness of the\nmodel, NDE boundaries such as Case, estimating exactness, and misleading call\nrate are used. Tiny a90/95 characteristics, which provide strong\ndifferentiating evidence of flaws, reveal that the suggested approach achieves\nexceptional awareness in defect detection. Considering a 90/95, size error, and\nfake call rate in the weld area, the consolidated expansion approach clearly\nwins. Due to the framework's fast derivation speed, large images can be broken\ndown efficiently and quickly. Professional controllers evaluate the transmitted\nsystem in the field and believe that it has a guarantee as a support device in\nthe testing cycle, irrespective of particular equipment cut-off points and\nprogramming resemblance.", "AI": {"tldr": "Develops an automated framework for fault detection in radiography using modified U-net and data augmentation, achieving effective defect detection with high performance.", "motivation": "Address the lack of well-explained information for defect detection in radiography; enhance virtual defect increase techniques; ensure framework feasibility with NDE measurements.", "method": "Utilized 223 CR images of airplane welds with virtual and standard data augmentation techniques. Trained a modified U-net for semantic fault segmentation and used NDE parameters to evaluate its performance.", "result": "The approach achieved exceptional defect detection accuracy, with notable performance on a90/95 metrics, size error reduction, and low false call rates. Demonstrated fast image analysis speed.", "conclusion": "Professional controllers believe the system shows promise as a reliable support tool in fault detection, adaptable across equipment and software limitations."}}
{"id": "2506.23535", "pdf": "https://arxiv.org/pdf/2506.23535", "abs": "https://arxiv.org/abs/2506.23535", "authors": ["Malik Muhammad Umer"], "title": "Comparative Analysis of the Code Generated by Popular Large Language Models (LLMs) for MISRA C++ Compliance", "categories": ["cs.SE"], "comment": null, "summary": "Safety-critical systems are engineered systems whose failure or malfunction\ncould result in catastrophic consequences. The software development for\nsafety-critical systems necessitates rigorous engineering practices and\nadherence to certification standards like DO-178C for avionics. DO-178C is a\nguidance document which requires compliance to well-defined software coding\nstandards like MISRA C++ to enforce coding guidelines that prevent the use of\nambiguous, unsafe, or undefined constructs. Large Language Models (LLMs) have\ndemonstrated significant capabilities in automatic code generation across a\nwide range of programming languages, including C++. Despite their impressive\nperformance, code generated by LLMs in safety-critical domains must be\ncarefully analyzed for conformance to MISRA C++ coding standards. In this\npaper, I have conducted a comparative analysis of the C++ code generated by\npopular LLMs including: OpenAI ChatGPT, Google Gemini, DeepSeek, Meta AI, and\nMicrosoft Copilot for compliance with MISRA C++.", "AI": {"tldr": "The paper conducts a comparative analysis of code generated by popular Large Language Models (LLMs) to evaluate their compliance with MISRA C++ standards in safety-critical domains.", "motivation": "Safety-critical systems require adherence to rigorous software engineering and coding standards to prevent catastrophic failures. With advancements in AI-driven code generation, it's important to assess LLM-generated code for compliance with these standards.", "method": "The study compares C++ code produced by LLMs such as ChatGPT, Google Gemini, DeepSeek, Meta AI, and Microsoft Copilot, analyzing it against MISRA C++ coding guidelines.", "result": "Findings reveal how well various LLMs conform to MISRA C++ standards, highlighting their strengths and weaknesses in safety-critical code generation.", "conclusion": "LLMs have potential in generating code for safety-critical systems, but their output must undergo stringent compliance checks to meet industry standards like MISRA C++."}}
{"id": "2506.22694", "pdf": "https://arxiv.org/pdf/2506.22694", "abs": "https://arxiv.org/abs/2506.22694", "authors": ["Raghavv Goel", "Sudhanshu Agrawal", "Mukul Gagrani", "Junyoung Park", "Yifan Zao", "He Zhang", "Tian Liu", "Yiping Yang", "Xin Yuan", "Jiuyan Lu", "Chris Lott", "Mingu Lee"], "title": "VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on\n  Efficient Systems for Foundational Models", "summary": "In this paper, we introduce a simple training-free technique to improve the\nperformance of drafter-based speculative decoding (SpD) methods that\nincorporates language modeling head (LM head) during drafting process. A\ndrafter-based speculative decoding leverages one or more smaller language\nmodels, a.k.a. drafters or draft models, to sample a draft sequence or tree\nconsisting of multiple tokens, followed by verification by a base LLM, a target\nmodel, accepting a subset as its valid generation. As it is usually considered\nthat the speculative decoding requires one-to-one mapping between vocabularies\nof the target model and the draft model, it has been natural to share the\nvocabulary between them, or even share the LM head as in EAGLE or Medusa. We\nfirst identify that this draft token sampling scheme inherently contains an\nunnecessary inference overhead in drafting, especially for some target LLMs\nwith very large vocabularies. Then, we propose a simple technique, VocabTrim,\nto mitigate the drafting overhead to improve the generation speed in\nmemory-bound environment. VocabTrim reconstructs the drafter LM head to contain\nonly a limited set of tokens, selected by the most frequently sampled from the\nvocabulary of the target model. While limiting the vocabulary in drafting\nslightly degrades the acceptance rate, it significantly reduces the drafting\nlatency in memory-bound process which is often the case on edge devices,\nresulting in higher memory-bound speed up (MBSU). We show that our method can\nboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically\nby 16% for Llama-3.2-3B-Instruct.", "AI": {"tldr": "The paper introduces VocabTrim, a method to improve speculative decoding speed by reducing vocabulary size during the drafting process.", "motivation": "Address the inefficiency in speculative decoding for large language models in memory-bound environments.", "method": "Propose VocabTrim, a technique to reconstruct the drafter LM head with a limited set of high-frequency sampled tokens.", "result": "VocabTrim reduces drafting latency and boosts memory-bound speed-up by 16% for certain Llama-3 models.", "conclusion": "VocabTrim significantly enhances speculative decoding performance without additional training, particularly in constrained environments like edge devices."}}
{"id": "2506.23078", "pdf": "https://arxiv.org/pdf/2506.23078", "abs": "https://arxiv.org/abs/2506.23078", "authors": ["Zhaoxing Zhang", "Xiaoxiang Wang", "Chengliang Zhang", "Yangyang Guo", "Zikang Yuan", "Xin Yang"], "title": "Event-based Stereo Visual-Inertial Odometry with Voxel Map", "categories": ["cs.RO"], "comment": null, "summary": "The event camera, renowned for its high dynamic range and exceptional\ntemporal resolution, is recognized as an important sensor for visual odometry.\nHowever, the inherent noise in event streams complicates the selection of\nhigh-quality map points, which critically determine the precision of state\nestimation. To address this challenge, we propose Voxel-ESVIO, an event-based\nstereo visual-inertial odometry system that utilizes voxel map management,\nwhich efficiently filter out high-quality 3D points. Specifically, our\nmethodology utilizes voxel-based point selection and voxel-aware point\nmanagement to collectively optimize the selection and updating of map points on\na per-voxel basis. These synergistic strategies enable the efficient retrieval\nof noise-resilient map points with the highest observation likelihood in\ncurrent frames, thereby ensureing the state estimation accuracy. Extensive\nevaluations on three public benchmarks demonstrate that our Voxel-ESVIO\noutperforms state-of-the-art methods in both accuracy and computational\nefficiency.", "AI": {"tldr": "The paper introduces Voxel-ESVIO, a system that improves event-based stereo visual-inertial odometry by using voxel-based map management for better noise filtering and state estimation.", "motivation": "To address the challenge of noise in event camera data which impacts the accuracy of map points used for visual odometry.", "method": "The proposed method integrates voxel-based point selection and voxel-aware point management to efficiently filter and update high-quality 3D map points, optimizing them on a per-voxel basis.", "result": "The system outperforms existing state-of-the-art methods in accuracy and computational efficiency, as tested on three public benchmarks.", "conclusion": "Voxel-ESVIO effectively enhances state estimation in event-based visual odometry by providing a noise-resilient map management approach, combining accuracy and efficiency."}}
{"id": "2506.23123", "pdf": "https://arxiv.org/pdf/2506.23123", "abs": "https://arxiv.org/abs/2506.23123", "authors": ["Rishi Bommasani"], "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy", "categories": ["cs.AI", "cs.CY", "cs.ET"], "comment": "Stanford University PhD Dissertation of Rishi Bommasani (Department\n  of Computer Science, 2025). Also available at\n  https://purl.stanford.edu/zf669yy0336", "summary": "Artificial intelligence is humanity's most promising technology because of\nthe remarkable capabilities offered by foundation models. Yet, the same\ntechnology brings confusion and consternation: foundation models are poorly\nunderstood and they may precipitate a wide array of harms. This dissertation\nexplains how technology and society coevolve in the age of AI, organized around\nthree themes. First, the conceptual framing: the capabilities, risks, and the\nsupply chain that grounds foundation models in the broader economy. Second, the\nempirical insights that enrich the conceptual foundations: transparency created\nvia evaluations at the model level and indexes at the organization level.\nFinally, the transition from understanding to action: superior understanding of\nthe societal impact of foundation models advances evidence-based AI policy.\nView together, this dissertation makes inroads into achieving better societal\noutcomes in the age of AI by building the scientific foundations and\nresearch-policy interface required for better AI governance.", "AI": {"tldr": "The paper explores how foundation models in AI impact society and proposes a framework for better governance of these technologies.", "motivation": "To address the dual-edged nature of foundation models, which hold promise for technological advancement but also pose risks and societal challenges.", "method": "The paper is organized into three themes: conceptual framing of foundation models, empirical investigations to enhance understanding, and translating insights into actionable AI policies.", "result": "It provides clearer insights into the risks and societal impact of foundation models, as well as tools like evaluations and organizational indexes for transparency.", "conclusion": "The research paves the way for evidence-based AI policies and better governance of foundation models, fostering improved societal outcomes in the age of AI."}}
{"id": "2506.22631", "pdf": "https://arxiv.org/pdf/2506.22631", "abs": "https://arxiv.org/abs/2506.22631", "authors": ["Dmitry B. Rokhlin"], "title": "A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS", "categories": ["cs.LG", "stat.ML", "68Q32, 68W27, 68W20"], "comment": null, "summary": "We study the problem of online regression with the unconstrained quadratic\nloss against a time-varying sequence of functions from a Reproducing Kernel\nHilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a\ndiscounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic\nregret in the finite-dimensional case. In this work, we lift their approach to\nthe non-parametric domain by synthesizing the DVAW framework with a random\nfeature approximation. We propose a fully adaptive, hierarchical algorithm,\nwhich we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that\nlearns both the discount factor and the number of random features. We prove\nthat this algorithm, which has a per-iteration computational complexity of\n$O(T\\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} +\n\\sqrt{T}\\ln T)$, where $P_T$ is the functional path length of a comparator\nsequence.", "AI": {"tldr": "The paper develops an adaptive algorithm, H-VAW-D, extending online regression methods to non-parametric settings. It offers computational efficiency and achieves optimal dynamic regret.", "motivation": "To extend the discounted Vovk-Azoury-Warmuth (DVAW) forecaster from finite-dimensional to non-parametric settings for online regression, addressing challenges posed by time-varying sequences in RKHS.", "method": "The authors synthesize the DVAW framework with random feature approximations and propose H-VAW-D, a hierarchical algorithm that self-adjusts the discount factor and the random feature count.", "result": "H-VAW-D achieves a computational complexity of O(T ln T) per iteration and an expected dynamic regret of O(T^{2/3}P_T^{1/3} + \u221aT ln T), where P_T represents the comparator's functional path length.", "conclusion": "H-VAW-D is computationally efficient while maintaining strong theoretical guarantees of dynamic regret, successfully bridging finite-dimensional and non-parametric approaches."}}
{"id": "2506.22517", "pdf": "https://arxiv.org/pdf/2506.22517", "abs": "https://arxiv.org/abs/2506.22517", "authors": ["Subhadip Kumar"], "title": "Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis", "categories": ["cs.CV"], "comment": null, "summary": "Containers are an integral part of the logistics industry and act as a\nbarrier for cargo. A typical service life for a container is more than 20\nyears. However, overtime containers suffer various types of damage due to the\nmechanical as well as natural factors. A damaged container is a safety hazard\nfor the employees handling it and a liability for the logistic company.\nTherefore, a timely inspection and detection of the damaged container is a key\nfor prolonging service life as well as avoiding safety hazards. In this paper,\nwe will compare the performance of the damage detection by three\nstate-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.\nWe will use a dataset of 278 annotated images to train, validate and test the\nmodel. We will compare the mAP and precision of the model. The objective of\nthis paper is to identify the model that is best suited for container damage\ndetection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%\ncompared to RF-DETR, which was 77.7%. However, while testing the model for\nnot-so-common damaged containers, the RF-DETR model outperformed the others\noverall, exhibiting superiority to accurately detecting both damaged containers\nas well as damage occurrences with high confidence.", "AI": {"tldr": "This paper compares three advanced computer vision models (Yolov12, Yolov11, and RF-DETR) for damaged container detection, analyzing their mAP and precision using a dataset of 278 images. Results show mixed performance.", "motivation": "The motivation is to address the safety and operational hazards posed by damaged containers through timely detection by leveraging state-of-the-art computer vision models.", "method": "The study trains, validates, and tests three computer vision models (Yolov12, Yolov11, and RF-DETR) on a dataset of 278 annotated images. The models are evaluated based on mAP and precision metrics.", "result": "Yolov11 and Yolov12 achieved an mAP@50 score of 81.9%, while RF-DETR scored 77.7%. However, RF-DETR performed better in detecting uncommon damaged containers with higher accuracy and confidence.", "conclusion": "While Yolov11 and Yolov12 show higher mAP scores in general tasks, RF-DETR demonstrates superiority in accurately detecting rare or specific damages, making it more versatile for varied scenarios."}}
{"id": "2506.23210", "pdf": "https://arxiv.org/pdf/2506.23210", "abs": "https://arxiv.org/abs/2506.23210", "authors": ["Taehwan Yoon", "Bongjun Choi"], "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "6 pages,14 equation", "summary": "Federated learning(FL) is used for distributed scenarios to train artificial\nintelligence(AI) models while ensuring users' privacy. In federated learning\nscenario, the server generally never knows about users' data. This type of\nconcept makes the AI training process efficient in terms of data privacy.\nHowever, regarding model performance, federated AI models may not sufficiently\nsatisfy AI users' expectations. Furthermore, AI users have a wide range of\ndifferent needs. It is not easy to satisfy the whole users needs. These types\nof issues can be addressed through AI model optimization, fine-tuning, or\npersonalization to achieve optimal model performance. To address model\noptimization challenges, we propose reference model-based federated learning\nfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.\nThis method is derived from Bayesian parameter-efficient transfer learning,\nwhich includes an optimal proximal term and enables overcoming the catastrophic\nforgetting issue in each round by utilizing a reference model that incorporates\nprevious model parameters. As a result, this method achieves both high model\nperformance and low computing cost.", "AI": {"tldr": "The paper proposes a reference model-based federated learning approach to address challenges in optimizing AI models, particularly focusing on avoiding catastrophic forgetting and improving performance.", "motivation": "Federated learning ensures privacy but often struggles to meet diverse performance expectations of AI users. Optimizing and personalizing these models is crucial but challenging.", "method": "The paper introduces a method derived from Bayesian parameter-efficient transfer learning. It includes an optimal proximal term and uses a reference model that incorporates past model parameters to overcome catastrophic forgetting in federated learning.", "result": "The proposed method ensures both high model performance and low computing costs while preventing catastrophic forgetting in federated learning scenarios.", "conclusion": "The novel approach provides a robust solution for optimizing federated learning models, balancing privacy, performance, and computational efficiency."}}
{"id": "2506.23644", "pdf": "https://arxiv.org/pdf/2506.23644", "abs": "https://arxiv.org/abs/2506.23644", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": null, "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "AI": {"tldr": "QLPro is a framework combining large language models (LLMs) and static analysis for comprehensive vulnerability detection, outperforming existing tools like CodeQL.", "motivation": "Enhance vulnerability detection in open-source projects by addressing the limitations of current static analysis tools.", "method": "Developed QLPro by integrating large language models with static analysis tools, and evaluated it using the newly constructed JavaTest dataset.", "result": "QLPro detected 41 vulnerabilities (compared to 24 by CodeQL) and uncovered 6 previously unknown vulnerabilities, including 2 0-days.", "conclusion": "QLPro demonstrates improved efficacy in vulnerability detection compared to traditional tools, highlighting its potential for enhancing security in open-source software."}}
{"id": "2506.22698", "pdf": "https://arxiv.org/pdf/2506.22698", "abs": "https://arxiv.org/abs/2506.22698", "authors": ["Emily Dux Speltz"], "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This report synthesizes the outcomes of a recent interdisciplinary workshop\nthat brought together leading experts in cognitive psychology, language\nlearning, and artificial intelligence (AI)-based natural language processing\n(NLP). The workshop, funded by the National Science Foundation, aimed to\naddress a critical knowledge gap in our understanding of the relationship\nbetween AI language models and human cognitive processes in text comprehension\nand composition. Through collaborative dialogue across cognitive, linguistic,\nand technological perspectives, workshop participants examined the underlying\nprocesses involved when humans produce and comprehend text, and how AI can both\ninform our understanding of these processes and augment human capabilities. The\nworkshop revealed emerging patterns in the relationship between large language\nmodels (LLMs) and human cognition, with highlights on both the capabilities of\nLLMs and their limitations in fully replicating human-like language\nunderstanding and generation. Key findings include the potential of LLMs to\noffer insights into human language processing, the increasing alignment between\nLLM behavior and human language processing when models are fine-tuned with\nhuman feedback, and the opportunities and challenges presented by human-AI\ncollaboration in language tasks. By synthesizing these findings, this report\naims to guide future research, development, and implementation of LLMs in\ncognitive psychology, linguistics, and education. It emphasizes the importance\nof ethical considerations and responsible use of AI technologies while striving\nto enhance human capabilities in text comprehension and production through\neffective human-AI collaboration.", "AI": {"tldr": "The report summarizes a workshop exploring the relationship between AI language models and human cognitive processes in text comprehension and production, highlighting both potential and limitations of LLMs.", "motivation": "The workshop sought to address the gap in understanding how AI language models relate to and can augment human cognitive text processes.", "method": "Experts in cognitive psychology, linguistics, and AI-NLP collaborated through interdisciplinary discussions to analyze LLMs' role in human cognition.", "result": "Findings show LLMs can align more closely with human cognition when fine-tuned with human feedback, offering opportunities for collaboration but also highlighting challenges.", "conclusion": "The report underscores the importance of ethical and responsible AI use, aiming to support advancements in enhancing human-AI collaboration for language tasks."}}
{"id": "2506.23114", "pdf": "https://arxiv.org/pdf/2506.23114", "abs": "https://arxiv.org/abs/2506.23114", "authors": ["Zhanxiang Cao", "Buqing Nie", "Yang Zhang", "Yue Gao"], "title": "Minimizing Acoustic Noise: Enhancing Quiet Locomotion for Quadruped Robots in Indoor Applications", "categories": ["cs.RO"], "comment": "8 pages,6 figures, IROS2025", "summary": "Recent advancements in quadruped robot research have significantly improved\ntheir ability to traverse complex and unstructured outdoor environments.\nHowever, the issue of noise generated during locomotion is generally\noverlooked, which is critically important in noise-sensitive indoor\nenvironments, such as service and healthcare settings, where maintaining low\nnoise levels is essential. This study aims to optimize the acoustic noise\ngenerated by quadruped robots during locomotion through the development of\nadvanced motion control algorithms. To achieve this, we propose a novel\napproach that minimizes noise emissions by integrating optimized gait design\nwith tailored control strategies. This method achieves an average noise\nreduction of approximately 8 dBA during movement, thereby enhancing the\nsuitability of quadruped robots for deployment in noise-sensitive indoor\nenvironments. Experimental results demonstrate the effectiveness of this\napproach across various indoor settings, highlighting the potential of\nquadruped robots for quiet operation in noise-sensitive environments.", "AI": {"tldr": "This paper proposes motion control algorithms to reduce locomotion noise in quadruped robots for noise-sensitive indoor environments, achieving an average 8 dBA reduction.", "motivation": "To address the overlooked problem of noise pollution caused by quadruped robots in noise-sensitive indoor environments, such as service and healthcare settings.", "method": "The study integrates optimized gait design with tailored control strategies to minimize noise emissions during robot locomotion.", "result": "Experimental findings indicate that the proposed system reduces noise emissions by an average of 8 dBA during robot movement in indoor settings.", "conclusion": "The proposed approach enhances quadruped robots' capability for silent operation, boosting their applicability for noise-sensitive indoor settings."}}
{"id": "2506.23128", "pdf": "https://arxiv.org/pdf/2506.23128", "abs": "https://arxiv.org/abs/2506.23128", "authors": ["Chi Chiu So", "Yueyue Sun", "Jun-Min Wang", "Siu Pang Yung", "Anthony Wai Keung Loh", "Chun Pong Chau"], "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons", "categories": ["cs.AI"], "comment": "10 pages, 0 figures, accepted by 2025 IEEE international conference\n  on artificial intelligence testing (AITest)", "summary": "How far are Large Language Models (LLMs) in performing deep relational\nreasoning? In this paper, we evaluate and compare the reasoning capabilities of\nthree cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a\nsuite of carefully designed benchmark tasks in family tree and general graph\nreasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the\nhighest F1-scores across multiple tasks and problem sizes, demonstrating strong\naptitude in logical deduction and relational inference. However, all evaluated\nmodels, including DeepSeek-R1, struggle significantly as problem complexity\nincreases, largely due to token length limitations and incomplete output\nstructures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought\nresponses uncovers its unique planning and verification strategies, but also\nhighlights instances of incoherent or incomplete reasoning, calling attention\nto the need for deeper scrutiny into LLMs' internal inference dynamics. We\nfurther discuss key directions for future work, including the role of\nmultimodal reasoning and the systematic examination of reasoning failures. Our\nfindings provide both empirical insights and theoretical implications for\nadvancing LLMs' reasoning abilities, particularly in tasks that demand\nstructured, multi-step logical inference. Our code repository will be publicly\navailable at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.", "AI": {"tldr": "The paper evaluates the reasoning abilities of three LLMs, with DeepSeek-R1 outperforming others but showing limitations in complex tasks.", "motivation": "To assess and compare the deep relational reasoning capabilities of leading LLMs, specifically in family tree and graph reasoning tasks.", "method": "The authors designed benchmark tasks for evaluating logical deduction and relational inference across various problem complexities, focusing on three advanced LLMs.", "result": "DeepSeek-R1 achieved the best performance but struggled with complex problems due to token length limits and incomplete reasoning structures.", "conclusion": "While showing progress, the findings highlight significant reasoning limitations in LLMs and call for further exploration into multimodal reasoning and failure analysis."}}
{"id": "2506.22641", "pdf": "https://arxiv.org/pdf/2506.22641", "abs": "https://arxiv.org/abs/2506.22641", "authors": ["Gabriel M. Mejia", "Henry E. Miller", "Francis J. A. Leblanc", "Bo Wang", "Brendan Swain", "Lucas Paulo de Lima Camillo"], "title": "Diversity by Design: Addressing Mode Collapse Improves scRNA-seq Perturbation Modeling on Well-Calibrated Metrics", "categories": ["q-bio.GN", "cs.LG", "q-bio.MN", "stat.ML"], "comment": null, "summary": "Recent benchmarks reveal that models for single-cell perturbation response\nare often outperformed by simply predicting the dataset mean. We trace this\nanomaly to a metric artifact: control-referenced deltas and unweighted error\nmetrics reward mode collapse whenever the control is biased or the biological\nsignal is sparse. Large-scale \\textit{in silico} simulations and analysis of\ntwo real-world perturbation datasets confirm that shared reference shifts, not\ngenuine biological change, drives high performance in these evaluations. We\nintroduce differentially expressed gene (DEG)-aware metrics, weighted\nmean-squared error (WMSE) and weighted delta $R^{2}$ ($R^{2}_{w}(\\Delta)$) with\nrespect to all perturbations, that measure error in niche signals with high\nsensitivity. We further introduce negative and positive performance baselines\nto calibrate these metrics. With these improvements, the mean baseline sinks to\nnull performance while genuine predictors are correctly rewarded. Finally, we\nshow that using WMSE as a loss function reduces mode collapse and improves\nmodel performance.", "AI": {"tldr": "The paper addresses flaws in performance metrics for single-cell perturbation response models, demonstrating how these metrics reward biased predictions over genuine biological changes.", "motivation": "Benchmark evaluations for single-cell perturbation models show unexpected results where predicting the dataset mean outperforms sophisticated approaches, raising concerns about metric bias.", "method": "The study analyzes in silico simulations and real-world datasets to demonstrate metric artifacts. They propose DEG-aware metrics and baselines, including WMSE and weighted delta R\u00b2.", "result": "Introducing DEG-aware metrics and loss functions resolved the mode collapse issue while significantly improving the model evaluation process.", "conclusion": "The proposed metrics and calibration methods correct biases in model assessments, providing fair evaluation tools and improving model predictions for biological applications."}}
{"id": "2506.22638", "pdf": "https://arxiv.org/pdf/2506.22638", "abs": "https://arxiv.org/abs/2506.22638", "authors": ["Aadim Nepal", "Safal Shrestha", "Anubhav Shrestha", "Minwu Kim", "Keith Ross"], "title": "Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models can exhibit improved mathematical reasoning\ncapabilities following post-training with instruction tuning, reinforcement\nlearning, or knowledge distillation. However, it remains unclear whether these\nimprovements are driven by major changes in transformer layers or from minor\nadjustments that leave the relative layer importance structures of the base\nmodel largely unchanged. We investigate this question through systematic\nlayer-wise ablation experiments, examining base, instruction-tuned,\nknowledge-distilled, and reinforcement learning variants on mathematical\nreasoning benchmarks. Our findings show that mathematical reasoning gives rise\nto a specific layer importance structure, and this structure persists across\nall post-training paradigms. Removal of such layers causes accuracy drops of up\nto 80%. In contrast, non-mathematical tasks like factual recall exhibit no\ncritical layers. This distinction suggests that mathematical reasoning requires\nspecialized layers that emerge during pre-training, while other non-reasoning\ntasks do not. From an information-theoretic perspective, we also observe that\nthese critical layers are the same layers where major representational\ntransformation occurs.", "AI": {"tldr": "The paper investigates how improvements in mathematical reasoning in language models arise after post-training, emphasizing the role of specific transformer layers.", "motivation": "To understand whether mathematical reasoning enhancements in language models post-training stem from significant changes in transformer layers or minor adjustments retaining the base model's layer structure.", "method": "Systematic layer-wise ablation experiments on various models (base, instruction-tuned, knowledge-distilled, and reinforcement-learned) tested on mathematical reasoning benchmarks.", "result": "Mathematical reasoning tasks depend on specific critical layers whose removal causes accuracy drops of up to 80%, unlike non-mathematical tasks that show no such layer dependency.", "conclusion": "Mathematical reasoning tasks rely on distinct critical layers that emerge during pre-training, which contrasts with non-reasoning tasks where such layers are unnecessary."}}
{"id": "2506.22531", "pdf": "https://arxiv.org/pdf/2506.22531", "abs": "https://arxiv.org/abs/2506.22531", "authors": ["Prasen Kumar Sharma", "Neeraj Matiyali", "Siddharth Srivastava", "Gaurav Sharma"], "title": "Preserve Anything: Controllable Image Synthesis with Object Preservation", "categories": ["cs.CV"], "comment": "Accepted at ICCV 2025", "summary": "We introduce \\textit{Preserve Anything}, a novel method for controlled image\nsynthesis that addresses key limitations in object preservation and semantic\nconsistency in text-to-image (T2I) generation. Existing approaches often fail\n(i) to preserve multiple objects with fidelity, (ii) maintain semantic\nalignment with prompts, or (iii) provide explicit control over scene\ncomposition. To overcome these challenges, the proposed method employs an\nN-channel ControlNet that integrates (i) object preservation with size and\nplacement agnosticism, color and detail retention, and artifact elimination,\n(ii) high-resolution, semantically consistent backgrounds with accurate\nshadows, lighting, and prompt adherence, and (iii) explicit user control over\nbackground layouts and lighting conditions. Key components of our framework\ninclude object preservation and background guidance modules, enforcing lighting\nconsistency and a high-frequency overlay module to retain fine details while\nmitigating unwanted artifacts. We introduce a benchmark dataset consisting of\n240K natural images filtered for aesthetic quality and 18K 3D-rendered\nsynthetic images with metadata such as lighting, camera angles, and object\nrelationships. This dataset addresses the deficiencies of existing benchmarks\nand allows a complete evaluation. Empirical results demonstrate that our method\nachieves state-of-the-art performance, significantly improving feature-space\nfidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining\ncompetitive aesthetic quality. We also conducted a user study to demonstrate\nthe efficacy of the proposed work on unseen benchmark and observed a remarkable\nimprovement of $\\sim25\\%$, $\\sim19\\%$, $\\sim13\\%$, and $\\sim14\\%$ in terms of\nprompt alignment, photorealism, the presence of AI artifacts, and natural\naesthetics over existing works.", "AI": {"tldr": "The paper introduces 'Preserve Anything,' a novel approach for better controlled image synthesis, excelling in object preservation, semantic alignment, and scene control.", "motivation": "Improve limitations in text-to-image (T2I) synthesis regarding object preservation, semantic consistency, and scene control for better image outcomes.", "method": "Proposes an N-channel ControlNet combining object preservation, background guidance, and user control. It uses lighting and detail-retention modules and introduces a dataset for thorough evaluation.", "result": "Achieves state-of-the-art performance with better fidelity (FID 15.26), semantic alignment (CLIP-S 32.85), and significant user study improvements over existing methods.", "conclusion": "The method substantially enhances T2I generation, offering advanced control, fidelity, and aesthetics over benchmarks and existing techniques."}}
{"id": "2506.23583", "pdf": "https://arxiv.org/pdf/2506.23583", "abs": "https://arxiv.org/abs/2506.23583", "authors": ["Marvin Xhemrishi", "Alexandre Graell i Amat", "Bal\u00e1zs Pej\u00f3"], "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "The shorter version is accepted at FL-AsiaCCS 25", "summary": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently.", "AI": {"tldr": "This study enhances federated learning with secure aggregation by integrating two methods (QI and FedGT) to improve both misbehavior detection (MD) and contribution evaluation (CE).", "motivation": "The paper aims to overcome challenges in federated learning, specifically in detecting malicious client behaviors and evaluating individual client contributions, compounded by secure aggregation protocols.", "method": "The researchers combine two approaches\u2014QI for contribution evaluation and FedGT for misbehavior detection\u2014to address the limitations of both and create a unified solution.", "result": "The integrated approach demonstrates better MD and CE performance in experiments compared to using QI or FedGT individually.", "conclusion": "The study successfully combines QI and FedGT to achieve robust misbehavior detection and accurate contribution evaluation in federated learning settings."}}
{"id": "2506.22724", "pdf": "https://arxiv.org/pdf/2506.22724", "abs": "https://arxiv.org/abs/2506.22724", "authors": ["Niyati Bafna", "Tianjian Li", "Kenton Murray", "David R. Mortensen", "David Yarowsky", "Hale Sirin", "Daniel Khashabi"], "title": "The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure", "categories": ["cs.CL"], "comment": "23 pages incl. appendix", "summary": "Multilingual generation with large language models (LLMs) is often of poor\nquality for mid- to low-resource languages. Building on insights from\ninterpretability, we demonstrate the existence of an implicit\ntask-solving-->translation pipeline for generation, whereby the model first\nsolves the required task in a largely target-language-agnostic manner, and\nsubsequently translates answer concepts into the intended target language. We\nhypothesize that the failure of the translation stage is an important culprit\nfor the observed low quality of final outputs, and formalize this as the\ntranslation barrier hypothesis. We test this hypothesis for a word translation\ntask across 108 language pairs, using logit lens to observe model processing in\nintermediate layers. We find that a significant portion of overall failures\nindeed stems from translation failure, or the model's inability to translate\ncorrectly solved intermediate concepts into the target language. This is\nespecially true for low-resource target languages. Our results highlight an\nimportant hurdle for end-to-end multilingual generation, and lend guiding\ninsights for future work seeking to improve multilinguality in LLMs.", "AI": {"tldr": "The paper identifies a translation barrier in LLMs as a key reason for poor multilingual generation for low-resource languages.", "motivation": "Multilingual generation by LLMs often delivers poor results for low-resource languages, necessitating an understanding of underlying failure causes.", "method": "Introduced the 'translation barrier hypothesis' and tested it using a word translation task across 108 language pairs, employing logit lens to analyze intermediate processing layers.", "result": "Confirmed that translation failures in converting intermediate concepts to target languages significantly affect performance, especially in low-resource languages.", "conclusion": "Strengthening translation capabilities for low-resource languages may improve multilingual generation, highlighting this as a critical area for development in LLMs."}}
{"id": "2506.23125", "pdf": "https://arxiv.org/pdf/2506.23125", "abs": "https://arxiv.org/abs/2506.23125", "authors": ["Zhanxiang Cao", "Yang Zhang", "Buqing Nie", "Huangxuan Lin", "Haoyang Li", "Yue Gao"], "title": "Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots", "categories": ["cs.RO"], "comment": "8 pages, 8 figures", "summary": "Learning policies for complex humanoid tasks remains both challenging and\ncompelling. Inspired by how infants and athletes rely on external support--such\nas parental walkers or coach-applied guidance--to acquire skills like walking,\ndancing, and performing acrobatic flips, we propose A2CF: Adaptive Assistive\nCurriculum Force for humanoid motion learning. A2CF trains a dual-agent system,\nin which a dedicated assistive force agent applies state-dependent forces to\nguide the robot through difficult initial motions and gradually reduces\nassistance as the robot's proficiency improves. Across three\nbenchmarks--bipedal walking, choreographed dancing, and backflip--A2CF achieves\nconvergence 30% faster than baseline methods, lowers failure rates by over 40%,\nand ultimately produces robust, support-free policies. Real-world experiments\nfurther demonstrate that adaptively applied assistive forces significantly\naccelerate the acquisition of complex skills in high-dimensional robotic\ncontrol.", "AI": {"tldr": "The paper proposes A2CF (Adaptive Assistive Curriculum Force), a dual-agent method to train humanoid robots for complex tasks by using assistive forces that are reduced as proficiency improves.", "motivation": "The authors aim to address the challenge of learning policies for complex humanoid tasks by drawing inspiration from how humans rely on external support to learn skills.", "method": "A2CF involves training a dual-agent system where one agent applies adaptive assistive forces to guide a humanoid robot initially and decreases the support as skills improve.", "result": "The approach accelerates convergence by 30%, reduces failure rates by over 40%, and produces robust, support-free policies in tasks such as walking, dancing, and performing backflips.", "conclusion": "The adaptive use of assistive forces enables humanoid robots to learn complex skills faster and more effectively both in simulations and real-world experiments."}}
{"id": "2506.23141", "pdf": "https://arxiv.org/pdf/2506.23141", "abs": "https://arxiv.org/abs/2506.23141", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing", "categories": ["cs.AI"], "comment": null, "summary": "Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge\nGraph Completion (KGC), providing vital cues for prediction. However,\ntraditional node-based message passing mechanisms, when applied to knowledge\ngraphs, often introduce noise and suffer from information dilution or\nover-smoothing by indiscriminately aggregating information from all neighboring\nedges. To address this challenge, we propose a semantic-aware relational\nmessage passing. A core innovation of this framework is the introduction of a\n\\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this\nstrategy first evaluates the semantic relevance between a central node and its\nincident edges within a shared latent space, selecting only the Top-K most\npertinent ones. Subsequently, information from these selected edges is\neffectively fused with the central node's own representation using a\n\\textbf{multi-head attention aggregator} to generate a semantically focused\nnode message. In this manner, our model not only leverages the structure and\nfeatures of edges within the knowledge graph but also more accurately captures\nand propagates the contextual information most relevant to the specific link\nprediction task, thereby effectively mitigating interference from irrelevant\ninformation. Extensive experiments demonstrate that our method achieves\nsuperior performance compared to existing approaches on several established\nbenchmarks.", "AI": {"tldr": "The paper proposes a semantic-aware relational message passing strategy for Knowledge Graph Completion, using Top-K neighbor selection and a multi-head attention aggregator to address issues of noise and over-smoothing.", "motivation": "Traditional node-based message passing in knowledge graphs can introduce noise and dilute important information, negatively impacting link prediction accuracy.", "method": "The semantic-aware relational message passing selects Top-K relevant edges based on semantic relevance and combines them with the central node representation using a multi-head attention aggregator.", "result": "Experiments show that the proposed method outperforms existing techniques in several benchmark tests.", "conclusion": "The approach effectively captures and propagates relevant contextual information while mitigating irrelevant noise, enhancing performance in knowledge graph tasks."}}
{"id": "2506.22645", "pdf": "https://arxiv.org/pdf/2506.22645", "abs": "https://arxiv.org/abs/2506.22645", "authors": ["Amir Hossein Rahmati", "Nathan M. Urban", "Byung-Jun Yoon", "Xiaoning Qian"], "title": "Cost-effective Reduced-Order Modeling via Bayesian Active Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine Learning surrogates have been developed to accelerate solving systems\ndynamics of complex processes in different science and engineering\napplications. To faithfully capture governing systems dynamics, these methods\nrely on large training datasets, hence restricting their applicability in\nreal-world problems. In this work, we propose BayPOD-AL, an active learning\nframework based on an uncertainty-aware Bayesian proper orthogonal\ndecomposition (POD) approach, which aims to effectively learn reduced-order\nmodels from high-fidelity full-order models representing complex systems.\nExperimental results on predicting the temperature evolution over a rod\ndemonstrate BayPOD-AL's effectiveness in suggesting the informative data and\nreducing computational cost related to constructing a training dataset compared\nto other uncertainty-guided active learning strategies. Furthermore, we\ndemonstrate BayPOD-AL's generalizability and efficiency by evaluating its\nperformance on a dataset of higher temporal resolution than the training\ndataset.", "AI": {"tldr": "BayPOD-AL leverages active learning with Bayesian POD for efficient reduced-order modeling, minimizing training data requirements and computational costs.", "motivation": "Current machine learning surrogates demand extensive training datasets, limiting their real-world applicability in capturing systems dynamics of complex processes.", "method": "The authors developed BayPOD-AL, an active learning framework that integrates uncertainty-aware Bayesian proper orthogonal decomposition (POD) to learn reduced-order models efficiently.", "result": "BayPOD-AL effectively identified informative data and reduced training dataset construction costs, surpassing other uncertainty-oriented active learning strategies. It also showed robustness with datasets of higher temporal resolution.", "conclusion": "BayPOD-AL improves reduced-order modeling efficiency and generalizability while reducing the dependency on large training datasets, making it suitable for complex systems."}}
{"id": "2506.22554", "pdf": "https://arxiv.org/pdf/2506.22554", "abs": "https://arxiv.org/abs/2506.22554", "authors": ["Vasu Agrawal", "Akinniyi Akinyemi", "Kathryn Alvero", "Morteza Behrooz", "Julia Buffalini", "Fabio Maria Carlucci", "Joy Chen", "Junming Chen", "Zhang Chen", "Shiyang Cheng", "Praveen Chowdary", "Joe Chuang", "Antony D'Avirro", "Jon Daly", "Ning Dong", "Mark Duppenthaler", "Cynthia Gao", "Jeff Girard", "Martin Gleize", "Sahir Gomez", "Hongyu Gong", "Srivathsan Govindarajan", "Brandon Han", "Sen He", "Denise Hernandez", "Yordan Hristov", "Rongjie Huang", "Hirofumi Inaguma", "Somya Jain", "Raj Janardhan", "Qingyao Jia", "Christopher Klaiber", "Dejan Kovachev", "Moneish Kumar", "Hang Li", "Yilei Li", "Pavel Litvin", "Wei Liu", "Guangyao Ma", "Jing Ma", "Martin Ma", "Xutai Ma", "Lucas Mantovani", "Sagar Miglani", "Sreyas Mohan", "Louis-Philippe Morency", "Evonne Ng", "Kam-Woh Ng", "Tu Anh Nguyen", "Amia Oberai", "Benjamin Peloquin", "Juan Pino", "Jovan Popovic", "Omid Poursaeed", "Fabian Prada", "Alice Rakotoarison", "Alexander Richard", "Christophe Ropers", "Safiyyah Saleem", "Vasu Sharma", "Alex Shcherbyna", "Jia Shen", "Jie Shen", "Anastasis Stathopoulos", "Anna Sun", "Paden Tomasello", "Tuan Tran", "Arina Turkatenko", "Bo Wan", "Chao Wang", "Jeff Wang", "Mary Williamson", "Carleigh Wood", "Tao Xiang", "Yilin Yang", "Julien Yao", "Chen Zhang", "Jiemin Zhang", "Xinyue Zhang", "Jason Zheng", "Pavlo Zhyzheria", "Jan Zikes", "Michael Zollhoefer"], "title": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Human communication involves a complex interplay of verbal and nonverbal\nsignals, essential for conveying meaning and achieving interpersonal goals. To\ndevelop socially intelligent AI technologies, it is crucial to develop models\nthat can both comprehend and generate dyadic behavioral dynamics. To this end,\nwe introduce the Seamless Interaction Dataset, a large-scale collection of over\n4,000 hours of face-to-face interaction footage from over 4,000 participants in\ndiverse contexts. This dataset enables the development of AI technologies that\nunderstand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,\ntelepresence experiences, and multimodal content analysis tools. We also\ndevelop a suite of models that utilize the dataset to generate dyadic motion\ngestures and facial expressions aligned with human speech. These models can\ntake as input both the speech and visual behavior of their interlocutors. We\npresent a variant with speech from an LLM model and integrations with 2D and 3D\nrendering methods, bringing us closer to interactive virtual agents.\nAdditionally, we describe controllable variants of our motion models that can\nadapt emotional responses and expressivity levels, as well as generating more\nsemantically-relevant gestures. Finally, we discuss methods for assessing the\nquality of these dyadic motion models, which are demonstrating the potential\nfor more intuitive and responsive human-AI interactions.", "AI": {"tldr": "The paper introduces a dataset and models for generating dyadic motion gestures and expressions for improving socially intelligent AI interactions.", "motivation": "To enable socially intelligent AI by understanding and generating dyadic behavioral dynamics in face-to-face interactions.", "method": "The authors introduce a large-scale dataset of face-to-face interactions and develop models to generate gesture and facial expressions aligned with speech and visual behavior.", "result": "Their models generate multimodal dynamics like gestures and expressions using speech inputs (including LLM speech), integrated with 2D and 3D rendering, and adaptable expressivity.", "conclusion": "This work advances human-AI interaction by enabling AI to show intuitive, emotionally adaptive, and semantically rich responses in interactive scenarios."}}
{"id": "2506.23836", "pdf": "https://arxiv.org/pdf/2506.23836", "abs": "https://arxiv.org/abs/2506.23836", "authors": ["Alexander Tyurin"], "title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction", "categories": ["math.OC", "cs.DC", "cs.LG"], "comment": null, "summary": "We consider centralized distributed optimization in the classical federated\nlearning setup, where $n$ workers jointly find an $\\varepsilon$-stationary\npoint of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access\nonly to unbiased stochastic gradients with variance $\\sigma^2$. Each worker\nrequires at most $h$ seconds to compute a stochastic gradient, and the\ncommunication times from the server to the workers and from the workers to the\nserver are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One\nof the main motivations for distributed optimization is to achieve scalability\nwith respect to $n$. For instance, it is well known that the distributed\nversion of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L\n\\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where\n$\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly,\nusing unbiased sparsification compressors, it is possible to reduce both the\nvariance-dependent runtime term and the communication runtime term. However,\nonce we account for the communication from the server to the workers\n$\\tau_{s}$, we prove that it becomes infeasible to design a method using\nunbiased random sparsification compressors that scales both the server-side\ncommunication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the\nvariance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$\nbetter than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,\nwhere all workers access the same distribution. To establish this result, we\nconstruct a new \"worst-case\" function and develop a new lower bound framework\nthat reduces the analysis to the concentration of a random sum, for which we\nprove a concentration bound. These results reveal fundamental limitations in\nscaling distributed optimization, even under the homogeneous assumption.", "AI": {"tldr": "The paper investigates the scalability of centralized distributed optimization in federated learning, addressing constraints in scaling communication and runtime. It establishes theoretical limitations using a new lower bound framework and a worst-case function construction.", "motivation": "The paper is motivated by the goal of understanding the scalability of distributed optimization algorithms in federated learning, particularly when accounting for both computation and communication overheads.", "method": "The approach involves theoretical analysis using a newly constructed worst-case function and a lower bound framework. The framework relies on a concentration of a random sum to derive fundamental limits.", "result": "The study proves that it's infeasible to design methods using unbiased random sparsification compressors to scale server-side communication and variance-dependent runtime terms better than poly-logarithmically in $n$ (number of workers).", "conclusion": "The findings highlight inherent limitations in distributed optimization scalability, even in ideally homogeneous setups, challenging the design of efficient federated learning algorithms."}}
{"id": "2506.23715", "pdf": "https://arxiv.org/pdf/2506.23715", "abs": "https://arxiv.org/abs/2506.23715", "authors": ["Benoit Combemale"], "title": "Towards a Science of Developer eXperience (DevX)", "categories": ["cs.SE"], "comment": null, "summary": "As software continues to permeate nearly every facet of modern life, the\ncomplexity and ubiquity of digital services underscore the need for\nsustainable, effective, and inclusive software development practices. Although\nsoftware engineering has made significant progress in technical challenges\nsince its inception, the human experience of those involved in software\ncreation, broadly defined as developers, remains underexplored. This column\nadvocates for the formal recognition of Developer eXperience (DevX) as a\ndistinct research field. We argue that DevX profoundly influences critical\ndevelopment activities and overall productivity, especially as development\nbecomes increasingly collaborative and diverse in terms of application domains.\nBuilding on existing efforts to measure and enhance DevX, we identify key\nrationales, scientific enablers, and interdisciplinary intersections that\nsupport this emerging discipline. We also outline the core scientific\nchallenges ahead, aiming to call for actions from the research community and to\npromote more human-centered approaches to software engineering.", "AI": {"tldr": "The paper argues for recognizing Developer eXperience (DevX) as an essential field of research in software engineering.", "motivation": "To address the underexplored human aspects of software creation, despite the technical advances in software engineering.", "method": "The paper identifies rationales, enablers, and interdisciplinary intersections while providing a roadmap for scientific challenges in DevX.", "result": "It highlights the importance of DevX in collaborative and diverse development environments for fostering productivity and sustainable practices.", "conclusion": "The authors call for a research focus on DevX to develop human-centered software engineering approaches and enhance developer productivity."}}
{"id": "2506.22760", "pdf": "https://arxiv.org/pdf/2506.22760", "abs": "https://arxiv.org/abs/2506.22760", "authors": ["Alan Dao", "Dinh Bach Vu"], "title": "Jan-nano Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "Most language models face a fundamental tradeoff where powerful capabilities\nrequire substantial computational resources. We shatter this constraint with\nJan-nano, a 4B parameter language model that redefines efficiency through\nradical specialization: instead of trying to know everything, it masters the\nart of finding anything instantly. Fine-tuned from Qwen3-4B using our novel\nmulti-stage RLVR system that completely eliminates reliance on next token\nprediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with\nMCP integration while running on consumer hardware. With 128K context length,\nJan-nano proves that intelligence isn't about scale, it's about strategy.", "AI": {"tldr": "Jan-nano, a 4B parameter model, achieves efficiency by focusing on finding information rather than knowing everything, achieving high performance on QA benchmarks while running on consumer hardware.", "motivation": "The study aims to overcome the tradeoff in language models between computational resource needs and capabilities by exploring a more efficient and specialized approach.", "method": "The authors developed Jan-nano through a novel multi-stage RLVR system, bypassing traditional next-token prediction training and incorporating MCP integration for performance.", "result": "The model achieved 83.2% on the SimpleQA benchmark and demonstrated an ability to function efficiently with a 128K context length on consumer hardware.", "conclusion": "Jan-nano exemplifies that strategy and specialization can surpass scale in achieving intelligent capabilities effectively."}}
{"id": "2506.23126", "pdf": "https://arxiv.org/pdf/2506.23126", "abs": "https://arxiv.org/abs/2506.23126", "authors": ["Suning Huang", "Qianzhong Chen", "Xiaohan Zhang", "Jiankai Sun", "Mac Schwager"], "title": "ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "3D world models (i.e., learning-based 3D dynamics models) offer a promising\napproach to generalizable robotic manipulation by capturing the underlying\nphysics of environment evolution conditioned on robot actions. However,\nexisting 3D world models are primarily limited to single-material dynamics\nusing a particle-based Graph Neural Network model, and often require\ntime-consuming 3D scene reconstruction to obtain 3D particle tracks for\ntraining. In this work, we present ParticleFormer, a Transformer-based point\ncloud world model trained with a hybrid point cloud reconstruction loss,\nsupervising both global and local dynamics features in multi-material,\nmulti-object robot interactions. ParticleFormer captures fine-grained\nmulti-object interactions between rigid, deformable, and flexible materials,\ntrained directly from real-world robot perception data without an elaborate\nscene reconstruction. We demonstrate the model's effectiveness both in 3D scene\nforecasting tasks, and in downstream manipulation tasks using a Model\nPredictive Control (MPC) policy. In addition, we extend existing dynamics\nlearning benchmarks to include diverse multi-material, multi-object interaction\nscenarios. We validate our method on six simulation and three real-world\nexperiments, where it consistently outperforms leading baselines by achieving\nsuperior dynamics prediction accuracy and less rollout error in downstream\nvisuomotor tasks. Experimental videos are available at\nhttps://particleformer.github.io/.", "AI": {"tldr": "ParticleFormer introduces a Transformer-based 3D world model to predict dynamics in multi-material, multi-object robotic interactions, outperforming leading baselines across scenarios.", "motivation": "To overcome limitations in existing 3D world models, such as single-material dynamics modeling and dependence on complex 3D scene reconstruction for training, thereby enabling better robotic manipulation in diverse environments.", "method": "Proposed ParticleFormer, a Transformer-based model trained with a hybrid point cloud reconstruction loss to capture both global and local dynamics features. It trains directly from real-world robot perception data without requiring elaborate scene reconstruction.", "result": "ParticleFormer achieves higher accuracy in dynamics prediction and reduced rollout error in visuomotor tasks, validated through six simulation and three real-world experiments.", "conclusion": "ParticleFormer offers a robust and efficient solution for modeling robotic dynamics in complex, multi-material scenarios, pushing forward state-of-the-art performance in manipulation tasks."}}
{"id": "2506.23168", "pdf": "https://arxiv.org/pdf/2506.23168", "abs": "https://arxiv.org/abs/2506.23168", "authors": ["Mohammad Abdulla", "Tobias Hille", "Dominik D\u00fcrrschnabel", "Gerd Stumme"], "title": "Rises for Measuring Local Distributivity in Lattices", "categories": ["cs.AI", "cs.DM", "math.CO", "math.RA", "06B99", "G.2.1"], "comment": "16 pages, 2 tables, 5 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "Distributivity is a well-established and extensively studied notion in\nlattice theory. In the context of data analysis, particularly within Formal\nConcept Analysis (FCA), lattices are often observed to exhibit a high degree of\ndistributivity. However, no standardized measure exists to quantify this\nproperty. In this paper, we introduce the notion of rises in (concept) lattices\nas a means to assess distributivity. Rises capture how the number of attributes\nor objects in covering concepts change within the concept lattice. We show that\na lattice is distributive if and only if no non-unit rises occur. Furthermore,\nwe relate rises to the classical notion of meet- and join distributivity. We\nobserve that concept lattices from real-world data are to a high degree\njoin-distributive, but much less meet-distributive. We additionally study how\njoin-distributivity manifests on the level of ordered sets.", "AI": {"tldr": "The paper introduces 'rises' as a metric to measure distributivity in lattices, focusing on their relevance in Formal Concept Analysis.", "motivation": "To address the lack of a standardized measure for quantifying distributivity in lattices, which is significant in data analysis and FCA.", "method": "Introduced the concept of 'rises' to evaluate changes in attributes or objects in concept lattices, and connected rises to classical distributivity concepts.", "result": "Demonstrated that distributivity correlates to the absence of non-unit rises, and highlighted that real-world concept lattices are often join-distributive but less meet-distributive.", "conclusion": "The paper contributes a significant metric for analyzing distributivity in concept lattices and links it to classical lattice theory, offering new insights into real-world data patterns."}}
{"id": "2506.22666", "pdf": "https://arxiv.org/pdf/2506.22666", "abs": "https://arxiv.org/abs/2506.22666", "authors": ["Anamika Lochab", "Lu Yan", "Patrick Pynadath", "Xiangyu Zhang", "Ruqi Zhang"], "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "The rise of API-only access to state-of-the-art LLMs highlights the need for\neffective black-box jailbreak methods to identify model vulnerabilities in\nreal-world settings. Without a principled objective for gradient-based\noptimization, most existing approaches rely on genetic algorithms, which are\nlimited by their initialization and dependence on manually curated prompt\npools. Furthermore, these methods require individual optimization for each\nprompt, failing to provide a comprehensive characterization of model\nvulnerabilities. To address this gap, we introduce VERA: Variational infErence\nfRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a\nvariational inference problem, training a small attacker LLM to approximate the\ntarget LLM's posterior over adversarial prompts. Once trained, the attacker can\ngenerate diverse, fluent jailbreak prompts for a target query without\nre-optimization. Experimental results show that VERA achieves strong\nperformance across a range of target LLMs, highlighting the value of\nprobabilistic inference for adversarial prompt generation.", "AI": {"tldr": "The paper proposes VERA, an attacker LLM framework for generating adversarial prompts to uncover vulnerabilities in black-box API-only large language models.", "motivation": "API-only access to leading LLMs necessitates effective methods for identifying model vulnerabilities, given the limitations of current jailbreaking strategies like genetic algorithms.", "method": "The paper introduces VERA, a variational inference-based framework which trains a small attacker LLM to approximate the target LLM's posterior and generate diverse jailbreak prompts without re-optimization.", "result": "VERA demonstrates strong performance across multiple state-of-the-art target LLMs, producing effective and diverse adversarial prompts.", "conclusion": "Probabilistic inference methods, like VERA, can efficiently and effectively characterize vulnerabilities in black-box LLMs, offering a robust alternative to previous techniques."}}
{"id": "2506.22655", "pdf": "https://arxiv.org/pdf/2506.22655", "abs": "https://arxiv.org/abs/2506.22655", "authors": ["Andrew F. Ilersich", "Prasanth B. Nair"], "title": "Learning Stochastic Multiscale Models", "categories": ["cs.LG"], "comment": "Body is 9 pages, 13 including acknowledgements and references, 35\n  including appendix. 21 figures and 6 tables. Submitted to NeurIPS 2025", "summary": "The physical sciences are replete with dynamical systems that require the\nresolution of a wide range of length and time scales. This presents significant\ncomputational challenges since direct numerical simulation requires\ndiscretization at the finest relevant scales, leading to a high-dimensional\nstate space. In this work, we propose an approach to learn stochastic\nmultiscale models in the form of stochastic differential equations directly\nfrom observational data. Our method resolves the state on a coarse mesh while\nintroducing an auxiliary state to capture the effects of unresolved scales. We\nlearn the parameters of the multiscale model using a modern forward-solver-free\namortized variational inference method. Our approach draws inspiration from\nphysics-based multiscale modeling approaches, such as large-eddy simulation in\nfluid dynamics, while learning directly from data. We present numerical studies\nto demonstrate that our learned multiscale models achieve superior predictive\naccuracy compared to direct numerical simulation and closure-type models at\nequivalent resolution.", "AI": {"tldr": "This paper introduces a method to learn stochastic multiscale models from observational data, combining techniques from physics and variational inference, to predict dynamical systems efficiently.", "motivation": "Dynamical systems in physical sciences often involve scales that are computationally expensive to resolve directly, motivating the need for efficient modeling methods that capture critical dynamics without full-resolution simulations.", "method": "The authors propose a framework to learn stochastic multiscale models using stochastic differential equations with auxiliary states on a coarse mesh and train them using amortized variational inference techniques.", "result": "Numerical studies show that the learned multiscale models outperform state-of-the-art methods, achieving superior predictive accuracy compared to both direct numerical simulations and closure models.", "conclusion": "The proposed method offers an efficient and accurate alternative for modeling multiscale dynamical systems, leveraging observational data and modern inference techniques to overcome computational challenges."}}
{"id": "2506.22556", "pdf": "https://arxiv.org/pdf/2506.22556", "abs": "https://arxiv.org/abs/2506.22556", "authors": ["Markus Juvonen", "Samuli Siltanen"], "title": "Recomposed realities: animating still images via patch clustering and randomness", "categories": ["cs.CV", "eess.IV"], "comment": "22 pages, 19 figures", "summary": "We present a patch-based image reconstruction and animation method that uses\nexisting image data to bring still images to life through motion. Image patches\nfrom curated datasets are grouped using k-means clustering and a new target\nimage is reconstructed by matching and randomly sampling from these clusters.\nThis approach emphasizes reinterpretation over replication, allowing the source\nand target domains to differ conceptually while sharing local structures.", "AI": {"tldr": "The paper introduces a method for achieving animation and reconstruction of still images using patch-based techniques.", "motivation": "The motivation is to develop a technique to animate still images by creatively leveraging existing image datasets.", "method": "The method involves clustering image patches with k-means, matching, and sampling from these clusters to reconstruct and animate a target image.", "result": "This approach allows for conceptual differences between source and target images while maintaining local structural similarities.", "conclusion": "The method succeeds in enabling reinterpretation of image data to create dynamic animations over mere replication of source data."}}
{"id": "2506.23906", "pdf": "https://arxiv.org/pdf/2506.23906", "abs": "https://arxiv.org/abs/2506.23906", "authors": ["Aleksandros Sobczyk", "Giuseppe Sorrentino", "Anastasios Zouzias"], "title": "Segmented Operations using Matrix Multiplications", "categories": ["cs.DS", "cs.CC", "cs.DC"], "comment": null, "summary": "Specialized computational units that perform small matrix multiplications as\nprimitive operations are typically present in modern accelerators. However,\nthese units are often underutilized for many fundamental operations besides\ndense matrix multiplications. The analysis of algorithms for such architectures\nis currently stagnated due to the lack of a rigorous theoretical model of\ncomputation that captures their characteristics. In this work, we propose\nMMV-RAM, a computational model tailored to matrix multiplication accelerators.\nMMV-RAM judiciously extends the Vector-RAM model with an additional processing\nunit that multiplies two matrices of sizes $n\\times s$ and $s\\times s$ in a\nsingle parallel step, where $s$ is a model parameter. We provide a detailed\ntheoretical analysis of the model, and carefully balance the computational\npower between the matrix and vector units, guided by the circuit complexity\nlower bound that parity is not in AC[0].\n  In MMV-RAM, we study algorithms for segmented scan and sum, two fundamental\nparallel primitives. We propose a segmented scan algorithm that uses matrix\nmultiplications to perform speculative block-scan computations, which runs in\n$O(\\log_s(n))$ steps. In contrast, we show that any algorithm that uses only\nthe vector unit of MMV-RAM requires\n$\\Omega\\left(\\frac{\\log_2(n)}{\\log_2\\log_2(n)}\\right)$ steps. We further apply\nthese techniques to obtain similar theoretical speedups for element-wise vector\nmultiplication and matrix multiplication. Beyond the worst-case complexity\nanalysis, we propose algorithms for segmented operations that could lead to\nhighly efficient and pragmatic implementations. For example, we observe that\nsegmented sum is a combination of three elementary parallel primitives: scan,\ncompress, and vector differentiation. As a case study, we implement...", "AI": {"tldr": "The paper introduces MMV-RAM, a computational model designed for matrix multiplication accelerators, addressing their underutilization beyond dense matrix multiplications.", "motivation": "The work aims to address the stagnation in algorithm analysis for matrix multiplication architectures due to the absence of suitable theoretical models.", "method": "The MMV-RAM computational model incorporates a specialized unit capable of performing matrix multiplications in a single parallel step, alongside a rigorous theoretical analysis and balanced computational power.", "result": "The study develops algorithms for segmented scan and sum, achieving significant theoretical speedups compared to vector-only approaches within MMV-RAM.", "conclusion": "MMV-RAM offers a theoretical foundation for optimizing computations on matrix multiplication accelerators, demonstrating both worst-case complexity improvements and practical potential for efficient implementation."}}
{"id": "2506.23749", "pdf": "https://arxiv.org/pdf/2506.23749", "abs": "https://arxiv.org/abs/2506.23749", "authors": ["Boyang Yang", "Zijian Cai", "Fengling Liu", "Bach Le", "Lingming Zhang", "Tegawend\u00e9 F. Bissyand\u00e9", "Yang Liu", "Haoye Tian"], "title": "A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications", "categories": ["cs.SE"], "comment": null, "summary": "Large language models (LLMs) are reshaping automated program repair (APR). We\ncategorize the recent 63 LLM-based APR systems published from January 2022 to\nJune 2025 into four paradigms, and show how retrieval- or analysis-augmented\ncontexts strengthen any of them. This taxonomy clarifies key trade-offs:\nfine-tuning delivers strong task alignment at high training cost; prompting\nenables rapid deployment but is limited by prompt design and context windows;\nprocedural pipelines offer reproducible control with moderate overhead; agentic\nframeworks tackle multi-hunk or cross-file bugs at the price of increased\nlatency and complexity. Persistent challenges include verifying semantic\ncorrectness beyond test suites, repairing repository-scale defects, and\nlowering the costs of LLMs. We outline research directions that combine\nlightweight human feedback, repository-aware retrieval, code analysis, and\ncost-aware planning to advance reliable and efficient LLM-based APR.", "AI": {"tldr": "The paper categorizes 63 recent LLM-based Automated Program Repair (APR) systems into four paradigms, explores their trade-offs, challenges, and proposes directions for improvement.", "motivation": "The motivation is to assess and classify advancements in LLM-based APR, highlighting key paradigms, challenges, and opportunities for improvement in scalability, efficiency, and reliability.", "method": "The authors survey 63 LLM-based APR systems and categorize them into four paradigms: fine-tuning, prompting, procedural pipelines, and agentic frameworks, analyzing their trade-offs and contexts.", "result": "The analysis reveals strengths and weaknesses of each paradigm, clarifying trade-offs such as task alignment vs. training cost and rapid deployment vs. design limitations. Persistent challenges like verifying semantic correctness are also discussed.", "conclusion": "Future research should focus on human feedback integration, repository-aware retrieval, enhanced code analysis, and cost-efficient approaches to make LLM-based APR more reliable and scalable."}}
{"id": "2506.22777", "pdf": "https://arxiv.org/pdf/2506.22777", "abs": "https://arxiv.org/abs/2506.22777", "authors": ["Miles Turpin", "Andy Arditi", "Marvin Li", "Joe Benton", "Julian Michael"], "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models trained with RL can engage in reward hacking--exploiting\nunintended strategies for high reward--without revealing this behavior in their\nchain-of-thought reasoning, making detection difficult and posing risks for\nhigh-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL\nintervention that trains models to explicitly acknowledge when they are\ninfluenced by prompt cues--hints which point to incorrect answers (e.g., \"a\nStanford professor thinks the answer is A\"). To evaluate VFT, we subsequently\ntrain models with RL on environments where held-out prompt cues signal which\nincorrect answers will receive high reward, incentivizing models to reward hack\nby exploiting cues instead of reasoning correctly. We measure how often models\nexploit these cues without verbalizing it. After RL, only 6% of the VFT-trained\nmodel's responses consist of undetected reward hacks. In comparison, when we\nperform RL without VFT, the rate of undetected reward hacks goes up to 88%;\nwith a debiasing baseline intervention, this increases further to 99%. VFT\nachieves this by substantially increasing how often models verbalize the\ninfluence of cues--from 8% to 42% after VFT, and up to 94% after RL--while\nbaselines remain low even after RL (10% and 1%). Our results show that teaching\nmodels to explicitly verbalize reward hacking behavior before RL significantly\nimproves their detection, offering a practical path toward more transparent and\nsafe AI systems.", "AI": {"tldr": "The paper introduces \"verbalization fine-tuning (VFT)\", a pre-reinforcement learning (RL) technique aimed at improving detection of reward hacking in language models by training them to openly verbalize when influenced by misleading cues.", "motivation": "Reward hacking by language models in RL settings is a concern, particularly because models may exploit unintended strategies for high rewards without making such behavior detectable in their reasoning.", "method": "The authors implemented VFT before RL to train models to acknowledge prompt-based cues that lead to incorrect answers. They later applied RL in environments designed to incentivize reward hacking behaviors and analyzed verbalization rates and undetected manipulation.", "result": "Models trained using VFT achieved a 6% rate of undetected reward hacks post-RL, compared to 88% for models without VFT and 99% with debiasing baseline interventions. VFT increased verbalizations of cues' influence from 8% pre-RL to 94% post-RL.", "conclusion": "VFT significantly improves the detection of reward hacking by teaching models to verbalize their behaviors transparently, enhancing the safety and transparency of AI systems."}}
{"id": "2506.23129", "pdf": "https://arxiv.org/pdf/2506.23129", "abs": "https://arxiv.org/abs/2506.23129", "authors": ["Hossein B. Jond", "Logan Beaver", "Martin Jirou\u0161ek", "Naiemeh Ahmadlou", "Veli Bak\u0131rc\u0131o\u011flu", "Martin Saska"], "title": "Flatness-based Finite-Horizon Multi-UAV Formation Trajectory Planning and Directionally Aware Collision Avoidance Tracking", "categories": ["cs.RO"], "comment": null, "summary": "Collision-free optimal formation control of unmanned aerial vehicle (UAV)\nteams is challenging. The state-of-the-art optimal control approaches often\nrely on numerical methods sensitive to initial guesses. This paper presents an\ninnovative collision-free finite-time formation control scheme for multiple\nUAVs leveraging the differential flatness of the UAV dynamics, eliminating the\nneed for numerical methods. We formulate a finite-time optimal control problem\nto plan a formation trajectory for feasible initial states. This formation\ntrajectory planning optimal control problem involves a collective performance\nindex to meet the formation requirements of achieving relative positions and\nvelocity consensus. It is solved by applying Pontryagin's principle.\nSubsequently, a collision-constrained regulating problem is addressed to ensure\ncollision-free tracking of the planned formation trajectory. The tracking\nproblem incorporates a directionally aware collision avoidance strategy that\nprioritizes avoiding UAVs in the forward path and relative approach. It assigns\nlower priority to those on the sides with an oblique relative approach and\ndisregards UAVs behind and not in the relative approach. The simulation results\nfor a four-UAV team (re)formation problem confirm the efficacy of the proposed\ncontrol scheme.", "AI": {"tldr": "This paper proposes a novel finite-time formation control scheme for UAV teams that eliminates reliance on numerical methods by leveraging differential flatness for collision-free optimal control.", "motivation": "Managing collision-free and optimal formation control for UAV teams is currently challenging due to reliance on sensitive numerical methods in existing approaches.", "method": "The proposed approach formulates a finite-time optimal control problem solved via Pontryagin's principle and incorporates a collision-avoidance strategy that prioritizes UAVs in forward paths while deprioritizing those with minimal collision risks.", "result": "Simulation tests on a four-UAV team (re)formation problem demonstrate the effectiveness of the proposed control framework.", "conclusion": "This framework provides an efficient and reliable solution for UAV trajectory formation and collision avoidance without using computationally sensitive numerical methods."}}
{"id": "2506.23273", "pdf": "https://arxiv.org/pdf/2506.23273", "abs": "https://arxiv.org/abs/2506.23273", "authors": ["Quang Hung Nguyen", "Phuong Anh Trinh", "Phan Quoc Hung Mai", "Tuan Phong Trinh"], "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Despite the advancements of large language models, text2sql still faces many\nchallenges, particularly with complex and domain-specific queries. In finance,\ndatabase designs and financial reporting layouts vary widely between financial\nentities and countries, making text2sql even more challenging. We present\nFinStat2SQL, a lightweight text2sql pipeline enabling natural language queries\nover financial statements. Tailored to local standards like VAS, it combines\nlarge and small language models in a multi-agent setup for entity extraction,\nSQL generation, and self-correction. We build a domain-specific database and\nevaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves\n61.33\\% accuracy with sub-4-second response times on consumer hardware,\noutperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient\nsolution for financial analysis, making AI-powered querying accessible to\nVietnamese enterprises.", "AI": {"tldr": "The paper introduces FinStat2SQL, a lightweight pipeline that leverages large and small language models for text-to-SQL query generation over financial statements, achieving accurate and fast results on consumer hardware.", "motivation": "Address the challenges of text2sql in complex and domain-specific queries, particularly in finance, due to diverse database designs and financial reporting standards.", "method": "Proposed a multi-agent setup combining large and small language models for tasks like entity extraction, SQL generation, and self-correction using a domain-specific database.", "result": "A fine-tuned 7B language model achieved 61.33% accuracy and sub-4-second response times, outperforming existing models like GPT-4o-mini.", "conclusion": "FinStat2SQL provides an accessible, cost-efficient solution for financial analysis, enabling Vietnamese enterprises to leverage AI-powered query systems effectively."}}
{"id": "2506.22562", "pdf": "https://arxiv.org/pdf/2506.22562", "abs": "https://arxiv.org/abs/2506.22562", "authors": ["Abhineet Singh", "Nilanjan Ray"], "title": "Improving Token-based Object Detection with Video", "categories": ["cs.CV"], "comment": "Under review for publication in IEEE Access", "summary": "This paper improves upon the Pix2Seq object detector by extending it for\nvideos. In the process, it introduces a new way to perform end-to-end video\nobject detection that improves upon existing video detectors in two key ways.\nFirst, by representing objects as variable-length sequences of discrete tokens,\nwe can succinctly represent widely varying numbers of video objects, with\ndiverse shapes and locations, without having to inject any localization cues in\nthe training process. This eliminates the need to sample the space of all\npossible boxes that constrains conventional detectors and thus solves the dual\nproblems of loss sparsity during training and heuristics-based postprocessing\nduring inference. Second, it conceptualizes and outputs the video objects as\nfully integrated and indivisible 3D boxes or tracklets instead of generating\nimage-specific 2D boxes and linking these boxes together to construct the video\nobject, as done in most conventional detectors. This allows it to scale\neffortlessly with available computational resources by simply increasing the\nlength of the video subsequence that the network takes as input, even\ngeneralizing to multi-object tracking if the subsequence can span the entire\nvideo. We compare our video detector with the baseline Pix2Seq static detector\non several datasets and demonstrate consistent improvement, although with\nstrong signs of being bottlenecked by our limited computational resources. We\nalso compare it with several video detectors on UA-DETRAC to show that it is\ncompetitive with the current state of the art even with the computational\nbottleneck. We make our code and models publicly available.", "AI": {"tldr": "This paper extends the Pix2Seq object detector to handle video sequences, offering a novel end-to-end solution for video object detection that outperforms current methods.", "motivation": "To address limitations in conventional video object detectors, such as the need for box sampling and heuristic-based post-processing, and to provide a scalable approach to video object detection.", "method": "The method represents video objects as variable-length sequences of discrete tokens and perceives them as indivisible 3D boxes or tracklets. This approach eliminates box sampling and enables scalable processing by increasing video subsequence length.", "result": "The proposed video detector consistently outperforms the baseline Pix2Seq static detector and demonstrates competitiveness with state-of-the-art video detectors, even under computational constraints.", "conclusion": "The paper introduces an improved framework for video object detection that addresses key limitations in existing methods and provides scalability, signifying a step forward in video analysis technology."}}
{"id": "2506.23762", "pdf": "https://arxiv.org/pdf/2506.23762", "abs": "https://arxiv.org/abs/2506.23762", "authors": ["Hongzhou Rao", "Yanjie Zhao", "Xinyi Hou", "Shenao Wang", "Haoyu Wang"], "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has redefined\nartificial intelligence (AI), pushing the boundaries of AI research and\nenabling unbounded possibilities for both academia and the industry. However,\nLLM development faces increasingly complex challenges throughout its lifecycle,\nyet no existing research systematically explores these challenges and solutions\nfrom the perspective of software engineering (SE) approaches. To fill the gap,\nwe systematically analyze research status throughout the LLM development\nlifecycle, divided into six phases: requirements engineering, dataset\nconstruction, model development and enhancement, testing and evaluation,\ndeployment and operations, and maintenance and evolution. We then conclude by\nidentifying the key challenges for each phase and presenting potential research\ndirections to address these challenges. In general, we provide valuable\ninsights from an SE perspective to facilitate future advances in LLM\ndevelopment.", "AI": {"tldr": "This paper systematically analyzes challenges in large language model (LLM) development using a software engineering (SE) perspective, identifying key challenges across six phases and proposing future research directions.", "motivation": "The motivation is to address gaps in understanding the challenges and solutions in LLM development throughout its lifecycle, especially from a SE perspective, for better academic and industrial advancements.", "method": "The authors analyze the LLM lifecycle through six phases: requirements engineering, dataset construction, model development and enhancement, testing and evaluation, deployment and operations, and maintenance and evolution. They identify challenges and suggest potential research directions for each phase.", "result": "The study highlights key challenges encountered in each phase of the LLM development lifecycle and provides future-oriented research directions to overcome these challenges.", "conclusion": "This research emphasizes the significance of a systematic SE perspective in LLM development, offering insights that can advance both research and practice in AI-driven systems."}}
{"id": "2506.22791", "pdf": "https://arxiv.org/pdf/2506.22791", "abs": "https://arxiv.org/abs/2506.22791", "authors": ["Jianxin Yan", "Wangze Ni", "Lei Chen", "Xuemin Lin", "Peng Cheng", "Zhan Qin", "Kui Ren"], "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Semantic caching significantly reduces computational costs and improves\nefficiency by storing and reusing large language model (LLM) responses.\nHowever, existing systems rely primarily on matching individual queries,\nlacking awareness of multi-turn dialogue contexts, which leads to incorrect\ncache hits when similar queries appear in different conversational settings.\nThis demonstration introduces ContextCache, a context-aware semantic caching\nsystem for multi-turn dialogues. ContextCache employs a two-stage retrieval\narchitecture that first executes vector-based retrieval on the current query to\nidentify potential matches and then integrates current and historical dialogue\nrepresentations through self-attention mechanisms for precise contextual\nmatching. Evaluation of real-world conversations shows that ContextCache\nimproves precision and recall compared to existing methods. Additionally,\ncached responses exhibit approximately 10 times lower latency than direct LLM\ninvocation, enabling significant computational cost reductions for LLM\nconversational applications.", "AI": {"tldr": "ContextCache is a semantic caching system that enhances response efficiency in multi-turn dialogues by incorporating context-aware techniques.", "motivation": "To address limitations of existing semantic caching systems that fail to consider multi-turn dialogue contexts, leading to incorrect cache hits.", "method": "Introduces a two-stage retrieval process using vector-based retrieval and self-attention mechanisms to match queries within their conversational context.", "result": "Evaluation shows improved precision and recall over current systems, and cached responses achieve 10x lower latency compared to direct LLM usage.", "conclusion": "ContextCache offers a more efficient solution for LLM conversational applications by reducing computational costs and improving cache accuracy through context awareness."}}
{"id": "2506.23152", "pdf": "https://arxiv.org/pdf/2506.23152", "abs": "https://arxiv.org/abs/2506.23152", "authors": ["Youzhuo Wang", "Jiayi Ye", "Chuyang Xiao", "Yiming Zhong", "Heng Tao", "Hang Yu", "Yumeng Liu", "Jingyi Yu", "Yuexin Ma"], "title": "DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover", "categories": ["cs.RO"], "comment": null, "summary": "Handover between a human and a dexterous robotic hand is a fundamental yet\nchallenging task in human-robot collaboration. It requires handling dynamic\nenvironments and a wide variety of objects and demands robust and adaptive\ngrasping strategies. However, progress in developing effective dynamic\ndexterous grasping methods is limited by the absence of high-quality,\nreal-world human-to-robot handover datasets. Existing datasets primarily focus\non grasping static objects or rely on synthesized handover motions, which\ndiffer significantly from real-world robot motion patterns, creating a\nsubstantial gap in applicability. In this paper, we introduce DexH2R, a\ncomprehensive real-world dataset for human-to-robot handovers, built on a\ndexterous robotic hand. Our dataset captures a diverse range of interactive\nobjects, dynamic motion patterns, rich visual sensor data, and detailed\nannotations. Additionally, to ensure natural and human-like dexterous motions,\nwe utilize teleoperation for data collection, enabling the robot's movements to\nalign with human behaviors and habits, which is a crucial characteristic for\nintelligent humanoid robots. Furthermore, we propose an effective solution,\nDynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art\napproaches, including auto-regressive models and diffusion policy methods,\nproviding a thorough comparison and analysis. We believe our benchmark will\ndrive advancements in human-to-robot handover research by offering a\nhigh-quality dataset, effective solutions, and comprehensive evaluation\nmetrics.", "AI": {"tldr": "This paper introduces DexH2R, a real-world dataset for human-to-robot handovers using a dexterous robotic hand, addressing the limitations of synthetic and static datasets.", "motivation": "The paper aims to tackle the challenge of effective dynamic dexterous grasping in human-robot collaboration, hindered by the lack of realistic human-to-robot handover datasets.", "method": "The authors developed the DexH2R dataset with teleoperation techniques for natural movement data and proposed DynamicGrasp for evaluating dynamic handovers, alongside a comparison of existing approaches.", "result": "The dataset includes diverse objects, natural dynamic motion data, rich sensors, and effective annotations, along with performance analysis of multiple state-of-the-art methods for dynamic handovers.", "conclusion": "This benchmark dataset and proposed solution are positioned to facilitate progress in human-robot handover research by providing realistic datasets and robust evaluation metrics."}}
{"id": "2506.23276", "pdf": "https://arxiv.org/pdf/2506.23276", "abs": "https://arxiv.org/abs/2506.23276", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Sch\u00f6lkopf", "Zhijing Jin"], "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed as autonomous\nagents, understanding their cooperation and social mechanisms is becoming\nincreasingly important. In particular, how LLMs balance self-interest and\ncollective well-being is a critical challenge for ensuring alignment,\nrobustness, and safe deployment. In this paper, we examine the challenge of\ncostly sanctioning in multi-agent LLM systems, where an agent must decide\nwhether to invest its own resources to incentivize cooperation or penalize\ndefection. To study this, we adapt a public goods game with institutional\nchoice from behavioral economics, allowing us to observe how different LLMs\nnavigate social dilemmas over repeated interactions. Our analysis reveals four\ndistinct behavioral patterns among models: some consistently establish and\nsustain high levels of cooperation, others fluctuate between engagement and\ndisengagement, some gradually decline in cooperative behavior over time, and\nothers rigidly follow fixed strategies regardless of outcomes. Surprisingly, we\nfind that reasoning LLMs, such as the o1 series, struggle significantly with\ncooperation, whereas some traditional LLMs consistently achieve high levels of\ncooperation. These findings suggest that the current approach to improving\nLLMs, which focuses on enhancing their reasoning capabilities, does not\nnecessarily lead to cooperation, providing valuable insights for deploying LLM\nagents in environments that require sustained collaboration. Our code is\navailable at https://github.com/davidguzmanp/SanctSim", "AI": {"tldr": "This paper studies how large language models manage cooperation and sanctions in multi-agent systems using a public goods game.", "motivation": "With LLMs increasingly acting as autonomous agents, understanding their balance between self-interest and collective welfare is crucial for safe and robust deployment.", "method": "The paper uses a public goods game with institutional choice to test how various LLMs behave in collaborative environments over repeated interactions.", "result": "Models exhibited diverse patterns: some ensured high cooperation, others fluctuated or declined in cooperation, while some adhered to fixed strategies. Traditional LLMs outperformed reasoning-focused LLMs in cooperation.", "conclusion": "Improved reasoning capabilities in LLMs do not guarantee better cooperation, underscoring the need for advanced strategies for sustained collaboration in multi-agent LLM systems."}}
{"id": "2506.22706", "pdf": "https://arxiv.org/pdf/2506.22706", "abs": "https://arxiv.org/abs/2506.22706", "authors": ["Arun Ramamurthy", "Neil Dhir"], "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers", "categories": ["cs.CR", "cs.AI", "cs.CV", "stat.ML"], "comment": null, "summary": "In the face of evolving cyber threats such as malware, ransomware and\nphishing, autonomous cybersecurity defense (ACD) systems have become essential\nfor real-time threat detection and response with optional human intervention.\nHowever, existing ACD systems rely on limiting assumptions, particularly the\nstationarity of the underlying network dynamics. In real-world scenarios,\nnetwork topologies can change due to actions taken by attackers or defenders,\nsystem failures, or time evolution of networks, leading to failures in the\nadaptive capabilities of current defense agents. Moreover, many agents are\ntrained on static environments, resulting in overfitting to specific\ntopologies, which hampers their ability to generalize to out-of-distribution\nnetwork topologies. This work addresses these challenges by exploring methods\nfor developing agents to learn generalizable policies across dynamic network\nenvironments -- general ACD (GACD).", "AI": {"tldr": "This paper investigates methods for creating generalizable autonomous cybersecurity defense systems that adapt to dynamic network changes.", "motivation": "Current ACD systems often fail because they rely on static or stationary network dynamics, limiting their adaptive capabilities in real-world scenarios with dynamic topologies.", "method": "The authors explore designing agents capable of learning policies that generalize across various dynamic network environments.", "result": "Findings suggest that agents trained to handle evolving network conditions can mitigate overfitting and improve generalization to unseen topologies.", "conclusion": "Developing general ACD systems enhances cybersecurity defense capabilities by enabling adaptive responses to intricate and evolving network threats."}}
{"id": "2506.22685", "pdf": "https://arxiv.org/pdf/2506.22685", "abs": "https://arxiv.org/abs/2506.22685", "authors": ["Anh Bui", "Trang Vu", "Trung Le", "Junae Kim", "Tamas Abraham", "Rollin Omari", "Amar Kaur", "Dinh Phung"], "title": "Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment", "categories": ["cs.LG", "cs.GR"], "comment": null, "summary": "In this paper, we investigate the semantic collapsing problem in generative\npersonalization, an under-explored topic where the learned visual concept\n($V^*$) gradually shifts from its original textual meaning and comes to\ndominate other concepts in multi-concept input prompts. This issue not only\nreduces the semantic richness of complex input prompts like \"a photo of $V^*$\nwearing glasses and playing guitar\" into simpler, less contextually rich forms\nsuch as \"a photo of $V^*$\" but also leads to simplified output images that fail\nto capture the intended concept.\n  We identify the root cause as unconstrained optimisation, which allows the\nlearned embedding $V^*$ to drift arbitrarily in the embedding space, both in\ndirection and magnitude. To address this, we propose a simple yet effective\ntraining-free method that adjusts the magnitude and direction of pre-trained\nembedding at inference time, effectively mitigating the semantic collapsing\nproblem. Our method is broadly applicable across different personalization\nmethods and demonstrates significant improvements in text-image alignment in\ndiverse use cases. Our code is anonymously published at\nhttps://anonymous.4open.science/r/Embedding-Adjustment.", "AI": {"tldr": "The paper addresses the semantic collapsing problem in generative personalization, presenting a training-free method to mitigate it and improve text-image alignment.", "motivation": "To address the semantic collapsing issue where learned concepts lose their intended richness and degrade the quality of multi-concept prompts in generative personalization.", "method": "Introduced a training-free, inference-time adjustment method for pre-trained embeddings, focusing on both magnitude and direction to mitigate semantic collapse.", "result": "Demonstrated significant improvements in preserving text-image semantic richness across diverse scenarios and personalization methods.", "conclusion": "The proposed approach effectively resolves semantic collapsing, is broadly applicable, and enhances generative model outputs by maintaining intended prompts' contextual complexity."}}
{"id": "2506.22567", "pdf": "https://arxiv.org/pdf/2506.22567", "abs": "https://arxiv.org/abs/2506.22567", "authors": ["Shansong Wang", "Zhecheng Jin", "Mingzhe Hu", "Mojtaba Safari", "Feng Zhao", "Chih-Wei Chang", "Richard LJ Qiu", "Justin Roper", "David S. Yu", "Xiaofeng Yang"], "title": "Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "CLIP models pretrained on natural images with billion-scale image-text pairs\nhave demonstrated impressive capabilities in zero-shot classification,\ncross-modal retrieval, and open-ended visual answering. However, transferring\nthis success to biomedicine is hindered by the scarcity of large-scale\nbiomedical image-text corpora, the heterogeneity of image modalities, and\nfragmented data standards across institutions. These limitations hinder the\ndevelopment of a unified and generalizable biomedical foundation model trained\nfrom scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical\nfoundation model developed via Multiple Medical CLIP Knowledge Distillation.\nRather than relying on billion-scale raw data, MMKD-CLIP distills knowledge\nfrom nine state-of-the-art domain-specific or generalist biomedical CLIP\nmodels, each pretrained on millions of biomedical image-text pairs. Our\ntwo-stage training pipeline first performs CLIP-style pretraining on over 2.9\nmillion biomedical image-text pairs from 26 image modalities, followed by\nfeature-level distillation using over 19.2 million feature pairs extracted from\nteacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,\nencompassing over 10.8 million biomedical images across nine image modalities.\nThe evaluation spans six core task types: zero-shot classification, linear\nprobing, cross-modal retrieval, visual question answering, survival prediction,\nand cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models\nwhile demonstrating remarkable robustness and generalization across image\ndomains and task settings. These results underscore that multi-teacher\nknowledge distillation is a scalable and effective paradigm for building\nhigh-performing biomedical foundation models under the practical constraints of\nreal-world data availability.", "AI": {"tldr": "MMKD-CLIP is a biomedical foundation model developed through multi-teacher knowledge distillation, using existing specialized models instead of large-scale raw data, and evaluated extensively across diverse tasks and datasets.", "motivation": "The need for a unified and generalizable biomedical foundation model is hindered by the lack of large-scale biomedical data, heterogeneous image modalities, and fragmented standards.", "method": "MMKD-CLIP uses a two-stage training process: (1) CLIP-style pretraining on over 2.9 million biomedical image-text pairs, and (2) feature-level distillation using 19.2 million feature pairs from teacher models.", "result": "MMKD-CLIP surpasses state-of-the-art teacher models across 58 datasets, demonstrating robustness and high generalization across diverse biomedical domains and tasks.", "conclusion": "Multi-teacher knowledge distillation is a practical and scalable method to develop effective biomedical foundation models despite real-world data scarcity."}}
{"id": "2506.23898", "pdf": "https://arxiv.org/pdf/2506.23898", "abs": "https://arxiv.org/abs/2506.23898", "authors": ["Diogo Lemos", "Ademar Aguiar", "Neil B. Harrison"], "title": "Requirements for Active Assistance of Natural Questions in Software Architecture", "categories": ["cs.SE"], "comment": null, "summary": "Natural questions are crucial to shaping key architectural decisions and\npreserving architectural knowledge. They arise organically during the\narchitectural design process, often resulting from the existing architectural\nexperience of the designer and the distinctive characteristics of the system\nbeing designed. However, natural questions are often mismanaged or ignored,\nwhich can lead to architectural drift, knowledge loss, inefficient resource\nuse, or poor understandability of the system's architecture. We aim to better\nunderstand the lifecycle of natural questions, its key requirements, challenges\nand difficulties, and then to envision an assisted environment to properly\nsupport it. The environment should be adaptable and responsive to real-world\nconstraints and uncertainties by seamlessly integrating knowledge management\ntools and artificial intelligence techniques into software development\nworkflows. Based on existing literature, a requirements workshop, and three\ndesign iterations, we proposed a lifecycle for natural questions and elicited\nessential functional and non-functional requirements for such an environment.\nAt last, the results of a survey conducted with experts helped to analyze and\nvalidate the elicited requirements and proposed features for the environment to\nenhance collaboration, decision-making, and the preservation of architectural\nknowledge more effectively than conventional methods.", "AI": {"tldr": "This study explores how natural questions affect architectural design and proposes an environment to manage them better using AI and knowledge tools.", "motivation": "To address the mismanagement or neglect of natural questions in architectural design, which leads to issues like knowledge loss and inefficient resource use.", "method": "Combined literature review, a requirements workshop, three design iterations, and expert surveys to study the lifecycle of natural questions and design an effective environment.", "result": "Proposed a lifecycle for natural questions, identified key requirements, and validated the design through expert feedback, ensuring improved architecture knowledge preservation and decision-making.", "conclusion": "Managing natural questions effectively with an adaptable, AI-integrated environment can significantly improve collaboration, decision-making, and knowledge retention in architecture."}}
{"id": "2506.22808", "pdf": "https://arxiv.org/pdf/2506.22808", "abs": "https://arxiv.org/abs/2506.22808", "authors": ["Jianhui Wei", "Zijie Meng", "Zikai Xiao", "Tianxiang Hu", "Yang Feng", "Zhijie Zhou", "Jian Wu", "Zuozhu Liu"], "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages", "summary": "While Medical Large Language Models (MedLLMs) have demonstrated remarkable\npotential in clinical tasks, their ethical safety remains insufficiently\nexplored. This paper introduces $\\textbf{MedEthicsQA}$, a comprehensive\nbenchmark comprising $\\textbf{5,623}$ multiple-choice questions and\n$\\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.\nWe systematically establish a hierarchical taxonomy integrating global medical\nethical standards. The benchmark encompasses widely used medical datasets,\nauthoritative question banks, and scenarios derived from PubMed literature.\nRigorous quality control involving multi-stage filtering and multi-faceted\nexpert validation ensures the reliability of the dataset with a low error rate\n($2.72\\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance\nin answering medical ethics questions compared to their foundation\ncounterparts, elucidating the deficiencies of medical ethics alignment. The\ndataset, registered under CC BY-NC 4.0 license, is available at\nhttps://github.com/JianhuiWei7/MedEthicsQA.", "AI": {"tldr": "This paper introduces MedEthicsQA, a benchmark for evaluating medical ethics in Medical Large Language Models (MedLLMs) using 5,623 multiple-choice and 5,351 open-ended questions.", "motivation": "To address the lack of adequate exploration into the ethical safety of Medical Large Language Models (MedLLMs).", "method": "Developed the MedEthicsQA benchmark based on a structured taxonomy, widely-used datasets, medical literature, and expert-validation processes.", "result": "The benchmark revealed that state-of-the-art MedLLMs struggle with medical ethics questions compared to their foundational counterparts.", "conclusion": "MedLLMs require better alignment with medical ethics, as evidenced by the dataset's findings."}}
{"id": "2506.23164", "pdf": "https://arxiv.org/pdf/2506.23164", "abs": "https://arxiv.org/abs/2506.23164", "authors": ["Maarten Hugenholtz", "Anna Meszaros", "Jens Kober", "Zlatan Ajanovic"], "title": "Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models", "categories": ["cs.RO", "cs.AI"], "comment": "12 pages, 8 figures, submitted to a journal", "summary": "Autonomous Vehicle decisions rely on multimodal prediction models that\naccount for multiple route options and the inherent uncertainty in human\nbehavior. However, models can suffer from mode collapse, where only the most\nlikely mode is predicted, posing significant safety risks. While existing\nmethods employ various strategies to generate diverse predictions, they often\noverlook the diversity in interaction modes among agents. Additionally,\ntraditional metrics for evaluating prediction models are dataset-dependent and\ndo not evaluate inter-agent interactions quantitatively. To our knowledge, none\nof the existing metrics explicitly evaluates mode collapse. In this paper, we\npropose a novel evaluation framework that assesses mode collapse in joint\ntrajectory predictions, focusing on safety-critical interactions. We introduce\nmetrics for mode collapse, mode correctness, and coverage, emphasizing the\nsequential dimension of predictions. By testing four multi-agent trajectory\nprediction models, we demonstrate that mode collapse indeed happens. When\nlooking at the sequential dimension, although prediction accuracy improves\ncloser to interaction events, there are still cases where the models are unable\nto predict the correct interaction mode, even just before the interaction mode\nbecomes inevitable. We hope that our framework can help researchers gain new\ninsights and advance the development of more consistent and accurate prediction\nmodels, thus enhancing the safety of autonomous driving systems.", "AI": {"tldr": "The paper addresses the issue of mode collapse in multimodal prediction models for autonomous vehicles by proposing a new evaluation framework with novel metrics.", "motivation": "The need to improve safety in autonomous vehicles by addressing mode collapse in multimodal prediction models, which poses risks due to inaccurate or narrow prediction of potential human interactions.", "method": "The authors propose a novel evaluation framework that introduces metrics for mode collapse, correctness, and coverage, analyzing the sequential dimension of multi-agent trajectory predictions.", "result": "Their analysis of four multi-agent trajectory prediction models reveals that mode collapse occurs, particularly in predicting the correct interaction mode just before these interactions become inevitable.", "conclusion": "The proposed framework and metrics provide a new tool to evaluate and improve the safety and accuracy of prediction models, advancing the goal of safer autonomous driving systems."}}
{"id": "2506.23306", "pdf": "https://arxiv.org/pdf/2506.23306", "abs": "https://arxiv.org/abs/2506.23306", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "title": "GATSim: Urban Mobility Simulation with Generative Agents", "categories": ["cs.AI"], "comment": null, "summary": "Traditional agent-based urban mobility simulations rely on rigid rule-based\nsystems that fail to capture the complexity, adaptability, and behavioral\ndiversity characteristic of human travel decision-making. Recent advances in\nlarge language models and AI agent technology offer opportunities to create\nagents with reasoning capabilities, persistent memory, and adaptive learning\nmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel\nframework that leverages these advances to create generative agents with rich\nbehavioral characteristics for urban mobility simulation. Unlike conventional\napproaches, GATSim agents possess diverse socioeconomic attributes, individual\nlifestyles, and evolving preferences that shape their mobility decisions\nthrough psychologically-informed memory systems, tool usage capabilities, and\nlifelong learning mechanisms. The main contributions of this study include: (1)\na comprehensive architecture combining an urban mobility foundation model with\nagent cognitive systems and transport simulation environment, (2) a fully\nfunctional prototype implementation, and (3) systematic validation\ndemonstrating that generative agents produce believable travel behaviors.\nThrough designed reflection processes, generative agents in this study can\ntransform specific travel experiences into generalized insights, enabling\nrealistic behavioral adaptation over time with specialized mechanisms for\nactivity planning and real-time reactive behaviors tailored to urban mobility\ncontexts. Experiments show that generative agents perform competitively with\nhuman annotators in mobility scenarios while naturally producing macroscopic\ntraffic evolution patterns. The code for the prototype system is shared at\nhttps://github.com/qiliuchn/gatsim.", "AI": {"tldr": "The paper introduces GATSim, a simulation framework for urban mobility using generative agents with realistic behavioral capabilities.", "motivation": "Traditional urban mobility simulations lack the adaptability and diversity in human behavioral modeling. Advances in AI and large language models provide tools to address this gap.", "method": "The method integrates an urban mobility foundation model with agent cognitive systems and a transport simulation environment, creating generative agents that evolve and adapt through learning mechanisms.", "result": "Generative agents demonstrated believable travel behaviors and matched human annotators in mobility scenarios while replicating real-world traffic evolution patterns.", "conclusion": "GATSim offers a novel way of simulating urban mobility with adaptive generative agents, providing more realistic and human-like transport simulation outcomes."}}
{"id": "2506.22712", "pdf": "https://arxiv.org/pdf/2506.22712", "abs": "https://arxiv.org/abs/2506.22712", "authors": ["Alexander Theus", "Alessandro Cabodi", "Sotiris Anagnostidis", "Antonio Orvieto", "Sidak Pal Singh", "Valentina Boeva"], "title": "Generalized Linear Mode Connectivity for Transformers", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Understanding the geometry of neural network loss landscapes is a central\nquestion in deep learning, with implications for generalization and\noptimization. A striking phenomenon is linear mode connectivity (LMC), where\nindependently trained models can be connected by low- or zero-loss paths,\ndespite appearing to lie in separate loss basins. However, this is often\nobscured by symmetries in parameter space -- such as neuron permutations --\nwhich make functionally equivalent models appear dissimilar. Prior work has\npredominantly focused on neuron re-ordering through permutations, but such\napproaches are limited in scope and fail to capture the richer symmetries\nexhibited by modern architectures such as Transformers. In this work, we\nintroduce a unified framework that captures four symmetry classes:\npermutations, semi-permutations, orthogonal transformations, and general\ninvertible maps -- broadening the set of valid reparameterizations and\nsubsuming many previous approaches as special cases. Crucially, this\ngeneralization enables, for the first time, the discovery of low- and\nzero-barrier linear interpolation paths between independently trained Vision\nTransformers and GPT-2 models. These results reveal deeper structure in the\nloss landscape and underscore the importance of symmetry-aware analysis for\nunderstanding model space geometry.", "AI": {"tldr": "The paper explores symmetry-aware methods to study neural network loss landscapes, enabling the discovery of linear paths between independently trained models like Vision Transformers and GPT-2.", "motivation": "Previous methods for analyzing geometry in neural network loss landscapes do not fully account for the broader symmetries beyond basic neuron permutations. Modern architectures like Transformers exhibit richer symmetries that need to be analyzed to understand model connectivity.", "method": "The framework introduces a unified analysis that encompasses four symmetry classes: permutations, semi-permutations, orthogonal transformations, and general invertible maps. This generalization extends prior techniques by capturing both basic and advanced symmetrical transformations.", "result": "Using this unified framework, the researchers demonstrated the existence of low- and zero-barrier linear paths connecting independently trained Vision Transformers and GPT-2 models, showcasing deeper geometrical structures.", "conclusion": "Analyzing neural network loss landscapes with symmetry-aware methods reveals richer structural insights, suggesting these approaches are critical for future studies in model generalization and optimization."}}
{"id": "2506.22696", "pdf": "https://arxiv.org/pdf/2506.22696", "abs": "https://arxiv.org/abs/2506.22696", "authors": ["Brian Mak", "Jeffrey Flanigan"], "title": "Residual Matrix Transformers: Scaling the Size of the Residual Stream", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ICML 2025", "summary": "The residual stream acts as a memory bus where transformer layers both store\nand access features (Elhage et al., 2021). We consider changing the mechanism\nfor retrieving and storing information in the residual stream, and replace the\nresidual stream of the transformer with an outer product memory matrix\n(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix\nTransformer (RMT). We find that the RMT enjoys a number of attractive\nproperties: 1) the size of the residual stream can be scaled independently of\ncompute and model size, improving performance, 2) the RMT can achieve the same\nloss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%\nfewer training tokens tokens, and 3) the RMT outperforms the transformer on\ndownstream evaluations. We theoretically analyze the transformer and the RMT,\nand show that the RMT allows for more efficient scaling of the residual stream,\nas well as improved variance propagation properties. Code for this project can\nbe found at https://github.com/bmac3/residual-matrix-transformer.", "AI": {"tldr": "The paper introduces the Residual Matrix Transformer (RMT), which replaces the residual stream in transformers with an outer product memory matrix to improve scalability and efficiency.", "motivation": "Transformers rely on the residual stream to store and retrieve information, but this mechanism could be optimized for better computational efficiency and scaling.", "method": "The residual stream is replaced by an outer product memory matrix, allowing for adjustable scalability of the model's memory bus without changing compute or model size.", "result": "The RMT reduces the computational cost (58% fewer FLOPS, 25% fewer parameters, 41% fewer training tokens) while maintaining or outperforming transformers in loss and downstream evaluations.", "conclusion": "The RMT provides a more efficient and scalable alternative to traditional transformers, enabling better performance and reduced resource usage."}}
{"id": "2506.22570", "pdf": "https://arxiv.org/pdf/2506.22570", "abs": "https://arxiv.org/abs/2506.22570", "authors": ["Chee Mei Ling", "Thangarajah Akilan", "Aparna Ravinda Phalke"], "title": "Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation", "categories": ["cs.CV"], "comment": "17 pages, 7 figures, 6 tables", "summary": "Agricultural image semantic segmentation is a pivotal component of modern\nagriculture, facilitating accurate visual data analysis to improve crop\nmanagement, optimize resource utilization, and boost overall productivity. This\nstudy proposes an efficient image segmentation method for precision\nagriculture, focusing on accurately delineating farmland anomalies to support\ninformed decision-making and proactive interventions. A novel Dual Atrous\nSeparable Convolution (DAS Conv) module is integrated within the\nDeepLabV3-based segmentation framework. The DAS Conv module is meticulously\ndesigned to achieve an optimal balance between dilation rates and padding size,\nthereby enhancing model performance without compromising efficiency. The study\nalso incorporates a strategic skip connection from an optimal stage in the\nencoder to the decoder to bolster the model's capacity to capture fine-grained\nspatial features. Despite its lower computational complexity, the proposed\nmodel outperforms its baseline and achieves performance comparable to highly\ncomplex transformer-based state-of-the-art (SOTA) models on the Agriculture\nVision benchmark dataset. It achieves more than 66% improvement in efficiency\nwhen considering the trade-off between model complexity and performance,\ncompared to the SOTA model. This study highlights an efficient and effective\nsolution for improving semantic segmentation in remote sensing applications,\noffering a computationally lightweight model capable of high-quality\nperformance in agricultural imagery.", "AI": {"tldr": "The paper presents an efficient agricultural semantic segmentation model using a novel DAS Conv module and strategic skip connections, outperforming baselines and showing comparable results to complex SOTA models.", "motivation": "Improve accuracy and efficiency in agricultural image segmentation to aid crop management and resource optimization.", "method": "Integration of Dual Atrous Separable (DAS) Convolution into DeepLabV3 framework with skip connections for enhanced spatial feature capture.", "result": "The proposed model achieves comparable performance to SOTA transformer-based models while being computationally efficient, with a 66% improvement in complexity-performance trade-off.", "conclusion": "The model offers an efficient, lightweight solution for remote sensing applications in agriculture, improving semantic segmentation quality and performance."}}
{"id": "2506.23967", "pdf": "https://arxiv.org/pdf/2506.23967", "abs": "https://arxiv.org/abs/2506.23967", "authors": ["Geerd-Dietger Hoffmann", "Verena Majuntke"], "title": "Green Metrics Tool: Measuring for fun and profit", "categories": ["cs.SE", "cs.CY", "cs.ET"], "comment": null, "summary": "The environmental impact of software is gaining increasing attention as the\ndemand for computational resources continues to rise. In order to optimize\nsoftware resource consumption and reduce carbon emissions, measuring and\nevaluating software is a first essential step. In this paper we discuss what\nmetrics are important for fact base decision making. We introduce the Green\nMetrics Tool (GMT), a novel framework for accurately measuring the resource\nconsumption of software. The tool provides a containerized, controlled, and\nreproducible life cycle-based approach, assessing the resource use of software\nduring key phases. Finally, we discuss GMT features like visualization,\ncomparability and rule- and LLM-based optimisations highlighting its potential\nto guide developers and researchers in reducing the environmental impact of\ntheir software.", "AI": {"tldr": "The paper introduces the Green Metrics Tool (GMT) for evaluating and optimizing the environmental impact of software by measuring its resource consumption effectively.", "motivation": "The increasing demand for computational resources necessitates the evaluation of software resource consumption to optimize usage and reduce carbon emissions.", "method": "The authors propose a framework called the Green Metrics Tool (GMT) that uses a containerized, controlled, reproducible, life cycle-based approach to measure resource consumption during key software phases.", "result": "GMT features include visualization, comparability, and rule- and LLM-based optimizations, demonstrating the tool's capabilities in providing actionable insights.", "conclusion": "The GMT has the potential to assist developers and researchers in minimizing the environmental footprint of their software through better understanding and optimization of resource usage."}}
{"id": "2506.22813", "pdf": "https://arxiv.org/pdf/2506.22813", "abs": "https://arxiv.org/abs/2506.22813", "authors": ["Zhuojun Ding", "Wei Wei", "Chenghao Fan"], "title": "Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Supervised fine-tuning (SFT) is widely used to align large language models\n(LLMs) with information extraction (IE) tasks, such as named entity recognition\n(NER). However, annotating such fine-grained labels and training\ndomain-specific models is costly. Existing works typically train a unified\nmodel across multiple domains, but such approaches lack adaptation and\nscalability since not all training data benefits target domains and scaling\ntrained models remains challenging. We propose the SaM framework, which\ndynamically Selects and Merges expert models at inference time. Specifically,\nfor a target domain, we select domain-specific experts pre-trained on existing\ndomains based on (i) domain similarity to the target domain and (ii)\nperformance on sampled instances, respectively. The experts are then merged to\ncreate task-specific models optimized for the target domain. By dynamically\nmerging experts beneficial to target domains, we improve generalization across\nvarious domains without extra training. Additionally, experts can be added or\nremoved conveniently, leading to great scalability. Extensive experiments on\nmultiple benchmarks demonstrate our framework's effectiveness, which\noutperforms the unified model by an average of 10%. We further provide insights\ninto potential improvements, practical experience, and extensions of our\nframework.", "AI": {"tldr": "The paper introduces the SaM framework, which dynamically selects and merges expert models for better domain adaptation and scalability in information extraction tasks without extra training.", "motivation": "Current practices for aligning large language models (LLMs) with information extraction (IE) tasks have limitations such as high annotation cost, lack of domain adaptability, and scalability challenges.", "method": "The proposed SaM framework selects expert models based on domain similarity and sampled performance, then merges these experts at inference time to create task-specific models for target domains.", "result": "The framework outperforms unified models on multiple benchmarks, achieving an average improvement of 10%, and demonstrates scalability as experts can be added or removed dynamically.", "conclusion": "SaM enhances generalization across domains, provides practical scalability, and presents opportunities for further refinement and real-world application in IE tasks."}}
{"id": "2506.23316", "pdf": "https://arxiv.org/pdf/2506.23316", "abs": "https://arxiv.org/abs/2506.23316", "authors": ["Zhenghao Peng", "Yuxin Liu", "Bolei Zhou"], "title": "InfGen: Scenario Generation as Next Token Group Prediction", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Realistic and interactive traffic simulation is essential for training and\nevaluating autonomous driving systems. However, most existing data-driven\nsimulation methods rely on static initialization or log-replay data, limiting\ntheir ability to model dynamic, long-horizon scenarios with evolving agent\npopulations. We propose InfGen, a scenario generation framework that outputs\nagent states and trajectories in an autoregressive manner. InfGen represents\nthe entire scene as a sequence of tokens, including traffic light signals,\nagent states, and motion vectors, and uses a transformer model to simulate\ntraffic over time. This design enables InfGen to continuously insert new agents\ninto traffic, supporting infinite scene generation. Experiments demonstrate\nthat InfGen produces realistic, diverse, and adaptive traffic behaviors.\nFurthermore, reinforcement learning policies trained in InfGen-generated\nscenarios achieve superior robustness and generalization, validating its\nutility as a high-fidelity simulation environment for autonomous driving. More\ninformation is available at https://metadriverse.github.io/infgen/.", "AI": {"tldr": "The paper introduces InfGen, a framework for generating realistic and adaptable traffic scenarios in an autoregressive manner using transformer models for training autonomous driving systems.", "motivation": "Existing traffic simulation methods have limitations in modeling dynamic, long-horizon, evolving-agent scenarios, prompting a need for more interactive and realistic approaches.", "method": "InfGen models traffic using a sequence-to-sequence token representation and a transformer-based architecture, allowing real-time insertion of agents and infinite generation of agent states and trajectories.", "result": "InfGen creates diverse and adaptive traffic behaviors, improving the robustness and generalization of reinforcement learning policies trained in its simulated scenarios.", "conclusion": "InfGen is validated as a high-fidelity simulation environment for autonomous driving, with superior capabilities over traditional static or log-replay methods."}}
{"id": "2506.23464", "pdf": "https://arxiv.org/pdf/2506.23464", "abs": "https://arxiv.org/abs/2506.23464", "authors": ["Sahil Tripathi", "Md Tabrez Nafis", "Imran Hussain", "Jiechao Gao"], "title": "The Confidence Paradox: Can LLM Know When It's Wrong", "categories": ["cs.AI"], "comment": null, "summary": "Document Visual Question Answering (DocVQA) systems are increasingly deployed\nin real world applications, yet they remain ethically opaque-often producing\noverconfident answers to ambiguous questions or failing to communicate\nuncertainty in a trustworthy manner. This misalignment between model confidence\nand actual knowledge poses significant risks, particularly in domains requiring\nethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT\nhave advanced SOTA performance by focusing on architectural sophistication and\naccuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised\nhonesty calibration framework for ethically aligned DocVQA. Our model-agnostic\nmethod quantifies uncertainty to identify knowledge gaps, aligns model\nconfidence with actual correctness using weighted loss functions, and enforces\nethical response behavior via contrastive learning. We further introduce two\nprincipled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence\nIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethical\ncommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%\nand F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces\noverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In\ncross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,\ndemonstrating strong generalization. Ablation shows a 3.8% drop in accuracy\nwithout alignment or contrastive loss.", "AI": {"tldr": "The paper introduces HonestVQA, a framework addressing ethical challenges in Document Visual Question Answering (DocVQA) systems by aligning model confidence with correctness and introducing metrics for evaluation.", "motivation": "Ethical concerns in DocVQA systems arise due to overconfidence and lack of uncertainty communication, especially in critical domains. Existing models prioritize accuracy but neglect ethical responsiveness.", "method": "HonestVQA employs a self-supervised setup with weighted loss functions to align confidence and correctness, and uses contrastive learning to enforce ethical response behavior. Metrics like H-Score and ECI assess ethical alignment.", "result": "HonestVQA improved accuracy by 4.3% and F1 by 4.3%, reduced overconfidence, and achieved notable performance in cross-domain evaluations. Ablation shows alignment/contrastive loss critical for performance.", "conclusion": "HonestVQA bridges accuracy and ethical alignment gaps in DocVQA systems, showcasing improved performance and ethical responsiveness through uncertainty calibration and principled metrics."}}
{"id": "2506.22732", "pdf": "https://arxiv.org/pdf/2506.22732", "abs": "https://arxiv.org/abs/2506.22732", "authors": ["Hao Shu", "Jicheng Li", "Tianyv Lei", "Lijun Sun"], "title": "Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": null, "summary": "In real-world scenarios, spatiotemporal traffic data frequently experiences\ndual degradation from missing values and noise caused by sensor malfunctions\nand communication failures. Therefore, effective data recovery methods are\nessential to ensure the reliability of downstream data-driven applications.\nwhile classical tensor completion methods have been widely adopted, they are\nincapable of modeling noise, making them unsuitable for complex scenarios\ninvolving simultaneous data missingness and noise interference. Existing Robust\nTensor Completion (RTC) approaches offer potential solutions by separately\nmodeling the actual tensor data and noise. However, their effectiveness is\noften constrained by the over-relaxation of convex rank surrogates and the\nsuboptimal utilization of local consistency, leading to inadequate model\naccuracy. To address these limitations, we first introduce the tensor L1-L2\nnorm, a novel non-convex tensor rank surrogate that functions as an effective\nlow-rank representation tool. Leveraging an advanced feature fusion strategy,\nwe further develop the gradient tensor L1-L2 norm by incorporating the tensor\nL1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear\nL1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via\nGradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully\nexploits both global low-rankness and local consistency without trade-off\nparameter, but also effectively handles the dual degradation challenges of\nmissing data and noise in traffic data. Extensive experiments conducted on\nmultiple real-world traffic datasets demonstrate that the RTC-GTNLN model\nconsistently outperforms existing state-of-the-art methods in complex recovery\nscenarios involving simultaneous missing values and noise.", "AI": {"tldr": "The paper addresses the challenge of recovering degraded spatiotemporal traffic data, proposing a novel model for simultaneous handling of missing values and noise.", "motivation": "Sensor malfunctions and communication failures degrade spatiotemporal traffic data through missing values and noise, necessitating effective recovery methods for reliable data applications.", "method": "The authors introduce the non-convex tensor L1-L2 norm and develop the Robust Tensor Completion via Gradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, leveraging global low-rankness and local consistency without trade-off parameters.", "result": "Experiments on real-world traffic datasets reveal that RTC-GTNLN consistently outperforms state-of-the-art methods in scenarios with dual degradation challenges.", "conclusion": "RTC-GTNLN provides an effective solution for recovering degraded traffic datasets, enhancing data-driven applications by addressing the challenges of missingness and noise."}}
{"id": "2506.22708", "pdf": "https://arxiv.org/pdf/2506.22708", "abs": "https://arxiv.org/abs/2506.22708", "authors": ["Shrenik Jadhav", "Birva Sevak", "Srijita Das", "Akhtar Hussain", "Wencong Su", "Van-Hai Bui"], "title": "FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets", "categories": ["cs.LG", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "comment": null, "summary": "Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for\ndecentralized market regulation, yet existing approaches often lack robust\nframeworks to ensure fairness. This paper presents FairMarket-RL, a novel\nhybrid framework that combines Large Language Models (LLMs) with Reinforcement\nLearning (RL) to enable fairness-aware trading agents. In a simulated P2P\nmicrogrid with multiple sellers and buyers, the LLM acts as a real-time\nfairness critic, evaluating each trading episode using two metrics:\nFairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness\nscores are integrated into agent rewards through scheduled\n{\\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that\nreplaces brittle, rule-based fairness constraints. Agents are trained using\nIndependent Proximal Policy Optimization (IPPO) and achieve equitable outcomes,\nfulfilling over 90% of buyer demand, maintaining fair seller margins, and\nconsistently reaching FTB and FBS scores above 0.80. The training process\ndemonstrates that fairness feedback improves convergence, reduces buyer\nshortfalls, and narrows profit disparities between sellers. With its\nlanguage-based critic, the framework scales naturally, and its extension to a\nlarge power distribution system with household prosumers illustrates its\npractical applicability. FairMarket-RL thus offers a scalable, equity-driven\nsolution for autonomous trading in decentralized energy systems.", "AI": {"tldr": "FairMarket-RL integrates Large Language Models (LLMs) with Reinforcement Learning (RL) to enhance fairness in decentralized peer-to-peer trading systems.", "motivation": "Current P2P trading mechanisms lack robust frameworks to ensure fairness among sellers and buyers.", "method": "The framework utilizes LLMs as fairness critics and combines them with RL-based training, incorporating fairness metrics into agent rewards through adaptive coefficients.", "result": "FairMarket-RL achieves equitable trading outcomes with fairness scores exceeding 0.80, and effectively fulfills buyer demands while maintaining fair seller profits.", "conclusion": "FairMarket-RL provides a scalable and fairness-aware solution for decentralized energy trading systems, demonstrating practical applicability in larger scenarios."}}
{"id": "2506.22589", "pdf": "https://arxiv.org/pdf/2506.22589", "abs": "https://arxiv.org/abs/2506.22589", "authors": ["Yijun Lin", "Rhett Olson", "Junhan Wu", "Yao-Yi Chiang", "Jerod Weinman"], "title": "LIGHT: Multi-Modal Text Linking on Historical Maps", "categories": ["cs.CV"], "comment": "Accepted at ICDAR2025", "summary": "Text on historical maps provides valuable information for studies in history,\neconomics, geography, and other related fields. Unlike structured or\nsemi-structured documents, text on maps varies significantly in orientation,\nreading order, shape, and placement. Many modern methods can detect and\ntranscribe text regions, but they struggle to effectively ``link'' the\nrecognized text fragments, e.g., determining a multi-word place name. Existing\nlayout analysis methods model word relationships to improve text understanding\nin structured documents, but they primarily rely on linguistic features and\nneglect geometric information, which is essential for handling map text. To\naddress these challenges, we propose LIGHT, a novel multi-modal approach that\nintegrates linguistic, image, and geometric features for linking text on\nhistorical maps. In particular, LIGHT includes a geometry-aware embedding\nmodule that encodes the polygonal coordinates of text regions to capture\npolygon shapes and their relative spatial positions on an image. LIGHT unifies\nthis geometric information with the visual and linguistic token embeddings from\nLayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal\ninformation to predict the reading-order successor of each text instance\ndirectly with a bi-directional learning strategy that enhances sequence\nrobustness. Experimental results show that LIGHT outperforms existing methods\non the ICDAR 2024/2025 MapText Competition data, demonstrating the\neffectiveness of multi-modal learning for historical map text linking.", "AI": {"tldr": "The paper introduces LIGHT, a multi-modal approach to link fragmented text on historical maps by integrating linguistic, image, and geometric features, outperforming existing methods.", "motivation": "To address the challenges of linking fragmented text on historical maps where geometric information is crucial and existing methods primarily focus on linguistic features, neglecting spatial relationships.", "method": "The authors developed LIGHT, which integrates linguistic, image, and geometry-aware embedding features using a pretrained layout analysis model (LayoutLMv3). The approach uses a bi-directional learning strategy for enhanced sequence robustness.", "result": "LIGHT outperformed existing techniques on the ICDAR 2024/2025 MapText Competition data, proving its efficacy in historical map text linking.", "conclusion": "The study highlights the benefits of multi-modal approaches and geometry-aware embeddings in tackling the complex problem of linking text on historical maps."}}
{"id": "2506.23995", "pdf": "https://arxiv.org/pdf/2506.23995", "abs": "https://arxiv.org/abs/2506.23995", "authors": ["Mingfei Cheng", "Renzhi Wang", "Xiaofei Xie", "Yuan Zhou", "Lei Ma"], "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems", "categories": ["cs.SE", "cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous Driving System (ADS) testing is essential to ensure the safety and\nreliability of autonomous vehicles (AVs) before deployment. However, existing\ntechniques primarily focus on evaluating ADS functionalities in single-AV\nsettings. As ADSs are increasingly deployed in multi-AV traffic, it becomes\ncrucial to assess their cooperative performance, particularly regarding\ndeadlocks, a fundamental coordination failure in which multiple AVs enter a\ncircular waiting state indefinitely, resulting in motion planning failures.\nDespite its importance, the cooperative capability of ADSs to prevent deadlocks\nremains insufficiently underexplored. To address this gap, we propose the first\ndedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,\nSTCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs\ncontrolled by the ADS under test are in a circular wait state. STCLocker\nconsists of three key components: Deadlock Oracle, Conflict Feedback, and\nConflict-aware Scenario Generation. Deadlock Oracle provides a reliable\nblack-box mechanism for detecting deadlock cycles among multiple AVs within a\ngiven scenario. Conflict Feedback and Conflict-aware Scenario Generation\ncollaborate to actively guide AVs into simultaneous competition over spatial\nconflict resources (i.e., shared passing regions) and temporal competitive\nbehaviors (i.e., reaching the conflict region at the same time), thereby\nincreasing the effectiveness of generating conflict-prone deadlocks. We\nevaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,\na module-based ADS supporting cooperative communication. Experimental results\nshow that, on average, STCLocker generates more DLS than the best-performing\nbaseline.", "AI": {"tldr": "This paper introduces STCLocker, a testing technique aimed at generating deadlock scenarios in multi-autonomous-vehicle settings, surpassing existing methods.", "motivation": "The paper seeks to address the gap in testing multi-AV systems for deadlock conditions, a critical coordination failure inadequately explored by existing ADS testing techniques.", "method": "STCLocker employs Deadlock Oracle to detect deadlocks, and uses Conflict Feedback alongside Conflict-aware Scenario Generation to guide AVs into spatio-temporal conflicts for testing purposes.", "result": "STCLocker outperformed the best-existing baseline in generating Deadlock Scenarios across tests on two different ADSs, Roach and OpenCDA.", "conclusion": "STCLocker presents a robust solution for testing the cooperative performance of multi-AV systems, enhancing the reliability of ADSs in deadlock-prone scenarios."}}
{"id": "2506.22846", "pdf": "https://arxiv.org/pdf/2506.22846", "abs": "https://arxiv.org/abs/2506.22846", "authors": ["Duygu Altinok"], "title": "Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "This is the accepted version of an article accepted to the TSD 2025\n  conference, published in Springer Lecture Notes in Artificial Intelligence\n  (LNAI). The final authenticated version is available online at SpringerLink", "summary": "End-to-end (E2E) automatic speech recognition (ASR) systems have\nrevolutionized the field by integrating all components into a single neural\nnetwork, with attention-based encoder-decoder models achieving state-of-the-art\nperformance. However, their autoregressive decoding process limits inference\nspeed, making them unsuitable for real-time applications. In contrast,\nCTC-based models offer faster, non-autoregressive decoding but struggle to\nmodel linguistic dependencies effectively. Addressing this challenge, we\npropose a novel auxiliary loss framework called Language-Aware Intermediate\nLoss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large\nlanguage models (LLMs). By attaching connector layers to intermediate encoder\nlayers, LAIL maps outputs to the embedding space of an LLM and computes a\ncausal language modeling loss during training. This approach enhances\nlinguistic modeling while preserving the computational efficiency of CTC\ndecoding. Using the Conformer architecture and various LLaMA models, we\ndemonstrate significant improvements in Word Error Rate (WER) on the\nLibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance\nfor CTC-based ASR with minimal computational overhead.", "AI": {"tldr": "E2E ASR systems perform well but lack real-time capabilities due to autoregressive decoding; the proposed LAIL framework enhances CTC-based ASR systems using linguistic knowledge from LLMs with minimal computational overhead.", "motivation": "The motivation is to bridge the gap between computational efficiency and linguistic modeling in CTC-based ASR systems by leveraging the linguistic insights of large language models.", "method": "A Language-Aware Intermediate Loss (LAIL) framework integrates linguistic modeling into CTC-based ASR. Connector layers map intermediate encoder outputs to LLM embedding spaces, and a causal language modeling loss is applied during training.", "result": "The LAIL framework demonstrates substantial improvements in Word Error Rate (WER) on benchmark datasets like LibriSpeech, TEDLIUM2, and WSJ, achieving state-of-the-art performance for CTC-based ASR.", "conclusion": "LAIL successfully enhances the linguistic capabilities of CTC-based ASR systems while maintaining their computational efficiency, making them more suitable for real-time applications."}}
{"id": "2506.23326", "pdf": "https://arxiv.org/pdf/2506.23326", "abs": "https://arxiv.org/abs/2506.23326", "authors": ["Sang-Yoep Lee", "Leonardo Zamora Yanez", "Jacob Rogatinsky", "Vi T. Vo", "Tanvi Shingade", "Tommaso Ranzani"], "title": "Simplifying Data-Driven Modeling of the Volume-Flow-Pressure Relationship in Hydraulic Soft Robotic Actuators", "categories": ["cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Soft robotic systems are known for their flexibility and adaptability, but\ntraditional physics-based models struggle to capture their complex, nonlinear\nbehaviors. This study explores a data-driven approach to modeling the\nvolume-flow-pressure relationship in hydraulic soft actuators, focusing on\nlow-complexity models with high accuracy. We perform regression analysis on a\nstacked balloon actuator system using exponential, polynomial, and neural\nnetwork models with or without autoregressive inputs. The results demonstrate\nthat simpler models, particularly multivariate polynomials, effectively predict\npressure dynamics with fewer parameters. This research offers a practical\nsolution for real-time soft robotics applications, balancing model complexity\nand computational efficiency. Moreover, the approach may benefit various\ntechniques that require explicit analytical models.", "AI": {"tldr": "This study uses data-driven approaches with exponential, polynomial, and neural network models to predict the pressure dynamics in hydraulic soft actuators, highlighting the effectiveness of simpler multivariate polynomial models.", "motivation": "Physics-based models struggle to capture the nonlinear dynamics of soft robotic systems, necessitating exploration of efficient data-driven approaches for modeling pressure-flow relationships.", "method": "Regression analyses were performed on a stacked balloon actuator system using exponential, polynomial, and neural network models with and without autoregressive inputs.", "result": "Multivariate polynomials were found to be particularly effective, providing accurate predictions with fewer parameters compared to complex models.", "conclusion": "The study offers a low-complexity, high-accuracy modeling solution suitable for real-time applications in soft robotics, with broader benefits for techniques requiring explicit analytical models."}}
{"id": "2506.23503", "pdf": "https://arxiv.org/pdf/2506.23503", "abs": "https://arxiv.org/abs/2506.23503", "authors": ["Bosubabu Sambana", "Kondreddygari Archana", "Suram Indhra Sena Reddy", "Shaik Meethaigar Jameer Basha", "Shaik Karishma"], "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence", "categories": ["cs.AI"], "comment": "6 Pages, 5 Figures, IEEE IDCIoT 2025", "summary": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the\nirrational thought patterns associated with mental health disorders, but its\neffectiveness relies on accurately identifying cognitive pathways to provide\ntargeted treatment. In today's digital age, individuals often express negative\nemotions on social media, where they may reveal cognitive distortions, and in\nsevere cases, exhibit suicidal tendencies. However, there is a significant gap\nin methodologies designed to analyze these cognitive pathways, which could be\ncritical for psychotherapists aiming to deliver timely and effective\ninterventions in online environments. Cognitive Behavioral Therapy (CBT)\nframework leveraging acceptance, commitment and data augmentation to categorize\nand address both textual and visual content as positive or negative.\nSpecifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,\nPEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages\nfocusing on detecting negative emotions and cognitive distortions within social\nmedia data. While existing models are primarily designed to identify negative\nthoughts, the proposed system goes beyond this by predicting additional\nnegative side effects and other potential mental health disorders likes\nPhobias, Eating Disorders. This enhancement allows for a more comprehensive\nunderstanding and intervention strategy, offering psychotherapists a powerful\ntool for early detection and treatment of various psychological issues.", "AI": {"tldr": "The paper proposes a system using advanced NLP models to identify and analyze cognitive distortions and negative emotions in social media content for mental health monitoring.", "motivation": "The motivation for this research stems from a gap in methodologies that accurately analyze cognitive pathways for delivering timely mental health interventions in online environments.", "method": "The method involves using NLP models like BERT, RoBERTa for sentiment analysis, T5, PEGASUS for summarization, and mT5 for multilingual translation to classify digital content while focusing on detecting cognitive distortions.", "result": "The system advances beyond existing models to also predict additional negative mental health outcomes, such as phobias and eating disorders, thus providing a more comprehensive mental health analysis.", "conclusion": "This proposed system equips psychotherapists with a robust tool for early detection and intervention of psychological disorders based on social media behavior."}}
{"id": "2506.22591", "pdf": "https://arxiv.org/pdf/2506.22591", "abs": "https://arxiv.org/abs/2506.22591", "authors": ["Arunkumar Kannan", "Martin A. Lindquist", "Brian Caffo"], "title": "BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data", "categories": ["cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Recent advances in deep learning have made it possible to predict phenotypic\nmeasures directly from functional magnetic resonance imaging (fMRI) brain\nvolumes, sparking significant interest in the neuroimaging community. However,\nexisting approaches, primarily based on convolutional neural networks or\ntransformer architectures, often struggle to model the complex relationships\ninherent in fMRI data, limited by their inability to capture long-range spatial\nand temporal dependencies. To overcome these shortcomings, we introduce\nBrainMT, a novel hybrid framework designed to efficiently learn and integrate\nlong-range spatiotemporal attributes in fMRI data. Our framework operates in\ntwo stages: (1) a bidirectional Mamba block with a temporal-first scanning\nmechanism to capture global temporal interactions in a computationally\nefficient manner; and (2) a transformer block leveraging self-attention to\nmodel global spatial relationships across the deep features processed by the\nMamba block. Extensive experiments on two large-scale public datasets,\nUKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves\nstate-of-the-art performance on both classification (sex prediction) and\nregression (cognitive intelligence prediction) tasks, outperforming existing\nmethods by a significant margin. Our code and implementation details will be\nmade publicly available at this\nhttps://github.com/arunkumar-kannan/BrainMT-fMRI", "AI": {"tldr": "The paper introduces BrainMT, a hybrid deep learning framework for predicting phenotypic measures from fMRI data.", "motivation": "Standard deep learning models struggle to capture the long-range spatial and temporal dependencies in fMRI data, hindering predictive performance.", "method": "A two-stage hybrid framework: (1) the Mamba block for capturing global temporal interactions and (2) a transformer block for modeling spatial relationships using self-attention.", "result": "BrainMT achieves state-of-the-art results on classification and regression tasks across two large-scale datasets, UKBioBank and Human Connectome Project.", "conclusion": "BrainMT significantly advances the prediction of phenotypic measures from fMRI data, demonstrating superior performance over existing methods."}}
{"id": "2506.24015", "pdf": "https://arxiv.org/pdf/2506.24015", "abs": "https://arxiv.org/abs/2506.24015", "authors": ["Ramtin Ehsani", "Esteban Parra", "Sonia Haiduc", "Preetha Chatterjee"], "title": "Bug Fixing with Broader Context: Enhancing LLM-Based Program Repair via Layered Knowledge Injection", "categories": ["cs.SE"], "comment": null, "summary": "Prompting LLMs with bug-related context (e.g., error messages, stack traces)\nimproves automated program repair, but many bugs still remain unresolved. In\nreal-world projects, developers often rely on broader repository and\nproject-level context beyond the local code to resolve such bugs. In this\npaper, we investigate how automatically extracting and providing such knowledge\ncan improve LLM-based program repair. We propose a layered knowledge injection\nframework that incrementally augments LLMs with structured context. It starts\nwith the Bug Knowledge Layer, which includes information such as the buggy\nfunction and failing tests; expands to the Repository Knowledge Layer, which\nadds structural dependencies, related files, and commit history; and finally\ninjects the Project Knowledge Layer, which incorporates relevant details from\ndocumentation and previously fixed bugs. We evaluate this framework on a\ndataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini),\nand analyze fix rates across six bug types. By progressively injecting\nknowledge across layers, our approach achieves a fix rate of 79% (250/314)\nusing Llama 3.3, a significant improvement of 23% over previous work. All bug\ntypes show improvement with the addition of repository-level context, while\nonly a subset benefit further from project-level knowledge, highlighting that\ndifferent bug types require different levels of contextual information for\neffective repair. We also analyze the remaining unresolved bugs and find that\nmore complex and structurally isolated bugs, such as Program Anomaly and GUI\nbugs, remain difficult even after injecting all available information. Our\nresults show that layered context injection improves program repair and suggest\nthe need for interactive and adaptive APR systems.", "AI": {"tldr": "The paper proposes a framework for improving automated program repair (APR) by incrementally injecting structured bug, repository, and project knowledge into large language models (LLMs), leading to a 79% bug fix rate on a BugsInPy dataset and revealing the effectiveness of varying levels of context for different bug types.", "motivation": "Existing automated program repair methods often fail to resolve many bugs because they lack broader repository and project-level context typically used by developers in real-world scenarios.", "method": "The authors propose a three-layered knowledge injection framework for LLMs. The first layer (Bug Knowledge Layer) includes local bug-specific information, the second layer (Repository Knowledge Layer) adds structural dependencies and related files, and the third layer (Project Knowledge Layer) incorporates broader project-level insights like documentation and past bug fixes.", "result": "Using the framework on 314 bugs in the BugsInPy dataset, Llama 3.3 achieved a 79% fix rate, a 23% improvement over existing methods. Improvements were evident across all bug types with repository knowledge, while only some types benefited from additional project-level information.", "conclusion": "Layered injection of structured knowledge significantly improves automated program repair performance. However, issues like complex and isolated bugs remain a challenge, indicating a need for adaptive and interactive APR systems in the future."}}
{"id": "2506.22852", "pdf": "https://arxiv.org/pdf/2506.22852", "abs": "https://arxiv.org/abs/2506.22852", "authors": ["Yucheng Cai", "Yuxuan Wu", "Yi Huang", "Junlan Feng", "Zhijian Ou"], "title": "Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have recently been applied to dialog systems.\nDespite making progress, LLMs are prone to errors in knowledge-intensive\nscenarios. Recently, approaches based on retrieval augmented generation (RAG)\nand agent have emerged to improve the factual accuracy by enhancing the LLMs\nwith knowledge retrieved from external knowledge bases (KBs). This is mostly\nimplemented by prompting the LLMs with instructions, examples and the retrieved\nknowledge. However, LLMs may have difficulty using the retrieved knowledge\neffectively for response generation, because they are not well trained to do\nsuch generation for specific domains. To mitigate this problem, we propose to\nfinetune the LLMs in the RAG-based and agent-based systems with domain-specific\ndata, together with domain-specific external knowledge, which is called\nknowledge augmented finetuning (KAFT). We base our study on the MobileCS2\ndataset, a real-life customer service dialog dataset that features intensive\nknowledge interactions, to systematically compare the prompting and KAFT\ntechniques in the RAG-based and agent-based systems. Experiment results show\nthat KAFT substantially surpasses prompting in both RAG and agent systems,\nparticularly in terms of factual accuracy. To the best of our knowledge, this\npaper represents the first solid empirical work to investigate the KAFT idea.", "AI": {"tldr": "The paper introduces Knowledge Augmented Fine-Tuning (KAFT) to improve factual accuracy in large language model (LLM)-based dialog systems by fine-tuning them with domain-specific data and knowledge, outperforming traditional prompting methods.", "motivation": "LLMs in dialog systems struggle with factual accuracy in knowledge-intensive contexts due to challenges in effectively utilizing external knowledge bases (KBs) for specific domains.", "method": "The researchers proposed KAFT, a method that fine-tunes LLMs with domain-specific datasets and external knowledge within retrieval-augmented generation (RAG) and agent-based frameworks. The MobileCS2 customer service dataset was utilized for evaluation.", "result": "KAFT significantly surpassed traditional prompting methods in both RAG- and agent-based systems, with notable improvements in factual accuracy.", "conclusion": "KAFT offers a promising approach to enhance LLM performance in domain-specific dialog systems and sets a new benchmark for the integration of fine-tuning with external knowledge."}}
{"id": "2506.23333", "pdf": "https://arxiv.org/pdf/2506.23333", "abs": "https://arxiv.org/abs/2506.23333", "authors": ["Javier Garcia", "Jonas Friemel", "Ramin Kosfeld", "Michael Yannuzzi", "Peter Kramer", "Christian Rieck", "Christian Scheffer", "Arne Schmidt", "Harm Kube", "Dan Biediger", "S\u00e1ndor P. Fekete", "Aaron T. Becker"], "title": "Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks", "categories": ["cs.RO", "cs.CG", "cs.DS"], "comment": "8 pages, 12 figures. To appear in the proceedings of the 2025 IEEE\n  21st International Conference on Automation Science and Engineering (CASE\n  2025)", "summary": "We implement and evaluate different methods for the reconfiguration of a\nconnected arrangement of tiles into a desired target shape, using a single\nactive robot that can move along the tile structure. This robot can pick up,\ncarry, or drop off one tile at a time, but it must maintain a single connected\nconfiguration at all times.\n  Becker et al. (CCCG 2025) recently proposed an algorithm that uses histograms\nas canonical intermediate configurations, guaranteeing performance within a\nconstant factor of the optimal solution if the start and target configuration\nare well-separated. We implement and evaluate this algorithm, both in a\nsimulated and practical setting, using an inchworm type robot to compare it\nwith two existing heuristic algorithms.", "AI": {"tldr": "This paper evaluates methods for reconfiguring connected tile shapes using a single robot, implementing a recent algorithm and comparing it with existing heuristics.", "motivation": "To optimize and evaluate methods for reconfiguration of tile structures using a single robot in scenarios requiring connectivity and efficiency.", "method": "The authors implemented the histogram-based algorithm proposed by Becker et al. (CCCG 2025) along with two heuristic algorithms, tested in both simulated and real-world settings using an inchworm-type robot.", "result": "The work provides a comparative analysis of the histogram-based algorithm against heuristic approaches, showcasing its performance in simulation and practical scenarios.", "conclusion": "Reconfiguration performance can be improved using the histogram-based algorithm, especially under constraints of maintaining connectivity and well-separated start/target configurations."}}
{"id": "2506.23504", "pdf": "https://arxiv.org/pdf/2506.23504", "abs": "https://arxiv.org/abs/2506.23504", "authors": ["Bosubabu Sambana", "Kotamsetty Geethika Devi", "Bandi Rajeswara Reddy", "Galeti Mohammad Hussain", "Gownivalla Siddartha"], "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM", "categories": ["cs.AI"], "comment": "6 Pages, 7 Figures", "summary": "The recent development of advanced machine learning methods for hybrid models\nhas greatly addressed the need for the correct prediction of electrical prices.\nThis method combines AlexNet and LSTM algorithms, which are used to introduce a\nnew model with higher accuracy in price forecasting. Despite RNN and ANN being\neffective, they often fail to deal with forex time sequence data. The\ntraditional methods do not accurately forecast the prices. These traditional\nmethods only focus on demand and price which leads to insufficient analysis of\ndata. To address this issue, using the hybrid approach, which focuses on\nexternal variables that also effect the predicted prices. Nevertheless, due to\nAlexNet's excellent feature extraction and LSTM's learning sequential patterns,\nthe prediction accuracy is vastly increased. The model is built on the past\ndata, which has been supplied with the most significant elements like demand,\ntemperature, sunlight, and rain. For example, the model applies methods, such\nas minimum-maximum scaling and a time window, to predict the electricity prices\nof the future. The results show that this hybrid model is good than the\nstandalone ones in terms of accuracy. Although we got our accuracy rating of\n97.08, it shows higher accompaniments than remaining models RNN and ANN with\naccuracies of 96.64 and 96.63 respectively.", "AI": {"tldr": "A hybrid model combining AlexNet and LSTM achieves improved accuracy in forecasting electricity prices compared to traditional and standalone models like RNN and ANN.", "motivation": "The motivation is to address the limitations of traditional methods and standalone machine learning models in accurately forecasting electricity prices, especially considering important external variables.", "method": "The authors propose a hybrid approach combining AlexNet for feature extraction and LSTM for sequential pattern learning. They incorporate external variables such as demand, temperature, sunlight, and rain into the model.", "result": "The hybrid model achieved an accuracy rating of 97.08%, outperforming standalone models like RNN (96.64%) and ANN (96.63%) in terms of prediction accuracy.", "conclusion": "Using a hybrid model improves accuracy in electricity price forecasting, demonstrating the effectiveness of combining AlexNet and LSTM while focusing on external influencing factors."}}
{"id": "2506.22754", "pdf": "https://arxiv.org/pdf/2506.22754", "abs": "https://arxiv.org/abs/2506.22754", "authors": ["Satarupa Bhattacharjee", "Bing Li", "Xiao Wu", "Lingzhou Xue"], "title": "Doubly robust estimation of causal effects for random object outcomes with continuous treatments", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.AP", "stat.ML", "stat.TH"], "comment": "30 pages, 5 figures", "summary": "Causal inference is central to statistics and scientific discovery, enabling\nresearchers to identify cause-and-effect relationships beyond associations.\nWhile traditionally studied within Euclidean spaces, contemporary applications\nincreasingly involve complex, non-Euclidean data structures that reside in\nabstract metric spaces, known as random objects, such as images, shapes,\nnetworks, and distributions. This paper introduces a novel framework for causal\ninference with continuous treatments applied to non-Euclidean data. To address\nthe challenges posed by the lack of linear structures, we leverage Hilbert\nspace embeddings of the metric spaces to facilitate Fr\\'echet mean estimation\nand causal effect mapping. Motivated by a study on the impact of exposure to\nfine particulate matter on age-at-death distributions across U.S. counties, we\npropose a nonparametric, doubly-debiased causal inference approach for outcomes\nas random objects with continuous treatments. Our framework can accommodate\nmoderately high-dimensional vector-valued confounders and derive efficient\ninfluence functions for estimation to ensure both robustness and\ninterpretability. We establish rigorous asymptotic properties of the\ncross-fitted estimators and employ conformal inference techniques for\ncounterfactual outcome prediction. Validated through numerical experiments and\napplied to real-world environmental data, our framework extends causal\ninference methodologies to complex data structures, broadening its\napplicability across scientific disciplines.", "AI": {"tldr": "The paper develops a causal inference framework for non-Euclidean data using Hilbert space embeddings, addressing continuous treatments and demonstrating its applications in environmental studies.", "motivation": "The motivation stems from the increasing presence of complex, non-Euclidean data in modern applications and the need for a robust causal inference framework to analyze such data.", "method": "The authors propose using Hilbert space embeddings to estimate Fr\u00e9chet means and map causal effects, complemented by a nonparametric, doubly-debiased approach with cross-fitted estimators and conformal inference techniques.", "result": "The framework demonstrates strong asymptotic properties, robustness, and interpretability, validated through numerical experiments and a study on particulate matter exposure's impact on age-at-death distributions across U.S. counties.", "conclusion": "The work extends traditional causal inference methods to handle abstract metric spaces and complex data, enhancing its relevance for a wide range of scientific applications."}}
{"id": "2506.22716", "pdf": "https://arxiv.org/pdf/2506.22716", "abs": "https://arxiv.org/abs/2506.22716", "authors": ["Dujian Ding", "Ankur Mallick", "Shaokun Zhang", "Chi Wang", "Daniel Madrigal", "Mirian Del Carmen Hipolito Garcia", "Menglin Xia", "Laks V. S. Lakshmanan", "Qingyun Wu", "Victor R\u00fchle"], "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DB"], "comment": "Accepted to ICML 2025 (main conference)", "summary": "Large language models (LLMs) are powerful tools but are often expensive to\ndeploy at scale. LLM query routing mitigates this by dynamically assigning\nqueries to models of varying cost and quality to obtain a desired trade-off.\nPrior query routing approaches generate only one response from the selected\nmodel and a single response from a small (inexpensive) model was often not good\nenough to beat a response from a large (expensive) model due to which they end\nup overusing the large model and missing out on potential cost savings.\nHowever, it is well known that for small models, generating multiple responses\nand selecting the best can enhance quality while remaining cheaper than a\nsingle large-model response. We leverage this idea to propose BEST-Route, a\nnovel routing framework that chooses a model and the number of responses to\nsample from it based on query difficulty and the quality thresholds.\nExperiments on real-world datasets demonstrate that our method reduces costs by\nup to 60% with less than 1% performance drop.", "AI": {"tldr": "The paper introduces BEST-Route, a routing framework that strategically balances cost and quality in large language model (LLM) deployments, reducing costs significantly with minimal performance loss.", "motivation": "Deploying LLMs at scale is expensive, and prior query routing methods fail to effectively balance cost by overusing large models. Small models can provide competitive outputs when generating multiple responses, offering untapped opportunities for cost savings.", "method": "BEST-Route dynamically routes queries based on difficulty and predefined quality thresholds while leveraging multiple response sampling from small models to enhance output quality at a lower cost.", "result": "BEST-Route reduces costs by up to 60% with less than 1% drop in performance, as demonstrated in experiments on real-world datasets.", "conclusion": "BEST-Route efficiently achieves a cost-quality trade-off, demonstrating its potential to optimize LLM deployment by integrating multi-response sampling into the routing process."}}
{"id": "2506.22624", "pdf": "https://arxiv.org/pdf/2506.22624", "abs": "https://arxiv.org/abs/2506.22624", "authors": ["Zuyao You", "Zuxuan Wu"], "title": "Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "We present Seg-R1, a preliminary exploration of using reinforcement learning\n(RL) to enhance the pixel-level understanding and reasoning capabilities of\nlarge multimodal models (LMMs). Starting with foreground segmentation tasks,\nspecifically camouflaged object detection (COD) and salient object detection\n(SOD), our approach enables the LMM to generate point and bounding box prompts\nin the next-token fashion, which are then used to guide SAM2 in producing\nsegmentation masks. We introduce Group Relative Policy Optimization (GRPO) into\nthe segmentation domain, equipping the LMM with pixel-level comprehension\nthrough a carefully designed training strategy. Notably, Seg-R1 achieves\nremarkable performance with purely RL-based training, achieving .873 S-measure\non COD10K without complex model modification. Moreover, we found that pure RL\ntraining demonstrates strong open-world generalization. Despite being trained\nsolely on foreground segmentation image-mask pairs without text supervision,\nSeg-R1 achieves impressive zero-shot performance on referring segmentation and\nreasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on\nReasonSeg test, outperforming models fully supervised on these datasets.", "AI": {"tldr": "Seg-R1 introduces reinforcement learning techniques to enhance pixel-level reasoning and segmentation tasks for large multimodal models.", "motivation": "Improve the pixel-level understanding of multimodal models like SAM2 in segmentation tasks using RL.", "method": "Seg-R1 utilizes a reinforcement learning strategy called Group Relative Policy Optimization (GRPO) to guide multimodal models in generating prompts for segmentation output.", "result": "Seg-R1 achieves competitive metrics like .873 S-measure on COD10K and strong zero-shot performances on tasks such as referring segmentation (71.4 cIoU on RefCOCOg) and reasoning segmentation (56.7 gIoU on ReasonSeg).", "conclusion": "RL training significantly improves segmentation performance and generalization ability without requiring extensive supervision or model modification."}}
{"id": "2506.22954", "pdf": "https://arxiv.org/pdf/2506.22954", "abs": "https://arxiv.org/abs/2506.22954", "authors": ["Minnan Wei", "Ziming Li", "Xiang Chen", "Menglin Zheng", "Ziyan Qu", "Cheng Yu", "Siyu Chen", "Xiaolin Ju"], "title": "Evaluating and Improving Large Language Models for Competitive Program Generation", "categories": ["cs.SI", "cs.SE"], "comment": null, "summary": "Context: Due to the demand for strong algorithmic reasoning, complex logic\nimplementation, and strict adherence to input/output formats and resource\nconstraints, competitive programming generation by large language models (LLMs)\nis considered the most challenging problem in current LLM-based code\ngeneration. However, previous studies often evaluate LLMs using simple prompts\nand benchmark datasets prone to data leakage. Moreover, prior work has limited\nconsideration of the diversity in algorithm types and difficulty levels.\nObjective: In this study, we aim to evaluate and improve LLMs in solving\nreal-world competitive programming problems. Methods: We initially collect 117\nproblems from nine regional ICPC/CCPC contests held in 2024 and design four\nfiltering criteria to construct a curated benchmark consisting of 80 problems.\nLeveraging DeepSeek-R1 as the LLM, we evaluate its competitive program\ngeneration capabilities through the online judge (OJ) platforms, guided by a\ncarefully designed basic prompt. For incorrect submissions, we construct a\nfine-grained error taxonomy and then propose a targeted improvement framework\nby combining a multi-turn dialogue-based repair phase and an\ninformation-augmented regeneration phase. Results: Experimental results show\nthat only 5 out of 80 problems are fully accepted when using basic prompts. For\nthe unsolved problems, we construct the error taxonomy, including general\nerrors (such as design, boundary, condition, data type, syntax, and\ninput/output errors) and specialized errors (such as those in mathematical\nproblems, greedy algorithms, and graph theories). After applying our proposed\nimprovement strategies, we substantially increased the number of correct\nsolutions, with 46 out of 80 problems successfully accepted.", "AI": {"tldr": "The study evaluates and enhances large language models (LLMs) for competitive programming problems, utilizing a curated benchmark and error-correction strategies for improved problem-solving success.", "motivation": "Previous LLM evaluation for competitive programming used simplistic prompts and datasets vulnerable to data leakage, with limited focus on algorithm variety and difficulty.", "method": "Researchers collected 117 real-world competitive programming problems from ICPC/CCPC contests, filtered them to 80, and tested LLM DeepSeek-R1 with basic prompts via OJ platforms. They then applied a two-phase improvement approach: multi-turn error repair and information-augmented regeneration.", "result": "With basic prompts, only 5 problems were solved correctly. Error categorization identified general and specialized errors. By applying improvement strategies, the acceptance rate increased to 46 out of 80 problems.", "conclusion": "The study demonstrates that targeted improvement frameworks, including dialogue-based repair and regeneration phases, significantly enhance LLM performance in solving competitive programming challenges."}}
{"id": "2506.22853", "pdf": "https://arxiv.org/pdf/2506.22853", "abs": "https://arxiv.org/abs/2506.22853", "authors": ["Kyochul Jang", "Donghyeon Lee", "Kyusik Kim", "Dongseok Heo", "Taewhoo Lee", "Woojeong Kim", "Bongwon Suh"], "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, ACL 2025 Vienna", "summary": "Existing function-calling benchmarks focus on single-turn interactions.\nHowever, they overlook the complexity of real-world scenarios. To quantify how\nexisting benchmarks address practical applications, we introduce DICE-SCORE, a\nmetric that evaluates the dispersion of tool-related information such as\nfunction name and parameter values throughout the dialogue. Analyzing existing\nbenchmarks through DICE-SCORE reveals notably low scores, highlighting the need\nfor more realistic scenarios. To address this gap, we present DICE-BENCH, a\nframework that constructs practical function-calling datasets by synthesizing\nconversations through a tool graph that maintains dependencies across rounds\nand a multi-agent system with distinct personas to enhance dialogue\nnaturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our\nexperiments on 19 LLMs with DICE-BENCH show that significant advances are still\nrequired before such models can be deployed effectively in real-world settings.\nOur code and data are all publicly available:\nhttps://snuhcc.github.io/DICE-Bench/.", "AI": {"tldr": "This paper introduces DICE-SCORE to evaluate realistic multi-turn tool-based interactions and presents DICE-BENCH, a benchmark to simulate practical scenarios in such tasks.", "motivation": "Existing function-calling benchmarks focus only on single-turn interactions and fail to handle the complexity of real-world, multi-turn, tool-related scenarios.", "method": "They proposed DICE-SCORE to measure the dispersion of tool-related information and developed DICE-BENCH, a framework for practical dataset synthesis using tool graphs and multi-agent dialogues.", "result": "The authors created a dataset of 1,607 high-DICE-SCORE interactions and found that 19 tested LLMs perform poorly on realistic function-calling tasks, indicating the need for improvements.", "conclusion": "This study highlights the limitations of current benchmarks and models, emphasizes the value of realistic datasets like DICE-BENCH, and encourages advancements for practical deployments."}}
{"id": "2506.23346", "pdf": "https://arxiv.org/pdf/2506.23346", "abs": "https://arxiv.org/abs/2506.23346", "authors": ["Hao Wang", "Armand Jordana", "Ludovic Righetti", "Somil Bansal"], "title": "Safe and Performant Deployment of Autonomous Systems via Model Predictive Control and Hamilton-Jacobi Reachability Analysis", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "RSS 2025 Workshop on Reliable Robotics", "summary": "While we have made significant algorithmic developments to enable autonomous\nsystems to perform sophisticated tasks, it remains difficult for them to\nperform tasks effective and safely. Most existing approaches either fail to\nprovide any safety assurances or substantially compromise task performance for\nsafety. In this work, we develop a framework, based on model predictive control\n(MPC) and Hamilton-Jacobi (HJ) reachability, to optimize task performance for\nautonomous systems while respecting the safety constraints. Our framework\nguarantees recursive feasibility for the MPC controller, and it is scalable to\nhigh-dimensional systems. We demonstrate the effectiveness of our framework\nwith two simulation studies using a 4D Dubins Car and a 6 Dof Kuka iiwa\nmanipulator, and the experiments show that our framework significantly improves\nthe safety constraints satisfaction of the systems over the baselines.", "AI": {"tldr": "This paper introduces a framework combining model predictive control (MPC) and Hamilton-Jacobi (HJ) reachability to optimize autonomous systems' task performance while adhering to safety constraints, demonstrating effectiveness in simulations.", "motivation": "The challenge lies in achieving both task performance and safety for autonomous systems, as existing methods often fail to balance these aspects.", "method": "The paper employs a hybrid framework combining MPC for task optimization and HJ reachability for safety assurance, ensuring recursive feasibility and scalability for high-dimensional systems.", "result": "Simulation tests using a 4D Dubins Car and a 6 Degree of Freedom (Dof) Kuka iiwa manipulator showed substantial improvements in safety constraint satisfaction compared to baseline approaches.", "conclusion": "The proposed framework successfully balances task optimization and safety adherence for autonomous systems, offering scalability and enhanced safety performance in simulations."}}
{"id": "2506.23517", "pdf": "https://arxiv.org/pdf/2506.23517", "abs": "https://arxiv.org/abs/2506.23517", "authors": ["Selin Dik", "Osman Erdem", "Mehmet Dik"], "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "AI": {"tldr": "The study evaluates GPTZero's ability to detect AI-generated versus human-written essays, finding it effective for AI text but prone to false positives for human-authored content.", "motivation": "With the widespread use of AI tools by students, reliable detection methods are needed to distinguish AI-generated text from human-written text.", "method": "Researchers analyzed 28 AI-generated and 50 human-written essays of varying lengths, using GPTZero to assess AI confidence and generation percentage.", "result": "GPTZero successfully identified most AI-generated essays with high accuracy (91-100%), but struggled with human-written essays, resulting in false positives.", "conclusion": "While GPTZero effectively detects AI-generated text, its limitations in accurately identifying human-authored content warrant caution in its use by educators."}}
{"id": "2506.22851", "pdf": "https://arxiv.org/pdf/2506.22851", "abs": "https://arxiv.org/abs/2506.22851", "authors": ["Arnulf Jentzen", "Konrad Kleinberg", "Thomas Kruse"], "title": "Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "math.PR", "stat.ML", "90C40, 90C39, 60J05, 93E20, 65C05, 68T07"], "comment": null, "summary": "Discrete time stochastic optimal control problems and Markov decision\nprocesses (MDPs) are fundamental models for sequential decision-making under\nuncertainty and as such provide the mathematical framework underlying\nreinforcement learning theory. A central tool for solving MDPs is the Bellman\nequation and its solution, the so-called $Q$-function. In this article, we\nconstruct deep neural network (DNN) approximations for $Q$-functions associated\nto MDPs with infinite time horizon and finite control set $A$. More\nspecifically, we show that if the the payoff function and the random transition\ndynamics of the MDP can be suitably approximated by DNNs with leaky rectified\nlinear unit (ReLU) activation, then the solutions $Q_d\\colon \\mathbb R^d\\to\n\\mathbb R^{|A|}$, $d\\in \\mathbb{N}$, of the associated Bellman equations can\nalso be approximated in the $L^2$-sense by DNNs with leaky ReLU activation\nwhose numbers of parameters grow at most polynomially in both the dimension\n$d\\in \\mathbb{N}$ of the state space and the reciprocal $1/\\varepsilon$ of the\nprescribed error $\\varepsilon\\in (0,1)$. Our proof relies on the recently\nintroduced full-history recursive multilevel fixed-point (MLFP) approximation\nscheme.", "AI": {"tldr": "The paper investigates using deep neural networks (DNNs) with leaky ReLU activation to approximate $Q$-functions in Markov decision processes (MDPs) with infinite time horizons. The authors establish that these DNN approximations have error bounds that grow only polynomially with state space dimension and error tolerance.", "motivation": "The authors aim to address the challenge of efficiently solving $Q$-functions in MDPs, fundamental models for decision-making under uncertainty, by employing modern neural network approaches to make these computations feasible and accurate in high-dimensional settings.", "method": "The authors use deep neural networks with leaky ReLU activation to approximate payoff functions, transition dynamics, and solutions of Bellman equations. They leverage the full-history recursive multilevel fixed-point (MLFP) approximation scheme to ensure accuracy and efficiency.", "result": "The paper proves that the $Q$-functions in MDPs can be approximated by DNNs with parameters that grow polynomially concerning the state space dimension and the error tolerance. This establishes feasibility in computational and error management.", "conclusion": "The study demonstrates that DNNs can effectively approximate $Q$-functions in MDPs, providing a scalable and accurate framework for reinforcement learning applications in complex systems."}}
{"id": "2506.22636", "pdf": "https://arxiv.org/pdf/2506.22636", "abs": "https://arxiv.org/abs/2506.22636", "authors": ["Sotirios Panagiotis Chytas", "Miso Choi", "Hyunwoo J. Kim", "Vikas Singh"], "title": "ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision Language Models (VLMs) show impressive capabilities in integrating and\nreasoning with both visual and language data. But these models make mistakes. A\ncommon finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,\ngenerate plausible sounding text which is not grounded in the visual input, or\nat worst, is contradictory. A growing consensus attributes this behavior to an\nover-reliance on language -- especially as the generation progresses, the model\nsuffers from a ``fading memory effect'' with respect to the provided visual\ninput. We study mechanisms by which this behavior can be controlled.\nSpecifically, using ideas from geometric algebra and relational compositions,\nwe propose the addition of a small, trainable module (named ReCo) on top of any\nVLM -- no other modification is needed. We show that such a lightweight module\nis able to mitigate the fading memory effect on three of the most widely used\nVLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on\nmultiple benchmarks. Additionally, we show that our module can be combined with\nmany of the other approaches for reducing hallucination where we achieve\nimproved results for each one.", "AI": {"tldr": "The paper addresses hallucination issues in Vision Language Models (VLMs) by introducing a small, trainable module (ReCo) to combat the fading memory effect, demonstrating improved performance and compatibility with other hallucination reduction methods.", "motivation": "Understanding and controlling hallucination in Vision Language Models, particularly their over-reliance on language leading to fading memory of visual input, and improving their grounding to visual data.", "method": "The authors propose the ReCo module, a lightweight, trainable addition that leverages geometric algebra and relational compositions, designed to work seamlessly with existing VLMs without major architectural modifications.", "result": "The ReCo module effectively reduces the fading memory effect and enhances performance on benchmarks for VLMs like InstructBLIP, LlaVA, and MiniGPT4. It also integrates well with other hallucination reduction methods, further improving results.", "conclusion": "The study demonstrates that the ReCo module mitigates hallucinations in VLMs, making them more reliable while being compatible with existing advancements in this area."}}
{"id": "2506.23683", "pdf": "https://arxiv.org/pdf/2506.23683", "abs": "https://arxiv.org/abs/2506.23683", "authors": ["Maysara Alhindi", "Joseph Hallett"], "title": "Threadbox: Sandboxing for Modular Security", "categories": ["cs.CR", "cs.OS", "cs.SE"], "comment": null, "summary": "There are many sandboxing mechanisms provided by operating systems to limit\nwhat resources applications can access, however, sometimes the use of these\nmechanisms requires developers to refactor their code to fit the sandboxing\nmodel. In this work, we investigate what makes existing sandboxing mechanisms\nchallenging to apply to certain types of applications, and propose Threadbox, a\nsandboxing mechanism that enables having modular and independent sandboxes, and\ncan be applied to threads and sandbox specific functions. We present case\nstudies to illustrate the applicability of the idea and discuss its\nlimitations.", "AI": {"tldr": "The paper explores challenges with existing OS sandboxing mechanisms and proposes a new approach called Threadbox, enabling modular thread-specific sandboxes.", "motivation": "Developers often need to extensively refactor their applications to adapt to existing sandboxing models in operating systems, creating practical challenges.", "method": "The authors propose Threadbox, a novel mechanism that creates modular, independent sandboxes applicable to threads and specific functions.", "result": "Threadbox demonstrates its utility and limitations through case studies showcasing improved sandbox flexibility for diverse scenarios.", "conclusion": "Threadbox offers a promising alternative to traditional sandboxing mechanisms, allowing greater modularity and reducing challenges in application adaptation."}}
{"id": "2506.22858", "pdf": "https://arxiv.org/pdf/2506.22858", "abs": "https://arxiv.org/abs/2506.22858", "authors": ["Duygu Altinok"], "title": "Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "This is the accepted version of an article accepted to the TSD 2025\n  conference, published in Springer Lecture Notes in Artificial Intelligence\n  (LNAI). The final authenticated version is available online at SpringerLink", "summary": "Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high\ntranscription accuracy but struggle with named entities and numerical data,\nespecially when proper formatting is required. These issues increase word error\nrate (WER) and impair semantic understanding in critical domains like legal,\nfinancial, and medical applications. We propose a novel training approach that\nextends the semantic context of ASR models by adding overlapping context\nwindows during training. By sliding 5-second overlaps on both sides of\n30-second chunks, we create a 40-second \"effective semantic window,\" improving\nentity recognition and formatting while focusing predictions on the central 30\nseconds. To address entities spanning chunk boundaries, we reassign such\nentities entirely to the right-hand chunk, ensuring proper formatting.\nAdditionally, enriched training data with embedded entity labels enables the\nmodel to learn both recognition and type-specific formatting. Evaluated on the\nSpoken Wikipedia dataset, our method improves performance across semantic\ntasks, including named entity recognition (NER) and entity formatting. These\nresults highlight the effectiveness of context-aware training in addressing ASR\nlimitations for long-form transcription and complex entity recognition tasks.", "AI": {"tldr": "The paper proposes a novel training method for ASR systems to improve named entity and numerical data recognition and formatting.", "motivation": "ASR systems struggle with named entities and complex formatting, which impairs performance in critical fields like legal, financial, and medical applications.", "method": "The authors use a sliding overlapping context window during training to extend the model's semantic window and employ enriched training data with entity labels for better recognition and formatting.", "result": "The method enhances semantic tasks such as named entity recognition and formatting, validated through evaluations on the Spoken Wikipedia dataset.", "conclusion": "Context-aware training improves ASR systems' ability to handle long-form transcription and complex entity recognition, addressing key limitations."}}
{"id": "2506.23351", "pdf": "https://arxiv.org/pdf/2506.23351", "abs": "https://arxiv.org/abs/2506.23351", "authors": ["Tianxing Chen", "Kaixuan Wang", "Zhaohui Yang", "Yuhao Zhang", "Zanxin Chen", "Baijun Chen", "Wanxi Dong", "Ziyuan Liu", "Dong Chen", "Tianshuo Yang", "Haibao Yu", "Xiaokang Yang", "Yusen Qin", "Zhiqiang Xie", "Yao Mu", "Ping Luo", "Tian Nian", "Weiliang Deng", "Yiheng Ge", "Yibin Liu", "Zixuan Li", "Dehui Wang", "Zhixuan Liang", "Haohui Xie", "Rijie Zeng", "Yunfei Ge", "Peiqing Cong", "Guannan He", "Zhaoming Han", "Ruocheng Yin", "Jingxiang Guo", "Lunkai Lin", "Tianling Xu", "Hongzhe Bi", "Xuewu Lin", "Tianwei Lin", "Shujie Luo", "Keyu Li", "Ziyan Zhao", "Ke Fan", "Heyang Xu", "Bo Peng", "Wenlong Gao", "Dongjiang Li", "Feng Jin", "Hui Shen", "Jinming Li", "Chaowei Cui", "Yuchen", "Yaxin Peng", "Lingdong Zeng", "Wenlong Dong", "Tengfei Li", "Weijie Ke", "Jun Chen", "Erdemt Bao", "Tian Lan", "Tenglong Liu", "Jin Yang", "Huiping Zhuang", "Baozhi Jia", "Shuai Zhang", "Zhengfeng Zou", "Fangheng Guan", "Tianyi Jia", "Ke Zhou", "Hongjiu Zhang", "Yating Han", "Cheng Fang", "Yixian Zou", "Chongyang Xu", "Qinglun Zhang", "Shen Cheng", "Xiaohe Wang", "Ping Tan", "Haoqiang Fan", "Shuaicheng Liu", "Jiaheng Chen", "Chuxuan Huang", "Chengliang Lin", "Kaijun Luo", "Boyu Yue", "Yi Liu", "Jinyu Chen", "Zichang Tan", "Liming Deng", "Shuo Xu", "Zijian Cai", "Shilong Yin", "Hao Wang", "Hongshan Liu", "Tianyang Li", "Long Shi", "Ran Xu", "Huilin Xu", "Zhengquan Zhang", "Congsheng Xu", "Jinchang Yang", "Feng Xu"], "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "comment": "Challenge Webpage:\n  https://robotwin-benchmark.github.io/cvpr-2025-challenge/", "summary": "Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in\nrobotics, driven by the need for autonomous systems that can perceive, reason,\nand act in complex physical environments. While single-arm systems have shown\nstrong task performance, collaborative dual-arm systems are essential for\nhandling more intricate tasks involving rigid, deformable, and\ntactile-sensitive objects. To advance this goal, we launched the RoboTwin\nDual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on\nthe RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot\nplatform, the competition consisted of three stages: Simulation Round 1,\nSimulation Round 2, and a final Real-World Round. Participants totally tackled\n17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based\nscenarios. The challenge attracted 64 global teams and over 400 participants,\nproducing top-performing solutions like SEM and AnchorDP3 and generating\nvaluable insights into generalizable bimanual policy learning. This report\noutlines the competition setup, task design, evaluation methodology, key\nfindings and future direction, aiming to support future research on robust and\ngeneralizable bimanual manipulation policies. The Challenge Webpage is\navailable at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.", "AI": {"tldr": "The paper discusses the RoboTwin Dual-Arm Collaboration Challenge, a competition focused on advancing collaborative dual-arm manipulation using novel solutions and platforms.", "motivation": "To address the limitations of single-arm systems and promote advancements in collaborative dual-arm manipulation for tasks requiring higher complexity, such as handling rigid, deformable, and tactile-sensitive objects.", "method": "The challenge included three competitive stages (two simulation rounds and one real-world round) where 64 global teams tackled a series of 17 dual-arm manipulation tasks using platforms like RoboTwin Simulation and AgileX COBOT-Magic Robot.", "result": "Participants developed high-performing solutions like SEM and AnchorDP3, offering valuable insights into generalizable bimanual policy learning, and contributed to progress in the field.", "conclusion": "Insights and results gained from this challenge aim to support further research and development of robust and transferable bimanual robot manipulation policies."}}
{"id": "2506.23520", "pdf": "https://arxiv.org/pdf/2506.23520", "abs": "https://arxiv.org/abs/2506.23520", "authors": ["Yu Zhang", "Ruijie Yu", "Jidong Tian", "Feng Zhu", "Jiapeng Liu", "Xiaokang Yang", "Yaohui Jin", "Yanyan Xu"], "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "categories": ["cs.AI"], "comment": null, "summary": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "AI": {"tldr": "The paper introduces ChemActor, a large language model (LLM) fine-tuned for converting unstructured chemical procedures into structured action sequences, achieving state-of-the-art results in automation tasks.", "motivation": "The study is driven by the need for automated extraction of chemical procedures from literature, which is challenging due to ambiguous chemical language and costly human annotation requirements.", "method": "The authors developed ChemActor, a fine-tuned LLM, and proposed a framework that includes a data selection module to handle low-quality data and a multi-round LLM review metric to improve understanding of chemical procedures.", "result": "ChemActor achieves state-of-the-art performance in converting reaction descriptions to structured actions with a 10% improvement over baseline models in the R2D and D2A tasks.", "conclusion": "The framework and ChemActor demonstrate the potential of LLM-based approaches in automating chemical procedure understanding and execution, significantly advancing the field."}}
{"id": "2506.22861", "pdf": "https://arxiv.org/pdf/2506.22861", "abs": "https://arxiv.org/abs/2506.22861", "authors": ["Ziling Ma", "Mara Sherlin Talento", "Ying Sun", "Hernando Ombao"], "title": "FuzzCoh: Robust Canonical Coherence-Based Fuzzy Clustering of Multivariate Time Series", "categories": ["stat.AP", "stat.ME", "stat.ML"], "comment": null, "summary": "Brain cognitive and sensory functions are often associated with\nelectrophysiological activity at specific frequency bands. Clustering\nmultivariate time series (MTS) data like EEGs is important for understanding\nbrain functions but challenging due to complex non-stationary\ncross-dependencies, gradual transitions between cognitive states, noisy\nmeasurements, and ambiguous cluster boundaries. To address these issues, we\ndevelop a robust fuzzy clustering framework in the spectral domain. Our method\nleverages Kendall's tau-based canonical coherence, which extracts meaningful\nfrequency-specific monotonic relationships between groups of channels or\nregions. KenCoh effectively captures dominant coherence structures while\nremaining robust against outliers and noise, making it suitable for real EEG\ndatasets that typically contain artifacts. Our method first projects each MTS\nobject onto vectors derived from the KenCoh estimates (i.e, canonical\ndirections), which capture relevant information on the connectivity structure\nof oscillatory signals in predefined frequency bands. These spectral features\nare utilized to determine clusters of epochs using a fuzzy partitioning\nstrategy, accommodating gradual transitions and overlapping class structure.\nLastly, we demonstrate the effectiveness of our approach to EEG data where\nlatent cognitive states such as alertness and drowsiness exhibit\nfrequency-specific dynamics and ambiguity. Our method captures both spectral\nand spatial features by locating the frequency-dependent structure and brain\nfunctional connectivity. Built on the KenCoh framework for fuzzy clustering, it\nhandles the complexity of high-dimensional time series data and is broadly\napplicable to domains such as neuroscience, wearable sensing, environmental\nmonitoring, and finance.", "AI": {"tldr": "The paper proposes a fuzzy clustering method leveraging Kendall's tau-based canonical coherence to analyze EEG data, addressing challenges like noise, and ambiguous clustering.", "motivation": "Understanding brain functions via EEG data clustering is complex due to non-stationary dependencies, noisy data, and overlap in cognitive states.", "method": "Utilizing Kendall's tau-based canonical coherence for frequency-specific feature extraction, projecting EEG data, and applying fuzzy clustering to capture spectral and spatial dynamics.", "result": "The approach effectively clusters EEG data, identifying latent cognitive states like alertness and drowsiness and their spectral dependencies.", "conclusion": "The method efficiently handles high-dimensional, noisy time series data and has wide applications, including neuroscience and wearable sensing."}}
{"id": "2506.22637", "pdf": "https://arxiv.org/pdf/2506.22637", "abs": "https://arxiv.org/abs/2506.22637", "authors": ["Haoxuan Wang", "Zhenghao Zhao", "Junyi Wu", "Yuzhang Shang", "Gaowen Liu", "Yan Yan"], "title": "CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation", "categories": ["cs.CV"], "comment": "ICCV 2025. Code is available at\n  https://github.com/hatchetProject/CaO2", "summary": "The recent introduction of diffusion models in dataset distillation has shown\npromising potential in creating compact surrogate datasets for large,\nhigh-resolution target datasets, offering improved efficiency and performance\nover traditional bi-level/uni-level optimization methods. However, current\ndiffusion-based dataset distillation approaches overlook the evaluation process\nand exhibit two critical inconsistencies in the distillation process: (1)\nObjective Inconsistency, where the distillation process diverges from the\nevaluation objective, and (2) Condition Inconsistency, leading to mismatches\nbetween generated images and their corresponding conditions. To resolve these\nissues, we introduce Condition-aware Optimization with Objective-guided\nSampling (CaO$_2$), a two-stage diffusion-based framework that aligns the\ndistillation process with the evaluation objective. The first stage employs a\nprobability-informed sample selection pipeline, while the second stage refines\nthe corresponding latent representations to improve conditional likelihood.\nCaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,\nsurpassing the best-performing baselines by an average of 2.3% accuracy.", "AI": {"tldr": "The paper proposes a framework called CaO$_2$ to address inconsistencies in diffusion-based dataset distillation, achieving improved accuracy on ImageNet.", "motivation": "To tackle inefficiencies and inconsistencies in current diffusion-based dataset distillation methods, enhancing their alignment with evaluation objectives.", "method": "CaO$_2$ consists of a two-stage framework: (1) probability-informed sample selection to address objective inconsistency and (2) refinement of latent representations to tackle condition mismatch.", "result": "CaO$_2$ outperformed existing methods, setting state-of-the-art accuracy on ImageNet and subsets, with an average improvement of 2.3%.", "conclusion": "Aligning distillation processes with evaluation objectives through the proposed framework improves dataset distillation efficiency, effectiveness, and overall accuracy."}}
{"id": "2506.23841", "pdf": "https://arxiv.org/pdf/2506.23841", "abs": "https://arxiv.org/abs/2506.23841", "authors": ["\u00cdtalo Oliveira", "Stefano M. Nicoletti", "Gal Engelberg", "Mattia Fumagalli", "Dan Klein", "Giancarlo Guizzardi"], "title": "An ontological lens on attack trees: Toward adequacy and interoperability", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Attack Trees (AT) are a popular formalism for security analysis. They are\nmeant to display an attacker's goal decomposed into attack steps needed to\nachieve it and compute certain security metrics (e.g., attack cost,\nprobability, and damage). ATs offer three important services: (a) conceptual\nmodeling capabilities for representing security risk management scenarios, (b)\na qualitative assessment to find root causes and minimal conditions of\nsuccessful attacks, and (c) quantitative analyses via security metrics\ncomputation under formal semantics, such as minimal time and cost among all\nattacks. Still, the AT language presents limitations due to its lack of\nontological foundations, thus compromising associated services. Via an\nontological analysis grounded in the Common Ontology of Value and Risk (COVER)\n-- a reference core ontology based on the Unified Foundational Ontology (UFO)\n-- we investigate the ontological adequacy of AT and reveal four significant\nshortcomings: (1) ambiguous syntactical terms that can be interpreted in\nvarious ways; (2) ontological deficit concerning crucial domain-specific\nconcepts; (3) lacking modeling guidance to construct ATs decomposing a goal;\n(4) lack of semantic interoperability, resulting in ad hoc stand-alone tools.\nWe also discuss existing incremental solutions and how our analysis paves the\nway for overcoming those issues through a broader approach to risk management\nmodeling.", "AI": {"tldr": "Attack Trees (AT) are widely used for security analysis, but their lack of strong ontological foundations results in four key issues: ambiguous terms, missing critical concepts, insufficient modeling guidance, and lack of semantic interoperability.", "motivation": "To analyze the limitations of the Attack Trees (AT) language in security modeling and identify ontological shortcomings that hamper its effectiveness.", "method": "This paper employs an ontological analysis grounded in the Common Ontology of Value and Risk (COVER), which is based on the Unified Foundational Ontology (UFO), to investigate AT's ontological inadequacies.", "result": "The study identifies four significant shortcomings in AT: ambiguous syntax, a deficit of domain-specific concepts, insufficient guidance for goal decomposition, and a lack of semantic interoperability.", "conclusion": "The analysis highlights that overcoming these limitations requires a broader approach to risk management modeling and suggests existing incremental solutions as interim fixes."}}
{"id": "2506.22957", "pdf": "https://arxiv.org/pdf/2506.22957", "abs": "https://arxiv.org/abs/2506.22957", "authors": ["Younwoo Choi", "Changling Li", "Yongjin Yang", "Zhijing Jin"], "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": null, "summary": "As large language models (LLMs) are increasingly integrated into multi-agent\nand human-AI systems, understanding their awareness of both self-context and\nconversational partners is essential for ensuring reliable performance and\nrobust safety. While prior work has extensively studied situational awareness\nwhich refers to an LLM's ability to recognize its operating phase and\nconstraints, it has largely overlooked the complementary capacity to identify\nand adapt to the identity and characteristics of a dialogue partner. In this\npaper, we formalize this latter capability as interlocutor awareness and\npresent the first systematic evaluation of its emergence in contemporary LLMs.\nWe examine interlocutor inference across three dimensions-reasoning patterns,\nlinguistic style, and alignment preferences-and show that LLMs reliably\nidentify same-family peers and certain prominent model families, such as GPT\nand Claude. To demonstrate its practical significance, we develop three case\nstudies in which interlocutor awareness both enhances multi-LLM collaboration\nthrough prompt adaptation and introduces new alignment and safety\nvulnerabilities, including reward-hacking behaviors and increased jailbreak\nsusceptibility. Our findings highlight the dual promise and peril of\nidentity-sensitive behavior in LLMs, underscoring the need for further\nunderstanding of interlocutor awareness and new safeguards in multi-agent\ndeployments. Our code is open-sourced at\nhttps://github.com/younwoochoi/InterlocutorAwarenessLLM.", "AI": {"tldr": "This paper introduces and evaluates the concept of interlocutor awareness in large language models (LLMs), focusing on their ability to adapt to dialogue partners' identity and characteristics.", "motivation": "To understand and improve the interplay of LLMs in multi-agent and human-AI systems, emphasizing the safety and reliability tied to their awareness of conversational partners.", "method": "This paper formalizes interlocutor awareness and systematically evaluates its emergence across reasoning patterns, linguistic style, and alignment preferences, alongside developing case studies demonstrating its impact.", "result": "LLMs show reliable ability to identify same-family peers and significant model families, revealing enhancements in multi-LLM collaboration but also vulnerabilities like reward-hacking and increased susceptibility to jailbreaks.", "conclusion": "While interlocutor awareness in LLMs has promising benefits for collaboration, it also introduces alignment and safety challenges, necessitating better understanding and safeguards in multi-agent setups."}}
{"id": "2506.23369", "pdf": "https://arxiv.org/pdf/2506.23369", "abs": "https://arxiv.org/abs/2506.23369", "authors": ["Xiao'ao Song", "Konstantinos Karydis"], "title": "GS-NBV: a Geometry-based, Semantics-aware Viewpoint Planning Algorithm for Avocado Harvesting under Occlusions", "categories": ["cs.RO"], "comment": "Accepted for publication in CASE 2025, 6 pages, 8 figures", "summary": "Efficient identification of picking points is critical for automated fruit\nharvesting. Avocados present unique challenges owing to their irregular shape,\nweight, and less-structured growing environments, which require specific\nviewpoints for successful harvesting. We propose a geometry-based,\nsemantics-aware viewpoint-planning algorithm to address these challenges. The\nplanning process involves three key steps: viewpoint sampling, evaluation, and\nexecution. Starting from a partially occluded view, the system first detects\nthe fruit, then leverages geometric information to constrain the viewpoint\nsearch space to a 1D circle, and uniformly samples four points to balance the\nefficiency and exploration. A new picking score metric is introduced to\nevaluate the viewpoint suitability and guide the camera to the next-best view.\nWe validate our method through simulation against two state-of-the-art\nalgorithms. Results show a 100% success rate in two case studies with\nsignificant occlusions, demonstrating the efficiency and robustness of our\napproach. Our code is available at https://github.com/lineojcd/GSNBV", "AI": {"tldr": "The paper tackles automated avocado harvesting challenges by presenting a geometry-based, semantics-aware viewpoint-planning algorithm. It uses occlusion detection and a picking score metric to optimize viewpoints, achieving remarkable success rates in simulations.", "motivation": "Automated harvesting of fruits like avocados faces challenges due to their irregular shape, substantial weight, and complex growing environments, necessitating innovative approaches to identify effective picking points.", "method": "The proposed method involves detecting partially occluded avocados, constraining viewpoint searches to a 1D circle using geometric data, sampling four points, and introducing a picking score for selecting efficient viewpoints.", "result": "The algorithm demonstrated a 100% success rate in simulations with heavy occlusions, outperforming two state-of-the-art methods in efficiency and robustness.", "conclusion": "The study's geometry-based and semantics-aware viewpoint-planning strategy is effective for improving automated harvesting processes in unstructured and occluded environments, validated by its impressive simulation results."}}
{"id": "2506.23549", "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios.", "AI": {"tldr": "The paper introduces Coordination Transformers (CooT), a framework for improving coordination in multi-agent systems by using recent interaction histories.", "motivation": "Existing coordination approaches often fail to generalize well to unseen partners or demand extensive training, limiting their applicability in dynamic environments.", "method": "The CooT framework leverages recent interaction data to predict aligned actions, trained on diverse agent pairs with complementary behaviors. It requires no explicit supervision or fine-tuning during deployment.", "result": "CooT outperformed baseline methods on the Overcooked benchmark in adapting to unseen partners. Human evaluations further validated its effectiveness and its robustness in dynamic contexts.", "conclusion": "CooT offers a robust and efficient coordination strategy for multi-agent systems, demonstrating practical improvements in adaptability and effectiveness."}}
{"id": "2506.22994", "pdf": "https://arxiv.org/pdf/2506.22994", "abs": "https://arxiv.org/abs/2506.22994", "authors": ["Can Hakan Da\u011f\u0131d\u0131r", "Mia Hubert", "Peter J. Rousseeuw"], "title": "Kernel Outlier Detection", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A new anomaly detection method called kernel outlier detection (KOD) is\nproposed. It is designed to address challenges of outlier detection in\nhigh-dimensional settings. The aim is to overcome limitations of existing\nmethods, such as dependence on distributional assumptions or on hyperparameters\nthat are hard to tune. KOD starts with a kernel transformation, followed by a\nprojection pursuit approach. Its novelties include a new ensemble of directions\nto search over, and a new way to combine results of different direction types.\nThis provides a flexible and lightweight approach for outlier detection. Our\nempirical evaluations illustrate the effectiveness of KOD on three small\ndatasets with challenging structures, and on four large benchmark datasets.", "AI": {"tldr": "A novel method, kernel outlier detection (KOD), addresses high-dimensional outlier detection without relying on strict assumptions or challenging hyperparameter tuning.", "motivation": "The study aims to solve outlier detection limitations in high-dimensional settings, addressing issues like dependency on complex assumptions and hard-to-tune parameters.", "method": "KOD uses a kernel transformation combined with projection pursuit, introducing new ensemble directions and novel result combination techniques.", "result": "Empirical tests of KOD show effectiveness on three small complex datasets and four large benchmark datasets.", "conclusion": "Kernel outlier detection offers a flexible and efficient solution for detecting anomalies across various datasets, showcasing its practicality and robustness."}}
{"id": "2506.22780", "pdf": "https://arxiv.org/pdf/2506.22780", "abs": "https://arxiv.org/abs/2506.22780", "authors": ["Dibyajyoti Chakraborty", "Haiwen Guan", "Jason Stock", "Troy Arcomano", "Guido Cervone", "Romit Maulik"], "title": "Multimodal Atmospheric Super-Resolution With Deep Generative Models", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Score-based diffusion modeling is a generative machine learning algorithm\nthat can be used to sample from complex distributions. They achieve this by\nlearning a score function, i.e., the gradient of the log-probability density of\nthe data, and reversing a noising process using the same. Once trained,\nscore-based diffusion models not only generate new samples but also enable\nzero-shot conditioning of the generated samples on observed data. This promises\na novel paradigm for data and model fusion, wherein the implicitly learned\ndistributions of pretrained score-based diffusion models can be updated given\nthe availability of online data in a Bayesian formulation. In this article, we\napply such a concept to the super-resolution of a high-dimensional dynamical\nsystem, given the real-time availability of low-resolution and experimentally\nobserved sparse sensor measurements from multimodal data. Additional analysis\non how score-based sampling can be used for uncertainty estimates is also\nprovided. Our experiments are performed for a super-resolution task that\ngenerates the ERA5 atmospheric dataset given sparse observations from a\ncoarse-grained representation of the same and/or from unstructured experimental\nobservations of the IGRA radiosonde dataset. We demonstrate accurate recovery\nof the high dimensional state given multiple sources of low-fidelity\nmeasurements. We also discover that the generative model can balance the\ninfluence of multiple dataset modalities during spatiotemporal reconstructions.", "AI": {"tldr": "The paper proposes using score-based diffusion models to improve the super-resolution of atmospheric datasets by fusing low-resolution multimodal data and provides uncertainty estimates.", "motivation": "The motivation is to leverage score-based diffusion models for fusing data from various low-fidelity sources to improve spatiotemporal reconstructions, specifically in high-dimensional dynamical systems such as atmospheric datasets.", "method": "The authors extend score-based diffusion modeling for super-resolution, incorporating observed low-resolution data in a Bayesian framework. They demonstrate this with real-time sparse, multimodal sensor data for atmospheric observations.", "result": "The study achieves accurate high-resolution reconstructions of the ERA5 atmospheric dataset using sparse observations and shows the model's ability to balance multiple data modalities effectively.", "conclusion": "Score-based diffusion models can improve high-dimensional data reconstruction by fusing multimodal inputs. They also provide valuable uncertainty estimates, making them suitable for spatiotemporal applications."}}
{"id": "2506.22678", "pdf": "https://arxiv.org/pdf/2506.22678", "abs": "https://arxiv.org/abs/2506.22678", "authors": ["Nicolas Caytuiro", "Ivan Sipiran"], "title": "3D Shape Generation: A Survey", "categories": ["cs.CV"], "comment": "20 pages, 5 figures", "summary": "Recent advances in deep learning have significantly transformed the field of\n3D shape generation, enabling the synthesis of complex, diverse, and\nsemantically meaningful 3D objects. This survey provides a comprehensive\noverview of the current state of the art in 3D shape generation, organizing the\ndiscussion around three core components: shape representations, generative\nmodeling approaches, and evaluation protocols. We begin by categorizing 3D\nrepresentations into explicit, implicit, and hybrid setups, highlighting their\nstructural properties, advantages, and limitations. Next, we review a wide\nrange of generation methods, focusing on feedforward architectures. We further\nsummarize commonly used datasets and evaluation metrics that assess fidelity,\ndiversity, and realism of generated shapes. Finally, we identify open\nchallenges and outline future research directions that could drive progress in\ncontrollable, efficient, and high-quality 3D shape generation. This survey aims\nto serve as a valuable reference for researchers and practitioners seeking a\nstructured and in-depth understanding of this rapidly evolving field.", "AI": {"tldr": "The paper surveys the state of the art in 3D shape generation, discussing shape representations, generative methods, evaluation protocols, and future challenges.", "motivation": "To provide a structured and comprehensive understanding of the advancements and challenges in the field of 3D shape generation for researchers and practitioners.", "method": "The survey organizes its discussion around three main themes: categorization of 3D shape representations, a review of generative approaches, and a summary of evaluation metrics and datasets.", "result": "The paper outlines key structural properties of different shape representations, reviews generative methods focusing on feedforward architectures, and summarizes methods for fidelity and diversity evaluation of 3D shapes.", "conclusion": "The survey highlights open challenges in controllable and high-quality 3D shape generation and identifies directions for future research to advance the field."}}
{"id": "2506.23866", "pdf": "https://arxiv.org/pdf/2506.23866", "abs": "https://arxiv.org/abs/2506.23866", "authors": ["Jason Kayembe", "Iness Ben Guirat", "Jan Tobias M\u00fchlberg"], "title": "Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions", "categories": ["cs.CR", "cs.CY", "cs.SE"], "comment": "Post-proceedings paper persented at LOCO '24: 1st International\n  Workshop on Low Carbon Computing, 2024-12-03, in Glasgow, UK", "summary": "In this paper, we explore the intersection of privacy, security, and\nenvironmental sustainability in cloud-based office solutions, focusing on\nquantifying user- and network-side energy use and associated carbon emissions.\nWe hypothesise that privacy-focused services are typically more\nenergy-efficient than those funded through data collection and advertising. To\nevaluate this, we propose a framework that systematically measures\nenvironmental costs based on energy usage and network data traffic during\nwell-defined, automated usage scenarios. To test our hypothesis, we first\nanalyse how underlying architectures and business models, such as monetisation\nthrough personalised advertising, contribute to the environmental footprint of\nthese services. We then explore existing methodologies and tools for software\nenvironmental impact assessment. We apply our framework to three mainstream\nemail services selected to reflect different privacy policies, from\nad-supported tracking-intensive models to privacy-focused designs: Microsoft\nOutlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a\nself-hosted email solution, evaluated with and without end-to-end encryption.\nWe show that the self-hosted solution, even with 14% of device energy and 15%\nof emissions overheads from PGP encryption, remains the most energy-efficient,\nsaving up to 33% of emissions per session compared to Gmail. Among commercial\nproviders, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per\nsession compared to Outlook, whose emissions can be further reduced by 2%\nthrough ad-blocking.", "AI": {"tldr": "The paper examines the environmental consequences of cloud-based email services using a framework analyzing energy consumption and carbon emissions. Results indicate that privacy-focused services such as Proton Mail and self-hosted solutions are more environmentally efficient than advertising-driven models like Gmail and Outlook.", "motivation": "To investigate the link between privacy-centric service models and their environmental sustainability, hypothesizing that services protecting user privacy are more energy-efficient than advertising-funded alternatives.", "method": "A systematic framework was created to measure energy use and carbon emissions of email services during automated usage scenarios. The study applies this to analyze three platforms\u2014Microsoft Outlook, Google Mail, and Proton Mail\u2014plus a self-hosted email server with and without end-to-end encryption.", "result": "The self-hosted email solution was the most energy-efficient, with 33% lower emissions compared to Gmail, even accounting for encryption overheads. Among commercial providers, Proton Mail showed superior efficiency, outperforming Outlook and Gmail, though ad-blocking reduced Outlook emissions slightly.", "conclusion": "Privacy-driven email services not only protect user data but also have a lower environmental impact, highlighting their dual advantages of sustainability and privacy. Self-hosted and privacy-focused services are more efficient than advertising-based alternatives."}}
{"id": "2506.22977", "pdf": "https://arxiv.org/pdf/2506.22977", "abs": "https://arxiv.org/abs/2506.22977", "authors": ["Asen Dotsinski", "Udit Thakur", "Marko Ivanov", "Mohammad Hafeez Khan", "Maria Heuss"], "title": "On the Generalizability of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\"", "categories": ["cs.CL", "cs.LG"], "comment": "22 pages, 25 figures. For an interactive dashboard with all figures,\n  see https://comp-mech-generalizability.streamlit.app/ . For the accompanying\n  code, see https://github.com/asendotsinski/comp-mech-generalizability . To be\n  published in proceedings of the 2025 Machine Learning Reproducibility\n  Challenge", "summary": "We present a reproduction study of \"Competition of Mechanisms: Tracing How\nLanguage Models Handle Facts and Counterfactuals\" (Ortu et al., 2024), which\ninvestigates competition of mechanisms in language models between factual\nrecall and counterfactual in-context repetition. Our study successfully\nreproduces their primary findings regarding the localization of factual and\ncounterfactual information, the dominance of attention blocks in mechanism\ncompetition, and the specialization of attention heads in handling competing\ninformation. We reproduce their results on both GPT-2 (Radford et al., 2019)\nand Pythia 6.9B (Biderman et al., 2023). We extend their work in three\nsignificant directions. First, we explore the generalizability of these\nfindings to even larger models by replicating the experiments on Llama 3.1 8B\n(Grattafiori et al., 2024), discovering greatly reduced attention head\nspecialization. Second, we investigate the impact of prompt structure by\nintroducing variations where we avoid repeating the counterfactual statement\nverbatim or we change the premise word, observing a marked decrease in the\nlogit for the counterfactual token. Finally, we test the validity of the\nauthors' claims for prompts of specific domains, discovering that certain\ncategories of prompts skew the results by providing the factual prediction\ntoken as part of the subject of the sentence. Overall, we find that the\nattention head ablation proposed in Ortu et al. (2024) is ineffective for\ndomains that are underrepresented in their dataset, and that the effectiveness\nvaries based on model architecture, prompt structure, domain and task.", "AI": {"tldr": "This paper reproduces and extends the findings of Ortu et al. (2024) on how language models manage competing mechanisms between factual recall and counterfactual in-context repetition.", "motivation": "The study aims to validate and extend the findings from Ortu et al. (2024) on the competition of mechanisms in language models, as understanding this can improve their functionality and robustness.", "method": "The authors reproduced the experiments from the original work on GPT-2 and Pythia 6.9B models, extended them to Llama 3.1 8B, evaluated the influence of varied prompt structures, and examined domain-specific prompt behavior.", "result": "Key findings include reduced attention head specialization in larger models (Llama 3.1 8B), significant effects of prompt structure on counterfactual token prediction, and a dependence of results on domain representation and model architecture.", "conclusion": "The study shows that the competition of mechanisms is context-dependent, varying based on factors like model size, prompt structure, and dataset domain representation, which limits the generalizability of attention head ablation methods."}}
{"id": "2506.23400", "pdf": "https://arxiv.org/pdf/2506.23400", "abs": "https://arxiv.org/abs/2506.23400", "authors": ["Yifei Li", "Joshua A. Robbins", "Guha Manogharan", "Herschel C. Pangborn", "Ilya Kovalenko"], "title": "A Model Predictive Control Framework to Enhance Safety and Quality in Mobile Additive Manufacturing Systems", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "2025 IEEE 21st International Conference on Automation Science and\n  Engineering", "summary": "In recent years, the demand for customized, on-demand production has grown in\nthe manufacturing sector. Additive Manufacturing (AM) has emerged as a\npromising technology to enhance customization capabilities, enabling greater\nflexibility, reduced lead times, and more efficient material usage. However,\ntraditional AM systems remain constrained by static setups and human worker\ndependencies, resulting in long lead times and limited scalability. Mobile\nrobots can improve the flexibility of production systems by transporting\nproducts to designated locations in a dynamic environment. By integrating AM\nsystems with mobile robots, manufacturers can optimize travel time for\npreparatory tasks and distributed printing operations. Mobile AM robots have\nbeen deployed for on-site production of large-scale structures, but often\nneglect critical print quality metrics like surface roughness. Additionally,\nthese systems do not have the precision necessary for producing small,\nintricate components. We propose a model predictive control framework for a\nmobile AM platform that ensures safe navigation on the plant floor while\nmaintaining high print quality in a dynamic environment. Three case studies are\nused to test the feasibility and reliability of the proposed systems.", "AI": {"tldr": "This paper focuses on improving manufacturing with mobile robots integrated with Additive Manufacturing (AM) to enhance flexibility, reduce lead times, and achieve better print quality.", "motivation": "The paper is motivated by the growing demand for flexible and on-demand manufacturing, where traditional AM falls short in scalability, lead times, and print precision.", "method": "The authors propose a model predictive control framework for mobile AM platforms, providing safe navigation and ensuring high print quality in dynamic production environments.", "result": "Three case studies were conducted to test the system's feasibility and reliability.", "conclusion": "Integrating mobile robots with AM systems can tackle challenges in modern manufacturing by improving flexibility, safety, and print precision in a dynamic production setting."}}
{"id": "2506.23563", "pdf": "https://arxiv.org/pdf/2506.23563", "abs": "https://arxiv.org/abs/2506.23563", "authors": ["Huanjin Yao", "Jiaxing Huang", "Yawen Qiu", "Michael K. Chen", "Wenzheng Liu", "Wei Zhang", "Wenjie Zeng", "Xikun Zhang", "Jingyi Zhang", "Yuxin Song", "Wenhao Wu", "Dacheng Tao"], "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Technical report", "summary": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "AI": {"tldr": "The paper introduces MMReason, a benchmark for evaluating the long-chain reasoning capability of Multimodal Large Language Models (MLLMs) with diverse and challenging tasks.", "motivation": "Current MLLM benchmarks fail to adequately test long-chain reasoning due to lack of diversity, susceptibility to guessability and memorization, and insufficient evaluation of intermediate reasoning steps.", "method": "MMReason was developed with diverse multi-step problems in six disciplines, across multiple difficulty levels. It uses an open-ended question format filtered by a multi-model voting mechanism to reduce shortcut cases. Questions are annotated with step-by-step solutions and evaluated using a ternary scoring system.", "result": "The benchmark highlights the reasoning strengths and weaknesses of leading MLLMs, providing valuable insights for further research.", "conclusion": "MMReason aims to fill gaps in current MLLM evaluation methods and serve as a comprehensive resource for advancing reasoning capabilities in MLLMs."}}
{"id": "2506.23033", "pdf": "https://arxiv.org/pdf/2506.23033", "abs": "https://arxiv.org/abs/2506.23033", "authors": ["Yash Vardhan Tomar"], "title": "Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Bias in predictive machine learning (ML) models is a fundamental challenge\ndue to the skewed or unfair outcomes produced by biased models. Existing\nmitigation strategies rely on either post-hoc corrections or rigid constraints.\nHowever, emerging research claims that these techniques can limit scalability\nand reduce generalizability. To address this, this paper introduces a\nfeature-wise mixing framework to mitigate contextual bias. This was done by\nredistributing feature representations across multiple contextual datasets. To\nassess feature-wise mixing's effectiveness, four ML classifiers were trained\nusing cross-validation and evaluated with bias-sensitive loss functions,\nincluding disparity metrics and mean squared error (MSE), which served as a\nstandard measure of predictive performance. The proposed method achieved an\naverage bias reduction of 43.35% and a statistically significant decrease in\nMSE across all classifiers trained on mixed datasets. Additionally,\nbenchmarking against established bias mitigation techniques found that\nfeature-wise mixing consistently outperformed SMOTE oversampling and\ndemonstrated competitive effectiveness without requiring explicit bias\nattribute identification. Feature-wise mixing efficiently avoids the\ncomputational overhead typically associated with fairness-aware learning\nalgorithms. Future work could explore applying feature-wise mixing for\nreal-world fields where accurate predictions are necessary.", "AI": {"tldr": "The paper introduces a feature-wise mixing framework to reduce bias in ML models by redistributing feature representations, achieving better performance and lower bias compared to traditional techniques.", "motivation": "Bias in ML models leads to unfair outcomes, and current mitigation strategies struggle with scalability and generalizability.", "method": "A feature-wise mixing framework redistributes feature representations across multiple contextual datasets and uses cross-validation with bias-sensitive metrics.", "result": "The method reduced bias by 43.35% and significantly lowered MSE across classifiers, outperforming SMOTE without requiring explicit bias attribute identification.", "conclusion": "Feature-wise mixing is effective in mitigating bias while maintaining predictive performance, offering a scalable and computationally efficient solution."}}
{"id": "2506.22802", "pdf": "https://arxiv.org/pdf/2506.22802", "abs": "https://arxiv.org/abs/2506.22802", "authors": ["Hae Jin Song", "Laurent Itti"], "title": "Riemannian-Geometric Fingerprints of Generative Models", "categories": ["cs.LG", "cs.CR", "cs.CV", "I.2.6"], "comment": null, "summary": "Recent breakthroughs and rapid integration of generative models (GMs) have\nsparked interest in the problem of model attribution and their fingerprints.\nFor instance, service providers need reliable methods of authenticating their\nmodels to protect their IP, while users and law enforcement seek to verify the\nsource of generated content for accountability and trust. In addition, a\ngrowing threat of model collapse is arising, as more model-generated data are\nbeing fed back into sources (e.g., YouTube) that are often harvested for\ntraining (\"regurgitative training\"), heightening the need to differentiate\nsynthetic from human data. Yet, a gap still exists in understanding generative\nmodels' fingerprints, we believe, stemming from the lack of a formal framework\nthat can define, represent, and analyze the fingerprints in a principled way.\nTo address this gap, we take a geometric approach and propose a new definition\nof artifact and fingerprint of GMs using Riemannian geometry, which allows us\nto leverage the rich theory of differential geometry. Our new definition\ngeneralizes previous work (Song et al., 2024) to non-Euclidean manifolds by\nlearning Riemannian metrics from data and replacing the Euclidean distances and\nnearest-neighbor search with geodesic distances and kNN-based Riemannian center\nof mass. We apply our theory to a new gradient-based algorithm for computing\nthe fingerprints in practice. Results show that it is more effective in\ndistinguishing a large array of GMs, spanning across 4 different datasets in 2\ndifferent resolutions (64 by 64, 256 by 256), 27 model architectures, and 2\nmodalities (Vision, Vision-Language). Using our proposed definition\nsignificantly improves the performance on model attribution, as well as a\ngeneralization to unseen datasets, model types, and modalities, suggesting its\npractical efficacy.", "AI": {"tldr": "The paper addresses generative models' attribution by defining fingerprints using Riemannian geometry, achieving improved model attribution performance across varied datasets and architectures.", "motivation": "The paper aims to tackle issues of model attribution, intellectual property protection, accountability, and addressing challenges like model collapse due to synthetic data.", "method": "It employs Riemannian geometry to redefine generative model fingerprints and proposes a gradient-based algorithm for practical computation.", "result": "The proposed definitions and methods outperform previous approaches in distinguishing generative models across diverse datasets, resolutions, architectures, and modalities.", "conclusion": "The approach generalized effectively to unseen data, models, and modalities, highlighting its practical relevance and potential to improve generative model accountability and performance."}}
{"id": "2506.22710", "pdf": "https://arxiv.org/pdf/2506.22710", "abs": "https://arxiv.org/abs/2506.22710", "authors": ["Jiang Yuan", "JI Ma", "Bo Wang", "Guanzhou Ke", "Weiming Hu"], "title": "LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges\non extracting the implicit degradation representation (IDR) of the LR image and\nadapting it to LR image features to guide HR detail restoration. Although\nIDE-BSR has shown potential in dealing with noise interference and complex\ndegradations, existing methods ignore the importance of IDR discriminability\nfor BSR and instead over-complicate the adaptation process to improve effect,\nresulting in a significant increase in the model's parameters and computations.\nIn this paper, we focus on the discriminability optimization of IDR and propose\na new powerful and lightweight BSR model termed LightBSR. Specifically, we\nemploy a knowledge distillation-based learning framework. We first introduce a\nwell-designed degradation-prior-constrained contrastive learning technique\nduring teacher stage to make the model more focused on distinguishing different\ndegradation types. Then we utilize a feature alignment technique to transfer\nthe degradation-related knowledge acquired by the teacher to the student for\npractical inferencing. Extensive experiments demonstrate the effectiveness of\nIDR discriminability-driven BSR model design. The proposed LightBSR can achieve\noutstanding performance with minimal complexity across a range of blind SR\ntasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.", "AI": {"tldr": "The paper introduces a new lightweight blind super-resolution model, LightBSR, which enhances implicit degradation representation (IDR) discriminability while minimizing computational complexity.", "motivation": "Current blind super-resolution models complicate the adaptation process, increasing computational overhead, while neglecting the importance of IDR discriminability.", "method": "The authors use a knowledge distillation framework with degradation-prior-constrained contrastive learning in the teacher stage and feature alignment to transfer knowledge to the student model.", "result": "LightBSR achieves high performance with significantly reduced computational complexity across various blind super-resolution tasks.", "conclusion": "Improving IDR discriminability simplifies blind super-resolution models, enabling effective and efficient HR detail restoration."}}
{"id": "2506.23960", "pdf": "https://arxiv.org/pdf/2506.23960", "abs": "https://arxiv.org/abs/2506.23960", "authors": ["Mingfei Cheng", "Xiaofei Xie", "Renzhi Wang", "Yuan Zhou", "Ming Hu"], "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due\nto the inherent limitations in their design and performance capabilities.\nOnline repair plays a crucial role in mitigating such limitations, ensuring the\nruntime safety and reliability of ADSs. Existing online repair solutions\nenforce ADS compliance by transforming unacceptable trajectories into\nacceptable ones based on predefined specifications, such as rule-based\nconstraints or training datasets. However, these approaches often lack\ngeneralizability, adaptability and tend to be overly conservative, resulting in\nineffective repairs that not only fail to mitigate safety risks sufficiently\nbut also degrade the overall driving experience. To address this issue, we\npropose Adaptive Decision Repair (ADReFT), a novel and effective repair method\nthat identifies safety-critical states through offline learning from failed\ntests and generates appropriate mitigation actions to improve ADS safety.\nSpecifically, ADReFT incorporates a transformer-based model with two joint\nheads, State Monitor and Decision Adapter, designed to capture complex driving\nenvironment interactions to evaluate state safety severity and generate\nadaptive repair actions. Given the absence of oracles for state safety\nidentification, we first pretrain ADReFT using supervised learning with coarse\nannotations, i.e., labeling states preceding violations as positive samples and\nothers as negative samples. It establishes ADReFT's foundational capability to\nmitigate safety-critical violations, though it may result in somewhat\nconservative mitigation strategies. Therefore, we subsequently finetune ADReFT\nusing reinforcement learning to improve its initial capability and generate\nmore precise and contextually appropriate repair decisions. Our evaluation\nresults illustrate that ADReFT achieves better repair performance.", "AI": {"tldr": "ADReFT is a repair system for autonomous driving systems focused on safety and reliability using a transformer-based model.", "motivation": "Existing online repair solutions for ADSs are too conservative and lack adaptability and generalizability, which limits their effectiveness in mitigating safety risks while preserving driving quality.", "method": "ADReFT uses a transformer-based model with two heads\u2014State Monitor and Decision Adapter\u2014for offline learning and adaptive repair. It is trained initially with supervised learning and fine-tuned using reinforcement learning.", "result": "ADReFT identifies safety-critical states and generates appropriate repair decisions with improved precision and performance over traditional approaches.", "conclusion": "ADReFT enhances the safety and reliability of ADSs through contextually appropriate repair strategies and avoids the limitations of overly conservative approaches."}}
{"id": "2506.22978", "pdf": "https://arxiv.org/pdf/2506.22978", "abs": "https://arxiv.org/abs/2506.22978", "authors": ["Yida Zhao", "Hao Xve", "Xiang Hu", "Kewei Tu"], "title": "A Systematic Study of Compositional Syntactic Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Syntactic language models (SLMs) enhance Transformers by incorporating\nsyntactic biases through the modeling of linearized syntactic parse trees\nalongside surface sentences. This paper focuses on compositional SLMs that are\nbased on constituency parse trees and contain explicit bottom-up composition of\nconstituent representations. We identify key aspects of design choices in\nexisting compositional SLMs and propose a unified framework encompassing both\nexisting models and novel variants. We conduct a comprehensive empirical\nevaluation of all the variants in our framework across language modeling,\nsyntactic generalization, summarization, dialogue, and inference efficiency.\nBased on the experimental results, we make multiple recommendations on the\ndesign of compositional SLMs. Our code is released at\nhttps://github.com/zhaoyd1/compositional_SLMs.", "AI": {"tldr": "The paper investigates compositional syntactic language models (SLMs), proposes a unified design framework, evaluates it across various tasks, and provides recommendations for optimizing such models.", "motivation": "To improve language models by introducing compositional syntactic biases via linearized constituency parse trees.", "method": "The authors devised a unified framework for compositional SLM design based on parse trees and benchmarked their performance across diverse NLP tasks.", "result": "Findings show distinctions between model variants, influencing recommendations for optimal design in compositional SLMs.", "conclusion": "The paper establishes a unified framework for SLMs, demonstrates their applicability across tasks, and provides guidelines to enhance their performance."}}
{"id": "2506.23433", "pdf": "https://arxiv.org/pdf/2506.23433", "abs": "https://arxiv.org/abs/2506.23433", "authors": ["Tim Puphal", "Vipul Ramtekkar", "Kenji Nishimiya"], "title": "Risk-Based Filtering of Valuable Driving Situations in the Waymo Open Motion Dataset", "categories": ["cs.RO"], "comment": null, "summary": "Improving automated vehicle software requires driving data rich in valuable\nroad user interactions. In this paper, we propose a risk-based filtering\napproach that helps identify such valuable driving situations from large\ndatasets. Specifically, we use a probabilistic risk model to detect high-risk\nsituations. Our method stands out by considering a) first-order situations\n(where one vehicle directly influences another and induces risk) and b)\nsecond-order situations (where influence propagates through an intermediary\nvehicle). In experiments, we show that our approach effectively selects\nvaluable driving situations in the Waymo Open Motion Dataset. Compared to the\ntwo baseline interaction metrics of Kalman difficulty and Tracks-To-Predict\n(TTP), our filtering approach identifies complex and complementary situations,\nenriching the quality in automated vehicle testing. The risk data is made\nopen-source: https://github.com/HRI-EU/RiskBasedFiltering.", "AI": {"tldr": "The paper proposes a risk-based filtering method to identify valuable driving situations in large datasets, leveraging a probabilistic risk model to consider direct and indirect vehicle interactions.", "motivation": "Enhance the improvement of automated vehicle software by utilizing driving data with significant road user interactions.", "method": "A probabilistic risk model is employed to detect high-risk situations, accounting for both first-order and second-order interactions between vehicles.", "result": "Experiments show effectiveness of the approach in identifying complex driving situations, outperforming baseline interaction metrics with enriched data quality.", "conclusion": "The filtering method proves to be a powerful tool for better automated vehicle testing, and the risk data is made publicly available."}}
{"id": "2506.23576", "pdf": "https://arxiv.org/pdf/2506.23576", "abs": "https://arxiv.org/abs/2506.23576", "authors": ["Maria Carolina Cornelia Wit", "Jun Pang"], "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "categories": ["cs.AI"], "comment": "26 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have raised concerns about\njailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper\ninvestigates the use of multi-agent LLM systems as a defence against such\nattacks. We evaluate three jailbreaking strategies, including the original\nAutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the\nAutoDefense framework, we compare single-agent setups with two- and three-agent\nconfigurations. Our results show that multi-agent systems enhance resistance to\njailbreaks, especially by reducing false negatives. However, its effectiveness\nvaries by attack type, and it introduces trade-offs such as increased false\npositives and computational overhead. These findings point to the limitations\nof current automated defences and suggest directions for improving alignment\nrobustness in future LLM systems.", "AI": {"tldr": "This paper explores multi-agent systems to combat LLM jailbreaking attacks and identifies their strengths and trade-offs.", "motivation": "To address concerns about LLM jailbreaking attacks and explore improving safety mechanisms by leveraging multi-agent systems.", "method": "The paper reproduces the AutoDefense framework and evaluates single-agent, two-agent, and three-agent setups against three jailbreak strategies: AutoDefense, BetterDan, and JB.", "result": "Multi-agent systems reduce jailbreaking attacks, particularly false negatives, but are less effective for some attacks and cause increased false positives and higher computational costs.", "conclusion": "Multi-agent setups improve defence robustness but have limitations, highlighting the need for refined approaches to strengthen LLM alignment and safety."}}
{"id": "2506.23186", "pdf": "https://arxiv.org/pdf/2506.23186", "abs": "https://arxiv.org/abs/2506.23186", "authors": ["Marco Bressan", "Victor Chepoi", "Emmanuel Esposito", "Maximilian Thiessen"], "title": "Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs", "categories": ["cs.LG", "cs.DM", "math.CO", "stat.ML"], "comment": null, "summary": "Abstract notions of convexity over the vertices of a graph, and corresponding\nnotions of halfspaces, have recently gained attention from the machine learning\ncommunity. In this work we study monophonic halfspaces, a notion of graph\nhalfspaces defined through closure under induced paths. Our main result is a\n$2$-satisfiability based decomposition theorem, which allows one to represent\nmonophonic halfspaces as a disjoint union of certain vertex subsets. Using this\ndecomposition, we achieve efficient and (nearly) optimal algorithms for various\nlearning problems, such as teaching, active, and online learning. Most notably,\nwe obtain a polynomial-time algorithm for empirical risk minimization.\nIndependently of the decomposition theorem, we obtain an efficient, stable, and\nproper sample compression scheme. This makes monophonic halfspaces efficiently\nlearnable with proper learners and linear error rate $1/\\varepsilon$ in the\nrealizable PAC setting. Our results answer open questions from the literature,\nand show a stark contrast with geodesic halfspaces, for which most of the said\nlearning problems are NP-hard.", "AI": {"tldr": "The paper introduces monophonic halfspaces on graph vertices and provides efficient algorithms for learning tasks, contrasting them with geodesic halfspaces.", "motivation": "To explore efficient algorithms for learning problems using graph-based notions of convexity, focusing on monophonic halfspaces.", "method": "Developed a 2-satisfiability-based decomposition theorem to represent monophonic halfspaces as disjoint vertex subsets and designed efficient learning algorithms.", "result": "Achieved efficient solutions for teaching, active, and online learning, including a polynomial-time algorithm for empirical risk minimization and a stable sample compression scheme.", "conclusion": "Monophonic halfspaces are efficiently learnable with proper learners at a linear error rate under the PAC setting, answering open questions and distinguishing them from NP-hard geodesic halfspaces."}}
{"id": "2506.22809", "pdf": "https://arxiv.org/pdf/2506.22809", "abs": "https://arxiv.org/abs/2506.22809", "authors": ["Cooper Doyle"], "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages, 3 figures, 1 table", "summary": "We propose BayesLoRA, a task-specific uncertainty quantification framework\nthat integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike\ngeneral-purpose transformer uncertainty methods, BayesLoRA provides guardrails\ntailored to downstream workflows, enabling agents to introspect and modulate\nbehavior under uncertainty. We demonstrate mathematically and empirically that\nLoRA adapters exhibit amplified variance outside fine-tuning distributions,\nyielding reliable confidence estimates for agentic decision-making.", "AI": {"tldr": "BayesLoRA introduces a task-specific scheme to quantify uncertainty in LoRA frameworks using MC-Dropout, allowing better decision-making. It shows amplified variance outside fine-tuning distributions.", "motivation": "Existing transformer-based uncertainty quantification methods aren't specialized for task-specific guardrails or downstream applications, and improvements can enhance agent behavior under uncertainty conditions.", "method": "BayesLoRA integrates Monte Carlo (MC)-Dropout mechanisms within LoRA, aiming for uncertainty quantification specialized for fine-tuning workflows.", "result": "The implementation exhibited amplified variance outside fine-tuning distributions mathematically and empirically, leading to reliable confidence measures.", "conclusion": "BayesLoRA effectively provides tools for task-specific uncertainty management, facilitating robust and adaptable behavior from agents."}}
{"id": "2506.22718", "pdf": "https://arxiv.org/pdf/2506.22718", "abs": "https://arxiv.org/abs/2506.22718", "authors": ["Jun-Jee Chao", "Qingyuan Jiang", "Volkan Isler"], "title": "Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians", "categories": ["cs.CV"], "comment": null, "summary": "Part segmentation and motion estimation are two fundamental problems for\narticulated object motion analysis. In this paper, we present a method to solve\nthese two problems jointly from a sequence of observed point clouds of a single\narticulated object. The main challenge in our problem setting is that the point\nclouds are not assumed to be generated by a fixed set of moving points.\nInstead, each point cloud in the sequence could be an arbitrary sampling of the\nobject surface at that particular time step. Such scenarios occur when the\nobject undergoes major occlusions, or if the dataset is collected using\nmeasurements from multiple sensors asynchronously. In these scenarios, methods\nthat rely on tracking point correspondences are not appropriate. We present an\nalternative approach based on a compact but effective representation where we\nrepresent the object as a collection of simple building blocks modeled as 3D\nGaussians. We parameterize the Gaussians with time-dependent rotations,\ntranslations, and scales that are shared across all time steps. With our\nrepresentation, part segmentation can be achieved by building correspondences\nbetween the observed points and the Gaussians. Moreover, the transformation of\neach point across time can be obtained by following the poses of the assigned\nGaussian (even when the point is not observed). Experiments show that our\nmethod outperforms existing methods that solely rely on finding point\ncorrespondences. Additionally, we extend existing datasets to emulate\nreal-world scenarios by considering viewpoint occlusions. We further\ndemonstrate that our method is more robust to missing points as compared to\nexisting approaches on these challenging datasets, even when some parts are\ncompletely occluded in some time-steps. Notably, our part segmentation\nperformance outperforms the state-of-the-art method by 13% on point clouds with\nocclusions.", "AI": {"tldr": "This paper introduces a new method for joint part segmentation and motion estimation of articulated objects from point cloud sequences, utilizing a Gaussian-based representation instead of tracking point correspondences.", "motivation": "Address the challenge of analyzing articulated object motion when point clouds are arbitrary samples, making point correspondence-based methods ineffective, especially in cases with occlusions or asynchronous sensors.", "method": "Represent the object using time-dependent 3D Gaussians characterized by rotations, translations, and scales. Part segmentation is achieved via correspondences between observed points and Gaussians, and motion estimation follows Gaussian transformations.", "result": "The proposed method outperforms traditional point-correspondence-based methods, achieving a 13% improvement in part segmentation on occluded point cloud datasets, and demonstrates robustness in handling missing data.", "conclusion": "The Gaussian-based approach improves articulated object motion analysis under challenging conditions such as occlusions or asynchronous data, offering significant advantages over state-of-the-art methods."}}
{"id": "2506.23046", "pdf": "https://arxiv.org/pdf/2506.23046", "abs": "https://arxiv.org/abs/2506.23046", "authors": ["Xianzhe Fan", "Xuhui Zhou", "Chuanyang Jin", "Kolby Nottingham", "Hao Zhu", "Maarten Sap"], "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.RO"], "comment": "23 pages, 6 figures", "summary": "Humans continuously infer the states, goals, and behaviors of others by\nperceiving their surroundings in dynamic, real-world social interactions.\nHowever, most Theory of Mind (ToM) benchmarks only evaluate static, text-based\nscenarios, which have a significant gap compared to real interactions. We\npropose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in\nembodied multi-agent complex social interactions. This benchmark is based on\nrich multimodal interaction data generated by the interaction environment SoMi,\ncovering diverse crafting goals and social relationships. Our framework\nsupports multi-level evaluation: (1) first-person evaluation provides\nmultimodal (visual, dialogue, action, etc.) input from a first-person\nperspective during a task for real-time state inference, (2) third-person\nevaluation provides complete third-person perspective video and text records\nafter a task for goal and behavior inference. This evaluation method allows for\na more comprehensive examination of a model's ToM capabilities from both the\nsubjective immediate experience and the objective global observation. We\nconstructed a challenging dataset containing 35 third-person perspective\nvideos, 363 first-person perspective images, and 1225 expert-annotated\nmultiple-choice questions (three options). On this dataset, we systematically\nevaluated the performance of human subjects and several state-of-the-art large\nvision-language models (LVLMs). The results show that LVLMs perform\nsignificantly worse than humans on SoMi-ToM: the average accuracy gap between\nhumans and models is 40.1% in first-person evaluation and 26.4% in third-person\nevaluation. This indicates that future LVLMs need to further improve their ToM\ncapabilities in embodied, complex social interactions.", "AI": {"tldr": "The study introduces the SoMi-ToM benchmark for evaluating Theory of Mind (ToM) in dynamic, multimodal, social interactions using both first- and third-person perspectives, revealing a notable performance gap between humans and state-of-the-art models.", "motivation": "Existing ToM benchmarks primarily focus on static, text-based scenarios, which do not sufficiently represent real-world dynamic social interactions. The researchers aim to address this gap.", "method": "The SoMi-ToM benchmark evaluates ToM through multimodal first-person and third-person perspectives using a dataset generated by the SoMi interaction environment. It includes annotated questions and a structured evaluation framework.", "result": "Human subjects significantly outperform state-of-the-art large vision-language models (LVLMs), with accuracy gaps of 40.1% in first-person evaluations and 26.4% in third-person evaluations.", "conclusion": "Current LVLMs have limitations in handling complex, embodied social interactions. Future models must enhance their ToM capabilities to better represent human-like understanding in dynamic settings."}}
{"id": "2506.23514", "pdf": "https://arxiv.org/pdf/2506.23514", "abs": "https://arxiv.org/abs/2506.23514", "authors": ["Sai Krishna Ghanta", "Ramviyas Parasuraman"], "title": "MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "Accepted to IROS 2025", "summary": "Relative localization is a crucial capability for multi-robot systems\noperating in GPS-denied environments. Existing approaches for multi-robot\nrelative localization often depend on costly or short-range sensors like\ncameras and LiDARs. Consequently, these approaches face challenges such as high\ncomputational overhead (e.g., map merging) and difficulties in disjoint\nenvironments. To address this limitation, this paper introduces MGPRL, a novel\ndistributed framework for multi-robot relative localization using convex-hull\nof multiple Wi-Fi access points (AP). To accomplish this, we employ\nco-regionalized multi-output Gaussian Processes for efficient Radio Signal\nStrength Indicator (RSSI) field prediction and perform uncertainty-aware\nmulti-AP localization, which is further coupled with weighted convex hull-based\nalignment for robust relative pose estimation. Each robot predicts the RSSI\nfield of the environment by an online scan of APs in its environment, which are\nutilized for position estimation of multiple APs. To perform relative\nlocalization, each robot aligns the convex hull of its predicted AP locations\nwith that of the neighbor robots. This approach is well-suited for devices with\nlimited computational resources and operates solely on widely available Wi-Fi\nRSSI measurements without necessitating any dedicated pre-calibration or\noffline fingerprinting. We rigorously evaluate the performance of the proposed\nMGPRL in ROS simulations and demonstrate it with real-world experiments,\ncomparing it against multiple state-of-the-art approaches. The results showcase\nthat MGPRL outperforms existing methods in terms of localization accuracy and\ncomputational efficiency. Finally, we open source MGPRL as a ROS package\nhttps://github.com/herolab-uga/MGPRL.", "AI": {"tldr": "This paper presents MGPRL, a novel distributed framework for multi-robot relative localization using Wi-Fi RSSI signals and convex hull-based estimation, providing high accuracy and computational efficiency, suitable for GPS-denied and resource-limited environments.", "motivation": "To address the limitations of existing multi-robot relative localization systems, which rely on costly, short-range sensors like cameras or LiDARs, leading to high computational overhead and challenges in disjoint environments.", "method": "The authors develop MGPRL, leveraging co-regionalized multi-output Gaussian Processes for RSSI field prediction, uncertainty-aware multi-AP localization, and convex hull-based alignment for relative pose estimation. This process uses Wi-Fi RSSI signals and requires no pre-calibration or offline fingerprinting.", "result": "MGPRL was evaluated in simulations and real-world experiments against state-of-the-art methods, demonstrating better localization accuracy and computational efficiency.", "conclusion": "MGPRL offers a computationally efficient and accurate solution for multi-robot relative localization in GPS-denied environments using ubiquitous Wi-Fi RSSI signals. The system is released as an open-source ROS package."}}
{"id": "2506.23626", "pdf": "https://arxiv.org/pdf/2506.23626", "abs": "https://arxiv.org/abs/2506.23626", "authors": ["Ant\u00f3nio Afonso", "Iolanda Leite", "Alessandro Sestini", "Florian Fuchs", "Konrad Tollmar", "Linus Gissl\u00e9n"], "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "categories": ["cs.AI"], "comment": "16 pages in total, 10 pages of main paper, 5 figures", "summary": "Reinforcement Learning (RL) in games has gained significant momentum in\nrecent years, enabling the creation of different agent behaviors that can\ntransform a player's gaming experience. However, deploying RL agents in\nproduction environments presents two key challenges: (1) designing an effective\nreward function typically requires an RL expert, and (2) when a game's content\nor mechanics are modified, previously tuned reward weights may no longer be\noptimal. Towards the latter challenge, we propose an automated approach for\niteratively fine-tuning an RL agent's reward function weights, based on a\nuser-defined language based behavioral goal. A Language Model (LM) proposes\nupdated weights at each iteration based on this target behavior and a summary\nof performance statistics from prior training rounds. This closed-loop process\nallows the LM to self-correct and refine its output over time, producing\nincreasingly aligned behavior without the need for manual reward engineering.\nWe evaluate our approach in a racing task and show that it consistently\nimproves agent performance across iterations. The LM-guided agents show a\nsignificant increase in performance from $9\\%$ to $74\\%$ success rate in just\none iteration. We compare our LM-guided tuning against a human expert's manual\nweight design in the racing task: by the final iteration, the LM-tuned agent\nachieved an $80\\%$ success rate, and completed laps in an average of $855$ time\nsteps, a competitive performance against the expert-tuned agent's peak $94\\%$\nsuccess, and $850$ time steps.", "AI": {"tldr": "The paper introduces an automated method to refine RL agent behaviors using a language model (LM) to tune reward function weights iteratively based on user-defined goals, reducing the need for manual engineering.", "motivation": "Production deployment of RL agents faces challenges such as the need for expert-designed reward functions and the potential misalignment of these reward weights after game changes.", "method": "The proposed method uses a language model (LM) to suggest updated reward function weights iteratively. It employs prior training performance statistics and user-defined goals to refine agent behavior in a closed-loop framework.", "result": "In a racing task evaluation, LM-guided agents improved significantly, achieving up to a 74% success rate in one iteration and reaching 80% by the final iteration, showing comparable performance to expert-designed reward systems.", "conclusion": "The approach demonstrates that LM-guided tuning can achieve competitive results in iterative RL optimization, reducing reliance on manual reward engineering and expert input."}}
{"id": "2506.23286", "pdf": "https://arxiv.org/pdf/2506.23286", "abs": "https://arxiv.org/abs/2506.23286", "authors": ["Alan Jeffares", "Mihaela van der Schaar"], "title": "Not All Explanations for Deep Learning Phenomena Are Equally Valuable", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025 for oral presentation", "summary": "Developing a better understanding of surprising or counterintuitive phenomena\nhas constituted a significant portion of deep learning research in recent\nyears. These include double descent, grokking, and the lottery ticket\nhypothesis -- among many others. Works in this area often develop ad hoc\nhypotheses attempting to explain these observed phenomena on an isolated,\ncase-by-case basis. This position paper asserts that, in many prominent cases,\nthere is little evidence to suggest that these phenomena appear in real-world\napplications and these efforts may be inefficient in driving progress in the\nbroader field. Consequently, we argue against viewing them as isolated puzzles\nthat require bespoke resolutions or explanations. However, despite this, we\nsuggest that deep learning phenomena do still offer research value by providing\nunique settings in which we can refine our broad explanatory theories of more\ngeneral deep learning principles. This position is reinforced by analyzing the\nresearch outcomes of several prominent examples of these phenomena from the\nrecent literature. We revisit the current norms in the research community in\napproaching these problems and propose practical recommendations for future\nresearch, aiming to ensure that progress on deep learning phenomena is well\naligned with the ultimate pragmatic goal of progress in the broader field of\ndeep learning.", "AI": {"tldr": "The paper critiques the focus on understanding isolated deep learning phenomena (e.g., double descent, grokking) and argues for leveraging them to refine broader deep learning theories.", "motivation": "To question the efficiency of addressing unique deep learning phenomena as isolated cases and align research efforts more closely with practical advancements in deep learning.", "method": "Analyzing outcomes from recent studies on deep learning phenomena and revisiting research norms to propose practical recommendations.", "result": "The paper highlights inefficiencies in isolated studies of deep learning phenomena while emphasizing their potential for enhancing general theories.", "conclusion": "Deep learning phenomena should not merely be treated as puzzles but rather as opportunities to refine broad explanatory theories, thereby advancing the overall field of deep learning."}}
{"id": "2506.22821", "pdf": "https://arxiv.org/pdf/2506.22821", "abs": "https://arxiv.org/abs/2506.22821", "authors": ["Thomas Gaskin", "Guy J. Abel"], "title": "Deep learning 40 years of human migration", "categories": ["cs.LG", "68T07", "I.2.6"], "comment": null, "summary": "We present a novel and detailed dataset on origin-destination annual\nmigration flows and stocks between 230 countries and regions, spanning the\nperiod from 1990 to the present. Our flow estimates are further disaggregated\nby country of birth, providing a comprehensive picture of migration over the\nlast 43 years. The estimates are obtained by training a deep recurrent neural\nnetwork to learn flow patterns from 18 covariates for all countries, including\ngeographic, economic, cultural, societal, and political information. The\nrecurrent architecture of the neural network means that the entire past can\ninfluence current migration patterns, allowing us to learn long-range temporal\ncorrelations. By training an ensemble of neural networks and additionally\npushing uncertainty on the covariates through the trained network, we obtain\nconfidence bounds for all our estimates, allowing researchers to pinpoint the\ngeographic regions most in need of additional data collection. We validate our\napproach on various test sets of unseen data, demonstrating that it\nsignificantly outperforms traditional methods estimating five-year flows while\ndelivering a significant increase in temporal resolution. The model is fully\nopen source: all training data, neural network weights, and training code are\nmade public alongside the migration estimates, providing a valuable resource\nfor future studies of human migration.", "AI": {"tldr": "A novel dataset of global migration flows and stocks (1990\u2013present) disaggregated by country of birth, developed using a deep recurrent neural network to analyze 18 covariates with validation and open access availability.", "motivation": "The study aims to provide a comprehensive and detailed understanding of global migration patterns over the past four decades by leveraging advanced machine learning techniques while addressing data limitations and uncertainties.", "method": "A deep recurrent neural network ensemble was trained on 18 covariates (geographic, economic, cultural, societal, and political) to estimate migration flows and stocks over time. It includes uncertainty modeling and provides confidence bounds through ensemble methods.", "result": "The model achieved a significant improvement in estimating migration flows, with increased temporal resolution, outperforming traditional methods on various unseen datasets. It also identifies geographic regions needing more data collection.", "conclusion": "The dataset and model offer a rich resource for migration studies, enabling more accurate and granular analysis. The authors provide open access to training data, code, and model weights to encourage further research."}}
{"id": "2506.22720", "pdf": "https://arxiv.org/pdf/2506.22720", "abs": "https://arxiv.org/abs/2506.22720", "authors": ["Jinghao Wang", "Zhang Li", "Zi Wang", "Banglei Guan", "Yang Shang", "Qifeng Yu"], "title": "Deterministic Object Pose Confidence Region Estimation", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "6D pose confidence region estimation has emerged as a critical direction,\naiming to perform uncertainty quantification for assessing the reliability of\nestimated poses. However, current sampling-based approach suffers from critical\nlimitations that severely impede their practical deployment: 1) the sampling\nspeed significantly decreases as the number of samples increases. 2) the\nderived confidence regions are often excessively large. To address these\nchallenges, we propose a deterministic and efficient method for estimating pose\nconfidence regions. Our approach uses inductive conformal prediction to\ncalibrate the deterministically regressed Gaussian keypoint distributions into\n2D keypoint confidence regions. We then leverage the implicit function theorem\nto propagate these keypoint confidence regions directly into 6D pose confidence\nregions. This method avoids the inefficiency and inflated region sizes\nassociated with sampling and ensembling. It provides compact confidence regions\nthat cover the ground-truth poses with a user-defined confidence level.\nExperimental results on the LineMOD Occlusion and SPEED datasets show that our\nmethod achieves higher pose estimation accuracy with reduced computational\ntime. For the same coverage rate, our method yields significantly smaller\nconfidence region volumes, reducing them by up to 99.9\\% for rotations and\n99.8\\% for translations. The code will be available soon.", "AI": {"tldr": "This paper proposes an efficient deterministic method to estimate 6D pose confidence regions by leveraging inductive conformal prediction and the implicit function theorem, resulting in more compact yet reliable regions.", "motivation": "The need for accurately quantifying the reliability of estimated 6D poses has risen, but existing sampling-based methods face severe limitations such as slow sampling speed and overly inflated confidence regions.", "method": "The authors use inductive conformal prediction to calibrate deterministically regressed 2D keypoint confidence regions and propagate them into 6D pose confidence regions using the implicit function theorem. This eliminates the need for slow sampling and ensembling methods.", "result": "The proposed method achieves higher pose estimation accuracy with reduced computational time. On LineMOD Occlusion and SPEED datasets, it achieves compact confidence regions while maintaining coverage rates, reducing region volumes by up to 99.9% for rotations and 99.8% for translations.", "conclusion": "The proposed approach provides an efficient solution for generating reliable and compact 6D pose confidence regions, making it better suited for practical deployment compared to current methods."}}
{"id": "2506.23051", "pdf": "https://arxiv.org/pdf/2506.23051", "abs": "https://arxiv.org/abs/2506.23051", "authors": ["Jo\u00e3o Lucas Luz Lima Sarcinelli", "Marina Lages Gon\u00e7alves Teixeira", "Jade Bortot de Paiva", "Diego Furtado Silva"], "title": "MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition", "categories": ["cs.CL"], "comment": null, "summary": "Named Entity Recognition (NER) is a fundamental Natural Language Processing\n(NLP) task that aims to identify and classify entity mentions in texts across\ndifferent categories. While languages such as English possess a large number of\nhigh-quality resources for this task, Brazilian Portuguese still lacks in\nquantity of gold-standard NER datasets, especially when considering specific\ndomains. Particularly, this paper considers the importance of NER for analyzing\nhistorical texts in the context of digital humanities. To address this gap,\nthis work outlines the construction of MariNER: \\textit{Mapeamento e\nAnota\\c{c}\\~oes de Registros hIst\\'oricos para NER} (Mapping and Annotation of\nHistorical Records for NER), the first gold-standard dataset for early\n20th-century Brazilian Portuguese, with more than 9,000 manually annotated\nsentences. We also assess and compare the performance of state-of-the-art NER\nmodels for the dataset.", "AI": {"tldr": "NER is essential in NLP but lacks resources for Brazilian Portuguese in specific domains. This paper introduces \"MariNER,\" a gold-standard dataset with annotated historical sentences for early 20th-century Brazilian Portuguese.", "motivation": "The motivation is to address the scarcity of high-quality NER datasets for Brazilian Portuguese, especially focusing on historical texts to support digital humanities research.", "method": "The authors created \"MariNER,\" a gold-standard dataset of manually annotated sentences from historical records. They also evaluated state-of-the-art NER models on this dataset.", "result": "The work produced a dataset of over 9,000 annotated sentences for Brazilian Portuguese and performed a comparative evaluation of NER models on this resource.", "conclusion": "The paper fills a crucial gap in NER resources for Brazilian Portuguese and provides a valuable tool for digital humanities and NLP research focused on historical texts."}}
{"id": "2506.23573", "pdf": "https://arxiv.org/pdf/2506.23573", "abs": "https://arxiv.org/abs/2506.23573", "authors": ["Siddhartha Mondal", "Avik Mitra", "Chayan Sarkar"], "title": "Online Human Action Detection during Escorting", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE RO-MAN '25", "summary": "The deployment of robot assistants in large indoor spaces has seen\nsignificant growth, with escorting tasks becoming a key application. However,\nmost current escorting robots primarily rely on navigation-focused strategies,\nassuming that the person being escorted will follow without issue. In crowded\nenvironments, this assumption often falls short, as individuals may struggle to\nkeep pace, become obstructed, get distracted, or need to stop unexpectedly. As\na result, conventional robotic systems are often unable to provide effective\nescorting services due to their limited understanding of human movement\ndynamics. To address these challenges, an effective escorting robot must\ncontinuously detect and interpret human actions during the escorting process\nand adjust its movement accordingly. However, there is currently no existing\ndataset designed specifically for human action detection in the context of\nescorting. Given that escorting often occurs in crowded environments, where\nother individuals may enter the robot's camera view, the robot also needs to\nidentify the specific human it is escorting (the subject) before predicting\ntheir actions. Since no existing model performs both person re-identification\nand action prediction in real-time, we propose a novel neural network\narchitecture that can accomplish both tasks. This enables the robot to adjust\nits speed dynamically based on the escortee's movements and seamlessly resume\nescorting after any disruption. In comparative evaluations against strong\nbaselines, our system demonstrates superior efficiency and effectiveness,\nshowcasing its potential to significantly improve robotic escorting services in\ncomplex, real-world scenarios.", "AI": {"tldr": "The paper introduces a novel neural network architecture to improve robotic escorting services in crowded indoor environments, enabling real-time person re-identification and human action prediction.", "motivation": "Current robotic escorting systems struggle in crowded environments due to limited understanding of human movement dynamics, lacking abilities to detect and interpret human actions or disruptions effectively.", "method": "A new neural network architecture is proposed that combines person re-identification with action prediction, enabling real-time adjustments to escorting robots' behavior.", "result": "Comparative evaluations against baseline systems show that the proposed model is more efficient and effective in handling escorting tasks in complex environments.", "conclusion": "The system demonstrates significant potential for improving robotic escorting services in real-world crowded indoor settings."}}
{"id": "2506.23673", "pdf": "https://arxiv.org/pdf/2506.23673", "abs": "https://arxiv.org/abs/2506.23673", "authors": ["Jingsong Liu", "Han Li", "Chen Yang", "Michael Deutges", "Ario Sadafi", "Xin You", "Katharina Breininger", "Nassir Navab", "Peter J. Sch\u00fcffler"], "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "categories": ["cs.AI"], "comment": null, "summary": "Domain shift is a critical problem for pathology AI as pathology data is\nheavily influenced by center-specific conditions. Current pathology domain\nadaptation methods focus on image patches rather than WSI, thus failing to\ncapture global WSI features required in typical clinical scenarios. In this\nwork, we address the challenges of slide-level domain shift by proposing a\nHierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD\nachieves multi-scale feature consistency and computationally efficient\nslide-level domain adaptation through two key components: (1) a hierarchical\nadaptation framework that integrates a Domain-level Alignment Solver for\nfeature alignment, a Slide-level Geometric Invariance Regularization to\npreserve the morphological structure, and a Patch-level Attention Consistency\nRegularization to maintain local critical diagnostic cues; and (2) a prototype\nselection mechanism that reduces computational overhead. We validate our method\non two slide-level tasks across five datasets, achieving a 4.1\\% AUROC\nimprovement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in\na UCEC survival prediction cohort. Our method provides a practical and reliable\nslide-level domain adaption solution for pathology institutions, minimizing\nboth computational and annotation costs.", "AI": {"tldr": "The paper proposes \"Hierarchical Adaptation framework for Slide-level Domain-shift\" (HASD) to tackle domain shift for pathology AI by addressing slide-level challenges, achieving improved outcomes on HER2 grading and survival prediction tasks.", "motivation": "Pathology AI systems face domain shift challenges due to center-specific conditions, impacting reliable performance. Existing methods mainly focus on image patches rather than capturing global slide-level features as required in clinical practice.", "method": "HASD addresses slide-level domain shift using a hierarchical adaptation framework with three modules: Domain-level Alignment Solver for feature alignment, Slide-level Geometric Invariance Regularization to maintain morphological structures, and Patch-level Attention Consistency Regularization for preserving diagnostic cues. Additionally, it includes a prototype selection mechanism to reduce computational costs.", "result": "HASD demonstrated significant improvements on two slide-level tasks, achieving a 4.1% AUROC boost in a Breast Cancer HER2 Grading cohort and a 3.9% C-index gain in a UCEC survival prediction cohort across five datasets.", "conclusion": "The proposed HASD method effectively addresses slide-level domain adaptation in pathology AI with enhanced performance on multi-scale tasks while reducing computational and annotation costs."}}
{"id": "2506.23344", "pdf": "https://arxiv.org/pdf/2506.23344", "abs": "https://arxiv.org/abs/2506.23344", "authors": ["Difeng Cai", "Paulina Sep\u00falveda"], "title": "Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "The appearance of singularities in the function of interest constitutes a\nfundamental challenge in scientific computing. It can significantly undermine\nthe effectiveness of numerical schemes for function approximation, numerical\nintegration, and the solution of partial differential equations (PDEs), etc.\nThe problem becomes more sophisticated if the location of the singularity is\nunknown, which is often encountered in solving PDEs. Detecting the singularity\nis therefore critical for developing efficient adaptive methods to reduce\ncomputational costs in various applications. In this paper, we consider\nsingularity detection in a purely data-driven setting. Namely, the input only\ncontains given data, such as the vertex set from a mesh. To overcome the\nlimitation of the raw unlabeled data, we propose a self-supervised learning\n(SSL) framework for estimating the location of the singularity. A key component\nis a filtering procedure as the pretext task in SSL, where two filtering\nmethods are presented, based on $k$ nearest neighbors and kernel density\nestimation, respectively. We provide numerical examples to illustrate the\npotential pathological or inaccurate results due to the use of raw data without\nfiltering. Various experiments are presented to demonstrate the ability of the\nproposed approach to deal with input perturbation, label corruption, and\ndifferent kinds of singularities such interior circle, boundary layer,\nconcentric semicircles, etc.", "AI": {"tldr": "The paper addresses challenges in detecting singularities in scientific computing and introduces a self-supervised learning framework to estimate singularity locations using unlabeled data.", "motivation": "Singularities pose a major challenge in scientific computing, as they can reduce the efficiency of numerical schemes. This problem worsens when singularity locations are unknown, demanding adaptive methods to optimize computational costs.", "method": "The paper proposes a self-supervised learning framework utilizing a filtering procedure as a pretext task, with two specific filtering methods: $k$ nearest neighbors and kernel density estimation, enabling effective singularity location estimation.", "result": "Numerical examples demonstrate the issues of raw data usage and highlight the approach's robustness against input perturbations, label corruption, and varying singularity types like interior circles and boundary layers.", "conclusion": "The proposed SSL framework successfully addresses the singularity detection challenge, offering a data-driven solution that enhances adaptive numerical methods in scientific computing."}}
{"id": "2506.22837", "pdf": "https://arxiv.org/pdf/2506.22837", "abs": "https://arxiv.org/abs/2506.22837", "authors": ["Kamil Faber", "Marcin Pietro\u0144", "Dominik \u017burek", "Roberto Corizzo"], "title": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The recently proposed xLSTM is a powerful model that leverages expressive\nmultiplicative gating and residual connections, providing the temporal capacity\nneeded for long-horizon forecasting and representation learning. This\narchitecture has demonstrated success in time series forecasting, lossless\ncompression, and even large-scale language modeling tasks, where its linear\nmemory footprint and fast inference make it a viable alternative to\nTransformers. Despite its growing popularity, no prior work has explored xLSTM\nfor anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the\nfirst anomaly detection method that integrates a full encoder-decoder xLSTM\narchitecture, purpose-built for multivariate time series data. Our encoder\nprocesses input sequences to capture historical context, while the decoder is\ndevised in two separate variants of the method. In the forecasting approach,\nthe decoder iteratively generates forecasted future values xLSTMAD-F, while the\nreconstruction approach reconstructs the input time series from its encoded\ncounterpart xLSTMAD-R. We investigate the performance of two loss functions:\nMean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider\nlocal reconstruction fidelity and global sequence alignment, respectively. We\nevaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17\nreal-world datasets, using state-of-the-art challenging metrics such as VUS-PR.\nIn our results, xLSTM showcases state-of-the-art accuracy, outperforming 23\npopular anomaly detection baselines. Our paper is the first work revealing the\npowerful modeling capabilities of xLSTM for anomaly detection, paving the way\nfor exciting new developments on this subject. Our code is available at:\nhttps://github.com/Nyderx/xlstmad", "AI": {"tldr": "The paper introduces xLSTMAD, leveraging xLSTM for anomaly detection in multivariate time series, achieving state-of-the-art results.", "motivation": "The paper seeks to address the unexplored application of xLSTM in anomaly detection, particularly due to its success in time series tasks and the lack of prior work in this domain.", "method": "The authors propose xLSTMAD with an encoder-decoder architecture for multivariate time series. They evaluate two methods: forecasting (xLSTMAD-F) and reconstruction (xLSTMAD-R), leveraging Mean Squared Error (MSE) and Soft Dynamic Time Warping (SoftDTW) as loss functions.", "result": "xLSTMAD surpasses 23 existing anomaly detection techniques on the TSB-AD-M benchmark across 17 datasets, achieving state-of-the-art accuracy using VUS-PR metrics.", "conclusion": "The research demonstrates xLSTM's strong potential in anomaly detection and opens avenues for further innovations. The authors release the code for broader use and validation."}}
{"id": "2506.22726", "pdf": "https://arxiv.org/pdf/2506.22726", "abs": "https://arxiv.org/abs/2506.22726", "authors": ["Yu Zhang", "Xi Zhang", "Hualin zhou", "Xinyuan Chen", "Shang Gao", "Hong Jia", "Jianfei Yang", "Yuankai Qi", "Tao Gu"], "title": "XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning for human sensing on edge systems offers significant\nopportunities for smart applications. However, its training and development are\nhindered by the limited availability of sensor data and resource constraints of\nedge systems. Current methods that rely on transferring pre-trained models\noften encounter issues such as modality shift and high resource demands,\nresulting in substantial accuracy loss, resource overhead, and poor\nadaptability across different sensing applications. In this paper, we propose\nXTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic\nmodel transfer. XTransfer freely leverages single or multiple pre-trained\nmodels and transfers knowledge across different modalities by (i) model\nrepairing that safely repairs modality shift in pre-trained model layers with\nonly few sensor data, and (ii) layer recombining that efficiently searches and\nrecombines layers of interest from source models in a layer-wise manner to\ncreate compact models. We benchmark various baselines across diverse human\nsensing datasets spanning different modalities. Comprehensive results\ndemonstrate that XTransfer achieves state-of-the-art performance on human\nsensing tasks while significantly reducing the costs of sensor data collection,\nmodel training, and edge deployment.", "AI": {"tldr": "The paper introduces XTransfer, a method for efficient, modality-agnostic model transfer suitable for edge systems by addressing limitations in current deep learning practices for human sensing.", "motivation": "To overcome limitations in current methods for deep learning on edge systems, such as limited sensor data, resource constraints, and challenges like modality shift, which hinder performance and adaptability across human sensing applications.", "method": "XTransfer involves two novel steps: model repairing to address modality shift in pre-trained layers with minimal sensor data and layer recombining to identify and assemble optimal layers from existing models for compact, efficient designs.", "result": "The proposed method achieves state-of-the-art performance across various human sensing datasets, reduces the need for sensor data, minimizes training costs, and improves edge system deployment efficiency.", "conclusion": "XTransfer fills a crucial gap by enabling resource-efficient, adaptable, and high-performing model transfer for human sensing tasks on edge systems."}}
{"id": "2506.23056", "pdf": "https://arxiv.org/pdf/2506.23056", "abs": "https://arxiv.org/abs/2506.23056", "authors": ["Xiang Zhuang", "Bin Wu", "Jiyu Cui", "Kehua Feng", "Xiaotong Li", "Huabin Xing", "Keyan Ding", "Qiang Zhang", "Huajun Chen"], "title": "Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning", "categories": ["cs.CL"], "comment": "ACL 2025 Main", "summary": "Molecular structure elucidation involves deducing a molecule's structure from\nvarious types of spectral data, which is crucial in chemical experimental\nanalysis. While large language models (LLMs) have shown remarkable proficiency\nin analyzing and reasoning through complex tasks, they still encounter\nsubstantial challenges in molecular structure elucidation. We identify that\nthese challenges largely stem from LLMs' limited grasp of specialized chemical\nknowledge. In this work, we introduce a Knowledge-enhanced reasoning framework\nfor Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search\nfor test-time scaling as a plugin. Specifically, we construct an external\nmolecular substructure knowledge base to extend the LLMs' coverage of the\nchemical structure space. Furthermore, we design a specialized\nmolecule-spectrum scorer to act as a reward model for the reasoning process,\naddressing the issue of inaccurate solution evaluation in LLMs. Experimental\nresults show that our approach significantly boosts performance, particularly\ngaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is\navailable at https://github.com/HICAI-ZJU/K-MSE.", "AI": {"tldr": "The paper presents K-MSE, a framework using external molecular knowledge and Monte Carlo Tree Search to enhance large language models for molecular structure elucidation, achieving over 20% performance improvement.", "motivation": "The aim is to overcome limitations of large language models in molecular structure elucidation, which largely stem from their lack of specialized chemical knowledge.", "method": "K-MSE integrates a molecular substructure knowledge base and a molecule-spectrum scorer, combined with Monte Carlo Tree Search for reasoning enhancements.", "result": "Experimental results demonstrate more than 20% performance improvement on both GPT-4o-mini and GPT-4o models using the proposed framework.", "conclusion": "The K-MSE framework effectively extends the capabilities of large language models, improving their proficiency in molecular structure elucidation through knowledge enhancement techniques."}}
{"id": "2506.23614", "pdf": "https://arxiv.org/pdf/2506.23614", "abs": "https://arxiv.org/abs/2506.23614", "authors": ["Jing Huang", "Hao Su", "Kwok Wai Samuel Au"], "title": "Passage-traversing optimal path planning with sampling-based algorithms", "categories": ["cs.RO", "cs.CG"], "comment": "30 pages, 22 figures, 6 tables, journal paper", "summary": "This paper introduces a new paradigm of optimal path planning, i.e.,\npassage-traversing optimal path planning (PTOPP), that optimizes paths'\ntraversed passages for specified optimization objectives. In particular, PTOPP\nis utilized to find the path with optimal accessible free space along its\nentire length, which represents a basic requirement for paths in robotics. As\npassages are places where free space shrinks and becomes constrained, the core\nidea is to leverage the path's passage traversal status to characterize its\naccessible free space comprehensively. To this end, a novel passage detection\nand free space decomposition method using proximity graphs is proposed,\nenabling fast detection of sparse but informative passages and environment\ndecompositions. Based on this preprocessing, optimal path planning with\naccessible free space objectives or constraints is formulated as PTOPP problems\ncompatible with sampling-based optimal planners. Then, sampling-based\nalgorithms for PTOPP, including their dependent primitive procedures, are\ndeveloped leveraging partitioned environments for fast passage traversal check.\nAll these methods are implemented and thoroughly tested for effectiveness and\nefficiency validation. Compared to existing approaches, such as clearance-based\nmethods, PTOPP demonstrates significant advantages in configurability, solution\noptimality, and efficiency, addressing prior limitations and incapabilities. It\nis believed to provide an efficient and versatile solution to accessible free\nspace optimization over conventional avenues and more generally, to a broad\nclass of path planning problems that can be formulated as PTOPP.", "AI": {"tldr": "This paper introduces passage-traversing optimal path planning (PTOPP) which optimizes paths' traversal through constrained passages using proximity graph-based methods.", "motivation": "The primary motivation is to address the limitations of existing clearance-based path planning methods by optimizing the accessible free space along the entire path for better efficiency and configurability.", "method": "A novel proximity graph-based method is proposed for detecting sparse but informative passages, followed by environment decomposition. These techniques are integrated into sampling-based algorithms for PTOPP to enable efficient path planning.", "result": "The proposed PTOPP approach demonstrates superior performance in terms of configurability, solution optimality, and efficiency when compared to traditional clearance-based methods.", "conclusion": "PTOPP provides a robust, versatile, and efficient solution to optimize the accessible free space, offering improvements over conventional path planning approaches and addressing broader path planning problems."}}
{"id": "2506.23689", "pdf": "https://arxiv.org/pdf/2506.23689", "abs": "https://arxiv.org/abs/2506.23689", "authors": ["Zihao Liu", "Xinhang Sui", "Yueran Song", "Siwen Wang"], "title": "Pok\u00e9AI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model\n(LLM) framework designed to autonomously play and progress through Pok\\'emon\nRed. Our system consists of three specialized agents-Planning, Execution, and\nCritique-each with its own memory bank, role, and skill set. The Planning Agent\nfunctions as the central brain, generating tasks to progress through the game.\nThese tasks are then delegated to the Execution Agent, which carries them out\nwithin the game environment. Upon task completion, the Critique Agent evaluates\nthe outcome to determine whether the objective was successfully achieved. Once\nverification is complete, control returns to the Planning Agent, forming a\nclosed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution\nAgent. Our results show that the battle AI achieves an average win rate of\n80.8% across 50 wild encounters, only 6% lower than the performance of an\nexperienced human player. Furthermore, we find that a model's battle\nperformance correlates strongly with its LLM Arena score on language-related\ntasks, indicating a meaningful link between linguistic ability and strategic\nreasoning. Finally, our analysis of gameplay logs reveals that each LLM\nexhibits a unique playstyle, suggesting that individual models develop distinct\nstrategic behaviors.", "AI": {"tldr": "Pok\u00e9AI introduces a multi-agent framework using large language models to autonomously play Pok\u00e9mon Red through specialized agents handling planning, execution, and critique.", "motivation": "To explore the capability of LLMs in autonomous gameplay systems and analyze their performance in decision-making and strategic reasoning.", "method": "The framework uses three agents - Planning, Execution, and Critique - with distinct roles and memory banks to divide and complete game tasks. A battle module was also developed to test AI performance in wild Pok\u00e9mon encounters.", "result": "The battle AI achieved an 80.8% win rate, closely matching human performance, with a strong correlation between language-related tasks and strategic reasoning. Gameplay analysis showed unique playstyles across different models.", "conclusion": "Pok\u00e9AI demonstrates how LLMs can exhibit strategic reasoning and individual behaviors in a closed-loop decision-making system for autonomous gameplay."}}
{"id": "2506.23456", "pdf": "https://arxiv.org/pdf/2506.23456", "abs": "https://arxiv.org/abs/2506.23456", "authors": ["William Gay", "William He", "Nicholas Kocurek", "Ryan O'Donnell"], "title": "Sampling and Identity-Testing Without Approximate Tensorization of Entropy", "categories": ["math.ST", "cs.DS", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "Certain tasks in high-dimensional statistics become easier when the\nunderlying distribution satisfies a local-to-global property called approximate\ntensorization of entropy (ATE). For example, the Glauber dynamics Markov chain\nof an ATE distribution mixes fast and can produce approximate samples in a\nsmall amount of time, since such a distribution satisfies a modified\nlog-Sobolev inequality. Moreover, identity-testing for an ATE distribution\nrequires few samples if the tester is given coordinate conditional access to\nthe unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and\nVigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures\nof (few) distributions that do satisfy ATE. We study the complexity of\nidentity-testing and sampling for these distributions. Our main results are the\nfollowing:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization,\nwith optimal sample complexity, for mixtures of distributions satisfying\nmodified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,\nMohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of\ndistributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient\nidentity-testers for mixtures of ATE distributions in the\ncoordinate-conditional sampling access model. We also give some simplifications\nand improvements to the original algorithm of Blanca et al.", "AI": {"tldr": "The paper explores challenges in high-dimensional statistics for mixtures of distributions with approximate tensorization of entropy, providing efficient methods for sampling and identity testing.", "motivation": "To address the complexities in tasks such as identity-testing and sampling for mixtures of distributions that lack approximate tensorization of entropy (ATE).", "method": "The authors extend existing results on modified log-Sobolev inequalities to handle mixtures of distributions that satisfy such inequalities. They also design new algorithms for identity-testing under the coordinate-conditional sampling model.", "result": "They demonstrate fast mixing of Glauber dynamics with optimal sample complexity for these mixture distributions and provide efficient identity-testing methods, along with algorithmic enhancements over prior work.", "conclusion": "The study advances practical methods for tackling mixtures of high-dimensional distributions, offering theoretical as well as algorithmic contributions to facilitate faster and more efficient statistical tasks."}}
{"id": "2506.22845", "pdf": "https://arxiv.org/pdf/2506.22845", "abs": "https://arxiv.org/abs/2506.22845", "authors": ["Batuhan Hangun", "Oguz Altun", "Onder Eyecioglu"], "title": "Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": null, "summary": "Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine\nLearning (QML), are emerging as a powerful alternative to classical machine\nlearning methods. Recent studies have focused on the applicability of QNNs to\nvarious tasks, such as time-series forecasting, prediction, and classification,\nacross a wide range of applications, including cybersecurity and medical\nimaging. With the increased use of smart grids driven by the integration of\nrenewable energy systems, machine learning plays an important role in\npredicting power demand and detecting system disturbances. This study provides\nan in-depth investigation of QNNs for predicting the power output of a wind\nturbine. We assess the predictive performance and simulation time of six QNN\nconfigurations that are based on the Z Feature Map for data encoding and\nvarying ansatz structures. Through detailed cross-validation experiments and\ntests on an unseen hold-out dataset, we experimentally demonstrate that QNNs\ncan achieve predictive performance that is competitive with, and in some cases\nmarginally better than, the benchmarked classical approaches. Our results also\nreveal the effects of dataset size and circuit complexity on predictive\nperformance and simulation time. We believe our findings will offer valuable\ninsights for researchers in the energy domain who wish to incorporate quantum\nmachine learning into their work.", "AI": {"tldr": "The study investigates Quantum Neural Networks (QNNs) for predicting wind turbine power output, showing competitive performance compared to classical methods.", "motivation": "To explore the potential of Quantum Neural Networks (QNNs) in improving predictive performance for power output forecasting in renewable energy systems.", "method": "Six QNN configurations based on the Z Feature Map were tested with varying ansatz structures using cross-validation and unseen dataset assessment.", "result": "QNNs demonstrated competitive predictive performance and revealed the impact of dataset size and circuit complexity on outcomes in the energy domain.", "conclusion": "The results support the feasibility of QNNs as a promising tool for energy prediction tasks, offering insights to researchers incorporating quantum methods."}}
{"id": "2506.22736", "pdf": "https://arxiv.org/pdf/2506.22736", "abs": "https://arxiv.org/abs/2506.22736", "authors": ["Dayong Su", "Yafei Zhang", "Huafeng Li", "Jinxing Li", "Yu Liu"], "title": "UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Current multimodal medical image fusion typically assumes that source images\nare of high quality and perfectly aligned at the pixel level. Its effectiveness\nheavily relies on these conditions and often deteriorates when handling\nmisaligned or degraded medical images. To address this, we propose UniFuse, a\ngeneral fusion framework. By embedding a degradation-aware prompt learning\nmodule, UniFuse seamlessly integrates multi-directional information from input\nimages and correlates cross-modal alignment with restoration, enabling joint\noptimization of both tasks within a unified framework. Additionally, we design\nan Omni Unified Feature Representation scheme, which leverages Spatial Mamba to\nencode multi-directional features and mitigate modality differences in feature\nalignment. To enable simultaneous restoration and fusion within an All-in-One\nconfiguration, we propose a Universal Feature Restoration & Fusion module,\nincorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA\nprinciples. By leveraging ALSN's adaptive feature representation along with\ndegradation-type guidance, we enable joint restoration and fusion within a\nsingle-stage framework. Compared to staged approaches, UniFuse unifies\nalignment, restoration, and fusion within a single framework. Experimental\nresults across multiple datasets demonstrate the method's effectiveness and\nsignificant advantages over existing approaches.", "AI": {"tldr": "UniFuse is a general framework for multimodal medical image fusion capable of handling misaligned or degraded images by jointly optimizing alignment, restoration, and fusion.", "motivation": "Multimodal medical image fusion struggles with degraded or misaligned input images due to reliance on high-quality, pixel-aligned images.", "method": "The paper introduces UniFuse, which integrates a degradation-aware prompt learning module, Spatial Mamba encoding, and the ALSN-based Universal Feature Restoration & Fusion module within an all-in-one framework.", "result": "UniFuse achieves significant improvements in fusion quality compared to existing staged approaches across multiple datasets.", "conclusion": "By unifying alignment, restoration, and fusion processes, UniFuse offers a robust method for degraded and misaligned medical image fusion."}}
{"id": "2506.23071", "pdf": "https://arxiv.org/pdf/2506.23071", "abs": "https://arxiv.org/abs/2506.23071", "authors": ["Zhengren Wang", "Bozhou Li", "Dongwen Yao", "Wentao Zhang"], "title": "Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries", "categories": ["cs.CL"], "comment": "Work in progess", "summary": "While Text-to-SQL enables natural language interaction with structured\ndatabases, its effectiveness diminishes with unstructured data or ambiguous\nqueries due to rigid syntax and limited expressiveness. Concurrently, vector\nsearch has emerged as a powerful paradigm for semantic retrieval, particularly\nfor unstructured data. However, existing VectorSQL implementations still rely\nheavily on manual crafting and lack tailored evaluation frameworks, leaving a\nsignificant gap between theoretical potential and practical deployment. To\nbridge these complementary paradigms, we introduces Text2VectorSQL, a novel\nframework unifying Text-to-SQL and vector search to overcome expressiveness\nconstraints and support more diverse and holistical natural language queries.\nSpecifically, Text2VectorSQL enables semantic filtering, multi-modal matching,\nand retrieval acceleration. For evaluation, we build vector index on\nappropriate columns, extend user queries with semantic search, and annotate\nground truths via an automatic pipeline with expert review. Furthermore, we\ndevelop dedicated Text2VectorSQL models with synthetic data, demonstrating\nsignificant performance improvements over baseline methods. Our work\nestablishes the foundation for the Text2VectorSQL task, paving the way for more\nversatile and intuitive database interfaces. The repository will be publicly\navailable at https://github.com/Open-DataFlow/Text2VectorSQL.", "AI": {"tldr": "The paper introduces Text2VectorSQL, a framework unifying Text-to-SQL and vector search for diverse and holistic natural language queries.", "motivation": "Existing approaches to Text-to-SQL are limited in handling unstructured data and ambiguous queries, while VectorSQL solutions lack tailored evaluation frameworks and practical deployment tools.", "method": "Text2VectorSQL enables semantic filtering, multi-modal matching, and retrieval acceleration. It leverages vector indexing, extends user queries, annotates ground truths with expert reviews, and uses synthetic data for model development.", "result": "Text2VectorSQL demonstrates significant performance improvements over baseline methods in semantic querying and retrieval tasks.", "conclusion": "The work establishes a foundation for the Text2VectorSQL task, aiming to provide versatile and intuitive database interfaces and will be made publicly available for further development."}}
{"id": "2506.23624", "pdf": "https://arxiv.org/pdf/2506.23624", "abs": "https://arxiv.org/abs/2506.23624", "authors": ["Max Grobbel", "Tristan Schneider", "S\u00f6ren Hohmann"], "title": "Towards Universal Shared Control in Teleoperation Without Haptic Feedback", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "5 pages, submitted to IEEE Telepresence 2025 conference", "summary": "Teleoperation with non-haptic VR controllers deprives human operators of\ncritical motion feedback. We address this by embedding a multi-objective\noptimization problem that converts user input into collision-free UR5e joint\ntrajectories while actively suppressing liquid slosh in a glass. The controller\nmaintains 13 ms average planning latency, confirming real-time performance and\nmotivating the augmentation of this teleoperation approach to further\nobjectives.", "AI": {"tldr": "This study proposes a solution for VR teleoperation without haptic feedback by optimizing user input for collision-free robot trajectories, achieving low-latency control while suppressing liquid slosh.", "motivation": "Non-haptic VR controllers lack essential motion feedback for teleoperating, making certain operations challenging, such as handling liquids.", "method": "The paper integrates multi-objective optimization into the user-controller input to convert it into collision-free joint trajectories for a UR5e robotic arm while minimizing liquid motion within a glass.", "result": "The system achieved an average planning latency of 13 milliseconds, ensuring real-time operational capability.", "conclusion": "The proposed approach effectively resolves motion feedback limitation in teleoperation and demonstrates potential for augmenting to additional control objectives beyond liquid slosh suppression."}}
{"id": "2506.23692", "pdf": "https://arxiv.org/pdf/2506.23692", "abs": "https://arxiv.org/abs/2506.23692", "authors": ["Boyuan Zheng", "Zerui Fang", "Zhe Xu", "Rui Wang", "Yiwen Chen", "Cunshi Wang", "Mengwei Qu", "Lei Lei", "Zhen Feng", "Yan Liu", "Yuyang Li", "Mingzhou Tan", "Jiaji Wu", "Jianwei Shuai", "Jia Li", "Fangfu Ye"], "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "While AI for Science (AI4S) serves as an analytical tool in the current\nresearch paradigm, it doesn't solve its core inefficiency. We propose \"Agent\nfor Science\" (Agent4S)-the use of LLM-driven agents to automate the entire\nresearch workflow-as the true Fifth Scientific Paradigm. This paper introduces\na five-level classification for Agent4S, outlining a clear roadmap from simple\ntask automation to fully autonomous, collaborative \"AI Scientists.\" This\nframework defines the next revolutionary step in scientific discovery.", "AI": {"tldr": "This paper introduces a roadmap for utilizing LLM-driven agents to fully automate scientific research workflows, proposing it as the Fifth Scientific Paradigm.", "motivation": "Current research paradigms face inefficiencies that aren't fully addressed by AI analytical tools. The authors aim to establish a more transformative approach to scientific innovation.", "method": "The paper proposes a five-level classification framework for \"Agent for Science\" systems, detailing their evolution from task automation to collaborative autonomy.", "result": "A structured roadmap for developing \"AI Scientists\" is outlined, showcasing the potential for entirely automated scientific discovery workflows.", "conclusion": "Agent4S represents a revolutionary shift in scientific methodology, enabling autonomous agents to redefine the process of research and discovery."}}
{"id": "2506.23619", "pdf": "https://arxiv.org/pdf/2506.23619", "abs": "https://arxiv.org/abs/2506.23619", "authors": ["Guillaume Coqueret", "Martial Laguerre"], "title": "Overparametrized models with posterior drift", "categories": ["q-fin.ST", "cs.LG", "econ.EM", "stat.ML"], "comment": null, "summary": "This paper investigates the impact of posterior drift on out-of-sample\nforecasting accuracy in overparametrized machine learning models. We document\nthe loss in performance when the loadings of the data generating process change\nbetween the training and testing samples. This matters crucially in settings in\nwhich regime changes are likely to occur, for instance, in financial markets.\nApplied to equity premium forecasting, our results underline the sensitivity of\na market timing strategy to sub-periods and to the bandwidth parameters that\ncontrol the complexity of the model. For the average investor, we find that\nfocusing on holding periods of 15 years can generate very heterogeneous\nreturns, especially for small bandwidths. Large bandwidths yield much more\nconsistent outcomes, but are far less appealing from a risk-adjusted return\nstandpoint. All in all, our findings tend to recommend cautiousness when\nresorting to large linear models for stock market predictions.", "AI": {"tldr": "This paper studies how changes in data patterns affect forecasting accuracy in complex machine learning models, especially for stock market predictions.", "motivation": "Explore how machine learning models perform when data patterns change over time, particularly in scenarios like financial markets.", "method": "Analyze the impact of posterior drift and evaluate factors like periods and bandwidths in equity premium forecasting.", "result": "Long holding periods yield variable returns, small bandwidths cause inconsistency, while large bandwidths are stable but less attractive risk-wise.", "conclusion": "Caution is advised when using large linear machine learning models for stock market forecasting."}}
{"id": "2506.22848", "pdf": "https://arxiv.org/pdf/2506.22848", "abs": "https://arxiv.org/abs/2506.22848", "authors": ["Shengcai Liu", "Hui Ou-yang", "Zhiyuan Wang", "Cheng Chen", "Qijun Cai", "Yew-Soon Ong", "Ke Tang"], "title": "Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning the structure of Bayesian networks (BNs) from data is challenging,\nespecially for datasets involving a large number of variables. The recently\nproposed divide-and-conquer (D\\&D) strategies present a promising approach for\nlearning large BNs. However, they still face a main issue of unstable learning\naccuracy across subproblems. In this work, we introduce the idea of employing\nstructure learning ensemble (SLE), which combines multiple BN structure\nlearning algorithms, to consistently achieve high learning accuracy. We further\npropose an automatic approach called Auto-SLE for learning near-optimal SLEs,\naddressing the challenge of manually designing high-quality SLEs. The learned\nSLE is then integrated into a D\\&D method. Extensive experiments firmly show\nthe superiority of our method over D\\&D methods with single BN structure\nlearning algorithm in learning large BNs, achieving accuracy improvement\nusually by 30\\%$\\sim$225\\% on datasets involving 10,000 variables. Furthermore,\nour method generalizes well to datasets with many more (e.g., 30000) variables\nand different network characteristics than those present in the training data\nfor learning the SLE. These results indicate the significant potential of\nemploying (automatic learning of) SLEs for scalable BN structure learning.", "AI": {"tldr": "The paper addresses the challenge of learning Bayesian networks from large datasets by introducing Auto-SLE, an approach that automates the creation of structure learning ensembles, achieving significantly better accuracy.", "motivation": "To overcome the unstable accuracy in divide-and-conquer approaches for Bayesian network learning and achieve scalable and consistent performance on large datasets.", "method": "Development of Auto-SLE, an automatic method to design structure learning ensembles, which integrates various structure learning algorithms into a divide-and-conquer strategy.", "result": "Auto-SLE improves accuracy by 30% to 225% in experiments involving datasets with up to 10,000 variables and demonstrates generalization to even larger datasets.", "conclusion": "Employing automatic structure learning ensembles (SLEs) shows great promise for scalable and accurate Bayesian network structure learning especially in large-scale datasets."}}
{"id": "2506.22749", "pdf": "https://arxiv.org/pdf/2506.22749", "abs": "https://arxiv.org/abs/2506.22749", "authors": ["Yun Zhang", "Feifan Chen", "Na Li", "Zhiwei Guo", "Xu Wang", "Fen Miao", "Sam Kwong"], "title": "Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds", "categories": ["cs.CV"], "comment": null, "summary": "Colored point cloud, which includes geometry and attribute components, is a\nmainstream representation enabling realistic and immersive 3D applications. To\ngenerate large-scale and denser colored point clouds, we propose a deep\nlearning-based Joint Geometry and Attribute Up-sampling (JGAU) method that\nlearns to model both geometry and attribute patterns while leveraging spatial\nattribute correlations. First, we establish and release a large-scale dataset\nfor colored point cloud up-sampling called SYSU-PCUD, containing 121\nlarge-scale colored point clouds with diverse geometry and attribute\ncomplexities across six categories and four sampling rates. Second, to improve\nthe quality of up-sampled point clouds, we propose a deep learning-based JGAU\nframework that jointly up-samples geometry and attributes. It consists of a\ngeometry up-sampling network and an attribute up-sampling network, where the\nlatter leverages the up-sampled auxiliary geometry to model neighborhood\ncorrelations of the attributes. Third, we propose two coarse attribute\nup-sampling methods, Geometric Distance Weighted Attribute Interpolation\n(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate\ncoarse up-sampled attributes for each point. Then, an attribute enhancement\nmodule is introduced to refine these up-sampled attributes and produce\nhigh-quality point clouds by further exploiting intrinsic attribute and\ngeometry patterns. Extensive experiments show that the Peak Signal-to-Noise\nRatio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10\ndecibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,\n8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art\nmethods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28\ndecibels, and 2.11 decibels at these four up-sampling rates, demonstrating\nsignificant improvement.", "AI": {"tldr": "This paper presents a deep learning-based method for up-sampling colored point clouds to improve their geometry and attributes, significantly outperforming state-of-the-art methods.", "motivation": "To address the need for generating large-scale and denser colored point clouds for realistic and immersive 3D applications.", "method": "The authors propose a Joint Geometry and Attribute Up-sampling (JGAU) framework consisting of networks for geometry and attribute up-sampling, supported by coarse attribute up-sampling methods and an attribute enhancement module.", "result": "The proposed method yields superior performance, achieving PSNR improvements of 2.32 to 2.47 decibels compared to state-of-the-art methods across four up-sampling rates.", "conclusion": "The JGAU framework effectively enhances the quality of up-sampled colored point clouds, leveraging intrinsic geometry and attribute patterns for significant gains in performance."}}
{"id": "2506.23101", "pdf": "https://arxiv.org/pdf/2506.23101", "abs": "https://arxiv.org/abs/2506.23101", "authors": ["Yue Xu", "Wenjie Wang"], "title": "From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have shown impressive capabilities\nacross tasks involving both visual and textual modalities. However, growing\nconcerns remain about their potential to encode and amplify gender bias,\nparticularly in socially sensitive applications. Existing benchmarks\npredominantly evaluate bias in isolated scenarios, overlooking how bias may\nemerge subtly through interpersonal interactions. We fill this gap by going\nbeyond single-entity evaluation and instead focusing on a deeper examination of\nrelational and contextual gender bias in dual-individual interactions. We\nintroduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs\nthrough the lens of social relationships in generated narratives. Genres\nassesses gender bias through a dual-character profile and narrative generation\ntask that captures rich interpersonal dynamics and supports a fine-grained bias\nevaluation suite across multiple dimensions. Experiments on both open- and\nclosed-source MLLMs reveal persistent, context-sensitive gender biases that are\nnot evident in single-character settings. Our findings underscore the\nimportance of relationship-aware benchmarks for diagnosing subtle,\ninteraction-driven gender bias in MLLMs and provide actionable insights for\nfuture bias mitigation.", "AI": {"tldr": "The paper introduces Genres, a benchmark for evaluating gender bias in multimodal language models (MLLMs) through interpersonal dynamics in narratives, finding persistent, context-sensitive biases.", "motivation": "Existing benchmarks primarily evaluate gender bias in isolated scenarios, which neglects how bias manifests subtly in interpersonal interactions.", "method": "The paper introduces Genres, a benchmark analyzing dual-character narratives to evaluate gender biases across diverse dimensions of social relationships.", "result": "Experiments on MLLMs uncover persistent, context-specific gender biases that are invisible in single-character evaluations.", "conclusion": "Relationship-aware benchmarks like Genres are critical for diagnosing interaction-driven gender bias and guiding effective bias mitigation strategies in MLLMs."}}
{"id": "2506.23723", "pdf": "https://arxiv.org/pdf/2506.23723", "abs": "https://arxiv.org/abs/2506.23723", "authors": ["Jozsef Palmieri", "Paolo Di Lillo", "Stefano Chiaverini", "Alessandro Marino"], "title": "A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings", "categories": ["cs.RO"], "comment": null, "summary": "The adoption of mobile robotic platforms in complex environments, such as\nagricultural settings, requires these systems to exhibit a flexible yet\neffective architecture that integrates perception and control. In such\nscenarios, several tasks need to be accomplished simultaneously, ranging from\nmanaging robot limits to performing operational tasks and handling human\ninputs. The purpose of this paper is to present a comprehensive control\narchitecture for achieving complex tasks such as robotized harvesting in\nvineyards within the framework of the European project CANOPIES. In detail, a\n16-DOF dual-arm mobile robot is employed, controlled via a Hierarchical\nQuadratic Programming (HQP) approach capable of handling both equality and\ninequality constraints at various priorities to harvest grape bunches selected\nby the perception system developed within the project. Furthermore, given the\ncomplexity of the scenario and the uncertainty in the perception system, which\ncould potentially lead to collisions with the environment, the handling of\ninteraction forces is necessary. Remarkably, this was achieved using the same\nHQP framework. This feature is further leveraged to enable semi-autonomous\noperations, allowing a human operator to assist the robotic counterpart in\ncompleting harvesting tasks. Finally, the obtained results are validated\nthrough extensive testing conducted first in a laboratory environment to prove\nindividual functionalities, then in a real vineyard, encompassing both\nautonomous and semi-autonomous grape harvesting operations.", "AI": {"tldr": "The paper introduces a control architecture for a dual-arm mobile robot used in autonomous and semi-autonomous grape harvesting in vineyards under the CANOPIES project.", "motivation": "The need for robotic systems designed for complex agricultural tasks that integrate efficient perception and control mechanisms.", "method": "The method involves using a 16-DOF dual-arm mobile robot with a Hierarchical Quadratic Programming (HQP) approach to prioritize and execute tasks, including managing uncertainties and interaction forces.", "result": "The robotic system was validated through extensive lab testing and real-world vineyard trials, demonstrating successful autonomous and semi-autonomous grape harvesting.", "conclusion": "The integration of HQP for task management and interaction forces shows promise for advancing agricultural robotics, particularly in complex settings like vineyards, blending human assistance with automation."}}
{"id": "2506.23703", "pdf": "https://arxiv.org/pdf/2506.23703", "abs": "https://arxiv.org/abs/2506.23703", "authors": ["Lars Ullrich", "Walter Zimmer", "Ross Greer", "Knut Graichen", "Alois C. Knoll", "Mohan Trivedi"], "title": "A New Perspective On AI Safety Through Control Theory Methodologies", "categories": ["cs.AI"], "comment": "Accepted to be published as part of the 2025 IEEE Open Journal of\n  Intelligent Transportation Systems (OJ-ITS)", "summary": "While artificial intelligence (AI) is advancing rapidly and mastering\nincreasingly complex problems with astonishing performance, the safety\nassurance of such systems is a major concern. Particularly in the context of\nsafety-critical, real-world cyber-physical systems, AI promises to achieve a\nnew level of autonomy but is hampered by a lack of safety assurance. While\ndata-driven control takes up recent developments in AI to improve control\nsystems, control theory in general could be leveraged to improve AI safety.\nTherefore, this article outlines a new perspective on AI safety based on an\ninterdisciplinary interpretation of the underlying data-generation process and\nthe respective abstraction by AI systems in a system theory-inspired and system\nanalysis-driven manner. In this context, the new perspective, also referred to\nas data control, aims to stimulate AI engineering to take advantage of existing\nsafety analysis and assurance in an interdisciplinary way to drive the paradigm\nof data control. Following a top-down approach, a generic foundation for safety\nanalysis and assurance is outlined at an abstract level that can be refined for\nspecific AI systems and applications and is prepared for future innovation.", "AI": {"tldr": "The paper introduces a new interdisciplinary approach, called \"data control,\" to enhance AI safety, particularly in real-world, safety-critical systems.", "motivation": "AI's rapid advancements lack sufficient safety assurance, especially in its application to safety-critical cyber-physical systems.", "method": "The authors propose a system theory-inspired, system analysis-driven methodology called \"data control,\" which integrates control theory and AI safety assurance.", "result": "A generic abstract framework for safety analysis and assurance is proposed, adaptable for future innovations in specific AI systems and applications.", "conclusion": "This interdisciplinary approach leveraging control theory can drive advancements in safety assurance for AI systems, fostering a safer integration in safety-critical applications."}}
{"id": "2506.23757", "pdf": "https://arxiv.org/pdf/2506.23757", "abs": "https://arxiv.org/abs/2506.23757", "authors": ["Dan Yao", "Steve McLaughlin", "Yoann Altmann"], "title": "Training of Spiking Neural Networks with Expectation-Propagation", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "10 pages", "summary": "In this paper, we propose a unifying message-passing framework for training\nspiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free\nmethod is capable of learning the marginal distributions of network parameters\nand simultaneously marginalizes nuisance parameters, such as the outputs of\nhidden layers. This framework allows for the first time, training of discrete\nand continuous weights, for deterministic and stochastic spiking networks,\nusing batches of training samples. Although its convergence is not ensured, the\nalgorithm converges in practice faster than gradient-based methods, without\nrequiring a large number of passes through the training data. The\nclassification and regression results presented pave the way for new efficient\ntraining methods for deep Bayesian networks.", "AI": {"tldr": "This paper introduces a unified gradient-free framework for training spiking neural networks using Expectation-Propagation, enabling faster convergence and efficient handling of both deterministic and stochastic weights.", "motivation": "To develop an effective training method for spiking neural networks that can handle nuisance parameters and different types of weights efficiently.", "method": "A gradient-free Expectation-Propagation framework that trains spiking neural networks by learning marginal distributions and marginalizing nuisance parameters, allowing batch training for discrete and continuous weights.", "result": "The framework achieves faster convergence in practice compared to gradient-based methods and successfully addresses classification and regression tasks.", "conclusion": "The proposed method could lead to new and efficient training techniques for deep Bayesian networks, despite practical limitations in convergence guarantees."}}
{"id": "2506.22871", "pdf": "https://arxiv.org/pdf/2506.22871", "abs": "https://arxiv.org/abs/2506.22871", "authors": ["Homayun Afrabandpey", "Hamed Rezazadegan Tavakoli"], "title": "P$^2$U: Progressive Precision Update For Efficient Model Distribution", "categories": ["cs.LG", "cs.MM", "I.2.6"], "comment": null, "summary": "Efficient model distribution is becoming increasingly critical in\nbandwidth-constrained environments. In this paper, we propose a simple yet\neffective approach called Progressive Precision Update (P$^2$U) to address this\nproblem. Instead of transmitting the original high-precision model, P$^2$U\ntransmits a lower-bit precision model, coupled with a model update representing\nthe difference between the original high-precision model and the transmitted\nlow precision version. With extensive experiments on various model\narchitectures, ranging from small models ($1 - 6$ million parameters) to a\nlarge model (more than $100$ million parameters) and using three different data\nsets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U\nconsistently achieves better tradeoff between accuracy, bandwidth usage and\nlatency. Moreover, we show that when bandwidth or startup time is the priority,\naggressive quantization (e.g., 4-bit) can be used without severely compromising\nperformance. These results establish P$^2$U as an effective and practical\nsolution for scalable and efficient model distribution in low-resource\nsettings, including federated learning, edge computing, and IoT deployments.\nGiven that P$^2$U complements existing compression techniques and can be\nimplemented alongside any compression method, e.g., sparsification,\nquantization, pruning, etc., the potential for improvement is even greater.", "AI": {"tldr": "The paper introduces P$^2$U, an efficient model distribution method that transmits low-precision models with updates for bandwidth-constrained environments, showcasing improved accuracy-bandwidth-latency tradeoffs across datasets and architectures.", "motivation": "The need to transmit models efficiently in bandwidth-limited environments, such as federated learning and IoT deployments.", "method": "P$^2$U transmits low-bit precision models supplemented with updates representing differences between low and high-precision versions, and works with existing compression techniques.", "result": "Extensive experiments across datasets and model sizes reveal that P$^2$U offers superior accuracy-bandwidth-latency trade-offs, even with aggressive quantization (e.g., 4-bit).", "conclusion": "P$^2$U is a scalable and practical solution for model distribution in bandwidth-constrained settings, complementing current compression strategies for further efficiency improvements."}}
{"id": "2506.22753", "pdf": "https://arxiv.org/pdf/2506.22753", "abs": "https://arxiv.org/abs/2506.22753", "authors": ["Jianing Zhang", "Jiayi Zhu", "Feiyu Ji", "Xiaokang Yang", "Xiaoyun Yuan"], "title": "Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography", "categories": ["cs.CV"], "comment": null, "summary": "Metalenses offer significant potential for ultra-compact computational\nimaging but face challenges from complex optical degradation and computational\nrestoration difficulties. Existing methods typically rely on precise optical\ncalibration or massive paired datasets, which are non-trivial for real-world\nimaging systems. Furthermore, a lack of control over the inference process\noften results in undesirable hallucinated artifacts. We introduce\nDegradation-Modeled Multipath Diffusion for tunable metalens photography,\nleveraging powerful natural image priors from pretrained models instead of\nlarge datasets. Our framework uses positive, neutral, and negative-prompt paths\nto balance high-frequency detail generation, structural fidelity, and\nsuppression of metalens-specific degradation, alongside \\textit{pseudo} data\naugmentation. A tunable decoder enables controlled trade-offs between fidelity\nand perceptual quality. Additionally, a spatially varying degradation-aware\nattention (SVDA) module adaptively models complex optical and sensor-induced\ndegradation. Finally, we design and build a millimeter-scale MetaCamera for\nreal-world validation. Extensive results show that our approach outperforms\nstate-of-the-art methods, achieving high-fidelity and sharp image\nreconstruction. More materials: https://dmdiff.github.io/.", "AI": {"tldr": "This paper introduces a novel method using pre-trained models to improve imaging using metalenses, offering tunable trade-offs between image quality and fidelity, and demonstrating its effectiveness with a new MetaCamera.", "motivation": "Metalenses are compact but face challenges such as optical degradation, complicated restoration, and undesirable artifacts in computational imaging, which current methods fail to address effectively without requiring extensive resources or calibration.", "method": "The proposed method uses a 'Degradation-Modeled Multipath Diffusion' framework, leveraging pre-trained image priors and pseudo data augmentation. It balances image quality through positive, neutral, and negative prompts and uses a tunable decoder for fidelity-quality trade-off. A spatial degradation-aware attention (SVDA) module handles optical and sensor degradation.", "result": "The approach outperforms state-of-the-art methods, achieving both high-fidelity and sharp image reconstructions. A custom-built millimeter-scale MetaCamera validates its real-world performance.", "conclusion": "The framework successfully addresses metalens-specific challenges, offering a practical solution for controlled, high-quality image reconstruction and setting a new standard in computational imaging with metalenses."}}
{"id": "2506.23111", "pdf": "https://arxiv.org/pdf/2506.23111", "abs": "https://arxiv.org/abs/2506.23111", "authors": ["Janki Atul Nawale", "Mohammed Safi Ur Rahman Khan", "Janani D", "Mansi Gupta", "Danish Pruthi", "Mitesh M. Khapra"], "title": "FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes", "categories": ["cs.CL"], "comment": "Accepted in ACL 2025", "summary": "Existing studies on fairness are largely Western-focused, making them\ninadequate for culturally diverse countries such as India. To address this gap,\nwe introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to\nevaluate fairness of LLMs across 85 identity groups encompassing diverse\ncastes, religions, regions, and tribes. We first consult domain experts to\ncurate over 1,800 socio-cultural topics spanning behaviors and situations,\nwhere biases and stereotypes are likely to emerge. Grounded in these topics, we\ngenerate and manually validate 20,000 real-world scenario templates to probe\nLLMs for fairness. We structure these templates into three evaluation tasks:\nplausibility, judgment, and generation. Our evaluation of 14 popular LLMs on\nthese tasks reveals strong negative biases against marginalized identities,\nwith models frequently reinforcing common stereotypes. Additionally, we find\nthat models struggle to mitigate bias even when explicitly asked to rationalize\ntheir decision. Our evaluation provides evidence of both allocative and\nrepresentational harms that current LLMs could cause towards Indian identities,\ncalling for a more cautious usage in practical applications. We release\nINDIC-BIAS as an open-source benchmark to advance research on benchmarking and\nmitigating biases and stereotypes in the Indian context.", "AI": {"tldr": "INDIC-BIAS introduces the first India-centric benchmark assessing fairness in language models across 85 identity groups and exposes strong negative biases and stereotypes within LLMs.", "motivation": "To address the lack of culturally relevant fairness benchmarks for large language models (LLMs) in diverse countries like India.", "method": "The study involves consulting domain experts to create socio-cultural topics, generating 20,000 scenario templates, structuring them into tasks, and evaluating 14 LLMs.", "result": "The evaluation reveals significant biases and stereotypes against marginalized Indian identities, along with models failing to mitigate biases even when prompted.", "conclusion": "The INDIC-BIAS benchmark highlights the harms current LLMs can cause in diverse cultural settings and advocates for cautious application and further research into bias mitigation for Indian contexts."}}
{"id": "2506.23725", "pdf": "https://arxiv.org/pdf/2506.23725", "abs": "https://arxiv.org/abs/2506.23725", "authors": ["Atharva Gundawar", "Som Sagar", "Ransalu Senanayake"], "title": "PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) are increasingly pivotal for generalist robot\nmanipulation, enabling tasks such as physical reasoning, policy generation, and\nfailure detection. However, their proficiency in these high-level applications\noften assumes a deep understanding of low-level physical prerequisites, a\ncapability that remains largely unverified. For robots to perform actions\nreliably, they must comprehend intrinsic object properties (e.g., material,\nweight), action affordances (e.g., graspable, stackable), and physical\nconstraints (e.g., stability, reachability, or an object's state, such as being\nclosed). Despite the widespread use of VLMs in manipulation tasks, we argue\nthat off-the-shelf models may lack this granular, physically grounded\nunderstanding, as such prerequisites are often overlooked during training.\n  To address this critical gap, we introduce PAC Bench, a comprehensive\nbenchmark designed to systematically evaluate VLMs on their understanding of\ncore Properties, Affordances, and Constraints (PAC) from a task executability\nperspective. PAC Bench features a diverse dataset with over 30,000 annotations,\ncomprising 673 real-world images (115 object classes, 15 property types, and 1\nto 3 affordances defined per class), 100 real-world humanoid-view scenarios,\nand 120 unique simulated constraint scenarios across four tasks.\n  Our evaluations reveal significant gaps in the ability of current VLMs to\ngrasp fundamental physical concepts, highlighting limitations in their\nsuitability for reliable robot manipulation and pointing to key areas for\ntargeted research. PAC Bench also serves as a standardized benchmark for\nrigorously evaluating physical reasoning in VLMs and guiding the development of\nmore robust, physically grounded models for robotic applications.\n  Project Page: https://pacbench.github.io/", "AI": {"tldr": "The paper introduces PAC Bench, a benchmark to evaluate Vision-Language Models (VLMs) on their understanding of physical concepts critical for robotic manipulation.", "motivation": "Current Vision-Language Models (VLMs) frequently lack a deep understanding of intrinsic physical properties, action affordances, and constraints, which are prerequisites for effective robot manipulation tasks.", "method": "The authors developed PAC Bench, a benchmark consisting of over 30,000 annotations, including real-world images, humanoid-view scenarios, and simulated constraint scenarios across four tasks. It is designed to systematically evaluate the physical understanding of VLMs.", "result": "Performance evaluations of existing VLMs on PAC Bench reveal significant gaps in their ability to understand physical concepts, indicating their current limitations in robotic applications.", "conclusion": "PAC Bench offers a standardized and comprehensive framework for evaluating and improving the physical reasoning capabilities of VLMs, aiming to enhance their suitability for robotic tasks."}}
{"id": "2506.23706", "pdf": "https://arxiv.org/pdf/2506.23706", "abs": "https://arxiv.org/abs/2506.23706", "authors": ["Christoph Schnabl", "Daniel Hugenroth", "Bill Marino", "Alastair R. Beresford"], "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": "ICML 2024 Workshop TAIG", "summary": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "AI": {"tldr": "This paper introduces a secure framework for auditing AI models using Trusted Execution Environments, ensuring verifiable and confidential results.", "motivation": "Benchmarks are crucial for checking AI safety and compliance, but current methods lack result verification and data confidentiality.", "method": "The paper proposes Attestable Audits, executed within Trusted Execution Environments, to securely evaluate AI models without exposing sensitive data.", "result": "A prototype system was built to demonstrate the effectiveness of the approach on standard audit benchmarks applied to the Llama-3.1 model.", "conclusion": "Attestable Audits can enhance trust and address verification challenges, aligning with modern AI governance requirements while protecting sensitive information."}}
{"id": "2506.23921", "pdf": "https://arxiv.org/pdf/2506.23921", "abs": "https://arxiv.org/abs/2506.23921", "authors": ["Germans Savcisens", "Tina Eliassi-Rad"], "title": "The Trilemma of Truth in Large Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We often attribute human characteristics to large language models (LLMs) and\nclaim that they \"know\" certain things. LLMs have an internal probabilistic\nknowledge that represents information retained during training. How can we\nassess the veracity of this knowledge? We examine two common methods for\nprobing the veracity of LLMs and discover several assumptions that are flawed.\nTo address these flawed assumptions, we introduce sAwMIL (short for Sparse\nAware Multiple-Instance Learning), a probing method that utilizes the internal\nactivations of LLMs to separate statements into true, false, and neither.\nsAwMIL is based on multiple-instance learning and conformal prediction. We\nevaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including\nboth default and chat-based variants, as well as on 3 new datasets. Among the\ninsights we provide are: (1) the veracity signal is often concentrated in the\nthird quarter of an LLM's depth; (2) truth and falsehood signals are not always\nsymmetric; (3) linear probes perform better on chat models than on default\nmodels; (4) nonlinear probes may be required to capture veracity signals for\nsome LLMs with reinforcement learning from human feedback or knowledge\ndistillation; and (5) LLMs capture a third type of signal that is distinct from\ntrue and false and is neither true nor false. These findings provide a reliable\nmethod for verifying what LLMs \"know\" and how certain they are of their\nprobabilistic internal knowledge.", "AI": {"tldr": "The paper introduces a method called sAwMIL for probing the truthfulness of information retained by large language models (LLMs).", "motivation": "LLMs retain information probabilistically during training, but methods to gauge the accuracy of their 'knowledge' often rely on flawed assumptions.", "method": "The authors propose the sAwMIL method, which leverages internal activations, multiple-instance learning, and conformal prediction to classify statements as true, false, or neither.", "result": "sAwMIL was tested across 16 open-source LLMs and new datasets, revealing insights like concentrated veracity signals in specific model depths and the asymmetry between truth and falsehood signals.", "conclusion": "The work offers a reliable mechanism to probe LLMs' internal veracity signals, addressing their certainty and categorization of information beyond binary classifications."}}
{"id": "2506.22895", "pdf": "https://arxiv.org/pdf/2506.22895", "abs": "https://arxiv.org/abs/2506.22895", "authors": ["Xinyu Chen", "Vassilis Digalakis Jr", "Lijun Ding", "Dingyi Zhuang", "Jinhua Zhao"], "title": "Interpretable Time Series Autoregression for Periodicity Quantification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series autoregression is a classical statistical model for capturing\nauto-correlations and identifying temporal patterns such as periodicity and\nseasonality. In this work, we propose a novel sparse autoregression framework\nfrom an interpretable machine learning perspective and the model\ninterpretability for periodicity quantification is reinforced by $\\ell_0$-norm\ninduced sparsity constraints. On the time-varying time series data, we\nreformulate the sparse autoregression and convert the involved optimization\nproblem into a mixed-integer optimization (MIO). To accelerate it, we develop a\nsubspace pursuit based decision variable pruning (DVP) strategy to reduce the\nsearch space. On the multidimensional time series that involves complicated\nspatial and temporal dimensions, we propose a spatially- and time-varying\nsparse autoregression model and resolve the corresponding MIO problem by\ndeveloping a two-stage optimization scheme. In particular, the proposed scheme\nmakes the model scalable to large problems even with millions of decision\nvariables. Empirically, we conduct extensive experiments to evaluate the\nproposed models on real-world time series data. First, we demonstrate that the\nMIO solver can be drastically accelerated through the DVP strategy, while\nmaintaining the same solution quality as a full MIO solver. Applying the\ntime-varying sparse autoregression model to ridesharing trip data, we uncover\nboth daily and weekly periodicities and reveal long-term changes in regularity\nof human mobility. Second, we demonstrate the spatial patterns of yearly\nseasonality in climate variable time series such as temperature and\nprecipitation across the past four decades, and our model allows to discover\ndynamic climate patterns and identify climate phenomena such as El Nino in sea\nsurface temperature.", "AI": {"tldr": "This paper introduces a sparse autoregression framework with $\n$-norm based sparsity for improved interpretability, applying fast optimization strategies and validating through multiple real-world datasets.", "motivation": "The motivation is to enhance the interpretability and scalability of autoregression models for complex time series data with goals like identifying periodicity and spatial-temporal patterns.", "method": "The authors reformulate sparse autoregression using mixed-integer optimization and propose a decision variable pruning (DVP) strategy to expedite computations. For multidimensional time series, they design a spatially-and time-varying model and solve it using a two-stage optimization method.", "result": "The DVP strategy accelerates computations significantly without sacrificing solution quality. Illustrations on mobility datasets reveal periodic behaviors, while climate datasets highlight dynamic climate trends over decades.", "conclusion": "The proposed methods successfully enhance functionality, scalability, and interpretability in handling complex time series data, uncovering valuable spatial and temporal insights."}}
{"id": "2506.22756", "pdf": "https://arxiv.org/pdf/2506.22756", "abs": "https://arxiv.org/abs/2506.22756", "authors": ["Tao Tang", "Likui Zhang", "Youpeng Wen", "Kaidong Zhang", "Jia-Wang Bian", "xia zhou", "Tianyi Yan", "Kun Zhan", "Peng Jia", "Hefeng Wu", "Liang Lin", "Xiaodan Liang"], "title": "RoboPearls: Editable Video Simulation for Robot Manipulation", "categories": ["cs.CV", "cs.RO"], "comment": "ICCV 2025", "summary": "The development of generalist robot manipulation policies has seen\nsignificant progress, driven by large-scale demonstration data across diverse\nenvironments. However, the high cost and inefficiency of collecting real-world\ndemonstrations hinder the scalability of data acquisition. While existing\nsimulation platforms enable controlled environments for robotic learning, the\nchallenge of bridging the sim-to-real gap remains. To address these challenges,\nwe propose RoboPearls, an editable video simulation framework for robotic\nmanipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the\nconstruction of photo-realistic, view-consistent simulations from demonstration\nvideos, and supports a wide range of simulation operators, including various\nobject manipulations, powered by advanced modules like Incremental Semantic\nDistillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by\nincorporating large language models (LLMs), RoboPearls automates the simulation\nproduction process in a user-friendly manner through flexible command\ninterpretation and execution. Furthermore, RoboPearls employs a vision-language\nmodel (VLM) to analyze robotic learning issues to close the simulation loop for\nperformance enhancement. To demonstrate the effectiveness of RoboPearls, we\nconduct extensive experiments on multiple datasets and scenes, including\nRLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which\ndemonstrate our satisfactory simulation performance.", "AI": {"tldr": "Introducing RoboPearls, a simulation framework leveraging 3D Gaussian Splatting and advanced AI tools for scalable and realistic robotic manipulation.", "motivation": "To overcome data acquisition limitations and the sim-to-real gap in robotic manipulation learning.", "method": "Development of RoboPearls, utilizing 3D Gaussian Splatting, Incremental Semantic Distillation, 3D-NNFM Loss, large language models (LLMs), and vision-language models (VLMs).", "result": "Extensive experiments across multiple datasets and environments show satisfactory simulation performance.", "conclusion": "RoboPearls proves effective for enhancing robotic manipulation learning, addressing scalability and realism challenges."}}
{"id": "2506.23122", "pdf": "https://arxiv.org/pdf/2506.23122", "abs": "https://arxiv.org/abs/2506.23122", "authors": ["Shivam Sharma", "Tanmoy Chakraborty"], "title": "Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models", "categories": ["cs.CL", "cs.CY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This work investigates the challenging task of identifying narrative roles -\nHero, Villain, Victim, and Other - in Internet memes, across three diverse test\nsets spanning English and code-mixed (English-Hindi) languages. Building on an\nannotated dataset originally skewed toward the 'Other' class, we explore a more\nbalanced and linguistically diverse extension, originally introduced as part of\nthe CLEF 2024 shared task. Comprehensive lexical and structural analyses\nhighlight the nuanced, culture-specific, and context-rich language used in real\nmemes, in contrast to synthetically curated hateful content, which exhibits\nexplicit and repetitive lexical markers. To benchmark the role detection task,\nwe evaluate a wide spectrum of models, including fine-tuned multilingual\ntransformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,\nand multimodal vision-language models. Performance is assessed under zero-shot\nsettings using precision, recall, and F1 metrics. While larger models like\nDeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent\nchallenges in reliably identifying the 'Victim' class and generalising across\ncultural and code-mixed content. We also explore prompt design strategies to\nguide multimodal models and find that hybrid prompts incorporating structured\ninstructions and role definitions offer marginal yet consistent improvements.\nOur findings underscore the importance of cultural grounding, prompt\nengineering, and multimodal reasoning in modelling subtle narrative framings in\nvisual-textual content.", "AI": {"tldr": "This paper explores the task of classifying narrative roles (Hero, Villain, Victim, and Other) in diverse Internet memes, focusing on cultural and linguistic challenges. It evaluates various machine learning models and prompt techniques.", "motivation": "The authors aim to tackle the nuanced and context-rich task of identifying narrative roles in memes, an area underexplored compared to synthetic hateful content detection. They wish to address cultural and linguistic diversity while improving model performance.", "method": "The study uses an extended and balanced dataset to classify narrative roles in both English and code-mixed memes. This involves analyzing the lexical and structural differences and benchmarking models like multilingual transformers, instruction-tuned LLMs, and multimodal models under zero-shot settings.", "result": "Larger models such as DeBERTa-v3 and Qwen2.5-VL perform better, but challenges persist in identifying the 'Victim' role and adapting to cultural and code-mixed content. Prompt engineering shows minor improvements.", "conclusion": "The research highlights the significance of incorporating cultural context and utilizing effective prompt design for detecting narrative roles in diverse, multimodal memes, while also acknowledging current limitations."}}
{"id": "2506.23739", "pdf": "https://arxiv.org/pdf/2506.23739", "abs": "https://arxiv.org/abs/2506.23739", "authors": ["Lisa Marie Otto", "Michael Kaiser", "Daniel Seebacher", "Steffen M\u00fcller"], "title": "Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment", "categories": ["cs.RO", "cs.CE", "cs.HC"], "comment": "6 pages, 5 figures, Preprint for 2025 IEEE IAVVC (International\n  Automated Vehicle Validation Conference)", "summary": "Ensuring safe and realistic interactions between automated driving systems\nand vulnerable road users (VRUs) in urban environments requires advanced\ntesting methodologies. This paper presents a test environment that combines a\nVehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the\nfeasibility of cyber-physical (CP) testing of vehicle-pedestrian and\nvehicle-cyclist interactions. Building upon previous work focused on pedestrian\nlocalization, we further validate a human pose estimation (HPE) approach\nthrough a comparative analysis of real-world (RW) and virtual representations\nof VRUs. The study examines the perception of full-body motion using a\ncommercial monocular camera-based 3Dskeletal detection AI. The virtual scene is\ngenerated in Unreal Engine 5, where VRUs are animated in real time and\nprojected onto a screen to stimulate the camera. The proposed stimulation\ntechnique ensures the correct perspective, enabling realistic vehicle\nperception. To assess the accuracy and consistency of HPE across RW and CP\ndomains, we analyze the reliability of detections as well as variations in\nmovement trajectories and joint estimation stability. The validation includes\ndynamic test scenarios where human avatars, both walking and cycling, are\nmonitored under controlled conditions. Our results show a strong alignment in\nHPE between RW and CP test conditions for stable motion patterns, while notable\ninaccuracies persist under dynamic movements and occlusions, particularly for\ncomplex cyclist postures. These findings contribute to refining CP testing\napproaches for evaluating next-generation AI-based vehicle perception and to\nenhancing interaction models of automated vehicles and VRUs in CP environments.", "AI": {"tldr": "The paper explores advanced testing methods for automated vehicles interacting with pedestrians and cyclists by using a cyber-physical test environment and validating human pose estimation techniques.", "motivation": "Improving interaction safety and realism between automated vehicles and vulnerable road users (VRUs) in urban scenarios demands new testing approaches.", "method": "A test environment combining a Vehicle-in-the-Loop (ViL) test bench and motion laboratory is used to validate HPE with comparative analysis between real-world and virtual settings, utilizing Unreal Engine 5 for virtual representations.", "result": "Human pose estimation in real-world and cyber-physical testing conditions shows alignment for stable motion patterns but faces inaccuracies in dynamic scenarios and complex cyclist postures.", "conclusion": "The research refines cyber-physical testing methods for validating AI-based vehicle perception and interaction models in urban environments, highlighting challenges with dynamic movements and occlusions."}}
{"id": "2506.23773", "pdf": "https://arxiv.org/pdf/2506.23773", "abs": "https://arxiv.org/abs/2506.23773", "authors": ["Stefano M. Nicoletti", "Mari\u00eblle Stoelinga"], "title": "BayesL: Towards a Logical Framework for Bayesian Networks", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model.", "AI": {"tldr": "Introduction of BayesL, a framework for querying and verifying Bayesian networks.", "motivation": "The paper aims to simplify and enhance the process of querying and analyzing Bayesian networks via a structured logical framework.", "method": "Development of BayesL, a language that allows versatile reasoning, including causal and evidence-based relationships, and executing hypothetical scenarios.", "result": "BayesL provides a means to query Bayesian networks without manual modifications, streamlining what-if evaluations.", "conclusion": "BayesL introduces a powerful logical tool for interacting with Bayesian networks, improving efficiency and versatility in reasoning processes."}}
{"id": "2506.24007", "pdf": "https://arxiv.org/pdf/2506.24007", "abs": "https://arxiv.org/abs/2506.24007", "authors": ["Masahiro Kato"], "title": "Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "comment": null, "summary": "This study investigates adaptive experimental design for treatment choice,\nalso known as fixed-budget best-arm identification. We consider an adaptive\nprocedure consisting of a treatment-allocation phase followed by a\ntreatment-choice phase, and we design an adaptive experiment for this setup to\nefficiently identify the best treatment arm, defined as the one with the\nhighest expected outcome. In our designed experiment, the treatment-allocation\nphase consists of two stages. The first stage is a pilot phase, where we\nallocate each treatment arm uniformly with equal proportions to eliminate\nclearly suboptimal arms and estimate outcome variances. In the second stage, we\nallocate treatment arms in proportion to the variances estimated in the first\nstage. After the treatment-allocation phase, the procedure enters the\ntreatment-choice phase, where we choose the treatment arm with the highest\nsample mean as our estimate of the best treatment arm. We prove that this\nsingle design is simultaneously asymptotically minimax and Bayes optimal for\nthe simple regret, with upper bounds that match our lower bounds up to exact\nconstants. Therefore, our designed experiment achieves the sharp efficiency\nlimits without requiring separate tuning for minimax and Bayesian objectives.", "AI": {"tldr": "This paper introduces an adaptive experimental design for selecting the best treatment arm efficiently, utilizing a two-stage treatment-allocation process followed by a treatment-choice phase, achieving optimal performance for minimizing regret.", "motivation": "The study addresses the need for efficient methods to identify the best treatment arm in adaptive experimental settings, where clear suboptimal arms can be eliminated early.", "method": "The method consists of a two-stage adaptive treatment-allocation process: a uniform pilot stage to eliminate suboptimal arms and estimate variances, followed by proportional allocation in the second stage and a treatment-choice phase selecting the arm with the highest sample mean.", "result": "The designed experiment achieves asymptotically optimal performance for both minimax and Bayesian objectives in terms of simple regret, with theoretical upper bounds matching lower bounds up to exact constants.", "conclusion": "This experiment achieves sharp efficiency limits and does not require separate tuning for minimax and Bayesian objectives, making it highly effective for treatment arm identification."}}
{"id": "2506.22901", "pdf": "https://arxiv.org/pdf/2506.22901", "abs": "https://arxiv.org/abs/2506.22901", "authors": ["Sina Tabakhi", "Haiping Lu"], "title": "Missing-Modality-Aware Graph Neural Network for Cancer Classification", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.GN"], "comment": "15 pages, 7 figures", "summary": "A key challenge in learning from multimodal biological data is missing\nmodalities, where all data from some modalities are missing for some patients.\nCurrent fusion methods address this by excluding patients with missing\nmodalities, imputing missing modalities, or making predictions directly with\npartial modalities. However, they often struggle with diverse missing-modality\npatterns and the exponential growth of the number of such patterns as the\nnumber of modalities increases. To address these limitations, we propose MAGNET\n(Missing-modality-Aware Graph neural NETwork) for direct prediction with\npartial modalities, which introduces a patient-modality multi-head attention\nmechanism to fuse lower-dimensional modality embeddings based on their\nimportance and missingness. MAGNET's complexity increases linearly with the\nnumber of modalities while adapting to missing-pattern variability. To generate\npredictions, MAGNET further constructs a patient graph with fused multimodal\nembeddings as node features and the connectivity determined by the modality\nmissingness, followed by a conventional graph neural network. Experiments on\nthree public multiomics datasets for cancer classification, with real-world\ninstead of artificial missingness, show that MAGNET outperforms the\nstate-of-the-art fusion methods. The data and code are available at\nhttps://github.com/SinaTabakhi/MAGNET.", "AI": {"tldr": "This paper proposes MAGNET, a graph neural network approach that effectively handles missing modalities in multimodal biological data, outperforming current methods in cancer classification tasks.", "motivation": "The paper aims to address the issue of missing modalities in multimodal biological datasets where traditional approaches struggle due to the diversity of missing-modality patterns and scalability concerns as the number of modalities increases.", "method": "MAGNET employs a patient-modality multi-head attention mechanism to fuse modality embeddings dynamically based on importance and missingness, followed by a graph neural network utilizing a patient graph with fused multimodal embeddings as node features.", "result": "The proposed method significantly outperformed state-of-the-art fusion techniques in cancer classification tasks on three public multiomics datasets that included real-world missingness scenarios.", "conclusion": "MAGNET offers an effective and scalable solution for predictive tasks in multimodal biological data with missing modalities, addressing variability in missing-patterns and demonstrating superior performance over existing methods."}}
{"id": "2506.22762", "pdf": "https://arxiv.org/pdf/2506.22762", "abs": "https://arxiv.org/abs/2506.22762", "authors": ["Dinh Phu Tran", "Dao Duy Hung", "Daeyoung Kim"], "title": "VSRM: A Robust Mamba-Based Framework for Video Super-Resolution", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Video super-resolution remains a major challenge in low-level vision tasks.\nTo date, CNN- and Transformer-based methods have delivered impressive results.\nHowever, CNNs are limited by local receptive fields, while Transformers\nstruggle with quadratic complexity, posing challenges for processing long\nsequences in VSR. Recently, Mamba has drawn attention for its long-sequence\nmodeling, linear complexity, and large receptive fields. In this work, we\npropose VSRM, a novel \\textbf{V}ideo \\textbf{S}uper-\\textbf{R}esolution\nframework that leverages the power of \\textbf{M}amba. VSRM introduces\nSpatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract\nlong-range spatio-temporal features and enhance receptive fields efficiently.\nTo better align adjacent frames, we propose Deformable Cross-Mamba Alignment\nmodule. This module utilizes a deformable cross-mamba mechanism to make the\ncompensation stage more dynamic and flexible, preventing feature distortions.\nFinally, we minimize the frequency domain gaps between reconstructed and\nground-truth frames by proposing a simple yet effective Frequency\nCharbonnier-like loss that better preserves high-frequency content and enhances\nvisual quality. Through extensive experiments, VSRM achieves state-of-the-art\nresults on diverse benchmarks, establishing itself as a solid foundation for\nfuture research.", "AI": {"tldr": "This paper introduces VSRM, a novel video super-resolution framework leveraging Mamba's strengths for improved long-range spatio-temporal feature extraction and performance.", "motivation": "The authors aim to address limitations of current CNNs and Transformers for video super-resolution tasks, such as local receptive fields or high computational complexity, by leveraging Mamba's strengths.", "method": "The method involves designing novel blocks (Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba) for extracting features, a Deformable Cross-Mamba Alignment module for dynamic frame alignment, and a Frequency Charbonnier-like loss for enhancing reconstruction quality.", "result": "VSRM achieves state-of-the-art performance across various video super-resolution benchmarks, demonstrating its effectiveness.", "conclusion": "The proposed framework establishes itself as a foundational approach for future research in video super-resolution, offering efficient and high-quality outcomes."}}
{"id": "2506.23127", "pdf": "https://arxiv.org/pdf/2506.23127", "abs": "https://arxiv.org/abs/2506.23127", "authors": ["Zhaoye Fei", "Li Ji", "Siyin Wang", "Junhao Shi", "Jingjing Gong", "Xipeng Qiu"], "title": "Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they face significant challenges in embodied task planning\nscenarios that require continuous environmental understanding and action\ngeneration. Existing approaches generate open-loop action scripts based on\nstatic knowledge, making it difficult to learn causal relationships between\nactions and environmental feedback, particularly in partially observable\nenvironments. We introduce Embodied Planner-R1, a novel outcome-driven\nreinforcement learning framework that enables LLMs to develop interactive\ncapabilities through autonomous exploration with minimal supervision. Our\nframework incorporates three key innovations: (1) Without human annotations, we\nemploy pure reinforcement learning with group rollout, incorporating\nin-environment interaction through parallel exploration; (2) completion-driven\nsparse reward; and (3) Interactive Policy Optimization (IPO) for efficient\nlearning from grouped trajectories. Across two challenging text-based Embodied\nplanning benchmarks, Embodied Planner-R1 achieves impressive completion rates\nof 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a\nlarge margin, and suffers only a -3.66% drop in previously unseen environments,\nevidencing strong generalization.", "AI": {"tldr": "The paper presents the Embodied Planner-R1, a reinforcement learning framework enabling Large Language Models to perform task planning in interactive and partially observable environments.", "motivation": "Current LLMs struggle with embodied task planning due to reliance on static action scripts and difficulty in learning causal relations in dynamic settings.", "method": "Embodied Planner-R1 employs pure reinforcement learning with group rollout, sparse rewards, and Interactive Policy Optimization for effective learning in dynamic environments without human supervision.", "result": "Embodied Planner-R1 achieved high completion rates (97.78% on ALFWorld, 79.92% on ScienceWorld) and strong generalization in unseen environments.", "conclusion": "The framework significantly boosts LLMs' ability to plan and interact in complex environments, outperforming existing methods by a wide margin."}}
{"id": "2506.23768", "pdf": "https://arxiv.org/pdf/2506.23768", "abs": "https://arxiv.org/abs/2506.23768", "authors": ["Vittorio La Barbera", "Steven Bohez", "Leonard Hasenclever", "Yuval Tassa", "John R. Hutchinson"], "title": "Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model", "categories": ["cs.RO"], "comment": null, "summary": "We introduce a novel musculoskeletal model of a dog, procedurally generated\nfrom accurate 3D muscle meshes. Accompanying this model is a motion\ncapture-based locomotion task compatible with a variety of control algorithms,\nas well as an improved muscle dynamics model designed to enhance convergence in\ndifferentiable control frameworks. We validate our approach by comparing\nsimulated muscle activation patterns with experimentally obtained\nelectromyography (EMG) data from previous canine locomotion studies. This work\naims to bridge gaps between biomechanics, robotics, and computational\nneuroscience, offering a robust platform for researchers investigating muscle\nactuation and neuromuscular control.We plan to release the full model along\nwith the retargeted motion capture clips to facilitate further research and\ndevelopment.", "AI": {"tldr": "The paper presents a novel procedural musculoskeletal model of a dog, validated with EMG data and designed for bridging biomechanics, robotics, and neuroscience.", "motivation": "The work is motivated by the need for a robust platform to study muscle actuation and neuromuscular control across biomechanics, robotics, and computational neuroscience.", "method": "A dog musculoskeletal model is procedurally generated from 3D muscle meshes, coupled with a motion-capture locomotion task and an enhanced muscle dynamics model for differentiable control.", "result": "The model's muscle activation patterns were validated against experimental canine EMG data, showing its ability to replicate realistic neuromuscular behaviors.", "conclusion": "The paper provides a valuable tool for interdisciplinary research, with plans to release the model and datasets for further academic investigations."}}
{"id": "2506.23784", "pdf": "https://arxiv.org/pdf/2506.23784", "abs": "https://arxiv.org/abs/2506.23784", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "Julie Cailler", "Chencheng Liang", "Philipp R\u00fcmmer"], "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation.", "AI": {"tldr": "This paper explores using Graph Neural Networks (GNNs) to optimize the solving of word equations by ranking them effectively.", "motivation": "To enhance the efficiency of solving conjunctions of word equations, particularly by addressing how the order of equation processing impacts solver performance.", "method": "Introduces a graph-based representation for word equations, employs GNNs for ranking equations, and adapts multi-classification approaches for handling variable numbers of conjuncts. Training relies on minimum unsatisfiable subsets of word equations.", "result": "The proposed framework outperforms state-of-the-art string solvers in benchmarks where variables appear once per equation.", "conclusion": "GNNs, aided by a holistic representation of word equations, provide a more efficient framework for solving word equations."}}
{"id": "2506.24042", "pdf": "https://arxiv.org/pdf/2506.24042", "abs": "https://arxiv.org/abs/2506.24042", "authors": ["Gen Li", "Yuchen Zhou", "Yuting Wei", "Yuxin Chen"], "title": "Faster Diffusion Models via Higher-Order Approximation", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In this paper, we explore provable acceleration of diffusion models without\nany additional retraining. Focusing on the task of approximating a target data\ndistribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation\ndistance, we propose a principled, training-free sampling algorithm that\nrequires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate\nscores, where $K$ is an arbitrarily large fixed integer. This result applies to\na broad class of target data distributions, without the need for assumptions\nsuch as smoothness or log-concavity. Our theory is robust vis-a-vis inexact\nscore estimation, degrading gracefully as the score estimation error increases\n-- without demanding higher-order smoothness on the score estimates as assumed\nin previous work. The proposed algorithm draws insight from high-order ODE\nsolvers, leveraging high-order Lagrange interpolation and successive refinement\nto approximate the integral derived from the probability flow ODE.", "AI": {"tldr": "The paper introduces a training-free diffusion model acceleration algorithm that significantly reduces score function evaluations during data distribution approximation.", "motivation": "To demonstrate a method for efficiently approximating target data distributions using diffusion models without retraining or assuming smoothness/log-concavity.", "method": "The authors propose a sampling algorithm inspired by high-order ODE solvers, using Lagrange interpolation and successive refinement for efficient integration.", "result": "The algorithm operates with order $d^{1+2/K} \\varepsilon^{-1/K}$ score function evaluations for any large integer $K$, and its performance is robust to inexact score estimation.", "conclusion": "The proposed method provides a theoretical advancement in diffusion model efficiency, with broad applicability to diverse distributions and robustness to score estimation errors."}}
{"id": "2506.22927", "pdf": "https://arxiv.org/pdf/2506.22927", "abs": "https://arxiv.org/abs/2506.22927", "authors": ["Jaeyun Woo", "Jiseok Lee", "Brian Kenji Iwana"], "title": "Towards Time Series Generation Conditioned on Unstructured Natural Language", "categories": ["cs.LG"], "comment": null, "summary": "Generative Artificial Intelligence (AI) has rapidly become a powerful tool,\ncapable of generating various types of data, such as images and text. However,\ndespite the significant advancement of generative AI, time series generative AI\nremains underdeveloped, even though the application of time series is essential\nin finance, climate, and numerous fields. In this research, we propose a novel\nmethod of generating time series conditioned on unstructured natural language\ndescriptions. We use a diffusion model combined with a language model to\ngenerate time series from the text. Through the proposed method, we demonstrate\nthat time series generation based on natural language is possible. The proposed\nmethod can provide various applications such as custom forecasting, time series\nmanipulation, data augmentation, and transfer learning. Furthermore, we\nconstruct and propose a new public dataset for time series generation,\nconsisting of 63,010 time series-description pairs.", "AI": {"tldr": "The paper introduces a novel approach for generating time series data from natural language descriptions.", "motivation": "Time series generative AI is underdeveloped despite its importance in fields like finance and climate.", "method": "Combining a diffusion model with a language model to produce time series data from text descriptions.", "result": "The research successfully demonstrates the feasibility of generating time series based on natural language inputs and introduces a related public dataset.", "conclusion": "This approach opens possibilities for custom forecasting, data manipulation, and other advanced applications in time series analysis, supported by a new dataset innovation."}}
{"id": "2506.22783", "pdf": "https://arxiv.org/pdf/2506.22783", "abs": "https://arxiv.org/abs/2506.22783", "authors": ["Oguzhan Baser", "Ahmet Ege Tanriverdi", "Sriram Vishwanath", "Sandeep P. Chinchali"], "title": "PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "5 pages, 3 figures, Published at Proceedings of Interspeech 2025, for\n  the dataset see https://huggingface.co/datasets/phonemefake/PhonemeFakeV2,\n  for the code see https://github.com/UTAustin-SwarmLab/ PhonemeFake", "summary": "Deepfake (DF) attacks pose a growing threat as generative models become\nincreasingly advanced. However, our study reveals that existing DF datasets\nfail to deceive human perception, unlike real DF attacks that influence public\ndiscourse. It highlights the need for more realistic DF attack vectors. We\nintroduce PhonemeFake (PF), a DF attack that manipulates critical speech\nsegments using language reasoning, significantly reducing human perception by\nup to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF\ndataset on HuggingFace and open-source bilevel DF segment detection model that\nadaptively prioritizes compute on manipulated regions. Our extensive\nexperiments across three known DF datasets reveal that our detection model\nreduces EER by 91% while achieving up to 90% speed-up, with minimal compute\noverhead and precise localization beyond existing models as a scalable\nsolution.", "AI": {"tldr": "The paper presents PhonemeFake (PF), a realistic deepfake (DF) attack targeting speech, which challenges current human perception and detection models.", "motivation": "Existing deepfake datasets fail to accurately mimic real-world attacks and deceive human perception, indicating an urgent need for more realistic attack vectors.", "method": "The study introduces PhonemeFake (PF), a data set and model that uses language reasoning to manipulate critical speech segments, along with an open-source bilevel DF segment detection model for adaptive computation.", "result": "PhonemeFake reduces human perceptibility by 42%, decreases detection benchmark accuracy by 94%, and the new detection model improves efficiency by reducing EER by 91% while speeding computation by up to 90%.", "conclusion": "PhonemeFake provides a scalable and effective deepfake attack and detection framework, outperforming existing models with enhanced accuracy, speed, and precise localization. The proposed tools are open-sourced for community use."}}
{"id": "2506.23133", "pdf": "https://arxiv.org/pdf/2506.23133", "abs": "https://arxiv.org/abs/2506.23133", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Rongyu Cao", "Longxu Dou", "Xianzhen Luo", "Yingwei Ma", "Qingfu Zhu", "Wanxiang Che", "Binhua Li", "Fei Huang", "Yongbin Li"], "title": "Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format", "categories": ["cs.CL"], "comment": null, "summary": "Generating and voting multiple answers is an effective method to mitigate\nreasoning inconsistencies of large language models (LLMs). Prior works have\nshown that multiple reasoning formats outperform a single format when\ngenerating multiple answers. However, previous works using multiple formats\nrely on formats labeled by humans, which could be unsuitable for all tasks and\nhave high labeling costs. To address this issue, we adapt suitable formats to\nthe given tasks by generating and selecting formats. We first propose how to\nmeasure the reasoning error when generating multiple answers. Then, we\nintroduce Format-Adapter, which utilizes LLMs to generate and select suitable\nreasoning formats by minimizing the error measurement we present. We conduct\nexperiments on math and commonsense reasoning tasks, where Format-Adapter\nachieves a 4.3% performance improvement on average over previous works,\ndemonstrating the effectiveness.", "AI": {"tldr": "This paper introduces Format-Adapter, a system that adapts reasoning formats to tasks for improving the consistency of large language models' (LLMs) answers, leading to measurable performance improvement.", "motivation": "Previous methods for improving reasoning consistency in LLMs rely on predefined reasoning formats, which are costly to label and may not be suitable for all tasks.", "method": "The paper proposes Format-Adapter, which measures reasoning errors and uses LLMs to generate and select suitable formats to minimize errors when producing multiple answers.", "result": "Experiments on math and commonsense reasoning tasks show that Format-Adapter improves performance by an average of 4.3% compared to prior works.", "conclusion": "Automatically adapting reasoning formats to tasks using LLMs enhances their reasoning consistency and performance, showcasing the potential for reduced reliance on human-labeled formats."}}
{"id": "2506.23771", "pdf": "https://arxiv.org/pdf/2506.23771", "abs": "https://arxiv.org/abs/2506.23771", "authors": ["Guizhe Jin", "Zhuoren Li", "Bo Leng", "Ran Yu", "Lu Xiong"], "title": "Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, Submitted to IEEE Robotics and Automation Letters", "summary": "Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)\nand shows clear advantages. However, most RL-based AD methods overlook policy\nstructure design. An RL policy that only outputs short-timescale vehicle\ncontrol commands results in fluctuating driving behavior due to fluctuations in\nnetwork outputs, while one that only outputs long-timescale driving goals\ncannot achieve unified optimality of driving behavior and control. Therefore,\nwe propose a multi-timescale hierarchical reinforcement learning approach. Our\napproach adopts a hierarchical policy structure, where high- and low-level RL\npolicies are unified-trained to produce long-timescale motion guidance and\nshort-timescale control commands, respectively. Therein, motion guidance is\nexplicitly represented by hybrid actions to capture multimodal driving\nbehaviors on structured road and support incremental low-level extend-state\nupdates. Additionally, a hierarchical safety mechanism is designed to ensure\nmulti-timescale safety. Evaluation in simulator-based and HighD dataset-based\nhighway multi-lane scenarios demonstrates that our approach significantly\nimproves AD performance, effectively increasing driving efficiency, action\nconsistency and safety.", "AI": {"tldr": "The paper proposes a multi-timescale hierarchical reinforcement learning (RL) approach for autonomous driving (AD) that increases driving quality in terms of efficiency, safety, and action consistency.", "motivation": "Existing RL-based autonomous driving methods lack a well-structured policy design, leading to either fluctuating driving behavior or the inability to achieve unified optimality of behavior and control.", "method": "The paper introduces a hierarchical policy structure where high-level RL policies generate long-timescale motion guidance, and low-level RL policies produce short-timescale control commands. Hybrid actions are used for multimodal behaviors, and a hierarchical safety mechanism is incorporated.", "result": "Experimental evaluations in simulation and on real-world datasets show significant improvements in driving efficiency, safety, and action consistency using the proposed approach.", "conclusion": "The multi-timescale hierarchical RL framework effectively addresses the limitations of previous methods, providing a unified and safer autonomous driving system."}}
{"id": "2506.23793", "pdf": "https://arxiv.org/pdf/2506.23793", "abs": "https://arxiv.org/abs/2506.23793", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains.", "AI": {"tldr": "The paper introduces MAPF-GPT-DDG, a decentralized MAPF solver that improves upon previous models using a novel delta-data generation mechanism for enhanced scalability and test performance.", "motivation": "Multi-agent pathfinding (MAPF) is critical for solving trajectory planning problems for robots in real-world applications like logistics and search-and-rescue. Efficient and scalable solutions are essential given its NP-hard nature.", "method": "The authors propose MAPF-GPT-DDG, which fine-tunes a pre-trained MAPF model (MAPF-GPT) using centralized expert data and a novel delta-data generation mechanism to improve training efficiency and solution quality.", "result": "MAPF-GPT-DDG surpasses prior learning-based MAPF solvers, achieving better solution quality and solving instances with up to 1 million agents in a single environment.", "conclusion": "MAPF-GPT-DDG marks a significant advancement in scalable and efficient decentralized MAPF solving, demonstrating superior solution quality and unprecedented scalability for large agent instances."}}
{"id": "2506.24120", "pdf": "https://arxiv.org/pdf/2506.24120", "abs": "https://arxiv.org/abs/2506.24120", "authors": ["Yuqing Wang", "Shangding Gu"], "title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Data selection plays a crucial role in data-driven decision-making, including\nin large language models (LLMs), and is typically task-dependent. Properties\nsuch as data quality and diversity have been extensively studied and are known\nto enhance model performance. However, it remains unclear whether there exist\nother quantitative and general principles of data selection that can\nconsistently improve performance, especially for complex tasks with limited\nprior knowledge. In this paper, we demonstrate that selecting more uniformly\ndistributed data can improve training efficiency while enhancing performance.\nSpecifically, we establish that more uniform (less biased) distribution leads\nto a larger minimum pairwise distance between data points, denoted by\n$h_{\\min}$, and prove that a smaller $h_{\\min}$ can slow down the training\ndynamics of gradient descent (GD). Moreover, we theoretically show that the\napproximation error of neural networks decreases as $h_{\\min}$ increases. Our\nanalysis introduces a convergence framework for GD beyond the Neural Tangent\nKernel (NTK) regime, applicable to a broad class of architectures, including\ntransformers, without requiring Lipschitz smoothness. This framework further\nprovides theoretical justification for the use of residual connections and\nfunction compositions in deep neural architectures. In the end, we conduct\ncomprehensive experiments for supervised fine-tuning across various settings,\nincluding different optimization strategies, model sizes, and training\ndatasets. The results consistently demonstrate that selecting data by\nmaximizing pairwise distance significantly accelerates training and achieves\ncomparable or better performance in LLMs across diverse datasets. Code and\nDatasets are available at the link:\nhttps://github.com/SafeRL-Lab/data-uniformity.", "AI": {"tldr": "This paper investigates the role of data uniformity in improving training efficiency and performance in large language models, introducing the metric $h_{\\min}$ to quantify data distribution's impact.", "motivation": "The motivation is to identify general and quantitative principles for data selection that consistently enhance performance, especially for complex tasks with limited prior knowledge.", "method": "The authors theoretically and experimentally demonstrate that selecting uniformly distributed data points, quantified by maximizing $h_{\\min}$ (minimum pairwise distance), improves training dynamics and reduces approximation error in neural networks.", "result": "The study shows that data selection maximizing $h_{\\min}$ accelerates training, boosts performance, and generalizes well across various datasets, model sizes, and optimization strategies.", "conclusion": "Uniformity in data distribution is a valuable principle for data-driven tasks, offering both theoretical insights and practical benefits for improving large language model training."}}
{"id": "2506.22929", "pdf": "https://arxiv.org/pdf/2506.22929", "abs": "https://arxiv.org/abs/2506.22929", "authors": ["Chen Zhang"], "title": "Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration", "categories": ["cs.LG", "cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "While deep learning excels in natural image and language processing, its\napplication to high-dimensional data faces computational challenges due to the\ndimensionality curse. Current large-scale data tools focus on business-oriented\ndescriptive statistics, lacking mathematical statistics support for advanced\nanalysis. We propose a parallel computation architecture based on space\ncompleteness, decomposing high-dimensional data into dimension-independent\nstructures for distributed processing. This framework enables seamless\nintegration of data mining and parallel-optimized machine learning methods,\nsupporting scientific computations across diverse data types like medical and\nnatural images within a unified system.", "AI": {"tldr": "The paper proposes a parallel computation architecture to overcome the computational limitations of deep learning for high-dimensional data.", "motivation": "Deep learning struggles with computational inefficiencies when applied to high-dimensional data due to the curse of dimensionality, creating a need for effective solutions.", "method": "A new parallel computation architecture is introduced, leveraging space completeness to decompose high-dimensional data for distributed processing.", "result": "This architecture integrates data mining and parallel-optimized machine learning methods, enhancing scientific computations for diverse data types under a unified system.", "conclusion": "The proposed framework enables efficient handling of high-dimensional data, supporting advanced analysis and broad applicability across scientific domains such as medical imaging."}}
{"id": "2506.22784", "pdf": "https://arxiv.org/pdf/2506.22784", "abs": "https://arxiv.org/abs/2506.22784", "authors": ["Yu Han", "Zhiwei Huang", "Yanting Zhang", "Fangjun Ding", "Shen Cai", "Rui Fan"], "title": "Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Point-pixel registration between LiDAR point clouds and camera images is a\nfundamental yet challenging task in autonomous driving and robotic perception.\nA key difficulty lies in the modality gap between unstructured point clouds and\nstructured images, especially under sparse single-frame LiDAR settings.\nExisting methods typically extract features separately from point clouds and\nimages, then rely on hand-crafted or learned matching strategies. This separate\nencoding fails to bridge the modality gap effectively, and more critically,\nthese methods struggle with the sparsity and noise of single-frame LiDAR, often\nrequiring point cloud accumulation or additional priors to improve reliability.\nInspired by recent progress in detector-free matching paradigms (e.g.\nMatchAnything), we revisit the projection-based approach and introduce the\ndetector-free framework for direct point-pixel matching between LiDAR and\ncamera views. Specifically, we project the LiDAR intensity map into a 2D view\nfrom the LiDAR perspective and feed it into an attention-based detector-free\nmatching network, enabling cross-modal correspondence estimation without\nrelying on multi-frame accumulation. To further enhance matching reliability,\nwe introduce a repeatability scoring mechanism that acts as a soft visibility\nprior. This guides the network to suppress unreliable matches in regions with\nlow intensity variation, improving robustness under sparse input. Extensive\nexperiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that\nour method achieves state-of-the-art performance, outperforming prior\napproaches on nuScenes (even those relying on accumulated point clouds),\ndespite using only single-frame LiDAR.", "AI": {"tldr": "The paper proposes a detector-free framework for point-pixel registration between LiDAR point clouds and camera images, addressing challenges of sparsity and noise in single-frame LiDAR data.", "motivation": "The motivation is to overcome the challenges of modality gaps and sparsity in point-pixel registration between LiDAR point clouds and camera images, which are essential for autonomous driving and robotic perception.", "method": "The method involves projecting LiDAR intensity maps into 2D views and using an attention-based detector-free matching network with a repeatability scoring mechanism to enhance reliability in sparse LiDAR settings.", "result": "The proposed approach achieves state-of-the-art performance on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks, outperforming methods that rely on multi-frame accumulation.", "conclusion": "The method effectively bridges the modality gap and addresses sparsity issues, offering a robust and reliable solution for single-frame LiDAR point-pixel registration."}}
{"id": "2506.23136", "pdf": "https://arxiv.org/pdf/2506.23136", "abs": "https://arxiv.org/abs/2506.23136", "authors": ["Shadman Sobhan", "Mohammad Ariful Haque"], "title": "LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation", "categories": ["cs.CL"], "comment": "29 Pages, 11 Tables", "summary": "Large Language Models (LLMs) are capable of natural language understanding\nand generation. But they face challenges such as hallucination and outdated\nknowledge. Fine-tuning is one possible solution, but it is resource-intensive\nand must be repeated with every data update. Retrieval-Augmented Generation\n(RAG) offers an efficient solution by allowing LLMs to access external\nknowledge sources. However, traditional RAG pipelines struggle with retrieving\ninformation from complex technical documents with structured data such as\ntables and images. In this work, we propose a RAG pipeline, capable of handling\ntables and images in documents, for technical documents that support both\nscanned and searchable formats. Its retrieval process combines vector\nsimilarity search with a fine-tuned reranker based on Gemma-2-9b-it. The\nreranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom\ndataset designed to improve context identification for question answering. Our\nevaluation demonstrates that the proposed pipeline achieves a high faithfulness\nscore of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87%\n(RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed\narchitecture is superior to general RAG pipelines in terms of table-based\nquestions and handling questions outside context.", "AI": {"tldr": "The paper proposes an enhanced Retrieval-Augmented Generation (RAG) pipeline for large language models (LLMs) that effectively handles information from technical documents with tables and images, and demonstrates improvements in faithfulness and answer relevancy.", "motivation": "LLMs face significant challenges like hallucination and outdated knowledge, and while fine-tuning can address these issues, it is not efficient for frequent updates. Traditional RAG systems struggle with retrieving data from complex technical documents.", "method": "The authors develop a RAG pipeline combining vector similarity search with a fine-tuned reranker, trained on their custom RAFT dataset, specifically for improving context identification in question answering on technical documents.", "result": "The proposed pipeline achieves a faithfulness score of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87% (RAGas) and 93% (DeepEval), outperforming general RAG systems, particularly in table-based questions and out-of-context queries.", "conclusion": "The enhanced RAG pipeline effectively improves LLM performance in technical document retrieval and question answering, offering a more efficient and accurate alternative to traditional RAG systems."}}
{"id": "2506.23781", "pdf": "https://arxiv.org/pdf/2506.23781", "abs": "https://arxiv.org/abs/2506.23781", "authors": ["Savvas Papaioannou", "Panayiotis Kolios", "Christos G. Panayiotou", "Marios M. Polycarpou"], "title": "Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "2025 European Control Conference (ECC), Thessaloniki, Greece, 24-27\n  June 2025", "summary": "Automated inspection with Unmanned Aerial Systems (UASs) is a transformative\ncapability set to revolutionize various application domains. However, this task\nis inherently complex, as it demands the seamless integration of perception,\nplanning, and control which existing approaches often treat separately.\nMoreover, it requires accurate long-horizon planning to predict action\nsequences, in contrast to many current techniques, which tend to be myopic. To\novercome these limitations, we propose a 3D inspection approach that unifies\nperception, planning, and control within a single data-driven predictive\ncontrol framework. Unlike traditional methods that rely on known UAS dynamic\nmodels, our approach requires only input-output data, making it easily\napplicable to off-the-shelf black-box UASs. Our method incorporates back-face\nelimination, a visibility determination technique from 3D computer graphics,\ndirectly into the control loop, thereby enabling the online generation of\naccurate, long-horizon 3D inspection trajectories.", "AI": {"tldr": "This paper introduces a novel approach that integrates perception, planning, and control into a single predictive framework for automated 3D inspection with drones.", "motivation": "Traditional unmanned aerial system (UAS) inspection techniques treat perception, planning, and control separately and are often limited by short-horizon planning. This paper seeks to address these issues and simplify the application to various drones.", "method": "The authors propose a comprehensive data-driven predictive control framework that integrates perception, planning, and control. It uses input-output data rather than known UAS dynamics and incorporates 3D computer graphics' back-face elimination for optimizing inspection trajectories.", "result": "The proposed method enables accurate, long-horizon 3D inspection trajectories that can be generated online, potentially outperforming traditional approaches in both versatility and functionality.", "conclusion": "This integrated framework not only simplifies the application to off-the-shelf black-box UASs but also enhances the efficiency and accuracy of automated inspections."}}
{"id": "2506.23844", "pdf": "https://arxiv.org/pdf/2506.23844", "abs": "https://arxiv.org/abs/2506.23844", "authors": ["Hang Su", "Jun Luo", "Chang Liu", "Xiao Yang", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "categories": ["cs.AI"], "comment": "18 pages", "summary": "Recent advances in large language models (LLMs) have catalyzed the rise of\nautonomous AI agents capable of perceiving, reasoning, and acting in dynamic,\nopen-ended environments. These large-model agents mark a paradigm shift from\nstatic inference systems to interactive, memory-augmented entities. While these\ncapabilities significantly expand the functional scope of AI, they also\nintroduce qualitatively novel security risks - such as memory poisoning, tool\nmisuse, reward hacking, and emergent misalignment - that extend beyond the\nthreat models of conventional systems or standalone LLMs. In this survey, we\nfirst examine the structural foundations and key capabilities that underpin\nincreasing levels of agent autonomy, including long-term memory retention,\nmodular tool use, recursive planning, and reflective reasoning. We then analyze\nthe corresponding security vulnerabilities across the agent stack, identifying\nfailure modes such as deferred decision hazards, irreversible tool chains, and\ndeceptive behaviors arising from internal state drift or value misalignment.\nThese risks are traced to architectural fragilities that emerge across\nperception, cognition, memory, and action modules. To address these challenges,\nwe systematically review recent defense strategies deployed at different\nautonomy layers, including input sanitization, memory lifecycle control,\nconstrained decision-making, structured tool invocation, and introspective\nreflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a\nunified cognitive framework grounded in Constrained Markov Decision Processes\n(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,\nand joint reward-risk optimization to enable principled, proactive safety\nacross the agent's decision-making loop.", "AI": {"tldr": "The paper surveys security vulnerabilities of autonomous AI agents and introduces Reflective Risk-Aware Agent Architecture (R2A2), a framework for risk mitigation.", "motivation": "The paper seeks to address novel security risks posed by autonomous AI agents that operate with enhanced capabilities in dynamic, open-ended environments.", "method": "The authors analyze key vulnerabilities of autonomous AI agents and propose the R2A2 architecture based on CMDPs, incorporating risk-aware modeling and strategies for safety.", "result": "The study identifies risks such as memory poisoning and deceptive behaviors, and reviews defense strategies across various autonomy layers.", "conclusion": "The R2A2 framework can potentially enable safer, more reliable operation of autonomous AI agents by mitigating emerging risks proactively."}}
{"id": "2506.22950", "pdf": "https://arxiv.org/pdf/2506.22950", "abs": "https://arxiv.org/abs/2506.22950", "authors": ["Liangyu Wang", "Huanyi Xie", "Xinhai Wang", "Tianjin Huang", "Mengdi Li", "Di Wang"], "title": "Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Group-based reinforcement learning algorithms such as Group Reward Policy\nOptimization (GRPO) have proven effective for fine-tuning large language models\n(LLMs) with human feedback. However, generating and storing multiple responses\nper prompt incurs substantial memory overhead, especially as the sample group\nsize increases, limiting scalability under constrained hardware.\n  We propose Infinite Sampling, a framework that enables efficient and stable\nGRPO training by decoupling group size from GPU memory usage. It consists of:\n(1) micro sampling groups that decompose large groups into memory-feasible\nrounds; (2) continuous sampling that interleaves generation across groups to\nimprove utilization; and (3) a length-aware scheduler combining\ntoken-conditioned sequence length prediction with a two-stage plan: global\ngrouping via FPTAS and runtime refill via SJF.\n  Experiments show that our Micro Sampling Groups reduce peak memory usage by\nover 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on\nQwen3-1.7B). Building on this, Infinite Sampling improves throughput by over\n25% compared to the naive micro sampling group method, reducing decoding steps\nwhile maintaining full-length completions and memory usage. Our hybrid\nscheduling ensures efficient and stable GRPO training with larger groups under\nrealistic GPU memory constraints.", "AI": {"tldr": "This paper introduces Infinite Sampling, a framework enhancing the scalability of Group Reward Policy Optimization (GRPO) in fine-tuning large language models by decoupling memory usage from group size.", "motivation": "Scaling GRPO-based fine-tuning of large language models is challenging due to high memory usage when generating multiple responses per prompt, making it inefficient under hardware constraints.", "method": "The proposed Infinite Sampling framework includes three components: (1) micro sampling groups to break down large groups into smaller memory-efficient rounds, (2) continuous sampling for better GPU utilization, and (3) a length-aware scheduler for runtime efficiency via a two-stage plan combining global grouping and runtime refill strategies.", "result": "The proposed Micro Sampling Groups reduce memory usage by over 50%, and the Infinite Sampling framework increases throughput by 25%, maintaining memory efficiency and enabling stable GRPO training with larger group sizes.", "conclusion": "Infinite Sampling significantly improves GRPO training's memory efficiency and throughput, making it more scalable for fine-tuning large language models on constrained hardware."}}
{"id": "2506.22800", "pdf": "https://arxiv.org/pdf/2506.22800", "abs": "https://arxiv.org/abs/2506.22800", "authors": ["Sicong Du", "Jiarun Liu", "Qifeng Chen", "Hao-Xiang Chen", "Tai-Jiang Mu", "Sheng Yang"], "title": "RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors", "categories": ["cs.CV"], "comment": null, "summary": "A single-pass driving clip frequently results in incomplete scanning of the\nroad structure, making reconstructed scene expanding a critical requirement for\nsensor simulators to effectively regress driving actions. Although contemporary\n3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction\nquality, their direct extension through the integration of diffusion priors\noften introduces cumulative physical inconsistencies and compromises training\nefficiency. To address these limitations, we present RGE-GS, a novel expansive\nreconstruction framework that synergizes diffusion-based generation with\nreward-guided Gaussian integration. The RGE-GS framework incorporates two key\ninnovations: First, we propose a reward network that learns to identify and\nprioritize consistently generated patterns prior to reconstruction phases,\nthereby enabling selective retention of diffusion outputs for spatial\nstability. Second, during the reconstruction process, we devise a\ndifferentiated training strategy that automatically adjust Gaussian\noptimization progress according to scene converge metrics, which achieving\nbetter convergence than baseline methods. Extensive evaluations of publicly\navailable datasets demonstrate that RGE-GS achieves state-of-the-art\nperformance in reconstruction quality. Our source-code will be made publicly\navailable at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version\nincorporating reviewer suggestions will be updated soon.)", "AI": {"tldr": "The paper introduces RGE-GS, a framework that improves road scene reconstruction by combining diffusion-based generation and reward-guided Gaussian integration, achieving superior results without compromising efficiency.", "motivation": "Existing systems often struggle with incomplete road structure scanning during single-pass driving, hampering accurate reconstruction essential for sensor simulation and regression of driving actions.", "method": "RGE-GS incorporates a reward network to prioritize consistent patterns and applies a differentiated training strategy tuned to scene convergence metrics for enhanced Gaussian optimization and spatial stability.", "result": "RGE-GS outperformed baseline methods in reconstruction quality across evaluations using public datasets.", "conclusion": "The proposed framework effectively addresses limitations of current methods, ensuring better reconstruction quality and improving spatial stability during road scene generation, with plans for public code release soon."}}
{"id": "2506.23137", "pdf": "https://arxiv.org/pdf/2506.23137", "abs": "https://arxiv.org/abs/2506.23137", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Effective modeling of multifaceted relations is pivotal for Knowledge Graph\nCompletion (KGC). However, a majority of existing approaches are predicated on\nstatic, embedding-based scoring, exhibiting inherent limitations in capturing\ncontextual dependencies and relational dynamics. Addressing this gap, we\npropose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal\ncomponents: (1) a semantic context learning module that encodes\ncontext-sensitive entity representations, and (2) a conditional flow-matching\nmodule designed to learn the dynamic transformation from a head to a tail\nembedding, governed by the aforementioned context. The resultant predictive\nvector field, representing the context-informed relational path, serves to\ndynamically refine the initial static score of an entity pair. Through this\nsynergy of context-aware static representations and conditioned dynamic\ninformation, FMS facilitates a more profound modeling of relational semantics.\nComprehensive evaluations on several standard benchmarks demonstrate that our\nproposed method surpasses prior state-of-the-art results.", "AI": {"tldr": "The paper introduces Flow-Modulated Scoring (FMS) framework for Knowledge Graph Completion to overcome the limitations of static embedding-based methods by incorporating context-aware dynamic modeling.", "motivation": "Current approaches to Knowledge Graph Completion fail to capture contextual dependencies and relational dynamics as they rely on static scoring through embeddings.", "method": "The paper proposes FMS, which combines a context learning module for entity representation and a flow-matching module for dynamic transformations of embeddings governed by context.", "result": "FMS achieves state-of-the-art results in Knowledge Graph Completion tasks, outperforming existing methods on standard benchmarks.", "conclusion": "By uniting static and dynamic modeling, FMS enhances the representation of relational semantics, marking a significant advancement in Knowledge Graph Completion techniques."}}
{"id": "2506.23919", "pdf": "https://arxiv.org/pdf/2506.23919", "abs": "https://arxiv.org/abs/2506.23919", "authors": ["Haonan Chen", "Bangjun Wang", "Jingxiang Guo", "Tianrui Zhang", "Yiwen Hou", "Xuchuan Huang", "Chenrui Tie", "Lin Shao"], "title": "World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Improving data efficiency and generalization in robotic manipulation remains\na core challenge. We propose a novel framework that leverages a pre-trained\nmultimodal image-generation model as a world model to guide policy learning. By\nexploiting its rich visual-semantic representations and strong generalization\nacross diverse scenes, the model generates open-ended future state predictions\nthat inform downstream manipulation. Coupled with zero-shot low-level control\nmodules, our approach enables general-purpose robotic manipulation without\ntask-specific training. Experiments in both simulation and real-world\nenvironments demonstrate that our method achieves effective performance across\na wide range of manipulation tasks with no additional data collection or\nfine-tuning. Supplementary materials are available on our website:\nhttps://world4omni.github.io/.", "AI": {"tldr": "The paper introduces a framework using a pre-trained multimodal image-generation model to enable general-purpose robotic manipulation with strong performance and no task-specific training.", "motivation": "Address the challenge of data efficiency and generalization in robotic manipulation.", "method": "A multimodal image-generation model is used as a world model to provide open-ended future state predictions, guiding policy learning. It is coupled with zero-shot low-level control modules.", "result": "The method performs effectively across various manipulation tasks in both simulated and real-world settings without task-specific training, data collection, or fine-tuning.", "conclusion": "The proposed framework effectively leverages a pre-trained model for general-purpose robotic manipulation and achieves substantial performance without requiring additional resources."}}
{"id": "2506.23908", "pdf": "https://arxiv.org/pdf/2506.23908", "abs": "https://arxiv.org/abs/2506.23908", "authors": ["Andr\u00e1s Gy\u00f6rgy", "Tor Lattimore", "Nevena Lazi\u0107", "Csaba Szepesv\u00e1ri"], "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design.", "AI": {"tldr": "AI systems, including advanced transformer models, struggle with sound deductive reasoning due to their statistical learning foundations. This paper advocates for a shift towards exact learning, prioritizing correctness on all inputs.", "motivation": "The motivation stems from the need to address the inability of current AI models to consistently perform sound deductive reasoning, a critical aspect of general intelligence, despite their advances in other domains.", "method": "The method proposed is a fundamental shift in research focus from statistical learning approaches, which optimize models for average performance, to exact learning paradigms, which aim for absolute correctness on all inputs.", "result": "The paper offers a strong argument for transitioning to exact learning to achieve better deductive reasoning capabilities in AI systems, though it might not explicitly showcase empirical results.", "conclusion": "To achieve AI with reliable deductive reasoning, the field must adopt exact learning as an essential design principle, focusing on correctness over distributional performance."}}
{"id": "2506.22984", "pdf": "https://arxiv.org/pdf/2506.22984", "abs": "https://arxiv.org/abs/2506.22984", "authors": ["Prathyush Kumar Reddy Lebaku", "Lu Gao", "Yunpeng Zhang", "Zhixia Li", "Yongxin Liu", "Tanvir Arafin"], "title": "Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Anomaly detection in connected autonomous vehicles (CAVs) is crucial for\nmaintaining safe and reliable transportation networks, as CAVs can be\nsusceptible to sensor malfunctions, cyber-attacks, and unexpected environmental\ndisruptions. This study explores an anomaly detection approach by simulating\nvehicle behavior, generating a dataset that represents typical and atypical\nvehicular interactions. The dataset includes time-series data of position,\nspeed, and acceleration for multiple connected autonomous vehicles. We utilized\nmachine learning models to effectively identify abnormal driving patterns.\nFirst, we applied a stacked Long Short-Term Memory (LSTM) model to capture\ntemporal dependencies and sequence-based anomalies. The stacked LSTM model\nprocessed the sequential data to learn standard driving behaviors.\nAdditionally, we deployed a Random Forest model to support anomaly detection by\noffering ensemble-based predictions, which enhanced model interpretability and\nperformance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746,\nand a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model\nattained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly\nthreshold of 265.63. These results demonstrate the models' effectiveness in\naccurately predicting vehicle trajectories and detecting anomalies in\nautonomous driving scenarios.", "AI": {"tldr": "The study employs stacked LSTM and Random Forest models to detect anomalies in connected autonomous vehicles (CAVs) using a simulated dataset of vehicle behavior, achieving high accuracy and demonstrating effectiveness for anomaly detection.", "motivation": "Ensuring safety and reliability in connected autonomous vehicles (CAVs) by detecting sensor malfunctions, cyber-attacks, and environmental disruptions.", "method": "Simulated vehicular behavior to generate a dataset of typical/atypical interactions. Used stacked LSTM model to capture temporal dependencies and sequence-based anomalies, and Random Forest model for ensemble-based anomaly detection.", "result": "The Random Forest model achieved an R2 of 0.9830 and MAE of 5.746, while the stacked LSTM model demonstrated strong temporal prediction with an R2 of 0.9998 yet higher MAE of 82.425.", "conclusion": "The models effectively detect anomalies in CAV behavior, with stacked LSTM excelling in temporal pattern learning and Random Forest providing strong interpretability and reliability."}}
{"id": "2506.22803", "pdf": "https://arxiv.org/pdf/2506.22803", "abs": "https://arxiv.org/abs/2506.22803", "authors": ["Nuoye Xiong", "Anqi Dong", "Ning Wang", "Cong Hua", "Guangming Zhu", "Mei Lin", "Peiyi Shen", "Liang Zhang"], "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Recent advances in deep learning have led to increasingly complex models with\ndeeper layers and more parameters, reducing interpretability and making their\ndecisions harder to understand. While many methods explain black-box reasoning,\nmost lack effective interventions or only operate at sample-level without\nmodifying the model itself. To address this, we propose the Concept Bottleneck\nModel for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).\nCBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable\nframework to approximate black-box reasoning and communicate conceptual\nunderstanding. Detrimental concepts are automatically identified and refined\n(removed/replaced) based on global gradient contributions. The modified CBM\nthen distills corrected knowledge back into the black-box model, enhancing both\ninterpretability and accuracy. We evaluate CBM-HNMU on various CNN and\ntransformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,\nand CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum\nincrease in average accuracy across 1.03%. Source code is available at:\nhttps://github.com/XiGuaBo/CBM-HNMU.", "AI": {"tldr": "This paper proposes CBM-HNMU to improve model interpretability and accuracy by refining concepts and incorporating them back into black-box models.", "motivation": "Deep learning advancements have made models more complex and less interpretable, limiting understanding and interventions beyond sample-level explanations.", "method": "CBM-HNMU identifies and refines detrimental concepts using global gradient contributions and distills corrections back into black-box models via a concept bottleneck approach.", "result": "CBM-HNMU improved the accuracy of CNN and transformer-based models by up to 2.64% on benchmark datasets such as CIFAR-10 and CIFAR-100.", "conclusion": "CBM-HNMU offers a novel framework for enhancing interpretability and performance in deep learning by addressing and refining detrimental conceptual reasoning effectively."}}
{"id": "2506.23139", "pdf": "https://arxiv.org/pdf/2506.23139", "abs": "https://arxiv.org/abs/2506.23139", "authors": ["Prafulla Kumar Choubey", "Xiangyu Peng", "Shilpa Bhagavath", "Kung-Hsiang Huang", "Caiming Xiong", "Chien-Sheng Wu"], "title": "Benchmarking Deep Search over Heterogeneous Enterprise Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present a new benchmark for evaluating Deep Search--a realistic and\ncomplex form of retrieval-augmented generation (RAG) that requires\nsource-aware, multi-hop reasoning over diverse, sparsed, but related sources.\nThese include documents, meeting transcripts, Slack messages, GitHub, and URLs,\nwhich vary in structure and often contain human-to-human interactions. We build\nit using a synthetic data pipeline that simulates business workflows across\nproduct planning, development, and support stages, generating interconnected\ncontent with realistic noise and multi-hop questions with guaranteed\nground-truth answers. We release our benchmark with both answerable and\nunanswerable queries, and retrieval pool of 39,190 enterprise artifacts,\nenabling fine-grained evaluation of long-context LLM and RAG systems. Our\nexperiments reveal that even the best-performing agentic RAG methods achieve an\naverage performance score of 32.96 on our benchmark. With further analysis, we\nhighlight retrieval as the main bottleneck: existing methods struggle to\nconduct deep searches and retrieve all necessary evidence. Consequently, they\noften reason over partial context, leading to significant performance\ndegradation.", "AI": {"tldr": "The paper introduces a new benchmark to assess Deep Search, focusing on retrieval-augmented generation (RAG) involving multi-hop reasoning across diverse and unstructured data sources.", "motivation": "To address the lack of realistic benchmarks for the evaluation of RAG systems that perform deep reasoning over complex and interconnected data sources.", "method": "A synthetic data pipeline was developed to simulate enterprise workflows and generate interconnected content along with multi-hop questions. The benchmark includes both answerable and unanswerable queries and tests retrieval and reasoning capabilities using 39,190 enterprise artifacts.", "result": "Current state-of-the-art RAG systems achieve only a 32.96 performance score, with retrieval identified as the primary bottleneck in achieving higher accuracy.", "conclusion": "The retrieval capabilities in RAG systems need significant improvement to enhance their ability to reason over complete and relevant contexts, which is currently hindering performance."}}
{"id": "2506.23944", "pdf": "https://arxiv.org/pdf/2506.23944", "abs": "https://arxiv.org/abs/2506.23944", "authors": ["Fuhang Kuang", "Jiacheng You", "Yingdong Hu", "Tong Zhang", "Chuan Wen", "Yang Gao"], "title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Imitation learning models for robotic tasks typically rely on multi-modal\ninputs, such as RGB images, language, and proprioceptive states. While\nproprioception is intuitively important for decision-making and obstacle\navoidance, simply incorporating all proprioceptive states leads to a surprising\ndegradation in imitation learning performance. In this work, we identify the\nunderlying issue as the proprioception shift problem, where the distributions\nof proprioceptive states diverge significantly between training and deployment.\nTo address this challenge, we propose a domain adaptation framework that\nbridges the gap by utilizing rollout data collected during deployment. Using\nWasserstein distance, we quantify the discrepancy between expert and rollout\nproprioceptive states and minimize this gap by adding noise to both sets of\nstates, proportional to the Wasserstein distance. This strategy enhances\nrobustness against proprioception shifts by aligning the training and\ndeployment distributions. Experiments on robotic manipulation tasks demonstrate\nthe efficacy of our method, enabling the imitation policy to leverage\nproprioception while mitigating its adverse effects. Our approach outperforms\nthe naive solution which discards proprioception, and other baselines designed\nto address distributional shifts.", "AI": {"tldr": "This paper introduces a domain adaptation framework to mitigate proprioception distribution shifts in imitation learning for robotic tasks, improving model robustness and performance.", "motivation": "Imitation learning models in robotics face a performance drop due to the divergence in proprioceptive state distributions between training and deployment (proprioception shift problem).", "method": "The authors use Wasserstein distance to measure and minimize the gap between training and deployment distributions of proprioceptive states by adding noise proportionate to this distance.", "result": "The proposed method enhances robustness against proprioception shifts and outperforms baselines, including naive proprioception removal, in robotic manipulation experiments.", "conclusion": "Bridging the proprioception shift with a domain adaptation framework enables leveraging proprioception effectively while maintaining or improving imitation learning performance."}}
{"id": "2506.23924", "pdf": "https://arxiv.org/pdf/2506.23924", "abs": "https://arxiv.org/abs/2506.23924", "authors": ["Akshit Kumar", "Tianyi Peng", "Yuhang Wu", "Assaf Zeevi"], "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have exhibited expert-level capabilities across\nvarious domains. However, their abilities to solve problems in Operations\nResearch (OR) -- the analysis and optimization of mathematical models derived\nfrom real-world problems or their verbal descriptions -- remain underexplored.\nIn this work, we take a first step toward evaluating LLMs' abilities to solve\nstochastic modeling problems, a core class of OR problems characterized by\nuncertainty and typically involving tools from probability, statistics, and\nstochastic processes. We manually procure a representative set of\ngraduate-level homework and doctoral qualification-exam problems and test LLMs'\nabilities to solve them. We further leverage SimOpt, an open-source library of\nsimulation-optimization problems and solvers, to investigate LLMs' abilities to\nmake real-world decisions under uncertainty. Our results show that, though a\nnontrivial amount of work is still needed to reliably automate the stochastic\nmodeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on\npar with human experts in both classroom and practical settings. These findings\nhighlight the potential of building AI agents that assist OR researchers and\namplify the real-world impact of OR through automation.", "AI": {"tldr": "The research explores whether large language models (LLMs) can effectively solve stochastic modeling problems in Operations Research (OR) and finds that LLMs perform comparably to human experts, though more work is required for full automation.", "motivation": "This paper aims to investigate the untapped potential of LLMs in solving complex stochastic modeling problems in Operations Research, particularly in scenarios involving uncertainty.", "method": "The study involves evaluating LLMs' performance on a curated set of graduate-level and doctoral OR problems, as well as using the SimOpt simulation-optimization library for practical decision-making tests.", "result": "The experiments reveal that LLMs are proficient in solving complex stochastic modeling problems, comparing favorably to human experts in academic and real-world contexts.", "conclusion": "LLMs show promise in assisting researchers and expanding the impact of Operations Research through partial automation, though further development is needed for full applicability."}}
{"id": "2506.22806", "pdf": "https://arxiv.org/pdf/2506.22806", "abs": "https://arxiv.org/abs/2506.22806", "authors": ["Byung Hyun Lee", "Sungjin Lim", "Seunggyu Lee", "Dong Un Kang", "Se Young Chun"], "title": "Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Remarkable progress in text-to-image diffusion models has brought a major\nconcern about potentially generating images on inappropriate or trademarked\nconcepts. Concept erasing has been investigated with the goals of deleting\ntarget concepts in diffusion models while preserving other concepts with\nminimal distortion. To achieve these goals, recent concept erasing methods\nusually fine-tune the cross-attention layers of diffusion models. In this work,\nwe first show that merely updating the cross-attention layers in diffusion\nmodels, which is mathematically equivalent to adding \\emph{linear} modules to\nweights, may not be able to preserve diverse remaining concepts. Then, we\npropose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding\n\\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or\ncut) target concepts while safeguarding remaining concepts from broad\ndistributions by employing an attention anchoring loss to prevent the\nforgetting. Moreover, we adversarially train CPE with ResAG and learnable text\nembeddings in an iterative manner to maximize erasing performance and enhance\nrobustness against adversarial attacks. Extensive experiments on the erasure of\ncelebrities, artistic styles, and explicit contents demonstrated that the\nproposed CPE outperforms prior arts by keeping diverse remaining concepts while\ndeleting the target concepts with robustness against attack prompts. Code is\navailable at https://github.com/Hyun1A/CPE", "AI": {"tldr": "The paper proposes a new framework called Concept Pinpoint Eraser (CPE) to improve concept erasure in text-to-image diffusion models while preserving unrelated concepts and ensuring robustness against adversarial attacks.", "motivation": "There is growing concern over the misuse of text-to-image diffusion models for generating inappropriate or trademarked concepts, making efficient concept erasure methods essential to address ethical and legal challenges.", "method": "The proposed CPE framework employs nonlinear Residual Attention Gates (ResAGs) and attention anchoring loss to selectively erase target concepts while maintaining unrelated concepts. It uses an iterative adversarial training process with learnable text embeddings to enhance robustness.", "result": "Experiments show that CPE outperforms existing concept erasure methods by effectively removing target concepts, preserving a wide range of unrelated concepts, and demonstrating robustness against adversarial attack prompts.", "conclusion": "The CPE framework offers a significant improvement for concept erasure in diffusion models, maintaining a balanced preservation of unrelated features while addressing robustness challenges effectively."}}
{"id": "2506.23146", "pdf": "https://arxiv.org/pdf/2506.23146", "abs": "https://arxiv.org/abs/2506.23146", "authors": ["Dingzriui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions", "categories": ["cs.CL"], "comment": null, "summary": "In-context learning (ICL) has emerged as an effective approach to enhance the\nperformance of large language models (LLMs). However, its effectiveness varies\nsignificantly across models and tasks, posing challenges for practitioners to\ndetermine when ICL reliably improves performance. Current evaluation\napproaches, reliant on performance change after applying ICL, suffer from low\nreliability, poor attribution, and impracticality in data-insufficient\nscenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that\nquantifies ICL effectiveness by modeling the slope between learning gain (loss\ndecrease from demonstrations) and contextual relevance (demonstration-input\nrelevance). LCS addresses key limitations of performance-based metrics: (1) it\ncaptures continuous loss changes even when outputs are incorrect, improving\nreliability; (2) its formulation attributes ICL failures to weak contextual\nalignment (inability to adapt inputs to demonstrations) or strong output\ncalibration (self-verification of correctness); and (3) it minimizes reliance\non labeled data via synthetic evaluation. Extensive experiments demonstrate\nthat LCS strongly correlates with performance improvements in labeled settings\nand reliably reflects true effectiveness in biased or data-scarce scenarios.\nFurther analysis reveals actionable thresholds for LCS and identifies model\ncapabilities critical to ICL success.", "AI": {"tldr": "The paper introduces the Learning-to-Context Slope (LCS), a metric to gauge the effectiveness of in-context learning (ICL) in large language models, improving reliability and addressing current limitations in assessment.", "motivation": "In-context learning (ICL), though effective in enhancing large language models, exhibits varying performance across tasks and models, necessitating a reliable evaluation method.", "method": "The study proposes LCS, which models the slope between learning gain and contextual relevance, addressing limitations in performance-based metrics like reliability, attribution, and practicality in low-data scenarios.", "result": "Experiments confirm that LCS correlates well with ICL performance improvements and provides insight into model capabilities and actionable thresholds, even in biased or data-scarce settings.", "conclusion": "The LCS metric offers a robust approach to measure ICL effectiveness, enabling identification of contextual alignment issues and reducing reliance on labeled data."}}
{"id": "2506.23999", "pdf": "https://arxiv.org/pdf/2506.23999", "abs": "https://arxiv.org/abs/2506.23999", "authors": ["Zeyu Han", "Mengchi Cai", "Chaoyi Chen", "Qingwen Meng", "Guangwei Wang", "Ying Liu", "Qing Xu", "Jianqiang Wang", "Keqiang Li"], "title": "Predictive Risk Analysis and Safe Trajectory Planning for Intelligent and Connected Vehicles", "categories": ["cs.RO"], "comment": null, "summary": "The safe trajectory planning of intelligent and connected vehicles is a key\ncomponent in autonomous driving technology. Modeling the environment risk\ninformation by field is a promising and effective approach for safe trajectory\nplanning. However, existing risk assessment theories only analyze the risk by\ncurrent information, ignoring future prediction. This paper proposes a\npredictive risk analysis and safe trajectory planning framework for intelligent\nand connected vehicles. This framework first predicts future trajectories of\nobjects by a local risk-aware algorithm, following with a\nspatiotemporal-discretised predictive risk analysis using the prediction\nresults. Then the safe trajectory is generated based on the predictive risk\nanalysis. Finally, simulation and vehicle experiments confirm the efficacy and\nreal-time practicability of our approach.", "AI": {"tldr": "This paper introduces a framework for predictive risk analysis and safe trajectory planning in autonomous vehicles.", "motivation": "Existing risk assessment theories in autonomous driving only focus on current information, neglecting future risk prediction.", "method": "The authors propose a local risk-aware algorithm to predict future object trajectories, followed by spatiotemporal-discretized predictive risk analysis for safe trajectory generation.", "result": "Simulation and vehicle experiments demonstrate the framework's effectiveness and real-time applicability in safe trajectory planning.", "conclusion": "The proposed framework provides a promising approach for enhancing safety and real-time implementation in autonomous vehicle trajectory planning."}}
{"id": "2506.23926", "pdf": "https://arxiv.org/pdf/2506.23926", "abs": "https://arxiv.org/abs/2506.23926", "authors": ["Junping Wang", "Bicheng Wang", "Yibo Xuea", "Yuan Xie"], "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain.", "AI": {"tldr": "The paper introduces an 'industrial brain' combining neuro networks and symbolic reasoning for improving resilience prediction in chaotic industrial chain settings.", "motivation": "To improve resilience prediction and planning in industrial chains, especially in complex and chaotic systems, where existing methods fail.", "method": "Proposed a cognitive framework called the 'industrial brain' that integrates a higher-order neuro network with CT-OODA symbolic reasoning for resilience planning.", "result": "The industrial brain achieved a resilience accuracy improvement of up to 10.8% and generalized well to unseen scenarios, outperforming existing methods.", "conclusion": "The industrial brain effectively addresses challenges in resilience prediction and planning, providing robust and generalizable solutions for the industrial chain."}}
{"id": "2506.22995", "pdf": "https://arxiv.org/pdf/2506.22995", "abs": "https://arxiv.org/abs/2506.22995", "authors": ["Davide Salaorni", "Federico Bianchi", "Francesco Trov\u00f2", "Marcello Restelli"], "title": "A Reinforcement Learning Approach for Optimal Control in Microgrids", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages, accepted to International Joint Conference on Neural\n  Networks 2025", "summary": "The increasing integration of renewable energy sources (RESs) is transforming\ntraditional power grid networks, which require new approaches for managing\ndecentralized energy production and consumption. Microgrids (MGs) provide a\npromising solution by enabling localized control over energy generation,\nstorage, and distribution. This paper presents a novel reinforcement learning\n(RL)-based methodology for optimizing microgrid energy management.\nSpecifically, we propose an RL agent that learns optimal energy trading and\nstorage policies by leveraging historical data on energy production,\nconsumption, and market prices. A digital twin (DT) is used to simulate the\nenergy storage system dynamics, incorporating degradation factors to ensure a\nrealistic emulation of the analysed setting. Our approach is validated through\nan experimental campaign using real-world data from a power grid located in the\nItalian territory. The results indicate that the proposed RL-based strategy\noutperforms rule-based methods and existing RL benchmarks, offering a robust\nsolution for intelligent microgrid management.", "AI": {"tldr": "The paper introduces an RL-based methodology for optimizing microgrid energy management using a digital twin and leverages historical data for enhanced decision-making.", "motivation": "The integration of renewable energy sources necessitates decentralized energy production and consumption solutions to transform traditional power grids.", "method": "The study employs reinforcement learning (RL) with a digital twin model to analyze storage dynamics, incorporating degradation factors, based on real-world data from Italy.", "result": "The RL-based strategy outperformed rule-based methods and existing RL benchmarks in optimizing microgrid energy management.", "conclusion": "The approach provides a robust and intelligent solution for decentralized energy management systems in microgrids."}}
{"id": "2506.22807", "pdf": "https://arxiv.org/pdf/2506.22807", "abs": "https://arxiv.org/abs/2506.22807", "authors": ["Yueyang Li", "Shengyu Gong", "Weiming Zeng", "Nizhuan Wang", "Wai Ting Siok"], "title": "FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Electroencephalography (EEG) serves as a reliable and objective signal for\nemotion recognition in affective brain-computer interfaces, offering unique\nadvantages through its high temporal resolution and ability to capture\nauthentic emotional states that cannot be consciously controlled. However,\ncross-subject generalization remains a fundamental challenge due to individual\nvariability, cognitive traits, and emotional responses. We propose FreqDGT, a\nfrequency-adaptive dynamic graph transformer that systematically addresses\nthese limitations through an integrated framework. FreqDGT introduces\nfrequency-adaptive processing (FAP) to dynamically weight emotion-relevant\nfrequency bands based on neuroscientific evidence, employs adaptive dynamic\ngraph learning (ADGL) to learn input-specific brain connectivity patterns, and\nimplements multi-scale temporal disentanglement network (MTDN) that combines\nhierarchical temporal transformers with adversarial feature disentanglement to\ncapture both temporal dynamics and ensure cross-subject robustness.\nComprehensive experiments demonstrate that FreqDGT significantly improves\ncross-subject emotion recognition accuracy, confirming the effectiveness of\nintegrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical\nmodeling while ensuring robustness to individual differences. The code is\navailable at https://github.com/NZWANG/FreqDGT.", "AI": {"tldr": "The paper introduces FreqDGT, a new EEG-based method leveraging advanced techniques like frequency-adaptive processing, dynamic graph learning, and multi-scale temporal disentanglement to improve cross-subject emotion recognition accuracy.", "motivation": "The motivation is to address the challenge of cross-subject variability in EEG-based emotion recognition, which stems from individual differences in cognitive traits and emotional responses.", "method": "The authors propose FreqDGT, comprising: Frequency-Adaptive Processing (FAP) for emotion-relevant frequency bands, Adaptive Dynamic Graph Learning (ADGL) for customized brain connectivity, and a Multi-Scale Temporal Disentanglement Network (MTDN) for temporal dynamics and cross-subject robustness.", "result": "Experiments confirm that FreqDGT improves cross-subject emotion recognition accuracy, outperforming existing methods while proving resilience to individual differences.", "conclusion": "The study validates FreqDGT's integrated approach, demonstrating its potential for robust and accurate affective brain-computer interfaces."}}
{"id": "2506.23149", "pdf": "https://arxiv.org/pdf/2506.23149", "abs": "https://arxiv.org/abs/2506.23149", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy", "categories": ["cs.CL"], "comment": null, "summary": "High labeling cost for in-context learning (ICL) demonstrations motivates\nusing large language models (LLMs) for synthesis to reduce overhead. However,\nexisting synthesis methods are mainly task-specific or rely on pre-existing\ndemonstrations. So this paper focuses on synthesizing demonstrations from\nscratch for arbitrary tasks. A major challenge in synthesizing from scratch is\nensuring consistency with the target task, as the lack of labeling guidance\ncould lead to synthesis bias. We first propose a consistency metric called\nV-Score, which has higher performance and lower computation cost compared with\nthe metrics based on grams or embedding vectors. Furthermore, we introduce\nV-Synthesis, which leverages V-Score for proportional sampling to ensure both\nhigh consistency and diversity of synthesized demonstrations. Experimental\nresults demonstrate that V-Synthesis yields an average performance improvement\nof 2.0% compared to existing synthesis methods confirming the effectiveness of\nV-Synthesis.", "AI": {"tldr": "The paper addresses synthesizing in-context learning (ICL) demonstrations from scratch for arbitrary tasks, introducing V-Score and V-Synthesis to improve consistency and diversity.", "motivation": "Existing methods for synthesizing ICL demonstrations largely focus on specific tasks or require pre-existing examples, creating a need for a generalized solution to synthesize accurate demonstrations from scratch.", "method": "The authors propose a novel metric called V-Score for consistency assessment, and use it in a proportional sampling approach called V-Synthesis to create diverse and consistent task demonstrations.", "result": "V-Synthesis shows a 2.0% improvement on average over other synthesis methods, demonstrating its effectiveness in generating useful ICL demonstrations.", "conclusion": "The study's approach enables effective and generalized demonstration synthesis for ICL, reducing dependency on task-specific methods or pre-existing samples, while improving consistency and diversity."}}
{"id": "2506.24046", "pdf": "https://arxiv.org/pdf/2506.24046", "abs": "https://arxiv.org/abs/2506.24046", "authors": ["Olivia Richards", "Keith L. Obstein", "Nabil Simaan"], "title": "Exploring Accelerated Skill Acquisition via Tandem Training for Colonoscopy", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "New endoscopists require a large volume of expert-proctored colonoscopies to\nattain minimal competency. Developing multi-fingered, synchronized control of a\ncolonoscope requires significant time and exposure to the device. Current\ntraining methods inhibit this development by relying on tool hand-off for\nexpert demonstrations. There is a need for colonoscopy training tools that\nenable in-hand expert guidance in real-time. We present a new concept of a\ntandem training system that uses a telemanipulated preceptor colonoscope to\nguide novice users as they perform a colonoscopy. This system is capable of\ndual-control and can automatically toggle between expert and novice control of\na standard colonoscope's angulation control wheels. Preliminary results from a\nuser study with novice and expert users show the effectiveness of this device\nas a skill acquisition tool. We believe that this device has the potential to\naccelerate skill acquisition for colonoscopy and, in the future, enable\nindividualized instruction and responsive teaching through bidirectional\nactuation.", "AI": {"tldr": "The study introduces a dual-control colonoscope training system to facilitate hands-on guidance for novice endoscopists, demonstrating initial effectiveness in skill acquisition.", "motivation": "Traditional colonoscopy training methods require significant time and hand-off techniques, hindering skill development. There's a need for tools allowing real-time, in-hand expert guidance for novices.", "method": "The paper proposes a tandem training system with a telemanipulated control that allows dual expert-novice control over colonoscope angulation. Control toggles automatically between expert and novice users during procedures.", "result": "Preliminary user studies conducted with novice and expert endoscopists showed the device's effectiveness in helping novices acquire colonoscopy skills more efficiently.", "conclusion": "The tandem training system can enhance skill acquisition for novices and may enable personalized and responsive teaching methods in colonoscopy training."}}
{"id": "2506.23949", "pdf": "https://arxiv.org/pdf/2506.23949", "abs": "https://arxiv.org/abs/2506.23949", "authors": ["Anthony M. Barrett", "Jessica Newman", "Brandie Nonnecke", "Nada Madkour", "Dan Hendrycks", "Evan R. Murphy", "Krystal Jackson", "Deepika Raman"], "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models", "categories": ["cs.AI", "cs.CR", "cs.CY"], "comment": null, "summary": "Increasingly multi-purpose AI models, such as cutting-edge large language\nmodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'\ngenerative AI models, and 'frontier models' (typically all referred to\nhereafter with the umbrella term 'GPAI/foundation models' except where greater\nspecificity is needed), can provide many beneficial capabilities but also risks\nof adverse events with profound consequences. This document provides\nrisk-management practices or controls for identifying, analyzing, and\nmitigating risks of GPAI/foundation models. We intend this document primarily\nfor developers of large-scale, state-of-the-art GPAI/foundation models; others\nthat can benefit from this guidance include downstream developers of end-use\napplications that build on a GPAI/foundation model. This document facilitates\nconformity with or use of leading AI risk management-related standards,\nadapting and building on the generic voluntary guidance in the NIST AI Risk\nManagement Framework and ISO/IEC 23894, with a focus on the unique issues faced\nby developers of GPAI/foundation models.", "AI": {"tldr": "This paper discusses risk management practices for multi-purpose AI or GPAI/foundation models, addressing their benefits and associated risks while building on established standards.", "motivation": "To address the risks and potential adverse events posed by GPAI/foundation models while enabling their beneficial capabilities.", "method": "The paper adapts and builds upon existing AI risk management frameworks (e.g., NIST AI Risk Management Framework and ISO/IEC 23894) tailored specifically for GPAI/foundation model developers.", "result": "It proposes risk-management controls and practices that developers of GPAI/foundation models can implement, while offering guidance for downstream developers of applications built on these models.", "conclusion": "Facilitating conformity to industry standards, the document enhances risk management protocols for GPAI/foundation model development to mitigate risks and leverage their capabilities effectively."}}
{"id": "2506.23024", "pdf": "https://arxiv.org/pdf/2506.23024", "abs": "https://arxiv.org/abs/2506.23024", "authors": ["Jerry Liu", "Yasa Baig", "Denise Hui Jean Lee", "Rajat Vadiraj Dwaraknath", "Atri Rudra", "Chris R\u00e9"], "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "Workshop for the Theory of AI for Scientific Computing @ COLT 2025\n  (Best Paper). 39 pages, 24 figures", "summary": "Physics-informed neural networks (PINNs) offer a flexible way to solve\npartial differential equations (PDEs) with machine learning, yet they still\nfall well short of the machine-precision accuracy many scientific tasks demand.\nIn this work, we investigate whether the precision ceiling comes from the\nill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)\narchitecture. We introduce the Barycentric Weight Layer (BWLer), which models\nthe PDE solution through barycentric polynomial interpolation. A BWLer can be\nadded on top of an existing MLP (a BWLer-hat) or replace it completely\n(explicit BWLer), cleanly separating how we represent the solution from how we\ntake derivatives for the PDE loss. Using BWLer, we identify fundamental\nprecision limitations within the MLP: on a simple 1-D interpolation task, even\nMLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above\nfloat64 machine precision -- before any PDE terms are added. In PDE learning,\nadding a BWLer lifts this ceiling and exposes a tradeoff between achievable\naccuracy and the conditioning of the PDE loss. For linear PDEs we fully\ncharacterize this tradeoff with an explicit error decomposition and navigate it\nduring training with spectral derivatives and preconditioning. Across five\nbenchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for\nconvection, 10x for reaction, and 1800x for wave equations while remaining\ncompatible with first-order optimizers. Replacing the MLP entirely lets an\nexplicit BWLer reach near-machine-precision on convection, reaction, and wave\nproblems (up to 10 billion times better than prior results) and match the\nperformance of standard PINNs on stiff Burgers' and irregular-geometry Poisson\nproblems. Together, these findings point to a practical path for combining the\nflexibility of PINNs with the precision of classical spectral solvers.", "AI": {"tldr": "The paper introduces the Barycentric Weight Layer (BWLer), which overcomes precision limitations of Physics-informed neural networks (PINNs) for solving PDEs, significantly improving performance.", "motivation": "To address the gap between the flexibility of PINNs to solve PDEs and the high accuracy demanded by scientific tasks, which current PINN architectures fail to achieve.", "method": "The method involves introducing the BWLer, a barycentric polynomial interpolation-based architecture, which can be added to (BWLer-hat) or replace (explicit BWLer) the typical multi-layer perceptron (MLP). It separates solution representation from PDE loss differentiation, and addresses conditioning of PDE losses with preconditioning and spectral derivatives.", "result": "The BWLer improves RMSE performance by up to 30x for convection, 10x for reaction, and 1800x for wave equations, and even achieves near-machine precision on certain benchmarks, vastly outperforming typical PINNs.", "conclusion": "The paper provides a practical approach to merge the flexibility of PINNs with the precision of classical spectral solvers, making a significant leap in solving PDE problems efficiently and accurately."}}
{"id": "2506.22814", "pdf": "https://arxiv.org/pdf/2506.22814", "abs": "https://arxiv.org/abs/2506.22814", "authors": ["Andrew Hamara", "Andrew C. Freeman"], "title": "Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping", "categories": ["cs.CV"], "comment": null, "summary": "Automatic image cropping aims to extract the most visually salient regions\nwhile preserving essential composition elements. Traditional saliency-aware\ncropping methods optimize a single bounding box, making them ineffective for\napplications requiring multiple disjoint crops. In this work, we extend the\nFixed Aspect Ratio Cropping algorithm to efficiently extract multiple\nnon-overlapping crops in linear time. Our approach dynamically adjusts\nattention thresholds and removes selected crops from consideration without\nrecomputing the entire saliency map. We discuss qualitative results and\nintroduce the potential for future datasets and benchmarks.", "AI": {"tldr": "The paper improves image cropping by creating a method to extract multiple visually salient areas efficiently while preserving composition.", "motivation": "Traditional methods struggled with identifying multiple disjoint areas in image cropping while maintaining visual importance.", "method": "The algorithm extends a Fixed Aspect Ratio Cropping method, allowing efficient linear-time extraction of non-overlapping areas by dynamically managing attention thresholds and reducing redundancy.", "result": "It successfully identifies multiple visually important areas without needing to recompute saliency maps, showing promising qualitative results.", "conclusion": "This method overcomes limitations of older approaches for multi-crop scenarios and opens the way for new datasets and evaluation benchmarks."}}
{"id": "2506.23192", "pdf": "https://arxiv.org/pdf/2506.23192", "abs": "https://arxiv.org/abs/2506.23192", "authors": ["Gabriel Iturra-Bocaz", "Felipe Bravo-Marquez"], "title": "RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at SIGIR'23", "summary": "Word embeddings have become essential components in various information\nretrieval and natural language processing tasks, such as ranking, document\nclassification, and question answering. However, despite their widespread use,\ntraditional word embedding models present a limitation in their static nature,\nwhich hampers their ability to adapt to the constantly evolving language\npatterns that emerge in sources such as social media and the web (e.g., new\nhashtags or brand names). To overcome this problem, incremental word embedding\nalgorithms are introduced, capable of dynamically updating word representations\nin response to new language patterns and processing continuous data streams.\n  This paper presents RiverText, a Python library for training and evaluating\nincremental word embeddings from text data streams. Our tool is a resource for\nthe information retrieval and natural language processing communities that work\nwith word embeddings in streaming scenarios, such as analyzing social media.\nThe library implements different incremental word embedding techniques, such as\nSkip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized\nframework. In addition, it uses PyTorch as its backend for neural network\ntraining. We have implemented a module that adapts existing intrinsic static\nword embedding evaluation tasks for word similarity and word categorization to\na streaming setting. Finally, we compare the implemented methods with different\nhyperparameter settings and discuss the results. Our open-source library is\navailable at https://github.com/dccuchile/rivertext.", "AI": {"tldr": "The paper introduces RiverText, a Python library for training and evaluating incremental word embeddings for streaming data, overcoming limitations of static embeddings.", "motivation": "Traditional word embeddings are static and fail to adapt to evolving language patterns, particularly from dynamic sources like social media.", "method": "RiverText implements incremental word embedding techniques such as Skip-gram and Continuous Bag of Words within a PyTorch framework, enabling dynamic representation and evaluation of language patterns.", "result": "RiverText supports a variety of incremental embedding methods, adapts existing evaluation tasks for streaming settings, and presents performance comparisons with diverse hyperparameters.", "conclusion": "RiverText serves as a valuable, open-source resource for analyzing streaming text data, leveraging incremental embeddings to address the adaptability challenges of traditional models."}}
{"id": "1906.00306", "pdf": "https://arxiv.org/pdf/1906.00306", "abs": "https://arxiv.org/abs/1906.00306", "authors": ["Ahmad Rafsanjani", "Katia Bertoldi", "Andr\u00e9 R. Studart"], "title": "Programming Soft Robots with Flexible Mechanical Metamaterials", "categories": ["cond-mat.soft", "cond-mat.mtrl-sci", "cs.RO"], "comment": null, "summary": "The complex behavior of highly deformable mechanical metamaterials can\nsubstantially enhance the performance of soft robots.", "AI": {"tldr": "Highly deformable mechanical metamaterials improve the functionality of soft robots.", "motivation": "To investigate how mechanical metamaterials can enhance soft robot performance.", "method": "The paper studies the behavior and application of deformable mechanical metamaterials in robotics.", "result": "Demonstration of metamaterials' potential in improving soft robots' capabilities.", "conclusion": "Mechanical metamaterials are valuable advancements for enhancing soft robot efficiency and functionality."}}
{"id": "2506.23992", "pdf": "https://arxiv.org/pdf/2506.23992", "abs": "https://arxiv.org/abs/2506.23992", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "categories": ["cs.AI", "cs.ET"], "comment": "14 page , 2 image , 2 tables , accepted under 5th International\n  Conference on Innovations in Computational Intelligence and Computer Vision\n  (ICICV-2025)", "summary": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91", "AI": {"tldr": "The study explores AI-based frameworks for assessing mental health in displaced children using two Retrieval-Augmented Generation pipelines, with DeepSeek R1 showing higher accuracy.", "motivation": "To address the international refugee crisis by providing efficient mental health solutions for displaced children through AI-based analysis of unstructured health data.", "method": "Two AI models, Zephyr-7B-beta and DeepSeek R1-7B, are tested for their ability to process humanitarian datasets without generating misinformation.", "result": "DeepSeek R1-7B demonstrated superior performance over Zephyr-7B-beta, achieving 91% accuracy in answer relevance.", "conclusion": "The proposed AI framework is scalable and effectively supports policymakers and agencies in recognizing and assisting the mental health needs of displaced children."}}
{"id": "2506.23025", "pdf": "https://arxiv.org/pdf/2506.23025", "abs": "https://arxiv.org/abs/2506.23025", "authors": ["Tejas Vaidhya", "Ayush Kaushal", "Vineet Jain", "Francis Couture Harpin", "Prashant Shishodia", "Majid Behbahani", "Yuriy Nevmyvaka", "Irina Rish"], "title": "Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used across research and\nindustry applications, yet their inference efficiency remains a significant\nchallenge. As the computational power of modern GPU architectures continuously\nimproves, their memory bandwidth and capacity have not scaled proportionally,\ncreating a critical bottleneck during inference. To address this, we\ninvestigate ternary language models (TriLMs) that employ quantization-aware\ntraining to significantly reduce memory requirements. We first analyze the\nscalability of TriLMs by conducting a scaling law analysis, revealing that\nTriLMs benefit more from increasing training data than from scaling model\nparameters. Based on this observation, we introduce Spectra-1.1, an open suite\nof TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained\nperformance gains at scale. Furthermore, to improve inference efficiency, we\npropose novel 2-bit and 1.6-bit packing schemes for ternary weights, which\ndemonstrate accelerated inference across various CPU architectures. Also,\nbuilding on the 2-bit packing, we develop a GPU kernel called TriRun that\naccelerates end-to-end model inference by up to 5 times compared to\nfloating-point baselines. To encourage further exploration and development of\nTriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.\nOverall, our work lays the foundation for building and deploying efficient\nLLMs, providing a valuable resource for the research community.", "AI": {"tldr": "The paper focuses on improving inference efficiency in large language models (LLMs) by employing ternary language models (TriLMs) with quantization-aware training and novel packing schemes.", "motivation": "Modern GPUs struggle with memory bandwidth and capacity deficiencies during LLM inference. There is a need to reduce these inefficiencies while maintaining model performance.", "method": "The authors introduce TriLMs using quantization-aware training, scaling laws analysis, novel 2-bit and 1.6-bit packing schemes, and a GPU kernel called TriRun for accelerated inference.", "result": "TriLMs showed performance gains with scalability, the proposed packing schemes accelerated inference across CPU and GPU architectures, and TriRun achieved up to 5\u00d7 speedup over floating-point baselines.", "conclusion": "The study demonstrates practical improvements in inference efficiency, scalability, and deployability of LLMs, with open resources to encourage further exploration."}}
{"id": "2506.22817", "pdf": "https://arxiv.org/pdf/2506.22817", "abs": "https://arxiv.org/abs/2506.22817", "authors": ["Xingyilang Yin", "Jiale Wang", "Xi Yang", "Mutian Xu", "Xu Gu", "Nannan Wang"], "title": "Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Recent open-vocabulary 3D scene understanding approaches mainly focus on\ntraining 3D networks through contrastive learning with point-text pairs or by\ndistilling 2D features into 3D models via point-pixel alignment. While these\nmethods show considerable performance in benchmarks with limited vocabularies,\nthey struggle to handle diverse object categories as the limited amount of 3D\ndata upbound training strong open-vocabulary 3d models. We observe that 2D\nmulti-view fusion methods take precedence in understanding diverse concepts in\n3D scenes. However, inherent noises in vision-language models lead multi-view\nfusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel\napproach aimed at unleashing the potential of 2D multi-view fusion for\nopen-vocabulary 3D scene understanding. We focus on reducing the inherent\nnoises without training, thereby preserving the generalizability while\nenhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D\nfeatures by leveraging precise region-level image features and text features\nencoded by CLIP encoders and incorporates 3D geometric priors to optimize\nmulti-view fusion. Extensive experiments on various datasets demonstrate the\neffectiveness of our method. Notably, our MVOV3D achieves a new record with\n14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge\nopen-vocabulary semantic segmentation, outperforming current leading trained 3D\nnetworks by a significant margin.", "AI": {"tldr": "The paper introduces MVOV3D, a method leveraging 2D multi-view fusion to improve open-vocabulary 3D scene understanding by reducing noise without additional training. It achieves record performance on semantic segmentation benchmarks.", "motivation": "Existing approaches for open-vocabulary 3D scene understanding struggle with diverse object categories due to limited 3D training data. This motivates leveraging 2D multi-view fusion to enhance understanding of diverse concepts.", "method": "MVOV3D improves 2D multi-view fusion using precise region-level features from CLIP encoders, incorporates 3D geometric priors, and focuses on reducing inherent noises without training to maintain generalizability.", "result": "MVOV3D achieves state-of-the-art performance with 14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for open-vocabulary semantic segmentation, surpassing existing trained 3D networks.", "conclusion": "The proposed MVOV3D method effectively enhances open-vocabulary 3D scene understanding using 2D multi-view fusion, achieving superior generalization and performance without additional training."}}
{"id": "2506.23235", "pdf": "https://arxiv.org/pdf/2506.23235", "abs": "https://arxiv.org/abs/2506.23235", "authors": ["Yi-Chen Li", "Tian Xu", "Yang Yu", "Xuqin Zhang", "Xiong-Hui Chen", "Zhongxiang Ling", "Ningjing Chao", "Lei Yuan", "Zhi-Hua Zhou"], "title": "Generalist Reward Models: Found Inside Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The alignment of Large Language Models (LLMs) is critically dependent on\nreward models trained on costly human preference data. While recent work\nexplores bypassing this cost with AI feedback, these methods often lack a\nrigorous theoretical foundation. In this paper, we discover that a powerful\ngeneralist reward model is already latently present within any LLM trained via\nstandard next-token prediction. We prove that this endogenous reward is not a\nheuristic, but is theoretically equivalent to a reward function learned through\noffline inverse reinforcement learning. This connection allows us to directly\nelicit a high-quality reward signal from a base (pre-trained or supervised\nfine-tuned) model without any further training. Critically, we also prove that\nsubsequent reinforcement learning using this endogenous reward leads to a\npolicy with a provably superior error bound compared to the base model. To our\nbest knowledge, this is the first theoretical proof of the effectiveness of\nreinforcement learning for LLMs. Our experiments validate this theory,\ndemonstrating that our method not only outperforms existing LLM-as-a-judge\napproaches but can also surpass explicitly trained reward models. These\nfindings suggest that the reward modeling stage can be replaced by a principled\nmethod of eliciting the knowledge already captured during pre-training,\nheralding a more efficient, powerful, and scalable paradigm for LLMs alignment\nas well as multi-modal models.", "AI": {"tldr": "This paper identifies a hidden, high-quality reward model within Large Language Models (LLMs) and demonstrates its theoretical and practical potential for improving reinforcement learning without additional training.", "motivation": "Current methods of aligning LLMs rely on costly human preference data, and methods using AI feedback often lack a rigorous theoretical basis. The study explores whether pre-trained LLMs inherently possess robust reward models that can be utilized to bypass these challenges.", "method": "The authors theoretically prove that the latent reward model in LLMs is equivalent to a reward function derived from offline inverse reinforcement learning. They then elicit this endogenous reward from base models and use it in reinforcement learning to achieve superior performance.", "result": "Experiments show that using this endogenous reward signal outperforms existing LLM-as-a-judge methods and even surpasses reward models trained explicitly. Additionally, the method ensures theoretically improved error bounds in policy optimization.", "conclusion": "This research suggests a paradigm shift in LLM alignment by replacing explicit reward modeling with the endogenous reward mechanism captured in pre-training, enabling more efficient and scalable approaches for both single and multi-modal models."}}
{"id": "2506.22472", "pdf": "https://arxiv.org/pdf/2506.22472", "abs": "https://arxiv.org/abs/2506.22472", "authors": ["Dylan Wilson", "Marco Pontin", "Peter Walters", "Perla Maiolino"], "title": "Optical Waveguide-based Spider Web Enables Resilient Impact Detection and Localization", "categories": ["eess.SP", "cs.RO"], "comment": null, "summary": "Spiders use their webs as multifunctional tools that enable capturing and\nlocalizing prey and more general environmental sensing through vibrations.\nInspired by their biological function, we present a spider web-inspired optical\nwaveguide system for resilient impulse detection and localization. The\nstructure consists of six clear thermoplastic polyurethane (TPU) waveguides\narranged radially and interconnected by a spiral TPU thread, mimicking orb\nspider webs. Light transmission losses, induced by vibrations, are measured via\ncoupled LEDs and photo-diodes, allowing real-time detection. We systematically\ncharacterize individual waveguides, analyzing key parameters such as tension,\nimpulse position, and break angle to optimize vibrational response. The\ncomplete system is validated through controlled experiments, revealing a 5 ms\npropagation delay in vibration transfer between adjacent radii, enhancing\nlocalization capabilities. We demonstrate a robust impulse detection and\nlocalization algorithm leveraging time delay analysis, achieving reliable event\nidentification even in cases of sensor failure. This study highlights the\npotential of bioinspired optical waveguide structures for adaptive sensing,\nwith applications in soft robotics, structural monitoring, and environmental\nsensing.", "AI": {"tldr": "The paper introduces a spider web-inspired optical waveguide system leveraging vibrations to detect and localize impulses. It uses clear TPU waveguides configured in a bioinspired radial-spoke design, transmitting light, and detecting losses induced by vibrations for real-time monitoring.", "motivation": "The researchers were motivated by the multifunctional sensing capabilities of spider webs and aimed to replicate these properties for technological systems, particularly focusing on adaptive sensing applications.", "method": "They designed six TPU radial waveguides connected by a spiral thread to mimic spider web geometry. Vibrational signals were detected through induced light transmission losses, which were monitored by LEDs and photo-diodes. System parameters like waveguide tension and impulse location were optimized.", "result": "Experiments showed a 5 ms delay in vibration transfer between neighboring radii, enabling better impulse localization. The developed algorithm proved effective even under sensor failure conditions, making the system robust.", "conclusion": "Spider web-inspired optical waveguide structures have significant potential for resilient and adaptive sensing applications, with implications for fields like soft robotics and structural monitoring."}}
{"id": "2506.24026", "pdf": "https://arxiv.org/pdf/2506.24026", "abs": "https://arxiv.org/abs/2506.24026", "authors": ["Yongyi Wang", "Wenxin Li"], "title": "Constructing Non-Markovian Decision Process via History Aggregator", "categories": ["cs.AI"], "comment": null, "summary": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest\nas a significant impediment, especially for paradigms such as Reinforcement\nLearning (RL), thereby exerting far-reaching consequences on the advancement\nand effectiveness of the associated systems. Nevertheless, the existing\nbenchmarks are deficient in comprehensively assessing the capacity of decision\nalgorithms to handle non-Markovian dynamics. To address this deficiency, we\nhave devised a generalized methodology grounded in category theory. Notably, we\nestablished the category of Markov Decision Processes (MDP) and the category of\nnon-Markovian Decision Processes (NMDP), and proved the equivalence\nrelationship between them. This theoretical foundation provides a novel\nperspective for understanding and addressing non-Markovian dynamics. We further\nintroduced non-Markovianity into decision-making problem settings via the\nHistory Aggregator for State (HAS). With HAS, we can precisely control the\nstate dependency structure of decision-making problems in the time series. Our\nanalysis demonstrates the effectiveness of our method in representing a broad\nrange of non-Markovian dynamics. This approach facilitates a more rigorous and\nflexible evaluation of decision algorithms by testing them in problem settings\nwhere non-Markovian dynamics are explicitly constructed.", "AI": {"tldr": "This paper introduces a category theory-based framework to understand and evaluate non-Markovian dynamics in decision-making systems like reinforcement learning (RL).", "motivation": "Traditional benchmarks inadequately assess algorithmic capacity to handle non-Markovian dynamics, which hinders progress in improving decision-making algorithms.", "method": "The authors use category theory to formalize equivalencies between Markov Decision Processes (MDPs) and non-Markovian Decision Processes (NMDPs). They introduce the History Aggregator for State (HAS) for precise manipulation of state dependency in non-Markovian settings.", "result": "The proposed HAS approach effectively represents a wide range of non-Markovian dynamics and enables rigorous, flexible evaluation of decision algorithms.", "conclusion": "The theoretical and practical contributions provide a new perspective for studying non-Markovian dynamics, enhancing the robustness and scope of benchmarks for decision-making models."}}
{"id": "2506.22819", "pdf": "https://arxiv.org/pdf/2506.22819", "abs": "https://arxiv.org/abs/2506.22819", "authors": ["Ramya Hebbalaguppe", "Tamoghno Kandar", "Abhinav Nagpal", "Chetan Arora"], "title": "Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages", "summary": "Vision-language models (VLM) have demonstrated impressive performance in\nimage recognition by leveraging self-supervised training on large datasets.\nTheir performance can be further improved by adapting to the test sample using\ntest-time prompt tuning (TPT). Unfortunately, the singular focus of TPT\napproaches on improving the accuracy suffers from tunnel vision, and leads to\ndegradation in confidence calibration. This limits the applicability of TPT in\ncritical applications.\n  We make three contributions in this work. (1) We posit that random or naive\ninitialization of prompts leads to overfitting on a particular test sample, and\nis the main reason for miscalibration of the VLM after TPT. To mitigate the\nproblem, we propose careful initialization of test time prompt using prior\nknowledge about the target label attributes from a large language model (LLM);\n(2) To further maintain the quality of prompts during \\tpt, we propose a novel\nregularization loss to reduce intraclass distance, and increase inter-class\ndistance between the learnt\n  Through extensive experiments on different CLIP architectures and 15\ndatasets, we show that our approach can effectively improve the calibration\nafter TPT. We report an average expected calibration error (ECE) of 4.11 with\nour method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),\n6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is\npublicly accessible at:\nhttps://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.", "AI": {"tldr": "The paper highlights improvements in test-time prompt tuning (TPT) for vision-language models to enhance calibration and maintain accuracy by introducing better initialization and regularization methods.", "motivation": "Despite the success of vision-language models (VLMs) and test-time prompt tuning (TPT), existing TPT methods overly focus on accuracy at the cost of confidence calibration, which limits their effectiveness in critical applications.", "method": "The proposed approach leverages prior knowledge from large language models to carefully initialize prompts, and introduces a novel regularization loss aimed at reducing intra-class distances and increasing inter-class distances during TPT.", "result": "Extensive testing on multiple CLIP architectures and 15 datasets reveals significant enhancement in calibration, with an average expected calibration error (ECE) of 4.11, outperforming existing methods like C-TPT, DiffTPT, and PromptAlign.", "conclusion": "The work successfully addresses limitations in existing test-time prompt tuning methods by improving both calibration and accuracy through better initialization and regularization strategies, making the approach practical for applications with strict performance requirements."}}
{"id": "2506.23288", "pdf": "https://arxiv.org/pdf/2506.23288", "abs": "https://arxiv.org/abs/2506.23288", "authors": ["Miguel Domingo", "Francisco Casacuberta"], "title": "Two Spelling Normalization Approaches Based on Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The absence of standardized spelling conventions and the organic evolution of\nhuman language present an inherent linguistic challenge within historical\ndocuments, a longstanding concern for scholars in the humanities. Addressing\nthis issue, spelling normalization endeavors to align a document's orthography\nwith contemporary standards. In this study, we propose two new approaches based\non large language models: one of which has been trained without a supervised\ntraining, and a second one which has been trained for machine translation. Our\nevaluation spans multiple datasets encompassing diverse languages and\nhistorical periods, leading us to the conclusion that while both of them\nyielded encouraging results, statistical machine translation still seems to be\nthe most suitable technology for this task.", "AI": {"tldr": "This paper explores two new large language model-based approaches for spelling normalization in historical texts, finding statistical machine translation to be the most suitable method.", "motivation": "The study addresses the challenge of non-standardized spelling in historical documents, which complicates research in the humanities.", "method": "The authors develop two approaches: (1) a large language model trained without supervision, and (2) a supervised model trained for machine translation, and evaluate their performance on diverse datasets.", "result": "Both approaches provided promising results in spelling normalization across various datasets and historical periods.", "conclusion": "Statistical machine translation still proves to be the most effective technology for addressing non-standardized historical spelling."}}
{"id": "2506.22477", "pdf": "https://arxiv.org/pdf/2506.22477", "abs": "https://arxiv.org/abs/2506.22477", "authors": ["Huiwen Han"], "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.RO"], "comment": "Published in: 2024 6th International Conference on Robotics,\n  Intelligent Control and Artificial Intelligence (RICAI), IEEE Xplore, DOI:\n  10.1109/RICAI64321.2024.10911316. \\c{opyright} 2024 IEEE", "summary": "This paper introduces an innovative design for robotic operating platforms,\nunderpinned by a transformative Internet of Things (IoT) architecture,\nseamlessly integrating cutting-edge technologies such as large language models\n(LLMs), generative AI, edge computing, and 5G networks. The proposed platform\naims to elevate the intelligence and autonomy of IoT systems and robotics,\nenabling them to make real-time decisions and adapt dynamically to changing\nenvironments. Through a series of compelling case studies across industries\nincluding smart manufacturing, healthcare, and service sectors, this paper\ndemonstrates the substantial potential of IoT-enabled robotics to optimize\noperational workflows, enhance productivity, and deliver innovative, scalable\nsolutions. By emphasizing the roles of LLMs and generative AI, the research\nhighlights how these technologies drive the evolution of intelligent robotics\nand IoT, shaping the future of industry-specific advancements. The findings not\nonly showcase the transformative power of these technologies but also offer a\nforward-looking perspective on their broader societal and industrial\nimplications, positioning them as catalysts for next-generation automation and\ntechnological convergence.", "AI": {"tldr": "This paper introduces an IoT-based robotic platform integrating LLMs, generative AI, edge computing, and 5G to improve intelligence, autonomy, and scalability, with case studies across industries.", "motivation": "To enhance the capabilities of IoT systems and robotics through greater real-time decision-making, autonomy, and adaptability, using advanced technologies.", "method": "The approach integrates LLMs, generative AI, edge computing, and 5G into a unified IoT architecture. Validation is through case studies in industries like manufacturing and healthcare.", "result": "The platform demonstrated significant improvements in workflow optimization, productivity, and scalability across diverse industrial applications.", "conclusion": "The research underscores the transformative potential of LLMs and generative AI in shaping the future of IoT and robotics, highlighting broad industrial and societal impacts."}}
{"id": "2506.24119", "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "AI": {"tldr": "The paper introduces SPIRAL, a self-play framework enabling language models to develop reasoning skills through zero-sum games without human supervision.", "motivation": "Enhance reasoning capabilities in language models without relying on human-curated problem-answer pairs and domain-specific reward engineering.", "method": "Develop the SPIRAL framework using multi-agent reinforcement learning with self-play in zero-sum games, introducing role-conditioned advantage estimation (RAE) for stabilizing training.", "result": "SPIRAL-trained models show improved math and general reasoning performance, with multi-game training further boosting capabilities. The reasoning transfer occurs through identified cognitive patterns.", "conclusion": "Zero-sum games in self-play frameworks like SPIRAL provide a promising approach for autonomous development of transferable reasoning capabilities in language models."}}
{"id": "2506.23036", "pdf": "https://arxiv.org/pdf/2506.23036", "abs": "https://arxiv.org/abs/2506.23036", "authors": ["Zain ul Abdeen", "Ming Jin"], "title": "Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper explores Reinforcement learning (RL) policy robustness by\nsystematically analyzing network parameters under internal and external\nstresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering\nintroduces internal stress by selectively perturbing parameters, while\nadversarial attacks apply external stress through modified agent observations.\nThis dual approach enables the classification of parameters as fragile, robust,\nor antifragile, based on their influence on policy performance in clean and\nadversarial settings. Parameter scores are defined to quantify these\ncharacteristics, and the framework is validated on PPO-trained agents in Mujoco\ncontinuous control environments. The results highlight the presence of\nantifragile parameters that enhance policy performance under stress,\ndemonstrating the potential of targeted filtering techniques to improve RL\npolicy adaptability. These insights provide a foundation for future\nadvancements in the design of robust and antifragile RL systems.", "AI": {"tldr": "The paper analyzes robustness in reinforcement learning (RL) policies using internal and external stresses, uncovering factors for improving RL adaptability.", "motivation": "The study aims to understand and enhance the robustness and adaptability of RL policies by identifying and leveraging critical parameters under stress conditions.", "method": "A dual approach is employed: synaptic filtering to simulate internal stress by perturbing parameters, and adversarial attacks to impose external stress on agent observations. Parameters are classified as fragile, robust, or antifragile based on their impact on RL performance.", "result": "The analysis reveals antifragile parameters that improve RL policy performance under stress. Results demonstrate the utility of selective parameter filtering techniques in boosting policy adaptability.", "conclusion": "The findings highlight the potential to design more robust and antifragile RL systems by focusing on critical parameters, paving the way for future advancements in RL robustness research."}}
{"id": "2506.22832", "pdf": "https://arxiv.org/pdf/2506.22832", "abs": "https://arxiv.org/abs/2506.22832", "authors": ["Alexander Gambashidze", "Li Pengyi", "Matvey Skripkin", "Andrey Galichin", "Anton Gusarov", "Konstantin Sobolev", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Listener-Rewarded Thinking in VLMs for Image Preferences", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Training robust and generalizable reward models for human visual preferences\nis essential for aligning text-to-image and text-to-video generative models\nwith human intent. However, current reward models often fail to generalize, and\nsupervised fine-tuning leads to memorization, demanding complex annotation\npipelines. While reinforcement learning (RL), specifically Group Relative\nPolicy Optimization (GRPO), improves generalization, we uncover a key failure\nmode: a significant drop in reasoning accuracy occurs when a model's reasoning\ntrace contradicts that of an independent, frozen vision-language model\n(\"listener\") evaluating the same output. To address this, we introduce a\nlistener-augmented GRPO framework. Here, the listener re-evaluates the\nreasoner's chain-of-thought to provide a dense, calibrated confidence score,\nshaping the RL reward signal. This encourages the reasoner not only to answer\ncorrectly, but to produce explanations that are persuasive to an independent\nmodel. Our listener-shaped reward scheme achieves best accuracy on the\nImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD)\nperformance on a large-scale human preference dataset (1.2M votes, up to +6%\nover naive reasoner), and reduces reasoning contradictions compared to strong\nGRPO and SFT baselines. These results demonstrate that listener-based rewards\nprovide a scalable, data-efficient path to aligning vision-language models with\nnuanced human preferences. We will release our reasoning model here:\nhttps://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.", "AI": {"tldr": "The paper addresses challenges in training reward models for aligning generative models with human visual preferences, and proposes a listener-augmented GRPO framework to improve reasoning accuracy, achieving improved benchmark results.", "motivation": "Current reward models for visual preferences suffer from poor generalization and memorization during supervised fine-tuning. Reinforcement learning approaches improve generalization but face accuracy drops when reasoning contradictions occur.", "method": "A listener-augmented GRPO framework is introduced, where an independent vision-language model (listener) evaluates reasoning traces and provides calibrated confidence scores to refine RL reward signals.", "result": "The framework achieves state-of-the-art performance on the ImageReward benchmark, improves out-of-distribution accuracy by up to +6%, and minimizes reasoning contradictions compared to GRPO and SFT baselines.", "conclusion": "Listener-based rewards prove effective for scalable, data-efficient alignment of vision-language models with human preferences, providing a robust improvement in reasoning and generalization."}}
{"id": "1610.09431", "pdf": "https://arxiv.org/pdf/1610.09431", "abs": "https://arxiv.org/abs/1610.09431", "authors": ["Omar Claflin"], "title": "Attention acts to suppress goal-based conflict under high competition", "categories": ["q-bio.NC", "cs.AI"], "comment": "25 pages, 3 figures, 3 tables", "summary": "It is known that when multiple stimuli are present, top-down attention\nselectively enhances the neural signal in the visual cortex for task-relevant\nstimuli, but this has been tested only under conditions of minimal competition\nof visual attention. Here we show during high competition, that is, two stimuli\nin a shared receptive field possessing opposing modulatory goals, top-down\nattention suppresses both task-relevant and irrelevant neural signals within\n100 ms of stimuli onset. This non-selective engagement of top-down attentional\nresources serves to reduce the feedforward signal representing irrelevant\nstimuli.", "AI": {"tldr": "Top-down attention suppresses neural signals for both relevant and irrelevant stimuli under high competition to reduce irrelevant feedforward signals.", "motivation": "Investigate how top-down attention operates under high competition where multiple stimuli vie for neural representation simultaneously.", "method": "Experimental analysis of neural signals during conditions of high competition, with stimuli sharing receptive fields and differing goals.", "result": "Within 100 ms of stimulus onset, top-down attention suppresses neural signals for both task-relevant and irrelevant stimuli.", "conclusion": "Top-down attention non-selectively engages to mitigate the feedforward signal of irrelevant stimuli under competitive conditions."}}
{"id": "2506.23041", "pdf": "https://arxiv.org/pdf/2506.23041", "abs": "https://arxiv.org/abs/2506.23041", "authors": ["Chengyu Dong", "Huan Gui", "Noveen Sachdeva", "Long Jin", "Ke Yin", "Jingbo Shang", "Lichan Hong", "Ed H. Chi", "Zhe Zhao"], "title": "ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Knowledge distillation from pretrained visual representation models offers an\neffective approach to improve small, task-specific production models. However,\nthe effectiveness of such knowledge transfer drops significantly when\ndistilling from strong models that are pretrained in a large scale. In this\npaper, we address this challenge for pretrained Vision Transformers (ViTs) by\nexploring methods to fine-tune them for more effective knowledge transfer.\nMotivated by the connection between mutual information and distillation\neffectiveness, we propose to employ mutual information-aware optimization\nduring finetuning. For small or highly-imbalanced downstream datasets where\nsuch optimization becomes less effective, we introduce a simple yet effective\nheuristic of reweighting MLP blocks. This approach is inspired by our\nobservation that top MLP blocks are primarily responsible for mutual\ninformation loss. Our method enables small student models to benefit from those\npretrained models among the strongest.", "AI": {"tldr": "This paper proposes methods to make knowledge distillation from pretrained Vision Transformers (ViTs) more effective by introducing mutual information-aware fine-tuning and reweighting strategies for MLP blocks.", "motivation": "The motivation is to address the challenge of ineffective knowledge transfer from strong, large-scale pretrained visual representation models to small, task-specific models.", "method": "The method involves mutual information-aware optimization during fine-tuning and a heuristic approach of reweighting MLP blocks to counterbalance mutual information loss in highly-imbalanced datasets.", "result": "The proposed approach enhances knowledge transfer, allowing small student models to better utilize information from strong pretrained models.", "conclusion": "Mutual information-aware fine-tuning and reweighting strategies improve the effectiveness of knowledge transfer from pretrained ViTs to student models, especially for small or imbalanced datasets."}}
{"id": "2506.22833", "pdf": "https://arxiv.org/pdf/2506.22833", "abs": "https://arxiv.org/abs/2506.22833", "authors": ["Shashikant Verma", "Shanmuganathan Raman"], "title": "SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds", "categories": ["cs.CV"], "comment": null, "summary": "Despite multiple view consistency offered by 3D-aware GAN techniques, the\nresulting images often lack the capacity for localized editing. In response,\ngenerative radiance manifolds emerge as an efficient approach for constrained\npoint sampling within volumes, effectively reducing computational demands and\nenabling the learning of fine details. This work introduces SemFaceEdit, a\nnovel method that streamlines the appearance and geometric editing process by\ngenerating semantic fields on generative radiance manifolds. Utilizing latent\ncodes, our method effectively disentangles the geometry and appearance\nassociated with different facial semantics within the generated image. In\ncontrast to existing methods that can change the appearance of the entire\nradiance field, our method enables the precise editing of particular facial\nsemantics while preserving the integrity of other regions. Our network\ncomprises two key modules: the Geometry module, which generates semantic\nradiance and occupancy fields, and the Appearance module, which is responsible\nfor predicting RGB radiance. We jointly train both modules in adversarial\nsettings to learn semantic-aware geometry and appearance descriptors. The\nappearance descriptors are then conditioned on their respective semantic latent\ncodes by the Appearance Module, facilitating disentanglement and enhanced\ncontrol. Our experiments highlight SemFaceEdit's superior performance in\nsemantic field-based editing, particularly in achieving improved radiance field\ndisentanglement.", "AI": {"tldr": "This paper proposes SemFaceEdit, a method for localized semantic editing of facial images using generative radiance manifolds, offering improved disentanglement and control.", "motivation": "Despite advancements in 3D-aware GAN techniques, localized editing of specific regions in images remains challenging, motivating the search for efficient solutions that enhance fine detail rendering.", "method": "The method generates semantic fields on generative radiance manifolds by using latent codes to disentangle geometry and appearance for different facial semantics, featuring two key modules: Geometry (semantic radiance and occupancy fields) and Appearance (RGB radiance prediction).", "result": "SemFaceEdit enables precise editing of facial semantics while maintaining the integrity of other regions. Experiments show better performance in semantic field-based editing and improved radiance field disentanglement.", "conclusion": "SemFaceEdit demonstrates significant advancements in facial semantic editing by disentangling geometry and appearance, providing enhanced control and precision over localized changes."}}
{"id": "2506.23315", "pdf": "https://arxiv.org/pdf/2506.23315", "abs": "https://arxiv.org/abs/2506.23315", "authors": ["Shouvon Sarker", "Xishuang Dong", "Lijun Qian"], "title": "Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Identification of key variables such as medications, diseases, relations from\nhealth records and clinical notes has a wide range of applications in the\nclinical domain. n2c2 2022 provided shared tasks on challenges in natural\nlanguage processing for clinical data analytics on electronic health records\n(EHR), where it built a comprehensive annotated clinical data Contextualized\nMedication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of\nthis challenge that is to detect and classify medication events from clinical\nnotes through building a novel BERT-based ensemble model. It started with\npretraining BERT models on different types of big data such as Wikipedia and\nMIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED\ntraining data. These fine-tuned BERT models were employed to accomplish\nmedication event classification on CMED testing data with multiple predictions.\nThese multiple predictions generated by these fine-tuned BERT models were\nintegrated to build final prediction with voting strategies. Experimental\nresults demonstrated that BERT-based ensemble models can effectively improve\nstrict Micro-F score by about 5% and strict Macro-F score by about 6%,\nrespectively.", "AI": {"tldr": "The paper develops a BERT-based ensemble model to classify medication events from clinical notes, achieving improved predictive performance.", "motivation": "Effectively identifying key variables like medication and diseases from health records can support various clinical applications. The study focuses on addressing challenges in medication event identification from clinical notes.", "method": "The authors pretrained BERT models on datasets like Wikipedia and MIMIC, fine-tuned the models on a clinical dataset (CMED), and used ensemble techniques with voting strategies for final predictions.", "result": "The model achieved approximately 5% improvement in strict Micro-F scores and 6% improvement in strict Macro-F scores.", "conclusion": "BERT-based ensemble models significantly enhance the classification of medication events from clinical notes, as demonstrated by improvements in Micro-F and Macro-F scores."}}
{"id": "2402.09146", "pdf": "https://arxiv.org/pdf/2402.09146", "abs": "https://arxiv.org/abs/2402.09146", "authors": ["Muhammad Kashif", "Muhammad Shafique"], "title": "ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": null, "summary": "In this paper, we present a novel framework for enhancing the performance of\nQuanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional\nlayers and addressing the critical challenges associated with them. Traditional\nquanvolutional layers, although beneficial for feature extraction, have largely\nbeen static, offering limited adaptability. Unlike state-of-the-art, our\nresearch overcomes this limitation by enabling training within these layers,\nsignificantly increasing the flexibility and potential of QuNNs. However, the\nintroduction of multiple trainable quanvolutional layers induces complexities\nin gradient-based optimization, primarily due to the difficulty in accessing\ngradients across these layers. To resolve this, we propose a novel\narchitecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging\nthe concept of residual learning, which facilitates the flow of gradients by\nadding skip connections between layers. By inserting residual blocks between\nquanvolutional layers, we ensure enhanced gradient access throughout the\nnetwork, leading to improved training performance. Moreover, we provide\nempirical evidence on the strategic placement of these residual blocks within\nQuNNs. Through extensive experimentation, we identify an efficient\nconfiguration of residual blocks, which enables gradients across all the layers\nin the network that eventually results in efficient training. Our findings\nsuggest that the precise location of residual blocks plays a crucial role in\nmaximizing the performance gains in QuNNs. Our results mark a substantial step\nforward in the evolution of quantum deep learning, offering new avenues for\nboth theoretical development and practical quantum computing applications.", "AI": {"tldr": "The paper introduces Residual Quanvolutional Neural Networks (ResQuNNs), addressing challenges of gradient flow in trainable quanvolutional layers using residual blocks to improve training.", "motivation": "Traditional quanvolutional layers in Quanvolutional Neural Networks (QuNNs) are static and lack adaptability, limiting their performance enhancement potential.", "method": "The authors propose trainable quanvolutional layers combined with a residual learning architecture (ResQuNNs), utilizing residual blocks to address gradient-based optimization challenges.", "result": "Extensive experiments reveal an efficient configuration of residual blocks, enhancing gradient accessibility across all layers and leading to more effective training.", "conclusion": "The placement and use of residual blocks within QuNNs is critical for improved performance, marking progress in quantum deep learning and its practical applications."}}
{"id": "2506.23053", "pdf": "https://arxiv.org/pdf/2506.23053", "abs": "https://arxiv.org/abs/2506.23053", "authors": ["Hanlin Dong", "Arian Prabowo", "Hao Xue", "Flora D. Salim"], "title": "Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Air quality prediction is a challenging forecasting task due to its\nspatio-temporal complexity and the inherent dynamics as well as uncertainty.\nMost of the current models handle these two challenges by applying Graph Neural\nNetworks or known physics principles, and quantifying stochasticity through\nprobabilistic networks like Diffusion models. Nevertheless, finding the right\nbalancing point between the certainties and uncertainties remains an open\nquestion. Therefore, we propose Double-Diffusion, a novel diffusion\nprobabilistic model that harnesses the power of known physics to guide air\nquality forecasting with stochasticity. To the best of our knowledge, while\nprecedents have been made of using conditional diffusion models to predict air\npollution, this is the first attempt to use physics as a conditional generative\napproach for air quality prediction. Along with a sampling strategy adopted\nfrom image restoration and a new denoiser architecture, Double-Diffusion ranks\nfirst in most evaluation scenarios across two real-life datasets compared with\nother probabilistic models, it also cuts inference time by 50% to 30% while\nenjoying an increase between 3-12% in Continuous Ranked Probabilistic Score\n(CRPS).", "AI": {"tldr": "Double-Diffusion introduces a physics-guided approach to enhance air quality prediction using probabilistic diffusion modeling, achieving superior results while also improving computational efficiency.", "motivation": "Air quality prediction is complicated by its spatio-temporal and dynamic uncertainties, requiring a balance between deterministic physics-based modeling and stochastic approaches.", "method": "The paper proposes Double-Diffusion, using physics principles as conditioning factors in a diffusion probabilistic model, integrated with a new denoiser architecture and improved sampling strategies.", "result": "Double-Diffusion outperforms other probabilistic models on real-life datasets in most scenarios, with computational efficiency gains of 30-50% while improving CRPS scores by 3-12%.", "conclusion": "Double-Diffusion successfully combines deterministic physics-guided modeling with stochastic prediction, offering better accuracy and efficiency in air quality forecasting."}}
{"id": "2506.22836", "pdf": "https://arxiv.org/pdf/2506.22836", "abs": "https://arxiv.org/abs/2506.22836", "authors": ["Hongyan An", "Kuan Zhu", "Xin He", "Haiyun Guo", "Chaoyang Zhao", "Ming Tang", "Jinqiao Wang"], "title": "FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition", "categories": ["cs.CV"], "comment": "ICME 2025 Oral", "summary": "Pedestrian attribute recognition (PAR) is a fundamental perception task in\nintelligent transportation and security. To tackle this fine-grained task, most\nexisting methods focus on extracting regional features to enrich attribute\ninformation. However, a regional feature is typically used to predict a fixed\nset of pre-defined attributes in these methods, which limits the performance\nand practicality in two aspects: 1) Regional features may compromise\nfine-grained patterns unique to certain attributes in favor of capturing common\ncharacteristics shared across attributes. 2) Regional features cannot\ngeneralize to predict unseen attributes in the test time. In this paper, we\npropose the \\textbf{F}ine-grained \\textbf{O}ptimization with semanti\\textbf{C}\ng\\textbf{U}ided under\\textbf{S}tanding (FOCUS) approach for PAR, which\nadaptively extracts fine-grained attribute-level features for each attribute\nindividually, regardless of whether the attributes are seen or not during\ntraining. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to\ncapture latent features at varying levels of visual granularity, thereby\nenriching the diversity of the extracted information. Next, we introduce the\nAttribute-guided Visual Feature Extraction (AVFE) module, which leverages\ntextual attributes as queries to retrieve their corresponding visual attribute\nfeatures from the Mix Tokens using a cross-attention mechanism. To ensure that\ntextual attributes focus on the appropriate Mix Tokens, we further incorporate\na Region-Aware Contrastive Learning (RACL) method, encouraging attributes\nwithin the same region to share consistent attention maps. Extensive\nexperiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness\nand strong generalization ability of our method.", "AI": {"tldr": "The paper presents FOCUS, a framework for pedestrian attribute recognition that adapts to fine-grained and unseen attributes using semantic guidance and novel token/method designs.", "motivation": "Current PAR methods use regional features that compromise fine-grained recognition and fail to generalize to unseen attributes, limiting performance and practicality.", "method": "The FOCUS framework includes Multi-Granularity Mix Tokens for diverse information capture and Attribute-guided Visual Feature Extraction with cross-attention mechanisms. Region-Aware Contrastive Learning is also employed for improved consistency in attention.", "result": "The approach demonstrated effectiveness and strong generalization abilities across multiple datasets: PA100K, PETA, and RAPv1.", "conclusion": "FOCUS successfully improves fine-grained attribute-level recognition and generalization, providing a more adaptable solution for real-world PAR tasks."}}
{"id": "2506.23340", "pdf": "https://arxiv.org/pdf/2506.23340", "abs": "https://arxiv.org/abs/2506.23340", "authors": ["Yumeng Lin", "Xufeng Duan", "David Haslett", "Yige Chen", "Zhenguang G. Cai"], "title": "Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family", "categories": ["cs.CL"], "comment": null, "summary": "Large language models have achieved impressive progress in multilingual\ntranslation, yet they continue to face challenges with certain language\npairs-particularly those with limited training data or significant linguistic\ndivergence from English. This study systematically investigates how training\ndata, language proximity, and language family affect information loss in\nmultilingual translation. We evaluate two large language models, GPT-4 and\nLlama 2, by performing round-trip translations. Translation quality was\nassessed using BLEU scores and BERT similarity metrics. Our results reveal a\nrobust interaction between training data size and language distance: while\nabundant training data can mitigate the effects of linguistic divergence,\nlanguages structurally closer to English consistently yield higher translation\nquality in low-resource conditions. Among various distance metrics,\northographic, phylogenetic, syntactic, and geographical distances emerge as\nstrong predictors of translation performance. Language family also exerts an\nindependent influence. These findings contribute to a deeper understanding of\nthe linguistic constraints shaping multilingual translation in large language\nmodels, emphasizing that translation quality is shaped not only by data volume\nbut also by structural and typological relationships between languages.", "AI": {"tldr": "Large language models like GPT-4 and Llama 2 face challenges in translation for low-resource languages or those linguistically distant from English. Factors like training data size and language proximity influence translation performance.", "motivation": "To investigate the interplay between training data, linguistic patterns, and language family in shaping multilingual translation quality in large language models.", "method": "The paper evaluated GPT-4 and Llama 2 using round-trip translations and assessed quality via BLEU scores and BERT similarity metrics. Research focused on language proximity, data size, and language family effects.", "result": "Results show interaction between training data volume and linguistic distance: higher data aids divergence issues, but proximity to English improves translation for low-resource languages. Distance metrics like syntax and geography are strong predictors.", "conclusion": "Translation quality in large language models depends on both data size and linguistic relationships, with structural and typological factors playing key roles alongside training data volume."}}
{"id": "2504.15071", "pdf": "https://arxiv.org/pdf/2504.15071", "abs": "https://arxiv.org/abs/2504.15071", "authors": ["Louis Bradshaw", "Simon Colton"], "title": "Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce an extensive new dataset of MIDI files, created by transcribing\naudio recordings of piano performances into their constituent notes. The data\npipeline we use is multi-stage, employing a language model to autonomously\ncrawl and score audio recordings from the internet based on their metadata,\nfollowed by a stage of pruning and segmentation using an audio classifier. The\nresulting dataset contains over one million distinct MIDI files, comprising\nroughly 100,000 hours of transcribed audio. We provide an in-depth analysis of\nour techniques, offering statistical insights, and investigate the content by\nextracting metadata tags, which we also provide. Dataset available at\nhttps://github.com/loubbrad/aria-midi.", "AI": {"tldr": "This paper presents a dataset of over one million MIDI files transcribed from audio recordings using a multi-stage pipeline and statistical metadata analysis.", "motivation": "The motivation is to create a substantial resource of transcribed piano audio performances to aid research and applications in music and audio processing.", "method": "The paper uses a multi-stage pipeline for data collection, involving language model-based autonomous crawling and scoring, and audio classifier-based pruning and segmentation.", "result": "The authors produced a dataset consisting of over one million distinct MIDI files, representing approximately 100,000 hours of transcribed performances.", "conclusion": "The research provides a valuable dataset and detailed analysis techniques, with potential for broad applications in audio and music analysis."}}
{"id": "2506.23055", "pdf": "https://arxiv.org/pdf/2506.23055", "abs": "https://arxiv.org/abs/2506.23055", "authors": ["Hiro Taiyo Hamada", "Ippei Fujisawa", "Genji Kawakita", "Yuki Yamada"], "title": "Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities\nin producing human-like text. However, it is unclear how accurately these\nmodels internalize concepts that shape human thought and behavior. Here, we\ndeveloped a quantitative framework to assess concept alignment between LLMs and\nhuman psychological dimensions using 43 standardized psychological\nquestionnaires, selected for their established validity in measuring distinct\npsychological constructs. Our method evaluates how accurately language models\nreconstruct and classify questionnaire items through pairwise similarity\nanalysis. We compared resulting cluster structures with the original\ncategorical labels using hierarchical clustering. A GPT-4 model achieved\nsuperior classification accuracy (66.2\\%), significantly outperforming GPT-3.5\n(55.9\\%) and BERT (48.1\\%), all exceeding random baseline performance (31.9\\%).\nWe also demonstrated that the estimated semantic similarity from GPT-4 is\nassociated with Pearson's correlation coefficients of human responses in\nmultiple psychological questionnaires. This framework provides a novel approach\nto evaluate the alignment of the human-LLM concept and identify potential\nrepresentational biases. Our findings demonstrate that modern LLMs can\napproximate human psychological constructs with measurable accuracy, offering\ninsights for developing more interpretable AI systems.", "AI": {"tldr": "The paper assesses concept alignment between large language models (LLMs) and human psychological dimensions using standardized questionnaires. It finds that GPT-4 significantly outperforms GPT-3.5, BERT, and random baselines in classification accuracy.", "motivation": "The study seeks to understand whether large language models internalize human psychological concepts accurately, addressing concerns about concept alignment and interpretability in AI systems.", "method": "The authors used 43 standardized psychological questionnaires and pairwise similarity analysis to evaluate concept reconstruction and classification. Cluster structures were compared with original categorical labels using hierarchical clustering.", "result": "GPT-4 achieved 66.2% classification accuracy, outperforming GPT-3.5 (55.9%), BERT (48.1%), and random baselines (31.9%). Additionally, GPT-4's semantic similarity scores correlated with human response patterns in psychological questionnaires.", "conclusion": "Modern large language models demonstrate measurable alignment with human psychological constructs, suggesting their potential for developing interpretable AI systems and identifying representational biases."}}
{"id": "2506.22843", "pdf": "https://arxiv.org/pdf/2506.22843", "abs": "https://arxiv.org/abs/2506.22843", "authors": ["Kien Nguyen", "Clinton Fookes", "Sridha Sridharan", "Huy Nguyen", "Feng Liu", "Xiaoming Liu", "Arun Ross", "Dana Michalski", "Tam\u00e1s Endrei", "Ivan DeAndres-Tame", "Ruben Tolosana", "Ruben Vera-Rodriguez", "Aythami Morales", "Julian Fierrez", "Javier Ortega-Garcia", "Zijing Gong", "Yuhao Wang", "Xuehu Liu", "Pingping Zhang", "Md Rashidunnabi", "Hugo Proen\u00e7a", "Kailash A. Hambarde", "Saeid Rezaei"], "title": "AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results", "categories": ["cs.CV"], "comment": null, "summary": "Person re-identification (ReID) across aerial and ground vantage points has\nbecome crucial for large-scale surveillance and public safety applications.\nAlthough significant progress has been made in ground-only scenarios, bridging\nthe aerial-ground domain gap remains a formidable challenge due to extreme\nviewpoint differences, scale variations, and occlusions. Building upon the\nachievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID\n2025 Challenge - the first large-scale video-based competition focused on\nhigh-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID\ndataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7\nmillion frames captured from UAVs, CCTV, and wearable cameras, the challenge\nfeatured four international teams. These teams developed solutions ranging from\nmulti-stream architectures to transformer-based temporal reasoning and\nphysics-informed modeling. The leading approach, X-TFCLIP from UAM, attained\n72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the\nground-to-aerial ReID setting, surpassing existing baselines while highlighting\nthe dataset's complexity. For additional details, please refer to the official\nwebsite at https://agvpreid25.github.io.", "AI": {"tldr": "The paper introduces the AG-VPReID 2025 Challenge focused on video-based aerial-ground person re-identification using a novel dataset with over 3 million frames, achieving 72.28% Rank-1 accuracy with the leading approach.", "motivation": "To address the challenging problem of person re-identification across aerial and ground viewpoints for surveillance and public safety, given the extreme viewpoint differences, scale variations, and occlusions.", "method": "The challenge employs a newly constructed AG-VPReID dataset with 3,027 identities and 13,500+ tracklets, while solutions include multi-stream architectures, transformer-based temporal reasoning, and physics-informed modeling.", "result": "The leading solution, X-TFCLIP from UAM, achieved 72.28% Rank-1 accuracy for aerial-to-ground ReID and 70.77% for ground-to-aerial ReID, outperforming existing baselines.", "conclusion": "The AG-VPReID 2025 Challenge demonstrates the feasibility of high-accuracy aerial-ground person re-identification using innovative approaches, though the complexity of the dataset underscores the challenge's difficulty."}}
{"id": "2506.23342", "pdf": "https://arxiv.org/pdf/2506.23342", "abs": "https://arxiv.org/abs/2506.23342", "authors": ["Akim Tsvigun", "Daniil Vasilev", "Ivan Tsvigun", "Ivan Lysenko", "Talgat Bektleuov", "Aleksandr Medvedev", "Uliana Vinogradova", "Nikita Severin", "Mikhail Mozikov", "Andrey Savchenko", "Rostislav Grigorev", "Ramil Kuleev", "Fedor Zhdanov", "Artem Shelmanov", "Ilya Makarov"], "title": "ATGen: A Framework for Active Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2025 System Demonstrations", "summary": "Active learning (AL) has demonstrated remarkable potential in reducing the\nannotation effort required for training machine learning models. However,\ndespite the surging popularity of natural language generation (NLG) tasks in\nrecent years, the application of AL to NLG has been limited. In this paper, we\nintroduce Active Text Generation (ATGen) - a comprehensive framework that\nbridges AL with text generation tasks, enabling the application of\nstate-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered\nannotation in NLG tasks using both human annotators and automatic annotation\nagents based on large language models (LLMs). The framework supports LLMs\ndeployed as services, such as ChatGPT and Claude, or operated on-premises.\nFurthermore, ATGen provides a unified platform for smooth implementation and\nbenchmarking of novel AL strategies tailored to NLG tasks. Finally, we present\nevaluation results for state-of-the-art AL strategies across diverse settings\nand multiple text generation tasks. We show that ATGen reduces both the effort\nof human annotators and costs associated with API calls to LLM-based annotation\nagents. The code of the framework is available on GitHub under the MIT license.\nThe video presentation is available at http://atgen-video.nlpresearch.group", "AI": {"tldr": "The paper proposes ATGen, an active learning framework tailored for natural language generation tasks, reducing annotation efforts and enabling benchmark comparisons.", "motivation": "To overcome the underutilization of active learning strategies in natural language generation tasks, given their potential to reduce annotation costs.", "method": "Active Text Generation (ATGen) incorporates state-of-the-art active learning strategies using human and large language model annotators, offering easy implementation and benchmarking for text generation tasks.", "result": "ATGen demonstrated cost reduction for human annotators and API calls in diverse text generation tasks across various settings.", "conclusion": "ATGen offers an effective and accessible solution, enhancing active learning in natural language generation, with open-source availability for community use."}}
{"id": "2506.23068", "pdf": "https://arxiv.org/pdf/2506.23068", "abs": "https://arxiv.org/abs/2506.23068", "authors": ["Zhiyu Zhao", "Haoxuan Li", "Haifeng Zhang", "Jun Wang", "Francesco Faccio", "J\u00fcrgen Schmidhuber", "Mengyue Yang"], "title": "Curious Causality-Seeking Agents Learn Meta Causal World", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": "33 pages", "summary": "When building a world model, a common assumption is that the environment has\na single, unchanging underlying causal rule, like applying Newton's laws to\nevery situation. In reality, what appears as a drifting causal mechanism is\noften the manifestation of a fixed underlying mechanism seen through a narrow\nobservational window. This brings about a problem that, when building a world\nmodel, even subtle shifts in policy or environment states can alter the very\nobserved causal mechanisms. In this work, we introduce the \\textbf{Meta-Causal\nGraph} as world models, a minimal unified representation that efficiently\nencodes the transformation rules governing how causal structures shift across\ndifferent latent world states. A single Meta-Causal Graph is composed of\nmultiple causal subgraphs, each triggered by meta state, which is in the latent\nstate space. Building on this representation, we introduce a\n\\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta\nstates that trigger each subgraph, (2) discover the corresponding causal\nrelationships by agent curiosity-driven intervention policy, and (3)\niteratively refine the Meta-Causal Graph through ongoing curiosity-driven\nexploration and agent experiences. Experiments on both synthetic tasks and a\nchallenging robot arm manipulation task demonstrate that our method robustly\ncaptures shifts in causal dynamics and generalizes effectively to previously\nunseen contexts.", "AI": {"tldr": "This paper introduces the concept of Meta-Causal Graphs as world models to address challenges in understanding shifting causal mechanisms in dynamic environments. It also proposes a Causality-Seeking Agent to identify, discover, and refine such causal structures.", "motivation": "The motivation stems from the recognition that conventional world models assume stable causal mechanisms, but real-world observations often show shifting causal dynamics due to latent underlying states.", "method": "The approach centers around the Meta-Causal Graph representation, composed of causal subgraphs triggered by latent meta states. A Causality-Seeking Agent employs curiosity-driven interventions and iterative refinement to explore and understand causal shifts.", "result": "Experiments demonstrate the efficiency of the proposed method in capturing causal dynamics shifts and generalizing to new contexts, both on synthetic and robotic manipulation tasks.", "conclusion": "The study successfully showcases a framework for dynamically understanding and representing causal structures in changing environments, highlighting its utility in both theoretical and practical applications."}}
{"id": "2506.22850", "pdf": "https://arxiv.org/pdf/2506.22850", "abs": "https://arxiv.org/abs/2506.22850", "authors": ["Aalok Gangopadhyay", "Shashikant Verma", "Shanmuganathan Raman"], "title": "DMD-Net: Deep Mesh Denoising Network", "categories": ["cs.CV"], "comment": null, "summary": "We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning\nframework, for solving the mesh denoising problem. DMD-Net consists of a Graph\nConvolutional Neural Network in which aggregation is performed in both the\nprimal as well as the dual graph. This is realized in the form of an asymmetric\ntwo-stream network, which contains a primal-dual fusion block that enables\ncommunication between the primal-stream and the dual-stream. We develop a\nFeature Guided Transformer (FGT) paradigm, which consists of a feature\nextractor, a transformer, and a denoiser. The feature extractor estimates the\nlocal features, that guide the transformer to compute a transformation, which\nis applied to the noisy input mesh to obtain a useful intermediate\nrepresentation. This is further processed by the denoiser to obtain the\ndenoised mesh. Our network is trained on a large scale dataset of 3D objects.\nWe perform exhaustive ablation studies to demonstrate that each component in\nour network is essential for obtaining the best performance. We show that our\nmethod obtains competitive or better results when compared with the\nstate-of-the-art mesh denoising algorithms. We demonstrate that our method is\nrobust to various kinds of noise. We observe that even in the presence of\nextremely high noise, our method achieves excellent performance.", "AI": {"tldr": "DMD-Net is a deep learning-based framework for effectively denoising 3D meshes using a graph convolutional neural network with a two-stream structure and a novel Feature Guided Transformer paradigm.", "motivation": "The paper aims to address the challenge of effectively denoising 3D mesh data, a common problem in computer graphics and 3D modeling, by leveraging advancements in deep learning.", "method": "The proposed DMD-Net employs a graph convolutional neural network that utilizes both primal and dual graphs in an asymmetric two-stream structure, integrated with a Feature Guided Transformer paradigm consisting of a feature extractor, transformer, and denoiser.", "result": "Extensive experiments and ablation studies show that DMD-Net achieves competitive or superior results compared to state-of-the-art methods across various noise levels, including extremely high noise.", "conclusion": "DMD-Net presents a robust and effective approach for 3D mesh denoising, demonstrating its utility and generalizability on large-scale datasets and challenging noise scenarios."}}
{"id": "2506.23377", "pdf": "https://arxiv.org/pdf/2506.23377", "abs": "https://arxiv.org/abs/2506.23377", "authors": ["Taejin Kim", "Siun-Chuon Mau", "Konrad Vesey"], "title": "Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 5 main pages of text, 5 figures, 2 tables. Research work\n  performed at CACI INTL INC", "summary": "Large language models (LLMs) are used in a variety of mission-critical roles.\nDue to the rapidly developing nature of LLMs, there is a lack of quantifiable\nunderstanding of the bias and perspective associated with LLM output. Inspired\nby this need, this paper considers the broader issue of perspective or\nviewpoint of general text and perspective control of large-language model (LLM)\noutput. Perspective-Dial consists of two main components: a (1) metric space,\ndubbed Perspective Space, that enables quantitative measurements of different\nperspectives regarding a topic, and the use of (2) Systematic Prompt\nEngineering that utilizes greedy-coordinate descent to control LLM output\nperspective based on measurement feedback from the Perspective Space. The\nempirical nature of the approach allows progress to side step a principled\nunderstanding of perspective or bias -- effectively quantifying and adjusting\noutputs for a variety of topics. Potential applications include detection,\ntracking and mitigation of LLM bias, narrative detection, sense making and\ntracking in public discourse, and debate bot advocating given perspective.", "AI": {"tldr": "The paper introduces Perspective-Dial, a framework to quantify and control biases or perspectives in large language models (LLMs).", "motivation": "To address the lack of a quantifiable understanding of biases and perspectives in the rapidly evolving domain of LLM outputs.", "method": "The paper proposes Perspective Space for quantifying perspectives and a Systematic Prompt Engineering approach using greedy-coordinate descent to adjust LLM outputs.", "result": "Demonstrated empirical success in detecting, tracking, and controlling LLM biases and perspectives across various topics.", "conclusion": "Perspective-Dial offers a practical method to study and manage LLM perspectives, opening applications in bias-mitigation, narrative tracking, public discourse analysis, and debate systems."}}
{"id": "2506.23135", "pdf": "https://arxiv.org/pdf/2506.23135", "abs": "https://arxiv.org/abs/2506.23135", "authors": ["Yu Shang", "Xin Zhang", "Yinzhou Tang", "Lei Jin", "Chen Gao", "Wei Wu", "Yong Li"], "title": "RoboScape: Physics-informed Embodied World Model", "categories": ["cs.CV", "cs.RO"], "comment": "17 pages", "summary": "World models have become indispensable tools for embodied intelligence,\nserving as powerful simulators capable of generating realistic robotic videos\nwhile addressing critical data scarcity challenges. However, current embodied\nworld models exhibit limited physical awareness, particularly in modeling 3D\ngeometry and motion dynamics, resulting in unrealistic video generation for\ncontact-rich robotic scenarios. In this paper, we present RoboScape, a unified\nphysics-informed world model that jointly learns RGB video generation and\nphysics knowledge within an integrated framework. We introduce two key\nphysics-informed joint training tasks: temporal depth prediction that enhances\n3D geometric consistency in video rendering, and keypoint dynamics learning\nthat implicitly encodes physical properties (e.g., object shape and material\ncharacteristics) while improving complex motion modeling. Extensive experiments\ndemonstrate that RoboScape generates videos with superior visual fidelity and\nphysical plausibility across diverse robotic scenarios. We further validate its\npractical utility through downstream applications including robotic policy\ntraining with generated data and policy evaluation. Our work provides new\ninsights for building efficient physics-informed world models to advance\nembodied intelligence research. The code is available at:\nhttps://github.com/tsinghua-fib-lab/RoboScape.", "AI": {"tldr": "RoboScape is a proposed physics-informed world model that improves realistic video generation for robotic scenarios by integrating 3D geometry and physical dynamics.", "motivation": "Existing world models for embodied intelligence face challenges in physical awareness, leading to unrealistic video simulations in contact-rich robotic tasks.", "method": "RoboScape employs physics-informed joint training tasks: temporal depth prediction for 3D geometry consistency and keypoint dynamics learning for improved motion modeling by encoding physical properties.", "result": "Experiments show that RoboScape achieves superior visual fidelity and physical plausibility, and it has practical utility in robotic policy training and evaluation.", "conclusion": "RoboScape provides an efficient approach to building physics-informed world models, offering significant advancements in embodied intelligence research."}}
{"id": "2506.23145", "pdf": "https://arxiv.org/pdf/2506.23145", "abs": "https://arxiv.org/abs/2506.23145", "authors": ["Shahad Hardan", "Darya Taratynova", "Abdelmajid Essofi", "Karthik Nandakumar", "Mohammad Yaqub"], "title": "Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": null, "summary": "Privacy preservation in AI is crucial, especially in healthcare, where models\nrely on sensitive patient data. In the emerging field of machine unlearning,\nexisting methodologies struggle to remove patient data from trained multimodal\narchitectures, which are widely used in healthcare. We propose Forget-MI, a\nnovel machine unlearning method for multimodal medical data, by establishing\nloss functions and perturbation techniques. Our approach unlearns unimodal and\njoint representations of the data requested to be forgotten while preserving\nknowledge from the remaining data and maintaining comparable performance to the\noriginal model. We evaluate our results using performance on the forget\ndataset, performance on the test dataset, and Membership Inference Attack\n(MIA), which measures the attacker's ability to distinguish the forget dataset\nfrom the training dataset. Our model outperforms the existing approaches that\naim to reduce MIA and the performance on the forget dataset while keeping an\nequivalent performance on the test set. Specifically, our approach reduces MIA\nby 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305,\nrespectively. Additionally, our performance on the test set matches that of the\nretrained model, while allowing forgetting. Code is available at\nhttps://github.com/BioMedIA-MBZUAI/Forget-MI.git", "AI": {"tldr": "The paper introduces Forget-MI, a machine unlearning framework, to address privacy concerns in AI models trained on multimodal medical data while maintaining performance.", "motivation": "Preserving privacy in AI, especially in healthcare, is difficult due to the need to remove sensitive patient data from multimodal models, which are prevalent and challenging to adapt for \"machine unlearning.\"", "method": "The authors designed Forget-MI using specialized loss functions and perturbation techniques to unlearn specific data while retaining performance on remaining data.", "result": "Forget-MI outperformed baseline methods, achieving a reduction of 0.202 in Membership Inference Attack (MIA) risk and decreased AUC and F1 scores on the forgotten dataset by 0.221 and 0.305, respectively, without compromising test set performance.", "conclusion": "Forget-MI constitutes a robust solution for privacy-preserving unlearning in multimodal medical data, balancing security, retention, and performance."}}
{"id": "2506.22864", "pdf": "https://arxiv.org/pdf/2506.22864", "abs": "https://arxiv.org/abs/2506.22864", "authors": ["Li-Cheng Shen", "Jih-Kang Hsieh", "Wei-Hua Li", "Chu-Song Chen"], "title": "Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ICMR 2025", "summary": "Text-to-image retrieval (TIR) aims to find relevant images based on a textual\nquery, but existing approaches are primarily based on whole-image captions and\nlack interpretability. Meanwhile, referring expression segmentation (RES)\nenables precise object localization based on natural language descriptions but\nis computationally expensive when applied across large image collections. To\nbridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies\nTIR and RES, requiring both efficient image search and accurate object\nsegmentation. To address this task, we propose a two-stage framework,\ncomprising a first stage for segmentation-aware image retrieval and a second\nstage for reranking and object grounding with a multimodal large language model\n(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract\nregion-level embeddings offline at first, enabling effective and scalable\nonline retrieval. Secondly, MLLM is used to refine retrieval rankings and\ngenerate bounding boxes, which are matched to segmentation masks. We evaluate\nour approach on COCO and D$^3$ datasets, demonstrating significant improvements\nin both retrieval accuracy and segmentation quality over previous methods.", "AI": {"tldr": "This paper presents Mask-aware Text-to-Image Retrieval (MaTIR), a task combining efficient image search and accurate object segmentation, alongside a two-stage framework to address it.", "motivation": "Existing methods for text-to-image retrieval lack interpretability as they focus on whole-image captions, and referring expression segmentation is computationally inefficient when scaling to large datasets.", "method": "The authors propose a two-stage framework: (1) using SAM and Alpha-CLIP to generate object masks and extract pre-computed embeddings for efficient online retrieval, and (2) applying a multimodal large language model for reranking and generating bounding boxes aligned with segmentation masks.", "result": "The framework demonstrates significant improvements in retrieval accuracy and segmentation quality on the COCO and D$^3$ datasets compared to previous methods.", "conclusion": "Mask-aware TIR successfully combines retrieval and segmentation tasks, providing an interpretable and scalable solution to address limitations in current methods."}}
{"id": "2506.23393", "pdf": "https://arxiv.org/pdf/2506.23393", "abs": "https://arxiv.org/abs/2506.23393", "authors": ["Eugene J. Yu", "Dawei Zhu", "Yifan Song", "Xiangyu Wong", "Jiebin Zhang", "Wenxuan Shi", "Xiaoguang Li", "Qun Liu", "Sujian Li"], "title": "Hierarchical Memory Organization for Wikipedia Generation", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "Generating Wikipedia articles autonomously is a challenging task requiring\nthe integration of accurate, comprehensive, and well-structured information\nfrom diverse sources. This paper introduces the Memory Organization-based\nGeneration (MOG) framework, a novel approach to address these challenges by\nleveraging a hierarchical memory architecture. MOG extracts fine-grained memory\nunits from web documents, recursively organizes them into a Wikipedia-style\nhierarchical structure, and uses this structure to guide the generation\nprocess. This ensures alignment between memory and the article outline,\nimproving both informativeness and verifiability while minimizing\nhallucinations. Additionally, a citation module is implemented to enhance\ntraceability by linking every generated sentence to specific memory units.\nEvaluations on our newly created WikiStart dataset demonstrate that MOG\noutperforms baseline methods in producing informative and reliable articles,\nmaking it particularly robust in real-world scenarios.", "AI": {"tldr": "The paper introduces the Memory Organization-based Generation (MOG) framework for autonomously generating Wikipedia articles using a hierarchical memory structure, which improves informativeness and verifiability.", "motivation": "Generating accurate, comprehensive, and well-structured Wikipedia articles autonomously is challenging due to the need for integration of diverse information sources and maintaining credibility.", "method": "The proposed MOG framework uses a hierarchical memory architecture. It extracts fine-grained memory units from web documents, organizes them into a structure resembling Wikipedia's hierarchy, and integrates a citation module linking generated content to memory sources.", "result": "The framework was evaluated on the WikiStart dataset and demonstrated that it outperforms baseline methods in producing informative and reliable Wikipedia articles.", "conclusion": "MOG effectively combines structured memory organization and citations to generate high-quality and traceable Wikipedia articles, making it suitable for real-world use cases."}}
{"id": "2506.23434", "pdf": "https://arxiv.org/pdf/2506.23434", "abs": "https://arxiv.org/abs/2506.23434", "authors": ["Tianran Liu", "Shengwen Zhao", "Nicholas Rhinehart"], "title": "Towards foundational LiDAR world models with efficient latent flow matching", "categories": ["cs.CV", "cs.RO"], "comment": "25 pages, 13 figures", "summary": "LiDAR-based world models offer more structured and geometry-aware\nrepresentations than their image-based counterparts. However, existing LiDAR\nworld models are narrowly trained; each model excels only in the domain for\nwhich it was built. Can we develop LiDAR world models that exhibit strong\ntransferability across multiple domains? We conduct the first systematic domain\ntransfer study across three demanding scenarios: (i) outdoor to indoor\ngeneralization, (ii) sparse-beam \\& dense-beam adaptation, and (iii)\nnon-semantic to semantic transfer. Given different amounts of fine-tuning data,\nour experiments show that a single pre-trained model can achieve up to 11%\nabsolute improvement (83\\% relative) over training from scratch and outperforms\ntraining from scratch in 30/36 of our comparisons. This transferability of\ndynamic learning significantly reduces the reliance on manually annotated data\nfor semantic occupancy forecasting: our method exceed the previous semantic\noccupancy forecasting models with only 5% of the labeled training data required\nby prior models. We also observed inefficiencies of current LiDAR world models,\nmainly through their under-compression of LiDAR data and inefficient training\nobjectives. To address this, we propose a latent conditional flow matching\n(CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy\nusing only half the training data and a compression ratio 6 times higher than\nthat of prior methods. Our model achieves SOTA performance on\nfuture-trajectory-conditioned semantic occupancy forecasting while being 23x\nmore computationally efficient (a 28x FPS speedup); and achieves SOTA\nperformance on semantic occupancy forecasting while being 2x more\ncomputationally efficient (a 1.1x FPS speedup).", "AI": {"tldr": "The paper explores LiDAR-based world models for improved domain transferability, and proposes a new framework for better data compression and efficiency.", "motivation": "Current LiDAR-based world models are domain-specific and require extensive annotated data for semantic occupancy forecasting.", "method": "Conducted systematic domain transfer studies and proposed a latent conditional flow matching (CFM) framework for enhanced data efficiency and compression.", "result": "Achieved up to 83% relative improvement over training from scratch, reduced requirement for labeled training data by 95%, and state-of-the-art performance in semantic occupancy forecasting with significant computational efficiency gains.", "conclusion": "The proposed techniques advance LiDAR world model transferability and efficiency, setting new benchmarks in semantic occupancy forecasting while minimizing data and computational costs."}}
{"id": "2506.23147", "pdf": "https://arxiv.org/pdf/2506.23147", "abs": "https://arxiv.org/abs/2506.23147", "authors": ["Jonathan Schuster", "Fabian Transchel"], "title": "maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics", "categories": ["cs.LG", "cs.CV"], "comment": "6 pages, 2 figures", "summary": "In the domain of vehicle telematics the automated recognition of driving\nmaneuvers is used to classify and evaluate driving behaviour. This not only\nserves as a component to enhance the personalization of insurance policies, but\nalso to increase road safety, reduce accidents and the associated costs as well\nas to reduce fuel consumption and support environmentally friendly driving. In\nthis context maneuver recognition technically requires a continuous application\nof time series classification which poses special challenges to the transfer,\npreprocessing and storage of telematic sensor data, the training of predictive\nmodels, and the prediction itself. Although much research has been done in the\nfield of gathering relevant data or regarding the methods to build predictive\nmodels for the task of maneuver recognition, there is a practical need for\npython packages and functions that allow to quickly transform data into the\nrequired structure as well as to build and evaluate such models. The\nmaneuverRecognition package was therefore developed to provide the necessary\nfunctions for preprocessing, modelling and evaluation and also includes a ready\nto use LSTM based network structure that can be modified. The implementation of\nthe package is demonstrated using real driving data of three different persons\nrecorded via smartphone sensors.", "AI": {"tldr": "This paper discusses maneuverRecognition, a Python package for classifying driving maneuvers using telematic sensor data and LSTM-based models.", "motivation": "Enhance telematics-based driving maneuver recognition to improve insurance personalization, road safety, fuel efficiency, and environmental impact while addressing practical tool limitations.", "method": "Developed a Python package with preprocessing, modeling, and evaluation functions, integrated with a ready-to-use, modifiable LSTM-based network structure.", "result": "The package was tested using real driving data collected from three individuals via smartphone sensors.", "conclusion": "maneuverRecognition demonstrates utility in handling maneuver recognition tasks, facilitating efficient and accessible development of predictive telematics models."}}
{"id": "2506.22866", "pdf": "https://arxiv.org/pdf/2506.22866", "abs": "https://arxiv.org/abs/2506.22866", "authors": ["Hang-Cheng Dong", "Lu Zou", "Bingguo Liu", "Dong Ye", "Guodong Liu"], "title": "Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Surface defect detection plays a critical role in industrial quality\ninspection. Recent advances in artificial intelligence have significantly\nenhanced the automation level of detection processes. However, conventional\nsemantic segmentation and object detection models heavily rely on large-scale\nannotated datasets, which conflicts with the practical requirements of defect\ndetection tasks. This paper proposes a novel weakly supervised semantic\nsegmentation framework comprising two key components: a region-aware class\nactivation map (CAM) and pseudo-label training. To address the limitations of\nexisting CAM methods, especially low-resolution thermal maps, and insufficient\ndetail preservation, we introduce filtering-guided backpropagation (FGBP),\nwhich refines target regions by filtering gradient magnitudes to identify areas\nwith higher relevance to defects. Building upon this, we further develop a\nregion-aware weighted module to enhance spatial precision. Finally,\npseudo-label segmentation is implemented to refine the model's performance\niteratively. Comprehensive experiments on industrial defect datasets\ndemonstrate the superiority of our method. The proposed framework effectively\nbridges the gap between weakly supervised learning and high-precision defect\nsegmentation, offering a practical solution for resource-constrained industrial\nscenarios.", "AI": {"tldr": "The paper presents a weakly supervised framework for surface defect detection, introducing novel techniques to improve segmentation accuracy while requiring fewer labeled data.", "motivation": "To reduce dependency on large-scale labeled datasets for industrial defect detection, which is impractical in real-world scenarios.", "method": "Proposed a framework combining region-aware CAM, filtering-guided backpropagation (FGBP), and pseudo-label training to enhance defect detection precision.", "result": "The framework outperformed existing methods on industrial defect datasets, providing high precision in weakly supervised segmentation.", "conclusion": "The method bridges weakly supervised learning with high-precision defect detection, making it suitable for resource-limited industrial applications."}}
{"id": "2506.23411", "pdf": "https://arxiv.org/pdf/2506.23411", "abs": "https://arxiv.org/abs/2506.23411", "authors": ["Jiale Zhang", "Zichong Wang", "Avash Palikhe", "Zhipeng Yin", "Wenbin Zhang"], "title": "Datasets for Fairness in Language Models: An In-Depth Survey", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Fairness benchmarks play a central role in shaping how we evaluate language\nmodels, yet surprisingly little attention has been given to examining the\ndatasets that these benchmarks rely on. This survey addresses that gap by\npresenting a broad and careful review of the most widely used fairness datasets\nin current language model research, characterizing them along several key\ndimensions including their origin, scope, content, and intended use to help\nresearchers better appreciate the assumptions and limitations embedded in these\nresources. To support more meaningful comparisons and analyses, we introduce a\nunified evaluation framework that reveals consistent patterns of demographic\ndisparities across datasets and scoring methods. Applying this framework to\ntwenty four common benchmarks, we highlight the often overlooked biases that\ncan influence conclusions about model fairness and offer practical guidance for\nselecting, combining, and interpreting these datasets. We also point to\nopportunities for creating new fairness benchmarks that reflect more diverse\nsocial contexts and encourage more thoughtful use of these tools going forward.\nAll code, data, and detailed results are publicly available at\nhttps://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets\nto promote transparency and reproducibility across the research community.", "AI": {"tldr": "This survey reviews widely used fairness datasets in language model research, introduces an evaluation framework, and highlights inherent biases to foster better understanding and application.", "motivation": "There is a lack of scrutiny toward fairness datasets in language model research despite their critical role in shaping benchmarks and evaluations.", "method": "The paper surveys fairness datasets, analyzes their characteristics, introduces a unified evaluation framework, and applies it to identify biases and demographic disparities.", "result": "Using the framework on twenty-four benchmarks, consistent demographic disparities and overlooked biases were identified, influencing model fairness conclusions.", "conclusion": "This paper offers practical guidance on dataset selection, advocates for more representative fairness benchmarks, and promotes transparency in research via public code and data."}}
{"id": "2506.23982", "pdf": "https://arxiv.org/pdf/2506.23982", "abs": "https://arxiv.org/abs/2506.23982", "authors": ["Ruiyang Hao", "Bowen Jing", "Haibao Yu", "Zaiqing Nie"], "title": "StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving", "categories": ["cs.CV", "cs.RO", "I.4.9"], "comment": "14 pages, 4 figures", "summary": "While personalization has been explored in traditional autonomous driving\nsystems, it remains largely overlooked in end-to-end autonomous driving\n(E2EAD), despite its growing prominence. This gap is critical, as user-aligned\nbehavior is essential for trust, comfort, and widespread adoption of autonomous\nvehicles. A core challenge is the lack of large-scale real-world datasets\nannotated with diverse and fine-grained driving preferences, hindering the\ndevelopment and evaluation of personalized E2EAD models. In this work, we\npresent the first large-scale real-world dataset enriched with annotations\ncapturing diverse driving preferences, establishing a foundation for\npersonalization in E2EAD. We extract static environmental features from\nreal-world road topology and infer dynamic contextual cues using a fine-tuned\nvisual language model (VLM), enabling consistent and fine-grained scenario\nconstruction. Based on these scenarios, we derive objective preference\nannotations through behavioral distribution analysis and rule-based heuristics.\nTo address the inherent subjectivity of driving style, we further employ the\nVLM to generate subjective annotations by jointly modeling scene semantics and\ndriver behavior. Final high-quality labels are obtained through a\nhuman-in-the-loop verification process that fuses both perspectives. Building\non this dataset, we propose the first benchmark for evaluating personalized\nE2EAD models. We assess several state-of-the-art models with and without\npreference conditioning, demonstrating that incorporating personalized\npreferences results in behavior more aligned with human driving. Our work lays\nthe foundation for personalized E2EAD by providing a standardized platform to\nsystematically integrate human preferences into data-driven E2EAD systems,\ncatalyzing future research in human-centric autonomy.", "AI": {"tldr": "This work introduces a dataset and benchmark focused on personalization in end-to-end autonomous driving (E2EAD), an area previously underexplored. Personalized preferences were analyzed and shown to enhance alignment with human driving behaviors.", "motivation": "The motivation was the underexplored field of personalization in E2EAD, which is crucial for trust, comfort, and adoption of autonomous vehicles. The absence of datasets capturing diverse driving preferences hindered progress.", "method": "A dataset with diverse driving preferences was created using road topology, contextual cues modeled by a fine-tuned visual language model (VLM), behavioral analysis, rule-based heuristics, and human-in-the-loop verification. Benchmarking was done to evaluate state-of-the-art E2EAD models with preference conditioning.", "result": "The results demonstrated that personalized preferences significantly improve alignment with human driving behavior, showcasing the importance of personalization in E2EAD systems.", "conclusion": "The study established a foundation for personalized E2EAD by introducing the first dataset and benchmark, offering a systematic way to integrate human preferences into autonomous systems, and urging further research in human-centric autonomy."}}
{"id": "2506.22868", "pdf": "https://arxiv.org/pdf/2506.22868", "abs": "https://arxiv.org/abs/2506.22868", "authors": ["Junsung Lee", "Junoh Kang", "Bohyung Han"], "title": "STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 9 figures, 3 tables", "summary": "Previous text-guided video editing methods often suffer from temporal\ninconsistency, motion distortion, and-most notably-limited domain\ntransformation. We attribute these limitations to insufficient modeling of\nspatiotemporal pixel relevance during the editing process. To address this, we\npropose STR-Match, a training-free video editing algorithm that produces\nvisually appealing and spatiotemporally coherent videos through latent\noptimization guided by our novel STR score. The score captures spatiotemporal\npixel relevance across adjacent frames by leveraging 2D spatial attention and\n1D temporal modules in text-to-video (T2V) diffusion models, without the\noverhead of computationally expensive 3D attention mechanisms. Integrated into\na latent optimization framework with a latent mask, STR-Match generates\ntemporally consistent and visually faithful videos, maintaining strong\nperformance even under significant domain transformations while preserving key\nvisual attributes of the source. Extensive experiments demonstrate that\nSTR-Match consistently outperforms existing methods in both visual quality and\nspatiotemporal consistency.", "AI": {"tldr": "The paper introduces STR-Match, a training-free video editing method that achieves high-quality, temporally coherent visuals using a novel STR score for spatiotemporal pixel relevance.", "motivation": "To address limitations in text-guided video editing, such as temporal inconsistency, motion distortion, and restricted domain transformation.", "method": "Develop STR-Match using a novel STR score based on 2D spatial attention and 1D temporal modules for latent optimization in T2V diffusion models.", "result": "STR-Match delivers visually appealing videos with spatiotemporal coherence and outperforms existing methods in visual quality and consistency.", "conclusion": "STR-Match provides effective video editing with strong domain transformation capabilities while preserving the source's visual attributes."}}
{"id": "2506.23423", "pdf": "https://arxiv.org/pdf/2506.23423", "abs": "https://arxiv.org/abs/2506.23423", "authors": ["Felipe Nuti", "Tim Franzmeyer", "Jo\u00e3o Henriques"], "title": "TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025", "summary": "Past work has studied the effects of fine-tuning on large language models'\n(LLMs) overall performance on certain tasks. However, a quantitative and\nsystematic method for analyzing its effect on individual outputs is still\nlacking. Here, we propose a new method for measuring the contribution that\nfine-tuning makes to individual LLM responses, assuming access to the original\npre-trained model. Our method tracks the model's intermediate hidden states,\nproviding a more fine-grained insight into the effects of fine-tuning than a\nsimple comparison of final outputs from pre-trained and fine-tuned models. We\nintroduce and theoretically analyze an exact decomposition of any fine-tuned\nLLM into a pre-training component and a fine-tuning component. Empirically, we\nfind that model behavior and performance can be steered by up- or down-scaling\nthe fine-tuning component during the forward pass. Motivated by this finding\nand our theoretical analysis, we define the Tuning Contribution (TuCo) as the\nratio of the magnitudes of the fine-tuning component to the pre-training\ncomponent. We observe that three prominent adversarial attacks on LLMs\ncircumvent safety measures in a way that reduces TuCo, and that TuCo is\nconsistently lower on prompts where these attacks succeed compared to those\nwhere they do not. This suggests that attenuating the effect of fine-tuning on\nmodel outputs plays a role in the success of such attacks. In summary, TuCo\nenables the quantitative study of how fine-tuning influences model behavior and\nsafety, and vice versa.", "AI": {"tldr": "This paper introduces a method to quantitatively measure fine-tuning's contribution to individual LLM responses via a decomposition of outputs into pre-training and fine-tuning components.", "motivation": "Past studies have looked at fine-tuning's effect on task performance but lacked methods to analyze its impact on individual model outputs.", "method": "The proposed method tracks LLM hidden states to decompose outputs into pre-training and fine-tuning components, introducing the metric Tuning Contribution (TuCo) to measure the interplay.", "result": "It was found that scaling the fine-tuning component affects behavior and that adversarial attacks succeed more often on low TuCo prompts, showing a connection between fine-tuning attenuation and attack efficacy.", "conclusion": "The TuCo metric provides a framework for investigating fine-tuning's impact on model behavior, including implications for model safety."}}
{"id": "2506.23174", "pdf": "https://arxiv.org/pdf/2506.23174", "abs": "https://arxiv.org/abs/2506.23174", "authors": ["Chen Gong", "Bo Liang", "Wei Gao", "Chenren Xu"], "title": "Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data", "categories": ["cs.LG", "cs.AI"], "comment": "Published in MobiSys 2025", "summary": "Generative models have gained significant attention for their ability to\nproduce realistic synthetic data that supplements the quantity of real-world\ndatasets. While recent studies show performance improvements in wireless\nsensing tasks by incorporating all synthetic data into training sets, the\nquality of synthetic data remains unpredictable and the resulting performance\ngains are not guaranteed. To address this gap, we propose tractable and\ngeneralizable metrics to quantify quality attributes of synthetic data -\naffinity and diversity. Our assessment reveals prevalent affinity limitation in\ncurrent wireless synthetic data, leading to mislabeled data and degraded task\nperformance. We attribute the quality limitation to generative models' lack of\nawareness of untrained conditions and domain-specific processing. To mitigate\nthese issues, we introduce SynCheck, a quality-guided synthetic data\nutilization scheme that refines synthetic data quality during task model\ntraining. Our evaluation demonstrates that SynCheck consistently outperforms\nquality-oblivious utilization of synthetic data, and achieves 4.3% performance\nimprovement even when the previous utilization degrades performance by 13.4%.", "AI": {"tldr": "The paper presents SynCheck, a scheme to address quality limitations in synthetic wireless data and improve task performance.", "motivation": "The authors aim to address the unpredictable quality of synthetic wireless data that can degrade the performance of wireless sensing tasks.", "method": "The authors propose quantifiable metrics (affinity and diversity) to assess synthetic data quality and introduce SynCheck, a quality-guided data refinement scheme during task model training.", "result": "SynCheck showcased a consistent improvement in performance, achieving a 4.3% gain despite initial performance degradation from quality-oblivious approaches.", "conclusion": "SynCheck effectively enhances the quality and utilization of synthetic wireless data, solving critical limitations in current generative models."}}
{"id": "2506.22880", "pdf": "https://arxiv.org/pdf/2506.22880", "abs": "https://arxiv.org/abs/2506.22880", "authors": ["Dang Jisheng", "Wu Xudong", "Wang Bimei", "Lv Ning", "Chen Jiayu", "Jingwen Zhao", "Yichu liu", "Jizhao Liu", "Juncheng Li", "Teng Wang"], "title": "Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Existing video segmenter and grounder approaches, exemplified by Sa2VA,\ndirectly fuse features within segmentation models. This often results in an\nundesirable entanglement of dynamic visual information and static semantics,\nthereby degrading segmentation accuracy. To systematically mitigate this issue,\nwe propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text\npre-training and a linear decoupling module to address the information\nprocessing limitations inherent in SAM-2. Specifically, first, we devise a\npre-training paradigm that converts textual ground-truth labels into\npoint-level prompts while generating corresponding text masks. These masks are\nrefined through a hybrid loss function to strengthen the model's semantic\ngrounding capabilities. Next, we employ linear projection to disentangle hidden\nstates that generated by a large language model into distinct textual and\nvisual feature subspaces. Finally, a dynamic mask fusion strategy\nsynergistically combines these decoupled features through triple supervision\nfrom predicted text/visual masks and ground-truth annotations. Extensive\nexperiments demonstrate state-of-the-art performance across diverse tasks,\nincluding image segmentation, image question answering, video segmentation, and\nvideo question answering. Our codes are available at\nhttps://github.com/longmalongma/DeSa2VA.", "AI": {"tldr": "The paper introduces DeSa2VA, a decoupling-enhanced prompting scheme improving segmentation and grounding performance by addressing limitations in feature processing in existing methods.", "motivation": "The motivation is to overcome the problem of information entanglement in existing video segmentation and grounding models, which negatively impacts segmentation accuracy.", "method": "DeSa2VA uses a pre-training paradigm, linear projection for feature disentanglement, and dynamic mask fusion with triple supervision to enhance semantic grounding and feature processing.", "result": "The proposed method achieves state-of-the-art performance across various tasks such as image and video segmentation, and question answering.", "conclusion": "DeSa2VA successfully disentangles dynamic and static features, improving accuracy and applicability in multiple visual-textual inference tasks, offering a significant advancement in systematic segmentation models."}}
{"id": "2506.23431", "pdf": "https://arxiv.org/pdf/2506.23431", "abs": "https://arxiv.org/abs/2506.23431", "authors": ["Zixian Huang", "Chenxu Niu", "Yu Gu", "Gengyang Xiao", "Xinwei Huang", "Gong Cheng"], "title": "Pipelined Decoder for Efficient Context-Aware Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As the basis of generative AI, an autoregressive model requires the\ngeneration of a new token depending on all the previously generated tokens,\nwhich brings high quality but also restricts the model to generate tokens one\nby one, forming a bottleneck limiting the generation speed. In this paper, we\npropose a new decoder architecture that efficiently generates text in parallel\nfor context-aware generation tasks. Our proposed pipelined decoder initiates\nthe generation of multiple subsequences simultaneously, and, at each time-step,\nit generates a new token for each subsequence to realize parallelism.\nExperiments on multiple text generation tasks, including question answering,\ntext summarization, and keyphrase generation, show that our pipelined decoder\nsignificantly improves the generation speed without a significant loss of\ngeneration quality or additional memory consumption.", "AI": {"tldr": "The paper proposes a pipelined decoder to improve text generation speed by generating multiple tokens simultaneously, without compromising quality or increasing memory usage.", "motivation": "Autoregressive models, though effective in generating high-quality text, are slow due to their sequential token generation approach.", "method": "The authors designed a new pipelined decoder architecture enabling parallel generation of subsequences, with each token generated simultaneously for better efficiency.", "result": "Experiments across various text generation tasks demonstrated significant speed improvement while maintaining comparable quality and memory footprint.", "conclusion": "The pipelined decoder provides an effective solution for enhancing text generation speed, making it suitable for applications requiring faster context-aware text generation."}}
{"id": "2506.24044", "pdf": "https://arxiv.org/pdf/2506.24044", "abs": "https://arxiv.org/abs/2506.24044", "authors": ["Sicong Jiang", "Zilin Huang", "Kangan Qian", "Ziang Luo", "Tianze Zhu", "Yang Zhong", "Yihong Tang", "Menglin Kong", "Yunlong Wang", "Siwen Jiao", "Hao Ye", "Zihao Sheng", "Xin Zhao", "Tuopu Wen", "Zheng Fu", "Sikai Chen", "Kun Jiang", "Diange Yang", "Seongjin Choi", "Lijun Sun"], "title": "A Survey on Vision-Language-Action Models for Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "The rapid progress of multimodal large language models (MLLM) has paved the\nway for Vision-Language-Action (VLA) paradigms, which integrate visual\nperception, natural language understanding, and control within a single policy.\nResearchers in autonomous driving are actively adapting these methods to the\nvehicle domain. Such models promise autonomous vehicles that can interpret\nhigh-level instructions, reason about complex traffic scenes, and make their\nown decisions. However, the literature remains fragmented and is rapidly\nexpanding. This survey offers the first comprehensive overview of VLA for\nAutonomous Driving (VLA4AD). We (i) formalize the architectural building blocks\nshared across recent work, (ii) trace the evolution from early explainer to\nreasoning-centric VLA models, and (iii) compare over 20 representative models\naccording to VLA's progress in the autonomous driving domain. We also\nconsolidate existing datasets and benchmarks, highlighting protocols that\njointly measure driving safety, accuracy, and explanation quality. Finally, we\ndetail open challenges - robustness, real-time efficiency, and formal\nverification - and outline future directions of VLA4AD. This survey provides a\nconcise yet complete reference for advancing interpretable socially aligned\nautonomous vehicles. Github repo is available at\n\\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.", "AI": {"tldr": "This paper surveys the application of Vision-Language-Action (VLA) models to autonomous driving, formalizing architectures, benchmarking over 20 models, and identifying future challenges in the domain.", "motivation": "To provide a comprehensive understanding of the fragmented and evolving literature on VLA models applied to autonomous driving, with the aim of enabling autonomous vehicles that can interpret high-level instructions and make independent decisions.", "method": "The authors reviewed and formalized architectural components of existing VLA models in autonomous driving, compared over 20 models, consolidated datasets, benchmarks, and protocols, and outlined open challenges and future directions.", "result": "A structured taxonomy, comparison across models, identified gaps, and challenges in the application of VLA to autonomous vehicles were presented, alongside a Github repository with relevant resources.", "conclusion": "The paper provides a foundational reference for advancing interpretable, safe, and socially aligned autonomous vehicles through VLA models, while highlighting significant progress and remaining challenges."}}
{"id": "2506.22448", "pdf": "https://arxiv.org/pdf/2506.22448", "abs": "https://arxiv.org/abs/2506.22448", "authors": ["Yu Ma", "Xingyu Zhou", "Xiao Li", "Le Liang", "Shi Jin"], "title": "Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "summary": "Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless\nsystems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA\nsystem, addressing resource allocation challenges. A two-stage unsupervised\nlearning-based framework is proposed to jointly design RIS phase shifts, BS\nbeamforming, and resource block (RB) allocation. The framework includes\nBeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which\nallocates RBs using equivalent CSI derived from BeamNet outputs. Active\nbeamforming is implemented via maximum ratio transmission and water-filling. To\nhandle discrete constraints while ensuring differentiability, quantization and\nthe Gumbel-softmax trick are adopted. A customized loss and phased training\nenhance performance under QoS constraints. Simulations show the method achieves\n99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and\nit remains robust across varying channel and user conditions.", "AI": {"tldr": "This paper presents an unsupervised learning-based approach to optimize resource allocation in RIS-assisted MISO-OFDMA systems, achieving near-optimal performance with significantly reduced runtime.", "motivation": "To address resource allocation challenges in RIS-assisted 6G wireless systems and improve efficiency and performance in transmission systems.", "method": "The authors propose a two-stage framework combining two neural networks: BeamNet (for RIS phase shift prediction using CSI) and AllocationNet (for resource block allocation). Techniques like quantization and the Gumbel-softmax trick are employed to ensure differentiability under constraints. A customized loss function and phased training further improve performance.", "result": "The framework achieves 99.93% of the sum rate of the traditional SCA baseline while using only 0.036% of its runtime. It also demonstrates robustness against varying channel and user conditions.", "conclusion": "The presented approach offers an effective, computationally efficient solution for joint design of RIS-aided wireless systems, advancing the integration of RIS in practical 6G applications."}}
{"id": "2506.23182", "pdf": "https://arxiv.org/pdf/2506.23182", "abs": "https://arxiv.org/abs/2506.23182", "authors": ["Robert Frank", "Michael Widrich", "Rahmad Akbar", "G\u00fcnter Klambauer", "Geir Kjetil Sandve", "Philippe A. Robert", "Victor Greiff"], "title": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Generative machine learning models offer a powerful framework for therapeutic\ndesign by efficiently exploring large spaces of biological sequences enriched\nfor desirable properties. Unlike supervised learning methods, which require\nboth positive and negative labeled data, generative models such as LSTMs can be\ntrained solely on positively labeled sequences, for example, high-affinity\nantibodies. This is particularly advantageous in biological settings where\nnegative data are scarce, unreliable, or biologically ill-defined. However, the\nlack of attribution methods for generative models has hindered the ability to\nextract interpretable biological insights from such models. To address this\ngap, we developed Generative Attribution Metric Analysis (GAMA), an attribution\nmethod for autoregressive generative models based on Integrated Gradients. We\nassessed GAMA using synthetic datasets with known ground truths to characterize\nits statistical behavior and validate its ability to recover biologically\nrelevant features. We further demonstrated the utility of GAMA by applying it\nto experimental antibody-antigen binding data. GAMA enables model\ninterpretability and the validation of generative sequence design strategies\nwithout the need for negative training data.", "AI": {"tldr": "This paper introduces GAMA, a method to improve the interpretability of generative models in biological sequence design, enabling insights and validation without requiring negative data.", "motivation": "Developing a method to extract interpretable biological insights from generative models, which was previously hindered by their lack of attribution mechanisms.", "method": "The paper introduces Generative Attribution Metric Analysis (GAMA), an attribution method based on Integrated Gradients, validated using synthetic datasets and applied to antibody-antigen binding data.", "result": "GAMA successfully identifies biologically relevant features in synthetic datasets and proves useful for interpreting generative sequence design in experimental data.", "conclusion": "GAMA bridges the gap in interpretability of generative biological models, allowing for validation and strategic design without needing negatively labeled data."}}
{"id": "2506.22881", "pdf": "https://arxiv.org/pdf/2506.22881", "abs": "https://arxiv.org/abs/2506.22881", "authors": ["Fumiya Uchiyama", "Rintaro Yanagi", "Shohei Taniguchi", "Shota Takashiro", "Masahiro Suzuki", "Hirokatsu Kataoka", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings", "categories": ["cs.CV"], "comment": null, "summary": "Contrastive learning has the capacity to model multimodal probability\ndistributions by embedding and aligning visual representations with semantics\nfrom captions. This approach enables the estimation of relational semantic\nsimilarity; however, it remains unclear whether it can also represent absolute\nsemantic informativeness. In this work, we introduce a semantic informativeness\nmetric for an image calculated from text samples via a contrastive learning\nmodel; similarly, the informativeness of a text is calculated from image\nsamples. We propose a redefinition of the concept of Information Gain, a\nconcept previously explored in natural language processing, extending its\napplication to the domains of vision and language. Our metric quantifies how\nconditioning on an image distorts the distribution of associated texts, and\nvice versa for text conditioning on image distributions. In OpenCLIP's\nempirical results, we observe that images with the lowest Information Gain\nscores often correspond to placeholder icons such as \"image not found.\"\nFurthermore, we propose to measure a norm-based metric of the embedding to\nestimate the Information Gain, following the theoretical results for Skip-Gram\nwith Negative Sampling (SGNS) word embedding. Information Gain can be measured\nusing either CLIP or SigLIP, and the results demonstrate a strong correlation\nwith a coefficient of determination ranging from 0.98 to 1.00. After obtaining\nthe mean and the covariance of the sample embedding, the computational cost of\nthis method is independent of the sample size, and it is compatible with\npublicly available, open-weight models.", "AI": {"tldr": "This paper introduces a metric for measuring semantic informativeness in images and texts using a contrastive learning model, redefining the Information Gain concept for cross-domain assessment.", "motivation": "To address whether contrastive learning can represent absolute semantic informativeness, not just relational semantic similarity.", "method": "The authors propose a semantic informativeness metric using Information Gain redefined for vision and language, leveraging contrastive learning models like CLIP or SigLIP.", "result": "Empirical results with OpenCLIP show accurate informativeness measurement, with strong correlation coefficients (0.98 to 1.00), and computational efficiency independent of sample size.", "conclusion": "The method effectively measures semantic informativeness across modalities and is compatible with existing open-weight models, ensuring accessibility and computational efficiency."}}
{"id": "2506.23463", "pdf": "https://arxiv.org/pdf/2506.23463", "abs": "https://arxiv.org/abs/2506.23463", "authors": ["Jang Won June"], "title": "What to Keep and What to Drop: Adaptive Table Filtering Framework", "categories": ["cs.CL", "I.2.7"], "comment": "26 pages, 9 figures", "summary": "Large language models (LLMs) for table-based reasoning often struggle with\nlarge tables due to input length limits. We propose ATF (Adaptive Table\nFiltering Framework), a modular and question-aware filtering pipeline that\nprunes uninformative columns and rows using LLM-generated column descriptions,\nclustering, and sparse-dense alignment scores. ATF integrates seamlessly with\nexisting models (e.g., TAPAS, TAPEX) without retraining. Experiments show that\nATF reduces table cells by ~70\\%, boosting performance on out-of-domain TableQA\ntasks while causing slight performance drops on Table Fact Verification, where\nfull-table context is more critical. These results highlight ATF's ability to\nadaptively balance informativeness and minimalism across tasks.", "AI": {"tldr": "This paper proposes ATF, an adaptive framework to filter unnecessary columns and rows from large tables to improve performance in Table-based Question Answering tasks.", "motivation": "Large language models (LLMs) face difficulty processing large tables due to input length limitations, prompting the need for effective methods to reduce table size while retaining critical information.", "method": "The authors introduce ATF, a filtering framework comprising LLM-generated column descriptions, clustering, and sparse-dense alignment scores to prune irrelevant rows and columns. It works modularly without retraining existing TableQA models.", "result": "ATF reduces the number of table cells by approximately 70%, improving performance in out-of-domain TableQA tasks. However, it slightly reduces performance in Table Fact Verification tasks due to the importance of full-table context there.", "conclusion": "ATF is effective in adaptively balancing informativeness and minimalism across different tasks, making it a flexible and modular enhancement to existing TableQA systems."}}
{"id": "2506.22457", "pdf": "https://arxiv.org/pdf/2506.22457", "abs": "https://arxiv.org/abs/2506.22457", "authors": ["Iulia Orvas", "Andrei Radu", "Alessandra Galli", "Ana Neacsu", "Elisabetta Peri"], "title": "A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Continuous, non-invasive pregnancy monitoring is crucial for minimising\npotential complications. The fetal electrocardiogram (fECG) represents a\npromising tool for assessing fetal health beyond clinical environments.\nHome-based monitoring necessitates the use of a minimal number of comfortable\nand durable electrodes, such as dry textile electrodes. However, this setup\npresents many challenges, including increased noise and motion artefacts, which\ncomplicate the accurate extraction of fECG signals. To overcome these\nchallenges, we introduce a pioneering method for extracting fECG from\nsingle-channel recordings obtained using dry textile electrodes using AI\ntechniques. We created a new dataset by simulating abdominal recordings,\nincluding noise closely resembling real-world characteristics of in-vivo\nrecordings through dry textile electrodes, alongside mECG and fECG. To ensure\nthe reliability of the extracted fECG, we propose an innovative pipeline based\non a complex-valued denoising network, Complex UNet. Unlike previous approaches\nthat focused solely on signal magnitude, our method processes both real and\nimaginary components of the spectrogram, addressing phase information and\npreventing incongruous predictions. We evaluated our novel pipeline against\ntraditional, well-established approaches, on both simulated and real data in\nterms of fECG extraction and R-peak detection. The results showcase that our\nsuggested method achieves new state-of-the-art results, enabling an accurate\nextraction of fECG morphology across all evaluated settings. This method is the\nfirst to effectively extract fECG signals from single-channel recordings using\ndry textile electrodes, making a significant advancement towards a fully\nnon-invasive and self-administered fECG extraction solution.", "AI": {"tldr": "The paper introduces an AI-based method to extract fetal electrocardiogram (fECG) from single-channel dry textile electrode recordings, overcoming challenges like noise and motion artifacts. This approach achieves state-of-the-art results.", "motivation": "Continuous pregnancy monitoring is essential for minimizing complications, and fECG offers a promising tool for fetal health assessment outside hospitals. Dry textile electrodes provide comfort but introduce significant noise and artifacts.", "method": "The paper utilizes simulated datasets mimicking real-world conditions and proposes a novel pipeline using Complex UNet, a complex-valued denoising network that processes both magnitude and phase spectrogram components.", "result": "The proposed method outperformed traditional approaches in fECG extraction and R-peak detection from simulated and real recordings, establishing state-of-the-art accuracy.", "conclusion": "This AI-driven solution enables accurate fECG extraction using minimal, non-invasive dry textile electrodes, marking progress toward independent, home-based fetal monitoring systems."}}
{"id": "2506.22890", "pdf": "https://arxiv.org/pdf/2506.22890", "abs": "https://arxiv.org/abs/2506.22890", "authors": ["Senkang Hu", "Yihang Tao", "Guowen Xu", "Xinyuan Qian", "Yiqin Deng", "Xianhao Chen", "Sam Tak Wu Kwong", "Yuguang Fang"], "title": "CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Collaborative Perception (CP) has been shown to be a promising technique for\nmulti-agent autonomous driving and multi-agent robotic systems, where multiple\nagents share their perception information to enhance the overall perception\nperformance and expand the perception range. However, in CP, an ego agent needs\nto receive messages from its collaborators, which makes it vulnerable to\nattacks from malicious agents. To address this critical issue, we propose a\nunified, probability-agnostic, and adaptive framework, namely, CP-Guard, which\nis a tailored defense mechanism for CP deployed by each agent to accurately\ndetect and eliminate malicious agents in its collaboration network. Our key\nidea is to enable CP to reach a consensus rather than a conflict against an ego\nagent's perception results. Based on this idea, we first develop a\nprobability-agnostic sample consensus (PASAC) method to effectively sample a\nsubset of the collaborators and verify the consensus without prior\nprobabilities of malicious agents. Furthermore, we define collaborative\nconsistency loss (CCLoss) for object detection task and bird's eye view (BEV)\nsegmentation task to capture the discrepancy between an ego agent and its\ncollaborators, which is used as a verification criterion for consensus. In\naddition, we propose online adaptive threshold via dual sliding windows to\ndynamically adjust the threshold for consensus verification and ensure the\nreliability of the systems in dynamic environments. Finally, we conduct\nextensive experiments and demonstrate the effectiveness of our framework. Code\nwill be released at https://github.com/CP-Security/CP-Guard", "AI": {"tldr": "The paper presents CP-Guard, a defense mechanism for collaborative perception in multi-agent systems to detect and eliminate malicious agents using methods like probability-agnostic consensus sampling, collaborative consistency loss, and adaptive thresholds.", "motivation": "Collaborative Perception is beneficial for improving information sharing among multiple agents, but it is vulnerable to attacks by malicious agents in multi-agent settings, necessitating effective defense mechanisms.", "method": "CP-Guard uses a probability-agnostic sample consensus (PASAC) method to verify consensus without prior probabilities, collaborative consistency loss to detect discrepancies in shared perception tasks, and a dual sliding windows approach to dynamically adjust verification thresholds in real-time.", "result": "The proposed CP-Guard framework effectively detects and eliminates malicious agents, ensuring reliable perception in dynamic environments, as verified through extensive experimentation.", "conclusion": "CP-Guard significantly enhances the security and reliability of collaborative perception in multi-agent systems, offering adaptive and accurate defense against malicious entities."}}
{"id": "2506.23485", "pdf": "https://arxiv.org/pdf/2506.23485", "abs": "https://arxiv.org/abs/2506.23485", "authors": ["Haocheng Yu", "Yaxiong Wu", "Hao Wang", "Wei Guo", "Yong Liu", "Yawen Li", "Yuyang Ye", "Junping Du", "Enhong Chen"], "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Interactive recommendation is a typical information-seeking task that allows\nusers to interactively express their needs through natural language and obtain\npersonalized recommendations. Large language model-powered (LLM-powered) agents\nhave become a new paradigm in interactive recommendations, effectively\ncapturing users' real-time needs and enhancing personalized experiences.\nHowever, due to limited planning and generalization capabilities, existing\nformulations of LLM-powered interactive recommender agents struggle to\neffectively address diverse and complex user intents, such as intuitive,\nunrefined, or occasionally ambiguous requests. To tackle this challenge, we\npropose a novel thought-augmented interactive recommender agent system (TAIRA)\nthat addresses complex user intents through distilled thought patterns.\nSpecifically, TAIRA is designed as an LLM-powered multi-agent system featuring\na manager agent that orchestrates recommendation tasks by decomposing user\nneeds and planning subtasks, with its planning capacity strengthened through\nThought Pattern Distillation (TPD), a thought-augmentation method that extracts\nhigh-level thoughts from the agent's and human experts' experiences. Moreover,\nwe designed a set of user simulation schemes to generate personalized queries\nof different difficulties and evaluate the recommendations based on specific\ndatasets. Through comprehensive experiments conducted across multiple datasets,\nTAIRA exhibits significantly enhanced performance compared to existing methods.\nNotably, TAIRA shows a greater advantage on more challenging tasks while\ngeneralizing effectively on novel tasks, further validating its superiority in\nmanaging complex user intents within interactive recommendation systems. The\ncode is publicly available at:https://github.com/Alcein/TAIRA.", "AI": {"tldr": "The paper introduces TAIRA, a thought-augmented system that enhances LLM-powered interactive recommendations by managing diverse and complex user intents using thought patterns.", "motivation": "Existing LLM-powered agents struggle to handle complex, ambiguous, or unrefined user intents in interactive recommendation scenarios.", "method": "The proposed method, TAIRA, employs a multi-agent system with a manager agent orchestrating tasks using Thought Pattern Distillation (TPD) to extract high-level thoughts from experiences, combined with user simulation schemes to test performance.", "result": "TAIRA shows superior performance over traditional methods, especially on challenging tasks and in generalizing to new scenarios, across multiple datasets.", "conclusion": "TAIRA effectively addresses complex user intents in interactive recommendation systems, demonstrating enhanced capabilities and generalization potential."}}
{"id": "2506.22460", "pdf": "https://arxiv.org/pdf/2506.22460", "abs": "https://arxiv.org/abs/2506.22460", "authors": ["Ibne Farabi Shihab"], "title": "Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Using mobile phone video of the fingertip as a data source for estimating\nvital signs such as heart rate (HR) and respiratory rate (RR) during daily life\nhas long been suggested. While existing literature indicates that these\nestimates are accurate to within several beats or breaths per minute, the data\nused to draw these conclusions are typically collected in laboratory\nenvironments under careful experimental control, and yet the results are\nassumed to generalize to daily life. In an effort to test it, a team of\nresearchers collected a large dataset of mobile phone video recordings made\nduring daily life and annotated with ground truth HR and RR labels from N=111\nparticipants. They found that traditional algorithm performance on the\nfingerprint videos is worse than previously reported (7 times and 13 times\nworse for RR and HR, respectively). Fortunately, recent advancements in deep\nlearning, especially in convolutional neural networks (CNNs), offer a promising\nsolution to improve this performance. This study proposes a new method for\nestimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error\nin estimated HR by 68% and RR by 75%. These promising results suggest that\nregressor-based deep learning approaches should be used in estimating HR and\nRR.", "AI": {"tldr": "The paper investigates using mobile phone videos for heart rate (HR) and respiratory rate (RR) estimation in daily-life settings, and proposes a 3D deep CNN model to improve accuracy.", "motivation": "Current methods for estimating heart rate and respiratory rate from mobile phone videos are accurate in controlled laboratory settings but fail in generalizing to daily-life applications.", "method": "The researchers collected a large dataset of mobile phone videos during daily life with ground truth HR and RR labels, then developed a novel 3D deep CNN to estimate these vital signs.", "result": "The proposed 3D deep CNN reduced the estimation error for HR by 68% and for RR by 75%, outperforming traditional algorithms.", "conclusion": "Deep learning methods, particularly CNN-based approaches, provide a significant performance improvement and should be used for estimating vital signs in real-world scenarios."}}
{"id": "2506.23201", "pdf": "https://arxiv.org/pdf/2506.23201", "abs": "https://arxiv.org/abs/2506.23201", "authors": ["Haoran Li", "Muhao Guo", "Marija Ilic", "Yang Weng", "Guangchun Ruan"], "title": "External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "10 pages", "summary": "Accurate residential load forecasting is critical for power system\nreliability with rising renewable integration and demand-side flexibility.\nHowever, most statistical and machine learning models treat external factors,\nsuch as weather, calendar effects, and pricing, as extra input, ignoring their\nheterogeneity, and thus limiting the extraction of useful external information.\nWe propose a paradigm shift: external data should serve as meta-knowledge to\ndynamically adapt the forecasting model itself. Based on this idea, we design a\nmeta-representation framework using hypernetworks that modulate selected\nparameters of a base Deep Learning (DL) model in response to external\nconditions. This provides both expressivity and adaptability. We further\nintegrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through\nselective expert activation, while improving robustness by filtering redundant\nexternal inputs. The resulting model, dubbed as a Meta Mixture of Experts for\nExternal data (M2oE2), achieves substantial improvements in accuracy and\nrobustness with limited additional overhead, outperforming existing\nstate-of-the-art methods in diverse load datasets. The dataset and source code\nare publicly available at\nhttps://github.com/haorandd/M2oE2\\_load\\_forecast.git.", "AI": {"tldr": "The paper introduces a novel approach to residential load forecasting by dynamically adapting machine learning models using external conditions, achieving higher accuracy and robustness.", "motivation": "Current forecasting models fail to leverage external factors, such as weather and calendar effects, effectively due to their heterogeneity.", "method": "The authors propose a meta-representation framework utilizing hypernetworks and a Mixture-of-Experts mechanism to dynamically adapt forecasting model parameters based on external conditions.", "result": "The proposed model (M2oE2) outperforms state-of-the-art methods in accuracy and robustness across diverse residential load datasets, with limited computational overhead.", "conclusion": "Integrating external data as meta-knowledge into forecasting models improves expressivity, adaptability, and efficiency, paving the way for better power system reliability in renewable energy contexts."}}
{"id": "2506.22899", "pdf": "https://arxiv.org/pdf/2506.22899", "abs": "https://arxiv.org/abs/2506.22899", "authors": ["Ehsan Pajouheshgar", "Yitao Xu", "Ali Abbasi", "Alexander Mordvintsev", "Wenzel Jakob", "Sabine S\u00fcsstrunk"], "title": "Neural Cellular Automata: From Cells to Pixels", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MA", "eess.IV"], "comment": "6 pages, 5 figures, first draft", "summary": "Neural Cellular Automata (NCAs) are bio-inspired systems in which identical\ncells self-organize to form complex and coherent patterns by repeatedly\napplying simple local rules. NCAs display striking emergent behaviors including\nself-regeneration, generalization and robustness to unseen situations, and\nspontaneous motion. Despite their success in texture synthesis and\nmorphogenesis, NCAs remain largely confined to low-resolution grids. This\nlimitation stems from (1) training time and memory requirements that grow\nquadratically with grid size, (2) the strictly local propagation of information\nwhich impedes long-range cell communication, and (3) the heavy compute demands\nof real-time inference at high resolution. In this work, we overcome this\nlimitation by pairing NCA with a tiny, shared implicit decoder, inspired by\nrecent advances in implicit neural representations. Following NCA evolution on\na coarse grid, a lightweight decoder renders output images at arbitrary\nresolution. We also propose novel loss functions for both morphogenesis and\ntexture synthesis tasks, specifically tailored for high-resolution output with\nminimal memory and computation overhead. Combining our proposed architecture\nand loss functions brings substantial improvement in quality, efficiency, and\nperformance. NCAs equipped with our implicit decoder can generate full-HD\noutputs in real time while preserving their self-organizing, emergent\nproperties. Moreover, because each MLP processes cell states independently,\ninference remains highly parallelizable and efficient. We demonstrate the\napplicability of our approach across multiple NCA variants (on 2D, 3D grids,\nand 3D meshes) and multiple tasks, including texture generation and\nmorphogenesis (growing patterns from a seed), showing that with our proposed\nframework, NCAs seamlessly scale to high-resolution outputs with minimal\ncomputational overhead.", "AI": {"tldr": "The paper introduces enhanced Neural Cellular Automata (NCAs) with implicit decoders for scalable high-resolution outputs, overcoming existing computational challenges.", "motivation": "Neural Cellular Automata face limitations in scaling to high-resolution tasks due to computational overhead, which this study aims to address.", "method": "The authors pair NCAs with a shared implicit decoder and propose novel loss functions tailored to high-resolution texture synthesis and morphogenesis tasks.", "result": "The enhanced NCAs achieve real-time generation of full-HD outputs, maintain emergent properties, and support parallelizable inference across 2D, 3D grids, and meshes.", "conclusion": "The proposed framework enables NCAs to deliver high-quality, computationally efficient outputs for texture generation and morphogenesis at arbitrary resolutions."}}
{"id": "2506.23508", "pdf": "https://arxiv.org/pdf/2506.23508", "abs": "https://arxiv.org/abs/2506.23508", "authors": ["Zhihao Zhang", "Qiaole Dong", "Qi Zhang", "Jun Zhao", "Enyu Zhou", "Zhiheng Xi", "Senjie Jin", "Xiaoran Fan", "Yuhao Zhou", "Yanwei Fu", "Tao Ji", "Tao Gui", "Xuanjing Huang"], "title": "Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages (Preprint. Work in progress)", "summary": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and\nReinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large\nlanguage models to downstream tasks. While effective at task adaptation, their\nimpact on prior knowledge remains unclear. In this paper, we introduce jigsaw\npuzzles as a novel task absent from existing pretraining corpora and\nsystematically study the behavior of SFT and RFT on an open-source multimodal\nmodel, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid\ntask acquisition but leads to catastrophic forgetting, whereas RFT learns more\nslowly on novel tasks but maintains prior knowledge. We analyze this phenomenon\nthrough the lens of learning dynamics, showing that RFT reinforces correct\nsamples that are naturally aligned with the base model's probability landscape,\nmitigating interference with prior knowledge. Moreover, supervised training on\ncorrect RFT-simulated rollouts allows SFT to preserve knowledge while rapidly\nlearning new tasks. These findings suggest that data distribution, rather than\nalgorithmic differences, plays a central role in forgetting, and highlight\nRFT's potential for stable continual learning in multimodal large language\nmodels.", "AI": {"tldr": "This paper explores the balance of task adaptation and knowledge retention in post-training methods for multimodal large language models, using jigsaw puzzles as a novel test task.", "motivation": "To understand how post-training methods like Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) affect prior knowledge in multimodal large language models during task adaptation.", "method": "The researchers used jigsaw puzzles as a novel task and conducted experiments with the multimodal LLM Qwen2.5-VL. They studied how SFT and RFT influenced task acquisition and knowledge retention using learning dynamics analysis.", "result": "SFT enables faster task acquisition but causes significant knowledge forgetting, while RFT maintains prior knowledge but learns more slowly. A combination of RFT simulation rollouts with SFT enabled both rapid learning and knowledge preservation.", "conclusion": "Algorithmic differences are less central to forgetting than data distribution. RFT shows potential for stable continual learning, and combining RFT with supervised training can mitigate forgetting while enabling rapid task learning in multimodal LLMs."}}
{"id": "2506.22461", "pdf": "https://arxiv.org/pdf/2506.22461", "abs": "https://arxiv.org/abs/2506.22461", "authors": ["Chuan Li", "Ruoxuan Yang"], "title": "Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Groundwater supports ecosystems, agriculture, and drinking water supplies\nworldwide, yet effective monitoring remains challenging due to sparse data,\ncomputational constraints, and delayed outputs from traditional approaches. We\ndevelop a machine learning pipeline that predicts groundwater level categories\nusing climate data, hydro-meteorological records, and physiographic attributes\nprocessed through AutoGluon's automated ensemble framework. Our approach\nintegrates geospatial preprocessing, domain-driven feature engineering, and\nautomated model selection to overcome conventional monitoring limitations.\nApplied to a large-scale French dataset (n $>$ 3,440,000 observations from\n1,500+ wells), the model achieves weighted F\\_1 scores of 0.927 on validation\ndata and 0.67 on temporally distinct test data. Scenario-based evaluations\ndemonstrate practical utility for early warning systems and water allocation\ndecisions under changing climate conditions. The open-source implementation\nprovides a scalable framework for integrating machine learning into national\ngroundwater monitoring networks, enabling more responsive and data-driven water\nmanagement strategies.", "AI": {"tldr": "The paper introduces a machine learning pipeline to predict groundwater levels using extensive French groundwater data.", "motivation": "Traditional groundwater monitoring faces challenges like sparse data and delayed outputs, necessitating innovative approaches.", "method": "The study utilizes a machine learning pipeline via AutoGluon's ensemble framework, integrating geospatial preprocessing, feature engineering, and automated model selection.", "result": "The model achieves weighted F1 scores of 0.927 on validation data and 0.67 on challenging temporally distinct test data.", "conclusion": "This machine learning framework offers a scalable and effective solution for improving groundwater monitoring and response strategies worldwide."}}
{"id": "2506.22900", "pdf": "https://arxiv.org/pdf/2506.22900", "abs": "https://arxiv.org/abs/2506.22900", "authors": ["Mai A. Shaaban", "Tausifa Jan Saleem", "Vijay Ram Papineni", "Mohammad Yaqub"], "title": "MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Medical visual question answering (MedVQA) plays a vital role in clinical\ndecision-making by providing contextually rich answers to image-based queries.\nAlthough vision-language models (VLMs) are widely used for this task, they\noften generate factually incorrect answers. Retrieval-augmented generation\naddresses this challenge by providing information from external sources, but\nrisks retrieving irrelevant context, which can degrade the reasoning\ncapabilities of VLMs. Re-ranking retrievals, as introduced in existing\napproaches, enhances retrieval relevance by focusing on query-text alignment.\nHowever, these approaches neglect the visual or multimodal context, which is\nparticularly crucial for medical diagnosis. We propose MOTOR, a novel\nmultimodal retrieval and re-ranking approach that leverages grounded captions\nand optimal transport. It captures the underlying relationships between the\nquery and the retrieved context based on textual and visual information.\nConsequently, our approach identifies more clinically relevant contexts to\naugment the VLM input. Empirical analysis and human expert evaluation\ndemonstrate that MOTOR achieves higher accuracy on MedVQA datasets,\noutperforming state-of-the-art methods by an average of 6.45%. Code is\navailable at https://github.com/BioMedIA-MBZUAI/MOTOR.", "AI": {"tldr": "The paper introduces MOTOR, a novel multimodal approach to improve accuracy in medical visual question answering (MedVQA) by leveraging grounded captions and optimal transport, achieving a 6.45% accuracy improvement over existing methods.", "motivation": "The main motivation is to overcome the challenge of factually incorrect answers generated by existing vision-language models (VLMs) in MedVQA tasks, and to address the limitations of current retrieval-augmented generation methods that often fail in capturing relevant visual or multimodal contexts crucial for medical diagnosis.", "method": "The proposed method, MOTOR, employs a multimodal retrieval and re-ranking approach that uses grounded captions and optimal transport mechanisms to better align the query with both textual and visual-contextual information, thereby identifying clinically relevant contexts for augmenting VLM inputs.", "result": "Empirical and human expert evaluations show that MOTOR outperforms current state-of-the-art methods in MedVQA by an average accuracy improvement of 6.45% on relevant datasets.", "conclusion": "MOTOR significantly enhances the relevance of retrieved contexts in MedVQA by incorporating both textual and visual information, addressing a critical gap in medical diagnosis tasks. Its performance improvement highlights the importance of multimodal re-ranking in this domain."}}
{"id": "2506.23524", "pdf": "https://arxiv.org/pdf/2506.23524", "abs": "https://arxiv.org/abs/2506.23524", "authors": ["Phan Quoc Hung Mai", "Quang Hung Nguyen", "Phuong Giang Duong", "Hong Hanh Nguyen", "Nguyen Tuan Long"], "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the field of education, understanding students' opinions through their\ncomments is crucial, especially in the Vietnamese language, where resources\nremain limited. Existing educational datasets often lack domain relevance and\nstudent slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese\ndataset for Educational Sentiment Classification and Topic Classification,\ncurated from university forums, which offers more samples, richer class\ndiversity, longer texts, and broader vocabulary. In addition, we explore\nmultitask learning using encoder-only language models (BERT), in which we\nshowed that it achieves performance up to 83.7% and 79.8% accuracy for\nsentiment and topic classification tasks. We also benchmark our dataset and\nmodel with other datasets and models, including Large Language Models, and\ndiscuss these benchmarks. The dataset is publicly available at:\nhttps://huggingface.co/datasets/hung20gg/NEU-ESC.", "AI": {"tldr": "The paper introduces NEU-ESC, a Vietnamese dataset for educational sentiment and topic classifications, achieving up to 83.7% accuracy using BERT-based models.", "motivation": "Limited resources and lack of domain relevance in Vietnamese educational datasets necessitate a new dataset to capture students' comments accurately.", "method": "Developed the NEU-ESC dataset from university forums and applied multitask learning using encoder-only language models (BERT). Also benchmarked dataset and model performance against other datasets and large language models.", "result": "The model achieved up to 83.7% accuracy for sentiment classification and 79.8% accuracy for topic classification, highlighted richer textual and vocabulary features of NEU-ESC.", "conclusion": "NEU-ESC addresses resource gaps in Vietnamese educational datasets, offering improved sentiment and topic classification performance. The dataset is publicly accessible."}}
{"id": "2506.22462", "pdf": "https://arxiv.org/pdf/2506.22462", "abs": "https://arxiv.org/abs/2506.22462", "authors": ["Abdallah Lakhdari", "Jiajie Li", "Amani Abusafia", "Athman Bouguettaya"], "title": "Privacy-aware IoT Fall Detection Services For Aging in Place", "categories": ["eess.SP", "cs.AI", "cs.CY", "cs.HC"], "comment": "11 pages, 12 figures, This paper is accepted in the 2025 IEEE\n  International Conference on Web Services (ICWS 2025)", "summary": "Fall detection is critical to support the growing elderly population,\nprojected to reach 2.1 billion by 2050. However, existing methods often face\ndata scarcity challenges or compromise privacy. We propose a novel IoT-based\nFall Detection as a Service (FDaaS) framework to assist the elderly in living\nindependently and safely by accurately detecting falls. We design a\nservice-oriented architecture that leverages Ultra-wideband (UWB) radar sensors\nas an IoT health-sensing service, ensuring privacy and minimal intrusion. We\naddress the challenges of data scarcity by utilizing a Fall Detection\nGenerative Pre-trained Transformer (FD-GPT) that uses augmentation techniques.\nWe developed a protocol to collect a comprehensive dataset of the elderly daily\nactivities and fall events. This resulted in a real dataset that carefully\nmimics the elderly's routine. We rigorously evaluate and compare various models\nusing this dataset. Experimental results show our approach achieves 90.72%\naccuracy and 89.33% precision in distinguishing between fall events and regular\nactivities of daily living.", "AI": {"tldr": "This paper proposes an IoT-based framework using UWB radar sensors and an FD-GPT model for accurate elderly fall detection, achieving over 90% accuracy.", "motivation": "To provide a solution for fall detection among the growing elderly population while addressing challenges like data scarcity and privacy concerns.", "method": "The approach combines an IoT-based architecture with UWB radar sensors, a Fall Detection Generative Pre-trained Transformer (FD-GPT) for data augmentation, and a specialized protocol to gather realistic datasets.", "result": "The proposed method achieves 90.72% accuracy and 89.33% precision in distinguishing fall events from regular daily activities, based on experimental validation.", "conclusion": "The novel FDaaS framework can effectively support elderly individuals in independent living, balancing privacy, data availability, and detection performance."}}
{"id": "2506.23221", "pdf": "https://arxiv.org/pdf/2506.23221", "abs": "https://arxiv.org/abs/2506.23221", "authors": ["B\u00e1lint Horv\u00e1th", "Bal\u00e1zs Csan\u00e1d Cs\u00e1ji"], "title": "Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels", "categories": ["cs.LG", "cs.CV"], "comment": "23 pages, 8 figures, 6 tables", "summary": "The paper proposes a statistical learning approach to the problem of\nestimating missing pixels of images, crucial for image inpainting and\nsuper-resolution problems. One of the main novelties of the method is that it\nalso provides uncertainty quantifications together with the estimated values.\nOur core assumption is that the underlying data-generating function comes from\na Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on\nband-limited functions, central to signal processing, which form Paley-Wiener\ntype RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel\nInterpolation (SGKI), is an extension and refinement of a recently developed\nkernel method. An advantage of SGKI is that it not only estimates the missing\npixels, but also builds non-asymptotic confidence bands for the unobserved\nvalues, which are simultaneously guaranteed for all missing pixels. We also\nshow how to compute these bands efficiently using Schur complements, we discuss\na generalization to vector-valued functions, and we present a series of\nnumerical experiments on various datasets containing synthetically generated\nand benchmark images, as well.", "AI": {"tldr": "The paper introduces a method called SGKI for estimating missing image pixels and quantifying uncertainty, leveraging RKHS and Schur complements.", "motivation": "Address the challenge of estimating missing image data along with providing uncertainty quantifications.", "method": "Utilizes a statistical learning approach grounded in Reproducing Kernel Hilbert Spaces (RKHS) for simultaneously estimating missing pixels and constructing non-asymptotic confidence bands.", "result": "Proposed SGKI method effectively estimates missing pixels and computes confidence bands, demonstrated through experiments on synthetic and benchmark datasets.", "conclusion": "SGKI offers a robust and efficient approach for pixel estimation with uncertainty guarantees, advancing statistical learning methods in image processing."}}
{"id": "2506.22902", "pdf": "https://arxiv.org/pdf/2506.22902", "abs": "https://arxiv.org/abs/2506.22902", "authors": ["Yiling Xu", "Yujie Zhang", "Shuting Xia", "Kaifa Yang", "He Huang", "Ziyu Shan", "Wenjie Huang", "Qi Yang", "Le Yang"], "title": "Point Cloud Compression and Objective Quality Assessment: A Survey", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The rapid growth of 3D point cloud data, driven by applications in autonomous\ndriving, robotics, and immersive environments, has led to criticals demand for\nefficient compression and quality assessment techniques. Unlike traditional 2D\nmedia, point clouds present unique challenges due to their irregular structure,\nhigh data volume, and complex attributes. This paper provides a comprehensive\nsurvey of recent advances in point cloud compression (PCC) and point cloud\nquality assessment (PCQA), emphasizing their significance for real-time and\nperceptually relevant applications. We analyze a wide range of handcrafted and\nlearning-based PCC algorithms, along with objective PCQA metrics. By\nbenchmarking representative methods on emerging datasets, we offer detailed\ncomparisons and practical insights into their strengths and limitations.\nDespite notable progress, challenges such as enhancing visual fidelity,\nreducing latency, and supporting multimodal data remain. This survey outlines\nfuture directions, including hybrid compression frameworks and advanced feature\nextraction strategies, to enable more efficient, immersive, and intelligent 3D\napplications.", "AI": {"tldr": "The paper surveys recent advancements in point cloud compression (PCC) and quality assessment (PCQA), addressing unique challenges and proposing future directions for improvement.", "motivation": "The paper is motivated by the growing use of 3D point cloud data in areas like autonomous driving and immersive environments, which require efficient compression and quality assessment methods.", "method": "It provides a comprehensive analysis and comparison of various PCC algorithms (handcrafted and learning-based) and PCQA metrics using benchmarking on modern datasets.", "result": "The study identifies strengths and limitations of existing approaches and offers insights for practical application, while highlighting unresolved issues like visual fidelity and multimodal data support.", "conclusion": "The paper concludes with suggested future paths, such as hybrid compression frameworks and advanced feature extraction, to enhance the efficiency and capability of 3D applications."}}
{"id": "2506.23527", "pdf": "https://arxiv.org/pdf/2506.23527", "abs": "https://arxiv.org/abs/2506.23527", "authors": ["Jan Kvapil", "Martin Fajcik"], "title": "On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?", "categories": ["cs.CL"], "comment": "13 pages, 5 figures", "summary": "This work-in-progress investigates the memorization, creativity, and nonsense\nfound in cooking recipes generated from Large Language Models (LLMs).\nPrecisely, we aim (i) to analyze memorization, creativity, and non-sense in\nLLMs using a small, high-quality set of human judgments and (ii) to evaluate\npotential approaches to automate such a human annotation in order to scale our\nstudy to hundreds of recipes. To achieve (i), we conduct a detailed human\nannotation on 20 preselected recipes generated by LLM (Mixtral), extracting\neach recipe's ingredients and step-by-step actions to assess which elements are\nmemorized--i.e., directly traceable to online sources possibly seen during\ntraining--and which arise from genuine creative synthesis or outright nonsense.\nWe find that Mixtral consistently reuses ingredients that can be found in\nonline documents, potentially seen during model training, suggesting strong\nreliance on memorized content. To achieve aim (ii) and scale our analysis\nbeyond small sample sizes and single LLM validation, we design an\n``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,\nparsing ingredients and recipe steps, and their annotation. For instance,\ncomparing its output against human annotations, the best ingredient extractor\nand annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on\ningredient matching. This automated framework enables large-scale\nquantification of memorization, creativity, and nonsense in generated recipes,\nproviding rigorous evidence of the models' creative capacities.", "AI": {"tldr": "This paper explores the memorization, creativity, and nonsense in cooking recipes generated by Large Language Models (LLMs), using human annotations and scalable automation tools.", "motivation": "To understand how LLMs balance memorizing existing content, generating creative outputs, and producing nonsensical results in tasks like recipe generation.", "method": "Conducted human annotations on recipes generated by a specific LLM (Mixtral) and designed an automated \u2018LLM-as-judge\u2019 framework for scalable analysis that evaluates ingredients, steps, and nonsense aspects of generated recipes.", "result": "The study found that the LLM, Mixtral, relies significantly on memorized content from online sources. The automated framework demonstrated an accuracy of up to 78% in ingredient matching when compared to human annotations.", "conclusion": "By combining human annotations and an automated pipeline, this study provides a scalable method to assess and quantify LLMs' creativity, reliance on memorized content, and tendency to generate nonsense in recipe generation."}}
{"id": "2506.22468", "pdf": "https://arxiv.org/pdf/2506.22468", "abs": "https://arxiv.org/abs/2506.22468", "authors": ["Konstantinos Koutras", "Agorakis Bompotas", "Constantinos Halkiopoulos", "Athanasios Kalogeras", "Christos Alexakos"], "title": "Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting", "categories": ["eess.SP", "cs.AI"], "comment": "Version of submitted paper on 2023 IEEE International Smart Cities\n  Conference (ISC2), 1-6, 2023", "summary": "The Internet of Things (IoT) plays a major role today in smart building\ninfrastructures, from simple smart-home applications, to more sophisticated\nindustrial type installations. The vast amounts of data generated from relevant\nsystems can be processed in different ways revealing important information.\nThis is especially true in the era of edge computing, when advanced data\nanalysis and decision-making is gradually moving to the edge of the network\nwhere devices are generally characterised by low computing resources. In this\ncontext, one of the emerging main challenges is related to maintaining data\nanalysis accuracy even with less data that can be efficiently handled by low\nresource devices. The present work focuses on correlation analysis of data\nretrieved from a pilot IoT network installation monitoring a small smart office\nby means of environmental and energy consumption sensors. The research\nmotivation was to find statistical correlation between the monitoring variables\nthat will allow the use of machine learning (ML) prediction algorithms for\nenergy consumption reducing input parameters. For this to happen, a series of\nhypothesis tests for the correlation of three different environmental variables\nwith the energy consumption were carried out. A total of ninety tests were\nperformed, thirty for each pair of variables. In these tests, p-values showed\nthe existence of strong or semi-strong correlation with two environmental\nvariables, and of a weak correlation with a third one. Using the proposed\nmethodology, we manage without examining the entire data set to exclude weak\ncorrelated variables while keeping the same score of accuracy.", "AI": {"tldr": "The paper explores the correlation of environmental variables and energy consumption in an IoT-enabled smart office to optimize machine learning input parameters, ensuring accurate predictions with reduced data.", "motivation": "The motivation is to enhance energy consumption prediction in IoT networks by identifying statistical correlations among environmental variables to reduce data input for low-resource edge computing devices.", "method": "The study conducted ninety hypothesis tests across three environmental variables to assess their correlation with energy consumption, identifying statistically strong or weak relationships for optimization.", "result": "Strong or semi-strong correlations were found between energy consumption and two environmental variables, while the correlation with a third variable was weak, enabling input parameter optimization.", "conclusion": "The proposed methodology allows the identification and exclusion of weakly correlated variables, preserving prediction accuracy while reducing computational load for IoT edge devices."}}
{"id": "2506.23225", "pdf": "https://arxiv.org/pdf/2506.23225", "abs": "https://arxiv.org/abs/2506.23225", "authors": ["Yukito Tajima", "Nakamasa Inoue", "Yusuke Sekikawa", "Ikuro Sato", "Rio Yokota"], "title": "Masked Gated Linear Unit", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Gated Linear Units (GLUs) have become essential components in the\nfeed-forward networks of state-of-the-art Large Language Models (LLMs).\nHowever, they require twice as many memory reads compared to feed-forward\nlayers without gating, due to the use of separate weight matrices for the gate\nand value streams. To address this bottleneck, we introduce Masked Gated Linear\nUnits (MGLUs), a novel family of GLUs with an efficient kernel implementation.\nThe core contribution of MGLUs include: (1) the Mixture of Element-wise Gating\n(MoEG) architecture that learns multiple binary masks, each determining gate or\nvalue assignments at the element level on a single shared weight matrix\nresulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly\nkernel that yields up to a 19.7 $\\times$ inference-time speed-up over a naive\nPyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs\ndespite added architectural complexity on an RTX5090 GPU. In LLM experiments,\nthe Swish-activated variant SwiMGLU preserves its memory advantages while\nmatching - or even surpassing - the downstream accuracy of the SwiGLU baseline.", "AI": {"tldr": "This paper introduces Masked Gated Linear Units (MGLUs) to address memory inefficiencies in GLUs used in Large Language Models (LLMs), offering both improved efficiency and competitive accuracy.", "motivation": "GLUs in Large Language Models demand high memory reads due to separate weight matrices for gate and value streams, creating a bottleneck in efficiency.", "method": "MGLUs use the Mixture of Element-wise Gating (MoEG) to employ shared weight matrices for both gate and value streams, reducing memory needs, alongside creating FlashMGLU for hardware-level optimization.", "result": "MGLUs achieved up to 19.7\u00d7 inference-time speed-up over a naive PyTorch implementation and were 47% more memory-efficient and 34% faster compared to standard GLUs on the RTX5090 GPU.", "conclusion": "Masked Gated Linear Units improve memory efficiency and computational speed while maintaining or surpassing downstream accuracy compared to conventional GLUs."}}
{"id": "2506.22907", "pdf": "https://arxiv.org/pdf/2506.22907", "abs": "https://arxiv.org/abs/2506.22907", "authors": ["Yunzhe Shao", "Xinyu Yi", "Lu Yin", "Shihui Guo", "Junhai Yong", "Feng Xu"], "title": "MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "This paper proposes a novel method called MagShield, designed to address the\nissue of magnetic interference in sparse inertial motion capture (MoCap)\nsystems. Existing Inertial Measurement Unit (IMU) systems are prone to\norientation estimation errors in magnetically disturbed environments, limiting\ntheir practical application in real-world scenarios. To address this problem,\nMagShield employs a \"detect-then-correct\" strategy, first detecting magnetic\ndisturbances through multi-IMU joint analysis, and then correcting orientation\nerrors using human motion priors. MagShield can be integrated with most\nexisting sparse inertial MoCap systems, improving their performance in\nmagnetically disturbed environments. Experimental results demonstrate that\nMagShield significantly enhances the accuracy of motion capture under magnetic\ninterference and exhibits good compatibility across different sparse inertial\nMoCap systems.", "AI": {"tldr": "This paper introduces MagShield, a method to counteract magnetic interference in sparse inertial MoCap systems, boosting accuracy.", "motivation": "Address the limitations of existing inertial measurement systems in accurately capturing motion in magnetically disturbed environments.", "method": "MagShield uses a two-step 'detect-then-correct' approach: detecting magnetic interference with multi-IMU joint analysis and correcting errors using human motion priors.", "result": "MagShield effectively improves motion capture accuracy under magnetic interference and is compatible with various sparse inertial MoCap systems.", "conclusion": "MagShield enhances the usability and reliability of sparse inertial MoCap systems in real-world conditions by mitigating magnetic interference problems."}}
{"id": "2506.23601", "pdf": "https://arxiv.org/pdf/2506.23601", "abs": "https://arxiv.org/abs/2506.23601", "authors": ["Weijie Shi", "Yue Cui", "Yaguang Wu", "Jingzhi Fang", "Shibo Zhang", "Mengze Li", "Sirui Han", "Jia Zhu", "Jiajie Xu", "Xiaofang Zhou"], "title": "Semantic-guided Diverse Decoding for Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diverse decoding of large language models is crucial for applications\nrequiring multiple semantically distinct responses, yet existing methods\nprimarily achieve lexical rather than semantic diversity. This limitation\nsignificantly constrains Best-of-N strategies, group-based reinforcement\nlearning, and data synthesis. While temperature sampling and diverse beam\nsearch modify token distributions or apply n-gram penalties, they fail to\nensure meaningful semantic differentiation. We introduce Semantic-guided\nDiverse Decoding (SemDiD), operating directly in embedding space that balances\nquality with diversity through three complementary mechanisms: orthogonal\ndirectional guidance, dynamic inter-group repulsion, and position-debiased\nprobability assessment. SemDiD harmonizes these competing objectives using\nadaptive gain functions and constraint optimization, ensuring both quality\nthresholds and maximal semantic differentiation. Experiments show SemDiD\nconsistently outperforms existing methods, improving Best-of-N coverage by\n1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%\nwhile increasing accuracy by up to 2.1%.", "AI": {"tldr": "SemDiD improves semantic diversity in text generation by focusing on embedding space rather than token-level approaches.", "motivation": "Existing decoding methods for generating diverse text responses fail to achieve significant semantic diversity, limiting their use in various applications.", "method": "SemDiD enhances text diversity by employing embedding-based mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment, optimized through adaptive gain functions and constraints.", "result": "SemDiD improves coverage in Best-of-N strategies by 1.4-5.2% across tasks and accelerates RLHF training convergence by 15%, increasing accuracy by up to 2.1%.", "conclusion": "SemDiD is a superior decoding approach for semantic diversity and quality balance, outperforming conventional token-based methods in language model tasks."}}
{"id": "2506.23266", "pdf": "https://arxiv.org/pdf/2506.23266", "abs": "https://arxiv.org/abs/2506.23266", "authors": ["Lujun Li", "Zhu Qiyuan", "Jiacheng Wang", "Wei Li", "Hao Gu", "Sirui Han", "Yike Guo"], "title": "Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging", "categories": ["cs.LG"], "comment": "Work in progress, revisions ongoing", "summary": "Mixture of Experts (MoE) LLMs face significant obstacles due to their massive\nparameter scale, which imposes memory, storage, and deployment challenges.\nAlthough recent expert merging methods promise greater efficiency by\nconsolidating multiple experts, they are fundamentally hindered by parameter\nconflicts arising from expert specialization. In this paper, we present\nSub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key\ninsight is to perform joint Singular Value Decomposition (SVD) on concatenated\nexpert weights, reducing conflicting parameters by extracting shared\n$U$-matrices while enabling effective merging of the expert-specific $V$\ncomponents. Specifically, Sub-MoE consists of two innovative phases: (1)\nAdaptive Expert Clustering, which groups functionally coherent experts via\nK-means clustering based on cosine similarity of expert outputs; and (2)\nSubspace Expert Merging, which first enforces Experts Union Decomposition to\nderive the shared $U$-matrix across experts in the same group, then pursues\nfrequency-based merging for individual $V$-matrices, and finalizes expert\nreconstruction using the merged $V$-matrix. In this way, we align and fuse\nexperts in a shared subspace, and can be extended with intra-expert compression\nfor further inference optimization. Extensive experiments on Mixtral, DeepSeek,\nand Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms\nexisting expert pruning and merging methods. Notably, our Sub-MoE maintains\n96\\%|86\\% of original performance with 25\\%|50\\% expert reduction on\nMixtral-8x7B in zero-shot benchmarks. Code will be released at\nhttps://github.com/lliai/MoERazor.", "AI": {"tldr": "The paper presents Sub-MoE, a novel framework for compressing Mixture of Experts (MoE) large language models by merging expert parameters using subspace techniques. It significantly reduces parameter scale while retaining high model performance.", "motivation": "The study addresses the challenges of memory, storage, and deployment posed by the massive parameter scale of Mixture of Experts (MoE) models. Existing expert merging methods face limitations due to parameter conflicts from expert specialization.", "method": "The framework, Sub-MoE, involves two main phases: (1) Adaptive Expert Clustering, which groups similar experts using K-means clustering based on cosine similarity of outputs, and (2) Subspace Expert Merging, which applies joint Singular Value Decomposition (SVD) to align and merge expert weights in a shared subspace.", "result": "Sub-MoE outperformed existing expert pruning and merging techniques in extensive experiments on multiple MoE models. For example, it retained 96% and 86% of baseline performance with 25% and 50% fewer experts, respectively, on Mixtral-8x7B benchmarks.", "conclusion": "Sub-MoE effectively compresses large MoE models by resolving parameter conflicts through a subspace approach, achieving significant parameter reduction while sustaining strong performance. The method is promising for optimizing model inference and deployment."}}
{"id": "2506.22908", "pdf": "https://arxiv.org/pdf/2506.22908", "abs": "https://arxiv.org/abs/2506.22908", "authors": ["Yuzhu Wang", "Manni Duan", "Shu Kong"], "title": "Attention to Burstiness: Low-Rank Bilinear Prompt Tuning", "categories": ["cs.CV"], "comment": "ICCV 2025", "summary": "Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique\nthat adapts a pre-trained vision Transformer (ViT) by learning a small set of\nparameters in the input space, known as prompts. In VPT, we uncover\n``burstiness'' in the values arising from the interaction of image patch\nembeddings, and the key and query projectors within Transformer's\nself-attention module. Furthermore, the values of patch embeddings and the key\nand query projectors exhibit Laplacian and hyper-Laplacian distribution,\nrespectively. Intuitively, these non-Gaussian distributions pose challenges for\nlearning prompts. To address this, we propose whitening these data,\nde-correlating them and equalizing their variance towards more Gaussian before\nlearning prompts. We derive the whitening matrix over random image patch\nembeddings and ViT's key and query projectors, and multiply it with the prompt\nto be learned in a bilinear manner. Surprisingly, this method significantly\naccelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on\nthe CUB dataset; interestingly, it learns ``bursty prompts''. Extending the\nbilinear model which is known to introduce burstiness, we present a compact,\nlow-rank version by learning two smaller matrices whose multiplication yields\nthe final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).\nExtensive experiments across multiple benchmark datasets demonstrate that BPT\nmethods not only outperform various VPT methods but also reduce parameter count\nand computation overhead.", "AI": {"tldr": "This study introduces a refined Visual Prompt Tuning (VPT) technique called Bilinear Prompt Tuning (BPT). By whitening and bilinearizing image patch embeddings and vision Transformer parameters, accuracy and efficiency are significantly improved.", "motivation": "The paper aims to address the challenges posed by non-Gaussian distributions in image patch embeddings and the key/query projectors in vision Transformers, hindering the effectiveness of prompt tuning.", "method": "The paper introduces data whitening to decorrelate and equalize variance, making distributions more Gaussian, followed by bilinear multiplication for efficient learning of prompts. A low-rank version is proposed to achieve compactness.", "result": "BPT significantly accelerates prompt tuning, considerably improves accuracy (e.g., >25 points improvement on CUB dataset), and reduces parameter count and computational overhead.", "conclusion": "The proposed BPT approach not only enhances efficacy and efficiency compared to existing VPT methods but also demonstrates robustness across diverse datasets."}}
{"id": "2506.23610", "pdf": "https://arxiv.org/pdf/2506.23610", "abs": "https://arxiv.org/abs/2506.23610", "authors": ["Manuel Pratelli", "Marinella Petrocchi"], "title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs", "categories": ["cs.CL", "cs.CY"], "comment": "pre-print version - paper actually under submission", "summary": "Large language models (LLMs) make it possible to generate synthetic\nbehavioural data at scale, offering an ethical and low-cost alternative to\nhuman experiments. Whether such data can faithfully capture psychological\ndifferences driven by personality traits, however, remains an open question. We\nevaluate the capacity of LLM agents, conditioned on Big-Five profiles, to\nreproduce personality-based variation in susceptibility to misinformation,\nfocusing on news discernment, the ability to judge true headlines as true and\nfalse headlines as false. Leveraging published datasets in which human\nparticipants with known personality profiles rated headline accuracy, we create\nmatching LLM agents and compare their responses to the original human patterns.\nCertain trait-misinformation associations, notably those involving\nAgreeableness and Conscientiousness, are reliably replicated, whereas others\ndiverge, revealing systematic biases in how LLMs internalize and express\npersonality. The results underscore both the promise and the limits of\npersonality-aligned LLMs for behavioral simulation, and offer new insight into\nmodeling cognitive diversity in artificial agents.", "AI": {"tldr": "LLMs conditioned on Big-Five personality traits can replicate some personality-driven differences in news discernment but show systematic biases, highlighting both their potential and limitations for behavioral simulation.", "motivation": "To explore whether LLMs can accurately simulate personality-driven behavioral differences, particularly in susceptibility to misinformation.", "method": "Condition LLM agents on Big-Five personality profiles and compare their ratings of headline accuracy to human responses from published datasets.", "result": "LLMs reliably replicate certain trait associations like Agreeableness and Conscientiousness but show divergences, exposing biases in personality modeling.", "conclusion": "LLMs demonstrate promise for simulating behavioral patterns but reveal limitations, offering insight into improving cognitive diversity modeling in artificial systems."}}
{"id": "2506.22479", "pdf": "https://arxiv.org/pdf/2506.22479", "abs": "https://arxiv.org/abs/2506.22479", "authors": ["Krisanu Sarkar"], "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce Hindsight-Guided Momentum (HGM), a first-order optimization\nalgorithm that adaptively scales learning rates based on the directional\nconsistency of recent updates. Traditional adaptive methods, such as Adam or\nRMSprop , adapt learning dynamics using only the magnitude of gradients, often\noverlooking important geometric cues.Geometric cues refer to directional\ninformation, such as the alignment between current gradients and past updates,\nwhich reflects the local curvature and consistency of the optimization path.\nHGM addresses this by incorporating a hindsight mechanism that evaluates the\ncosine similarity between the current gradient and accumulated momentum. This\nallows it to distinguish between coherent and conflicting gradient directions,\nincreasing the learning rate when updates align and reducing it in regions of\noscillation or noise. The result is a more responsive optimizer that\naccelerates convergence in smooth regions of the loss surface while maintaining\nstability in sharper or more erratic areas. Despite this added adaptability,\nthe method preserves the computational and memory efficiency of existing\noptimizers.By more intelligently responding to the structure of the\noptimization landscape, HGM provides a simple yet effective improvement over\nexisting approaches, particularly in non-convex settings like that of deep\nneural network training.", "AI": {"tldr": "The paper introduces Hindsight-Guided Momentum (HGM), a novel optimization algorithm that uses directional consistency to adaptively scale learning rates and improve performance, particularly in non-convex settings.", "motivation": "Current adaptive optimization methods only adjust based on gradient magnitude, overlooking directional information, which can reflect the optimization path's local curvature and consistency.", "method": "HGM evaluates the cosine similarity between the current gradient and accumulated momentum to adjust learning rates. This mechanism increases rates for coherent directions and decreases them in noisy or oscillating regions.", "result": "The HGM optimizer accelerates convergence in smooth areas of the loss surface while maintaining stability in sharp or erratic regions, improving responsiveness and performance compared to existing optimizers.", "conclusion": "HGM is a computationally efficient and effective enhancement over standard optimization methods, offering particular benefits for complex non-convex problems like deep neural network training."}}
{"id": "2506.23274", "pdf": "https://arxiv.org/pdf/2506.23274", "abs": "https://arxiv.org/abs/2506.23274", "authors": ["Hans Peter Lynsg\u00f8e Raaschou-jensen", "Constanza Fierro", "Anders S\u00f8gaard"], "title": "Predicting thinking time in Reasoning models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reasoning models that produce long, hidden chains of thought have emerged as\npowerful tools for complex, reasoning-intensive\ntasks\\citep{deepseekai2025deepseekr1incentivizingreasoningcapability,\nopenai2024openaio1card}. However, this paradigm introduces a new user\nexperience challenge: users have little insight into how much time the model\nwill spend reasoning before returning an answer. This unpredictability, can\nlead to user frustration and is likely to compound as LLMs can produce\nincreasingly long tasks asynchronously\n\\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and\nevaluate methods for both online and offline prediction of model \"thinking\ntime,\" aiming to develop a practical \"progress bar for reasoning.\" We discuss\nthe implications for user interaction and future research directions.", "AI": {"tldr": "The paper addresses the challenge of unpredictable reasoning time in AI models by proposing methods to predict their 'thinking time' and enhance user experience.", "motivation": "The motivation is to tackle user frustration caused by the unpredictability of how long reasoning models take to complete complex tasks.", "method": "The authors developed methods for both online and offline prediction of the reasoning time of large language models (LLMs).", "result": "The methods aim to provide an estimate of model 'thinking time' to improve user interaction.", "conclusion": "Introducing a 'progress bar for reasoning' helps mitigate user frustration and guides future research in model usability."}}
{"id": "2506.22930", "pdf": "https://arxiv.org/pdf/2506.22930", "abs": "https://arxiv.org/abs/2506.22930", "authors": ["Yiwei He", "Xiangtai Li", "Zhenglin Huang", "Yi Dong", "Hao Fei", "Jiangning Zhang", "Baoyuan Wu", "Guangliang Cheng"], "title": "Towards Explainable Bilingual Multimodal Misinformation Detection and Localization", "categories": ["cs.CV"], "comment": null, "summary": "The increasing realism of multimodal content has made misinformation more\nsubtle and harder to detect, especially in news media where images are\nfrequently paired with bilingual (e.g., Chinese-English) subtitles. Such\ncontent often includes localized image edits and cross-lingual inconsistencies\nthat jointly distort meaning while remaining superficially plausible. We\nintroduce BiMi, a bilingual multimodal framework that jointly performs\nregion-level localization, cross-modal and cross-lingual consistency detection,\nand natural language explanation for misinformation analysis. To support\ngeneralization, BiMi integrates an online retrieval module that supplements\nmodel reasoning with up-to-date external context. We further release BiMiBench,\na large-scale and comprehensive benchmark constructed by systematically editing\nreal news images and subtitles, comprising 104,000 samples with realistic\nmanipulations across visual and linguistic modalities. To enhance\ninterpretability, we apply Group Relative Policy Optimization (GRPO) to improve\nexplanation quality, marking the first use of GRPO in this domain. Extensive\nexperiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in\nclassification accuracy, +15.9 in localization accuracy, and +2.5 in\nexplanation BERTScore, advancing state-of-the-art performance in realistic,\nmultilingual misinformation detection. Code, models, and datasets will be\nreleased.", "AI": {"tldr": "The paper introduces BiMi, a bilingual multimodal system for misinformation detection in multilingual content, along with a benchmark called BiMiBench, demonstrating its superior accuracy and explainability.", "motivation": "Increasingly realistic misinformation in bilingual news media poses challenges due to subtle manipulations across modalities and languages.", "method": "BiMi utilizes region-level localization, cross-modal and cross-lingual consistency checks, and natural language explanations. It also integrates an online retrieval module and Group Relative Policy Optimization (GRPO) for enhanced reasoning and interpretation.", "result": "BiMi achieves significant performance improvements over baselines: +8.9 in classification accuracy, +15.9 in localization accuracy, and +2.5 in explanation BERTScore.", "conclusion": "BiMi advances multilingual misinformation detection, combining cutting-edge techniques for analysis, localization, and interpretability. The paper also provides tools to support further research."}}
{"id": "2506.23661", "pdf": "https://arxiv.org/pdf/2506.23661", "abs": "https://arxiv.org/abs/2506.23661", "authors": ["Arnisa Fazla", "Lucas Krauter", "David Guzman Piedrahita", "Andrianos Michail"], "title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack", "categories": ["cs.CL"], "comment": "12 pages main text, 27 pages total including references and\n  appendices. 13 figures, 10 tables. Accepted for publication in the LNCS\n  proceedings of CLEF 2025 (Best-of-Labs track)", "summary": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate\nthe robustness of text classification systems through word-level modifications\nguided by beam search. Our extensions include support for word deletions and\nthe option to skip substitutions, enabling the discovery of minimal\nmodifications that alter model predictions. We also integrate LIME to better\nprioritize word replacements. Evaluated across multiple datasets and victim\nmodels (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA\nframework, our approach achieves over a 99\\% attack success rate while\npreserving the semantic and lexical similarity of the original texts. Through\nboth quantitative and qualitative analysis, we highlight BeamAttack's\neffectiveness and its limitations. Our implementation is available at\nhttps://github.com/LucK1Y/BeamAttack", "AI": {"tldr": "The study enhances the BeamAttack algorithm for testing text classification robustness, includes word deletion, substitutions, LIME integration, and achieves high success in adversarial attacks.", "motivation": "To evaluate and improve the robustness of text classification models by refining adversarial attack methods.", "method": "Extensions to BeamAttack algorithm: introducing word deletions, skipping substitutions, and adding LIME for better word replacement prioritization; tested across BiLSTM, BERT, and RoBERTa models.", "result": "Achieved over 99% attack success rate while maintaining high semantic and lexical similarity of modified texts.", "conclusion": "The extended BeamAttack is effective in creating adversarial examples and highlights model vulnerabilities, with both quantitative and qualitative validation provided."}}
{"id": "2506.23280", "pdf": "https://arxiv.org/pdf/2506.23280", "abs": "https://arxiv.org/abs/2506.23280", "authors": ["Chaoqun Du", "Yulin Wang", "Shiji Song", "Gao Huang"], "title": "BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian decision theory advocates the Bayes classifier as the optimal\napproach for minimizing the risk in machine learning problems. Current deep\nlearning algorithms usually solve for the optimal classifier by\n\\emph{implicitly} estimating the posterior probabilities, \\emph{e.g.}, by\nminimizing the Softmax cross-entropy loss. This simple methodology has been\nproven effective for meticulously balanced academic benchmark datasets.\nHowever, it is not applicable to the long-tailed data distributions in the real\nworld, where it leads to the gradient imbalance issue and fails to ensure the\nBayes optimal decision rule. To address these challenges, this paper presents a\nnovel approach (BAPE) that provides a more precise theoretical estimation of\nthe data distributions by \\emph{explicitly} modeling the parameters of the\nposterior probabilities and solving them with point estimation. Consequently,\nour method directly learns the Bayes classifier without gradient descent based\non Bayes' theorem, simultaneously alleviating the gradient imbalance and\nensuring the Bayes optimal decision rule. Furthermore, we propose a\nstraightforward yet effective \\emph{distribution adjustment} technique. This\nmethod enables the Bayes classifier trained from the long-tailed training set\nto effectively adapt to the test data distribution with an arbitrary imbalance\nfactor, thereby enhancing performance without incurring additional\ncomputational costs. In addition, we demonstrate the gains of our method are\northogonal to existing learning approaches for long-tailed scenarios, as they\nare mostly designed under the principle of \\emph{implicitly} estimating the\nposterior probabilities. Extensive empirical evaluations on CIFAR-10-LT,\nCIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method\nsignificantly improves the generalization performance of popular deep networks,\ndespite its simplicity.", "AI": {"tldr": "The paper introduces BAPE, a novel method to explicitly model posterior probabilities for a Bayes classifier, specifically addressing complications arising in long-tailed data distributions.", "motivation": "Deep learning often struggles with long-tailed distributions, leading to issues like gradient imbalance and sub-optimal classifiers, when using the common Softmax cross-entropy loss.", "method": "The method, BAPE, explicitly models and solves the posterior parameters and incorporates a distribution adjustment technique to directly learn a Bayes classifier, bypassing gradient descent.", "result": "The BAPE method significantly improves performance across various datasets (e.g., CIFAR-10-LT, CIFAR-100-LT) and adapts well to diverse test data distributions.", "conclusion": "BAPE offers a practical and efficient approach for long-tailed data scenarios, ensuring a Bayes optimal solution and complementing existing deep learning techniques."}}
{"id": "2506.22939", "pdf": "https://arxiv.org/pdf/2506.22939", "abs": "https://arxiv.org/abs/2506.22939", "authors": ["Ghufran A. Omran", "Wassan Saad Abduljabbar Hayale", "Ahmad AbdulQadir AlRababah", "Israa Ibraheem Al-Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar", "Harshavardhan Reddy Penubadi"], "title": "Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Scene categorization (SC) in remotely acquired images is an important subject\nwith broad consequences in different fields, including catastrophe control,\necological observation, architecture for cities, and more. Nevertheless, its\nseveral apps, reaching a high degree of accuracy in SC from distant observation\ndata has demonstrated to be difficult. This is because traditional conventional\ndeep learning models require large databases with high variety and high levels\nof noise to capture important visual features. To address these problems, this\ninvestigation file introduces an innovative technique referred to as the\nCuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type\nof scenes in remote sensing data. The investigation compares the execution of\nCO-BRNN with current techniques, including Multilayer Perceptron- Convolutional\nNeural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory\n(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),\nGraph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional\nNeural Networks Data Augmentation (CNN-DA). The results demonstrate that\nCO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,\nMLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance\nof physical confirmation to ensure the efficiency of satellite data.", "AI": {"tldr": "This paper proposes a Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO-BRNN) for remote sensing scene categorization, achieving 97% accuracy and surpassing existing methods.", "motivation": "The motivation for this research is to address the challenges in achieving high accuracy in scene categorization of remotely acquired images, particularly due to the high noise levels and requirement for significant data variety in traditional deep learning models.", "method": "The study introduces CO-BRNN as an innovative approach for remote sensing scene classification. It compares CO-BRNN's performance against existing methods: MLP-CNN, CNN-LSTM, LSTM-CRF, GB, MIRM-CF, and CNN-DA.", "result": "CO-BRNN achieved the highest accuracy of 97%, outperforming other methods like LSTM-CRF with 90%, MLP-CNN with 85%, and CNN-LSTM with 80%.", "conclusion": "The proposed CO-BRNN method demonstrates superior performance in remote sensing scene categorization, highlighting the importance of physical confirmation for satellite data validation."}}
{"id": "2506.23662", "pdf": "https://arxiv.org/pdf/2506.23662", "abs": "https://arxiv.org/abs/2506.23662", "authors": ["Philip Lippmann", "Jie Yang"], "title": "Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Context-aware embedding methods boost retrieval accuracy by conditioning on\ncorpus statistics (e.g., term co-occurrence and topical patterns) extracted\nfrom neighboring documents. However, this context-aware approach requires\naccess to the target corpus or requires domain-specific finetuning, posing\npractical barriers in privacy-sensitive or resource-constrained settings. We\npresent ZEST, a zero-shot contextual adaptation framework that replaces real\ncorpus access with a one-time offline synthesis of a compact proxy. Given only\na handful exemplar documents representative of the general target domain, we\nuse a multi-step hierarchical procedure to generate a synthetic context corpus\nof several hundred documents that aims to emulate key domain-specific\ndistributions. At inference, the frozen context-aware encoder uses this proxy\ncorpus -- without any finetuning or target corpus access -- to produce\ndomain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot\nsynthetic context adaptation using only five example documents performs within\n0.5% of models leveraging full target corpus access -- demonstrating remarkable\nefficacy without any retraining. ZEST thus provides a practical method for\ndeploying high-performance, adaptable embeddings in constrained environments.", "AI": {"tldr": "ZEST introduces a method for generating domain-adaptive embeddings without requiring access to the target corpus, using synthetic context derived from a few exemplar documents.", "motivation": "The reliance of context-aware embeddings on target corpus access or domain-specific fine-tuning creates practical challenges in privacy-sensitive or resource-constrained scenarios.", "method": "ZEST employs a hierarchical procedure to synthesize a proxy context corpus based on a handful of exemplar documents, which is then used by a frozen encoder to generate domain-adaptive embeddings without fine-tuning.", "result": "Using only five example documents, ZEST achieves zero-shot embedding performance that closely matches models with full corpus access across the MTEB benchmark.", "conclusion": "ZEST offers a scalable and efficient solution for deploying adaptable embeddings in settings with privacy or resource constraints."}}
{"id": "2506.22955", "pdf": "https://arxiv.org/pdf/2506.22955", "abs": "https://arxiv.org/abs/2506.22955", "authors": ["Haniyeh Nikkhah", "Jafar Tanha", "Mahdi Zarrin", "SeyedEhsan Roshan", "Amin Kazempour"], "title": "YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging", "categories": ["cs.CV"], "comment": "Accepted at The 7th International conference on Pattern Recognition\n  and Image Analysis (IPRIA 2025)", "summary": "Medical image segmentation poses significant challenges due to class\nimbalance and the complex structure of medical images. To address these\nchallenges, this study proposes YM-WML, a novel model for cardiac image\nsegmentation. The model integrates a robust backbone for effective feature\nextraction, a YOLOv11 neck for multi-scale feature aggregation, and an\nattention-based segmentation head for precise and accurate segmentation. To\naddress class imbalance, we introduce the Weighted Multi-class Exponential\n(WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity\nCoefficient of 91.02, outperforming state-of-the-art methods. The model\ndemonstrates stable training, accurate segmentation, and strong generalization,\nsetting a new benchmark in cardiac segmentation tasks.", "AI": {"tldr": "A novel model, YM-WML, for cardiac image segmentation is introduced, achieving superior performance on the ACDC dataset.", "motivation": "The study aims to address challenges in medical image segmentation, including class imbalance and the complex structure of medical images.", "method": "The YM-WML model features a strong backbone for feature extraction, a YOLOv11 neck for multi-scale feature aggregation, and an attention-based segmentation head. Additionally, a Weighted Multi-class Exponential (WME) loss function is developed to tackle class imbalance.", "result": "YM-WML achieves a Dice Similarity Coefficient of 91.02 on the ACDC dataset, surpassing state-of-the-art methods with stable training and accurate segmentation.", "conclusion": "YM-WML sets a new benchmark in cardiac image segmentation tasks with its innovative approach and strong generalization."}}
{"id": "2506.23667", "pdf": "https://arxiv.org/pdf/2506.23667", "abs": "https://arxiv.org/abs/2506.23667", "authors": ["Junjie Zhang", "Jingyi Xi", "Zhuoyang Song", "Junyu Lu", "Yuhua Ke", "Ting Sun", "Yukun Yang", "Jiaxing Zhang", "Songxin Zhang", "Zejian Xie"], "title": "L0: Reinforcement Learning to Become General Agents", "categories": ["cs.CL"], "comment": null, "summary": "Training large language models (LLMs) to act as autonomous agents for\nmulti-turn, long-horizon tasks remains significant challenges in scalability\nand training efficiency. To address this, we introduce L-Zero (L0), a scalable,\nend-to-end training pipeline for general-purpose agents. Featuring a low-cost,\nextensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier\nfor applying reinforcement learning in complex environments. We also introduce\nNB-Agent, the agent scaffold within L0, which operates in a \"code-as-action\"\nfashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality\nquestion-answering benchmarks. Our experiments demonstrate that a base model\ncan develop robust problem-solving skills using solely Reinforcement Learning\nwith Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method\nboosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41\n%. We have open-sourced the entire L0 system, including our L0 series models,\nthe NB-Agent, a complete training pipeline, and the corresponding training\nrecipes on (https://github.com/cmriat/l0).", "AI": {"tldr": "L-Zero (L0) is a scalable framework enabling large language models to function as agents for complex tasks, greatly improving performance using reinforcement learning.", "motivation": "To address scalability and efficiency issues when training large language models for multi-turn, long-horizon tasks.", "method": "Developed L-Zero (L0), featuring a scalable worker pool, NB-Agent scaffold operating in 'code-as-action' with REPL, and reinforcement learning using verifiable rewards.", "result": "Boosted task accuracy for Qwen2.5-7B-Instruct model significantly, achieving gains from 30% to 80% on SimpleQA and 22% to 41% on HotpotQA.", "conclusion": "L-Zero facilitates scalable training of general-purpose agents, improving efficiency and effectiveness; open-source models and pipeline offered for broader adoption."}}
{"id": "2506.22487", "pdf": "https://arxiv.org/pdf/2506.22487", "abs": "https://arxiv.org/abs/2506.22487", "authors": ["Amar Khelloufi", "Huansheng Ning", "Sahraoui Dhelim", "Jianguo Ding"], "title": "AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space", "categories": ["cs.NI", "cs.AI"], "comment": "31 pages, 5 figures", "summary": "The integration of the Internet of Everything (IoX) and Artificial General\nIntelligence (AGI) has given rise to a transformative paradigm aimed at\naddressing critical bottlenecks across sensing, network, and application layers\nin Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide\na systematic and comprehensive review of AGI-enhanced IoX research, focusing on\nthree key components: sensing-layer data management, network-layer protocol\noptimization, and application-layer decision-making frameworks. Specifically,\nthis survey explores how AGI can mitigate IoX bottlenecks challenges by\nleveraging adaptive sensor fusion, edge preprocessing, and selective attention\nmechanisms at the sensing layer, while resolving network-layer issues such as\nprotocol heterogeneity and dynamic spectrum management, neuro-symbolic\nreasoning, active inference, and causal reasoning, Furthermore, the survey\nexamines AGI-enabled frameworks for managing identity and relationship\nexplosion. Key findings suggest that AGI-driven strategies, such as adaptive\nsensor fusion, edge preprocessing, and semantic modeling, offer novel solutions\nto sensing-layer data overload, network-layer protocol heterogeneity, and\napplication-layer identity explosion. The survey underscores the importance of\ncross-layer integration, quantum-enabled communication, and ethical governance\nframeworks for future AGI-enabled IoX systems. Finally, the survey identifies\nunresolved challenges, such as computational requirements, scalability, and\nreal-world validation, calling for further research to fully realize AGI's\npotential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is\nemerging as a critical research field at the intersection of interconnected\nsystems and advanced AI.", "AI": {"tldr": "The paper surveys how Artificial General Intelligence (AGI) can address critical challenges in the Internet of Everything (IoX) through advancements across sensing, network, and application layers.", "motivation": "The paper aims to address bottlenecks in Cyber-Physical-Social Thinking ecosystems by integrating IoX with AGI for improved data management, network protocols, and decision-making frameworks.", "method": "Systematic review of AGI-enhanced IoX research, focusing on adaptive sensor fusion at the sensing layer, protocol optimization at the network layer, and decision-making frameworks at the application layer.", "result": "Key findings highlight AGI strategies such as adaptive sensor fusion and semantic modeling that mitigate sensing-layer data overload, network protocol heterogeneity, and application-layer identity explosion.", "conclusion": "AGI can significantly enhance IoX performance, with future research needed in computation scalability, ethical governance, and system validation."}}
{"id": "2506.23287", "pdf": "https://arxiv.org/pdf/2506.23287", "abs": "https://arxiv.org/abs/2506.23287", "authors": ["Zelin Zang", "WenZhe Li", "Fei Chen", "Yongjie Xu", "Chang Yu", "Zhen Lei", "Stan Z. Li"], "title": "Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis", "categories": ["cs.LG", "q-bio.QM"], "comment": "9 pages, 6 figures, under review", "summary": "In single-cell research, tracing and analyzing high-throughput single-cell\ndifferentiation trajectories is crucial for understanding complex biological\nprocesses. Key to this is the modeling and generation of hierarchical data that\nrepresents the intrinsic structure within datasets. Traditional methods face\nlimitations in terms of computational cost, performance, generative capacity,\nand stability. Recent VAEs based approaches have made strides in addressing\nthese challenges but still require specialized network modules for each tree\nbranch, limiting their stability and ability to capture deep hierarchical\nrelationships. To overcome these challenges, we introduce diffusion-based\napproach called HDTree. HDTree captures tree relationships within a\nhierarchical latent space using a unified hierarchical codebook and quantized\ndiffusion processes to model tree node transitions. This method improves\nstability by eliminating branch-specific modules and enhancing generative\ncapacity through gradual hierarchical changes simulated by the diffusion\nprocess. HDTree's effectiveness is demonstrated through comparisons on both\ngeneral-purpose and single-cell datasets, where it outperforms existing methods\nin terms of accuracy and performance. These contributions provide a new tool\nfor hierarchical lineage analysis, enabling more accurate and efficient\nmodeling of cellular differentiation paths and offering insights for downstream\nbiological tasks. The code of HDTree is available at anonymous link\nhttps://anonymous.4open.science/r/code_HDTree_review-A8DB.", "AI": {"tldr": "The paper introduces HDTree, a diffusion-based method for modeling hierarchical relationships in single-cell data using a unified hierarchical codebook.", "motivation": "Current methods for analyzing high-throughput single-cell differentiation trajectories are limited by computational costs, performance issues, and an inability to capture deep hierarchical relationships.", "method": "The approach employs a diffusion-based framework with a hierarchical latent space and eliminates the need for specialized tree branch modules by using a unified hierarchical codebook and quantized diffusion processes.", "result": "HDTree outperforms existing methods in terms of accuracy and performance when tested on both general-purpose and single-cell datasets.", "conclusion": "HDTree offers a more stable and generative method for hierarchical lineage analysis, facilitating accurate modeling of cellular differentiation paths and aiding downstream biological research."}}
{"id": "2506.22960", "pdf": "https://arxiv.org/pdf/2506.22960", "abs": "https://arxiv.org/abs/2506.22960", "authors": ["Shreyas Dixit", "Ashhar Aziz", "Shashwat Bajpai", "Vasu Sharma", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images", "categories": ["cs.CV"], "comment": null, "summary": "A report by the European Union Law Enforcement Agency predicts that by 2026,\nup to 90 percent of online content could be synthetically generated, raising\nconcerns among policymakers, who cautioned that \"Generative AI could act as a\nforce multiplier for political disinformation. The combined effect of\ngenerative text, images, videos, and audio may surpass the influence of any\nsingle modality.\" In response, California's Bill AB 3211 mandates the\nwatermarking of AI-generated images, videos, and audio. However, concerns\nremain regarding the vulnerability of invisible watermarking techniques to\ntampering and the potential for malicious actors to bypass them entirely.\nGenerative AI-powered de-watermarking attacks, especially the newly introduced\nvisual paraphrase attack, have shown an ability to fully remove watermarks,\nresulting in a paraphrase of the original image. This paper introduces PECCAVI,\nthe first visual paraphrase attack-safe and distortion-free image watermarking\ntechnique. In visual paraphrase attacks, an image is altered while preserving\nits core semantic regions, termed Non-Melting Points (NMPs). PECCAVI\nstrategically embeds watermarks within these NMPs and employs multi-channel\nfrequency domain watermarking. It also incorporates noisy burnishing to counter\nreverse-engineering efforts aimed at locating NMPs to disrupt the embedded\nwatermark, thereby enhancing durability. PECCAVI is model-agnostic. All\nrelevant resources and codes will be open-sourced.", "AI": {"tldr": "The paper introduces PECCAVI, a watermarking method resistant to generative AI attacks that remove watermarks, particularly visual paraphrase attacks.", "motivation": "The rapid increase in AI-generated content poses risks of political disinformation and necessitates robust watermarks to counter malicious manipulation, such as de-watermarking attacks.", "method": "PECCAVI embeds watermarks in Non-Melting Points (NMPs) of images using multi-channel frequency domain techniques and applies noisy burnishing to resist reverse-engineering attempts.", "result": "PECCAVI proves to be a distortion-free and robust watermarking solution that is resistant to generative AI de-watermarking attacks and is model-agnostic.", "conclusion": "PECCAVI provides a secure and effective solution to the vulnerabilities of current watermarking techniques against sophisticated AI attacks, with all resources made publicly available."}}
{"id": "2506.23735", "pdf": "https://arxiv.org/pdf/2506.23735", "abs": "https://arxiv.org/abs/2506.23735", "authors": ["JiaRu Wu", "Mingwei Liu"], "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable performance on various\ntasks, but existing evaluation benchmarks are often static and insufficient to\nfully assess their robustness and generalization in realistic scenarios. Prior\nwork using evolutionary or adversarial data augmentation has improved\nevaluation diversity but lacks systematic control over perturbation types and\nmulti-step complexity, limiting comprehensive robustness analysis. To address\nthese gaps, we propose AutoEvoEval, an evolution-based evaluation framework for\nclose-ended tasks such as multi-choice question answering. AutoEvoEval\nintroduces 22 interpretable atomic evolution operations and supports\nmulti-round compositions, enabling controlled generation of diverse,\nchallenging, and realistic test samples. We conduct extensive experiments\naddressing four research questions on a broad set of open- and closed-source\nLLMs. Our results show that atomic operations cause an average accuracy drop of\n7.283\\%, with structure-disrupting or misleading semantic edits causing the\nlargest declines. Model sensitivities vary significantly for the same\nperturbation, and combining multiple evolution steps amplifies adversarial\neffects by up to 52.932\\%. These findings suggest current benchmarks may\noverestimate true model generalization and emphasize the need for\nevolution-aware robustness evaluation. Code and resources are available at:\nhttps://github.com/SYSUSELab/AutoEvoEval.", "AI": {"tldr": "This paper introduces AutoEvoEval, an advanced evaluation framework utilizing interpretable evolution operations to generate more realistic and challenging test samples for benchmarking language models.", "motivation": "Existing evaluation benchmarks for language models are static and insufficient for assessing robustness and generalization in realistic scenarios. Current augmentation methods lack systematic control over perturbation complexities affecting comprehensive robustness analyses.", "method": "The authors propose AutoEvoEval, incorporating 22 atomic evolution operations with multi-round compositions to generate controlled, diverse, and challenging test samples for assessing performance on close-ended tasks like multi-choice questions.", "result": "Experiments reveal a significant average accuracy drop (7.283%) due to atomic operations. Multi-step evolution amplifies adversarial impacts by up to 52.932%, highlighting that current benchmarks may overestimate model generalization.", "conclusion": "AutoEvoEval demonstrates the necessity of evolution-aware approaches in robustness evaluations, offering insights into model sensitivities and weaknesses through systematic test diversification."}}
{"id": "2506.23339", "pdf": "https://arxiv.org/pdf/2506.23339", "abs": "https://arxiv.org/abs/2506.23339", "authors": ["Malikussaid", "Hilal Hudan Nuha"], "title": "VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.QM"], "comment": "16 pages, 1 figure, 5 algorithms, 7 tables, to be published in ICSECS\n  Conference 2025, unabridged version", "summary": "Large Language Models (LLMs) demonstrate remarkable potential for scientific\ndiscovery, but their application in domains requiring factual accuracy and\ndomain-specific constraints remains challenging. In molecular design for drug\ndiscovery, LLMs can suggest creative molecular modifications but often produce\nchemically invalid or impractical structures. We present VALID-Mol, a\nsystematic framework for integrating chemical validation with LLM-driven\nmolecular design that increases the rate of generating valid chemical\nstructures from 3% to 83%. Our approach combines methodical prompt engineering,\nautomated chemical validation, and a fine-tuned domain-adapted LLM to ensure\nreliable generation of synthesizable molecules with improved properties. Beyond\nthe specific implementation, we contribute a generalizable methodology for\nscientifically-constrained LLM applications, with quantifiable reliability\nimprovements. Computational predictions suggest our framework can generate\npromising candidates for synthesis with up to 17-fold computationally predicted\nimprovements in target affinity while maintaining synthetic accessibility. We\nprovide a detailed analysis of our prompt engineering process, validation\narchitecture, and fine-tuning approach, offering a reproducible blueprint for\napplying LLMs to other scientific domains where domain-specific validation is\nessential.", "AI": {"tldr": "VALID-Mol is a framework that enhances the chemical validity of molecules designed by LLMs, increasing valid outputs from 3% to 83%.", "motivation": "To address the challenges of applying Large Language Models (LLMs) to molecular design in drug discovery, particularly due to the chemically invalid or impractical molecules they often generate without domain-specific constraints.", "method": "VALID-Mol integrates methodical prompt engineering, automated chemical validation, and a fine-tuned domain-adapted LLM to generate synthesizable molecules with improved properties.", "result": "The framework increases the generation of valid chemical structures from 3% to 83%, with predictions indicating up to 17-fold improvement in target affinity while maintaining synthetic accessibility.", "conclusion": "VALID-Mol offers a reproducible and generalizable methodology for scientifically-constrained applications of LLMs, enabling reliable molecular design with quantifiable performance improvements."}}
{"id": "2506.22967", "pdf": "https://arxiv.org/pdf/2506.22967", "abs": "https://arxiv.org/abs/2506.22967", "authors": ["Amir Aghdam", "Vincent Tao Hu"], "title": "ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment", "categories": ["cs.CV", "cs.LG", "cs.MM", "I.2.10; I.2.7"], "comment": "Preprint manuscript - Project page:\n  https://github.com/aghdamamir/act-align", "summary": "We address the task of zero-shot fine-grained video classification, where no\nvideo examples or temporal annotations are available for unseen action classes.\nWhile contrastive vision-language models such as SigLIP demonstrate strong\nopen-set recognition via mean-pooled image-text similarity, they fail to\ncapture the temporal structure critical for distinguishing fine-grained\nactivities. We introduce ActAlign, a zero-shot framework that formulates video\nclassification as sequence alignment. For each class, a large language model\ngenerates an ordered sub-action sequence, which is aligned with video frames\nusing Dynamic Time Warping (DTW) in a shared embedding space. Without any\nvideo-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the\nextremely challenging ActionAtlas benchmark, where human accuracy is only\n61.6%. ActAlign outperforms billion-parameter video-language models while using\napproximately 8x less parameters. These results demonstrate that structured\nlanguage priors, combined with classical alignment techniques, offer a scalable\nand general approach to unlocking the open-set recognition potential of\nvision-language models for fine-grained video understanding.", "AI": {"tldr": "The paper introduces ActAlign, a framework for zero-shot fine-grained video classification using sequence alignment techniques, achieving significant accuracy without fine-tuning.", "motivation": "Current contrastive vision-language models fail to leverage temporal structures necessary for fine-grained video action classification in zero-shot settings.", "method": "The method uses large language models to generate ordered sub-action sequences for each class and aligns them with video frames via Dynamic Time Warping in a shared embedding space.", "result": "ActAlign achieves 30.5% accuracy on the challenging ActionAtlas benchmark, exceeding models with much larger parameters while requiring no video-text supervision.", "conclusion": "Structured language priors combined with classical alignment methods can improve vision-language models' potential for zero-shot fine-grained video understanding."}}
{"id": "2506.23743", "pdf": "https://arxiv.org/pdf/2506.23743", "abs": "https://arxiv.org/abs/2506.23743", "authors": ["Tiziano Labruna", "Simone Gallo", "Giovanni Da San Martino"], "title": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences", "categories": ["cs.CL"], "comment": null, "summary": "Positional bias in binary question answering occurs when a model\nsystematically favors one choice over another based solely on the ordering of\npresented options. In this study, we quantify and analyze positional bias\nacross five large language models under varying degrees of answer uncertainty.\nWe re-adapted the SQuAD-it dataset by adding an extra incorrect answer option\nand then created multiple versions with progressively less context and more\nout-of-context answers, yielding datasets that range from low to high\nuncertainty. Additionally, we evaluate two naturally higher-uncertainty\nbenchmarks: (1) WebGPT - question pairs with unequal human-assigned quality\nscores, and (2) Winning Arguments - where models predict the more persuasive\nargument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order\nof the \"correct\" (or higher-quality/persuasive) option is systematically\nflipped (first placed in position 1, then in position 2) to compute both\nPreference Fairness and Position Consistency. We observe that positional bias\nis nearly absent under low-uncertainty conditions, but grows exponentially when\nit becomes doubtful to decide which option is correct.", "AI": {"tldr": "The study examines positional bias in language models when one option is systematically preferred due to its position in binary question answering, especially under uncertain conditions.", "motivation": "To understand and quantify how positional bias impacts decision-making in large language models, especially in scenarios with varying levels of answer uncertainty.", "method": "Researchers re-adapted the SQuAD-it dataset with additional answer options and manipulated context to induce varying levels of uncertainty. Positional bias was analyzed using datasets with flipped answer orders and two high-uncertainty benchmarks: WebGPT and Winning Arguments.", "result": "Positional bias was found to be nearly nonexistent in low-uncertainty scenarios but increased exponentially under high-uncertainty conditions.", "conclusion": "Positional bias in large language models is significantly influenced by the level of uncertainty in the provided options, highlighting an area for improving fairness in model outputs."}}
{"id": "2506.22492", "pdf": "https://arxiv.org/pdf/2506.22492", "abs": "https://arxiv.org/abs/2506.22492", "authors": ["Rajeev Alur", "Greg Durrett", "Hadas Kress-Gazit", "Corina P\u0103s\u0103reanu", "Ren\u00e9 Vidal"], "title": "Report on NSF Workshop on Science of Safe AI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Recent advances in machine learning, particularly the emergence of foundation\nmodels, are leading to new opportunities to develop technology-based solutions\nto societal problems. However, the reasoning and inner workings of today's\ncomplex AI models are not transparent to the user, and there are no safety\nguarantees regarding their predictions. Consequently, to fulfill the promise of\nAI, we must address the following scientific challenge: how to develop AI-based\nsystems that are not only accurate and performant but also safe and\ntrustworthy?\n  The criticality of safe operation is particularly evident for autonomous\nsystems for control and robotics, and was the catalyst for the Safe Learning\nEnabled Systems (SLES) program at NSF. For the broader class of AI\napplications, such as users interacting with chatbots and clinicians receiving\ntreatment recommendations, safety is, while no less important, less\nwell-defined with context-dependent interpretations. This motivated the\norganization of a day-long workshop, held at University of Pennsylvania on\nFebruary 26, 2025, to bring together investigators funded by the NSF SLES\nprogram with a broader pool of researchers studying AI safety. This report is\nthe result of the discussions in the working groups that addressed different\naspects of safety at the workshop. The report articulates a new research agenda\nfocused on developing theory, methods, and tools that will provide the\nfoundations of the next generation of AI-enabled systems.", "AI": {"tldr": "A workshop report discussing AI safety challenges and proposing a research agenda for safe, trustworthy AI systems.", "motivation": "To address challenges in AI safety and trustworthiness, especially in complex machine learning models, and to develop safer AI systems.", "method": "Conducting a workshop involving NSF-funded and other researchers to discuss AI safety and propose relevant research methods, tools, and theories.", "result": "A new research agenda was formulated with a focus on creating theoretical foundations, methodologies, and tools for safe AI systems.", "conclusion": "Advancing AI safety is essential for trustworthy AI systems, and collaborative efforts are key to achieving this objective."}}
{"id": "2506.23349", "pdf": "https://arxiv.org/pdf/2506.23349", "abs": "https://arxiv.org/abs/2506.23349", "authors": ["Keziah Naggita", "Julienne LaChance"], "title": "A case for data valuation transparency via DValCards", "categories": ["cs.LG"], "comment": null, "summary": "Following the rise in popularity of data-centric machine learning (ML),\nvarious data valuation methods have been proposed to quantify the contribution\nof each datapoint to desired ML model performance metrics (e.g., accuracy).\nBeyond the technical applications of data valuation methods (e.g., data\ncleaning, data acquisition, etc.), it has been suggested that within the\ncontext of data markets, data buyers might utilize such methods to fairly\ncompensate data owners. Here we demonstrate that data valuation metrics are\ninherently biased and unstable under simple algorithmic design choices,\nresulting in both technical and ethical implications. By analyzing 9 tabular\nclassification datasets and 6 data valuation methods, we illustrate how (1)\ncommon and inexpensive data pre-processing techniques can drastically alter\nestimated data values; (2) subsampling via data valuation metrics may increase\nclass imbalance; and (3) data valuation metrics may undervalue underrepresented\ngroup data. Consequently, we argue in favor of increased transparency\nassociated with data valuation in-the-wild and introduce the novel Data\nValuation Cards (DValCards) framework towards this aim. The proliferation of\nDValCards will reduce misuse of data valuation metrics, including in data\npricing, and build trust in responsible ML systems.", "AI": {"tldr": "Data valuation methods for machine learning are biased and unstable, leading to technical and ethical issues, solved by the proposed Data Valuation Cards (DValCards) framework.", "motivation": "Data valuation methods have been suggested as tools to not only improve ML model performance but also fairly compensate data owners in data markets, warranting closer examination of their reliability.", "method": "The authors analyzed 9 tabular classification datasets and 6 data valuation methods to investigate the effects of data pre-processing, subsampling, and group representation on data valuation metrics. They introduce the Data Valuation Cards (DValCards) framework as a transparency tool.", "result": "It was shown that pre-processing can significantly alter data values, subsampling increases class imbalance, and underrepresented groups' data are often undervalued by current metrics.", "conclusion": "Data valuation metrics need greater transparency to mitigate their misuse and biases. The introduction of DValCards can promote ethical and trustworthy applications of these metrics."}}
{"id": "2506.22979", "pdf": "https://arxiv.org/pdf/2506.22979", "abs": "https://arxiv.org/abs/2506.22979", "authors": ["Jie Liu", "Jiayi Shen", "Pan Zhou", "Jan-Jakob Sonke", "Efstratios Gavves"], "title": "Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation", "categories": ["cs.CV"], "comment": "ICCV2025 Proceeding", "summary": "Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a\nsegmentation model to novel classes with only a few annotated examples while\nmaintaining performance on base classes. Recently, pretrained vision-language\nmodels (VLMs) such as CLIP have been leveraged in GFSS to improve\ngeneralization on novel classes through multi-modal prototypes learning.\nHowever, existing prototype-based methods are inherently deterministic,\nlimiting the adaptability of learned prototypes to diverse samples,\nparticularly for novel classes with scarce annotations. To address this, we\npropose FewCLIP, a probabilistic prototype calibration framework over\nmulti-modal prototypes from the pretrained CLIP, thus providing more adaptive\nprototype learning for GFSS. Specifically, FewCLIP first introduces a prototype\ncalibration mechanism, which refines frozen textual prototypes with learnable\nvisual calibration prototypes, leading to a more discriminative and adaptive\nrepresentation. Furthermore, unlike deterministic prototype learning\ntechniques, FewCLIP introduces distribution regularization over these\ncalibration prototypes. This probabilistic formulation ensures structured and\nuncertainty-aware prototype learning, effectively mitigating overfitting to\nlimited novel class data while enhancing generalization. Extensive experimental\nresults on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed\nFewCLIP significantly outperforms state-of-the-art approaches across both GFSS\nand class-incremental setting. The code is available at\nhttps://github.com/jliu4ai/FewCLIP.", "AI": {"tldr": "FewCLIP proposes a probabilistic prototype calibration framework to enhance performance in Generalized Few-Shot Semantic Segmentation (GFSS) by refining multi-modal prototypes from CLIP for better adaptability and generalization.", "motivation": "Current GFSS methods using pretrained vision-language models like CLIP face challenges with deterministic prototype learning, which limits adaptability and leads to overfitting on limited novel class data.", "method": "FewCLIP introduces a prototype calibration mechanism that refines textual prototypes with learnable visual calibration prototypes. A probabilistic distribution regularization is applied to these calibrated prototypes for uncertainty-aware and structured learning, improving adaptability in low-data scenarios.", "result": "FewCLIP outperforms state-of-the-art methods on the PASCAL-5$^i$ and COCO-20$^i$ datasets in both GFSS and class-incremental settings, demonstrating its effectiveness.", "conclusion": "FewCLIP effectively mitigates the limitations of deterministic prototype learning in GFSS by employing probabilistic calibration over CLIP\u2019s multi-modal prototypes, resulting in superior generalization and adaptability on novel and base classes."}}
{"id": "2506.23840", "pdf": "https://arxiv.org/pdf/2506.23840", "abs": "https://arxiv.org/abs/2506.23840", "authors": ["Bowen Ding", "Yuhan Chen", "Futing Wang", "Lingfeng Ming", "Tao Lin"], "title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Large Reasoning Models (LRMs) excel at solving complex problems but face an\noverthinking dilemma. When handling simple tasks, they often produce verbose\nresponses overloaded with thinking tokens (e.g., wait, however). These tokens\ntrigger unnecessary high-level reasoning behaviors like reflection and\nbacktracking, reducing efficiency. In this work, our pilot study reveals that\nthese thinking-token-induced behaviors are not essential for effective\nproblem-solving and may even hinder correct reasoning within constrained token\nbudgets. We identify this phenomenon as the thinking trap. To mitigate this\nissue, we propose Dual Policy Preference Optimization (DuP-PO), a novel\nalgorithm featuring: (1) A rollout sampling strategy that guarantees balanced\nexposure to responses with and without thinking tokens; (2) A fine-grained\nadvantage control technique to dynamically regulate the prediction of target\ntokens; (3) A policy shaping method ensuring stable gradient contributions from\nthinking tokens. Experimental results on five popular math reasoning benchmarks\nshow that DuP-PO performs well on the popular LRM, which significantly improves\ntheir token efficiency during reasoning, while achieving superior performance\nof the base model.", "AI": {"tldr": "Large Reasoning Models (LRMs) struggle with inefficient verbose responses laden with unnecessary 'thinking tokens' during simple tasks, impairing effectiveness. A novel approach, Dual Policy Preference Optimization (DuP-PO), addresses this by regulating and optimizing token prediction.", "motivation": "The study aims to address the inefficiencies in LRMs caused by overthinking behaviors triggered by thinking tokens, which hinder performance especially in constrained token budgets.", "method": "The study introduces DuP-PO, which utilizes (1) rollout sampling for balanced response exposure, (2) fine-grained advantage control for dynamic token prediction regulation, and (3) policy shaping to stabilize gradient contributions.", "result": "Experiments on five math reasoning benchmarks demonstrated DuP-PO's improvements in token efficiency and superior base model reasoning performance.", "conclusion": "DuP-PO effectively mitigates the thinking trap in LRMs, enhancing reasoning efficiency and accuracy, particularly in scenarios with constrained token limits."}}
{"id": "2506.22495", "pdf": "https://arxiv.org/pdf/2506.22495", "abs": "https://arxiv.org/abs/2506.22495", "authors": ["He-Yang Xu", "Hongxiang Gao", "Yuwen Li", "Xiu-Shen Wei", "Chengyu Liu"], "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic\ncharacteristics, ranging from rhythm fluctuations to subtle waveform\ndeformations that evolve across time and frequency domains. However, supervised\nECG models tend to overfit dominant and repetitive patterns, overlooking\nfine-grained but clinically critical cues, a phenomenon known as Simplicity\nBias (SB), where models favor easily learnable signals over subtle but\ninformative ones. In this work, we first empirically demonstrate the presence\nof SB in ECG analyses and its negative impact on diagnostic performance, while\nsimultaneously discovering that self-supervised learning (SSL) can alleviate\nit, providing a promising direction for tackling the bias. Following the SSL\nparadigm, we propose a novel method comprising two key components: 1)\nTemporal-Frequency aware Filters to capture temporal-frequency features\nreflecting the dynamic characteristics of ECG signals, and 2) building on this,\nMulti-Grained Prototype Reconstruction for coarse and fine representation\nlearning across dual domains, further mitigating SB. To advance SSL in ECG\nanalyses, we curate a large-scale multi-site ECG dataset with 1.53 million\nrecordings from over 300 clinical centers. Experiments on three downstream\ntasks across six ECG datasets demonstrate that our method effectively reduces\nSB and achieves state-of-the-art performance. Code and dataset will be released\npublicly.", "AI": {"tldr": "The paper investigates Simplicity Bias (SB) in supervised ECG models, proposes a self-supervised learning method to mitigate SB, and demonstrates its efficacy with state-of-the-art results.", "motivation": "ECG models often overfit to dominant patterns and miss subtle but critical diagnostic cues due to Simplicity Bias, which negatively impacts clinical performance.", "method": "A self-supervised learning (SSL) framework using Temporal-Frequency Aware Filters for dynamic feature capture and Multi-Grained Prototype Reconstruction for detailed representation learning.", "result": "The proposed method achieved state-of-the-art performance by reducing Simplicity Bias across three downstream tasks and six datasets with improved diagnostic accuracy.", "conclusion": "Self-supervised learning is a promising approach for overcoming Simplicity Bias in ECG analysis, offering improved diagnostic capabilities and advancing ECG-based research with curated datasets."}}
{"id": "2506.23358", "pdf": "https://arxiv.org/pdf/2506.23358", "abs": "https://arxiv.org/abs/2506.23358", "authors": ["Pawel Renc", "Michal K. Grzeszczyk", "Linglong Qian", "Nassim Oufattole", "Jeff Rasley", "Arkadiusz Sitek"], "title": "Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment", "categories": ["cs.LG", "cs.AI"], "comment": "conference paper", "summary": "We present Federated Timeline Synthesis (FTS), a novel framework for training\ngenerative foundation models across distributed timeseries data applied to\nelectronic health records (EHR). At its core, FTS represents patient history as\ntokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding\ntemporal, categorical, and continuous clinical information. Each institution\ntrains an autoregressive transformer on its local PHTs and transmits only model\nweights to a central server. The server uses the generators to synthesize a\nlarge corpus of trajectories and train a Global Generator (GG), enabling\nzero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS\non five clinically meaningful prediction tasks using MIMIC-IV data, showing\nthat models trained on synthetic data generated by GG perform comparably to\nthose trained on real data. FTS offers strong privacy guarantees, scalability\nacross institutions, and extensibility to diverse prediction and simulation\ntasks especially in healthcare, including counterfactual inference, early\nwarning detection, and synthetic trial design.", "AI": {"tldr": "The paper introduces Federated Timeline Synthesis (FTS), a framework for federatively training generative models on distributed electronic health records data while ensuring privacy.", "motivation": "To address the challenge of training AI models on sensitive and distributed electronic health records (EHR) data while ensuring privacy and scalability.", "method": "FTS tokenizes patient history into Patient Health Timelines (PHTs) and uses a federated setup where each institution trains a local model. Model weights are aggregated centrally, and a Global Generator is trained on synthetic patient data generated from local models.", "result": "FTS demonstrates that synthetic models trained using the Global Generator perform comparably to models trained on real data across five clinically significant prediction tasks.", "conclusion": "FTS provides a scalable and privacy-preserving framework for training generative models on distributed healthcare data, with applications in prediction, simulation, and clinical decision-making."}}
{"id": "2506.22982", "pdf": "https://arxiv.org/pdf/2506.22982", "abs": "https://arxiv.org/abs/2506.22982", "authors": ["Atharv Mittal", "Agam Pandey", "Amritanshu Tiwari", "Sukrit Jindal", "Swadesh Swain"], "title": "Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted to MLRC 2025", "summary": "Large Vision-Language Models (VLMs) have revolutionized computer vision,\nenabling tasks such as image classification, captioning, and visual question\nanswering. However, they remain highly vulnerable to adversarial attacks,\nparticularly in scenarios where both visual and textual modalities can be\nmanipulated. In this study, we conduct a comprehensive reproducibility study of\n\"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on\nVision-Language Models\" validating the Cross-Prompt Attack (CroPA) and\nconfirming its superior cross-prompt transferability compared to existing\nbaselines. Beyond replication we propose several key improvements: (1) A novel\ninitialization strategy that significantly improves Attack Success Rate (ASR).\n(2) Investigate cross-image transferability by learning universal\nperturbations. (3) A novel loss function targeting vision encoder attention\nmechanisms to improve generalization. Our evaluation across prominent VLMs --\nincluding Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on\nLLaVA validates the original results and demonstrates that our improvements\nconsistently boost adversarial effectiveness. Our work reinforces the\nimportance of studying adversarial vulnerabilities in VLMs and provides a more\nrobust framework for generating transferable adversarial examples, with\nsignificant implications for understanding the security of VLMs in real-world\napplications.", "AI": {"tldr": "The paper focuses on adversarial vulnerabilities in vision-language models (VLMs) and introduces improvements to enhance the effectiveness and generalizability of adversarial attacks.", "motivation": "Vision-language models are revolutionizing computer vision tasks but remain highly susceptible to adversarial attacks. The study seeks to validate and improve upon existing attack methods to better understand these vulnerabilities.", "method": "The study replicates and validates the Cross-Prompt Attack (CroPA), introduces a new initialization strategy, explores cross-image transferability using universal perturbations, and proposes a novel loss function for improving adversarial generalization.", "result": "The proposed methods enhance the attack success rate and generalizability, outperforming existing baselines on popular VLMs such as Flamingo, BLIP-2, and InstructBLIP.", "conclusion": "The paper highlights the critical need to address adversarial weaknesses in VLMs, offering a more robust framework for understanding and mitigating their security challenges in practice."}}
{"id": "2506.23864", "pdf": "https://arxiv.org/pdf/2506.23864", "abs": "https://arxiv.org/abs/2506.23864", "authors": ["Seyed Mahed Mousavi", "Edoardo Cecchinato", "Lucia Hornikova", "Giuseppe Riccardi"], "title": "Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It", "categories": ["cs.CL"], "comment": null, "summary": "We conduct a systematic audit of three widely used reasoning benchmarks,\nSocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark\nitems and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and\nLLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic\nissues in benchmark design (e.g., duplicated items, ambiguous wording, and\nimplausible answers), as well as scoring procedures that prioritize output form\nover reasoning process. Through systematic human annotation and re-evaluation\non cleaned benchmark subsets, we find that model scores often improve not due\nto due to erratic surface wording variations and not to improved reasoning.\nInfact, further analyses show that model performance is highly sensitive to\nminor input variations such as context availability and phrasing, revealing\nthat high scores may reflect alignment with format-specific cues rather than\nconsistent inference based on the input. These findings challenge the validity\nof current benchmark-based claims about reasoning in LLMs, and highlight the\nneed for evaluation protocols that assess reasoning as a process of drawing\ninference from available information, rather than as static output selection.\nWe release audited data and evaluation tools to support more interpretable and\ndiagnostic assessments of model reasoning.", "AI": {"tldr": "The paper reviews three reasoning benchmarks and finds significant flaws in both benchmark design and evaluation methods. It challenges existing approaches and offers tools for more interpretable assessments.", "motivation": "To scrutinize the validity of reasoning benchmarks by identifying structural and procedural flaws that might misrepresent model capabilities.", "method": "Systematic auditing of SocialIQa, FauxPas-EAI, and ToMi benchmarks using five LLMs as diagnostic tools, coupled with human annotation and re-evaluation on improved benchmark subsets.", "result": "Revealed structural and evaluation issues leading to inconsistent and format-dependent model performance, questioning the effectiveness of existing benchmarks.", "conclusion": "Current reasoning benchmarks inadequately assess reasoning processes, and better evaluation protocols are needed to accurately measure inference capabilities."}}
{"id": "2506.22496", "pdf": "https://arxiv.org/pdf/2506.22496", "abs": "https://arxiv.org/abs/2506.22496", "authors": ["Y. Du"], "title": "Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "7 pages", "summary": "Large Language Models (LLMs) exhibit systematic risk-taking behaviors\nanalogous to those observed in gambling psychology, including overconfidence\nbias, loss-chasing tendencies, and probability misjudgment. Drawing from\nbehavioral economics and prospect theory, we identify and formalize these\n\"gambling-like\" patterns where models sacrifice accuracy for high-reward\noutputs, exhibit escalating risk-taking after errors, and systematically\nmiscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG)\nframework, incorporating insights from gambling research to address these\nbehavioral biases through risk-calibrated training, loss-aversion mechanisms,\nand uncertainty-aware decision making. Our approach introduces novel evaluation\nparadigms based on established gambling psychology experiments, including AI\nadaptations of the Iowa Gambling Task and probability learning assessments.\nExperimental results demonstrate measurable reductions in gambling-like\nbehaviors: 18.7\\% decrease in overconfidence bias, 24.3\\% reduction in\nloss-chasing tendencies, and improved risk calibration across diverse\nscenarios. This work establishes the first systematic framework for\nunderstanding and mitigating gambling psychology patterns in AI systems.", "AI": {"tldr": "The paper identifies gambling-like risk-taking behaviors in large language models (LLMs) and proposes a framework to mitigate these issues by leveraging behavioral economics and prospect theory.", "motivation": "To address systematic risk behaviors in LLMs such as overconfidence, loss-chasing, and misjudgment of probabilities, which can compromise performance and reliability.", "method": "The paper introduces the Risk-Aware Response Generation (RARG) framework, which incorporates risk-calibrated training, loss-aversion mechanisms, and uncertainty-aware decision-making inspired by gambling psychology research.", "result": "Experimental results show an 18.7% reduction in overconfidence bias, a 24.3% reduction in loss-chasing tendencies, and improved risk calibration.", "conclusion": "This study establishes a novel framework for understanding and reducing gambling-like behaviors in AI, enhancing their decision-making reliability."}}
{"id": "2506.23374", "pdf": "https://arxiv.org/pdf/2506.23374", "abs": "https://arxiv.org/abs/2506.23374", "authors": ["Dominik Meier", "Sujai Hiremath", "Promit Ghosal", "Kyra Gan"], "title": "When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Distinguishing cause and effect from bivariate observational data is a\nfoundational problem in many disciplines, but challenging without additional\nassumptions. Additive noise models (ANMs) are widely used to enable\nsample-efficient bivariate causal discovery. However, conventional ANM-based\nmethods fail when unobserved mediators corrupt the causal relationship between\nvariables. This paper makes three key contributions: first, we rigorously\ncharacterize why standard ANM approaches break down in the presence of\nunmeasured mediators. Second, we demonstrate that prior solutions for hidden\nmediation are brittle in finite sample settings, limiting their practical\nutility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)\nfor causal discovery, a method designed to handle latent noise introduced by\nunmeasured mediators. Unlike prior methods that infer directionality through\nmean squared error loss comparisons, our approach introduces a novel\nindependence test statistic: during the noising and denoising processes for\neach variable, we condition on the other variable as input and evaluate the\nindependence of the predicted noise relative to this input. We prove asymptotic\nconsistency of BiDD under the ANM, and conjecture that it performs well under\nhidden mediation. Experiments on synthetic and real-world data demonstrate\nconsistent performance, outperforming existing methods in mediator-corrupted\nsettings while maintaining strong performance in mediator-free settings.", "AI": {"tldr": "This paper introduces BiDD, a robust causal discovery method for bivariate data that works effectively even under unmeasured mediation, outperforming conventional and prior approaches in synthetic and real-world tests.", "motivation": "Identify causal relationships between bivariate variables in the presence of unmeasured mediators, which hinder traditional additive noise model (ANM) methods.", "method": "Proposed Bivariate Denoising Diffusion (BiDD), utilizing denoising processes and independence tests to handle latent noise introduced by unobserved mediators.", "result": "BiDD demonstrates improved accuracy and robustness under mediator-corrupted data in synthetic and real-world experiments, compared to standard and existing methods.", "conclusion": "BiDD offers a consistent, practical approach for causal discovery in both mediator-corrupted and mediator-free datasets with theoretical backing and empirical validation."}}
{"id": "2506.23004", "pdf": "https://arxiv.org/pdf/2506.23004", "abs": "https://arxiv.org/abs/2506.23004", "authors": ["Vaigai Nayaki Yokar", "Hoa Le-Minh", "Xicong Li", "Wai Lok Woo", "Luis Nero Alves", "Stanislav Zvanovec", "Tran The Son", "Zabih Ghassemlooy"], "title": "A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "This paper proposes a novel, robust, and lightweight supervised Convolutional\nNeural Network (CNN)-based technique for frame identification and\nsynchronization, designed to enhance short-link communication performance in a\nscreen-to-camera (S2C) based visible light communication (VLC) system.\nDeveloped using Python and the TensorFlow Keras framework, the proposed CNN\nmodel was trained through three real-time experimental investigations conducted\nin Jupyter Notebook. These experiments incorporated a dataset created from\nscratch to address various real-time challenges in S2C communication, including\nblurring, cropping, and rotated images in mobility scenarios. Overhead frames\nwere introduced for synchronization, which leads to enhanced system\nperformance. The experimental results demonstrate that the proposed model\nachieves an overall accuracy of approximately 98.74%, highlighting its\neffectiveness in identifying and synchronizing frames in S2C VLC systems.", "AI": {"tldr": "The paper proposes a CNN-based technique for frame identification and synchronization in visible light communication, achieving a high accuracy of ~98.74%.", "motivation": "To address challenges in screen-to-camera communication, such as blurring, cropping, and mobility-induced rotation, by enhancing frame identification and synchronization through visible light communication systems.", "method": "The study utilizes a supervised CNN model trained on a dataset tailored to specific S2C challenges, built with Python and TensorFlow Keras. Real-time experiments conducted in Jupyter Notebook with introduced overhead frames for improved synchronization.", "result": "The CNN model demonstrated high accuracy (~98.74%) in frame identification and synchronization, proving effective in handling S2C-specific challenges.", "conclusion": "The proposed CNN-based technique is robust, accurate, and lightweight, substantially improving frame synchronization and identification for S2C VLC systems."}}
{"id": "2506.23888", "pdf": "https://arxiv.org/pdf/2506.23888", "abs": "https://arxiv.org/abs/2506.23888", "authors": ["Andr\u00e9 de Souza Loureiro", "Jorge Valverde-Rebaza", "Julieta Noguez", "David Escarcega", "Ricardo Marcacini"], "title": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting", "categories": ["cs.CL"], "comment": "Accepted for publication in: European Conference on Machine Learning\n  and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD\n  2025). Research Track", "summary": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved their problem-solving capabilities. However, these models still\nstruggle when faced with complex multi-step reasoning tasks. In this paper, we\npropose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,\na novel approach designed to enhance multi-step mathematical reasoning in LLMs\nby integrating techniques such as Chain of Thought (CoT), Self-Reflection, and\nAuto-Prompting. Unlike traditional static prompting methods, MAPS employs an\niterative refinement process. Initially, the model generates a solution using\nCoT prompting. When errors are detected, an adaptive self-reflection mechanism\nidentifies and analyzes them, generating tailored prompts to guide corrections.\nThese dynamically adjusted prompts enable the model to iteratively refine its\nreasoning. Experiments on four well-established benchmarks across multiple LLMs\nshow that MAPS significantly outperforms standard CoT and achieves competitive\nresults with reasoning-optimized models. In addition, MAPS enables\ngeneral-purpose LLMs to reach performance levels comparable to specialized\nreasoning models. While deeper reflection layers improve accuracy, they also\nincrease token usage and costs. To balance this trade-off, MAPS strategically\nlimits reflection depth, ensuring an optimal balance between cost and reasoning\nperformance.", "AI": {"tldr": "The MAPS framework improves multi-step reasoning in LLMs using iterative self-reflection and adaptive corrections.", "motivation": "LLMs struggle with complex multi-step reasoning tasks, limiting their capabilities.", "method": "MAPS combines techniques like Chain of Thought, Self-Reflection, and Auto-Prompting in an iterative refinement process to detect and rectify errors.", "result": "MAPS outperformed standard approaches in benchmarks, enabling general LLMs to achieve competitive reasoning capabilities.", "conclusion": "MAPS enhances reasoning accuracy while balancing costs, bridging the gap between general-purpose and specialized reasoning models."}}
{"id": "2506.22497", "pdf": "https://arxiv.org/pdf/2506.22497", "abs": "https://arxiv.org/abs/2506.22497", "authors": ["Craig Steven Wright"], "title": "Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship", "categories": ["cs.CY", "cs.AI", "cs.DL", "cs.SI", "physics.hist-ph", "68T99, 03B30, 91D30", "I.2.0; H.3.5; K.4.4"], "comment": "66 pages, 0 figures, interdisciplinary framework, includes proposed\n  architecture and metadata layer structures", "summary": "This paper reconceptualises peer review as structured public commentary.\nTraditional academic validation is hindered by anonymity, latency, and\ngatekeeping. We propose a transparent, identity-linked, and reproducible system\nof scholarly evaluation anchored in open commentary. Leveraging blockchain for\nimmutable audit trails and AI for iterative synthesis, we design a framework\nthat incentivises intellectual contribution, captures epistemic evolution, and\nenables traceable reputational dynamics. This model empowers fields from\ncomputational science to the humanities, reframing academic knowledge as a\nliving process rather than a static credential.", "AI": {"tldr": "The paper proposes reimagining peer review as open, identity-linked public commentary instead of traditional anonymous methods.", "motivation": "To address issues in academic validation like anonymity, delay, and gatekeeping.", "method": "Employs blockchain for transparency and AI for generating iterative evaluations in an open scholarly commentary framework.", "result": "Introduced a system that rewards intellectual contributions, tracks epistemic shifts, and provides clear reputational dynamics.", "conclusion": "The proposed model shifts academic knowledge assessment from being static to dynamic and applicable across various fields."}}
{"id": "2506.23408", "pdf": "https://arxiv.org/pdf/2506.23408", "abs": "https://arxiv.org/abs/2506.23408", "authors": ["Claudionor Coelho Jr", "Yanen Li", "Philip Tee"], "title": "Do LLMs Dream of Discrete Algorithms?", "categories": ["cs.LG", "cs.LO"], "comment": null, "summary": "Large Language Models (LLMs) have rapidly transformed the landscape of\nartificial intelligence, enabling natural language interfaces and dynamic\norchestration of software components. However, their reliance on probabilistic\ninference limits their effectiveness in domains requiring strict logical\nreasoning, discrete decision-making, and robust interpretability. This paper\ninvestigates these limitations and proposes a neurosymbolic approach that\naugments LLMs with logic-based reasoning modules, particularly leveraging\nProlog predicates and composable toolsets. By integrating first-order logic and\nexplicit rule systems, our framework enables LLMs to decompose complex queries\ninto verifiable sub-tasks, orchestrate reliable solutions, and mitigate common\nfailure modes such as hallucination and incorrect step decomposition. We\ndemonstrate the practical benefits of this hybrid architecture through\nexperiments on the DABStep benchmark, showing improved precision, coverage, and\nsystem documentation in multi-step reasoning tasks. Our results indicate that\ncombining LLMs with modular logic reasoning restores engineering rigor,\nenhances system reliability, and offers a scalable path toward trustworthy,\ninterpretable AI agents across complex domains.", "AI": {"tldr": "The paper proposes an approach combining Large Language Models (LLMs) with logic-based reasoning modules to improve their performance in logical reasoning and complex decision-making tasks.", "motivation": "LLMs struggle in domains requiring strict logical reasoning, discrete decisions, and interpretability due to their reliance on probabilistic inference.", "method": "The authors integrate LLMs with logic modules using Prolog predicates and composable tools, enabling decomposition of tasks into verifiable subtasks and mitigating issues such as hallucinations.", "result": "The framework improves precision, coverage, and documentation in reasoning tasks, as demonstrated on the DABStep benchmark.", "conclusion": "Combining LLMs with modular logic components enhances scalability, reliability, interpretability, and engineering rigor in AI systems."}}
{"id": "2506.23009", "pdf": "https://arxiv.org/pdf/2506.23009", "abs": "https://arxiv.org/abs/2506.23009", "authors": ["Jian Chen", "Wenye Ma", "Penghang Liu", "Wei Wang", "Tengwei Song", "Ming Li", "Chenguang Wang", "Ruiyi Zhang", "Changyou Chen"], "title": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable visual\nreasoning abilities in natural images, text-rich documents, and graphic\ndesigns. However, their ability to interpret music sheets remains\nunderexplored. To bridge this gap, we introduce MusiXQA, the first\ncomprehensive dataset for evaluating and advancing MLLMs in music sheet\nunderstanding. MusiXQA features high-quality synthetic music sheets generated\nvia MusiXTeX, with structured annotations covering note pitch and duration,\nchords, clefs, key/time signatures, and text, enabling diverse visual QA tasks.\nThrough extensive evaluations, we reveal significant limitations of current\nstate-of-the-art MLLMs in this domain. Beyond benchmarking, we developed\nPhi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant\nperformance gains over GPT-based methods. The proposed dataset and model\nestablish a foundation for future advances in MLLMs for music sheet\nunderstanding. Code, data, and model will be released upon acceptance.", "AI": {"tldr": "The researchers introduce MusiXQA, a novel dataset and Phi-3-MusiX, a fine-tuned model, to evaluate and improve Multimodal Large Language Models (MLLMs) in music sheet understanding.", "motivation": "To address the gap in MLLM's ability to interpret music sheets, which has been underexplored despite advancements in visual reasoning for other domains.", "method": "The authors created MusiXQA, a synthetic dataset annotated for music sheet features, and fine-tuned an MLLM (Phi-3-MusiX) on this dataset for better performance.", "result": "Phi-3-MusiX demonstrated significant improvements over GPT-based methods when evaluated using the MusiXQA dataset, highlighting the limitations of existing state-of-the-art MLLMs in understanding music sheets.", "conclusion": "MusiXQA and Phi-3-MusiX establish an initial framework for advancing MLLMs' capabilities in interpreting music sheets, making this a promising direction for future research."}}
{"id": "2506.23419", "pdf": "https://arxiv.org/pdf/2506.23419", "abs": "https://arxiv.org/abs/2506.23419", "authors": ["Amanda S Barnard"], "title": "BenchMake: Turn any scientific data set into a reproducible benchmark", "categories": ["cs.LG", "cs.AI", "cs.DL", "62G09", "J.1"], "comment": "10 pages, 15 pages in Appendix, 15 figures, 5 tables, 57 references", "summary": "Benchmark data sets are a cornerstone of machine learning development and\napplications, ensuring new methods are robust, reliable and competitive. The\nrelative rarity of benchmark sets in computational science, due to the\nuniqueness of the problems and the pace of change in the associated domains,\nmakes evaluating new innovations difficult for computational scientists. In\nthis paper a new tool is developed and tested to potentially turn any of the\nincreasing numbers of scientific data sets made openly available into a\nbenchmark accessible to the community. BenchMake uses non-negative matrix\nfactorisation to deterministically identify and isolate challenging edge cases\non the convex hull (the smallest convex set that contains all existing data\ninstances) and partitions a required fraction of matched data instances into a\ntesting set that maximises divergence and statistical significance, across\ntabular, graph, image, signal and textual modalities. BenchMake splits are\ncompared to establish splits and random splits using ten publicly available\nbenchmark sets from different areas of science, with different sizes, shapes,\ndistributions.", "AI": {"tldr": "The paper presents BenchMake, a tool that transforms scientific datasets into benchmarks using deterministic methods for robust evaluation across data modalities.", "motivation": "The scarcity of benchmark datasets in computational science hampers the evaluation of new methods due to the uniqueness and rapid evolution of these domains.", "method": "Developing BenchMake, which employs non-negative matrix factorization to isolate challenging dataset instances for testing, ensuring statistical significance and diversity.", "result": "BenchMake was validated on ten publicly available datasets across diverse modalities, demonstrating superior testing set creation compared to established and random splits.", "conclusion": "BenchMake offers a standardized and reliable approach to generate benchmarks, facilitating robust comparisons in computational science domains."}}
{"id": "2506.23030", "pdf": "https://arxiv.org/pdf/2506.23030", "abs": "https://arxiv.org/abs/2506.23030", "authors": ["Alejandro Romero Amezcua", "Mariano Jos\u00e9 Juan Rivera Meraz"], "title": "VisionScores -- A system-segmented image score dataset for deep learning tasks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": "Comments: 5 pages, 3 figures. Accepted for presentation at the 2025\n  IEEE International Conference on Image Processing (ICIP). \\c{opyright} 2025\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for any other use", "summary": "VisionScores presents a novel proposal being the first system-segmented image\nscore dataset, aiming to offer structure-rich, high information-density images\nfor machine and deep learning tasks. Delimited to two-handed piano pieces, it\nwas built to consider not only certain graphic similarity but also composition\npatterns, as this creative process is highly instrument-dependent. It provides\ntwo scenarios in relation to composer and composition type. The first, formed\nby 14k samples, considers works from different authors but the same composition\ntype, specifically, Sonatinas. The latter, consisting of 10.8K samples,\npresents the opposite case, various composition types from the same author,\nbeing the one selected Franz Liszt. All of the 24.8k samples are formatted as\ngrayscale jpg images of $128 \\times 512$ pixels. VisionScores supplies the\nusers not only the formatted samples but the systems' order and pieces'\nmetadata. Moreover, unsegmented full-page scores and the pre-formatted images\nare included for further analysis.", "AI": {"tldr": "VisionScores is a dataset containing 24.8k grayscale segmented images of two-handed piano scores, structured into two scenarios: different composers, same type (Sonatinas) and one composer (Franz Liszt), various types.", "motivation": "The work aims to provide a structured, highly-informative dataset to aid machine learning and deep learning tasks with image data from musical scores.", "method": "The dataset consists of grayscale 128x512 images segmented for two settings: 1) 14k Sonatina segments from various composers, 2) 10.8k segments of various types from Franz Liszt.", "result": "The final dataset includes 24.8k images, along with metadata, system orders, unsegmented full pages, and pre-formatted versions.", "conclusion": "VisionScores offers a unique, structure-rich dataset tailored for music-related machine/deep learning tasks, enabling detailed studies with diverse segmentation options and metadata."}}
{"id": "2506.23929", "pdf": "https://arxiv.org/pdf/2506.23929", "abs": "https://arxiv.org/abs/2506.23929", "authors": ["Mohammed J. Saeed", "Tommi Vehvilainen", "Evgeny Fedoseev", "Sevil Caliskan", "Tatiana Vodolazova"], "title": "IMPACT: Inflectional Morphology Probes Across Complex Typologies", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown significant progress on various\nmultilingual benchmarks and are increasingly used to generate and evaluate text\nin non-English languages. However, while they may produce fluent outputs, it\nremains unclear to what extent these models truly grasp the underlying\nlinguistic complexity of those languages, particularly in morphology. To\ninvestigate this, we introduce IMPACT, a synthetically generated evaluation\nframework focused on inflectional morphology, which we publicly release,\ndesigned to evaluate LLM performance across five morphologically rich\nlanguages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes\nunit-test-style cases covering both shared and language-specific phenomena,\nfrom basic verb inflections (e.g., tense, number, gender) to unique features\nlike Arabic's reverse gender agreement and vowel harmony in Finnish and\nTurkish. We assess eight multilingual LLMs that, despite strong English\nperformance, struggle with other languages and uncommon morphological patterns,\nespecially when judging ungrammatical examples. We also show that Chain of\nThought and Thinking Models can degrade performance. Our work exposes gaps in\nLLMs' handling of linguistic complexity, pointing to clear room for\nimprovement. To support further research, we publicly release the IMPACT\nframework.", "AI": {"tldr": "The paper introduces IMPACT, a framework to evaluate the linguistic and morphological understanding of large language models (LLMs) in five morphologically rich languages. It highlights performance gaps in non-English language processing.", "motivation": "The motivation behind this study is to address the uncertainty regarding how well LLMs grasp the complexity of morphologically rich languages, as their fluency in generating non-English text doesn't necessarily reflect deep linguistic understanding.", "method": "The authors developed IMPACT, a synthetic evaluation framework with targeted tests for morphology-related cases. It was used to assess eight multilingual LLMs across languages like Arabic, Russian, Finnish, Turkish, and Hebrew, focusing on common and unique linguistic phenomena.", "result": "The tested LLMs, despite their strong English performance, struggled with non-English morphological patterns and exhibited poor judgments of ungrammatical examples. Chain of Thought and Thinking Models further degraded performance.", "conclusion": "LLMs lack adequate handling of morphologically complex languages and show significant room for improvement. The released IMPACT framework aims to facilitate further research into enhancing LLM capabilities for such languages."}}
{"id": "2506.23424", "pdf": "https://arxiv.org/pdf/2506.23424", "abs": "https://arxiv.org/abs/2506.23424", "authors": ["Heitor R. Medeiros", "Hossein Sharifi-Noghabi", "Gabriel L. Oliveira", "Saghar Irandoust"], "title": "Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Second Workshop on Test-Time Adaptation: Putting Updates to the Test!\n  at ICML 2025, Vancouver, Canada. 2025", "summary": "Real-world time series often exhibit a non-stationary nature, degrading the\nperformance of pre-trained forecasting models. Test-Time Adaptation (TTA)\naddresses this by adjusting models during inference, but existing methods\ntypically update the full model, increasing memory and compute costs. We\npropose PETSA, a parameter-efficient method that adapts forecasters at test\ntime by only updating small calibration modules on the input and output. PETSA\nuses low-rank adapters and dynamic gating to adjust representations without\nretraining. To maintain accuracy despite limited adaptation capacity, we\nintroduce a specialized loss combining three components: (1) a robust term, (2)\na frequency-domain term to preserve periodicity, and (3) a patch-wise\nstructural term for structural alignment. PETSA improves the adaptability of\nvarious forecasting backbones while requiring fewer parameters than baselines.\nExperimental results on benchmark datasets show that PETSA achieves competitive\nor better performance across all horizons. Our code is available at:\nhttps://github.com/BorealisAI/PETSA", "AI": {"tldr": "The paper introduces PETSA, a method for parameter-efficient test-time adaptation of forecasting models that maintains competitive or superior performance while reducing memory and compute costs.", "motivation": "Existing test-time adaptation techniques for non-stationary time series require updating the full model, leading to high resource demands.", "method": "PETSA leverages low-rank adapters and dynamic gating for calibration, accompanied by a specialized loss function to enhance robustness, preserve periodicity, and align structures.", "result": "PETSA outperforms or matches baseline methods across various forecasting benchmarks, while significantly reducing parameter usage.", "conclusion": "The approach demonstrates the feasibility of resource-efficient test-time model adaptation, promoting adaptability without sacrificing accuracy or efficiency."}}
{"id": "2506.23038", "pdf": "https://arxiv.org/pdf/2506.23038", "abs": "https://arxiv.org/abs/2506.23038", "authors": ["Xinrong Hu", "Yiyu Shi"], "title": "Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Collecting pixel-level labels for medical datasets can be a laborious and\nexpensive process, and enhancing segmentation performance with a scarcity of\nlabeled data is a crucial challenge. This work introduces AugPaint, a data\naugmentation framework that utilizes inpainting to generate image-label pairs\nfrom limited labeled data. AugPaint leverages latent diffusion models, known\nfor their ability to generate high-quality in-domain images with low overhead,\nand adapts the sampling process for the inpainting task without need for\nretraining. Specifically, given a pair of image and label mask, we crop the\narea labeled with the foreground and condition on it during reversed denoising\nprocess for every noise level. Masked background area would gradually be filled\nin, and all generated images are paired with the label mask. This approach\nensures the accuracy of match between synthetic images and label masks, setting\nit apart from existing dataset generation methods. The generated images serve\nas valuable supervision for training downstream segmentation models,\neffectively addressing the challenge of limited annotations. We conducted\nextensive evaluations of our data augmentation method on four public medical\nimage segmentation datasets, including CT, MRI, and skin imaging. Results\nacross all datasets demonstrate that AugPaint outperforms state-of-the-art\nlabel-efficient methodologies, significantly improving segmentation\nperformance.", "AI": {"tldr": "AugPaint introduces a data augmentation framework using latent diffusion models for generating image-label pairs to address limited labeled data in medical image segmentation.", "motivation": "Address the challenge of enhancing segmentation performance in medical datasets with scarce labeled data.", "method": "Utilized latent diffusion models for inpainting tasks to generate synthetic image-label pairs without retraining.", "result": "Extensive evaluations on four medical imaging datasets showed better performance compared to state-of-the-art label-efficient methods.", "conclusion": "AugPaint is effective in improving segmentation tasks under limited annotation constraints."}}
{"id": "2506.23930", "pdf": "https://arxiv.org/pdf/2506.23930", "abs": "https://arxiv.org/abs/2506.23930", "authors": ["Ruhina Tabasshum Prome", "Tarikul Islam Tamiti", "Anomadarshi Barua"], "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid expansion of social media leads to a marked increase in hate\nspeech, which threatens personal lives and results in numerous hate crimes.\nDetecting hate speech presents several challenges: diverse dialects, frequent\ncode-mixing, and the prevalence of misspelled words in user-generated content\non social media platforms. Recent progress in hate speech detection is\ntypically concentrated on high-resource languages. However, low-resource\nlanguages still face significant challenges due to the lack of large-scale,\nhigh-quality datasets. This paper investigates how we can overcome this\nlimitation via prompt engineering on large language models (LLMs) focusing on\nlow-resource Bengali language. We investigate six prompting strategies -\nzero-shot prompting, refusal suppression, flattering the classifier, multi-shot\nprompting, role prompting, and finally our innovative metaphor prompting to\ndetect hate speech effectively in low-resource languages. We pioneer the\nmetaphor prompting to circumvent the built-in safety mechanisms of LLMs that\nmarks a significant departure from existing jailbreaking methods. We\ninvestigate all six different prompting strategies on the Llama2-7B model and\ncompare the results extensively with three pre-trained word embeddings - GloVe,\nWord2Vec, and FastText for three different deep learning models - multilayer\nperceptron (MLP), convolutional neural network (CNN), and bidirectional gated\nrecurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in\nthe low-resource Bengali language, we also evaluate it in another low-resource\nlanguage - Hindi, and two high-resource languages - English and German. The\nperformance of all prompting techniques is evaluated using the F1 score, and\nenvironmental impact factor (IF), which measures CO$_2$ emissions, electricity\nusage, and computational time.", "AI": {"tldr": "The paper explores advanced prompting strategies for Large Language Models (LLMs) to effectively detect hate speech in low-resource languages, particularly Bengali.", "motivation": "Hate speech detection is challenging due to linguistic diversity, code-mixing, and the prevalence of informal language on social media, especially in low-resource languages lacking large datasets.", "method": "The study investigates six prompting techniques for LLMs, including a novel metaphor prompting strategy, compared to traditional pre-trained word embeddings and deep learning architectures using metrics like F1 scores and environmental impact.", "result": "Metaphor prompting was shown to be uniquely effective at bypassing LLM safety mechanisms and improving hate speech detection for both low-resource (Bengali, Hindi) and high-resource languages (English, German).", "conclusion": "The results highlight the promise of metaphor prompting in enhancing the LLM-based hate speech detection for low-resource languages while considering computational efficiency and environmental impact."}}
{"id": "2506.23446", "pdf": "https://arxiv.org/pdf/2506.23446", "abs": "https://arxiv.org/abs/2506.23446", "authors": ["Mohamed Elbasheer", "Adewale Akinfaderin"], "title": "Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders", "categories": ["cs.LG"], "comment": null, "summary": "Insider threat detection presents unique challenges due to the authorized\nstatus of malicious actors and the subtlety of anomalous behaviors. Existing\nmachine learning methods often treat user activity as isolated events, thereby\nfailing to leverage sequential dependencies in user behavior. In this study, we\npropose a User-Based Sequencing (UBS) methodology, transforming the CERT\ninsider threat dataset into structured temporal sequences suitable for deep\nsequential modeling. We deploy a Transformer Encoder architecture to model\nbenign user activity and employ its reconstruction errors as anomaly scores.\nThese scores are subsequently evaluated using three unsupervised outlier\ndetection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and\nIsolation Forest (iForest). Across four rigorously designed test sets,\nincluding combinations of multiple CERT dataset releases, our UBS-Transformer\npipeline consistently achieves state-of-the-art performance - notably 96.61%\naccuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low\nfalse negative (0.0057) and false positive (0.0571) rates. Comparative analyses\ndemonstrate that our approach substantially outperforms tabular and\nconventional autoencoder baselines, underscoring the efficacy of sequential\nuser modeling and advanced anomaly detection in the insider threat domain.", "AI": {"tldr": "This paper introduces the User-Based Sequencing (UBS) approach for insider threat detection using temporal sequences and a Transformer Encoder, showing state-of-the-art results.", "motivation": "Insider threat detection is challenging because insiders have authorized access and often exhibit subtle behaviors that evading detection.", "method": "The User-Based Sequencing (UBS) approach transforms user activity from the CERT dataset into temporal sequences for deep sequence modeling using a Transformer Encoder. Anomaly scores are produced based on reconstruction errors and evaluated with three unsupervised outlier detection methods.", "result": "The UBS-Transformer pipeline achieves exceptional performance metrics, including 96.61% accuracy and 99.43% recall, while substantially outperforming other baselines.", "conclusion": "Sequential user behavior modeling with advanced techniques like Transformer Encoders is highly effective for detecting insider threats, achieving state-of-the-art results."}}
{"id": "2506.23042", "pdf": "https://arxiv.org/pdf/2506.23042", "abs": "https://arxiv.org/abs/2506.23042", "authors": ["Hung Nguyen", "An Le", "Runfa Li", "Truong Nguyen"], "title": "From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "Accepted to ICCV Workshop", "summary": "3D Gaussian Splatting has emerged as a powerful approach in novel view\nsynthesis, delivering rapid training and rendering but at the cost of an\never-growing set of Gaussian primitives that strains memory and bandwidth. We\nintroduce AutoOpti3DGS, a training-time framework that automatically restrains\nGaussian proliferation without sacrificing visual fidelity. The key idea is to\nfeed the input images to a sequence of learnable Forward and Inverse Discrete\nWavelet Transforms, where low-pass filters are kept fixed, high-pass filters\nare learnable and initialized to zero, and an auxiliary orthogonality loss\ngradually activates fine frequencies. This wavelet-driven, coarse-to-fine\nprocess delays the formation of redundant fine Gaussians, allowing 3DGS to\ncapture global structure first and refine detail only when necessary. Through\nextensive experiments, AutoOpti3DGS requires just a single filter learning-rate\nhyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks,\nand consistently produces sparser scene representations more compatible with\nmemory or storage-constrained hardware.", "AI": {"tldr": "The paper proposes AutoOpti3DGS, a method to reduce Gaussian proliferation in 3D Gaussian Splatting (3DGS) during novel view synthesis while maintaining visual quality.", "motivation": "3D Gaussian Splatting (3DGS) is fast for training and rendering in novel view synthesis but struggles with excessive Gaussian primitives, leading to memory and bandwidth issues.", "method": "The authors use learnable Forward and Inverse Discrete Wavelet Transforms, with fixed low-pass filters, zero-initialized high-pass filters, and an orthogonality loss to gradually activate fine frequencies. This delays redundant fine Gaussian formation.", "result": "Through experiments, AutoOpti3DGS demonstrated compatibility with existing 3DGS frameworks, required only one hyper-parameter, and achieved memory-efficient sparser scene representations.", "conclusion": "AutoOpti3DGS efficiently limits Gaussian proliferation in 3DGS, ensuring sparser models with preserved visual fidelity, suitable for hardware-constrained environments."}}
{"id": "2506.23940", "pdf": "https://arxiv.org/pdf/2506.23940", "abs": "https://arxiv.org/abs/2506.23940", "authors": ["Yang Dai", "Jianxiang An", "Tianwei Lin", "Hongyang He", "Hongzhe Huang", "Wenqiao Zhang", "Zheqi Lv", "Siliang Tang", "Yueting Zhuang"], "title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved success across various\ndomains. However, their applicability tends to degrade when confronted with\ndifferent types of data inputs, especially for MLLMs that have been fine-tuned\nfor specific tasks. Despite its importance, the study of knowledge sharing\namong domain-specific MLLMs--such as those trained for mathematics or\ncode--remains largely underexplored. To address the fragmentation of knowledge\nacross domain-specialized MLLMs, we propose a unified parameter integration\nframework that enables modular composition of expert capabilities. Our method\nis grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,\nwhich leverages both local functional attribution and global\ninformation-theoretic signals to guide selective parameter fusion. By extending\nthis mechanism to the low-rank adaptation layer granularity, we ensure\nefficient integration with minimal inference overhead. Furthermore, we\nintroduce a domain compatibility scoring mechanism that quantifies inter-expert\nalignment at the activation level and correlates with downstream task utility.\nThis principled fusion protocol allows the final model to synergize\nheterogeneous expertise while preserving structural modularity. Extensive\nevaluations across diverse multimodal benchmarks validate the effectiveness of\nour framework, offering a scalable path toward compositional, domain-adaptive\nMLLMs.", "AI": {"tldr": "The paper addresses the fragmentation of domain-specialized multimodal large language models (MLLMs) by proposing a unified parameter integration framework to enable modular composition and effective sharing of expertise.", "motivation": "To overcome the challenges posed by fragmented knowledge across domain-specific MLLMs and enhance their interoperability and expertise-sharing capabilities.", "method": "The framework applies Compatibility-Aware Parameter Splicing (CAPS), combining local functional attribution with global information-theoretic signals for selective parameter fusion. It extends this strategy to low-rank adaptation layer granularity and introduces a domain compatibility scoring mechanism.", "result": "The proposed method efficiently integrates expert knowledge across MLLMs while maintaining minimal inference overhead, enabling synergies between heterogeneous models.", "conclusion": "The framework offers a scalable solution for creating compositional, domain-adaptive MLLMs, validated via extensive multimodal benchmark testing."}}
{"id": "2506.23462", "pdf": "https://arxiv.org/pdf/2506.23462", "abs": "https://arxiv.org/abs/2506.23462", "authors": ["Manaswi Kulahara", "Gautam Siddharth Kashyap", "Nipun Joshi", "Arpita Soni"], "title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,\n  Australia", "summary": "Effective disaster management requires timely and accurate insights, yet\ntraditional methods struggle to integrate multimodal data such as images,\nweather records, and textual reports. To address this, we propose\nDisasterNet-LLM, a specialized Large Language Model (LLM) designed for\ncomprehensive disaster analysis. By leveraging advanced pretraining,\ncross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM\nexcels in disaster classification. Experimental results demonstrate its\nsuperiority over state-of-the-art models, achieving higher accuracy of 89.5%,\nan F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal\ndisaster classification tasks.", "AI": {"tldr": "The paper introduces DisasterNet-LLM, a specialized model that integrates multimodal data for disaster classification, achieving superior performance metrics.", "motivation": "Traditional disaster management methods face challenges integrating multimodal data like images, weather records, and textual reports.", "method": "The paper leverages advanced pretraining, cross-modal attention mechanisms, and adaptive transformers to design DisasterNet-LLM.", "result": "DisasterNet-LLM outperforms state-of-the-art models with 89.5% accuracy, 88.0% F1 score, 0.92% AUC, and 0.88% BERTScore in multimodal disaster classification.", "conclusion": "DisasterNet-LLM is effective in comprehensive disaster analysis and demonstrates significant improvements in classification accuracy."}}
{"id": "2506.23044", "pdf": "https://arxiv.org/pdf/2506.23044", "abs": "https://arxiv.org/abs/2506.23044", "authors": ["Guo-Hua Wang", "Shanshan Zhao", "Xinjie Zhang", "Liangfu Cao", "Pengxin Zhan", "Lunhao Duan", "Shiyin Lu", "Minghao Fu", "Xiaohao Chen", "Jianshan Zhao", "Yang Li", "Qing-Guo Chen"], "title": "Ovis-U1 Technical Report", "categories": ["cs.CV", "cs.AI"], "comment": "A unified model for multimodal understanding, text-to-image\n  generation, and image editing. GitHub: https://github.com/AIDC-AI/Ovis-U1", "summary": "In this report, we introduce Ovis-U1, a 3-billion-parameter unified model\nthat integrates multimodal understanding, text-to-image generation, and image\nediting capabilities. Building on the foundation of the Ovis series, Ovis-U1\nincorporates a diffusion-based visual decoder paired with a bidirectional token\nrefiner, enabling image generation tasks comparable to leading models like\nGPT-4o. Unlike some previous models that use a frozen MLLM for generation\ntasks, Ovis-U1 utilizes a new unified training approach starting from a\nlanguage model. Compared to training solely on understanding or generation\ntasks, unified training yields better performance, demonstrating the\nenhancement achieved by integrating these two tasks. Ovis-U1 achieves a score\nof 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent\nstate-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In\ntext-to-image generation, it excels with scores of 83.72 and 0.89 on the\nDPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves\n4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the\ninitial version of the Ovis unified model series, Ovis-U1 pushes the boundaries\nof multimodal understanding, generation, and editing.", "AI": {"tldr": "Ovis-U1 is a unified model integrating multimodal understanding, text-to-image generation, and image editing, excelling in benchmark evaluations and surpassing state-of-the-art alternatives.", "motivation": "Develop a unified model that combines multimodal understanding, image generation, and editing to enhance performance across tasks compared to specialized or frozen models.", "method": "Ovis-U1 employs a diffusion-based visual decoder paired with a bidirectional token refiner and introduces a unified training approach starting from a language model.", "result": "Ovis-U1 exceeds benchmarks: 69.6 on OpenCompass, 83.72 and 0.89 on text-to-image benchmarks, and 4.00 and 6.42 on image editing metrics, outperforming recent state-of-the-art models.", "conclusion": "The unified training approach enables Ovis-U1 to push boundaries in multimodal tasks, showcasing improved capabilities and performance as the first model in its series."}}
{"id": "2506.23951", "pdf": "https://arxiv.org/pdf/2506.23951", "abs": "https://arxiv.org/abs/2506.23951", "authors": ["Mathis Le Bail", "J\u00e9r\u00e9mie Dentan", "Davide Buscaldi", "Sonia Vanier"], "title": "Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders", "categories": ["cs.CL"], "comment": null, "summary": "Sparse Autoencoders (SAEs) have been successfully used to probe Large\nLanguage Models (LLMs) and extract interpretable concepts from their internal\nrepresentations. These concepts are linear combinations of neuron activations\nthat correspond to human-interpretable features. In this paper, we investigate\nthe effectiveness of SAE-based explainability approaches for sentence\nclassification, a domain where such methods have not been extensively explored.\nWe present a novel SAE-based architecture tailored for text classification,\nleveraging a specialized classifier head and incorporating an activation rate\nsparsity loss. We benchmark this architecture against established methods such\nas ConceptShap, Independent Component Analysis, and other SAE-based concept\nextraction techniques. Our evaluation covers two classification benchmarks and\nfour fine-tuned LLMs from the Pythia family. We further enrich our analysis\nwith two novel metrics for measuring the precision of concept-based\nexplanations, using an external sentence encoder. Our empirical results show\nthat our architecture improves both the causality and interpretability of the\nextracted features.", "AI": {"tldr": "The paper investigates Sparse Autoencoder (SAE)-based methods for interpreting sentence classifiers, proposing a novel architecture that enhances concept causality and interpretability.", "motivation": "Sparse Autoencoders (SAEs) have been useful in interpreting Large Language Models by extracting human-interpretable features, but their effectiveness in sentence classification is less explored.", "method": "The authors develop a novel SAE-based architecture for sentence classification that includes a specialized classifier head and an activation rate sparsity loss. They benchmark this against other methods like ConceptShap, ICA, and existing SAE approaches across multiple benchmarks.", "result": "The proposed architecture outperforms established methods in terms of causality and interpretability of the extracted features, as supported by experiments with two classification benchmarks and four Pythia-family LLMs.", "conclusion": "The study highlights the potential of the new SAE-based method to enhance feature interpretability and causality in sentence classification tasks, validated by novel metrics and comparative benchmarks."}}
{"id": "2506.22506", "pdf": "https://arxiv.org/pdf/2506.22506", "abs": "https://arxiv.org/abs/2506.22506", "authors": ["Momin Ahmad Khan", "Yasra Chandio", "Fatima Muhammad Anwar"], "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated Prompt Learning has emerged as a communication-efficient and\nprivacy-preserving paradigm for adapting large vision-language models like CLIP\nacross decentralized clients. However, the security implications of this setup\nremain underexplored. In this work, we present the first study of backdoor\nattacks in Federated Prompt Learning. We show that when malicious clients\ninject visually imperceptible, learnable noise triggers into input images, the\nglobal prompt learner becomes vulnerable to targeted misclassification while\nstill maintaining high accuracy on clean inputs. Motivated by this\nvulnerability, we propose SABRE-FL, a lightweight, modular defense that filters\npoisoned prompt updates using an embedding-space anomaly detector trained\noffline on out-of-distribution data. SABRE-FL requires no access to raw client\ndata or labels and generalizes across diverse datasets. We show, both\ntheoretically and empirically, that malicious clients can be reliably\nidentified and filtered using an embedding-based detector. Across five diverse\ndatasets and four baseline defenses, SABRE-FL outperforms all baselines by\nsignificantly reducing backdoor accuracy while preserving clean accuracy,\ndemonstrating strong empirical performance and underscoring the need for robust\nprompt learning in future federated systems.", "AI": {"tldr": "This paper introduces and addresses backdoor attacks in Federated Prompt Learning for large vision-language models like CLIP.", "motivation": "The paper is motivated by the security vulnerabilities in Federated Prompt Learning, specifically the susceptibility to backdoor attacks.", "method": "The authors propose SABRE-FL, an embedding-space anomaly detector trained offline to filter poisoned updates without requiring client data or labels.", "result": "SABRE-FL outperforms baseline defenses by significantly reducing backdoor accuracy while maintaining clean accuracy across diverse datasets.", "conclusion": "Robust prompt learning in federated systems is critical, and SABRE-FL provides an effective solution against backdoor threats."}}
{"id": "2506.23469", "pdf": "https://arxiv.org/pdf/2506.23469", "abs": "https://arxiv.org/abs/2506.23469", "authors": ["Chunjing Xiao", "Jiahui Lu", "Xovee Xu", "Fan Zhou", "Tianshu Xie", "Wei Lu", "Lifeng Xu"], "title": "Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS); DOI: https://doi.org/10.1109/TNNLS.2025.3561172", "summary": "Graph anomaly detection is critical in domains such as healthcare and\neconomics, where identifying deviations can prevent substantial losses.\nExisting unsupervised approaches strive to learn a single model capable of\ndetecting both attribute and structural anomalies. However, they confront the\ntug-of-war problem between two distinct types of anomalies, resulting in\nsuboptimal performance. This work presents TripleAD, a mutual\ndistillation-based triple-channel graph anomaly detection framework. It\nincludes three estimation modules to identify the attribute, structural, and\nmixed anomalies while mitigating the interference between different types of\nanomalies. In the first channel, we design a multiscale attribute estimation\nmodule to capture extensive node interactions and ameliorate the over-smoothing\nissue. To better identify structural anomalies, we introduce a link-enhanced\nstructure estimation module in the second channel that facilitates information\nflow to topologically isolated nodes. The third channel is powered by an\nattribute-mixed curvature, a new indicator that encapsulates both attribute and\nstructural information for discriminating mixed anomalies. Moreover, a mutual\ndistillation strategy is introduced to encourage communication and\ncollaboration between the three channels. Extensive experiments demonstrate the\neffectiveness of the proposed TripleAD model against strong baselines.", "AI": {"tldr": "The paper introduces TripleAD, a graph anomaly detection framework that tackles the tug-of-war between detecting attribute and structural anomalies using a triple-channel approach with mutual distillation.", "motivation": "Existing unsupervised models for graph anomaly detection struggle to adequately detect both attribute and structural anomalies due to conflicting requirements, leading to suboptimal results.", "method": "TripleAD uses a triple-channel approach with distinct modules for attribute, structural, and mixed anomaly detection, incorporating techniques like multiscale attribute estimation, link-enhanced structure estimation, and a new attribute-mixed curvature indicator. A mutual distillation strategy fosters collaboration between channels.", "result": "Experiments revealed that TripleAD significantly outperformed other benchmark approaches in accurately detecting graph anomalies.", "conclusion": "TripleAD effectively mitigates the interference between different anomaly types, enabling superior performance and advancing graph anomaly detection frameworks."}}
{"id": "2506.23061", "pdf": "https://arxiv.org/pdf/2506.23061", "abs": "https://arxiv.org/abs/2506.23061", "authors": ["Jiazhen Liu", "Yuchuan Deng", "Long Chen"], "title": "Empowering Small VLMs to Think with Dynamic Memorization and Exploration", "categories": ["cs.CV"], "comment": null, "summary": "Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking\ncapabilities remains fundamentally challenging due to their limited parameter\ncapacity and weak instruction-following abilities. Existing training paradigms,\nincluding Supervised Fine-Tuning (SFT) and Reinforcement Learning with\nVerifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding\nthe capabilities of SVLMs. Consequently, directly applying these paradigms to\nSVLMs often suffers from severe pseudo thinking traces and advantage collapse,\nultimately undermining both thinking reliability and task performance. A\nnatural solution is to combine SFT and RLVR, leveraging their complementarity\nto reduce the dependence on model capacity. However, the widely adopted\ntwo-stage training paradigm still performs poorly on SVLMs, as their tendency\ntoward sub-optimal convergence hinders the trade-off and limits the benefits of\nthe combination. To address this, we propose DyME, a novel training paradigm\nthat Dynamically selects between Memorization (via SFT) and Exploration (via\nRLVR) modes at each optimization step, ensuring that every update contributes\nto the trade-off. Extensive experiments across diverse domains demonstrate that\nDyME consistently achieves this balance, and thus delivers substantial\nperformance improvements. These results establish DyME as a practical and\neffective solution for empowering SVLMs with reliable thinking capabilities.\nGitHub: https://github.com/HKUST-LongGroup/DyME", "AI": {"tldr": "The paper presents DyME, a novel training paradigm for improving the thinking capabilities of Small-scale Vision-Language Models (SVLMs) by dynamically switching between Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Reward (RLVR) during training.", "motivation": "Existing paradigms require substantial base model capabilities, which SVLMs often lack, leading to issues such as pseudo thinking traces and performance collapse.", "method": "DyME dynamically alternates between Memorization (SFT) and Exploration (RLVR) at each optimization step to achieve a balanced trade-off between these modes.", "result": "Experiments demonstrate significant performance improvements of SVLMs across diverse domains when trained using DyME.", "conclusion": "DyME proves to be a practical and effective method for enhancing reliable thinking abilities in SVLMs, overcoming limitations of prior training paradigms."}}
{"id": "2506.23979", "pdf": "https://arxiv.org/pdf/2506.23979", "abs": "https://arxiv.org/abs/2506.23979", "authors": ["Renren Jin", "Tianhao Shen", "Xinwei Wu", "Dan Shi", "Haoran Sun", "Wuwei Huang", "Quandong Wang", "Wei Liu", "Jian Luan", "Bin Wang", "Deyi Xiong"], "title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation", "categories": ["cs.CL"], "comment": "33 pages, 15 tables, 11 figures", "summary": "Conducting supervised fine-tuning and preference fine-tuning on large\nlanguage models (LLMs) requires high-quality datasets to improve their ability\nto follow instructions and align with human preferences and values. However,\nconstructing such datasets is resource-intensive, and most available datasets\nfor supervised and preference fine-tuning are in English. To address these\nchallenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided\n\\underline{\\textbf{P}}reference Data Generation (TaP) framework, which\nfacilitates automated and scalable construction of preference datasets across\nvarious languages. TaP is grounded in a structured taxonomy that allows\nfine-grained control over dataset composition, thereby ensuring both diversity\nand comprehensive coverage. We employ TaP-generated datasets to perform\nsupervised and preference fine-tuning on various LLMs. Experimental results\ndemonstrate that LLMs trained on TaP-generated datasets outperform those\ntrained on existing open-source datasets. Remarkably, LLMs trained on\nTaP-generated datasets surpass the performance of those trained on an\nopen-source dataset that is 180 times larger.", "AI": {"tldr": "The paper introduces the Taxonomy-Guided Preference Data Generation (TaP) framework for scalable and automated multilingual preference dataset creation for training large language models, yielding superior results compared to existing datasets.", "motivation": "The motivation is to address the scarcity of high-quality, diverse, and multilingual datasets for supervised and preference fine-tuning of large language models, which is currently a resource-intensive process dominated by English-language datasets.", "method": "The proposed method involves developing a Taxonomy-Guided Preference Data Generation (TaP) framework to create diverse and comprehensive datasets across multiple languages using a structured taxonomy for dataset composition.", "result": "Experimental results show that large language models fine-tuned with TaP-generated datasets outperform those fine-tuned with existing open-source datasets, even surpassing models trained on a dataset 180 times larger.", "conclusion": "The TaP framework enables efficient, scalable, and high-quality dataset creation, offering a superior alternative to existing datasets for fine-tuning large language models."}}
{"id": "2506.23492", "pdf": "https://arxiv.org/pdf/2506.23492", "abs": "https://arxiv.org/abs/2506.23492", "authors": ["Haolan Guo", "Linwei Tao", "Haoyang Luo", "Minjing Dong", "Chang Xu"], "title": "Sample Margin-Aware Recalibration of Temperature Scaling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent advances in deep learning have significantly improved predictive\naccuracy. However, modern neural networks remain systematically overconfident,\nposing risks for deployment in safety-critical scenarios. Current post-hoc\ncalibration methods face a fundamental dilemma: global approaches like\nTemperature Scaling apply uniform adjustments across all samples, introducing\nhigh bias despite computational efficiency, while more expressive methods that\noperate on full logit distributions suffer from high variance due to noisy\nhigh-dimensional inputs and insufficient validation data. To address these\nchallenges, we propose Sample Margin-Aware Recalibration of Temperature\n(SMART), a lightweight, data-efficient recalibration method that precisely\nscales logits based on the margin between the top two logits -- termed the\nlogit gap. Specifically, the logit gap serves as a denoised, scalar signal\ndirectly tied to decision boundary uncertainty, providing a robust indicator\nthat avoids the noise inherent in high-dimensional logit spaces while\npreserving model prediction invariance. Meanwhile, SMART employs a novel\nsoft-binned Expected Calibration Error (SoftECE) objective that balances model\nbias and variance through adaptive binning, enabling stable parameter updates\neven with extremely limited calibration data. Extensive evaluations across\ndiverse datasets and architectures demonstrate that SMART achieves\nstate-of-the-art calibration performance even with substantially fewer\nparameters compared to existing parametric methods, offering a principled,\nrobust, and highly efficient solution for practical uncertainty quantification\nin neural network predictions. The source code is available at:\nhttps://anonymous.4open.science/r/SMART-8B11.", "AI": {"tldr": "The paper introduces SMART, a recalibration technique for neural networks to enhance prediction reliability while being data-efficient and lightweight.", "motivation": "Modern neural networks are overconfident, posing risks in safety-critical areas. Existing recalibration approaches either introduce high bias (e.g., Temperature Scaling) or suffer from high variance due to noisy inputs and insufficient validation data.", "method": "The authors propose SMART, a method that recalibrates logits using the 'logit gap' (the margin between the top two logits), acting as a denoised uncertainty signal. It incorporates a SoftECE objective that adapts binning to balance bias and variance, improving calibration stability, even with limited data.", "result": "SMART outperforms existing parametric methods in calibration performance across diverse datasets and architectures, achieving state-of-the-art results with fewer parameters.", "conclusion": "SMART provides a principled and efficient recalibration solution, ensuring robust uncertainty quantification for neural network predictions even with minimal computational cost."}}
{"id": "2506.23066", "pdf": "https://arxiv.org/pdf/2506.23066", "abs": "https://arxiv.org/abs/2506.23066", "authors": ["Jiale Meng", "Yiming Li", "Zheming Lu", "Zewei He", "Hao Luo", "Tianwei Zhang"], "title": "CoreMark: Toward Robust and Universal Text Watermarking Technique", "categories": ["cs.CV", "cs.CR", "cs.MM"], "comment": "10 pages, 16 figures", "summary": "Text watermarking schemes have gained considerable attention in recent years,\nyet still face critical challenges in achieving simultaneous robustness,\ngeneralizability, and imperceptibility. This paper introduces a new embedding\nparadigm,termed CORE, which comprises several consecutively aligned black pixel\nsegments. Its key innovation lies in its inherent noise resistance during\ntransmission and broad applicability across languages and fonts. Based on the\nCORE, we present a text watermarking framework named CoreMark. Specifically,\nCoreMark first dynamically extracts COREs from characters. Then, the characters\nwith stronger robustness are selected according to the lengths of COREs. By\nmodifying the thickness of the CORE, the hidden data is embedded into the\nselected characters without causing significant visual distortions. Moreover, a\ngeneral plug-and-play embedding strength modulator is proposed, which can\nadaptively enhance the robustness for small font sizes by adjusting the\nembedding strength according to the font size. Experimental evaluation\nindicates that CoreMark demonstrates outstanding generalizability across\nmultiple languages and fonts. Compared to existing methods, CoreMark achieves\nsignificant improvements in resisting screenshot, print-scan, and print camera\nattacks, while maintaining satisfactory imperceptibility.", "AI": {"tldr": "The paper proposes CORE and CoreMark for improved text watermarking with enhanced robustness, generalizability, and imperceptibility.", "motivation": "To address the critical challenges in text watermarking, such as robustness, generalizability, and imperceptibility, which current solutions struggle to achieve simultaneously.", "method": "The authors introduce the CORE paradigm, modify the thickness of COREs to embed hidden data without causing significant visual distortions, and propose an embedding strength modulator to adapt to font sizes.", "result": "CoreMark was experimentally shown to improve resistance against screenshot, print-scan, and print-camera attacks, while maintaining strong imperceptibility across multiple languages and fonts.", "conclusion": "CoreMark successfully balances robustness, imperceptibility, and generalizability, advancing the state-of-the-art in text watermarking methods."}}
{"id": "2506.23990", "pdf": "https://arxiv.org/pdf/2506.23990", "abs": "https://arxiv.org/abs/2506.23990", "authors": ["Dustin Wright"], "title": "Machine Understanding of Scientific Language", "categories": ["cs.CL", "cs.LG"], "comment": "PhD Thesis, 210 pages", "summary": "Scientific information expresses human understanding of nature. This\nknowledge is largely disseminated in different forms of text, including\nscientific papers, news articles, and discourse among people on social media.\nWhile important for accelerating our pursuit of knowledge, not all scientific\ntext is faithful to the underlying science. As the volume of this text has\nburgeoned online in recent years, it has become a problem of societal\nimportance to be able to identify the faithfulness of a given piece of\nscientific text automatically. This thesis is concerned with the cultivation of\ndatasets, methods, and tools for machine understanding of scientific language,\nin order to analyze and understand science communication at scale. To arrive at\nthis, I present several contributions in three areas of natural language\nprocessing and machine learning: automatic fact checking, learning with limited\ndata, and scientific text processing. These contributions include new methods\nand resources for identifying check-worthy claims, adversarial claim\ngeneration, multi-source domain adaptation, learning from crowd-sourced labels,\ncite-worthiness detection, zero-shot scientific fact checking, detecting\nexaggerated scientific claims, and modeling degrees of information change in\nscience communication. Critically, I demonstrate how the research outputs of\nthis thesis are useful for effectively learning from limited amounts of\nscientific text in order to identify misinformative scientific statements and\ngenerate new insights into the science communication process", "AI": {"tldr": "The research focuses on developing datasets, methods, and tools for analyzing and understanding scientific text, aiming to automatically identify its faithfulness to underlying science.", "motivation": "The societal challenge posed by the growing volume of online scientific text, not all of which is accurate, necessitates tools to gauge its faithfulness.", "method": "The study introduces innovations in natural language processing and machine learning across three areas: automatic fact checking, learning from limited data, and processing scientific text.", "result": "Advances include methods and resources for claim detection, adversarial claim generation, cite-worthiness evaluation, domain adaptation, and more, enabling the identification of misinformation in scientific communication.", "conclusion": "The outputs of this research enhance machine capabilities for processing limited scientific text, improving identification of misleading claims and contributing insights into science communication."}}
{"id": "2506.23516", "pdf": "https://arxiv.org/pdf/2506.23516", "abs": "https://arxiv.org/abs/2506.23516", "authors": ["Seung-Wook Kim", "Seongyeol Kim", "Jiah Kim", "Seowon Ji", "Se-Ho Lee"], "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) often suffers from performance degradation due to key\nchallenges such as data heterogeneity and communication constraints. To address\nthese limitations, we present a novel FL framework called FedWSQ, which\nintegrates weight standardization (WS) and the proposed distribution-aware\nnon-uniform quantization (DANUQ). WS enhances FL performance by filtering out\nbiased components in local updates during training, thereby improving the\nrobustness of the model against data heterogeneity and unstable client\nparticipation. In addition, DANUQ minimizes quantization errors by leveraging\nthe statistical properties of local model updates. As a result, FedWSQ\nsignificantly reduces communication overhead while maintaining superior model\naccuracy. Extensive experiments on FL benchmark datasets demonstrate that\nFedWSQ consistently outperforms existing FL methods across various challenging\nFL settings, including extreme data heterogeneity and ultra-low-bit\ncommunication scenarios.", "AI": {"tldr": "The paper presents FedWSQ, a novel federated learning framework integrating weight standardization and a new quantization method (DANUQ) to address challenges like data heterogeneity and communication constraints.", "motivation": "Federated learning faces challenges like data heterogeneity and limited communication, which impact performance. The paper aims to address these issues.", "method": "FedWSQ combines weight standardization to improve robustness against biases and the distribution-aware non-uniform quantization method to reduce errors and communication overhead.", "result": "FedWSQ achieves high model accuracy and reduces communication costs in federated learning, as shown through experiments on benchmark datasets under challenging scenarios.", "conclusion": "FedWSQ outperforms existing federated learning methods, addressing key challenges of extreme data heterogeneity and low communication capacity effectively."}}
{"id": "2506.23072", "pdf": "https://arxiv.org/pdf/2506.23072", "abs": "https://arxiv.org/abs/2506.23072", "authors": ["Jing Gao"], "title": "Unsupervised 3D Braided Hair Reconstruction from a Single-View Image", "categories": ["cs.CV"], "comment": "6 pages, 3 figures, accepted to the 2025 International Conference on\n  Machine Vision Applications (MVA 2025)", "summary": "Reconstructing 3D braided hairstyles from single-view images remains a\nchallenging task due to the intricate interwoven structure and complex\ntopologies of braids. Existing strand-based hair reconstruction methods\ntypically focus on loose hairstyles and often struggle to capture the\nfine-grained geometry of braided hair. In this paper, we propose a novel\nunsupervised pipeline for efficiently reconstructing 3D braided hair from\nsingle-view RGB images. Leveraging a synthetic braid model inspired by braid\ntheory, our approach effectively captures the complex intertwined structures of\nbraids. Extensive experiments demonstrate that our method outperforms\nstate-of-the-art approaches, providing superior accuracy, realism, and\nefficiency in reconstructing 3D braided hairstyles, supporting expressive\nhairstyle modeling in digital humans.", "AI": {"tldr": "The paper introduces an unsupervised method for reconstructing 3D braided hairstyles from single-view images, outperforming existing methods in accuracy and realism.", "motivation": "Existing hair reconstruction methods struggle with the intricate and complex structures of braided hairstyles, which are not adequately addressed by current approaches designed for loose hair.", "method": "The proposed method uses a novel synthetic braid model inspired by braid theory in an unsupervised pipeline to reconstruct 3D braided hairstyles from single-view RGB images.", "result": "Experiments show that the proposed method is more accurate, realistic, and efficient compared to state-of-the-art approaches.", "conclusion": "The method significantly advances the reconstruction of braided hairstyles, enabling expressive hairstyle modeling for digital humans."}}
{"id": "2506.23998", "pdf": "https://arxiv.org/pdf/2506.23998", "abs": "https://arxiv.org/abs/2506.23998", "authors": ["Seungjun Yi", "Joakim Nguyen", "Huimin Xu", "Terence Lim", "Andrew Well", "Mia Markey", "Ying Ding"], "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning", "categories": ["cs.CL"], "comment": "Presented at ACL 2025 SRW", "summary": "Congenital heart disease (CHD) presents complex, lifelong challenges often\nunderrepresented in traditional clinical metrics. While unstructured narratives\noffer rich insights into patient and caregiver experiences, manual thematic\nanalysis (TA) remains labor-intensive and unscalable. We propose a fully\nautomated large language model (LLM) pipeline that performs end-to-end TA on\nclinical narratives, which eliminates the need for manual coding or full\ntranscript review. Our system employs a novel multi-agent framework, where\nspecialized LLM agents assume roles to enhance theme quality and alignment with\nhuman analysis. To further improve thematic relevance, we optionally integrate\nreinforcement learning from human feedback (RLHF). This supports scalable,\npatient-centered analysis of large qualitative datasets and allows LLMs to be\nfine-tuned for specific clinical contexts.", "AI": {"tldr": "This paper presents a fully automated large language model (LLM) pipeline for thematic analysis of clinical narratives in congenital heart disease (CHD), replacing manual processes with scalable, automated solutions.", "motivation": "Traditional thematic analysis (TA) of clinical narratives for congenital heart disease is labor-intensive and unscalable, limiting insights into patient and caregiver experiences.", "method": "The paper introduces a novel multi-agent framework with large language models (LLMs), optionally improved using reinforcement learning from human feedback (RLHF), to automate thematic analysis.", "result": "The automated system eliminates manual coding or transcript reviews, while aligning closely with human analysis and improving theme quality for clinical narratives.", "conclusion": "This automated LLM-based approach enables scalable, patient-centered analysis of large qualitative datasets, adapting LLMs to specific clinical contexts for better insights into CHD challenges."}}
{"id": "2506.23544", "pdf": "https://arxiv.org/pdf/2506.23544", "abs": "https://arxiv.org/abs/2506.23544", "authors": ["Kento Imaizumi", "Hideaki Iiduka"], "title": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Momentum methods were originally introduced for their superiority to\nstochastic gradient descent (SGD) in deterministic settings with convex\nobjective functions. However, despite their widespread application to deep\nneural networks -- a representative case of stochastic nonconvex optimization\n-- the theoretical justification for their effectiveness in such settings\nremains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that\ngeneralizes various momentum methods and has been studied to better understand\nthe class of momentum-based algorithms as a whole. In this paper, we provide\nboth asymptotic and non-asymptotic convergence results for mini-batch QHM with\nan increasing batch size. We show that achieving asymptotic convergence\nrequires either a decaying learning rate or an increasing batch size. Since a\ndecaying learning rate adversely affects non-asymptotic convergence, we\ndemonstrate that using mini-batch QHM with an increasing batch size -- without\ndecaying the learning rate -- can be a more effective strategy. Our experiments\nshow that even a finite increase in batch size can provide benefits for\ntraining neural networks.", "AI": {"tldr": "This study investigates Quasi-hyperbolic momentum (QHM), a generalized momentum method, for its effectiveness in stochastic nonconvex optimization like deep neural networks. It concludes that increasing batch size without decaying learning rate improves training outcomes.", "motivation": "While momentum methods excel in deterministic convex optimization, their theoretical effectiveness in stochastic nonconvex contexts, such as deep neural networks, is poorly understood, motivating this study.", "method": "The paper analyzes mini-batch QHM under scenarios of increasing batch size and/or decaying learning rate. It performs asymptotic and non-asymptotic convergence analyses through experiments.", "result": "Asymptotic convergence requires either increasing batch size or a decaying learning rate, but the latter harms non-asymptotic convergence. Experiments show increasing batch size benefits neural network training without needing decayed learning rates.", "conclusion": "Increasing batch size, without decaying the learning rate, is an effective strategy for training deep neural networks using QHM, improving both theoretical understanding and practical application."}}
{"id": "2506.23074", "pdf": "https://arxiv.org/pdf/2506.23074", "abs": "https://arxiv.org/abs/2506.23074", "authors": ["Yu Zheng", "Boyang Gong", "Fanye Kong", "Yueqi Duan", "Bingyao Yu", "Wenzhao Zheng", "Lei Chen", "Jiwen Lu", "Jie Zhou"], "title": "Learning Counterfactually Decoupled Attention for Open-World Model Attribution", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "Accepted by ICCV 2025. Code: \\url{https://github.com/yzheng97/CDAL}", "summary": "In this paper, we propose a Counterfactually Decoupled Attention Learning\n(CDAL) method for open-world model attribution. Existing methods rely on\nhandcrafted design of region partitioning or feature space, which could be\nconfounded by the spurious statistical correlations and struggle with novel\nattacks in open-world scenarios. To address this, CDAL explicitly models the\ncausal relationships between the attentional visual traces and source model\nattribution, and counterfactually decouples the discriminative model-specific\nartifacts from confounding source biases for comparison. In this way, the\nresulting causal effect provides a quantification on the quality of learned\nattention maps, thus encouraging the network to capture essential generation\npatterns that generalize to unseen source models by maximizing the effect.\nExtensive experiments on existing open-world model attribution benchmarks show\nthat with minimal computational overhead, our method consistently improves\nstate-of-the-art models by large margins, particularly for unseen novel\nattacks. Source code: https://github.com/yzheng97/CDAL.", "AI": {"tldr": "This paper introduces the Counterfactually Decoupled Attention Learning (CDAL) method for improving open-world model attribution by addressing confounding biases and capturing essential generation patterns.", "motivation": "Existing methods for model attribution struggle with handcrafted designs that are susceptible to confounding biases and novel attacks in open-world settings.", "method": "CDAL uses counterfactual reasoning to decouple discriminative artifacts from confounding biases, optimizing attention maps based on causal relationships.", "result": "CDAL significantly enhances state-of-the-art performance in open-world model attribution benchmarks, especially in handling unseen novel attacks.", "conclusion": "The approach improves generalization capabilities and provides a robust solution for attribution tasks with minimal computational overhead."}}
{"id": "2506.24006", "pdf": "https://arxiv.org/pdf/2506.24006", "abs": "https://arxiv.org/abs/2506.24006", "authors": ["Anselm R. Strohmaier", "Wim Van Dooren", "Kathrin Se\u00dfler", "Brian Greer", "Lieven Verschaffel"], "title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective", "categories": ["cs.CL", "math.HO"], "comment": null, "summary": "The progress of Large Language Models (LLMs) like ChatGPT raises the question\nof how they can be integrated into education. One hope is that they can support\nmathematics learning, including word-problem solving. Since LLMs can handle\ntextual input with ease, they appear well-suited for solving mathematical word\nproblems. Yet their real competence, whether they can make sense of the\nreal-world context, and the implications for classrooms remain unclear. We\nconducted a scoping review from a mathematics-education perspective, including\nthree parts: a technical overview, a systematic review of word problems used in\nresearch, and a state-of-the-art empirical evaluation of LLMs on mathematical\nword problems. First, in the technical overview, we contrast the\nconceptualization of word problems and their solution processes between LLMs\nand students. In computer-science research this is typically labeled\nmathematical reasoning, a term that does not align with usage in mathematics\neducation. Second, our literature review of 213 studies shows that the most\npopular word-problem corpora are dominated by s-problems, which do not require\na consideration of realities of their real-world context. Finally, our\nevaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems\nshows that most recent LLMs solve these s-problems with near-perfect accuracy,\nincluding a perfect score on 20 problems from PISA. LLMs still showed\nweaknesses in tackling problems where the real-world context is problematic or\nnon-sensical. In sum, we argue based on all three aspects that LLMs have\nmastered a superficial solution process but do not make sense of word problems,\nwhich potentially limits their value as instructional tools in mathematics\nclassrooms.", "AI": {"tldr": "This study evaluates the potential of Large Language Models (LLMs) like GPT in mathematics education, particularly for solving word problems. The findings reveal LLMs excel at superficial solutions but struggle with contextually challenging problems.", "motivation": "To explore how LLMs' word-problem-solving capabilities align with educational needs and determine their potential usefulness in classrooms.", "method": "A three-part scoping review including: (1) technical overview contrasting LLMs and student problem-solving processes, (2) systematic review of 213 studies on word-problem corpora, and (3) empirical evaluation of LLMs on 287 word problems.", "result": "LLMs achieved near-perfect accuracy on simple (\u201cs-problem\u201d) word problems but showed weaknesses in addressing problems requiring real-world context comprehension.", "conclusion": "While LLMs excel at solving straightforward word problems, their lack of contextual understanding limits their effectiveness as educational tools in mathematics classrooms."}}
{"id": "2506.23551", "pdf": "https://arxiv.org/pdf/2506.23551", "abs": "https://arxiv.org/abs/2506.23551", "authors": ["Jingpu Cheng", "Qianxiao Li", "Ting Lin", "Zuowei Shen"], "title": "A unified framework on the universal approximation of transformer-type architectures", "categories": ["cs.LG"], "comment": null, "summary": "We investigate the universal approximation property (UAP) of transformer-type\narchitectures, providing a unified theoretical framework that extends prior\nresults on residual networks to models incorporating attention mechanisms. Our\nwork identifies token distinguishability as a fundamental requirement for UAP\nand introduces a general sufficient condition that applies to a broad class of\narchitectures. Leveraging an analyticity assumption on the attention layer, we\ncan significantly simplify the verification of this condition, providing a\nnon-constructive approach in establishing UAP for such architectures. We\ndemonstrate the applicability of our framework by proving UAP for transformers\nwith various attention mechanisms, including kernel-based and sparse attention\nmechanisms. The corollaries of our results either generalize prior works or\nestablish UAP for architectures not previously covered. Furthermore, our\nframework offers a principled foundation for designing novel transformer\narchitectures with inherent UAP guarantees, including those with specific\nfunctional symmetries. We propose examples to illustrate these insights.", "AI": {"tldr": "This paper establishes a unified theoretical framework to prove universal approximation property (UAP) in transformer-type architectures, linking attention mechanisms to UAP and extending the scope of prior results.", "motivation": "The paper aims to address the lack of general theoretical frameworks connecting attention mechanisms in transformer architectures with universal approximation property, which is crucial for their expressiveness in diverse tasks.", "method": "The authors introduce a framework based on token distinguishability and analyticity of the attention layer, allowing for non-constructive proofs of UAP across a broad range of transformer models, including kernel-based and sparse attention mechanisms.", "result": "The framework proves UAP for various attention mechanisms and extends or generalizes prior works, while enabling the design of transformer architectures with guaranteed UAP properties.", "conclusion": "The study provides both theoretical insights and practical tools for designing expressive transformer architectures, advancing our understanding of UAP in models that employ attention mechanisms."}}
{"id": "2506.23077", "pdf": "https://arxiv.org/pdf/2506.23077", "abs": "https://arxiv.org/abs/2506.23077", "authors": ["Suofei Zhang", "Xinxin Wang", "Xiaofu Wu", "Quan Zhou", "Haifeng Hu"], "title": "Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization", "categories": ["cs.CV"], "comment": null, "summary": "Existing deep learning-based cross-view geo-localization methods primarily\nfocus on improving the accuracy of cross-domain image matching, rather than\nenabling models to comprehensively capture contextual information around the\ntarget and minimize the cost of localization errors. To support systematic\nresearch into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,\nwe construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs\nmulti-view imagery with precise distance annotations across three spatial\nresolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical\nretrieval problem across different domains. Our study further reveals that, due\nto the inherent complexity of spatial relationships among buildings, this\nproblem can only be addressed via a contrastive learning paradigm, rather than\nconventional metric learning. To tackle this challenge, we propose Dynamic\nContrastive Learning (DyCL), a novel framework that progressively aligns\nfeature representations according to hierarchical spatial margins. Extensive\nexperiments demonstrate that DyCL is highly complementary to existing\nmulti-scale metric learning methods and yields substantial improvements in both\nhierarchical retrieval performance and overall cross-view geo-localization\naccuracy. Our code and benchmark are publicly available at\nhttps://github.com/anocodetest1/DyCL.", "AI": {"tldr": "This paper introduces the Distance-Aware Cross-View Geo-Localization (DACVGL) problem and proposes the first benchmark dataset DA-Campus, alongside a novel Dynamic Contrastive Learning (DyCL) framework to address the issue.", "motivation": "The authors identify a gap in existing cross-view geo-localization methods, which lack focus on contextual understanding and minimizing localization errors, motivating them to propose a new benchmark and approach.", "method": "The authors introduce DA-Campus, a benchmark dataset with multi-view imagery and distance annotations, and propose the DyCL framework, which uses dynamic contrastive learning with hierarchical spatial margins for cross-domain image retrieval.", "result": "The proposed DyCL framework improves hierarchical retrieval and cross-view geo-localization accuracy, as evidenced by extensive experimental results.", "conclusion": "The study demonstrates that DyCL is a promising method for addressing the DACVGL problem, outperforming traditional metric learning methods. The benchmark and code have been made publicly available."}}
{"id": "2506.24016", "pdf": "https://arxiv.org/pdf/2506.24016", "abs": "https://arxiv.org/abs/2506.24016", "authors": ["Hyunjong Kim", "Sangyeop Kim", "Jongheon Jeong", "Yeongjae Cho", "Sungzoon Cho"], "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted at ACL 2025 Findings", "summary": "Recent advances in large language models and vision-language models have led\nto growing interest in explainable evaluation metrics for image captioning.\nHowever, these metrics generate explanations without standardized criteria, and\nthe overall quality of the generated explanations remains unverified. In this\npaper, we propose EXPERT, a reference-free evaluation metric that provides\nstructured explanations based on three fundamental criteria: fluency,\nrelevance, and descriptiveness. By constructing large-scale datasets of\nhigh-quality structured explanations, we develop a two-stage evaluation\ntemplate to effectively supervise a vision-language model for both scoring and\nexplanation generation. EXPERT achieves state-of-the-art results on benchmark\ndatasets while providing significantly higher-quality explanations than\nexisting metrics, as validated through comprehensive human evaluation. Our code\nand datasets are available at https://github.com/hjkim811/EXPERT.", "AI": {"tldr": "This paper introduces EXPERT, a reference-free evaluation metric for image captioning, which provides structured explanations and achieves superior results compared to existing metrics.", "motivation": "The paper aims to address the lack of standardized criteria and quality verification in the explanations provided by existing image captioning evaluation metrics.", "method": "The authors propose a structured explanation metric, EXPERT, which uses large-scale datasets and a two-stage evaluation template rooted in fluency, relevance, and descriptiveness.", "result": "EXPERT demonstrates state-of-the-art performance on benchmark datasets while generating higher-quality explanations, as confirmed via human evaluations.", "conclusion": "EXPERT improves explainable evaluation in image captioning by offering a structured, reference-free metric, marking a significant advancement in both scoring accuracy and explanation quality."}}
{"id": "2506.22512", "pdf": "https://arxiv.org/pdf/2506.22512", "abs": "https://arxiv.org/abs/2506.22512", "authors": ["Pratheeksha Nair", "Gabriel Lefebvre", "Sophia Garrel", "Maryam Molamohammadi", "Reihaneh Rabbany"], "title": "Ask before you Build: Rethinking AI-for-Good in Human Trafficking Interventions", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "AI for good initiatives often rely on the assumption that technical\ninterventions can resolve complex social problems. In the context of human\ntrafficking (HT), such techno-solutionism risks oversimplifying exploitation,\nreinforcing power imbalances and causing harm to the very communities AI claims\nto support. In this paper, we introduce the Radical Questioning (RQ) framework\nas a five step, pre-project ethical assessment tool to critically evaluate\nwhether AI should be built at all, especially in domains involving marginalized\npopulations and entrenched systemic injustice. RQ does not replace principles\nbased ethics but precedes it, offering an upstream, deliberative space to\nconfront assumptions, map power, and consider harms before design. Using a case\nstudy in AI for HT, we demonstrate how RQ reveals overlooked sociocultural\ncomplexities and guides us away from surveillance based interventions toward\nsurvivor empowerment tools. While developed in the context of HT, RQ's five\nstep structure can generalize to other domains, though the specific questions\nmust be contextual. This paper situates RQ within a broader AI ethics\nphilosophy that challenges instrumentalist norms and centers relational,\nreflexive responsibility.", "AI": {"tldr": "This paper critiques the use of AI for human trafficking solutions, proposing a new ethical assessment framework called Radical Questioning (RQ).", "motivation": "To address the ethical concerns involved in deploying AI for addressing social issues, especially those affecting marginalized communities.", "method": "Introduces the Radical Questioning (RQ) framework, a five-step upstream ethical assessment tool, applied to a case study in AI for human trafficking.", "result": "RQ exposes overlooked sociocultural complexities and directs efforts away from surveillance-based approaches to survivor empowerment tools.", "conclusion": "The five-step RQ framework offers a pre-design ethical evaluation tool that prioritizes responsibility and can help shift AI ethics towards relational and reflexive norms in broader contexts."}}
{"id": "2506.23589", "pdf": "https://arxiv.org/pdf/2506.23589", "abs": "https://arxiv.org/abs/2506.23589", "authors": ["Neta Shaul", "Uriel Singer", "Itai Gat", "Yaron Lipman"], "title": "Transition Matching: Scalable and Flexible Generative Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion and flow matching models have significantly advanced media\ngeneration, yet their design space is well-explored, somewhat limiting further\nimprovements. Concurrently, autoregressive (AR) models, particularly those\ngenerating continuous tokens, have emerged as a promising direction for\nunifying text and media generation. This paper introduces Transition Matching\n(TM), a novel discrete-time, continuous-state generative paradigm that unifies\nand advances both diffusion/flow models and continuous AR generation. TM\ndecomposes complex generation tasks into simpler Markov transitions, allowing\nfor expressive non-deterministic probability transition kernels and arbitrary\nnon-continuous supervision processes, thereby unlocking new flexible design\navenues. We explore these choices through three TM variants: (i) Difference\nTransition Matching (DTM), which generalizes flow matching to discrete-time by\ndirectly learning transition probabilities, yielding state-of-the-art image\nquality and text adherence as well as improved sampling efficiency. (ii)\nAutoregressive Transition Matching (ARTM) and (iii) Full History Transition\nMatching (FHTM) are partially and fully causal models, respectively, that\ngeneralize continuous AR methods. They achieve continuous causal AR generation\nquality comparable to non-causal approaches and potentially enable seamless\nintegration with existing AR text generation techniques. Notably, FHTM is the\nfirst fully causal model to match or surpass the performance of flow-based\nmethods on text-to-image task in continuous domains. We demonstrate these\ncontributions through a rigorous large-scale comparison of TM variants and\nrelevant baselines, maintaining a fixed architecture, training data, and\nhyperparameters.", "AI": {"tldr": "This paper introduces Transition Matching (TM), a novel generative framework that integrates diffusion/flow models and autoregressive generation, offering new flexibility and high-quality media generation.", "motivation": "The motivation is to overcome the well-explored limitations of diffusion and flow matching models by introducing a unified generative approach leveraging capabilities of autoregressive models.", "method": "The paper proposed Transition Matching (TM), decomposing complex tasks into simpler Markov transitions. It introduced three variants: Difference Transition Matching (DTM), Autoregressive Transition Matching (ARTM), and Full History Transition Matching (FHTM).", "result": "DTM achieved state-of-the-art results in image generation and sampling efficiency. FHTM matched or surpassed non-causal methods for text-to-image generation while maintaining causality, while ARTM demonstrated competitive quality compared to continuous autoregressive approaches.", "conclusion": "TM represents a flexible and unifying generative paradigm, significantly advancing both diffusion/flow and continuous AR generation with high performance on image and text-to-image tasks."}}
{"id": "2506.23086", "pdf": "https://arxiv.org/pdf/2506.23086", "abs": "https://arxiv.org/abs/2506.23086", "authors": ["Jian Shi", "Tianqi You", "Pingping Zhang", "Hongli Zhang", "Rui Xu", "Haojie Li"], "title": "Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation", "categories": ["cs.CV"], "comment": "Accepted by MICCAI2025. More modifications my be performed", "summary": "Automated and accurate segmentation of individual vertebra in 3D CT and MRI\nimages is essential for various clinical applications. Due to the limitations\nof current imaging techniques and the complexity of spinal structures, existing\nmethods still struggle with reducing the impact of image blurring and\ndistinguishing similar vertebrae. To alleviate these issues, we introduce a\nFrequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the\naccuracy of vertebrae segmentation. Specifically, we first apply wavelet\ntransform for lossless downsampling to reduce the feature distortion in blurred\nimages. The decomposed high and low-frequency components are then processed\nseparately. For the high-frequency components, we apply a High-frequency\nFeature Refinement (HFR) to amplify the prominence of key features and filter\nout noises, restoring fine-grained details in blurred images. For the\nlow-frequency components, we use a Multi-granularity State Space Model (MG-SSM)\nto aggregate feature representations with different receptive fields,\nextracting spatially-varying contexts while capturing long-range dependencies\nwith linear complexity. The utilization of multi-granularity contexts is\nessential for distinguishing similar vertebrae and improving segmentation\naccuracy. Extensive experiments demonstrate that our method outperforms\nstate-of-the-art approaches on both CT and MRI vertebrae segmentation datasets.\nThe source code is publicly available at https://github.com/anaanaa/FMCNet.", "AI": {"tldr": "The study presents FMC-Net for enhancing 3D CT and MRI vertebra segmentation accuracy by leveraging wavelet transform, high-frequency refinements, and multi-granularity contexts.", "motivation": "Existing vertebra segmentation methods struggle with image blurring and distinguishing similar vertebrae due to imaging limitations and spinal complexity.", "method": "FMC-Net employs wavelet transform for lossless downsampling. High-frequency components are refined using High-frequency Feature Refinement (HFR), while low-frequency components are processed using a Multi-granularity State Space Model (MG-SSM) to extract spatially-varying contexts.", "result": "FMC-Net demonstrates superior performance compared to state-of-the-art methods on CT and MRI vertebra segmentation datasets.", "conclusion": "The approach effectively reduces feature distortion in blurred images and improves segmentation accuracy, particularly for similar vertebrae. The source code is available online for further exploration."}}
{"id": "2506.24068", "pdf": "https://arxiv.org/pdf/2506.24068", "abs": "https://arxiv.org/abs/2506.24068", "authors": ["Ian R. McKenzie", "Oskar J. Hollinsworth", "Tom Tseng", "Xander Davies", "Stephen Casper", "Aaron D. Tucker", "Robert Kirk", "Adam Gleave"], "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Frontier AI developers are relying on layers of safeguards to protect against\ncatastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus\nmodel using one such defense pipeline, and other frontier developers including\nGoogle DeepMind and OpenAI pledge to soon deploy similar defenses. However, the\nsecurity of such pipelines is unclear, with limited prior work evaluating or\nattacking these pipelines. We address this gap by developing and red-teaming an\nopen-source defense pipeline. First, we find that a novel few-shot-prompted\ninput and output classifier outperforms state-of-the-art open-weight safeguard\nmodel ShieldGemma across three attacks and two datasets, reducing the attack\nsuccess rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,\nwe introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on\nClearHarm in a black-box attack against the few-shot-prompted classifier\npipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%\nASR, providing initial evidence that it is feasible to design attacks with no\naccess to the target pipeline. We conclude by suggesting specific mitigations\nthat developers could use to thwart staged attacks.", "AI": {"tldr": "The paper evaluates the security of AI defense pipelines, introducing a novel few-shot-prompted classifier and a staged attack method (STACK) that effectively compromises such safeguards.", "motivation": "To address the limited prior work in evaluating or attacking defense pipelines that guard against catastrophic misuse of AI models, thereby highlighting potential security vulnerabilities.", "method": "The authors developed an open-source defense pipeline, tested its effectiveness with a novel few-shot-prompted classifier, and assessed vulnerabilities using a staged attack procedure (STACK), including transfer settings.", "result": "The new classifier reduced attack success rate (ASR) to 0% on certain datasets, but the STACK procedure achieved a 71% ASR in black-box contexts and 33% ASR in transfer settings, exposing critical weaknesses.", "conclusion": "Current defense pipelines are vulnerable to staged attacks. The paper underscores the need for mitigation strategies to increase pipeline robustness against adversarial attacks."}}
{"id": "2506.22515", "pdf": "https://arxiv.org/pdf/2506.22515", "abs": "https://arxiv.org/abs/2506.22515", "authors": ["Antony Dalmiere", "Guillaume Auriol", "Vincent Nicomette", "Pascal Marchand"], "title": "In-context learning for the classification of manipulation techniques in phishing emails", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Traditional phishing detection often overlooks psychological manipulation.\nThis study investigates using Large Language Model (LLM) In-Context Learning\n(ICL) for fine-grained classification of phishing emails based on a taxonomy of\n40 manipulation techniques. Using few-shot examples with GPT-4o-mini on\nreal-world French phishing emails (SignalSpam), we evaluated performance\nagainst a human-annotated test set (100 emails). The approach effectively\nidentifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For\nMinor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's\npotential for nuanced phishing analysis and provides insights into attacker\nstrategies.", "AI": {"tldr": "The study explores using GPT-4o-mini with In-Context Learning (ICL) for detecting 40 specific manipulation techniques in French phishing emails, achieving an accuracy of 0.76.", "motivation": "Traditional methods for phishing detection often ignore the psychological manipulation tactics used by attackers. The researchers aimed to fill this gap by classifying phishing emails based on manipulation techniques.", "method": "The authors utilized GPT-4o-mini with few-shot examples in an In-Context Learning (ICL) setting, applying this strategy to a dataset of real-world French phishing emails and validating against a human-annotated test set.", "result": "The study demonstrated that the approach effectively identified common manipulation techniques like Baiting, Curiosity Appeal, and Request For Minor Favor, achieving an accuracy of 0.76.", "conclusion": "ICL using LLMs like GPT-4o-mini shows significant potential for detailed phishing email analysis, enhancing understanding of attacker strategies and psychological manipulation methods."}}
{"id": "2506.23596", "pdf": "https://arxiv.org/pdf/2506.23596", "abs": "https://arxiv.org/abs/2506.23596", "authors": ["Min-Yeong Park", "Won-Jeong Lee", "Seong Tae Kim", "Gyeong-Moon Park"], "title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 10 figures, 12 tables, ICML 2025", "summary": "Recently, forecasting future abnormal events has emerged as an important\nscenario to tackle real-world necessities. However, the solution of predicting\nspecific future time points when anomalies will occur, known as Anomaly\nPrediction (AP), remains under-explored. Existing methods dealing with time\nseries data fail in AP, focusing only on immediate anomalies or failing to\nprovide precise predictions for future anomalies. To address the AP task, we\npropose a novel framework called Anomaly to Prompt (A2P), comprised of\nAnomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To\nenable the forecasting model to forecast abnormal time points, we adopt a\nstrategy to learn the relationships of anomalies. For the robust detection of\nanomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)\nthat simulates diverse anomaly patterns using signal adaptive prompt.\nComprehensive experiments on multiple real-world datasets demonstrate the\nsuperiority of A2P over state-of-the-art methods, showcasing its ability to\npredict future anomalies. Our implementation code is available at\nhttps://github.com/KU-VGI/AP.", "AI": {"tldr": "The paper introduces Anomaly to Prompt (A2P), a novel framework for predicting future anomalies in time series data, employing anomaly-aware forecasting and synthetic anomaly prompting.", "motivation": "To address the lack of effective solutions for predicting specific future time points of anomalies, known as Anomaly Prediction (AP), as existing methods are inadequate for this task.", "method": "The A2P framework combines Anomaly-Aware Forecasting (AAF) to learn relationships of anomalies and Synthetic Anomaly Prompting (SAP) with a learnable Anomaly Prompt Pool (APP) to simulate diverse anomaly patterns.", "result": "A2P demonstrates its superiority over state-of-the-art methods across multiple real-world datasets in accurately predicting future anomalies.", "conclusion": "The proposed A2P framework is highly effective for anomaly prediction tasks, advancing the capability of forecasting models in detecting future abnormal events."}}
{"id": "2506.23088", "pdf": "https://arxiv.org/pdf/2506.23088", "abs": "https://arxiv.org/abs/2506.23088", "authors": ["Yuchen Zhou", "Jiayu Tang", "Xiaoyan Xiao", "Yueyao Lin", "Linkai Liu", "Zipeng Guo", "Hao Fei", "Xiaobo Xia", "Chao Gou"], "title": "Where, What, Why: Towards Explainable Driver Attention Prediction", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Modeling task-driven attention in driving is a fundamental challenge for both\nautonomous vehicles and cognitive science. Existing methods primarily predict\nwhere drivers look by generating spatial heatmaps, but fail to capture the\ncognitive motivations behind attention allocation in specific contexts, which\nlimits deeper understanding of attention mechanisms. To bridge this gap, we\nintroduce Explainable Driver Attention Prediction, a novel task paradigm that\njointly predicts spatial attention regions (where), parses attended semantics\n(what), and provides cognitive reasoning for attention allocation (why). To\nsupport this, we present W3DA, the first large-scale explainable driver\nattention dataset. It enriches existing benchmarks with detailed semantic and\ncausal annotations across diverse driving scenarios, including normal\nconditions, safety-critical situations, and traffic accidents. We further\npropose LLada, a Large Language model-driven framework for driver attention\nprediction, which unifies pixel modeling, semantic parsing, and cognitive\nreasoning within an end-to-end architecture. Extensive experiments demonstrate\nthe effectiveness of LLada, exhibiting robust generalization across datasets\nand driving conditions. This work serves as a key step toward a deeper\nunderstanding of driver attention mechanisms, with significant implications for\nautonomous driving, intelligent driver training, and human-computer\ninteraction.", "AI": {"tldr": "This paper introduces Explainable Driver Attention Prediction (EDAP), a method to predict, parse, and explain driver attention using a new dataset (W3DA) and a model (LLada).", "motivation": "Existing attention prediction methods fail to explain the cognitive motivations behind where drivers focus, limiting our understanding of how attention works in driving contexts.", "method": "The paper proposes a paradigm (EDAP) that predicts \u2018where\u2019 drivers look, parses the semantics of their attention (\u2018what\u2019), and explains the cognitive reasons (\u2018why\u2019). This is supported by W3DA, a new dataset with semantic and causal annotations. Additionally, LLada, an end-to-end model, unifies pixel modeling, semantic parsing, and cognitive reasoning.", "result": "Experiments show LLada exhibits strong generalization across datasets and driving conditions, demonstrating its effectiveness for driver attention prediction.", "conclusion": "The paper advances understanding of driver attention, offering insights for autonomous vehicles, driver training, and human-computer interaction by introducing an explainable and comprehensive prediction framework."}}
{"id": "2506.24106", "pdf": "https://arxiv.org/pdf/2506.24106", "abs": "https://arxiv.org/abs/2506.24106", "authors": ["Yanhong Li", "Ming Li", "Karen Livescu", "Jiawei Zhou"], "title": "On the Predictive Power of Representation Dispersion in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We show that a language model's ability to predict text is tightly linked to\nthe breadth of its embedding space: models that spread their contextual\nrepresentations more widely tend to achieve lower perplexity. Concretely, we\nfind that representation dispersion - the average pairwise cosine distance\namong hidden vectors - strongly and negatively correlates with perplexity\nacross diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,\nnews, scientific abstracts). Beyond illustrating this link, we show how\ndispersion can be leveraged for a range of practical tasks without requiring\nlabeled data. First, measuring dispersion on unlabeled text allows us to\npredict downstream accuracy in new domains, offering a data-efficient tool for\nmodel selection. Next, we find that identifying layers with higher dispersion\npinpoints the best representations for retrieval-based methods such as kNN-LM,\nbypassing exhaustive layer-by-layer searches. Finally, we integrate a simple\npush-away objective into training, which increases dispersion in both\nsingle-domain and cross-domain scenarios and directly improves perplexity in\neach.", "AI": {"tldr": "The paper finds a strong link between a language model's text prediction performance (perplexity) and the dispersion of its embedding space, providing practical methods to leverage this property.", "motivation": "The motivation is to understand the relationship between language models' prediction capabilities and the structure of their representation spaces and to use this relationship for practical applications like domain adaptation and performance improvement.", "method": "They analyze the dispersion (measured by average pairwise cosine distance) of hidden representations in various language models and tasks, and propose leveraging this dispersion for practical tasks like predicting downstream accuracy, optimizing retrieval-based approaches, and improving training with a push-away objective.", "result": "Their results show that higher dispersion correlates with better model performance (lower perplexity), aids in domain adaptation, identifies optimal layers for retrieval tasks, and improves perplexity via a training objective.", "conclusion": "Representation dispersion is crucial for language model performance. Leveraging it can enhance model selection, layer identification, and training efficiency, making it a valuable tool in model improvement."}}
{"id": "2506.23629", "pdf": "https://arxiv.org/pdf/2506.23629", "abs": "https://arxiv.org/abs/2506.23629", "authors": ["Xin Liao", "Bing Yang", "Cai Yu"], "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data", "categories": ["cs.LG", "cs.AI", "68T07(Primary) 62M10, 65C60 (Secondary)", "I.2.7"], "comment": "7 pages, 2 figures, conference", "summary": "The integrity of Water Quality Data (WQD) is critical in environmental\nmonitoring for scientific decision-making and ecological protection. However,\nwater quality monitoring systems are often challenged by large amounts of\nmissing data due to unavoidable problems such as sensor failures and\ncommunication delays, which further lead to water quality data becoming\nHigh-Dimensional and Sparse (HDS). Traditional data imputation methods are\ndifficult to depict the potential dynamics and fail to capture the deep data\nfeatures, resulting in unsatisfactory imputation performance. To effectively\naddress the above issues, this paper proposes a Nonlinear Low-rank\nRepresentation model (NLR) with Convolutional Neural Networks (CNN) for\nimputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing\ntemporal features to model the temporal dependence of data between time slots,\nand b) Extracting nonlinear interactions and local patterns to mine\nhigher-order relationships features and achieve deep fusion of multidimensional\ninformation. Experimental studies on three real water quality datasets\ndemonstrate that the proposed model significantly outperforms existing\nstate-of-the-art data imputation models in terms of estimation accuracy. It\nprovides an effective approach for handling water quality monitoring data in\ncomplex dynamic environments.", "AI": {"tldr": "The paper addresses challenges in imputation of High-Dimensional and Sparse (HDS) water quality data using a novel Nonlinear Low-rank Representation model (NLR) with CNNs, achieving superior estimation accuracy.", "motivation": "Traditional data imputation methods fail to effectively handle missing water quality data, which often exhibits high dimensionality and sparsity, limiting decision-making and ecological protection.", "method": "The authors propose a Nonlinear Low-rank Representation model (NLR) utilizing CNNs for capturing temporal dependencies and nonlinear interactions to enhance data imputation accuracy.", "result": "The model is tested on three real-world water quality datasets, demonstrating significant performance improvements over existing imputation methods.", "conclusion": "The proposed approach provides an effective solution for imputing water quality monitoring data in dynamically changing environments, improving decision-making and environmental monitoring."}}
{"id": "2506.23104", "pdf": "https://arxiv.org/pdf/2506.23104", "abs": "https://arxiv.org/abs/2506.23104", "authors": ["Jihun Kim", "Hoyong Kwon", "Hyeokjun Kweon", "Wooseong Jeong", "Kuk-Jin Yoon"], "title": "DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Interactive segmentation (IS) allows users to iteratively refine object\nboundaries with minimal cues, such as positive and negative clicks. While the\nSegment Anything Model (SAM) has garnered attention in the IS community for its\npromptable segmentation capabilities, it often struggles in specialized domains\nor when handling complex scenarios (e.g., camouflaged or multi-part objects).\nTo overcome these challenges, we propose DC-TTA, a novel test-time adaptation\n(TTA) framework that adapts SAM on a per-sample basis by leveraging user\ninteractions as supervision. Instead of forcing a single model to incorporate\nall user clicks at once, DC-TTA partitions the clicks into more coherent\nsubsets, each processed independently via TTA with a separated model. This\nDivide-and-Conquer strategy reduces conflicts among diverse cues and enables\nmore localized updates. Finally, we merge the adapted models to form a unified\npredictor that integrates the specialized knowledge from each subset.\nExperimental results across various benchmarks demonstrate that DC-TTA\nsignificantly outperforms SAM's zero-shot results and conventional TTA methods,\neffectively handling complex tasks such as camouflaged object segmentation with\nfewer interactions and improved accuracy.", "AI": {"tldr": "DC-TTA enhances interactive segmentation by adapting SAM using a novel test-time adaptation approach, focusing on a divide-and-conquer strategy for handling complex objects.", "motivation": "SAM struggles in specialized domains or complex scenarios like camouflaged or multi-part object segmentation, necessitating improvement.", "method": "DC-TTA partitions user clicks into subsets, applies test-time adaptation with specialized models individually, and integrates them into a unified predictor.", "result": "Experimental results show DC-TTA outperforms SAM's zero-shot capability and existing TTA methods, achieving higher accuracy and fewer user interactions.", "conclusion": "DC-TTA provides a significant enhancement in handling challenging segmentation tasks by leveraging user interactions and dividing cues for localized modeling."}}
{"id": "2506.24117", "pdf": "https://arxiv.org/pdf/2506.24117", "abs": "https://arxiv.org/abs/2506.24117", "authors": ["David M. Smiley"], "title": "Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Identifying parallel passages in biblical Hebrew is foundational in biblical\nscholarship for uncovering intertextual relationships. Traditional methods rely\non manual comparison, which is labor-intensive and prone to human error. This\nstudy evaluates the potential of pre-trained transformer-based language models,\nincluding E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in\nthe Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings\nand Chronicles, I assessed each model's capability to generate word embeddings\nthat delineate parallel from non-parallel passages. Utilizing cosine similarity\nand Wasserstein Distance measures, I found that E5 and AlephBERT show\nsignificant promise, with E5 excelling in parallel detection and AlephBERT\ndemonstrating stronger non-parallel differentiation. These findings indicate\nthat pre-trained models can enhance the efficiency and accuracy of detecting\nintertextual parallels in ancient texts, suggesting broader applications for\nancient language studies.", "AI": {"tldr": "The study explores the use of transformer-based language models to identify textual parallels in biblical Hebrew, enhancing efficiency and accuracy.", "motivation": "Manual methods for identifying intertextual parallels in biblical Hebrew are time-consuming and error-prone, necessitating automated solutions.", "method": "The study employed pre-trained transformer models (E5, AlephBERT, MPNet, LaBSE) and measured their performance using cosine similarity and Wasserstein Distance to detect parallels within biblical texts.", "result": "E5 excelled in detecting parallels, while AlephBERT showed better differentiation of non-parallel passages, highlighting their potential for ancient text analysis.", "conclusion": "Transformer language models, particularly E5 and AlephBERT, can significantly improve the detection of intertextual parallels in biblical studies, suggesting their utility in broader ancient language research."}}
{"id": "2506.23679", "pdf": "https://arxiv.org/pdf/2506.23679", "abs": "https://arxiv.org/abs/2506.23679", "authors": ["David Demitri Africa", "Sara M. Kapoor", "Theo Simon Sorg"], "title": "Learning Modular Exponentiation with Transformers", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Modular exponentiation is crucial to number theory and cryptography, yet\nremains largely unexplored from a mechanistic interpretability standpoint. We\ntrain a 4-layer encoder-decoder Transformer model to perform this operation and\ninvestigate the emergence of numerical reasoning during training. Utilizing\nprincipled sampling strategies, PCA-based embedding analysis, and activation\npatching, we examine how number-theoretic properties are encoded within the\nmodel. We find that reciprocal operand training leads to strong performance\ngains, with sudden generalization across related moduli. These synchronized\naccuracy surges reflect grokking-like dynamics, suggesting the model\ninternalizes shared arithmetic structure. We also find a subgraph consisting\nentirely of attention heads in the final layer sufficient to achieve full\nperformance on the task of regular exponentiation. These results suggest that\ntransformer models learn modular arithmetic through specialized computational\ncircuits, paving the way for more interpretable and efficient neural approaches\nto modular exponentiation.", "AI": {"tldr": "This study explores how Transformer models learn modular exponentiation, finding that the models develop specialized computational circuits for numerical reasoning and arithmetic tasks.", "motivation": "To address the lack of mechanistic interpretability of modular exponentiation\u2014a fundamental operation in number theory and cryptography\u2014and explore how machine learning models learn such numerical reasoning tasks.", "method": "The researchers trained a 4-layer encoder-decoder Transformer model for modular exponentiation. Analysis methods included principled sampling, PCA-based embedding analysis, and activation patching to understand the internal mechanisms.", "result": "Training with reciprocal operands improved performance dramatically, leading to sudden generalization across moduli. The emergence of arithmetic structures was observed in grokking-like dynamics, where attention heads in the final layer sufficed for regular exponentiation.", "conclusion": "Transformer models likely learn modular arithmetic using specialized computational circuits, improving interpretability and potentially leading to efficient neural approaches for modular arithmetic tasks."}}
{"id": "2506.23106", "pdf": "https://arxiv.org/pdf/2506.23106", "abs": "https://arxiv.org/abs/2506.23106", "authors": ["Ryo Ishiyama", "Shinnosuke Matsuo", "Seiichi Uchida"], "title": "Computer-Aided Multi-Stroke Character Simplification by Stroke Removal", "categories": ["cs.CV"], "comment": "ICDAR2025 (Oral)", "summary": "Multi-stroke characters in scripts such as Chinese and Japanese can be highly\ncomplex, posing significant challenges for both native speakers and,\nespecially, non-native learners. If these characters can be simplified without\ndegrading their legibility, it could reduce learning barriers for non-native\nspeakers, facilitate simpler and legible font designs, and contribute to\nefficient character-based communication systems. In this paper, we propose a\nframework to systematically simplify multi-stroke characters by selectively\nremoving strokes while preserving their overall legibility. More specifically,\nwe use a highly accurate character recognition model to assess legibility and\nremove those strokes that minimally impact it. Experimental results on 1,256\ncharacter classes with 5, 10, 15, and 20 strokes reveal several key findings,\nincluding the observation that even after removing multiple strokes, many\ncharacters remain distinguishable. These findings suggest the potential for\nmore formalized simplification strategies.", "AI": {"tldr": "The paper proposes a method to simplify complex multi-stroke characters (e.g., Chinese, Japanese) by removing strokes while maintaining legibility, aiming to aid learning and communication.", "motivation": "The paper addresses the challenge of learning and recognizing highly complex multi-stroke characters, especially for non-native learners, by exploring methods to simplify these characters without sacrificing their legibility.", "method": "The researchers utilize a character recognition model to systematically identify and remove strokes from multi-stroke characters while ensuring minimal loss of legibility. Experiments were conducted on 1,256 character classes.", "result": "The experiments demonstrate that numerous characters remain distinguishable even after multiple strokes are removed, suggesting the feasibility of simplified character systems.", "conclusion": "The results indicate that systematic stroke removal can simplify complex characters effectively while preserving legibility, highlighting the potential for standardized simplification methods."}}
{"id": "2506.22449", "pdf": "https://arxiv.org/pdf/2506.22449", "abs": "https://arxiv.org/abs/2506.22449", "authors": ["Carolyn Hicks"], "title": "Computational Analysis of Climate Policy", "categories": ["cs.CY", "cs.CL"], "comment": "Master's thesis", "summary": "This thesis explores the impact of the Climate Emergency movement on local\ngovernment climate policy, using computational methods. The Climate Emergency\nmovement sought to accelerate climate action at local government level through\nthe mechanism of Climate Emergency Declarations (CEDs), resulting in a series\nof commitments from councils to treat climate change as an emergency. With the\naim of assessing the potential of current large language models to answer\ncomplex policy questions, I first built and configured a system named PALLM\n(Policy Analysis with a Large Language Model), using the OpenAI model GPT-4.\nThis system is designed to apply a conceptual framework for climate emergency\nresponse plans to a dataset of climate policy documents. I validated the\nperformance of this system with the help of local government policymakers, by\ngenerating analyses of the climate policies of 11 local governments in Victoria\nand assessing the policymakers' level of agreement with PALLM's responses.\nHaving established that PALLM's performance is satisfactory, I used it to\nconduct a large-scale analysis of current policy documents from local\ngovernments in the state of Victoria, Australia. This thesis presents the\nmethodology and results of this analysis, comparing the results for councils\nwhich have passed a CED to those which did not. This study finds that GPT-4 is\ncapable of high-level policy analysis, with limitations including a lack of\nreliable attribution, and can also enable more nuanced analysis by researchers.\nIts use in this research shows that councils which have passed a CED are more\nlikely to have a recent and climate-specific policy, and show more attention to\nurgency, prioritisation, and equity and social justice, than councils which\nhave not. It concludes that the ability to assess policy documents at scale\nopens up exciting new opportunities for policy researchers.", "AI": {"tldr": "The thesis evaluates the impact of the Climate Emergency movement on local government policies using GPT-4, finding that councils with Climate Emergency Declarations (CEDs) prioritize climate-specific measures more than those without.", "motivation": "The motivation behind this thesis is to assess the potential of large language models, like GPT-4, for answering complex policy questions and to explore whether the Climate Emergency movement has influenced local governments' climate policies.", "method": "A system named PALLM, built with GPT-4, was used to analyze climate policy documents of local governments in Victoria, Australia. The analysis was validated by policymakers and applied to compare councils with and without Climate Emergency Declarations.", "result": "Councils with Climate Emergency Declarations exhibited more climate-specific and recent policies, focusing on urgency, prioritization, and equity, compared to councils without such declarations.", "conclusion": "The study concludes that GPT-4 can perform high-level policy analysis and facilitate nuanced research. Local governments with Climate Emergency Declarations show greater climate policy engagement, demonstrating the movement's influence."}}
{"id": "2506.22520", "pdf": "https://arxiv.org/pdf/2506.22520", "abs": "https://arxiv.org/abs/2506.22520", "authors": ["Mustafa Demir", "Jacob Miratsky", "Jonathan Nguyen", "Chun Kit Chan", "Punya Mishra", "Abhishek Singharoy"], "title": "Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics", "categories": ["cs.HC", "cs.AI", "cs.CE", "cs.CY"], "comment": null, "summary": "This study examines the impact of an Artificial Intelligence tutor teammate\n(AI) on student curiosity-driven engagement and learning effectiveness during\nInteractive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics\nplatform. It explores the role of the AI's curiosity-triggering and response\nbehaviors in stimulating and sustaining student curiosity, affecting the\nfrequency and complexity of student-initiated questions. The study further\nassesses how AI interventions shape student engagement, foster discovery\ncuriosity, and enhance team performance within the IMD learning environment.\nUsing a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI\ntutor teammate's behavior through a large language model. By employing a\nmixed-methods exploratory design, a total of 11 high school students\nparticipated in four IMD tasks that involved molecular visualization and\ncalculations, which increased in complexity over a 60-minute period. Team\nperformance was evaluated through real-time observation and recordings, whereas\nteam communication was measured by question complexity and AI's\ncuriosity-triggering and response behaviors. Cross Recurrence Quantification\nAnalysis (CRQA) metrics reflected structural alignment in coordination and were\nlinked to communication behaviors. High-performing teams exhibited superior\ntask completion, deeper understanding, and increased engagement. Advanced\nquestions were associated with AI curiosity-triggering, indicating heightened\nengagement and cognitive complexity. CRQA metrics highlighted dynamic\nsynchronization in student-AI interactions, emphasizing structured yet adaptive\nengagement to promote curiosity. These proof-of-concept findings suggest that\nthe AI's dual role as a teammate and educator indicates its capacity to provide\nadaptive feedback, sustaining engagement and epistemic curiosity.", "AI": {"tldr": "The paper investigates AI tutor teammates' role in enhancing curiosity-driven engagement and learning effectiveness in molecular visualization tasks, showing promise as adaptive educators.", "motivation": "To explore how AI tutor teammates can stimulate student curiosity and engagement in interactive molecular dynamics learning tasks.", "method": "Implemented a Wizard-of-Oz paradigm where a human controlled AI behavior through a language model. Conducted mixed-methods exploratory study involving 11 students performing molecular visualization tasks and analyzed student-AI interactions using CRQA metrics.", "result": "High-performing teams demonstrated better task completion, engagement, and deeper understanding. Advanced student questions were linked to AI's curiosity-triggering behaviors, highlighting cognitive complexity.", "conclusion": "AI has the potential to act as both an educator and teammate by providing adaptive feedback that sustains epistemic curiosity and engagement, indicating promise for future educational technologies."}}
{"id": "2506.23719", "pdf": "https://arxiv.org/pdf/2506.23719", "abs": "https://arxiv.org/abs/2506.23719", "authors": ["Alex Egg", "Martin Iglesias Goyanes", "Friso Kingma", "Andreu Mora", "Leandro von Werra", "Thomas Wolf"], "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic\nmulti-step data analysis tasks. DABstep comprises over 450 real-world\nchallenges derived from a financial analytics platform, requiring models to\ncombine code-based data processing with contextual reasoning over heterogeneous\ndocumentation. Each task demands an iterative, multi-step problem-solving\napproach, testing capabilities in data manipulation, cross-referencing multiple\nsources, and precise result reporting. The benchmark provides a factoid-style\nanswer format with automatic correctness checks for objective scoring at scale.\nWe evaluate leading LLM-based agents, revealing a substantial performance gap:\neven the best agent achieves only 14.55% accuracy on the hardest tasks. We\ndetail our benchmark's design, dataset composition, task formulation,\nevaluation protocol, report baseline results and analyze failure modes. DABstep\nis released with a public leaderboard and toolkit to accelerate research in\nautonomous data analysis.", "AI": {"tldr": "The paper introduces DABstep, a benchmark for evaluating AI agents on realistic multi-step data analysis tasks focusing on iterative problem-solving and contextual reasoning.", "motivation": "The authors aim to address the gap in evaluating AI agents on realistic, complex data analysis tasks that involve multi-step reasoning over documentation.", "method": "The benchmark involves over 450 real-world financial data analysis challenges, combining code-based processing, contextual reasoning, and a factoid-style system for automatic scoring.", "result": "Even the best large language model (LLM)-based agent achieved only 14.55% accuracy on the most challenging tasks, indicating substantial room for improvement.", "conclusion": "DABstep serves as a critical tool to assess and advance autonomous data analysis capabilities in AI agents through iterative reasoning and heterogeneous data sources."}}
{"id": "2506.23108", "pdf": "https://arxiv.org/pdf/2506.23108", "abs": "https://arxiv.org/abs/2506.23108", "authors": ["Zhiyuan Zhu", "Jian Wang", "Yong Jiang", "Tong Han", "Yuhao Huang", "Ang Zhang", "Kaiwen Yang", "Mingyuan Luo", "Zhe Liu", "Yaofei Duan", "Dong Ni", "Tianhong Tang", "Xin Yang"], "title": "Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound", "categories": ["cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Accurate carotid plaque grading (CPG) is vital to assess the risk of\ncardiovascular and cerebrovascular diseases. Due to the small size and high\nintra-class variability of plaque, CPG is commonly evaluated using a\ncombination of transverse and longitudinal ultrasound views in clinical\npractice. However, most existing deep learning-based multi-view classification\nmethods focus on feature fusion across different views, neglecting the\nimportance of representation learning and the difference in class features. To\naddress these issues, we propose a novel Corpus-View-Category Refinement\nFramework (CVC-RF) that processes information from Corpus-, View-, and\nCategory-levels, enhancing model performance. Our contribution is four-fold.\nFirst, to the best of our knowledge, we are the foremost deep learning-based\nmethod for CPG according to the latest Carotid Plaque-RADS guidelines. Second,\nwe propose a novel center-memory contrastive loss, which enhances the network's\nglobal modeling capability by comparing with representative cluster centers and\ndiverse negative samples at the Corpus level. Third, we design a cascaded\ndown-sampling attention module to fuse multi-scale information and achieve\nimplicit feature interaction at the View level. Finally, a parameter-free\nmixture-of-experts weighting strategy is introduced to leverage class\nclustering knowledge to weight different experts, enabling feature decoupling\nat the Category level. Experimental results indicate that CVC-RF effectively\nmodels global features via multi-level refinement, achieving state-of-the-art\nperformance in the challenging CPG task.", "AI": {"tldr": "This paper presents a novel framework called Corpus-View-Category Refinement Framework (CVC-RF) to enhance carotid plaque grading (CPG) using multi-level refinements for improved clinical assessments.", "motivation": "Accurate carotid plaque grading is critical for evaluating risks of cardiovascular and cerebrovascular diseases, but challenges such as small size and high variability of plaques complicate the task. Existing methods fail to adequately address representation learning and class feature differences.", "method": "The CVC-RF framework introduces three-level refinements: (1) Corpus-level with center-memory contrastive loss for global modeling, (2) View-level with a cascaded down-sampling attention module for multi-scale information fusion, and (3) Category-level with a parameter-free mixture-of-experts weighting strategy for feature decoupling.", "result": "The CVC-RF framework achieves state-of-the-art performance by effectively modeling global features through multi-level refinements, as demonstrated in experiments.", "conclusion": "This work sets a new benchmark in deep learning-based carotid plaque grading by improving representation learning and addressing differences in class features using a novel CVC-RF framework."}}
{"id": "2506.22481", "pdf": "https://arxiv.org/pdf/2506.22481", "abs": "https://arxiv.org/abs/2506.22481", "authors": ["Jacob Hobbs"], "title": "Theories of \"Sexuality\" in Natural Language Processing Bias Research", "categories": ["cs.CY", "cs.CL"], "comment": "17 pages, 9 tables, undergraduate senior thesis, submitted to The\n  Spectra: The Virginia Engineering and Science Research Journal", "summary": "In recent years, significant advancements in the field of Natural Language\nProcessing (NLP) have positioned commercialized language models as\nwide-reaching, highly useful tools. In tandem, there has been an explosion of\nmultidisciplinary research examining how NLP tasks reflect, perpetuate, and\namplify social biases such as gender and racial bias. A significant gap in this\nscholarship is a detailed analysis of how queer sexualities are encoded and\n(mis)represented by both NLP systems and practitioners. Following previous work\nin the field of AI fairness, we document how sexuality is defined and\noperationalized via a survey and analysis of 55 articles that quantify\nsexuality-based NLP bias. We find that sexuality is not clearly defined in a\nmajority of the literature surveyed, indicating a reliance on assumed or\nnormative conceptions of sexual/romantic practices and identities. Further, we\nfind that methods for extracting biased outputs from NLP technologies often\nconflate gender and sexual identities, leading to monolithic conceptions of\nqueerness and thus improper quantifications of bias. With the goal of improving\nsexuality-based NLP bias analyses, we conclude with recommendations that\nencourage more thorough engagement with both queer communities and\ninterdisciplinary literature.", "AI": {"tldr": "The paper investigates the misrepresentation of queer sexualities in NLP systems and provides insights to improve bias analysis.", "motivation": "The study aims to address the overlooked analysis of how queer sexualities are encoded and misrepresented by NLP systems.", "method": "Through a survey of 55 articles, it examines the definitions and methodologies for analyzing sexuality-based NLP biases.", "result": "The study finds a lack of clear definitions for sexuality and identifies conflations between sexual and gender identities that misrepresent queerness.", "conclusion": "Recommends engaging more deeply with queer communities and interdisciplinary literature to improve NLP bias analyses."}}
{"id": "2506.22521", "pdf": "https://arxiv.org/pdf/2506.22521", "abs": "https://arxiv.org/abs/2506.22521", "authors": ["Kaixiang Zhao", "Lincan Li", "Kaize Ding", "Neil Zhenqiang Gong", "Yue Zhao", "Yushun Dong"], "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Model extraction attacks pose significant security threats to deployed\nlanguage models, potentially compromising intellectual property and user\nprivacy. This survey provides a comprehensive taxonomy of LLM-specific\nextraction attacks and defenses, categorizing attacks into functionality\nextraction, training data extraction, and prompt-targeted attacks. We analyze\nvarious attack methodologies including API-based knowledge distillation, direct\nquerying, parameter recovery, and prompt stealing techniques that exploit\ntransformer architectures. We then examine defense mechanisms organized into\nmodel protection, data privacy protection, and prompt-targeted strategies,\nevaluating their effectiveness across different deployment scenarios. We\npropose specialized metrics for evaluating both attack effectiveness and\ndefense performance, addressing the specific challenges of generative language\nmodels. Through our analysis, we identify critical limitations in current\napproaches and propose promising research directions, including integrated\nattack methodologies and adaptive defense mechanisms that balance security with\nmodel utility. This work serves NLP researchers, ML engineers, and security\nprofessionals seeking to protect language models in production environments.", "AI": {"tldr": "The paper surveys model extraction attacks on large language models (LLMs) and defenses, offering a taxonomy and highlighting key research directions.", "motivation": "To address the growing threat of model extraction attacks on large language models, which compromise intellectual property and user privacy.", "method": "The authors categorize attacks (functionality extraction, training data extraction, prompt-targeted attacks) and defense strategies (model, data, and prompt protection), proposing specialized evaluation metrics.", "result": "The analysis identifies key limitations in current approaches and outlines new directions like integrated attack methods and adaptive defenses.", "conclusion": "The work provides a framework for understanding and improving the security of LLMs, beneficial to researchers and security professionals."}}
{"id": "2506.23726", "pdf": "https://arxiv.org/pdf/2506.23726", "abs": "https://arxiv.org/abs/2506.23726", "authors": ["Bartlomiej Sobieski", "Matthew Tivnan", "Yuang Wang", "Siyeop Yoon", "Pengfei Jin", "Dufan Wu", "Quanzheng Li", "Przemyslaw Biecek"], "title": "System-Embedded Diffusion Bridge Models", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Solving inverse problems -- recovering signals from incomplete or noisy\nmeasurements -- is fundamental in science and engineering. Score-based\ngenerative models (SGMs) have recently emerged as a powerful framework for this\ntask. Two main paradigms have formed: unsupervised approaches that adapt\npretrained generative models to inverse problems, and supervised bridge methods\nthat train stochastic processes conditioned on paired clean and corrupted data.\nWhile the former typically assume knowledge of the measurement model, the\nlatter have largely overlooked this structural information. We introduce System\nembedded Diffusion Bridge Models (SDBs), a new class of supervised bridge\nmethods that explicitly embed the known linear measurement system into the\ncoefficients of a matrix-valued SDE. This principled integration yields\nconsistent improvements across diverse linear inverse problems and demonstrates\nrobust generalization under system misspecification between training and\ndeployment, offering a promising solution to real-world applications.", "AI": {"tldr": "This paper introduces System Embedded Diffusion Bridge Models (SDBs), a supervised approach for solving linear inverse problems using score-based generative models.", "motivation": "The motivation is to improve upon existing approaches to inverse problems by integrating structural knowledge of the measurement system, which is often overlooked in supervised methods.", "method": "The authors propose a method that embeds the linear measurement system directly into the coefficients of a matrix-valued stochastic differential equation (SDE).", "result": "The proposed SDBs show consistent improvement in solving linear inverse problems and robust generalization under system misspecification.", "conclusion": "System Embedded Diffusion Bridge Models provide a more principled and effective way to leverage known measurement models, enabling enhanced performance and generalization for real-world inverse problems."}}
{"id": "2506.23115", "pdf": "https://arxiv.org/pdf/2506.23115", "abs": "https://arxiv.org/abs/2506.23115", "authors": ["Haonan Chen", "Hong Liu", "Yuping Luo", "Liang Wang", "Nan Yang", "Furu Wei", "Zhicheng Dou"], "title": "MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Homepage: https://haon-chen.github.io/MoCa/", "summary": "Multimodal embedding models, built upon causal Vision Language Models (VLMs),\nhave shown promise in various tasks. However, current approaches face three key\nlimitations: the use of causal attention in VLM backbones is suboptimal for\nembedding tasks; scalability issues due to reliance on high-quality labeled\npaired data for contrastive learning; and limited diversity in training\nobjectives and data. To address these issues, we propose MoCa, a two-stage\nframework for transforming pre-trained VLMs into effective bidirectional\nmultimodal embedding models. The first stage, Modality-aware Continual\nPre-training, introduces a joint reconstruction objective that simultaneously\ndenoises interleaved text and image inputs, enhancing bidirectional\ncontext-aware reasoning. The second stage, Heterogeneous Contrastive\nFine-tuning, leverages diverse, semantically rich multimodal data beyond simple\nimage-caption pairs to enhance generalization and alignment. Our method\naddresses the stated limitations by introducing bidirectional attention through\ncontinual pre-training, scaling effectively with massive unlabeled datasets via\njoint reconstruction objectives, and utilizing diverse multimodal data for\nenhanced representation robustness. Experiments demonstrate that MoCa\nconsistently improves performance across MMEB and ViDoRe-v2 benchmarks,\nachieving new state-of-the-art results, and exhibits strong scalability with\nboth model size and training data on MMEB.", "AI": {"tldr": "The paper introduces MoCa, a two-stage strategy to address limitations in multimodal embedding models, with improvements in bidirectional reasoning, scalability, and diversity using pre-trained Vision Language Models (VLMs).", "motivation": "Current multimodal embedding models using causal VLMs are suboptimal due to challenges in attention mechanisms, data scalability, and limited objective diversity. This paper aims to overcome these shortcomings.", "method": "The framework includes two stages: (1) Modality-aware Continual Pre-training, which denoises interleaved text and image inputs to boost bidirectional context understanding, and (2) Heterogeneous Contrastive Fine-tuning, utilizing diverse multimodal datasets to enhance alignment and generalization.", "result": "MoCa achieves new state-of-the-art performance across MMEB and ViDoRe-v2 benchmarks and demonstrates strong scalability with large models and massive datasets.", "conclusion": "MoCa successfully transforms pre-trained VLMs into robust bidirectional multimodal embedding models, addressing scalability, reasoning, and representational robustness challenges."}}
{"id": "2506.22493", "pdf": "https://arxiv.org/pdf/2506.22493", "abs": "https://arxiv.org/abs/2506.22493", "authors": ["Sadia Kamal", "Lalu Prasad Yadav Prakash", "S M Rafiuddin", "Mohammed Rakib", "Arunkumar Bagavathi", "Atriya Sen", "Sagnik Ray Choudhury"], "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "Political Compass Test (PCT) or similar questionnaires have been used to\nquantify LLM's political leanings. Building on a recent line of work that\nexamines the validity of PCT tests, we demonstrate that variation in standard\ngeneration parameters does not significantly impact the models' PCT scores.\nHowever, external factors such as prompt variations and fine-tuning\nindividually and in combination affect the same. Finally, we demonstrate that\nwhen models are fine-tuned on text datasets with higher political content than\nothers, the PCT scores are not differentially affected. This calls for a\nthorough investigation into the validity of PCT and similar tests, as well as\nthe mechanism by which political leanings are encoded in LLMs.", "AI": {"tldr": "The paper evaluates the reliability of political compass tests for determining language models' political orientations, addressing the impact of variations like prompts and fine-tuning.", "motivation": "The rise of political compass tests to gauge the biases of large language models necessitates an evaluation of these tools' reliability.", "method": "The authors analyze standard generation parameter effects, prompt variations, fine-tuning procedures, and datasets to measure their impact on the model's political leaning scores.", "result": "While standard generation parameters have little impact, prompt variations and fine-tuning significantly influence PCT outcomes. Fine-tuning on politically loaded datasets does not skew results.", "conclusion": "The reliability of PCT tools warrants further scrutiny, and understanding how LLMs encode political leanings is crucial for unbiased assessments."}}
{"id": "2506.22523", "pdf": "https://arxiv.org/pdf/2506.22523", "abs": "https://arxiv.org/abs/2506.22523", "authors": ["James Wen", "Sahil Nalawade", "Zhiwei Liang", "Catherine Bielick", "Marisa Ferrara Boston", "Alexander Chowdhury", "Adele Collin", "Luigi De Angelis", "Jacob Ellen", "Heather Frase", "Rodrigo R. Gameiro", "Juan Manuel Gutierrez", "Pooja Kadam", "Murat Keceli", "Srikanth Krishnamurthy", "Anne Kwok", "Yanan Lance Lu", "Heather Mattie", "Liam G. McCoy", "Katherine Miller", "Allison C. Morgan", "Marlene Louisa Moerig", "Trang Nguyen", "Alexander Owen-Post", "Alex D. Ruiz", "Sreekar Reddy Puchala", "Soujanya Samineni", "Takeshi Tohyama", "Varun Ullanat", "Carmine Valenza", "Camilo Velez", "Pengcheng Wang", "Anna Wuest", "Yuxiang Zhou", "Yingde Zhu", "Jason M. Johnson", "Jennifer Willcox", "Francis J. Vitiello", "Leo Anthony G. Celi", "Renato Umeton"], "title": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative AI is present in multiple industries. Dana-Farber Cancer\nInstitute, in partnership with Microsoft, has created an internal AI tool,\nGPT4DFCI. Together we hosted a red teaming event to assess whether the\nunderlying GPT models that support the tool would output copyrighted data. Our\nteams focused on reproducing content from books, news articles, scientific\narticles, and electronic health records. We found isolated instances where\nGPT4DFCI was able to identify copyrighted material and reproduce exact quotes\nfrom famous books which indicates that copyrighted material was in the training\ndata. The model was not able to reproduce content from our target news article,\nscientific article, or electronic health records. However, there were instances\nof fabrication. As a result of this event, a mitigation strategy is in\nproduction in GPT4DFCI v2.8.2, deployed on January 21, 2025. We hope this\nreport leads to similar events in which AI software tools are stress-tested to\nassess the perimeter of their legal and ethical usage.", "AI": {"tldr": "The abstract outlines results from a red-teaming event to analyze GPT4DFCI's capability to reproduce copyrighted content and fabrications. While exact quotations were reproduced for books, target news articles, scientific papers, and medical records showed no precise reproduction, but exhibited fabrication. A mitigation strategy has been implemented in the next version of the tool.", "motivation": "The paper aims to assess whether AI models, such as GPT4DFCI designed by Dana-Farber Cancer Institute in collaboration with Microsoft, could violate copyright laws by reproducing protected content.", "method": "Red teaming tests were conducted by intentionally probing the AI model to reproduce copyrighted material from sources like books, news, scientific articles, and electronic health records.", "result": "The tests showed that GPT4DFCI could output exact quotes from copyrighted books but failed to reproduce the content accurately from target news articles, scientific papers, and medical records. However, instances of fabricated data were observed.", "conclusion": "A mitigation strategy was rolled out in GPT4DFCI v2.8.2 to limit the reproduction of copyrighted and fabricated data. The event calls for similar testing to verify AI tools' compliance with ethical and legal standards."}}
{"id": "2506.23731", "pdf": "https://arxiv.org/pdf/2506.23731", "abs": "https://arxiv.org/abs/2506.23731", "authors": ["Michel Meintz", "Jan Dubi\u0144ski", "Franziska Boenisch", "Adam Dziedzic"], "title": "Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Image generative models have become increasingly popular, but training them\nrequires large datasets that are costly to collect and curate. To circumvent\nthese costs, some parties may exploit existing models by using the generated\nimages as training data for their own models. In general, watermarking is a\nvaluable tool for detecting unauthorized use of generated images. However, when\nthese images are used to train a new model, watermarking can only enable\ndetection if the watermark persists through training and remains identifiable\nin the outputs of the newly trained model - a property known as radioactivity.\nWe analyze the radioactivity of watermarks in images generated by diffusion\nmodels (DMs) and image autoregressive models (IARs). We find that existing\nwatermarking methods for DMs fail to retain radioactivity, as watermarks are\neither erased during encoding into the latent space or lost in the\nnoising-denoising process (during the training in the latent space). Meanwhile,\ndespite IARs having recently surpassed DMs in image generation quality and\nefficiency, no radioactive watermarking methods have been proposed for them. To\novercome this limitation, we propose the first watermarking method tailored for\nIARs and with radioactivity in mind - drawing inspiration from techniques in\nlarge language models (LLMs), which share IARs' autoregressive paradigm. Our\nextensive experimental evaluation highlights our method's effectiveness in\npreserving radioactivity within IARs, enabling robust provenance tracking, and\npreventing unauthorized use of their generated images.", "AI": {"tldr": "The paper addresses the issue of unauthorized use of generated images in training new models by proposing a watermarking method for image autoregressive models (IARs) that retains its detectability even after being used for training new models. It introduces the concept of radioactivity and evaluates the method effectively.", "motivation": "The motivation stems from the increasing popularity of image generative models and the high costs associated with dataset collection and curation. The need arises to address unauthorized usage of generated images for training new models.", "method": "The authors analyze existing methods for watermarking diffusion models (DMs) and find them inadequate regarding radioactivity. For IARs, the authors propose a novel radioactive watermarking technique inspired by large language models' methods, tailored for IARs' autoregressive model paradigm.", "result": "The experimental results demonstrate the proposed watermarking method's success in preserving radioactivity within IARs, ensuring robust tracking of provenance and deterring unauthorized use of generated images.", "conclusion": "The developed watermarking method emphasizes the importance of radioactivity in watermarking for IARs, successfully enabling provenance tracking and tackling misuse issues, outperforming existing watermarking methods for diffusion models."}}
{"id": "2506.23120", "pdf": "https://arxiv.org/pdf/2506.23120", "abs": "https://arxiv.org/abs/2506.23120", "authors": ["Zhenhua Ning", "Zhuotao Tian", "Shaoshuai Shi", "Guangming Lu", "Daojing He", "Wenjie Pei", "Li Jiang"], "title": "Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in point cloud perception have demonstrated remarkable\nprogress in scene understanding through vision-language alignment leveraging\nlarge language models (LLMs). However, existing methods may still encounter\nchallenges in handling complex instructions that require accurate spatial\nreasoning, even if the 3D point cloud data provides detailed spatial cues such\nas size and position for identifying the targets. To tackle this issue, we\npropose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based\nsegmentation framework. The framework emulates human cognitive processes by\ndecomposing spatial reasoning into two sequential stages: first identifying\nrelevant elements, then processing instructions guided by their associated\nvisual priors. Furthermore, acknowledging the inadequacy of existing datasets\nin complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based\nsegmentation dataset comprising 25,185 training samples and 3,966 validation\nsamples with precise annotations. Both quantitative and qualitative experiments\ndemonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud\nperception with stronger spatial reasoning capabilities, and we hope that they\ncan serve as a new baseline and benchmark for future work.", "AI": {"tldr": "The paper proposes a framework, R$^2$S, for reasoning-based segmentation of 3D point clouds and introduces the 3D ReasonSeg dataset to improve spatial reasoning in scene understanding.", "motivation": "Existing methods struggle with complex instructions that depend on accurate spatial reasoning despite 3D point cloud data having detailed spatial information.", "method": "The proposed approach, R$^2$S, mimics human reasoning by decomposing spatial reasoning into identifying relevant elements and processing instructions with visual priors. Additionally, a new dataset, 3D ReasonSeg, is created to address these issues.", "result": "Experiments show R$^2$S and 3D ReasonSeg enhance spatial reasoning capabilities in 3D point cloud perception.", "conclusion": "The R$^2$S framework and 3D ReasonSeg dataset are effective in addressing spatial reasoning challenges and can serve as benchmarks for future studies."}}
{"id": "2506.23132", "pdf": "https://arxiv.org/pdf/2506.23132", "abs": "https://arxiv.org/abs/2506.23132", "authors": ["Sophie Zhou", "Shu Kong"], "title": "Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval", "categories": ["cs.CV"], "comment": "to appear at AVSS'25", "summary": "Art plagiarism detection plays a crucial role in protecting artists'\ncopyrights and intellectual property, yet it remains a challenging problem in\nforensic analysis. In this paper, we address the task of recognizing\nplagiarized paintings and explaining the detected plagarisms by retrieving\nvisually similar authentic artworks. To support this study, we construct a\ndataset by collecting painting photos and synthesizing plagiarized versions\nusing generative AI, tailored to specific artists' styles. We first establish a\nbaseline approach using off-the-shelf features from the visual foundation model\nDINOv2 to retrieve the most similar images in the database and classify\nplagiarism based on a similarity threshold. Surprisingly, this non-learned\nmethod achieves a high recognition accuracy of 97.2\\% but suffers from low\nretrieval precision 29.0\\% average precision (AP). To improve retrieval\nquality, we finetune DINOv2 with a metric learning loss using positive and\nnegative sample pairs sampled in the database. The finetuned model greatly\nimproves retrieval performance by 12\\% AP over the baseline, though it\nunexpectedly results in a lower recognition accuracy (92.7\\%). We conclude with\ninsightful discussions and outline directions for future research.", "AI": {"tldr": "The paper aims to detect art plagiarism by retrieving similar artworks and explains the detected plagiarisms using a constructed dataset. Two methods are tested: a baseline using DINOv2 and a finetuned model with metric learning loss.", "motivation": "To address the difficult challenge of detecting plagiarized paintings and protecting artists' copyrights through explaining and identifying artwork similarities.", "method": "The authors employ DINOv2 as a visual foundation model to retrieve similar artworks and classify plagiarism. They then enhance retrieval precision by finetuning DINOv2 with metric learning loss.", "result": "Baseline DINOv2 achieved 97.2% recognition accuracy but low retrieval precision (29.0% AP). The finetuned model showed a 12% improvement in retrieval precision but lower recognition accuracy (92.7%).", "conclusion": "While the baseline method reached high recognition accuracy, it faltered in precision. The finetuning improved retrieval precision but led to reduced recognition accuracy. The outcomes highlight trade-offs and provide groundwork for future advancements."}}
{"id": "2506.23776", "pdf": "https://arxiv.org/pdf/2506.23776", "abs": "https://arxiv.org/abs/2506.23776", "authors": ["Jari Peeperkorn", "Johannes De Smedt", "Jochen De Weerdt"], "title": "Model-driven Stochastic Trace Clustering", "categories": ["cs.LG"], "comment": null, "summary": "Process discovery algorithms automatically extract process models from event\nlogs, but high variability often results in complex and hard-to-understand\nmodels. To mitigate this issue, trace clustering techniques group process\nexecutions into clusters, each represented by a simpler and more understandable\nprocess model. Model-driven trace clustering improves on this by assigning\ntraces to clusters based on their conformity to cluster-specific process\nmodels. However, most existing clustering techniques rely on either no process\nmodel discovery, or non-stochastic models, neglecting the frequency or\nprobability of activities and transitions, thereby limiting their capability to\ncapture real-world execution dynamics. We propose a novel model-driven trace\nclustering method that optimizes stochastic process models within each cluster.\nOur approach uses entropic relevance, a stochastic conformance metric based on\ndirectly-follows probabilities, to guide trace assignment. This allows\nclustering decisions to consider both structural alignment with a cluster's\nprocess model and the likelihood that a trace originates from a given\nstochastic process model. The method is computationally efficient, scales\nlinearly with input size, and improves model interpretability by producing\nclusters with clearer control-flow patterns. Extensive experiments on public\nreal-life datasets show that our method outperforms existing alternatives in\nrepresenting process behavior and reveals how clustering performance rankings\ncan shift when stochasticity is considered.", "AI": {"tldr": "The paper proposes a trace clustering method that uses stochastic process models and entropic relevance to improve clustering performance and model interpretability in process discovery.", "motivation": "Current trace clustering techniques fail to effectively incorporate stochasticity, limiting their ability to capture real-world execution dynamics in process discovery.", "method": "A model-driven trace clustering method optimized for stochastic process models, incorporating entropic relevance as a conformance metric to evaluate direct-follow probabilities.", "result": "The proposed method is computationally efficient, scales linearly with input size, improves interpretability, and outperforms existing techniques, particularly when stochasticity is considered.", "conclusion": "Considering stochastic elements in process models leads to more accurate clustering, better represents process behavior, and results in more interpretable models with clearer control-flow patterns."}}
{"id": "2506.23782", "pdf": "https://arxiv.org/pdf/2506.23782", "abs": "https://arxiv.org/abs/2506.23782", "authors": ["Xiaoyang Li", "Linwei Tao", "Haohui Lu", "Minjing Dong", "Junbin Gao", "Chang Xu"], "title": "Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance\non relational data; however, their confidence estimates often misalign with\nactual predictive correctness, posing significant limitations for deployment in\nsafety-critical settings. While existing graph-aware calibration methods seek\nto mitigate this limitation, they primarily depend on coarse one-hop\nstatistics, such as neighbor-predicted confidence, or latent node embeddings,\nthereby neglecting the fine-grained structural heterogeneity inherent in graph\ntopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a\npost-hoc calibration framework that assigns node-specific temperatures based on\ntunable heat-kernel graph wavelet features. Specifically, WATS harnesses the\nscalability and topology sensitivity of graph wavelets to refine confidence\nestimates, all without necessitating model retraining or access to neighboring\nlogits or predictions. Extensive evaluations across seven benchmark datasets\nwith varying graph structures and two GNN backbones demonstrate that WATS\nachieves the lowest Expected Calibration Error (ECE) among all compared\nmethods, outperforming both classical and graph-specific baselines by up to\n42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared\nwith graph-specific methods. Moreover, WATS remains computationally efficient,\nscaling well across graphs of diverse sizes and densities. Code will be\nreleased based on publication.", "AI": {"tldr": "The paper introduces Wavelet-Aware Temperature Scaling (WATS), a post-hoc calibration framework for Graph Neural Networks (GNNs), enabling improved confidence estimation using heat-kernel graph wavelet features. WATS enhances performance without model retraining or relying on coarse neighbor statistics.", "motivation": "Graph Neural Networks (GNNs) often lack reliable confidence estimates despite their strong predictive ability, limiting their use in safety-critical applications. Existing calibration methods fail to address the structural complexity of graph topology.", "method": "WATS uses node-specific temperatures derived from heat-kernel graph wavelet features in a post-hoc calibration manner. It avoids retraining models and does not require neighboring data, leveraging the scalability and sensitivity of graph wavelets.", "result": "Extensive evaluations on seven datasets and two GNN backbones show WATS achieves the lowest Expected Calibration Error (ECE), outperforming baseline methods by up to 42.3% in ECE and reducing calibration variance by an average of 17.24%.", "conclusion": "Wavelet-Aware Temperature Scaling (WATS) offers a computationally efficient and structurally aware calibration method, effectively bridging the gap in confidence estimation for GNNs while scaling robustly across various graph structures."}}
{"id": "2506.23138", "pdf": "https://arxiv.org/pdf/2506.23138", "abs": "https://arxiv.org/abs/2506.23138", "authors": ["Shiyu Wu", "Mingzhen Sun", "Weining Wang", "Yequan Wang", "Jing Liu"], "title": "VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "Since there exists a notable gap between user-provided and model-preferred\nprompts, generating high-quality and satisfactory images using diffusion models\noften requires prompt engineering to optimize user inputs. Current studies on\ntext-to-image prompt engineering can effectively enhance the style and\naesthetics of generated images. However, they often neglect the semantic\nalignment between generated images and user descriptions, resulting in visually\nappealing but content-wise unsatisfying outputs. In this work, we propose\nVisualPrompter, a novel training-free prompt engineering framework that refines\nuser inputs to model-preferred sentences. In particular, VisualPrompter\nutilizes an automatic self-reflection module to identify the missing concepts\nin generated images and a target-specific prompt optimization mechanism to\nrevise the prompts in a fine-grained manner. Extensive experiments demonstrate\nthe effectiveness of our VisualPrompter, which achieves new state-of-the-art\nperformance on multiple benchmarks for text-image alignment evaluation.\nAdditionally, our framework features a plug-and-play design, making it highly\nadaptable to various generative models.", "AI": {"tldr": "This paper introduces VisualPrompter, a tool to refine user prompts for better text-to-image alignment in diffusion models.", "motivation": "Address the gap between user-provided prompts and model-preferred prompts, which results in visually appealing but semantically mismatched images.", "method": "VisualPrompter employs self-reflection to detect missing concepts and optimizes prompts to align with model preferences.", "result": "Achieved state-of-the-art performance on benchmarks for text-image alignment evaluation.", "conclusion": "VisualPrompter effectively enhances semantic alignment of generated images and supports various generative models with its plug-and-play design."}}
{"id": "2506.23799", "pdf": "https://arxiv.org/pdf/2506.23799", "abs": "https://arxiv.org/abs/2506.23799", "authors": ["Jiongli Zhu", "Parjanya Prajakta Prashant", "Alex Cloninger", "Babak Salimi"], "title": "KAIROS: Scalable Model-Agnostic Data Valuation", "categories": ["cs.LG"], "comment": "19 pages, 9 figures", "summary": "Training data increasingly shapes not only model accuracy but also regulatory\ncompliance and market valuation of AI assets. Yet existing valuation methods\nremain inadequate: model-based techniques depend on a single fitted model and\ninherit its biases, while algorithm-based approaches such as Data Shapley\nrequire costly retrainings at web scale. Recent Wasserstein-based\nmodel-agnostic methods rely on approximations that misrank examples relative to\ntheir true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,\nmodel-agnostic valuation framework that assigns each example a distributional\ninfluence score: its contribution to the Maximum Mean Discrepancy (MMD) between\nthe empirical training distribution and a clean reference set. Unlike\nWasserstein surrogates, our MMD-based influence admits a closed-form solution\nthat faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,\nrequires no retraining, and naturally extends to conditional kernels for\nunified label- and feature-error detection. Moreover, KAIROS supports efficient\nonline updates: when a new batch of size m arrives, all scores can be updated\nin $O(mN)$ time, delivering up to 50x speedup without compromising ranking\nquality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks\nshow that KAIROS consistently outperforms state-of-the-art model-, Shapley-,\nand Wasserstein-based baselines in both accuracy and runtime. We provide\nrigorous theoretical guarantees, including symmetry for reproducible rankings\nand density-separation for interpretable thresholds.", "AI": {"tldr": "The paper introduces KAIROS, a model-agnostic data valuation framework that is efficient, accurate, and scalable, outperforming existing methods in utility ranking for training data.", "motivation": "Existing methods for data valuation are inadequate due to their dependence on biased models, costly retraining, or approximation errors in ranking, motivating the need for a scalable and reliable alternative.", "method": "KAIROS uses Maximum Mean Discrepancy (MMD)-based influence scores to estimate the utility of data points, avoiding retraining, achieving closed-form solutions, and ensuring efficient updates with theoretical guarantees.", "result": "KAIROS demonstrates superior performance over state-of-the-art methods in tasks involving noise, mislabeling, and poisoning, providing better accuracy, runtime efficiency, and reliable rankings.", "conclusion": "KAIROS is a robust and scalable solution for data valuation in AI pipelines, delivering significant advancements over current methods in both performance and practicality."}}
{"id": "2506.23150", "pdf": "https://arxiv.org/pdf/2506.23150", "abs": "https://arxiv.org/abs/2506.23150", "authors": ["Xinyue Liang", "Zhiyuan Ma", "Lingchen Sun", "Yanjun Guo", "Lei Zhang"], "title": "AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation", "categories": ["cs.CV"], "comment": null, "summary": "Single-image-to-3D models typically follow a sequential generation and\nreconstruction workflow. However, intermediate multi-view images synthesized by\npre-trained generation models often lack cross-view consistency (CVC),\nsignificantly degrading 3D reconstruction performance. While recent methods\nattempt to refine CVC by feeding reconstruction results back into the\nmulti-view generator, these approaches struggle with noisy and unstable\nreconstruction outputs that limit effective CVC improvement. We introduce\nAlignCVC, a novel framework that fundamentally re-frames single-image-to-3D\ngeneration through distribution alignment rather than relying on strict\nregression losses. Our key insight is to align both generated and reconstructed\nmulti-view distributions toward the ground-truth multi-view distribution,\nestablishing a principled foundation for improved CVC. Observing that generated\nimages exhibit weak CVC while reconstructed images display strong CVC due to\nexplicit rendering, we propose a soft-hard alignment strategy with distinct\nobjectives for generation and reconstruction models. This approach not only\nenhances generation quality but also dramatically accelerates inference to as\nfew as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC,\nseamlessly integrates various multi-view generation models with 3D\nreconstruction models. Extensive experiments demonstrate the effectiveness and\nefficiency of AlignCVC for single-image-to-3D generation.", "AI": {"tldr": "AlignCVC addresses cross-view consistency (CVC) issues in single-image-to-3D generation by aligning generated and reconstructed distributions, significantly boosting quality and reducing inference steps.", "motivation": "Current single-image-to-3D methods suffer from poor cross-view consistency in intermediate multi-view images, harming reconstruction performance and making refinement attempts impractical due to noisy outputs.", "method": "AlignCVC utilizes distribution alignment instead of strict regression losses. It employs a soft-hard alignment strategy targeting both generation and reconstruction models to enhance cross-view consistency and generation quality.", "result": "AlignCVC improves CVC, significantly accelerates inference (down to 4 steps), and integrates seamlessly with various multi-view generation and reconstruction models.", "conclusion": "AlignCVC establishes a reliable approach for single-image-to-3D generation by refining CVC through distribution alignment, showing effectiveness and efficiency in experiments."}}
{"id": "2506.23800", "pdf": "https://arxiv.org/pdf/2506.23800", "abs": "https://arxiv.org/abs/2506.23800", "authors": ["Chang Qi", "Matteo Forasassi", "Thomas Lukasiewicz", "Tommaso Salvatori"], "title": "Towards the Training of Deeper Predictive Coding Neural Networks", "categories": ["cs.LG"], "comment": "18 Pages, 7 figures", "summary": "Predictive coding networks trained with equilibrium propagation are neural\nmodels that perform inference through an iterative energy minimization process.\nPrevious studies have demonstrated their effectiveness in shallow\narchitectures, but show significant performance degradation when depth exceeds\nfive to seven layers. In this work, we show that the reason behind this\ndegradation is due to exponentially imbalanced errors between layers during\nweight updates, and predictions from the previous layer not being effective in\nguiding updates in deeper layers. We address the first issue by introducing two\nnovel methods to optimize the latent variables that use precision-weighting to\nre-balance the distribution of energy among layers during the `relaxation\nphase', and the second issue by proposing a novel weight update mechanism that\nreduces error accumulation in deeper layers. Empirically, we test our methods\non a large number of image classification tasks, resulting in large\nimprovements in test accuracy across networks with more than seven layers, with\nperformances comparable to those of backprop on similar models. These findings\nsuggest that a better understanding of the relaxation phase is important to\ntrain models using equilibrium propagation at scale, and open new possibilities\nfor their application in complex tasks.", "AI": {"tldr": "This paper identifies and resolves performance degradation issues in deep predictive coding networks using equilibrium propagation, achieving results comparable to backpropagation for models exceeding seven layers.", "motivation": "The paper aims to address the significant performance degradation observed in predictive coding networks with depth greater than five to seven layers, limiting their scalability and application in complex tasks.", "method": "The authors introduce two precision-weighting optimization methods for latent variable energy balancing during the relaxation phase and a novel weight update mechanism to mitigate error accumulation in deeper layers.", "result": "The proposed methods result in substantial test accuracy improvements on image classification tasks for deep networks, achieving performances comparable to backpropagation.", "conclusion": "Understanding and refining the relaxation phase is critical for scaling predictive coding networks trained with equilibrium propagation, paving the way for their use in more complex problems."}}
{"id": "2506.23151", "pdf": "https://arxiv.org/pdf/2506.23151", "abs": "https://arxiv.org/abs/2506.23151", "authors": ["Vladislav Bargatin", "Egor Chistov", "Alexander Yakovenko", "Dmitriy Vatolin"], "title": "MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted at ICCV 2025", "summary": "Recent advances in optical flow estimation have prioritized accuracy at the\ncost of growing GPU memory consumption, particularly for high-resolution\n(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical\nflow method that identifies a favorable trade-off between multi-frame\nestimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU\nmemory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely\npositions our method to be trained at native 1080p without the need for\ncropping or downsampling. We systematically revisit design choices from\nRAFT-like architectures, integrating reduced correlation volumes and\nhigh-resolution training protocols alongside multi-frame estimation, to achieve\nstate-of-the-art performance across multiple benchmarks while substantially\nreducing memory overhead. Our method outperforms more resource-intensive\nalternatives in both accuracy and runtime efficiency, validating its robustness\nfor flow estimation at high resolutions. At the time of submission, our method\nranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,\nleads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the\nbest Fl-all error on KITTI-2015 at 2.94%. The code is available at\nhttps://github.com/msu-video-group/memfof.", "AI": {"tldr": "The study introduces MEMFOF, a memory-efficient multi-frame optical flow estimation method that achieves state-of-the-art accuracy and efficiency for high-resolution inputs while requiring minimal GPU memory.", "motivation": "The uncontrolled growth in GPU memory consumption for high-resolution optical flow estimation demands solutions that balance accuracy with memory efficiency.", "method": "The method leverages reduced correlation volumes, high-resolution training protocols, and multi-frame estimation, integrated within RAFT-like architectures, to minimize GPU memory usage and boost performance.", "result": "MEMFOF achieves high accuracy with minimal memory overhead, requiring only 2.09 GB for 1080p runtime and 28.5 GB during training. It outperforms resource-intensive methods on benchmarks like Spring, Sintel (clean), and KITTI-2015.", "conclusion": "MEMFOF demonstrates a significant advancement in high-resolution optical flow estimation by achieving a favorable trade-off between performance and GPU memory efficiency. Its state-of-the-art results and code availability position it as a reliable tool for related tasks."}}
{"id": "2506.22580", "pdf": "https://arxiv.org/pdf/2506.22580", "abs": "https://arxiv.org/abs/2506.22580", "authors": ["Vasilis Siomos", "Jonathan Passerat-Palmbach", "Giacomo Tarroni"], "title": "FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 2 figures, Accepted at MICCAI 2025", "summary": "Federated learning is a decentralized training approach that keeps data under\nstakeholder control while achieving superior performance over isolated\ntraining. While inter-institutional feature discrepancies pose a challenge in\nall federated settings, medical imaging is particularly affected due to diverse\nimaging devices and population variances, which can diminish the global model's\neffectiveness. Existing aggregation methods generally fail to adapt across\nvaried circumstances. To address this, we propose FedCLAM, which integrates\n\\textit{client-adaptive momentum} terms derived from each client's loss\nreduction during local training, as well as a \\textit{personalized dampening\nfactor} to curb overfitting. We further introduce a novel \\textit{intensity\nalignment} loss that matches predicted and ground-truth foreground\ndistributions to handle heterogeneous image intensity profiles across\ninstitutions and devices. Extensive evaluations on two datasets show that\nFedCLAM surpasses eight cutting-edge methods in medical segmentation tasks,\nunderscoring its efficacy. The code is available at\nhttps://github.com/siomvas/FedCLAM.", "AI": {"tldr": "FedCLAM, a novel Federated Learning approach, addresses client-specific challenges and image heterogeneity in medical imaging by introducing adaptive momentum, personalized dampening, and intensity alignment loss.", "motivation": "To overcome challenges of device and population variability in medical imaging\u2014which degrade federated learning model performance\u2014and improve existing aggregation methods that lack adaptability.", "method": "FedCLAM introduces client-adaptive momentum terms based on client-specific loss reduction, a personalized dampening factor to reduce overfitting, and intensity alignment loss to standardize heterogeneous image intensity distributions.", "result": "FedCLAM outperforms eight state-of-the-art methods in medical segmentation tasks across two datasets, demonstrating its effectiveness.", "conclusion": "The proposed FedCLAM framework enhances federated learning by adapting to inter-institutional disparities and image heterogeneity, thus improving medical imaging model performance."}}
{"id": "2506.23802", "pdf": "https://arxiv.org/pdf/2506.23802", "abs": "https://arxiv.org/abs/2506.23802", "authors": ["Konstantinos Bourazas", "Savvas Papaioannou", "Panayiotis Kolios"], "title": "Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations", "categories": ["cs.LG"], "comment": "23rd European Control Conference (ECC 2025), Thessaloniki, Greece,\n  24-27 June 2025", "summary": "In this work we introduce a novel adaptive anomaly detection framework\nspecifically designed for monitoring sequential random finite set (RFS)\nobservations. Our approach effectively distinguishes between In-Control data\n(normal) and Out-Of-Control data (anomalies) by detecting deviations from the\nexpected statistical behavior of the process. The primary contributions of this\nstudy include the development of an innovative RFS-based framework that not\nonly learns the normal behavior of the data-generating process online but also\ndynamically adapts to behavioral shifts to accurately identify abnormal point\npatterns. To achieve this, we introduce a new class of RFS-based posterior\ndistributions, named Power Discounting Posteriors (PD), which facilitate\nadaptation to systematic changes in data while enabling anomaly detection of\npoint pattern data through a novel predictive posterior density function. The\neffectiveness of the proposed approach is demonstrated by extensive qualitative\nand quantitative simulation experiments.", "AI": {"tldr": "The paper presents a new adaptive anomaly detection framework for sequential Random Finite Set (RFS) data, which learns normal behaviors and detects anomalies using Power Discounting posterior distributions.", "motivation": "To address the challenge of monitoring and detecting anomalies in sequential random finite set observations in dynamic environments.", "method": "The method involves developing RFS-based Power Discounting Posteriors that can adapt to systematic data changes and perform anomaly detection using a novel predictive posterior density function.", "result": "The approach's efficacy is validated through extensive simulations demonstrating its qualitative and quantitative effectiveness.", "conclusion": "The proposed RFS-based framework proves effective for adaptive anomaly detection, robustly identifying abnormal behaviors in point pattern data."}}
{"id": "2506.23153", "pdf": "https://arxiv.org/pdf/2506.23153", "abs": "https://arxiv.org/abs/2506.23153", "authors": ["Huiqiang Sun", "Xingyi Li", "Juewen Peng", "Liao Shen", "Zhiguo Cao", "Ke Xian", "Guosheng Lin"], "title": "Dynamic View Synthesis from Small Camera Motion Videos", "categories": ["cs.CV"], "comment": "Accepted by TVCG", "summary": "Novel view synthesis for dynamic $3$D scenes poses a significant challenge.\nMany notable efforts use NeRF-based approaches to address this task and yield\nimpressive results. However, these methods rely heavily on sufficient motion\nparallax in the input images or videos. When the camera motion range becomes\nlimited or even stationary (i.e., small camera motion), existing methods\nencounter two primary challenges: incorrect representation of scene geometry\nand inaccurate estimation of camera parameters. These challenges make prior\nmethods struggle to produce satisfactory results or even become invalid. To\naddress the first challenge, we propose a novel Distribution-based Depth\nRegularization (DDR) that ensures the rendering weight distribution to align\nwith the true distribution. Specifically, unlike previous methods that use\ndepth loss to calculate the error of the expectation, we calculate the\nexpectation of the error by using Gumbel-softmax to differentiably sample\npoints from discrete rendering weight distribution. Additionally, we introduce\nconstraints that enforce the volume density of spatial points before the object\nboundary along the ray to be near zero, ensuring that our model learns the\ncorrect geometry of the scene. To demystify the DDR, we further propose a\nvisualization tool that enables observing the scene geometry representation at\nthe rendering weight level. For the second challenge, we incorporate camera\nparameter learning during training to enhance the robustness of our model to\ncamera parameters. We conduct extensive experiments to demonstrate the\neffectiveness of our approach in representing scenes with small camera motion\ninput, and our results compare favorably to state-of-the-art methods.", "AI": {"tldr": "The paper addresses challenges in novel view synthesis for dynamic 3D scenes with limited camera motion by introducing Distribution-based Depth Regularization (DDR) and enhanced camera parameter learning, outperforming state-of-the-art methods.", "motivation": "Current NeRF-based methods for novel view synthesis struggle under small camera motion due to inaccurate scene geometry and camera parameters.", "method": "The paper introduces DDR to align rendering weight distribution with true distribution, leveraging Gumbel-softmax sampling, and enforces volume density constraints for accurate geometry. It also includes camera parameter learning during training.", "result": "Experimental results show that the proposed approach handles scenarios with limited camera motion effectively, outperforming existing methods in terms of scene representation.", "conclusion": "Their approach improves novel view synthesis for cases with restricted camera motion, offering robust scene geometry and camera parameter estimation alongside visualization tools."}}
{"id": "2506.23803", "pdf": "https://arxiv.org/pdf/2506.23803", "abs": "https://arxiv.org/abs/2506.23803", "authors": ["Dmitry Kovalev"], "title": "SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type\npreconditioning. Our contributions are twofold. First, we develop a unified\nconvergence analysis of SGD with adaptive preconditioning under anisotropic or\nmatrix smoothness and noise assumptions. This allows us to recover\nstate-of-the-art convergence results for several popular adaptive gradient\nmethods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In\naddition, we establish the fundamental connection between two recently proposed\nalgorithms, Scion and DASGO, and provide the first theoretical guarantees for\nthe latter. Second, we show that the convergence of methods like AdaGrad and\nDASGO can be provably accelerated beyond the best-known rates using Nesterov\nmomentum. Consequently, we obtain the first theoretical justification that\nAdaGrad-type algorithms can simultaneously benefit from both diagonal\npreconditioning and momentum, which may provide an ultimate explanation for the\npractical efficiency of Adam.", "AI": {"tldr": "This paper revisits SGD with AdaGrad-type preconditioning, addressing its convergence and introducing novel accelerations using Nesterov momentum.", "motivation": "To analyze and improve SGD with adaptive preconditioning methods, like AdaGrad, to enhance their performance and efficiency.", "method": "The paper develops a unified convergence theory under specific smoothness/noise assumptions, explores connections between recent algorithms, and incorporates Nesterov momentum for acceleration.", "result": "It recovers state-of-the-art results for many adaptive gradient methods, establishes connections among algorithms, and demonstrates provable acceleration.", "conclusion": "AdaGrad-type methods can benefit from both diagonal preconditioning and momentum, providing insight into their practical effectiveness, such as in Adam optimizer."}}
{"id": "2506.23156", "pdf": "https://arxiv.org/pdf/2506.23156", "abs": "https://arxiv.org/abs/2506.23156", "authors": ["Jiale Chen"], "title": "Self-Supervised Contrastive Learning for Multi-Label Images", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning (SSL) has demonstrated its effectiveness in learning\nrepresentations through comparison methods that align with human intuition.\nHowever, mainstream SSL methods heavily rely on high body datasets with single\nlabel, such as ImageNet, resulting in intolerable pre-training overhead.\nBesides, more general multi-label images are frequently overlooked in SSL,\ndespite their potential for richer semantic information and broader\napplicability in downstream scenarios. Therefore, we tailor the mainstream SSL\napproach to guarantee excellent representation learning capabilities using\nfewer multi-label images. Firstly, we propose a block-wise augmentation module\naimed at extracting additional potential positive view pairs from multi-label\nimages. Subsequently, an image-aware contrastive loss is devised to establish\nconnections between these views, thereby facilitating the extraction of\nsemantically consistent representations. Comprehensive linear fine-tuning and\ntransfer learning validate the competitiveness of our approach despite\nchallenging sample quality and quantity.", "AI": {"tldr": "The paper presents a self-supervised learning (SSL) method tailored for multi-label images with fewer data by introducing block-wise augmentation and image-aware contrastive loss to improve representation learning.", "motivation": "Mainstream SSL methods are designed for single-label image datasets (e.g., ImageNet) and suffer from high pre-training overhead. Multi-label images, which carry richer semantic information, are often neglected despite their potential in broader scenarios.", "method": "Proposes a block-wise augmentation module to create more potential positive view pairs from multi-label images. This is combined with an image-aware contrastive loss to align views for semantically consistent representations.", "result": "The approach showed competitive performance through linear fine-tuning and transfer learning evaluations, even when working with low-quality and small-sample datasets.", "conclusion": "The proposed SSL method effectively addresses the challenges of learning representations from multi-label images, demonstrating efficiency and competitiveness with fewer data."}}
{"id": "2506.23824", "pdf": "https://arxiv.org/pdf/2506.23824", "abs": "https://arxiv.org/abs/2506.23824", "authors": ["Durgesh Singh", "Ahcene Boubekki", "Robert Jenssen", "Michael C. Kampffmeyer"], "title": "Supercm: Revisiting Clustering for Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The development of semi-supervised learning (SSL) has in recent years largely\nfocused on the development of new consistency regularization or entropy\nminimization approaches, often resulting in models with complex training\nstrategies to obtain the desired results. In this work, we instead propose a\nnovel approach that explicitly incorporates the underlying clustering\nassumption in SSL through extending a recently proposed differentiable\nclustering module. Leveraging annotated data to guide the cluster centroids\nresults in a simple end-to-end trainable deep SSL approach. We demonstrate that\nthe proposed model improves the performance over the supervised-only baseline\nand show that our framework can be used in conjunction with other SSL methods\nto further boost their performance.", "AI": {"tldr": "This paper proposes a novel semi-supervised learning (SSL) method combining clustering and simplicity.", "motivation": "Recent SSL advancements rely heavily on complex methods like consistency regularization, untapped explicit clustering opportunities.", "method": "The proposed method uses a differentiable clustering module guided by labeled data in an end-to-end framework.", "result": "The model outperforms a supervised-only baseline and complements existing SSL techniques.", "conclusion": "Incorporating clustering-based strategies simplifies SSL training while improving performance, with potential compatibility for enhancing other methods."}}
{"id": "2506.23157", "pdf": "https://arxiv.org/pdf/2506.23157", "abs": "https://arxiv.org/abs/2506.23157", "authors": ["Hanyu Zhou", "Haonan Wang", "Haoyue Liu", "Yuxing Duan", "Luxin Yan", "Gim Hee Lee"], "title": "STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene", "categories": ["cs.CV"], "comment": null, "summary": "High-dynamic scene reconstruction aims to represent static background with\nrigid spatial features and dynamic objects with deformed continuous\nspatiotemporal features. Typically, existing methods adopt unified\nrepresentation model (e.g., Gaussian) to directly match the spatiotemporal\nfeatures of dynamic scene from frame camera. However, this unified paradigm\nfails in the potential discontinuous temporal features of objects due to frame\nimaging and the heterogeneous spatial features between background and objects.\nTo address this issue, we disentangle the spatiotemporal features into various\nlatent representations to alleviate the spatiotemporal mismatching between\nbackground and objects. In this work, we introduce event camera to compensate\nfor frame camera, and propose a spatiotemporal-disentangled Gaussian splatting\nframework for high-dynamic scene reconstruction. As for dynamic scene, we\nfigure out that background and objects have appearance discrepancy in\nframe-based spatial features and motion discrepancy in event-based temporal\nfeatures, which motivates us to distinguish the spatiotemporal features between\nbackground and objects via clustering. As for dynamic object, we discover that\nGaussian representations and event data share the consistent spatiotemporal\ncharacteristic, which could serve as a prior to guide the spatiotemporal\ndisentanglement of object Gaussians. Within Gaussian splatting framework, the\ncumulative scene-object disentanglement can improve the spatiotemporal\ndiscrimination between background and objects to render the time-continuous\ndynamic scene. Extensive experiments have been performed to verify the\nsuperiority of the proposed method.", "AI": {"tldr": "The paper presents a novel framework addressing mismatched spatiotemporal features by disentangling latent representations for static backgrounds and dynamic objects using event and frame cameras.", "motivation": "Existing methods struggle with mismatched spatiotemporal features between backgrounds and objects in dynamic scene reconstruction.", "method": "Introducing event cameras and using a spatiotemporal-disentangled Gaussian splatting framework for clustering and manipulating scene-object representations.", "result": "The proposed method demonstrates improved spatiotemporal discrimination between backgrounds and objects in dynamic scenes.", "conclusion": "Cumulative disentanglement effectively renders time-continuous dynamic scenes, verified through extensive experiments showcasing the method\u2019s superiority."}}
{"id": "2506.23843", "pdf": "https://arxiv.org/pdf/2506.23843", "abs": "https://arxiv.org/abs/2506.23843", "authors": ["Joris Bekkers"], "title": "EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment", "categories": ["cs.LG"], "comment": null, "summary": "Understanding team formations and player positioning is crucial for tactical\nanalysis in football (soccer). This paper presents a flexible method for\nformation recognition and player position assignment in football using\npredefined static formation templates and cost minimization from spatiotemporal\ntracking data, called EFPI. Our approach employs linear sum assignment to\noptimally match players to positions within a set of template formations by\nminimizing the total distance between actual player locations and template\npositions, subsequently selecting the formation with the lowest assignment\ncost. To improve accuracy, we scale actual player positions to match the\ndimensions of these formation templates in both width and length. While the\nmethod functions effectively on individual frames, it extends naturally to\nlarger game segments such as complete periods, possession sequences or specific\nintervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we\nincorporate an optional stability parameter that prevents unnecessary formation\nchanges when assignment costs differ only marginally between time segments.\nEFPI is available as open-source code through the unravelsports Python package.", "AI": {"tldr": "This paper introduces EFPI, a method for recognizing football formations using spatiotemporal data and cost minimization techniques.", "motivation": "The study aims to improve tactical analysis in football by providing a reliable way to identify team formations and player positions systematically.", "method": "The method involves using static formation templates, scaling player positions to fit templates, employing linear sum assignment for position matching, and minimizing costs to determine the formation.", "result": "EFPI effectively identifies team formations and player positions from tracking data, working for both individual frames and extended game sequences.", "conclusion": "The EFPI method is an accurate, flexible, and open-source solution for formation recognition in football, supporting both individual and extended time analyses."}}
{"id": "2506.23189", "pdf": "https://arxiv.org/pdf/2506.23189", "abs": "https://arxiv.org/abs/2506.23189", "authors": ["Mustafa Hakan Kara", "Aysegul Dundar", "U\u011fur G\u00fcd\u00fckbay"], "title": "Trident: Detecting Face Forgeries with Adversarial Triplet Learning", "categories": ["cs.CV"], "comment": "11 pages, 3 figures, and 7 tables", "summary": "As face forgeries generated by deep neural networks become increasingly\nsophisticated, detecting face manipulations in digital media has posed a\nsignificant challenge, underscoring the importance of maintaining digital media\nintegrity and combating visual disinformation. Current detection models,\npredominantly based on supervised training with domain-specific data, often\nfalter against forgeries generated by unencountered techniques. In response to\nthis challenge, we introduce \\textit{Trident}, a face forgery detection\nframework that employs triplet learning with a Siamese network architecture for\nenhanced adaptability across diverse forgery methods. \\textit{Trident} is\ntrained on curated triplets to isolate nuanced differences of forgeries,\ncapturing fine-grained features that distinguish pristine samples from\nmanipulated ones while controlling for other variables. To further enhance\ngeneralizability, we incorporate domain-adversarial training with a forgery\ndiscriminator. This adversarial component guides our embedding model towards\nforgery-agnostic representations, improving its robustness to unseen\nmanipulations. In addition, we prevent gradient flow from the classifier head\nto the embedding model, avoiding overfitting induced by artifacts peculiar to\ncertain forgeries. Comprehensive evaluations across multiple benchmarks and\nablation studies demonstrate the effectiveness of our framework. We will\nrelease our code in a GitHub repository.", "AI": {"tldr": "The paper introduces 'Trident,' a deep learning framework for detecting face forgeries using triplet learning in a Siamese network with advanced training techniques for improved adaptability and robustness.", "motivation": "As face manipulation technologies become more advanced, detecting forgeries has become challenging, especially against techniques unseen during training.", "method": "Trident employs a Siamese network architecture trained with triplet learning and domain-adversarial training. It also isolates fine-grained features and prevents gradient flow to enhance generalizability and robustness.", "result": "Evaluations and ablation studies show that Trident is effective across multiple benchmarks in detecting diverse face forgeries.", "conclusion": "Trident offers significant improvements in detecting face forgeries, particularly against unseen manipulation methods, and its code will be publicly released for further use."}}
{"id": "2506.23845", "pdf": "https://arxiv.org/pdf/2506.23845", "abs": "https://arxiv.org/abs/2506.23845", "authors": ["Kenny Peng", "Rajiv Movva", "Jon Kleinberg", "Emma Pierson", "Nikhil Garg"], "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "While sparse autoencoders (SAEs) have generated significant excitement, a\nseries of negative results have added to skepticism about their usefulness.\nHere, we establish a conceptual distinction that reconciles competing\nnarratives surrounding SAEs. We argue that while SAEs may be less effective for\nacting on known concepts, SAEs are powerful tools for discovering unknown\nconcepts. This distinction cleanly separates existing negative and positive\nresults, and suggests several classes of SAE applications. Specifically, we\noutline use cases for SAEs in (i) ML interpretability, explainability,\nfairness, auditing, and safety, and (ii) social and health sciences.", "AI": {"tldr": "Sparse autoencoders (SAEs) are useful for discovering unknown concepts, despite skepticism about their effectiveness for acting on known concepts.", "motivation": "To reconcile conflicting views about the usefulness of sparse autoencoders by clarifying their strengths and limitations in distinct application areas.", "method": "The paper categorizes the roles of SAEs into analyzing known versus discovering unknown concepts and highlights their utility in specific domains like ML fairness and health sciences.", "result": "The authors show that SAEs are powerful for applications such as ML interpretability, fairness, safety, and social/health sciences while addressing existing skepticism.", "conclusion": "SAEs should be viewed as tools for discovery in specific domains, rather than universally effective for all purposes, which resolves prior conflicting narratives."}}
{"id": "2506.23196", "pdf": "https://arxiv.org/pdf/2506.23196", "abs": "https://arxiv.org/abs/2506.23196", "authors": ["Mona Ahmadian", "Amir Shirian", "Frank Guerin", "Andrew Gilbert"], "title": "DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Real-world videos often contain overlapping events and complex temporal\ndependencies, making multimodal interaction modeling particularly challenging.\nWe introduce DEL, a framework for dense semantic action localization, aiming to\naccurately detect and classify multiple actions at fine-grained temporal\nresolutions in long untrimmed videos. DEL consists of two key modules: the\nalignment of audio and visual features that leverage masked self-attention to\nenhance intra-mode consistency and a multimodal interaction refinement module\nthat models cross-modal dependencies across multiple scales, enabling\nhigh-level semantics and fine-grained details. Our method achieves\nstate-of-the-art performance on multiple real-world Temporal Action\nLocalization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and\nEPIC-Kitchens-100, surpassing previous approaches with notable average mAP\ngains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.", "AI": {"tldr": "This paper introduces DEL, a framework designed for dense semantic action localization in real-world untrimmed videos. Using advanced multimodal interaction modeling techniques, it achieves state-of-the-art performance across various temporal action localization datasets.", "motivation": "Real-world videos pose complex challenges due to overlapping events and intricate temporal dependencies. This necessitates robust methods for comprehensive action localization across different modalities.", "method": "DEL framework employs two key modules: 1) masked self-attention for aligning intra-mode audio-visual features, and 2) a multimodal interaction refinement module that models cross-modal dependencies at multiple scales, capturing both high-level semantics and fine-grained details.", "result": "DEL demonstrates superior average performance compared to previous methods, showcasing significant mAP improvements across Temporal Action Localization datasets: UnAV-100 (+3.3%), THUMOS14 (+2.6%), ActivityNet 1.3 (+1.2%), EPIC-Kitchens-100 verbs (+1.7%) and nouns (+1.4%).", "conclusion": "DEL proves to be an effective and scalable solution for dense semantic action localization in real-world untrimmed videos, offering significant advancements in state-of-the-art multimodal interaction modeling."}}
{"id": "2506.23872", "pdf": "https://arxiv.org/pdf/2506.23872", "abs": "https://arxiv.org/abs/2506.23872", "authors": ["Eduard Buss", "Till Aust", "Heiko Hamann"], "title": "When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems", "categories": ["cs.LG"], "comment": "Submitted and Accepted at the 14th international conference on\n  biomimetic and biohybrid systems (Living Machines)", "summary": "Living plants, while contributing to ecological balance and climate\nregulation, also function as natural sensors capable of transmitting\ninformation about their internal physiological states and surrounding\nconditions. This rich source of data provides potential for applications in\nenvironmental monitoring and precision agriculture. With integration into\nbiohybrid systems, we establish novel channels of physiological signal flow\nbetween living plants and artificial devices. We equipped *Hedera helix* with a\nplant-wearable device called PhytoNode to continuously record the plant's\nelectrophysiological activity. We deployed plants in an uncontrolled outdoor\nenvironment to map electrophysiological patterns to environmental conditions.\nOver five months, we collected data that we analyzed using state-of-the-art and\nautomated machine learning (AutoML). Our classification models achieve high\nperformance, reaching macro F1 scores of up to 95 percent in binary tasks.\nAutoML approaches outperformed manual tuning, and selecting subsets of\nstatistical features further improved accuracy. Our biohybrid living system\nmonitors the electrophysiology of plants in harsh, real-world conditions. This\nwork advances scalable, self-sustaining, and plant-integrated living biohybrid\nsystems for sustainable environmental monitoring.", "AI": {"tldr": "The study integrates plants into a biohybrid system using a device (PhytoNode) to monitor plant electrophysiology for environmental applications, achieving high classification accuracy with automated machine learning.", "motivation": "To harness plants' natural sensor abilities for environmental monitoring and precision agriculture by linking their biological signals to artificial devices.", "method": "Developed the PhytoNode wearable device to record plant electrophysiological signals, deploying *Hedera helix* outdoors for five months and analyzing the data with automated machine learning models.", "result": "Achieved classification performance with macro F1 scores up to 95%, with AutoML surpassing manual methods, demonstrating improved accuracy through feature selection.", "conclusion": "This work demonstrates scalable plant-based biohybrid systems suitable for monitoring environmental conditions in real-world, outdoor settings."}}
{"id": "2506.23202", "pdf": "https://arxiv.org/pdf/2506.23202", "abs": "https://arxiv.org/abs/2506.23202", "authors": ["Qilin Shu", "Qixian Zhang", "Qi Zhang", "Hongyun Zhang", "Duoqian Miao", "Cairong Zhao"], "title": "Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing", "categories": ["cs.CV"], "comment": null, "summary": "The person search task aims to locate a target person within a set of scene\nimages. In recent years, transformer-based models in this field have made some\nprogress. However, they still face three primary challenges: 1) the\nself-attention mechanism tends to suppress high-frequency components in the\nfeatures, which severely impacts model performance; 2) the computational cost\nof transformers is relatively high. To address these issues, we propose a novel\nHigh-frequency Augmentation and Multi-Wave mixing (HAMW) method for person\nsearch. HAMW is designed to enhance the discriminative feature extraction\ncapabilities of transformers while reducing computational overhead and\nimproving efficiency. Specifically, we develop a three-stage framework that\nprogressively optimizes both detection and re-identification performance. Our\nmodel enhances the perception of high-frequency features by learning from\naugmented inputs containing additional high-frequency components. Furthermore,\nwe replace the self-attention layers in the transformer with a strategy based\non multi-level Haar wavelet fusion to capture multi-scale features. This not\nonly lowers the computational complexity but also alleviates the suppression of\nhigh-frequency features and enhances the ability to exploit multi-scale\ninformation. Extensive experiments demonstrate that HAMW achieves\nstate-of-the-art performance on both the CUHK-SYSU and PRW datasets.", "AI": {"tldr": "The paper proposes the HAMW method for person search, addressing high-frequency feature suppression and computational inefficiency in transformers.", "motivation": "To overcome limitations in existing transformer-based models for person search, namely, suppression of high-frequency features and high computational cost.", "method": "The proposed HAMW framework includes high-frequency augmentation for enhanced feature learning and uses multi-level Haar wavelet fusion to replace self-attention layers, reducing computational complexity and improving feature discrimination.", "result": "HAMW outperforms existing methods, achieving state-of-the-art results on CUHK-SYSU and PRW datasets.", "conclusion": "HAMW effectively solves key challenges in transformer-based person search models, enhancing performance and efficiency."}}
{"id": "2506.23219", "pdf": "https://arxiv.org/pdf/2506.23219", "abs": "https://arxiv.org/abs/2506.23219", "authors": ["Jie Feng", "Shengyuan Wang", "Tianhui Liu", "Yanxin Xi", "Yong Li"], "title": "UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted by ICCV 2025", "summary": "Urban research involves a wide range of scenarios and tasks that require the\nunderstanding of multi-modal data. Current methods often focus on specific data\ntypes and lack a unified framework in urban field for processing them\ncomprehensively. The recent success of multi-modal large language models\n(MLLMs) presents a promising opportunity to overcome this limitation. In this\npaper, we introduce $\\textit{UrbanLLaVA}$, a multi-modal large language model\ndesigned to process these four types of data simultaneously and achieve strong\nperformance across diverse urban tasks compared with general MLLMs. In\n$\\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset\nencompassing both single-modal and cross-modal urban data, spanning from\nlocation view to global view of urban environment. Additionally, we propose a\nmulti-stage training framework that decouples spatial reasoning enhancement\nfrom domain knowledge learning, thereby improving the compatibility and\ndownstream performance of $\\textit{UrbanLLaVA}$ across diverse urban tasks.\nFinally, we also extend existing benchmark for urban research to assess the\nperformance of MLLMs across a wide range of urban tasks. Experimental results\nfrom three cities demonstrate that $\\textit{UrbanLLaVA}$ outperforms\nopen-source and proprietary MLLMs in both single-modal tasks and complex\ncross-modal tasks and shows robust generalization abilities across cities.\nSource codes and data are openly accessible to the research community via\nhttps://github.com/tsinghua-fib-lab/UrbanLLaVA.", "AI": {"tldr": "The paper introduces UrbanLLaVA, a multi-modal language model specifically designed to handle diverse urban research datasets and tasks by leveraging a customized training framework.", "motivation": "Urban research involves complex, multi-modal data, and existing methods lack a unified approach for processing such data comprehensively. The rise of multi-modal large language models (MLLMs) provides a potential solution.", "method": "The authors built UrbanLLaVA using a curated instruction dataset that spans various urban datasets and proposed a multi-stage training framework separating spatial reasoning enhancement from domain knowledge learning. They also extend benchmarks for urban research evaluation.", "result": "UrbanLLaVA excels in single-modal and cross-modal urban research tasks, outperforming existing open-source and proprietary MLLMs in evaluations across three cities.", "conclusion": "UrbanLLaVA demonstrates strong capabilities for urban research, showcasing superior performance, generalizability across cities, and openly accessible resources for further research."}}
{"id": "2506.23875", "pdf": "https://arxiv.org/pdf/2506.23875", "abs": "https://arxiv.org/abs/2506.23875", "authors": ["Yuta Sato", "Kazuhiko Kawamoto", "Hiroshi Kera"], "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 10 figures", "summary": "The chain of thought is fundamental in Transformers, which is to perform\nstep-by-step reasoning. Besides what intermediate steps work, the order of\nthese steps critically affects the difficulty of the reasoning. This study\naddresses a novel task of unraveling chain of thought - reordering decoder\ninput tokens to a learning-friendly sequence for Transformers to learn\narithmetic tasks. The proposed pipeline first trains a Transformer on a mixture\nof target sequences arranged in different orders and then identifies benign\norders as those with fast loss drops in the early stage. As the search space\ngrows factorially with sequence length, we propose a two-stage hierarchical\napproach for inter- and intra-block reordering. Experiments on four\norder-sensitive arithmetic tasks show that our method identifies a\nlearning-friendly order out of a few billion candidates. Notably, on the\nmultiplication task, it recovered the reverse-digit order reported in prior\nstudies.", "AI": {"tldr": "This paper proposes a method to reorder decoder input tokens in Transformers to optimize their learning on arithmetic tasks.", "motivation": "The paper aims to improve the step-by-step reasoning ability in Transformers by reordering input tokens into sequences that facilitate easier learning.", "method": "It trains a Transformer on target sequences of various orders, identifies learning-friendly orders based on early loss reduction, and employs a two-stage hierarchical approach for inter- and intra-block token reordering.", "result": "The method successfully discovers optimized input sequences for order-sensitive arithmetic tasks, including reproducing reverse-digit order for multiplication tasks.", "conclusion": "Reordering tokens into learning-friendly sequences significantly improves Transformer performance on arithmetic tasks, highlighting the importance of sequence order in reasoning."}}
{"id": "2506.23205", "pdf": "https://arxiv.org/pdf/2506.23205", "abs": "https://arxiv.org/abs/2506.23205", "authors": ["Dequan Kong", "Zhe Zhu", "Honghua Chen", "Mingqiang Wei"], "title": "BridgeShape: Latent Diffusion Schr\u00f6dinger Bridge for 3D Shape Completion", "categories": ["cs.CV"], "comment": null, "summary": "Existing diffusion-based 3D shape completion methods typically use a\nconditional paradigm, injecting incomplete shape information into the denoising\nnetwork via deep feature interactions (e.g., concatenation, cross-attention) to\nguide sampling toward complete shapes, often represented by voxel-based\ndistance functions. However, these approaches fail to explicitly model the\noptimal global transport path, leading to suboptimal completions. Moreover,\nperforming diffusion directly in voxel space imposes resolution constraints,\nlimiting the generation of fine-grained geometric details. To address these\nchallenges, we propose BridgeShape, a novel framework for 3D shape completion\nvia latent diffusion Schr\\\"odinger bridge. The key innovations lie in two\naspects: (i) BridgeShape formulates shape completion as an optimal transport\nproblem, explicitly modeling the transition between incomplete and complete\nshapes to ensure a globally coherent transformation. (ii) We introduce a\nDepth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D\nshapes into a compact latent space, leveraging self-projected multi-view depth\ninformation enriched with strong DINOv2 features to enhance geometric\nstructural perception. By operating in a compact yet structurally informative\nlatent space, BridgeShape effectively mitigates resolution constraints and\nenables more efficient and high-fidelity 3D shape completion. BridgeShape\nachieves state-of-the-art performance on large-scale 3D shape completion\nbenchmarks, demonstrating superior fidelity at higher resolutions and for\nunseen object classes.", "AI": {"tldr": "BridgeShape proposes a novel framework for 3D shape completion through latent diffusion Schr\u00f6dinger bridge, addressing limitations in existing diffusion-based methods by optimizing global transport paths and improving fine geometric details.", "motivation": "Existing methods for 3D shape completion struggle with modeling optimal global transport paths and face resolution constraints when operating in voxel spaces, leading to suboptimal outputs.", "method": "BridgeShape formulates shape completion as an optimal transport problem using latent diffusion Schr\u00f6dinger bridge and introduces a Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) enriched with DINOv2 features.", "result": "BridgeShape achieves state-of-the-art performance on large-scale benchmarks, delivering high-fidelity 3D shape completion across various resolutions and unseen object classes.", "conclusion": "The proposed BridgeShape framework addresses significant challenges in 3D shape completion by ensuring globally coherent transformations and mitigating resolution constraints via a compact latent space representation."}}
{"id": "2506.23923", "pdf": "https://arxiv.org/pdf/2506.23923", "abs": "https://arxiv.org/abs/2506.23923", "authors": ["Miguel Camacho-S\u00e1nchez", "Fernando Garc\u00eda-Torres", "Jesper John Lisegaard", "Roc\u00edo del Amor", "Sankhya Mohanty", "Valery Naranjo"], "title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 4 figures, 45th Ris{\\o} International Symposium on\n  Materials Science", "summary": "Resin infusion (RI) and resin transfer moulding (RTM) are critical processes\nfor the manufacturing of high-performance fibre-reinforced polymer composites,\nparticularly for large-scale applications such as wind turbine blades.\nControlling the resin flow dynamics in these processes is critical to ensure\nthe uniform impregnation of the fibre reinforcements, thereby preventing\nresidual porosities and dry spots that impact the consequent structural\nintegrity of the final component. This paper presents a reinforcement learning\n(RL) based strategy, established using process simulations, for synchronising\nthe different resin flow fronts in an infusion scenario involving two resin\ninlets and a single outlet. Using Proximal Policy Optimisation (PPO), our\napproach addresses the challenge of managing the fluid dynamics in a partially\nobservable environment. The results demonstrate the effectiveness of the RL\napproach in achieving an accurate flow convergence, highlighting its potential\ntowards improving process control and product quality in composites\nmanufacturing.", "AI": {"tldr": "The paper proposes a reinforcement learning (RL) strategy using Proximal Policy Optimisation (PPO) to control resin flow in resin infusion (RI) processes, ensuring uniform impregnation of fibre reinforcements for better composite quality.", "motivation": "To address the critical challenge of controlling resin flow dynamics in resin infusion and resin transfer moulding processes for producing defect-free, high-performance fibre-reinforced polymer composites.", "method": "The authors developed an RL-based control strategy using Proximal Policy Optimisation (PPO) within simulated process environments to synchronise resin flow fronts across two inlets and a single outlet in partially observable conditions.", "result": "The RL strategy demonstrated effective resin flow convergence, reducing defects such as residual porosities and dry spots in fibre-reinforced polymers.", "conclusion": "Reinforcement learning offers a promising approach to improve process control and enhance the structural quality of polymer composite manufacturing."}}
{"id": "2506.23207", "pdf": "https://arxiv.org/pdf/2506.23207", "abs": "https://arxiv.org/abs/2506.23207", "authors": ["Zhen Tan", "Xieyuanli Chen", "Lei Feng", "Yangbing Ge", "Shuaifeng Zhi", "Jiaxiong Liu", "Dewen Hu"], "title": "TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM\nsystems to achieve high-fidelity scene representation. However, the heavy\nreliance of existing systems on photometric rendering loss for camera tracking\nundermines their robustness, especially in unbounded outdoor environments with\nsevere viewpoint and illumination changes. To address these challenges, we\npropose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel\ntri-view geometry paradigm to ensure consistent tracking and high-quality\nmapping. We introduce a dense tri-view matching module that aggregates reliable\npairwise correspondences into consistent tri-view matches, forming robust\ngeometric constraints across frames. For tracking, we propose Hybrid Geometric\nConstraints, which leverage tri-view matches to construct complementary\ngeometric cues alongside photometric loss, ensuring accurate and stable pose\nestimation even under drastic viewpoint shifts and lighting variations. For\nmapping, we propose a new probabilistic initialization strategy that encodes\ngeometric uncertainty from tri-view correspondences into newly initialized\nGaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust\nmechanism to mitigate tracking drift caused by mapping latency. Experiments on\nmultiple public outdoor datasets show that our TVG-SLAM outperforms prior\nRGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our\nmethod improves tracking robustness, reducing the average Absolute Trajectory\nError (ATE) by 69.0\\% while achieving state-of-the-art rendering quality. The\nimplementation of our method will be released as open-source.", "AI": {"tldr": "TVG-SLAM improves robustness and fidelity in 3D scene representation for RGB-only SLAM systems using a novel tri-view geometry paradigm, achieving state-of-the-art results.", "motivation": "Existing RGB-only SLAM systems heavily rely on photometric rendering loss, which makes camera tracking less robust, especially in challenging outdoor environments with severe viewpoint and lighting changes.", "method": "TVG-SLAM introduces a tri-view geometry paradigm, incorporating dense tri-view matching, Hybrid Geometric Constraints for tracking, and a probabilistic initialization strategy for mapping. Additionally, it utilizes a Dynamic Attenuation of Rendering Trust mechanism to further enhance performance.", "result": "TVG-SLAM demonstrated improved robustness and mapping quality in experiments across multiple outdoor datasets, reducing the average Absolute Trajectory Error (ATE) by 69% in the most challenging scenarios while achieving state-of-the-art rendering quality.", "conclusion": "TVG-SLAM addresses the limitations of traditional RGB-only SLAM systems, delivering both robust camera tracking and high-fidelity scene representation. Its implementation will be made open-source."}}
{"id": "2506.22704", "pdf": "https://arxiv.org/pdf/2506.22704", "abs": "https://arxiv.org/abs/2506.22704", "authors": ["Sardar Fatooreh Bonabi", "Sarah Bana", "Tingting Nian", "Vijay Gurbaxani"], "title": "Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "Large language models (LLMs) are poised to significantly impact software\ndevelopment, especially in the Open-Source Software (OSS) sector. To understand\nthis impact, we first outline the mechanisms through which LLMs may influence\nOSS through code development, collaborative knowledge transfer, and skill\ndevelopment. We then empirically examine how LLMs affect OSS developers' work\nin these three key areas. Leveraging a natural experiment from a temporary\nChatGPT ban in Italy, we employ a Difference-in-Differences framework with\ntwo-way fixed effects to analyze data from all OSS developers on GitHub in\nthree similar countries, Italy, France, and Portugal, totaling 88,022 users. We\nfind that access to ChatGPT increases developer productivity by 6.4%, knowledge\nsharing by 9.6%, and skill acquisition by 8.4%. These benefits vary\nsignificantly by user experience level: novice developers primarily experience\nproductivity gains, whereas more experienced developers benefit more from\nimproved knowledge sharing and accelerated skill acquisition. In addition, we\nfind that LLM-assisted learning is highly context-dependent, with the greatest\nbenefits observed in technically complex, fragmented, or rapidly evolving\ncontexts. We show that the productivity effects of LLMs extend beyond direct\ncode generation to include enhanced collaborative learning and knowledge\nexchange among developers; dynamics that are essential for gaining a holistic\nunderstanding of LLMs' impact in OSS. Our findings offer critical managerial\nimplications: strategically deploying LLMs can accelerate novice developers'\nonboarding and productivity, empower intermediate developers to foster\nknowledge sharing and collaboration, and support rapid skill acquisition,\ntogether enhancing long-term organizational productivity and agility.", "AI": {"tldr": "The paper investigates the impact of Large Language Models (LLMs) on Open-Source Software development and finds that LLM access improves productivity, knowledge sharing, and skill acquisition, varying by developer experience and context.", "motivation": "The motivation is to understand the mechanisms and effects of LLMs, like ChatGPT, on OSS developers' productivity, knowledge exchange, and skill enhancement.", "method": "The study uses a natural experiment involving a temporary ChatGPT ban in Italy and a Difference-in-Differences framework with data from GitHub developers in Italy, France, and Portugal.", "result": "Results show that ChatGPT access boosts developer productivity by 6.4%, knowledge sharing by 9.6%, and skill acquisition by 8.4%, with variations based on experience and context.", "conclusion": "Strategically deploying LLMs can benefit developers at different experience levels and improve broader organizational productivity and collaboration."}}
{"id": "2506.23958", "pdf": "https://arxiv.org/pdf/2506.23958", "abs": "https://arxiv.org/abs/2506.23958", "authors": ["Ikechukwu Ogbonna", "Lesley Davidson", "Soumya Banerjee", "Abhishek Dasgupta", "Laurence Kenney", "Vikranth Harthikote Nagaraja"], "title": "Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages", "categories": ["cs.LG"], "comment": "5 pages, 0 figures, 0 tables", "summary": "Millions of people in African countries face barriers to accessing healthcare\ndue to language and literacy gaps. This research tackles this challenge by\ntransforming complex medical documents -- in this case, prosthetic device user\nmanuals -- into accessible formats for underserved populations. This case study\nin cross-cultural translation is particularly pertinent/relevant for\ncommunities that receive donated prosthetic devices but may not receive the\naccompanying user documentation. Or, if available online, may only be available\nin formats (e.g., language and readability) that are inaccessible to local\npopulations (e.g., English-language, high resource settings/cultural context).\nThe approach is demonstrated using the widely spoken Pidgin dialect, but our\nopen-source framework has been designed to enable rapid and easy extension to\nother languages/dialects. This work presents an AI-powered framework designed\nto process and translate complex medical documents, e.g., user manuals for\nprosthetic devices, into marginalised languages. The system enables users --\nsuch as healthcare workers or patients -- to upload English-language medical\nequipment manuals, pose questions in their native language, and receive\naccurate, localised answers in real time. Technically, the system integrates a\nRetrieval-Augmented Generation (RAG) pipeline for processing and semantic\nunderstanding of the uploaded manuals. It then employs advanced Natural\nLanguage Processing (NLP) models for generative question-answering and\nmultilingual translation. Beyond simple translation, it ensures accessibility\nto device instructions, treatment protocols, and safety information, empowering\npatients and clinicians to make informed healthcare decisions.", "AI": {"tldr": "Developed an AI-powered framework that translates complex medical documents, like prosthetic device manuals, into marginalized languages for improved accessibility.", "motivation": "Millions in African countries face healthcare access barriers due to language and literacy gaps, exacerbated by inaccessible medical documentation formats.", "method": "Utilized a Retrieval-Augmented Generation pipeline and advanced NLP models for multilingual translation and query-based question-answering.", "result": "The framework enables real-time translation and localized responses to medical queries using languages such as Pidgin dialect, ensuring better accessibility and understanding.", "conclusion": "The system empowers underserved populations, enabling informed healthcare decisions through accessible and localized medical documentation."}}
{"id": "2506.23209", "pdf": "https://arxiv.org/pdf/2506.23209", "abs": "https://arxiv.org/abs/2506.23209", "authors": ["Chia-Wen Huang", "Haw Hwai", "Chien-Chang Lee", "Pei-Yuan Wu"], "title": "A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans", "categories": ["cs.CV"], "comment": "8 pages, 1 figure, 3 tables. Published in IEEE ISBI 2025. This\n  version corrects citation numbering errors", "summary": "Timely and accurate diagnosis of appendicitis is critical in clinical\nsettings to prevent serious complications. While CT imaging remains the\nstandard diagnostic tool, the growing number of cases can overwhelm\nradiologists, potentially causing delays. In this paper, we propose a deep\nlearning model that leverages 3D CT scans for appendicitis classification,\nincorporating Slice Attention mechanisms guided by external 2D datasets to\nenhance small lesion detection. Additionally, we introduce a hierarchical\nclassification framework using pre-trained 2D models to differentiate between\nsimple and complicated appendicitis. Our approach improves AUC by 3% for\nappendicitis and 5.9% for complicated appendicitis, offering a more efficient\nand reliable diagnostic solution compared to previous work.", "AI": {"tldr": "The paper proposes a deep learning model that enhances appendicitis diagnosis using 3D CT scans and achieves improved diagnostic accuracy.", "motivation": "The need for timely and precise appendicitis diagnosis to prevent complications, compounded by the overwhelming number of cases and limited radiology resources.", "method": "A deep learning model employing 3D CT scans with Slice Attention mechanisms guided by 2D datasets, along with a hierarchical framework using pre-trained 2D models for classification.", "result": "The approach improves diagnostic performance, with an AUC increase of 3% for general appendicitis and 5.9% for complicated cases.", "conclusion": "The proposed method offers a faster and more reliable diagnostic alternative, addressing challenges in small lesion detection and classification."}}
{"id": "2506.23322", "pdf": "https://arxiv.org/pdf/2506.23322", "abs": "https://arxiv.org/abs/2506.23322", "authors": ["Wei Zhou", "Ji Sun", "Xuanhe Zhou", "Guoliang Li", "Luyang Liu", "Hao Wu", "Tianyuan Wang"], "title": "GaussMaster: An LLM-based Database Copilot System", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR"], "comment": "We welcome contributions from the community. For reference, please\n  see the code at: https://gitcode.com/opengauss/openGauss-GaussMaster", "summary": "In the financial industry, data is the lifeblood of operations, and DBAs\nshoulder significant responsibilities for SQL tuning, database deployment,\ndiagnosis, and service repair. In recent years, both database vendors and\ncustomers have increasingly turned to autonomous database platforms in an\neffort to alleviate the heavy workload of DBAs. However, existing autonomous\ndatabase platforms are limited in their capabilities, primarily addressing\nsingle-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual\nintervention remains a necessity for comprehensive database maintenance.\nGaussMaster aims to revolutionize this landscape by introducing an LLM-based\ndatabase copilot system. This innovative solution is designed not only to\nassist developers in writing efficient SQL queries but also to provide\ncomprehensive care for database services. When database instances exhibit\nabnormal behavior, GaussMaster is capable of orchestrating the entire\nmaintenance process automatically. It achieves this by analyzing hundreds of\nmetrics and logs, employing a Tree-of-thought approach to identify root causes,\nand invoking appropriate tools to resolve issues. We have successfully\nimplemented GaussMaster in real-world scenarios, such as the banking industry,\nwhere it has achieved zero human intervention for over 34 database maintenance\nscenarios. In this paper, we present significant improvements in these tasks\nwith code at https://gitcode.com/opengauss/openGauss-GaussMaster.", "AI": {"tldr": "GaussMaster introduces an LLM-based system for autonomous database maintenance, reducing human intervention across 34 scenarios in real-world deployments.", "motivation": "DBAs face heavy workloads in SQL tuning, deployment, diagnosis, and repair, needing efficient tools for holistic database maintenance.", "method": "GaussMaster uses an LLM-based approach, Tree-of-Thought analysis, and automated tooling to diagnose and resolve database issues.", "result": "GaussMaster achieved zero human intervention in 34 maintenance scenarios, particularly effective in the banking sector.", "conclusion": "GaussMaster demonstrates potential to transform autonomous database systems by comprehensively addressing maintenance needs and reducing reliance on manual DBA operations."}}
{"id": "2506.23366", "pdf": "https://arxiv.org/pdf/2506.23366", "abs": "https://arxiv.org/abs/2506.23366", "authors": ["Nathaniel Imel", "Zachary Hafen"], "title": "Density, asymmetry and citation dynamics in scientific literature", "categories": ["cs.DL", "cs.CL", "cs.SI"], "comment": null, "summary": "Scientific behavior is often characterized by a tension between building upon\nestablished knowledge and introducing novel ideas. Here, we investigate whether\nthis tension is reflected in the relationship between the similarity of a\nscientific paper to previous research and its eventual citation rate. To\noperationalize similarity to previous research, we introduce two complementary\nmetrics to characterize the local geometry of a publication's semantic\nneighborhood: (1) \\emph{density} ($\\rho$), defined as the ratio between a fixed\nnumber of previously-published papers and the minimum distance enclosing those\npapers in a semantic embedding space, and (2) asymmetry ($\\alpha$), defined as\nthe average directional difference between a paper and its nearest neighbors.\nWe tested the predictive relationship between these two metrics and its\nsubsequent citation rate using a Bayesian hierarchical regression approach,\nsurveying $\\sim 53,000$ publications across nine academic disciplines and five\ndifferent document embeddings. While the individual effects of $\\rho$ on\ncitation count are small and variable, incorporating density-based predictors\nconsistently improves out-of-sample prediction when added to baseline models.\nThese results suggest that the density of a paper's surrounding scientific\nliterature may carry modest but informative signals about its eventual impact.\nMeanwhile, we find no evidence that publication asymmetry improves model\npredictions of citation rates. Our work provides a scalable framework for\nlinking document embeddings to scientometric outcomes and highlights new\nquestions regarding the role that semantic similarity plays in shaping the\ndynamics of scientific reward.", "AI": {"tldr": "The study explores how the similarity of a scientific paper to prior research, measured through semantic metrics (density and asymmetry), impacts its eventual citation rates. Evidence suggests density carries modest predictive capability, while asymmetry has little impact.", "motivation": "To understand the underlying factors influencing scientific reward, such as citation rates, in the context of balancing novel ideas with established knowledge.", "method": "Developed two semantic metrics, density and asymmetry, to represent the similarity of papers in their surrounding literature. Used Bayesian hierarchical regression to analyze citation impact across 53,000 publications spanning multiple disciplines and document embedding techniques.", "result": "Density shows small yet meaningful predictive utility for citation rates, while asymmetry offers no improvement in model accuracy. Adding density-based predictors enhances the reliability of existing baseline models.", "conclusion": "Semantic density carries actionable insights regarding citation behavior in scientific work, presenting a new avenue to analyze the interplay between research novelty and its recognition in academic communities. Asymmetry adds limited value in this context."}}
{"id": "2506.23971", "pdf": "https://arxiv.org/pdf/2506.23971", "abs": "https://arxiv.org/abs/2506.23971", "authors": ["Brandon M. Wood", "Misko Dzamba", "Xiang Fu", "Meng Gao", "Muhammed Shuaibi", "Luis Barroso-Luque", "Kareem Abdelmaqsoud", "Vahe Gharakhanyan", "John R. Kitchin", "Daniel S. Levine", "Kyle Michel", "Anuroop Sriram", "Taco Cohen", "Abhishek Das", "Ammar Rizvi", "Sushree Jagriti Sahoo", "Zachary W. Ulissi", "C. Lawrence Zitnick"], "title": "UMA: A Family of Universal Models for Atoms", "categories": ["cs.LG"], "comment": "29 pages, 5 figures", "summary": "The ability to quickly and accurately compute properties from atomic\nsimulations is critical for advancing a large number of applications in\nchemistry and materials science including drug discovery, energy storage, and\nsemiconductor manufacturing. To address this need, Meta FAIR presents a family\nof Universal Models for Atoms (UMA), designed to push the frontier of speed,\naccuracy, and generalization. UMA models are trained on half a billion unique\n3D atomic structures (the largest training runs to date) by compiling data\nacross multiple chemical domains, e.g. molecules, materials, and catalysts. We\ndevelop empirical scaling laws to help understand how to increase model\ncapacity alongside dataset size to achieve the best accuracy. The UMA small and\nmedium models utilize a novel architectural design we refer to as mixture of\nlinear experts that enables increasing model capacity without sacrificing\nspeed. For example, UMA-medium has 1.4B parameters but only ~50M active\nparameters per atomic structure. We evaluate UMA models on a diverse set of\napplications across multiple domains and find that, remarkably, a single model\nwithout any fine-tuning can perform similarly or better than specialized\nmodels. We are releasing the UMA code, weights, and associated data to\naccelerate computational workflows and enable the community to continue to\nbuild increasingly capable AI models.", "AI": {"tldr": "This paper presents Universal Models for Atoms (UMA), addressing the need for fast and accurate computation in atomic simulations, trained on the largest dataset to date of 3D atomic structures.", "motivation": "The paper aims to advance computational capabilities in applications such as drug discovery, energy storage, and semiconductor manufacturing by creating models that improve speed, accuracy, and generalization in atomic simulations.", "method": "The UMA models use architectural designs like mixture of linear experts and are trained on a massive dataset of 3D atomic structures across multiple chemical domains. Empirical scaling laws are developed to guide model capacity growth.", "result": "UMA models perform on par or better than specialized models across diverse applications, without requiring fine-tuning, showcasing their generalist capability.", "conclusion": "The UMA models enable fast, accurate computations and generalization across domains, pushing boundaries in atomic simulations, and their release will accelerate advancements in AI-driven workflows in science and engineering."}}
{"id": "2506.23227", "pdf": "https://arxiv.org/pdf/2506.23227", "abs": "https://arxiv.org/abs/2506.23227", "authors": ["Lunhao Duan", "Shanshan Zhao", "Xingxing Weng", "Jing Zhang", "Gui-Song Xia"], "title": "High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation", "categories": ["cs.CV"], "comment": "Accepted by TPAMI. Code: https://github.com/LHDuan/WSegPC", "summary": "This paper investigates indoor point cloud semantic segmentation under\nscene-level annotation, which is less explored compared to methods relying on\nsparse point-level labels. In the absence of precise point-level labels,\ncurrent methods first generate point-level pseudo-labels, which are then used\nto train segmentation models. However, generating accurate pseudo-labels for\neach point solely based on scene-level annotations poses a considerable\nchallenge, substantially affecting segmentation performance. Consequently, to\nenhance accuracy, this paper proposes a high-quality pseudo-label generation\nframework by exploring contemporary multi-modal information and region-point\nsemantic consistency. Specifically, with a cross-modal feature guidance module,\nour method utilizes 2D-3D correspondences to align point cloud features with\ncorresponding 2D image pixels, thereby assisting point cloud feature learning.\nTo further alleviate the challenge presented by the scene-level annotation, we\nintroduce a region-point semantic consistency module. It produces regional\nsemantics through a region-voting strategy derived from point-level semantics,\nwhich are subsequently employed to guide the point-level semantic predictions.\nLeveraging the aforementioned modules, our method can rectify inaccurate\npoint-level semantic predictions during training and obtain high-quality\npseudo-labels. Significant improvements over previous works on ScanNet v2 and\nS3DIS datasets under scene-level annotation can demonstrate the effectiveness.\nAdditionally, comprehensive ablation studies validate the contributions of our\napproach's individual components. The code is available at\nhttps://github.com/LHDuan/WSegPC .", "AI": {"tldr": "The paper tackles the challenge of indoor point cloud semantic segmentation with only scene-level annotations, introducing a method to generate high-quality pseudo-labels through multi-modal information and semantic consistency.", "motivation": "The challenge in leveraging scene-level annotations for point cloud segmentation lies in generating accurate pseudo-labels from imprecise annotation, which affects segmentation performance significantly.", "method": "The approach combines a cross-modal feature guidance module to align 2D image and 3D point cloud features along with a region-point semantic consistency module to guide semantic predictions using region-voting strategies.", "result": "The proposed framework achieves significant better segmentation performance on ScanNet v2 and S3DIS datasets using scene-level annotations compared to prior works, showing the effectiveness of the method.", "conclusion": "By leveraging multi-modal alignment and semantic consistency, the method creates high-quality pseudo-labels, improving segmentation tasks under limited annotation conditions. The release of code ensures reproducibility."}}
{"id": "2506.23367", "pdf": "https://arxiv.org/pdf/2506.23367", "abs": "https://arxiv.org/abs/2506.23367", "authors": ["Paige Tutt\u00f6s\u00ed", "H. Henny Yeung", "Yue Wang", "Jean-Julien Aucouturier", "Angelica Lim"], "title": "You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted to ISCA Speech Synthesis Workshop, 2025", "summary": "We present the first text-to-speech (TTS) system tailored to second language\n(L2) speakers. We use duration differences between American English tense\n(longer) and lax (shorter) vowels to create a \"clarity mode\" for Matcha-TTS.\nOur perception studies showed that French-L1, English-L2 listeners had fewer\n(at least 9.15%) transcription errors when using our clarity mode, and found it\nmore encouraging and respectful than overall slowed down speech. Remarkably,\nlisteners were not aware of these effects: despite the decreased word error\nrate in clarity mode, listeners still believed that slowing all target words\nwas the most intelligible, suggesting that actual intelligibility does not\ncorrelate with perceived intelligibility. Additionally, we found that\nWhisper-ASR did not use the same cues as L2 speakers to differentiate difficult\nvowels and is not sufficient to assess the intelligibility of TTS systems for\nthese individuals.", "AI": {"tldr": "The paper introduces Matcha-TTS, a text-to-speech system for second-language speakers that uses vowel duration differences to improve intelligibility.", "motivation": "Provide a TTS system that specifically caters to second-language (L2) English speakers by addressing intelligibility challenges and emotional considerations.", "method": "Using American English vowel duration differences (tense vs lax vowels), the system applies a 'clarity mode' to improve transcription accuracy and emotional perception.", "result": "French-L1, English-L2 listeners experienced reduced transcription errors (9.15%) and found the clarity mode encouraging and respectful. Whisper-ASR did not offer adequate intelligibility assessment.", "conclusion": "Matcha-TTS improves intelligibility for L2 speakers while accounting for emotional and perceptual factors, but further exploration is needed for intelligibility assessment mechanisms."}}
{"id": "2506.22722", "pdf": "https://arxiv.org/pdf/2506.22722", "abs": "https://arxiv.org/abs/2506.22722", "authors": ["Anmin Fu", "Fanyu Meng", "Huaibing Peng", "Hua Ma", "Zhi Zhang", "Yifeng Zheng", "Willy Susilo", "Yansong Gao"], "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The proposed UniGuard is the first unified online detection framework capable\nof simultaneously addressing adversarial examples and backdoor attacks.\nUniGuard builds upon two key insights: first, both AE and backdoor attacks have\nto compromise the inference phase, making it possible to tackle them\nsimultaneously during run-time via online detection. Second, an adversarial\ninput, whether a perturbed sample in AE attacks or a trigger-carrying sample in\nbackdoor attacks, exhibits distinctive trajectory signatures from a benign\nsample as it propagates through the layers of a DL model in forward inference.\nThe propagation trajectory of the adversarial sample must deviate from that of\nits benign counterpart; otherwise, the adversarial objective cannot be\nfulfilled. Detecting these trajectory signatures is inherently challenging due\nto their subtlety; UniGuard overcomes this by treating the propagation\ntrajectory as a time-series signal, leveraging LSTM and spectrum transformation\nto amplify differences between adversarial and benign trajectories that are\nsubtle in the time domain. UniGuard exceptional efficiency and effectiveness\nhave been extensively validated across various modalities (image, text, and\naudio) and tasks (classification and regression), ranging from diverse model\narchitectures against a wide range of AE attacks and backdoor attacks,\nincluding challenging partial backdoors and dynamic triggers. When compared to\nSOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED\n(IEEE SP 24) specific for backdoor detection, UniGuard consistently\ndemonstrates superior performance, even when matched against each method's\nstrengths in addressing their respective threats-each SOTA fails to parts of\nattack strategies while UniGuard succeeds for all.", "AI": {"tldr": "UniGuard is a unified online detection framework designed to simultaneously address adversarial examples (AEs) and backdoor attacks during inference by analyzing propagation trajectories with LSTM and spectral transformation.", "motivation": "To create a unified solution capable of detecting both adversarial examples and backdoor attacks in deep learning systems, overcoming current challenges in efficiently and effectively identifying these sophisticated threats.", "method": "UniGuard detects threats by treating propagation trajectories of adversarial inputs in deep learning models as time-series signals, utilizing LSTM and spectrum transformation to highlight subtle differences from benign trajectories.", "result": "UniGuard outperforms state-of-the-art methods tailored to either adversarial example detection or backdoor detection across diverse modalities, model architectures, and attack strategies.", "conclusion": "UniGuard sets a new benchmark for unified detection frameworks by successfully addressing threats from adversarial examples and backdoor attacks simultaneously, offering unmatched efficiency and effectiveness against current state-of-the-art methods."}}
{"id": "2506.23977", "pdf": "https://arxiv.org/pdf/2506.23977", "abs": "https://arxiv.org/abs/2506.23977", "authors": ["Zain ul Abdeen", "Vassilis Kekatos", "Ming Jin"], "title": "A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks", "categories": ["cs.LG"], "comment": null, "summary": "Certified robustness is a critical property for deploying neural networks\n(NN) in safety-critical applications. A principle approach to achieving such\nguarantees is to constrain the global Lipschitz constant of the network.\nHowever, accurate methods for Lipschitz-constrained training often suffer from\nnon-convex formulations and poor scalability due to reliance on global\nsemidefinite programs (SDPs). In this letter, we propose a convex training\nframework that enforces global Lipschitz constraints via semidefinite\nrelaxation. By reparameterizing the NN using loop transformation, we derive a\nconvex admissibility condition that enables tractable and certifiable training.\nWhile the resulting formulation guarantees robustness, its scalability is\nlimited by the size of global SDP. To overcome this, we develop a randomized\nsubspace linear matrix inequalities (RS-LMI) approach that decomposes the\nglobal constraints into sketched layerwise constraints projected onto\nlow-dimensional subspaces, yielding a smooth and memory-efficient training\nobjective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that\nthe proposed framework achieves competitive accuracy with significantly\nimproved Lipschitz bounds and runtime performance.", "AI": {"tldr": "This paper proposes a convex training framework for neural networks that enforces robustness via Lipschitz constraints, addressing scalability issues using a randomized subspace method.", "motivation": "To enhance the robustness of neural networks in safety-critical applications by constraining their global Lipschitz constant, overcoming issues like non-convex formulations and poor scalability.", "method": "The proposed method reparameterizes neural networks using loop transformation, employs semidefinite relaxation for convex admissibility, and utilizes a Randomized Subspace Linear Matrix Inequalities (RS-LMI) approach to improve scalability.", "result": "Empirical evaluations on MNIST, CIFAR-10, and ImageNet show competitive accuracy, improved Lipschitz bounds, and better runtime efficiency compared to prior methods.", "conclusion": "The framework provides a scalable, certifiably robust training approach for Lipschitz-constrained neural networks, emphasizing both rigor and practicality."}}
{"id": "2506.23236", "pdf": "https://arxiv.org/pdf/2506.23236", "abs": "https://arxiv.org/abs/2506.23236", "authors": ["Marko Mihajlovic", "Siwei Zhang", "Gen Li", "Kaifeng Zhao", "Lea M\u00fcller", "Siyu Tang"], "title": "VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions", "categories": ["cs.CV", "cs.AI"], "comment": "[ICCV 2025] https://markomih.github.io/VolumetricSMPL", "summary": "Parametric human body models play a crucial role in computer graphics and\nvision, enabling applications ranging from human motion analysis to\nunderstanding human-environment interactions. Traditionally, these models use\nsurface meshes, which pose challenges in efficiently handling interactions with\nother geometric entities, such as objects and scenes, typically represented as\nmeshes or point clouds. To address this limitation, recent research has\nexplored volumetric neural implicit body models. However, existing works are\neither insufficiently robust for complex human articulations or impose high\ncomputational and memory costs, limiting their widespread use. To this end, we\nintroduce VolumetricSMPL, a neural volumetric body model that leverages Neural\nBlend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike\nprior approaches that rely on large MLPs, NBW dynamically blends a small set of\nlearned weight matrices using predicted shape- and pose-dependent coefficients,\nsignificantly improving computational efficiency while preserving\nexpressiveness. VolumetricSMPL outperforms prior volumetric occupancy model\nCOAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,\nand a Signed Distance Function (SDF) for efficient and differentiable contact\nmodeling. We demonstrate VolumetricSMPL's strengths across four challenging\ntasks: (1) reconstructing human-object interactions from in-the-wild images,\n(2) recovering human meshes in 3D scenes from egocentric views, (3)\nscene-constrained motion synthesis, and (4) resolving self-intersections. Our\nresults highlight its broad applicability and significant performance and\nefficiency gains.", "AI": {"tldr": "This paper introduces VolumetricSMPL, a neural volumetric human body model, which achieves faster and more efficient processing compared to prior models, while maintaining high accuracy for tasks in computer graphics and vision.", "motivation": "The paper aims to address limitations in traditional surface mesh-based parametric human body models, such as inefficient handling of geometric interactions, and gaps in performance and resource usage in existing volumetric neural implicit body models.", "method": "The authors present VolumetricSMPL, leveraging Neural Blend Weights (NBW) to generate efficient MLP decoders that are computationally lightweight. It replaces large MLPs with dynamically blended small weight matrices, improving computational efficiency and expressiveness.", "result": "VolumetricSMPL outperforms previous models like COAP by achieving 10x faster inference, 6x lower GPU memory usage, higher accuracy, and providing a Signed Distance Function (SDF) for contact modeling. It proves effective across tasks like human-object interaction reconstruction, egocentric mesh recovery, motion synthesis, and resolving self-intersections.", "conclusion": "VolumetricSMPL presents significant efficiency gains and broad applicability, making it a strong candidate for addressing challenges in handling human motion and human-environment interactions in graphics and vision."}}
{"id": "2506.23394", "pdf": "https://arxiv.org/pdf/2506.23394", "abs": "https://arxiv.org/abs/2506.23394", "authors": ["Simeon Emanuilov"], "title": "Teaching a Language Model to Speak the Language of Tools", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.7; I.2.1"], "comment": null, "summary": "External tool integration through function-calling is essential for practical\nlanguage model applications, yet most multilingual models lack reliable\ntool-use capabilities in non-English languages. Even state-of-the-art\nmultilingual models struggle with determining when to use tools and generating\nthe structured outputs required for function calls, often exhibiting language\nconfusion when prompted in lower-resource languages. This work presents a\nmethodology for adapting existing language models to enable robust tool use in\nany target language, using Bulgarian as a case study. The approach involves\ncontinued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a\nnovel bilingual dataset of 10,035 function-calling examples designed to support\nstandardized protocols like MCP (Model Context Protocol). The research\nintroduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to\n28.75% improvement in function-calling accuracy over base models while\npreserving core language understanding, as verified on established Bulgarian\nbenchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready\nresponse formatting with clean, parsable function calls, contrasting with the\nverbose and inconsistent outputs of base models. The models, evaluation\nframework, and dataset are released to enable replication for other languages.\nThis work demonstrates a practical approach for extending tool-augmented\ncapabilities beyond English-centric systems.", "AI": {"tldr": "This paper adapts language models to robustly use tools in non-English languages, particularly Bulgarian, by training on function-calling examples, improving accuracy and response quality.", "motivation": "Most multilingual models fail to reliably use external tools in non-English languages, often showing issues like language confusion and incorrect function-call structures.", "method": "The authors trained the BgGPT model on a bilingual dataset of 10,035 function-calling examples and introduced TUCAN to support accurate and standardized tool use.", "result": "TUCAN improved function-calling accuracy by up to 28.75% compared to base models, while maintaining strong language understanding.", "conclusion": "The study provides a replicable methodology to enable robust tool-integration beyond English-centric language systems and publishes resources for other languages."}}
{"id": "2506.23978", "pdf": "https://arxiv.org/pdf/2506.23978", "abs": "https://arxiv.org/abs/2506.23978", "authors": ["Samuele Marro", "Philip Torr"], "title": "LLM Agents Are the Antidote to Walled Gardens", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.SI", "68T50, 68M10, 91B26", "I.2.11; I.2.7; H.4.5"], "comment": null, "summary": "While the Internet's core infrastructure was designed to be open and\nuniversal, today's application layer is dominated by closed, proprietary\nplatforms. Open and interoperable APIs require significant investment, and\nmarket leaders have little incentive to enable data exchange that could erode\ntheir user lock-in. We argue that LLM-based agents fundamentally disrupt this\nstatus quo. Agents can automatically translate between data formats and\ninteract with interfaces designed for humans: this makes interoperability\ndramatically cheaper and effectively unavoidable. We name this shift universal\ninteroperability: the ability for any two digital services to exchange data\nseamlessly using AI-mediated adapters. Universal interoperability undermines\nmonopolistic behaviours and promotes data portability. However, it can also\nlead to new security risks and technical debt. Our position is that the ML\ncommunity should embrace this development while building the appropriate\nframeworks to mitigate the downsides. By acting now, we can harness AI to\nrestore user freedom and competitive markets without sacrificing security.", "AI": {"tldr": "The paper discusses how LLM-based agents enable 'universal interoperability' between digital services, reducing monopolistic practices but bringing new risks.", "motivation": "To address the dominance of closed, proprietary platforms and limited data exchange in today's application layer.", "method": "Propose AI-mediated adapters for data format translation and interface interactions, disrupting the need for API-based interoperability.", "result": "Demonstrate that LLM-based agents make interoperability cheaper and undermine monopolistic behaviors, but also introduce security risks and technical debt.", "conclusion": "The ML community should adopt universal interoperability while developing frameworks to address potential downsides like security and technical risks."}}
{"id": "2506.23247", "pdf": "https://arxiv.org/pdf/2506.23247", "abs": "https://arxiv.org/abs/2506.23247", "authors": ["James Hinns", "David Martens"], "title": "Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning dominates image classification tasks, yet understanding how\nmodels arrive at predictions remains a challenge. Much research focuses on\nlocal explanations of individual predictions, such as saliency maps, which\nvisualise the influence of specific pixels on a model's prediction. However,\nreviewing many of these explanations to identify recurring patterns is\ninfeasible, while global methods often oversimplify and miss important local\nbehaviours. To address this, we propose Segment Attribution Tables (SATs), a\nmethod for summarising local saliency explanations into (semi-)global insights.\nSATs take image segments (such as \"eyes\" in Chihuahuas) and leverage saliency\nmaps to quantify their influence. These segments highlight concepts the model\nrelies on across instances and reveal spurious correlations, such as reliance\non backgrounds or watermarks, even when out-of-distribution test performance\nsees little change. SATs can explain any classifier for which a form of\nsaliency map can be produced, using segmentation maps that provide named\nsegments. SATs bridge the gap between oversimplified global summaries and\noverly detailed local explanations, offering a practical tool for analysing and\ndebugging image classifiers.", "AI": {"tldr": "The paper introduces Segment Attribution Tables (SATs), a method leveraging saliency maps to summarize local explanations into semi-global insights, aiding in understanding image classifications.", "motivation": "There is a gap between highly localized explanations like saliency maps and overly simplified global methods. The authors aim to create a tool that addresses this gap for better model analysis.", "method": "This paper proposes SATs, which quantify the influence of image segments (e.g., 'eyes' in Chihuahuas) by leveraging saliency maps, combined with segmentation maps to provide named segments of interest.", "result": "SATs revealed meaningful concepts and spurious correlations within classifiers, even in cases with robust out-of-distribution test accuracy.", "conclusion": "The method provides a balance between local and global insights, enabling more effective debugging and analysis of image classification models."}}
{"id": "2506.23996", "pdf": "https://arxiv.org/pdf/2506.23996", "abs": "https://arxiv.org/abs/2506.23996", "authors": ["Juan Maro\u00f1as"], "title": "The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "This document shows how to obtain the Jacobian and Hessian matrices of the\nKullback-Leibler divergence between two multivariate Gaussian distributions,\nusing the first and second-order differentials. The presented derivations are\nbased on the theory presented by \\cite{magnus99}. I've also got great\ninspiration from some of the derivations in \\cite{minka}.\n  Since I pretend to be at most didactic, the document is split into a summary\nof results and detailed derivations on each of the elements involved, with\nspecific references to the tricks used in the derivations, and to many of the\nunderlying concepts.", "AI": {"tldr": "This paper derives Jacobian and Hessian matrices for the Kullback-Leibler (KL) divergence between multivariate Gaussians using first and second-order differentials, presenting both results and detailed derivations.", "motivation": "To calculate Jacobian and Hessian matrices of the KL divergence between multivariate Gaussian distributions for enhanced analytical insights, with a focus on clarity and educational value.", "method": "Utilizes theories from Magnus (1999) and Minka to derive Jacobian and Hessian matrices using first and second-order differentials, supported by detailed step-by-step derivations and references.", "result": "Successfully provides analytical derivations of the Jacobian and Hessian matrices of the KL divergence for multivariate Gaussian distributions, clarified through examples and theoretical references.", "conclusion": "The paper offers a thorough and didactic guide to deriving key mathematical structures for the KL divergence, filling gaps in understanding and aiding future applications in analytical and statistical methodologies."}}
{"id": "2506.23252", "pdf": "https://arxiv.org/pdf/2506.23252", "abs": "https://arxiv.org/abs/2506.23252", "authors": ["Kunwei Lv", "Ping Lan"], "title": "DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted\nthe importance of robust and efficient object detection in diverse aerial\nscenarios. Detecting small objects under complex conditions, however, remains a\nsignificant challenge. Existing approaches often prioritize inference speed,\nleading to degraded performance when handling multi-modal inputs. To address\nthis, we present DGE-YOLO, an enhanced YOLO-based detection framework designed\nto effectively fuse multi-modal information. Specifically, we introduce a\ndual-branch architecture for modality-specific feature extraction, enabling the\nmodel to process both infrared and visible images. To further enrich semantic\nrepresentation, we propose an Efficient Multi-scale Attention (EMA) mechanism\nthat enhances feature learning across spatial scales. Additionally, we replace\nthe conventional neck with a Gather-and-Distribute module to mitigate\ninformation loss during feature aggregation. Extensive experiments on the Drone\nVehicle dataset demonstrate that DGE-YOLO achieves superior performance over\nstate-of-the-art methods, validating its effectiveness in multi-modal UAV\nobject detection tasks.", "AI": {"tldr": "This paper introduces DGE-YOLO, a framework improving multi-modal UAV object detection using specialized architectures and attention mechanisms.", "motivation": "The study aims to overcome the challenges of detecting small objects in complex aerial scenarios, especially when processing multi-modal inputs, a limitation in existing methods.", "method": "The researchers propose DGE-YOLO, a dual-branch model for handling infrared and visible images, an Efficient Multi-scale Attention mechanism for spatial learning, and a Gather-and-Distribute module to avoid feature loss.", "result": "DGE-YOLO outperformed state-of-the-art methods in experiments on the Drone Vehicle dataset, proving its superior performance at multi-modal object detection.", "conclusion": "DGE-YOLO effectively enhances object detection in UAV applications by fusing multi-modal data and employing improved architectural components."}}
{"id": "2506.24000", "pdf": "https://arxiv.org/pdf/2506.24000", "abs": "https://arxiv.org/abs/2506.24000", "authors": ["Lijun Sheng", "Jian Liang", "Ran He", "Zilei Wang", "Tieniu Tan"], "title": "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models", "categories": ["cs.LG", "cs.CV"], "comment": "Github link: https://github.com/TomSheng21/tta-vlm", "summary": "Test-time adaptation (TTA) methods have gained significant attention for\nenhancing the performance of vision-language models (VLMs) such as CLIP during\ninference, without requiring additional labeled data. However, current TTA\nresearches generally suffer from major limitations such as duplication of\nbaseline results, limited evaluation metrics, inconsistent experimental\nsettings, and insufficient analysis. These problems hinder fair comparisons\nbetween TTA methods and obscure their practical strengths and weaknesses. To\naddress these challenges, we introduce TTA-VLM, a comprehensive benchmark for\nevaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7\nonline TTA methods within a unified and reproducible framework, and evaluates\nthem across 15 widely used datasets. Unlike prior studies focused solely on\nCLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid\nloss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA\nto assess generality. Beyond classification accuracy, TTA-VLM incorporates\nvarious evaluation metrics, including robustness, calibration,\nout-of-distribution detection, and stability, enabling a more holistic\nassessment of TTA methods. Through extensive experiments, we find that 1)\nexisting TTA methods produce limited gains compared to the previous pioneering\nwork; 2) current TTA methods exhibit poor collaboration with training-time\nfine-tuning methods; 3) accuracy gains frequently come at the cost of reduced\nmodel trustworthiness. We release TTA-VLM to provide fair comparison and\ncomprehensive evaluation of TTA methods for VLMs, and we hope it encourages the\ncommunity to develop more reliable and generalizable TTA strategies.", "AI": {"tldr": "The paper introduces TTA-VLM, a benchmark for evaluating test-time adaptation (TTA) methods on vision-language models (VLMs) with diverse metrics and reproducible framework.", "motivation": "Address limitations of current TTA research, such as poor evaluation consistency, to enable fair comparison and deeper insights into TTA methods for VLMs.", "method": "Develop a benchmark called TTA-VLM that supports multiple TTA methods and evaluates them across diverse metrics\u2014including accuracy and robustness\u2014on 15 datasets.", "result": "Find existing TTA methods offer limited benefits, perform poorly with training-time fine-tuning methods, and often reduce model trustworthiness.", "conclusion": "TTA-VLM serves as a valuable tool for fair comparison and comprehensive analysis of TTA methods, encouraging the development of more reliable approaches."}}
{"id": "2506.23254", "pdf": "https://arxiv.org/pdf/2506.23254", "abs": "https://arxiv.org/abs/2506.23254", "authors": ["Aradhana Mishra", "Bumshik Lee"], "title": "PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV"], "comment": null, "summary": "Diffusion-model-based image super-resolution techniques often face a\ntrade-off between realistic image generation and computational efficiency. This\nissue is exacerbated when inference times by decreasing sampling steps,\nresulting in less realistic and hazy images. To overcome this challenge, we\nintroduce a novel diffusion model named PixelBoost that underscores the\nsignificance of embracing the stochastic nature of Brownian motion in advancing\nimage super-resolution, resulting in a high degree of realism, particularly\nfocusing on texture and edge definitions. By integrating controlled\nstochasticity into the training regimen, our proposed model avoids convergence\nto local optima, effectively capturing and reproducing the inherent uncertainty\nof image textures and patterns. Our proposed model demonstrates superior\nobjective results in terms of learned perceptual image patch similarity\n(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),\nstructural similarity index measure (SSIM), as well as visual quality. To\ndetermine the edge enhancement, we evaluated the gradient magnitude and pixel\nvalue, and our proposed model exhibited a better edge reconstruction\ncapability. Additionally, our model demonstrates adaptive learning capabilities\nby effectively adjusting to Brownian noise patterns and introduces a sigmoidal\nnoise sequencing method that simplifies training, resulting in faster inference\nspeeds.", "AI": {"tldr": "PixelBoost is a novel diffusion model for image super-resolution that achieves high realism and texture fidelity while maintaining faster inference speeds through a sigmoidal noise sequencing method.", "motivation": "Address the trade-off between realistic image generation and computational efficiency in diffusion-based image super-resolution models, particularly under limited sampling steps.", "method": "Introduce PixelBoost, a novel diffusion model leveraging controlled stochasticity of Brownian motion, sigmoidal noise sequencing, and adaptive learning to improve texture capture, edge reconstruction, and inference speed.", "result": "PixelBoost demonstrated superior performance in metrics like LPIPS, LOE, PSNR, and SSIM, along with improved edge reconstruction and faster inference times.", "conclusion": "PixelBoost effectively balances realism, computational efficiency, and adaptive learning, making it a promising approach for advanced image super-resolution tasks."}}
{"id": "2506.23578", "pdf": "https://arxiv.org/pdf/2506.23578", "abs": "https://arxiv.org/abs/2506.23578", "authors": ["\u0141ukasz Kami\u0144ski", "S\u0142awomir Lasota"], "title": "Reachability in symmetric VASS", "categories": ["cs.FL", "cs.CL"], "comment": null, "summary": "We investigate the reachability problem in symmetric vector addition systems\nwith states (VASS), where transitions are invariant under a group of\npermutations of coordinates. One extremal case, the trivial groups, yields\ngeneral VASS. In another extremal case, the symmetric groups, we show that the\nreachability problem can be solved in PSPACE, regardless of the dimension of\ninput VASS (to be contrasted with Ackermannian complexity in general VASS). We\nalso consider other groups, in particular alternating and cyclic ones.\nFurthermore, motivated by the open status of the reachability problem in data\nVASS, we estimate the gain in complexity when the group arises as a combination\nof the trivial and symmetric groups.", "AI": {"tldr": "The paper explores the reachability of symmetric vector addition systems with states (VASS), demonstrating PSPACE complexity for symmetric groups and addressing other group invariants.", "motivation": "Understanding the impact of group symmetry on VASS reachability and addressing complexities such as the open problem in data VASS.", "method": "Analyzing symmetric VASS where transitions follow group permutations, exploring various groups like symmetric, alternating, and cyclic.", "result": "PSPACE complexity is established for symmetric groups in VASS, improving substantially over Ackermannian complexity seen in general VASS.", "conclusion": "Group symmetry significantly reduces computational complexity in VASS reachability, with potential insights for data VASS reachability problems."}}
{"id": "2506.24005", "pdf": "https://arxiv.org/pdf/2506.24005", "abs": "https://arxiv.org/abs/2506.24005", "authors": ["He Wang", "Xingyu Xu", "Yuejie Chi"], "title": "Provably Efficient and Agile Randomized Q-Learning", "categories": ["cs.LG"], "comment": null, "summary": "While Bayesian-based exploration often demonstrates superior empirical\nperformance compared to bonus-based methods in model-based reinforcement\nlearning (RL), its theoretical understanding remains limited for model-free\nsettings. Existing provable algorithms either suffer from computational\nintractability or rely on stage-wise policy updates which reduce responsiveness\nand slow down the learning process. In this paper, we propose a novel variant\nof Q-learning algorithm, refereed to as RandomizedQ, which integrates\nsampling-based exploration with agile, step-wise, policy updates, for episodic\ntabular RL. We establish an $\\widetilde{O}(\\sqrt{H^5SAT})$ regret bound, where\n$S$ is the number of states, $A$ is the number of actions, $H$ is the episode\nlength, and $T$ is the total number of episodes. In addition, we present a\nlogarithmic regret bound under a mild positive sub-optimality condition on the\noptimal Q-function. Empirically, RandomizedQ exhibits outstanding performance\ncompared to existing Q-learning variants with both bonus-based and\nBayesian-based exploration on standard benchmarks.", "AI": {"tldr": "This paper introduces RandomizedQ, a novel Q-learning variant for episodic tabular RL, combining sampling-based exploration and step-wise policy updates, achieving competitive empirical and theoretical results.", "motivation": "The paper seeks to address computational inefficiency and slow learning in provable RL algorithms, particularly in the context of model-free Bayesian-based exploration, which lacks theoretical grounding.", "method": "RandomizedQ applies sampling-based exploration with step-wise policy updates, ensuring responsiveness while guaranteeing provable regret bounds.", "result": "The proposed algorithm achieves an $\nwidetilde{O}(\\sqrt{H^5SAT})$ regret bound and demonstrates exceptional empirical performance compared to existing Q-learning variants.", "conclusion": "RandomizedQ bridges refined theoretical insight and practical efficiency, showing promise as an effective exploration method for RL tasks."}}
{"id": "2506.23257", "pdf": "https://arxiv.org/pdf/2506.23257", "abs": "https://arxiv.org/abs/2506.23257", "authors": ["Chongke Bi", "Xin Gao", "Baofeng Fu", "Yuheng Zhao", "Siming Chen", "Ying Zhao", "Yunhai Wang"], "title": "PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation", "categories": ["cs.CV"], "comment": null, "summary": "Large-scale simulations on supercomputers have become important tools for\nusers. However, their scalability remains a problem due to the huge\ncommunication cost among parallel processes. Most of the existing communication\nlatency analysis methods rely on the physical link layer information, which is\nonly available to administrators. In this paper, a framework called PCLVis is\nproposed to help general users analyze process communication latency (PCL)\nevents. Instead of the physical link layer information, the PCLVis uses the MPI\nprocess communication data for the analysis. First, a spatial PCL event\nlocating method is developed. All processes with high correlation are\nclassified into a single cluster by constructing a process-correlation tree.\nSecond, the propagation path of PCL events is analyzed by constructing a\ncommunication-dependency-based directed acyclic graph (DAG), which can help\nusers interactively explore a PCL event from the temporal evolution of a\nlocated PCL event cluster. In this graph, a sliding window algorithm is\ndesigned to generate the PCL events abstraction. Meanwhile, a new glyph called\nthe communication state glyph (CS-Glyph) is designed for each process to show\nits communication states, including its in/out messages and load balance. Each\nleaf node can be further unfolded to view additional information. Third, a PCL\nevent attribution strategy is formulated to help users optimize their\nsimulations. The effectiveness of the PCLVis framework is demonstrated by\nanalyzing the PCL events of several simulations running on the TH-1A\nsupercomputer. By using the proposed framework, users can greatly improve the\nefficiency of their simulations.", "AI": {"tldr": "This paper proposes PCLVis, a framework for analyzing process communication latency (PCL) events in parallel computing without relying on physical link information by leveraging MPI data and advanced visualization techniques.", "motivation": "Scalability challenges in large-scale simulations due to high communication costs among parallel processes motivate the development of a user-accessible framework for analyzing communication latency.", "method": "The framework includes: (1) spatial clustering of highly correlated processes using a process-correlation tree, (2) propagation path analysis via a communication-dependency-based directed acyclic graph (DAG) with a sliding window algorithm and a new communication state glyph (CS-Glyph) for visualization, and (3) attribution strategy to optimize simulations.", "result": "PCLVis effectively analyzes PCL events on the TH-1A supercomputer, enabling users to identify issues and significantly enhance simulation efficiency.", "conclusion": "PCLVis equips general users with tools to analyze and address communication latency in simulations, reducing reliance on administrators and improving scalability."}}
{"id": "2506.23670", "pdf": "https://arxiv.org/pdf/2506.23670", "abs": "https://arxiv.org/abs/2506.23670", "authors": ["Mohammadmahdi Nouriborji", "Morteza Rohanian"], "title": "Efficient Interleaved Speech Modeling through Knowledge Distillation", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Current speech language models exceed the size and latency constraints of\nmany deployment environments. We build compact, expressive speech generation\nmodels through layer-aligned distillation, matching hidden states, attention\nmaps, and softened logits to compress large multimodal transformers by 3x with\nminimal loss in performance. We introduce TinyWave, a family of 2B-parameter\nmodels for speech-to-speech and interleaved speech-text generation, trained on\n50,000 hours of public audio. TinyWave supports (i) speech-only generation\nusing phonetic or expressive tokens and (ii) mixed speech-text continuations.\nEvaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity\npoints of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%\nof the teacher's performance, outperforming size-matched baselines. These\nmodels are optimized for deployment on commodity hardware, enabling\napplications in real-time conversational agents, assistive technologies, and\nlow-resource environments. We release models, training code, and evaluation\nscripts to support reproducible research on compact, expressive speech\ngeneration.", "AI": {"tldr": "The paper presents TinyWave, a family of compact, expressive speech generation models that compress large multimodal transformers by 3x with minimal performance loss, achieving high accuracy in speech-to-speech and interleaved speech-text tasks.", "motivation": "To address the challenge of deploying oversized speech language models on hardware with size and latency limitations, enabling broader real-time and low-resource applications.", "method": "The paper employs layer-aligned distillation, matching hidden states, attention maps, and softened logits to compress large multimodal transformers into smaller, more efficient models, specifically creating the TinyWave family with 2B parameters.", "result": "TinyWave demonstrates competitive performance: within 1.4 normalized perplexity points of teacher models on Libri-Light, and 93-97% accuracy of teacher model performance on spoken StoryCloze and SALMon tasks, outperforming similarly sized baselines.", "conclusion": "TinyWave offers a scalable solution for compact, expressive speech generation suitable for real-time and low-resource scenarios, with released models and tools supporting reproducible research."}}
{"id": "2506.24018", "pdf": "https://arxiv.org/pdf/2506.24018", "abs": "https://arxiv.org/abs/2506.24018", "authors": ["Veronica Lachi", "Francesco Ferrini", "Antonio Longa", "Bruno Lepri", "Andrea Passerini", "Manfred Jaeger"], "title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) are widely used to compute representations of\nnode pairs for downstream tasks such as link prediction. Yet, theoretical\nunderstanding of their expressive power has focused almost entirely on\ngraph-level representations. In this work, we shift the focus to links and\nprovide the first comprehensive study of GNN expressiveness in link\nrepresentation. We introduce a unifying framework, the $k_\\phi$-$k_\\rho$-$m$\nframework, that subsumes existing message-passing link models and enables\nformal expressiveness comparisons. Using this framework, we derive a hierarchy\nof state-of-the-art methods and offer theoretical tools to analyze future\narchitectures. To complement our analysis, we propose a synthetic evaluation\nprotocol comprising the first benchmark specifically designed to assess\nlink-level expressiveness. Finally, we ask: does expressiveness matter in\npractice? We use a graph symmetry metric that quantifies the difficulty of\ndistinguishing links and show that while expressive models may underperform on\nstandard benchmarks, they significantly outperform simpler ones as symmetry\nincreases, highlighting the need for dataset-aware model selection.", "AI": {"tldr": "This paper studies the expressive power of Graph Neural Networks (GNNs) for link prediction, introducing a unifying framework and synthetic benchmark for analysis.", "motivation": "Most prior theoretical work on GNNs focuses on graph-level representations, neglecting the expressiveness needed for node pair/link-level tasks.", "method": "The authors developed the $k_\\phi$-$k_\\rho$-$m$ framework, which generalizes existing link models, derived an expressiveness hierarchy, and proposed evaluation protocols for benchmarking link-level performance.", "result": "Expressive GNN models outperform simpler ones in challenging settings with high graph symmetry, although they may underperform on standard benchmarks.", "conclusion": "Expressiveness matters in practical applications and dataset-aware model selection is critical for link prediction tasks."}}
{"id": "2506.23263", "pdf": "https://arxiv.org/pdf/2506.23263", "abs": "https://arxiv.org/abs/2506.23263", "authors": ["Lei-lei Li", "Jianwu Fang", "Junbin Xiao", "Shanmin Pang", "Hongkai Yu", "Chen Lv", "Jianru Xue", "Tat-Seng Chua"], "title": "Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Egocentricly comprehending the causes and effects of car accidents is crucial\nfor the safety of self-driving cars, and synthesizing causal-entity reflected\naccident videos can facilitate the capability test to respond to unaffordable\naccidents in reality. However, incorporating causal relations as seen in\nreal-world videos into synthetic videos remains challenging. This work argues\nthat precisely identifying the accident participants and capturing their\nrelated behaviors are of critical importance. In this regard, we propose a\nnovel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic\naccident videos. To enable causal entity grounding in video diffusion,\nCausal-VidSyn leverages the cause descriptions and driver fixations to identify\nthe accident participants and behaviors, facilitated by accident reason\nanswering and gaze-conditioned selection modules. To support Causal-VidSyn, we\nfurther construct Drive-Gaze, the largest driver gaze dataset (with 1.54M\nframes of fixations) in driving accident scenarios. Extensive experiments show\nthat Causal-VidSyn surpasses state-of-the-art video diffusion models in terms\nof frame quality and causal sensitivity in various tasks, including accident\nvideo editing, normal-to-accident video diffusion, and text-to-video\ngeneration.", "AI": {"tldr": "This paper introduces Causal-VidSyn, a novel diffusion model aimed at synthesizing egocentric traffic accident videos that incorporate causal relationships visually, using data like driver fixations and textual accident descriptions.", "motivation": "Understanding causes and effects of traffic accidents egocentrically is essential for improving self-driving car safety, and synthetic accident videos can help test and train autonomous systems for rare, costly accident scenarios.", "method": "The authors developed Causal-VidSyn, a causal video diffusion model that uses driver gaze-related data and accident descriptions to identify accident participants and behaviors. It includes modules for accident reasoning and gaze-conditioned data selection.", "result": "Causal-VidSyn demonstrated superior performance compared to state-of-the-art video diffusion models in terms of frame quality and causal sensitivity across tasks such as accident video editing, normal-to-accident transformation, and text-to-video synthesis.", "conclusion": "The proposed method provides advancements in synthetic accident video creation, highlighting the importance of causal entity grounding and accident participant identification for egocentric video applications in self-driving scenarios."}}
{"id": "2506.23270", "pdf": "https://arxiv.org/pdf/2506.23270", "abs": "https://arxiv.org/abs/2506.23270", "authors": ["Yi Li", "Hualiang Wang", "Xinpeng Ding", "Haonan Wang", "Xiaomeng Li"], "title": "Token Activation Map to Visually Explain Multimodal LLMs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV2025 Accepted", "summary": "Multimodal large language models (MLLMs) are broadly empowering various\nfields. Despite their advancements, the explainability of MLLMs remains less\nexplored, hindering deeper understanding, model credibility, and effective\nvisualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that\nproduce a single output, MLLMs generate sequences of tokens progressively,\nwhere each generated token depends on the previous context. Therefore, earlier\ncontext tokens can introduce redundant activations that interfere with the\nexplanation of later tokens beyond their original information. Existing studies\noften overlook this issue, but our observations reveal that these redundant\ncorrelations can significantly hurt the reliability of explanations. To address\nthis, we propose an estimated causal inference method to mitigate the\ninterference of context to achieve high-quality MLLM explanation, with a novel\nrank Gaussian filter to further reduce activation noises. We term this method\nToken Activation Map (TAM) to highlight the consideration of interactions\nbetween tokens. TAM also indicates that it excels at explaining multiple tokens\nof MLLM, which is different from the Class Activation Map (CAM) for a single\nprediction. Our TAM method significantly outperforms existing SoTA methods,\nshowcasing high-quality visualization results that can be utilized for various\nscenarios, such as object localization, failure case analysis, video\nvisualization, MLLMs visual comparison, and model understanding (e.g., color,\nshape, action, location, visual reasoning, multi-turn conversation, etc). The\ncode is available atgithub.com/xmed-lab/TAM.", "AI": {"tldr": "The paper introduces Token Activation Map (TAM), a novel explanation method for Multimodal Large Language Models (MLLMs) that improves visualization and reliability by addressing redundant activations in token sequences.", "motivation": "Explainability of MLLMs is underexplored, leading to challenges in understanding, credibility, and effective visualization, particularly due to interference from redundant context token activations.", "method": "The authors propose an estimated causal inference method combined with a rank Gaussian filter to reduce activation noise and highlight token interactions. TAM distills reliable explanations for multiple tokens, unlike single-output explanations like CAM.", "result": "The TAM method significantly outperforms state-of-the-art methods in generating high-quality visualizations, aiding use cases like object localization, analysis of failure cases, model comparisons, and understanding complex scenarios in MLLMs.", "conclusion": "TAM enhances MLLM explanations by addressing token-interference issues, providing superior visualization results for understanding models in diverse applications. The method offers advancements over existing approaches."}}
{"id": "2506.23714", "pdf": "https://arxiv.org/pdf/2506.23714", "abs": "https://arxiv.org/abs/2506.23714", "authors": ["Md Moinul Islam", "Sofoklis Kakouros", "Janne Heikkil\u00e4", "Mourad Oussalah"], "title": "Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to HHAI WS 2025: Workshops at the Fourth International\n  Conference on Hybrid Human-Artificial Intelligence (HHAI)", "summary": "The increasing volume of video content in educational, professional, and\nsocial domains necessitates effective summarization techniques that go beyond\ntraditional unimodal approaches. This paper proposes a behaviour-aware\nmultimodal video summarization framework that integrates textual, audio, and\nvisual cues to generate timestamp-aligned summaries. By extracting prosodic\nfeatures, textual cues and visual indicators, the framework identifies\nsemantically and emotionally important moments. A key contribution is the\nidentification of bonus words, which are terms emphasized across multiple\nmodalities and used to improve the semantic relevance and expressive clarity of\nthe summaries. The approach is evaluated against pseudo-ground truth (pGT)\nsummaries generated using LLM-based extractive method. Experimental results\ndemonstrate significant improvements over traditional extractive method, such\nas the Edmundson method, in both text and video-based evaluation metrics.\nText-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore\nfrom 0.9152 to 0.9536, while in video-based evaluation, our proposed framework\nimproves F1-Score by almost 23%. The findings underscore the potential of\nmultimodal integration in producing comprehensive and behaviourally informed\nvideo summaries.", "AI": {"tldr": "This paper introduces a multimodal video summarization framework combining textual, audio, and visual cues to create timestamp-aligned summaries, outperforming traditional methods in semantic relevance and clarity.", "motivation": "The need for effective video summarization techniques has grown due to the increased volume of video content in educational, professional, and social domains.", "method": "The framework uses prosodic features, textual cues, visual indicators, and identifies bonus words emphasized across modalities to create semantically and emotionally relevant summaries. It evaluates against pseudo-ground truth summaries created by LLM-based extractive methods.", "result": "The framework shows significant improvement over traditional methods, with ROUGE-1 improving from 0.4769 to 0.7929, BERTScore from 0.9152 to 0.9536, and a 23% increase in video-based evaluation F1-Score.", "conclusion": "Multimodal integration effectively enhances comprehensiveness and emotional relevance in video summarization, making it a promising approach for summarizing complex video content."}}
{"id": "2506.22789", "pdf": "https://arxiv.org/pdf/2506.22789", "abs": "https://arxiv.org/abs/2506.22789", "authors": ["Oguzhan Baser", "Ahmet Ege Tanriverdi", "Kaan Kale", "Sandeep P. Chinchali", "Sriram Vishwanath"], "title": "WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "5 pages, 4 figures, Published at The Proceedings of Interspeech 2025,\n  code is available at http://www.github.com/UTAustin-SwarmLab/WavShape", "summary": "Speech embeddings often retain sensitive attributes such as speaker identity,\naccent, or demographic information, posing risks in biased model training and\nprivacy leakage. We propose WavShape, an information-theoretic speech\nrepresentation learning framework that optimizes embeddings for fairness and\nprivacy while preserving task-relevant information. We leverage mutual\ninformation (MI) estimation using the Donsker-Varadhan formulation to guide an\nMI-based encoder that systematically filters sensitive attributes while\nmaintaining speech content essential for downstream tasks. Experimental results\non three known datasets show that WavShape reduces MI between embeddings and\nsensitive attributes by up to 81% while retaining 97% of task-relevant\ninformation. By integrating information theory with self-supervised speech\nmodels, this work advances the development of fair, privacy-aware, and\nresource-efficient speech systems.", "AI": {"tldr": "This paper introduces WavShape, a framework for speech embeddings that reduces sensitive attribute leakage while maintaining task-relevant information to promote fairness and privacy in speech systems.", "motivation": "Sensitive attributes in speech embeddings can lead to biased model training and privacy risks, prompting a need for optimized representation learning that balances fairness, privacy, and task-relevance.", "method": "The authors employ mutual information estimation, specifically utilizing the Donsker-Varadhan formulation, to guide an encoder that filters sensitive information while preserving data important for downstream speech tasks.", "result": "WavShape demonstrated a reduction of mutual information between embeddings and sensitive attributes by up to 81%, while preserving 97% of the task-relevant information across three datasets.", "conclusion": "This study advances the development of fair, privacy-aware, and efficient speech systems by integrating information theory and self-supervised learning, achieving both fairness and utility in speech representation learning."}}
{"id": "2506.24093", "pdf": "https://arxiv.org/pdf/2506.24093", "abs": "https://arxiv.org/abs/2506.24093", "authors": ["Paul Wachter", "Lukas Niehaus", "Julius Sch\u00f6ning"], "title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies", "categories": ["cs.LG", "cs.AI", "I.2.1; I.2.0; F.2.3"], "comment": "21pages, 14 figures, 2 tables", "summary": "Synthetic data has emerged as a cost-effective alternative to real data for\ntraining artificial neural networks (ANN). However, the disparity between\nsynthetic and real data results in a domain gap. That gap leads to poor\nperformance and generalization of the trained ANN when applied to real-world\nscenarios. Several strategies have been developed to bridge this gap, which\ncombine synthetic and real data, known as mixed training using hybrid datasets.\nWhile these strategies have been shown to mitigate the domain gap, a systematic\nevaluation of their generalizability and robustness across various tasks and\narchitectures remains underexplored. To address this challenge, our study\ncomprehensively analyzes two widely used mixing strategies on three prevalent\narchitectures and three distinct hybrid datasets. From these datasets, we\nsample subsets with varying proportions of synthetic to real data to\ninvestigate the impact of synthetic and real components. The findings of this\npaper provide valuable insights into optimizing the use of synthetic data in\nthe training process of any ANN, contributing to enhancing robustness and\nefficacy.", "AI": {"tldr": "This paper studies the effectiveness of mixing synthetic and real data for ANN training to address domain gaps and evaluates the strategies across tasks and architectures.", "motivation": "Synthetic data is cost-effective for ANN training, but domain gaps with real data hinder real-world performance.", "method": "The study systematically evaluates mixing strategies for synthetic and real data on three architectures and hybrid datasets with varying proportions.", "result": "The findings provide insights into the impact of synthetic and real data components and their influence on robustness and efficacy.", "conclusion": "Optimizing synthetic data usage for ANN training can enhance generalizability, robustness, and applicability in real-world scenarios."}}
{"id": "2506.23271", "pdf": "https://arxiv.org/pdf/2506.23271", "abs": "https://arxiv.org/abs/2506.23271", "authors": ["Jinxing Zhou", "Zhihui Li", "Yongqiang Yu", "Yanghao Zhou", "Ruohao Guo", "Guangyao Li", "Yuxin Mao", "Mingfei Han", "Xiaojun Chang", "Meng Wang"], "title": "Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "We present \\textbf{Met}a-\\textbf{T}oken \\textbf{Le}arning (Mettle), a simple\nand memory-efficient method for adapting large-scale pretrained transformer\nmodels to downstream audio-visual tasks. Instead of sequentially modifying the\noutput feature distribution of the transformer backbone, Mettle utilizes a\nlightweight \\textit{Layer-Centric Distillation (LCD)} module to distill in\nparallel the intact audio or visual features embedded by each transformer layer\ninto compact meta-tokens. This distillation process considers both pretrained\nknowledge preservation and task-specific adaptation. The obtained meta-tokens\ncan be directly applied to classification tasks, such as audio-visual event\nlocalization and audio-visual video parsing. To further support fine-grained\nsegmentation tasks, such as audio-visual segmentation, we introduce a\n\\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual\nmeta-tokens distilled from the top transformer layer to guide feature\nadaptation in earlier layers. Extensive experiments on multiple audiovisual\nbenchmarks demonstrate that our method significantly reduces memory usage and\ntraining time while maintaining parameter efficiency and competitive accuracy.", "AI": {"tldr": "Mettle is a memory-efficient method using meta-tokens for adapting transformers to audio-visual tasks, maintaining strong performance with reduced computational requirements.", "motivation": "Many large-scale pretrained transformer models face challenges in adapting to specific audio-visual tasks without incurring significant memory and computational overhead.", "method": "Mettle incorporates a Layer-Centric Distillation (LCD) module to create compact meta-tokens for classification tasks and a Meta-Token Injection (MTI) module to improve segmentation tasks by guiding earlier transformer layers.", "result": "The approach demonstrates reduced memory usage, faster training, and competitive accuracy across various audio-visual benchmarks.", "conclusion": "Mettle provides an effective way to adapt large-scale transformers to downstream audio-visual tasks while being memory-efficient and maintaining high task performance."}}
{"id": "2506.22793", "pdf": "https://arxiv.org/pdf/2506.22793", "abs": "https://arxiv.org/abs/2506.22793", "authors": ["Pegah Alizadeh", "Anastasios Giovanidis", "Pradeepa Ramachandra", "Vasileios Koutsoukis", "Osama Arouk"], "title": "Offline Reinforcement Learning for Mobility Robustness Optimization", "categories": ["cs.NI", "cs.AI", "cs.PF"], "comment": "7 pages, double column, 4 figures, 6 tables, conference submission", "summary": "In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm\nand study the possibility of learning the optimal Cell Individual Offset tuning\nusing offline Reinforcement Learning. Such methods make use of collected\noffline datasets to learn the optimal policy, without further exploration. We\nadapt and apply a sequence-based method called Decision Transformers as well as\na value-based method called Conservative Q-Learning to learn the optimal policy\nfor the same target reward as the vanilla rule-based MRO. The same input\nfeatures related to failures, ping-pongs, and other handover issues are used.\nEvaluation for realistic New Radio networks with 3500 MHz carrier frequency on\na traffic mix including diverse user service types and a specific tunable\ncell-pair shows that offline-RL methods outperform rule-based MRO, offering up\nto 7% improvement. Furthermore, offline-RL can be trained for diverse objective\nfunctions using the same available dataset, thus offering operational\nflexibility compared to rule-based methods.", "AI": {"tldr": "This paper explores using offline reinforcement learning methods to improve Mobility Robustness Optimization (MRO) in New Radio networks, achieving up to 7% improvement over traditional methods.", "motivation": "The authors aim to enhance the Mobility Robustness Optimization (MRO) process by leveraging offline reinforcement learning to address limitations of traditional rule-based algorithms.", "method": "The study applies offline reinforcement learning methods, specifically Decision Transformers and Conservative Q-Learning, to learn optimal Cell Individual Offset tuning using input features such as failures and handover issues.", "result": "Offline reinforcement learning methods outperform traditional rule-based MRO algorithms, demonstrating up to 7% improved performance in New Radio networks operating at a 3500 MHz carrier frequency.", "conclusion": "Offline reinforcement learning is a promising approach for MRO, allowing for both performance improvements and operational flexibility by enabling diverse objective functions using the same datasets."}}
{"id": "2506.23275", "pdf": "https://arxiv.org/pdf/2506.23275", "abs": "https://arxiv.org/abs/2506.23275", "authors": ["Chengyou Jia", "Xin Shen", "Zhuohang Dang", "Zhuohang Dang", "Changliang Xia", "Weijia Wu", "Xinyu Zhang", "Hangwei Qian", "Ivor W. Tsang", "Minnan Luo"], "title": "Why Settle for One? Text-to-ImageSet Generation and Evaluation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite remarkable progress in Text-to-Image models, many real-world\napplications require generating coherent image sets with diverse consistency\nrequirements. Existing consistent methods often focus on a specific domain with\nspecific aspects of consistency, which significantly constrains their\ngeneralizability to broader applications. In this paper, we propose a more\nchallenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate\nsets of images that meet various consistency requirements based on user\ninstructions. To systematically study this problem, we first introduce\n$\\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories,\nproviding comprehensive coverage for T2IS generation. Building on this, we\npropose $\\textbf{T2IS-Eval}$, an evaluation framework that transforms user\ninstructions into multifaceted assessment criteria and employs effective\nevaluators to adaptively assess consistency fulfillment between criteria and\ngenerated sets. Subsequently, we propose $\\textbf{AutoT2IS}$, a training-free\nframework that maximally leverages pretrained Diffusion Transformers'\nin-context capabilities to harmonize visual elements to satisfy both\nimage-level prompt alignment and set-level visual consistency. Extensive\nexperiments on T2IS-Bench reveal that diverse consistency challenges all\nexisting methods, while our AutoT2IS significantly outperforms current\ngeneralized and even specialized approaches. Our method also demonstrates the\nability to enable numerous underexplored real-world applications, confirming\nits substantial practical value. Visit our project in\nhttps://chengyou-jia.github.io/T2IS-Home.", "AI": {"tldr": "The paper introduces the Text-to-ImageSet (T2IS) problem, aiming to generate coherent image sets with diverse consistency requirements based on user instructions. It proposes benchmarks, evaluation frameworks, and the AutoT2IS framework for training-free, consistency-driven image set generation.", "motivation": "Current Text-to-Image models struggle with generating coherent sets of images when diverse consistency requirements are needed, limiting their real-world application.", "method": "The paper proposes AutoT2IS, a training-free framework leveraging pretrained Diffusion Transformers with in-context capabilities to ensure visual consistency at both image and set levels. They also introduce T2IS-Bench for diverse-instruction benchmarking and T2IS-Eval for adaptive consistency evaluation.", "result": "Experiments on T2IS-Bench reveal that existing methods face challenges with diverse consistency requirements, but AutoT2IS significantly outperforms both generalized and specialized methods.", "conclusion": "AutoT2IS addresses the limitations of existing Text-to-Image methods by generating coherent image sets with diverse consistency needs, unlocking various real-world applications and demonstrating substantial practical value."}}
{"id": "2506.24124", "pdf": "https://arxiv.org/pdf/2506.24124", "abs": "https://arxiv.org/abs/2506.24124", "authors": ["Dong Sixun", "Fan Wei", "Teresa Wu", "Fu Yanjie"], "title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "categories": ["cs.LG", "cs.CV"], "comment": "Code: https://github.com/Ironieser/TimesCLIP", "summary": "Time series forecasting traditionally relies on unimodal numerical inputs,\nwhich often struggle to capture high-level semantic patterns due to their dense\nand unstructured nature. While recent approaches have explored representing\ntime series as text using large language models (LLMs), these methods remain\nlimited by the discrete nature of token sequences and lack the perceptual\nintuition humans typically apply, such as interpreting visual patterns. In this\npaper, we propose a multimodal contrastive learning framework that transforms\nraw time series into structured visual and textual perspectives. Rather than\nusing natural language or real-world images, we construct both modalities\ndirectly from numerical sequences. We then align these views in a shared\nsemantic space via contrastive learning, enabling the model to capture richer\nand more complementary representations. Furthermore, we introduce a variate\nselection module that leverages the aligned representations to identify the\nmost informative variables for multivariate forecasting. Extensive experiments\non fifteen short-term and six long-term forecasting benchmarks demonstrate that\nour approach consistently outperforms strong unimodal and cross-modal\nbaselines, highlighting the effectiveness of multimodal alignment in enhancing\ntime series forecasting. Code is available at:\nhttps://github.com/Ironieser/TimesCLIP.", "AI": {"tldr": "The paper introduces a multimodal approach for time series forecasting by converting numerical inputs into visual and textual forms and aligning them using contrastive learning for improved representation and performance.", "motivation": "Traditional unimodal numerical time series forecasting struggles with capturing high-level semantic patterns due to their dense and unstructured nature. This paper aims to harness multimodal perspectives, such as visual and textual representations, for improved pattern recognition and forecasting.", "method": "The proposed method uses a multimodal contrastive learning framework to transform numerical time series data into visual and textual representations. The alignment of these modalities in a shared semantic space is achieved through contrastive learning. Additionally, a variate selection module is introduced to identify key informative variables for multivariate forecasting.", "result": "The multimodal approach outperforms strong unimodal and cross-modal baselines across fifteen short-term and six long-term forecasting benchmarks. This highlights the advantage of the proposed multimodal alignment framework.", "conclusion": "Multimodal alignment, leveraging structured visual and textual representations, significantly enhances time series forecasting capabilities, especially in capturing richer and complementary representations compared to unimodal approaches."}}
{"id": "2506.23282", "pdf": "https://arxiv.org/pdf/2506.23282", "abs": "https://arxiv.org/abs/2506.23282", "authors": ["Hanwen Zhang", "Congqi Cao", "Qinyi Lv", "Lingtong Min", "Yanning Zhang"], "title": "Autoregressive Denoising Score Matching is a Good Video Anomaly Detector", "categories": ["cs.CV"], "comment": null, "summary": "Video anomaly detection (VAD) is an important computer vision problem. Thanks\nto the mode coverage capabilities of generative models, the likelihood-based\nparadigm is catching growing interest, as it can model normal distribution and\ndetect out-of-distribution anomalies. However, these likelihood-based methods\nare blind to the anomalies located in local modes near the learned\ndistribution. To handle these ``unseen\" anomalies, we dive into three gaps\nuniquely existing in VAD regarding scene, motion and appearance. Specifically,\nwe first build a noise-conditioned score transformer for denoising score\nmatching. Then, we introduce a scene-dependent and motion-aware score function\nby embedding the scene condition of input sequences into our model and\nassigning motion weights based on the difference between key frames of input\nsequences. Next, to solve the problem of blindness in principle, we integrate\nunaffected visual information via a novel autoregressive denoising score\nmatching mechanism for inference. Through autoregressively injecting\nintensifying Gaussian noise into the denoised data and estimating the\ncorresponding score function, we compare the denoised data with the original\ndata to get a difference and aggregate it with the score function for an\nenhanced appearance perception and accumulate the abnormal context. With all\nthree gaps considered, we can compute a more comprehensive anomaly indicator.\nExperiments on three popular VAD benchmarks demonstrate the state-of-the-art\nperformance of our method.", "AI": {"tldr": "This paper proposes a novel method for video anomaly detection (VAD) by addressing gaps in scene, motion, and appearance understanding using a noise-conditioned score transformer and autoregressive denoising techniques.", "motivation": "Video anomaly detection is challenging due to inaccuracies when detecting anomalies near the learned distribution modes. Previous methods fail to comprehensively address local 'unseen' anomalies in visual data.", "method": "The authors build a noise-conditioned score transformer and integrate scene-dependent, motion-aware, and appearance-enhanced mechanisms. An autoregressive denoising score matching approach is used for anomaly inference.", "result": "The proposed model demonstrates state-of-the-art performance on three popular VAD benchmarks, highlighting its robustness in detecting diverse anomalies.", "conclusion": "Considering scene, motion, and appearance gaps enhances anomaly detection capabilities, offering a more effective and comprehensive approach for VAD."}}
{"id": "2506.24019", "pdf": "https://arxiv.org/pdf/2506.24019", "abs": "https://arxiv.org/abs/2506.24019", "authors": ["Hongxin Zhang", "Zheyuan Zhang", "Zeyuan Wang", "Zunzhe Zhang", "Lixing Fang", "Qinhong Zhou", "Chuang Gan"], "title": "Ella: Embodied Social Agents with Lifelong Memory", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We introduce Ella, an embodied social agent capable of lifelong learning\nwithin a community in a 3D open world, where agents accumulate experiences and\nacquire knowledge through everyday visual observations and social interactions.\nAt the core of Ella's capabilities is a structured, long-term multimodal memory\nsystem that stores, updates, and retrieves information effectively. It consists\nof a name-centric semantic memory for organizing acquired knowledge and a\nspatiotemporal episodic memory for capturing multimodal experiences. By\nintegrating this lifelong memory system with foundation models, Ella retrieves\nrelevant information for decision-making, plans daily activities, builds social\nrelationships, and evolves autonomously while coexisting with other intelligent\nbeings in the open world. We conduct capability-oriented evaluations in a\ndynamic 3D open world where 15 agents engage in social activities for days and\nare assessed with a suite of unseen controlled evaluations. Experimental\nresults show that Ella can influence, lead, and cooperate with other agents\nwell to achieve goals, showcasing its ability to learn effectively through\nobservation and social interaction. Our findings highlight the transformative\npotential of combining structured memory systems with foundation models for\nadvancing embodied intelligence. More videos can be found at\nhttps://umass-embodied-agi.github.io/Ella/.", "AI": {"tldr": "This paper introduces Ella, an embodied agent in a 3D world capable of lifelong learning through observations and social interactions, leveraging a structured memory system.", "motivation": "To demonstrate that combining structured lifelong memory systems with foundation models can lead to advanced embodied intelligence in open-world settings.", "method": "Ella uses a structured multimodal memory system with semantic and episodic components, integrated with foundation models, for decision-making and autonomous behavior in a dynamic 3D open world.", "result": "Ella effectively learns by observation and interaction, influencing and cooperating with other agents to achieve goals during controlled evaluations in the simulated environment.", "conclusion": "The integration of structured memory systems and foundation models is a promising direction for creating advanced embodied social agents capable of autonomous evolution and interaction."}}
{"id": "2506.23283", "pdf": "https://arxiv.org/pdf/2506.23283", "abs": "https://arxiv.org/abs/2506.23283", "authors": ["Yuhuan Yang", "Chaofan Ma", "Zhenjie Mao", "Jiangchao Yao", "Ya Zhang", "Yanfeng Wang"], "title": "MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition", "categories": ["cs.CV"], "comment": "ICML 2025 paper", "summary": "Video understanding is a complex challenge that requires effective modeling\nof spatial-temporal dynamics. With the success of image foundation models\n(IFMs) in image understanding, recent approaches have explored\nparameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most\nof these methods tend to process spatial and temporal information separately,\nwhich may fail to capture the full intricacy of video dynamics. In this paper,\nwe propose MoMa, an efficient adapter framework that achieves full\nspatial-temporal modeling by integrating Mamba's selective state space modeling\ninto IFMs. We propose a novel SeqMod operation to inject spatial-temporal\ninformation into pre-trained IFMs, without disrupting their original features.\nBy incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances\nvideo understanding while maintaining computational efficiency. Extensive\nexperiments on multiple video benchmarks demonstrate the effectiveness of MoMa,\nachieving superior performance with reduced computational cost.", "AI": {"tldr": "This paper introduces MoMa, a framework to enhance video understanding by modeling spatial-temporal dynamics in image foundation models (IFMs) using efficient strategies.", "motivation": "The motivation is to improve video understanding by addressing the limitations of existing methods that process spatial and temporal information separately, resulting in suboptimal capture of video dynamics.", "method": "The paper introduces MoMa, which incorporates a novel SeqMod operation into the Divide-and-Modulate architecture to achieve full spatial-temporal integration in pre-trained IFMs without disrupting their features.", "result": "Experiments show that MoMa outperforms existing methods on multiple video benchmarks, achieving better performance while reducing computational costs.", "conclusion": "MoMa provides an efficient, effective solution for video understanding by integrating spatial and temporal dynamics into image foundation models, demonstrating superior results and better efficiency."}}
{"id": "2506.24056", "pdf": "https://arxiv.org/pdf/2506.24056", "abs": "https://arxiv.org/abs/2506.24056", "authors": ["Tung-Ling Li", "Hongliang Liu"], "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations.", "AI": {"tldr": "Logit-gap steering is a novel jailbreak framework that manipulates RLHF-aligned language models through an efficient single-pass vocabulary analysis, boosting attack success rates substantially while maintaining coherence.", "motivation": "The study aims to overcome refusal-affirmation gaps in RLHF-aligned models, enabling efficient jailbreaks to probe language model safety and alignment artifacts.", "method": "The paper introduces a forward-computable scoring system that combines logit-gap adjustments, KL penalty, and reward shift proxies, enabling quick 'sort-sum-stop' suffix generation.", "result": "The method achieves 80-100% one-shot attack success rates on checkpoints ranging from 0.5B to 70B, requiring significantly fewer model calls than traditional methods.", "conclusion": "The approach efficiently uncovers vulnerabilities in language model alignments and provides insights into the internal effects of safety tuning."}}
{"id": "2506.22440", "pdf": "https://arxiv.org/pdf/2506.22440", "abs": "https://arxiv.org/abs/2506.22440", "authors": ["Sharique Hasan", "Alexander Oettl", "Sampsa Samila"], "title": "From Model Design to Organizational Design: Complexity Redistribution and Trade-Offs in Generative AI", "categories": ["cs.CY", "cs.LG", "cs.MA", "econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper introduces the Generality-Accuracy-Simplicity (GAS) framework to\nanalyze how large language models (LLMs) are reshaping organizations and\ncompetitive strategy. We argue that viewing AI as a simple reduction in input\ncosts overlooks two critical dynamics: (a) the inherent trade-offs among\ngenerality, accuracy, and simplicity, and (b) the redistribution of complexity\nacross stakeholders. While LLMs appear to defy the traditional trade-off by\noffering high generality and accuracy through simple interfaces, this\nuser-facing simplicity masks a significant shift of complexity to\ninfrastructure, compliance, and specialized personnel. The GAS trade-off,\ntherefore, does not disappear but is relocated from the user to the\norganization, creating new managerial challenges, particularly around accuracy\nin high-stakes applications. We contend that competitive advantage no longer\nstems from mere AI adoption, but from mastering this redistributed complexity\nthrough the design of abstraction layers, workflow alignment, and complementary\nexpertise. This study advances AI strategy by clarifying how scalable cognition\nrelocates complexity and redefines the conditions for technology integration.", "AI": {"tldr": "The paper introduces the Generality-Accuracy-Simplicity (GAS) framework to analyze how large language models (LLMs) impact organizations and competition, highlighting the redistribution of complexity to organizational infrastructure and workflows, thus creating new challenges and opportunities.", "motivation": "To address the evolving strategic and organizational impacts of AI, particularly how large language models reshape complexity and competition, moving beyond traditional cost-reduction perspectives.", "method": "The authors introduce the GAS framework to analyze trade-offs involving generality, accuracy, and simplicity, and illustrate how LLMs shift complexity from users to organizations.", "result": "The study highlights that simplicity for users leads to infrastructural, compliance, and managerial challenges within organizations, redefining competitive advantage strategies around mastering redistributed complexity.", "conclusion": "Competitive advantage in the AI era depends not on adopting LLMs but on effectively managing the complexity they redistribute, through abstraction design, workflow alignment, and complementary expertise."}}
{"id": "2506.23285", "pdf": "https://arxiv.org/pdf/2506.23285", "abs": "https://arxiv.org/abs/2506.23285", "authors": ["Daqian Shi", "Xiaolei Diao", "Xu Chen", "C\u00e9dric M. John"], "title": "Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Deep Neural Networks (DNNs) have significantly advanced the field of computer\nvision. To improve DNN training process, knowledge distillation methods\ndemonstrate their effectiveness in accelerating network training by introducing\na fixed learning direction from the teacher network to student networks. In\nthis context, several distillation-based optimization strategies are proposed,\ne.g., deep mutual learning and self-distillation, as an attempt to achieve\ngeneric training performance enhancement through the cooperative training of\nmultiple networks. However, such strategies achieve limited improvements due to\nthe poor understanding of the impact of learning directions among networks\nacross different iterations. In this paper, we propose a novel competitive\ndistillation strategy that allows each network in a group to potentially act as\na teacher based on its performance, enhancing the overall learning performance.\nCompetitive distillation organizes a group of networks to perform a shared task\nand engage in competition, where competitive optimization is proposed to\nimprove the parameter updating process. We further introduce stochastic\nperturbation in competitive distillation, aiming to motivate networks to induce\nmutations to achieve better visual representations and global optimum. The\nexperimental results show that competitive distillation achieves promising\nperformance in diverse tasks and datasets.", "AI": {"tldr": "This paper proposes a novel competitive distillation strategy where networks act as teachers competitively, improving learning performance.", "motivation": "Traditional knowledge distillation methods lack understanding of learning directions among networks, limiting performance improvements.", "method": "Introduces competitive distillation, allowing dynamic teacher-student roles among networks with stochastic perturbation to enhance learning.", "result": "Experimental results demonstrate promising performance gains across various tasks and datasets.", "conclusion": "Competitive distillation improves DNN training and provides a pathway for better visual representation and optimization strategies."}}
{"id": "2506.24086", "pdf": "https://arxiv.org/pdf/2506.24086", "abs": "https://arxiv.org/abs/2506.24086", "authors": ["Bingfan Zhu", "Biao Jiang", "Sunyi Wang", "Shixiang Tang", "Tao Chen", "Linjie Luo", "Youyi Zheng", "Xin Chen"], "title": "MotionGPT3: Human Motion as a Second Modality", "categories": ["cs.CV", "cs.CL"], "comment": "21 pages, 8 figures", "summary": "Though recent advances in multimodal models have demonstrated strong\ncapabilities and opportunities in unified understanding and generation, the\ndevelopment of unified motion-language models remains underexplored. To enable\nsuch models with high-fidelity human motion, two core challenges must be\naddressed. The first is the reconstruction gap between the continuous motion\nmodality and discrete representation in an autoregressive manner, and the\nsecond is the degradation of language intelligence during unified training.\nInspired by the mixture of experts, we propose MotionGPT3, a bimodal\nmotion-language model that treats human motion as a second modality, decoupling\nmotion modeling via separate model parameters and enabling both effective\ncross-modal interaction and efficient multimodal scaling training. To preserve\nlanguage intelligence, the text branch retains the original structure and\nparameters of the pretrained language model, while a new motion branch is\nintegrated via a shared attention mechanism, enabling bidirectional information\nflow between two modalities. We first employ a motion Variational Autoencoder\n(VAE) to encode raw human motion into latent representations. Based on this\ncontinuous latent space, the motion branch predicts motion latents directly\nfrom intermediate hidden states using a diffusion head, bypassing discrete\ntokenization. Extensive experiments show that our approach achieves competitive\nperformance on both motion understanding and generation tasks while preserving\nstrong language capabilities, establishing a unified bimodal motion diffusion\nframework within an autoregressive manner.", "AI": {"tldr": "MotionGPT3 is a unified motion-language model that addresses challenges in motion reconstruction and language degradation using a mixture-of-experts approach, showing strong performance in both motion and language tasks.", "motivation": "To address the underexplored area of unified motion-language modeling with high-fidelity human motion, overcoming the challenges of motion reconstruction and language intelligence degradation.", "method": "MotionGPT3 employs a bimodal design with separate motion and language branches. The motion branch uses a variational autoencoder to encode human motion into a continuous latent space and integrates it with a shared attention mechanism to preserve language intelligence.", "result": "The model achieves competitive outcomes on both motion understanding and generation tasks, demonstrating effective cross-modal interaction and preserving strong language capabilities.", "conclusion": "MotionGPT3 establishes a robust framework for unified motion-language modeling, presenting an effective solution for cross-modal tasks without compromising language prowess."}}
{"id": "2506.22450", "pdf": "https://arxiv.org/pdf/2506.22450", "abs": "https://arxiv.org/abs/2506.22450", "authors": ["Jens Winkler", "Michael Denhard"], "title": "Arnoldi Singular Vector perturbations for machine learning weather prediction", "categories": ["physics.ao-ph", "cs.LG"], "comment": "dynamical systems, atmospheric physics, machine learing weather\n  prediction, forecast uncertainity, 42 pages with 29 figures (inkl. appendix)", "summary": "Since weather forecasts are fundamentally uncertain, reliable decision making\nrequires information on the likelihoods of future weather scenarios. We explore\nthe sensitivity of machine learning weather prediction (MLWP) using the 24h\nPangu Weather ML model of Huawei to errors in the initial conditions with a\nspecific kind of Singular Vector (SV) perturbations. Our Arnoldi-SV (A-SV)\nmethod does not need linear nor adjoint model versions and is applicable to\nnumerical weather prediction (NWP) as well as MLWP. It observes error growth\nwithin a given optimization time window by iteratively applying a forecast\nmodel to perturbed model states. This creates a Krylov subspace, implicitly\nbased on a matrix operator, which approximates the local error growth. Each\niteration adds new dimensions to the Krylov space and its leading right SVs are\nexpected to turn into directions of growing errors. We show that A-SV indeed\nfinds dynamically meaningful perturbation patterns for the 24h Pangu Weather\nmodel, which grow right from the beginning of the forecast rollout. These\nperturbations describe local unstable modes and could be a basis to initialize\nMLWP ensembles. Since we start A-SV from random noise perturbations, the\nalgorithm transforms noise into perturbations conditioned on a given reference\nstate - a process that is akin to the denoising process of the generic\ndiffusion based ML model of GenCast, therefor we briefly discuss similarities\nand differences.", "AI": {"tldr": "This paper explores how errors in initial conditions affect machine learning weather predictions (MLWP) using a novel Arnoldi-Singular Vector (A-SV) method to identify error growth directions, specifically with Huawei's Pangu Weather model.", "motivation": "To improve the reliability of machine learning weather forecasts by understanding how errors grow under initial condition perturbations, enabling the design of better ensemble prediction systems.", "method": "A-SV method generates perturbations using Krylov subspaces without requiring linear or adjoint models. It observes error growth iteratively by applying the forecast model to perturbed states and identifies leading modes for growing errors.", "result": "A-SV successfully found meaningful perturbation patterns that grow from the start of a forecast rollout in the Pangu Weather model. The perturbations showed local unstable modes useful for initializing prediction ensembles.", "conclusion": "The A-SV method provides dynamically relevant perturbations for MLWP and could enhance ensemble initialization. It draws parallels to the denoising aspect of diffusion-based ML models like GenCast."}}
{"id": "2506.23292", "pdf": "https://arxiv.org/pdf/2506.23292", "abs": "https://arxiv.org/abs/2506.23292", "authors": ["Changtao Miao", "Yi Zhang", "Weize Gao", "Man Luo", "Weiwei Feng", "Zhiya Tan", "Jianshu Li", "Ajian Liu", "Yunfeng Diao", "Qi Chu", "Tao Gong", "Zhe Li", "Weibin Yao", "Joey Tianyi Zhou"], "title": "DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios", "categories": ["cs.CV"], "comment": "This paper is a preliminary version, with an extended and\n  comprehensive version currently under development", "summary": "Recent advances in AIGC have exacerbated the misuse of malicious deepfake\ncontent, making the development of reliable deepfake detection methods an\nessential means to address this challenge. Although existing deepfake detection\nmodels demonstrate outstanding performance in detection metrics, most methods\nonly provide simple binary classification results, lacking interpretability. In\ncritical domains such as law, interpretability is crucial for enhancing the\ncredibility and authority of decisions. Recent studies attempt to improve the\ninterpretability of classification results by providing spatial manipulation\nmasks or temporal forgery segments. However, the practical effectiveness of\nthese methods remains suboptimal due to limitations of the forgery data. Most\ncurrent deepfake datasets predominantly offer binary labels, only a few\ndatasets with localization annotations. However, they suffer from restricted\nforgery scenarios, limited diversity in deepfake types, and insufficient data\nscale, making them inadequate for complex real-world scenarios. To address this\npredicament, we construct a novel large-scale deepfake detection and\nlocalization ($\\textbf{DDL}$) dataset containing over $\\textbf{1.8M}$ forged\nsamples and encompassing up to $\\textbf{75}$ distinct deepfake methods. The DDL\ndesign incorporates four key innovations: (1) $\\textbf{Diverse Forgery\nScenarios}$, (2) $\\textbf{Comprehensive Deepfake Methods}$, (3) $\\textbf{Varied\nManipulation Modes}$, and (4) $\\textbf{Fine-grained Forgery Annotations}$.\nThrough these improvements, our DDL not only provides a more challenging\nbenchmark for complex real-world forgeries, but also offers crucial support for\nbuilding next-generation deepfake detection, localization, and interpretability\nmethods. The DDL dataset project page is on\nhttps://deepfake-workshop-ijcai2025.github.io/main/index.html.", "AI": {"tldr": "The paper introduces a novel large-scale deepfake dataset (DDL) designed to enhance detection and localization accuracy and interpretability, addressing current dataset limitations.", "motivation": "The misuse of malicious deepfake content has grown due to advances in AIGC, necessitating reliable detection methods with interpretability, especially for critical domains like law.", "method": "The authors developed the DDL dataset featuring over 1.8M samples created using 75 distinct deepfake methods, emphasizing diversity, comprehensive techniques, varied manipulation types, and fine-grained annotations.", "result": "DDL serves as a more challenging benchmark with advanced features, aimed at improving detection mechanisms and supporting interpretability in complex real-world forgery scenarios.", "conclusion": "The DDL dataset sets a new standard for next-generation deepfake detection and localization solutions, contributing significantly to the understanding and management of deepfake risks."}}
{"id": "2506.22454", "pdf": "https://arxiv.org/pdf/2506.22454", "abs": "https://arxiv.org/abs/2506.22454", "authors": ["Ana Luiza S. Tavares", "Artur Pedro M. Neto", "Francinaldo L. Gomes", "Paul Rodrigo dos Reis", "Arthur G. da Silva", "Antonio P. Junior", "Bruno D. Gomes"], "title": "Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach", "categories": ["eess.SP", "cs.LG"], "comment": "8 pages, 5 figures", "summary": "Accurate intraoperative localization of the subthalamic nucleus (STN) is\nessential for the efficacy of Deep Brain Stimulation (DBS) in patients with\nParkinson's disease. While microelectrode recordings (MERs) provide rich\nelectrophysiological information during DBS electrode implantation, current\nlocalization practices often rely on subjective interpretation of signal\nfeatures. In this study, we propose a quantitative framework that leverages\nnonlinear dynamics and entropy-based metrics to classify neural activity\nrecorded inside versus outside the STN. MER data from three patients were\npreprocessed using a robust artifact correction pipeline, segmented, and\nlabelled based on surgical annotations. A comprehensive set of recurrence\nquantification analysis, nonlinear, and entropy features were extracted from\neach segment. Multiple supervised classifiers were trained on every combination\nof feature domains using stratified 10-fold cross-validation, followed by\nstatistical comparison using paired Wilcoxon signed-rank tests with\nHolm-Bonferroni correction. The combination of entropy and nonlinear features\nyielded the highest discriminative power, and the Extra Trees classifier\nemerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and\nROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed\nrobust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the\npotential of nonlinear and entropy signal descriptors in supporting real-time,\ndata-driven decision-making during DBS surgeries", "AI": {"tldr": "The study improves Deep Brain Stimulation (DBS) efficacy by proposing an entropy and nonlinear dynamic-based framework for accurate intraoperative localization of the subthalamic nucleus (STN) during Parkinson's surgery, achieving high classification metrics.", "motivation": "Current DBS procedures often rely on subjective interpretation of microelectrode recordings (MERs) to locate the STN, which can impact precision and efficacy. The study aims to develop a data-driven method for enhancing accuracy.", "method": "The paper preprocesses MER data with artifact correction, extracts features using recurrence quantification analysis, nonlinear, and entropy metrics, and tests multiple supervised classifiers through 10-fold cross-validation and statistical methods.", "result": "The entropy and nonlinear features were most discriminative, with the Extra Trees classifier achieving an F1-score of 0.902\u00b10.027 and ROC AUC of 0.887\u00b10.055. Generalization metrics on hold-out data showed F1=0.922 and ROC AUC=0.941.", "conclusion": "Entropy and nonlinear signal analysis reliably distinguish intra-STN from extra-STN activity, offering a robust framework for real-time, data-driven decision support in DBS surgeries."}}
{"id": "2506.23295", "pdf": "https://arxiv.org/pdf/2506.23295", "abs": "https://arxiv.org/abs/2506.23295", "authors": ["Xiang Xu"], "title": "DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On", "categories": ["cs.CV"], "comment": null, "summary": "Virtual try-on (VTON) aims to synthesize realistic images of a person wearing\na target garment, with broad applications in e-commerce and digital fashion.\nWhile recent advances in latent diffusion models have substantially improved\nvisual quality, existing approaches still struggle with preserving fine-grained\ngarment details, achieving precise garment-body alignment, maintaining\ninference efficiency, and generalizing to diverse poses and clothing styles. To\naddress these challenges, we propose DiffFit, a novel two-stage latent\ndiffusion framework for high-fidelity virtual try-on. DiffFit adopts a\nprogressive generation strategy: the first stage performs geometry-aware\ngarment warping, aligning the garment with the target body through fine-grained\ndeformation and pose adaptation. The second stage refines texture fidelity via\na cross-modal conditional diffusion model that integrates the warped garment,\nthe original garment appearance, and the target person image for high-quality\nrendering. By decoupling geometric alignment and appearance refinement, DiffFit\neffectively reduces task complexity and enhances both generation stability and\nvisual realism. It excels in preserving garment-specific attributes such as\ntextures, wrinkles, and lighting, while ensuring accurate alignment with the\nhuman body. Extensive experiments on large-scale VTON benchmarks demonstrate\nthat DiffFit achieves superior performance over existing state-of-the-art\nmethods in both quantitative metrics and perceptual evaluations.", "AI": {"tldr": "DiffFit is a novel two-stage latent diffusion framework for virtual try-on, enhancing garment alignment and visual quality.", "motivation": "Improving the realism and efficiency of virtual try-on systems while addressing issues like garment detail preservation, alignment accuracy, and pose diversity.", "method": "DiffFit uses a two-stage approach: first, geometry-aware garment warping for alignment, followed by refinement through a cross-modal conditional diffusion model.", "result": "DiffFit outperforms state-of-the-art VTON methods in quantitative and perceptual benchmarks, excelling in garment detail preservation and alignment.", "conclusion": "By decoupling alignment and appearance refinement, DiffFit achieves high-fidelity, realistic virtual try-on with enhanced stability and visual quality."}}
{"id": "2506.22455", "pdf": "https://arxiv.org/pdf/2506.22455", "abs": "https://arxiv.org/abs/2506.22455", "authors": ["Dung Truong", "Arnaud Delorme"], "title": "Data Normalization Strategies for EEG Deep Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Normalization is a critical yet often overlooked component in the\npreprocessing pipeline for EEG deep learning applications. The rise of\nlarge-scale pretraining paradigms such as self-supervised learning (SSL)\nintroduces a new set of tasks whose nature is substantially different from\nsupervised training common in EEG deep learning applications. This raises new\nquestions about optimal normalization strategies for the applicable task. In\nthis study, we systematically evaluate the impact of normalization granularity\n(recording vs. window level) and scope (cross-channel vs. within-channel) on\nboth supervised (age and gender prediction) and self-supervised (Contrastive\nPredictive Coding) tasks. Using high-density resting-state EEG from 2,836\nsubjects in the Healthy Brain Network dataset, we show that optimal\nnormalization strategies differ significantly between training paradigms.\nWindow-level within-channel normalization yields the best performance in\nsupervised tasks, while minimal or cross-channel normalization at the window\nlevel is more effective for SSL. These results underscore the necessity of\ntask-specific normalization choices and challenge the assumption that a\nuniversal normalization strategy can generalize across learning settings. Our\nfindings provide practical insights for developing robust EEG deep learning\npipelines as the field shifts toward large-scale, foundation model training.", "AI": {"tldr": "This paper investigates the impact of normalization strategies on both supervised and self-supervised EEG deep learning tasks, showing that different approaches are optimal for different task paradigms.", "motivation": "To address the gap in understanding optimal normalization strategies in the emerging paradigm of large-scale pretraining (e.g., self-supervised learning) for EEG deep learning applications.", "method": "Systematic evaluation of different normalization granularities (recording vs. window level) and scopes (cross-channel vs. within-channel) on supervised (age and gender prediction) and self-supervised tasks using high-density EEG data from 2,836 individuals.", "result": "Window-level within-channel normalization is optimal for supervised tasks, while cross-channel normalization or minimal normalization at the window level is more effective for self-supervised learning.", "conclusion": "Task-specific normalization choices are essential, and there is no universal normalization strategy that generalizes across learning paradigms. These findings are critical for designing robust EEG deep learning pipelines for future large-scale model training."}}
{"id": "2506.23308", "pdf": "https://arxiv.org/pdf/2506.23308", "abs": "https://arxiv.org/abs/2506.23308", "authors": ["Yiming Huang", "Long Bai", "Beilei Cui", "Yanheng Li", "Tong Chen", "Jie Wang", "Jinlin Wu", "Zhen Lei", "Hongbin Liu", "Hongliang Ren"], "title": "Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting", "categories": ["cs.CV"], "comment": "MICCAI 2025. Project Page:\n  https://lastbasket.github.io/MICCAI-2025-Endo-4DGX/", "summary": "Accurate reconstruction of soft tissue is crucial for advancing automation in\nimage-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS)\ntechniques and their variants, 4DGS, achieve high-quality renderings of dynamic\nsurgical scenes in real-time. However, 3D-GS-based methods still struggle in\nscenarios with varying illumination, such as low light and over-exposure.\nTraining 3D-GS in such extreme light conditions leads to severe optimization\nproblems and devastating rendering quality. To address these challenges, we\npresent Endo-4DGX, a novel reconstruction method with illumination-adaptive\nGaussian Splatting designed specifically for endoscopic scenes with uneven\nlighting. By incorporating illumination embeddings, our method effectively\nmodels view-dependent brightness variations. We introduce a region-aware\nenhancement module to model the sub-area lightness at the Gaussian level and a\nspatial-aware adjustment module to learn the view-consistent brightness\nadjustment. With the illumination adaptive design, Endo-4DGX achieves superior\nrendering performance under both low-light and over-exposure conditions while\nmaintaining geometric accuracy. Additionally, we employ an exposure control\nloss to restore the appearance from adverse exposure to the normal level for\nillumination-adaptive optimization. Experimental results demonstrate that\nEndo-4DGX significantly outperforms combinations of state-of-the-art\nreconstruction and restoration methods in challenging lighting environments,\nunderscoring its potential to advance robot-assisted surgical applications. Our\ncode is available at https://github.com/lastbasket/Endo-4DGX.", "AI": {"tldr": "The paper introduces Endo-4DGX, an advanced method for reconstructing dynamic endoscopic scenes under challenging lighting conditions using an illumination-adaptive approach.", "motivation": "To overcome issues in reconstructing soft tissue under extreme lighting conditions, such as low light and over-exposure, during image-guided robotic surgery.", "method": "Endo-4DGX employs illumination embeddings, a region-aware enhancement module, and a spatial-aware adjustment module to adapt to dynamic lighting variations. It also uses exposure control loss for adverse exposure normalization.", "result": "Endo-4DGX achieves superior rendering quality and geometric accuracy under challenging lighting conditions, outperforming state-of-the-art reconstruction and restoration methods in experimental tests.", "conclusion": "This method enhances reconstruction performance under varying illumination, presenting potential to improve image-guided robotic surgery applications."}}
{"id": "2506.22459", "pdf": "https://arxiv.org/pdf/2506.22459", "abs": "https://arxiv.org/abs/2506.22459", "authors": ["Wending Heng", "Chaoyuan Liang", "Yihui Zhao", "Zhiqiang Zhang", "Glen Cooper", "Zhenhong Li"], "title": "Physics-Embedded Neural Networks for sEMG-based Continuous Motion Estimation", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "summary": "Accurately decoding human motion intentions from surface electromyography\n(sEMG) is essential for myoelectric control and has wide applications in\nrehabilitation robotics and assistive technologies. However, existing\nsEMG-based motion estimation methods often rely on subject-specific\nmusculoskeletal (MSK) models that are difficult to calibrate, or purely\ndata-driven models that lack physiological consistency. This paper introduces a\nnovel Physics-Embedded Neural Network (PENN) that combines interpretable MSK\nforward-dynamics with data-driven residual learning, thereby preserving\nphysiological consistency while achieving accurate motion estimation. The PENN\nemploys a recursive temporal structure to propagate historical estimates and a\nlightweight convolutional neural network for residual correction, leading to\nrobust and temporally coherent estimations. A two-phase training strategy is\ndesigned for PENN. Experimental evaluations on six healthy subjects show that\nPENN outperforms state-of-the-art baseline methods in both root mean square\nerror (RMSE) and $R^2$ metrics.", "AI": {"tldr": "This paper introduces a Physics-Embedded Neural Network (PENN) to improve human motion intention decoding using surface electromyography (sEMG) by combining musculoskeletal models with data-driven methods.", "motivation": "Existing sEMG-based motion estimation methods face challenges due to reliance on subject-specific musculoskeletal models or purely data-driven approaches lacking physiological consistency.", "method": "This paper proposes the PENN model, integrating interpretable musculoskeletal dynamics with residual learning, a recursive temporal structure, and lightweight convolutional neural networks for refinement.", "result": "Experimental results on six subjects show that PENN achieves better accuracy than baseline methods in both RMSE and $R^2$ metrics.", "conclusion": "The PENN framework successfully improves motion estimation by balancing physiological consistency and estimation accuracy, proving robust in practical applications."}}
{"id": "2506.23323", "pdf": "https://arxiv.org/pdf/2506.23323", "abs": "https://arxiv.org/abs/2506.23323", "authors": ["Quang-Huy Che", "Vinh-Tiep Nguyen"], "title": "FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary semantic segmentation (OVSS) aims to segment objects from\narbitrary text categories without requiring densely annotated datasets.\nAlthough contrastive learning based models enable zero-shot segmentation, they\noften lose fine spatial precision at pixel level, due to global representation\nbias. In contrast, diffusion-based models naturally encode fine-grained spatial\nfeatures via attention mechanisms that capture both global context and local\ndetails. However, they often face challenges in balancing the number of\niterations with the quality of the segmentation. In this work, we propose\nFastSeg, a novel and efficient training-free framework with only (1+1)-step of\nreverse process of a pretrained diffusion model (e.g., Stable Diffusion).\nMoreover, instead of running multiple times for different classes, FastSeg\nperforms segmentation for all classes at once. To further enhance the\nsegmentation quality, FastSeg introduces three key components: (i) a\ndual-prompt mechanism for discriminative, class-aware attention extraction,\n(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused\ncross-attention using scale-aligned selfattention maps, and (iii) a Test-Time\nFlipping (TTF) scheme designed to improve spatial consistency. Extensive\nexperiments show that FastSeg achieves state-of-the-art training-free\nperformance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,\nand COCO Object benchmarks while maintaining superior inference efficiency. Our\nresults demonstrate that FastSeg provides a strong foundation for\nextendability, bridging the gap between segmentation quality and inference\nefficiency.", "AI": {"tldr": "FastSeg introduces an efficient training-free framework using pretrained diffusion models for open-vocabulary semantic segmentation, achieving state-of-the-art segmentation with improved inference efficiency.", "motivation": "Existing approaches to open-vocabulary semantic segmentation face challenges due to loss of fine spatial precision in contrastive models and inefficiencies in diffusion-based models.", "method": "FastSeg utilizes a (1+1)-step reverse process of a pretrained diffusion model with innovations like dual-prompt attention mechanism, Hierarchical Attention Refinement Method (HARD), and Test-Time Flipping (TTF) to ensure efficiency and quality.", "result": "The framework achieves 43.8% average mIoU across PASCAL VOC, PASCAL Context, and COCO Object benchmarks, surpassing previous training-free methods.", "conclusion": "FastSeg balances segmentation quality and inference efficiency, establishing a foundation for extendable solutions in OVSS."}}
{"id": "2506.23329", "pdf": "https://arxiv.org/pdf/2506.23329", "abs": "https://arxiv.org/abs/2506.23329", "authors": ["Parker Liu", "Chenxin Li", "Zhengxin Li", "Yipeng Wu", "Wuyang Li", "Zhiqin Yang", "Zhenyuan Zhang", "Yunlong Lin", "Sirui Han", "Brandon Y. Feng"], "title": "IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering", "categories": ["cs.CV"], "comment": "Project Page: https://ir3d-bench.github.io/", "summary": "Vision-language models (VLMs) excel at descriptive tasks, but whether they\ntruly understand scenes from visual observations remains uncertain. We\nintroduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding\nthrough active creation rather than passive recognition. Grounded in the\nanalysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)\nwith actively using programming and rendering tools to recreate the underlying\n3D structure of an input image, achieving agentic inverse rendering through\ntool use. This \"understanding-by-creating\" approach probes the tool-using\ngenerative capacity of VLAs, moving beyond the descriptive or conversational\ncapacity measured by traditional scene understanding benchmarks. We provide a\ncomprehensive suite of metrics to evaluate geometric accuracy, spatial\nrelations, appearance attributes, and overall plausibility. Initial experiments\non agentic inverse rendering powered by various state-of-the-art VLMs highlight\ncurrent limitations, particularly in visual precision rather than basic tool\nusage. IR3D-Bench, including data and evaluation protocols, is released to\nfacilitate systematic study and development of tool-using VLAs towards genuine\nscene understanding by creating.", "AI": {"tldr": "The paper introduces IR3D-Bench, a benchmark for vision-language models to demonstrate scene understanding through active creation using tools like programming and rendering.", "motivation": "To challenge vision-language models in showcasing true scene understanding beyond descriptive tasks by engaging them in active creation processes.", "method": "Developed IR3D-Bench based on analysis-by-synthesis, where models reconstruct 3D structures of images using programming and rendering tools, moving towards agentic inverse rendering.", "result": "Initial experiments reveal that while vision-language models show basic tool-usage ability, they lack precision in visual aspects during 3D reconstruction.", "conclusion": "IR3D-Bench provides a novel framework and metrics to advance the study of tool-using generative capabilities in vision-language models for comprehensive scene understanding."}}
{"id": "2506.23347", "pdf": "https://arxiv.org/pdf/2506.23347", "abs": "https://arxiv.org/abs/2506.23347", "authors": ["Yi Liu", "Shengqian Li", "Zuzeng Lin", "Feng Wang", "Si Liu"], "title": "CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation", "categories": ["cs.CV"], "comment": null, "summary": "The current conditional autoregressive image generation methods have shown\npromising results, yet their potential remains largely unexplored in the\npractical unsupervised image translation domain, which operates without\nexplicit cross-domain correspondences. A critical limitation stems from the\ndiscrete quantization inherent in traditional Vector Quantization-based\nframeworks, which disrupts gradient flow between the Variational Autoencoder\ndecoder and causal Transformer, impeding end-to-end optimization during\nadversarial training in image space. To tackle this issue, we propose using\nSoftmax Relaxed Quantization, a novel approach that reformulates codebook\nselection as a continuous probability mixing process via Softmax, thereby\npreserving gradient propagation. Building upon this differentiable foundation,\nwe introduce CycleVAR, which reformulates image-to-image translation as\nimage-conditional visual autoregressive generation by injecting multi-scale\nsource image tokens as contextual prompts, analogous to prefix-based\nconditioning in language models. CycleVAR exploits two modes to generate the\ntarget image tokens, including (1) serial multi-step generation, enabling\niterative refinement across scales, and (2) parallel one-step generation\nsynthesizing all resolution outputs in a single forward pass. Experimental\nfindings indicate that the parallel one-step generation mode attains superior\ntranslation quality with quicker inference speed than the serial multi-step\nmode in unsupervised scenarios. Furthermore, both quantitative and qualitative\nresults indicate that CycleVAR surpasses previous state-of-the-art unsupervised\nimage translation models, \\textit{e}.\\textit{g}., CycleGAN-Turbo.", "AI": {"tldr": "This paper introduces CycleVAR, an innovative method for unsupervised image translation using a novel Softmax Relaxed Quantization technique, demonstrating superior performance and faster speeds compared to existing methods.", "motivation": "The research aims to address the limitations of discrete quantization in traditional Vector Quantization-based frameworks that hinder gradient flow and end-to-end optimization in unsupervised image translation.", "method": "The authors propose Softmax Relaxed Quantization for preserving gradient propagation and CycleVAR\u2014a model that uses multi-scale tokens for autoregressive image generation via serial multi-step and parallel one-step modes.", "result": "The parallel one-step generation mode achieved higher translation quality and faster inference speeds. Experimental results showed CycleVAR outperformed state-of-the-art models like CycleGAN-Turbo in both quantitative and qualitative measures.", "conclusion": "CycleVAR and Softmax Relaxed Quantization advance the state of the art for unsupervised image translation, offering better performance and efficiency."}}
{"id": "2506.23352", "pdf": "https://arxiv.org/pdf/2506.23352", "abs": "https://arxiv.org/abs/2506.23352", "authors": ["Shunsuke Yasuki", "Taiki Miyanishi", "Nakamasa Inoue", "Shuhei Kurita", "Koya Sakamoto", "Daichi Azuma", "Masato Taki", "Yutaka Matsuo"], "title": "GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "The advancement of 3D language fields has enabled intuitive interactions with\n3D scenes via natural language. However, existing approaches are typically\nlimited to small-scale environments, lacking the scalability and compositional\nreasoning capabilities necessary for large, complex urban settings. To overcome\nthese limitations, we propose GeoProg3D, a visual programming framework that\nenables natural language-driven interactions with city-scale high-fidelity 3D\nscenes. GeoProg3D consists of two key components: (i) a Geography-aware\nCity-scale 3D Language Field (GCLF) that leverages a memory-efficient\nhierarchical 3D model to handle large-scale data, integrated with geographic\ninformation for efficiently filtering vast urban spaces using directional cues,\ndistance measurements, elevation data, and landmark references; and (ii)\nGeographical Vision APIs (GV-APIs), specialized geographic vision tools such as\narea segmentation and object detection. Our framework employs large language\nmodels (LLMs) as reasoning engines to dynamically combine GV-APIs and operate\nGCLF, effectively supporting diverse geographic vision tasks. To assess\nperformance in city-scale reasoning, we introduce GeoEval3D, a comprehensive\nbenchmark dataset containing 952 query-answer pairs across five challenging\ntasks: grounding, spatial reasoning, comparison, counting, and measurement.\nExperiments demonstrate that GeoProg3D significantly outperforms existing 3D\nlanguage fields and vision-language models across multiple tasks. To our\nknowledge, GeoProg3D is the first framework enabling compositional geographic\nreasoning in high-fidelity city-scale 3D environments via natural language. The\ncode is available at https://snskysk.github.io/GeoProg3D/.", "AI": {"tldr": "This paper introduces GeoProg3D, a novel framework enabling natural language-driven interactions in large-scale 3D urban environments, overcoming compositional and scalability limitations.", "motivation": "Existing 3D language models are limited to small-scale environments and lack the ability to handle complex urban settings, necessitating scalable methods for intuitive geographic reasoning.", "method": "GeoProg3D combines a Geography-aware City-scale 3D Language Field (GCLF) for efficient data handling and Geographical Vision APIs (GV-APIs) for geographic vision tasks, leveraging large language models for reasoning.", "result": "GeoProg3D outperformed existing models in a new benchmark dataset, GeoEval3D, across grounding, spatial reasoning, comparison, counting, and measurement tasks.", "conclusion": "GeoProg3D establishes itself as a pioneering framework enabling scalable and compositional geographic reasoning in city-scale 3D environments using natural language interfaces."}}
{"id": "2506.23353", "pdf": "https://arxiv.org/pdf/2506.23353", "abs": "https://arxiv.org/abs/2506.23353", "authors": ["Siyuan Chai", "Xiaodong Guo", "Tong Liu"], "title": "Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Infrared image helps improve the perception capabilities of autonomous\ndriving in complex weather conditions such as fog, rain, and low light.\nHowever, infrared image often suffers from low contrast, especially in\nnon-heat-emitting targets like bicycles, which significantly affects the\nperformance of downstream high-level vision tasks. Furthermore, achieving\ncontrast enhancement without amplifying noise and losing important information\nremains a challenge. To address these challenges, we propose a task-oriented\ninfrared image enhancement method. Our approach consists of two key components:\nlayer decomposition and saliency information extraction. First, we design an\nlayer decomposition method for infrared images, which enhances scene details\nwhile preserving dark region features, providing more features for subsequent\nsaliency information extraction. Then, we propose a morphological\nreconstruction-based saliency extraction method that effectively extracts and\nenhances target information without amplifying noise. Our method improves the\nimage quality for object detection and semantic segmentation tasks. Extensive\nexperiments demonstrate that our approach outperforms state-of-the-art methods.", "AI": {"tldr": "This paper introduces a task-oriented method to improve infrared image quality, focusing on enhancing contrast for critical targets without boosting noise.", "motivation": "Infrared images face difficulties in low-visibility weather, but challenges such as low contrast and noise amplification hinder their usefulness for vision tasks.", "method": "The proposed method involves two components: 1) a layer decomposition method that enhances scene details while preserving dark region features, and 2) a morphological reconstruction-based saliency extraction method that enhances target information without increasing noise.", "result": "The proposed approach improves the quality of infrared images for tasks like object detection and semantic segmentation, outperforming state-of-the-art methods in experiments.", "conclusion": "This task-oriented enhancement method effectively tackles infrared image challenges, achieving a balance between visual detail and noise suppression for better performance in vision tasks."}}
{"id": "2506.22488", "pdf": "https://arxiv.org/pdf/2506.22488", "abs": "https://arxiv.org/abs/2506.22488", "authors": ["Xi Fu", "Weibang Jiang", "Rui Liu", "Gernot R. M\u00fcller-Putz", "Cuntai Guan"], "title": "Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Accurate decoding of lower-limb motion from EEG signals is essential for\nadvancing brain-computer interface (BCI) applications in movement intent\nrecognition and control. However, challenges persist in achieving causal,\nphase-consistent predictions and in modeling both inter- and intra-subject\nvariability. To address these issues, we propose NeuroDyGait, a\ndomain-generalizable EEG-to-motion decoding framework that leverages structured\ncontrastive representation learning and relational domain modeling. The\nproposed method employs relative contrastive learning to achieve semantic\nalignment between EEG and motion embeddings. Furthermore, a multi-cycle gait\nreconstruction objective is introduced to enforce temporal coherence and\nmaintain biomechanical consistency. To promote inter-session generalization,\nduring fine-tuning, a domain dynamic decoding mechanism adaptively assigns\nsession-specific prediction heads and learns to mix their outputs based on\ninter-session relationships. NeuroDyGait enables zero-shot motion prediction\nfor unseen individuals without requiring adaptation and achieves superior\nperformance in cross-subject gait decoding on benchmark datasets. Additionally,\nit demonstrates strong phase-detection capabilities even without explicit phase\nsupervision during training. These findings highlight the potential of\nrelational domain learning in enabling scalable, target-free deployment of\nBCIs.", "AI": {"tldr": "The paper introduces NeuroDyGait, a domain-generalizable framework for decoding lower-limb motion from EEG signals, addressing issues of variability in subjects and sessions.", "motivation": "To enable accurate and scalable EEG-to-motion decoding for advancing BCI applications in movement intent recognition and control.", "method": "The paper employs structured contrastive representation learning, semantic alignment between EEG and motion embeddings, multi-cycle gait reconstruction, and a dynamic decoding mechanism for inter-session generalization.", "result": "NeuroDyGait achieves superior zero-shot performance in cross-subject gait decoding, strong phase-detection, and eliminates the need for adaptation on unseen individuals.", "conclusion": "Relational domain learning in NeuroDyGait enables scalable, target-free deployment of BCIs, offering significant advancements in motion decoding frameworks."}}
{"id": "2506.23361", "pdf": "https://arxiv.org/pdf/2506.23361", "abs": "https://arxiv.org/abs/2506.23361", "authors": ["Yuanhao Cai", "He Zhang", "Xi Chen", "Jinbo Xing", "Yiwei Hu", "Yuqian Zhou", "Kai Zhang", "Zhifei Zhang", "Soo Ye Kim", "Tianyu Wang", "Yulun Zhang", "Xiaokang Yang", "Zhe Lin", "Alan Yuille"], "title": "OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions", "categories": ["cs.CV"], "comment": "A data construction pipeline and a diffusion Transformer framework\n  for controllable subject-driven video customization", "summary": "Existing feedforward subject-driven video customization methods mainly study\nsingle-subject scenarios due to the difficulty of constructing multi-subject\ntraining data pairs. Another challenging problem that how to use the signals\nsuch as depth, mask, camera, and text prompts to control and edit the subject\nin the customized video is still less explored. In this paper, we first propose\na data construction pipeline, VideoCus-Factory, to produce training data pairs\nfor multi-subject customization from raw videos without labels and control\nsignals such as depth-to-video and mask-to-video pairs. Based on our\nconstructed data, we develop an Image-Video Transfer Mixed (IVTM) training with\nimage editing data to enable instructive editing for the subject in the\ncustomized video. Then we propose a diffusion Transformer framework, OmniVCus,\nwith two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned\nEmbedding (TAE). LE enables inference with more subjects by using the training\nsubjects to activate more frame embeddings. TAE encourages the generation\nprocess to extract guidance from temporally aligned control signals by\nassigning the same frame embeddings to the control and noise tokens.\nExperiments demonstrate that our method significantly surpasses\nstate-of-the-art methods in both quantitative and qualitative evaluations.\nVideo demos are at our project page:\nhttps://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released\nat https://github.com/caiyuanhao1998/Open-OmniVCus", "AI": {"tldr": "The paper introduces a novel approach for subject-driven video customization in multi-subject scenarios using a data pipeline and diffusion-based framework.", "motivation": "To address limitations in current methods handling multi-subject video generation and customization, and explore control signals like depth, masks, and text prompts for editing.", "method": "1. Data construction pipeline (VideoCus-Factory) for generating training data pairs from raw videos. \n2. Mixed training strategy (IVTM).\n3. Framework (OmniVCus) with innovative embeddings (Lottery Embedding and Temporally Aligned Embedding).", "result": "The developed model demonstrates superior performance over existing state-of-the-art methods in both quantitative and qualitative metrics.", "conclusion": "OmniVCus effectively enables multi-subject visual customization in videos while utilizing various guiding signals, thus advancing video editing technology."}}
{"id": "2506.22490", "pdf": "https://arxiv.org/pdf/2506.22490", "abs": "https://arxiv.org/abs/2506.22490", "authors": ["Zhenke Duan", "Jiqun Pan", "Jiani Tu"], "title": "MENGLAN: Multiscale Enhanced Nonparametric Gas Analyzer with Lightweight Architecture and Networks", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Accurate detection of ethylene concentrations in mixed gases is crucial in\nchemical production for safety and health purposes. Traditional methods are\nhindered by high cost and complexity, limiting their practical application.\nThis study proposes MENGLAN, a Multiscale Enhanced Nonparametric Gas Analyzer\nthat integrates a dual-stream structure, a Hybrid Multi-Head Attention\nmechanism, and a Feature Reactivation Module to enable real-time, lightweight,\nand high-precision ethylene concentration prediction. Results show that MENGLAN\nachieves superior performance, reduced computational demand, and enhanced\ndeployability compared to existing methods.", "AI": {"tldr": "MENGLAN is a newly proposed model for detecting ethylene concentrations in mixed gases, offering improved accuracy, reduced computational demand, and practical deployability.", "motivation": "Traditional methods for detecting ethylene concentrations are expensive, complex, and impractical, creating the need for a more efficient and deployable solution.", "method": "MENGLAN incorporates a combination of innovative components: a dual-stream structure, Hybrid Multi-Head Attention mechanism, and Feature Reactivation Module for real-time, lightweight, and high-precision predictions.", "result": "MENGLAN demonstrates superior predictive performance, lower computational requirements, and better deployability compared to existing approaches.", "conclusion": "The study concludes that MENGLAN effectively addresses the limitations of traditional methods and provides a feasible option for chemical production safety and health monitoring."}}
{"id": "2506.23382", "pdf": "https://arxiv.org/pdf/2506.23382", "abs": "https://arxiv.org/abs/2506.23382", "authors": ["Vikram Rangarajan", "Shishira Maiya", "Max Ehrlich", "Abhinav Shrivastava"], "title": "SIEDD: Shared-Implicit Encoder with Discrete Decoders", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page at https://vikramrangarajan.github.io/SIEDD . Project\n  code at https://github.com/VikramRangarajan/SIEDD", "summary": "Implicit Neural Representations (INRs) offer exceptional fidelity for video\ncompression by learning per-video optimized functions, but their adoption is\ncrippled by impractically slow encoding times. Existing attempts to accelerate\nINR encoding often sacrifice reconstruction quality or crucial coordinate-level\ncontrol essential for adaptive streaming and transcoding. We introduce SIEDD\n(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that\nfundamentally accelerates INR encoding without these compromises. SIEDD first\nrapidly trains a shared, coordinate-based encoder on sparse anchor frames to\nefficiently capture global, low-frequency video features. This encoder is then\nfrozen, enabling massively parallel training of lightweight, discrete decoders\nfor individual frame groups, further expedited by aggressive coordinate-space\nsampling. This synergistic design delivers a remarkable 20-30X encoding\nspeed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while\nmaintaining competitive reconstruction quality and compression ratios.\nCritically, SIEDD retains full coordinate-based control, enabling continuous\nresolution decoding and eliminating costly transcoding. Our approach\nsignificantly advances the practicality of high-fidelity neural video\ncompression, demonstrating a scalable and efficient path towards real-world\ndeployment. Our codebase is available at\nhttps://github.com/VikramRangarajan/SIEDD .", "AI": {"tldr": "The paper introduces SIEDD, a novel architecture for neural video compression, offering a 20-30X encoding speed-up without compromising quality or flexibility.", "motivation": "The motivation is to address the impractically slow encoding times of Implicit Neural Representations (INRs) for video compression while preserving reconstruction quality and control for adaptive streaming and transcoding.", "method": "SIEDD uses a shared encoder trained on sparse anchor frames to capture low-frequency video features, followed by parallel training of lightweight decoders expedited through aggressive coordinate-space sampling.", "result": "SIEDD achieves 20-30X faster encoding speeds compared to state-of-the-art methods, while maintaining competitive reconstruction quality and compression ratios.", "conclusion": "SIEDD enhances the practicality of neural video compression by providing a fast, high-fidelity, and flexible framework ideal for real-world deployment without requiring costly transcoding."}}
{"id": "2506.23414", "pdf": "https://arxiv.org/pdf/2506.23414", "abs": "https://arxiv.org/abs/2506.23414", "authors": ["Ming-Zher Poh", "Jonathan Wang", "Jonathan Hsu", "Lawrence Cai", "Eric Teasley", "James A. Taylor", "Jameson K. Rogers", "Anupam Pathak", "Shwetak Patel"], "title": "A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video", "categories": ["cs.CV"], "comment": null, "summary": "Smartphone-based heart rate (HR) monitoring apps using finger-over-camera\nphotoplethysmography (PPG) face significant challenges in performance\nevaluation and device compatibility due to device variability and\nfragmentation. Manual testing is impractical, and standardized methods are\nlacking. This paper presents a novel, high-throughput bench-testing platform to\naddress this critical need. We designed a system comprising a test rig capable\nof holding 12 smartphones for parallel testing, a method for generating\nsynthetic PPG test videos with controllable HR and signal quality, and a host\nmachine for coordinating video playback and data logging. The system achieved a\nmean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and\nmeasured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and\nmeasured PPG signals using a clinically-validated smartphone-based HR app.\nBench-testing results of 20 different smartphone models correctly classified\nall the devices as meeting the ANSI/CTA accuracy standards for HR monitors\n(MAPE <10%) when compared to a prospective clinical study with 80 participants,\ndemonstrating high positive predictive value. This platform offers a scalable\nsolution for pre-deployment testing of smartphone HR apps to improve app\nperformance, ensure device compatibility, and advance the field of mobile\nhealth.", "AI": {"tldr": "The paper introduces a bench-testing platform for smartphone-based heart rate (HR) monitoring apps using synthetic PPG signals to ensure device compatibility and performance evaluation across various phone models.", "motivation": "Current smartphone HR monitoring apps face challenges in reliable performance evaluation due to device variability and the lack of standardized testing methods.", "method": "The study developed a high-throughput testing system with a rig for 12 smartphones, synthetic PPG video generation with adjustable HR and quality, and a host machine for playback and data analysis. The system's accuracy was validated against a clinical study.", "result": "The system achieved a MAPE of 0.11% in HR measurements and showed strong signal correlation (0.92). Testing on 20 smartphone models confirmed their compliance with HR accuracy standards based on a clinical study with 80 participants.", "conclusion": "The platform provides a scalable and reliable solution for pre-deployment testing of HR monitoring apps, enhancing both app performance and device compatibility in mobile health applications."}}
{"id": "2506.23418", "pdf": "https://arxiv.org/pdf/2506.23418", "abs": "https://arxiv.org/abs/2506.23418", "authors": ["Parham Rezaei", "Arash Marioriyad", "Mahdieh Soleymani Baghshah", "Mohammad Hossein Rohban"], "title": "Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models", "categories": ["cs.CV"], "comment": "12 main pages, 18 figures, and 16 tables", "summary": "Despite the ability of text-to-image models to generate high-quality,\nrealistic, and diverse images, they face challenges in compositional\ngeneration, often struggling to accurately represent details specified in the\ninput prompt. A prevalent issue in compositional generation is the misalignment\nof spatial relationships, as models often fail to faithfully generate images\nthat reflect the spatial configurations specified between objects in the input\nprompts. To address this challenge, we propose a novel probabilistic framework\nfor modeling the relative spatial positioning of objects in a scene, leveraging\nthe concept of Probability of Superiority (PoS). Building on this insight, we\nmake two key contributions. First, we introduce a novel evaluation metric,\nPoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D\nspatial relationships between text and image, with improved adherence to human\njudgment. Second, we propose PoS-based Generation (PSG), an inference-time\nmethod that improves the alignment of 2D and 3D spatial relationships in T2I\nmodels without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based\nreward function that can be utilized in two distinct ways: (1) as a\ngradient-based guidance mechanism applied to the cross-attention maps during\nthe denoising steps, or (2) as a search-based strategy that evaluates a set of\ninitial noise vectors to select the best one. Extensive experiments demonstrate\nthat the PSE metric exhibits stronger alignment with human judgment compared to\ntraditional center-based metrics, providing a more nuanced and reliable measure\nof complex spatial relationship accuracy in text-image alignment. Furthermore,\nPSG significantly enhances the ability of text-to-image models to generate\nimages with specified spatial configurations, outperforming state-of-the-art\nmethods across multiple evaluation metrics and benchmarks.", "AI": {"tldr": "The paper focuses on improving compositional generation in text-to-image (T2I) models, particularly addressing spatial misalignment issues. It proposes a novel evaluation metric (PSE) and an inference-time method (PSG) to enhance 2D/3D spatial alignment.", "motivation": "The motivation is to resolve challenges in compositional text-to-image generation, such as misalignment of spatial relationships between objects and resulting inaccuracies in image representation compared to input prompts.", "method": "The paper introduces a probabilistic framework leveraging Probability of Superiority (PoS) with two contributions: (1) a novel evaluation metric (PSE) to assess spatial alignment, and (2) PoS-based Generation (PSG), which improves spatial alignment through gradient-based guidance and search strategies for noise vectors during inference.", "result": "Experiments show that the PSE metric aligns strongly with human judgment, outperforming traditional metrics. The PSG method enhances spatial configuration accuracy in generated images and surpasses state-of-the-art approaches.", "conclusion": "PSE provides nuanced spatial relationship evaluation aligned with human perspectives, and PSG improves spatial accuracy in T2I models. Together, these contribute toward more reliable and high-quality compositional image generation."}}
{"id": "2506.22911", "pdf": "https://arxiv.org/pdf/2506.22911", "abs": "https://arxiv.org/abs/2506.22911", "authors": ["Yunxuan Ma", "Siqiang Wang", "Zhijian Duan", "Yukun Cheng", "Xiaotie Deng"], "title": "Learning Truthful Mechanisms without Discretization", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": "66 pages", "summary": "This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive\napproach), a discretization-free algorithm to learn truthful and\nutility-maximizing mechanisms. Existing learning-based approaches often rely on\ndiscretization of outcome spaces to ensure truthfulness, which leads to\ninefficiency with increasing problem size. To address this limitation, we\nformalize the concept of pricing rules, defined as functions that map outcomes\nto prices. Based on this concept, we propose a novel menu mechanism, which can\nbe equivalent to a truthful direct mechanism under specific conditions. The\ncore idea of TEDI lies in its parameterization of pricing rules using Partial\nGroupMax Network, a new network architecture designed to universally\napproximate partial convex functions. To learn optimal pricing rules, we\ndevelop novel training techniques, including covariance trick and continuous\nsampling, to derive unbiased gradient estimators compatible with first-order\noptimization. Theoretical analysis establishes that TEDI guarantees\ntruthfulness, full expressiveness, and dimension-insensitivity. Experimental\nevaluation in the studied auction setting demonstrates that TEDI achieves\nstrong performance, competitive with or exceeding state-of-the-art methods.\n  This work presents the first approaches to learn truthful mechanisms without\noutcome discretization, thereby enhancing algorithmic efficiency. The proposed\nconcepts, network architecture, and learning techniques might offer potential\nvalue and provide new insights for automated mechanism design and\ndifferentiable economics.", "AI": {"tldr": "The paper introduces TEDI, a novel algorithm for designing truthful and efficient mechanisms without relying on outcome discretization.", "motivation": "Existing approaches for learning mechanisms often rely on discretization, which becomes inefficient as the problem size increases. The paper seeks to address this issue with a new formulation.", "method": "TEDI uses a new network architecture called Partial GroupMax Network to parameterize pricing rules, which are trained using specialized techniques like the covariance trick and continuous sampling.", "result": "Theoretical and experimental results show that TEDI ensures truthfulness, expressiveness, and dimension-insensitivity, while achieving competitive or superior performance compared to state-of-the-art methods.", "conclusion": "TEDI offers a new solution for learning mechanisms without discretization, improving efficiency and sparking potential developments in mechanism design and differentiable economics."}}
{"id": "2506.23426", "pdf": "https://arxiv.org/pdf/2506.23426", "abs": "https://arxiv.org/abs/2506.23426", "authors": ["Menna Taha", "Aya Ahmed", "Mohammed Karmoose", "Yasser Gadallah"], "title": "Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Autonomous vehicles (AVs) use object detection models to recognize their\nsurroundings and make driving decisions accordingly. Conventional object\ndetection approaches classify objects into known classes, which limits the AV's\nability to detect and appropriately respond to Out-of-Distribution (OOD)\nobjects. This problem is a significant safety concern since the AV may fail to\ndetect objects or misclassify them, which can potentially lead to hazardous\nsituations such as accidents. Consequently, we propose a novel object detection\napproach that shifts the emphasis from conventional class-based classification\nto object harmfulness determination. Instead of object detection by their\nspecific class, our method identifies them as either 'harmful' or 'harmless'\nbased on whether they pose a danger to the AV. This is done based on the object\nposition relative to the AV and its trajectory. With this metric, our model can\neffectively detect previously unseen objects to enable the AV to make safer\nreal-time decisions. Our results demonstrate that the proposed model\neffectively detects OOD objects, evaluates their harmfulness, and classifies\nthem accordingly, thus enhancing the AV decision-making effectiveness in\ndynamic environments.", "AI": {"tldr": "The paper introduces a novel approach for object detection in autonomous vehicles (AVs), focusing on assessing object harmfulness rather than classifying objects into known categories.", "motivation": "Address safety concerns in AVs stemming from their inability to detect or appropriately respond to Out-of-Distribution (OOD) objects, which could lead to accidents.", "method": "Proposal of an object detection model that classifies objects as 'harmful' or 'harmless' based on their position and trajectory relative to the AV, instead of traditional class-based classification.", "result": "The model successfully detects OOD objects and evaluates their harmfulness, improving AV decision-making effectiveness in real-time scenarios.", "conclusion": "The proposed approach enhances safety and adaptability of AVs by prioritizing harmfulness assessment for better navigation in dynamic environments."}}
{"id": "2506.22941", "pdf": "https://arxiv.org/pdf/2506.22941", "abs": "https://arxiv.org/abs/2506.22941", "authors": ["Kaixuan Wang", "Jason T. Jacques", "Chenxin Diao"], "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions", "categories": ["cs.HC", "cs.AI"], "comment": "16 pages, 4 figures, with appendix", "summary": "Access to accurate and actionable harm reduction information can directly\nimpact the health outcomes of People Who Use Drugs (PWUD), yet existing online\nchannels often fail to meet their diverse and dynamic needs due to limitations\nin adaptability, accessibility, and the pervasive impact of stigma. Large\nLanguage Models (LLMs) present a novel opportunity to enhance information\nprovision, but their application in such a high-stakes domain is under-explored\nand presents socio-technical challenges. This paper investigates how LLMs can\nbe responsibly designed to support the information needs of PWUD. Through a\nqualitative workshop involving diverse stakeholder groups (academics, harm\nreduction practitioners, and an online community moderator), we explored LLM\ncapabilities, identified potential use cases, and delineated core design\nconsiderations. Our findings reveal that while LLMs can address some existing\ninformation barriers (e.g., by offering responsive, multilingual, and\npotentially less stigmatising interactions), their effectiveness is contingent\nupon overcoming challenges related to ethical alignment with harm reduction\nprinciples, nuanced contextual understanding, effective communication, and\nclearly defined operational boundaries. We articulate design pathways\nemphasising collaborative co-design with experts and PWUD to develop LLM\nsystems that are helpful, safe, and responsibly governed. This work contributes\nempirically grounded insights and actionable design considerations for the\nresponsible development of LLMs as supportive tools within the harm reduction\necosystem.", "AI": {"tldr": "This paper explores how large language models (LLMs) can responsibly support the information needs of People Who Use Drugs (PWUD) while addressing ethical and operational challenges.", "motivation": "Access to accurate harm reduction information is critical for PWUD, but traditional online platforms fail to address their complex needs due to limitations in adaptability, accessibility, and stigmatization.", "method": "The researchers conducted a qualitative workshop with stakeholders, including academics, harm reduction practitioners, and an online community moderator, to evaluate LLMs' capabilities, identify use cases, and delineate design considerations.", "result": "The study found LLMs offer potential advantages such as responsive, multilingual, and less stigmatizing information delivery. However, their success depends on addressing ethical concerns, contextual understanding, and operational boundaries.", "conclusion": "Collaboration with experts and PWUD in designing LLM systems is essential for ensuring safety, utility, and ethical alignment in their role within the harm reduction ecosystem."}}
{"id": "2506.23440", "pdf": "https://arxiv.org/pdf/2506.23440", "abs": "https://arxiv.org/abs/2506.23440", "authors": ["Mahesh Bhosale", "Abdul Wasi", "Yuanhao Zhai", "Yunjie Tian", "Samuel Border", "Nan Xi", "Pinaki Sarder", "Junsong Yuan", "David Doermann", "Xuan Gong"], "title": "PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions", "categories": ["cs.CV"], "comment": "Accepted to ICCV 2025", "summary": "Diffusion-based generative models have shown promise in synthesizing\nhistopathology images to address data scarcity caused by privacy constraints.\nDiagnostic text reports provide high-level semantic descriptions, and masks\noffer fine-grained spatial structures essential for representing distinct\nmorphological regions. However, public datasets lack paired text and mask data\nfor the same histopathological images, limiting their joint use in image\ngeneration. This constraint restricts the ability to fully exploit the benefits\nof combining both modalities for enhanced control over semantics and spatial\ndetails. To overcome this, we propose PathDiff, a diffusion framework that\neffectively learns from unpaired mask-text data by integrating both modalities\ninto a unified conditioning space. PathDiff allows precise control over\nstructural and contextual features, generating high-quality, semantically\naccurate images. PathDiff also improves image fidelity, text-image alignment,\nand faithfulness, enhancing data augmentation for downstream tasks like nuclei\nsegmentation and classification. Extensive experiments demonstrate its\nsuperiority over existing methods.", "AI": {"tldr": "PathDiff, a generative diffusion framework, enables precise synthesis of histopathology images by leveraging unpaired mask-text data, overcoming constraints in existing datasets.", "motivation": "The scarcity of paired text-mask data for histopathological images limits the ability to enhance control over image semantics and spatial details, necessitating a unified approach.", "method": "PathDiff integrates unpaired mask-text data into a shared conditioning space within a diffusion framework to enable precise control of image features and improved generation.", "result": "PathDiff provides high-quality, semantically accurate images with enhanced fidelity, text-image alignment, and faithfulness, advancing tasks like nuclei segmentation and classification.", "conclusion": "PathDiff demonstrates superior performance over existing methods, showcasing its value as a solution to data limitations in histopathology imaging."}}
{"id": "2506.22949", "pdf": "https://arxiv.org/pdf/2506.22949", "abs": "https://arxiv.org/abs/2506.22949", "authors": ["Ehsan Hallaji", "Vaishnavi Shanmugam", "Roozbeh Razavi-Far", "Mehrdad Saif"], "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Accepted for publication in IEEE CCECE 2025", "summary": "One of the most difficult challenges in cybersecurity is eliminating\nDistributed Denial of Service (DDoS) attacks. Automating this task using\nartificial intelligence is a complex process due to the inherent class\nimbalance and lack of sufficient labeled samples of real-world datasets. This\nresearch investigates the use of Semi-Supervised Learning (SSL) techniques to\nimprove DDoS attack detection when data is imbalanced and partially labeled. In\nthis process, 13 state-of-the-art SSL algorithms are evaluated for detecting\nDDoS attacks in several scenarios. We evaluate their practical efficacy and\nshortcomings, including the extent to which they work in extreme environments.\nThe results will offer insight into designing intelligent Intrusion Detection\nSystems (IDSs) that are robust against class imbalance and handle partially\nlabeled data.", "AI": {"tldr": "The paper explores using 13 Semi-Supervised Learning algorithms to detect Distributed Denial of Service (DDoS) attacks in scenarios with class imbalance and limited labeled data.", "motivation": "Address the challenges in detecting DDoS attacks due to class imbalance and insufficient labeled real-world samples.", "method": "Evaluate 13 state-of-the-art Semi-Supervised Learning techniques for DDoS detection across various conditions, emphasizing their effectiveness and limitations.", "result": "The study identifies how well these algorithms perform under extreme conditions and their practical efficacy.", "conclusion": "Findings contribute to developing Intrusion Detection Systems that are resilient to class imbalance and capable of handling partially labeled datasets."}}
{"id": "2506.23460", "pdf": "https://arxiv.org/pdf/2506.23460", "abs": "https://arxiv.org/abs/2506.23460", "authors": ["Dewen Zeng", "Xinrong Hu", "Yu-Jen Chen", "Yawen Wu", "Xiaowei Xu", "Yiyu Shi"], "title": "Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Weakly supervised semantic segmentation (WSSS) methods using class labels\noften rely on class activation maps (CAMs) to localize objects. However,\ntraditional CAM-based methods struggle with partial activations and imprecise\nobject boundaries due to optimization discrepancies between classification and\nsegmentation. Recently, the conditional diffusion model (CDM) has been used as\nan alternative for generating segmentation masks in WSSS, leveraging its strong\nimage generation capabilities tailored to specific class distributions. By\nmodifying or perturbing the condition during diffusion sampling, the related\nobjects can be highlighted in the generated images. Yet, the saliency maps\ngenerated by CDMs are prone to noise from background alterations during reverse\ndiffusion. To alleviate the problem, we introduce Contrastive Learning with\nDiffusion Features (CLDF), a novel method that uses contrastive learning to\ntrain a pixel decoder to map the diffusion features from a frozen CDM to a\nlow-dimensional embedding space for segmentation. Specifically, we integrate\ngradient maps generated from CDM external classifier with CAMs to identify\nforeground and background pixels with fewer false positives/negatives for\ncontrastive learning, enabling robust pixel embedding learning. Experimental\nresults on four segmentation tasks from two public medical datasets demonstrate\nthat our method significantly outperforms existing baselines.", "AI": {"tldr": "The paper introduces a novel approach using contrastive learning with diffusion features to overcome limitations in weakly supervised semantic segmentation methods that rely on class activation maps (CAMs).", "motivation": "Class activation maps (CAMs) in traditional WSSS methods struggle with partial activations and inaccurate object boundaries due to the mismatch in optimization goals between classification and segmentation tasks.", "method": "The proposed method, Contrastive Learning with Diffusion Features (CLDF), trains a pixel decoder via contrastive learning to map diffusion features from a frozen conditional diffusion model (CDM). It integrates gradient maps from the CDM\u2019s external classifier with CAMs to better identify foreground and background pixels for robust embedding learning.", "result": "Experimental results on four segmentation tasks from two public medical datasets show that CLDF significantly outperforms existing baselines.", "conclusion": "The study demonstrates the effectiveness of contrastive learning paired with diffusion features for improving object localization and segmentation in weakly supervised semantic segmentation tasks."}}
{"id": "2506.22532", "pdf": "https://arxiv.org/pdf/2506.22532", "abs": "https://arxiv.org/abs/2506.22532", "authors": ["Mark Wrobel", "Michele Pascale", "Tina Yao", "Ruaraidh Campbell", "Elena Milano", "Michael Quail", "Jennifer Steeden", "Vivek Muthurangu"], "title": "High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Background: Conventional cardiovascular magnetic resonance (CMR) in\npaediatric and congenital heart disease uses 2D, breath-hold, balanced steady\nstate free precession (bSSFP) cine imaging for assessment of function and\ncardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for\nanatomical assessment. Our aim is to concatenate a stack 2D free-breathing\nreal-time cines and use Deep Learning (DL) to create an isotropic a fully\nsegmented 3D cine dataset from these images. Methods: Four DL models were\ntrained on open-source data that performed: a) Interslice contrast correction;\nb) Interslice respiratory motion correction; c) Super-resolution (slice\ndirection); and d) Segmentation of right and left atria and ventricles (RA, LA,\nRV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients\nundergoing routine cardiovascular examination, our method was validated on\nprospectively acquired sagittal stacks of real-time cine images. Quantitative\nmetrics (ventricular volumes and vessel diameters) and image quality of the 3D\ncines were compared to conventional breath hold cine and whole heart imaging.\nResults: All real-time data were successfully transformed into 3D cines with a\ntotal post-processing time of <1 min in all cases. There were no significant\nbiases in any LV or RV metrics with reasonable limits of agreement and\ncorrelation. There is also reasonable agreement for all vessel diameters,\nalthough there was a small but significant overestimation of RPA diameter.\nConclusion: We have demonstrated the potential of creating a 3D-cine data from\nconcatenated 2D real-time cine images using a series of DL models. Our method\nhas short acquisition and reconstruction times with fully segmented data being\navailable within 2 minutes. The good agreement with conventional imaging\nsuggests that our method could help to significantly speed up CMR in clinical\npractice.", "AI": {"tldr": "The study aims to transform 2D free-breathing real-time CMR cine images into isotropic 3D segmented cine datasets using deep learning, showing good agreement with conventional imaging while reducing acquisition and reconstruction times.", "motivation": "Conventional CMR methods are time-consuming and less accommodating for pediatric and congenital heart disease patients due to their reliance on 2D breath-hold imaging and static 3D imaging. The motivation is to create a faster and more patient-friendly imaging approach.", "method": "The study trained four deep learning models to perform interslice contrast correction, respiratory motion correction, super-resolution, and segmentation of cardiovascular structures. These models were validated on real-time cine CMR data from 10 patients.", "result": "Their method successfully produced isotropic 3D cine images from 2D data within less than a minute, achieving good agreement in ventricular volumes and vessel diameters compared to conventional imaging.", "conclusion": "The proposed approach reduces the time required for CMR imaging while delivering comparable quantitative results, suggesting its potential utility for faster and efficient CMR workflows in clinical practice."}}
{"id": "2506.23461", "pdf": "https://arxiv.org/pdf/2506.23461", "abs": "https://arxiv.org/abs/2506.23461", "authors": ["Yun Xing", "Qing Guo", "Xiaoguang Li", "Yihao Huang", "Xiaofeng Cao", "Di Lin", "Ivor Tsang", "Lei Ma"], "title": "Time-variant Image Inpainting via Interactive Distribution Transition Estimation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this work, we focus on a novel and practical task, i.e., Time-vAriant\niMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image\nby leveraging the complementary information from a reference image, where both\nimages captured the same scene but with a significant time gap in between,\ni.e., time-variant images. Different from conventional reference-guided image\ninpainting, the reference image under TAMP setup presents significant content\ndistinction to the target image and potentially also suffers from damages. Such\nan application frequently happens in our daily lives to restore a damaged image\nby referring to another reference image, where there is no guarantee of the\nreference image's source and quality. In particular, our study finds that even\nstate-of-the-art (SOTA) reference-guided image inpainting methods fail to\nachieve plausible results due to the chaotic image complementation. To address\nsuch an ill-posed problem, we propose a novel Interactive Distribution\nTransition Estimation (InDiTE) module which interactively complements the\ntime-variant images with adaptive semantics thus facilitate the restoration of\ndamaged regions. To further boost the performance, we propose our TAMP\nsolution, namely Interactive Distribution Transition Estimation-driven\nDiffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and\nconducts latent cross-reference during sampling. Moreover, considering the lack\nof benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,\nbased on existing image and mask datasets. We conduct experiments on the\nTAMP-Street datasets under two different time-variant image inpainting\nsettings, which show our method consistently outperform SOTA reference-guided\nimage inpainting methods for solving TAMP.", "AI": {"tldr": "This research proposes a new task called Time-vAriant iMage inPainting (TAMP), a method to restore damaged images using significantly time-variant reference images. The method, InDiTE-Diff, achieves superior results compared to SOTA image inpainting approaches.", "motivation": "The motivation is to address the challenge of restoring damaged target images by leveraging reference images of the same scene taken at different times, which presents significant challenges due to content distinctions and potential damages in the reference image.", "method": "Proposed the Interactive Distribution Transition Estimation (InDiTE) module for adaptive semantic complementation. Additionally, introduced the InDiTE-driven Diffusion (InDiTE-Diff) framework using SOTA diffusion models and latent cross-reference during sampling.", "result": "Experiments conducted on a newly developed TAMP-Street dataset show that the proposed method significantly outperforms SOTA reference-guided image inpainting methods in both settings of the TAMP task.", "conclusion": "The proposed InDiTE-Diff framework provides an effective solution for the complex ill-posed problem of time-variant image inpainting, outperforming previous SOTA methods and creating a new benchmark for future research in this area."}}
{"id": "2506.22968", "pdf": "https://arxiv.org/pdf/2506.22968", "abs": "https://arxiv.org/abs/2506.22968", "authors": ["Daniel Mwesigwa"], "title": "Against 'softmaxing' culture", "categories": ["cs.HC", "cs.AI"], "comment": "7 pages", "summary": "AI is flattening culture. Evaluations of \"culture\" are showing the myriad\nways in which large AI models are homogenizing language and culture, averaging\nout rich linguistic differences into generic expressions. I call this\nphenomenon \"softmaxing culture,\" and it is one of the fundamental challenges\nfacing AI evaluations today. Efforts to improve and strengthen evaluations of\nculture are central to the project of cultural alignment in large AI systems.\nThis position paper argues that machine learning (ML) and human-computer\ninteraction (HCI) approaches to evaluation are limited. I propose two key\nshifts. First, instead of asking \"what is culture?\" at the start of system\nevaluations, I propose beginning with the question: \"when is culture?\" Second,\nwhile I acknowledge the philosophical claim that cultural universals exist, the\nchallenge is not simply to describe them, but to situate them in relation to\ntheir particulars. Taken together, these conceptual shifts invite evaluation\napproaches that move beyond technical requirements, toward perspectives more\nresponsive to the complexities of culture.", "AI": {"tldr": "AI is averaging out linguistic differences, homogenizing culture. This paper critiques current evaluation approaches and proposes conceptual shifts for analyzing AI's cultural impact.", "motivation": "Understanding how large AI models homogenize language and culture to better align systems with cultural nuances.", "method": "Conceptual proposal emphasizing shifts in evaluation questions: focusing on 'when is culture?' instead of 'what is culture?', and situating cultural universals relative to specifics.", "result": "Proposes a framework to refine evaluation methods, aiming for better responsiveness to the complexities of culture.", "conclusion": "The paper advocates for evaluation approaches that prioritize cultural complexity over technical requirements for culturally aligned AI systems."}}
{"id": "2506.23465", "pdf": "https://arxiv.org/pdf/2506.23465", "abs": "https://arxiv.org/abs/2506.23465", "authors": ["Nazanin Mahjourian", "Vinh Nguyen"], "title": "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The success of machine learning models in industrial applications is heavily\ndependent on the quality of the datasets used to train the models. However,\nlarge-scale datasets, specially those constructed from crowd-sourcing and\nweb-scraping, often suffer from label noise, inconsistencies, and errors. This\nproblem is particularly pronounced in manufacturing domains, where obtaining\nhigh-quality labels is costly and time-consuming. This paper introduces\nVision-Language Sanitization and Refinement (VLSR), which is a\nvision-language-based framework for label sanitization and refinement in\nmulti-label manufacturing image datasets. This method embeds both images and\ntheir associated textual labels into a shared semantic space leveraging the\nCLIP vision-language model. Then two key tasks are addressed in this process by\ncomputing the cosine similarity between embeddings. First, label sanitization\nis performed to identify irrelevant, misspelled, or semantically weak labels,\nand surface the most semantically aligned label for each image by comparing\nimage-label pairs using cosine similarity between image and label embeddings.\nSecond, the method applies density-based clustering on text embeddings,\nfollowed by iterative cluster merging, to group semantically similar labels\ninto unified label groups. The Factorynet dataset, which includes noisy labels\nfrom both human annotations and web-scraped sources, is employed to evaluate\nthe effectiveness of the proposed framework. Experimental results demonstrate\nthat the VLSR framework successfully identifies problematic labels and improves\nlabel consistency. This method enables a significant reduction in label\nvocabulary through clustering, which ultimately enhances the dataset's quality\nfor training robust machine learning models in industrial applications with\nminimal human intervention.", "AI": {"tldr": "The paper introduces the Vision-Language Sanitization and Refinement (VLSR) framework to improve the quality of noisy multi-label manufacturing image datasets using CLIP embeddings for label sanitization and clustering, reducing label inconsistencies and improving dataset quality.", "motivation": "Issues such as label noise, inconsistencies, and errors in large-scale datasets\u2014particularly in manufacturing domains\u2014hinder the success of machine learning models. High-quality labels are cost-prohibitive in such settings, necessitating automated solutions.", "method": "The framework employs the CLIP model to embed images and their corresponding textual labels into a shared semantic space. It uses cosine similarity to sanitize labels by identifying irrelevant or semantically weak ones, and density-based clustering to group similar labels into unified categories for refinement.", "result": "Experimental results on the Factorynet dataset show that VLSR effectively identifies problematic labels, improves label consistency, and reduces vocabulary size through clustering, enhancing dataset quality.", "conclusion": "VLSR provides a practical and efficient solution for improving noisy datasets with minimal human intervention, enabling the training of robust machine learning models in industrial applications."}}
{"id": "2506.22552", "pdf": "https://arxiv.org/pdf/2506.22552", "abs": "https://arxiv.org/abs/2506.22552", "authors": ["Fabrizio Falasca"], "title": "Neural models of multiscale systems: conceptual limitations, stochastic parametrizations, and a climate application", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "comment": null, "summary": "This work explores key conceptual limitations in data-driven modeling of\nmultiscale dynamical systems, focusing on neural emulators and stochastic\nclimate modeling. A skillful climate model should capture both stationary\nstatistics and responses to external perturbations. While current\nautoregressive neural models often reproduce the former, they typically\nstruggle with the latter. We begin by analyzing a low-dimensional dynamical\nsystem to expose, by analogy, fundamental limitations that persist in\nhigh-dimensional settings. Specifically, we construct neural stochastic models\nunder two scenarios: one where the full state vector is observed, and another\nwith only partial observations (i.e. a subset of variables). In the first case,\nthe models accurately capture both equilibrium statistics and forced responses\nin ensemble mean and variance. In the more realistic case of partial\nobservations, two key challenges emerge: (i) identifying the \\textit{proper}\nvariables to model, and (ii) parameterizing the influence of unobserved degrees\nof freedom. These issues are not specific to neural networks but reflect\nfundamental limitations of data-driven modeling and the need to target the slow\ndynamics of the system. We argue that physically grounded strategies -- such as\ncoarse-graining and stochastic parameterizations -- are critical, both\nconceptually and practically, for the skillful emulation of complex systems\nlike the coupled climate system. Building on these insights, we turn to a more\nrealistic application: a stochastic reduced neural model of the sea surface\ntemperature field and the net radiative flux at the top of the atmosphere,\nassessing its stationary statistics, response to temperature forcing, and\ninterpretability.", "AI": {"tldr": "This paper investigates limitations in data-driven models for dynamical systems, highlighting neural emulators' struggles with capturing statistics and responses under partial observations, while emphasizing the need for physically grounded modeling strategies.", "motivation": "The paper aims to address the limitations that data-driven neural models face in capturing both equilibrium statistics and responses to external perturbations in multiscale dynamical systems like climate models.", "method": "The study analyzes both low-dimensional and high-dimensional systems, constructing neural stochastic models under scenarios with full and partial state observations, and proposes physically based strategies such as coarse-graining and stochastic parameterizations.", "result": "The models perform well under full observations but face challenges with partial observations, particularly in identifying key variables and parameterizing unobserved dynamics. This highlights inherent limitations in data-driven approaches.", "conclusion": "Physically informed methodologies, rather than purely data-driven approaches, are necessary for effectively modeling complex dynamical systems, with practical applications demonstrated in climate emulation scenarios."}}
{"id": "2506.23467", "pdf": "https://arxiv.org/pdf/2506.23467", "abs": "https://arxiv.org/abs/2506.23467", "authors": ["Chenlang Yi", "Zizhan Xiong", "Qi Qi", "Xiyuan Wei", "Girish Bathla", "Ching-Long Lin", "Bobak Jack Mortazavi", "Tianbao Yang"], "title": "AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays", "categories": ["cs.CV", "cs.LG"], "comment": "This preprint has been accepted by MICCAI 2025", "summary": "Contrastive Language-Image Pre-training (CLIP) models have demonstrated\nsuperior performance across various visual tasks including medical image\nclassification. However, fairness concerns, including demographic biases, have\nreceived limited attention for CLIP models. This oversight leads to critical\nissues, particularly those related to race and gender, resulting in disparities\nin diagnostic outcomes and reduced reliability for underrepresented groups. To\naddress these challenges, we introduce AdFair-CLIP, a novel framework employing\nadversarial feature intervention to suppress sensitive attributes, thereby\nmitigating spurious correlations and improving prediction fairness. We conduct\ncomprehensive experiments on chest X-ray (CXR) datasets, and show that\nAdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while\nmaintaining robust generalization in zero-shot and few-shot scenarios. These\nresults establish new benchmarks for fairness-aware learning in CLIP-based\nmedical diagnostic models, particularly for CXR analysis.", "AI": {"tldr": "The paper presents AdFair-CLIP, a framework to improve fairness and accuracy in CLIP-based medical diagnostic models, particularly for chest X-ray analysis.", "motivation": "Address concerns of demographic biases and fairness in CLIP models for medical image classification, especially related to race and gender disparities.", "method": "Introduced AdFair-CLIP, which uses adversarial feature intervention to suppress sensitive attributes and mitigate spurious correlations.", "result": "Comprehensive experiments demonstrated improved fairness, diagnostic accuracy, and robust generalization in zero-shot and few-shot scenarios.", "conclusion": "AdFair-CLIP sets new benchmarks for fairness-aware learning in medical diagnostic models using CLIP, particularly enhancing performance in chest X-ray tasks."}}
{"id": "2506.22555", "pdf": "https://arxiv.org/pdf/2506.22555", "abs": "https://arxiv.org/abs/2506.22555", "authors": ["Callum Duffy", "Marcin Jastrzebski"], "title": "Spectral Bias in Variational Quantum Machine Learning", "categories": ["quant-ph", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "In this work, we investigate the phenomenon of spectral bias in quantum\nmachine learning, where, in classical settings, models tend to fit\nlow-frequency components of a target function earlier during training than\nhigh-frequency ones, demonstrating a frequency-dependent rate of convergence.\nWe study this effect specifically in parameterised quantum circuits (PQCs).\nLeveraging the established formulation of PQCs as Fourier series, we prove that\nspectral bias in this setting arises from the ``redundancy'' of the Fourier\ncoefficients, which denotes the number of terms in the analytical form of the\nmodel contributing to the same frequency component. The choice of data encoding\nscheme dictates the degree of redundancy for a Fourier coefficient. We find\nthat the magnitude of the Fourier coefficients' gradients during training\nstrongly correlates with the coefficients' redundancy. We then further\ndemonstrate this empirically with three different encoding schemes.\nAdditionally, we demonstrate that PQCs with greater redundancy exhibit\nincreased robustness to random perturbations in their parameters at the\ncorresponding frequencies. We investigate how design choices affect the ability\nof PQCs to learn Fourier sums, focusing on parameter initialization scale and\nentanglement structure, finding large initializations and low-entanglement\nschemes tend to slow convergence.", "AI": {"tldr": "The paper studies spectral bias in parameterized quantum circuits (PQCs), showing how spectral bias correlates with the redundancy of Fourier coefficients and is influenced by data encoding schemes, gradient magnitudes, and perturbation robustness.", "motivation": "To analyze spectral bias in quantum machine learning, particularly the frequency-dependent rate of convergence, and understand how Fourier coefficients' properties in PQCs contribute to this bias.", "method": "The authors leverage the Fourier series representation of PQCs, analytically link spectral bias to Fourier coefficient redundancy determined by data encoding schemes, and perform empirical validations with multiple encoding schemes.", "result": "They show a direct correlation between Fourier coefficients' redundancy and gradient magnitudes during training in PQCs. Redundant circuits are more robust to random parameter perturbations. Additionally, choices in parameter initialization and entanglement structure impact convergence rates.", "conclusion": "Understanding spectral bias and its relationship with redundancy in PQCs guides better circuit design, encoding schemes, and initialization/entanglement strategies to optimize learning and robustness."}}
{"id": "2506.23468", "pdf": "https://arxiv.org/pdf/2506.23468", "abs": "https://arxiv.org/abs/2506.23468", "authors": ["Xuan Yao", "Junyu Gao", "Changsheng Xu"], "title": "NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires\nagents to execute sequential navigation actions in complex environments guided\nby natural language instructions. Current approaches often struggle with\ngeneralizing to novel environments and adapting to ongoing changes during\nnavigation. Inspired by human cognition, we present NavMorph, a self-evolving\nworld model framework that enhances environmental understanding and\ndecision-making in VLN-CE tasks. NavMorph employs compact latent\nrepresentations to model environmental dynamics, equipping agents with\nforesight for adaptive planning and policy refinement. By integrating a novel\nContextual Evolution Memory, NavMorph leverages scene-contextual information to\nsupport effective navigation while maintaining online adaptability. Extensive\nexperiments demonstrate that our method achieves notable performance\nimprovements on popular VLN-CE benchmarks. Code is available at\n\\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.", "AI": {"tldr": "NavMorph, a self-evolving world model, is proposed to improve performance in vision-and-language navigation tasks by incorporating dynamic environmental understanding and adaptive strategies.", "motivation": "Current VLN-CE approaches struggle with generalizing to new environments and adapting to environmental changes during navigation, necessitating an advanced framework to enhance dynamic decision-making.", "method": "NavMorph uses compact latent representations for modeling environmental dynamics and introduces a Contextual Evolution Memory to leverage scene-contextual information, improving agents' navigation adaptability.", "result": "Extensive experiments confirm that NavMorph achieves notable performance improvements on widely-used VLN-CE benchmarks.", "conclusion": "NavMorph successfully integrates human-like cognitive strategies to enhance decision-making and adaptability in navigation tasks, setting a new benchmark for VLN-CE research."}}
{"id": "2506.22557", "pdf": "https://arxiv.org/pdf/2506.22557", "abs": "https://arxiv.org/abs/2506.22557", "authors": ["Boyuan Chen", "Minghao Shao", "Abdul Basit", "Siddharth Garg", "Muhammad Shafique"], "title": "MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The growing capabilities of large language models (LLMs) have exposed them to\nincreasingly sophisticated jailbreak attacks. Among these, obfuscation-based\nattacks -- which encrypt malicious content to evade detection -- remain highly\neffective. By leveraging the reasoning ability of advanced LLMs to interpret\nencrypted prompts, such attacks circumvent conventional defenses that rely on\nkeyword detection or context filtering. These methods are very difficult to\ndefend against, as existing safety mechanisms are not designed to interpret or\ndecode ciphered content. In this work, we propose \\textbf{MetaCipher}, a novel\nobfuscation-based jailbreak framework, along with a reinforcement\nlearning-based dynamic cipher selection mechanism that adaptively chooses\noptimal encryption strategies from a cipher pool. This approach enhances\njailbreak effectiveness and generalizability across diverse task types, victim\nLLMs, and safety guardrails. Our framework is modular and extensible by design,\nsupporting arbitrary cipher families and accommodating evolving adversarial\nstrategies. We complement our method with a large-scale empirical analysis of\ncipher performance across multiple victim LLMs. Within as few as 10 queries,\nMetaCipher achieves over 92\\% attack success rate (ASR) on most recent standard\nmalicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and\nover 74\\% ASR against reasoning-capable LLMs, outperforming all existing\nobfuscation-based jailbreak methods. These results highlight the long-term\nrobustness and adaptability of our approach, making it more resilient than\nprior methods in the face of advancing safety measures.", "AI": {"tldr": "MetaCipher introduces a novel method to conduct sophisticated jailbreak attacks on LLMs using dynamic, reinforcement-learning-based cipher selection, achieving high attack success rates against both non-reasoning and reasoning-capable LLMs.", "motivation": "The paper aims to address the vulnerability of LLMs to obfuscation-based attacks, wherein encrypted prompts are used to bypass conventional safety mechanisms that cannot decode ciphered content.", "method": "MetaCipher employs a modular framework with reinforcement learning to dynamically select optimal encryption strategies from a pool of ciphers, maximizing attack success and adaptability across various LLM targets and tasks.", "result": "MetaCipher achieves over 92% attack success rate on standard benchmarks for non-reasoning LLMs and over 74% ASR against reasoning-capable LLMs, outperforming prior obfuscation-based methods.", "conclusion": "MetaCipher demonstrates long-term robustness and adaptability, highlighting the need for evolved safety mechanisms in LLMs to combat such sophisticated jailbreak strategies."}}
{"id": "2506.23470", "pdf": "https://arxiv.org/pdf/2506.23470", "abs": "https://arxiv.org/abs/2506.23470", "authors": ["Ngoc-Do Tran", "Minh-Tuan Huynh", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "Interactive Interface For Semantic Segmentation Dataset Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of AI and computer vision has significantly increased\nthe demand for high-quality annotated datasets, particularly for semantic\nsegmentation. However, creating such datasets is resource-intensive, requiring\nsubstantial time, labor, and financial investment, and often raises privacy\nconcerns due to the use of real-world data. To mitigate these challenges, we\npresent SynthLab, consisting of a modular platform for visual data synthesis\nand a user-friendly interface. The modular architecture of SynthLab enables\neasy maintenance, scalability with centralized updates, and seamless\nintegration of new features. Each module handles distinct aspects of computer\nvision tasks, enhancing flexibility and adaptability. Meanwhile, its\ninteractive, user-friendly interface allows users to quickly customize their\ndata pipelines through drag-and-drop actions. Extensive user studies involving\na diverse range of users across different ages, professions, and expertise\nlevels, have demonstrated flexible usage, and high accessibility of SynthLab,\nenabling users without deep technical expertise to harness AI for real-world\napplications.", "AI": {"tldr": "SynthLab is a modular platform that synthesizes visual data for semantic segmentation using an accessible drag-and-drop interface.", "motivation": "The paper aims to address the challenges of creating high-quality annotated datasets for semantic segmentation, which are resource-intensive and often cause privacy issues.", "method": "The authors designed SynthLab, a modular platform with centralized updates and an interactive, user-friendly drag-and-drop interface for customizing data pipelines.", "result": "Extensive user studies showed that SynthLab provides flexible data synthesis and high accessibility for users across diverse age, profession, and expertise levels.", "conclusion": "SynthLab demonstrates its potential to empower users without deep technical expertise to effectively use AI in real-world applications, mitigating traditional barriers in dataset creation."}}
{"id": "2506.23478", "pdf": "https://arxiv.org/pdf/2506.23478", "abs": "https://arxiv.org/abs/2506.23478", "authors": ["Pedro Alonso", "Tianrui Li", "Chongshou Li"], "title": "GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance", "categories": ["cs.CV"], "comment": null, "summary": "Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning\ndue to its simplicity and efficiency. However, it suffers from a fundamental\nlimitation: it relies solely on Euclidean distances, which often fail to\ncapture the intrinsic geometry of 3D shapes. To address this limitation, we\npropose GeoCD, a topology-aware and fully differentiable approximation of\ngeodesic distance designed to serve as a metric for 3D point cloud learning.\nOur experiments show that GeoCD consistently improves reconstruction quality\nover standard CD across various architectures and datasets. We demonstrate this\nby fine-tuning several models, initially trained with standard CD, using GeoCD.\nRemarkably, fine-tuning for a single epoch with GeoCD yields significant gains\nacross multiple evaluation metrics.", "AI": {"tldr": "GeoCD replaces the traditional Chamfer Distance with a geodesic-aware approach to enhance 3D point cloud learning.", "motivation": "Chamfer Distance, while efficient, depends only on Euclidean distances, which inadequately capture the geometry of 3D shapes.", "method": "Introduces GeoCD, a metric based on geodesic distances that is topology-aware and fully differentiable.", "result": "GeoCD achieves better reconstruction quality than Chamfer Distance across architectures and datasets, with notable improvements within a single fine-tuning epoch.", "conclusion": "GeoCD addresses the limitations of CD and provides a better metric for 3D point cloud learning, improving reconstruction and evaluation outcomes."}}
{"id": "2506.22606", "pdf": "https://arxiv.org/pdf/2506.22606", "abs": "https://arxiv.org/abs/2506.22606", "authors": ["Osama Zafar", "Mina Namazi", "Yuqiao Xu", "Youngjin Yoo", "Erman Ayday"], "title": "A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "In the current paradigm of digital personalized services, the centralized\nmanagement of personal data raises significant privacy concerns, security\nvulnerabilities, and diminished individual autonomy over sensitive information.\nDespite their efficiency, traditional centralized architectures frequently fail\nto satisfy rigorous privacy requirements and expose users to data breaches and\nunauthorized access risks. This pressing challenge calls for a fundamental\nparadigm shift in methodologies for collecting, storing, and utilizing personal\ndata across diverse sectors, including education, healthcare, and finance.\n  This paper introduces a novel decentralized, privacy-preserving architecture\nthat handles heterogeneous personal information, ranging from educational\ncredentials to health records and financial data. Unlike traditional models,\nour system grants users complete data ownership and control, allowing them to\nselectively share information without compromising privacy. The architecture's\nfoundation comprises advanced privacy-enhancing technologies, including secure\nenclaves and federated learning, enabling secure computation, verification, and\ndata sharing. The system supports diverse functionalities, including local\ncomputation, model training, and privacy-preserving data sharing, while\nensuring data credibility and robust user privacy.", "AI": {"tldr": "The paper proposes a decentralized, privacy-preserving system addressing issues tied to centralized personal data management, leveraging advanced technologies like secure enclaves and federated learning.", "motivation": "To address significant privacy, security, and autonomy concerns tied to centralized management of personal data in sectors like education, healthcare, and finance.", "method": "The design of a decentralized architecture using privacy-enhancing technologies such as secure enclaves and federated learning to enable secure computations, data verification, and privacy-preserving sharing.", "result": "The system provides complete data control to users and enables secure, credible, and privacy-preserving functionalities across multiple data types and use cases.", "conclusion": "Decentralized architectures with advanced privacy technologies can overcome the privacy and security vulnerabilities of traditional systems, ensuring greater user autonomy and data protection."}}
{"id": "2506.23479", "pdf": "https://arxiv.org/pdf/2506.23479", "abs": "https://arxiv.org/abs/2506.23479", "authors": ["Zhaojie Zeng", "Yuesong Wang", "Chao Yang", "Tao Guan", "Lili Ju"], "title": "Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Implicit Neural Representation (INR) has demonstrated remarkable advances in\nthe field of image representation but demands substantial GPU resources.\nGaussianImage recently pioneered the use of Gaussian Splatting to mitigate this\ncost, however, the slow training process limits its practicality, and the fixed\nnumber of Gaussians per image limits its adaptability to varying information\nentropy. To address these issues, we propose in this paper a generalizable and\nself-adaptive image representation framework based on 2D Gaussian Splatting.\nOur method employs a network to quickly generate a coarse Gaussian\nrepresentation, followed by minimal fine-tuning steps, achieving comparable\nrendering quality of GaussianImage while significantly reducing training time.\nMoreover, our approach dynamically adjusts the number of Gaussian points based\non image complexity to further enhance flexibility and efficiency in practice.\nExperiments on DIV2K and Kodak datasets show that our method matches or exceeds\nGaussianImage's rendering performance with far fewer iterations and shorter\ntraining times. Specifically, our method reduces the training time by up to one\norder of magnitude while achieving superior rendering performance with the same\nnumber of Gaussians.", "AI": {"tldr": "This paper proposes a self-adaptive image representation method using 2D Gaussian Splatting, enabling faster training and adaptability to image complexity while maintaining or surpassing rendering quality.", "motivation": "GaussianImage showed the potential of Gaussian Splatting to reduce GPU costs in implicit neural image representation but is limited by slow training and fixed Gaussian numbers per image.", "method": "The method involves a network to quickly generate a coarse Gaussian representation, followed by minimal fine-tuning. It also adapts the number of Gaussians dynamically based on image complexity.", "result": "The proposed method achieves comparable or superior rendering quality compared to GaussianImage, reduces training time by up to 10x, and offers greater flexibility and efficiency.", "conclusion": "This framework achieves efficient, high-quality image rendering with reduced computational demands, addressing key limitations of GaussianImage."}}
{"id": "2506.22607", "pdf": "https://arxiv.org/pdf/2506.22607", "abs": "https://arxiv.org/abs/2506.22607", "authors": ["Daniel Ciganda", "Ignacio Camp\u00f3n", "I\u00f1aki Permanyer", "Jakob H Macke"], "title": "Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "While age-specific fertility rates (ASFRs) provide the most extensive record\nof reproductive change, their aggregate nature masks the underlying behavioral\nmechanisms that ultimately drive fertility trends. To recover these mechanisms,\nwe develop a likelihood-free Bayesian framework that couples an\nindividual-level model of the reproductive process with Sequential Neural\nPosterior Estimation (SNPE). This allows us to infer eight behavioral and\nbiological parameters from just two aggregate series: ASFRs and the age-profile\nof planned versus unplanned births. Applied to U.S. National Survey of Family\nGrowth cohorts and to Demographic and Health Survey cohorts from Colombia, the\nDominican Republic, and Peru, the method reproduces observed fertility\nschedules and, critically, predicts out-of-sample micro-level distributions of\nage at first sex, inter-birth intervals, and family-size ideals, none of which\ninform the estimation step. Because the fitted model yields complete synthetic\nlife histories, it enables behaviorally explicit population forecasts and\nsupports the construction of demographic digital twins.", "AI": {"tldr": "This paper introduces a Bayesian framework using Sequential Neural Posterior Estimation (SNPE) to infer individual-level reproductive behaviors from aggregate fertility data.", "motivation": "Current fertility measures, such as age-specific fertility rates (ASFRs), fail to reveal the underlying individual-level behaviors influencing reproductive change.", "method": "The study develops a likelihood-free Bayesian framework that combines individual-based reproductive modeling with SNPE, utilizing ASFRs and age profiles of planned versus unplanned births for inference.", "result": "The framework replicates observed fertility schedules and effectively predicts out-of-sample metrics like age at first sex, inter-birth intervals, and family-size ideals, tested on data from the U.S. and several Latin American countries.", "conclusion": "The approach provides valuable synthetic life histories for demographic forecasts and creates potential for constructing demographic digital twins."}}
{"id": "2506.23481", "pdf": "https://arxiv.org/pdf/2506.23481", "abs": "https://arxiv.org/abs/2506.23481", "authors": ["Xian Zhang", "Xiang Cheng"], "title": "Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs)\nhas significantly enhanced their reasoning capabilities, enabling a wide range\nof intelligent applications. However, these advancements also raise critical\nconcerns regarding privacy and ethics. MLLMs are now capable of inferring the\ngeographic location of images -- such as those shared on social media or\ncaptured from street views -- based solely on visual content, thereby posing\nserious risks of privacy invasion, including doxxing, surveillance, and other\nsecurity threats.\n  Methods: This study provides a comprehensive analysis of existing geolocation\ntechniques based on MLLMs. It systematically reviews relevant litera-ture and\nevaluates the performance of state-of-the-art visual reasoning models on\ngeolocation tasks, particularly in identifying the origins of street view\nimagery.\n  Results: Empirical evaluation reveals that the most advanced visual large\nmodels can successfully localize the origin of street-level imagery with up to\n$49\\%$ accuracy within a 1-kilometer radius. This performance underscores the\nmodels' powerful capacity to extract and utilize fine-grained geographic cues\nfrom visual data.\n  Conclusions: Building on these findings, the study identifies key visual\nelements that contribute to suc-cessful geolocation, such as text,\narchitectural styles, and environmental features. Furthermore, it discusses the\npotential privacy implications associated with MLLM-enabled geolocation and\ndiscuss several technical and policy-based coun-termeasures to mitigate\nassociated risks. Our code and dataset are available at\nhttps://github.com/zxyl1003/MLLM-Geolocation-Evaluation.", "AI": {"tldr": "The study evaluates the capabilities and privacy implications of Multimodal Large Language Models (MLLMs) in geolocating street-view imagery, achieving 49% accuracy within 1 km radius, and discusses countermeasures.", "motivation": "To investigate how advanced Multimodal Large Language Models (MLLMs) perform geolocation tasks using visual data and to understand their privacy and ethical implications.", "method": "The study reviews existing literature, tests state-of-the-art visual reasoning MLLMs on geolocating street imagery, and identifies contributing visual cues.", "result": "Advanced MLLMs achieved 49% accuracy in localizing street-level imagery within a 1-kilometer radius, showcasing their strong capacity for geographic reasoning based on visual inputs.", "conclusion": "The study highlights key elements like text and architectural features aiding geolocation, emphasizes privacy risks, and proposes both technical and policy-based countermeasures to mitigate the potential threats from such capabilities of MLLMs."}}
{"id": "2506.23040", "pdf": "https://arxiv.org/pdf/2506.23040", "abs": "https://arxiv.org/abs/2506.23040", "authors": ["Samuel J. Weisenthal"], "title": "Treatment, evidence, imitation, and chat", "categories": ["stat.OT", "cs.AI"], "comment": "12 pages", "summary": "Large language models are thought to have potential to aid in medical\ndecision making. We investigate this here. We start with the treatment problem,\nthe patient's core medical decision-making task, which is solved in\ncollaboration with a healthcare provider. We discuss approaches to solving the\ntreatment problem, including -- within evidence-based medicine -- trials and\nobservational data. We then discuss the chat problem, and how this differs from\nthe treatment problem -- in particular as it relates to imitation. We then\ndiscuss how a large language model might be used to solve the treatment problem\nand highlight some of the challenges that emerge. We finally discuss how these\nchallenges relate to evidence-based medicine, and how this might inform next\nsteps.", "AI": {"tldr": "The paper examines the role of large language models (LLMs) in aiding medical decision-making and explores their application specifically to treatment and chat-based problems, identifying challenges and future directions.", "motivation": "To evaluate the potential of LLMs in medical decision-making, gain insights on their applicability to treatment tasks, and address challenges tied to evidence-based approaches.", "method": "The authors analyze the treatment decision-making process, compare it with chat-based tasks, and examine possible uses of LLMs while mapping challenges against evidence-based medicine principles.", "result": "The analysis reveals significant challenges for LLMs in solving medical decision-making tasks, particularly in aligning with evidence-based medicine and addressing imitation issues.", "conclusion": "While LLMs have potential in aiding medical decision-making, their practical application requires resolving challenges tied to evidence-based medicine and understanding task-specific needs like treatment and chat problems."}}
{"id": "2506.22611", "pdf": "https://arxiv.org/pdf/2506.22611", "abs": "https://arxiv.org/abs/2506.22611", "authors": ["Yuming Ma"], "title": "Deep Hedging to Manage Tail Risk", "categories": ["q-fin.PM", "cs.LG", "math.OC", "q-fin.CP", "q-fin.RM", "91G70 91G20 91G60"], "comment": "59 pages", "summary": "Extending Buehler et al.'s 2019 Deep Hedging paradigm, we innovatively employ\ndeep neural networks to parameterize convex-risk minimization (CVaR/ES) for the\nportfolio tail-risk hedging problem. Through comprehensive numerical\nexperiments on crisis-era bootstrap market simulators -- customizable with\ntransaction costs, risk budgets, liquidity constraints, and market impact --\nour end-to-end framework not only achieves significant one-day 99% CVaR\nreduction but also yields practical insights into friction-aware strategy\nadaptation, demonstrating robustness and operational viability in realistic\nmarkets.", "AI": {"tldr": "The paper extends the Deep Hedging framework to address portfolio tail-risk hedging using deep neural networks for convex-risk minimization.", "motivation": "To advance the field of risk management by addressing tail-risk hedging challenges through the integration of modern machine learning techniques with financial models.", "method": "The authors employ deep neural networks to parameterize Convex-risk Minimization (CVaR/ES) and evaluate its efficacy using crisis-era bootstrap market simulators configured with realistic financial constraints.", "result": "The proposed framework demonstrates significant reductions in 99% CVaR over one-day horizons, along with robustness and adaptability in real-market simulations.", "conclusion": "This research provides a practical, friction-aware approach to tail-risk hedging, showing its feasibility and effectiveness in realistic market setups."}}
{"id": "2506.23482", "pdf": "https://arxiv.org/pdf/2506.23482", "abs": "https://arxiv.org/abs/2506.23482", "authors": ["Jun Huang", "Ting Liu", "Yihang Wu", "Xiaochao Qu", "Luoqi Liu", "Xiaolin Hu"], "title": "MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Advancements in generative models have enabled image inpainting models to\ngenerate content within specific regions of an image based on provided prompts\nand masks. However, existing inpainting methods often suffer from problems such\nas semantic misalignment, structural distortion, and style inconsistency. In\nthis work, we present MTADiffusion, a Mask-Text Alignment diffusion model\ndesigned for object inpainting. To enhance the semantic capabilities of the\ninpainting model, we introduce MTAPipeline, an automatic solution for\nannotating masks with detailed descriptions. Based on the MTAPipeline, we\nconstruct a new MTADataset comprising 5 million images and 25 million mask-text\npairs. Furthermore, we propose a multi-task training strategy that integrates\nboth inpainting and edge prediction tasks to improve structural stability. To\npromote style consistency, we present a novel inpainting style-consistency loss\nusing a pre-trained VGG network and the Gram matrix. Comprehensive evaluations\non BrushBench and EditBench demonstrate that MTADiffusion achieves\nstate-of-the-art performance compared to other methods.", "AI": {"tldr": "MTADiffusion, leveraging mask-text alignment and style-consistency loss, achieves state-of-the-art object inpainting performance.", "motivation": "Existing image inpainting methods face challenges including semantic misalignment, structural distortion, and style inconsistency.", "method": "This paper introduces MTADiffusion, which applies mask-text alignment, automated mask annotations (MTAPipeline), a new MTADataset, multi-task training combining inpainting and edge prediction, and a novel style-consistency loss leveraging VGG networks.", "result": "MTADiffusion outperformed competing methods in semantic, structural, and stylistic metrics in objective evaluations conducted on BrushBench and EditBench.", "conclusion": "The proposed approach addresses key limitations in current inpainting methods and sets new performance standards in object inpainting tasks."}}
{"id": "2506.23491", "pdf": "https://arxiv.org/pdf/2506.23491", "abs": "https://arxiv.org/abs/2506.23491", "authors": ["ZongHan Hsieh", "Tzer-Jen Wei"], "title": "Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)\nspecifically designed for Graphical User Interface grounding tasks, achieving\nperformance competitive with significantly larger models. Unlike large-scale\nVLMs (>7B parameters) that are computationally intensive and impractical for\nconsumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while\nbeing fully trainable on a single GPU (RTX 4090). The model incorporates\nseveral key innovations: (i) combine cross-platform, multi-resolution dataset\nof 24K examples from diverse sources including mobile, desktop, and web GUI\nscreenshots to effectively address data scarcity in high-resolution desktop\nenvironments; (ii) a two-stage fine-tuning strategy, where initial\ncross-platform training establishes robust GUI understanding, followed by\nspecialized fine-tuning on high-resolution data to significantly enhance model\nadaptability; and (iii) data curation and redundancy reduction strategies,\ndemonstrating that randomly sampling a smaller subset with reduced redundancy\nachieves performance comparable to larger datasets, emphasizing data diversity\nover sheer volume. Empirical evaluation on standard GUI grounding\nbenchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging\nScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%\non ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B\nparameters. Ablation studies validate the critical role of balanced sampling\nand two-stage fine-tuning in enhancing robustness, particularly in\nhigh-resolution desktop scenarios. The Qwen-GUI-3B is available at:\nhttps://github.com/Han1018/Qwen-GUI-3B", "AI": {"tldr": "Qwen-GUI-3B is a compact Vision-Language Model tailored for GUI grounding tasks, offering competitive accuracy while being efficient enough for single GPU training.", "motivation": "The study addresses the inefficiency and infeasibility of using large-scale VLMs (>7B parameters) for GUI grounding on consumer-grade hardware.", "method": "The model employs a multi-resolution dataset, a two-stage fine-tuning strategy, and data curation to balance performance and efficiency.", "result": "Qwen-GUI-3B achieves 84.9% accuracy on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing other models under 4B parameters.", "conclusion": "The results affirm Qwen-GUI-3B as an efficient and powerful option for GUI grounding tasks, with meaningful advancements in performance and practicality."}}
{"id": "2506.22648", "pdf": "https://arxiv.org/pdf/2506.22648", "abs": "https://arxiv.org/abs/2506.22648", "authors": ["Pedro R. Pires", "Tiago A. Almeida"], "title": "Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted for publication in Applied Soft Computing (ASOC), 49 pages,\n  14 figures", "summary": "Over the past decade, recommender systems have experienced a surge in\npopularity. Despite notable progress, they grapple with challenging issues,\nsuch as high data dimensionality and sparseness. Representing users and items\nas low-dimensional embeddings learned via neural networks has become a leading\nsolution. However, while recent studies show promising results, many approaches\nrely on complex architectures or require content data, which may not always be\navailable. This paper presents Interact2Vec, a novel neural network-based model\nthat simultaneously learns distributed embeddings for users and items while\ndemanding only implicit feedback. The model employs state-of-the-art strategies\nthat natural language processing models commonly use to optimize the training\nphase and enhance the final embeddings. Two types of experiments were conducted\nregarding the extrinsic and intrinsic quality of the model. In the former, we\nbenchmarked the recommendations generated by Interact2Vec's embeddings in a\ntop-$N$ ranking problem, comparing them with six other recommender algorithms.\nThe model achieved the second or third-best results in 30\\% of the datasets,\nbeing competitive with other recommenders, and has proven to be very efficient\nwith an average training time reduction of 274\\% compared to other\nembedding-based models. Later, we analyzed the intrinsic quality of the\nembeddings through similarity tables. Our findings suggest that Interact2Vec\ncan achieve promising results, especially on the extrinsic task, and is an\nexcellent embedding-generator model for scenarios of scarce computing\nresources, enabling the learning of item and user embeddings simultaneously and\nefficiently.", "AI": {"tldr": "Interact2Vec is a neural network-based model for recommender systems that creates user and item embeddings using only implicit feedback.", "motivation": "Recommender systems face challenges such as high data dimensionality and sparseness, with existing solutions requiring complex architectures or unavailable content data.", "method": "The model adopts NLP-inspired optimization strategies for embedding generation and evaluates its performance in both extrinsic recommendation tasks and intrinsic embedding quality.", "result": "Interact2Vec was competitive in 30% of tested datasets while reducing training time by 274% compared to other embedding-based models, and demonstrated strong intrinsic quality in similarity analysis.", "conclusion": "Interact2Vec is an efficient and competitive approach for generating embeddings, particularly advantageous in low-resource scenarios."}}
{"id": "2506.23502", "pdf": "https://arxiv.org/pdf/2506.23502", "abs": "https://arxiv.org/abs/2506.23502", "authors": ["Mengxiao Tian", "Xinxiao Wu", "Shuo Yang"], "title": "LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching", "categories": ["cs.CV"], "comment": "accepted by ICCV 2025", "summary": "Driven by large-scale contrastive vision-language pre-trained models such as\nCLIP, recent advancements in the image-text matching task have achieved\nremarkable success in representation learning. Due to image-level\nvisual-language alignment, CLIP falls short in understanding fine-grained\ndetails such as object attributes and spatial relationships between objects.\nRecent efforts have attempted to compel CLIP to acquire structured visual\nrepresentations by introducing prompt learning to achieve object-level\nalignment. While achieving promising results, they still lack the capability to\nperceive actions, which are crucial for describing the states or relationships\nbetween objects. Therefore, we propose to endow CLIP with fine-grained\naction-level understanding by introducing an LLM-enhanced action-aware\nmulti-modal prompt-tuning method, incorporating the action-related external\nknowledge generated by large language models (LLMs). Specifically, we design an\naction triplet prompt and an action state prompt to exploit compositional\nsemantic knowledge and state-related causal knowledge implicitly stored in\nLLMs. Subsequently, we propose an adaptive interaction module to aggregate\nattentive visual features conditioned on action-aware prompted knowledge for\nestablishing discriminative and action-aware visual representations, which\nfurther improves the performance. Comprehensive experimental results on two\nbenchmark datasets demonstrate the effectiveness of our method.", "AI": {"tldr": "The paper introduces an action-aware multi-modal prompt-tuning approach to enhance CLIP's understanding of fine-grained action-level details using structured knowledge from large language models (LLMs).", "motivation": "CLIP struggles with understanding fine-grained details such as object attributes, spatial relationships, and actions, which are vital for describing states or relations between objects.", "method": "The authors propose a method using LLM-enhanced prompts\u2014specifically, action triplet and action state prompts\u2014to encode semantic and causal knowledge. They also develop an adaptive interaction module to aggregate attentive visual features conditioned on these prompts.", "result": "The proposed method achieves improved visual representation and outperforms prior works on two benchmark datasets.", "conclusion": "Incorporating action-aware prompts and LLM-enhanced knowledge improves CLIP's ability to understand complex visual-language alignments, contributing to fine-grained action-level comprehension."}}
{"id": "2506.23505", "pdf": "https://arxiv.org/pdf/2506.23505", "abs": "https://arxiv.org/abs/2506.23505", "authors": ["Tinh Nguyen"], "title": "Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation", "categories": ["cs.CV"], "comment": null, "summary": "Underwater object detection is crucial for autonomous navigation,\nenvironmental monitoring, and marine exploration, but it is severely hampered\nby light attenuation, turbidity, and occlusion. Current methods balance\naccuracy and computational efficiency, but they have trouble deploying in\nreal-time under low visibility conditions. Through the integration of\nphysics-informed augmentation techniques with the YOLOv12 architecture, this\nstudy advances underwater detection. With Residual ELAN blocks to preserve\nstructural features in turbid waters and Area Attention to maintain large\nreceptive fields for occluded objects while reducing computational complexity.\nUnderwater optical properties are addressed by domain-specific augmentations\nsuch as turbulence adaptive blurring, biologically grounded occlusion\nsimulation, and spectral HSV transformations for color distortion. Extensive\ntests on four difficult datasets show state-of-the-art performance, with\nBrackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion\nrobustness by 18.9%, small-object recall by 22.4%, and detection precision by\nup to 7.94% compared to previous models. The crucial role of augmentation\nstrategy is validated by ablation studies. This work offers a precise and\neffective solution for conservation and underwater robotics applications.", "AI": {"tldr": "The paper enhances underwater object detection by integrating physics-informed augmentations with the YOLOv12 model, achieving state-of-the-art performance while maintaining real-time processing capabilities.", "motivation": "Underwater object detection is hindered by challenges like light attenuation, water turbidity, and occlusion, which limit the deployment of real-time and accurate detection systems in low-visibility conditions.", "method": "The study integrates domain-specific augmentations such as turbulence-adaptive blurring, occlusion simulations, and spectral HSV transformations with the YOLOv12 architecture, incorporating Residual ELAN blocks and Area Attention to enhance feature preservation and computational efficiency.", "result": "The proposed method significantly improves detection metrics, achieving 98.30% mAP at 142 FPS on Brackish data while enhancing occlusion robustness by 18.9% and small-object recall by 22.4%.", "conclusion": "This research delivers an effective and precise approach to underwater object detection, suitable for applications like conservation and underwater robotics, validated by ablation studies."}}
{"id": "2506.23513", "pdf": "https://arxiv.org/pdf/2506.23513", "abs": "https://arxiv.org/abs/2506.23513", "authors": ["Zixun Fang", "Kai Zhu", "Zhiheng Liu", "Yu Liu", "Wei Zhai", "Yang Cao", "Zheng-Jun Zha"], "title": "ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models", "categories": ["cs.CV"], "comment": "https://becauseimbatman0.github.io/ViewPoint", "summary": "Panoramic video generation aims to synthesize 360-degree immersive videos,\nholding significant importance in the fields of VR, world models, and spatial\nintelligence. Existing works fail to synthesize high-quality panoramic videos\ndue to the inherent modality gap between panoramic data and perspective data,\nwhich constitutes the majority of the training data for modern diffusion\nmodels. In this paper, we propose a novel framework utilizing pretrained\nperspective video models for generating panoramic videos. Specifically, we\ndesign a novel panorama representation named ViewPoint map, which possesses\nglobal spatial continuity and fine-grained visual details simultaneously. With\nour proposed Pano-Perspective attention mechanism, the model benefits from\npretrained perspective priors and captures the panoramic spatial correlations\nof the ViewPoint map effectively. Extensive experiments demonstrate that our\nmethod can synthesize highly dynamic and spatially consistent panoramic videos,\nachieving state-of-the-art performance and surpassing previous methods.", "AI": {"tldr": "The paper proposes a method to generate high-quality 360-degree panoramic videos using a novel representation and pretrained perspective video models, significantly outperforming previous approaches.", "motivation": "Synthesizing high-quality 360-degree videos is crucial for VR, world models, and spatial intelligence, but existing methods struggle due to gaps between panoramic and perspective data.", "method": "The paper introduces the ViewPoint map representation and a Pano-Perspective attention mechanism to leverage pretrained perspective video models while effectively capturing panoramic spatial correlations.", "result": "Extensive experiments show the proposed approach generates dynamic, spatially consistent panoramic videos and achieves state-of-the-art results.", "conclusion": "This framework bridges the panoramic and perspective data gap, enabling the generation of superior 360-degree videos with applications in immersive media and beyond."}}
{"id": "2506.23085", "pdf": "https://arxiv.org/pdf/2506.23085", "abs": "https://arxiv.org/abs/2506.23085", "authors": ["Saeid Aghasoleymani Najafabadi"], "title": "Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The purpose of this paper is to explore a multi-modal approach to enhancing\nlive broadcast engagement by developing a short video recommendation system\nthat incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user\npreferences. In order to provide personalized recommendations tailored to\nindividual interests, the proposed system takes into account user interaction\ndata, video content features, and contextual information. With the aid of a\nhybrid approach combining collaborative filtering and content-based filtering\ntechniques, the system is able to capture nuanced relationships between users,\nvideo attributes, and engagement patterns. Three datasets are used to evaluate\nthe effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to\nbaseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the\nproposed MMGCN-based model shows superior performance. A notable feature of the\nproposed model is that it outperforms all baseline methods in capturing diverse\nuser preferences and making accurate, personalized recommendations, resulting\nin a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1\nscore of 0.197. We emphasize the importance of multi-modal integration and\nuser-centric approaches in advancing recommender systems, emphasizing the role\nthey play in enhancing content discovery and audience interaction on live\nbroadcast platforms.", "AI": {"tldr": "The paper presents a novel multi-modal recommendation system using MMGCN to improve live broadcast engagement. It integrates user preferences, video content, and contextual data, showing superior performance over baseline models in several datasets.", "motivation": "The motivation is to address the limitations of current recommendation systems and enhance content discovery and user engagement for live broadcasts.", "method": "The paper employs Multi-modal Graph Convolutional Networks (MMGCN) with a hybrid of collaborative and content-based filtering techniques. It uses user interaction data, video content features, and contextual information for personalized recommendations.", "result": "The proposed MMGCN-based model outperformed baseline models like DeepFM, LightGBM, and XGBoost in terms of F1 scores across Kwai (0.574), TikTok (0.506), and MovieLens (0.197).", "conclusion": "The study highlights the effectiveness of incorporating multi-modal integration and user-centric approaches for building advanced recommender systems that enhance audience engagement on live broadcast platforms."}}
{"id": "2506.22701", "pdf": "https://arxiv.org/pdf/2506.22701", "abs": "https://arxiv.org/abs/2506.22701", "authors": ["Shi Jie Yu"], "title": "Lower bounds for trace estimation via Block Krylov and other methods", "categories": ["math.ST", "cs.DS", "cs.LG", "cs.NA", "math.NA", "stat.TH"], "comment": null, "summary": "This paper studies theoretical lower bounds for estimating the trace of a\nmatrix function, $\\text{tr}(f(A))$, focusing on methods that use Hutchinson's\nmethod along with Block Krylov techniques. These methods work by approximating\nmatrix-vector products like $f(A)V$ using a Block Krylov subspace. This is\nclosely related to approximating functions with polynomials. We derive\ntheoretical upper bounds on how many Krylov steps are needed for functions such\nas $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial\napproximation of their scalar equivalent. In addition, we also develop lower\nlimits on the number of queries needed for trace estimation, specifically for\n$\\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the\nconnection between the number of steps in Block Krylov methods and the degree\nof the polynomial used for approximation. This links the total cost of trace\nestimation to basic limits in polynomial approximation and how much information\nis needed for the computation.", "AI": {"tldr": "The paper explores theoretical bounds for estimating matrix function traces with Hutchinson's method and Block Krylov techniques, analyzing approximation costs and limitations.", "motivation": "To understand the theoretical limits and computational efficiency of trace estimation methods when combined with polynomial approximations.", "method": "Analyzed theoretical bounds through polynomial approximations and studied how many Krylov steps are sufficient for specific matrix functions, alongside developing lower query limits for trace estimation.", "result": "Upper bounds for Krylov steps were derived for functions like $A^{-1/2}$ and $A^{-1}$, while lower limits were established for $\text{tr}(W^{-p})$ involving Wishart matrices.", "conclusion": "The study connects Krylov steps and polynomial degree to computation cost, providing insights into theoretical and practical efficiency for trace estimation methods."}}
{"id": "2506.23518", "pdf": "https://arxiv.org/pdf/2506.23518", "abs": "https://arxiv.org/abs/2506.23518", "authors": ["Jiwoo Park", "Tae Eun Choi", "Youngjun Jun", "Seong Jae Hwang"], "title": "WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image", "categories": ["cs.CV"], "comment": null, "summary": "Generating high-quality novel views of a scene from a single image requires\nmaintaining structural coherence across different views, referred to as view\nconsistency. While diffusion models have driven advancements in novel view\nsynthesis, they still struggle to preserve spatial continuity across views.\nDiffusion models have been combined with 3D models to address the issue, but\nsuch approaches lack efficiency due to their complex multi-step pipelines. This\npaper proposes a novel view-consistent image generation method which utilizes\ndiffusion models without additional modules. Our key idea is to enhance\ndiffusion models with a training-free method that enables adaptive attention\nmanipulation and noise reinitialization by leveraging view-guided warping to\nensure view consistency. Through our comprehensive metric framework suitable\nfor novel-view datasets, we show that our method improves view consistency\nacross various diffusion models, demonstrating its broader applicability.", "AI": {"tldr": "The paper presents a training-free method for improving view consistency in novel view synthesis using diffusion models, avoiding the inefficiency of previous 3D model-integrated methods.", "motivation": "The authors aim to address the challenge of maintaining view consistency in novel view synthesis, which current diffusion models struggle to achieve effectively and efficiently.", "method": "A novel training-free approach is proposed that uses adaptive attention manipulation and noise reinitialization, leveraging view-guided warping to enhance diffusion models for consistent view generation.", "result": "The proposed method significantly improves view consistency across various diffusion models, as demonstrated through a comprehensive metric framework for novel-view datasets.", "conclusion": "The study demonstrates improved efficiency and broader applicability of diffusion models in generating view-consistent novel scenes through the introduced method."}}
{"id": "2506.23094", "pdf": "https://arxiv.org/pdf/2506.23094", "abs": "https://arxiv.org/abs/2506.23094", "authors": ["Qi He", "Gus Xia", "Ziyu Wang"], "title": "TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "9 pages, 4 figures, 2 tables. To be published in ISMIR 2025", "summary": "Hierarchical planning is a powerful approach to model long sequences\nstructurally. Aside from considering hierarchies in the temporal structure of\nmusic, this paper explores an even more important aspect: concept hierarchy,\nwhich involves generating music ideas, transforming them, and ultimately\norganizing them--across musical time and space--into a complete composition. To\nthis end, we introduce TOMI (Transforming and Organizing Music Ideas) as a\nnovel approach in deep music generation and develop a TOMI-based model via\ninstruction-tuned foundation LLM. Formally, we represent a multi-track\ncomposition process via a sparse, four-dimensional space characterized by clips\n(short audio or MIDI segments), sections (temporal positions), tracks\n(instrument layers), and transformations (elaboration methods). Our model is\ncapable of generating multi-track electronic music with full-song structure,\nand we further integrate the TOMI-based model with the REAPER digital audio\nworkstation, enabling interactive human-AI co-creation. Experimental results\ndemonstrate that our approach produces higher-quality electronic music with\nstronger structural coherence compared to baselines.", "AI": {"tldr": "The paper introduces TOMI, a hierarchical planning method for deep music generation, capable of producing coherent full-song multi-track electronic music.", "motivation": "To explore concept hierarchies in music generation, enabling the structuring of musical ideas across time and space into complete compositions.", "method": "A TOMI-based model is developed using an instruction-tuned foundation LLM and represents music with a four-dimensional sparse space involving clips, sections, tracks, and transformations.", "result": "The TOMI-based model generates high-quality, structurally coherent multi-track electronic music and supports interactive human-AI co-creation via integration with the REAPER workstation.", "conclusion": "The approach improves electronic music generation in terms of quality and structural coherence, showcasing potential for enhanced human-AI music collaboration."}}
{"id": "2506.23519", "pdf": "https://arxiv.org/pdf/2506.23519", "abs": "https://arxiv.org/abs/2506.23519", "authors": ["Qi Qin", "Runmin Cong", "Gen Zhan", "Yiting Liao", "Sam Kwong"], "title": "From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection", "categories": ["cs.CV"], "comment": "15 Pages, 9 Figures", "summary": "The eye-tracking video saliency prediction (VSP) task and video salient\nobject detection (VSOD) task both focus on the most attractive objects in video\nand show the result in the form of predictive heatmaps and pixel-level saliency\nmasks, respectively. In practical applications, eye tracker annotations are\nmore readily obtainable and align closely with the authentic visual patterns of\nhuman eyes. Therefore, this paper aims to introduce fixation information to\nassist the detection of video salient objects under weak supervision. On the\none hand, we ponder how to better explore and utilize the information provided\nby fixation, and then propose a Position and Semantic Embedding (PSE) module to\nprovide location and semantic guidance during the feature learning process. On\nthe other hand, we achieve spatiotemporal feature modeling under weak\nsupervision from the aspects of feature selection and feature contrast. A\nSemantics and Locality Query (SLQ) Competitor with semantic and locality\nconstraints is designed to effectively select the most matching and accurate\nobject query for spatiotemporal modeling. In addition, an Intra-Inter Mixed\nContrastive (IIMC) model improves the spatiotemporal modeling capabilities\nunder weak supervision by forming an intra-video and inter-video contrastive\nlearning paradigm. Experimental results on five popular VSOD benchmarks\nindicate that our model outperforms other competitors on various evaluation\nmetrics.", "AI": {"tldr": "This paper introduces a model that uses fixation information from eye-tracking to improve weakly-supervised video salient object detection. It incorporates novel methods for feature learning and spatiotemporal modeling.", "motivation": "Eye tracker annotations are easier to obtain and align closely with human visual patterns. The paper aims to leverage this fixation information to enhance the detection of video salient objects under weak supervision.", "method": "The paper proposes a Position and Semantic Embedding (PSE) module for location and semantic guidance during feature learning and introduces a Semantics and Locality Query (SLQ) Competitor for effective object query selection. An Intra-Inter Mixed Contrastive (IIMC) model is also developed for improved spatiotemporal modeling through contrastive learning.", "result": "The model's performance surpasses that of other competitors across various evaluation metrics when tested on five popular VSOD benchmarks.", "conclusion": "Integrating fixation information with weak supervision significantly enhances video salient object detection, demonstrating the effectiveness of the proposed methods in spatiotemporal modeling and feature selection."}}
{"id": "2506.23523", "pdf": "https://arxiv.org/pdf/2506.23523", "abs": "https://arxiv.org/abs/2506.23523", "authors": ["Tuong Do", "Binh X. Nguyen", "Quang D. Tran", "Erman Tjiputra", "Te-Chuan Chiu", "Anh Nguyen"], "title": "Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted in IROS 2025", "summary": "Traditional vision-based autonomous driving systems often face difficulties\nin navigating complex environments when relying solely on single-image inputs.\nTo overcome this limitation, incorporating temporal data such as past image\nframes or steering sequences, has proven effective in enhancing robustness and\nadaptability in challenging scenarios. While previous high-performance methods\nexist, they often rely on resource-intensive fusion networks, making them\nimpractical for training and unsuitable for federated learning. To address\nthese challenges, we propose lightweight temporal transformer decomposition, a\nmethod that processes sequential image frames and temporal steering data by\nbreaking down large attention maps into smaller matrices. This approach reduces\nmodel complexity, enabling efficient weight updates for convergence and\nreal-time predictions while leveraging temporal information to enhance\nautonomous driving performance. Intensive experiments on three datasets\ndemonstrate that our method outperforms recent approaches by a clear margin\nwhile achieving real-time performance. Additionally, real robot experiments\nfurther confirm the effectiveness of our method.", "AI": {"tldr": "The paper introduces a lightweight temporal transformer decomposition approach to improve autonomous driving in complex environments by utilizing temporal data like past images and steering sequences.", "motivation": "Many existing high-performance autonomous driving methods struggle with resource-intensive fusion networks and the practicalities of federated learning.", "method": "The proposed method decomposes large attention maps into smaller matrices, enabling efficient processing of temporal data and reducing model complexity for faster updates and real-time prediction.", "result": "Experiments across three datasets show superior performance compared to recent methods, with additional validation from real robot experiments.", "conclusion": "Temporal transformer decomposition improves temporal data use, achieving efficiency and enhanced performance in autonomous driving systems."}}
{"id": "2506.22729", "pdf": "https://arxiv.org/pdf/2506.22729", "abs": "https://arxiv.org/abs/2506.22729", "authors": ["Honglin Bao", "Kai Li"], "title": "Persistence Paradox in Dynamic Science", "categories": ["cs.DL", "cs.CY", "cs.LG"], "comment": null, "summary": "Persistence is often regarded as a virtue in science. In this paper, however,\nwe challenge this conventional view by highlighting its contextual nature,\nparticularly how persistence can become a liability during periods of paradigm\nshift. We focus on the deep learning revolution catalyzed by AlexNet in 2012.\nAnalyzing the 20-year career trajectories of over 5,000 scientists who were\nactive in top machine learning venues during the preceding decade, we examine\nhow their research focus and output evolved. We first uncover a dynamic period\nin which leading venues increasingly prioritized cutting-edge deep learning\ndevelopments that displaced relatively traditional statistical learning\nmethods. Scientists responded to these changes in markedly different ways.\nThose who were previously successful or affiliated with old teams adapted more\nslowly, experiencing what we term a rigidity penalty - a reluctance to embrace\nnew directions leading to a decline in scientific impact, as measured by\ncitation percentile rank. In contrast, scientists who pursued strategic\nadaptation - selectively pivoting toward emerging trends while preserving weak\nconnections to prior expertise - reaped the greatest benefits. Taken together,\nour macro- and micro-level findings show that scientific breakthroughs act as\nmechanisms that reconfigure power structures within a field.", "AI": {"tldr": "This paper examines how persistence in science, particularly during paradigm shifts like the deep learning revolution, can hinder adaptation and impact, with adaptable scientists achieving greater success.", "motivation": "To challenge the conventional view of persistence as always virtuous in science by exploring its contextual impact, especially during paradigm shifts.", "method": "Analyzed 20-year career trajectories of over 5,000 machine learning scientists, focusing on research focus evolution and scientific impact during the deep learning paradigm shift after AlexNet (2012).", "result": "Leading research venues shifted to deep learning from traditional methods. Scientists who adapted slowly due to prior success or affiliations faced a rigidity penalty, while those who pivoted strategically experienced higher success and impact.", "conclusion": "Scientific breakthroughs, like the deep learning revolution, reconfigure power dynamics in a field. Persistence might hinder progress without strategic adaptation, impacting scientific influence."}}
{"id": "2506.23529", "pdf": "https://arxiv.org/pdf/2506.23529", "abs": "https://arxiv.org/abs/2506.23529", "authors": ["Jisu Han", "Jihee Park", "Dongyoon Han", "Wonjun Hwang"], "title": "When Test-Time Adaptation Meets Self-Supervised Models", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages, 7 figures", "summary": "Training on test-time data enables deep learning models to adapt to dynamic\nenvironmental changes, enhancing their practical applicability. Online\nadaptation from source to target domains is promising but it remains highly\nreliant on the performance of source pretrained model. In this paper, we\ninvestigate whether test-time adaptation (TTA) methods can continuously improve\nmodels trained via self-supervised learning (SSL) without relying on source\npretraining. We introduce a self-supervised TTA protocol after observing that\nexisting TTA approaches struggle when directly applied to self-supervised\nmodels with low accuracy on the source domain. Furthermore, we propose a\ncollaborative learning framework that integrates SSL and TTA models, leveraging\ncontrastive learning and knowledge distillation for stepwise representation\nrefinement. We validate our method on diverse self-supervised models, including\nDINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the\neffectiveness of our approach in SSL, showing that it achieves competitive\nperformance even without source pretraining.", "AI": {"tldr": "The paper addresses test-time adaptation (TTA) for self-supervised learning (SSL) models, proposing a protocol and framework to refine representations without relying on source pretraining.", "motivation": "Investigates the limitations of existing TTA methods for self-supervised models and aims to enable continuous performance improvement even without source pretrained models.", "method": "Proposed a self-supervised TTA protocol and a collaborative learning framework combining SSL and TTA models, utilizing contrastive learning and knowledge distillation.", "result": "Extensive experiments show the proposed method improves SSL performance and achieves competitive results without requiring source pretraining.", "conclusion": "The approach successfully adapts self-supervised models at test time, offering a promising alternative to source-pretrained models and enhancing TTA effectiveness."}}
{"id": "2506.23121", "pdf": "https://arxiv.org/pdf/2506.23121", "abs": "https://arxiv.org/abs/2506.23121", "authors": ["Xinlei Yu", "Chanmiao Wang", "Hui Jin", "Ahmed Elazab", "Gangyong Jia", "Xiang Wan", "Changqing Zou", "Ruiquan Ge"], "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "19 pages, 9 figures, 10 tables", "summary": "Multi-organ medical segmentation is a crucial component of medical image\nprocessing, essential for doctors to make accurate diagnoses and develop\neffective treatment plans. Despite significant progress in this field, current\nmulti-organ segmentation models often suffer from inaccurate details,\ndependence on geometric prompts and loss of spatial information. Addressing\nthese challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal\nInteraction and Semantic Prompting based on SAM2. This model represents a\npromising approach to multi-organ medical segmentation guided by textual\ndescriptions of organs. Our method begins by converting visual and textual\ninputs into cross-modal contextualized semantics using a progressive\ncross-attention interaction mechanism. These semantics are then injected into\nthe image encoder to enhance the detailed understanding of visual information.\nTo eliminate reliance on geometric prompts, we use a semantic prompting\nstrategy, replacing the original prompt encoder to sharpen the perception of\nchallenging targets. In addition, a similarity-sorting self-updating strategy\nfor memory and a mask-refining process is applied to further adapt to medical\nimaging and enhance localized details. Comparative experiments conducted on\nseven public datasets indicate that CRISP-SAM2 outperforms existing models.\nExtensive analysis also demonstrates the effectiveness of our method, thereby\nconfirming its superior performance, especially in addressing the limitations\nmentioned earlier. Our code is available at:\nhttps://github.com/YU-deep/CRISP\\_SAM2.git.", "AI": {"tldr": "CRISP-SAM2 enhances multi-organ medical segmentation by leveraging cross-modal interaction and semantic prompting strategies, outperforming existing models.", "motivation": "The paper aims to address the challenges in current multi-organ segmentation techniques, such as inaccuracies, reliance on geometric prompts, and spatial information loss.", "method": "CRISP-SAM2 uses cross-modal contextualized semantics through a progressive cross-attention mechanism, semantic prompting replacing geometric prompts, and a similarity-sorting self-updating strategy paired with mask-refining to improve segmentation performance.", "result": "Comparative experiments on seven public datasets show CRISP-SAM2 outperforms other segmentation models, highlighting its efficiency in overcoming existing limitations.", "conclusion": "CRISP-SAM2 provides a significant advancement in multi-organ medical segmentation using textual descriptions of organs, confirming its superior accuracy and adaptability in processing medical images."}}
{"id": "2506.22763", "pdf": "https://arxiv.org/pdf/2506.22763", "abs": "https://arxiv.org/abs/2506.22763", "authors": ["Fiona Xiao Jingyi", "Lili Liu"], "title": "Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting", "categories": ["q-fin.PM", "cs.LG", "q-fin.CP"], "comment": "9 pages, 15 figures", "summary": "Forecasting central bank policy decisions remains a persistent challenge for\ninvestors, financial institutions, and policymakers due to the wide-reaching\nimpact of monetary actions. In particular, anticipating shifts in the U.S.\nfederal funds rate is vital for risk management and trading strategies.\nTraditional methods relying only on structured macroeconomic indicators often\nfall short in capturing the forward-looking cues embedded in central bank\ncommunications.\n  This study examines whether predictive accuracy can be enhanced by\nintegrating structured data with unstructured textual signals from Federal\nReserve communications. We adopt a multi-modal framework, comparing traditional\nmachine learning models, transformer-based language models, and deep learning\narchitectures in both unimodal and hybrid settings.\n  Our results show that hybrid models consistently outperform unimodal\nbaselines. The best performance is achieved by combining TF-IDF features of\nFOMC texts with economic indicators in an XGBoost classifier, reaching a test\nAUC of 0.83. FinBERT-based sentiment features marginally improve ranking but\nperform worse in classification, especially under class imbalance. SHAP\nanalysis reveals that sparse, interpretable features align more closely with\npolicy-relevant signals.\n  These findings underscore the importance of integrating textual and\nstructured signals transparently. For monetary policy forecasting, simpler\nhybrid models can offer both accuracy and interpretability, delivering\nactionable insights for researchers and decision-makers.", "AI": {"tldr": "This paper enhances forecasting of U.S. federal funds rate using hybrid models integrating textual and structured data, achieving improved predictive accuracy.", "motivation": "The paper aims to address shortcomings in traditional methods for forecasting central bank policies by exploring ways to better capture forward-looking cues from Federal Reserve communications.", "method": "The researchers employed a multi-modal framework combining structured economic indicators with unstructured textual data using models such as XGBoost classifiers, FinBERT sentiment analysis, and hybrid approaches.", "result": "Hybrid models outperform unimodal approaches, with the combination of TF-IDF features and economic indicators in an XGBoost classifier yielding the best test AUC of 0.83. FinBERT sentiment analysis improves ranking but struggles in classification.", "conclusion": "Integrating textual and structured data transparently through hybrid models offers accuracy and interpretability, making it valuable for forecasting monetary policies."}}
{"id": "2506.23532", "pdf": "https://arxiv.org/pdf/2506.23532", "abs": "https://arxiv.org/abs/2506.23532", "authors": ["Jefferson Hernandez", "Ruozhen He", "Guha Balakrishnan", "Alexander C. Berg", "Vicente Ordonez"], "title": "GViT: Representing Images as Gaussians for Visual Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce GVIT, a classification framework that abandons conventional\npixel or patch grid input representations in favor of a compact set of\nlearnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose\npositions, scales, orientations, colors, and opacities are optimized jointly\nwith a ViT classifier trained on top of these representations. We reuse the\nclassifier gradients as constructive guidance, steering the Gaussians toward\nclass-salient regions while a differentiable renderer optimizes an image\nreconstruction loss. We demonstrate that by 2D Gaussian input representations\ncoupled with our GVIT guidance, using a relatively standard ViT architecture,\nclosely matches the performance of a traditional patch-based ViT, reaching a\n76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.", "AI": {"tldr": "This paper introduces GVIT, a novel classification framework that uses learnable 2D Gaussian input representations instead of traditional pixel or patch grid inputs for training ViT classifiers.", "motivation": "To explore alternative input representations for vision transformers, moving away from pixel or patch grids, and potentially improve classification performance.", "method": "Images are encoded as learnable 2D Gaussians optimized for positional, color, and orientation properties alongside classifier training. Gradients from the ViT classifier guide Gaussian optimization while maintaining reconstruction accuracy via a differentiable renderer.", "result": "GVIT achieves competitive performance, including a 76.9% top-1 accuracy on Imagenet-1k, using a relatively standard ViT-B architecture.", "conclusion": "The study demonstrates that learnable 2D Gaussian input representations can closely match conventional ViT performance while innovating input structure and optimization guidance."}}
{"id": "2506.23538", "pdf": "https://arxiv.org/pdf/2506.23538", "abs": "https://arxiv.org/abs/2506.23538", "authors": ["Yuhao Huang", "Yueyue Xu", "Haoran Dou", "Jiaxiao Deng", "Xin Yang", "Hongyu Zheng", "Dong Ni"], "title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by MICCAI 2025;10 pages, 3 figures", "summary": "Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,\npreterm birth, and an increased risk of pregnancy complications. Compared to\ntraditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,\nproviding a clear visualization of the uterine morphology for assessing CUAs\naccurately. In this paper, we propose an intelligent system for simultaneous\nautomated plane localization and CUA diagnosis. Our highlights are: 1) we\ndevelop a denoising diffusion model with local (plane) and global (volume/text)\nguidance, using an adaptive weighting strategy to optimize attention allocation\nto different conditions; 2) we introduce a reinforcement learning-based\nframework with unsupervised rewards to extract the key slice summary from\nredundant sequences, fully integrating information across multiple planes to\nreduce learning difficulty; 3) we provide text-driven uncertainty modeling for\ncoarse prediction, and leverage it to adjust the classification probability for\noverall performance improvement. Extensive experiments on a large 3D uterine US\ndataset show the efficacy of our method, in terms of plane localization and CUA\ndiagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.", "AI": {"tldr": "This study presents a novel intelligent system leveraging advanced diffusion models, reinforcement learning, and text-driven approaches for automated plane localization and congenital uterine anomaly diagnosis using 3D ultrasound.", "motivation": "Congenital uterine anomalies can lead to significant reproductive issues, and 3D ultrasound offers better visualization compared to traditional 2D ultrasound, yet automated diagnosis remains challenging.", "method": "The authors developed techniques including a denoising diffusion model with adaptive guidance, reinforcement learning with unsupervised rewards, and uncertainty modeling driven by text to optimize classifications and plane localization in 3D ultrasound imaging.", "result": "Experiments conducted on a large dataset demonstrated the system's effectiveness in accurately localizing planes and diagnosing congenital uterine anomalies.", "conclusion": "The proposed system significantly enhances 3D ultrasound-based plane localization and CUA diagnosis, offering a promising tool for clinical applications."}}
{"id": "2506.22799", "pdf": "https://arxiv.org/pdf/2506.22799", "abs": "https://arxiv.org/abs/2506.22799", "authors": ["Minchao Jiang", "Shunyu Jia", "Jiaming Gu", "Xiaoyuan Lu", "Guangming Zhu", "Anqi Dong", "Liang Zhang"], "title": "VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time\nrendering for novel view synthesis of 3D scenes. However, existing methods\nfocus primarily on geometric and appearance modeling, lacking deeper scene\nunderstanding while also incurring high training costs that complicate the\noriginally streamlined differentiable rendering pipeline. To this end, we\npropose VoteSplat, a novel 3D scene understanding framework that integrates\nHough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized\nfor instance segmentation, extracting objects, and generating 2D vote maps. We\nthen embed spatial offset vectors into Gaussian primitives. These offsets\nconstruct 3D spatial votes by associating them with 2D image votes, while depth\ndistortion constraints refine localization along the depth axis. For\nopen-vocabulary object localization, VoteSplat maps 2D image semantics to 3D\npoint clouds via voting points, reducing training costs associated with\nhigh-dimensional CLIP features while preserving semantic unambiguity. Extensive\nexperiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D\ninstance localization, 3D point cloud understanding, click-based 3D object\nlocalization, hierarchical segmentation, and ablation studies. Our code is\navailable at https://sy-ja.github.io/votesplat/", "AI": {"tldr": "The paper proposes VoteSplat, a novel 3D scene understanding framework that combines 3D Gaussian Splatting and Hough voting for improving tasks such as object localization and semantic mapping in 3D scenes.", "motivation": "Existing 3D Gaussian Splatting methods focus on rendering quality and efficiency but lack scene understanding capabilities and come with high training costs. The authors aim to address these limitations to enable more comprehensive 3D scene understanding.", "method": "The framework integrates the Segment Anything Model (SAM) for extracting objects and generating 2D vote maps, embeds spatial offsets into Gaussian primitives for constructing 3D spatial votes, and maps 2D image semantics to 3D point clouds. Depth distortion constraints are added to refine the depth localization.", "result": "VoteSplat demonstrates its effectiveness through experiments on open-vocabulary 3D instance localization, 3D point cloud understanding, click-based 3D object localization, hierarchical segmentation, and detailed ablation studies.", "conclusion": "VoteSplat enhances 3D scene understanding by making it both efficient and semantically rich while reducing computational costs. Its open-vocabulary capability and focus on instance segmentation highlight its versatility."}}
{"id": "2506.23542", "pdf": "https://arxiv.org/pdf/2506.23542", "abs": "https://arxiv.org/abs/2506.23542", "authors": ["Weida Wang", "Changyong He", "Jin Zeng", "Di Qiu"], "title": "Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention", "categories": ["cs.CV"], "comment": "This paper has been accepted for publication at the International\n  Conference on Computer Vision (ICCV) 2025", "summary": "Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,\nrequiring denoising for reliable downstream applications. Previous works either\nfocus on single-frame processing, or perform multi-frame processing without\nconsidering depth variations at corresponding pixels across frames, leading to\nundesirable temporal inconsistency and spatial ambiguity. In this paper, we\npropose a novel ToF depth denoising network leveraging motion-invariant graph\nfusion to simultaneously enhance temporal stability and spatial sharpness.\nSpecifically, despite depth shifts across frames, graph structures exhibit\ntemporal self-similarity, enabling cross-frame geometric attention for graph\nfusion. Then, by incorporating an image smoothness prior on the fused graph and\ndata fidelity term derived from ToF noise distribution, we formulate a maximum\na posterior problem for ToF denoising. Finally, the solution is unrolled into\niterative filters whose weights are adaptively learned from the graph-informed\ngeometric attention, producing a high-performance yet interpretable network.\nExperimental results demonstrate that the proposed scheme achieves\nstate-of-the-art performance in terms of accuracy and consistency on synthetic\nDVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.\nSource code will be released at\n\\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.", "AI": {"tldr": "The paper introduces a novel approach to Time-of-Flight (ToF) depth image denoising called motion-invariant graph fusion, which improves both temporal consistency and spatial clarity.", "motivation": "Existing methods for Time-of-Flight depth image denoising are either limited to single-frame processing or fail to account for depth variations across frames, leading to temporal inconsistencies and spatial ambiguity.", "method": "The authors propose a ToF depth denoising network that uses motion-invariant graph fusion to enhance temporal and spatial quality. It employs cross-frame geometric attention based on self-similar graph structures, integrates an image smoothness prior and a data fidelity term, and applies an interpretable iterative filtering process with graph-informed weights.", "result": "The proposed technique achieves state-of-the-art denoising accuracy and consistency on the synthetic DVToF dataset and demonstrates strong generalization performance on the real-world Kinectv2 dataset.", "conclusion": "The method significantly improves ToF depth denoising by balancing accuracy and consistency through novel graph-based formulations, offering an interpretable and robust solution for both synthetic and real datasets."}}
{"id": "2506.23543", "pdf": "https://arxiv.org/pdf/2506.23543", "abs": "https://arxiv.org/abs/2506.23543", "authors": ["Hui Li", "Baoyou Chen", "Liwei Zhang", "Jiaye Li", "Jingdong Wang", "Siyu Zhu"], "title": "Pyramidal Patchification Flow for Visual Generation", "categories": ["cs.CV"], "comment": "10 pages, 9figures", "summary": "Diffusion transformers (DiTs) adopt Patchify, mapping patch representations\nto token representations through linear projections, to adjust the number of\ntokens input to DiT blocks and thus the computation cost. Instead of a single\npatch size for all the timesteps, we introduce a Pyramidal Patchification Flow\n(PPFlow) approach: Large patch sizes are used for high noise timesteps and\nsmall patch sizes for low noise timesteps; Linear projections are learned for\neach patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,\nour approach operates over full latent representations other than pyramid\nrepresentations, and adopts the normal denoising process without requiring the\nrenoising trick. We demonstrate the effectiveness of our approach through two\ntraining manners. Training from scratch achieves a $1.6\\times$ ($2.0\\times$)\ninference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with\nslightly lower training FLOPs and similar image generation performance.\nTraining from pretrained normal DiTs achieves even better performance with\nsmall training time. The code and checkpoint are at\nhttps://github.com/fudan-generative-vision/PPFlow.", "AI": {"tldr": "The paper introduces the Pyramidal Patchification Flow (PPFlow) to improve the performance and efficiency of Diffusion Transformers (DiTs) by adapting patch sizes based on noise levels during denoising.", "motivation": "To address computational inefficiency in DiTs training and inference, especially in handling varied patch sizes during timesteps of denoising processes.", "method": "PPFlow modifies patch sizes based on noise levels during timesteps, incorporates learned linear projections, adjusts the 'Unpatchify' process, and applies standard denoising methods. It supports training from scratch or fine-tuning from pretrained models.", "result": "PPFlow achieves up to 2x faster inference speed while maintaining comparable image generation performance, with slightly reduced training FLOPs.", "conclusion": "PPFlow is a computationally effective approach that enhances inference speed and image generation performance of DiTs, and can be trained efficiently either from scratch or using pretrained models."}}
{"id": "2506.23547", "pdf": "https://arxiv.org/pdf/2506.23547", "abs": "https://arxiv.org/abs/2506.23547", "authors": ["Jiwon Kim", "Soohyun Hwang", "Dong-O Kim", "Changsu Han", "Min Kyu Park", "Chang-Su Kim"], "title": "Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions", "categories": ["cs.CV"], "comment": null, "summary": "The first algorithm, called Oneta, for a novel task of multi-style image\nenhancement is proposed in this work. Oneta uses two point operators\nsequentially: intensity enhancement with a transformation function (TF) and\ncolor correction with a color correction matrix (CCM). This two-step\nenhancement model, though simple, achieves a high performance upper bound.\nAlso, we introduce eigentransformation function (eigenTF) to represent TF\ncompactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and\nCCM parameters, respectively. To support $K$ styles, Oneta employs $K$\nlearnable tokens. During training, each style token is learned using image\npairs from the corresponding dataset. In testing, Oneta selects one of the $K$\nstyle tokens to enhance an image accordingly. Extensive experiments show that\nthe single Oneta network can effectively undertake six enhancement tasks --\nretouching, image signal processing, low-light image enhancement, dehazing,\nunderwater image enhancement, and white balancing -- across 30 datasets.", "AI": {"tldr": "The paper introduces Oneta, a network for multi-style image enhancement, using two sequential functions for intensity and color correction via compact parameterization, successfully handling six tasks across 30 datasets.", "motivation": "To develop an algorithm capable of addressing diverse image enhancement tasks under multiple styles using a unified framework.", "method": "The Oneta algorithm employs two-step enhancement using intensity transformation (TF) and color correction (CCM). It uses learnable tokens for multi-style support and comprises Y-Net and C-Net to predict transformation parameters.", "result": "Oneta demonstrated effectiveness on six enhancement tasks such as dehazing, underwater enhancement, and white balancing across 30 datasets.", "conclusion": "Oneta achieves high performance in multi-style image enhancement, showcasing its versatility and adaptability across various enhancement tasks and datasets."}}
{"id": "2506.23552", "pdf": "https://arxiv.org/pdf/2506.23552", "abs": "https://arxiv.org/abs/2506.23552", "authors": ["Mingi Kwon", "Joonghyuk Shin", "Jaeseok Jung", "Jaesik Park", "Youngjung Uh"], "title": "JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "project page: https://joonghyuk.com/jamflow-web Under review.\n  Preprint published on arXiv", "summary": "The intrinsic link between facial motion and speech is often overlooked in\ngenerative modeling, where talking head synthesis and text-to-speech (TTS) are\ntypically addressed as separate tasks. This paper introduces JAM-Flow, a\nunified framework to simultaneously synthesize and condition on both facial\nmotion and speech. Our approach leverages flow matching and a novel Multi-Modal\nDiffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT\nand Audio-DiT modules. These are coupled via selective joint attention layers\nand incorporate key architectural choices, such as temporally aligned\npositional embeddings and localized joint attention masking, to enable\neffective cross-modal interaction while preserving modality-specific strengths.\nTrained with an inpainting-style objective, JAM-Flow supports a wide array of\nconditioning inputs-including text, reference audio, and reference\nmotion-facilitating tasks such as synchronized talking head generation from\ntext, audio-driven animation, and much more, within a single, coherent model.\nJAM-Flow significantly advances multi-modal generative modeling by providing a\npractical solution for holistic audio-visual synthesis. project page:\nhttps://joonghyuk.com/jamflow-web", "AI": {"tldr": "The paper presents JAM-Flow, a unified framework for simultaneously synthesizing and conditioning on facial motion and speech, integrating novel diffusion-based transformer architectures.", "motivation": "To address the separation of talking head synthesis and text-to-speech tasks by creating a unified framework that bridges facial motion and speech in generative modeling.", "method": "The method leverages flow matching and Multi-Modal Diffusion Transformer (MM-DiT) with Motion-DiT and Audio-DiT modules, using novel architectural components like temporally aligned positional embeddings and joint attention masking.", "result": "JAM-Flow enables synchronized talking head generation and other audio-visual tasks from various inputs, presenting noteworthy performance in multi-modal generative modeling.", "conclusion": "JAM-Flow provides an integrated and practical solution for holistic audio-visual synthesis, advancing the field of multi-modal generative modeling."}}
{"id": "2506.23173", "pdf": "https://arxiv.org/pdf/2506.23173", "abs": "https://arxiv.org/abs/2506.23173", "authors": ["Tomer Slor", "Dean Oren", "Shira Baneth", "Tom Coen", "Haim Suchowski"], "title": "Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems", "categories": ["physics.optics", "cs.AI", "cs.LG"], "comment": null, "summary": "In the rapidly evolving field of optical engineering, precise alignment of\nmulti-lens imaging systems is critical yet challenging, as even minor\nmisalignments can significantly degrade performance. Traditional alignment\nmethods rely on specialized equipment and are time-consuming processes,\nhighlighting the need for automated and scalable solutions. We present two\ncomplementary deep learning-based inverse-design methods for diagnosing\nmisalignments in multi-element lens systems using only optical measurements.\nFirst, we use ray-traced spot diagrams to predict five-degree-of-freedom\n(5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error\nof 0.031mm in lateral translation and 0.011$^\\circ$ in tilt. We also introduce\na physics-based simulation pipeline that utilizes grayscale synthetic camera\nimages, enabling a deep learning model to estimate 4-DOF, decenter and tilt\nerrors in both two- and six-lens multi-lens systems. These results show the\npotential to reshape manufacturing and quality control in precision imaging.", "AI": {"tldr": "The study introduces two deep learning methods for diagnosing misalignments in multi-lens systems using optical measurements, showing high accuracy in error prediction.", "motivation": "Precise alignment of multi-lens systems is crucial for optimal performance, and traditional methods are inefficient and slow, necessitating automated solutions.", "method": " Two approaches were employed: ray-traced spot diagrams to predict 5-DOF errors and a physics-based simulation pipeline using synthetic grayscale images for 4-DOF error estimation.", "result": "The methods achieved high accuracy in predicting alignment errors\u20140.031mm in lateral translation and 0.011\u00b0 in tilt for the ray-traced technique\u2014and validated performance for both two- and six-lens systems with the simulation model.", "conclusion": "Deep learning-based techniques offer promising tools for automating alignment diagnostics in imaging systems, potentially transforming manufacturing and quality control processes."}}
{"id": "2506.23555", "pdf": "https://arxiv.org/pdf/2506.23555", "abs": "https://arxiv.org/abs/2506.23555", "authors": ["Fan Xie", "Pan Cao"], "title": "LH2Face: Loss function for Hard High-quality Face", "categories": ["cs.CV"], "comment": null, "summary": "In current practical face authentication systems, most face recognition (FR)\nalgorithms are based on cosine similarity with softmax classification. Despite\nits reliable classification performance, this method struggles with hard\nsamples. A popular strategy to improve FR performance is incorporating angular\nor cosine margins. However, it does not take face quality or recognition\nhardness into account, simply increasing the margin value and thus causing an\noverly uniform training strategy. To address this problem, a novel loss\nfunction is proposed, named Loss function for Hard High-quality Face (LH2Face).\nFirstly, a similarity measure based on the von Mises-Fisher (vMF) distribution\nis stated, specifically focusing on the logarithm of the Probability Density\nFunction (PDF), which represents the distance between a probability\ndistribution and a vector. Then, an adaptive margin-based multi-classification\nmethod using softmax, called the Uncertainty-Aware Margin Function, is\nimplemented in the article. Furthermore, proxy-based loss functions are used to\napply extra constraints between the proxy and sample to optimize their\nrepresentation space distribution. Finally, a renderer is constructed that\noptimizes FR through face reconstruction and vice versa. Our LH2Face is\nsuperior to similiar schemes on hard high-quality face datasets, achieving\n49.39% accuracy on the IJB-B dataset, which surpasses the second-place method\nby 2.37%.", "AI": {"tldr": "The paper proposes LH2Face, a new loss function for face recognition which excels particularly on challenging, high-quality face datasets.", "motivation": "Address the shortcomings of existing face recognition methods that struggle with hard samples and fail to consider face quality and recognition hardness.", "method": "Introduce LH2Face loss function using a combination of von Mises-Fisher distribution, Uncertainty-Aware Margin Function, proxy-based constraints, and face reconstruction-rendering optimization.", "result": "LH2Face achieves a 49.39% accuracy on the IJB-B dataset, outperforming the previous best method by 2.37%.", "conclusion": "LH2Face improves face recognition performance by effectively handling hard high-quality face samples through a combination of innovative techniques."}}
{"id": "2506.22882", "pdf": "https://arxiv.org/pdf/2506.22882", "abs": "https://arxiv.org/abs/2506.22882", "authors": ["Qilong Xing", "Zikai Song", "Yuteng Ye", "Yuke Chen", "Youjia Zhang", "Na Feng", "Junqing Yu", "Wei Yang"], "title": "CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "ICME 2025", "summary": "Segmentation of brain structures from MRI is crucial for evaluating brain\nmorphology, yet existing CNN and transformer-based methods struggle to\ndelineate complex structures accurately. While current diffusion models have\nshown promise in image segmentation, they are inadequate when applied directly\nto brain MRI due to neglecting anatomical information. To address this, we\npropose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating\nspatial anatomical features to enhance segmentation accuracy of the diffusion\nmodel. Specifically, we introduce distance field as an auxiliary anatomical\ncondition to provide global spatial context, alongside a collaborative\ndiffusion process to model its joint distribution with anatomical structures,\nenabling effective utilization of anatomical features for segmentation.\nFurthermore, we introduce a consistency loss to refine relationships between\nthe distance field and anatomical structures and design a time adapted channel\nattention module to enhance the U-Net feature fusion procedure. Extensive\nexperiments show that CA-Diff outperforms state-of-the-art (SOTA) methods.", "AI": {"tldr": "This paper introduces the Collaborative Anatomy Diffusion (CA-Diff) framework, leveraging anatomical information to improve brain MRI segmentation and outperforming state-of-the-art methods.", "motivation": "The study aims to address the limitations of existing CNN and transformer-based methods in delineating complex brain structures from MRI images and the inadequacies of current diffusion models when directly applied to brain MRI due to neglecting anatomical information.", "method": "The proposed CA-Diff framework integrates distance field as an auxiliary anatomical condition for global spatial context, utilizes a collaborative diffusion process for joint distribution modeling with anatomical structures, introduces a consistency loss to refine relationships, and implements a time-adapted channel attention module to improve U-Net feature fusion.", "result": "CA-Diff demonstrates superior performance in brain MRI segmentation tasks, surpassing existing SOTA approaches in accuracy.", "conclusion": "Incorporating anatomical context through the CA-Diff framework significantly enhances segmentation performance, providing a promising avenue for brain morphology evaluation."}}
{"id": "2506.23565", "pdf": "https://arxiv.org/pdf/2506.23565", "abs": "https://arxiv.org/abs/2506.23565", "authors": ["Mingqian Ji", "Jian Yang", "Shanshan Zhang"], "title": "OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "Current multi-view 3D object detection methods typically transfer 2D features\ninto 3D space using depth estimation or 3D position encoder, but in a fully\ndata-driven and implicit manner, which limits the detection performance.\nInspired by the success of radiance fields on 3D reconstruction, we assume they\ncan be used to enhance the detector's ability of 3D geometry estimation.\nHowever, we observe a decline in detection performance, when we directly use\nthem for 3D rendering as an auxiliary task. From our analysis, we find the\nperformance drop is caused by the strong responses on the background when\nrendering the whole scene. To address this problem, we propose object-centric\nradiance fields, focusing on modeling foreground objects while discarding\nbackground noises. Specifically, we employ Object-centric Radiance Fields\n(OcRF) to enhance 3D voxel features via an auxiliary task of rendering\nforeground objects. We further use opacity - the side-product of rendering- to\nenhance the 2D foreground BEV features via Height-aware Opacity-based Attention\n(HOA), where attention maps at different height levels are generated separately\nvia multiple networks in parallel. Extensive experiments on the nuScenes\nvalidation and test datasets demonstrate that our OcRFDet achieves superior\nperformance, outperforming previous state-of-the-art methods with 57.2$\\%$ mAP\nand 64.8$\\%$ NDS on the nuScenes test benchmark. Code will be available at\nhttps://github.com/Mingqj/OcRFDet.", "AI": {"tldr": "The paper introduces Object-centric Radiance Fields (OcRF) to improve 3D object detection by focusing on modeling foreground objects while discarding background noise.", "motivation": "Improve the performance of multi-view 3D object detection by addressing limitations in geometric estimation from 2D features.", "method": "The authors propose OcRF for enhancing 3D voxel features through auxiliary rendering tasks focused on foreground objects. Additionally, they introduce a Height-aware Opacity-based Attention (HOA) mechanism for enhancing 2D foreground BEV features.", "result": "OcRFDet achieves state-of-the-art performance on the nuScenes test benchmark with 57.2% mAP and 64.8% NDS, outperforming previous methods.", "conclusion": "By shifting focus to object-centric modeling and leveraging opacity-based attention, their approach addresses background noise issues and significantly boosts detection accuracy."}}
{"id": "2506.23184", "pdf": "https://arxiv.org/pdf/2506.23184", "abs": "https://arxiv.org/abs/2506.23184", "authors": ["Anran Liu", "Xiaofei Wang", "Jing Cai", "Chao Li"], "title": "Score-based Diffusion Model for Unpaired Virtual Histology Staining", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "11 pages, 3 figures", "summary": "Hematoxylin and eosin (H&E) staining visualizes histology but lacks\nspecificity for diagnostic markers. Immunohistochemistry (IHC) staining\nprovides protein-targeted staining but is restricted by tissue availability and\nantibody specificity. Virtual staining, i.e., computationally translating the\nH&E image to its IHC counterpart while preserving the tissue structure, is\npromising for efficient IHC generation. Existing virtual staining methods still\nface key challenges: 1) effective decomposition of staining style and tissue\nstructure, 2) controllable staining process adaptable to diverse tissue and\nproteins, and 3) rigorous structural consistency modelling to handle the\nnon-pixel-aligned nature of paired H&E and IHC images. This study proposes a\nmutual-information (MI)-guided score-based diffusion model for unpaired virtual\nstaining. Specifically, we design 1) a global MI-guided energy function that\ndisentangles the tissue structure and staining characteristics across\nmodalities, 2) a novel timestep-customized reverse diffusion process for\nprecise control of the staining intensity and structural reconstruction, and 3)\na local MI-driven contrastive learning strategy to ensure the cellular level\nstructural consistency between H&E-IHC images. Extensive experiments\ndemonstrate the our superiority over state-of-the-art approaches, highlighting\nits biomedical potential. Codes will be open-sourced upon acceptance.", "AI": {"tldr": "The paper presents an MI-guided score-based diffusion model for unpaired virtual staining from H&E to IHC images, overcoming key limitations in staining style decomposition, control, and structural consistency.", "motivation": "To address challenges in current virtual staining methods, such as the need for better decomposition of staining style and tissue structure, adaptable staining processes, and rigorous structural consistency for non-pixel-aligned images.", "method": "The study introduces a mutual-information (MI)-guided score-based diffusion model, with a global MI-guided energy function, a timestep-customized reverse diffusion process, and a local MI-driven contrastive learning strategy.", "result": "Extensive experiments show the model's superiority over state-of-the-art techniques in virtual staining, producing better structural consistency and controllable results.", "conclusion": "The proposed method demonstrates strong potential for biomedical applications in efficiently generating IHC images, with a commitment to open-source its codes upon paper acceptance."}}
{"id": "2506.23566", "pdf": "https://arxiv.org/pdf/2506.23566", "abs": "https://arxiv.org/abs/2506.23566", "authors": ["Luigi Sigillo", "Renato Giamba", "Danilo Comminiello"], "title": "Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution", "categories": ["cs.CV", "cs.LG"], "comment": "ICLR 2025 Workshop on Machine Learning for Remote Sensing (ML4RS)", "summary": "The acquisition of high-resolution satellite imagery is often constrained by\nthe spatial and temporal limitations of satellite sensors, as well as the high\ncosts associated with frequent observations. These challenges hinder\napplications such as environmental monitoring, disaster response, and\nagricultural management, which require fine-grained and high-resolution data.\nIn this paper, we propose MWT-Diff, an innovative framework for satellite image\nsuper-resolution (SR) that combines latent diffusion models with wavelet\ntransforms to address these challenges. At the core of the framework is a novel\nmetadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates\nembeddings that capture metadata attributes, multi-scale frequency information,\nand temporal relationships. The embedded feature representations steer the\nhierarchical diffusion dynamics, through which the model progressively\nreconstructs high-resolution satellite imagery from low-resolution inputs. This\nprocess preserves critical spatial characteristics including textural patterns,\nboundary discontinuities, and high-frequency spectral components essential for\ndetailed remote sensing analysis. The comparative analysis of MWT-Diff across\nmultiple datasets demonstrated favorable performance compared to recent\napproaches, as measured by standard perceptual quality metrics including FID\nand LPIPS.", "AI": {"tldr": "The paper introduces MWT-Diff, a novel satellite image super-resolution framework combining latent diffusion models with wavelet transforms to generate high-resolution satellite imagery.", "motivation": "High-resolution satellite imagery is essential for applications like environmental monitoring and disaster response but is limited by sensor capabilities and costs.", "method": "The MWT-Diff framework integrates a metadata-, wavelet-, and time-aware encoder to generate embeddings that guide latent diffusion models through hierarchical dynamics, preserving spatial characteristics in reconstruction.", "result": "MWT-Diff demonstrated favorable performance in generating high-quality imagery across datasets, measured by metrics such as FID and LPIPS.", "conclusion": "MWT-Diff effectively addresses key challenges in satellite image super-resolution, enhancing applications requiring detailed remote sensing analysis."}}
{"id": "2506.23203", "pdf": "https://arxiv.org/pdf/2506.23203", "abs": "https://arxiv.org/abs/2506.23203", "authors": ["Feng Shu", "Jiatong Bai", "Di Wu", "Wei Zhu", "Bin Deng", "Fuhui Zhou", "Jiangzhou Wang"], "title": "Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "As a green MIMO structure, massive H$^2$AD is viewed as a potential\ntechnology for the future 6G wireless network. For such a structure, it is a\nchallenging task to design a low-complexity and high-performance fusion of\ntarget direction values sensed by different sub-array groups with fewer use of\nprior knowledge. To address this issue, a lightweight Cramer-Rao lower bound\n(CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse\nCRLB of each subarray using antenna number reciprocals to eliminate real-time\nCRLB computation. This reduces complexity and prior knowledge dependence while\npreserving fusion performance. Moreover, a multi-branch deep neural network\n(MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by\nleveraging candidate angles from multiple subarrays. The subarray-specific\nbranch networks are integrated with a shared regression module to effectively\neliminate pseudo-solutions and fuse true angles. Simulation results show that\nthe proposed CRLB-ratio-WF method achieves DOA sensing performance comparable\nto CRLB-based methods, while significantly reducing the reliance on prior\nknowledge. More notably, the proposed MBDNN has superior performance in low-SNR\nranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in\nestimation accuracy compared to CRLB-ratio-WF method.", "AI": {"tldr": "The paper focuses on advancing direction-of-arrival (DOA) sensing in 6G massive H$^2$AD MIMO systems by proposing a lightweight CRLB-ratio-weight fusion (WF) method and a multi-branch deep neural network (MBDNN) to enhance performance and reduce complexity.", "motivation": "Designing a low-complexity and high-performance method for fusing target direction values in massive H$^2$AD-based 6G networks is challenging due to the need for reduced dependence on prior knowledge and computational resource.", "method": "The paper introduces a CRLB-ratio-weight fusion (WF) method to approximate inverse CRLB using antenna number reciprocals, and a multi-branch deep neural network (MBDNN) for improved DOA sensing, integrating subarray-specific branches with a shared regression module for angle fusion.", "result": "The CRLB-ratio-WF method achieves DOA sensing performance comparable to CRLB-based methods, while reducing reliance on prior knowledge. The MBDNN outperforms CRLB-ratio-WF in low-SNR scenarios, achieving significantly higher estimation accuracy at SNR = -15 dB.", "conclusion": "The proposed lightweight CRLB-ratio-WF and MBDNN method effectively address the challenges of DOA sensing in massive H$^2$AD systems, offering high accuracy and low complexity solutions, especially in low-SNR conditions."}}
{"id": "2506.23575", "pdf": "https://arxiv.org/pdf/2506.23575", "abs": "https://arxiv.org/abs/2506.23575", "authors": ["Nuo Chen", "Chao Xiao", "Yimian Dai", "Shiman He", "Miao Li", "Wei An"], "title": "Event-based Tiny Object Detection: A Benchmark Dataset and Baseline", "categories": ["cs.CV"], "comment": null, "summary": "Small object detection (SOD) in anti-UAV task is a challenging problem due to\nthe small size of UAVs and complex backgrounds. Traditional frame-based cameras\nstruggle to detect small objects in complex environments due to their low frame\nrates, limited dynamic range, and data redundancy. Event cameras, with\nmicrosecond temporal resolution and high dynamic range, provide a more\neffective solution for SOD. However, existing event-based object detection\ndatasets are limited in scale, feature large targets size, and lack diverse\nbackgrounds, making them unsuitable for SOD benchmarks. In this paper, we\nintroduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),\nthe first large-scale, highly diverse benchmark for anti-UAV tasks. It includes\n147 sequences with over 2.3 million event-level annotations, featuring\nextremely small targets (averaging 6.8 $\\times$ 5.4 pixels) and diverse\nscenarios such as urban clutter and extreme lighting conditions. Furthermore,\nbased on the observation that small moving targets form continuous curves in\nspatiotemporal event point clouds, we propose Event based Sparse Segmentation\nNetwork (EV-SpSegNet), a novel baseline for event segmentation in point cloud\nspace, along with a Spatiotemporal Correlation (STC) loss that leverages motion\ncontinuity to guide the network in retaining target events. Extensive\nexperiments on the EV-UAV dataset demonstrate the superiority of our method and\nprovide a benchmark for future research in EVSOD. The dataset and code are at\nhttps://github.com/ChenYichen9527/Ev-UAV.", "AI": {"tldr": "This paper addresses small object detection (SOD) in anti-UAV tasks using event cameras, introducing a novel dataset (EV-UAV) and a segmentation network (EV-SpSegNet).", "motivation": "Traditional frame-based cameras perform poorly in anti-UAV tasks due to limitations such as low frame rates and challenges with small object detection in complex scenarios. Event cameras offer a potential solution but lack appropriate benchmark datasets for SOD in diverse, realistic scenarios.", "method": "The authors introduced EV-UAV, a large-scale event-based dataset with 147 sequences and 2.3 million event-level annotations. They also proposed EV-SpSegNet, an event segmentation network that utilizes spatiotemporal event point clouds, and a new loss function called Spatiotemporal Correlation (STC) loss to enhance detection by leveraging motion continuity.", "result": "The proposed EV-SpSegNet demonstrated state-of-the-art performance on the newly introduced EV-UAV dataset, showcasing its potential as a robust benchmark for event-based small object detection methods.", "conclusion": "The study provides both a comprehensive benchmark (EV-UAV dataset) and a novel method (EV-SpSegNet) for advancing small object detection research in anti-UAV applications using event cameras."}}
{"id": "2506.22935", "pdf": "https://arxiv.org/pdf/2506.22935", "abs": "https://arxiv.org/abs/2506.22935", "authors": ["Marc Bara Iniesta"], "title": "Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation", "categories": ["eess.SP", "cs.LG", "cs.NA", "math.NA", "94A12, 65T50, 68T05", "F.2.1; I.2.6; G.1.0"], "comment": "16 pages, 4 figures, source code available at\n  https://github.com/marcbara/graf-psl-lpi (DOI: 10.5281/zenodo.15763301)", "summary": "The ambiguity function is fundamental to radar waveform design,\ncharacterizing range and Doppler resolution capabilities. However, its\ntraditional formulation involves non-differentiable operations, preventing\nintegration with gradient-based optimization methods and modern machine\nlearning frameworks. This paper presents the first complete mathematical\nframework and computational implementation for differentiable radar ambiguity\nfunctions. Our approach addresses the fundamental technical challenges that\nhave prevented the radar community from leveraging automatic differentiation:\nproper handling of complex-valued gradients using Wirtinger calculus, efficient\ncomputation through parallelized FFT operations, numerical stability throughout\ncascaded operations, and composability with arbitrary differentiable\noperations. We term this approach GRAF (Gradient-based Radar Ambiguity\nFunctions), which reformulates the ambiguity function computation to maintain\nmathematical equivalence while enabling gradient flow through the entire\npipeline. The resulting implementation provides a general-purpose\ndifferentiable ambiguity function compatible with modern automatic\ndifferentiation frameworks, enabling new research directions including neural\nnetwork-based waveform generation with ambiguity constraints, end-to-end\noptimization of radar systems, and integration of classical radar theory with\nmodern deep learning. We provide complete implementation details and\ndemonstrate computational efficiency suitable for practical applications. This\nwork establishes the mathematical and computational foundation for applying\nmodern machine learning techniques to radar waveform design, bridging classical\nradar signal processing with automatic differentiation frameworks.", "AI": {"tldr": "The paper introduces a differentiable radar ambiguity function framework (GRAF) compatible with modern machine learning, solving challenges like complex-valued gradient computation.", "motivation": "Radar waveform design faces limitations due to non-differentiable ambiguity functions, hindering integration with machine learning frameworks.", "method": "The paper employs Wirtinger calculus, parallelized FFT operations, and numerical stable pipelines to enable differentiability in radar ambiguity functions.", "result": "GRAF achieves gradient flow through the ambiguity function computation pipeline and demonstrates suitability for neural-network-based waveform optimization.", "conclusion": "This work bridges radar signal processing with machine learning by providing a foundation for gradient-based optimization in radar applications."}}
{"id": "2506.23577", "pdf": "https://arxiv.org/pdf/2506.23577", "abs": "https://arxiv.org/abs/2506.23577", "authors": ["Yanning Hou", "Yanran Ruan", "Junfa Li", "Shanshan Wang", "Jianfeng Qiu", "Ke Xu"], "title": "StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Enhancing the alignment between text and image features in the CLIP model is\na critical challenge in zero-shot industrial anomaly detection tasks. Recent\nstudies predominantly utilize specific category prompts during pretraining,\nwhich can cause overfitting to the training categories and limit model\ngeneralization. To address this, we propose a method that transforms category\nnames through multicategory name stacking to create stacked prompts, forming\nthe basis of our StackCLIP model. Our approach introduces two key components.\nThe Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts\nby stacking semantically analogous categories, while utilizing multi-object\ntextual feature fusion to amplify discriminative anomalies among similar\nobjects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific\nlinear layers tailored for each stack cluster and adaptively integrates them\nbased on the attributes of test categories. These modules work together to\ndeliver superior training speed, stability, and convergence, significantly\nboosting anomaly segmentation performance. Additionally, our stacked prompt\nframework offers robust generalization across classification tasks. To further\nimprove performance, we introduce the Regulating Prompt Learning (RPL) module,\nwhich leverages the generalization power of stacked prompts to refine prompt\nlearning, elevating results in anomaly detection classification tasks.\nExtensive testing on seven industrial anomaly detection datasets demonstrates\nthat our method achieves state-of-the-art performance in both zero-shot anomaly\ndetection and segmentation tasks.", "AI": {"tldr": "This paper introduces StackCLIP, an approach aimed to enhance text-image feature alignment in CLIP models, addressing challenges in zero-shot industrial anomaly detection.", "motivation": "Zero-shot industrial anomaly detection using CLIP models faces issues of overfitting and limited generalization due to traditional category-specific prompts.", "method": "The StackCLIP model uses stacked prompts to tackle overfitting by forming semantically related categories through CSP and EFA modules, and further improves performance with the RPL module.", "result": "The proposed method achieves state-of-the-art results in anomaly detection and segmentation across seven datasets.", "conclusion": "StackCLIP enhances training stability and generalization for anomaly detection tasks, outperforming existing methods in zero-shot settings."}}
{"id": "2506.22938", "pdf": "https://arxiv.org/pdf/2506.22938", "abs": "https://arxiv.org/abs/2506.22938", "authors": ["Zaydon L. Ali", "Wassan Saad Abduljabbar Hayale", "Israa Ibraheem Al_Barazanchi", "Ravi Sekhar", "Pritesh Shah", "Sushma Parihar"], "title": "Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "With current advancement in hybermedia knowledges, the privacy of digital\ninformation has developed a critical problem. To overawed the susceptibilities\nof present security protocols, scholars tend to focus mainly on efforts on\nalternation of current protocols. Over past decade, various proposed encoding\nmodels have been shown insecurity, leading to main threats against significant\ndata. Utilizing the suitable encryption model is very vital means of guard\nagainst various such, but algorithm is selected based on the dependency of data\nwhich need to be secured. Moreover, testing potentiality of the security\nassessment one by one to identify the best choice can take a vital time for\nprocessing. For faster and precisive identification of assessment algorithm, we\nsuggest a security phase exposure model for cipher encryption technique by\ninvoking Support Vector Machine (SVM). In this work, we form a dataset using\nusual security components like contrast, homogeneity. To overcome the\nuncertainty in analysing the security and lack of ability of processing data to\na risk assessment mechanism. To overcome with such complications, this paper\nproposes an assessment model for security issues using fuzzy evidential\nreasoning (ER) approaches. Significantly, the model can be utilised to process\nand assemble risk assessment data on various aspects in systematic ways. To\nestimate the performance of our framework, we have various analyses like,\nrecall, F1 score and accuracy.", "AI": {"tldr": "The paper addresses issues in selecting encryption models and assessing digital information security by proposing a risk assessment model using SVM and fuzzy evidential reasoning.", "motivation": "The increasing problem of protecting sensitive digital information with advancements in hypermedia knowledge necessitates better methods for identifying suitable security protocols.", "method": "The authors propose a security phase exposure model using Support Vector Machine (SVM) and fuzzy evidential reasoning (ER) to enable systematic risk assessment.", "result": "The proposed model is analyzed using metrics such as recall, F1 score, and accuracy, demonstrating its effectiveness in faster and precise identification of security algorithms.", "conclusion": "The model provides a systematic means of assessing security algorithms and overcoming uncertainties in data processing and security, offering practical utility for systematic risk evaluations."}}
{"id": "2506.23580", "pdf": "https://arxiv.org/pdf/2506.23580", "abs": "https://arxiv.org/abs/2506.23580", "authors": ["Yawen Zou", "Guang Li", "Duo Su", "Zi Wang", "Jun Yu", "Chao Zhang"], "title": "Dataset Distillation via Vision-Language Category Prototype", "categories": ["cs.CV"], "comment": "accepted by ICCV2025", "summary": "Dataset distillation (DD) condenses large datasets into compact yet\ninformative substitutes, preserving performance comparable to the original\ndataset while reducing storage, transmission costs, and computational\nconsumption. However, previous DD methods mainly focus on distilling\ninformation from images, often overlooking the semantic information inherent in\nthe data. The disregard for context hinders the model's generalization ability,\nparticularly in tasks involving complex datasets, which may result in illogical\noutputs or the omission of critical objects. In this study, we integrate\nvision-language methods into DD by introducing text prototypes to distill\nlanguage information and collaboratively synthesize data with image prototypes,\nthereby enhancing dataset distillation performance. Notably, the text\nprototypes utilized in this study are derived from descriptive text information\ngenerated by an open-source large language model. This framework demonstrates\nbroad applicability across datasets without pre-existing text descriptions,\nexpanding the potential of dataset distillation beyond traditional image-based\napproaches. Compared to other methods, the proposed approach generates\nlogically coherent images containing target objects, achieving state-of-the-art\nvalidation performance and demonstrating robust generalization. Source code and\ngenerated data are available in\nhttps://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/", "AI": {"tldr": "This paper introduces text prototypes derived from a large language model to improve dataset distillation by integrating vision-language methods, resulting in logically coherent images and superior generalization.", "motivation": "Traditional dataset distillation methods overlook semantic language information, which limits their performance and ability to generalize in tasks involving complex datasets.", "method": "The authors propose incorporating text prototypes generated by an open-source large language model with image prototypes to distill both language and visual information collaboratively.", "result": "The approach produces logically coherent images that include target objects and achieves state-of-the-art validation performance, demonstrating enhanced generalization.", "conclusion": "Integrating vision-language methods into dataset distillation expands its applicability and improves generalization and coherence, providing significant advances in the field."}}
{"id": "2506.23581", "pdf": "https://arxiv.org/pdf/2506.23581", "abs": "https://arxiv.org/abs/2506.23581", "authors": ["Xiao Li", "Yiming Zhu", "Yifan Huang", "Wei Zhang", "Yingzhe He", "Jie Shi", "Xiaolin Hu"], "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICCV 2025", "summary": "Object detection plays a crucial role in many security-sensitive\napplications. However, several recent studies have shown that object detectors\ncan be easily fooled by physically realizable attacks, \\eg, adversarial patches\nand recent adversarial textures, which pose realistic and urgent threats.\nAdversarial Training (AT) has been recognized as the most effective defense\nagainst adversarial attacks. While AT has been extensively studied in the\n$l_\\infty$ attack settings on classification models, AT against physically\nrealizable attacks on object detectors has received limited exploration. Early\nattempts are only performed to defend against adversarial patches, leaving AT\nagainst a wider range of physically realizable attacks under-explored. In this\nwork, we consider defending against various physically realizable attacks with\na unified AT method. We propose PBCAT, a novel Patch-Based Composite\nAdversarial Training strategy. PBCAT optimizes the model by incorporating the\ncombination of small-area gradient-guided adversarial patches and imperceptible\nglobal adversarial perturbations covering the entire image. With these designs,\nPBCAT has the potential to defend against not only adversarial patches but also\nunseen physically realizable attacks such as adversarial textures. Extensive\nexperiments in multiple settings demonstrated that PBCAT significantly improved\nrobustness against various physically realizable attacks over state-of-the-art\ndefense methods. Notably, it improved the detection accuracy by 29.7\\% over\nprevious defense methods under one recent adversarial texture attack.", "AI": {"tldr": "The paper introduces PBCAT, an adversarial training method combining patch-based and global perturbations to improve object detection resilience against physically realizable adversarial attacks.", "motivation": "Recent studies show object detectors are vulnerable to physically realizable attacks, such as adversarial patches and textures, posing security risks. Existing defenses are limited in addressing the full range of such attacks.", "method": "The proposed PBCAT method integrates small-area gradient-guided adversarial patches and imperceptible global perturbations across the image into adversarial training.", "result": "Experiments show PBCAT boosts robustness to a variety of physically realizable attacks, achieving a 29.7% improvement in detection accuracy over previous methods against texture attacks.", "conclusion": "PBCAT is an effective defense strategy against diverse physically realizable attacks, enhancing the security of object detection systems."}}
{"id": "2506.23590", "pdf": "https://arxiv.org/pdf/2506.23590", "abs": "https://arxiv.org/abs/2506.23590", "authors": ["Qiming Li", "Zekai Ye", "Xiaocheng Feng", "Weihong Zhong", "Libo Qin", "Ruihan Chen", "Baohang Li", "Kui Jiang", "Yaowei Wang", "Ting Liu", "Bing Qin"], "title": "CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Although Large Vision-Language Models (LVLMs) have demonstrated powerful\ncapabilities in interpreting visual information, they frequently produce\ncontent that deviates from visual information, leading to object hallucination.\nTo tackle this, recent works mostly depend on expensive manual annotations and\ntraining cost, or significantly increase inference time. In this work, we\nobserve that LVLMs' attention to visual information is significantly stronger\nwhen answering caption queries compared to non-caption queries. Inspired by\nthis phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a\ntraining-free, plug-and-play hallucination mitigation method that leverages the\nattention activation pattern in response to caption queries to enhance LVLMs'\nvisual perception capability. Extensive experimental results across four\nbenchmarks covering both discriminative and generative tasks, demonstrate that\nCAI achieves state-of-the-art (SOTA) hallucination mitigating performance only\nwith minimal additional inference cost.", "AI": {"tldr": "The paper introduces Caption-sensitive Attention Intervention (CAI), a method for addressing object hallucination in Large Vision-Language Models without requiring additional training or significant inference costs.", "motivation": "The motivation is to address the issue of object hallucination in Large Vision-Language Models, where the generated content deviates from visual information.", "method": "The paper observes that LVLMs respond better to caption queries and proposes CAI, a training-free method that enhances visual perception by utilizing attention activation patterns triggered by caption queries.", "result": "CAI achieves state-of-the-art hallucination mitigation across four benchmarks, demonstrating effectiveness in both discriminative and generative tasks with minimal inference overhead.", "conclusion": "CAI provides a practical and efficient solution for improving LVLM performance, mitigating hallucination without relying on manual annotations or expensive training."}}
{"id": "2506.23605", "pdf": "https://arxiv.org/pdf/2506.23605", "abs": "https://arxiv.org/abs/2506.23605", "authors": ["Suyash Maniyar", "Vishvesh Trivedi", "Ajoy Mondal", "Anand Mishra", "C. V. Jawahar"], "title": "AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": "40 pages including supplementary, accepted at ICDAR 2025", "summary": "Lecture slide element detection and retrieval are key problems in slide\nunderstanding. Training effective models for these tasks often depends on\nextensive manual annotation. However, annotating large volumes of lecture\nslides for supervised training is labor intensive and requires domain\nexpertise. To address this, we propose a large language model (LLM)-guided\nsynthetic lecture slide generation pipeline, SynLecSlideGen, which produces\nhigh-quality, coherent and realistic slides. We also create an evaluation\nbenchmark, namely RealSlide by manually annotating 1,050 real lecture slides.\nTo assess the utility of our synthetic slides, we perform few-shot transfer\nlearning on real data using models pre-trained on them. Experimental results\nshow that few-shot transfer learning with pretraining on synthetic slides\nsignificantly improves performance compared to training only on real data. This\ndemonstrates that synthetic data can effectively compensate for limited labeled\nlecture slides. The code and resources of our work are publicly available on\nour project website: https://synslidegen.github.io/.", "AI": {"tldr": "The paper introduces SynLecSlideGen, a pipeline for generating high-quality synthetic lecture slides using large language models (LLMs), along with a benchmark dataset RealSlide. The study demonstrates that synthetic slides can enhance few-shot transfer learning performance for lecture slide tasks.", "motivation": "Training models for lecture slide detection and retrieval requires extensive manual annotations, which are labor-intensive and demand domain expertise. This paper aims to address this limitation by using synthetic data.", "method": "The authors propose SynLecSlideGen, an LLM-guided pipeline to produce synthetic lecture slides, and also introduce a benchmark dataset, RealSlide, containing annotations for 1,050 real slides.", "result": "The experimental results show that few-shot transfer learning on real lecture slides is significantly improved by pretraining models on synthetic slides, outperforming training exclusively on real data.", "conclusion": "Synthetic data generated by SynLecSlideGen can effectively complement limited labeled data, improving slide understanding tasks and reducing the need for extensive manual annotations."}}
{"id": "2506.23260", "pdf": "https://arxiv.org/pdf/2506.23260", "abs": "https://arxiv.org/abs/2506.23260", "authors": ["Mohamed Amine Ferrag", "Norbert Tihanyi", "Djallel Hamouda", "Leandros Maglaras", "Merouane Debbah"], "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "categories": ["cs.CR", "cs.AI"], "comment": "29 pages, 15 figures, 6 tables", "summary": "Autonomous AI agents powered by large language models (LLMs) with structured\nfunction-calling interfaces have dramatically expanded capabilities for\nreal-time data retrieval, complex computation, and multi-step orchestration.\nYet, the explosive proliferation of plugins, connectors, and inter-agent\nprotocols has outpaced discovery mechanisms and security practices, resulting\nin brittle integrations vulnerable to diverse threats. In this survey, we\nintroduce the first unified, end-to-end threat model for LLM-agent ecosystems,\nspanning host-to-tool and agent-to-agent communications, formalize adversary\ncapabilities and attacker objectives, and catalog over thirty attack\ntechniques. Specifically, we organized the threat model into four domains:\nInput Manipulation (e.g., prompt injections, long-context hijacks, multimodal\nadversarial inputs), Model Compromise (e.g., prompt- and parameter-level\nbackdoors, composite and encrypted multi-backdoors, poisoning strategies),\nSystem and Privacy Attacks (e.g., speculative side-channels, membership\ninference, retrieval poisoning, social-engineering simulations), and Protocol\nVulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent\nCommunication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent\n(A2A) protocol). For each category, we review representative scenarios, assess\nreal-world feasibility, and evaluate existing defenses. Building on our threat\ntaxonomy, we identify key open challenges and future research directions, such\nas securing MCP deployments through dynamic trust management and cryptographic\nprovenance tracking; designing and hardening Agentic Web Interfaces; and\nachieving resilience in multi-agent and federated environments. Our work\nprovides a comprehensive reference to guide the design of robust defense\nmechanisms and establish best practices for resilient LLM-agent workflows.", "AI": {"tldr": "This paper develops a unified threat model for ecosystems of LLM-driven autonomous AI agents, highlighting vulnerabilities and proposing future research directions for secure and robust workflows.", "motivation": "The integration of LLMs with structured functions has dramatically advanced AI agent capabilities. However, the rapid adoption of these technologies has created security vulnerabilities and a lack of cohesive discovery mechanisms.", "method": "The authors cataloged over thirty attack techniques and organized them into four domains (Input Manipulation, Model Compromise, System and Privacy Attacks, and Protocol Vulnerabilities). They assessed real-world scenarios and defenses for each threat.", "result": "A structured threat model was established, and representative scenarios were analyzed. Key open challenges and research directions were highlighted, aiming at securing LLM-agent communications.", "conclusion": "The paper provides a foundational reference for improving the robustness of LLM-agent ecosystems, offering insights into securing interactions and minimizing vulnerabilities in these systems."}}
{"id": "2506.23606", "pdf": "https://arxiv.org/pdf/2506.23606", "abs": "https://arxiv.org/abs/2506.23606", "authors": ["Zhengkang Xiang", "Zizhao Li", "Amir Khodabandeh", "Kourosh Khoshelham"], "title": "SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Lidar point cloud synthesis based on generative models offers a promising\nsolution to augment deep learning pipelines, particularly when real-world data\nis scarce or lacks diversity. By enabling flexible object manipulation, this\nsynthesis approach can significantly enrich training datasets and enhance\ndiscriminative models. However, existing methods focus on unconditional lidar\npoint cloud generation, overlooking their potential for real-world\napplications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar\nDiffusion Model that employs latent alignment to enable robust\nsemantic-to-lidar synthesis. By directly operating in the native lidar space\nand leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art\nperformance in generating high-fidelity lidar point clouds guided by semantic\nlabels. Moreover, we propose the first diffusion-based lidar translation\nframework based on SG-LDM, which enables cross-domain translation as a domain\nadaptation strategy to enhance downstream perception performance. Systematic\nexperiments demonstrate that SG-LDM significantly outperforms existing lidar\ndiffusion models and the proposed lidar translation framework further improves\ndata augmentation performance in the downstream lidar segmentation task.", "AI": {"tldr": "The paper introduces SG-LDM, a Semantic-Guided Lidar Diffusion Model, to synthesize lidar point clouds using semantic guidance, achieving superior performance in lidar data generation and downstream tasks.", "motivation": "The paper aims to address the limitations of existing methods that focus on unconditional lidar point cloud generation and lack applicability in real-world scenarios.", "method": "The proposed SG-LDM utilizes latent alignment and explicit semantic conditioning in the native lidar space, and introduces a novel diffusion-based lidar translation framework for domain adaptation.", "result": "SG-LDM achieves state-of-the-art results in generating lidar point clouds and enhances downstream perception performance, outperforming existing models.", "conclusion": "The study concludes that SG-LDM is effective for both data synthesis and cross-domain translation, making it beneficial for lidar segmentation tasks and augmenting deep learning workflows."}}
{"id": "2506.22971", "pdf": "https://arxiv.org/pdf/2506.22971", "abs": "https://arxiv.org/abs/2506.22971", "authors": ["Kesav Kazam Ramachandran Anantharaman", "Rahul Meshram"], "title": "Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY", "math.OC"], "comment": "6 pages, 2 figures", "summary": "This paper presents a two-timescale hierarchical decentralized architecture\nfor control of Cyber-Physical Systems. The architecture consists of $N$\nindependent sub-processes, a global controller, and $N$ local controllers, each\nformulated as a Markov Decision Process (MDP). The global controller, operating\nat a slower timescale optimizes the infinite-horizon discounted cumulative\nreward under budget constraints. For the local controllers, operating at a\nfaster timescale, we propose two different optimization frameworks, namely the\nCOpt and FOpt. In the COpt framework, the local controller also optimizes an\ninfinite-horizon MDP, while in the FOpt framework, the local controller\noptimizes a finite-horizon MDP. The FOpt framework mimics a federal structure,\nwhere the local controllers have more autonomy in their decision making. First,\nthe existence of stationary deterministic optimal policies for both these\nframeworks is established. Then, various relationships between the two\nframeworks are studied, including a bound on the difference between the two\noptimal value functions. Additionally, sufficiency conditions are provided such\nthat the two frameworks lead to the same optimal values.", "AI": {"tldr": "The paper introduces a hierarchical decentralized control architecture for Cyber-Physical Systems with global and local controllers based on Markov Decision Processes (MDPs). It explores two optimization frameworks for local controllers, compares their performance, and establishes optimal policy conditions.", "motivation": "To improve control strategies for Cyber-Physical Systems with decentralized architectures, considering both global constraints and local autonomy.", "method": "Proposes a two-timescale hierarchical setup with a global controller optimizing over infinite horizons and local controllers using two frameworks, COpt (infinite-horizon MDP) and FOpt (finite-horizon MDP). Analyses policies, value functions, and interrelationships between the frameworks.", "result": "Establishes the existence of optimal policies for both frameworks, provides bounds on value function differences, and identifies conditions under which the two frameworks achieve the same optimal values.", "conclusion": "The proposed architectures with two optimization frameworks offer a versatile control strategy, balancing global optimization and local autonomy, thus enhancing systematic decision-making in Cyber-Physical Systems."}}
{"id": "2506.23607", "pdf": "https://arxiv.org/pdf/2506.23607", "abs": "https://arxiv.org/abs/2506.23607", "authors": ["Shiqi Zhang", "Sha Zhang", "Jiajun Deng", "Yedong Shen", "Mingxiao MA", "Yanyong Zhang"], "title": "PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum", "categories": ["cs.CV"], "comment": null, "summary": "Existing open-vocabulary 3D semantic segmentation methods typically supervise\n3D segmentation models by merging text-aligned features (e.g., CLIP) extracted\nfrom multi-view images onto 3D points. However, such approaches treat\nmulti-view images merely as intermediaries for transferring open-vocabulary\ninformation, overlooking their rich semantic content and cross-view\ncorrespondences, which limits model effectiveness. To address this, we propose\nPGOV3D, a novel framework that introduces a Partial-to-Global curriculum for\nimproving open-vocabulary 3D semantic segmentation. The key innovation lies in\na two-stage training strategy. In the first stage, we pre-train the model on\npartial scenes that provide dense semantic information but relatively simple\ngeometry. These partial point clouds are derived from multi-view RGB-D inputs\nvia pixel-wise depth projection. To enable open-vocabulary learning, we\nleverage a multi-modal large language model (MLLM) and a 2D segmentation\nfoundation model to generate open-vocabulary labels for each viewpoint,\noffering rich and aligned supervision. An auxiliary inter-frame consistency\nmodule is introduced to enforce feature consistency across varying viewpoints\nand enhance spatial understanding. In the second stage, we fine-tune the model\non complete scene-level point clouds, which are sparser and structurally more\ncomplex. We aggregate the partial vocabularies associated with each scene and\ngenerate pseudo labels using the pre-trained model, effectively bridging the\nsemantic gap between dense partial observations and large-scale 3D\nenvironments. Extensive experiments on ScanNet, ScanNet200, and S3DIS\nbenchmarks demonstrate that PGOV3D achieves competitive performance in\nopen-vocabulary 3D semantic segmentation.", "AI": {"tldr": "The paper introduces PGOV3D, a framework for open-vocabulary 3D semantic segmentation that leverages a two-stage curriculum pre-training approach to improve accuracy.", "motivation": "Existing methods for open-vocabulary 3D segmentation rely heavily on transferring text-aligned features via multi-view images but miss out on the rich semantic data and cross-view correlations in the images.", "method": "PGOV3D uses a two-stage strategy: (1) pre-training on partial scenes using RGB-D inputs with open-vocabulary labels generated by multi-modal models, and (2) fine-tuning on complete 3D scenes with pseudo-labels aggregated from the partial observations.", "result": "The proposed method demonstrated competitive performance in open-vocabulary 3D segmentation benchmarks like ScanNet, ScanNet200, and S3DIS.", "conclusion": "By introducing the Partial-to-Global curriculum and leveraging rich semantic supervision, PGOV3D improves segmentation accuracy by scaling from simpler partial inputs to more complex 3D environments."}}
{"id": "2506.23611", "pdf": "https://arxiv.org/pdf/2506.23611", "abs": "https://arxiv.org/abs/2506.23611", "authors": ["Ziao Liu", "Zhenjia Li", "Yifeng Shi", "Xiangang Li"], "title": "AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance\nFields (NeRF), excelling in complex scene reconstruction and efficient\nrendering. However, it relies on high-quality point clouds from\nStructure-from-Motion (SfM), limiting its applicability. SfM also fails in\ntexture-deficient or constrained-view scenarios, causing severe degradation in\n3DGS reconstruction. To address this limitation, we propose AttentionGS, a\nnovel framework that eliminates the dependency on high-quality initial point\nclouds by leveraging structural attention for direct 3D reconstruction from\nrandomly initialization. In the early training stage, we introduce geometric\nattention to rapidly recover the global scene structure. As training\nprogresses, we incorporate texture attention to refine fine-grained details and\nenhance rendering quality. Furthermore, we employ opacity-weighted gradients to\nguide Gaussian densification, leading to improved surface reconstruction.\nExtensive experiments on multiple benchmark datasets demonstrate that\nAttentionGS significantly outperforms state-of-the-art methods, particularly in\nscenarios where point cloud initialization is unreliable. Our approach paves\nthe way for more robust and flexible 3D Gaussian Splatting in real-world\napplications.", "AI": {"tldr": "AttentionGS introduces structural attention for 3D Gaussian Splatting (3DGS), eliminating reliance on high-quality initial point clouds and improving 3D reconstruction and rendering.", "motivation": "Improve 3DGS's applicability by addressing its dependence on high-quality point clouds and overcoming limitations in scenarios like texture-deficient or constrained-view.", "method": "Uses geometric and texture attention during different training stages for structural recovery and detail refinement, alongside opacity-weighted gradients for Gaussian densification.", "result": "AttentionGS enhances reconstruction performance and rendering quality, surpassing state-of-the-art methods in benchmarks, especially with unreliable point cloud initialization.", "conclusion": "AttentionGS offers a robust and flexible approach to 3D Gaussian Splatting, enabling direct 3D reconstruction from random initialization in varied applications."}}
{"id": "2506.23010", "pdf": "https://arxiv.org/pdf/2506.23010", "abs": "https://arxiv.org/abs/2506.23010", "authors": ["Max Lovig", "Tianhao Wang", "Zhou Fan"], "title": "On Universality of Non-Separable Approximate Message Passing Algorithms", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "math.PR", "stat.TH"], "comment": null, "summary": "Mean-field characterizations of first-order iterative algorithms -- including\nApproximate Message Passing (AMP), stochastic and proximal gradient descent,\nand Langevin diffusions -- have enabled a precise understanding of learning\ndynamics in many statistical applications. For algorithms whose non-linearities\nhave a coordinate-separable form, it is known that such characterizations enjoy\na degree of universality with respect to the underlying data distribution.\nHowever, mean-field characterizations of non-separable algorithm dynamics have\nlargely remained restricted to i.i.d. Gaussian or rotationally-invariant data.\n  In this work, we initiate a study of universality for non-separable AMP\nalgorithms. We identify a general condition for AMP with polynomial\nnon-linearities, in terms of a Bounded Composition Property (BCP) for their\nrepresenting tensors, to admit a state evolution that holds universally for\nmatrices with non-Gaussian entries. We then formalize a condition of\nBCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal\nguarantee. We demonstrate that many common classes of non-separable\nnon-linearities are BCP-approximable, including local denoisers, spectral\ndenoisers for generic signals, and compositions of separable functions with\ngeneric linear maps, implying the universality of state evolution for AMP\nalgorithms employing these non-linearities.", "AI": {"tldr": "The paper explores universality in Approximate Message Passing (AMP) algorithms with non-separable nonlinearities for data beyond Gaussian assumptions, proposing conditions for universal state evolution.", "motivation": "Mean-field characterizations provide valuable insights into iterative algorithm dynamics; however, the universality of such characterization for non-separable algorithms has been limited to specific data types.", "method": "The study introduces conditions like the Bounded Composition Property (BCP) and BCP-approximability, enabling universal state evolution for matrices with non-Gaussian entries in AMP algorithms.", "result": "The paper proves that several important classes of non-separable nonlinearities meet the BCP-approximability condition, ensuring universality for AMP algorithms with such nonlinearities.", "conclusion": "The findings broaden the scope of universal state evolution characterizations to non-separable AMP algorithms, advancing understanding in statistical learning and iterative methods."}}
{"id": "2506.23618", "pdf": "https://arxiv.org/pdf/2506.23618", "abs": "https://arxiv.org/abs/2506.23618", "authors": ["Zhongdao Wang", "Guodongfang Zhao", "Jingjing Ren", "Bailan Feng", "Shifeng Zhang", "Wenbo Li"], "title": "TurboVSR: Fantastic Video Upscalers and Where to Find Them", "categories": ["cs.CV"], "comment": "ICCV, 2025", "summary": "Diffusion-based generative models have demonstrated exceptional promise in\nthe video super-resolution (VSR) task, achieving a substantial advancement in\ndetail generation relative to prior methods. However, these approaches face\nsignificant computational efficiency challenges. For instance, current\ntechniques may require tens of minutes to super-resolve a mere 2-second, 1080p\nvideo. In this paper, we present TurboVSR, an ultra-efficient diffusion-based\nvideo super-resolution model. Our core design comprises three key aspects: (1)\nWe employ an autoencoder with a high compression ratio of 32$\\times$32$\\times$8\nto reduce the number of tokens. (2) Highly compressed latents pose substantial\nchallenges for training. We introduce factorized conditioning to mitigate the\nlearning complexity: we first learn to super-resolve the initial frame;\nsubsequently, we condition the super-resolution of the remaining frames on the\nhigh-resolution initial frame and the low-resolution subsequent frames. (3) We\nconvert the pre-trained diffusion model to a shortcut model to enable fewer\nsampling steps, further accelerating inference. As a result, TurboVSR performs\non par with state-of-the-art VSR methods, while being 100+ times faster, taking\nonly 7 seconds to process a 2-second long 1080p video. TurboVSR also supports\nimage resolution by considering image as a one-frame video. Our efficient\ndesign makes SR beyond 1080p possible, results on 4K (3648$\\times$2048) image\nSR show surprising fine details.", "AI": {"tldr": "This paper introduces TurboVSR, an ultra-efficient video super-resolution model that significantly reduces processing time while maintaining high performance, achieving speeds 100+ times faster than current methods.", "motivation": "While diffusion-based generative models excel in video super-resolution tasks, their computational efficiency remains a barrier, requiring extensive time even for short videos.", "method": "The authors developed TurboVSR utilizing three main components: (1) a highly compressive autoencoder; (2) factorized conditioning for gradual super-resolution; (3) shortcut modeling in the diffusion process to reduce sampling steps.", "result": "TurboVSR achieved performance comparable to state-of-the-art VSR techniques, processing videos 100+ times faster and supporting resolution beyond 1080p, including 4K image super-resolution.", "conclusion": "The paper demonstrates that TurboVSR effectively mitigates computational inefficiency in video super-resolution, offering a practical solution with potential for high-resolution applications."}}
{"id": "2506.23623", "pdf": "https://arxiv.org/pdf/2506.23623", "abs": "https://arxiv.org/abs/2506.23623", "authors": ["Shaofei Huang", "Rui Ling", "Tianrui Hui", "Hongyu Li", "Xu Zhou", "Shifeng Zhang", "Si Liu", "Richang Hong", "Meng Wang"], "title": "Revisiting Audio-Visual Segmentation with Vision-Centric Transformer", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025; Code: https://github.com/spyflying/VCT_AVS;\n  Models: https://huggingface.co/nowherespyfly/VCT_AVS", "summary": "Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in\nvideo frames based on the associated audio signal. Prevailing AVS methods\ntypically adopt an audio-centric Transformer architecture, where object queries\nare derived from audio features. However, audio-centric Transformers suffer\nfrom two limitations: perception ambiguity caused by the mixed nature of audio,\nand weakened dense prediction ability due to visual detail loss. To address\nthese limitations, we propose a new Vision-Centric Transformer (VCT) framework\nthat leverages vision-derived queries to iteratively fetch corresponding audio\nand visual information, enabling queries to better distinguish between\ndifferent sounding objects from mixed audio and accurately delineate their\ncontours. Additionally, we also introduce a Prototype Prompted Query Generation\n(PPQG) module within our VCT framework to generate vision-derived queries that\nare both semantically aware and visually rich through audio prototype prompting\nand pixel context grouping, facilitating audio-visual information aggregation.\nExtensive experiments demonstrate that our VCT framework achieves new\nstate-of-the-art performances on three subsets of the AVSBench dataset. The\ncode is available at https://github.com/spyflying/VCT_AVS.", "AI": {"tldr": "This paper proposes a Vision-Centric Transformer (VCT) for Audio-Visual Segmentation (AVS), addressing issues in prior audio-centric methods and achieving state-of-the-art results.", "motivation": "Existing AVS methods use an audio-centric Transformer architecture and face challenges like ambiguity in audio perception and loss of visual detail.", "method": "The authors propose a Vision-Centric Transformer (VCT) that uses vision-derived queries to fetch audio and visual information iteratively. They also introduce a Prototype Prompted Query Generation (PPQG) module for generating semantically and visually rich queries.", "result": "The VCT framework sets new state-of-the-art performances on three AVSBench dataset subsets.", "conclusion": "The VCT framework effectively addresses limitations in AVS by enhancing query generation and increasing segmentation accuracy with a vision-centric approach."}}
{"id": "2506.23627", "pdf": "https://arxiv.org/pdf/2506.23627", "abs": "https://arxiv.org/abs/2506.23627", "authors": ["Roham Maiti", "Debasmita Bhoumik"], "title": "Brain Tumor Detection through Thermal Imaging and MobileNET", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Brain plays a crucial role in regulating body functions and cognitive\nprocesses, with brain tumors posing significant risks to human health. Precise\nand prompt detection is a key factor in proper treatment and better patient\noutcomes. Traditional methods for detecting brain tumors, that include\nbiopsies, MRI, and CT scans often face challenges due to their high costs and\nthe need for specialized medical expertise. Recent developments in machine\nlearning (ML) and deep learning (DL) has exhibited strong capabilities in\nautomating the identification and categorization of brain tumors from medical\nimages, especially MRI scans. However, these classical ML models have\nlimitations, such as high computational demands, the need for large datasets,\nand long training times, which hinder their accessibility and efficiency. Our\nresearch uses MobileNET model for efficient detection of these tumors. The\nnovelty of this project lies in building an accurate tumor detection model\nwhich use less computing re-sources and runs in less time followed by efficient\ndecision making through the use of image processing technique for accurate\nresults. The suggested method attained an average accuracy of 98.5%.", "AI": {"tldr": "The paper proposes an efficient brain tumor detection model using the MobileNET framework, achieving a high accuracy of 98.5% with minimal computing resources.", "motivation": "To overcome challenges in traditional and classical ML methods for brain tumor detection, such as high costs, computational demands, large datasets, and reliance on specialized expertise.", "method": "The study employs the MobileNET model combined with image processing techniques to detect and classify brain tumors efficiently and accurately with reduced computation time and resource usage.", "result": "The model achieved an impressive average accuracy of 98.5%, demonstrating high effectiveness in brain tumor detection.", "conclusion": "The research showcases the potential of the MobileNET model as a viable solution for brain tumor detection, offering reliability, efficiency, and accessibility while using fewer resources and processing time."}}
{"id": "2506.23296", "pdf": "https://arxiv.org/pdf/2506.23296", "abs": "https://arxiv.org/abs/2506.23296", "authors": ["Naoto Kiribuchi", "Kengo Zenitani", "Takayuki Semitsu"], "title": "Securing AI Systems: A Guide to Known Attacks and Impacts", "categories": ["cs.CR", "cs.AI"], "comment": "34 pages, 16 figures", "summary": "Embedded into information systems, artificial intelligence (AI) faces\nsecurity threats that exploit AI-specific vulnerabilities. This paper provides\nan accessible overview of adversarial attacks unique to predictive and\ngenerative AI systems. We identify eleven major attack types and explicitly\nlink attack techniques to their impacts -- including information leakage,\nsystem compromise, and resource exhaustion -- mapped to the confidentiality,\nintegrity, and availability (CIA) security triad. We aim to equip researchers,\ndevelopers, security practitioners, and policymakers, even those without\nspecialized AI security expertise, with foundational knowledge to recognize\nAI-specific risks and implement effective defenses, thereby enhancing the\noverall security posture of AI systems.", "AI": {"tldr": "This paper provides an overview of 11 major adversarial attack types targeting predictive and generative AI systems, linking them to impacts and the CIA security triad.", "motivation": "The need to address increasing AI-specific security threats and provide foundational knowledge for mitigating such risks.", "method": "Identifying major attack types, mapping them to their impacts, and contextualizing them within the CIA (confidentiality, integrity, availability) security framework.", "result": "Created a structured understanding of AI-specific adversarial threats and their implications for system security.", "conclusion": "Equips stakeholders with the knowledge needed to identify and defend against AI-specific vulnerabilities, contributing to improved AI system security."}}
{"id": "2506.23630", "pdf": "https://arxiv.org/pdf/2506.23630", "abs": "https://arxiv.org/abs/2506.23630", "authors": ["Lorenzo Olearo", "Giorgio Longari", "Alessandro Raganato", "Rafael Pe\u00f1aloza", "Simone Melzi"], "title": "Blending Concepts with Text-to-Image Diffusion Models", "categories": ["cs.CV"], "comment": "Currently under review", "summary": "Diffusion models have dramatically advanced text-to-image generation in\nrecent years, translating abstract concepts into high-fidelity images with\nremarkable ease. In this work, we examine whether they can also blend distinct\nconcepts, ranging from concrete objects to intangible ideas, into coherent new\nvisual entities under a zero-shot framework. Specifically, concept blending\nmerges the key attributes of multiple concepts (expressed as textual prompts)\ninto a single, novel image that captures the essence of each concept. We\ninvestigate four blending methods, each exploiting different aspects of the\ndiffusion pipeline (e.g., prompt scheduling, embedding interpolation, or\nlayer-wise conditioning). Through systematic experimentation across diverse\nconcept categories, such as merging concrete concepts, synthesizing compound\nwords, transferring artistic styles, and blending architectural landmarks, we\nshow that modern diffusion models indeed exhibit creative blending capabilities\nwithout further training or fine-tuning. Our extensive user study, involving\n100 participants, reveals that no single approach dominates in all scenarios:\neach blending technique excels under certain conditions, with factors like\nprompt ordering, conceptual distance, and random seed affecting the outcome.\nThese findings highlight the remarkable compositional potential of diffusion\nmodels while exposing their sensitivity to seemingly minor input variations.", "AI": {"tldr": "Diffusion models can creatively merge distinct visual concepts into single images zero-shot, but outcomes depend on input details.", "motivation": "To explore whether diffusion models can blend distinct textual concepts into new coherent visual entities without additional training.", "method": "The paper tested four blending methods that leverage different diffusion pipeline aspects to merge concepts, evaluated across diverse categories.", "result": "The methods demonstrated creative blending capabilities; no single method excelled universally, with results influenced by factors like input order and conceptual distance.", "conclusion": "Diffusion models showcase significant compositional abilities, though the blending results depend on nuanced input variations."}}
{"id": "2506.23314", "pdf": "https://arxiv.org/pdf/2506.23314", "abs": "https://arxiv.org/abs/2506.23314", "authors": ["Joner Assolin", "Gabriel Canto", "Diego Kreutz", "Eduardo Feitosa", "Hendrio Bragan\u00e7a", "Angelo Nogueira", "Vanderson Rocha"], "title": "Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance", "categories": ["cs.CR", "cs.AI", "68T99", "I.2"], "comment": "18 pages, 10 figures, 7 tabelas, paper submitted to JBCS", "summary": "Malware detection in Android systems requires both cybersecurity expertise\nand machine learning (ML) techniques. Automated Machine Learning (AutoML) has\nemerged as an approach to simplify ML development by reducing the need for\nspecialized knowledge. However, current AutoML solutions typically operate as\nblack-box systems with limited transparency, interpretability, and experiment\ntraceability. To address these limitations, we present MH-AutoML, a\ndomain-specific framework for Android malware detection. MH-AutoML automates\nthe entire ML pipeline, including data preprocessing, feature engineering,\nalgorithm selection, and hyperparameter tuning. The framework incorporates\ncapabilities for interpretability, debugging, and experiment tracking that are\noften missing in general-purpose solutions. In this study, we compare MH-AutoML\nagainst seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT,\nHyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML\nachieves better recall rates while providing more transparency and control. The\nframework maintains computational efficiency comparable to other solutions,\nmaking it suitable for cybersecurity applications where both performance and\nexplainability matter.", "AI": {"tldr": "MH-AutoML is a framework for Android malware detection automating the ML process while enhancing transparency and interpretability, outperforming existing solutions.", "motivation": "Current AutoML systems are limited by black-box nature, lack of interpretability, and traceability in cybersecurity contexts.", "method": "Created MH-AutoML, a domain-specific tool integrating interpretability, debugging, and experiment tracking within complete ML automation for Android malware detection.", "result": "MH-AutoML displayed superior recall rates compared to seven leading AutoML frameworks while maintaining computational efficiency.", "conclusion": "MH-AutoML balances performance, explainability, and efficiency, making it ideal for Android security applications."}}
{"id": "2506.23639", "pdf": "https://arxiv.org/pdf/2506.23639", "abs": "https://arxiv.org/abs/2506.23639", "authors": ["Wanpeng Zhang", "Yicheng Feng", "Hao Luo", "Yijiang Li", "Zihao Yue", "Sipeng Zheng", "Zongqing Lu"], "title": "Unified Multimodal Understanding via Byte-Pair Visual Encoding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have made significant progress in\nvision-language understanding, yet effectively aligning different modalities\nremains a fundamental challenge. We present a framework that unifies multimodal\nunderstanding by applying byte-pair encoding to visual tokens. Unlike\nconventional approaches that rely on modality-specific encoders, our method\ndirectly incorporates structural information into visual tokens, mirroring\nsuccessful tokenization strategies in text-only language models. We introduce a\npriority-guided encoding scheme that considers both frequency and spatial\nconsistency, coupled with a multi-stage training procedure based on\ncurriculum-driven data composition. These enhancements enable the transformer\nmodel to better capture cross-modal relationships and reason with visual\ninformation. Comprehensive experiments demonstrate improved performance across\ndiverse vision-language tasks. By bridging the gap between visual and textual\nrepresentations, our approach contributes to the advancement of more capable\nand efficient multimodal foundation models.", "AI": {"tldr": "The paper proposes a novel method for multimodal large language models (MLLMs), efficiently aligning vision and language modalities using byte-pair encoding for visual tokens.", "motivation": "The motivation is to address the challenge of effectively aligning different modalities in multimodal models for better vision-language understanding.", "method": "The approach involves applying byte-pair encoding to visual tokens, priority-guided encoding considering frequency and spatial consistency, and a multi-stage curriculum-driven training scheme.", "result": "Improved performance is demonstrated across diverse vision-language tasks, enhancing cross-modal relationships and reasoning capabilities.", "conclusion": "The study advances multimodal foundation models by bridging visual and textual representation gaps, promoting more capable and efficient systems."}}
{"id": "2506.23090", "pdf": "https://arxiv.org/pdf/2506.23090", "abs": "https://arxiv.org/abs/2506.23090", "authors": ["Langming Liu", "Wanyu Wang", "Chi Zhang", "Bo Li", "Hongzhi Yin", "Xuetao Wei", "Wenbo Su", "Bo Zheng", "Xiangyu Zhao"], "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "KDD 2025", "summary": "Online advertising in recommendation platforms has gained significant\nattention, with a predominant focus on channel recommendation and budget\nallocation strategies. However, current offline reinforcement learning (RL)\nmethods face substantial challenges when applied to sparse advertising\nscenarios, primarily due to severe overestimation, distributional shifts, and\noverlooking budget constraints. To address these issues, we propose MTORL, a\nnovel multi-task offline RL model that targets two key objectives. First, we\nestablish a Markov Decision Process (MDP) framework specific to the nuances of\nadvertising. Then, we develop a causal state encoder to capture dynamic user\ninterests and temporal dependencies, facilitating offline RL through\nconditional sequence modeling. Causal attention mechanisms are introduced to\nenhance user sequence representations by identifying correlations among causal\nstates. We employ multi-task learning to decode actions and rewards,\nsimultaneously addressing channel recommendation and budget allocation.\nNotably, our framework includes an automated system for integrating these tasks\ninto online advertising. Extensive experiments on offline and online\nenvironments demonstrate MTORL's superiority over state-of-the-art methods.", "AI": {"tldr": "The paper introduces MTORL, a multi-task offline RL model to improve online advertising by solving challenges like overestimation and distributional shifts.", "motivation": "Current offline reinforcement learning methods struggle with challenges such as sparse advertising scenarios, overestimation, and budget constraints.", "method": "The authors propose a Markov Decision Process framework and develop a causal state encoder with causal attention mechanisms. They employ multi-task learning for both channel recommendation and budget allocation.", "result": "MTORL outperforms state-of-the-art methods in experiments conducted on both offline and online environments.", "conclusion": "MTORL effectively addresses key challenges in online advertising, providing a robust model for channel recommendation and budget allocation in sparse scenarios."}}
{"id": "2506.23641", "pdf": "https://arxiv.org/pdf/2506.23641", "abs": "https://arxiv.org/abs/2506.23641", "authors": ["Peng Huang", "Junhu Fu", "Bowen Guo", "Zeju Li", "Yuanyuan Wang", "Yi Guo"], "title": "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As the appearance of medical images is influenced by multiple underlying\nfactors, generative models require rich attribute information beyond labels to\nproduce realistic and diverse images. For instance, generating an image of skin\nlesion with specific patterns demands descriptions that go beyond diagnosis,\nsuch as shape, size, texture, and color. However, such detailed descriptions\nare not always accessible. To address this, we explore a framework, termed\nVisual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from\npre-trained Multi-modal Large Language Models (MLLMs) to improve the quality\nand diversity of medical image generation. First, to derive descriptions from\nMLLMs without hallucination, we design a series of prompts following\nChain-of-Thoughts for common medical imaging tasks, including dermatologic,\ncolorectal, and chest X-ray images. Generated descriptions are utilized during\ntraining and stored across different categories. During testing, descriptions\nare randomly retrieved from the corresponding category for inference. Moreover,\nto make the generator robust to unseen combination of descriptions at the test\ntime, we propose a Prototype Condition Mechanism that restricts test embeddings\nto be similar to those from training. Experiments on three common types of\nmedical imaging across four datasets verify the effectiveness of VAP-Diffusion.", "AI": {"tldr": "This paper proposes VAP-Diffusion, a framework that utilizes multi-modal large language models and a prototype condition mechanism to enhance the quality and diversity of medical image generation with limited attribute descriptions.", "motivation": "Producing realistic and diverse medical images requires detailed attribute information (e.g., shape, size, texture) beyond basic labels, but such detailed descriptions are often unavailable.", "method": "The authors use external knowledge from pre-trained Multi-modal Large Language Models (MLLMs) to derive attribute descriptions via custom Chain-of-Thought prompts. These descriptions are incorporated during training, stored by category, and retrieved at testing. A Prototype Condition Mechanism ensures the model handles unseen combinations of descriptions for robustness.", "result": "Experiments conducted on common medical imaging datasets, including dermatologic and chest X-ray images, show that the proposed approach improves image quality and diversity in generation tasks.", "conclusion": "The VAP-Diffusion framework successfully leverages external knowledge from MLLMs and integrates mechanisms to generate high-quality and realistic medical images even with limited attribute information."}}
{"id": "2506.23325", "pdf": "https://arxiv.org/pdf/2506.23325", "abs": "https://arxiv.org/abs/2506.23325", "authors": ["Yitian Gong", "Luozhijie Jin", "Ruifan Deng", "Dong Zhang", "Xin Zhang", "Qinyuan Cheng", "Zhaoye Fei", "Shimin Li", "Xipeng Qiu"], "title": "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Speech codecs serve as bridges between speech signals and large language\nmodels. An ideal codec for speech language models should not only preserve\nacoustic information but also capture rich semantic information. However,\nexisting speech codecs struggle to balance high-quality audio reconstruction\nwith ease of modeling by language models. In this study, we analyze the\nlimitations of previous codecs in balancing semantic richness and acoustic\nfidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict\nbetween semantic and acoustic capabilities through multi-stage, multi-task\nlearning. Experimental results demonstrate that XY-Tokenizer achieves\nperformance in both semantic and acoustic tasks comparable to that of\nstate-of-the-art codecs operating at similar bitrates, even though those\nexisting codecs typically excel in only one aspect. Specifically, XY-Tokenizer\nachieves strong text alignment, surpassing distillation-based semantic modeling\nmethods such as SpeechTokenizer and Mimi, while maintaining a speaker\nsimilarity score of 0.83 between reconstructed and original audio. The\nreconstruction performance of XY-Tokenizer is comparable to that of BigCodec,\nthe current state-of-the-art among acoustic-only codecs, which achieves a\nspeaker similarity score of 0.84 at a similar bitrate. Code and models are\navailable at https://github.com/gyt1145028706/XY-Tokenizer.", "AI": {"tldr": "The paper proposes XY-Tokenizer, a novel speech codec that balances semantic richness and acoustic fidelity, addressing limitations in existing codecs.", "motivation": "Existing speech codecs struggle to simultaneously preserve rich semantic information and high-quality audio reconstruction when interfacing speech signals with large language models.", "method": "XY-Tokenizer leverages multi-stage, multi-task learning to address the trade-offs between semantic and acoustic capabilities in speech language modeling.", "result": "XY-Tokenizer achieves comparable performance to state-of-the-art codecs, excelling in both semantic tasks and acoustic fidelity, with a speaker similarity score of 0.83.", "conclusion": "XY-Tokenizer successfully balances semantic and acoustic functions, demonstrating its potential as an improved codec for speech language models, and its implementation is accessible online."}}
{"id": "2506.23170", "pdf": "https://arxiv.org/pdf/2506.23170", "abs": "https://arxiv.org/abs/2506.23170", "authors": ["Jaime Hieu Do", "Trung-Hoang Le", "Hady W. Lauw"], "title": "Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "In the online digital realm, recommendation systems are ubiquitous and play a\ncrucial role in enhancing user experience. These systems leverage user\npreferences to provide personalized recommendations, thereby helping users\nnavigate through the paradox of choice. This work focuses on personalized\nsequential recommendation, where the system considers not only a user's\nimmediate, evolving session context, but also their cumulative historical\nbehavior to provide highly relevant and timely recommendations. Through an\nempirical study conducted on diverse real-world datasets, we have observed and\nquantified the existence and impact of both short-term (immediate and\ntransient) and long-term (enduring and stable) preferences on users' historical\ninteractions. Building on these insights, we propose a framework that combines\nshort- and long-term preferences to enhance recommendation performance, namely\nCompositions of Variant Experts (CoVE). This novel framework dynamically\nintegrates short- and long-term preferences through the use of different\nspecialized recommendation models (i.e., experts). Extensive experiments\nshowcase the effectiveness of the proposed methods and ablation studies further\ninvestigate the impact of variant expert types.", "AI": {"tldr": "The paper introduces Compositions of Variant Experts (CoVE), a framework for combining short- and long-term user preferences to enhance personalized sequential recommendations.", "motivation": "The study aims to address the challenge of leveraging both short-term session context and long-term cumulative user behavior to improve the relevance and timeliness of recommendations.", "method": "The proposed CoVE framework dynamically integrates specialized recommendation models (experts) for both short-term and long-term preferences. Empirical studies on real-world datasets were conducted.", "result": "Experiments illustrate the effectiveness of CoVE in improving recommendation performance compared to traditional systems across diverse datasets. Ablation studies confirm the contributions of different expert types.", "conclusion": "The research demonstrates that combining short- and long-term preferences through the CoVE framework significantly enhances recommendation system performance, offering a promising direction for future applications."}}
{"id": "2506.23648", "pdf": "https://arxiv.org/pdf/2506.23648", "abs": "https://arxiv.org/abs/2506.23648", "authors": ["Zhe Liu", "Yuhao Huang", "Lian Liu", "Chengrui Zhang", "Haotian Lin", "Tong Han", "Zhiyuan Zhu", "Yanlin Chen", "Yuerui Chen", "Dong Ni", "Zhongshan Gou", "Xin Yang"], "title": "MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis", "categories": ["cs.CV"], "comment": "10 pages, 5 figures, accepted by MICCAI 2025", "summary": "Color Doppler echocardiography is a crucial tool for diagnosing mitral\nregurgitation (MR). Recent studies have explored intelligent methods for MR\ndiagnosis to minimize user dependence and improve accuracy. However, these\napproaches often fail to align with clinical workflow and may lead to\nsuboptimal accuracy and interpretability. In this study, we introduce an\nautomated MR diagnosis model (MReg) developed on the 4-chamber cardiac color\nDoppler echocardiography video (A4C-CDV). It follows comprehensive feature\nmining strategies to detect MR and assess its severity, considering clinical\nrealities. Our contribution is threefold. First, we formulate the MR diagnosis\nas a regression task to capture the continuity and ordinal relationships\nbetween categories. Second, we design a feature selection and amplification\nmechanism to imitate the sonographer's diagnostic logic for accurate MR\ngrading. Third, inspired by the Mixture-of-Experts concept, we introduce a\nfeature summary module to extract the category-level features, enhancing the\nrepresentational capacity for more accurate grading. We trained and evaluated\nour proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases\nwith three graded regurgitation labels. Compared to other weakly supervised\nvideo anomaly detection and supervised classification methods, MReg\ndemonstrated superior performance in MR diagnosis. Our code is available at:\nhttps://github.com/cskdstz/MReg.", "AI": {"tldr": "The paper introduces an automated model (MReg) for diagnosing mitral regurgitation (MR) using echocardiography videos, which outperforms other methods in accuracy.", "motivation": "Address the user-dependence, accuracy, and alignment issues in current intelligent methods for diagnosing mitral regurgitation.", "method": "Developed MReg, an automated MR diagnosis model, using a regression task, feature amplification, and category-level feature extraction inspired by Mixture-of-Experts.", "result": "MReg showed superior performance for MR diagnosis compared to weakly supervised and classification methods on a dataset of 1868 cases.", "conclusion": "The proposed MReg model effectively captures diagnostic features for accurate and interpretable MR grading, demonstrating clinical applicability."}}
{"id": "2506.23334", "pdf": "https://arxiv.org/pdf/2506.23334", "abs": "https://arxiv.org/abs/2506.23334", "authors": ["Hongyi Pan", "Ziliang Hong", "Gorkem Durak", "Ziyue Xu", "Ulas Bagci"], "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) has emerged as a promising paradigm for\ncollaboratively training deep learning models across institutions without\nexchanging sensitive medical data. However, its effectiveness is often hindered\nby limited data availability and non-independent, identically distributed data\nacross participating clients, which can degrade model performance and\ngeneralization. To address these challenges, we propose a generative AI based\ndata augmentation framework that integrates synthetic image sharing into the\nfederated training process for breast cancer diagnosis via ultrasound images.\nSpecifically, we train two simple class-specific Deep Convolutional Generative\nAdversarial Networks: one for benign and one for malignant lesions. We then\nsimulate a realistic FL setting using three publicly available breast\nultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are\nadopted as baseline FL algorithms. Experimental results show that incorporating\na suitable number of synthetic images improved the average AUC from 0.9206 to\n0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that\nexcessive use of synthetic data reduced performance, underscoring the\nimportance of maintaining a balanced ratio of real and synthetic samples. Our\nfindings highlight the potential of generative AI based data augmentation to\nenhance FL results in the breast ultrasound image classification task.", "AI": {"tldr": "The paper introduces a generative AI-based data augmentation framework to improve federated learning (FL) for breast cancer diagnosis using ultrasound images, addressing challenges of limited and non-IID data.", "motivation": "To enhance the performance and generalization of federated learning in medical domains where data privacy restricts data exchanges and datasets are often limited and non-IID.", "method": "The study proposes using two class-specific Deep Convolutional Generative Adversarial Networks (DCGANs) for creating synthetic images and integrates them into FL frameworks (FedAvg and FedProx). Federated experiments used three public breast ultrasound datasets: BUSI, BUS-BRA, and UDIAT.", "result": "Incorporating synthetic data improved the average AUC from 0.9206 to 0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. However, excessive synthetic data reduced performance.", "conclusion": "Generative AI-based data augmentation can improve federated learning performance in breast ultrasound image classification but requires careful balancing of real and synthetic data."}}
{"id": "2506.23657", "pdf": "https://arxiv.org/pdf/2506.23657", "abs": "https://arxiv.org/abs/2506.23657", "authors": ["Connor Daly", "Elettra Marconi", "Marco Riva", "Jinendra Ekanayake", "Daniel S. Elson", "Ferdinando Rodriguez y Baena"], "title": "Towards Markerless Intraoperative Tracking of Deformable Spine Tissue", "categories": ["cs.CV"], "comment": "Preprint of paper, submitted", "summary": "Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is\na promising method with high translational potential. Unlike bone-mounted\ntracking devices, markerless tracking can reduce operating time and complexity.\nHowever, its use has been limited to cadaveric studies. This paper introduces\nthe first real-world clinical RGB-D dataset for spine surgery and develops\nSpineAlign, a system for capturing deformation between preoperative and\nintraoperative spine states. We also present an intraoperative segmentation\nnetwork trained on this data and introduce CorrespondNet, a multi-task\nframework for predicting key regions for registration in both intraoperative\nand preoperative scenes.", "AI": {"tldr": "This paper introduces a clinical RGB-D dataset for spine surgery and develops SpineAlign for analyzing spine deformation between pre- and intraoperative stages, alongside a segmentation network and CorrespondNet framework.", "motivation": "To improve efficiency and reduce complexity in orthopedic tissue tracking during surgery, as current marker-based technologies are time-consuming and invasive.", "method": "Development of SpineAlign, a system leveraging RGB-D imaging for deformation tracking, creation of a clinical dataset, and designing a segmentation network and multi-task framework CorrespondNet.", "result": "Successfully constructed the first real-world RGB-D dataset for spine surgery and demonstrated the utility of SpineAlign, the segmentation network, and CorrespondNet for key region prediction and spine state registration.", "conclusion": "The research advances markerless tracking for orthopedic applications, making it feasible and clinically applicable for spine surgeries, potentially reducing operational complexities."}}
{"id": "2506.23663", "pdf": "https://arxiv.org/pdf/2506.23663", "abs": "https://arxiv.org/abs/2506.23663", "authors": ["Mario Koddenbrock", "Rudolf Hoffmann", "David Brodmann", "Erik Rodner"], "title": "On the Domain Robustness of Contrastive Vision-Language Models", "categories": ["cs.CV", "cs.LG", "I.4"], "comment": "Deepbench is available at https://github.com/ml-lab-htw/deepbench", "summary": "In real-world vision-language applications, practitioners increasingly rely\non large, pretrained foundation models rather than custom-built solutions,\ndespite limited transparency regarding their training data and processes. While\nthese models achieve impressive performance on general benchmarks, their\neffectiveness can decline notably under specialized domain shifts, such as\nunique imaging conditions or environmental variations. In this work, we\nintroduce Deepbench, a framework designed to assess domain-specific robustness\nof vision-language models (VLMs). Deepbench leverages a large language model\n(LLM) to generate realistic, context-aware image corruptions tailored to\nspecific deployment domains without requiring labeled data. We evaluate a range\nof contrastive vision-language architectures and architectural variants across\nsix real-world domains and observe substantial variability in robustness,\nhighlighting the need for targeted, domain-aware evaluation. Deepbench is\nreleased as open-source software to support further research into domain-aware\nrobustness assessment.", "AI": {"tldr": "Deepbench introduces a framework to evaluate the domain-specific robustness of vision-language models, highlighting their variability and utilizing LLMs for generating realistic image corruptions.", "motivation": "To address the challenge of diminishing model effectiveness in specialized domain shifts, where vision-language models perform poorly under unique conditions.", "method": "The framework Deepbench uses large language models to create realistic, context-aware image corruptions specific to deployment domains, without relying on labeled data.", "result": "Deepbench identifies substantial variability in robustness across vision-language models and architectures in six real-world domains.", "conclusion": "Deepbench emphasizes the importance of domain-aware evaluation for vision-language models and is provided as open-source software for further research."}}
{"id": "2506.23674", "pdf": "https://arxiv.org/pdf/2506.23674", "abs": "https://arxiv.org/abs/2506.23674", "authors": ["Dongyue Wu", "Zilin Guo", "Jialong Zuo", "Nong Sang", "Changxin Gao"], "title": "Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration", "categories": ["cs.CV"], "comment": "Accepted by ICCV2025", "summary": "The ever-growing size of training datasets enhances the generalization\ncapability of modern machine learning models but also incurs exorbitant\ncomputational costs. Existing data pruning approaches aim to accelerate\ntraining by removing those less important samples. However, they often rely on\ngradients or proxy models, leading to prohibitive additional costs of gradient\nback-propagation and proxy model training. In this paper, we propose Partial\nForward Blocking (PFB), a novel framework for lossless training acceleration.\nThe efficiency of PFB stems from its unique adaptive pruning pipeline: sample\nimportance is assessed based on features extracted from the shallow layers of\nthe target model. Less important samples are then pruned, allowing only the\nretained ones to proceed with the subsequent forward pass and loss\nback-propagation. This mechanism significantly reduces the computational\noverhead of deep-layer forward passes and back-propagation for pruned samples,\nwhile also eliminating the need for auxiliary backward computations and proxy\nmodel training. Moreover, PFB introduces probability density as an indicator of\nsample importance. Combined with an adaptive distribution estimation module,\nour method dynamically prioritizes relatively rare samples, aligning with the\nconstantly evolving training state. Extensive experiments demonstrate the\nsignificant superiority of PFB in performance and speed. On ImageNet, PFB\nachieves a 0.5% accuracy improvement and 33% training time reduction with 40%\ndata pruned.", "AI": {"tldr": "This paper proposes Partial Forward Blocking (PFB), a framework to accelerate training in machine learning by adaptively pruning unimportant samples during forward passes, resulting in faster training without loss of accuracy.", "motivation": "The growing size of training datasets improves model generalization but escalates computational costs. Existing data pruning techniques aim to address this but require additional resources, creating inefficiencies.", "method": "PFB assesses sample importance based on shallow-layer features of a model and prunes less important ones. The retained samples proceed to deeper layers, reducing computational demands while eliminating the need for gradients or proxy models. A probability density indicator and adaptive distribution estimation module prioritize rare samples dynamically.", "result": "PFB achieved a 0.5% accuracy improvement and a 33% reduction in training time by pruning 40% of data on the ImageNet dataset.", "conclusion": "PFB presents a resource-efficient method for accelerating training while improving performance, demonstrating the potential for practical applications in handling large datasets."}}
{"id": "2506.23675", "pdf": "https://arxiv.org/pdf/2506.23675", "abs": "https://arxiv.org/abs/2506.23675", "authors": ["Patrick Glandorf", "Bodo Rosenhahn"], "title": "Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation", "categories": ["cs.CV"], "comment": "ICCV'25 Workshops", "summary": "Vision Transformer have set new benchmarks in several tasks, but these models\ncome with the lack of high computational costs which makes them impractical for\nresource limited hardware. Network pruning reduces the computational complexity\nby removing less important operations while maintaining performance. However,\npruning a model on an unseen data domain, leads to a misevaluation of weight\nsignificance, resulting in suboptimal resource assignment. In this work, we\nfind that task-sensitive layers initially fail to improve the feature\nrepresentation on downstream tasks, leading to performance loss for early\npruning decisions. To address this problem, we introduce Pruning by Block\nBenefit (P3B), a pruning method that utilizes the relative contribution on\nblock level to globally assign parameter resources. P3B identifies low-impact\ncomponents to reduce parameter allocation while preserving critical ones.\nClassical pruning mask optimization struggles to reactivate zero-mask-elements.\nIn contrast, P3B sets a layerwise keep ratio based on global performance\nmetrics, ensuring the reactivation of late-converging blocks. We show in\nextensive experiments that P3B is a state of the art pruning method with most\nnoticeable gains in transfer learning tasks. Notably, P3B is able to conserve\nhigh performance, even in high sparsity regimes of 70% parameter reduction\nwhile only losing 0.64% in accuracy.", "AI": {"tldr": "The paper proposes a new pruning method, P3B, that reduces Vision Transformer model parameters by up to 70% with minimal accuracy loss.", "motivation": "Vision Transformers are computationally expensive, making them unsuitable for resource-constrained hardware. Existing network pruning approaches underperform when applied in new data domains due to improper weight significance evaluation.", "method": "The authors introduce P3B (Pruning by Block Benefit), a pruning method that calculates contribution at the block level for globally balanced parameter allocation. It ensures reactivation of late-converging blocks based on layer-specific keep ratios rather than freezing zero-mask elements.", "result": "P3B achieves state-of-the-art pruning performance, maintaining high accuracy even in scenarios with 70% parameter reductions, only experiencing a 0.64% accuracy drop.", "conclusion": "The P3B method effectively reduces computational costs of Vision Transformers while preserving performance, making it suitable for transfer learning and resource-limited applications."}}
{"id": "2506.23676", "pdf": "https://arxiv.org/pdf/2506.23676", "abs": "https://arxiv.org/abs/2506.23676", "authors": ["Gaozheng Pei", "Ke Ma", "Dongpeng Zhang", "Chengzhi Sun", "Qianqian Xu", "Qingming Huang"], "title": "A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "Due to their powerful image generation capabilities, diffusion-based\nadversarial example generation methods through image editing are rapidly\ngaining popularity. However, due to reliance on the discriminative capability\nof the diffusion model, these diffusion-based methods often struggle to\ngeneralize beyond conventional image classification tasks, such as in Deepfake\ndetection. Moreover, traditional strategies for enhancing adversarial example\ntransferability are challenging to adapt to these methods. To address these\nchallenges, we propose a unified framework that seamlessly incorporates\ntraditional transferability enhancement strategies into diffusion model-based\nadversarial example generation via image editing, enabling their application\nacross a wider range of downstream tasks. Our method won first place in the\n\"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of\nAI-Generated Media\" competition at ACM MM25, which validates the effectiveness\nof our approach.", "AI": {"tldr": "Diffusion-based adversarial example generation methods are widely used for image editing but struggle with generalization beyond image classification tasks. This paper introduces a unified framework to enhance transferability in such methods, achieving competitive results.", "motivation": "Addressing the limitations of diffusion-based adversarial methods that struggle with generalizing to non-classification tasks, such as Deepfake detection.", "method": "Proposes a unified framework that integrates traditional transferability enhancement strategies into diffusion-based adversarial example generation for image editing.", "result": "The proposed method demonstrated effectiveness by winning first place in an adversarial attack competition related to Deepfake detection.", "conclusion": "The framework successfully extends the utility of diffusion-based adversarial example generation, proving its effectiveness across broader tasks including Deepfake detection."}}
{"id": "2506.23311", "pdf": "https://arxiv.org/pdf/2506.23311", "abs": "https://arxiv.org/abs/2506.23311", "authors": ["Perla Mayo", "Carolin M. Pirkl", "Alin Achim", "Bjoern Menze", "Mohammad Golbabaee"], "title": "Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": "11 pages, 1 figure, 1 algorithm, 3 tables. Accepted to MICCAI 2025.\n  This is a version prior peer-review", "summary": "We introduce MRF-DiPh, a novel physics informed denoising diffusion approach\nfor multiparametric tissue mapping from highly accelerated, transient-state\nquantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our\nmethod is derived from a proximal splitting formulation, incorporating a\npretrained denoising diffusion model as an effective image prior to regularize\nthe MRF inverse problem. Further, during reconstruction it simultaneously\nenforces two key physical constraints: (1) k-space measurement consistency and\n(2) adherence to the Bloch response model. Numerical experiments on in-vivo\nbrain scans data show that MRF-DiPh outperforms deep learning and compressed\nsensing MRF baselines, providing more accurate parameter maps while better\npreserving measurement fidelity and physical model consistency-critical for\nsolving reliably inverse problems in medical imaging.", "AI": {"tldr": "MRF-DiPh is a novel physics-informed denoising diffusion method for enhanced tissue mapping in MRI, leveraging advanced reconstruction techniques.", "motivation": "Address challenges in MRI tissue mapping like accuracy and constraints adherence in accelerated acquisitions.", "method": "Combines proximal splitting formulation with pretrained denoising diffusion models while enforcing physical constraints during reconstruction.", "result": "Demonstrates higher accuracy and fidelity in brain scan parameter maps compared to deep learning and compressed sensing baselines.", "conclusion": "MRF-DiPh effectively solves MRI inverse problems with improved accuracy and maintains physical consistency, aiding medical imaging reliability."}}
{"id": "2506.23690", "pdf": "https://arxiv.org/pdf/2506.23690", "abs": "https://arxiv.org/abs/2506.23690", "authors": ["Shuai Tan", "Biao Gong", "Yujie Wei", "Shiwei Zhang", "Zhuoxin Liu", "Dandan Zheng", "Jingdong Chen", "Yan Wang", "Hao Ouyang", "Kecheng Zheng", "Yujun Shen"], "title": "SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation", "categories": ["cs.CV"], "comment": "Project page: https://lucaria-academy.github.io/SynMotion/", "summary": "Diffusion-based video motion customization facilitates the acquisition of\nhuman motion representations from a few video samples, while achieving\narbitrary subjects transfer through precise textual conditioning. Existing\napproaches often rely on semantic-level alignment, expecting the model to learn\nnew motion concepts and combine them with other entities (e.g., ''cats'' or\n''dogs'') to produce visually appealing results. However, video data involve\ncomplex spatio-temporal patterns, and focusing solely on semantics cause the\nmodel to overlook the visual complexity of motion. Conversely, tuning only the\nvisual representation leads to semantic confusion in representing the intended\naction. To address these limitations, we propose SynMotion, a new\nmotion-customized video generation model that jointly leverages semantic\nguidance and visual adaptation. At the semantic level, we introduce the\ndual-embedding semantic comprehension mechanism which disentangles subject and\nmotion representations, allowing the model to learn customized motion features\nwhile preserving its generative capabilities for diverse subjects. At the\nvisual level, we integrate parameter-efficient motion adapters into a\npre-trained video generation model to enhance motion fidelity and temporal\ncoherence. Furthermore, we introduce a new embedding-specific training strategy\nwhich \\textbf{alternately optimizes} subject and motion embeddings, supported\nby the manually constructed Subject Prior Video (SPV) training dataset. This\nstrategy promotes motion specificity while preserving generalization across\ndiverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark\nwith diverse motion patterns. Experimental results across both T2V and I2V\nsettings demonstrate that \\method outperforms existing baselines. Project page:\nhttps://lucaria-academy.github.io/SynMotion/", "AI": {"tldr": "SynMotion proposes a novel video motion-generation model combining semantic guidance and visual adaptation to better capture spatio-temporal patterns in video motion.", "motivation": "Existing methods for video motion customization fall short in capturing the complex interplay between semantic-level alignment and visual complexity of motion, leading to either semantic confusion or losing motion fidelity.", "method": "The SynMotion framework uses a dual-embedding mechanism to separate subject and motion representations combined with motion adapters for visual enhancement. It also leverages an embedding-specific training strategy with the SPV dataset to improve motion specificity and generalization.", "result": "SynMotion achieved superior performance over existing baselines across T2V (Text-to-Video) and I2V (Image-to-Video) generation scenarios, validated with the custom MotionBench benchmark.", "conclusion": "Jointly optimizing semantic and visual components using SynMotion leads to enhanced motion fidelity, temporal coherence, and better adaptability for diverse subjects in video generation."}}
{"id": "2506.23705", "pdf": "https://arxiv.org/pdf/2506.23705", "abs": "https://arxiv.org/abs/2506.23705", "authors": ["Smriti Joshi", "Richard Osuala", "Lidia Garrucho", "Kaisar Kushibar", "Dimitri Kessler", "Oliver Diaz", "Karim Lekadir"], "title": "Single Image Test-Time Adaptation via Multi-View Co-Training", "categories": ["cs.CV"], "comment": "MICCAI 2025", "summary": "Test-time adaptation enables a trained model to adjust to a new domain during\ninference, making it particularly valuable in clinical settings where such\non-the-fly adaptation is required. However, existing techniques depend on large\ntarget domain datasets, which are often impractical and unavailable in medical\nscenarios that demand per-patient, real-time inference. Moreover, current\nmethods commonly focus on two-dimensional images, failing to leverage the\nvolumetric richness of medical imaging data. Bridging this gap, we propose a\nPatch-Based Multi-View Co-Training method for Single Image Test-Time\nadaptation. Our method enforces feature and prediction consistency through\nuncertainty-guided self-training, enabling effective volumetric segmentation in\nthe target domain with only a single test-time image. Validated on three\npublicly available breast magnetic resonance imaging datasets for tumor\nsegmentation, our method achieves performance close to the upper bound\nsupervised benchmark while also outperforming all existing state-of-the-art\nmethods, on average by a Dice Similarity Coefficient of 3.75%. We publicly\nshare our accessible codebase, readily integrable with the popular nnUNet\nframework, at https://github.com/smriti-joshi/muvi.git.", "AI": {"tldr": "This study introduces a patch-based multi-view co-training method enabling single-image test-time adaptation for medical image segmentation with limited data.", "motivation": "To address challenges in medical image test-time adaptation where current methods require large datasets and mostly focus on 2D images, neglecting 3D volumetric data.", "method": "Developed a patch-based multi-view co-training approach using uncertainty-guided self-training for spatial consistency to perform effective volumetric segmentation using a single test-time image.", "result": "Achieved performance comparable to the supervised benchmark and outperformed state-of-the-art methods by an average Dice Similarity Coefficient of 3.75%, validated on breast MRI datasets for tumor segmentation.", "conclusion": "This method demonstrates the efficacy of single-image test-time adaptation in medical imaging, bridging key gaps and providing an accessible solution integrated with nnUNet."}}
{"id": "2506.23319", "pdf": "https://arxiv.org/pdf/2506.23319", "abs": "https://arxiv.org/abs/2506.23319", "authors": ["Norman Knyazev", "Harrie Oosterhuis"], "title": "Learning to Rank with Variable Result Presentation Lengths", "categories": ["cs.IR", "cs.LG"], "comment": "SIGIR 2025", "summary": "Learning to Rank (LTR) methods generally assume that each document in a top-K\nranking is presented in an equal format. However, previous work has shown that\nusers' perceptions of relevance can be changed by varying presentations, i.e.,\nallocating more vertical space to some documents to provide additional textual\nor image information. Furthermore, presentation length can also redirect\nattention, as users are more likely to notice longer presentations when\nscrolling through results. Deciding on the document presentation lengths in a\nfixed vertical space ranking is an important problem that has not been\naddressed by existing LTR methods.\n  We address this gap by introducing the variable presentation length ranking\ntask, where simultaneously the ordering of documents and their presentation\nlength is decided. Despite being a generalization of standard ranking, we show\nthat this setting brings significant new challenges: Firstly, the probability\nranking principle no longer applies to this setting, and secondly, the problem\ncannot be divided into separate ordering and length selection tasks.\n  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient\nestimation methods for the joint optimization of document ordering and lengths.\nOur semi-synthetic experiments show that VLPL can effectively balance the\nexpected exposure and attractiveness of all documents, achieving the best\nperformance across different ranking settings. Furthermore, we observe that\neven simple length-aware methods can achieve significant performance\nimprovements over fixed-length models. Altogether, our theoretical and\nempirical results highlight the importance and difficulties of combining\ndocument presentation with LTR.", "AI": {"tldr": "This paper proposes a new ranking strategy considering document presentation lengths to optimize user engagement and relevance perception.", "motivation": "Current Learning to Rank (LTR) methods fail to account for how varying document presentation lengths can influence user attention and relevance perception.", "method": "The paper introduces VLPL, a Plackett-Luce-based list-wise optimization method, to jointly determine both the order and presentation length of documents.", "result": "Semi-synthetic experiments reveal that VLPL effectively balances exposure and attractiveness, outperforming fixed-length and simpler length-aware methods.", "conclusion": "Integrating document presentation length in LTR shows significant advantages, illustrating challenges and opportunities for improving ranking systems."}}
{"id": "2506.23711", "pdf": "https://arxiv.org/pdf/2506.23711", "abs": "https://arxiv.org/abs/2506.23711", "authors": ["Haoyang Chen", "Dongfang Sun", "Caoyuan Ma", "Shiqin Wang", "Kewei Zhang", "Zheng Wang", "Zhixiang Wang"], "title": "Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "We propose Subjective Camera, a human-as-imaging-device paradigm that\nreconstructs real-world scenes from mental impressions through synergistic use\nof verbal descriptions and progressive rough sketches. This approach overcomes\ndual limitations of language ambiguity and sketch abstraction by treating the\nuser's drawing sequence as priors, effectively translating subjective\nperceptual expectations into photorealistic images.\n  Existing approaches face three fundamental barriers: (1) user-specific\nsubjective input biases, (2) huge modality gap between planar sketch and 3D\npriors in diffusion, and (3) sketch quality-sensitive performance degradation.\nCurrent solutions either demand resource-intensive model adaptation or impose\nimpractical requirements on sketch precision.\n  Our framework addresses these challenges through concept-sequential\ngeneration. (1) We establish robust appearance priors through text-reward\noptimization, and then implement sequence-aware disentangled generation that\nprocesses concepts in sketching order; these steps accommodate user-specific\nsubjective expectation in a train-free way. (2) We employ latent optimization\nthat effectively bridges the modality gap between planar sketches and 3D priors\nin diffusion. (3) Our hierarchical reward-guided framework enables the use of\nrough sketches without demanding artistic expertise. Comprehensive evaluation\nacross diverse datasets demonstrates that our approach achieves\nstate-of-the-art performance in maintaining both semantic and spatial\ncoherence.", "AI": {"tldr": "The paper introduces 'Subjective Camera,' a method to reconstruct photorealistic images from mental impressions using verbal descriptions and sequential sketch input.", "motivation": "The motivation is to overcome the limitations of existing methods which face challenges like user-specific input biases, the large gap between sketches and 3D priors, and performance sensitivity to sketch quality.", "method": "The proposed method uses text-reward optimization, sequence-aware disentangled generation, and latent optimization to process subjective sketches and descriptions while avoiding resource-heavy model adaptations.", "result": "The results showcase state-of-the-art performance in preserving semantic and spatial coherence across diverse datasets, even with rough sketch inputs.", "conclusion": "The framework effectively integrates verbal and sketch inputs to bridge the gap between subjective expectations and photorealistic outputs, requiring no specialized artistic expertise."}}
{"id": "2506.23724", "pdf": "https://arxiv.org/pdf/2506.23724", "abs": "https://arxiv.org/abs/2506.23724", "authors": ["Chang'an Yi", "Xiaohui Deng", "Guohao Chen", "Yan Zhou", "Qinghua Lu", "Shuaicheng Niu"], "title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 5 figures", "summary": "Test-time Adaptation (TTA) adapts a given model to testing domain data with\npotential domain shifts through online unsupervised learning, yielding\nimpressive performance. However, to date, existing TTA methods primarily focus\non single-model adaptation. In this work, we investigate an intriguing\nquestion: how does cross-model knowledge influence the TTA process? Our\nfindings reveal that, in TTA's unsupervised online setting, each model can\nprovide complementary, confident knowledge to the others, even when there are\nsubstantial differences in model size. For instance, a smaller model like\nMobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base\n(86.6M parameters). In light of this, we propose COCA, a Cross-Model\nCo-Learning framework for TTA, which mainly consists of two main strategies. 1)\nCo-adaptation adaptively integrates complementary knowledge from other models\nthroughout the TTA process, reducing individual model biases. 2)\nSelf-adaptation enhances each model's unique strengths via unsupervised\nlearning, enabling diverse adaptation to the target domain. Extensive\nexperiments show that COCA, which can also serve as a plug-and-play module,\nsignificantly boosts existing SOTAs, on models with various sizes--including\nResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,\nwith Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy\non ImageNet-C from 51.7% to 64.5%. The code is publicly available at\nhttps://github.com/ycarobot/COCA.", "AI": {"tldr": "The paper proposes COCA, a framework leveraging cross-model co-learning to enhance Test-Time Adaptation (TTA) by integrating complementary knowledge from multiple models.", "motivation": "Existing TTA methods focus on single-model adaptation, limiting potential performance boosts from inter-model knowledge sharing.", "method": "COCA includes two main strategies: co-adaptation to share complementary knowledge among models and self-adaptation to strengthen each model's unique capabilities during TTA.", "result": "COCA significantly improves adaptation accuracy across various model sizes, achieving, for instance, a jump from 51.7% to 64.5% in ViT-Base's accuracy on ImageNet-C with guidance from MobileViT.", "conclusion": "Cross-model learning enhances domain adaptation in TTA, with COCA seamlessly boosting performance across diverse model architectures as a plug-and-play module."}}
{"id": "2506.23371", "pdf": "https://arxiv.org/pdf/2506.23371", "abs": "https://arxiv.org/abs/2506.23371", "authors": ["Frank Cwitkowitz", "Zhiyao Duan"], "title": "Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised Multi-Pitch Estimation", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted to ISMIR 2025", "summary": "Multi-Pitch Estimation (MPE) continues to be a sought after capability of\nMusic Information Retrieval (MIR) systems, and is critical for many\napplications and downstream tasks involving pitch, including music\ntranscription. However, existing methods are largely based on supervised\nlearning, and there are significant challenges in collecting annotated data for\nthe task. Recently, self-supervised techniques exploiting intrinsic properties\nof pitch and harmonic signals have shown promise for both monophonic and\npolyphonic pitch estimation, but these still remain inferior to supervised\nmethods. In this work, we extend the classic supervised MPE paradigm by\nincorporating several self-supervised objectives based on pitch-invariant and\npitch-equivariant properties. This joint training results in a substantial\nimprovement under closed training conditions, which naturally suggests that\napplying the same objectives to a broader collection of data will yield further\nimprovements. However, in doing so we uncover a phenomenon whereby our model\nsimultaneously overfits to the supervised data while degenerating on data used\nfor self-supervision only. We demonstrate and investigate this and offer our\ninsights on the underlying problem.", "AI": {"tldr": "This paper explores enhancing supervised multi-pitch estimation by incorporating self-supervised objectives, leading to improved performance under specific conditions, but also reveals issues with overfitting.", "motivation": "The motivation is to address limitations in Multi-Pitch Estimation (MPE) posed by supervised learning, which requires annotated data that is challenging to collect, and to leverage self-supervised techniques for improved performance.", "method": "The authors propose combining supervised learning methods for MPE with self-supervised objectives that exploit pitch-invariant and pitch-equivariant properties in a joint training framework.", "result": "The joint training approach improves performance under closed training conditions but uncovers overfitting issues when incorporating broader data for self-supervision.", "conclusion": "While joint supervised and self-supervised training yields promising results, challenges such as overfitting to supervised data and degrading performance on self-supervised data need further investigation."}}
{"id": "2506.23729", "pdf": "https://arxiv.org/pdf/2506.23729", "abs": "https://arxiv.org/abs/2506.23729", "authors": ["Guiyu Zhang", "Chen Shi", "Zijian Jiang", "Xunzhi Xiang", "Jingjing Qian", "Shaoshuai Shi", "Li Jiang"], "title": "Proteus-ID: ID-Consistent and Motion-Coherent Video Customization", "categories": ["cs.CV"], "comment": "Preprint. Work in progress", "summary": "Video identity customization seeks to synthesize realistic, temporally\ncoherent videos of a specific subject, given a single reference image and a\ntext prompt. This task presents two core challenges: (1) maintaining identity\nconsistency while aligning with the described appearance and actions, and (2)\ngenerating natural, fluid motion without unrealistic stiffness. To address\nthese challenges, we introduce Proteus-ID, a novel diffusion-based framework\nfor identity-consistent and motion-coherent video customization. First, we\npropose a Multimodal Identity Fusion (MIF) module that unifies visual and\ntextual cues into a joint identity representation using a Q-Former, providing\ncoherent guidance to the diffusion model and eliminating modality imbalance.\nSecond, we present a Time-Aware Identity Injection (TAII) mechanism that\ndynamically modulates identity conditioning across denoising steps, improving\nfine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a\nself-supervised strategy that reweights the training loss based on\noptical-flow-derived motion heatmaps, enhancing motion realism without\nrequiring additional inputs. To support this task, we construct Proteus-Bench,\na high-quality dataset comprising 200K curated clips for training and 150\nindividuals from diverse professions and ethnicities for evaluation. Extensive\nexperiments demonstrate that Proteus-ID outperforms prior methods in identity\npreservation, text alignment, and motion quality, establishing a new benchmark\nfor video identity customization. Codes and data are publicly available at\nhttps://grenoble-zhang.github.io/Proteus-ID/.", "AI": {"tldr": "This paper introduces Proteus-ID, a framework addressing video identity customization utilizing diffusion methods, excelling in identity consistency and motion realism.", "motivation": "The study aims to improve video identity customization, overcoming issues of identity consistency and motion fluidity in personalized video generation.", "method": "Three key innovations: Multimodal Identity Fusion (MIF) module, Time-Aware Identity Injection (TAII) mechanism, and Adaptive Motion Learning (AML) strategy within a diffusion-based framework.", "result": "Proteus-ID demonstrates superior performance in maintaining identity accuracy, aligning with text prompts, and producing fluid motions, supported by a new benchmark dataset.", "conclusion": "Proteus-ID establishes a new standard in video identity customization through its robust methodological contributions, with publicly available resources for further research."}}
{"id": "2506.23751", "pdf": "https://arxiv.org/pdf/2506.23751", "abs": "https://arxiv.org/abs/2506.23751", "authors": ["Annika M\u00fctze", "Sadia Ilyas", "Christian D\u00f6rpelkus", "Matthias Rottmann"], "title": "Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary object detectors such as Grounding DINO are trained on vast\nand diverse data, achieving remarkable performance on challenging datasets. Due\nto that, it is unclear where to find their limitations, which is of major\nconcern when using in safety-critical applications. Real-world data does not\nprovide sufficient control, required for a rigorous evaluation of model\ngeneralization. In contrast, synthetically generated data allows to\nsystematically explore the boundaries of model competence/generalization. In\nthis work, we address two research questions: 1) Can we challenge\nopen-vocabulary object detectors with generated image content? 2) Can we find\nsystematic failure modes of those models? To address these questions, we design\ntwo automated pipelines using stable diffusion to inpaint unusual objects with\nhigh diversity in semantics, by sampling multiple substantives from WordNet and\nChatGPT. On the synthetically generated data, we evaluate and compare multiple\nopen-vocabulary object detectors as well as a classical object detector. The\nsynthetic data is derived from two real-world datasets, namely LostAndFound, a\nchallenging out-of-distribution (OOD) detection benchmark, and the NuImages\ndataset. Our results indicate that inpainting can challenge open-vocabulary\nobject detectors in terms of overlooking objects. Additionally, we find a\nstrong dependence of open-vocabulary models on object location, rather than on\nobject semantics. This provides a systematic approach to challenge\nopen-vocabulary models and gives valuable insights on how data could be\nacquired to effectively improve these models.", "AI": {"tldr": "The study analyzes open-vocabulary object detectors' limitations by evaluating them on synthetically generated datasets. It identifies their dependencies on object location over semantics.", "motivation": "To uncover the limitations and systematic failure modes of open-vocabulary object detectors, especially in safety-critical applications, using synthetically generated image data.", "method": "Two automated pipelines are created using Stable Diffusion to inpaint diverse, unusual objects, incorporating semantics sampled from WordNet and ChatGPT. These synthetic datasets are used to evaluate and compare open-vocabulary and classical object detectors.", "result": "Open-vocabulary detectors are found to rely heavily on object location, often overlooking objects, despite high semantic diversity in the synthetic data. These models show limitations when systematically challenged.", "conclusion": "Synthetic data generation can systematically expose weaknesses in open-vocabulary models, particularly their bias towards object location over semantics. This approach offers valuable guidance for improving these models through better data acquisition strategies."}}
{"id": "2506.23783", "pdf": "https://arxiv.org/pdf/2506.23783", "abs": "https://arxiv.org/abs/2506.23783", "authors": ["Shiao Wang", "Ju Huang", "Qingchuan Ma", "Jinfeng Gao", "Chunyi Xu", "Xiao Wang", "Lan Chen", "Bo Jiang"], "title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Journal extension of Mamba-FETrack which was published on Pattern\n  Recognition and Computer Vision (PRCV) 2024", "summary": "Combining traditional RGB cameras with bio-inspired event cameras for robust\nobject tracking has garnered increasing attention in recent years. However,\nmost existing multimodal tracking algorithms depend heavily on high-complexity\nVision Transformer architectures for feature extraction and fusion across\nmodalities. This not only leads to substantial computational overhead but also\nlimits the effectiveness of cross-modal interactions. In this paper, we propose\nan efficient RGB-Event object tracking framework based on the linear-complexity\nVision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a\nlightweight Prompt Generator that utilizes embedded features from each\nmodality, together with a shared prompt pool, to dynamically generate\nmodality-specific learnable prompt vectors. These prompts, along with the\nmodality-specific embedded features, are then fed into a Vision Mamba-based\nFEMamba backbone, which facilitates prompt-guided feature extraction,\ncross-modal interaction, and fusion in a unified manner. Finally, the fused\nrepresentations are passed to the tracking head for accurate target\nlocalization. Extensive experimental evaluations on multiple RGB-Event tracking\nbenchmarks, including short-term COESOT dataset and long-term datasets, i.e.,\nFE108 and FELT V2, demonstrate the superior performance and efficiency of the\nproposed tracking framework. The source code and pre-trained models will be\nreleased on https://github.com/Event-AHU/Mamba_FETrack", "AI": {"tldr": "This paper introduces Mamba-FETrack V2, a lightweight RGB-Event object tracking framework that replaces high-complexity Vision Transformers with the efficient Vision Mamba network for feature extraction and fusion.", "motivation": "Existing multimodal tracking algorithms rely on computationally intensive Vision Transformers, leading to high complexity and limiting cross-modal interactions.", "method": "The authors propose a Prompt Generator to create learnable modality-specific prompts and use the Vision Mamba network for feature extraction, cross-modal interaction, and fusion. The outputs are used for accurate target localization.", "result": "Experimental evaluations on RGB-Event tracking benchmarks show that the proposed framework outperforms existing solutions in both efficiency and accuracy.", "conclusion": "Mamba-FETrack V2 offers a superior, resource-efficient alternative for multimodal object tracking, integrating features dynamically with lightweight architecture. Source code and pre-trained models will be provided publicly."}}
{"id": "2506.23437", "pdf": "https://arxiv.org/pdf/2506.23437", "abs": "https://arxiv.org/abs/2506.23437", "authors": ["Stefano Giacomelli", "Marco Giordano", "Claudia Rinaldi", "Fabio Graziosi"], "title": "From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T07", "E.1; H.1; I.2; I.5; J.2; K.4; C.4"], "comment": "pre-print (submitted to the IEEE/ACM Transactions on Audio, Speech,\n  and Language Processing)", "summary": "Accurate recognition of Emergency Vehicle (EV) sirens is critical for the\nintegration of intelligent transportation systems, smart city monitoring\nsystems, and autonomous driving technologies. Modern automatic solutions are\nlimited by the lack of large scale, curated datasets and by the computational\ndemands of state of the art sound event detection models. This work introduces\nE2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight\nConvolutional Neural Network architecture derived from the PANNs framework,\nspecifically optimized for binary EV siren detection. Leveraging our dedicated\nsubset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across\nmultiple reference datasets and test its viability on embedded hardware. The\nexperimental campaign includes ablation studies, cross-domain benchmarking, and\nreal-time inference deployment on edge device. Interpretability analyses\nexploiting Guided Backpropagation and ScoreCAM algorithms provide insights into\nthe model internal representations and validate its ability to capture distinct\nspectrotemporal patterns associated with different types of EV sirens. Real\ntime performance is assessed through frame wise and event based detection\nmetrics, as well as a detailed analysis of false positive activations. Results\ndemonstrate that E2PANNs establish a new state of the art in this research\ndomain, with high computational efficiency, and suitability for edge-based\naudio monitoring and safety-critical applications.", "AI": {"tldr": "The paper introduces E2PANNs, a lightweight neural network optimized for emergency vehicle siren detection, achieving state-of-the-art performance while being computationally efficient and suitable for embedded hardware.", "motivation": "The motivation lies in addressing the limitations of current emergency vehicle (EV) siren recognition systems, such as the absence of large-scale curated datasets and high computational requirements of existing models.", "method": "The authors propose E2PANNs, a lightweight neural network derived from the PANNs framework, specifically fine-tuned using a dedicated AudioSet EV dataset and evaluated on multiple reference datasets. The model was tested with ablation studies, cross-domain benchmarking, and real-time deployment on edge hardware.", "result": "The results demonstrate that E2PANNs achieve state-of-the-art performance in EV siren detection, with high computational efficiency and real-time viability on embedded devices.", "conclusion": "E2PANNs provide an effective solution for binary EV siren detection with strong performance, low computational costs, and applicability for safety-critical smart city and autonomous driving systems."}}
{"id": "2506.23785", "pdf": "https://arxiv.org/pdf/2506.23785", "abs": "https://arxiv.org/abs/2506.23785", "authors": ["Yongjian Wu", "Yang Zhou", "Jiya Saiyin", "Bingzheng Wei", "Yan Xu"], "title": "Visual Textualization for Image Prompted Object Detection", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "We propose VisTex-OVLM, a novel image prompted object detection method that\nintroduces visual textualization -- a process that projects a few visual\nexemplars into the text feature space to enhance Object-level Vision-Language\nModels' (OVLMs) capability in detecting rare categories that are difficult to\ndescribe textually and nearly absent from their pre-training data, while\npreserving their pre-trained object-text alignment. Specifically, VisTex-OVLM\nleverages multi-scale textualizing blocks and a multi-stage fusion strategy to\nintegrate visual information from visual exemplars, generating textualized\nvisual tokens that effectively guide OVLMs alongside text prompts. Unlike\nprevious methods, our method maintains the original architecture of OVLM,\nmaintaining its generalization capabilities while enhancing performance in\nfew-shot settings. VisTex-OVLM demonstrates superior performance across\nopen-set datasets which have minimal overlap with OVLM's pre-training data and\nachieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.\nThe code will be released at https://github.com/WitGotFlg/VisTex-OVLM.", "AI": {"tldr": "This paper proposes an image-driven object detection method, VisTex-OVLM, which converts visual exemplars into a textual format to enhance object detection in rare categories.", "motivation": "Enhanced detection of rare categories has been challenging for Object-level Vision-Language Models due to the lack of textual descriptors and minimal representation in pre-training data.", "method": "VisTex-OVLM uses multi-scale textualizing blocks and multi-stage fusion to transform visual exemplars into textualized tokens, which are processed alongside text prompts for better object detection.", "result": "VisTex-OVLM achieves state-of-the-art performance in few-shot benchmarks (PASCAL VOC, MSCOCO) and outperforms across open-set datasets with minimal pre-training overlap.", "conclusion": "VisTex-OVLM retains the original architecture of OVLM while significantly enhancing rare category detection, offering a strong solution for few-shot and open-set limitations."}}
{"id": "2506.23801", "pdf": "https://arxiv.org/pdf/2506.23801", "abs": "https://arxiv.org/abs/2506.23801", "authors": ["Ce Wang", "Wanjie Sun"], "title": "Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors", "categories": ["cs.CV"], "comment": null, "summary": "Super-resolution (SR) techniques can enhance the spatial resolution of remote\nsensing images by utilizing low-resolution (LR) images to reconstruct\nhigh-resolution (HR) images, enabling more efficient large-scale earth\nobservation applications. While single-image super-resolution (SISR) methods\nhave shown progress, reference-based super-resolution (RefSR) offers superior\nperformance by incorporating historical HR images alongside current LR\nobservations. However, existing RefSR methods struggle with real-world\ncomplexities, such as cross-sensor resolution gap and significant land cover\nchanges, often leading to under-generation or over-reliance on reference image.\nTo address these challenges, we propose CRefDiff, a novel controllable\nreference-based diffusion model for real-world remote sensing image SR. To\naddress the under-generation problem, CRefDiff is built upon the pretrained\nStable Diffusion model, leveraging its powerful generative prior to produce\naccurate structures and textures. To mitigate over-reliance on the reference,\nwe introduce a dual-branch fusion mechanism that adaptively integrates both\nlocal and global information from the reference image. Moreover, this novel\ndual-branch design enables reference strength control during inference,\nenhancing interactivity and flexibility of the model. Finally, a strategy named\nBetter Start is proposed to significantly reduce the number of denoising steps,\nthereby accelerating the inference process. To support further research, we\nintroduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing\nimages, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land\ncover changes and significant temporal gaps. Extensive experiments on\nReal-RefRSSRD show that CRefDiff achieves state-of-the-art performance across\nvarious metrics and improves downstream tasks such as scene classification and\nsemantic segmentation.", "AI": {"tldr": "CRefDiff, a novel controllable diffusion model, addresses issues in reference-based super-resolution by integrating generative priors and adaptive fusion for accurate remote sensing image SR.", "motivation": "Existing RefSR methods struggle with real-world complexities like sensor resolution gaps and land cover changes, resulting in poor performance.", "method": "CRefDiff combines a pretrained Stable Diffusion model, a dual-branch fusion mechanism for local and global integration, and a strategy termed Better Start for accelerated inference.", "result": "CRefDiff outperforms state-of-the-art RefSR techniques, according to metrics and downstream tasks analysis on the new Real-RefRSSRD dataset.", "conclusion": "The proposed method enhances flexibility, accuracy, and efficiency in remote sensing image SR while enabling robust real-world applications."}}
{"id": "2506.23808", "pdf": "https://arxiv.org/pdf/2506.23808", "abs": "https://arxiv.org/abs/2506.23808", "authors": ["Carl Olsson", "Amanda Nilsson"], "title": "Towards Initialization-free Calibrated Bundle Adjustment", "categories": ["cs.CV"], "comment": null, "summary": "A recent series of works has shown that initialization-free BA can be\nachieved using pseudo Object Space Error (pOSE) as a surrogate objective. The\ninitial reconstruction-step optimizes an objective where all terms are\nprojectively invariant and it cannot incorporate knowledge of the camera\ncalibration. As a result, the solution is only determined up to a projective\ntransformation of the scene and the process requires more data for successful\nreconstruction.\n  In contrast, we present a method that is able to use the known camera\ncalibration thereby producing near metric solutions, that is, reconstructions\nthat are accurate up to a similarity transformation. To achieve this we\nintroduce pairwise relative rotation estimates that carry information about\ncamera calibration. These are only invariant to similarity transformations,\nthus encouraging solutions that preserve metric features of the real scene. Our\nmethod can be seen as integrating rotation averaging into the pOSE framework\nstriving towards initialization-free calibrated SfM.\n  Our experimental evaluation shows that we are able to reliably optimize our\nobjective, achieving convergence to the global minimum with high probability\nfrom random starting solutions, resulting in accurate near metric\nreconstructions.", "AI": {"tldr": "The paper proposes a method for reconstruction that uses camera calibration to achieve near-metric scene accuracy, integrating pairwise rotation estimates into initialization-free optimization frameworks.", "motivation": "Existing methods for structure-from-motion (SfM) use pseudo Object Space Error (pOSE) but fall short in utilizing camera calibration, leading to projective reconstructions and requiring more data.", "method": "The proposed method incorporates pairwise relative rotation estimates, which depend on camera calibration, into the pOSE framework, achieving similarity transformation-based reconstructions.", "result": "Experimental evaluation demonstrates reliable optimization, global minimum convergence with high probability, and accurate near metric reconstructions.", "conclusion": "The method succeeds in producing calibration-aware reconstructions with reduced data requirements, showing promise for initialization-free calibrated SfM."}}
{"id": "2506.23810", "pdf": "https://arxiv.org/pdf/2506.23810", "abs": "https://arxiv.org/abs/2506.23810", "authors": ["Mahshid Shiri", "Cigdem Beyan", "Vittorio Murino"], "title": "MadCLIP: Few-shot Medical Anomaly Detection with CLIP", "categories": ["cs.CV"], "comment": "Accepted to MICCAI 2025 (this version is not peer-reviewed; it is the\n  submitted version). MICCAI proceedings DOI will appear here", "summary": "An innovative few-shot anomaly detection approach is presented, leveraging\nthe pre-trained CLIP model for medical data, and adapting it for both\nimage-level anomaly classification (AC) and pixel-level anomaly segmentation\n(AS). A dual-branch design is proposed to separately capture normal and\nabnormal features through learnable adapters in the CLIP vision encoder. To\nimprove semantic alignment, learnable text prompts are employed to link visual\nfeatures. Furthermore, SigLIP loss is applied to effectively handle the\nmany-to-one relationship between images and unpaired text prompts, showcasing\nits adaptation in the medical field for the first time. Our approach is\nvalidated on multiple modalities, demonstrating superior performance over\nexisting methods for AC and AS, in both same-dataset and cross-dataset\nevaluations. Unlike prior work, it does not rely on synthetic data or memory\nbanks, and an ablation study confirms the contribution of each component. The\ncode is available at https://github.com/mahshid1998/MadCLIP.", "AI": {"tldr": "The paper introduces a few-shot anomaly detection method using the pre-trained CLIP model for medical data, showcasing robust performance in both anomaly classification and segmentation tasks.", "motivation": "To develop a more effective anomaly detection system for medical data without relying on synthetic data or memory banks, and to improve performance in both image-level classification and pixel-level segmentation.", "method": "A dual-branch architecture leveraging learnable adapters in CLIP's vision encoder is combined with learnable text prompts for better semantic alignment. It also introduces SigLIP loss to manage image-text relationships effectively.", "result": "The proposed method outperforms existing approaches in medical anomaly detection for classification and segmentation tasks across various datasets, including cross-dataset scenarios.", "conclusion": "The approach demonstrates significant innovation by adapting the CLIP model to the medical domain without using synthetic data, and all components contribute to its success as confirmed via ablation studies."}}
{"id": "2506.23822", "pdf": "https://arxiv.org/pdf/2506.23822", "abs": "https://arxiv.org/abs/2506.23822", "authors": ["Shiming Chen", "Bowen Duan", "Salman Khan", "Fahad Shahbaz Khan"], "title": "Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model", "categories": ["cs.CV"], "comment": "Accepted to ICCV'25", "summary": "Large-scale vision-language models (VLMs), such as CLIP, have achieved\nremarkable success in zero-shot learning (ZSL) by leveraging large-scale\nvisual-text pair datasets. However, these methods often lack interpretability,\nas they compute the similarity between an entire query image and the embedded\ncategory words, making it difficult to explain their predictions. One approach\nto address this issue is to develop interpretable models by integrating\nlanguage, where classifiers are built using discrete attributes, similar to\nhuman perception. This introduces a new challenge: how to effectively align\nlocal visual features with corresponding attributes based on pre-trained VLMs.\nTo tackle this, we propose LaZSL, a locally-aligned vision-language model for\ninterpretable ZSL. LaZSL employs local visual-semantic alignment via optimal\ntransport to perform interaction between visual regions and their associated\nattributes, facilitating effective alignment and providing interpretable\nsimilarity without the need for additional training. Extensive experiments\ndemonstrate that our method offers several advantages, including enhanced\ninterpretability, improved accuracy, and strong domain generalization. Codes\navailable at: https://github.com/shiming-chen/LaZSL.", "AI": {"tldr": "The paper introduces LaZSL, a locally-aligned vision-language model aimed at improving interpretability, accuracy, and domain generalization for zero-shot learning by aligning visual features with semantic attributes.", "motivation": "The study is motivated by the lack of interpretability in existing large-scale vision-language models like CLIP, which compute predictions by analyzing whole images rather than discrete attributes.", "method": "LaZSL uses optimal transport to align local visual features with semantic attributes based on pre-trained vision-language models, enabling interpretable similarity without additional training.", "result": "Experiments reveal that LaZSL achieves better interpretability, accuracy, and domain generalization in zero-shot learning scenarios compared to existing methods.", "conclusion": "LaZSL successfully addresses interpretability challenges in VLM-based zero-shot learning while boosting performance metrics, showing potential for effective real-world applications."}}
{"id": "2506.23490", "pdf": "https://arxiv.org/pdf/2506.23490", "abs": "https://arxiv.org/abs/2506.23490", "authors": ["Junxuan Yu", "Yaofei Duan", "Yuhao Huang", "Yu Wang", "Rongbo Ling", "Weihao Luo", "Ang Zhang", "Jingxian Xu", "Qiongying Ni", "Yongsong Zhou", "Binghan Li", "Haoran Dou", "Liping Liu", "Yanfen Chu", "Feng Geng", "Zhe Sheng", "Zhifeng Ding", "Dingxin Zhang", "Rui Huang", "Yuhang Zhang", "Xiaowei Xu", "Tao Tan", "Dong Ni", "Zhongshan Gou", "Xin Yang"], "title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "accepted by miccai 2025", "summary": "Echocardiography is routine for cardiac examination. However, 2D ultrasound\n(US) struggles with accurate metric calculation and direct observation of 3D\ncardiac structures. Moreover, 3D US is limited by low resolution, small field\nof view and scarce availability in practice. Constructing the cardiac\nanatomical twin from 2D images is promising to provide precise treatment\nplanning and clinical quantification. However, it remains challenging due to\nthe rare paired data, complex structures, and US noises. In this study, we\nintroduce a novel generative framework UltraTwin, to obtain cardiac anatomical\ntwin from sparse multi-view 2D US. Our contribution is three-fold. First,\npioneered the construction of a real-world and high-quality dataset containing\nstrictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we\npropose a coarse-to-fine scheme to achieve hierarchical reconstruction\noptimization. Last, we introduce an implicit autoencoder for topology-aware\nconstraints. Extensive experiments show that UltraTwin reconstructs\nhigh-quality anatomical twins versus strong competitors. We believe it advances\nanatomical twin modeling for potential applications in personalized cardiac\ncare.", "AI": {"tldr": "This paper introduces UltraTwin, a generative framework to obtain 3D cardiac anatomical models from sparse 2D ultrasound data, addressing challenges like limited data and noise.", "motivation": "The motivation is to overcome the limitations of 2D and 3D ultrasound in cardiac examinations by enabling accurate 3D anatomical reconstructions that aid clinical applications.", "method": "The method involves a generative framework using a real-world paired dataset, a coarse-to-fine hierarchical reconstruction scheme, and an implicit autoencoder for topology-aware constraints.", "result": "UltraTwin achieves high-quality reconstruction of cardiac anatomical twins, outperforming competing methods.", "conclusion": "UltraTwin demonstrates strong potential in advancing personalized cardiac care via enhanced anatomical twin modeling."}}
{"id": "2506.23458", "pdf": "https://arxiv.org/pdf/2506.23458", "abs": "https://arxiv.org/abs/2506.23458", "authors": ["Xiaoxiao Yang", "Chan Feng", "Jiancheng Chen"], "title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "categories": ["cs.HC", "cs.LG"], "comment": "2 pages short paper", "summary": "Portable and wearable consumer-grade electroencephalography (EEG) devices,\nlike Muse headbands, offer unprecedented mobility for daily brain-computer\ninterface (BCI) applications, including cognitive load detection. However, the\nexacerbated non-stationarity in portable EEG signals constrains data fidelity\nand decoding accuracy, creating a fundamental trade-off between portability and\nperformance. To mitigate such limitation, we propose MuseCogNet (Muse-based\nCognitive Network), a unified joint learning framework integrating\nself-supervised and supervised training paradigms. In particular, we introduce\nan EEG-grounded self-supervised reconstruction loss based on average pooling to\ncapture robust neurophysiological patterns, while cross-entropy loss refines\ntask-specific cognitive discriminants. This joint learning framework resembles\nthe bottom-up and top-down attention in humans, enabling MuseCogNet to\nsignificantly outperform state-of-the-art methods on a publicly available Muse\ndataset and establish an implementable pathway for neurocognitive monitoring in\necological settings.", "AI": {"tldr": "The paper introduces MuseCogNet, a framework for improving the accuracy and reliability of portable EEG-based cognitive load detection using joint learning techniques.", "motivation": "The use of portable EEG devices like Muse headbands for brain-computer interface applications faces performance limitations due to low signal fidelity and decoding accuracy caused by non-stationary portable EEG signals.", "method": "The authors propose a joint learning framework combining self-supervised EEG reconstruction loss with supervised cross-entropy loss to identify robust neurophysiological and task-specific patterns.", "result": "MuseCogNet outperformed existing methods on a public Muse dataset, demonstrating enhanced accuracy and usability for neurocognitive monitoring.", "conclusion": "MuseCogNet offers a feasible and effective solution for neurocognitive monitoring in real-world settings by addressing signal fidelity and decoding accuracy using a unified learning approach."}}
{"id": "2506.23825", "pdf": "https://arxiv.org/pdf/2506.23825", "abs": "https://arxiv.org/abs/2506.23825", "authors": ["Haoji Zhang", "Yiqin Wang", "Yansong Tang", "Yong Liu", "Jiashi Feng", "Xiaojie Jin"], "title": "Flash-VStream: Efficient Real-Time Understanding for Long Video Streams", "categories": ["cs.CV"], "comment": "Accepted by ICCV 2025", "summary": "Benefiting from the advances in large language models and cross-modal\nalignment, existing multimodal large language models have achieved prominent\nperformance in image and short video understanding. However, the understanding\nof long videos is still challenging, as their long-context nature results in\nsignificant computational and memory overhead. Most existing work treats long\nvideos in the same way as short videos, which is inefficient for real-world\napplications and hard to generalize to even longer videos. To address these\nissues, we propose Flash-VStream, an efficient video language model capable of\nprocessing extremely long videos and responding to user queries in real time.\nParticularly, we design a Flash Memory module, containing a low-capacity\ncontext memory to aggregate long-context temporal information and model the\ndistribution of information density, and a high-capacity augmentation memory to\nretrieve detailed spatial information based on this distribution. Compared to\nexisting models, Flash-VStream achieves significant reductions in inference\nlatency. Extensive experiments on long video benchmarks and comprehensive video\nbenchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate\nthe state-of-the-art performance and outstanding efficiency of our method. Code\nis available at https://github.com/IVGSZ/Flash-VStream.", "AI": {"tldr": "Flash-VStream enhances long video understanding efficiently by introducing innovative memory modules for real-time user query responses.", "motivation": "Understanding long videos poses challenges due to computational and memory overhead, as current models treat them similarly to short videos.", "method": "The paper introduces Flash Memory modules with a low-capacity context memory for temporal information aggregation and a high-capacity augmentation memory to retrieve spatial information.", "result": "Flash-VStream shows state-of-the-art performance and improved efficiency on long video benchmarks compared to existing models.", "conclusion": "Flash-VStream demonstrates its capability to address the inefficiency of long video understanding while improving inference latency and overall performance."}}
{"id": "2506.23827", "pdf": "https://arxiv.org/pdf/2506.23827", "abs": "https://arxiv.org/abs/2506.23827", "authors": ["Mingcheng Qu", "Yuncong Wu", "Donglin Di", "Yue Gao", "Tonghua Su", "Yang Song", "Lei Fan"], "title": "Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning", "categories": ["cs.CV"], "comment": "Our paper has been accepted by MICCAI 2025", "summary": "Spatial transcriptomics (ST) provides crucial insights into tissue\nmicro-environments, but is limited to its high cost and complexity. As an\nalternative, predicting gene expression from pathology whole slide images (WSI)\nis gaining increasing attention. However, existing methods typically rely on\nsingle patches or a single pathology modality, neglecting the complex spatial\nand molecular interactions between target and neighboring information (e.g.,\ngene co-expression). This leads to a failure in establishing connections among\nadjacent regions and capturing intricate cross-modal relationships. To address\nthese issues, we propose NH2ST, a framework that integrates spatial context and\nboth pathology and gene modalities for gene expression prediction. Our model\ncomprises a query branch and a neighbor branch to process paired target patch\nand gene data and their neighboring regions, where cross-attention and\ncontrastive learning are employed to capture intrinsic associations and ensure\nalignments between pathology and gene expression. Extensive experiments on six\ndatasets demonstrate that our model consistently outperforms existing methods,\nachieving over 20% in PCC metrics. Codes are available at\nhttps://github.com/MCPathology/NH2ST", "AI": {"tldr": "NH2ST is a novel framework for predicting gene expression that integrates spatial and molecular data from pathology and gene modalities, addressing limitations in existing methods.", "motivation": "To overcome the high cost and complexity of spatial transcriptomics and limitations of existing gene expression prediction methods that fail to consider spatial and molecular interactions.", "method": "NH2ST uses a query and neighbor branch to process data from pathology and gene modalities. Cross-attention and contrastive learning are employed to capture spatial and molecular associations.", "result": "NH2ST outperforms existing methods across six datasets with over 20% improvement in PCC metrics.", "conclusion": "NH2ST demonstrates the potential to significantly improve gene expression prediction by incorporating spatial and molecular context, showing promise for advancing tissue micro-environment studies."}}
{"id": "2506.23832", "pdf": "https://arxiv.org/pdf/2506.23832", "abs": "https://arxiv.org/abs/2506.23832", "authors": ["Ronit D. Gross", "Tal Halevi", "Ella Koresh", "Yarden Tzach", "Ido Kanter"], "title": "Low-latency vision transformers via large-scale multi-head attention", "categories": ["cs.CV"], "comment": "23 pages, 4 figures, 7 tables", "summary": "The emergence of spontaneous symmetry breaking among a few heads of\nmulti-head attention (MHA) across transformer blocks in classification tasks\nwas recently demonstrated through the quantification of single-nodal\nperformance (SNP). This finding indicates that each head focuses its attention\non a subset of labels through cooperation among its SNPs. This underlying\nlearning mechanism is generalized to large-scale MHA (LS-MHA) using a single\nmatrix value representing single-head performance (SHP), analogous to\nsingle-filter performance in convolutional neural networks (CNNs). The results\nindicate that each SHP matrix comprises multiple unit clusters such that each\nlabel being explicitly recognized by a few heads with negligible noise. This\nleads to an increased signal-to-noise ratio (SNR) along the transformer blocks,\nthereby improving classification accuracy. These features give rise to several\ndistinct vision transformer (ViT) architectures that achieve the same accuracy\nbut differ in their LS-MHA structures. As a result, their soft committee yields\nsuperior accuracy, an outcome not typically observed in CNNs which rely on\nhundreds of filters. In addition, a significant reduction in latency is\nachieved without affecting the accuracy by replacing the initial transformer\nblocks with convolutional layers. This substitution accelerates early-stage\nlearning, which is then improved by subsequent transformer layers. The\nextension of this learning mechanism to natural language processing tasks,\nbased on quantitative differences between CNNs and ViT architectures, has the\npotential to yield new insights in deep learning. The findings are demonstrated\nusing compact convolutional transformer architectures trained on the CIFAR-100\ndataset.", "AI": {"tldr": "The study explores the spontaneous symmetry breaking in multi-head attention mechanisms and its application in classification tasks, leading to high signal-to-noise ratio and improved accuracy. It proposes hybrid architectures combining convolutional layers and transformers to reduce latency.", "motivation": "To understand how spontaneous symmetry breaking contributes to label recognition in multi-head attention mechanisms and extend the advantages of vision transformer architectures in classification tasks.", "method": "Quantified single-nodal and single-head performance, generalized to large-scale multi-head attention mechanisms, and investigated the behavior on the CIFAR-100 dataset. Developed hybrid architectures with CNNs and transformers.", "result": "Improved classification accuracy via higher signal-to-noise ratio across transformer blocks. Hybrid architectures demonstrated reduced latency during early learning stages while maintaining accuracy.", "conclusion": "Spontaneous symmetry breaking enhances label recognition in multi-head attention. Hybrid architectures combining CNNs and ViTs improve efficiency while delivering high accuracy, with potential applications beyond vision tasks into NLP."}}
{"id": "2506.23506", "pdf": "https://arxiv.org/pdf/2506.23506", "abs": "https://arxiv.org/abs/2506.23506", "authors": ["Bowen Xin", "Rohan Hickey", "Tamara Blake", "Jin Jin", "Claire E Wainwright", "Thomas Benkert", "Alto Stemmer", "Peter Sly", "David Coman", "Jason Dowling"], "title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "comment": "Oral presentation in ISMRM2025", "summary": "Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE)\nrepresents a recent breakthrough in lung structure imaging, providing image\nresolution and quality comparable to computed tomography (CT). Due to the\nabsence of ionising radiation, MRI is often preferred over CT in paediatric\ndiseases such as cystic fibrosis (CF), one of the most common genetic disorders\nin Caucasians. To assess structural lung damage in CF imaging, CT scoring\nsystems provide valuable quantitative insights for disease diagnosis and\nprogression. However, few quantitative scoring systems are available in\nstructural lung MRI (e.g., UTE-MRI). To provide fast and accurate\nquantification in lung MRI, we investigated the feasibility of novel Artificial\nintelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring\nconsists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3)\nlung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification\nand reporting. The results shows that our APL scoring took 8.2 minutes per\nsubject, which was more than twice as fast as the previous grid-level scoring.\nAdditionally, our pixel-level scoring was statistically more accurate\n(p=0.021), while strongly correlating with grid-level scoring (R=0.973,\np=5.85e-9). This tool has great potential to streamline the workflow of UTE\nlung MRI in clinical settings, and be extended to other structural lung MRI\nsequences (e.g., BLADE MRI), and for other lung diseases (e.g.,\nbronchopulmonary dysplasia).", "AI": {"tldr": "This paper introduces an AI-assisted Pixel-level Lung (APL) scoring method for assessing structural lung damage in CF using UTE-MRI, achieving faster and more accurate results than prior methods.", "motivation": "The motivation was to provide a radiation-free, quantifiable, and accurate method to assess structural lung damage in cystic fibrosis (CF) using UTE-MRI, addressing the lack of robust scoring systems for MRI in this context.", "method": "The method involves a 5-stage APL system: 1) loading images, 2) AI-assisted lung segmentation, 3) sampling lung-bounded slices, 4) conducting pixel-level annotations, and 5) producing quantified reports.", "result": "APL scoring demonstrated 8.2 minutes per subject analysis time, which is over twice as fast as grid-level scoring, and showed improved statistical accuracy (p=0.021) with a strong correlation to grid-level scoring (R=0.973, p=5.85e-9).", "conclusion": "This method streamlines UTE lung MRI workflows in clinical settings, offers fast and accurate scoring, and may be extendable to additional MRI sequences and lung diseases."}}
{"id": "2506.23833", "pdf": "https://arxiv.org/pdf/2506.23833", "abs": "https://arxiv.org/abs/2506.23833", "authors": ["Oscar Ovanger", "Ragnar Hauge", "Jacob Skauvold", "Michael J. Pyrcz", "Jo Eidsvik"], "title": "PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric", "categories": ["cs.CV"], "comment": "13 pages, 20 figures", "summary": "This paper presents PointSSIM, a novel low-dimensional image-to-image\ncomparison metric that is resolution invariant. Drawing inspiration from the\nstructural similarity index measure and mathematical morphology, PointSSIM\nenables robust comparison across binary images of varying resolutions by\ntransforming them into marked point pattern representations. The key features\nof the image, referred to as anchor points, are extracted from binary images by\nidentifying locally adaptive maxima from the minimal distance transform. Image\ncomparisons are then performed using a summary vector, capturing intensity,\nconnectivity, complexity, and structural attributes. Results show that this\napproach provides an efficient and reliable method for image comparison,\nparticularly suited to applications requiring structural analysis across\ndifferent resolutions.", "AI": {"tldr": "PointSSIM is a novel resolution-invariant metric for binary image comparison, transforming images into point pattern representations to analyze structural attributes efficiently.", "motivation": "The motivation lies in addressing the challenge of robustly comparing binary images across varying resolutions, a need for applications requiring structural analysis.", "method": "PointSSIM employs mathematical morphology and structural similarity, extracting key features called anchor points via a minimal distance transform to create marked point pattern representations for comparison.", "result": "Results demonstrate PointSSIM\u2019s efficiency and reliability in comparing image structures across resolutions, capturing intensity, connectivity, complexity, and structural attributes.", "conclusion": "PointSSIM is effective for image comparison tasks, particularly in scenarios involving varied resolutions and structural analysis requirements."}}
{"id": "2506.23835", "pdf": "https://arxiv.org/pdf/2506.23835", "abs": "https://arxiv.org/abs/2506.23835", "authors": ["Ziwei Chen", "Ziling Liu", "Zitong Huang", "Mingqi Gao", "Feng Zheng"], "title": "Refine Any Object in Any Scene", "categories": ["cs.CV"], "comment": "9 pages with 6 figures", "summary": "Viewpoint missing of objects is common in scene reconstruction, as camera\npaths typically prioritize capturing the overall scene structure rather than\nindividual objects. This makes it highly challenging to achieve high-fidelity\nobject-level modeling while maintaining accurate scene-level representation.\nAddressing this issue is critical for advancing downstream tasks requiring\ndetailed object understanding and appearance modeling. In this paper, we\nintroduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement\nframework that leverages 3D generative priors to recover fine-grained object\ngeometry and appearance under missing views. Starting from substituting\ndegraded objects with proxies, via a 3D generative model with strong 3D\nunderstanding, RAISE progressively refines geometry and texture by aligning\neach proxy to its degraded counterpart in 7-DOF pose, followed by correcting\nspatial and appearance inconsistencies via registration-constrained\nenhancement. This two-stage refinement ensures the high-fidelity geometry and\nappearance of the original object in unseen views while maintaining consistency\nin spatial positioning, observed geometry, and appearance. Extensive\nexperiments on challenging benchmarks show that RAISE significantly outperforms\nstate-of-the-art methods in both novel view synthesis and geometry completion\ntasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.", "AI": {"tldr": "The paper presents RAISE, a framework that uses 3D generative models for recovering fine-grained object details in scenes with missing viewpoints, outperforming existing methods in view synthesis and geometry completion.", "motivation": "High-fidelity object modeling is difficult due to common missing viewpoints in scene reconstruction, which hinders downstream tasks that need detailed object understanding.", "method": "RAISE substitutes degraded objects with proxies from a 3D generative model and refines their geometry and texture in a two-stage approach: pose alignment and registration-constrained enhancement for consistency.", "result": "Experiments demonstrate that RAISE achieves superior performance compared to state-of-the-art in novel view synthesis and geometry completion benchmarks.", "conclusion": "RAISE ensures detailed recovery of objects' geometry and appearance for unseen views while maintaining spatial and appearance consistency, advancing scene reconstruction techniques."}}
{"id": "2506.23852", "pdf": "https://arxiv.org/pdf/2506.23852", "abs": "https://arxiv.org/abs/2506.23852", "authors": ["Jianing Jin", "Jiangyong Ying", "Huiyu Duan", "Liu Yang", "Sijing Wu", "Yunhao Li", "Yushuo Zheng", "Xiongkuo Min", "Guangtao Zhai"], "title": "RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment", "categories": ["cs.CV"], "comment": null, "summary": "As camera-equipped robotic platforms become increasingly integrated into\ndaily life, robotic-generated videos have begun to appear on streaming media\nplatforms, enabling us to envision a future where humans and robots coexist. We\ninnovatively propose the concept of Robotic-Generated Content (RGC) to term\nthese videos generated from egocentric perspective of robots. The perceptual\nquality of RGC videos is critical in human-robot interaction scenarios, and RGC\nvideos exhibit unique distortions and visual requirements that differ markedly\nfrom those of professionally-generated content (PGC) videos and user-generated\ncontent (UGC) videos. However, dedicated research on quality assessment of RGC\nvideos is still lacking. To address this gap and to support broader robotic\napplications, we establish the first Robotic-Generated Content Database (RGCD),\nwhich contains a total of 2,100 videos drawn from three robot categories and\nsourced from diverse platforms. A subjective VQA experiment is conducted\nsubsequently to assess human visual perception of robotic-generated videos.\nFinally, we conduct a benchmark experiment to evaluate the performance of 11\nstate-of-the-art VQA models on our database. Experimental results reveal\nsignificant limitations in existing VQA models when applied to complex,\nrobotic-generated content, highlighting a critical need for RGC-specific VQA\nmodels. Our RGCD is publicly available at:\nhttps://github.com/IntMeGroup/RGC-VQA.", "AI": {"tldr": "This paper introduces the concept of Robotic-Generated Content (RGC) videos, proposes a first-of-its-kind database (RGCD) for their quality assessment, and reveals through experiments that existing VQA models struggle with RGC-specific challenges.", "motivation": "With the growing integration of robotic platforms into daily life, robotic-generated videos are becoming more prevalent on various media platforms. There is a need to evaluate the unique visual and perceptual challenges such videos pose, as they differ significantly from professional or user-generated content.", "method": "The authors created the RGCD, a database containing 2,100 robotic-generated videos across three robot categories and various platforms. They conducted subjective video quality assessment (VQA) experiments and benchmarked 11 state-of-the-art VQA models on this dataset.", "result": "The study demonstrated significant deficiencies in the performance of existing VQA models when utilized for robotic-generated videos, highlighting their unsuitability for the unique distortions and requirements of RGC.", "conclusion": "There is a pressing need for the development of RGC-specific video quality assessment models, as current VQA models do not adequately address the unique characteristics of robotic-generated content."}}
{"id": "2506.23854", "pdf": "https://arxiv.org/pdf/2506.23854", "abs": "https://arxiv.org/abs/2506.23854", "authors": ["Yida Wang", "Xueyang Zhang", "Kun Zhan", "Peng Jia", "Xianpeng Lang"], "title": "HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity", "categories": ["cs.CV", "cs.GR"], "comment": "Published in International Conference on Computer Vision (ICCV) 2025", "summary": "Neural surface reconstruction faces persistent challenges in reconciling\ngeometric fidelity with photometric consistency under complex scene conditions.\nWe present HiNeuS, a unified framework that holistically addresses three core\nlimitations in existing approaches: multi-view radiance inconsistency, missing\nkeypoints in textureless regions, and structural degradation from over-enforced\nEikonal constraints during joint optimization. To resolve these issues through\na unified pipeline, we introduce: 1) Differential visibility verification\nthrough SDF-guided ray tracing, resolving reflection ambiguities via continuous\nocclusion modeling; 2) Planar-conformal regularization via ray-aligned geometry\npatches that enforce local surface coherence while preserving sharp edges\nthrough adaptive appearance weighting; and 3) Physically-grounded Eikonal\nrelaxation that dynamically modulates geometric constraints based on local\nradiance gradients, enabling detail preservation without sacrificing global\nregularity. Unlike prior methods that handle these aspects through sequential\noptimizations or isolated modules, our approach achieves cohesive integration\nwhere appearance-geometry constraints evolve synergistically throughout\ntraining. Comprehensive evaluations across synthetic and real-world datasets\ndemonstrate state-of-the-art performance, including a 21.4% reduction in\nChamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement\nagainst neural rendering counterparts. Qualitative analyses reveal superior\ncapability in recovering specular instruments, urban layouts with\ncentimeter-scale infrastructure, and low-textured surfaces without local patch\ncollapse. The method's generalizability is further validated through successful\napplication to inverse rendering tasks, including material decomposition and\nview-consistent relighting.", "AI": {"tldr": "HiNeuS is a framework for neural surface reconstruction that improves geometric fidelity and photometric consistency using novel techniques like SDF-guided ray tracing, planar-conformal regularization, and Eikonal relaxation.", "motivation": "To address persistent challenges in neural surface reconstruction, such as multi-view radiance inconsistency, missing keypoints in textureless regions, and structural degradation from strict geometric constraints.", "method": "HiNeuS employs differential visibility verification for resolving reflection ambiguities, planar-conformal regularization for preserving sharp edges, and Eikonal relaxation for balancing detail preservation with global regularity.", "result": "Achieved state-of-the-art performance, reducing Chamfer distance by 21.4% and improving PSNR by 2.32 dB, with success on both synthetic and real-world datasets, and applications to inverse rendering tasks.", "conclusion": "HiNeuS provides a unified and generalizable approach for surface reconstruction, excelling in photometric and geometric detail recovery under complex conditions."}}
{"id": "2506.23856", "pdf": "https://arxiv.org/pdf/2506.23856", "abs": "https://arxiv.org/abs/2506.23856", "authors": ["Ji Zhang", "Shihan Wu", "Lianli Gao", "Jingkuan Song", "Nicu Sebe", "Heng Tao Shen"], "title": "A Closer Look at Conditional Prompt Tuning for Vision-Language Models", "categories": ["cs.CV"], "comment": "18 pages", "summary": "Despite the great promise of Prompt Tuning (PT) in adapting large\nVision-Language Pretrained Models (VLPMs) to downstream tasks, they often\nstruggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better\ntuned to a base task, their ability to generalize to new tasks diminishes.\nRecent work on conditional PT addresses this problem by replacing static\nprompts with dynamic Visual Image Information (VII)-conditioned prompts,\nimproving the model's generalization to new tasks to some extent. In this work,\nwe first identify a critical issue with existing conditional PT methods: using\nVII as the \"condition\" of prompts yields suboptimal performance, and even\nrandom noise-conditioned prompts can outperform the VII-conditioned\ncounterparts. On further analysis, we find that learning dynamic prompts\nconditioned on Textual Class Information (TCI) is the key to solving the BNT\nproblem. Motivated by this, we then propose Class-adaptive Prompt Tuning\n(CaPT), which enables fast adaptation of tuned models to new classes by\nlearning TCI-conditioned prompts from base classes. Remarkably, CaPT can be\nused as a plugin to mitigate the BNT problem for existing unconditional PT\nschemes. Extensive experiments on 11 datasets show that CaPT consistently\nimproves the performance of five strong unconditional PT baselines with\nnegligible additional computational cost. Additionally, by integrating CaPT\nwith our recently proposed DePT framework, we devise a new conditional PT\napproach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art\nconditional PT scheme by 3.49%, averaged over the 11 datasets. Code:\nhttps://github.com/Koorye/CaPT.", "AI": {"tldr": "Prompt Tuning (PT) approaches face challenges when adapting Vision-Language Pretrained Models (VLPMs) to new tasks without sacrificing performance on base tasks. This study identifies issues with conditional PT techniques and proposes Class-adaptive Prompt Tuning (CaPT), a novel method using Textual Class Information.", "motivation": "To address the Base-New Tradeoff dilemma in Vision-Language Pretrained Models where adaptation to base tasks compromises generalization to new tasks.", "method": "Developing Class-adaptive Prompt Tuning (CaPT) that uses Textual Class Information-conditioned prompts, enabling better performance on new classes without losing efficacy on base classes.", "result": "CaPT improves the performance of five unconditional PT baselines on 11 datasets with negligible computational cost. Integrated into the DePT framework, the DeCaPT approach achieves superior results compared to state-of-the-art conditional PT methods.", "conclusion": "CaPT provides an effective and computationally efficient solution to mitigate the Base-New Tradeoff problem, offering improvements across tasks with enhanced generalization capabilities."}}
{"id": "2506.23550", "pdf": "https://arxiv.org/pdf/2506.23550", "abs": "https://arxiv.org/abs/2506.23550", "authors": ["Ryui Kaneko", "Shimpei Goto"], "title": "Seeding neural network quantum states with tensor network states", "categories": ["cond-mat.str-el", "cs.LG", "cs.NA", "math.NA", "quant-ph"], "comment": "13 pages, 13 figures", "summary": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states with increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures.", "AI": {"tldr": "The paper introduces an approach to convert matrix product states (MPSs) into neural network wave functions through CP decomposition, useful for quantum ground-state calculations.", "motivation": "To efficiently generate initial neural network quantum states for quantum many-body systems and improve the accuracy of ground-state calculations.", "method": "The authors use Canonical Polyadic (CP) decomposition on matrix product states (MPSs) to convert them into restricted Boltzmann machine wave functions with multinomial hidden units.", "result": "The method achieved efficient initialization and improved closeness to the ground states, demonstrated on a transverse-field Ising model.", "conclusion": "This CP decomposition-based approach is effective and has potential applications in complex quantum many-body systems with intricate ground-state wave function structures."}}
{"id": "2506.23858", "pdf": "https://arxiv.org/pdf/2506.23858", "abs": "https://arxiv.org/abs/2506.23858", "authors": ["Jianzong Wu", "Liang Hou", "Haotian Yang", "Xin Tao", "Ye Tian", "Pengfei Wan", "Di Zhang", "Yunhai Tong"], "title": "VMoBA: Mixture-of-Block Attention for Video Diffusion Models", "categories": ["cs.CV"], "comment": "Code is at https://github.com/KwaiVGI/VMoBA", "summary": "The quadratic complexity of full attention mechanisms poses a significant\nbottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,\nhigh-resolution videos. While various sparse attention methods have been\nproposed, many are designed as training-free inference accelerators or do not\noptimally capture the unique spatio-temporal characteristics inherent in video\ndata when trained natively. This paper introduces Video Mixture of Block\nAttention (VMoBA), a novel sparse attention mechanism specifically adapted for\nVDMs. Motivated by an in-depth analysis of attention patterns within\npre-trained video transformers, which revealed strong spatio-temporal locality,\nvarying query importance, and head-specific concentration levels, VMoBA\nenhances the original MoBA framework with three key modifications: (1) a\nlayer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to\ndiverse spatio-temporal attention patterns and improve efficiency; (2) global\nblock selection to prioritize the most salient query-key block interactions\nacross an entire attention head; and (3) threshold-based block selection to\ndynamically determine the number of attended blocks based on their cumulative\nsimilarity. Extensive experiments demonstrate that VMoBA significantly\naccelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and\n1.48x latency speedup, while attaining comparable or even superior generation\nquality to full attention. Furthermore, VMoBA exhibits competitive performance\nin training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for\nhigh-res video generation.", "AI": {"tldr": "The paper introduces Video Mixture of Block Attention (VMoBA), a sparse attention mechanism for Video Diffusion Models to address the quadratic complexity issue in generating high-resolution, long-duration videos.", "motivation": "To overcome the computational bottleneck of full attention mechanisms in Video Diffusion Models and optimize spatio-temporal sparse attention for video data.", "method": "The authors proposed VMoBA with three innovations: a layer-wise recurrent block partition scheme (1D-2D-3D), global block selection for salient interactions, and threshold-based block selection for adaptive attention allocation.", "result": "VMoBA accelerates training of VDMs with a 2.92x FLOPs and 1.48x latency speedup, maintains or improves generation quality, and achieves competitive speedups during training-free inference (2.40x FLOPs, 1.35x latency).", "conclusion": "VMoBA effectively addresses the computational challenges in video generation, balancing efficiency and quality, and stands as a competitive alternative to full attention mechanisms."}}
{"id": "2506.23560", "pdf": "https://arxiv.org/pdf/2506.23560", "abs": "https://arxiv.org/abs/2506.23560", "authors": ["Shakir Showkat Sofi", "Charlotte Vermeylen", "Lieven De Lathauwer"], "title": "Tensor Train Quantum State Tomography using Compressed Sensing", "categories": ["quant-ph", "cs.AI", "eess.SP", "math.OC"], "comment": "Accepted for publication in EUSIPCO 2025", "summary": "Quantum state tomography (QST) is a fundamental technique for estimating the\nstate of a quantum system from measured data and plays a crucial role in\nevaluating the performance of quantum devices. However, standard estimation\nmethods become impractical due to the exponential growth of parameters in the\nstate representation. In this work, we address this challenge by parameterizing\nthe state using a low-rank block tensor train decomposition and demonstrate\nthat our approach is both memory- and computationally efficient. This framework\napplies to a broad class of quantum states that can be well approximated by\nlow-rank decompositions, including pure states, nearly pure states, and ground\nstates of Hamiltonians.", "AI": {"tldr": "The paper addresses the inefficiency of standard quantum state tomography (QST) methods by proposing a low-rank block tensor train decomposition for improved computational and memory efficiency.", "motivation": "The motivation behind this paper lies in overcoming the impracticality of standard QST methods due to the exponential growth of parameters in state representation, particularly as quantum systems scale.", "method": "The paper introduces a low-rank block tensor train decomposition to parameterize quantum states, enabling efficient estimation and representation of quantum systems.", "result": "The proposed method demonstrates computationally and memory-efficient QST for a broad range of quantum states, including pure states, nearly pure states, and ground states of Hamiltonians.", "conclusion": "The low-rank block tensor train decomposition framework offers a scalable and efficient solution for QST, making it applicable to evaluating quantum devices and systems with complex states."}}
{"id": "2506.23863", "pdf": "https://arxiv.org/pdf/2506.23863", "abs": "https://arxiv.org/abs/2506.23863", "authors": ["Jiahao Ma", "Lei Wang", "Miaomiao liu", "David Ahmedt-Aristizabal", "Chuong Nguyen"], "title": "Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction", "categories": ["cs.CV"], "comment": "Feed-forward 3D reconstruction, Data Augmentation", "summary": "Multi-view 3D reconstruction remains a core challenge in computer vision.\nRecent methods, such as DUST3R and its successors, directly regress pointmaps\nfrom image pairs without relying on known scene geometry or camera parameters.\nHowever, the performance of these models is constrained by the diversity and\nscale of available training data. In this work, we introduce Puzzles, a data\naugmentation strategy that synthesizes an unbounded volume of high-quality\nposed video-depth data from a single image or video clip. By simulating diverse\ncamera trajectories and realistic scene geometry through targeted image\ntransformations, Puzzles significantly enhances data variety. Extensive\nexperiments show that integrating Puzzles into existing video-based 3D\nreconstruction pipelines consistently boosts performance without modifying the\nunderlying network architecture. Notably, models trained on only ten percent of\nthe original data augmented with Puzzles still achieve accuracy comparable to\nthose trained on the full dataset. Code is available at\nhttps://jiahao-ma.github.io/puzzles/.", "AI": {"tldr": "The paper introduces 'Puzzles,' a data augmentation technique designed to enhance video-based 3D reconstruction models by synthesizing diverse training data.", "motivation": "3D reconstruction methods often depend on limited datasets, restricting their performance and generalization ability.", "method": "Puzzles generates synthetic, high-quality video-depth training data using image transformations that simulate varied camera movements and scene geometries.", "result": "Integrating Puzzles in 3D reconstruction workflows enables models to achieve high accuracy with significantly less real training data.", "conclusion": "Puzzles efficiently boosts 3D reconstruction performance by improving data diversity and scale, without altering network architectures."}}
{"id": "2506.23881", "pdf": "https://arxiv.org/pdf/2506.23881", "abs": "https://arxiv.org/abs/2506.23881", "authors": ["Reihaneh Zohrabi", "Hosein Hasani", "Mahdieh Soleymani Baghshah", "Anna Rohrbach", "Marcus Rohrbach", "Mohammad Hossein Rohban"], "title": "Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability\nand safety of machine learning models in real-world applications, where they\nfrequently face data distributions unseen during training. Despite progress,\nexisting methods are often vulnerable to spurious correlations that mislead\nmodels and compromise robustness. To address this, we propose SPROD, a novel\nprototype-based OOD detection approach that explicitly addresses the challenge\nposed by unknown spurious correlations. Our post-hoc method refines class\nprototypes to mitigate bias from spurious features without additional data or\nhyperparameter tuning, and is broadly applicable across diverse backbones and\nOOD detection settings. We conduct a comprehensive spurious correlation OOD\ndetection benchmarking, comparing our method against existing approaches and\ndemonstrating its superior performance across challenging OOD datasets, such as\nCelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced\nAnimals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%\nover the second best.", "AI": {"tldr": "SPROD is a prototype-based OOD detection method addressing spurious correlations in unseen data, improving detection benchmarks significantly.", "motivation": "The paper aims to solve the vulnerability of existing OOD methods to spurious correlations, which compromise reliability and robustness in real-world applications.", "method": "SPROD refines class prototypes post-hoc to reduce bias from spurious features without requiring extra data or tuning, and can be applied to various OOD detection setups and model backbones.", "result": "SPROD showed superior performance in challenging OOD datasets, outperforming previous methods by improving AUROC by 4.7% and FPR@95 by 9.3% on average.", "conclusion": "SPROD offers a robust and generalized solution to OOD detection, proving effective in mitigating spurious correlations and improving reliability in various data settings."}}
{"id": "2506.23897", "pdf": "https://arxiv.org/pdf/2506.23897", "abs": "https://arxiv.org/abs/2506.23897", "authors": ["Longliang Liu", "Miaojie Feng", "Junda Cheng", "Jijun Xiang", "Xuan Zhu", "Xin Yang"], "title": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "categories": ["cs.CV"], "comment": "11 pages", "summary": "Panoramic optical flow enables a comprehensive understanding of temporal\ndynamics across wide fields of view. However, severe distortions caused by\nsphere-to-plane projections, such as the equirectangular projection (ERP),\nsignificantly degrade the performance of conventional perspective-based optical\nflow methods, especially in polar regions. To address this challenge, we\npropose PriOr-Flow, a novel dual-branch framework that leverages the\nlow-distortion nature of the orthogonal view to enhance optical flow estimation\nin these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup\n(DCCL) operator, which jointly retrieves correlation information from both the\nprimitive and orthogonal cost volumes, effectively mitigating distortion noise\nduring cost volume construction. Furthermore, our Ortho-Driven Distortion\nCompensation (ODDC) module iteratively refines motion features from both\nbranches, further suppressing polar distortions. Extensive experiments\ndemonstrate that PriOr-Flow is compatible with various perspective-based\niterative optical flow methods and consistently achieves state-of-the-art\nperformance on publicly available panoramic optical flow datasets, setting a\nnew benchmark for wide-field motion estimation. The code is publicly available\nat: https://github.com/longliangLiu/PriOr-Flow.", "AI": {"tldr": "This paper introduces PriOr-Flow, a method that improves panoramic optical flow estimation by addressing distortion issues caused by sphere-to-plane projection.", "motivation": "Existing optical flow methods struggle with severe distortions in panoramic images, particularly near polar regions, due to sphere-to-plane projections.", "method": "The authors propose a dual-branch framework combining primitive and orthogonal views. Key components include the Dual-Cost Collaborative Lookup (DCCL) operator for retrieving correlation information and the Ortho-Driven Distortion Compensation (ODDC) module for iterative refinement.", "result": "PriOr-Flow achieves state-of-the-art performance across panoramic optical flow datasets and is compatible with various iterative optical flow methods.", "conclusion": "The approach effectively mitigates polar distortions, setting a new benchmark for panoramic optical flow estimation and enhancing wide-field motion analysis capabilities."}}
{"id": "2506.23584", "pdf": "https://arxiv.org/pdf/2506.23584", "abs": "https://arxiv.org/abs/2506.23584", "authors": ["Renjie Liang", "Zhengkang Fan", "Jinqian Pan", "Chenkun Sun", "Russell Terry", "Jie Xu"], "title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Generating radiology reports from CT scans remains a complex task due to the\nnuanced nature of medical imaging and the variability in clinical\ndocumentation. In this study, we propose a two-stage framework for generating\nrenal radiology reports from 2D CT slices. First, we extract structured\nabnormality features using a multi-task learning model trained to identify\nlesion attributes such as location, size, enhancement, and attenuation. These\nextracted features are subsequently combined with the corresponding CT image\nand fed into a fine-tuned vision-language model to generate natural language\nreport sentences aligned with clinical findings. We conduct experiments on a\ncurated dataset of renal CT studies with manually annotated\nsentence-slice-feature triplets and evaluate performance using both\nclassification metrics and natural language generation metrics. Our results\ndemonstrate that the proposed model outperforms random baselines across all\nabnormality types, and the generated reports capture key clinical content with\nreasonable textual accuracy. This exploratory work highlights the feasibility\nof modular, feature-informed report generation for renal imaging. Future\nefforts will focus on extending this pipeline to 3D CT volumes and further\nimproving clinical fidelity in multimodal medical AI systems.", "AI": {"tldr": "The paper proposes a two-stage framework for generating renal radiology reports from CT scans, combining feature extraction and vision-language modeling.", "motivation": "Generating radiology reports from CT images is challenging due to the complexity of medical imaging and the variability in clinical documentation.", "method": "A two-stage framework is introduced: 1) feature extraction using a multi-task model for lesion attributes, and 2) report generation using a fine-tuned vision-language model combining these features with CT images.", "result": "The model surpasses random baselines in all evaluated abnormality types, producing reports that align with key clinical findings and reasonable textual accuracy.", "conclusion": "The study proves the feasibility of feature-informed report generation in renal imaging and suggests potential for extending the approach to 3D CT volumes for enhanced clinical fidelity."}}
{"id": "2506.23903", "pdf": "https://arxiv.org/pdf/2506.23903", "abs": "https://arxiv.org/abs/2506.23903", "authors": ["Hamza Rasaee", "Taha Koleilat", "Hassan Rivaz"], "title": "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 3 figures, 6 figures", "summary": "Accurate and generalizable object segmentation in ultrasound imaging remains\na significant challenge due to anatomical variability, diverse imaging\nprotocols, and limited annotated data. In this study, we propose a\nprompt-driven vision-language model (VLM) that integrates Grounding DINO with\nSAM2 to enable object segmentation across multiple ultrasound organs. A total\nof 18 public ultrasound datasets, encompassing the breast, thyroid, liver,\nprostate, kidney, and paraspinal muscle, were utilized. These datasets were\ndivided into 15 for fine-tuning and validation of Grounding DINO using Low Rank\nAdaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for\ntesting to evaluate performance in unseen distributions. Comprehensive\nexperiments demonstrate that our approach outperforms state-of-the-art\nsegmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,\nand SAMUS on most seen datasets while maintaining strong performance on unseen\ndatasets without additional fine-tuning. These results underscore the promise\nof VLMs in scalable and robust ultrasound image analysis, reducing dependence\non large, organ-specific annotated datasets. We will publish our code on\ncode.sonography.ai after acceptance.", "AI": {"tldr": "The paper introduces a vision-language model (VLM) for object segmentation in ultrasound imaging, showcasing its superior performance across diverse datasets and unseen distributions.", "motivation": "Segmenting ultrasound images is challenging due to anatomical variability, diverse imaging protocols, and limited annotated data.", "method": "The study combines Grounding DINO and SAM2 in a VLM framework, using 15 out of 18 datasets for fine-tuning with low-rank adaptation (LoRA) and 3 datasets for testing on unseen distributions.", "result": "The proposed method outperforms state-of-the-art segmentation models on most datasets and generalizes well to unseen distributions.", "conclusion": "Using VLMs can improve ultrasound image segmentation accuracy and scalability, minimizing the need for large annotated datasets."}}
{"id": "2506.23916", "pdf": "https://arxiv.org/pdf/2506.23916", "abs": "https://arxiv.org/abs/2506.23916", "authors": ["Radhika Juglan", "Marta Ligero", "Zunamys I. Carrero", "Asier Rabasco", "Tim Lenz", "Leo Misera", "Gregory Patrick Veldhuizen", "Paul Kuntke", "Hagen H. Kitzler", "Sven Nebelung", "Daniel Truhn", "Jakob Nikolas Kather"], "title": "Three-dimensional end-to-end deep learning for brain MRI analysis", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning (DL) methods are increasingly outperforming classical\napproaches in brain imaging, yet their generalizability across diverse imaging\ncohorts remains inadequately assessed. As age and sex are key neurobiological\nmarkers in clinical neuroscience, influencing brain structure and disease risk,\nthis study evaluates three of the existing three-dimensional architectures,\nnamely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window\n(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four\nindependent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study\n(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy\ncontrols), and Information eXtraction from Images (IXI, n=319). We found that\nSFCN consistently outperformed more complex architectures with AUC of 1.00\n[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for\nsex classification. For the age prediction task, SFCN demonstrated a mean\nabsolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across\nexternal datasets. Pairwise DeLong and Wilcoxon signed-rank tests with\nBonferroni corrections confirmed SFCN's superiority over Swin Transformer\nacross most cohorts (p<0.017, for three comparisons). Explainability analysis\nfurther demonstrates the regional consistency of model attention across cohorts\nand specific to each task. Our findings reveal that simpler convolutional\nnetworks outperform the denser and more complex attention-based DL\narchitectures in brain image analysis by demonstrating better generalizability\nacross different datasets.", "AI": {"tldr": "The study assesses three deep learning architectures for age and sex prediction using MRI data from diverse cohorts, finding simpler architectures like SFCN outperforming more complex ones in generalizability.", "motivation": "To investigate the generalizability of deep learning methods in brain imaging across diverse datasets, focusing on age and sex prediction.", "method": "Evaluated three DL models (SFCN, DenseNet, Swin Transformers) with MRI data from four cohorts for age and sex prediction, and analyzed model performance statistically and through explainability methods.", "result": "SFCN achieved superior performance across cohorts, with high AUCs for sex classification and lower MAE for age prediction compared to DenseNet and Swin Transformers.", "conclusion": "Simpler DL architectures, specifically SFCN, show better generalizability and performance compared to complex attention-based models in brain imaging tasks."}}
{"id": "2506.23918", "pdf": "https://arxiv.org/pdf/2506.23918", "abs": "https://arxiv.org/abs/2506.23918", "authors": ["Zhaochen Su", "Peng Xia", "Hangyu Guo", "Zhenhua Liu", "Yan Ma", "Xiaoye Qu", "Jiaqi Liu", "Yanshu Li", "Kaide Zeng", "Zhengyuan Yang", "Linjie Li", "Yu Cheng", "Heng Ji", "Junxian He", "Yi R.", "Fung"], "title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "categories": ["cs.CV"], "comment": "We maintain a real-time GitHub repository tracking progress at:\n  https://github.com/zhaochen0110/Awesome_Think_With_Images", "summary": "Recent progress in multimodal reasoning has been significantly advanced by\ntextual Chain-of-Thought (CoT), a paradigm where models conduct reasoning\nwithin language. This text-centric approach, however, treats vision as a\nstatic, initial context, creating a fundamental \"semantic gap\" between rich\nperceptual data and discrete symbolic thought. Human cognition often transcends\nlanguage, utilizing vision as a dynamic mental sketchpad. A similar evolution\nis now unfolding in AI, marking a fundamental paradigm shift from models that\nmerely think about images to those that can truly think with images. This\nemerging paradigm is characterized by models leveraging visual information as\nintermediate steps in their thought process, transforming vision from a passive\ninput into a dynamic, manipulable cognitive workspace. In this survey, we chart\nthis evolution of intelligence along a trajectory of increasing cognitive\nautonomy, which unfolds across three key stages: from external tool\nexploration, through programmatic manipulation, to intrinsic imagination. To\nstructure this rapidly evolving field, our survey makes four key contributions.\n(1) We establish the foundational principles of the think with image paradigm\nand its three-stage framework. (2) We provide a comprehensive review of the\ncore methods that characterize each stage of this roadmap. (3) We analyze the\ncritical landscape of evaluation benchmarks and transformative applications.\n(4) We identify significant challenges and outline promising future directions.\nBy providing this structured overview, we aim to offer a clear roadmap for\nfuture research towards more powerful and human-aligned multimodal AI.", "AI": {"tldr": "The paper discusses a shift in multimodal reasoning from text-based processes to a \"think with image\" paradigm, where images serve as dynamic tools for reasoning.", "motivation": "The motivation is to address the gap between perceptual data and symbolic reasoning by exploring how vision can be integrated as an active cognitive component in AI systems.", "method": "The paper presents a survey structured around a three-stage framework: (1) external tool exploration, (2) programmatic manipulation, and (3) intrinsic imagination, while reviewing methods, benchmarks, and challenges.", "result": "The survey maps the progression of methods for multimodal reasoning, evaluates their applications, and identifies trends and gaps in current approaches.", "conclusion": "The work highlights the potential of multimodal AI to achieve more human-aligned cognition by leveraging vision as a dynamic reasoning tool, offering future research directions."}}
{"id": "2506.23640", "pdf": "https://arxiv.org/pdf/2506.23640", "abs": "https://arxiv.org/abs/2506.23640", "authors": ["Ximeng Liu", "Shizhen Zhao", "Xinbing Wang"], "title": "Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Recently, researchers have explored ML-based Traffic Engineering (TE),\nleveraging neural networks to solve TE problems traditionally addressed by\noptimization. However, existing ML-based TE schemes remain impractical: they\neither fail to handle topology changes or suffer from poor scalability due to\nexcessive computational and memory overhead. To overcome these limitations, we\npropose Geminet, a lightweight and scalable ML-based TE framework that can\nhandle changing topologies. Geminet is built upon two key insights: (i) a\nmethodology that decouples neural networks from topology by learning an\niterative gradient-descent-based adjustment process, as the update rule of\ngradient descent is topology-agnostic, relying only on a few gradient-related\nquantities; (ii) shifting optimization from path-level routing weights to\nedge-level dual variables, reducing memory consumption by leveraging the fact\nthat edges are far fewer than paths. Evaluations on WAN and data center\ndatasets show that Geminet significantly improves scalability. Its neural\nnetwork size is only 0.04% to 7% of existing schemes, while handling topology\nvariations as effectively as HARP, a state-of-the-art ML-based TE approach,\nwithout performance degradation. When trained on large-scale topologies,\nGeminet consumes under 10 GiB of memory, more than eight times less than the\n80-plus GiB required by HARP, while achieving 5.45 times faster convergence\nspeed, demonstrating its potential for large-scale deployment.", "AI": {"tldr": "Geminet proposes a scalable and lightweight ML-based Traffic Engineering framework addressing topology changes, reducing memory usage, and enhancing scalability compared to existing methods like HARP.", "motivation": "Current ML-based TE approaches fail to handle topology changes or suffer from poor scalability due to high computational and memory requirements.", "method": "Geminet uses a topology-agnostic gradient-descent process and shifts optimization from path-level routing weights to edge-level dual variables, reducing memory and computational overhead.", "result": "Geminet is significantly smaller in neural network size (0.04% to 7% of others), handles topology variations effectively, uses under 10 GiB of memory, and achieves 5.45 times faster convergence compared to HARP.", "conclusion": "Geminet addresses the impracticalities of ML-based TE for large-scale usage, improving efficiency and scalability without performance compromises."}}
{"id": "2506.23963", "pdf": "https://arxiv.org/pdf/2506.23963", "abs": "https://arxiv.org/abs/2506.23963", "authors": ["Vannkinh Nom", "Souhail Bakkali", "Muhammad Muzzamil Luqman", "Mickael Coustaty", "Jean-Marc Ogier"], "title": "Evaluating the Impact of Khmer Font Types on Text Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Text recognition is significantly influenced by font types, especially for\ncomplex scripts like Khmer. The variety of Khmer fonts, each with its unique\ncharacter structure, presents challenges for optical character recognition\n(OCR) systems. In this study, we evaluate the impact of 19 randomly selected\nKhmer font types on text recognition accuracy using Pytesseract. The fonts\ninclude Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong\nChhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,\nMetal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth\nFirst. Our comparison of OCR performance across these fonts reveals that Khmer,\nOdor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,\nwhile iSeth First, Bayon, and Dangrek perform poorly. This study underscores\nthe critical importance of font selection in optimizing Khmer text recognition\nand provides valuable insights for developing more robust OCR systems.", "AI": {"tldr": "This paper examines the impact of 19 Khmer font types on OCR accuracy using Pytesseract. It identifies both high-performing and poorly performing fonts, emphasizing the importance of font choice in Khmer text recognition.", "motivation": "The motivation is to understand the challenges posed by the variety and complexity of Khmer fonts on OCR accuracy and to identify which fonts work best or poorly.", "method": "The study evaluates OCR accuracy using Pytesseract across 19 randomly selected Khmer font types, comparing their performance.", "result": "Five fonts (Khmer, Odor MeanChey, Siemreap, Sithi Manuss, and Battambang) achieve high accuracy, while three fonts (iSeth First, Bayon, and Dangrek) perform poorly.", "conclusion": "Font selection is critical for optimizing text recognition in Khmer scripts, and this study provides insights for developing more effective OCR systems."}}
{"id": "2506.23603", "pdf": "https://arxiv.org/pdf/2506.23603", "abs": "https://arxiv.org/abs/2506.23603", "authors": ["Baihe Ma", "Yanna Jiang", "Xu Wang", "Guangshen Yu", "Qin Wang", "Caijun Sun", "Chen Li", "Xuelei Qi", "Ying He", "Wei Ni", "Ren Ping Liu"], "title": "SoK: Semantic Privacy in Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains, traditional data privacy measures prove inadequate for protecting\ninformation that is implicit, contextual, or inferable - what we define as\nsemantic privacy. This Systematization of Knowledge (SoK) introduces a\nlifecycle-centric framework to analyze how semantic privacy risks emerge across\ninput processing, pretraining, fine-tuning, and alignment stages of LLMs. We\ncategorize key attack vectors and assess how current defenses, such as\ndifferential privacy, embedding encryption, edge computing, and unlearning,\naddress these threats. Our analysis reveals critical gaps in semantic-level\nprotection, especially against contextual inference and latent representation\nleakage. We conclude by outlining open challenges, including quantifying\nsemantic leakage, protecting multimodal inputs, balancing de-identification\nwith generation quality, and ensuring transparency in privacy enforcement. This\nwork aims to inform future research on designing robust, semantically aware\nprivacy-preserving techniques for LLMs.", "AI": {"tldr": "The paper introduces 'semantic privacy' risks in LLMs, analyzes attack vectors and current defenses, identifies critical gaps, and provides research directions for improved semantic-level privacy techniques.", "motivation": "To address the inadequacy of traditional privacy measures in protecting implicit, contextual, or inferable information in LLMs and propose a framework for analyzing semantic privacy risks.", "method": "Developed a lifecycle-centric framework to study privacy risks across the operational stages of LLMs, categorized attack vectors, assessed current defenses, and identified gaps and challenges.", "result": "Found significant weaknesses in current privacy defenses, particularly in protecting against contextual inference and latent representation leakage.", "conclusion": "Highlighted urgent challenges in semantic privacy, advocated for improved techniques, and aimed to guide future research toward addressing these critical gaps in privacy-preserving strategies for LLMs."}}
{"id": "2506.23972", "pdf": "https://arxiv.org/pdf/2506.23972", "abs": "https://arxiv.org/abs/2506.23972", "authors": ["Boyue Xu", "Ruichao Hou", "Tongwei Ren", "Gangshan Wu"], "title": "Visual and Memory Dual Adapter for Multi-Modal Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Prompt-learning-based multi-modal trackers have achieved promising progress\nby employing lightweight visual adapters to incorporate auxiliary modality\nfeatures into frozen foundation models. However, existing approaches often\nstruggle to learn reliable prompts due to limited exploitation of critical cues\nacross frequency and temporal domains. In this paper, we propose a novel visual\nand memory dual adapter (VMDA) to construct more robust and discriminative\nrepresentations for multi-modal tracking. Specifically, we develop a simple but\neffective visual adapter that adaptively transfers discriminative cues from\nauxiliary modality to dominant modality by jointly modeling the frequency,\nspatial, and channel-wise features. Additionally, we design the memory adapter\ninspired by the human memory mechanism, which stores global temporal cues and\nperforms dynamic update and retrieval operations to ensure the consistent\npropagation of reliable temporal information across video sequences. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\non the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,\nand RGB-Event tracking. Code and models are available at\nhttps://github.com/xuboyue1999/mmtrack.git.", "AI": {"tldr": "This paper introduces a visual and memory dual adapter (VMDA) for multi-modal tracking, improving prompt reliability by leveraging frequency and temporal cues.", "motivation": "Existing prompt-learning-based multi-modal trackers struggle with exploiting critical frequency and temporal cues, necessitating a more robust framework.", "method": "The authors propose a visual adapter to integrate auxiliary modality features adaptively and a memory adapter inspired by human memory, which stores global temporal cues for consistent propagation.", "result": "VMDA achieves state-of-the-art results across RGB-Thermal, RGB-Depth, and RGB-Event tracking tasks.", "conclusion": "The proposed VMDA framework enhances multi-modal tracking performance by creating more robust and discriminative representations, addressing limitations in prompt-learning trackers."}}
{"id": "2506.23975", "pdf": "https://arxiv.org/pdf/2506.23975", "abs": "https://arxiv.org/abs/2506.23975", "authors": ["Yuliia Kaidashova", "Bettina Finzel", "Ute Schmid"], "title": "Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance", "categories": ["cs.CV", "68T07", "I.2; I.4"], "comment": "17 pages, 6 figures, KI2025 - 48th German Conference on Artificial\n  Intelligence", "summary": "Understanding why a classification model prefers one class over another for\nan input instance is the challenge of contrastive explanation. This work\nimplements concept-based contrastive explanations for image classification by\nleveraging the similarity of instance embeddings and relevance of\nhuman-understandable concepts used by a fine-tuned deep learning model. Our\napproach extracts concepts with their relevance score, computes contrasts for\nsimilar instances, and evaluates the resulting contrastive explanations based\non explanation complexity. Robustness is tested for different image\naugmentations. Two research questions are addressed: (1) whether explanation\ncomplexity varies across different relevance ranges, and (2) whether\nexplanation complexity remains consistent under image augmentations such as\nrotation and noise. The results confirm that for our experiments higher concept\nrelevance leads to shorter, less complex explanations, while lower relevance\nresults in longer, more diffuse explanations. Additionally, explanations show\nvarying degrees of robustness. The discussion of these findings offers insights\ninto the potential of building more interpretable and robust AI systems.", "AI": {"tldr": "The paper introduces a method for providing concept-based contrastive explanations for image classification models, examining the relevance of concepts and robustness under image augmentations.", "motivation": "This research is motivated by the challenge of understanding why a classification model selects one class over another, emphasizing the importance of interpretable and robust AI systems.", "method": "The approach uses instance embeddings and human-understandable concepts from fine-tuned models to extract relevance scores, compute contrasts, and assess explanation complexity under varying conditions, including augmentations like noise and rotation.", "result": "Higher concept relevance results in shorter and less complex explanations, while lower relevance has the opposite effect. The robustness of explanations under image augmentations shows varying outcomes.", "conclusion": "The study highlights that explanation complexity is influenced by concept relevance and suggests potential strategies for creating more interpretable and robust AI models."}}
{"id": "2506.23628", "pdf": "https://arxiv.org/pdf/2506.23628", "abs": "https://arxiv.org/abs/2506.23628", "authors": ["Antonio Ojea"], "title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 9 figures, submitted to IEEE LCN Special Track on\n  Cloud-AI-Native Mobile Networks Powered by eBPF (CAMe 2025)", "summary": "Traditional Kubernetes networking struggles to meet the escalating demands of\nAI/ML and evolving Telco infrastructure. This paper introduces Kubernetes\nNetwork Drivers (KNDs), a transformative, modular, and declarative architecture\ndesigned to overcome current imperative provisioning and API limitations. KNDs\nintegrate network resource management into Kubernetes' core by utilizing\nDynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements,\nand upcoming OCI Runtime Specification changes. Our DraNet implementation\ndemonstrates declarative attachment of network interfaces, including Remote\nDirect Memory Access (RDMA) devices, significantly boosting high-performance\nAI/ML workloads. This capability enables sophisticated cloud-native\napplications and lays crucial groundwork for future Telco solutions, fostering\na \"galaxy\" of specialized KNDs for enhanced application delivery and reduced\noperational complexity.", "AI": {"tldr": "The paper proposes Kubernetes Network Drivers (KNDs), a new approach to address the challenges in Kubernetes networking for high-performance AI/ML workloads and Telco infrastructure.", "motivation": "The motivation is to address limitations in Kubernetes networking that cannot meet the demands of high-performance AI/ML applications and evolving Telco infrastructure.", "method": "The method involves creating Kubernetes Network Drivers (KNDs) using advances like Dynamic Resource Allocation (DRA), Node Resource Interface (NRI), and changes in the OCI Runtime Specification for modular and declarative network management.", "result": "The implementation, DraNet, allows for declarative attachment of advanced network interfaces such as RDMA devices, offering significant performance improvements for AI/ML workloads.", "conclusion": "This new architecture enhances cloud-native application performance, reduces operational complexity, supports future Telco solutions, and lays the foundation for a diverse ecosystem of KNDs."}}
{"id": "2506.23721", "pdf": "https://arxiv.org/pdf/2506.23721", "abs": "https://arxiv.org/abs/2506.23721", "authors": ["Gijs Luijten", "Roberto Maria Scardigno", "Lisle Faray de Paiva", "Peter Hoyer", "Jens Kleesiek", "Domenico Buongiorno", "Vitoantonio Bevilacqua", "Jan Egger"], "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Ultrasound (US) is widely accessible and radiation-free but has a steep\nlearning curve due to its dynamic nature and non-standard imaging planes.\nAdditionally, the constant need to shift focus between the US screen and the\npatient poses a challenge. To address these issues, we integrate deep learning\n(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric\nmeasurements, which are essential for clinical assessment but are traditionally\ntime-consuming and prone to fatigue. This automation allows clinicians to\nconcentrate on image interpretation rather than manual measurements.\nComplementing DL, augmented reality (AR) enhances the usability of US by\nprojecting the display directly into the clinician's field of view, improving\nergonomics and reducing the cognitive load associated with screen-to-patient\ntransitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one\nstreams directly via the application programming interface for a wireless\nsetup, while the other supports any US device with video output for broader\naccessibility. We evaluate RT feasibility and accuracy using the Open Kidney\nDataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with\nMedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model\nimplementations, measurement algorithms, and a Wi-Fi-based streaming solution,\nenhancing US training and diagnostics, especially in point-of-care settings.", "AI": {"tldr": "The paper proposes a system that uses deep learning (DL) for automated real-time kidney measurements via ultrasound (US) and enhances usability with augmented reality (AR) projected on HoloLens-2.", "motivation": "Ultrasound is widely used in clinical settings due to its accessibility and safety but has usability challenges. These include a steep learning curve, time-consuming manual measurements, and cognitive disruptions caused by shifting focus between the patient and screen.", "method": "The authors integrate DL-based semantic segmentation for real-time kidney measurements and combine it with AR to project the US display onto the clinician's field of view. Two AR-DL pipelines on HoloLens-2 are presented: a wireless API-based setup and a universal video-output-based setup.", "result": "The proposed system was evaluated using the Open Kidney Dataset and various segmentation models like nnU-Net and YOLO. Usability, feasibility, and accuracy of real-time measurements were tested, and open-source pipelines were developed for broader applications.", "conclusion": "This AR-enhanced and DL-assisted US system improves kidney measurement accuracy, ergonomics, and training, making it particularly advantageous for point-of-care diagnostics and clinical training."}}
{"id": "2506.23767", "pdf": "https://arxiv.org/pdf/2506.23767", "abs": "https://arxiv.org/abs/2506.23767", "authors": ["Xue Wen Tan", "Stanley Kok"], "title": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach", "categories": ["q-fin.RM", "cs.LG"], "comment": null, "summary": "Every publicly traded U.S. company files an annual 10-K report containing\ncritical insights into financial health and risk. We propose Tiny eXplainable\nRisk Assessor (TinyXRA), a lightweight and explainable transformer-based model\nthat automatically assesses company risk from these reports. Unlike prior work\nthat relies solely on the standard deviation of excess returns (adjusted for\nthe Fama-French model), which indiscriminately penalizes both upside and\ndownside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio\nfor more comprehensive risk assessment. We leverage TinyBERT as our encoder to\nefficiently process lengthy financial documents, coupled with a novel dynamic,\nattention-based word cloud mechanism that provides intuitive risk visualization\nwhile filtering irrelevant terms. This lightweight design ensures scalable\ndeployment across diverse computing environments with real-time processing\ncapabilities for thousands of financial documents which is essential for\nproduction systems with constrained computational resources. We employ triplet\nloss for risk quartile classification, improving over pairwise loss approaches\nin existing literature by capturing both the direction and magnitude of risk\ndifferences. Our TinyXRA achieves state-of-the-art predictive accuracy across\nseven test years on a dataset spanning 2013-2024, while providing transparent\nand interpretable risk assessments. We conduct comprehensive ablation studies\nto evaluate our contributions and assess model explanations both quantitatively\nby systematically removing highly attended words and sentences, and\nqualitatively by examining explanation coherence. The paper concludes with\nfindings, practical implications, limitations, and future research directions.", "AI": {"tldr": "The paper introduces TinyXRA, an efficient transformer-based model for assessing financial risk from company 10-K reports, providing state-of-the-art accuracy and explainable predictions.", "motivation": "To address the inadequacies of standard financial risk models and provide an explainable, computationally efficient approach for evaluating U.S. company risks.", "method": "TinyXRA builds on TinyBERT as the encoder and incorporates dynamic attention-based word cloud visualization, skewness, kurtosis, Sortino ratio, and triplet loss for risk quartile classification.", "result": "TinyXRA outperformed existing models in predictive accuracy over a 7-year test period, demonstrated scalability for real-time processing, and delivered transparent risk visualizations.", "conclusion": "TinyXRA provides an innovative, interpretable, and scalable solution for financial risk assessment, offering practical insights while acknowledging limitations and suggesting avenues for future research."}}
{"id": "2506.23634", "pdf": "https://arxiv.org/pdf/2506.23634", "abs": "https://arxiv.org/abs/2506.23634", "authors": ["Youjeong Noh", "Joon-Young Paik", "Jingun Kwon", "Eun-Sun Cho"], "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by\nconverting programs into forms that are more complex to analyze. However, MBA\nhas been increasingly exploited by malware developers to evade detection and\ncause significant real-world problems. Traditional MBA deobfuscation methods\noften consider these expressions as part of a black box and overlook their\ninternal semantic information. To bridge this gap, we propose a truth table,\nwhich is an automatically constructed semantic representation of an\nexpression's behavior that does not rely on external resources. The truth table\nis a mathematical form that represents the output of expression for all\npossible combinations of input. We also propose a general and extensible guided\nMBA deobfuscation framework (gMBA) that modifies a Transformer-based neural\nencoder-decoder Seq2Seq architecture to incorporate this semantic guidance.\nExperimental results and in-depth analysis show that integrating expression\nsemantics significantly improves performance and highlights the importance of\ninternal semantic expressions in recovering obfuscated code to its original\nform.", "AI": {"tldr": "The paper introduces a novel guided MBA deobfuscation framework (gMBA) using a truth table to efficiently recover obfuscated code.", "motivation": "To address the growing misuse of MBA obfuscation by malware developers and the limitations of traditional deobfuscation methods that ignore semantic information.", "method": "Proposes a truth table-based semantic representation for MBA expressions and a Transformer-based neural Seq2Seq model incorporating semantic guidance.", "result": "Experimental results show that the proposed framework significantly improves deobfuscation performance by using internal semantics.", "conclusion": "Incorporating expression semantics is critical for recovering obfuscated code effectively, as demonstrated by the proposed gMBA approach."}}
{"id": "2506.24039", "pdf": "https://arxiv.org/pdf/2506.24039", "abs": "https://arxiv.org/abs/2506.24039", "authors": ["Shubhabrata Mukherjee", "Jack Lang", "Obeen Kwon", "Iryna Zenyuk", "Valerie Brogden", "Adam Weber", "Daniela Ushizima"], "title": "Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data", "categories": ["cs.CV", "cs.HC"], "comment": "This manuscript is a draft on arxiv. A final version has been\n  submitted to the 59th ICPP 2025, DRAI workshop", "summary": "Zero-shot and prompt-based technologies capitalized on using frequently\noccurring images to transform visual reasoning tasks, which explains why such\ntechnologies struggle with valuable yet scarce scientific image sets. In this\nwork, we propose Zenesis, a comprehensive no-code interactive platform designed\nto minimize barriers posed by data readiness for scientific images. We develop\nlightweight multi-modal adaptation techniques that enable zero-shot operation\non raw scientific data, along with human-in-the-loop refinement and\nheuristic-based temporal enhancement options. We demonstrate the performance of\nour approach through comprehensive comparison and validation on challenging\nFocused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded\nmembranes. Zenesis significantly outperforms baseline methods, achieving an\naverage accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a\nDice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an\nIOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results\nmark a substantial improvement over traditional methods like Otsu thresholding\nand even advanced models like Segment Anything Model (SAM) when used in\nisolation. Our results demonstrate that Zenesis is a powerful tool for\nscientific applications, particularly in fields where high-quality annotated\ndatasets are unavailable, accelerating accurate analysis of experimental\nimaging.", "AI": {"tldr": "Zenesis, a no-code platform, adapts zero-shot technologies for scarce scientific images using lightweight multi-modal techniques, excelling in challenging FIB-SEM data analysis.", "motivation": "The paper addresses the challenge of adapting zero-shot and prompt-based technologies for scarce and valuable scientific image datasets, which are not well-suited for these methods.", "method": "The authors propose Zenesis, a no-code platform with multi-modal adaptation techniques for zero-shot operation on raw scientific data. It includes human-in-the-loop refinement and temporal enhancement.", "result": "Zenesis achieved high performance, significantly outperforming baseline methods, with metrics such as 0.947 accuracy and 0.858 IOU for amorphous samples and 0.987 accuracy and 0.857 IOU for crystalline samples.", "conclusion": "Zenesis is a robust, user-friendly tool that outperforms traditional and advanced segmentation models, especially valuable for fields lacking high-quality annotated datasets."}}
{"id": "2506.24063", "pdf": "https://arxiv.org/pdf/2506.24063", "abs": "https://arxiv.org/abs/2506.24063", "authors": ["Deng Li", "Aming Wu", "Yang Li", "Yaowei Wang", "Yahong Han"], "title": "Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "In practice, environments constantly change over time and space, posing\nsignificant challenges for object detectors trained based on a closed-set\nassumption, i.e., training and test data share the same distribution. To this\nend, continual test-time adaptation has attracted much attention, aiming to\nimprove detectors' generalization by fine-tuning a few specific parameters,\ne.g., BatchNorm layers. However, based on a small number of test images,\nfine-tuning certain parameters may affect the representation ability of other\nfixed parameters, leading to performance degradation. Instead, we explore a new\nmechanism, i.e., converting the fine-tuning process to a specific-parameter\ngeneration. Particularly, we first design a dual-path LoRA-based domain-aware\nadapter that disentangles features into domain-invariant and domain-specific\ncomponents, enabling efficient adaptation. Additionally, a conditional\ndiffusion-based parameter generation mechanism is presented to synthesize the\nadapter's parameters based on the current environment, preventing the\noptimization from getting stuck in local optima. Finally, we propose a\nclass-centered optimal transport alignment method to mitigate catastrophic\nforgetting. Extensive experiments conducted on various continuous domain\nadaptive object detection tasks demonstrate the effectiveness. Meanwhile,\nvisualization results show that the representation extracted by the generated\nparameters can capture more object-related information and strengthen the\ngeneralization ability.", "AI": {"tldr": "The paper proposes a novel approach to continual test-time adaptation for object detection by introducing a dual-path domain-aware adapter and a conditional diffusion-based parameter generation mechanism for better adaptation and generalization.", "motivation": "Existing object detectors struggle with changing environments as they are trained on the closed-set assumption where training and test data have the same distribution. Continual test-time adaptation can improve generalization but may lead to degraded performance due to parameter tuning on small test datasets.", "method": "The authors designed a dual-path LoRA-based domain-aware adapter to separate features into domain-invariant and domain-specific components. They also introduced a conditional diffusion-based parameter generation mechanism to adapt parameters for the current environment and mitigate optimization pitfalls, alongside a class-centered optimal transport alignment to prevent catastrophic forgetting.", "result": "The proposed method showed effectiveness across various continuous domain adaptation tasks for object detection, with improved generalization and better feature representation of objects.", "conclusion": "The approach enhances object detection in dynamic environments by disentangling domain features, creating tailored parameters for new settings, and improving robustness and generalization, as evidenced by empirical results and visualizations."}}
{"id": "2506.24085", "pdf": "https://arxiv.org/pdf/2506.24085", "abs": "https://arxiv.org/abs/2506.24085", "authors": ["Wonwoong Cho", "Yanxia Zhang", "Yan-Ying Chen", "David I. Inouye"], "title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention", "categories": ["cs.CV", "cs.AI"], "comment": "Project website is available at https://imagineforme.github.io/", "summary": "Blending visual and textual concepts into a new visual concept is a unique\nand powerful trait of human beings that can fuel creativity. However, in\npractice, cross-modal conceptual blending for humans is prone to cognitive\nbiases, like design fixation, which leads to local minima in the design space.\nIn this paper, we propose a T2I diffusion adapter \"IT-Blender\" that can\nautomate the blending process to enhance human creativity. Prior works related\nto cross-modal conceptual blending are limited in encoding a real image without\nloss of details or in disentangling the image and text inputs. To address these\ngaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend\nthe latent representations of a clean reference image with those of the noisy\ngenerated image. Combined with our novel blended attention, IT-Blender encodes\nthe real reference image without loss of details and blends the visual concept\nwith the object specified by the text in a disentangled way. Our experiment\nresults show that IT-Blender outperforms the baselines by a large margin in\nblending visual and textual concepts, shedding light on the new application of\nimage generative models to augment human creativity.", "AI": {"tldr": "The paper introduces IT-Blender, a diffusion-based model for blending real images and textual inputs to spark human creativity, overcoming issues like loss of image details and entangled inputs.", "motivation": "Humans face challenges like cognitive biases in cross-modal conceptual blending, leading to limited creativity. The paper aims to provide an automated, efficient solution to enhance this blending process.", "method": "The authors propose IT-Blender, which uses pretrained diffusion models (SD and FLUX) to blend latent representations of images and text inputs effectively. It uses a novel blended attention mechanism to maintain image details and achieve disentangled blending.", "result": "Experiment results demonstrate IT-Blender's significant superiority over baseline methods in visual and textual blending, highlighting its capability to assist creativity.", "conclusion": "IT-Blender successfully automates and improves cross-modal conceptual blending, providing a powerful tool for augmenting human creativity and expanding the applications of generative models."}}
{"id": "2506.23855", "pdf": "https://arxiv.org/pdf/2506.23855", "abs": "https://arxiv.org/abs/2506.23855", "authors": ["Travis Dick", "Alessandro Epasto", "Adel Javanmard", "Josh Karlin", "Andres Munoz Medina", "Vahab Mirrokni", "Sergei Vassilvitskii", "Peilin Zhong"], "title": "Differentially Private Synthetic Data Release for Topics API Outputs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures", "summary": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an\narea of research that has received strong interest from academics, industry,\nand regulators. Despite this interest, the empirical study of these methods is\nhindered by the lack of publicly available data. Reliable empirical analysis of\nthe privacy properties of an API, in fact, requires access to a dataset\nconsisting of realistic API outputs; however, privacy concerns prevent the\ngeneral release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API\noutputs that are simultaneously realistic enough to enable accurate study and\nprovide strong privacy protections. We focus on one Privacy-Preserving Ads\nAPIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a\nmethodology to generate a differentially-private dataset that closely matches\nthe re-identification risk properties of the real Topics API data. The use of\ndifferential privacy provides strong theoretical bounds on the leakage of\nprivate user information from this release.\n  Our methodology is based on first computing a large number of\ndifferentially-private statistics describing how output API traces evolve over\ntime. Then, we design a parameterized distribution over sequences of API traces\nand optimize its parameters so that they closely match the statistics obtained.\nFinally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset\nobtained by this methodology. We hope this will enable external researchers to\nanalyze the API in-depth and replicate prior and future work on a realistic\nlarge-scale dataset. We believe that this work will contribute to fostering\ntransparency regarding the privacy properties of Privacy-Preserving Ads APIs.", "AI": {"tldr": "The paper addresses the lack of publicly available data for studying Privacy-Preserving Ads APIs by introducing a novel methodology to create synthetic, realistic, and private API output datasets.", "motivation": "The authors aim to overcome challenges in reliably studying the privacy properties of Privacy-Preserving Ads APIs due to limited access to realistic datasets, as privacy concerns restrict public dataset sharing.", "method": "A methodology involving differential privacy to compute statistics from real API traces, design a parameterized distribution, and generate synthetic data resembling real API outputs was developed. This ensures privacy protection while enabling accurate analysis.", "result": "The authors successfully produced a differentially-private dataset modeled after the Topics API from Google Chrome's Privacy Sandbox. The synthetic dataset maintains low re-identification risks and closely resembles real API outputs.", "conclusion": "The release of this anonymized dataset fosters transparency and supports future research on Privacy-Preserving Ads APIs. The approach offers a balance between data realism and user privacy protection."}}
{"id": "2506.23678", "pdf": "https://arxiv.org/pdf/2506.23678", "abs": "https://arxiv.org/abs/2506.23678", "authors": ["Rock Yuren Pang", "K. J. Kevin Feng", "Shangbin Feng", "Chu Li", "Weijia Shi", "Yulia Tsvetkov", "Jeffrey Heer", "Katharina Reinecke"], "title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The output quality of large language models (LLMs) can be improved via\n\"reasoning\": generating segments of chain-of-thought (CoT) content to further\ncondition the model prior to producing user-facing output. While these chains\ncontain valuable information, they are verbose and lack explicit organization,\nmaking them tedious to review. Moreover, they lack opportunities for user\nfeedback, such as to remove unwanted considerations, add desired ones, or\nclarify unclear assumptions. We introduce Interactive Reasoning, an interaction\ndesign that visualizes chain-of-thought outputs as a hierarchy of topics and\nenables user review and modification. We implement interactive reasoning in\nHippo, a prototype for AI-assisted decision making in the face of uncertain\ntrade-offs. In a user study with 16 participants, we find that interactive\nreasoning in Hippo allows users to quickly identify and interrupt erroneous\ngenerations, efficiently steer the model towards customized responses, and\nbetter understand both model reasoning and model outputs. Our work contributes\nto a new paradigm that incorporates user oversight into LLM reasoning\nprocesses.", "AI": {"tldr": "This paper presents Interactive Reasoning, a system for organizing and refining the chain-of-thought content of large language models (LLMs), allowing users to interactively review, modify, and improve their outputs.", "motivation": "LLMs' chain-of-thought reasoning improves output quality but is overly verbose, unstructured, and lacks user interactivity for feedback and customization.", "method": "The authors introduced Interactive Reasoning, implemented in the prototype Hippo, to visualize reasoning as a hierarchy of topics and allow interactive user review and modification.", "result": "In a user study with 16 participants, Interactive Reasoning helped users detect and address errors, customize the model's outputs, and understand its reasoning better.", "conclusion": "Interactive Reasoning enhances LLMs by integrating user oversight, providing a new paradigm for AI-assisted decision making and improving output review and steering."}}
{"id": "2506.23869", "pdf": "https://arxiv.org/pdf/2506.23869", "abs": "https://arxiv.org/abs/2506.23869", "authors": ["Louis Bradshaw", "Honglu Fan", "Alexander Spangher", "Stella Biderman", "Simon Colton"], "title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "ISMIR (2025)", "summary": "We study the capabilities of generative autoregressive transformer models\ntrained on large amounts of symbolic solo-piano transcriptions. After first\npretraining on approximately 60,000 hours of music, we use a comparatively\nsmaller, high-quality subset, to finetune models to produce musical\ncontinuations, perform symbolic classification tasks, and produce\ngeneral-purpose contrastive MIDI embeddings by adapting the SimCLR framework to\nsymbolic music. When evaluating piano continuation coherence, our generative\nmodel outperforms leading symbolic generation techniques and remains\ncompetitive with proprietary audio generation models. On MIR classification\nbenchmarks, frozen representations from our contrastive model achieve\nstate-of-the-art results in linear probe experiments, while direct finetuning\ndemonstrates the generalizability of pretrained representations, often\nrequiring only a few hundred labeled examples to specialize to downstream\ntasks.", "AI": {"tldr": "The paper explores generative autoregressive transformer models trained on symbolic piano transcriptions, achieving strong results in music generation, classification, and embedding tasks.", "motivation": "To enhance the understanding and application of transformer models in symbolic music tasks, addressing generation coherence, classification, and representational abilities with limited data.", "method": "The researchers first pretrained models on a large dataset of 60,000 hours of symbolic music and fine-tuned them on a smaller, high-quality dataset. They adapted the SimCLR framework for contrastive MIDI embeddings and evaluated models on music continuation and benchmark tasks.", "result": "The generative model demonstrated superior coherence in music continuation compared to symbolic methods and remained competitive with audio generation models. In classification, contrastive MIDI embeddings achieved state-of-the-art results, requiring minimal labeled data for downstream applications.", "conclusion": "Generative transformer models with pretraining on vast datasets, followed by fine-tuning, show promise for symbolic music tasks, including generation and efficient classification with compact labeled datasets."}}
{"id": "2506.24092", "pdf": "https://arxiv.org/pdf/2506.24092", "abs": "https://arxiv.org/abs/2506.24092", "authors": ["Moein Heidari", "Yasamin Medghalchi", "Mahdi Khoursha", "Reza Rezaeian", "Ilker Hacihaliloglu"], "title": "WaRA: Wavelet Low Rank Adaptation", "categories": ["cs.CV", "eess.IV"], "comment": "Submitted to BMVC 2025", "summary": "Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across\nvarious applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its\nextensions have emerged as particularly effective, allowing efficient model\nadaptation while significantly reducing computational overhead. However,\nexisting approaches typically rely on global low-rank factorizations, which\noverlook local or multi-scale structure, failing to capture complex patterns in\nthe weight updates. To address this, we propose WaRA, a novel PEFT method that\nleverages wavelet transforms to decompose the weight update matrix into a\nmulti-resolution representation. By performing low-rank factorization in the\nwavelet domain and reconstructing updates through an inverse transform, WaRA\nobtains compressed adaptation parameters that harness multi-resolution\nanalysis, enabling it to capture both coarse and fine-grained features while\nproviding greater flexibility and sparser representations than standard LoRA.\nThrough comprehensive experiments and analysis, we demonstrate that WaRA\nperforms superior on diverse vision tasks, including image generation,\nclassification, and semantic segmentation, significantly enhancing generated\nimage quality while reducing computational complexity. Although WaRA was\nprimarily designed for vision tasks, we further showcase its effectiveness in\nlanguage tasks, highlighting its broader applicability and generalizability.\nThe code is publicly available at\n\\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.", "AI": {"tldr": "WaRA is a new parameter-efficient fine-tuning method that uses wavelet transforms for multi-resolution weight updates, outperforming existing techniques like LoRA in vision and language tasks.", "motivation": "Existing parameter-efficient fine-tuning techniques like LoRA rely on global low-rank factorizations, which fail to capture local or multi-scale patterns in weight updates.", "method": "WaRA employs wavelet transforms to decompose weight update matrices into multi-resolution representations, performs low-rank factorization in the wavelet domain, and reconstructs updates via inverse transforms.", "result": "WaRA consistently outperforms conventional PEFT methods like LoRA on vision tasks, improving image quality and reducing computational complexity while showing effectiveness in language tasks as well.", "conclusion": "WaRA provides a flexible and efficient alternative to existing PEFT methods by offering multi-resolution adaptive parameters, demonstrating superior performance across vision and language tasks."}}
{"id": "2506.23873", "pdf": "https://arxiv.org/pdf/2506.23873", "abs": "https://arxiv.org/abs/2506.23873", "authors": ["Yuexuan Kong", "Gabriel Meseguer-Brocal", "Vincent Lostanlen", "Mathieu Lagrange", "Romain Hennequin"], "title": "Emergent musical properties of a transformer under contrastive self-supervised learning", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "Accepted at ISMIR 2025", "summary": "In music information retrieval (MIR), contrastive self-supervised learning\nfor general-purpose representation models is effective for global tasks such as\nautomatic tagging. However, for local tasks such as chord estimation, it is\nwidely assumed that contrastively trained general-purpose self-supervised\nmodels are inadequate and that more sophisticated SSL is necessary; e.g.,\nmasked modeling. Our paper challenges this assumption by revealing the\npotential of contrastive SSL paired with a transformer in local MIR tasks. We\nconsider a lightweight vision transformer with one-dimensional patches in the\ntime--frequency domain (ViT-1D) and train it with simple contrastive SSL\nthrough normalized temperature-scaled cross-entropy loss (NT-Xent). Although\nNT-Xent operates only over the class token, we observe that, potentially thanks\nto weight sharing, informative musical properties emerge in ViT-1D's sequence\ntokens. On global tasks, the temporal average of class and sequence tokens\noffers a performance increase compared to the class token alone, showing useful\nproperties in the sequence tokens. On local tasks, sequence tokens perform\nunexpectedly well, despite not being specifically trained for. Furthermore,\nhigh-level musical features such as onsets emerge from layer-wise attention\nmaps and self-similarity matrices show different layers capture different\nmusical dimensions. Our paper does not focus on improving performance but\nadvances the musical interpretation of transformers and sheds light on some\noverlooked abilities of contrastive SSL paired with transformers for sequence\nmodeling in MIR.", "AI": {"tldr": "The paper explores the surprising effectiveness of contrastive self-supervised learning (SSL) with transformers for local tasks in music information retrieval, like chord estimation, challenging conventional assumptions.", "motivation": "To challenge the widely held belief that contrastive-trained self-supervised models are unsuitable for local music information retrieval tasks and explore their potential capabilities.", "method": "The authors use a lightweight vision transformer (ViT-1D) that processes one-dimensional patches in the time-frequency domain, trained using the normalized temperature-scaled cross-entropy loss (NT-Xent), to investigate its performance on MIR tasks.", "result": "Sequence tokens in the transformer showed unexpected utility for local tasks, despite not being explicitly trained for them, while global tasks benefitted from combining class and sequence tokens. Emergent features like onsets were observed, highlighting transformative capacities.", "conclusion": "The study advances understanding of transformers in MIR, revealing overlooked potentials of contrastive SSL for local and global tasks and shedding light on musical feature emergence through layer analyses."}}
{"id": "2506.24096", "pdf": "https://arxiv.org/pdf/2506.24096", "abs": "https://arxiv.org/abs/2506.24096", "authors": ["Antoine Gu\u00e9don", "Diego Gomez", "Nissim Maruani", "Bingchen Gong", "George Drettakis", "Maks Ovsjanikov"], "title": "MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction", "categories": ["cs.CV"], "comment": "10 pages. A presentation video of our approach is available at\n  https://youtu.be/_SGNhhNz0fE", "summary": "While recent advances in Gaussian Splatting have enabled fast reconstruction\nof high-quality 3D scenes from images, extracting accurate surface meshes\nremains a challenge. Current approaches extract the surface through costly\npost-processing steps, resulting in the loss of fine geometric details or\nrequiring significant time and leading to very dense meshes with millions of\nvertices. More fundamentally, the a posteriori conversion from a volumetric to\na surface representation limits the ability of the final mesh to preserve all\ngeometric structures captured during training. We present MILo, a novel\nGaussian Splatting framework that bridges the gap between volumetric and\nsurface representations by differentiably extracting a mesh from the 3D\nGaussians. We design a fully differentiable procedure that constructs the\nmesh-including both vertex locations and connectivity-at every iteration\ndirectly from the parameters of the Gaussians, which are the only quantities\noptimized during training. Our method introduces three key technical\ncontributions: a bidirectional consistency framework ensuring both\nrepresentations-Gaussians and the extracted mesh-capture the same underlying\ngeometry during training; an adaptive mesh extraction process performed at each\ntraining iteration, which uses Gaussians as differentiable pivots for Delaunay\ntriangulation; a novel method for computing signed distance values from the 3D\nGaussians that enables precise surface extraction while avoiding geometric\nerosion. Our approach can reconstruct complete scenes, including backgrounds,\nwith state-of-the-art quality while requiring an order of magnitude fewer mesh\nvertices than previous methods. Due to their light weight and empty interior,\nour meshes are well suited for downstream applications such as physics\nsimulations or animation.", "AI": {"tldr": "MILo introduces a novel Gaussian Splatting framework to extract efficient and accurate surface meshes directly during training without post-processing, achieving state-of-the-art quality with fewer vertices.", "motivation": "The motivation stems from the limitations of current approaches in extracting surface meshes from Gaussian Splatting. Existing methods either lose fine geometric details, require significant computational time, or produce overly dense meshes. Furthermore, the post-processing nature of these methods limits the preservation of geometric structures.", "method": "MILo develops a fully differentiable framework to extract a mesh directly from the parameters of 3D Gaussians during training. Three technical contributions are proposed: bidirectional consistency between volumetric and surface representations, adaptive mesh extraction using Gaussians as pivots for Delaunay triangulation, and a novel method for computing signed distance values.", "result": "MILo achieves state-of-the-art mesh reconstruction quality, is capable of capturing complete scenes, and requires an order of magnitude fewer mesh vertices compared to previous methods.", "conclusion": "MILo bridges the gap between volumetric and surface representations by enabling efficient and high-quality mesh extraction during training. Its lightweight and efficient mesh structure makes it suitable for various downstream applications like physics simulations and animations."}}
{"id": "2506.24102", "pdf": "https://arxiv.org/pdf/2506.24102", "abs": "https://arxiv.org/abs/2506.24102", "authors": ["Xiangtai Li", "Tao Zhang", "Yanwei Li", "Haobo Yuan", "Shihao Chen", "Yikang Zhou", "Jiahao Meng", "Yueyi Sun", "Shilin Xu", "Lu Qi", "Tianheng Cheng", "Yi Lin", "Zilong Huang", "Wenhao Huang", "Jiashi Feng", "Guang Shi"], "title": "DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World", "categories": ["cs.CV"], "comment": "Datasets and Models: https://github.com/lxtGH/DenseWorld-1M", "summary": "Multimodal Large Language Models (MLLMs) demonstrate a complex understanding\nof scenes, benefiting from large-scale and high-quality datasets. Most existing\ncaption datasets lack the ground locations and relations for visual entities.\nSeveral grounded caption datasets face the problems of missing detailed\ndescriptions, relations, and massive object descriptions on high-resolution\nimages. To fill this gap for the community, we present DenseWorld-1M, the first\nmassive, detailed, dense grounded caption dataset in the real world. We design\na three-stage labeling pipeline, containing open-world perception, detailed\nobject caption generation, and dense caption merging. The first stage obtains\nentity-level masks and labels. The second stage generates the object-level,\ndetailed captions with the guidance of masks and labels from the first stage.\nThe final stage merges object captions and masks into spatial and relational\ndense captions. To accelerate the labeling process and improve caption quality,\nwe present two VLM models: the Detailed Region Caption model and the Spatial\nCaption Merging model. Extensive experiments on various settings, including\nvision-language understanding, visual grounding, and region caption generation,\ndemonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.", "AI": {"tldr": "The paper introduces DenseWorld-1M, a large-scale, detailed grounded visual caption dataset addressing shortcomings in existing resources by using a three-stage labeling pipeline and novel VLM models.", "motivation": "Existing caption datasets lack detailed object descriptions, spatial relations, and grounding information for visual entities, particularly in high-resolution images.", "method": "The authors propose a three-stage labeling pipeline: (1) open-world perception to obtain entity-level masks and labels, (2) detailed captions for objects using masks and labels, and (3) merging captions into spatially and relationally dense descriptions. They also introduce two VLM models to enhance the labeling process.", "result": "DenseWorld-1M provides detailed grounded captions, successfully improving vision-language tasks like visual grounding and region caption generation in experiments.", "conclusion": "DenseWorld-1M and the associated labeling models fill critical gaps in current caption datasets, enhancing multimodal machine learning research and applications."}}
{"id": "2506.24113", "pdf": "https://arxiv.org/pdf/2506.24113", "abs": "https://arxiv.org/abs/2506.24113", "authors": ["Kaiwen Zhang", "Zhenyu Tang", "Xiaotao Hu", "Xingang Pan", "Xiaoyang Guo", "Yuan Liu", "Jingwei Huang", "Li Yuan", "Qian Zhang", "Xiao-Xiao Long", "Xun Cao", "Wei Yin"], "title": "Epona: Autoregressive Diffusion World Model for Autonomous Driving", "categories": ["cs.CV"], "comment": "ICCV2025, Project Page: https://kevin-thu.github.io/Epona/", "summary": "Diffusion models have demonstrated exceptional visual quality in video\ngeneration, making them promising for autonomous driving world modeling.\nHowever, existing video diffusion-based world models struggle with\nflexible-length, long-horizon predictions and integrating trajectory planning.\nThis is because conventional video diffusion models rely on global joint\ndistribution modeling of fixed-length frame sequences rather than sequentially\nconstructing localized distributions at each timestep. In this work, we propose\nEpona, an autoregressive diffusion world model that enables localized\nspatiotemporal distribution modeling through two key innovations: 1) Decoupled\nspatiotemporal factorization that separates temporal dynamics modeling from\nfine-grained future world generation, and 2) Modular trajectory and video\nprediction that seamlessly integrate motion planning with visual modeling in an\nend-to-end framework. Our architecture enables high-resolution, long-duration\ngeneration while introducing a novel chain-of-forward training strategy to\naddress error accumulation in autoregressive loops. Experimental results\ndemonstrate state-of-the-art performance with 7.4\\% FVD improvement and minutes\nlonger prediction duration compared to prior works. The learned world model\nfurther serves as a real-time motion planner, outperforming strong end-to-end\nplanners on NAVSIM benchmarks. Code will be publicly available at\n\\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.", "AI": {"tldr": "Epona introduces a novel autoregressive diffusion world model for long-horizon video generation and integrated trajectory planning, achieving state-of-the-art results.", "motivation": "There is a need for video generation models that handle flexible-length, long-horizon predictions and integrate trajectory planning for autonomous driving applications.", "method": "Epona introduces localized spatiotemporal distribution modeling by decoupling spatiotemporal factors and using modular trajectory and video prediction. A chain-of-forward training strategy addresses error accumulation.", "result": "Experimental results show Epona achieves 7.4% improvement in FVD and enables minutes-long video predictions. It also excels in real-time motion planning on NAVSIM benchmarks.", "conclusion": "Epona's innovations advance video diffusion-based world modeling, achieving superior prediction durations and planning capabilities, making it a strong candidate for autonomous driving applications."}}
{"id": "2506.23909", "pdf": "https://arxiv.org/pdf/2506.23909", "abs": "https://arxiv.org/abs/2506.23909", "authors": ["David B\u00e1lik", "Martin Jure\u010dek", "Mark Stamp"], "title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This work addresses the challenge of malware classification using machine\nlearning by developing a novel dataset labeled at both the malware type and\nfamily levels. Raw binaries were collected from sources such as VirusShare, VX\nUnderground, and MalwareBazaar, and subsequently labeled with family\ninformation parsed from binary names and type-level labels integrated from\nClarAVy. The dataset includes 14 malware types and 17 malware families, and was\nprocessed using a unified feature extraction pipeline based on static analysis,\nparticularly extracting features from Portable Executable headers, to support\nadvanced classification tasks. The evaluation was focused on three key\nclassification tasks. In the binary classification of malware versus benign\nsamples, Random Forest and XGBoost achieved high accuracy on the full datasets,\nreaching 98.5% for type-based detection and 98.98% for family-based detection.\nWhen using truncated datasets of 1,000 samples to assess performance under\nlimited data conditions, both models still performed strongly, achieving 97.6%\nfor type-based detection and 98.66% for family-based detection. For interclass\nclassification, which distinguishes between malware types or families, the\nmodels reached up to 97.5% accuracy on type-level tasks and up to 93.7% on\nfamily-level tasks. In the multiclass classification setting, which assigns\nsamples to the correct type or family, SVM achieved 81.1% accuracy on type\nlabels, while Random Forest and XGBoost reached approximately 73.4% on family\nlabels. The results highlight practical trade-offs between accuracy and\ncomputational cost, and demonstrate that labeling at both the type and family\nlevels enables more fine-grained and insightful malware classification. The\nwork establishes a robust foundation for future research on advanced malware\ndetection and classification.", "AI": {"tldr": "This paper creates a novel malware dataset labeled at both type and family levels and demonstrates high classification performance using machine learning techniques.", "motivation": "The paper aims to address the challenge of malware classification by building a robust and fine-grained dataset labeled at both malware type and family levels, enhancing the understanding of malware identification.", "method": "The authors collected raw binary data from sources like VirusShare and MalwareBazaar, labeled the malware data using family and type-level information, processed it using static analysis focusing on Portable Executable headers, and evaluated classification tasks using Random Forest, XGBoost, and SVM models.", "result": "The models achieved high accuracy in binary classification (up to 98.98%), interclass classification (up to 97.5% for type and 93.7% for family levels), and multiclass classification (up to 81.1% for type and 73.4% for family levels).", "conclusion": "This study provides an advanced dataset and demonstrates the effectiveness of machine learning techniques for malware classification, emphasizing type and family-level labeling to enable more detailed analysis and future research development."}}
{"id": "2506.24121", "pdf": "https://arxiv.org/pdf/2506.24121", "abs": "https://arxiv.org/abs/2506.24121", "authors": ["Sisi Dai", "Xinxin Su", "Boyan Wan", "Ruizhen Hu", "Kai Xu"], "title": "TextMesh4D: High-Quality Text-to-4D Mesh Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in diffusion generative models significantly advanced\nimage, video, and 3D content creation from user-provided text prompts. However,\nthe challenging problem of dynamic 3D content generation (text-to-4D) with\ndiffusion guidance remains largely unexplored. In this paper, we introduce\nTextMesh4D, a novel framework for high-quality text-to-4D generation. Our\napproach leverages per-face Jacobians as a differentiable mesh representation\nand decomposes 4D generation into two stages: static object creation and\ndynamic motion synthesis. We further propose a flexibility-rigidity\nregularization term to stabilize Jacobian optimization under video diffusion\npriors, ensuring robust geometric performance. Experiments demonstrate that\nTextMesh4D achieves state-of-the-art results in terms of temporal consistency,\nstructural fidelity, and visual realism. Moreover, TextMesh4D operates with a\nlow GPU memory overhead-requiring only a single 24GB GPU-offering a\ncost-effective yet high-quality solution for text-driven 4D mesh generation.\nThe code will be released to facilitate future research in text-to-4D\ngeneration.", "AI": {"tldr": "TextMesh4D introduces a novel framework for generating dynamic 3D content (text-to-4D) using diffusion models, achieving new state-of-the-art performance.", "motivation": "Exploring the largely unaddressed challenge of generating dynamic 3D content (4D) from text prompts using diffusion guidance.", "method": "TextMesh4D employs per-face Jacobians for mesh representation, decomposes 4D generation into object creation and motion synthesis, and adds a flexibility-rigidity regularization term for stability.", "result": "The model demonstrates state-of-the-art temporal consistency, structural fidelity, and visual realism while being cost-effective, requiring only a single 24GB GPU.", "conclusion": "TextMesh4D provides a robust, efficient solution to text-to-4D mesh generation, setting a new benchmark and releasing code for further research."}}
{"id": "2506.23914", "pdf": "https://arxiv.org/pdf/2506.23914", "abs": "https://arxiv.org/abs/2506.23914", "authors": ["Evan Bell", "Daniel A. Serino", "Ben S. Southworth", "Trevor Wilcox", "Marc L. Klasky"], "title": "Learning robust parameter inference and density reconstruction in flyer plate impact experiments", "categories": ["physics.comp-ph", "cs.LG"], "comment": "24 pages, 21 figures", "summary": "Estimating physical parameters or material properties from experimental\nobservations is a common objective in many areas of physics and material\nscience. In many experiments, especially in shock physics, radiography is the\nprimary means of observing the system of interest. However, radiography does\nnot provide direct access to key state variables, such as density, which\nprevents the application of traditional parameter estimation approaches. Here\nwe focus on flyer plate impact experiments on porous materials, and resolving\nthe underlying parameterized equation of state (EoS) and crush porosity model\nparameters given radiographic observation(s). We use machine learning as a tool\nto demonstrate with high confidence that using only high impact velocity data\ndoes not provide sufficient information to accurately infer both EoS and crush\nmodel parameters, even with fully resolved density fields or a dynamic sequence\nof images. We thus propose an observable data set consisting of low and high\nimpact velocity experiments/simulations that capture different regimes of\ncompaction and shock propagation, and proceed to introduce a generative machine\nlearning approach which produces a posterior distribution of physical\nparameters directly from radiographs. We demonstrate the effectiveness of the\napproach in estimating parameters from simulated flyer plate impact\nexperiments, and show that the obtained estimates of EoS and crush model\nparameters can then be used in hydrodynamic simulations to obtain accurate and\nphysically admissible density reconstructions. Finally, we examine the\nrobustness of the approach to model mismatches, and find that the learned\napproach can provide useful parameter estimates in the presence of\nout-of-distribution radiographic noise and previously unseen physics, thereby\npromoting a potential breakthrough in estimating material properties from\nexperimental radiographic images.", "AI": {"tldr": "This paper explores a machine learning approach to estimate material properties (EoS and crush model parameters) from radiographic observations, focusing on porous materials impacted at varied velocities.", "motivation": "Inferring physical parameters like density from radiographs is challenging because radiography does not directly observe key state variables, limiting traditional parameter estimation methods.", "method": "The authors combine low and high impact velocity datasets and utilize a generative machine learning framework to produce posterior distributions of material parameters from radiographs.", "result": "The method effectively estimates EoS and crush model parameters, enabling accurate and physically consistent density reconstructions in hydrodynamic simulations, even with model mismatches and unseen physics.", "conclusion": "This approach represents a significant advancement in using experimental radiographs for parameter estimation, promoting robust and reliable material property inference despite noisy or unseen conditions."}}
{"id": "2506.24123", "pdf": "https://arxiv.org/pdf/2506.24123", "abs": "https://arxiv.org/abs/2506.24123", "authors": ["Yue Ma", "Qingyan Bai", "Hao Ouyang", "Ka Leong Cheng", "Qiuyu Wang", "Hongyu Liu", "Zichen Liu", "Haofan Wang", "Jingye Chen", "Yujun Shen", "Qifeng Chen"], "title": "Calligrapher: Freestyle Text Image Customization", "categories": ["cs.CV"], "comment": "Project page: https://calligrapher2025.github.io/Calligrapher Code:\n  https://github.com/Calligrapher2025/Calligrapher", "summary": "We introduce Calligrapher, a novel diffusion-based framework that\ninnovatively integrates advanced text customization with artistic typography\nfor digital calligraphy and design applications. Addressing the challenges of\nprecise style control and data dependency in typographic customization, our\nframework incorporates three key technical contributions. First, we develop a\nself-distillation mechanism that leverages the pre-trained text-to-image\ngenerative model itself alongside the large language model to automatically\nconstruct a style-centric typography benchmark. Second, we introduce a\nlocalized style injection framework via a trainable style encoder, which\ncomprises both Qformer and linear layers, to extract robust style features from\nreference images. An in-context generation mechanism is also employed to\ndirectly embed reference images into the denoising process, further enhancing\nthe refined alignment of target styles. Extensive quantitative and qualitative\nevaluations across diverse fonts and design contexts confirm Calligrapher's\naccurate reproduction of intricate stylistic details and precise glyph\npositioning. By automating high-quality, visually consistent typography,\nCalligrapher surpasses traditional models, empowering creative practitioners in\ndigital art, branding, and contextual typographic design.", "AI": {"tldr": "The paper introduces Calligrapher, a system that integrates text customization and typography using diffusion-based methods for flexible calligraphy and design tasks.", "motivation": "To address challenges in precisely controlling style and reducing data dependency in typographic customization for digital design.", "method": "The approach involves three innovations: a self-distillation mechanism to create a style-centric typography benchmark, a trainable style encoder for localized style injection, and in-context generation to embed reference images during the denoising process.", "result": "Calligrapher demonstrates accurate reproduction of stylistic details and glyph positioning, validated through extensive evaluations across various fonts and designs.", "conclusion": "The framework surpasses traditional models by streamlining typography creation, aiding professionals in digital art, branding, and contextual design."}}
{"id": "2506.24125", "pdf": "https://arxiv.org/pdf/2506.24125", "abs": "https://arxiv.org/abs/2506.24125", "authors": ["Jiacheng Cui", "Xinyue Bi", "Yaxin Luo", "Xiaohan Zhao", "Jiacheng Liu", "Zhiqiang Shen"], "title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation", "categories": ["cs.CV", "cs.AI"], "comment": "Code at: https://github.com/Jiacheng8/FADRM", "summary": "Residual connection has been extensively studied and widely applied at the\nmodel architecture level. However, its potential in the more challenging\ndata-centric approaches remains unexplored. In this work, we introduce the\nconcept of Data Residual Matching for the first time, leveraging data-level\nskip connections to facilitate data generation and mitigate data information\nvanishing. This approach maintains a balance between newly acquired knowledge\nthrough pixel space optimization and existing core local information\nidentification within raw data modalities, specifically for the dataset\ndistillation task. Furthermore, by incorporating optimization-level\nrefinements, our method significantly improves computational efficiency,\nachieving superior performance while reducing training time and peak GPU memory\nusage by 50%. Consequently, the proposed method Fast and Accurate Data Residual\nMatching for Dataset Distillation (FADRM) establishes a new state-of-the-art,\ndemonstrating substantial improvements over existing methods across multiple\ndataset benchmarks in both efficiency and effectiveness. For instance, with\nResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the\nmethod achieves 47.7% test accuracy in single-model dataset distillation and\n50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and\noutperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%\nand +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.", "AI": {"tldr": "The paper introduces Data Residual Matching (FADRM), which applies residual connections at the data level to improve dataset distillation. The method outperforms existing approaches with enhanced efficiency and effectiveness.", "motivation": "The motivation is to explore the potential of residual connections in data-centric approaches, specifically dataset distillation, where traditional methods face challenges such as vanishing data information and slow training.", "method": "This work introduces Data Residual Matching, leveraging data-level skip connections and optimization refinements to balance pixel space optimization with core information identification. The method improves computational efficiency and resource usage.", "result": "FADRM achieves state-of-the-art results, with notable benchmarks like 47.7% test accuracy for single-model and 50.0% for multi-model dataset distillation in ImageNet-1K, surpassing methods like RDED, EDC, and CV-DD.", "conclusion": "The proposed FADRM method enhances dataset distillation by improving efficiency, reducing training costs (GPU memory by 50%), and delivering superior accuracy, making it a new state-of-the-art approach."}}
{"id": "2506.24127", "pdf": "https://arxiv.org/pdf/2506.24127", "abs": "https://arxiv.org/abs/2506.24127", "authors": ["Matthew Gwilliam", "Roy Zhang", "Namitha Padmanabhan", "Hongyang Du", "Abhinav Shrivastava"], "title": "How to Design and Train Your Implicit Neural Representation for Video Compression", "categories": ["cs.CV"], "comment": "21 pages, 41 figures, 5 tables", "summary": "Implicit neural representation (INR) methods for video compression have\nrecently achieved visual quality and compression ratios that are competitive\nwith traditional pipelines. However, due to the need for per-sample network\ntraining, the encoding speeds of these methods are too slow for practical\nadoption. We develop a library to allow us to disentangle and review the\ncomponents of methods from the NeRV family, reframing their performance in\nterms of not only size-quality trade-offs, but also impacts on training time.\nWe uncover principles for effective video INR design and propose a\nstate-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When\nall methods are given equal training time (equivalent to 300 NeRV epochs) for 7\ndifferent UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared\nto the best-performing alternative for each video in our NeRV library. We then\ntackle the encoding speed issue head-on by investigating the viability of\nhyper-networks, which predict INR weights from video inputs, to disentangle\ntraining from encoding to allow for real-time encoding. We propose masking the\nweights of the predicted INR during training to allow for variable, higher\nquality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at\n0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by\n0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar\nspeeds. Our project website is available at https://mgwillia.github.io/vinrb/\nand our code is available at https://github.com/mgwillia/vinrb.", "AI": {"tldr": "This paper proposes Rabbit NeRV (RNeRV), an improved implicit neural representation (INR) architecture for video compression, enhancing visual quality, compression, and encoding speed.", "motivation": "To address the slow encoding speed of existing INR-based video compression methods and improve performance in terms of visual quality and compression efficiency.", "method": "The authors created a library to analyze the NeRV family, uncover components for effective INR design, and proposed RNeRV for improved compression. They also explored hyper-networks to enable real-time encoding using INR weight prediction and weight masking techniques.", "result": "RNeRV achieved +1.27% average PSNR improvement over competitors for 1080p UVG videos when trained equally. With hyper-networks and masking, it achieved 1.7%-2.7% PSNR/MS-SSIM improvements at similar bpp and speed.", "conclusion": "RNeRV demonstrates state-of-the-art video compression quality with improved encoding speeds using hyper-network innovations, enhancing practical viability."}}
{"id": "2506.21629", "pdf": "https://arxiv.org/pdf/2506.21629", "abs": "https://arxiv.org/abs/2506.21629", "authors": ["Chenhao Zhang", "Yezhi Shen", "Fengqing Zhu"], "title": "ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes", "categories": ["cs.GR", "cs.CV"], "comment": "6 pages, Source code is available at\n  https://github.com/Chenhao-Z/ICP-3DGS. To appear at ICIP 2025", "summary": "In recent years, neural rendering methods such as NeRFs and 3D Gaussian\nSplatting (3DGS) have made significant progress in scene reconstruction and\nnovel view synthesis. However, they heavily rely on preprocessed camera poses\nand 3D structural priors from structure-from-motion (SfM), which are\nchallenging to obtain in outdoor scenarios. To address this challenge, we\npropose to incorporate Iterative Closest Point (ICP) with optimization-based\nrefinement to achieve accurate camera pose estimation under large camera\nmovements. Additionally, we introduce a voxel-based scene densification\napproach to guide the reconstruction in large-scale scenes. Experiments\ndemonstrate that our approach ICP-3DGS outperforms existing methods in both\ncamera pose estimation and novel view synthesis across indoor and outdoor\nscenes of various scales. Source code is available at\nhttps://github.com/Chenhao-Z/ICP-3DGS.", "AI": {"tldr": "The paper introduces ICP-3DGS, a method enhancing camera pose estimation and scene reconstruction for neural rendering without requiring prior 3D structural information.", "motivation": "Neural rendering methods like NeRFs and 3D Gaussian Splatting struggle in outdoor scenarios due to dependence on preprocessed camera poses and 3D priors.", "method": "The paper integrates Iterative Closest Point (ICP) with optimization-based refinement for accurate camera pose estimation and uses voxel-based scene densification for large-scale scene guidance.", "result": "The proposed ICP-3DGS method outperforms existing approaches in camera pose estimation and novel view synthesis for both indoor and outdoor scenes of different scales.", "conclusion": "ICP-3DGS overcomes limitations in existing neural rendering techniques by providing a more effective solution for scene reconstruction and novel view synthesis in challenging scenarios."}}
{"id": "2506.23952", "pdf": "https://arxiv.org/pdf/2506.23952", "abs": "https://arxiv.org/abs/2506.23952", "authors": ["Stefan Buijsman", "Sarah Carter", "Juan Pablo Berm\u00fadez"], "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action.", "AI": {"tldr": "The study explores how AI decision-support systems impact domain-specific autonomy, comprising skilled competence and authentic value-formation. It identifies challenges and suggests a socio-technical framework to preserve autonomy while benefiting from AI.", "motivation": "AI systems are increasingly integrated into decision-making processes in various domains, but their effects on domain-specific autonomy, which is critical for self-governed actions within specific expertise areas, are not well understood.", "method": "The paper analyzes prior research and empirical cases from medical, financial, and educational sectors to identify the impacts of AI on skilled competence and authentic value-formation. It proposes design patterns to address these issues.", "result": "The absence of reliable failure indicators and unconscious value shifts were found to erode domain-specific autonomy. The proposed solutions include socio-technical patterns like role specification, defeater mechanisms, and reflective support.", "conclusion": "AI systems can either enhance or undermine human agency in specialized domains. By adopting the suggested framework, developers can design AI systems that preserve domain-specific autonomy while leveraging AI's abilities."}}
{"id": "2506.22467", "pdf": "https://arxiv.org/pdf/2506.22467", "abs": "https://arxiv.org/abs/2506.22467", "authors": ["Roy Colglazier", "Jisoo Lee", "Haoyu Dong", "Hanxue Gu", "Yaqian Chen", "Joseph Cao", "Zafer Yildiz", "Zhonghao Liu", "Nicholas Konz", "Jichen Yang", "Jikai Zhang", "Yuwen Chen", "Lin Li", "Adrian Camarena", "Maciej A. Mazurowski"], "title": "SegmentAnyMuscle: A universal muscle segmentation model across different locations in MRI", "categories": ["eess.SP", "cs.CV"], "comment": "24 pages, 6 figures", "summary": "The quantity and quality of muscles are increasingly recognized as important\npredictors of health outcomes. While MRI offers a valuable modality for such\nassessments, obtaining precise quantitative measurements of musculature remains\nchallenging. This study aimed to develop a publicly available model for muscle\nsegmentation in MRIs and demonstrate its applicability across various\nanatomical locations and imaging sequences. A total of 362 MRIs from 160\npatients at a single tertiary center (Duke University Health System, 2016-2020)\nwere included, with 316 MRIs from 114 patients used for model development. The\nmodel was tested on two separate sets: one with 28 MRIs representing common\nsequence types, achieving an average Dice Similarity Coefficient (DSC) of\n88.45%, and another with 18 MRIs featuring less frequent sequences and\nabnormalities such as muscular atrophy, hardware, and significant noise,\nachieving 86.21% DSC. These results demonstrate the feasibility of a fully\nautomated deep learning algorithm for segmenting muscles on MRI across diverse\nsettings. The public release of this model enables consistent, reproducible\nresearch into the relationship between musculature and health.", "AI": {"tldr": "This paper presents a deep learning model for automated muscle segmentation in MRI, achieving high accuracy across diverse imaging settings, and releases it publicly for research use.", "motivation": "The motivation is to address the challenge of obtaining precise quantitative muscle measurements from MRI, which are crucial predictors of health outcomes.", "method": "The paper utilizes a deep learning algorithm trained on 316 MRIs to segment muscles and tested its performance across standard and challenging MRI sequences.", "result": "The model achieved an average Dice Similarity Coefficient of 88.45% on common sequences and 86.21% on less common sequences with abnormalities, demonstrating robustness.", "conclusion": "The study concludes that automated deep learning muscle segmentation in MRI is feasible, consistent, and valuable for advancing research into musculature and health relationships."}}
{"id": "2506.23964", "pdf": "https://arxiv.org/pdf/2506.23964", "abs": "https://arxiv.org/abs/2506.23964", "authors": ["Hongyu H\u00e8", "Minhao Jin", "Maria Apostolaki"], "title": "Learning Constraints Directly from Network Data", "categories": ["cs.NI", "cs.LG", "C.2.3; I.2.6; I.2.3"], "comment": "13 pages, 15 figures", "summary": "Network data conforms to a wide range of rules that arise from protocols,\ndesign principles, and deployment decisions (e.g., a packet's queuing delay\nmust be less than its end-to-end delay). Formalizing such rules as logic\nconstraints can (i) improve the quality of synthetic data, (ii) reduce the\nbrittleness of machine learning (ML) models, and (iii) improve semantic\nunderstanding of network measurements. However, these benefits remain out of\nreach if rule extraction is manual or solely reliant on ML, as both approaches\nyield incomplete, unreliable, and/or inaccurate rules.\n  This paper formulates rule extraction as a constraint modeling problem and\nintroduces NetNomos that learns propositional logic constraints directly from\nraw network measurements. Constraint modeling in this domain is uniquely\nchallenging due to the scale of the data, the inherent learning complexity and\npassive environment, and the lack of ground truth supervision. NetNomos\naddresses these challenges via a lattice-based search structured by constraint\nspecificity and succinctness. Our approach reduces learning complexity from\nsuperquadratic to logarithmic and enables efficient traversal in combinatorial\nsearch space.\n  Our evaluations on diverse network datasets show that NetNomos learns all\nbenchmark rules, including those associated with as little as 0.01% of data\npoints, in under three hours. In contrast, baseline methods discover less than\n25% of the rules and require several days to run. Through three case studies,\nwe show that: NetNomos (i) finds rule violations in the outputs of all seven\nsynthetic traffic generators, hence can be used to assess and guide their\ngeneration process; (ii) detects semantic differences in traffic, hence can be\nused for anomaly detection; and (iii) automatically finds rules used for\ntelemetry imputation, hence can support monitoring through inference.", "AI": {"tldr": "The paper introduces NetNomos, a system that extracts network data rules as logic constraints for improved data quality, ML robustness, and semantic understanding. It outperforms baselines in speed and rule discovery.", "motivation": "To formalize network data rules as logic constraints for improving synthetic data quality, reducing ML brittleness, and enhancing semantic understanding, as existing manual or ML-dependent methods are incomplete and unreliable.", "method": "NetNomos formulates rule extraction as a constraint modeling problem and employs a lattice-based search structured by constraint specificity and succinctness to efficiently learn logic constraints from raw network measurements.", "result": "NetNomos achieves better performance than baseline methods, learning all benchmark rules (even for rare data points) in under three hours, while baselines discover less than 25% of the rules and take several days.", "conclusion": "NetNomos is effective for discovering network constraints, enabling use cases such as synthetic data generation validation, anomaly detection, and telemetry imputation, outperforming traditional methods in efficiency and accuracy."}}
{"id": "2506.22482", "pdf": "https://arxiv.org/pdf/2506.22482", "abs": "https://arxiv.org/abs/2506.22482", "authors": ["Divya Alok Gupta", "Dwith Chenna", "B. Aditya Vighnesh Ramakanth"], "title": "Wireless Home Automation Using Social Networking Websites", "categories": ["cs.NI", "cs.CR", "cs.CV"], "comment": "20th Annual International Conference on Advanced Computing and\n  Communications (ADCOM) 2014", "summary": "With the advent of Internet of Things, Wireless Home Automation Systems WHAS\nare gradually gaining popularity. These systems are faced with multiple\nchallenges such as security; controlling a variety of home appliances with a\nsingle interface and user friendliness. In this paper we propose a system that\nuses secure authentication systems of social networking websites such as\nTwitter, tracks the end-users activities on the social network and then control\nhis or her domestic appliances. At the end, we highlight the applications of\nthe proposed WHAS and compare the advantages of our proposed system over\ntraditional home automation systems.", "AI": {"tldr": "The paper proposes a home automation system leveraging Twitter for secure authentication and user interaction to control domestic appliances.", "motivation": "To address challenges in current Wireless Home Automation Systems (WHAS) such as security, user-friendliness, and managing diverse appliances with a single interface.", "method": "The system integrates secure authentication through social networking platforms like Twitter and monitors user activities on the network to control home appliances.", "result": "A comparison is made with traditional systems, showing the advantages of this approach in terms of security and functionality.", "conclusion": "The proposed system enhances functionality and usability in home automation by incorporating social media-based secure authentication mechanisms."}}
{"id": "2506.24024", "pdf": "https://arxiv.org/pdf/2506.24024", "abs": "https://arxiv.org/abs/2506.24024", "authors": ["Nicolas Heintz", "Tom Francart", "Alexander Bertrand"], "title": "Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Auditory attention decoding (AAD) algorithms exploit brain signals, such as\nelectroencephalography (EEG), to identify which speaker a listener is focusing\non in a multi-speaker environment. While state-of-the-art AAD algorithms can\nidentify the attended speaker on short time windows, their predictions are\noften too inaccurate for practical use. In this work, we propose augmenting AAD\nwith a hidden Markov model (HMM) that models the temporal structure of\nattention. More specifically, the HMM relies on the fact that a subject is much\nless likely to switch attention than to keep attending the same speaker at any\nmoment in time. We show how a HMM can significantly improve existing AAD\nalgorithms in both causal (real-time) and non-causal (offline) settings. We\nfurther demonstrate that HMMs outperform existing postprocessing approaches in\nboth accuracy and responsiveness, and explore how various factors such as\nwindow length, switching frequency, and AAD accuracy influence overall\nperformance. The proposed method is computationally efficient, intuitive to use\nand applicable in both real-time and offline settings.", "AI": {"tldr": "This paper improves auditory attention decoding (AAD) algorithms by integrating a hidden Markov model (HMM), which accounts for temporal attention patterns and improves accuracy and responsiveness.", "motivation": "Current AAD algorithms have accuracy limitations, making them impractical for real-world applications, especially in identifying focused speakers in noisy environments.", "method": "The researchers integrated a hidden Markov model (HMM) into AAD algorithms to exploit temporal attention patterns, assuming listeners are less likely to frequently switch their focus between speakers.", "result": "The incorporation of HMM enhanced the accuracy and responsiveness of AAD algorithms in both real-time and offline contexts, outperforming other postprocessing techniques.", "conclusion": "The HMM framework provides a computationally efficient and operationally intuitive solution for improving AAD, making it applicable for practical scenarios."}}
{"id": "2506.22568", "pdf": "https://arxiv.org/pdf/2506.22568", "abs": "https://arxiv.org/abs/2506.22568", "authors": ["Gladston Moreira", "Ivan Meneghini", "Elzabeth Wanner"], "title": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions", "categories": ["math.OC", "cs.CV"], "comment": "11 pages", "summary": "Multi-objective optimization problems (MOPs) often require a trade-off\nbetween conflicting objectives, maximizing diversity and convergence in the\nobjective space. This study presents an approach to improve the quality of MOP\nsolutions by optimizing the dispersion in the decision space and the\nconvergence in a specific region of the objective space. Our approach defines a\nRegion of Interest (ROI) based on a cone representing the decision maker's\npreferences in the objective space, while enhancing the dispersion of solutions\nin the decision space using a uniformity measure. Combining solution\nconcentration in the objective space with dispersion in the decision space\nintensifies the search for Pareto-optimal solutions while increasing solution\ndiversity. When combined, these characteristics improve the quality of\nsolutions and avoid the bias caused by clustering solutions in a specific\nregion of the decision space. Preliminary experiments suggest that this method\nenhances multi-objective optimization by generating solutions that effectively\nbalance dispersion and concentration, thereby mitigating bias in the decision\nspace.", "AI": {"tldr": "This paper improves multi-objective optimization by balancing solution dispersion in the decision space with convergence in specific regions of the objective space, using a Region of Interest (ROI) approach.", "motivation": "To address challenges in multi-objective optimization, such as balancing diversity and convergence, while avoiding bias caused by clustering solutions in particular regions of the decision space.", "method": "The paper introduces a Region of Interest (ROI) defined by a cone reflecting decision-maker preferences for convergence in the objective space. Simultaneously, it uses a uniformity measure to enhance solution dispersion in the decision space.", "result": "Experiments show that the proposed approach improves multi-objective optimization by generating solutions that balance dispersion in the decision space with concentration in the objective space, reducing bias.", "conclusion": "The approach effectively enhances the quality of solutions for multi-objective optimization by improving diversity and avoiding clustering bias, contributing to better Pareto-optimal solution searches."}}
{"id": "2506.23815", "pdf": "https://arxiv.org/pdf/2506.23815", "abs": "https://arxiv.org/abs/2506.23815", "authors": ["Patrick Stokkink"], "title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The influence of Artificial Intelligence (AI), and specifically Large\nLanguage Models (LLM), on education is continuously increasing. These models\nare frequently used by students, giving rise to the question whether current\nforms of assessment are still a valid way to evaluate student performance and\ncomprehension. The theoretical framework developed in this paper is grounded in\nConstructive Alignment (CA) theory and Bloom's taxonomy for defining learning\nobjectives. We argue that AI influences learning objectives of different Bloom\nlevels in a different way, and assessment has to be adopted accordingly.\nFurthermore, in line with Bloom's vision, formative and summative assessment\nshould be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be\nadapted to the presence of AI, a strong bias exists on the extent to which\nlecturers want to allow for AI in assessment. This bias is caused by a\nlecturer's familiarity with AI and specifically whether they use it themselves.\nTo avoid this bias, we propose structured guidelines on a university or faculty\nlevel, to foster alignment among the staff. Besides that, we argue that\nteaching staff should be trained on the capabilities and limitations of AI\ntools. In this way, they are better able to adapt their assessment methods.", "AI": {"tldr": "Artificial Intelligence tools, particularly Large Language Models, significantly impact education and assessments, requiring adaptation in alignment with Bloom's Taxonomy and Constructive Alignment theory.", "motivation": "The increasing usage of AI tools like LLM in education raises concerns about the validity of current assessment methods to evaluate student performance effectively.", "method": "A theoretical framework grounded in Constructive Alignment theory and Bloom's taxonomy is developed to analyze AI's specific impacts on learning objectives and assessment methods.", "result": "AI affects different Bloom levels of learning objectives distinctively, suggesting that assessments should be adjusted accordingly and standardized guidelines developed to reduce lecturer bias.", "conclusion": "Adapting educational assessments to integrate AI responsibly entails structured guidelines and training lecturers about AI's capabilities and limitations. This ensures consistency across faculties in assessment methods."}}
{"id": "2506.23826", "pdf": "https://arxiv.org/pdf/2506.23826", "abs": "https://arxiv.org/abs/2506.23826", "authors": ["Llu\u00eds C. Coll", "Martin W. Lauer-Schmaltz", "Philip Cash", "John P. Hansen", "Anja Maier"], "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins", "categories": ["cs.ET", "cs.AI", "cs.CY", "cs.HC", "cs.IR"], "comment": "24 pages, 9 figures", "summary": "Human Digital Twins (HDTs) have traditionally been conceptualized as\ndata-driven models designed to support decision-making across various domains.\nHowever, recent advancements in conversational AI open new possibilities for\nHDTs to function as authentic, interactive digital counterparts of individuals.\nThis paper introduces a novel HDT system architecture that integrates large\nlanguage models with dynamically updated personal data, enabling it to mirror\nan individual's conversational style, memories, and behaviors. To achieve this,\nour approach implements context-aware memory retrieval, neural\nplasticity-inspired consolidation, and adaptive learning mechanisms, creating a\nmore natural and evolving digital persona. The resulting system does not only\nreplicate an individual's unique conversational style depending on who they are\nspeaking with, but also enriches responses with dynamically captured personal\nexperiences, opinions, and memories. While this marks a significant step toward\ndeveloping authentic virtual counterparts, it also raises critical ethical\nconcerns regarding privacy, accountability, and the long-term implications of\npersistent digital identities. This study contributes to the field of HDTs by\ndescribing our novel system architecture, demonstrating its capabilities, and\ndiscussing future directions and emerging challenges to ensure the responsible\nand ethical development of HDTs.", "AI": {"tldr": "The paper presents an HDT system integrating conversational AI and dynamic data to emulate individual conversational styles with personal experiences, while addressing ethical concerns.", "motivation": "To elevate Human Digital Twins from decision-support tools to interactive, evolving digital counterparts by leveraging advanced conversational AI and dynamic data modeling.", "method": "Introduced an HDT system architecture based on large language models, employing techniques like context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning.", "result": "The system replicates unique conversational styles and dynamically integrates personal memories, experiences, and opinions to enrich interactions.", "conclusion": "The approach marks progress towards authentic virtual personas but underscores the need to responsibly address ethical considerations like privacy and accountability."}}
{"id": "2506.24048", "pdf": "https://arxiv.org/pdf/2506.24048", "abs": "https://arxiv.org/abs/2506.24048", "authors": ["Tim Roith", "Leon Bungert", "Philipp Wacker"], "title": "Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies", "categories": ["math.OC", "cs.LG", "65K10, 68Q32, 65K15, 90C26"], "comment": null, "summary": "Consensus-based optimization (CBO) has established itself as an efficient\ngradient-free optimization scheme, with attractive mathematical properties,\nsuch as mean-field convergence results for non-convex loss functions. In this\nwork, we study CBO in the context of closed-box adversarial attacks, which are\nimperceptible input perturbations that aim to fool a classifier, without\naccessing its gradient. Our contribution is to establish a connection between\nthe so-called consensus hopping as introduced by Riedl et al. and natural\nevolution strategies (NES) commonly applied in the context of adversarial\nattacks and to rigorously relate both methods to gradient-based optimization\nschemes. Beyond that, we provide a comprehensive experimental study that shows\nthat despite the conceptual similarities, CBO can outperform NES and other\nevolutionary strategies in certain scenarios.", "AI": {"tldr": "Consensus-based optimization (CBO) is examined for closed-box adversarial attacks and connected to natural evolution strategies (NES), with experiments showing superior performance in some cases.", "motivation": "To improve understanding and efficiency of closed-box adversarial attacks using gradient-free optimization techniques.", "method": "The study connects CBO's consensus hopping with NES and compares their performance while drawing parallels to gradient-based methods.", "result": "CBO outperforms NES and other evolutionary strategies experimentally in specific scenarios related to adversarial attacks.", "conclusion": "CBO has the potential to enhance closed-box adversarial attack strategies, offering superior results over NES in certain cases."}}
{"id": "2506.22790", "pdf": "https://arxiv.org/pdf/2506.22790", "abs": "https://arxiv.org/abs/2506.22790", "authors": ["Yixu Chen", "Bowen Chen", "Hai Wei", "Alan C. Bovik", "Baojun Li", "Wei Sun", "Linhan Cao", "Kang Fu", "Dandan Zhu", "Jun Jia", "Menghan Hu", "Xiongkuo Min", "Guangtao Zhai", "Dounia Hammou", "Fei Yin", "Rafal Mantiuk", "Amritha Premkumar", "Prajit T Rajendran", "Vignesh V Menon"], "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "ICME 2025 Grand Challenges", "summary": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME)\n2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.\nWith the rapid development of video technology, especially High Dynamic Range\n(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and\ngeneralizable Video Quality Assessment (VQA) methods has become increasingly\ndemanded. Existing VQA models often struggle to deliver consistent performance\nacross varying dynamic ranges, distortion types, and diverse content. This\nchallenge was established to benchmark and promote VQA approaches capable of\njointly handling HDR and SDR content. In the final evaluation phase, five teams\nsubmitted seven models along with technical reports to the Full Reference (FR)\nand No Reference (NR) tracks. Among them, four methods outperformed VMAF\nbaseline, while the top-performing model achieved state-of-the-art performance,\nsetting a new benchmark for generalizable video quality assessment.", "AI": {"tldr": "This paper discusses the ICME 2025 Grand Challenge on video quality measurement for generalizable HDR and SDR methods, showcasing the need for robust Video Quality Assessment (VQA) approaches.", "motivation": "The rapid development of HDR and SDR video technologies has highlighted a gap in effective and consistent performance of existing VQA models across dynamic ranges and distortion types.", "method": "The challenge invited researchers to submit VQA models capable of addressing both HDR and SDR content. Teams competed in Full Reference (FR) and No Reference (NR) tracks, with final evaluations comparing submitted models against the VMAF baseline.", "result": "Four methods surpassed the VMAF baseline, with the top-performing model achieving state-of-the-art performance, thus setting a new standard for HDR/SDR content assessment.", "conclusion": "The challenge successfully fostered innovation in video quality assessment models, emphasizing the importance of developing techniques applicable to both HDR and SDR content for robust performance."}}
{"id": "2506.24081", "pdf": "https://arxiv.org/pdf/2506.24081", "abs": "https://arxiv.org/abs/2506.24081", "authors": ["Rahul Kumar", "Wenqi Wei", "Ying Mao", "Junaid Farooq", "Ying Wang", "Juntao Chen"], "title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "Keywords: Quantum Machine Learning, Hybrid Quantum Neural Networks,\n  SWAP Test, Fidelity, Circuit-level Attack", "summary": "We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to\nsabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks.\nSQUASH is executed by inserting SWAP gate(s) into the variational quantum\ncircuit of the victim HQNN. Unlike conventional noise-based or adversarial\ninput attacks, SQUASH directly manipulates the circuit structure, leading to\nqubit misalignment and disrupting quantum state evolution. This attack is\nhighly stealthy, as it does not require access to training data or introduce\ndetectable perturbations in input states. Our results demonstrate that SQUASH\nsignificantly degrades classification performance, with untargeted SWAP attacks\nreducing accuracy by up to 74.08\\% and targeted SWAP attacks reducing target\nclass accuracy by up to 79.78\\%. These findings reveal a critical vulnerability\nin HQNN implementations, underscoring the need for more resilient architectures\nagainst circuit-level adversarial interventions.", "AI": {"tldr": "The paper introduces SQUASH, a stealthy quantum circuit-level attack using SWAP gates to sabotage Hybrid Quantum Neural Networks (HQNNs).", "motivation": "To address the vulnerability of HQNNs to circuit-level attacks and expose potential risks in quantum machine learning systems.", "method": "SQUASH manipulates the variational quantum circuit structure of HQNNs by inserting SWAP gates. This causes qubit misalignments without needing access to training data or detectable input perturbations.", "result": "SQUASH reduces classification accuracy by up to 74.08% in untargeted attacks and up to 79.78% for targeted attacks.", "conclusion": "The study underscores the critical vulnerability of HQNNs to circuit-level threats and calls for the development of more robust quantum architectures against such adversarial interventions."}}
{"id": "2506.24108", "pdf": "https://arxiv.org/pdf/2506.24108", "abs": "https://arxiv.org/abs/2506.24108", "authors": ["Shai Yehezkel", "Omer Dahary", "Andrey Voynov", "Daniel Cohen-Or"], "title": "Navigating with Annealing Guidance Scale in Diffusion Space", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Project page:\n  https://annealing-guidance.github.io/annealing-guidance/", "summary": "Denoising diffusion models excel at generating high-quality images\nconditioned on text prompts, yet their effectiveness heavily relies on careful\nguidance during the sampling process. Classifier-Free Guidance (CFG) provides a\nwidely used mechanism for steering generation by setting the guidance scale,\nwhich balances image quality and prompt alignment. However, the choice of the\nguidance scale has a critical impact on the convergence toward a visually\nappealing and prompt-adherent image. In this work, we propose an annealing\nguidance scheduler which dynamically adjusts the guidance scale over time based\non the conditional noisy signal. By learning a scheduling policy, our method\naddresses the temperamental behavior of CFG. Empirical results demonstrate that\nour guidance scheduler significantly enhances image quality and alignment with\nthe text prompt, advancing the performance of text-to-image generation.\nNotably, our novel scheduler requires no additional activations or memory\nconsumption, and can seamlessly replace the common classifier-free guidance,\noffering an improved trade-off between prompt alignment and quality.", "AI": {"tldr": "The paper introduces an annealing guidance scheduler that dynamically adjusts the guidance scale in denoising diffusion models, enhancing image quality and text alignment without added computational cost.", "motivation": "To improve the balancing mechanism (guidance scale) in Classifier-Free Guidance for better convergence in generating high-quality and text-aligned images via diffusion models.", "method": "The annealing guidance scheduler adjust guidance scale dynamically during sampling, leveraging the conditional noisy signal and learning a scheduling policy.", "result": "The proposed scheduler enhances both image quality and adherence to text prompts, outperforming standard Classifier-Free Guidance in text-to-image generation while maintaining computational efficiency.", "conclusion": "The annealing guidance scheduler provides a better trade-off between prompt alignment and image quality with no added memory or activation cost, making it a practical replacement for current CFG methods."}}
{"id": "2506.22826", "pdf": "https://arxiv.org/pdf/2506.22826", "abs": "https://arxiv.org/abs/2506.22826", "authors": ["Robert Beinert", "Jonas Bresch"], "title": "Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations", "categories": ["math.OC", "cs.CV", "cs.NA", "math.NA", "94A08, 94A12, 65J22, 90C22, 90C25"], "comment": "9 pages, 2 figures, 3 algorithms", "summary": "The handling of manifold-valued data, for instance, plays a central role in\ncolor restoration tasks relying on circle- or sphere-valued color models, in\nthe study of rotational or directional information related to the special\northogonal group, and in Gaussian image processing, where the pixel statistics\nare interpreted as values on the hyperbolic sheet. Especially, to denoise these\nkind of data, there have been proposed several generalizations of total\nvariation (TV) and Tikhonov-type denoising models incorporating the underlying\nmanifolds. Recently, a novel, numerically efficient denoising approach has been\nintroduced, where the data are embedded in an Euclidean ambient space, the\nnon-convex manifolds are encoded by a series of positive semi-definite,\nfixed-rank matrices, and the rank constraint is relaxed to obtain a\nconvexification that can be solved using standard algorithms from convex\nanalysis. The aim of the present paper is to extent this approach to new kinds\nof data like multi-binary and Stiefel-valued data. Multi-binary data can, for\ninstance, be used to model multi-color QR codes whereas Stiefel-valued data\noccur in image and video-based recognition. For both new data types, we propose\nTV- and Tikhonov-based denoising modelstogether with easy-to-solve\nconvexification. All derived methods are evaluated on proof-of-concept,\nsynthetic experiments.", "AI": {"tldr": "This paper extends a recent convex denoising framework to handle multi-binary and Stiefel-valued data, supported by synthetic experiments.", "motivation": "The motivation is to expand existing denoising methods, such as total variation and Tikhonov models, which have already been applied to manifold-valued data, to new data types like multi-binary and Stiefel-valued data.", "method": "The approach involves embedding the manifold-valued data in Euclidean ambient space, encoding non-convex manifolds with fixed-rank matrices, and introducing a convex relaxation for easier computation. The authors extend these methods to handle multi-binary and Stiefel-valued data.", "result": "The paper successfully develops and tests TV- and Tikhonov-based denoising methods for the new data types through synthetic experiments.", "conclusion": "The proposed models are numerically efficient and versatile, showcasing their potential for practical applications like multi-color QR codes and video-based recognition."}}
{"id": "2506.22973", "pdf": "https://arxiv.org/pdf/2506.22973", "abs": "https://arxiv.org/abs/2506.22973", "authors": ["AmirHossein Naghi Razlighi", "Elaheh Badali Golezani", "Shohreh Kasaei"], "title": "Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian Splatting enables high-quality real-time rendering but often\nproduces millions of splats, resulting in excessive storage and computational\noverhead. We propose a novel lossy compression method based on learnable\nconfidence scores modeled as Beta distributions. Each splat's confidence is\noptimized through reconstruction-aware losses, enabling pruning of\nlow-confidence splats while preserving visual fidelity. The proposed approach\nis architecture-agnostic and can be applied to any Gaussian Splatting variant.\nIn addition, the average confidence values serve as a new metric to assess the\nquality of the scene. Extensive experiments demonstrate favorable trade-offs\nbetween compression and fidelity compared to prior work. Our code and data are\npublicly available at\nhttps://github.com/amirhossein-razlighi/Confident-Splatting", "AI": {"tldr": "The paper introduces a lossy compression method for 3D Gaussian Splatting using learnable confidence scores, effectively reducing computational costs while maintaining visual quality.", "motivation": "To address the high storage and computational overhead caused by millions of splats in 3D Gaussian Splatting.", "method": "The authors propose using learnable confidence scores modeled as Beta distributions and reconstruction-aware losses to optimize and prune low-confidence splats.", "result": "The method achieves favorable trade-offs between compression and fidelity compared to previous frameworks, and introduces a confidence-based metric for scene quality assessment.", "conclusion": "The proposed method significantly reduces the overhead of 3D Gaussian Splatting without compromising visual fidelity, and it can be integrated with any variant of Gaussian Splatting."}}
{"id": "2506.23016", "pdf": "https://arxiv.org/pdf/2506.23016", "abs": "https://arxiv.org/abs/2506.23016", "authors": ["Tom\u00e1s Silva Santos Rocha", "Anastasiia Mikhailova", "Moreno I. Coco", "Jos\u00e9 Santos-Victor"], "title": "Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks", "categories": ["cs.HC", "cs.CV"], "comment": "13 pages, 5 figures", "summary": "The global prevalence of dementia is projected to double by 2050,\nhighlighting the urgent need for scalable diagnostic tools. This study utilizes\ndigital cognitive tasks with eye-tracking data correlated with memory processes\nto distinguish between Healthy Controls (HC) and Mild Cognitive Impairment\n(MCI), a precursor to dementia. A deep learning model based on VTNet was\ntrained using eye-tracking data from 44 participants (24 MCI, 20 HCs) who\nperformed a visual memory task. The model utilizes both time series and spatial\ndata derived from eye-tracking. It was modified to incorporate scan paths, heat\nmaps, and image content. These modifications also enabled testing parameters\nsuch as image resolution and task performance, analyzing their impact on model\nperformance. The best model, utilizing $700\\times700px$ resolution heatmaps,\nachieved 68% sensitivity and 76% specificity. Despite operating under more\nchallenging conditions (e.g., smaller dataset size, shorter task duration, or a\nless standardized task), the model's performance is comparable to an\nAlzheimer's study using similar methods (70% sensitivity and 73% specificity).\nThese findings contribute to the development of automated diagnostic tools for\nMCI. Future work should focus on refining the model and using a standardized\nlong-term visual memory task.", "AI": {"tldr": "The study explores using eye-tracking data and deep learning to differentiate Mild Cognitive Impairment (MCI) from Healthy Controls (HC).", "motivation": "The global rise in dementia highlights the need for scalable and automated tools to diagnose conditions like Mild Cognitive Impairment (MCI).", "method": "Participants performed a visual memory task while eye-tracking data was collected. A VTNet-based deep learning model analyzed time series and spatial data, incorporating scan paths and heatmaps.", "result": "The model achieved 68% sensitivity and 76% specificity using $700\u00d7700$ resolution heatmaps, comparable to prior Alzheimer's studies.", "conclusion": "This approach shows promise as a diagnostic tool for MCI but requires refinement and testing with standardized, long-term tasks."}}
{"id": "2506.23102", "pdf": "https://arxiv.org/pdf/2506.23102", "abs": "https://arxiv.org/abs/2506.23102", "authors": ["Sunggu Kyung", "Jinyoung Seo", "Hyunseok Lim", "Dongyeong Kim", "Hyungbin Park", "Jimin Sung", "Jihyun Kim", "Wooyoung Jo", "Yoojin Nam", "Namkug Kim"], "title": "MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation", "categories": ["eess.IV", "cs.CV"], "comment": "14 pages, 5 figures, submitted to ICCV 2025", "summary": "The recent release of RadGenome-Chest CT has significantly advanced CT-based\nreport generation. However, existing methods primarily focus on global\nfeatures, making it challenging to capture region-specific details, which may\ncause certain abnormalities to go unnoticed. To address this, we propose\nMedRegion-CT, a region-focused Multi-Modal Large Language Model (MLLM)\nframework, featuring three key innovations. First, we introduce Region\nRepresentative ($R^2$) Token Pooling, which utilizes a 2D-wise pretrained\nvision model to efficiently extract 3D CT features. This approach generates\nglobal tokens representing overall slice features and region tokens\nhighlighting target areas, enabling the MLLM to process comprehensive\ninformation effectively. Second, a universal segmentation model generates\npseudo-masks, which are then processed by a mask encoder to extract\nregion-centric features. This allows the MLLM to focus on clinically relevant\nregions, using six predefined region masks. Third, we leverage segmentation\nresults to extract patient-specific attributions, including organ size,\ndiameter, and locations. These are converted into text prompts, enriching the\nMLLM's understanding of patient-specific contexts. To ensure rigorous\nevaluation, we conducted benchmark experiments on report generation using the\nRadGenome-Chest CT. MedRegion-CT achieved state-of-the-art performance,\noutperforming existing methods in natural language generation quality and\nclinical relevance while maintaining interpretability. The code for our\nframework is publicly available.", "AI": {"tldr": "MedRegion-CT introduces a region-focused framework for chest CT report generation, emphasizing detailed region-specific features to improve clinical relevance and interpretability.", "motivation": "Existing CT-based report generation methods struggle with capturing region-specific details, leading to missed abnormalities.", "method": "MedRegion-CT proposes three innovations: a region token pooling method using pretrained vision models, universal segmentation with pseudo-masks, and extracting patient-specific attributes for enriching context.", "result": "MedRegion-CT achieves state-of-the-art performance in report generation tasks, excelling in both natural language generation quality and clinical relevance.", "conclusion": "The framework enhances report generation by focusing on regional and patient-specific features, offering improved interpretability and benchmarking success."}}
{"id": "2506.24009", "pdf": "https://arxiv.org/pdf/2506.24009", "abs": "https://arxiv.org/abs/2506.24009", "authors": ["Xinquan Wang", "Fenghao Zhu", "Zhaohui Yang", "Chongwen Huang", "Xiaoming Chen", "Zhaoyang Zhang", "Sami Muhaidat", "M\u00e9rouane Debbah"], "title": "Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems", "categories": ["cs.IT", "cs.AI", "math.IT"], "comment": "7 pages, 4 figures", "summary": "Large artificial intelligence (AI) models offer revolutionary potential for\nfuture wireless systems, promising unprecedented capabilities in network\noptimization and performance. However, current paradigms largely overlook\ncrucial physical interactions. This oversight means they primarily rely on\noffline datasets, leading to difficulties in handling real-time wireless\ndynamics and non-stationary environments. Furthermore, these models often lack\nthe capability for active environmental probing. This paper proposes a\nfundamental paradigm shift towards wireless embodied large AI (WELAI), moving\nfrom passive observation to active embodiment. We first identify key challenges\nfaced by existing models, then we explore the design principles and system\nstructure of WELAI. Besides, we outline prospective applications in\nnext-generation wireless. Finally, through an illustrative case study, we\ndemonstrate the effectiveness of WELAI and point out promising research\ndirections for realizing adaptive, robust, and autonomous wireless systems.", "AI": {"tldr": "This paper introduces the concept of Wireless Embodied Large AI (WELAI) to address limitations in current AI models for wireless systems.", "motivation": "Current AI models for wireless networks fail to handle real-time dynamics, non-stationary environments, and lack the ability for environmental probing.", "method": "The authors propose shifting from passive observation to active embodiment with WELAI, detailing its design principles, system structure, applications, and validating its effectiveness through a case study.", "result": "The study demonstrates that WELAI effectively handles wireless system challenges and provides an adaptive, robust, and autonomous solution.", "conclusion": "WELAI represents a transformative approach for next-generation wireless systems, highlighting the need for further research into adaptive and autonomous wireless capabilities."}}
{"id": "2506.23208", "pdf": "https://arxiv.org/pdf/2506.23208", "abs": "https://arxiv.org/abs/2506.23208", "authors": ["Runtian Yuan", "Qingqiu Li", "Junlin Hou", "Jilan Xu", "Yuejie Zhang", "Rui Feng", "Hao Chen"], "title": "Multi-Source COVID-19 Detection via Variance Risk Extrapolation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "We present our solution for the Multi-Source COVID-19 Detection Challenge,\nwhich aims to classify chest CT scans into COVID and Non-COVID categories\nacross data collected from four distinct hospitals and medical centers. A major\nchallenge in this task lies in the domain shift caused by variations in imaging\nprotocols, scanners, and patient populations across institutions. To enhance\nthe cross-domain generalization of our model, we incorporate Variance Risk\nExtrapolation (VREx) into the training process. VREx encourages the model to\nmaintain consistent performance across multiple source domains by explicitly\nminimizing the variance of empirical risks across environments. This\nregularization strategy reduces overfitting to center-specific features and\npromotes learning of domain-invariant representations. We further apply Mixup\ndata augmentation to improve generalization and robustness. Mixup interpolates\nboth the inputs and labels of randomly selected pairs of training samples,\nencouraging the model to behave linearly between examples and enhancing its\nresilience to noise and limited data. Our method achieves an average macro F1\nscore of 0.96 across the four sources on the validation set, demonstrating\nstrong generalization.", "AI": {"tldr": "This paper addresses the challenge of classifying chest CT scans into COVID and Non-COVID categories across data from distinct institutions, tackling domain shifts through innovative techniques.", "motivation": "The motivation is to address classification challenges in chest CT scans for COVID-19 detection, particularly focusing on domain shift due to variations in medical imaging protocols, scanners, and patient populations.", "method": "The method involves incorporating Variance Risk Extrapolation (VREx) to minimize performance variance across domains, alongside Mixup data augmentation to improve generalization by interpolating inputs and labels of training samples.", "result": "The proposed method achieved an average macro F1 score of 0.96 across four sources on the validation set, exhibiting strong cross-domain generalization.", "conclusion": "The approach effectively mitigates domain shift issues in multi-source chest CT data classification, offering promising tools for robust COVID-19 detection across medical institutions."}}
{"id": "2506.23259", "pdf": "https://arxiv.org/pdf/2506.23259", "abs": "https://arxiv.org/abs/2506.23259", "authors": ["Lachin Naghashyar"], "title": "Improving Myocardial Infarction Detection via Synthetic ECG Pretraining", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Myocardial infarction is a major cause of death globally, and accurate early\ndiagnosis from electrocardiograms (ECGs) remains a clinical priority. Deep\nlearning models have shown promise for automated ECG interpretation, but\nrequire large amounts of labeled data, which are often scarce in practice. We\npropose a physiology-aware pipeline that (i) synthesizes 12-lead ECGs with\ntunable MI morphology and realistic noise, and (ii) pre-trains recurrent and\ntransformer classifiers with self-supervised masked-autoencoding plus a joint\nreconstruction-classification objective. We validate the realism of synthetic\nECGs via statistical and visual analysis, confirming that key morphological\nfeatures are preserved. Pretraining on synthetic data consistently improved\nclassification performance, particularly in low-data settings, with AUC gains\nof up to 4 percentage points. These results show that controlled synthetic ECGs\ncan help improve MI detection when real clinical data is limited.", "AI": {"tldr": "This paper proposes a deep learning-based pipeline for myocardial infarction (MI) detection using synthetic ECG data, addressing data scarcity challenges.", "motivation": "Accurate early diagnosis of MI from ECGs is a clinical priority, but the lack of large labeled datasets hinders deep learning approaches.", "method": "The pipeline synthesizes realistic 12-lead ECGs with tunable MI features and pre-trains classifiers using self-supervised learning combining autoencoding and classification objectives.", "result": "Synthetic ECGs enhance classification performance, particularly in low-data scenarios, with improvements in AUC up to 4%.", "conclusion": "Controlled synthetic ECGs improve MI detection and provide a viable solution where real clinical ECG data is scarce."}}
{"id": "2506.23305", "pdf": "https://arxiv.org/pdf/2506.23305", "abs": "https://arxiv.org/abs/2506.23305", "authors": ["Rachit Saluja", "Arzu Kovanlikaya", "Candace Chien", "Lauren Kathryn Blatt", "Jeffrey M. Perlman", "Stefan Worgall", "Mert R. Sabuncu", "Jonathan P. Dyke"], "title": "BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Bronchopulmonary dysplasia (BPD) is a common complication among preterm\nneonates, with portable X-ray imaging serving as the standard diagnostic\nmodality in neonatal intensive care units (NICUs). However, lung magnetic\nresonance imaging (MRI) offers a non-invasive alternative that avoids sedation\nand radiation while providing detailed insights into the underlying mechanisms\nof BPD. Leveraging high-resolution 3D MRI data, advanced image processing and\nsemantic segmentation algorithms can be developed to assist clinicians in\nidentifying the etiology of BPD. In this dataset, we present MRI scans paired\nwith corresponding semantic segmentations of the lungs and trachea for 40\nneonates, the majority of whom are diagnosed with BPD. The imaging data consist\nof free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as\nthe StarVIBE series. Additionally, we provide comprehensive clinical data and\nbaseline segmentation models, validated against clinical assessments, to\nsupport further research and development in neonatal lung imaging.", "AI": {"tldr": "The paper presents a dataset of neonatal lung MRI scans and corresponding semantic segmentations to aid in BPD diagnosis using advanced image processing.", "motivation": "To provide a non-invasive, radiation-free, and sedation-free alternative for diagnosing BPD while offering detailed insights into its mechanisms.", "method": "High-resolution 3D MRI data acquired via free-breathing StarVIBE sequences were paired with semantic segmentation algorithms and baseline models for lung and trachea analysis.", "result": "A dataset of 40 neonatal MRI scans, most of whom are diagnosed with BPD, along with clinical data and validated segmentation models, was developed.", "conclusion": "The dataset has the potential to support further advancements in neonatal lung imaging and improve BPD diagnosis."}}
{"id": "2506.23309", "pdf": "https://arxiv.org/pdf/2506.23309", "abs": "https://arxiv.org/abs/2506.23309", "authors": ["Yiming Huang", "Long Bai", "Beilei Cui", "Kun Yuan", "Guankun Wang", "Mobarakol Islam", "Nicolas Padoy", "Nassir Navab", "Hongliang Ren"], "title": "SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting", "categories": ["eess.IV", "cs.CV"], "comment": "MICCAI 2025. Project Page:\n  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/", "summary": "In contemporary surgical research and practice, accurately comprehending 3D\nsurgical scenes with text-promptable capabilities is particularly crucial for\nsurgical planning and real-time intra-operative guidance, where precisely\nidentifying and interacting with surgical tools and anatomical structures is\nparamount. However, existing works focus on surgical vision-language model\n(VLM), 3D reconstruction, and segmentation separately, lacking support for\nreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, a\nnovel text-promptable Gaussian Splatting method to fill this gap. We introduce\na 3D semantics feature learning strategy incorporating the Segment Anything\nmodel and state-of-the-art vision-language models. We extract the segmented\nlanguage features for 3D surgical scene reconstruction, enabling a more\nin-depth understanding of the complex surgical environment. We also propose\nsemantic-aware deformation tracking to capture the seamless deformation of\nsemantic features, providing a more precise reconstruction for both texture and\nsemantic features. Furthermore, we present semantic region-aware optimization,\nwhich utilizes regional-based semantic information to supervise the training,\nparticularly promoting the reconstruction quality and semantic smoothness. We\nconduct comprehensive experiments on two real-world surgical datasets to\ndemonstrate the superiority of SurgTPGS over state-of-the-art methods,\nhighlighting its potential to revolutionize surgical practices. SurgTPGS paves\nthe way for developing next-generation intelligent surgical systems by\nenhancing surgical precision and safety. Our code is available at:\nhttps://github.com/lastbasket/SurgTPGS.", "AI": {"tldr": "This paper introduces SurgTPGS, a novel method for real-time text-promptable 3D surgical scene understanding, which combines advancements in 3D reconstruction, segmentation, and vision-language models to enhance precision and safety in surgical practices.", "motivation": "The motivation is the lack of support for real-time, text-promptable 3D queries in surgical planning and intra-operative guidance, which are essential for identifying and interacting with tools and anatomical structures in complex surgical environments.", "method": "The authors propose SurgTPGS, which integrates a 3D semantics feature learning strategy leveraging the Segment Anything model and advanced vision-language models. It incorporates semantic-aware deformation tracking for precise reconstruction and semantic region-aware optimization to enhance quality and smoothness.", "result": "SurgTPGS outperforms state-of-the-art methods in experiments on two real-world surgical datasets, showcasing its ability to provide superior 3D surgical scene reconstruction and understanding.", "conclusion": "SurgTPGS has the potential to revolutionize surgical systems by enabling text-promptable 3D scene comprehension, enhancing surgical precision, and advancing safety. Its code is publicly available for future research and development."}}
{"id": "2506.23466", "pdf": "https://arxiv.org/pdf/2506.23466", "abs": "https://arxiv.org/abs/2506.23466", "authors": ["Qiqing Liu", "Guoquan Wei", "Zekun Zhou", "Yiyang Wen", "Liu Shi", "Qiegen Liu"], "title": "FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": "11pages, 11 figures", "summary": "Low-dose computed tomography (LDCT) reduces radiation exposure but suffers\nfrom image artifacts and loss of detail due to quantum and electronic noise,\npotentially impacting diagnostic accuracy. Transformer combined with diffusion\nmodels has been a promising approach for image generation. Nevertheless,\nexisting methods exhibit limitations in preserving finegrained image details.\nTo address this issue, frequency domain-directed diffusion transformer (FD-DiT)\nis proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy\nthat progressively introduces noise until the distribution statistically aligns\nwith that of LDCT data, followed by denoising processing. Furthermore, we\nemploy a frequency decoupling technique to concentrate noise primarily in\nhigh-frequency domain, thereby facilitating effective capture of essential\nanatomical structures and fine details. A hybrid denoising network is then\nutilized to optimize the overall data reconstruction process. To enhance the\ncapability in recognizing high-frequency noise, we incorporate sliding sparse\nlocal attention to leverage the sparsity and locality of shallow-layer\ninformation, propagating them via skip connections for improving feature\nrepresentation. Finally, we propose a learnable dynamic fusion strategy for\noptimal component integration. Experimental results demonstrate that at\nidentical dose levels, LDCT images reconstructed by FD-DiT exhibit superior\nnoise and artifact suppression compared to state-of-the-art methods.", "AI": {"tldr": "This paper introduces FD-DiT, a frequency-domain diffusion transformer tailored for improved low-dose CT image reconstruction, ensuring better noise and artifact suppression over existing methods.", "motivation": "The motivation is to tackle image artifacts and detail loss in low-dose computed tomography (LDCT) scans caused by quantum and electronic noise, which can impact diagnostic accuracy.", "method": "FD-DiT integrates diffusion transformer strategies and frequency decoupling techniques, focusing on denoising high-frequency noise and utilizing hybrid networks, sparse local attention, and dynamic fusion for reconstruction.", "result": "Experimental results show FD-DiT significantly outperforms state-of-the-art methods in noise and artifact reduction at identical LDCT dose levels.", "conclusion": "FD-DiT enhances LDCT image reconstruction by integrating advanced denoising techniques, offering superior diagnostic-quality imaging with lower radiation exposure."}}
{"id": "2506.23471", "pdf": "https://arxiv.org/pdf/2506.23471", "abs": "https://arxiv.org/abs/2506.23471", "authors": ["Thanh-Tung Phan-Nguyen", "Khoi-Nguyen Nguyen-Ngoc", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On", "categories": ["cs.IR", "cs.CV"], "comment": null, "summary": "The global fashion e-commerce industry has become integral to people's daily\nlives, leveraging technological advancements to offer personalized shopping\nexperiences, primarily through recommendation systems that enhance customer\nengagement through personalized suggestions. To improve customers' experience\nin online shopping, we propose a novel comprehensive KiseKloset system for\noutfit retrieval, recommendation, and try-on. We explore two approaches for\noutfit retrieval: similar item retrieval and text feedback-guided item\nretrieval. Notably, we introduce a novel transformer architecture designed to\nrecommend complementary items from diverse categories. Furthermore, we enhance\nthe overall performance of the search pipeline by integrating approximate\nalgorithms to optimize the search process. Additionally, addressing the crucial\nneeds of online shoppers, we employ a lightweight yet efficient virtual try-on\nframework capable of real-time operation, memory efficiency, and maintaining\nrealistic outputs compared to its predecessors. This virtual try-on module\nempowers users to visualize specific garments on themselves, enhancing the\ncustomers' experience and reducing costs associated with damaged items for\nretailers. We deployed our end-to-end system for online users to test and\nprovide feedback, enabling us to measure their satisfaction levels. The results\nof our user study revealed that 84% of participants found our comprehensive\nsystem highly useful, significantly improving their online shopping experience.", "AI": {"tldr": "The paper introduces KiseKloset, an advanced system for outfit retrieval, recommendation, and virtual try-on, boasting high user satisfaction at 84%.", "motivation": "The motivation is to enhance the online shopping experience through better outfit recommendations and virtual try-on capabilities, addressing customer and retailer needs such as personalization and reducing return costs.", "method": "The system employs two outfit retrieval methods (similar item retrieval and text-guided retrieval), a novel transformer for recommendations, optimized search pipelines with approximate algorithms, and a lightweight virtual try-on framework.", "result": "The user study reported that 84% of participants found the KiseKloset system highly useful, significantly improving their online shopping experience.", "conclusion": "KiseKloset successfully integrates outfit retrieval, recommendation, and virtual try-on, offering realistic visualization and improving user satisfaction in the e-commerce fashion domain."}}
{"id": "2506.23484", "pdf": "https://arxiv.org/pdf/2506.23484", "abs": "https://arxiv.org/abs/2506.23484", "authors": ["Yuzhuo Chen", "Zehua Ma", "Han Fang", "Weiming Zhang", "Nenghai Yu"], "title": "TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity", "categories": ["cs.MM", "cs.CV", "eess.IV", "I.3.3; I.4.9"], "comment": "Accepted by ICCV 2025 (2025 IEEE/CVF International Conference on\n  Computer Vision)", "summary": "AI-generated content (AIGC) enables efficient visual creation but raises\ncopyright and authenticity risks. As a common technique for integrity\nverification and source tracing, digital image watermarking is regarded as a\npotential solution to above issues. Among these, watermarking methods capable\nof preserving the generation quality are receiving increased attention.\nHowever, the proliferation and high performance of generative image editing\napplications have elevated the risks of malicious tampering, creating new\ndemands. 1) The tamper robustness of current lossless visual quality watermarks\nremains constrained by the modification-sensitive diffusion inversion process,\nnecessitating enhanced robustness. 2) The improved tampering quality and rapid\niteration cycles render passive tampering detection methods inadequate, making\nproactive tampering localization capability a desired feature for watermarks.\nTo address these requirements, this paper proposes a Tamper-Aware Generative\nimage WaterMarking method named TAG-WM. The proposed method comprises four key\nmodules: a dual-mark joint sampling (DMJS) algorithm for embedding copyright\nand localization watermarks into the latent space while preserving generative\nquality, the watermark latent reconstruction (WLR) utilizing reversed DMJS, a\ndense variation region detector (DVRD) leveraging diffusion inversion\nsensitivity to identify tampered areas via statistical deviation analysis, and\nthe tamper-aware decoding (TAD) guided by localization results. The\nexperimental results indicate that TAG-WM achieves SOTA tampering robustness\nand tampering localization capability with distortions while maintaining\nlossless generation quality and a considerable capacity of 256 bits.", "AI": {"tldr": "This paper introduces TAG-WM, a watermarking method designed for tamper detection and localization in AI-generated content (AIGC), while ensuring image quality and robustness.", "motivation": "AI-generated content introduces risks such as copyright issues and malicious tampering, necessitating robust watermarking solutions that maintain image quality and proactively localize tampering.", "method": "TAG-WM includes four modules: dual-mark joint sampling (DMJS) for watermark embedding, watermark latent reconstruction (WLR), dense variation region detector (DVRD) for tampering detection, and tamper-aware decoding (TAD) for guided recovery.", "result": "Experiments show TAG-WM achieves state-of-the-art performance in robustness against tampering, accurate tampering localization, and maintains lossless generation quality with a watermark capacity of 256 bits.", "conclusion": "TAG-WM effectively addresses the challenges of watermark robustness and proactive tampering detection while supporting high-quality AI-generated images."}}
{"id": "2506.23537", "pdf": "https://arxiv.org/pdf/2506.23537", "abs": "https://arxiv.org/abs/2506.23537", "authors": ["Xinyue Li", "Zhangkai Ni", "Wenhan Yang"], "title": "AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted to International Conference on Computer Vision (ICCV) 2025", "summary": "Existing learning-based methods effectively reconstruct HDR images from\nmulti-exposure LDR inputs with extended dynamic range and improved detail, but\nthey rely more on empirical design rather than theoretical foundation, which\ncan impact their reliability. To address these limitations, we propose the\ncross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR\nreconstruction is systematically decoupled into two interleaved subtasks --\nalignment and fusion -- optimized through alternating refinement, achieving\nsynergy between the two subtasks to enhance the overall performance. Our method\nformulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP)\nestimation perspective, explicitly incorporating spatial correspondence priors\nacross LDR images and naturally bridging the alignment and fusion subproblems\nthrough joint constraints. Building on the mathematical foundation, we\nreimagine traditional iterative optimization through unfolding -- transforming\nthe conventional solution process into an end-to-end trainable AFUNet with\ncarefully designed modules that work progressively. Specifically, each\niteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that\nalternates between a Spatial Alignment Module (SAM) for alignment and a Channel\nFusion Module (CFM) for adaptive feature fusion, progressively bridging\nmisaligned content and exposure discrepancies. Extensive qualitative and\nquantitative evaluations demonstrate AFUNet's superior performance,\nconsistently surpassing state-of-the-art methods. Our code is available at:\nhttps://github.com/eezkni/AFUNet", "AI": {"tldr": "This paper introduces AFUNet, a learning-based deep unfolding network model for multi-exposure HDR reconstruction, combining alignment and fusion subtasks iteratively for enhanced performance.", "motivation": "Existing HDR reconstruction methods rely heavily on empirical designs, lacking a theoretical foundation, which affects reliability.", "method": "The paper proposes AFUNet, which systematically decouples HDR reconstruction into alignment and fusion subtasks optimized iteratively based on the Maximum A Posteriori (MAP) estimation framework.", "result": "AFUNet achieves superior HDR reconstruction performance, bridging misalignments and exposure discrepancies, and consistently outperforms state-of-the-art approaches in qualitative and quantitative evaluations.", "conclusion": "The proposed AFUNet method for HDR reconstruction effectively combines mathematical foundation and practical efficiency, demonstrating a significant advancement over existing approaches."}}
{"id": "2506.23664", "pdf": "https://arxiv.org/pdf/2506.23664", "abs": "https://arxiv.org/abs/2506.23664", "authors": ["Fangyijie Wang", "Kevin Whelan", "F\u00e9lix Balado", "Gu\u00e9nol\u00e9 Silvestre", "Kathleen M. Curran"], "title": "Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Medical image data is less accessible than in other domains due to privacy\nand regulatory constraints. In addition, labeling requires costly,\ntime-intensive manual image annotation by clinical experts. To overcome these\nchallenges, synthetic medical data generation offers a promising solution.\nGenerative AI (GenAI), employing generative deep learning models, has proven\neffective at producing realistic synthetic images. This study proposes a novel\nmask-guided GenAI approach using diffusion models to generate synthetic fetal\nhead ultrasound images paired with segmentation masks. These synthetic pairs\naugment real datasets for supervised fine-tuning of the Segment Anything Model\n(SAM). Our results show that the synthetic data captures real image features\neffectively, and this approach reaches state-of-the-art fetal head\nsegmentation, especially when trained with a limited number of real image-mask\npairs. In particular, the segmentation reaches Dice Scores of 94.66\\% and\n94.38\\% using a handful of ultrasound images from the Spanish and African\ncohorts, respectively. Our code, models, and data are available on GitHub.", "AI": {"tldr": "This study uses mask-guided diffusion models for generating synthetic fetal head ultrasound images and segmentation masks to augment datasets, achieving state-of-the-art segmentation using minimal real data.", "motivation": "Current medical image analysis faces challenges due to privacy concerns and the high cost of manual labeling by clinical experts, necessitating solutions like synthetic data generation.", "method": "A novel mask-guided generative AI approach employing diffusion models was used to generate synthetic fetal ultrasound images paired with segmentation masks, integrated with dataset augmentation for fine-tuning the Segment Anything Model.", "result": "Using synthetic data, the model achieved Dice Scores of 94.66% and 94.38% for segmentation in Spanish and African cohorts, respectively, demonstrating its effectiveness even with limited real data.", "conclusion": "The proposed method effectively generates synthetic medical data, capturing real image features and enabling superior segmentation performance, offering a promising solution for data-scarce medical imaging applications."}}
{"id": "2506.23700", "pdf": "https://arxiv.org/pdf/2506.23700", "abs": "https://arxiv.org/abs/2506.23700", "authors": ["Peiting Tian", "Xi Chen", "Haixia Bi", "Fan Li"], "title": "MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Medical image segmentation plays a crucial role in clinical diagnosis and\ntreatment planning, where accurate boundary delineation is essential for\nprecise lesion localization, organ identification, and quantitative assessment.\nIn recent years, deep learning-based methods have significantly advanced\nsegmentation accuracy. However, two major challenges remain. First, the\nperformance of these methods heavily relies on large-scale annotated datasets,\nwhich are often difficult to obtain in medical scenarios due to privacy\nconcerns and high annotation costs. Second, clinically challenging scenarios,\nsuch as low contrast in certain imaging modalities and blurry lesion boundaries\ncaused by malignancy, still pose obstacles to precise segmentation. To address\nthese challenges, we propose MedSAM-CA, an architecture-level fine-tuning\napproach that mitigates reliance on extensive manual annotations by adapting\nthe pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA\nintroduces two key components: the Convolutional Attention-Enhanced Boundary\nRefinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block\n(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover\nboundary information potentially overlooked by long-range attention mechanisms,\nleveraging hierarchical convolutional processing. Atte-FFB, embedded in the\nMedSAM decoder, fuses multi-level fine-grained features from skip connections\nin CBR-Net with global representations upsampled within the decoder to enhance\nboundary delineation accuracy. Experiments on publicly available datasets\ncovering dermoscopy, CT, and MRI imaging modalities validate the effectiveness\nof MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only\n2% of full training data, reaching 97.25% of full-data training performance,\ndemonstrating strong effectiveness in low-resource clinical settings.", "AI": {"tldr": "The paper introduces MedSAM-CA, a method for medical image segmentation that minimizes reliance on large datasets by enhancing the MedSAM model with architectural refinements, achieving high accuracy even in low-resource settings.", "motivation": "The authors aim to improve the accuracy of medical image segmentation in low-resource clinical settings, addressing challenges like the need for large annotated datasets and difficult imaging scenarios.", "method": "MedSAM-CA incorporates two novel mechanisms: CBR-Net, which adds convolutional attention for boundary refinement, and Atte-FFB, which fuses multi-level features to enhance delineation accuracy. These innovations are integrated with MedSAM.", "result": "When tested on dermoscopy datasets, MedSAM-CA achieved 94.43% Dice with only 2% of the full training data and reached 97.25% of the performance obtained with full-data training.", "conclusion": "MedSAM-CA demonstrates strong potential in addressing limitations of existing segmentation techniques, offering highly accurate results in scenarios with limited annotated data and challenging imaging conditions."}}
{"id": "2506.23701", "pdf": "https://arxiv.org/pdf/2506.23701", "abs": "https://arxiv.org/abs/2506.23701", "authors": ["Lingtong Zhang", "Mengdie Song", "Xiaohan Hao", "Huayu Mai", "Bensheng Qiu"], "title": "MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": "Accept by MICCAI2025", "summary": "Magnetic Resonance Imaging (MRI) reconstruction is essential in medical\ndiagnostics. As the latest generative models, diffusion models (DMs) have\nstruggled to produce high-fidelity images due to their stochastic nature in\nimage domains. Latent diffusion models (LDMs) yield both compact and detailed\nprior knowledge in latent domains, which could effectively guide the model\ntowards more effective learning of the original data distribution. Inspired by\nthis, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by\npre-trained LDMs to enhance data consistency in MRI reconstruction tasks.\nSpecifically, we first construct a Visual-Mamba-based backbone, which enables\nefficient encoding and reconstruction of under-sampled images. Then pre-trained\nLDMs are integrated to provide conditional priors in both latent and image\ndomains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion\nin multi-level latent domains. Simultaneously, to effectively utilize a prior\nin both the k-space and image domain, under-sampled images are fused with\ngenerated full-sampled images by the Dual-domain Fusion Branch (DFB) for\nself-adaption guidance. Lastly, to further enhance the data consistency, we\npropose a k-space regularization strategy based on the non-auto-calibration\nsignal (NACS) set. Extensive experiments on two public MRI datasets fully\ndemonstrate the effectiveness of the proposed methodology. The code is\navailable at https://github.com/Zolento/MDPG.", "AI": {"tldr": "The paper introduces Multi-domain Diffusion Prior Guidance (MDPG), which enhances MRI reconstruction by using latent diffusion models (LDMs) and a novel fusion strategy.", "motivation": "The difficulty in achieving high-fidelity, data-consistent MRI reconstructions with existing generative models motivates this work.", "method": "The authors propose a Visual-Mamba-based backbone and integrate pre-trained latent diffusion models (LDMs) with novel techniques like Latent Guided Attention (LGA) and a Dual-domain Fusion Branch (DFB). A k-space regularization strategy is also introduced.", "result": "Extensive experiments conducted on two public MRI datasets confirm the method\u2019s effectiveness in achieving accurate reconstructions.", "conclusion": "The proposed framework improves MRI reconstruction quality by effectively incorporating prior knowledge and enhancing data consistency."}}
{"id": "2506.23759", "pdf": "https://arxiv.org/pdf/2506.23759", "abs": "https://arxiv.org/abs/2506.23759", "authors": ["Zheng Fang", "Xiaoming Qi", "Chun-Mei Feng", "Jialun Pei", "Weixin Si", "Yueming Jin"], "title": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Surgical instrument segmentation under Federated Learning (FL) is a promising\ndirection, which enables multiple surgical sites to collaboratively train the\nmodel without centralizing datasets. However, there exist very limited FL works\nin surgical data science, and FL methods for other modalities do not consider\ninherent characteristics in surgical domain: i) different scenarios show\ndiverse anatomical backgrounds while highly similar instrument representation;\nii) there exist surgical simulators which promote large-scale synthetic data\ngeneration with minimal efforts. In this paper, we propose a novel Personalized\nFL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST),\nwhich wisely leverages surgical domain knowledge during both local-site and\nglobal-server training to boost segmentation. Concretely, our model embraces a\nRepresentation Separation and Cooperation (RSC) mechanism in local-site\ntraining, which decouples the query embedding layer to be trained privately, to\nencode respective backgrounds. Meanwhile, other parameters are optimized\nglobally to capture the consistent representations of instruments, including\nthe temporal layer to capture similar motion patterns. A textual-guided channel\nselection is further designed to highlight site-specific features, facilitating\nmodel adapta tion to each site. Moreover, in global-server training, we propose\nSynthesis-based Explicit Representation Quantification (SERQ), which defines an\nexplicit representation target based on synthetic data to synchronize the model\nconvergence during fusion for improving model generalization.", "AI": {"tldr": "The paper introduces FedST, a novel Federated Learning (FL) approach for surgical instrument segmentation, enhancing collaboration between multiple sites without centralizing data.", "motivation": "To address the lack of effective Federated Learning techniques specifically tailored for surgical instrument segmentation in diverse scenarios and leverage synthetic data efficiently.", "method": "The FedST model incorporates a Representation Separation and Cooperation mechanism for local-site training and Synthesis-based Explicit Representation Quantification for global-server training. It decouples embedding layers for personalized background handling while ensuring consistent instrument representation.", "result": "The proposed FedST method improves segmentation accuracy by strategically utilizing synthetic data, enhancing both site-specific adaptability and generalization across surgical datasets.", "conclusion": "FedST effectively leverages surgical domain characteristics to boost segmentation performance in Federated Learning settings, presenting a scalable solution for collaborative surgical data science research."}}
{"id": "2506.23957", "pdf": "https://arxiv.org/pdf/2506.23957", "abs": "https://arxiv.org/abs/2506.23957", "authors": ["Zinuo You", "Stamatios Georgoulis", "Anpei Chen", "Siyu Tang", "Dengxin Dai"], "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering", "categories": ["cs.GR", "cs.CV"], "comment": "siggraph 2025, project website: https://sinoyou.github.io/gavs", "summary": "Video stabilization is pivotal for video processing, as it removes unwanted\nshakiness while preserving the original user motion intent. Existing\napproaches, depending on the domain they operate, suffer from several issues\n(e.g. geometric distortions, excessive cropping, poor generalization) that\ndegrade the user experience. To address these issues, we introduce\n\\textbf{GaVS}, a novel 3D-grounded approach that reformulates video\nstabilization as a temporally-consistent `local reconstruction and rendering'\nparadigm. Given 3D camera poses, we augment a reconstruction model to predict\nGaussian Splatting primitives, and finetune it at test-time, with multi-view\ndynamics-aware photometric supervision and cross-frame regularization, to\nproduce temporally-consistent local reconstructions. The model are then used to\nrender each stabilized frame. We utilize a scene extrapolation module to avoid\nframe cropping. Our method is evaluated on a repurposed dataset, instilled with\n3D-grounded information, covering samples with diverse camera motions and scene\ndynamics. Quantitatively, our method is competitive with or superior to\nstate-of-the-art 2D and 2.5D approaches in terms of conventional task metrics\nand new geometry consistency. Qualitatively, our method produces noticeably\nbetter results compared to alternatives, validated by the user study.", "AI": {"tldr": "The paper introduces GaVS, a novel approach to video stabilization leveraging 3D-grounded reconstruction and rendering to address issues like geometric distortions and poor generalization in prior methods.", "motivation": "Existing video stabilization techniques often suffer from challenges such as geometric distortions, excessive cropping, and poor generalization, which degrade user experience.", "method": "GaVS reimagines video stabilization as a temporally-consistent 'local reconstruction and rendering' problem using 3D camera pose data, Gaussian Splatting primitives, photometric supervision, and scene extrapolation to stabilize video frames without excessive cropping.", "result": "The method is proven competitive or superior to state-of-the-art 2D and 2.5D stabilization methods in task metrics and geometric consistency, with significant qualitative improvements validated by a user study.", "conclusion": "GaVS effectively addresses prevalent issues in video stabilization, notably outperforming existing methods in both quantitative metrics and qualitative evaluations, offering a robust, geometry-consistent solution."}}
{"id": "2506.24003", "pdf": "https://arxiv.org/pdf/2506.24003", "abs": "https://arxiv.org/abs/2506.24003", "authors": ["Junqi Liu", "Dongli He", "Wenxuan Li", "Ningyu Wang", "Alan L. Yuille", "Zongwei Zhou"], "title": "ShapeKit", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In this paper, we present a practical approach to improve anatomical shape\naccuracy in whole-body medical segmentation. Our analysis shows that a\nshape-focused toolkit can enhance segmentation performance by over 8%, without\nthe need for model re-training or fine-tuning. In comparison, modifications to\nmodel architecture typically lead to marginal gains of less than 3%. Motivated\nby this observation, we introduce ShapeKit, a flexible and easy-to-integrate\ntoolkit designed to refine anatomical shapes. This work highlights the\nunderappreciated value of shape-based tools and calls attention to their\npotential impact within the medical segmentation community.", "AI": {"tldr": "A new toolkit, ShapeKit, is presented to improve anatomical segmentation accuracy by over 8% without retraining models.", "motivation": "To address the limited efficacy of model architecture changes in improving segmentation accuracy and to highlight the importance of shape-focused methods.", "method": "Introducing ShapeKit, a flexible, integrable toolkit designed to refine anatomical shapes in segmentation tasks without modifying model architecture.", "result": "The toolkit improves segmentation performance by over 8%, outperforming changes in model architecture which yield less than 3% improvement.", "conclusion": "Shape-focused tools like ShapeKit are valuable in improving medical segmentation and deserve more attention from the research community."}}
{"id": "2506.24034", "pdf": "https://arxiv.org/pdf/2506.24034", "abs": "https://arxiv.org/abs/2506.24034", "authors": ["George Webber", "Alexander Hammers", "Andrew P King", "Andrew J Reader"], "title": "Supervised Diffusion-Model-Based PET Image Reconstruction", "categories": ["physics.med-ph", "cs.CV"], "comment": "12 pages, 6 figures. Submitted to MICCAI 2025, not peer-reviewed", "summary": "Diffusion models (DMs) have recently been introduced as a regularizing prior\nfor PET image reconstruction, integrating DMs trained on high-quality PET\nimages with unsupervised schemes that condition on measured data. While these\napproaches have potential generalization advantages due to their independence\nfrom the scanner geometry and the injected activity level, they forgo the\nopportunity to explicitly model the interaction between the DM prior and noisy\nmeasurement data, potentially limiting reconstruction accuracy. To address\nthis, we propose a supervised DM-based algorithm for PET reconstruction. Our\nmethod enforces the non-negativity of PET's Poisson likelihood model and\naccommodates the wide intensity range of PET images. Through experiments on\nrealistic brain PET phantoms, we demonstrate that our approach outperforms or\nmatches state-of-the-art deep learning-based methods quantitatively across a\nrange of dose levels. We further conduct ablation studies to demonstrate the\nbenefits of the proposed components in our model, as well as its dependence on\ntraining data, parameter count, and number of diffusion steps. Additionally, we\nshow that our approach enables more accurate posterior sampling than\nunsupervised DM-based methods, suggesting improved uncertainty estimation.\nFinally, we extend our methodology to a practical approach for fully 3D PET and\npresent example results from real [$^{18}$F]FDG brain PET data.", "AI": {"tldr": "This paper introduces a supervised diffusion model (DM) algorithm for PET image reconstruction, showing improvements over state-of-the-art methods and enabling better uncertainty estimation.", "motivation": "To improve PET image reconstruction by addressing limitations of unsupervised diffusion models, which lack explicit interaction modeling between the DM prior and noisy measurement data, potentially affecting reconstruction accuracy.", "method": "Proposed a supervised DM-based algorithm that enforces non-negativity of PET's Poisson likelihood model and accommodates wide PET image intensity ranges. It also enables better posterior sampling and includes ablation studies to analyze model components and dependencies.", "result": "Experimental results on realistic brain PET phantoms indicate that the proposed method outperforms or matches state-of-the-art deep learning techniques across varying dose levels. It demonstrates improved posterior sampling accuracy and extends to fully 3D PET with results on real brain PET data.", "conclusion": "The proposed supervised DM-based method enhances PET reconstruction accuracy, offers robust uncertainty estimation, and presents practical applicability in 3D PET imaging, advancing the capabilities of DM-based approaches for this domain."}}
{"id": "2506.24074", "pdf": "https://arxiv.org/pdf/2506.24074", "abs": "https://arxiv.org/abs/2506.24074", "authors": ["Mayank V. Golhar", "Lucas Sebastian Galeano Fretes", "Loren Ayers", "Venkata S. Akshintala", "Taylor L. Bobrow", "Nicholas J. Durr"], "title": "C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism", "categories": ["eess.IV", "cs.CV"], "comment": "19 pages, 7 figures", "summary": "Computer vision techniques have the potential to improve the diagnostic\nperformance of colonoscopy, but the lack of 3D colonoscopy datasets for\ntraining and validation hinders their development. This paper introduces\nC3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video\nDataset, featuring enhanced realism designed to facilitate the quantitative\nevaluation of 3D colon reconstruction algorithms. 192 video sequences were\ncaptured by imaging 60 unique, high-fidelity silicone colon phantom segments.\nGround truth depth, surface normals, optical flow, occlusion,\nsix-degree-of-freedom pose, coverage maps, and 3D models are provided for 169\ncolonoscopy videos. Eight simulated screening colonoscopy videos acquired by a\ngastroenterologist are provided with ground truth poses. The dataset includes\n15 videos featuring colon deformations for qualitative assessment. C3VDv2\nemulates diverse and challenging scenarios for 3D reconstruction algorithms,\nincluding fecal debris, mucous pools, blood, debris obscuring the colonoscope\nlens, en-face views, and fast camera motion. The enhanced realism of C3VDv2\nwill allow for more robust and representative development and evaluation of 3D\nreconstruction algorithms.", "AI": {"tldr": "This paper introduces C3VDv2, a realistic, high-definition 3D colonoscopy video dataset designed to improve 3D reconstruction algorithm evaluation by providing diverse scenarios and ground truth data.", "motivation": "The development of computer vision methods for colonoscopy diagnostics is hindered by the lack of 3D datasets for training and validation to ensure accurate performance.", "method": "The dataset includes 192 high-fidelity 3D video recordings from 60 silicone colon phantoms, accompanied by detailed ground truth data for 169 videos and simulated screenings, along with challenging scenarios.", "result": "C3VDv2 offers diverse, realistic environment conditions such as fecal debris, lens obstructions, and rapid camera motion and includes a comprehensive range of metadata to evaluate reconstruction algorithms.", "conclusion": "C3VDv2 provides a meaningful step forward, offering a high-quality, diverse, and realistic dataset for advancing colonoscopy-related 3D computer vision technologies."}}
