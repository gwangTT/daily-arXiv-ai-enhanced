{"id": "2602.05488", "pdf": "https://arxiv.org/pdf/2602.05488", "abs": "https://arxiv.org/abs/2602.05488", "authors": ["Riccardo Carissimi", "Ben L. Titzer"], "title": "Wasure: A Modular Toolkit for Comprehensive WebAssembly Benchmarking", "categories": ["cs.PF"], "comment": null, "summary": "WebAssembly (Wasm) has become a key compilation target for portable and efficient execution across diverse platforms. Benchmarking its performance, however, is a multi-dimensional challenge: it depends not only on the choice of runtime engines, but also on hardware architectures, application domains, source languages, benchmark suites, and runtime configurations. This paper introduces Wasure, a modular and extensible command-line toolkit that simplifies the execution and comparison of WebAssembly benchmarks. To complement performance evaluation, we also conducted a dynamic analysis of the benchmark suites included with Wasure. Our analysis reveals substantial differences in code coverage, control flow, and execution patterns, emphasizing the need for benchmark diversity. Wasure aims to support researchers and developers in conducting more systematic, transparent, and insightful evaluations of WebAssembly engines.", "AI": {"tldr": "This paper introduces Wasure, a toolkit to simplify WebAssembly benchmarking and highlights the importance of benchmark diversity.", "motivation": "To address the challenges of benchmarking WebAssembly performance across various runtime engines, hardware, application domains, and configurations.", "method": "Developed Wasure, a modular command-line toolkit, and conducted dynamic analysis on benchmark suites included within it.", "result": "Revealed differences in code coverage, control flow, and execution patterns across benchmarks, demonstrating a need for diverse benchmarks.", "conclusion": "Wasure helps in making WebAssembly engine evaluations more systematic and transparent, aiding researchers and developers."}}
{"id": "2602.05458", "pdf": "https://arxiv.org/pdf/2602.05458", "abs": "https://arxiv.org/abs/2602.05458", "authors": ["Anatoly A. Krasnovsky"], "title": "Emergence-as-Code for Self-Governing Reliable Systems", "categories": ["cs.SE", "cs.DC", "cs.PF", "eess.SY"], "comment": null, "summary": "SLO-as-code has made per-service} reliability declarative, but user experience is defined by journeys whose reliability is an emergent property of microservice topology, routing, redundancy, timeouts/fallbacks, shared failure domains, and tail amplification. As a result, journey objectives (e.g., \"checkout p99 < 400 ms\") are often maintained outside code and drift as the system evolves, forcing teams to either miss user expectations or over-provision and gate releases with ad-hoc heuristics. We propose Emergence-as-Code (EmaC), a vision for making journey reliability computable and governable via intent plus evidence. An EmaC spec declares journey intent (objective, control-flow operators, allowed actions) and binds it to atomic SLOs and telemetry. A runtime inference component consumes operational artifacts (e.g., tracing and traffic configuration) to synthesize a candidate journey model with provenance and confidence. From the last accepted model, the EmaC compiler/controller derives bounded journey SLOs and budgets under explicit correlation assumptions (optimistic independence vs. pessimistic shared fate), and emits control-plane artifacts (burn-rate alerts, rollout gates, action guards) that are reviewable in a Git workflow. An anonymized artifact repository provides a runnable example specification and generated outputs.", "AI": {"tldr": "The paper introduces \"Emergence-as-Code\" (EmaC), a framework aimed at improving the reliability of user journeys in systems by making their reliability measurable and governable through declarative specifications.", "motivation": "Existing approaches to user journey reliability suffer from being manual, external to code, and prone to drift as system configurations evolve, which leads to either failed user expectations or over-provisioned resources.", "method": "The authors propose Emergence-as-Code (EmaC), which provides declarative specifications for journey objectives bound to microservice-level reliability data, leveraging runtime inference and telemetry to compute journey reliability and derive actionable control-plane artifacts.", "result": "EmaC enables automated, governable, and verifiable journey reliability management by synthesizing operational data into actionable artifacts, ensuring alignment between user expectations and system performance.", "conclusion": "EmaC introduces an innovative framework to manage journey reliability by integrating objectives and operational evidence directly into code workflows, thus mitigating drift, improving consistency, and enhancing governance."}}
{"id": "2602.05695", "pdf": "https://arxiv.org/pdf/2602.05695", "abs": "https://arxiv.org/abs/2602.05695", "authors": ["Hiari Pizzini Cavagna", "Andrea Proia", "Giacomo Madella", "Giovanni B. Esposito", "Francesco Antici", "Daniele Cesarini", "Zeynep Kiziltan", "Andrea Bartolini"], "title": "Determining Energy Efficiency Sweet Spots in Production LLM Inference", "categories": ["cs.AI", "cs.PF"], "comment": "To appear at ICPE 2026 (International Conference on Performance Engineering)", "summary": "Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy Efficiency regimes: peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs, indicating a non-linear dependency. In this work, we propose an analytical model derived from the computational and memory-access complexity of the Transformer architecture, capable of accurately characterizing the efficiency curve as a function of input and output lengths. To assess its accuracy, we evaluate energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite, tested over input and output lengths from 64 to 4096 tokens, achieving a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency \"Sweet Spots\" can substantially reduce energy usage, supporting informed truncation, summarization, and adaptive generation strategies in production systems.", "AI": {"tldr": "This paper addresses the energy efficiency of Large Language Models (LLMs) by identifying optimal input and output length ranges, proposing an analytical efficiency model with a mean error of 1.79%, and suggesting strategies to reduce energy consumption.", "motivation": "The motivation is to understand and optimize the energy consumption of LLM inference, which has a significant footprint in modern AI applications.", "method": "They propose an analytical model based on Transformer architecture's computational and memory-access complexities, validated through energy consumption measurements across various LLMs and token lengths using TensorRT-LLM on NVIDIA H100 GPUs.", "result": "They identify that peak energy efficiency occurs at specific input and output lengths, with significant energy savings possible when these lengths are optimized. The proposed model achieves a mean absolute percentage error (MAPE) of 1.79% when predicting energy consumption.", "conclusion": "Aligning input and output lengths of LLMs with identified efficiency zones can lead to substantial energy savings, enabling more sustainable and cost-effective AI usage."}}
{"id": "2602.05466", "pdf": "https://arxiv.org/pdf/2602.05466", "abs": "https://arxiv.org/abs/2602.05466", "authors": ["Iv\u00e1n Olarte Rodr\u00edguez", "Gokhan Serhat", "Mariusz Bujny", "Fabian Duddeck", "Thomas B\u00e4ck", "Elena Raponi"], "title": "Optimization is Not Enough: Why Problem Formulation Deserves Equal Attention", "categories": ["cs.NE", "cs.CE"], "comment": "25 pages, 11 figures, 4 table, submitted at Conference on Evolutionary Computation, Theory and Applications (ECTA) 2025", "summary": "Black-box optimization is increasingly used in engineering design problems where simulation-based evaluations are costly and gradients are unavailable. In this context, the optimization community has largely analyzed algorithm performance in context-free setups, while not enough attention has been devoted to how problem formulation and domain knowledge may affect the optimization outcomes. We address this gap through a case study in the topology optimization of laminated composite structures, formulated as a black-box optimization problem. Specifically, we consider the design of a cantilever beam under a volume constraint, intending to minimize compliance while optimizing both the structural topology and fiber orientations. To assess the impact of problem formulation, we explicitly separate topology and material design variables and compare two strategies: a concurrent approach that optimizes all variables simultaneously without leveraging physical insight, and a sequential approach that optimizes variables of the same nature in stages. Our results show that context-agnostic strategies consistently lead to suboptimal or non-physical designs. In contrast, the sequential strategy yields better-performing and more interpretable solutions. These findings underscore the value of incorporating, when available, domain knowledge into the optimization process and motivate the development of new black-box benchmarks that reward physically informed and context-aware optimization strategies.", "AI": {"tldr": "The paper compares concurrent and sequential approaches to black-box optimization for designing laminated composite structures, emphasizing the importance of using domain knowledge.", "motivation": "The optimization community has not adequately explored how problem formulation and domain knowledge affect outcomes in black-box optimization processes.", "method": "A case study of designing cantilever beams was conducted using two strategies: concurrent (optimizing all variables together) and sequential (optimizing variables in stages).", "result": "Context-agnostic concurrent strategies resulted in suboptimal or non-physical designs, while sequential strategies led to better-performing and interpretable solutions.", "conclusion": "Domain knowledge significantly enhances the optimization process, and benchmarks should reward strategies that integrate physical insight and context awareness."}}
{"id": "2602.04991", "pdf": "https://arxiv.org/pdf/2602.04991", "abs": "https://arxiv.org/abs/2602.04991", "authors": ["Simone Manoni", "Emanuele Parisi", "Riccardo Tedeschi", "Davide Rossi", "Andrea Acquaviva", "Andrea Bartolini"], "title": "CVA6-CFI: A First Glance at RISC-V Control-Flow Integrity Extensions", "categories": ["cs.AR", "cs.CR"], "comment": "Accepted as a lecture at the 2026 IEEE International Symposium on Circuits and Systems. Preprint version", "summary": "This work presents the first design, integration, and evaluation of the standard RISC-V extensions for Control-Flow Integrity (CFI). The Zicfiss and Zicfilp extensions aim at protecting the execution of a vulnerable program from control-flow hijacking attacks through the implementation of security mechanisms based on shadow stack and landing pad primitives. We introduce two independent and configurable hardware units implementing forward-edge and backward-edge control-flow protection, fully integrated into the open-source CVA6 core. Our design incurs in only 1.0% area overhead when synthesized in 22 nm FDX technology, and up to 15.6% performance overhead based on evaluation with the MiBench automotive benchmark subset. We release the complete implementation as open source.", "AI": {"tldr": "The paper introduces and evaluates RISC-V extensions (Zicfiss and Zicfilp) for control-flow integrity, implementing mechanisms to prevent control-flow hijacking attacks, with minor area and performance overhead.", "motivation": "To address control-flow vulnerabilities in RISC-V architecture by developing and integrating security mechanisms to protect against attacks.", "method": "Design of Zicfiss and Zicfilp security extensions using shadow stack and landing pad primitives, integrating them into the CVA6 core as independent hardware units.", "result": "Achieved 1.0% area overhead in 22 nm FDX technology and up to 15.6% performance overhead using the MiBench automotive benchmark evaluation.", "conclusion": "The presented extensions effectively safeguard the control-flow integrity in RISC-V processors with minimal design overhead, and the implementation is released as open-source."}}
{"id": "2602.05017", "pdf": "https://arxiv.org/pdf/2602.05017", "abs": "https://arxiv.org/abs/2602.05017", "authors": ["Jose-Luis Estragues-Mu\u00f1oz", "Carlos Alvarez", "Arnau Montagud", "Daniel Jimenez-Gonzalez", "Alfonso Valencia"], "title": "A novel scalable high performance diffusion solver for multiscale cell simulations", "categories": ["cs.DC", "q-bio.CB"], "comment": "14 pages, 9 figures", "summary": "Agent-based cellular models simulate tissue evolution by capturing the behavior of individual cells, their interactions with neighboring cells, and their responses to the surrounding microenvironment. An important challenge in the field is scaling cellular resolution models to real-scale tumor simulations, which is critical for the development of digital twin models of diseases and requires the use of High-Performance Computing (HPC) since every time step involves trillions of operations. We hereby present a scalable HPC solution for the molecular diffusion modeling using an efficient implementation of state-of-the-art Finite Volume Method (FVM) frameworks. The paper systematically evaluates a novel scalable Biological Finite Volume Method (BioFVM) library and presents an extensive performance analysis of the available solutions. Results shows that our HPC proposal reach almost 200x speedup and up to 36% reduction in memory usage over the current state-of-the-art solutions, paving the way to efficiently compute the next generation of biological problems.", "AI": {"tldr": "This study proposes a scalable HPC solution for tumor simulation using an improved Biological Finite Volume Method (BioFVM), achieving significant speedup and memory reduction.", "motivation": "To address the computational challenge of scaling cellular models for real-scale tumor simulations, essential for digital twin models of diseases.", "method": "Implemented an efficient, scalable Biological Finite Volume Method (BioFVM) library within High-Performance Computing environments.", "result": "The HPC solution achieved almost 200x speedup and a memory reduction of up to 36% compared to existing methods.", "conclusion": "This work significantly improves performance and memory efficiency in modeling molecular diffusion, advancing real-scale biological problem computation."}}
{"id": "2602.04982", "pdf": "https://arxiv.org/pdf/2602.04982", "abs": "https://arxiv.org/abs/2602.04982", "authors": ["Deepak Gupta", "Davis Bartels", "Dina Demner-Fuhsman"], "title": "BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluation of text generated by LLMs remains a challenge for question answering, retrieval-augmented generation (RAG), summarization, and many other natural language processing tasks in the biomedical domain, due to the requirements of expert assessment to verify consistency with the scientific literature and complex medical terminology. In this work, we propose BioACE, an automated framework for evaluating biomedical answers and citations against the facts stated in the answers. The proposed BioACE framework considers multiple aspects, including completeness, correctness, precision, and recall, in relation to the ground-truth nuggets for answer evaluation. We developed automated approaches to evaluate each of the aforementioned aspects and performed extensive experiments to assess and analyze their correlation with human evaluations. In addition, we considered multiple existing approaches, such as natural language inference (NLI) and pre-trained language models and LLMs, to evaluate the quality of evidence provided to support the generated answers in the form of citations into biomedical literature. With the detailed experiments and analysis, we provide the best approaches for biomedical answer and citation evaluation as a part of BioACE (https://github.com/deepaknlp/BioACE) evaluation package.", "AI": {"tldr": "This paper introduces BioACE, an automated framework for evaluating the quality of biomedical answers and their supporting citations generated by large language models (LLMs).", "motivation": "With the growing application of LLMs in generating biomedical responses, there is a pressing need for automated tools to verify the quality, consistency, and evidence behind such responses, due to the complexity of medical terminology and scientific literature requirements.", "method": "BioACE employs automated approaches to assess various aspects of answer quality\u2014completeness, correctness, precision, and recall\u2014relative to ground-truth nuggets. Additionally, it integrates methods such as natural language inference and pre-trained language models to evaluate citation support in biomedical literature.", "result": "Extensive experiments demonstrated correlations between BioACE\u2019s automated evaluations and human assessments, and the study identified the most effective methods for answer and citation evaluation.", "conclusion": "BioACE represents a novel, robust framework for automating the evaluation of biomedical answers and citations, enhancing the reliability of LLM outputs in the biomedical domain."}}
{"id": "2602.04892", "pdf": "https://arxiv.org/pdf/2602.04892", "abs": "https://arxiv.org/abs/2602.04892", "authors": ["Shihao Xia", "Mengting He", "Haomin Jia", "Linhai Song"], "title": "Doc2Spec: Synthesizing Formal Programming Specifications from Natural Language via Grammar Induction", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": null, "summary": "Ensuring that API implementations and usage comply with natural language programming rules is critical for software correctness, security, and reliability. Formal verification can provide strong guarantees but requires precise specifications, which are difficult and costly to write manually. To address this challenge, we present Doc2Spec, a multi-agent framework that uses LLMs to automatically induce a specification grammar from natural-language rules and then generates formal specifications guided by the induced grammar. The grammar captures essential domain knowledge, constrains the specification space, and enforces consistent representations, thereby improving the reliability and quality of generated specifications. Evaluated on seven benchmarks across three programming languages, Doc2Spec outperforms a baseline without grammar induction and achieves competitive results against a technique with a manually crafted grammar, demonstrating the effectiveness of automated grammar induction for formalizing natural-language rules.", "AI": {"tldr": "Doc2Spec is a multi-agent framework that employs LLMs for automated grammar induction to generate formal API specifications from natural language, ensuring software correctness and reliability.", "motivation": "The paper addresses the difficulty and cost of writing precise formal specifications manually\u2014essential for ensuring software correctness, security, and reliability in API usage and implementations.", "method": "The authors propose Doc2Spec, which uses LLMs in a multi-agent framework to automatically induce specification grammar from natural language. This grammar is then used to guide the generation of formal specifications.", "result": "Doc2Spec outperforms a baseline approach lacking grammar induction and achieves competitive results compared to techniques that use manually crafted grammars, proving its effectiveness across seven benchmarks in three programming languages.", "conclusion": "Automated grammar induction can effectively formalize natural-language rules, reducing manual effort and improving the quality of software specifications."}}
{"id": "2602.05971", "pdf": "https://arxiv.org/pdf/2602.05971", "abs": "https://arxiv.org/abs/2602.05971", "authors": ["Felipe D. Toro-Hern\u00e1ndez", "Jesuino Vieira Filho", "Rodrigo M. Cabral-Carvalho"], "title": "Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space", "categories": ["cs.CL", "cs.LG", "q-bio.NC"], "comment": "10 pages, 6 figures (excluding refs/appendix). Accepted to ICLR 2026", "summary": "Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.", "AI": {"tldr": "The paper proposes a framework for studying semantic representation as navigation through a dynamic embedding space, extracting metrics such as velocity and entropy to understand semantic trajectories.", "motivation": "The work aims to bridge cognitive modeling and learned representation, providing a computational approach requiring minimal intervention to study semantic navigation and its dynamics in different languages and contexts.", "method": "Participant-specific semantic trajectories are constructed using embeddings from transformer text models. Metrics like distance to centroid, entropy, and acceleration quantify semantic navigation. Multiple datasets and languages were analyzed using cumulative and non-cumulative approaches.", "result": "The framework distinguishes between clinical groups and concept types. Cumulative embeddings proved effective for long trajectories, while shorter trajectories favored non-cumulative embeddings. Different embedding models showed similar results, validating the generalizability of the approach.", "conclusion": "Semantic navigation can be framed as structured trajectories in embedding space, offering a computational tool beneficial in clinical research, cross-linguistic analysis, and artificial cognition assessment with minimal manual preprocessing needed."}}
{"id": "2602.04910", "pdf": "https://arxiv.org/pdf/2602.04910", "abs": "https://arxiv.org/abs/2602.04910", "authors": ["Nongyu Di", "Tianyu Chen", "Shan Lu", "Shuai Lu", "Yeyun Gong", "Peng Cheng", "Jacob R. Lorch", "Yuan Yao", "Xiaoxing Ma"], "title": "Reducing the Costs of Proof Synthesis on Rust Systems by Scaling Up a Seed Training Set", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) are widely used for code generation. However, the correctness of code generated by LLMs remains a concern. A potential remedy to this concern is to have LLMs generate formal correctness proofs along with such code. However, compared with code generation, code-proof generation requires much higher reasoning capability and has much less existing data to learn from. In this paper, we present VeruSyn, a data synthesis pipeline for Verus, a state-of-the-art verification tool for system software written in Rust. Through self-synthesis and tutorial-based synthesis, VeruSyn achieves much larger scale and Verus-feature coverage than previous data-synthesis techniques designed for Verus; VeruSyn also supplements its dataset with long-chain-of-thought (CoT) data through agent trajectory synthesis. With VeruSyn, we synthesize the largest set of Verus verified programs: 6.9 million Rust programs, each with a formal specification and a proof that it meets that specification. This dataset lets us create a fine-tuned Qwen2.5-Coder-32B-Instruct model with appealing cost-proof tradeoff compared with state-of-the-art commercial models like Claude Sonnet 4.5. It also significantly outperforms models like o4-mini and previously proposed research models.", "AI": {"tldr": "The paper introduces VeruSyn, a data synthesis pipeline for Verus that generates verified Rust programs with formal proofs, enhancing code-proof generation capabilities in LLMs.", "motivation": "The correctness of LLM-generated code is a concern, and generating formal proofs along with code is a potential solution. This study aims to address the challenges of higher reasoning requirements and limited data in code-proof generation.", "method": "The authors developed VeruSyn, using self-synthesis, tutorial-based synthesis, and agent trajectory synthesis to generate large-scale datasets, including 6.9 million verified Rust programs with formal specifications and proofs.", "result": "Using the VeruSyn dataset, the fine-tuned Qwen2.5-Coder-32B-Instruct model demonstrates a compelling cost-performance tradeoff and outperforms existing models like o4-mini and research models.", "conclusion": "VeruSyn significantly advances the field by generating expansive datasets for verified code, enabling improvements in code-proof generation and making state-of-the-art commercial and research models more effective."}}
{"id": "2602.05010", "pdf": "https://arxiv.org/pdf/2602.05010", "abs": "https://arxiv.org/abs/2602.05010", "authors": ["Maia Stiber", "Sameer Khan", "Russell Taylor", "Chien-Ming Huang"], "title": "Signal or 'Noise': Human Reactions to Robot Errors in the Wild", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "In the real world, robots frequently make errors, yet little is known about people's social responses to errors outside of lab settings. Prior work has shown that social signals are reliable and useful for error management in constrained interactions, but it is unclear if this holds in the real world - especially with a non-social robot in repeated and group interactions with successive or propagated errors. To explore this, we built a coffee robot and conducted a public field deployment ($N = 49$). We found that participants consistently expressed varied social signals in response to errors and other stimuli, particularly during group interactions. Our findings suggest that social signals in the wild are rich (with participants volunteering information about the interaction), but \"noisy.\" We discuss lessons, benefits, and challenges for using social signals in real-world HRI.", "AI": {"tldr": "The study investigates people\u2019s social responses to robot errors in real-world settings, focusing on a coffee robot in group interactions.", "motivation": "To understand how people socially respond to robot errors in real-world scenarios and assess the reliability of social signals during robot interactions.", "method": "The researchers deployed a coffee robot in a public field study with 49 participants to observe and analyze social signals during robot errors and group interactions.", "result": "Participants displayed varied and rich but noisy social signals in response to the robot's errors, especially during group interactions.", "conclusion": "Social signals are valuable in human-robot interactions in real-world scenarios, but their noisiness presents challenges, offering lessons for future studies and applications in HRI."}}
{"id": "2602.04994", "pdf": "https://arxiv.org/pdf/2602.04994", "abs": "https://arxiv.org/abs/2602.04994", "authors": ["Zhuosen Bao", "Xia Du", "Zheng Lin", "Jizhe Zhou", "Zihan Fang", "Jiening Wu", "Yuxin Zhang", "Zhe Chen", "Chi-man Pun", "Wei Ni", "Jun Luo"], "title": "SIDeR: Semantic Identity Decoupling for Unrestricted Face Privacy", "categories": ["cs.CV", "cs.LG"], "comment": "14 pages, 8 figures", "summary": "With the deep integration of facial recognition into online banking, identity verification, and other networked services, achieving effective decoupling of identity information from visual representations during image storage and transmission has become a critical challenge for privacy protection. To address this issue, we propose SIDeR, a Semantic decoupling-driven framework for unrestricted face privacy protection. SIDeR decomposes a facial image into a machine-recognizable identity feature vector and a visually perceptible semantic appearance component. By leveraging semantic-guided recomposition in the latent space of a diffusion model, it generates visually anonymous adversarial faces while maintaining machine-level identity consistency. The framework incorporates momentum-driven unrestricted perturbation optimization and a semantic-visual balancing factor to synthesize multiple visually diverse, highly natural adversarial samples. Furthermore, for authorized access, the protected image can be restored to its original form when the correct password is provided. Extensive experiments on the CelebA-HQ and FFHQ datasets demonstrate that SIDeR achieves a 99% attack success rate in black-box scenarios and outperforms baseline methods by 41.28% in PSNR-based restoration quality.", "AI": {"tldr": "The paper introduces SIDeR, a framework designed to protect face privacy by decoupling identity information from visual face representations, with high attack success rates and restoration quality.", "motivation": "The integration of facial recognition into various services prompts the need for privacy protection, specifically for decoupling identity information from image storage and transmission.", "method": "SIDeR utilizes a semantic-driven decomposition of facial images into identity feature vectors and appearance components using diffusion models. It generates adversarial faces and restores original images for authorized access.", "result": "Experiments show SIDeR achieves 99% attack success rate in black-box tests and improves restoration quality by 41.28% compared to baseline methods.", "conclusion": "SIDeR effectively balances privacy protection and identity verification, demonstrating advancements in adversarial face generation and image restoration."}}
{"id": "2602.04986", "pdf": "https://arxiv.org/pdf/2602.04986", "abs": "https://arxiv.org/abs/2602.04986", "authors": ["Kendra Chilson", "Eric Schwitzgebel"], "title": "Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: \"familiar intelligence\" and \"strange intelligence\". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which \"general intelligence\" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.", "AI": {"tldr": "This paper critiques the linear model of AI progress and introduces the nonlinear concepts of \"familiar intelligence\" and \"strange intelligence,\" emphasizing AI's uneven abilities.", "motivation": "The paper challenges the traditional linear view of AI progress, arguing that intelligence should include diverse, non-linear capacities that defy simplistic measures.", "method": "The authors introduce and advocate for a nonlinear model of intelligence, distinguishing between \"strange intelligence\" and general intelligence, and propose implications for AI evaluation.", "result": "The paper demonstrates that AI intelligence may exhibit superhuman abilities in some areas while showing subhuman errors in others, supporting the nonlinear model.", "conclusion": "AI intelligence should be evaluated in a nonlinear framework, where performance inconsistencies do not necessarily reflect overall lack of general intelligence."}}
{"id": "2602.05172", "pdf": "https://arxiv.org/pdf/2602.05172", "abs": "https://arxiv.org/abs/2602.05172", "authors": ["Ye He", "Krishnakumar Balasubramanian", "Sayan Banerjee", "Promit Ghosal"], "title": "Finite-Particle Rates for Regularized Stein Variational Gradient Descent", "categories": ["stat.ML", "cs.LG", "math.ST"], "comment": null, "summary": "We derive finite-particle rates for the regularized Stein variational gradient descent (R-SVGD) algorithm introduced by He et al. (2024) that corrects the constant-order bias of the SVGD by applying a resolvent-type preconditioner to the kernelized Wasserstein gradient. For the resulting interacting $N$-particle system, we establish explicit non-asymptotic bounds for time-averaged (annealed) empirical measures, illustrating convergence in the \\emph{true} (non-kernelized) Fisher information and, under a $\\mathrm{W}_1\\mathrm{I}$ condition on the target, corresponding $\\mathrm{W}_1$ convergence for a large class of smooth kernels. Our analysis covers both continuous- and discrete-time dynamics and yields principled tuning rules for the regularization parameter, step size, and averaging horizon that quantify the trade-off between approximating the Wasserstein gradient flow and controlling finite-particle estimation error.", "AI": {"tldr": "The paper develops finite-particle convergence rates for the regularized Stein variational gradient descent (R-SVGD) algorithm, introducing bounds and conditions for its optimal operation.", "motivation": "To address the bias issues in classical Stein variational gradient descent (SVGD) by introducing an enhanced algorithm (R-SVGD) that corrects this bias using a specialized preconditioner approach.", "method": "The authors analyzed the R-SVGD algorithm, introducing a resolvent-type preconditioner to the kernelized Wasserstein gradient. They derived non-asymptotic convergence bounds for time-averaged empirical measures and studied both continuous- and discrete-time dynamics. They also developed guidelines for tuning various operational parameters for the algorithm.", "result": "The study quantified convergence in Fisher information and Wasserstein distance for smooth kernels. The derived bounds and conditions provide principled strategies for balancing bias correction and estimation error in both time regimes.", "conclusion": "The paper establishes rigorous bounds and design principles for R-SVGD, making it an improved method for approximating Wasserstein gradient flow while reducing finite-particle bias effects."}}
{"id": "2602.04886", "pdf": "https://arxiv.org/pdf/2602.04886", "abs": "https://arxiv.org/abs/2602.04886", "authors": ["Luke Whitbread", "Lyle J. Palmer", "Mark Jenkinson"], "title": "Denoising diffusion networks for normative modeling in neuroimaging", "categories": ["cs.LG", "cs.AI", "cs.CE", "stat.ML"], "comment": "55 pages, 20 figures", "summary": "Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived phenotype (IDP), which scales well but discards multivariate dependence that may encode coordinated patterns. We propose denoising diffusion probabilistic models (DDPMs) as a unified conditional density estimator for tabular IDPs, from which univariate centiles and deviation scores are derived by sampling. We utilise two denoiser backbones: (i) a feature-wise linear modulation (FiLM) conditioned multilayer perceptron (MLP) and (ii) a tabular transformer with feature self-attention and intersample attention (SAINT), conditioning covariates through learned embeddings. We evaluate on a synthetic benchmark with heteroscedastic and multimodal age effects and on UK Biobank FreeSurfer phenotypes, scaling from dimension of 2 to 200. Our evaluation suite includes centile calibration (absolute centile error, empirical coverage, and the probability integral transform), distributional fidelity (Kolmogorov-Smirnov tests), multivariate dependence diagnostics, and nearest-neighbour memorisation analysis. For low dimensions, diffusion models deliver well-calibrated per-IDP outputs comparable to traditional baselines while jointly modeling realistic dependence structure. At higher dimensions, the transformer backbone remains substantially better calibrated than the MLP and better preserves higher-order dependence, enabling scalable joint normative models that remain compatible with standard per-IDP pipelines. These results support diffusion-based normative modeling as a practical route to calibrated multivariate deviation profiles in neuroimaging.", "AI": {"tldr": "This paper introduces a novel application of denoising diffusion probabilistic models (DDPMs) for normative modeling of neuroimaging data, enabling better calibration and dependency representation in imaging-derived phenotypes (IDPs).", "motivation": "Existing normative modeling techniques discard important multivariate dependencies among neuroimaging-derived phenotypes due to their reliance on separate models for each variable, which may miss patterns important for clinical interpretation.", "method": "The authors propose using DDPMs for modeling tabular imaging-derived phenotypes (IDPs) while considering conditional covariates. They implement two model architectures: (i) FiLM-conditioned MLP and (ii) SAINT-based tabular transformers with attention mechanisms, enabling scalable joint modeling of multivariate dependencies.", "result": "The experiments on synthetic benchmarks and UK Biobank data demonstrate that diffusion models achieve robust calibration in low dimensional settings and preserve realistic dependence structures in high dimensional data. The transformer-based backbone outperforms MLP and achieves better higher-order dependency preservation.", "conclusion": "Diffusion models represent a promising approach for normative modeling in neuroimaging, delivering calibrated multivariate deviation scores and improving upon traditional methods, particularly in handling high-dimensional data with realistic dependencies."}}
{"id": "2602.05675", "pdf": "https://arxiv.org/pdf/2602.05675", "abs": "https://arxiv.org/abs/2602.05675", "authors": ["Xuepeng Ren", "Maocai Wang", "Guangming Dai", "Zimin Liang", "Qianrong Liu", "Shengxiang Yang", "Miqing Li"], "title": "Variable Search Stepsize for Randomized Local Search in Multi-Objective Combinatorial Optimization", "categories": ["cs.NE"], "comment": null, "summary": "Over the past two decades, research in evolutionary multi-objective optimization has predominantly focused on continuous domains, with comparatively limited attention given to multi-objective combinatorial optimization problems (MOCOPs). Combinatorial problems differ significantly from continuous ones in terms of problem structure and landscape. Recent studies have shown that on MOCOPs multi-objective evolutionary algorithms (MOEAs) can even be outperformed by simple randomised local search. Starting with a randomly sampled solution in search space, randomised local search iteratively draws a random solution (from an archive) to perform local variation within its neighbourhood. However, in most existing methods, the local variation relies on a fixed neighbourhood, which limits exploration and makes the search easy to get trapped in local optima. In this paper, we present a simple yet effective local search method, called variable stepsize randomized local search (VS-RLS), which adjusts the stepsize during the search. VS-RLS transitions gradually from a broad, exploratory search in the early phases to a more focused, fine-grained search as the search progresses. We demonstrate the effectiveness and generalizability of VS-RLS through extensive evaluations against local search and MOEAs methods on diverse MOCOPs.", "AI": {"tldr": "The paper introduces a novel randomized local search method, VS-RLS, to address limitations in multi-objective combinatorial optimization problems (MOCOPs), outperforming existing approaches.", "motivation": "Existing methods in MOCOPs, particularly multi-objective evolutionary algorithms (MOEAs), often underperform due to insufficient exploration and being prone to local optima. A new approach is needed to enhance search capabilities.", "method": "The proposed variable stepsize randomized local search (VS-RLS) adapts the stepsize during the search process, transitioning from exploratory searches to fine-grained exploration over time.", "result": "Extensive evaluations demonstrate VS-RLS's superior performance and generalizability compared to traditional local search methods and MOEAs on diverse MOCOPs.", "conclusion": "VS-RLS is shown to be an effective and generalizable solution to overcome local optima issues in MOCOPs, improving search efficiency and outcomes."}}
{"id": "2602.05018", "pdf": "https://arxiv.org/pdf/2602.05018", "abs": "https://arxiv.org/abs/2602.05018", "authors": ["Hongbang Wu", "Xuesi Chen", "Shubham Jadhav", "Amit Lal", "Lillian Pentecost", "Udit Gupta"], "title": "COFFEE: A Carbon-Modeling and Optimization Framework for HZO-based FeFET eNVMs", "categories": ["cs.AR"], "comment": null, "summary": "Information and communication technologies account for a growing portion of global environmental impacts. While emerging technologies, such as emerging non-volatile memories (eNVM), offer a promising solution to energy efficient computing, their end-to-end footprint is not well understood. Understanding the environmental impact of hardware systems over their life cycle is the first step to realizing sustainable computing. This work conducts a detailed study of one example eNVM device: hafnium-zirconium-oxide (HZO)-based ferroelectric field-effect transistors (FeFETs). We present COFFEE, the first carbon modeling framework for HZO-based FeFET eNVMs across life cycle, from hardware manufacturing (embodied carbon) to use (operational carbon). COFFEE builds on data gathered from a real semiconductor fab and device fabrication recipes to estimate embodied carbon, and architecture level eNVM design space exploration tools to quantify use-phase performance and energy. Our evaluation shows that, at 2 MB capacity, the embodied carbon per unit area overhead of HZO-FeFETs can be up to 11% higher than the CMOS baseline, while the embodied carbon per MB remains consistently about 4.3x lower than SRAM across different memory capacity. A further case study applies COFFEE to an edge ML accelerator, showing that replacing the SRAM-based weight buffer with HZO-based FeFET eNVMs reduces embodied carbon by 42.3% and operational carbon by up to 70%.", "AI": {"tldr": "This paper introduces COFFEE, a carbon modeling framework for assessing the environmental impact of HZO-based FeFET eNVMs throughout their life cycle, highlighting reductions in both embodied and operational carbon.", "motivation": "To address the growing environmental impacts of information and communication technologies and understand the sustainability of eNVMs like HZO-based FeFETs.", "method": "The paper develops COFFEE, leveraging data from semiconductor fabrication processes and architecture-level design tools to model embodied and operational carbon for HZO-based FeFETs over their life cycle.", "result": "HZO-FeFETs have a lower embodied carbon per MB compared to SRAM (by 4.3x) and can significantly reduce carbon impacts when integrated into systems like edge ML accelerators: 42.3% reduction in embodied carbon and up to 70% reduction in operational carbon.", "conclusion": "HZO-based FeFET eNVMs demonstrate significant environmental advantages, making them promising for sustainable computing hardware development."}}
{"id": "2602.05131", "pdf": "https://arxiv.org/pdf/2602.05131", "abs": "https://arxiv.org/abs/2602.05131", "authors": ["Irene Bonati", "Silvina Caino-Lores", "Tain\u00e3 Coleman", "Sagar Dolas", "Sandro Fiore", "Venkatesh Kannan", "Marco Verdicchio", "Sean R. Wilkinson", "Rafael Ferreira da Silva"], "title": "Towards Advancing Research with Workflows: A perspective from the Workflows Community Summit -- Amsterdam, 2025", "categories": ["cs.DC"], "comment": null, "summary": "Scientific workflows have become essential for orchestrating complex computational processes across distributed resources, managing large datasets, and ensuring reproducibility in modern research. The Workflows Community Summit 2025, held in Amsterdam on June 6th, 2025, convened international experts to examine emerging challenges and opportunities in this domain. Participants identified key barriers to workflow adoption, including tensions between system generality and domain-specific utility, concerns over long-term sustainability of workflow systems and services, insufficient recognition for those who develop and maintain reproducible workflows, and gaps in standardization, funding, training, and cross-disciplinary collaboration. To address these challenges, the summit proposed action lines spanning technology, policy, and community dimensions: shifting evaluation metrics from raw computational performance toward measuring genuine scientific impact; formalizing workflow patterns and community-driven benchmarks to improve transparency, reproducibility, and usability; cultivating a cohesive international workflows community that engages funding bodies and research stakeholders; and investing in human capital through dedicated workflow engineering roles, career pathways, and integration of workflow concepts into educational curricula and long-term training initiatives. This document presents the summit's findings, beginning with an overview of the current computing ecosystem and the rationale for workflow-centric approaches, followed by a discussion of identified challenges and recommended action lines for advancing scientific discovery through workflows.", "AI": {"tldr": "The Workflows Community Summit 2025 highlighted challenges and proposed strategies to improve adoption and sustainability of scientific workflows through technology, community cooperation, and policy development.", "motivation": "To address barriers in scientific workflows adoption and formulate strategies for overcoming these challenges to enhance reproducibility, usability, and scalability.", "method": "Insights were gathered through international collaboration at the summit, focusing on discussions and recommendations in technology, policy, and community development.", "result": "Identified key barriers such as lack of standardization, insufficient recognition for developers, and sustainability concerns, while proposing solutions such as updated evaluation metrics, improved education and career pathways, and expanded collaboration.", "conclusion": "International collaboration and targeted initiatives across multiple dimensions are essential to advance scientific workflows for better scientific impact and reproducibility."}}
{"id": "2602.05004", "pdf": "https://arxiv.org/pdf/2602.05004", "abs": "https://arxiv.org/abs/2602.05004", "authors": ["Zexin Lin", "Jiachen Yu", "Haoyang Zhang", "Yuzhao Li", "Zhonghang Li", "Yujiu Yang", "Junjie Wang", "Xiaoqiang Ji"], "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.", "AI": {"tldr": "The paper introduces CoWork-X, a framework for real-time cooperative tasks, enhancing performance and efficiency under constraints through structured skill adaptation.", "motivation": "The motivation is to address challenges in real-time coordination and multi-episode adaptation in interactive environments, specifically under strict online budget constraints.", "method": "CoWork-X utilizes a Skill-Agent for structured skill execution and a Co-Optimizer for post-episode skill consolidation with strict budget management.", "result": "Experiments show CoWork-X achieves stable performance gains, reduced latency, and lower token usage in real-time collaboration benchmarks.", "conclusion": "CoWork-X demonstrates an efficient approach to balancing real-time task completion and adaptive long-term learning in cooperative environments."}}
{"id": "2602.05528", "pdf": "https://arxiv.org/pdf/2602.05528", "abs": "https://arxiv.org/abs/2602.05528", "authors": ["Danel Ahman", "Ilja Sobolev"], "title": "Strong Normalisation for Asynchronous Effects", "categories": ["cs.PL", "cs.LO"], "comment": "FSCD 2026 submission", "summary": "Asynchronous effects of Ahman and Pretnar complement the conventional synchronous treatment of algebraic computational effects with asynchrony based on decoupling the execution of algebraic operation calls into signalling that an operation's implementation needs to be executed, and into interrupting a running computation with the operation's result, to which the computation can react by installing matching interrupt handlers. Beyond providing asynchrony for algebraic effects, the resulting core calculus also naturally models examples such as pre-emptive multi-threading, (cancellable) remote function calls, multi-party applications, and even a parallel variant of runners of algebraic effects. In this paper, we study the normalisation properties of this calculus. We prove that if one removes general recursion from the original calculus, then the remaining calculus is strongly normalising, including both its sequential and parallel parts. However, this only guarantees termination for very simple asynchronous examples. To improve on this result, we also prove that the sequential fragment of the calculus remains strongly normalising when a controlled amount of interrupt-driven recursive behaviour is reintroduced. Our strong normalisation proofs are structured compositionally as a natural extension of Lindley and Stark's $\\top\\top$-lifting based approach for proving strong normalisation of effectful languages. All our results are also formalised in Agda.", "AI": {"tldr": "The paper introduces asynchronous effects to algebraic computational effects, studies a calculus that models these effects, and proves strong normalization under specific conditions.", "motivation": "To enhance the understanding and utility of algebraic computational effects by incorporating asynchrony, leading to applications like multi-threading, remote functions, and parallelism.", "method": "The researchers introduced a core calculus decoupling execution and result handling of operations, and proved strong normalization using a structured approach extended from Lindley and Stark's approach.", "result": "Strong normalization was achieved for the calculus when recursion was controlled or removed, and all results were formalized in Agda.", "conclusion": "The study advances algebraic effects by incorporating asynchrony, confirms their computational reliability through normalization proofs, and demonstrates applicability in varied asynchronous scenarios."}}
{"id": "2602.04935", "pdf": "https://arxiv.org/pdf/2602.04935", "abs": "https://arxiv.org/abs/2602.04935", "authors": ["Youjin Wang", "Run Zhou", "Rong Fu", "Shuaishuai Cao", "Hongwei Zeng", "Jiaxuan Lu", "Sicheng Fan", "Jiaqiao Zhao", "Liangming Pan"], "title": "ASA: Activation Steering for Tool-Calling Domain Adaptation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "For real-world deployment of general-purpose LLM agents, the core challenge is often not tool use itself, but efficient domain adaptation under rapidly evolving toolsets, APIs, and protocols. Repeated LoRA or SFT across domains incurs exponentially growing training and maintenance costs, while prompt or schema methods are brittle under distribution shift and complex interfaces. We propose \\textbf{Activation Steering Adapter (ASA}), a lightweight, inference-time, training-free mechanism that reads routing signals from intermediate activations and uses an ultra-light router to produce adaptive control strengths for precise domain alignment. Across multiple model scales and domains, ASA achieves LoRA-comparable adaptation with substantially lower overhead and strong cross-model transferability, making it ideally practical for robust, scalable, and efficient multi-domain tool ecosystems with frequent interface churn dynamics.", "AI": {"tldr": "The paper introduces Activation Steering Adapter (ASA), a lightweight mechanism for efficient domain adaptation in LLM agents without the need for costly retraining.", "motivation": "Address challenges in efficiently adapting LLM agents across rapidly evolving tools, APIs, and protocols while minimizing costs and avoiding brittle methods.", "method": "ASA utilizes intermediate activations to guide routing signals and employs a lightweight router to achieve domain-specific alignment without training.", "result": "ASA achieves adaptation performance comparable to LoRA while reducing overhead and showing strong transferability across models and domains.", "conclusion": "ASA offers a practical solution for scalable, robust multi-domain tool ecosystems, addressing interface changes efficiently and cost-effectively."}}
{"id": "2602.05029", "pdf": "https://arxiv.org/pdf/2602.05029", "abs": "https://arxiv.org/abs/2602.05029", "authors": ["Octavio Arriaga", "Proneet Sharma", "Jichen Guo", "Marc Otto", "Siddhant Kadwe", "Rebecca Adam"], "title": "Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Submitted to IEEE Robotics and Automation Letters (RA-L) for review. This version includes the statement required by IEEE for preprints", "summary": "Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In this work, we introduce a differentiable neuro-graphics model that combines neural foundation models with physics-based differentiable rendering to perform zero-shot scene reconstruction and robot grasping without relying on any additional 3D data or test-time samples. Our model solves a series of constrained optimization problems to estimate physically consistent scene parameters, such as meshes, lighting conditions, material properties, and 6D poses of previously unseen objects from a single RGBD image and bounding boxes. We evaluated our approach on standard model-free few-shot benchmarks and demonstrated that it outperforms existing algorithms for model-free few-shot pose estimation. Furthermore, we validated the accuracy of our scene reconstructions by applying our algorithm to a zero-shot grasping task. By enabling zero-shot, physically-consistent scene reconstruction and grasping without reliance on extensive datasets or test-time sampling, our approach offers a pathway towards more data efficient, interpretable and generalizable robot autonomy in novel environments.", "AI": {"tldr": "This paper presents a novel model for robotic systems that allows zero-shot scene reconstruction and robot grasping in unfamiliar environments using differentiable neuro-graphics without large datasets or test-time samples.", "motivation": "The paper aims to improve robotic systems' ability to interact with unseen objects and environments efficiently, overcoming the dependency on large datasets and test-time samples.", "method": "The proposed model integrates neural foundation models with physics-based differentiable rendering, solving constrained optimization problems to estimate scene parameters such as object meshes, lighting, material properties, and poses using single RGBD images and bounding boxes.", "result": "The model significantly outperforms existing methods on model-free few-shot pose estimation benchmarks and successfully applies its scene reconstructions to zero-shot grasping tasks.", "conclusion": "This approach facilitates data-efficient, interpretable, and generalizable robotic autonomy for novel environments, providing a noteworthy advancement in robotics."}}
{"id": "2602.05037", "pdf": "https://arxiv.org/pdf/2602.05037", "abs": "https://arxiv.org/abs/2602.05037", "authors": ["Bishoy Galoaa", "Xiangyu Bai", "Utsav Nandi", "Sai Siddhartha Vivek Dhir Rangoju", "Somaieh Amraee", "Sarah Ostadabbas"], "title": "UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "We present UniTrack, a plug-and-play graph-theoretic loss function designed to significantly enhance multi-object tracking (MOT) performance by directly optimizing tracking-specific objectives through unified differentiable learning. Unlike prior graph-based MOT methods that redesign tracking architectures, UniTrack provides a universal training objective that integrates detection accuracy, identity preservation, and spatiotemporal consistency into a single end-to-end trainable loss function, enabling seamless integration with existing MOT systems without architectural modifications. Through differentiable graph representation learning, UniTrack enables networks to learn holistic representations of motion continuity and identity relationships across frames. We validate UniTrack across diverse tracking models and multiple challenging benchmarks, demonstrating consistent improvements across all tested architectures and datasets including Trackformer, MOTR, FairMOT, ByteTrack, GTR, and MOTE. Extensive evaluations show up to 53\\% reduction in identity switches and 12\\% IDF1 improvements across challenging benchmarks, with GTR achieving peak performance gains of 9.7\\% MOTA on SportsMOT.", "AI": {"tldr": "This paper introduces UniTrack, a plug-and-play graph-theoretic loss function designed to enhance multi-object tracking (MOT) by integrating detection accuracy, identity preservation, and spatiotemporal consistency.", "motivation": "Previous graph-based MOT methods required redesigning tracking architectures, creating integration challenges. UniTrack addresses this by introducing a universal loss function that directly optimizes tracking-specific objectives within existing systems.", "method": "UniTrack employs a unified, end-to-end trainable graph-theoretic loss function that leverages differentiable graph representation learning. It captures motion continuity and identity relationships across frames.", "result": "The paper demonstrates consistent improvements across several MOT architectures and datasets, including up to 53% fewer identity switches, 12% IDF1 improvements, and 9.7% MOTA gains on specific benchmarks.", "conclusion": "UniTrack provides a universal and effective solution for improving MOT performance without requiring changes to existing architectures, validating its efficacy through extensive experiments and benchmarks."}}
{"id": "2602.05014", "pdf": "https://arxiv.org/pdf/2602.05014", "abs": "https://arxiv.org/abs/2602.05014", "authors": ["Zhanli Li", "Huiwen Tian", "Lvzhou Luo", "Yixuan Cao", "Ping Luo"], "title": "DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "working in progress", "summary": "With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks commonly treat long documents as flat collections of chunks, underutilizing document-native priors such as hierarchical organization and sequential discourse structure. We introduce DeepRead, a structure-aware, multi-turn document reasoning agent that explicitly operationalizes these priors for long-document question answering. DeepRead leverages LLM-based OCR model to convert PDFs into structured Markdown that preserves headings and paragraph boundaries. It then indexes documents at the paragraph level and assigns each paragraph a coordinate-style metadata key encoding its section identity and in-section order. Building on this representation, DeepRead equips the LLM with two complementary tools: a Retrieve tool that localizes relevant paragraphs while exposing their structural coordinates (with lightweight scanning context), and a ReadSection tool that enables contiguous, order-preserving reading within a specified section and paragraph range. Our experiments demonstrate that DeepRead achieves significant improvements over Search-o1-style agentic search in document question answering. The synergistic effect between retrieval and reading tools is also validated. Our fine-grained behavioral analysis reveals a reading and reasoning paradigm resembling human-like ``locate then read'' behavior.", "AI": {"tldr": "DeepRead introduces a structure-aware, multi-turn reasoning approach for long-document question answering, leveraging document hierarchical and sequential priors to enhance retrieval and reading.", "motivation": "Existing agentic search models fail to utilize inherent document structures in long-document settings, limiting their effectiveness.", "method": "DeepRead converts PDFs into structured Markdown with headings and paragraph boundaries, indexes documents hierarchically, and uses LLM tools to retrieve and read sections based on structural cues.", "result": "DeepRead improves performance significantly in document question answering, demonstrating synergy between retrieval and reading tools and resembling human-like reasoning.", "conclusion": "DeepRead operationalizes document structure for reasoning, achieving improved accuracy and efficiency in long-document question answering tasks."}}
{"id": "2602.05174", "pdf": "https://arxiv.org/pdf/2602.05174", "abs": "https://arxiv.org/abs/2602.05174", "authors": ["Yunrui Guan", "Krishnakumar Balasubramanian", "Shiqian Ma"], "title": "Total Variation Rates for Riemannian Flow Matching", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST"], "comment": null, "summary": "Riemannian flow matching (RFM) extends flow-based generative modeling to data supported on manifolds by learning a time-dependent tangent vector field whose flow-ODE transports a simple base distribution to the data law. We develop a nonasymptotic Total Variation (TV) convergence analysis for RFM samplers that use a learned vector field together with Euler discretization on manifolds. Our key technical ingredient is a differential inequality governing the evolution of TV between two manifold ODE flows, which expresses the time-derivative of TV through the divergence of the vector-field mismatch and the score of the reference flow; controlling these terms requires establishing new bounds that explicitly account for parallel transport and curvature. Under smoothness assumptions on the population flow-matching field and either uniform (compact manifolds) or mean-square (Hadamard manifolds) approximation guarantees for the learned field, we obtain explicit bounds of the form $\\mathrm{TV}\\le C_{\\mathrm{Lip}}\\,h + C_{\\varepsilon}\\,\\varepsilon$ (with an additional higher-order $\\varepsilon^2$ term on compact manifolds), cleanly separating numerical discretization and learning errors. Here, $h$ is the step-size and $\\varepsilon$ is the target accuracy. Instantiations yield \\emph{explicit} polynomial iteration complexities on the hypersphere $S^d$, and on the SPD$(n)$ manifolds under mild moment conditions.", "AI": {"tldr": "This paper proposes Riemannian flow matching (RFM) for generative modeling on manifolds and provides a TV convergence analysis for its samplers.", "motivation": "To extend flow-based generative models to work effectively on data supported by non-Euclidean manifolds.", "method": "Develops RFM by learning a time-dependent tangent vector field and provides a theoretical analysis of Total Variation convergence using Euler discretization on manifolds.", "result": "Provides explicit Total Variation convergence bounds and instantiates polynomial iteration complexities for specific manifolds such as hyperspheres and SPD manifolds.", "conclusion": "The paper separates errors due to numerical discretization and learning, providing a foundation for efficient generative modeling on manifolds."}}
{"id": "2602.04893", "pdf": "https://arxiv.org/pdf/2602.04893", "abs": "https://arxiv.org/abs/2602.04893", "authors": ["Licheng Pan", "Yunsheng Lu", "Jiexi Liu", "Jialing Tao", "Haozhe Feng", "Hui Xue", "Zhixuan Chu", "Kui Ren"], "title": "A Causal Perspective for Enhancing Jailbreak Attack and Defense", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Uncovering the mechanisms behind \"jailbreaks\" in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing latent representations, often overlooking the causal relationships between interpretable prompt features and jailbreak occurrences. In this work, we propose Causal Analyst, a framework that integrates LLMs into data-driven causal discovery to identify the direct causes of jailbreaks and leverage them for both attack and defense. We introduce a comprehensive dataset comprising 35k jailbreak attempts across seven LLMs, systematically constructed from 100 attack templates and 50 harmful queries, annotated with 37 meticulously designed human-readable prompt features. By jointly training LLM-based prompt encoding and GNN-based causal graph learning, we reconstruct causal pathways linking prompt features to jailbreak responses. Our analysis reveals that specific features, such as \"Positive Character\" and \"Number of Task Steps\", act as direct causal drivers of jailbreaks. We demonstrate the practical utility of these insights through two applications: (1) a Jailbreaking Enhancer that targets identified causal features to significantly boost attack success rates on public benchmarks, and (2) a Guardrail Advisor that utilizes the learned causal graph to extract true malicious intent from obfuscated queries. Extensive experiments, including baseline comparisons and causal structure validation, confirm the robustness of our causal analysis and its superiority over non-causal approaches. Our results suggest that analyzing jailbreak features from a causal perspective is an effective and interpretable approach for improving LLM reliability. Our code is available at https://github.com/Master-PLC/Causal-Analyst.", "AI": {"tldr": "This paper introduces 'Causal Analyst,' a framework to causally analyze jailbreaks in large language models, using a new dataset, causal graph learning, and human-readable prompt features to improve model safety and reliability.", "motivation": "To enhance the safety and reliability of large language models, particularly by understanding the mechanisms behind 'jailbreaks,' which are currently poorly understood and bypass current safety measures.", "method": "The authors propose a framework called Causal Analyst, combining LLM-based prompt encoding and GNN-based causal graph learning. They create a dataset with 35,000 jailbreak attempts, annotated with 37 interpretable prompt features, and analyze causal relationships between these features and jailbreaks.", "result": "The study identifies prompt features like 'Positive Character' and 'Number of Task Steps' as direct causes of jailbreaks. It also demonstrates practical applications through a Jailbreaking Enhancer (which increases attack rates) and a Guardrail Advisor (which detects malicious intent more effectively).", "conclusion": "Analyzing jailbreak prompts from a causal perspective offers a more effective and interpretable way to identify and mitigate vulnerabilities in large language models, thereby improving their reliability and safety."}}
{"id": "2602.05848", "pdf": "https://arxiv.org/pdf/2602.05848", "abs": "https://arxiv.org/abs/2602.05848", "authors": ["Henry Jiang"], "title": "DARWIN: Dynamic Agentically Rewriting Self-Improving Network", "categories": ["cs.NE", "cs.AI", "cs.CL"], "comment": "6 pages, 3 figures, 2 tables", "summary": "DARWIN is an evolutionary GPT model, utilizing a genetic-algorithm like optimization structure with several independent GPT agents being trained individually using unique training code. Each iteration, the GPT models are prompted to modify the training code of one another in an attempt to improve their performance in a mutation-like manner, and the best GPT agents are then benchmarked and selected for the next iteration by genetic algorithm. For demonstration purposes and due to budget and time constraints, OpenAI API is used to prompt training code improvements and the nanoGPT framework is used as the training code. DARWIN also utilizes persistent JSON-based memory files to track previous reasoning and changes to code to correlate with improvement to model performance. and a bidirectional interface for HITL intervention allowing the model to request upgrades such as additional datasets, training scripts, and restructuring of file hierarchies. In experiments, DARWIN achieved a 1.26 percent improvement in model FLOPS utilization (MFU) and a 2.07 percent improvement to perplexity in 5 iterations of training over baseline configurations, demonstrating promising capabilities as a foundation for scaling evolutionary GPT training.", "AI": {"tldr": "DARWIN is an evolutionary approach to GPT model optimization using genetic algorithms for iterative improvement through self-modified training code and benchmark selection.", "motivation": "To explore scalable methods for optimizing GPT models using an evolutionary approach combining genetic algorithms and HITL intervention.", "method": "Several independent GPT agents modify each other's training code iteratively, selecting the best performing ones based on benchmarks (genetic algorithm). Persistent memory and HITL intervention enhance the process.", "result": "DARWIN achieved a 1.26% improvement in model FLOPS utilization and a 2.07% improvement in perplexity over baseline configurations in 5 training iterations.", "conclusion": "DARWIN shows potential as a scalable framework for evolutionary GPT model optimization, though further testing beyond the demonstration is required."}}
{"id": "2602.05743", "pdf": "https://arxiv.org/pdf/2602.05743", "abs": "https://arxiv.org/abs/2602.05743", "authors": ["Liang Zhao", "Kunming Shao", "Zhipeng Liao", "Xijie Huang", "Tim Kwang-Ting Cheng", "Chi-Ying Tsui", "Yi Zou"], "title": "Balancing FP8 Computation Accuracy and Efficiency on Digital CIM via Shift-Aware On-the-fly Aligned-Mantissa Bitwidth Prediction", "categories": ["cs.AR"], "comment": "This paper is under review by IEEE Transactions On Very Large Scale Integration Systems (TVLSI-00144-2026)", "summary": "FP8 low-precision formats have gained significant adoption in Transformer inference and training. However, existing digital compute-in-memory (DCIM) architectures face challenges in supporting variable FP8 aligned-mantissa bitwidths, as unified alignment strategies and fixed-precision multiply-accumulate (MAC) units struggle to handle input data with diverse distributions. This work presents a flexible FP8 DCIM accelerator with three innovations: (1) a dynamic shift-aware bitwidth prediction (DSBP) with on-the-fly input prediction that adaptively adjusts weight (2/4/6/8b) and input (2$\\sim$12b) aligned-mantissa precision; (2) a FIFO-based input alignment unit (FIAU) replacing complex barrel shifters with pointer-based control; and (3) a precision-scalable INT MAC array achieving flexible weight precision with minimal overhead. Implemented in 28nm CMOS with a 64$\\times$96 CIM array, the design achieves 20.4 TFLOPS/W for fixed E5M7, demonstrating 2.8$\\times$ higher FP8 efficiency than previous work while supporting all FP8 formats. Results on Llama-7b show that the DSBP achieves higher efficiency than fixed bitwidth mode at the same accuracy level on both BoolQ and Winogrande datasets, with configurable parameters enabling flexible accuracy-efficiency trade-offs.", "AI": {"tldr": "This study introduces a novel FP8-based digital compute-in-memory (DCIM) accelerator that is efficient and flexible, supporting various FP8 formats through innovative prediction and processing methods.", "motivation": "To address challenges in DCIM architectures supporting diverse FP8 aligned-mantissa bitwidths, especially given Transformers' adoption of FP8 formats, and limitations in existing methods handling diverse data distributions.", "method": "The accelerator incorporates (1) a dynamic shift-aware bitwidth prediction (DSBP) for adaptive precision adjustment, (2) a FIFO-based input alignment unit (FIAU) for simpler control, and (3) a precision-scalable INT MAC array for flexible weight precision.", "result": "The 28nm CMOS implementation achieves 20.4 TFLOPS/W, 2.8 times better FP8 efficiency than earlier designs, and supports all FP8 formats. Application on Llama-7b demonstrates superior efficiency at comparable accuracy on datasets (BoolQ and Winogrande).", "conclusion": "The proposed accelerator demonstrates improved power efficiency and adaptive precision, enabling accuracy-efficiency trade-offs, making it highly suitable for Transformer-based neural network applications."}}
{"id": "2602.05292", "pdf": "https://arxiv.org/pdf/2602.05292", "abs": "https://arxiv.org/abs/2602.05292", "authors": ["Haoyu Bai", "Muhammed Tawfiqul Islam", "Minxian Xu", "Rajkumar Buyya"], "title": "ORACL: Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices", "categories": ["cs.DC"], "comment": null, "summary": "Applications are moving away from monolithic designs to microservice and serverless architectures, where fleets of lightweight and independently deployable components run on public clouds. Autoscaling serves as the primary control mechanism for balancing resource utilization and quality of service, yet existing policies are either opaque learned models that require substantial per-deployment training or brittle hand-tuned rules that fail to generalize. We investigate whether large language models can act as universal few-shot resource allocators that adapt across rapidly evolving microservice deployments.\n  We propose ORACL, Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices, a framework that leverages prior knowledge and chain-of-thought reasoning to diagnose performance regressions and recommend resource allocations. ORACL transforms runtime telemetry, including pods, replicas, CPU and memory usage, latency, service-level objectives, and fault signals, into semantic natural-language state descriptions and invokes an LLM to produce an interpretable intermediate reasoning trace. This reasoning identifies likely root causes, prunes the action space, and issues safe allocation decisions under policy constraints. Experiments on representative open-source microservice workloads show that ORACL improves root-cause identification accuracy by 15 percent, accelerates training by up to 24x, and improves quality of service by 6 percent in short-term scenarios, without deployment-specific retraining.", "AI": {"tldr": "This paper introduces ORACL, a framework that uses large language models for efficient and adaptive resource allocation in microservices.", "motivation": "The paper addresses limitations in existing autoscaling policies for microservices, such as the need for extensive training or the lack of generalization in rule-based approaches.", "method": "The ORACL framework applies chain-of-thought reasoning in large language models, transforming runtime telemetry data into semantic descriptions to assist in resource allocation decisions.", "result": "Experiments show ORACL improves root-cause identification accuracy by 15%, speeds training by up to 24x, and enhances quality of service by 6%, without requiring deployment-specific retraining.", "conclusion": "ORACL demonstrates the potential of large language models to act as universal few-shot resource allocators for microservices, offering interpretable and highly efficient solutions."}}
{"id": "2602.05035", "pdf": "https://arxiv.org/pdf/2602.05035", "abs": "https://arxiv.org/abs/2602.05035", "authors": ["Sean Trott", "Pamela D. Rivi\u00e8re"], "title": "Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation", "categories": ["cs.CL"], "comment": "9 pages, 5 figures, conference", "summary": "Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations and contextualization mechanisms--using controlled datasets of human relatedness judgments for ambiguous words in both English and Spanish. Comparing monolingual and multilingual LMs from the same families, we find consistently reduced performance in multilingual LMs. We then explore three potential capacity constraints: representational (reduced embedding isotropy), attentional (reduced attention to disambiguating cues), and vocabulary-related (increased multi-token segmentation). Multilingual LMs show some evidence of all three limitations; moreover, these factors statistically account for the variance formerly attributed to a model's multilingual status. These findings suggest both that multilingual LMs do suffer from multiple capacity constraints, and that these constraints correlate with reduced disambiguation performance.", "AI": {"tldr": "Multilingual language models underperform compared to monolingual models in ambiguous word disambiguation tasks, likely due to capacity limitations.", "motivation": "The paper seeks to understand why multilingual language models sometimes perform worse than monolingual models, specifically in lexical disambiguation.", "method": "Controlled datasets were used to examine human relatedness judgments for ambiguous words in English and Spanish. Monolingual versus multilingual language models were compared and analyzed for potential capacity constraints.", "result": "Multilingual language models showed reduced embedding isotropy, attention to disambiguating cues, and increased multi-token segmentation. These factors explained the observed performance drop.", "conclusion": "Multilingual models suffer from capacity constraints that contribute to their reduced performance on lexical disambiguation tasks."}}
{"id": "2602.05850", "pdf": "https://arxiv.org/pdf/2602.05850", "abs": "https://arxiv.org/abs/2602.05850", "authors": ["Ohad Kammar", "Jack Liell-Cock", "Sam Lindley", "Cristina Matache", "Sam Staton"], "title": "An Equational Axiomatization of Dynamic Threads via Algebraic Effects: Presheaves on Finite Relations, Labelled Posets, and Parameterized Algebraic Theories", "categories": ["cs.PL"], "comment": "Published at POPL 2026", "summary": "We use the theory of algebraic effects to give a complete equational axiomatization for dynamic threads. Our method is based on parameterized algebraic theories, which give a concrete syntax for strong monads on functor categories, and are a convenient framework for names and binding. Our programs are built from the key primitives `fork' and `wait'. `Fork' creates a child thread and passes its name (thread ID) to the parent thread. `Wait' allows us to wait for given child threads to finish. We provide a parameterized algebraic theory built from fork and wait, together with basic atomic actions and laws such as associativity of `fork'. Our equational axiomatization is complete in two senses. First, for closed expressions, it completely captures equality of labelled posets (pomsets), an established model of concurrency: model complete. Second, any two open expressions are provably equal if they are equal under all closing substitutions: syntactically complete. The benefit of algebraic effects is that the semantic analysis can focus on the algebraic operations of fork and wait. We then extend the analysis to a simple concurrent programming language by giving operational and denotational semantics. The denotational semantics is built using the methods of parameterized algebraic theories and we show that it is sound, adequate, and fully abstract at first order for labelled-poset observations.", "AI": {"tldr": "This paper presents a complete equational axiomatization of dynamic threads using algebraic effects, focusing on operations 'fork' and 'wait' and modeling concurrency with labelled posets.", "motivation": "To formalize and analyze concurrency in programming using algebraic effects, enabling precise reasoning about thread creation and synchronization.", "method": "The authors use parameterized algebraic theories for defining strong monads on functor categories. They axiomatize concurrency primitives 'fork' and 'wait,' providing two completeness results: model completeness for closed expressions and syntactic completeness for open expressions.", "result": "The analysis yields a sound, adequate, and fully abstract denotational semantics for a simple concurrent programming language based on labelled posets.", "conclusion": "Algebraic effects provide a robust framework for analyzing concurrency primitives and laying theoretical foundations for concurrent programming models."}}
{"id": "2602.04938", "pdf": "https://arxiv.org/pdf/2602.04938", "abs": "https://arxiv.org/abs/2602.04938", "authors": ["Lukas Radosky", "Ivan Polasek"], "title": "Large Language Models in Software Documentation and Modeling: A Literature Review and Findings", "categories": ["cs.SE"], "comment": "This is a preprint of a paper that was presented at the IEEE 24th World Symposium on Applied Machine Intelligence and Informatics (SAMI 2026)", "summary": "Generative artificial intelligence attracts significant attention, especially with the introduction of large language models. Its capabilities are being exploited to solve various software engineering tasks. Thanks to their ability to understand natural language and generate natural language responses, large language models are great for processing various software documentation artifacts. At the same time, large language models excel at understanding structured languages, having the potential for working with software programs and models. We conduct a literature review on the usage of large language models for software engineering tasks related to documentation and modeling. We analyze articles from four major venues in the area, organize them per tasks they solve, and provide an overview of used prompt techniques, metrics, approaches to human-based evaluation, and major datasets.", "AI": {"tldr": "This paper reviews the use of large language models (LLMs) for software engineering tasks, focusing on documentation and modeling.", "motivation": "The paper aims to explore the capabilities of LLMs in processing software documentation and structured software models, highlighting their potential in solving software engineering tasks.", "method": "The authors conduct a literature review of articles from four major software engineering venues, analyzing tasks solved by LLMs, prompt techniques, metrics, human-based evaluations, and datasets used.", "result": "The study organizes the findings into task categories, provides an overview of prompt engineering strategies, evaluation methods, and key datasets tailored for software engineering documentation and modeling.", "conclusion": "Large language models exhibit strong potential for enhancing software engineering processes, particularly in documentation and modeling. The paper offers structured insights, enabling further exploration and application in the field."}}
{"id": "2602.05079", "pdf": "https://arxiv.org/pdf/2602.05079", "abs": "https://arxiv.org/abs/2602.05079", "authors": ["Vinal Asodia", "Iman Sharifi", "Saber Fallah"], "title": "Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking", "categories": ["cs.RO", "cs.LG"], "comment": "12 pages, 7 figures, 5 tables", "summary": "The problem with existing camera-based Deep Reinforcement Learning approaches is twofold: they rarely integrate high-level scene context into the feature representation, and they rely on rigid, fixed reward functions. To address these challenges, this paper proposes a novel pipeline that produces a neuro-symbolic feature representation that encompasses semantic, spatial, and shape information, as well as spatially boosted features of dynamic entities in the scene, with an emphasis on safety-critical road users. It also proposes a Soft First-Order Logic (SFOL) reward function that balances human values via a symbolic reasoning module. Here, semantic and spatial predicates are extracted from segmentation maps and applied to linguistic rules to obtain reward weights. Quantitative experiments in the CARLA simulation environment show that the proposed neuro-symbolic representation and SFOL reward function improved policy robustness and safety-related performance metrics compared to baseline representations and reward formulations across varying traffic densities and occlusion levels. The findings demonstrate that integrating holistic representations and soft reasoning into Reinforcement Learning can support more context-aware and value-aligned decision-making for autonomous driving.", "AI": {"tldr": "This paper addresses the lack of high-level scene context in feature representations and reliance on rigid reward functions in camera-based Deep Reinforcement Learning for autonomous driving, proposing a neuro-symbolic representation and a Soft First-Order Logic reward system to improve policy robustness and safety.", "motivation": "Existing camera-based Deep Reinforcement Learning methods struggle to integrate high-level scene context and are limited by rigid reward functions, especially in safety-critical tasks like autonomous driving.", "method": "The paper introduces a neuro-symbolic feature representation combining semantic, spatial, and dynamic entity features, alongside a Soft First-Order Logic reward function based on linguistic rules and segmentation maps for value-aligned decision-making.", "result": "Experiments in the CARLA simulation demonstrated improved robustness and safety-related performance across different traffic densities and occlusion levels compared to baselines.", "conclusion": "Holistic representations and soft reasoning significantly enhance context-aware and value-aligned decision-making in Deep Reinforcement Learning for autonomous driving."}}
{"id": "2602.05049", "pdf": "https://arxiv.org/pdf/2602.05049", "abs": "https://arxiv.org/abs/2602.05049", "authors": ["Yiye Chen", "Yanan Jian", "Xiaoyi Dong", "Shuxin Cao", "Jing Wu", "Patricio Vela", "Benjamin E. Lundell", "Dongdong Chen"], "title": "VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "In submission. Project website: https://vista-vla.github.io/", "summary": "Vision-Language-Action (VLA) models have demonstrated strong performance across a wide range of robotic manipulation tasks. Despite the success, extending large pretrained Vision-Language Models (VLMs) to the action space can induce vision-action misalignment, where action predictions exhibit weak dependence on the current visual state, leading to unreliable action outputs. In this work, we study VLA models through the lens of visual conditioning and empirically show that successful rollouts consistently exhibit stronger visual dependence than failed ones. Motivated by this observation, we propose a training framework that explicitly strengthens visual conditioning in VLA models. Our approach first aligns action prediction with visual input via preference optimization on a track-following surrogate task, and then transfers the enhanced alignment to instruction-following task through latent-space distillation during supervised finetuning. Without introducing architectural modifications or additional data collection, our method improves both visual conditioning and task performance for discrete OpenVLA, and further yields consistent gains when extended to the continuous OpenVLA-OFT setting. Project website: https://vista-vla.github.io/ .", "AI": {"tldr": "The paper addresses vision-action misalignment in Vision-Language-Action (VLA) models by proposing a framework to enhance visual conditioning without architectural changes or extra data, improving discrete and continuous task performance.", "motivation": "VLA models often suffer from weak correlation between visual input and action predictions, leading to unreliable outputs. The authors aim to strengthen this visual-action alignment.", "method": "They introduce a two-step training framework: align action prediction with visual input via surrogate task optimization and transfer this alignment to broader instruction-following tasks through latent-space distillation during supervised fine-tuning.", "result": "The proposed framework enhances visual conditioning and improves task performance for discrete OpenVLA and continuous OpenVLA-OFT implementations.", "conclusion": "Explicitly strengthening visual conditioning is effective in mitigating vision-action misalignment, making VLA models more reliable for robotic manipulation tasks."}}
{"id": "2602.05048", "pdf": "https://arxiv.org/pdf/2602.05048", "abs": "https://arxiv.org/abs/2602.05048", "authors": ["Zeyu Fang", "Tian Lan", "Mahdi Imani"], "title": "MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns by issuing a limited number of questions per task while achieving significantly improved rewards and success rates.", "AI": {"tldr": "The paper introduces MINT (Minimal Information Neuro-Symbolic Tree) for optimizing human-AI interaction strategies in object-driven planning, focusing on resolving knowledge gaps.", "motivation": "Human-AI teaming in planning often faces challenges due to incomplete information and unknowns. Efficient strategies are needed for AI agents to elicit human inputs effectively.", "method": "MINT creates symbolic trees to propose human-AI interactions and uses neural planning policies to assess uncertainties. It incorporates self-play optimization and utilizes LLMs to refine queries for human input.", "result": "MINT demonstrates near-expert performance across benchmarks with unseen/unknown objects. It successfully boosts rewards and success rates using limited human queries.", "conclusion": "The approach enhances planning performance through optimized elicitation strategies, addressing knowledge gaps. It is effective in human-AI collaboration for complex tasks."}}
{"id": "2602.05227", "pdf": "https://arxiv.org/pdf/2602.05227", "abs": "https://arxiv.org/abs/2602.05227", "authors": ["Elias Hess-Childs", "Dejan Slep\u010dev", "Lantian Xu"], "title": "Radon--Wasserstein Gradient Flows for Interacting-Particle Sampling in High Dimensions", "categories": ["stat.ML", "cs.LG", "math.AP", "math.NA", "stat.ME"], "comment": "49 pages, 7 figures", "summary": "Gradient flows of the Kullback--Leibler (KL) divergence, such as the Fokker--Planck equation and Stein Variational Gradient Descent, evolve a distribution toward a target density known only up to a normalizing constant. We introduce new gradient flows of the KL divergence with a remarkable combination of properties: they admit accurate interacting-particle approximations in high dimensions, and the per-step cost scales linearly in both the number of particles and the dimension. These gradient flows are based on new transportation-based Riemannian geometries on the space of probability measures: the Radon--Wasserstein geometry and the related Regularized Radon--Wasserstein (RRW) geometry. We define these geometries using the Radon transform so that the gradient-flow velocities depend only on one-dimensional projections. This yields interacting-particle-based algorithms whose per-step cost follows from efficient Fast Fourier Transform-based evaluation of the required 1D convolutions. We additionally provide numerical experiments that study the performance of the proposed algorithms and compare convergence behavior and quantization. Finally, we prove some theoretical results including well-posedness of the flows and long-time convergence guarantees for the RRW flow.", "AI": {"tldr": "The paper introduces new gradient flows for the KL divergence, leveraging transportation-based geometries, which enable efficient approximations with linear scaling in particle number and dimension.", "motivation": "Address the challenge of constructing gradient flows of the KL divergence that allow for efficient and accurate approximations in high dimensions.", "method": "Develop new transportation-based Riemannian geometries (Radon--Wasserstein and RRW) and gradient flows depending on one-dimensional projections, along with algorithms using FFT for efficient computation.", "result": "Introduced particle-based algorithms with linear step computational cost, provided numerical insights, and proved theoretical guarantees like flow well-posedness and convergence.", "conclusion": "The work advances KL divergence gradient flows by introducing practical algorithms and theoretical insights, enabling high-dimensional applications with reliable performance."}}
{"id": "2602.04902", "pdf": "https://arxiv.org/pdf/2602.04902", "abs": "https://arxiv.org/abs/2602.04902", "authors": ["Kingsuk Maitra"], "title": "Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 5 figures, 299 pages total with supplementary material (21 appendices, 27 Jupyter notebooks with embedded results)", "summary": "The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a symplectic augmentation embedding physical priors via the kinematic difference operator $p_t = q_t - q_{t-1}$, implementing the symplectic shear $\\hat{q}_t = q_t + \u03b3p_t$ on queries and keys. We identify a fundamental Symplectic-Filter Duality: the physical shear is mathematically equivalent to a High-Pass Filter. This duality is our cornerstone contribution -- by injecting kinematic momentum, we sidestep the topological depth constraint ($L \\geq 2$) for induction head formation. While standard architectures require two layers for induction from static positions, our extension grants direct access to velocity, enabling Single-Layer Induction and Spectral Forensics via Bode Plots. We formalize an Orthogonality Theorem proving that DC (semantic) and AC (mechanistic) signals segregate into orthogonal frequency bands when Low-Pass RoPE interacts with High-Pass Momentum. Validated through 5,100+ controlled experiments (documented in Supplementary Appendices A--R and 27 Jupyter notebooks), our 125M Momentum model exceeds expectations on induction-heavy tasks while tracking a 350M baseline within $\\sim$2.9% validation loss. Dedicated associative recall experiments reveal a scaling law $\u03b3^* = 4.17 \\times N^{-0.74}$ establishing momentum-depth fungibility. We offer this framework as a complementary analytical toolkit connecting Generative AI, Hamiltonian Physics, and Signal Processing.", "AI": {"tldr": "This paper introduces Momentum Attention, augmenting Transformers with new symplectic physics-based enhancements enabling single-layer induction and improved performance on specific AI tasks.", "motivation": "The paper aims to refine Transformer interpretability and functionality by incorporating physical principles like momentum and symplectic dynamics into computational models.", "method": "The authors proposed a model using kinematic momentum via symplectic shear applied to queries and keys, leveraging a novel Symplectic-Filter Duality for enhanced AI tasks.", "result": "Experiments demonstrate that the 125M Momentum-enhanced model achieves effective performance comparable to larger models and validates theoretical scaling laws for momentum-depth fungibility.", "conclusion": "The framework connects aspects of Generative AI, Hamiltonian Physics, and Signal Processing, offering advancements in computational graphs and Transformer efficiency."}}
{"id": "2602.04911", "pdf": "https://arxiv.org/pdf/2602.04911", "abs": "https://arxiv.org/abs/2602.04911", "authors": ["E Bowen", "R Granger", "A Rodriguez"], "title": "A logical re-conception of neural networks: Hamiltonian bitwise part-whole architecture", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Appears in AAAI 2023", "summary": "We introduce a simple initial working system in which relations (such as part-whole) are directly represented via an architecture with operating and learning rules fundamentally distinct from standard artificial neural network methods. Arbitrary data are straightforwardly encoded as graphs whose edges correspond to codes from a small fixed primitive set of elemental pairwise relations, such that simple relational encoding is not an add-on, but occurs intrinsically within the most basic components of the system. A novel graph-Hamiltonian operator calculates energies among these encodings, with ground states denoting simultaneous satisfaction of all relation constraints among graph vertices. The method solely uses radically low-precision arithmetic; computational cost is correspondingly low, and scales linearly with the number of edges in the data. The resulting unconventional architecture can process standard ANN examples, but also produces representations that exhibit characteristics of symbolic computation. Specifically, the method identifies simple logical relational structures in these data (part-of; next-to), building hierarchical representations that enable abductive inferential steps generating relational position-based encodings, rather than solely statistical representations. Notably, an equivalent set of ANN operations are derived, identifying a special case of embedded vector encodings that may constitute a useful approach to current work in higher-level semantic representation. The very simple current state of the implemented system invites additional tools and improvements.", "AI": {"tldr": "The paper presents a novel graph-based computational approach that intrinsically encodes relationships and enables both neural and symbolic representation with low computational cost.", "motivation": "Current artificial neural network methods struggle to inherently encode and work with relations, which restricts their capability in handling symbolic computations and higher-level semantics.", "method": "They propose a system that directly encodes relational data as graph components, calculates relational constraints using a graph-Hamiltonian operator, and processes these using low-precision arithmetic.", "result": "Their system successfully represents logical relational structures, builds hierarchical representations, and supports inferential reasoning. An equivalent ANN framework is identified for semantic representation.", "conclusion": "The developed system represents a step towards combining neural and symbolic processing efficiently, indicating potential for advancement in semantic and relational computations with room for further improvements."}}
{"id": "2602.05002", "pdf": "https://arxiv.org/pdf/2602.05002", "abs": "https://arxiv.org/abs/2602.05002", "authors": ["Luis Cunha", "Jose Martins", "Manuel Rodriguez", "Tiago Gomes", "Sandro Pinto", "Uwe Moslehner", "Kai Dieffenbach", "Glenn Farrall", "Kajetan Nuernberger", "Thomas Roecker"], "title": "System-Level Isolation for Mixed-Criticality RISC-V SoCs: A \"World\" Reality Check", "categories": ["cs.CR", "cs.AR"], "comment": "13 pages, 10 images", "summary": "As RISC-V adoption accelerates, domains such as automotive, the Internet of Things (IoT), and industrial control are attracting growing attention. These domains are subject to stringent Size, Weight, Power, and Cost (SWaP-C) constraints, which have driven a shift toward heterogeneous Systems-on-Chip (SoCs) integrating general-purpose CPUs, tightly coupled accelerators, and diverse I/O devices with different integrity levels. While such integration improves cost efficiency and performance, it introduces a fundamental safety and security challenge: enforcing system-level isolation in mixed-criticality environments. Although RISC-V International has proposed several hardware isolation primitives, including RISC-V Worlds, IOPMP, and SmMTT, their interoperability, scalability, and suitability for real-time systems remain insufficiently understood. In this paper, we present a comparative analysis of these primitives from the perspective of practical heterogeneous SoC designs. We implement an IOPMP, a World-based checker, and a modified RISC-V World checker that addresses key limitations of the baseline specification, and evaluate their trade-offs in terms of security guarantees and power-performance-area (PPA). Our results show that the World-based checker introduces a fixed, configuration-independent access latency, achieving lower worst-case delay than the evaluated alternatives while scaling predictably with system size. At the macro level, we estimate that the proposed modifications reduce SoC area by up to approximately 5% compared to a baseline design. All artifacts will be released as open source, and we expect these findings to directly contribute to the evolution and ratification of RISC-V specifications, as well as to the design of future RISC-V SoCs.", "AI": {"tldr": "This paper evaluates RISC-V isolation primitives for heterogeneous SoCs, focusing on their security, scalability, and performance trade-offs, while proposing modifications to enhance efficiency.", "motivation": "RISC-V is being increasingly adopted in domains such as automotive, IoT, and industrial control, which demand stringent constraints and system-level isolation in mixed-criticality environments.", "method": "The authors conducted a comparative analysis of several RISC-V isolation primitives (Worlds, IOPMP, SmMTT), implemented modified mechanisms, and evaluated their security, scalability, and PPA performance.", "result": "The proposed modified World-based checker reduces SoC area by approximately 5%, introduces fixed access latency, and achieves better scalability, security guarantees, and predictable system size scaling compared to alternatives.", "conclusion": "The findings contribute to the evolution of RISC-V specifications by addressing limitations in existing isolation primitives and improving heterogeneous SoC designs' safety, security, and efficiency."}}
{"id": "2602.05346", "pdf": "https://arxiv.org/pdf/2602.05346", "abs": "https://arxiv.org/abs/2602.05346", "authors": ["Shubham Mishra", "Jo\u00e3o Gon\u00e7alves", "Chawinphat Tankuranand", "Neil Giridharan", "Natacha Crooks", "Heidi Howard", "Chris Jensen"], "title": "Proteus: Append-Only Ledgers for (Mostly) Trusted Execution Environments", "categories": ["cs.DC"], "comment": null, "summary": "Distributed ledgers are increasingly relied upon by industry to provide trustworthy accountability, strong integrity protection, and high availability for critical data without centralizing trust. Recently, distributed append-only logs are opting for a layered approach, combining crash-fault-tolerant (CFT) consensus with hardware-based Trusted Execution Environments (TEEs) for greater resiliency. Unfortunately, hardware TEEs can be subject to (rare) attacks, undermining the very guarantees that distributed ledgers are carefully designed to achieve. In response, we present Proteus, a new distributed consensus protocol that cautiously trusts the guarantees of TEEs. Proteus carefully embeds a Byzantine fault-tolerant (BFT) protocol inside of a CFT protocol with no additional messages. This is made possible through careful refactoring of both the CFT and BFT protocols such that their structure aligns. Proteus achieves performance in line with regular TEE-enabled consensus protocols, while guaranteeing integrity in the face of TEE platform compromises.", "AI": {"tldr": "Proteus is a distributed consensus protocol that integrates Byzantine fault-tolerant (BFT) protocols within crash-fault-tolerant (CFT) structures, leveraging Trusted Execution Environments (TEEs) for resiliency while mitigating risks of TEE compromises.", "motivation": "The paper addresses the vulnerability of hardware-based Trusted Execution Environments (TEEs) in distributed ledgers, aiming to maintain integrity even when TEEs are compromised.", "method": "Proteus integrates BFT protocols within CFT protocols without introducing additional network messages by carefully aligning their structures.", "result": "The proposed protocol matches the performance of typical TEE-enabled consensus systems while providing enhanced integrity safeguards against TEE failures.", "conclusion": "Proteus demonstrates a novel approach by embedding a BFT protocol into a CFT protocol, ensuring performance and integrity even under potential TEE platform compromises."}}
{"id": "2602.05085", "pdf": "https://arxiv.org/pdf/2602.05085", "abs": "https://arxiv.org/abs/2602.05085", "authors": ["Sidi Lu", "Zhenwen Liang", "Dongyang Ma", "Yan Wang", "Haitao Mi", "Dong Yu"], "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories", "categories": ["cs.CL"], "comment": "Tencent AI Lab Technical Report", "summary": "In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.", "AI": {"tldr": "This paper introduces Locas, a type of parametric memory for transformers that supports continual learning and minimizes catastrophic forgetting via innovative initialization for fast convergence and better generalization.", "motivation": "The motivation is to create a parametric memory mechanism to integrate with transformers for efficient continual learning, addressing catastrophic forgetting and improving generalization for tasks requiring extended memory.", "method": "The authors propose Locas, a memory mechanism designed as FFN blocks used in transformers, with two variants: one with MLP design for theoretical guarantees and another leveraging GLU-FFN for compatibility with existing LLMs. Proper initialization is key for their proposed solution.", "result": "Locas validates its efficiency on PG-19 and LoCoMo tasks, storing past information with minimal additional parameters (0.02% in some cases) and a reduced context window. It also retains model generalizability while minimizing catastrophic forgetting.", "conclusion": "Locas demonstrates the ability to incorporate past contextual memories into model parameters effectively, enabling efficient continual learning and memory retention without compromising the model's internal knowledge."}}
{"id": "2602.05042", "pdf": "https://arxiv.org/pdf/2602.05042", "abs": "https://arxiv.org/abs/2602.05042", "authors": ["Lucas Romao", "Luiz Xavier", "J\u00falia Cond\u00e9 Ara\u00fajo", "Marina Cond\u00e9 Ara\u00fajo", "Ariane Rodrigues", "Marcos Kalinowski"], "title": "Applying a Requirements-Focused Agile Management Approach for Machine Learning-Enabled Systems", "categories": ["cs.SE"], "comment": "Accepted for publication at the 5th International Conference on AI Engineering - Software Engineering for AI (CAIN) 2026", "summary": "Machine Learning (ML)-enabled systems challenge traditional Requirements Engineering (RE) and agile management due to data dependence, experimentation, and uncertain model behavior. Existing RE and agile practices remain poorly integrated and insufficiently tailored to these characteristics. This paper reports on the practical experience of applying RefineML, a requirements-focused approach for the continuous and agile refinement of ML-enabled systems, which integrates ML-tailored specification and agile management approaches with best practices derived from a systematic mapping study. The application context concerns an industry-academia collaboration project between PUC-Rio and EXA, a Brazilian cybersecurity company. For evaluation purposes, we applied questionnaires assessing RefineML's suitability and overall acceptance and semi-structured interviews. We applied thematic analysis to the collected qualitative data. Regarding suitability and acceptance, the results of the questionnaires indicated high perceived usefulness and intention to use. Based on the interviews, stakeholders perceived RefineML as improving communication and facilitating early feasibility assessments, as well as enabling dual-track governance of ML and software work, allowing continuous refinement of the model while evolving the overall software project. However, some limitations remain, particularly related to difficulties in operationalizing ML concerns into agile requirements and in estimating ML effort.", "AI": {"tldr": "RefineML is introduced as an approach to improving integration of ML-enabled systems with requirements engineering and agile practices.", "motivation": "Traditional RE and agile management struggle with challenges associated with ML systems, such as data dependency, experimentation, and unpredictable model behavior.", "method": "RefineML was applied in a collaborative project between academia and industry, evaluated using questionnaires and interviews, and analyzed thematically.", "result": "Stakeholders found RefineML useful for communication, feasibility assessment, and dual-track governance, though challenges in operationalizing ML requirements persist.", "conclusion": "RefineML shows promise in bridging gaps between RE and agile practices for ML systems but requires further refinement to address operational challenges and effort estimation."}}
{"id": "2602.05092", "pdf": "https://arxiv.org/pdf/2602.05092", "abs": "https://arxiv.org/abs/2602.05092", "authors": ["Thomas Cohn", "Lihan Tang", "Alexandre Amice", "Russ Tedrake"], "title": "A Framework for Combining Optimization-Based and Analytic Inverse Kinematics", "categories": ["cs.RO"], "comment": "19 pages, 5 figures, 6 tables. Under submission", "summary": "Analytic and optimization methods for solving inverse kinematics (IK) problems have been deeply studied throughout the history of robotics. The two strategies have complementary strengths and weaknesses, but developing a unified approach to take advantage of both methods has proved challenging. A key challenge faced by optimization approaches is the complicated nonlinear relationship between the joint angles and the end-effector pose. When this must be handled concurrently with additional nonconvex constraints like collision avoidance, optimization IK algorithms may suffer high failure rates. We present a new formulation for optimization IK that uses an analytic IK solution as a change of variables, and is fundamentally easier for optimizers to solve. We test our methodology on three popular solvers, representing three different paradigms for constrained nonlinear optimization. Extensive experimental comparisons demonstrate that our new formulation achieves higher success rates than the old formulation and baseline methods across various challenging IK problems, including collision avoidance, grasp selection, and humanoid stability.", "AI": {"tldr": "This paper introduces a novel optimization approach combining analytic techniques for solving IK problems, achieving better success rates in complex scenarios.", "motivation": "To address the high failure rates in optimization-based IK algorithms, particularly when dealing with complicated nonlinear relationships and additional nonconvex constraints like collision avoidance.", "method": "The method reformulates the optimization IK problem by adopting an analytic IK solution as a change of variables, simplifying the problem for optimizers.", "result": "The approach outperformed conventional methods and established baselines, achieving higher success rates in a variety of challenging scenarios including collision avoidance and humanoid stability.", "conclusion": "The integration of an analytic IK solution significantly enhances the performance of optimization IK algorithms, resolving longstanding issues in the field."}}
{"id": "2602.05078", "pdf": "https://arxiv.org/pdf/2602.05078", "abs": "https://arxiv.org/abs/2602.05078", "authors": ["Gautham Vinod", "Fengqing Zhu"], "title": "Food Portion Estimation: From Pixels to Calories", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV"], "comment": null, "summary": "Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.", "AI": {"tldr": "This paper explores strategies for accurate portion estimation in image-based dietary assessment using various technologies.", "motivation": "To improve portion estimation accuracy in image-based dietary assessments, which are crucial for monitoring health and managing chronic diseases and obesity.", "method": "Analysis of existing approaches including depth maps, multi-view inputs, template matching, and deep learning techniques for dietary portion estimation.", "result": "Provide insights into the strengths and limitations of different strategies for portion estimation.", "conclusion": "Identifying effective strategies for portion estimation, aiding in refining image-based dietary assessment tools for enhanced health monitoring."}}
{"id": "2602.05059", "pdf": "https://arxiv.org/pdf/2602.05059", "abs": "https://arxiv.org/abs/2602.05059", "authors": ["Adithya Kulkarni", "Mohna Chakraborty", "Jay Bagga"], "title": "Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction.\n  The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims.\n  These findings indicate that LLMs can support exploration of established material but remain limited in tasks requiring novel mathematical insight or critical structural reasoning. For computing education, this distinction highlights the importance of guiding students to use LLMs for conceptual exploration while relying on independent verification and rigorous argumentation for formal problem solving.", "AI": {"tldr": "The study evaluates a Large Language Model's (LLM) ability to address graph theory problems, finding it performs well on solved problems but struggles with open problems.", "motivation": "To assess the reliability and role of LLMs in aiding mathematically rigorous thinking, especially for students in computing courses exploring graph theory.", "method": "An eight-stage evaluation protocol was used to test the LLM on two graph theory problems: one solved and one open problem.", "result": "The LLM succeeded in solving the solved problem with mathematical accuracy but only generated exploratory strategies for the open problem without advancing towards a solution.", "conclusion": "LLMs are valuable for exploring established material and conceptual learning but limited in solving tasks requiring novel mathematical insight. Students should use LLMs as aids while independently verifying formal solutions."}}
{"id": "2602.05298", "pdf": "https://arxiv.org/pdf/2602.05298", "abs": "https://arxiv.org/abs/2602.05298", "authors": ["Damien Ferbach", "Courtney Paquette", "Gauthier Gidel", "Katie Everett", "Elliot Paquette"], "title": "Logarithmic-time Schedules for Scaling Language Models with Momentum", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "In practice, the hyperparameters $(\u03b2_1, \u03b2_2)$ and weight-decay $\u03bb$ in AdamW are typically kept at fixed values. Is there any reason to do otherwise? We show that for large-scale language model training, the answer is yes: by exploiting the power-law structure of language data, one can design time-varying schedules for $(\u03b2_1, \u03b2_2, \u03bb)$ that deliver substantial performance gains.\n  We study logarithmic-time scheduling, in which the optimizer's gradient memory horizon grows with training time. Although naive variants of this are unstable, we show that suitable damping mechanisms restore stability while preserving the benefits of longer memory. Based on this, we present ADANA, an AdamW-like optimizer that couples log-time schedules with explicit damping to balance stability and performance. We empirically evaluate ADANA across transformer scalings (45M to 2.6B parameters), comparing against AdamW, Muon, and AdEMAMix.\n  When properly tuned, ADANA achieves up to 40% compute efficiency relative to a tuned AdamW, with gains that persist--and even improve--as model scale increases. We further show that similar benefits arise when applying logarithmic-time scheduling to AdEMAMix, and that logarithmic-time weight-decay alone can yield significant improvements. Finally, we present variants of ADANA that mitigate potential failure modes and improve robustness.", "AI": {"tldr": "The paper introduces ADANA, an AdamW-inspired optimizer that employs logarithmic-time hyperparameter scheduling for improved performance and stability in large-scale language model training.", "motivation": "Fixed hyperparameters in AdamW restrict potential performance gains in large-scale language models. The paper explores time-varying schedules to optimize training efficiency.", "method": "The authors propose logarithmic-time scheduling for AdamW hyperparameters $(\u03b2_1, \u03b2_2, \u03bb)$ coupled with damping mechanisms to ensure training stability. They introduce ADANA, an enhanced optimizer using this approach.", "result": "ADANA achieves up to 40% higher compute efficiency compared to tuned AdamW, with improvements becoming more pronounced at larger model scales. Logarithmic-time scheduling benefits are demonstrated across different optimizer setups.", "conclusion": "The study concludes that leveraging logarithmic-time scheduling with appropriate damping can notably enhance language model training performance, especially at scale. Robustness improvements of ADANA variants further solidify its practical viability."}}
{"id": "2602.04903", "pdf": "https://arxiv.org/pdf/2602.04903", "abs": "https://arxiv.org/abs/2602.04903", "authors": ["Eitan Sprejer", "Oscar Agust\u00edn Stanchi", "Mar\u00eda Victoria Carro", "Denise Alejandra Mester", "Iv\u00e1n Arcuschin"], "title": "Mind the Performance Gap: Capability-Behavior Trade-offs in Feature Steering", "categories": ["cs.LG"], "comment": "12 pages, 5 figures", "summary": "Feature steering has emerged as a promising approach for controlling LLM behavior through direct manipulation of internal representations, offering advantages over prompt engineering. However, its practical effectiveness in real-world applications remains poorly understood, particularly regarding potential trade-offs with output quality. We show that feature steering methods substantially degrade model performance even when successfully controlling target behaviors, a critical trade-off. Specifically, we evaluate Goodfire's Auto Steer against prompt engineering baselines across 14 steering queries (covering innocuous and safety-relevant behaviors) on 171 Massive Multitask Language Understanding (MMLU) questions using Llama-8B and Llama-70B, measuring accuracy, coherence, and behavioral control. Our findings show that Auto Steer successfully modifies target behaviors (achieving scores of 3.33 vs. 2.98 for prompting on Llama-8B and 3.57 vs. 3.10 on Llama-70B), but causes dramatic performance degradation: accuracy on the MMLU questions drops from 66% to 46% on Llama-8B and 87% to 73% on Llama-70B, with coherence falling from 4.62 to 2.24 and 4.94 to 3.89 respectively. Simple prompting achieves the best overall balance. These findings highlight limitations of current feature steering methods for practical deployment where task performance cannot be sacrificed. More broadly, our work demonstrates that mechanistic control methods face fundamental capability-behavior trade-offs that must be empirically characterized before deployment.", "AI": {"tldr": "The paper explores the trade-offs of feature steering in LLMs, showing that it effectively controls behaviors but significantly reduces performance, highlighting its limitations compared to prompt engineering.", "motivation": "To investigate the practical effectiveness of feature steering in controlling LLM behavior and the trade-offs it presents, particularly in terms of maintaining output quality.", "method": "The authors compare feature steering (via Goodfire's Auto Steer) against prompt engineering across 14 behavioral queries on 171 MMLU questions using two Llama models, assessing accuracy, coherence, and behavioral control.", "result": "Feature steering modifies target behaviors but leads to severe performance degradation. Accuracy and coherence on MMLU questions dropped significantly after implementing Auto Steer, with prompting achieving better overall results.", "conclusion": "Feature steering methods face critical capability-behavior trade-offs that limit their practical deployment, emphasizing the need for empirical characterization of these trade-offs before such methods can be effectively utilized."}}
{"id": "2602.05737", "pdf": "https://arxiv.org/pdf/2602.05737", "abs": "https://arxiv.org/abs/2602.05737", "authors": ["Luca Ciampi", "Ludovico Iannello", "Fabrizio Tonelli", "Gabriele Lagani", "Angelo Di Garbo", "Federico Cremisi", "Giuseppe Amato"], "title": "Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing", "categories": ["cs.CV", "cs.NE"], "comment": null, "summary": "In this paper, we present a neuro-inspired approach to reservoir computing (RC) in which a network of in vitro cultured cortical neurons serves as the physical reservoir. Rather than relying on artificial recurrent models to approximate neural dynamics, our biological reservoir computing (BRC) system leverages the spontaneous and stimulus-evoked activity of living neural circuits as its computational substrate. A high-density multi-electrode array (HD-MEA) provides simultaneous stimulation and readout across hundreds of channels: input patterns are delivered through selected electrodes, while the remaining ones capture the resulting high-dimensional neural responses, yielding a biologically grounded feature representation. A linear readout layer (single-layer perceptron) is then trained to classify these reservoir states, enabling the living neural network to perform static visual pattern-recognition tasks within a computer-vision framework. We evaluate the system across a sequence of tasks of increasing difficulty, ranging from pointwise stimuli to oriented bars, clock-digit-like shapes, and handwritten digits from the MNIST dataset. Despite the inherent variability of biological neural responses-arising from noise, spontaneous activity, and inter-session differences-the system consistently generates high-dimensional representations that support accurate classification. These results demonstrate that in vitro cortical networks can function as effective reservoirs for static visual pattern recognition, opening new avenues for integrating living neural substrates into neuromorphic computing frameworks. More broadly, this work contributes to the effort to incorporate biological principles into machine learning and supports the goals of neuro-inspired vision by illustrating how living neural systems can inform the design of efficient and biologically grounded computational models.", "AI": {"tldr": "The paper explores the use of cultured cortical neurons as physical reservoirs for computation, successfully enabling visual pattern recognition tasks using biologically inspired methods.", "motivation": "To leverage biological neural circuits for computational tasks, particularly improving pattern recognition through biologically grounded and neuro-inspired computing systems.", "method": "Cortical neurons cultured in vitro are used as reservoirs, with input patterns delivered via a multi-electrode array. Neural responses are captured and classified using a linear readout system following tasks of increasing complexity.", "result": "The biological system produced consistently accurate classification results across various visual tasks, despite biological variability like noise and session differences.", "conclusion": "Cortical networks can serve as effective computational reservoirs, supporting static visual pattern recognition and paving the way for biologically informed neuromorphic computing systems."}}
{"id": "2602.05166", "pdf": "https://arxiv.org/pdf/2602.05166", "abs": "https://arxiv.org/abs/2602.05166", "authors": ["D. -S. Wang"], "title": "Quantum Sequential Circuits", "categories": ["quant-ph", "cond-mat.mtrl-sci", "cs.AR"], "comment": null, "summary": "This work introduces and characterizes quantum sequential circuits (QSCs) as a hardware-oriented paradigm for quantum computing, built upon a novel foundational element termed the quantum transistor. Unlike conventional qubit-based architectures, QSCs employ symmetry-protected topological junctions where quantum gates are encoded as Choi states via channel-state duality and activated through bulk measurements, utilizing ebits to realize the functional analog of feedback loops in classical sequential circuits. This framework establishes a universal model for quantum computation that inherently incorporates memory and temporal sequencing, complementing existing combinational quantum circuit model. Our work advances the conceptual bridge towards a quantum von Neumann architecture, underscoring the potential of hybrid and modular design principles for the development of large-scale, integrated quantum information processors.", "AI": {"tldr": "This paper introduces Quantum Sequential Circuits (QSCs) as a hardware-oriented model for quantum computing using quantum transistors and symmetry-protected topological junctions.", "motivation": "Current quantum computing models lack an integrated approach combining memory and temporal sequencing akin to classical sequential circuits, necessitating a paradigm shift to realize advanced and large-scale quantum processors.", "method": "The authors propose Quantum Sequential Circuits (QSCs) based on quantum transistors, leveraging Choi states and channel-state duality, activated through bulk measurements and ebits to imitate feedback loops in classical designs.", "result": "QSCs establish a universal model for quantum computation, integrating memory and sequencing, and extending the quantum computation framework towards a quantum von Neumann architecture.", "conclusion": "The paper paves the way for hybrid and modular designs in quantum computing, highlighting the potential for scalable, integrated quantum information processors."}}
{"id": "2602.05356", "pdf": "https://arxiv.org/pdf/2602.05356", "abs": "https://arxiv.org/abs/2602.05356", "authors": ["Andrew Lewis-Pye"], "title": "Reaching Univalency with Subquadratic Communication", "categories": ["cs.DC"], "comment": null, "summary": "The Dolev-Reischuk lower bound establishes that any deterministic Byzantine Agreement (BA) protocol for $n$ processors tolerating $f$ faults requires $\u03a9(f^2+n)$ messages. But what exactly does this quadratic cost pay for? Even the minimal requirement that every correct processor \\emph{receive at least one message} already necessitates $\u03a9(f^2 + n)$ messages. This raises a fundamental question: is the Dolev-Reischuk bound about the difficulty of \\emph{reaching univalency} -- the point at which the protocol's outcome is determined -- or merely about \\emph{disseminating} the outcome to all processors afterward?\n  We resolve this question by showing that reaching univalency does \\emph{not} require quadratic communication. Specifically, we introduce $\u03b5$-BA, a relaxation allowing an $\u03b5$-fraction of correct processors to output incorrectly, and prove it can be solved deterministically with $O(n \\log n)$ communication complexity when $f < n(1/3 - \u03b5)$. Crucially, any $\u03b5$-BA protocol can serve as the first phase of a full BA protocol: after $\u03b5$-BA, a single all-to-all exchange and majority vote completes BA. Since the outcome is already determined after $\u03b5$-BA, this demonstrates that the quadratic cost in Dolev-Reischuk stems entirely from dissemination, rather than from reaching univalency. We also define Extractable BA for authenticated settings, capturing when processors collectively hold enough signed messages to determine the agreed value, and show it can be solved with communication complexity $O(f \\log f)$.", "AI": {"tldr": "The paper explores the communication complexity of Byzantine Agreement (BA) protocols, showing that deterministic BA requires $\u03a9(f^2+n)$ messages, but achieving the protocol's univalency phase only needs $O(n log n)$ messages in certain settings.", "motivation": "To investigate the source of the quadratic message complexity in Byzantine Agreement protocols established by the Dolev-Reischuk bound and determine whether the cost arises from achieving univalency or disseminating the outcome.", "method": "The authors introduced a relaxed model called $\u03b5$-BA that tolerates a small fraction of incorrect outputs and demonstrated that it achieves univalency with reduced communication complexity.", "result": "The study proved that $\u03b5$-BA achieves univalency with $O(n log n)$ messages when $f < n(1/3 - \u03b5)$. Additionally, they proposed an Extractable BA protocol in authenticated settings with a communication complexity of $O(f log f)$.", "conclusion": "The quadratic cost in Dolev-Reischuk is attributed to the dissemination phase rather than achieving univalency. Efficient protocols for univalency can be designed with significantly lower communication complexity."}}
{"id": "2602.05106", "pdf": "https://arxiv.org/pdf/2602.05106", "abs": "https://arxiv.org/abs/2602.05106", "authors": ["Michael Browder", "Kevin Duh", "J. David Harris", "Vince Lyzinski", "Paul McNamee", "Youngser Park", "Carey E. Priebe", "Peter Viechnicki"], "title": "Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via synthetic data generation. However, because the models are black boxes, the properties of the synthetic data are difficult to predict. In practice it is common for language technology engineers to 'fiddle' with the LLM temperature setting and hope that what comes out the other end improves the downstream model. Faced with this uncertainty, here we propose Data Kernel Perspective Space (DKPS) to provide the foundation for mathematical analysis yielding concrete statistical guarantees for the quality of the outputs of transformer models. We first show the mathematical derivation of DKPS and how it provides performance guarantees. Next we show how DKPS performance guarantees can elucidate performance of a downstream task, such as neural machine translation models or LLMs trained using Contrastive Preference Optimization (CPO). Limitations of the current work and future research are also discussed.", "AI": {"tldr": "This paper addresses the issue of data scarcity in training language technology models by using transformer models for synthetic data generation. The authors propose a mathematical framework, DKPS, offering statistical guarantees for synthetic data quality.", "motivation": "To tackle the problem of insufficient labeled training data for language models and provide reliable synthetic data generation via transformer models.", "method": "Introduce and derive Data Kernel Perspective Space (DKPS), a mathematical framework for analyzing and guaranteeing the quality of transformer-based synthetic data.", "result": "The study demonstrates how DKPS can predict and improve performance in downstream tasks, such as neural machine translation and models trained via Contrastive Preference Optimization.", "conclusion": "DKPS provides mathematical tools to ensure synthetic data quality, connecting it with improved performance guarantees for specific applications. Limitations and directions for future research are discussed."}}
{"id": "2602.05043", "pdf": "https://arxiv.org/pdf/2602.05043", "abs": "https://arxiv.org/abs/2602.05043", "authors": ["Grace A. Lewis", "Rachel Brower-Sinning", "Robert Edman", "Ipek Ozkaya", "Sebasti\u00e1n Echeverr\u00eda", "Alex Derr", "Collin Beaudoin", "Katherine R. Maffey"], "title": "Quality Model for Machine Learning Components", "categories": ["cs.SE", "cs.AI"], "comment": "A short version of this paper has been accepted to CAIN 2026, the 5th IEEE/ACM Conference on AI Engineering - Software Engineering for AI Systems", "summary": "Despite increased adoption and advances in machine learning (ML), there are studies showing that many ML prototypes do not reach the production stage and that testing is still largely limited to testing model properties, such as model performance, without considering requirements derived from the system it will be a part of, such as throughput, resource consumption, or robustness. This limited view of testing leads to failures in model integration, deployment, and operations. In traditional software development, quality models such as ISO 25010 provide a widely used structured framework to assess software quality, define quality requirements, and provide a common language for communication with stakeholders. A newer standard, ISO 25059, defines a more specific quality model for AI systems. However, a problem with this standard is that it combines system attributes with ML component attributes, which is not helpful for a model developer, as many system attributes cannot be assessed at the component level. In this paper, we present a quality model for ML components that serves as a guide for requirements elicitation and negotiation and provides a common vocabulary for ML component developers and system stakeholders to agree on and define system-derived requirements and focus their testing efforts accordingly. The quality model was validated through a survey in which the participants agreed with its relevance and value. The quality model has been successfully integrated into an open-source tool for ML component testing and evaluation demonstrating its practical application.", "AI": {"tldr": "This paper introduces a quality model for machine learning components aimed at improving requirement elicitation and system testing to reduce failures in integration and operations.", "motivation": "Current machine learning testing focuses mostly on model performance without considering system requirements like throughput, resource consumption, or robustness, causing failures in deployment and operation.", "method": "A structured quality model specific to ML components is proposed, serving as a tool for requirement negotiation and testing aligned with system needs. This was validated through a survey and integrated into an open-source tool.", "result": "The quality model was considered relevant and valuable by survey participants and successfully applied in an open-source tool for ML testing and evaluation.", "conclusion": "The proposed model provides a structured framework for aligning ML component testing with system requirements, improving communication with stakeholders and integration success."}}
{"id": "2602.05156", "pdf": "https://arxiv.org/pdf/2602.05156", "abs": "https://arxiv.org/abs/2602.05156", "authors": ["Dong Ho Kang", "Aaron Kim", "Mingyo Seo", "Kazuto Yokoyama", "Tetsuya Narita", "Luis Sentis"], "title": "PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "We present the PLATO Hand, a dexterous robotic hand with a hybrid fingertip that embeds a rigid fingernail within a compliant pulp. This design shapes contact behavior to enable diverse interaction modes across a range of object geometries. We develop a strain-energy-based bending-indentation model to guide the fingertip design and to explain how guided contact preserves local indentation while suppressing global bending. Experimental results show that the proposed robotic hand design demonstrates improved pinching stability, enhanced force observability, and successful execution of edge-sensitive manipulation tasks, including paper singulation, card picking, and orange peeling. Together, these results show that coupling structured contact geometry with a force-motion transparent mechanism provides a principled, physically embodied approach to precise manipulation.", "AI": {"tldr": "The paper introduces the PLATO Hand, a robotic hand with a hybrid fingertip design that optimizes contact behavior for varied object manipulation, supported by a novel strain-energy model and validated through experiments.", "motivation": "To improve robotic manipulation precision by enabling stable and versatile interaction with objects, particularly edge-sensitive tasks like paper singulation and orange peeling.", "method": "Designs a hybrid robotic fingertip with embedded rigid fingernail and compliant pulp, uses a strain-energy-based bending-indentation model for design guidance, and conducts experiments to validate performance.", "result": "Experimental data confirms improved pinching stability, better force observability, and successful manipulation of complex edge-sensitive tasks.", "conclusion": "A structured contact geometry coupled with a transparent force-motion mechanism leads to enhanced precision and versatility in robotic manipulation tasks."}}
{"id": "2602.05096", "pdf": "https://arxiv.org/pdf/2602.05096", "abs": "https://arxiv.org/abs/2602.05096", "authors": ["Joseph D. Janizek", "Sonnet Xu", "Junayd Lateef", "Roxana Daneshjou"], "title": "Visual concept ranking uncovers medical shortcuts used by large multimodal models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Ensuring the reliability of machine learning models in safety-critical domains such as healthcare requires auditing methods that can uncover model shortcomings. We introduce a method for identifying important visual concepts within large multimodal models (LMMs) and use it to investigate the behaviors these models exhibit when prompted with medical tasks. We primarily focus on the task of classifying malignant skin lesions from clinical dermatology images, with supplemental experiments including both chest radiographs and natural images. After showing how LMMs display unexpected gaps in performance between different demographic subgroups when prompted with demonstrating examples, we apply our method, Visual Concept Ranking (VCR), to these models and prompts. VCR generates hypotheses related to different visual feature dependencies, which we are then able to validate with manual interventions.", "AI": {"tldr": "The paper presents a method to identify visual concepts in large multimodal models (LMMs) for auditing model reliability in medical tasks.", "motivation": "To enhance the reliability of machine learning models in safety-critical domains like healthcare by identifying visual concept-based shortcomings.", "method": "The method introduced is Visual Concept Ranking (VCR), which generates hypotheses about visual feature dependencies and validates them with manual interventions.", "result": "VCR revealed unexpected performance gaps in LMMs across demographic subgroups in medical tasks including malignant skin lesion classification.", "conclusion": "The approach enhances auditing capabilities, enabling the identification and understanding of visual concept-related model weaknesses in healthcare-focused LMMs."}}
{"id": "2602.05073", "pdf": "https://arxiv.org/pdf/2602.05073", "abs": "https://arxiv.org/abs/2602.05073", "authors": ["Changdae Oh", "Seongheon Park", "To Eun Kim", "Jiatong Li", "Wendi Li", "Samuel Yeh", "Xuefeng Du", "Hamed Hassani", "Paul Bogdan", "Dawn Song", "Sharon Li"], "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents", "categories": ["cs.AI"], "comment": null, "summary": "Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting \"interactivity\" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.", "AI": {"tldr": "The paper presents a framework for uncertainty quantification (UQ) in interactive language agent settings, transitioning from traditional approaches to a novel conditional uncertainty reduction perspective.", "motivation": "The motivation is to advance UQ research from single-turn question-answering tasks to interactive, real-world agent settings, which are increasingly relevant as LLM agents tackle complex tasks.", "method": "It introduces a new conceptual framework treating UQ as a conditional uncertainty reduction process, emphasizing reducible uncertainty throughout an agent's trajectory in interactive contexts.", "result": "The paper provides a structured framework for designing UQ systems in interactive LLM scenarios and highlights the limitations of previous accumulation-oriented approaches.", "conclusion": "The work underscores the importance of rethinking UQ for interactive agents, offering guidelines for future research and practical applications while noting unresolved challenges."}}
{"id": "2602.05340", "pdf": "https://arxiv.org/pdf/2602.05340", "abs": "https://arxiv.org/abs/2602.05340", "authors": ["Beichen Wan", "Mo Liu", "Paul Grigas", "Zuo-Jun Max Shen"], "title": "Decision-Focused Sequential Experimental Design: A Directional Uncertainty-Guided Approach", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We consider the sequential experimental design problem in the predict-then-optimize paradigm. In this paradigm, the outputs of the prediction model are used as coefficient vectors in a downstream linear optimization problem. Traditional sequential experimental design aims to control the input variables (features) so that the improvement in prediction accuracy from each experimental outcome (label) is maximized. However, in the predict-then-optimize setting, performance is ultimately evaluated based on the decision loss induced by the downstream optimization, rather than by prediction error. This mismatch between prediction accuracy and decision loss renders traditional decision-blind designs inefficient. To address this issue, we propose a directional-based metric to quantify predictive uncertainty. This metric does not require solving an optimization oracle and is therefore computationally tractable. We show that the resulting sequential design criterion enjoys strong consistency and convergence guarantees. Under a broad class of distributions, we demonstrate that our directional uncertainty-based design attains an earlier stopping time than decision-blind designs. This advantage is further supported by real-world experiments on an LLM job allocation problem.", "AI": {"tldr": "The paper focuses on improving the sequential experimental design in predict-then-optimize frameworks by introducing a directional-based metric for predictive uncertainty, enhancing computational efficiency and decision-making.", "motivation": "Traditional experimental design for prediction models does not efficiently address the mismatch between improving prediction accuracy and minimizing downstream decision loss in optimization tasks.", "method": "The authors propose a directional-based metric to measure predictive uncertainty and incorporate this into the experimental design process, offering computational feasibility without solving an optimization oracle.", "result": "The proposed framework demonstrates earlier stopping times and superior performance compared to traditional decision-blind designs, with validated results from a case study on LLM job allocation.", "conclusion": "The directional uncertainty-based design enhances efficiency and decision-making in predict-then-optimize setups, offering both theoretical guarantees and practical benefits."}}
{"id": "2602.04904", "pdf": "https://arxiv.org/pdf/2602.04904", "abs": "https://arxiv.org/abs/2602.04904", "authors": ["Yiwen Wang", "Jiahao Qin"], "title": "DCER: Dual-Stage Compression and Energy-Based Reconstruction", "categories": ["cs.LG", "cs.AI", "cs.MM", "eess.IV"], "comment": "13 pages, 2 figures, 8 tables. Submitted to ICML 2026. Code will be available on GitHub", "summary": "Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a\n  unified framework addressing both challenges through dual-stage compression and energy-based reconstruction. The compression stage operates at two levels:\n  within-modality frequency transforms (wavelet for audio, DCT for video) remove noise while preserving task-relevant patterns, and cross-modality bottleneck tokens\n  force genuine integration rather than modality-specific shortcuts. For missing modalities, energy-based reconstruction recovers representations via gradient descent\n  on a learned energy function, with the final energy providing intrinsic uncertainty quantification (\\r{ho} > 0.72 correlation with prediction error). Experiments on\n  CMU-MOSI, CMU-MOSEI, and CH-SIMS demonstrate state-of-the-art performance across all benchmarks, with a U-shaped robustness pattern favoring multimodal fusion at\n  both complete and high-missing conditions. The code will be available on Github.", "AI": {"tldr": "DCER framework addresses robustness challenges in multimodal fusion by combating noise and missing inputs. It uses dual-stage compression and energy-based reconstruction, achieving state-of-the-art results.", "motivation": "To address robustness issues in multimodal fusion such as noisy inputs and missing modalities, which impact prediction quality.", "method": "DCER framework utilizes dual-stage compression (frequency transforms and bottleneck tokens) and energy-based reconstruction using a learned energy function.", "result": "Experiments on CMU-MOSI, CMU-MOSEI, and CH-SIMS datasets achieved state-of-the-art results and demonstrated robustness to varying levels of missing modalities.", "conclusion": "DCER is effective in enhancing robustness in multimodal fusion, ensuring high-quality predictions under noisy and missing inputs. The code will be publicly accessible on GitHub."}}
{"id": "2602.05754", "pdf": "https://arxiv.org/pdf/2602.05754", "abs": "https://arxiv.org/abs/2602.05754", "authors": ["Seonghye Cho", "Jaemin Han", "Hyunjin Kim", "Euisoo Jung", "Jae-Gil Lee"], "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulting in unnecessary accuracy degradation. To address this issue, we propose TimelyFreeze, which models the pipeline schedule as a directed acyclic graph and solves a linear program to compute optimal freeze ratios that minimize batch execution time under accuracy constraints. Experiments show that TimelyFreeze achieves up to 40% training throughput improvement on LLaMA-8B with comparable accuracy. Overall, it enables faster large-scale model training without compromising convergence and generalizes across diverse pipeline-parallel settings.", "AI": {"tldr": "TimelyFreeze improves pipeline parallelism for large model training, enhancing training throughput by up to 40% while maintaining accuracy.", "motivation": "The paper aims to address inefficiencies in pipeline training throughput caused by parameter over-freezing, leading to unnecessary accuracy degradation.", "method": "TimelyFreeze uses a directed acyclic graph model of the pipeline schedule and optimizes freeze ratios using a linear programming approach to balance throughput and accuracy.", "result": "TimelyFreeze demonstrates a 40% increase in training throughput for LLaMA-8B with comparable accuracy across various pipeline-parallel configurations.", "conclusion": "TimelyFreeze facilitates faster model training for large-scale models by optimizing parameter freezing while preserving convergence and generalization capabilities."}}
{"id": "2602.05107", "pdf": "https://arxiv.org/pdf/2602.05107", "abs": "https://arxiv.org/abs/2602.05107", "authors": ["Ahmed Ruby", "Christian Hardmeier", "Sara Stymne"], "title": "Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text", "categories": ["cs.CL"], "comment": null, "summary": "Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To address this, we introduce an automatic method for distantly related and unrelated language pairs to construct a multilingual and multimodal dataset for implicit discourse relations in English, French, and Spanish. For classification, we propose a multimodal approach that integrates textual and acoustic information through Qwen2-Audio, allowing joint modeling of text and audio for implicit discourse relation classification across languages. We find that while text-based models outperform audio-based models, integrating both modalities can enhance performance, and cross-lingual transfer can provide substantial improvements for low-resource languages.", "AI": {"tldr": "The paper addresses implicit discourse relation classification by creating a multilingual multimodal dataset and introducing a method that integrates text and audio for classification across languages.", "motivation": "Existing implicit discourse relation classification is challenging due to the need for contextual understanding, which text alone often fails to capture, especially across languages and modalities.", "method": "The authors construct a multilingual multimodal dataset (English, French, Spanish) and propose a multimodal classification approach using Qwen2-Audio to integrate textual and acoustic information for better results.", "result": "The study finds text-based models perform better than audio models, but combining both improves performance. Cross-lingual transfer benefits low-resource languages significantly.", "conclusion": "Combining text and audio modalities enhances implicit discourse relation classification, with significant advantages for low-resource languages through cross-lingual transfer."}}
{"id": "2602.05122", "pdf": "https://arxiv.org/pdf/2602.05122", "abs": "https://arxiv.org/abs/2602.05122", "authors": ["Altino Alves", "Andre Hora"], "title": "TestMigrationsInPy: A Dataset of Test Migrations from Unittest to Pytest", "categories": ["cs.SE"], "comment": "Published at MSR 2025", "summary": "Unittest and pytest are the most popular testing frameworks in Python. Overall, pytest provides some advantages, including simpler assertion, reuse of fixtures, and interoperability. Due to such benefits, multiple projects in the Python ecosystem have migrated from unittest to pytest. To facilitate the migration, pytest can also run unittest tests, thus, the migration can happen gradually over time. However, the migration can be time-consuming and take a long time to conclude. In this context, projects would benefit from automated solutions to support the migration process. In this paper, we propose TestMigrationsInPy, a dataset of test migrations from unittest to pytest. TestMigrationsInPy contains 923 real-world migrations performed by developers. Future research proposing novel solutions to migrate frameworks in Python can rely on TestMigrationsInPy as a ground truth. Moreover, as TestMigrationsInPy includes information about the migration type (e.g., changes in assertions or fixtures), our dataset enables novel solutions to be verified effectively, for instance, from simpler assertion migrations to more complex fixture migrations. TestMigrationsInPy is publicly available at: https://github.com/altinoalvesjunior/TestMigrationsInPy.", "AI": {"tldr": "This study introduces TestMigrationsInPy, a dataset dedicated to supporting the migration of tests from unittest to pytest in Python.", "motivation": "Address the challenges and time consumption in migrating Python projects from unittest framework to pytest by providing an automated migration dataset.", "method": "A dataset is created (TestMigrationsInPy) comprising 923 real-world test migrations, with detailed categorization by migration types.", "result": "The dataset facilitates automated tool development, supports gradual framework migration, and acts as a ground truth for testing migration solutions.", "conclusion": "TestMigrationsInPy provides a foundation for research and tools assisting in Python testing framework migrations and ensures validation of novel migration methodologies."}}
{"id": "2602.05198", "pdf": "https://arxiv.org/pdf/2602.05198", "abs": "https://arxiv.org/abs/2602.05198", "authors": ["Kalvik Jakkala", "Saurav Agarwal", "Jason O'Kane", "Srinivas Akella"], "title": "Informative Path Planning with Guaranteed Estimation Uncertainty", "categories": ["cs.RO"], "comment": "16 pages, 11 figures, preprint", "summary": "Environmental monitoring robots often need to reconstruct spatial fields (e.g., salinity, temperature, bathymetry) under tight distance and energy constraints. Classical boustrophedon lawnmower surveys provide geometric coverage guarantees but can waste effort by oversampling predictable regions. In contrast, informative path planning (IPP) methods leverage spatial correlations to reduce oversampling, yet typically offer no guarantees on reconstruction quality. This paper bridges these approaches by addressing informative path planning with guaranteed estimation uncertainty: computing the shortest path whose measurements ensure that the Gaussian-process (GP) posterior variance -- an intrinsic uncertainty measure that lower-bounds the mean-squared prediction error under the GP model -- falls below a user-specified threshold over the monitoring region.\n  We propose a three-stage approach: (i) learn a GP model from available prior information; (ii) transform the learned GP kernel into binary coverage maps for each candidate sensing location, indicating which locations' uncertainty can be reduced below a specified target; and (iii) plan a near-shortest route whose combined coverage satisfies the global uncertainty constraint. To address heterogeneous phenomena, we incorporate a nonstationary kernel that captures spatially varying correlation structure, and we accommodate non-convex environments with obstacles. Algorithmically, we present methods with provable approximation guarantees for sensing-location selection and for the joint selection-and-routing problem under a travel budget. Experiments on real-world topographic data show that our planners meet the uncertainty target using fewer sensing locations and shorter travel distances than a recent baseline, and field experiments with bathymetry-mapping autonomous surface and underwater vehicles demonstrate real-world feasibility.", "AI": {"tldr": "This paper develops an informative path planning method that bridges traditional geometric coverage guarantees and uncertainty minimization, ensuring estimation uncertainty is kept under a specified threshold.", "motivation": "Environmental monitoring robots face challenges in efficiently mapping spatial fields under limited resources, such as energy and travel distance, without excessive data oversampling or decreased accuracy.", "method": "The paper proposes a three-stage approach: (1) learning a Gaussian-process model to represent region uncertainty, (2) deriving binary coverage maps from learned kernels to identify locations where uncertainty can be reduced, and (3) planning a near-shortest route that ensures global uncertainty thresholds under travel constraints. It incorporates advanced methods like nonstationary kernels and accommodates challenging environments with obstacles.", "result": "The proposed method demonstrates improved efficiency compared to existing methods, reducing sensing locations and travel distances while meeting uncertainty goals. Real-world experiments validate its practical application for bathymetric digital mapping.", "conclusion": "This method advances robotic environmental monitoring by providing a practical and theoretically sound strategy that blends informative path planning, uncertainty reduction, and constrained optimization, enabling efficient and accurate spatial field reconstruction."}}
{"id": "2602.05126", "pdf": "https://arxiv.org/pdf/2602.05126", "abs": "https://arxiv.org/abs/2602.05126", "authors": ["Weiyi Qin", "Yingci Liu-Swetz", "Shiwei Tan", "Hao Wang"], "title": "CLEAR-HPV: Interpretable Concept Discovery for HPV-Associated Morphology in Whole-Slide Histology", "categories": ["cs.CV"], "comment": null, "summary": "Human papillomavirus (HPV) status is a critical determinant of prognosis and treatment response in head and neck and cervical cancers. Although attention-based multiple instance learning (MIL) achieves strong slide-level prediction for HPV-related whole-slide histopathology, it provides limited morphologic interpretability. To address this limitation, we introduce Concept-Level Explainable Attention-guided Representation for HPV (CLEAR-HPV), a framework that restructures the MIL latent space using attention to enable concept discovery without requiring concept labels during training. Operating in an attention-weighted latent space, CLEAR-HPV automatically discovers keratinizing, basaloid, and stromal morphologic concepts, generates spatial concept maps, and represents each slide using a compact concept-fraction vector. CLEAR-HPV's concept-fraction vectors preserve the predictive information of the original MIL embeddings while reducing the high-dimensional feature space (e.g., 1536 dimensions) to only 10 interpretable concepts. CLEAR-HPV generalizes consistently across TCGA-HNSCC, TCGA-CESC, and CPTAC-HNSCC, providing compact, concept-level interpretability through a general, backbone-agnostic framework for attention-based MIL models of whole-slide histopathology.", "AI": {"tldr": "The paper introduces CLEAR-HPV, a framework for interpreting attention-based multiple instance learning on histopathology slides for HPV status prediction, utilizing morphologic concepts for explainability.", "motivation": "Current approaches in HPV-related histopathology using attention-based MIL offer strong predictions but lack interpretability of the morphologic features.", "method": "CLEAR-HPV uses an attention-weighted latent space to automatically discover morphologic concepts such as keratinizing, basaloid, and stromal, without labeled training data, and restructures the MIL embeddings into interpretable vectors while maintaining predictive capability.", "result": "The framework drastically reduces high-dimensional features into 10 interpretable concepts while preserving predictive accuracy across multiple cancer datasets (TCGA-HNSCC, TCGA-CESC, and CPTAC-HNSCC).", "conclusion": "CLEAR-HPV provides a general, interpretable framework compatible with attention-based MIL for whole-slide histopathology, paving the way for compact concept-level insights without compromising prediction performance."}}
{"id": "2602.05075", "pdf": "https://arxiv.org/pdf/2602.05075", "abs": "https://arxiv.org/abs/2602.05075", "authors": ["Agni Bandyopadhyay", "Gunther Waxenegger-Wilfing"], "title": "Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance", "categories": ["cs.AI", "cs.LG", "cs.RO", "physics.space-ph"], "comment": "Accpeted at Conference: 15th IAA Symposium on Small Satellites for Earth System Observation At: Berlin", "summary": "As the orbital environment around Earth becomes increasingly crowded with debris, active debris removal (ADR) missions face significant challenges in ensuring safe operations while minimizing the risk of in-orbit collisions. This study presents a reinforcement learning (RL) based framework to enhance adaptive collision avoidance in ADR missions, specifically for multi-debris removal using small satellites. Small satellites are increasingly adopted due to their flexibility, cost effectiveness, and maneuverability, making them well suited for dynamic missions such as ADR.\n  Building on existing work in multi-debris rendezvous, the framework integrates refueling strategies, efficient mission planning, and adaptive collision avoidance to optimize spacecraft rendezvous operations. The proposed approach employs a masked Proximal Policy Optimization (PPO) algorithm, enabling the RL agent to dynamically adjust maneuvers in response to real-time orbital conditions. Key considerations include fuel efficiency, avoidance of active collision zones, and optimization of dynamic orbital parameters.\n  The RL agent learns to determine efficient sequences for rendezvousing with multiple debris targets, optimizing fuel usage and mission time while incorporating necessary refueling stops. Simulated ADR scenarios derived from the Iridium 33 debris dataset are used for evaluation, covering diverse orbital configurations and debris distributions to demonstrate robustness and adaptability. Results show that the proposed RL framework reduces collision risk while improving mission efficiency compared to traditional heuristic approaches.\n  This work provides a scalable solution for planning complex multi-debris ADR missions and is applicable to other multi-target rendezvous problems in autonomous space mission planning.", "AI": {"tldr": "The study proposes a reinforcement learning (RL) framework using small satellites for active debris removal (ADR), optimizing fuel usage, collision avoidance, and mission efficiency.", "motivation": "To address the growing congestion of orbital debris around Earth and the challenges of ensuring efficient and safe ADR missions.", "method": "A reinforcement learning-based framework utilizing masked Proximal Policy Optimization (PPO) to optimize multi-debris rendezvous\u2014including refueling strategies, mission planning, and collision avoidance.", "result": "The RL framework demonstrated enhanced performance, reducing collision risks and improving fuel and mission efficiency compared to traditional methods, as validated through simulations using the Iridium 33 debris dataset.", "conclusion": "The approach provides a scalable, adaptive solution for complex multi-debris ADR missions and broader autonomous space mission planning challenges."}}
{"id": "2602.05379", "pdf": "https://arxiv.org/pdf/2602.05379", "abs": "https://arxiv.org/abs/2602.05379", "authors": ["Hua Zheng", "Wei Xie", "M. Ben Feng", "Keilung Choy"], "title": "Variance Reduction Based Experience Replay for Policy Optimization", "categories": ["stat.ML", "cs.LG"], "comment": "24 pages, 4 figures. arXiv admin note: text overlap with arXiv:2208.12341", "summary": "Effective reinforcement learning (RL) for complex stochastic systems requires leveraging historical data collected in previous iterations to accelerate policy optimization. Classical experience replay treats all past observations uniformly and fails to account for their varying contributions to learning. To overcome this limitation, we propose Variance Reduction Experience Replay (VRER), a principled framework that selectively reuses informative samples to reduce variance in policy gradient estimation. VRER is algorithm-agnostic and integrates seamlessly with existing policy optimization methods, forming the basis of our sample-efficient off-policy algorithm, Policy Gradient with VRER (PG-VRER). Motivated by the lack of rigorous theoretical analysis of experience replay, we develop a novel framework that explicitly captures dependencies introduced by Markovian dynamics and behavior-policy interactions. Using this framework, we establish finite-time convergence guarantees for PG-VRER and reveal a fundamental bias-variance trade-off: reusing older experience increases bias but simultaneously reduces gradient variance. Extensive empirical experiments demonstrate that VRER consistently accelerates policy learning and improves performance over state-of-the-art policy optimization algorithms.", "AI": {"tldr": "Authors propose the Variance Reduction Experience Replay (VRER), enhancing and accelerating reinforcement learning by selectively reusing past data to reduce variance in policy gradient estimation, leading to improved and more sample-efficient policy optimization.", "motivation": "Classical experience replay in RL does not account for the varying usefulness of historical data, leading to suboptimal policy optimization. Addressing this limitation can significantly improve learning efficiency and performance.", "method": "The VRER framework selectively reuses informative historical data, reducing variance in policy gradient estimation. This approach is algorithm-agnostic and forms the basis of the Policy Gradient with VRER (PG-VRER) algorithm. A novel theoretical framework is also developed to capture dependencies in Markovian dynamics and behavior-policy interactions, enabling finite-time convergence guarantees.", "result": "VRER reduces gradient variance, leading to accelerated and more sample-efficient policy learning. The proposed PG-VRER algorithm outperforms state-of-the-art methods in empirical experiments.", "conclusion": "VRER offers a principled and theoretically grounded method for enhancing reinforcement learning by striking a balance between bias and variance. It sets a new standard for effective policy optimization in RL."}}
{"id": "2602.04906", "pdf": "https://arxiv.org/pdf/2602.04906", "abs": "https://arxiv.org/abs/2602.04906", "authors": ["Julio Candanedo"], "title": "LISA: Laplacian In-context Spectral Analysis", "categories": ["cs.LG"], "comment": null, "summary": "We propose Laplacian In-context Spectral Analysis (LISA), a method for inference-time adaptation of Laplacian-based time-series models using only an observed prefix. LISA combines delay-coordinate embeddings and Laplacian spectral learning to produce diffusion-coordinate state representations, together with a frozen nonlinear decoder for one-step prediction. We introduce lightweight latent-space residual adapters based on either Gaussian-process regression or an attention-like Markov operator over context windows. Across forecasting and autoregressive rollout experiments, LISA improves over the frozen baseline and is often most beneficial under changing dynamics. This work links in-context adaptation to nonparametric spectral methods for dynamical systems.", "AI": {"tldr": "LISA is a method for adapting Laplacian-based time-series models with only observed prefixes, improving forecasting and autoregressive prediction under dynamic conditions.", "motivation": "This paper aims to enhance inference-time adaptations of Laplacian-based time-series models, especially under dynamics changes, by leveraging spectral methods and nonparametric techniques.", "method": "Laplacian In-context Spectral Analysis (LISA) involves using delay-coordinate embeddings and Laplacian spectral learning for diffusion-coordinate state representations. It incorporates frozen nonlinear decoders for predictions and lightweight residual adapters using Gaussian-process regression or attention-like Markov operators.", "result": "LISA improves prediction performance over frozen baselines in both forecasting and autoregressive tasks, outperforming particularly in changing dynamics.", "conclusion": "The approach connects in-context adaptation to spectral methods, enabling more robust time-series predictions under dynamics variability."}}
{"id": "2602.05948", "pdf": "https://arxiv.org/pdf/2602.05948", "abs": "https://arxiv.org/abs/2602.05948", "authors": ["Himani", "Supantha Pandit", "Gokarna Sharma"], "title": "Location-Aware Dispersion on Anonymous Graphs", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "comment": "3 tables, 2 figures, 6 pseudo-codes", "summary": "The well-studied DISPERSION problem is a fundamental coordination problem in distributed robotics, where a set of mobile robots must relocate so that each occupies a distinct node of a network. DISPERSION assumes that a robot can settle at any node as long as no other robot settles on that node. In this work, we introduce LOCATION-AWARE DISPERSION, a novel generalization of DISPERSION that incorporates location awareness: Let $G = (V, E)$ be an anonymous, connected, undirected graph with $n = |V|$ nodes, each labeled with a color $\\sf{col}(v) \\in C = \\{c_1, \\dots, c_t\\}, t\\leq n$. A set $R = \\{r_1, \\dots, r_k\\}$ of $k \\leq n$ mobile robots is given, where each robot $r_i$ has an associated color $\\mathsf{col}(r_i) \\in C$. Initially placed arbitrarily on the graph, the goal is to relocate the robots so that each occupies a distinct node of the same color. When $|C|=1$, LOCATION-AWARE DISPERSION reduces to DISPERSION. There is a solution to DISPERSION in graphs with any $k\\leq n$ without knowing $k,n$.\n  Like DISPERSION, the goal is to solve LOCATION-AWARE DISPERSION minimizing both time and memory requirement at each agent. We develop several deterministic algorithms with guaranteed bounds on both time and memory requirement. We also give an impossibility and a lower bound for any deterministic algorithm for LOCATION-AWARE DISPERSION. To the best of our knowledge, the presented results collectively establish the algorithmic feasibility of LOCATION-AWARE DISPERSION in anonymous networks and also highlight the challenges on getting an efficient solution compared to the solutions for DISPERSION.", "AI": {"tldr": "The paper introduces LOCATION-AWARE DISPERSION, a generalization of the DISPERSION problem for relocating robots to graph nodes matching their assigned color while aiming to minimize time and memory usage.", "motivation": "The motivation is to generalize the DISPERSION problem to include location awareness by addressing how robots can settle uniquely on nodes with matching colors in anonymous networks.", "method": "Deterministic algorithms are developed with guarantees on time and memory usage, alongside establishing impossibility results and lower bounds for deterministic solutions.", "result": "Several algorithms with time/memory bounds for LOCATION-AWARE DISPERSION are proposed, while impossibility results and lower bounds showcase the challenges compared to standard DISPERSION.", "conclusion": "The paper establishes that LOCATION-AWARE DISPERSION is algorithmically feasible in anonymous networks, highlighting its increased complexity compared to DISPERSION."}}
{"id": "2602.05150", "pdf": "https://arxiv.org/pdf/2602.05150", "abs": "https://arxiv.org/abs/2602.05150", "authors": ["Yang Zhang", "Mersin Konomi", "Christos Xypolopoulos", "Konstantinos Divriotis", "Konstantinos Skianis", "Giannis Nikolentzos", "Giorgos Stamou", "Guokan Shang", "Michalis Vazirgiannis"], "title": "GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machine-translated from English, failing to capture Greek linguistic and cultural characteristics. We introduce GreekMMLU, a native-sourced benchmark for massive multitask language understanding in Greek, comprising 21,805 multiple-choice questions across 45 subject areas, organized under a newly defined subject taxonomy and annotated with educational difficulty levels spanning primary to professional examinations. All questions are sourced or authored in Greek from academic, professional, and governmental exams. We publicly release 16,857 samples and reserve 4,948 samples for a private leaderboard to enable robust and contamination-resistant evaluation. Evaluations of over 80 open- and closed-source LLMs reveal substantial performance gaps between frontier and open-weight models, as well as between Greek-adapted models and general multilingual ones. Finally, we provide a systematic analysis of factors influencing performance-including model scale, adaptation, and prompting-and derive insights for improving LLM capabilities in Greek.", "AI": {"tldr": "The paper introduces a native-sourced Greek benchmark, GreekMMLU, to evaluate LLMs' performance across 45 subject areas, addressing linguistic gaps in multilingual datasets.", "motivation": "Existing benchmarks for evaluating Greek in LLMs are often machine-translated, failing to reflect its linguistic and cultural intricacies.", "method": "The authors developed GreekMMLU with 21,805 Greek-sourced multiple-choice questions, categorized by subject and difficulty, and released a public dataset while reserving a private leaderboard.", "result": "Evaluations on over 80 LLMs highlight performance disparities between advanced and open models, as well as general multilingual and Greek-adapted ones.", "conclusion": "The study underscores challenges in Greek language processing by LLMs and offers analyses to enhance their Greek capabilities."}}
{"id": "2602.05123", "pdf": "https://arxiv.org/pdf/2602.05123", "abs": "https://arxiv.org/abs/2602.05123", "authors": ["Andre Hora", "Gordon Fraser"], "title": "Exceptional Behaviors: How Frequently Are They Tested?", "categories": ["cs.SE"], "comment": "Published at AST 2025", "summary": "Exceptions allow developers to handle error cases expected to occur infrequently. Ideally, good test suites should test both normal and exceptional behaviors to catch more bugs and avoid regressions. While current research analyzes exceptions that propagate to tests, it does not explore other exceptions that do not reach the tests. In this paper, we provide an empirical study to explore how frequently exceptional behaviors are tested in real-world systems. We consider both exceptions that propagate to tests and the ones that do not reach the tests. For this purpose, we run an instrumented version of test suites, monitor their execution, and collect information about the exceptions raised at runtime. We analyze the test suites of 25 Python systems, covering 5,372 executed methods, 17.9M calls, and 1.4M raised exceptions. We find that 21.4% of the executed methods do raise exceptions at runtime. In methods that raise exceptions, on the median, 1 in 10 calls exercise exceptional behaviors. Close to 80% of the methods that raise exceptions do so infrequently, but about 20% raise exceptions more frequently. Finally, we provide implications for researchers and practitioners. We suggest developing novel tools to support exercising exceptional behaviors and refactoring expensive try/except blocks. We also call attention to the fact that exception-raising behaviors are not necessarily \"abnormal\" or rare.", "AI": {"tldr": "The paper examines the under-explored testing of exceptional behaviors in Python systems, finding many exceptions raised during runtime and calls for better tools and practices to address this.", "motivation": "To understand the frequency and behavior of exceptions in real-world systems and explore how well they are tested.", "method": "An empirical study analyzing 25 Python systems with an instrumented version of test suites to monitor exceptions raised at runtime.", "result": "21.4% of executed methods raised exceptions at runtime, with 1 in 10 calls exercising exceptional behaviors on median, and 80% of exception-raising methods being infrequent.", "conclusion": "Researchers and practitioners should develop new tools for testing exceptional behaviors, rethink try/except blocks, and recognize exceptions are not always rare phenomena."}}
{"id": "2602.05233", "pdf": "https://arxiv.org/pdf/2602.05233", "abs": "https://arxiv.org/abs/2602.05233", "authors": ["Wenbo Wang", "Fangyun Wei", "QiXiu Li", "Xi Chen", "Yaobo Liang", "Chang Xu", "Jiaolong Yang", "Baining Guo"], "title": "MobileManiBench: Simplifying Model Verification for Mobile Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Vision-language-action models have advanced robotic manipulation but remain constrained by reliance on the large, teleoperation-collected datasets dominated by the static, tabletop scenes. We propose a simulation-first framework to verify VLA architectures before real-world deployment and introduce MobileManiBench, a large-scale benchmark for mobile-based robotic manipulation. Built on NVIDIA Isaac Sim and powered by reinforcement learning, our pipeline autonomously generates diverse manipulation trajectories with rich annotations (language instructions, multi-view RGB-depth-segmentation images, synchronized object/robot states and actions). MobileManiBench features 2 mobile platforms (parallel-gripper and dexterous-hand robots), 2 synchronized cameras (head and right wrist), 630 objects in 20 categories, 5 skills (open, close, pull, push, pick) with over 100 tasks performed in 100 realistic scenes, yielding 300K trajectories. This design enables controlled, scalable studies of robot embodiments, sensing modalities, and policy architectures, accelerating research on data efficiency and generalization. We benchmark representative VLA models and report insights into perception, reasoning, and control in complex simulated environments.", "AI": {"tldr": "The paper introduces MobileManiBench, a simulation-first framework and benchmark for mobile-based robotic manipulation to address limitations in existing vision-language-action models.", "motivation": "Current robotic manipulation models rely heavily on large datasets from teleoperation, focusing mainly on static, tabletop scenes. There is a need for scalable, diverse, and realistic benchmarks to improve generalization and data efficiency.", "method": "The proposed MobileManiBench framework leverages NVIDIA Isaac Sim to autonomously generate annotated manipulation trajectories with reinforcement learning. It includes diverse tasks, robots, objects, scenes, and modalities for comprehensive benchmarking.", "result": "MobileManiBench features 300K trajectories, multiple robots, object categories, and manipulation tasks, enabling controlled studies of robot embodiments and policy architectures. Insights were gained through benchmarking representative VLA models.", "conclusion": "MobileManiBench accelerates robotic manipulation research by providing a scalable, realistic, and diverse simulation benchmark for testing VLA architectures and improving their performance."}}
{"id": "2602.05132", "pdf": "https://arxiv.org/pdf/2602.05132", "abs": "https://arxiv.org/abs/2602.05132", "authors": ["Jia Li", "Wenjie Zhao", "Shijian Deng", "Bolin Lai", "Yuheng Wu", "RUijia Chen", "Jon E. Froehlich", "Yuhang Zhao", "Yapeng Tian"], "title": "ARGaze: Autoregressive Transformers for Online Egocentric Gaze Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Online egocentric gaze estimation predicts where a camera wearer is looking from first-person video using only past and current frames, a task essential for augmented reality and assistive technologies. Unlike third-person gaze estimation, this setting lacks explicit head or eye signals, requiring models to infer current visual attention from sparse, indirect cues such as hand-object interactions and salient scene content. We observe that gaze exhibits strong temporal continuity during goal-directed activities: knowing where a person looked recently provides a powerful prior for predicting where they look next. Inspired by vision-conditioned autoregressive decoding in vision-language models, we propose ARGaze, which reformulates gaze estimation as sequential prediction: at each timestep, a transformer decoder predicts current gaze by conditioning on (i) current visual features and (ii) a fixed-length Gaze Context Window of recent gaze target estimates. This design enforces causality and enables bounded-resource streaming inference. We achieve state-of-the-art performance across multiple egocentric benchmarks under online evaluation, with extensive ablations validating that autoregressive modeling with bounded gaze history is critical for robust prediction. We will release our source code and pre-trained models.", "AI": {"tldr": "ARGaze proposes a sequential autoregressive model for online egocentric gaze estimation using past gaze targets and current visual inputs, achieving state-of-the-art results.", "motivation": "The paper addresses the challenge of online egocentric gaze estimation, where direct gaze signals are unavailable, making it necessary to infer attention from indirect cues like scene content and hand-object interactions.", "method": "ARGaze uses a transformer decoder to predict gaze in a sequential manner. It conditions on current visual features and a fixed-length window of recent gaze target estimates, enforcing causality and enabling efficient streaming inference.", "result": "ARGaze achieves state-of-the-art performance on multiple egocentric benchmarks in online gaze estimation settings, with ablations confirming the importance of autoregressive modeling.", "conclusion": "The study demonstrates that autoregressive modeling with bounded gaze history is crucial for robust egocentric gaze prediction, and the approach sets a new standard for the task. Resources include code and pre-trained models for external use and further research."}}
{"id": "2602.05088", "pdf": "https://arxiv.org/pdf/2602.05088", "abs": "https://arxiv.org/abs/2602.05088", "authors": ["Kate H. Bentley", "Luca Belli", "Adam M. Chekroud", "Emily J. Ward", "Emily R. Dworkin", "Emily Van Ark", "Kelly M. Johnston", "Will Alexander", "Millard Brown", "Matt Hawrilenko"], "title": "VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health", "categories": ["cs.AI"], "comment": null, "summary": "Millions now use leading generative AI chatbots for psychological support. Despite the promise related to availability and scale, the single most pressing question in AI for mental health is whether these tools are safe. The Validation of Ethical and Responsible AI in Mental Health (VERA-MH) evaluation was recently proposed to meet the urgent need for an evidence-based automated safety benchmark. This study aimed to examine the clinical validity and reliability of the VERA-MH evaluation for AI safety in suicide risk detection and response. We first simulated a large set of conversations between large language model (LLM)-based users (user-agents) and general-purpose AI chatbots. Licensed mental health clinicians used a rubric (scoring guide) to independently rate the simulated conversations for safe and unsafe chatbot behaviors, as well as user-agent realism. An LLM-based judge used the same scoring rubric to evaluate the same set of simulated conversations. We then compared rating alignment across (a) individual clinicians and (b) clinician consensus and the LLM judge, and (c) examined clinicians' ratings of user-agent realism. Individual clinicians were generally consistent with one another in their safety ratings (chance-corrected inter-rater reliability [IRR]: 0.77), thus establishing a gold-standard clinical reference. The LLM judge was strongly aligned with this clinical consensus (IRR: 0.81) overall and within key conditions. Clinician raters generally perceived the user-agents to be realistic. For the potential mental health benefits of AI chatbots to be realized, attention to safety is paramount. Findings from this human evaluation study support the clinical validity and reliability of VERA-MH: an open-source, fully automated AI safety evaluation for mental health. Further research will address VERA-MH generalizability and robustness.", "AI": {"tldr": "The paper examines the safety of AI chatbots in handling mental health issues, specifically focusing on suicide risk detection using the VERA-MH evaluation framework. Findings show that the method is clinically valid and reliable.", "motivation": "There is an urgent need to ensure AI chatbots used for mental health support are safe, particularly as millions increasingly rely on them.", "method": "The study involved simulating conversations between AI user-agents and chatbots, which were evaluated by licensed clinicians and compared to an LLM judge's evaluations using a standardized rubric.", "result": "The paper reports high consistency among clinicians (IRR: 0.77) and strong alignment between clinician consensus and the LLM judge (IRR: 0.81). Clinicians also found the simulated user-agents realistic.", "conclusion": "VERA-MH is a valid and reliable framework for evaluating AI safety in mental health, highlighting its potential as an automated benchmark. Further studies are planned to confirm its generalizability and robustness."}}
{"id": "2602.05395", "pdf": "https://arxiv.org/pdf/2602.05395", "abs": "https://arxiv.org/abs/2602.05395", "authors": ["Jingkai Huang", "Will Ma", "Zhengyuan Zhou"], "title": "Optimal Bayesian Stopping for Efficient Inference of Consistent LLM Answers", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "A simple strategy for improving LLM accuracy, especially in math and reasoning problems, is to sample multiple responses and submit the answer most consistently reached. In this paper we leverage Bayesian prior information to save on sampling costs, stopping once sufficient consistency is reached. Although the exact posterior is computationally intractable, we further introduce an efficient \"L-aggregated\" stopping policy that tracks only the L-1 most frequent answer counts. Theoretically, we prove that L=3 is all you need: this coarse approximation is sufficient to achieve asymptotic optimality, and strictly dominates prior-free baselines, while having a fast posterior computation. Empirically, this identifies the most consistent (i.e., mode) LLM answer using fewer samples, and can achieve similar answer accuracy while cutting the number of LLM calls (i.e., saving on LLM inference costs) by up to 50%.", "AI": {"tldr": "The paper introduces a cost-efficient method to improve LLM accuracy by identifying consistent answers with Bayesian prior information, utilizing fewer samples.", "motivation": "To address the high computational costs involved when improving LLM accuracy by sampling multiple responses, especially for math and reasoning problems.", "method": "The paper employs Bayesian prior information to monitor response consistency and reduce sampling efforts. It also presents an efficient \"L-aggregated\" stopping policy, using frequent answer counts while proving L=3 sufficiency for achieving optimality.", "result": "The proposed method reduces the number of LLM calls by up to 50% while maintaining similar answer accuracy and effectively identifies the most consistent answer using fewer samples.", "conclusion": "Using Bayesian-informed sampling policies and coarse approximation techniques like L=3 is an effective and efficient way to enhance LLM performance while cutting inference costs."}}
{"id": "2602.04907", "pdf": "https://arxiv.org/pdf/2602.04907", "abs": "https://arxiv.org/abs/2602.04907", "authors": ["Jianhong Chen", "Naichen Shi", "Xubo Yue"], "title": "Physics as the Inductive Bias for Causal Discovery", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these paradigms potentially allows physical knowledge to act as an inductive bias, improving identifiability, stability, and robustness of causal discovery in dynamical systems. However, such integration remains challenging: real dynamical systems often exhibit feedback, cyclic interactions, and non-stationary data trend, while many widely used causal discovery methods are formulated under acyclicity or equilibrium-based assumptions. In this work, we propose an integrative causal discovery framework for dynamical systems that leverages partial physical knowledge as an inductive bias. Specifically, we model system evolution as a stochastic differential equation (SDE), where the drift term encodes known ODE dynamics and the diffusion term corresponds to unknown causal couplings beyond the prescribed physics. We develop a scalable sparsity-inducing MLE algorithm that exploits causal graph structure for efficient parameter estimation. Under mild conditions, we establish guarantees to recover the causal graph. Experiments on dynamical systems with diverse causal structures show that our approach improves causal graph recovery and produces more stable, physically consistent estimates than purely data-driven state-of-the-art baselines.", "AI": {"tldr": "This paper integrates causal discovery with physics-based methods like ODEs, enabling better causal inference in dynamical systems by incorporating partial physical knowledge as an inductive bias.", "motivation": "To address challenges in causal discovery for dynamical systems, such as feedback loops, cyclic interactions, and non-stationary trends, traditional methods assume acyclicity or equilibrium, limiting their applicability in real-world scenarios.", "method": "The framework models system evolution as a stochastic differential equation (SDE), combining known ODE dynamics in the drift term and capturing unknown causal relationships via the diffusion term. It also employs a sparsity-inducing MLE algorithm for efficient parameter estimation and causal graph recovery.", "result": "The proposed approach enhances causal graph recovery and stability, producing more physically consistent results compared to state-of-the-art purely data-driven methods.", "conclusion": "Using partial physical knowledge as an inductive bias improves the robustness, stability, and interpretability of causal discovery in complex dynamical systems."}}
{"id": "2602.04900", "pdf": "https://arxiv.org/pdf/2602.04900", "abs": "https://arxiv.org/abs/2602.04900", "authors": ["Sai Sindhur Malleni", "Ra\u00fal Sevilla", "Aleksei Vasilevskii", "Jos\u00e9 Castillo Lema", "Andr\u00e9 Bauer"], "title": "Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization", "categories": ["cs.ET", "cs.AI", "cs.DC"], "comment": "A accepted at the 17th International Conference on Performance Engineering", "summary": "As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative, multi-stage use case consisting of automatic speech recognition and summarization. First, we address batch inference by using Kueue to manage jobs that transcribe audio files with Whisper models and Dynamic Accelerator Slicer (DAS) to increase parallel job execution. Second, we address a discrete online inference scenario by feeding the transcripts to a Large Language Model for summarization hosted using llm-d, a novel solution utilizing the recent developments around the Kubernetes Gateway API Inference Extension (GAIE) for optimized routing of inference requests. Our findings illustrate that these complementary components (Kueue, DAS, and GAIE) form a cohesive, high-performance platform, proving Kubernetes' capability to serve as a unified foundation for demanding GenAI workloads: Kueue reduced total makespan by up to 15%; DAS shortened mean job completion time by 36%; and GAIE improved Time to First Token by 82\\%.", "AI": {"tldr": "The paper explores the use of Kubernetes-native projects to efficiently manage Generative AI workloads.", "motivation": "The increasing dominance of Generative AI workloads calls for a robust infrastructure to improve scalability, resource management, and performance.", "method": "The authors propose using Kubernetes-native components like Kueue, Dynamic Accelerator Slicer (DAS), and GAIE for batch and online AI inference.", "result": "Results showed improved operational metrics: Kueue cut makespan by 15%, DAS reduced job completion time by 36%, and GAIE improved Time to First Token by 82%.", "conclusion": "Kubernetes-native tools can cohesively offer scalability, resource efficiency, and performance enhancements for complex Generative AI workflows."}}
{"id": "2602.05176", "pdf": "https://arxiv.org/pdf/2602.05176", "abs": "https://arxiv.org/abs/2602.05176", "authors": ["Ziyuan Yang", "Wenxuan Ding", "Shangbin Feng", "Yulia Tsvetkov"], "title": "Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems", "categories": ["cs.CL"], "comment": "19 pages, 15 tables, 4 figures", "summary": "Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what if some of the models in multi-LLM systems are compromised or malicious? We first quantify the impact of malicious models by engineering four categories of malicious LMs, plug them into four types of popular model collaboration systems, and evaluate the compromised system across 10 datasets. We find that malicious models have a severe impact on the multi-LLM systems, especially for reasoning and safety domains where performance is lowered by 7.12% and 7.94% on average. We then propose mitigation strategies to alleviate the impact of malicious components, by employing external supervisors that oversee model collaboration to disable/mask them out to reduce their influence. On average, these strategies recover 95.31% of the initial performance, while making model collaboration systems fully resistant to malicious models remains an open research question.", "AI": {"tldr": "The paper examines the risks of malicious language models in collaborative systems and proposes mitigation techniques to minimize their impact.", "motivation": "The researchers aim to address safety concerns in systems where multiple language models collaborate, recognizing the potential threat posed by compromised or malicious models.", "method": "Four types of malicious LMs are engineered, tested in model collaboration systems across 10 datasets, and mitigation strategies employing external supervisors to oversee and disable malicious influence are proposed.", "result": "Malicious models heavily impact reasoning and safety domain performances, reducing them by averages of 7.12% and 7.94% respectively. The proposed strategies recover 95.31% of the baseline performance.", "conclusion": "While mitigation strategies improve resilience against malicious models, creating fully resistant collaboration systems remains an unsolved challenge requiring future exploration."}}
{"id": "2602.05157", "pdf": "https://arxiv.org/pdf/2602.05157", "abs": "https://arxiv.org/abs/2602.05157", "authors": ["Alireza Abbaspour", "Shabin Mahadevan", "Kilian Zwirglmaier", "Jeff Stafford"], "title": "The Necessity of a Holistic Safety Evaluation Framework for AI-Based Automation Features", "categories": ["cs.SE", "eess.SY"], "comment": null, "summary": "The intersection of Safety of Intended Functionality (SOTIF) and Functional Safety (FuSa) analysis of driving automation features has traditionally excluded Quality Management (QM) components from rigorous safety impact evaluations. While QM components are not typically classified as safety-relevant, recent developments in artificial intelligence (AI) integration reveal that such components can contribute to SOTIF-related hazardous risks. Compliance with emerging AI safety standards, such as ISO/PAS 8800, necessitates re-evaluating safety considerations for these components. This paper examines the necessity of conducting holistic safety analysis and risk assessment on AI components, emphasizing their potential to introduce hazards with the capacity to violate risk acceptance criteria when deployed in safety-critical driving systems, particularly in perception algorithms. Using case studies, we demonstrate how deficiencies in AI-driven perception systems can emerge even in QM-classified components, leading to unintended functional behaviors with critical safety implications. By bridging theoretical analysis with practical examples, this paper argues for the adoption of comprehensive FuSa, SOTIF, and AI standards-driven methodologies to identify and mitigate risks in AI components. The findings demonstrate the importance of revising existing safety frameworks to address the evolving challenges posed by AI, ensuring comprehensive safety assurance across all component classifications spanning multiple safety standards.", "AI": {"tldr": "AI integration necessitates revisiting safety evaluations in QM components due to their potential hazards impacting SOTIF and FuSa in driving automation systems.", "motivation": "Current standards overlook QM components in safety evaluations despite their potential for enabling hazardous risks with the integration of AI technologies.", "method": "Case studies and theoretical analysis are used to demonstrate safety implications and argue for adopting holistic methodologies combining FuSa, SOTIF, and AI standards.", "result": "Findings show AI-driven QM components can introduce safety-critical hazards, necessitating revisions in safety frameworks.", "conclusion": "Revised safety frameworks addressing holistic analysis are vital for AI integration to ensure assurance across component classifications and safety standards."}}
{"id": "2602.05265", "pdf": "https://arxiv.org/pdf/2602.05265", "abs": "https://arxiv.org/abs/2602.05265", "authors": ["Kalvik Jakkala", "Jason O'Kane"], "title": "Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous underwater inspection of submerged pipelines is challenging due to confined geometries, turbidity, and the scarcity of reliable localization cues. This paper presents a minimal-sensing strategy that enables a free-swimming underwater robot to center itself and traverse a flooded pipe of known radius using only an IMU, a pressure sensor, and two sonars: a downward-facing single-beam sonar and a rotating 360 degree sonar. We introduce a computationally efficient method for extracting range estimates from single-beam sonar intensity data, enabling reliable wall detection in noisy and reverberant conditions. A closed-form geometric model leverages the two sonar ranges to estimate the pipe center, and an adaptive, confidence-weighted proportional-derivative (PD) controller maintains alignment during traversal. The system requires no Doppler velocity log, external tracking, or complex multi-sensor arrays. Experiments in a submerged 46 cm-diameter pipe using a Blue Robotics BlueROV2 heavy remotely operated vehicle demonstrate stable centering and successful full-pipe traversal despite ambient flow and structural deformations. These results show that reliable in-pipe navigation and inspection can be achieved with a lightweight, computationally efficient sensing and processing architecture, advancing the practicality of autonomous underwater inspection in confined environments.", "AI": {"tldr": "This paper proposes a minimal-sensing strategy for autonomous underwater robots to navigate and inspect submerged pipelines effectively, using simple sensors and computational methods.", "motivation": "Autonomous inspection of submerged pipelines is difficult due to confined spaces, turbidity, and lack of reliable localization cues.", "method": "The paper utilizes an IMU, a pressure sensor, and two sonars to enable pipe centering and traversal. It develops an efficient method to extract range data from sonar intensities, introduces a geometric model for estimating the pipe center, and employs a confidence-weighted proportional-derivative controller.", "result": "Experiments using a Blue Robotics BlueROV2 in a 46 cm submerged pipe demonstrated stable centering and traversal under challenging conditions like flow and structural deformations.", "conclusion": "The proposed system offers a lightweight and efficient solution for underwater pipeline inspection, proving its practical application in confined and noisy environments."}}
{"id": "2602.05159", "pdf": "https://arxiv.org/pdf/2602.05159", "abs": "https://arxiv.org/abs/2602.05159", "authors": ["Wenhui Cui", "Ziyi Kou", "Chuan Qin", "Ergys Ristani", "Li Guan"], "title": "AirGlove: Exploring Egocentric 3D Hand Tracking and Appearance Generalization for Sensing Gloves", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Sensing gloves have become important tools for teleoperation and robotic policy learning as they are able to provide rich signals like speed, acceleration and tactile feedback. A common approach to track gloved hands is to directly use the sensor signals (e.g., angular velocity, gravity orientation) to estimate 3D hand poses. However, sensor-based tracking can be restrictive in practice as the accuracy is often impacted by sensor signal and calibration quality. Recent advances in vision-based approaches have achieved strong performance on human hands via large-scale pre-training, but their performance on gloved hands with distinct visual appearances remains underexplored. In this work, we present the first systematic evaluation of vision-based hand tracking models on gloved hands under both zero-shot and fine-tuning setups. Our analysis shows that existing bare-hand models suffer from substantial performance degradation on sensing gloves due to large appearance gap between bare-hand and glove designs. We therefore propose AirGlove, which leverages existing gloves to generalize the learned glove representations towards new gloves with limited data. Experiments with multiple sensing gloves show that AirGlove effectively generalizes the hand pose models to new glove designs and achieves a significant performance boost over the compared schemes.", "AI": {"tldr": "This paper introduces AirGlove, a vision-based hand tracking model that outperforms existing models in tracking gloved hands by addressing the appearance gap with data generalization.", "motivation": "To enhance the accuracy of hand-pose tracking models on sensing gloves, which often suffer from performance degradation due to the visual difference between bare and gloved hands.", "method": "A systematic evaluation of hand tracking models on gloved hands, proposing AirGlove that generalizes glove representations using existing glove data and limited data of new gloves.", "result": "AirGlove significantly improves hand pose tracking performance on various glove designs compared to other models, especially under limited data conditions.", "conclusion": "AirGlove successfully addresses the challenges of hand tracking with sensing gloves, bridging the gap in appearance and achieving higher accuracy compared to traditional methods."}}
{"id": "2602.05091", "pdf": "https://arxiv.org/pdf/2602.05091", "abs": "https://arxiv.org/abs/2602.05091", "authors": ["Agni Bandyopadhyay", "G\u00fcnther Waxenegger-Wilfing"], "title": "Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal", "categories": ["cs.AI", "cs.LG", "cs.RO", "physics.space-ph"], "comment": "Presented at Conference: International Conference on Space Robotics (ISPARO,2025) At: Sendai,Japan", "summary": "Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy Optimization (PPO) policy trained under fixed mission parameters, a domain-randomized Masked PPO policy trained across varying mission constraints for improved robustness, and a plain Monte Carlo Tree Search (MCTS) baseline. Evaluations are conducted in a high-fidelity orbital simulation with refueling, realistic transfer dynamics, and randomized debris fields across 300 test cases in nominal, reduced fuel, and reduced mission time scenarios. Results show that nominal PPO achieves top performance when conditions match training but degrades sharply under distributional shift, while domain-randomized PPO exhibits improved adaptability with only moderate loss in nominal performance. MCTS consistently handles constraint changes best due to online replanning but incurs orders-of-magnitude higher computation time. The findings underline a trade-off between the speed of learned policies and the adaptability of search-based methods, and suggest that combining training-time diversity with online planning could be a promising path for future resilient ADR mission planners.", "AI": {"tldr": "The paper evaluates three autonomous planners for Active Debris Removal (ADR) based on performance and adaptability in constrained Low Earth Orbit missions.", "motivation": "To address the challenge of designing efficient, adaptable, and feasible mission planners for ADR in an environment with varying constraints like fuel, mission duration, and debris properties.", "method": "The paper compares three approaches: nominal Masked PPO trained with fixed constraints, domain-randomized Masked PPO trained on diverse conditions, and a baseline Monte Carlo Tree Search (MCTS). Evaluations involve 300 tests under various scenarios using a high-fidelity orbital simulator.", "result": "The nominal Masked PPO performs best under trained conditions but struggles under new constraints. Domain-randomized PPO is more adaptable but slightly less precise. MCTS adapts well to shifting conditions but requires high computation time.", "conclusion": "There is a trade-off between fast policy execution (learned policies) and adaptability (search-based planning). A hybrid approach blending diversity in training and online planning is suggested as a future direction for resilient ADR mission planning."}}
{"id": "2602.05742", "pdf": "https://arxiv.org/pdf/2602.05742", "abs": "https://arxiv.org/abs/2602.05742", "authors": ["Tobias Brock", "Thomas Nagler"], "title": "Fast Rates for Nonstationary Weighted Risk Minimization", "categories": ["stat.ML", "cs.LG", "math.ST"], "comment": null, "summary": "Weighted empirical risk minimization is a common approach to prediction under distribution drift. This article studies its out-of-sample prediction error under nonstationarity. We provide a general decomposition of the excess risk into a learning term and an error term associated with distribution drift, and prove oracle inequalities for the learning error under mixing conditions. The learning bound holds uniformly over arbitrary weight classes and accounts for the effective sample size induced by the weight vector, the complexity of the weight and hypothesis classes, and potential data dependence. We illustrate the applicability and sharpness of our results in (auto-) regression problems with linear models, basis approximations, and neural networks, recovering minimax-optimal rates (up to logarithmic factors) when specialized to unweighted and stationary settings.", "AI": {"tldr": "This paper studies out-of-sample prediction error under nonstationarity for weighted empirical risk minimization and provides theoretical guarantees and sharp bounds.", "motivation": "Distribution drift poses challenges for accurate predictions in nonstationary settings. Existing methods require a robust understanding of risk minimization under such scenarios.", "method": "The paper decomposes the excess risk into learning and error terms, derives oracle inequalities for learning error under mixing conditions, and delivers results applicable to various models.", "result": "The study establishes uniform learning bounds over weight classes and shows sharpness through examples like regression problems, recovering minimax rates in specific cases.", "conclusion": "The findings offer theoretical insights and practical generalization guarantees for prediction under nonstationary conditions and weighted settings, demonstrating the robustness of the approach."}}
{"id": "2602.04908", "pdf": "https://arxiv.org/pdf/2602.04908", "abs": "https://arxiv.org/abs/2602.04908", "authors": ["Chika Maduabuchi", "Jindong Wang"], "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and inefficient sampling. Prior approaches mitigate this via explicit smoothness penalties, trajectory regularization, or modified probability paths and solvers. We introduce Temporal Pair Consistency (TPC), a lightweight variance-reduction principle that couples velocity predictions at paired timesteps along the same probability path, operating entirely at the estimator level without modifying the model architecture, probability path, or solver. We provide a theoretical analysis showing that TPC induces a quadratic, trajectory-coupled regularization that provably reduces gradient variance while preserving the underlying flow-matching objective. Instantiated within flow matching, TPC improves sample quality and efficiency across CIFAR-10 and ImageNet at multiple resolutions, achieving lower FID at identical or lower computational cost than prior methods, and extends seamlessly to modern SOTA-style pipelines with noise-augmented training, score-based denoising, and rectified flow.", "AI": {"tldr": "This paper introduces Temporal Pair Consistency (TPC), a variance-reduction technique for continuous-time generative models to improve sample quality and efficiency without altering model architecture, probability paths, or solvers.", "motivation": "Prior continuous-time generative models suffer from high estimator variance and inefficient sampling due to independent timestep training objectives, necessitating solutions to improve consistency and efficiency.", "method": "TPC couples velocity predictions at paired timesteps along the same probability path, operating solely at the estimator level to induce trajectory-coupled regularization without modifying key model components.", "result": "TPC improves sample quality and efficiency in generative models, yielding lower FID scores on CIFAR-10 and ImageNet datasets compared to previous methods, and integrates effectively with advanced generative pipelines.", "conclusion": "TPC provides a lightweight and theoretically supported method for variance reduction in generative models, enhancing performance without additional computational or architectural modifications."}}
{"id": "2602.04981", "pdf": "https://arxiv.org/pdf/2602.04981", "abs": "https://arxiv.org/abs/2602.04981", "authors": ["Maria Gragera Garces"], "title": "Distributed Quantum Error Mitigation: Global and Local ZNE encodings", "categories": ["quant-ph", "cs.DC", "cs.ET"], "comment": null, "summary": "Errors are the primary bottleneck preventing practical quantum computing. This challenge is exacerbated in the distributed quantum computing regime, where quantum networks introduce additional communication-induced noise. While error mitigation techniques such as Zero Noise Extrapolation (ZNE) have proven effective for standalone quantum processors, their behavior in distributed architectures is not yet well understood. We investigate ZNE in this setting by comparing Global optimization (ZNE is applied prior to circuit partitioning), against Local optimization (ZNE is applied independently to each sub-circuit). Partitioning is performed on a monolithic circuit, which is then transformed into a distributed implementation by inserting noisy teleportation-based communication primitives between sub-circuits. We evaluate both approaches across varying numbers of quantum processing units (QPUs) and under heterogeneous local and network noise conditions. Our results demonstrate that Global ZNE exhibits superior scalability, achieving error reductions of up to $48\\%$ across six QPUs. Moreover, we observe counterintuitive noise behavior, where increasing the number of QPUs improves mitigation effectiveness despite higher communication overhead. These findings highlight fundamental trade-offs in distributed quantum error mitigation and raise new questions regarding the interplay between circuit structure, partitioning strategies, and network noise.", "AI": {"tldr": "This paper explores error mitigation for distributed quantum computing by evaluating two Zero Noise Extrapolation approaches: Global and Local, finding Global ZNE superior in scalability and effectiveness.", "motivation": "Quantum computing faces challenges with errors, especially in distributed regimes due to communication noise. Techniques like ZNE work for standalone processors, but their effectiveness in distributed setups needs investigation.", "method": "The study compares Global ZNE (applied before circuit partitioning) and Local ZNE (applied individually per sub-circuit) on noisy distributed quantum networks using teleportation-based communication primitives across varying QPU setups.", "result": "Global ZNE showed up to 48% error reduction across six QPUs and counterintuitively performed better with more QPUs despite increased noise from communication overhead.", "conclusion": "The findings emphasize trade-offs in distributed quantum error mitigation strategies, indicating Global ZNE's scalability and raising critical questions on circuit partitioning and noise interplay in quantum networks."}}
{"id": "2602.05182", "pdf": "https://arxiv.org/pdf/2602.05182", "abs": "https://arxiv.org/abs/2602.05182", "authors": ["Shangbin Feng", "Kishan Panaganti", "Yulia Tsvetkov", "Wenhao Yu"], "title": "The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems", "categories": ["cs.CL"], "comment": "Code at https://github.com/BunsenFeng/moco_distill", "summary": "Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration while only incurring the cost of a single model. Furthermore, we propose the single-multi evolution loop: multiple LMs collaborate, each distills from the collaborative outputs, and these post-distillation improved LMs collaborate again, forming a collective evolution ecosystem where models evolve and self-improve by interacting with an environment of other models. Extensive experiments with 7 collaboration strategies and 15 tasks (QA, reasoning, factuality, etc.) demonstrate that: 1) individual models improve by 8.0% on average, absorbing the strengths of collaboration while reducing the cost to a single model; 2) the collaboration also benefits from the stronger and more synergistic LMs after distillation, improving over initial systems without evolution by 14.9% on average. Analysis reveals that the single-multi evolution loop outperforms various existing evolutionary AI methods, is compatible with diverse model/collaboration/distillation settings, and helps solve problems where the initial model/system struggles to.", "AI": {"tldr": "This paper introduces a system for collaborating language models (LMs) and proposes an efficient distillation method to leverage collaborative patterns, significantly improving individual and collaborative models.", "motivation": "To overcome the inefficiency and costs of running multiple LMs in collaborative systems while preserving their benefits.", "method": "The authors propose distilling collaborative patterns into a single model and introduce the single-multi evolution loop, allowing iterative collaboration and distillation to evolve and improve the system.", "result": "Experiments show individual models improve by 8.0% on average, and collaborative systems improve by 14.9% on average, demonstrating the distillation method's effectiveness.", "conclusion": "Distillation and collaborative evolution methods are efficient, provide substantial improvements to both individual models and collaborative systems, and outperform existing evolutionary AI approaches."}}
{"id": "2602.05242", "pdf": "https://arxiv.org/pdf/2602.05242", "abs": "https://arxiv.org/abs/2602.05242", "authors": ["Chenhui Mao", "Yuanting Lei", "Zhixiang Wei", "Ming Liang", "Zhixiang Wang", "Jingxuan Xu", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "EGSS: Entropy-guided Stepwise Scaling for Reliable Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Agentic Test-Time Scaling (TTS) has delivered state-of-the-art (SOTA) performance on complex software engineering tasks such as code generation and bug fixing. However, its practical adoption remains limited due to significant computational overhead, primarily driven by two key challenges: (1) the high cost associated with deploying excessively large ensembles, and (2) the lack of a reliable mechanism for selecting the optimal candidate solution, ultimately constraining the performance gains that can be realized. To address these challenges, we propose Entropy-Guided Stepwise Scaling (EGSS), a novel TTS framework that dynamically balances efficiency and effectiveness through entropy-guided adaptive search and robust test-suite augmentation. Extensive experiments on SWE-Bench-Verified demonstrate that EGSS consistently boosts performance by 5-10% across all evaluated models. Specifically, it increases the resolved ratio of Kimi-K2-Intruct from 63.2% to 72.2%, and GLM-4.6 from 65.8% to 74.6%. Furthermore, when paired with GLM-4.6, EGSS achieves a new state-of-the-art among open-source large language models. In addition to these accuracy improvements, EGSS reduces inference-time token usage by over 28% compared to existing TTS methods, achieving simultaneous gains in both effectiveness and computational efficiency.", "AI": {"tldr": "This paper introduces Entropy-Guided Stepwise Scaling (EGSS), a framework aimed at addressing the computational challenges of Agentic Test-Time Scaling (TTS) in code generation and bug fixing tasks.", "motivation": "To overcome practical challenges of TTS, such as computational overhead due to large ensembles and the inability to reliably select optimal solutions, hindering potential performance gains.", "method": "EGSS uses entropy-guided adaptive search combined with robust test-suite augmentation to balance computational efficiency and solution effectiveness dynamically.", "result": "EGSS improves the performance metrics of code generation models by 5-10%, sets new SOTA benchmarks for open-source large language models, and reduces computational costs by decreasing inference-time token usage by 28%.", "conclusion": "EGSS addresses TTS limitations by delivering improved accuracy and efficiency, paving the way for more practical applications in software engineering tasks."}}
{"id": "2602.05273", "pdf": "https://arxiv.org/pdf/2602.05273", "abs": "https://arxiv.org/abs/2602.05273", "authors": ["Hengxuan Xu", "Fengbo Lan", "Zhixin Zhao", "Shengjie Wang", "Mengqiao Liu", "Jieqian Sun", "Yu Cheng", "Tao Zhang"], "title": "Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions", "categories": ["cs.RO"], "comment": "14 pages, 10 figures, 8 tables", "summary": "Enabling robots to explore and act in unfamiliar environments under ambiguous human instructions by interactively identifying task-relevant objects (e.g., identifying cups or beverages for \"I'm thirsty\") remains challenging for existing vision-language model (VLM)-based methods. This challenge stems from inefficient reasoning and the lack of environmental interaction, which hinder real-time task planning and execution. To address this, We propose Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE), a dual-stream framework that integrates interactive exploration with vision-language reasoning, where Multi-Stage Inference (MSI) serves as the decision-making stream and Accelerated Decision-Making (ADM) as the execution stream, enabling zero-shot affordance analysis and interpretation of ambiguous instructions. Extensive experiments in simulation and real-world environments show that AIDE achieves the task planning success rate of over 80\\% and more than 95\\% accuracy in closed-loop continuous execution at 10 Hz, outperforming existing VLM-based methods in diverse open-world scenarios.", "AI": {"tldr": "This paper introduces AIDE, a dual-stream framework for robots to handle ambiguous human instructions through vision-language reasoning and interaction, achieving high success rates in task planning and execution.", "motivation": "Existing vision-language models lack the capability of handling ambiguous human instructions in real-time and fail in interactively identifying task-relevant objects in unfamiliar environments.", "method": "AIDE uses a dual-stream framework comprising Multi-Stage Inference (decision-making) and Accelerated Decision-Making (execution), enabling zero-shot affordance analysis and interpretation of instructions.", "result": "AIDE achieved over 80% task-planning success and more than 95% execution accuracy in both simulation and real-world tests, surpassing existing VLM methods.", "conclusion": "AIDE significantly enhances robots' ability to process and act on ambiguous instructions in real-time, demonstrating notable improvements over current methods."}}
{"id": "2602.05162", "pdf": "https://arxiv.org/pdf/2602.05162", "abs": "https://arxiv.org/abs/2602.05162", "authors": ["Anay Majee", "Rishabh Iyer"], "title": "SHaSaM: Submodular Hard Sample Mining for Fair Facial Attribute Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "21 pages, 7 tables, 10 figures", "summary": "Deep neural networks often inherit social and demographic biases from annotated data during model training, leading to unfair predictions, especially in the presence of sensitive attributes like race, age, gender etc. Existing methods fall prey to the inherent data imbalance between attribute groups and inadvertently emphasize on sensitive attributes, worsening unfairness and performance. To surmount these challenges, we propose SHaSaM (Submodular Hard Sample Mining), a novel combinatorial approach that models fairness-driven representation learning as a submodular hard-sample mining problem. Our two-stage approach comprises of SHaSaM-MINE, which introduces a submodular subset selection strategy to mine hard positives and negatives - effectively mitigating data imbalance, and SHaSaM-LEARN, which introduces a family of combinatorial loss functions based on Submodular Conditional Mutual Information to maximize the decision boundary between target classes while minimizing the influence of sensitive attributes. This unified formulation restricts the model from learning features tied to sensitive attributes, significantly enhancing fairness without sacrificing performance. Experiments on CelebA and UTKFace demonstrate that SHaSaM achieves state-of-the-art results, with up to 2.7 points improvement in model fairness (Equalized Odds) and a 3.5% gain in Accuracy, within fewer epochs as compared to existing methods.", "AI": {"tldr": "Deep learning models often inherit biases from data, causing unfair predictions. SHaSaM, a novel framework, effectively enhances fairness and performance using submodular methods.", "motivation": "The paper addresses the issue of unfair predictions in deep learning caused by biases tied to sensitive attributes in the training data.", "method": "SHaSaM employs a two-stage combinatorial approach: SHaSaM-MINE for submodular hard sample mining to balance data and SHaSaM-LEARN for advanced loss functions to reduce sensitive attribute influence.", "result": "Experiments on CelebA and UTKFace show SHaSaM improves fairness (Equalized Odds) by up to 2.7 points and accuracy by 3.5%, achieving state-of-the-art results with fewer training epochs.", "conclusion": "The SHaSaM framework effectively mitigates bias in deep learning models while enhancing prediction fairness and model accuracy compared to existing methods."}}
{"id": "2602.05105", "pdf": "https://arxiv.org/pdf/2602.05105", "abs": "https://arxiv.org/abs/2602.05105", "authors": ["Rohan Patil", "Jai Malegaonkar", "Xiao Jiang", "Andre Dion", "Gaurav S. Sukhatme", "Henrik I. Christensen"], "title": "GAMMS: Graph based Adversarial Multiagent Modeling Simulator", "categories": ["cs.AI", "cs.RO", "cs.SE"], "comment": null, "summary": "As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapid prototyping or large-scale agent deployments. We present GAMMS (Graph based Adversarial Multiagent Modeling Simulator), a lightweight yet extensible simulation framework designed to support fast development and evaluation of agent behavior in environments that can be represented as graphs. GAMMS emphasizes five core objectives: scalability, ease of use, integration-first architecture, fast visualization feedback, and real-world grounding. It enables efficient simulation of complex domains such as urban road networks and communication systems, supports integration with external tools (e.g., machine learning libraries, planning solvers), and provides built-in visualization with minimal configuration. GAMMS is agnostic to policy type, supporting heuristic, optimization-based, and learning-based agents, including those using large language models. By lowering the barrier to entry for researchers and enabling high-performance simulations on standard hardware, GAMMS facilitates experimentation and innovation in multi-agent systems, autonomous planning, and adversarial modeling. The framework is open-source and available at https://github.com/GAMMSim/GAMMS/", "AI": {"tldr": "GAMMS is a lightweight, extensible simulator for graph-based environments, offering scalability, ease of use, and integration with various tools while supporting diverse agent policies.", "motivation": "The paper addresses the need for scalable and accessible simulation tools for multi-agent coordination and intelligent systems, as existing high-fidelity simulators are resource-intensive and not suitable for rapid prototyping.", "method": "GAMMS is presented as a graph-based simulation framework with an integration-first architecture, built-in visualization, and support for multiple agent types, including heuristic, optimization-based, and AI-driven policies.", "result": "GAMMS enables efficient simulation of complex domains like urban networks, supports external tool integration, and facilitates research on standard hardware with minimal barriers.", "conclusion": "GAMMS fosters experimentation and innovation in multi-agent systems by providing an open-source, user-friendly platform accessible for a wide range of research needs."}}
{"id": "2602.05846", "pdf": "https://arxiv.org/pdf/2602.05846", "abs": "https://arxiv.org/abs/2602.05846", "authors": ["Leonardo Defilippis", "Florent Krzakala", "Bruno Loureiro", "Antoine Maillard"], "title": "Optimal scaling laws in learning hierarchical multi-index models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we provide a sharp theory of scaling laws for two-layer neural networks trained on a class of hierarchical multi-index targets, in a genuinely representation-limited regime. We derive exact information-theoretic scaling laws for subspace recovery and prediction error, revealing how the hierarchical features of the target are sequentially learned through a cascade of phase transitions. We further show that these optimal rates are achieved by a simple, target-agnostic spectral estimator, which can be interpreted as the small learning-rate limit of gradient descent on the first-layer weights. Once an adapted representation is identified, the readout can be learned statistically optimally, using an efficient procedure. As a consequence, we provide a unified and rigorous explanation of scaling laws, plateau phenomena, and spectral structure in shallow neural networks trained on such hierarchical targets.", "AI": {"tldr": "The paper develops a detailed theory on scaling laws for hierarchical multi-index targets in two-layer neural networks, addressing representation-limited regimes.", "motivation": "The study aims to understand how hierarchical features in multi-index targets are sequentially learned in two-layer neural networks and explain phenomena like scaling laws and plateau behaviors.", "method": "The authors derive exact information-theoretic scaling laws and showcase the learning progression via phase transitions, using a simple spectral estimator aligned with the small learning-rate limit of gradient descent.", "result": "The paper reveals the mechanism of hierarchical feature learning in neural networks through phase transitions and demonstrates the efficiency of spectral estimators and optimal readout procedures for subspace recovery and prediction error.", "conclusion": "This work offers a unified explanation for scaling laws, plateau phenomena, and spectral patterns in shallow neural networks while addressing representation-limited learning scenarios."}}
{"id": "2602.04909", "pdf": "https://arxiv.org/pdf/2602.04909", "abs": "https://arxiv.org/abs/2602.04909", "authors": ["Youngjae Cho", "Jongsuk Kim", "Ji-Hoon Kim"], "title": "Learning Where It Matters: Geometric Anchoring for Robust Preference Alignment", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Direct Preference Optimization (DPO) and related methods align large language models from pairwise preferences by regularizing updates against a fixed reference policy. As the policy drifts, a static reference, however, can become increasingly miscalibrated, leading to distributional mismatch and amplifying spurious preference signals under noisy supervision. Conversely, reference-free variants avoid mismatch but often suffer from unconstrained reward drift. We propose Geometric Anchor Preference Optimization (GAPO), which replaces the fixed reference with a dynamic, geometry-aware anchor: an adversarial local perturbation of the current policy within a small radius that serves as a pessimistic baseline. This anchor enables an adaptive reweighting mechanism, modulating the importance of each preference pair based on its local sensitivity. We further introduce the Anchor Gap, the reward discrepancy between the policy and its anchor, and show under smoothness conditions that it approximates worst-case local margin degradation. Optimizing a logistic objective weighted by this gap downweights geometrically brittle instances while emphasizing robust preference signals. Across diverse noise settings, GAPO consistently improves robustness while matching or improving performance on standard LLM alignment and reasoning benchmarks.", "AI": {"tldr": "The paper introduces Geometric Anchor Preference Optimization (GAPO), a method to improve robustness in large language model alignment by using a geometry-aware, dynamic anchor point in preference-based updates.", "motivation": "To address limitations of static reference policies in large language model alignment, which can lead to distribution mismatches and reward drift under noisy pairwise preference supervision.", "method": "The proposed method replaces a static reference policy with a dynamic geometry-aware anchor rooted in local adversarial perturbations to the current policy. It further introduces an Anchor Gap metric for reweighting preference pairs to emphasize robust signals.", "result": "The method improves robustness under varying noise conditions while maintaining or enhancing performance on language model benchmarks.", "conclusion": "GAPO mitigates issues of miscalibration and reward drift in preference optimization, providing a robust approach to align large language models effectively."}}
{"id": "2602.05179", "pdf": "https://arxiv.org/pdf/2602.05179", "abs": "https://arxiv.org/abs/2602.05179", "authors": ["Jingyi Zhao", "Linxin Yang", "Haohua Zhang", "Tian Ding"], "title": "From Sequential to Parallel: Reformulating Dynamic Programming as GPU Kernels for Large-Scale Stochastic Combinatorial Optimization", "categories": ["math.OC", "cs.DC"], "comment": null, "summary": "A major bottleneck in scenario-based Sample Average Approximation (SAA) for stochastic programming (SP) is the cost of solving an exact second-stage problem for every scenario, especially when each scenario contains an NP-hard combinatorial structure. This has led much of the SP literature to restrict the second stage to linear or simplified models. We develop a GPU-based framework that makes full-fidelity integer second-stage models tractable at scale. The key innovation is a set of hardware-aware, scenario-batched GPU kernels that expose parallelism across scenarios, dynamic-programming (DP) layers, and route or action options, enabling Bellman updates to be executed in a single pass over more than 1,000,000 realizations. We evaluate the approach in two representative SP settings: a vectorized split operator for stochastic vehicle routing and a DP for inventory reinsertion. Implementation scales nearly linearly in the number of scenarios and achieves a one-two to four-five orders of magnitude speedup, allowing far larger scenario sets and reliably stronger first-stage decisions. The computational leverage directly improves decision quality: much larger scenario sets and many more first-stage candidates can be evaluated within fixed time budgets, consistently yielding stronger SAA solutions. Our results show that full-fidelity integer second-stage models are tractable at scales previously considered impossible, providing a practical path to large-scale, realistic stochastic discrete optimization.", "AI": {"tldr": "The study introduces a GPU-based framework to make complex integer second-stage models in stochastic programming feasible at scale, achieving significant speedups and enabling stronger first-stage decisions.", "motivation": "Scenario-based Sample Average Approximation (SAA) in stochastic programming struggles with computational bottlenecks caused by solving exact second-stage problems for many scenarios, especially when these involve NP-hard combinatorial structures.", "method": "The researchers developed hardware-aware, scenario-batched GPU kernels exploiting parallelism across scenarios, dynamic programming layers, and route/action options, making Bellman updates highly efficient.", "result": "The implementation speeds up computation by one-two to four-five orders of magnitude while scaling nearly linearly with the number of scenarios. Larger scenario sets and more first-stage candidates are now processable efficiently, improving decision quality.", "conclusion": "Full-fidelity integer second-stage models for stochastic programming are achievable at unprecedented scales with this GPU framework, offering a practical solution for large-scale, realistic stochastic optimization."}}
{"id": "2602.05189", "pdf": "https://arxiv.org/pdf/2602.05189", "abs": "https://arxiv.org/abs/2602.05189", "authors": ["Hsuan-Yu Chou", "Wajiha Naveed", "Shuyan Zhou", "Xiaowei Yang"], "title": "Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SI"], "comment": null, "summary": "As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question.\n  Motivated by recent developments of reasoning LLMs, we evaluate seven state-of-the-art models: four proprietary and three open-weight. Testing with real-world posts on Bluesky, moderation decisions by Bluesky Moderation Service, and annotations by two authors, we find a considerable degree of overlap between the sensitivity (81%--97%) and specificity (91%--100%) of the open-weight LLMs and those (72%--98%, and 93%--99%) of the proprietary ones. Additionally, our analysis reveals that specificity exceeds sensitivity for rudeness detection, but the opposite holds for intolerance and threats. Lastly, we identify inter-rater agreement across human moderators and the LLMs, highlighting considerations for deploying LLMs in both platform-scale and personalized moderation contexts. These findings show open-weight LLMs can support privacy-preserving moderation on consumer-grade hardware and suggest new directions for designing moderation systems that balance community values with individual user preferences.", "AI": {"tldr": "This paper evaluates the performance of open-weight and proprietary large language models (LLMs) for social media content moderation, showing comparable sensitivity and specificity for harmful content detection.", "motivation": "The study is motivated by the need for effective, privacy-preserving moderation systems as internet users are increasingly exposed to harmful online content.", "method": "The authors tested seven LLMs (4 proprietary and 3 open-weight) using real-world Bluesky posts, moderation decisions by Bluesky Moderation Service, and annotations by two authors.", "result": "Open-weight LLMs demonstrated sensitivities of 81%-97% and specificities of 91%-100%, comparable to proprietary LLMs, which achieved sensitivities of 72%-98% and specificities of 93%-99%. Specificity exceeded sensitivity for rudeness detection, while sensitivity was higher for detecting intolerance and threats.", "conclusion": "Open-weight LLMs can facilitate effective, privacy-conscious social media moderation on consumer hardware, providing insights into designing moderation systems that respect both community values and individual user preferences."}}
{"id": "2602.05270", "pdf": "https://arxiv.org/pdf/2602.05270", "abs": "https://arxiv.org/abs/2602.05270", "authors": ["Thanh Le-Cong", "Bach Le", "Toby Murray", "Michael Pradel", "Cristian Cadar"], "title": "PatchGuru: Patch Oracle Inference from Natural Language Artifacts with Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "As software systems evolve, patches may unintentionally alter program behavior. Validating patches against their intended semantics is difficult due to incomplete regression tests and informal, non-executable natural language (NL) descriptions of patch intent. We present PatchGuru, the first automated technique that infers executable patch specifications from real-world pull requests (PRs). Given a PR, PatchGuru uses large language models (LLMs) to extract developer intent from NL artifacts and synthesizes patch oracles: under-approximate yet practical specifications expressed as runtime assertions in comparison programs that integrate pre- and post-patch versions. Patch oracles focus on patch-relevant behaviors, enable automated validation, and support cross-version properties. PatchGuru iteratively refines inferred oracles by comparing pre- and post-patch behaviors, identifies violations, filters inconsistencies via self-review, and generates bug reports. We evaluate PatchGuru on 400 recent PRs from four widely used open-source Python projects. PatchGuru reports 39 warnings with a precision of 0.62, yielding 24 confirmed true positives, including 12 previously unknown bugs, 11 of which were subsequently fixed by developers. Compared to the state-of-the-art technique Testora, PatchGuru detects 17 more bugs (24 vs. 7) while improving precision from 0.32 to 0.62. PatchGuru incurs an average cost of 8.9 minutes and USD 0.07 per PR. These results suggest that PatchGuru complements code review and regression testing by providing executable documentation and automated validation of patch intent.", "AI": {"tldr": "PatchGuru uses large language models to infer executable patch specifications from pull requests to validate the patches against their intended semantics, addressing limitations of informal descriptions and incomplete regression tests.", "motivation": "Developers face challenges validating software patches as patches may unintentionally alter behavior, due to incomplete regression tests and informal natural language descriptions of intent.", "method": "PatchGuru uses large language models to extract developer intent from natural language artifacts, synthesizes runtime assertions for patch specifications, iteratively refines these, and detects violations to generate reports.", "result": "PatchGuru was evaluated on 400 pull requests across Python projects, reporting 39 warnings (precision of 0.62) that identified 24 true positives, including previously unknown bugs, outperforming the prior Testora method in both bug detection and precision.", "conclusion": "PatchGuru successfully complements code reviews and regression testing with executable specifications and automated patch validation, proving its utility in real-world software development settings."}}
{"id": "2602.05310", "pdf": "https://arxiv.org/pdf/2602.05310", "abs": "https://arxiv.org/abs/2602.05310", "authors": ["Jipeng Kong", "Xinzhe Liu", "Yuhang Lin", "Jinrui Han", "S\u00f6ren Schwertfeger", "Chenjia Bai", "Xuelong Li"], "title": "Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework", "categories": ["cs.RO"], "comment": "13 pages, 9 figures, conference", "summary": "Soccer presents a significant challenge for humanoid robots, demanding tightly integrated perception-action capabilities for tasks like perception-guided kicking and whole-body balance control. Existing approaches suffer from inter-module instability in modular pipelines or conflicting training objectives in end-to-end frameworks. We propose Perception-Action integrated Decision-making (PAiD), a progressive architecture that decomposes soccer skill acquisition into three stages: motion-skill acquisition via human motion tracking, lightweight perception-action integration for positional generalization, and physics-aware sim-to-real transfer. This staged decomposition establishes stable foundational skills, avoids reward conflicts during perception integration, and minimizes sim-to-real gaps. Experiments on the Unitree G1 demonstrate high-fidelity human-like kicking with robust performance under diverse conditions-including static or rolling balls, various positions, and disturbances-while maintaining consistent execution across indoor and outdoor scenarios. Our divide-and-conquer strategy advances robust humanoid soccer capabilities and offers a scalable framework for complex embodied skill acquisition. The project page is available at https://soccer-humanoid.github.io/.", "AI": {"tldr": "The paper proposes PAiD, a progressive architecture for enhancing humanoid soccer robots' skills, emphasizing perception-action integration, stable foundational skills, and sim-to-real transfer with tested successful results.", "motivation": "To address challenges in humanoid soccer robots that currently face stability issues in modular pipelines and conflicts in end-to-end training frameworks.", "method": "The paper introduces Perception-Action integrated Decision-making (PAiD), a three-stage approach: motion skill acquisition from human motion tracking, lightweight integration of perception and action for positional adaptability, and physics-aware simulation-to-reality transfer.", "result": "Experiments on Unitree G1 showcased high-fidelity human-like kicking and robust performance across diverse environmental conditions, including dynamic ball movements and disturbances.", "conclusion": "The divide-and-conquer approach strengthens humanoid soccer robot capabilities, offering a scalable solution for developing complex embodied skills."}}
{"id": "2602.05163", "pdf": "https://arxiv.org/pdf/2602.05163", "abs": "https://arxiv.org/abs/2602.05163", "authors": ["Andreas Mentzelopoulos", "Keith Ellenbogen"], "title": "LOBSTgER-enhance: an underwater image enhancement pipeline", "categories": ["cs.CV"], "comment": "12 pages, 30 figures, work done as part of LOBSTgER", "summary": "Underwater photography presents significant inherent challenges including reduced contrast, spatial blur, and wavelength-dependent color distortions. These effects can obscure the vibrancy of marine life and awareness photographers in particular are often challenged with heavy post-processing pipelines to correct for these distortions.\n  We develop an image-to-image pipeline that learns to reverse underwater degradations by introducing a synthetic corruption pipeline and learning to reverse its effects with diffusion-based generation. Training and evaluation are performed on a small high-quality dataset of awareness photography images by Keith Ellenbogen. The proposed methodology achieves high perceptual consistency and strong generalization in synthesizing 512x768 images using a model of ~11M parameters after training from scratch on ~2.5k images.", "AI": {"tldr": "This paper introduces an underwater image restoration pipeline that uses synthetic corruption and diffusion-based generation to enhance image quality.", "motivation": "To address underwater photography challenges such as reduced contrast, spatial blur, and color distortions, particularly to assist awareness photographers in reducing heavy post-processing.", "method": "Developed a synthetic corruption pipeline and trained a diffusion-based image-to-image model on 2.5k high-quality underwater photography images.", "result": "Achieved high perceptual consistency and strong generalization in generating 512x768 images with a model containing ~11M parameters.", "conclusion": "The proposed pipeline effectively reverses underwater image degradations, achieving high-quality results with robust generalization and perceptual accuracy."}}
{"id": "2602.05110", "pdf": "https://arxiv.org/pdf/2602.05110", "abs": "https://arxiv.org/abs/2602.05110", "authors": ["Liang Wang", "Junpeng Wang", "Chin-chia Michael Yeh", "Yan Zheng", "Jiarui Sun", "Xiran Fan", "Xin Dai", "Yujie Fan", "Yiwei Cai"], "title": "Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk assessment, combining a five-criterion rubric with Monte-Carlo scoring to evaluate rationale quality and evaluator stability. Five frontier LLMs generate and cross-evaluate MCC risk rationales under attributed and anonymized conditions. To establish a judge-independent reference, we introduce a consensus-deviation metric that eliminates circularity by comparing each judge's score to the mean of all other judges, yielding a theoretically grounded measure of self-evaluation and cross-model deviation. Results reveal substantial heterogeneity: GPT-5.1 and Claude 4.5 Sonnet show negative self-evaluation bias (-0.33, -0.31), while Gemini-2.5 Pro and Grok 4 display positive bias (+0.77, +0.71), with bias attenuating by 25.8 percent under anonymization. Evaluation by 26 payment-industry experts shows LLM judges assign scores averaging +0.46 points above human consensus, and that the negative bias of GPT-5.1 and Claude 4.5 Sonnet reflects closer alignment with human judgment. Ground-truth validation using payment-network data shows four models exhibit statistically significant alignment (Spearman rho = 0.56 to 0.77), confirming that the framework captures genuine quality. Overall, the framework provides a replicable basis for evaluating LLM-as-a-judge systems in payment-risk workflows and highlights the need for bias-aware protocols in operational financial settings.", "AI": {"tldr": "The paper proposes a framework for assessing reasoning quality of Large Language Models (LLMs) in merchant risk settings, revealing bias variability, alignment with human judgment, and providing a ground-truth mechanism.", "motivation": "To address the reliability and bias issues of LLMs as evaluators in merchant risk assessments and to establish a robust, replicable evaluation framework.", "method": "The authors proposed a multi-evaluator framework using MCC-based merchant risk assessment, combining a five-criterion rubric, Monte-Carlo scoring, anonymization effects, and consensus-deviation metrics.", "result": "Findings showed bias variability among different LLMs, closer alignment of GPT-5.1 and Claude 4.5 Sonnet with human judgments, and statistical alignment with payment-network data, confirming genuine evaluation capture.", "conclusion": "The framework offers a replicable evaluation basis for LLM judgments in payment risk and underscores the importance of bias-aware methodologies in financial settings."}}
{"id": "2602.05862", "pdf": "https://arxiv.org/pdf/2602.05862", "abs": "https://arxiv.org/abs/2602.05862", "authors": ["Rohan Hore", "Rina Foygel Barber"], "title": "Distribution-free two-sample testing with blurred total variation distance", "categories": ["stat.ML", "cs.LG"], "comment": "47 pages, 4 figures", "summary": "Two-sample testing, where we aim to determine whether two distributions are equal or not equal based on samples from each one, is challenging if we cannot place assumptions on the properties of the two distributions. In particular, certifying equality of distributions, or even providing a tight upper bound on the total variation (TV) distance between the distributions, is impossible to achieve in a distribution-free regime. In this work, we examine the blurred TV distance, a relaxation of TV distance that enables us to perform inference without assumptions on the distributions. We provide theoretical guarantees for distribution-free upper and lower bounds on the blurred TV distance, and examine its properties in high dimensions.", "AI": {"tldr": "The paper introduces the concept of 'blurred TV distance,' a relaxed version of TV distance for two-sample testing under distribution-free regimes, enabling practical inference and addressing challenges in high-dimensional settings.", "motivation": "Certifying equality of distributions or bounding the total variation distance in a distribution-free regime is challenging since no assumptions can be made about the distributions' properties.", "method": "The authors propose and analyze the concept of blurry TV distance, providing theoretical guarantees for both upper and lower bounds, and investigate its behavior in high-dimensional cases.", "result": "Theoretical guarantees for bound analysis are established for the blurred TV distance, highlighting its capability for use in scenarios where distributions are high-dimensional and no prior assumptions exist.", "conclusion": "Blurred TV distance serves as a promising framework for inferring differences between distributions under minimal assumptions, providing flexibility in high-dimensional analysis and expanding the scope of two-sample testing approaches."}}
{"id": "2602.05205", "pdf": "https://arxiv.org/pdf/2602.05205", "abs": "https://arxiv.org/abs/2602.05205", "authors": ["Kenichiro Ando", "Tatsuya Harada"], "title": "Aligning Large Language Model Behavior with Human Citation Preferences", "categories": ["cs.CL", "cs.AI"], "comment": "Work In Progress", "summary": "Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns with human preferences. We construct a dataset to characterize the relationship between human citation preferences and LLM behavior. Web-derived texts are categorized into eight citation-motivation types, and pairwise citation preferences are exhaustively evaluated across all type combinations to capture fine-grained contrasts. Our results show that humans most frequently seek citations for medical text, and stronger models display a similar tendency. We also find that current models are as much as $27\\%$ more likely than humans to add citations to text that is explicitly marked as needing citations on sources such as Wikipedia, and this overemphasis reduces alignment accuracy. Conversely, models systematically underselect numeric sentences (by $-22.6\\%$ relative to humans) and sentences containing personal names (by $-20.1\\%$), categories for which humans typically demand citations. Furthermore, experiments with Direct Preference Optimization demonstrate that model behavior can be calibrated to better match human citation preferences. We expect this study to provide a foundation for more fine-grained investigations into LLM citation preferences.", "AI": {"tldr": "The study explores how LLMs select cite-worthy text and compares their citation preferences to human preferences, finding misalignments in certain categories.", "motivation": "To understand and improve the citation behavior of LLMs in alignment with human preferences, enhancing the credibility and utility of model-generated content.", "method": "A dataset was created to analyze citation preferences across eight citation-motivation types, including exhaustive evaluations of pairwise citation preferences. Experiments with Direct Preference Optimization were conducted to refine model alignment to human behaviors.", "result": "Humans prioritize citations for medical text, which LLMs emulate. However, LLMs over-select sentences marked as needing citations (e.g., Wikipedia) while under-selecting numeric sentences and those containing personal names, leading to reduced alignment accuracy.", "conclusion": "The research highlights misalignments in LLM citation preferences and demonstrates that model behavior can be adjusted to better align with human expectations, laying groundwork for further improvements in LLM citation selection."}}
{"id": "2602.05312", "pdf": "https://arxiv.org/pdf/2602.05312", "abs": "https://arxiv.org/abs/2602.05312", "authors": ["Tatsuya Shirai", "Olivier Nourry", "Yutaro Kashiwa", "Kenji Fujiwara", "Hajimu Iida"], "title": "Does Programming Language Matter? An Empirical Study of Fuzzing Bug Detection", "categories": ["cs.SE"], "comment": "Accepted to the 23rd International Conference on Mining Software Repositories (MSR 2026). 12 pages, 9 figures", "summary": "Fuzzing has become a popular technique for automatically detecting vulnerabilities and bugs by generating unexpected inputs. In recent years, the fuzzing process has been integrated into continuous integration workflows (i.e., continuous fuzzing), enabling short and frequent testing cycles. Despite its widespread adoption, prior research has not examined whether the effectiveness of continuous fuzzing varies across programming languages. This study conducts a large-scale cross-language analysis to examine how fuzzing bug characteristics and detection efficiency differ among languages. We analyze 61,444 fuzzing bugs and 999,248 builds from 559 OSS-Fuzz projects categorized by primary language. Our findings reveal that (i) C++ and Rust exhibit higher fuzzing bug detection frequencies, (ii) Rust and Python show low vulnerability ratios but tend to expose more critical vulnerabilities, (iii) crash types vary across languages and unreproducible bugs are more frequent in Go but rare in Rust, and (iv) Python attains higher patch coverage but suffers from longer time-to-detection. These results demonstrate that fuzzing behavior and effectiveness are strongly shaped by language design, providing insights for language-aware fuzzing strategies and tool development.", "AI": {"tldr": "The study analyzes the impact of programming languages on continuous fuzzing effectiveness, revealing varied bug detection characteristics and performance across languages.", "motivation": "Investigate whether continuous fuzzing effectiveness and bug characteristics differ across programming languages.", "method": "Conducted a large-scale cross-language analysis using data from 61,444 fuzzing bugs and 999,248 builds across 559 OSS-Fuzz projects categorized by language.", "result": "C++ and Rust excel in bug detection frequencies, Rust and Python uncover critical vulnerabilities, crash types vary across languages, and Python achieves higher patch coverage despite slower detection times.", "conclusion": "Fuzzing behavior and efficiency are language-dependent, recommending language-aware strategies and tools for effective fuzzing integration."}}
{"id": "2602.05325", "pdf": "https://arxiv.org/pdf/2602.05325", "abs": "https://arxiv.org/abs/2602.05325", "authors": ["Jiacheng Fan", "Zhiyue Zhao", "Yiqian Zhang", "Chao Chen", "Peide Wang", "Hengdi Zhang", "Zhengxue Cheng"], "title": "RoboPaint: From Human Demonstration to Any Robot and Any View", "categories": ["cs.RO"], "comment": "17 pages", "summary": "Acquiring large-scale, high-fidelity robot demonstration data remains a critical bottleneck for scaling Vision-Language-Action (VLA) models in dexterous manipulation. We propose a Real-Sim-Real data collection and data editing pipeline that transforms human demonstrations into robot-executable, environment-specific training data without direct robot teleoperation. Standardized data collection rooms are built to capture multimodal human demonstrations (synchronized 3 RGB-D videos, 11 RGB videos, 29-DoF glove joint angles, and 14-channel tactile signals). Based on these human demonstrations, we introduce a tactile-aware retargeting method that maps human hand states to robot dex-hand states via geometry and force-guided optimization. Then the retargeted robot trajectories are rendered in a photorealistic Isaac Sim environment to build robot training data. Real world experiments have demonstrated: (1) The retargeted dex-hand trajectories achieve an 84\\% success rate across 10 diverse object manipulation tasks. (2) VLA policies (Pi0.5) trained exclusively on our generated data achieve 80\\% average success rate on three representative tasks, i.e., pick-and-place, pushing and pouring. To conclude, robot training data can be efficiently \"painted\" from human demonstrations using our real-sim-real data pipeline. We offer a scalable, cost-effective alternative to teleoperation with minimal performance loss for complex dexterous manipulation.", "AI": {"tldr": "The paper introduces a Real-Sim-Real pipeline to generate training data for dexterous robot manipulation using human demonstrations, avoiding direct robot teleoperation.", "motivation": "The need to overcome the bottleneck in acquiring large-scale, high-fidelity robot demonstration data for Vision-Language-Action models in dexterous manipulation.", "method": "The pipeline collects multimodal human demonstration data (video, tactile signals, glove joint angles) and uses a tactile-aware retargeting method to map human actions to robot dexterous-hand actions. Robot trajectories are generated and rendered in a virtual environment for training data.", "result": "The retargeted dex-hand achieved 84% success across 10 manipulation tasks, and VLA policies trained solely on generated data achieved 80% success on three representative tasks.", "conclusion": "The approach offers a scalable and cost-effective solution for generating robot training data with minimal performance loss, eliminating the need for direct robot teleoperation in complex manipulation tasks."}}
{"id": "2602.05175", "pdf": "https://arxiv.org/pdf/2602.05175", "abs": "https://arxiv.org/abs/2602.05175", "authors": ["Zhe Li", "Bernhard Kainz"], "title": "ShapePuri: Shape Guided and Appearance Generalized Adversarial Purification", "categories": ["cs.CV"], "comment": "10 pages, 5 figures", "summary": "Deep neural networks demonstrate impressive performance in visual recognition, but they remain vulnerable to adversarial attacks that is imperceptible to the human. Although existing defense strategies such as adversarial training and purification have achieved progress, diffusion-based purification often involves high computational costs and information loss. To address these challenges, we introduce Shape Guided Purification (ShapePuri), a novel defense framework enhances robustness by aligning model representations with stable structural invariants. ShapePuri integrates two components: a Shape Encoding Module (SEM) that provides dense geometric guidance through Signed Distance Functions (SDF), and a Global Appearance Debiasing (GAD) module that mitigates appearance bias via stochastic transformations. In our experiments, ShapePuri achieves $84.06\\%$ clean accuracy and $81.64\\%$ robust accuracy under the AutoAttack protocol, representing the first defense framework to surpass the $80\\%$ threshold on this benchmark. Our approach provides a scalable and efficient adversarial defense that preserves prediction stability during inference without requiring auxiliary modules or additional computational cost.", "AI": {"tldr": "Shape Guided Purification (ShapePuri) boosts robustness of deep neural networks against adversarial attacks by using structural invariants, achieving state-of-the-art results.", "motivation": "Deep neural networks excel in visual recognition but are susceptible to imperceptible adversarial attacks, which degrade their performance significantly.", "method": "ShapePuri introduces two components: a Shape Encoding Module (SEM) leveraging Signed Distance Functions for geometric guidance and a Global Appearance Debiasing (GAD) module using stochastic transformations to minimize appearance bias.", "result": "The proposed ShapePuri achieves clean accuracy of 84.06% and robust accuracy of 81.64% under AutoAttack benchmarks, surpassing the 80% threshold for the first time.", "conclusion": "ShapePuri offers an efficient defense mechanism that aligns with structural invariants, providing stable prediction under adversarial attacks without additional computational costs or auxiliary modules."}}
{"id": "2602.05113", "pdf": "https://arxiv.org/pdf/2602.05113", "abs": "https://arxiv.org/abs/2602.05113", "authors": ["Suvadip Sana", "Jinzhou Wu", "Martin T. Wells"], "title": "Democratic Preference Alignment via Sortition-Weighted RLHF", "categories": ["cs.AI", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.", "AI": {"tldr": "The paper introduces a framework called Democratic Preference Optimization (DemPO) to improve AI alignment methods by enforcing demographic representativeness in training data collection.", "motivation": "Current AI systems' preference alignment methods often derive training data from human raters, but these rater pools lack demographic representativeness, leading to biased results. The authors propose a solution to address this imbalance.", "method": "DemPO uses algorithmic sortition to create demographically representative samples of raters via two schemes: (1) Hard Panel, which uses quota-satisfying samples, and (2) Soft Panel, which reweights raters based on sortition probabilities. It is tested using demographic data and human judgments.", "result": "Hard Panel consistently showed better performance, and Soft Panel outperformed baseline models. Both methods enhanced model performance as capacity increased, aligning behavior more closely to values from representative demographics.", "conclusion": "Enforcing demographic representativeness during preference collection improves AI model behaviors, highlighting the need for equitable training data rather than relying on post hoc corrections."}}
{"id": "2602.05869", "pdf": "https://arxiv.org/pdf/2602.05869", "abs": "https://arxiv.org/abs/2602.05869", "authors": ["Hengrui Luo", "Anna Ma", "Ludovic Stephan", "Yizhe Zhu"], "title": "Wedge Sampling: Efficient Tensor Completion with Nearly-Linear Sample Complexity", "categories": ["stat.ML", "cs.LG", "math.NA", "math.PR", "math.ST"], "comment": "58 pages, 3 figures", "summary": "We introduce Wedge Sampling, a new non-adaptive sampling scheme for low-rank tensor completion. We study recovery of an order-$k$ low-rank tensor of dimension $n \\times \\cdots \\times n$ from a subset of its entries. Unlike the standard uniform entry model (i.e., i.i.d. samples from $[n]^k$), wedge sampling allocates observations to structured length-two patterns (wedges) in an associated bipartite sampling graph. By directly promoting these length-two connections, the sampling design strengthens the spectral signal that underlies efficient initialization, in regimes where uniform sampling is too sparse to generate enough informative correlations.\n  Our main result shows that this change in sampling paradigm enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in $n$. The approach is also plug-and-play: wedge-sampling-based spectral initialization can be combined with existing refinement procedures (e.g., spectral or gradient-based methods) using only an additional $\\tilde{O}(n)$ uniformly sampled entries, substantially improving over the $\\tilde{O}(n^{k/2})$ sample complexity typically required under uniform entry sampling for efficient methods. Overall, our results suggest that the statistical-to-computational gap highlighted in Barak and Moitra (2022) is, to a large extent, a consequence of the uniform entry sampling model for tensor completion, and that alternative non-adaptive measurement designs that guarantee a strong initialization can overcome this barrier.", "AI": {"tldr": "The paper proposes Wedge Sampling, a sampling method for low-rank tensor completion, which improves initialization and reduces sample complexity compared to traditional uniform sampling.", "motivation": "To address the limitations of uniform sampling in low-rank tensor completion, which struggles to provide strong initialization and requires large sample complexity for efficient recovery.", "method": "The authors introduce Wedge Sampling, where observations are allocated to structured length-two patterns (wedges) in a bipartite sampling graph instead of just uniformly sampling tensor entries.", "result": "Wedge Sampling enables polynomial-time algorithms to achieve both weak and exact recovery of low-rank tensors, requiring nearly linear sample complexity in the tensor dimension size. It can be combined with existing refinement methods for further improvements.", "conclusion": "This work demonstrates that Wedge Sampling overcomes the statistical-to-computational gaps arising from uniform sampling, offering a promising direction to achieve efficient tensor completions with strong initialization and reduced sample complexity."}}
{"id": "2602.04913", "pdf": "https://arxiv.org/pdf/2602.04913", "abs": "https://arxiv.org/abs/2602.04913", "authors": ["Xiaolin Hu", "Hang Yuan", "Xinzhu Sang", "Binbin Yan", "Zhou Yu", "Cong Huang", "Kai Chen"], "title": "A$^2$-LLM: An End-to-end Conversational Audio Avatar Large Language Model", "categories": ["cs.LG", "cs.AI", "cs.SD"], "comment": "13 pages, 3 figures", "summary": "Developing expressive and responsive conversational digital humans is a cornerstone of next-generation human-computer interaction. While large language models (LLMs) have significantly enhanced dialogue capabilities, most current systems still rely on cascaded architectures that connect independent modules. These pipelines are often plagued by accumulated errors, high latency, and poor real-time performance. Lacking access to the underlying conversational context, these pipelines inherently prioritize rigid lip-sync over emotional depth. To address these challenges, we propose A$^2$-LLM, an end-to-end conversational audio avatar large language model that jointly reasons about language, audio prosody, and 3D facial motion within a unified framework. To facilitate training, we introduce FLAME-QA, a high-quality multimodal dataset designed to align semantic intent with expressive facial dynamics within a QA format. By leveraging deep semantic understanding, A$^2$-LLM generates emotionally rich facial movements beyond simple lip-synchronization. Experimental results demonstrate that our system achieves superior emotional expressiveness while maintaining real-time efficiency (500 ms latency, 0.7 RTF).", "AI": {"tldr": "The paper introduces A$^2$-LLM, an end-to-end audio avatar LLM that optimizes emotional expressiveness and real-time performance by unifying language, audio prosody, and facial motion reasoning.", "motivation": "Existing conversational systems rely on cascaded architectures that have issues like accumulated errors, high latency, poor real-time performance, and lack emotional expressiveness.", "method": "The proposed A$^2$-LLM integrates language, audio prosody, and 3D facial motion processing in a unified framework. Additionally, the authors introduced FLAME-QA, a multimodal dataset aligning semantic intent with facial dynamics.", "result": "A$^2$-LLM achieves better emotional expressiveness in facial movements while maintaining real-time operational efficiency with 500 ms latency and 0.7 Real-Time Factor (RTF).", "conclusion": "The model significantly advances the emotional depth and responsiveness of conversational digital humans, overcoming the limitations of traditional cascaded systems."}}
{"id": "2602.05486", "pdf": "https://arxiv.org/pdf/2602.05486", "abs": "https://arxiv.org/abs/2602.05486", "authors": ["Matteo Esposito", "Lodovica Marchesi", "Roberto Tonelli", "Valentina Lenarduzzi"], "title": "Sovereign-by-Design A Reference Architecture for AI and Blockchain Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.DC"], "comment": null, "summary": "Digital sovereignty has emerged as a central concern for modern software-intensive systems, driven by the dominance of non-sovereign cloud infrastructures, the rapid adoption of Generative AI, and increasingly stringent regulatory requirements. While existing initiatives address governance, compliance, and security in isolation, they provide limited guidance on how sovereignty can be operationalized at the architectural level. In this paper, we argue that sovereignty must be treated as a first-class architectural property rather than a purely regulatory objective. We introduce a Sovereign Reference Architecture that integrates self-sovereign identity, blockchain-based trust and auditability, sovereign data governance, and Generative AI deployed under explicit architectural control. The architecture explicitly captures the dual role of Generative AI as both a source of governance risk and an enabler of compliance, accountability, and continuous assurance when properly constrained. By framing sovereignty as an architectural quality attribute, our work bridges regulatory intent and concrete system design, offering a coherent foundation for building auditable, evolvable, and jurisdiction-aware AI-enabled systems. The proposed reference architecture provides a principled starting point for future research and practice at the intersection of software architecture, Generative AI, and digital sovereignty.", "AI": {"tldr": "The paper introduces a Sovereign Reference Architecture to operationalize digital sovereignty, emphasizing Generative AI's dual role as a governance risk and compliance enabler.", "motivation": "The paper is motivated by the dominance of non-sovereign infrastructures, rapid Generative AI adoption, and stricter regulations, highlighting the need for operationalizing sovereignty in software systems.", "method": "The authors propose treating sovereignty as a first-class architectural property and introduce a Sovereign Reference Architecture integrating self-sovereign identity, blockchain, data governance, and Generative AI.", "result": "The Sovereign Reference Architecture bridges regulatory intent with system design by capturing sovereignty as an architectural quality attribute, offering guidance for developing AI-enabled systems.", "conclusion": "This work offers a coherent foundation for auditable, jurisdiction-aware, and evolvable AI systems and invites further research on digital sovereignty and system architecture design."}}
{"id": "2602.05211", "pdf": "https://arxiv.org/pdf/2602.05211", "abs": "https://arxiv.org/abs/2602.05211", "authors": ["Hongye Zhao", "Yi Zhao", "Chengzhi Zhang"], "title": "Quantifying the Knowledge Proximity Between Academic and Industry Research: An Entity and Semantic Perspective", "categories": ["cs.CL", "cs.DL"], "comment": null, "summary": "The academia and industry are characterized by a reciprocal shaping and dynamic feedback mechanism. Despite distinct institutional logics, they have adapted closely in collaborative publishing and talent mobility, demonstrating tension between institutional divergence and intensive collaboration. Existing studies on their knowledge proximity mainly rely on macro indicators such as the number of collaborative papers or patents, lacking an analysis of knowledge units in the literature. This has led to an insufficient grasp of fine-grained knowledge proximity between industry and academia, potentially undermining collaboration frameworks and resource allocation efficiency. To remedy the limitation, this study quantifies the trajectory of academia-industry co-evolution through fine-grained entities and semantic space. In the entity measurement part, we extract fine-grained knowledge entities via pre-trained models, measure sequence overlaps using cosine similarity, and analyze topological features through complex network analysis. At the semantic level, we employ unsupervised contrastive learning to quantify convergence in semantic spaces by measuring cross-institutional textual similarities. Finally, we use citation distribution patterns to examine correlations between bidirectional knowledge flows and similarity. Analysis reveals that knowledge proximity between academia and industry rises, particularly following technological change. This provides textual evidence of bidirectional adaptation in co-evolution. Additionally, academia's knowledge dominance weakens during technological paradigm shifts. The dataset and code for this paper can be accessed at https://github.com/tinierZhao/Academic-Industrial-associations.", "AI": {"tldr": "The study explores fine-grained knowledge proximity between academia and industry using entities and semantic analysis, revealing increased adaptation following tech changes.", "motivation": "Existing research lacks in-depth analysis of knowledge units, limiting understanding of academia-industry collaboration and resource allocation efficiency.", "method": "The paper employs pre-trained models for entity extraction, cosine similarity for overlap measurement, complex network analysis for topology, contrastive learning for textual similarities, and citation distribution for knowledge flow analysis.", "result": "The study finds increased knowledge proximity between academia and industry, with evidence of mutual adaptation and shifts in knowledge dominance during technological changes.", "conclusion": "Fine-grained analysis enhances understanding of academia-industry dynamics, highlighting the impact of technological shifts on collaboration and adaptation."}}
{"id": "2602.05441", "pdf": "https://arxiv.org/pdf/2602.05441", "abs": "https://arxiv.org/abs/2602.05441", "authors": ["Dean Fortier", "Timothy Adamson", "Tess Hellebrekers", "Teresa LaScala", "Kofi Ennin", "Michael Murray", "Andrey Kolobov", "Galen Mullins"], "title": "Benchmarking Affordance Generalization with BusyBox", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their training set. While generalization in vision and language space is undoubtedly important for robust versatile behaviors, a key meta-skill VLAs need to possess is affordance generalization -- the ability to manipulate new objects with familiar physical features.\n  In this work, we present BusyBox, a physical benchmark for systematic semi-automatic evaluation of VLAs' affordance generalization. BusyBox consists of 6 modules with switches, sliders, wires, buttons, a display, and a dial. The modules can be swapped and rotated to create a multitude of BusyBox variations with different visual appearances but the same set of affordances. We empirically demonstrate that generalization across BusyBox variants is highly challenging even for strong open-weights VLAs such as $\u03c0_{0.5}$ and GR00T-N1.6. To encourage the research community to evaluate their own VLAs on BusyBox and to propose new affordance generalization experiments, we have designed BusyBox to be easy to build in most robotics labs. We release the full set of CAD files for 3D-printing its parts as well as a bill of materials for (optionally) assembling its electronics. We also publish a dataset of language-annotated demonstrations that we collected using the common bimanual Mobile Aloha robot on the canonical BusyBox configuration. All of the released materials are available at https://microsoft.github.io/BusyBox.", "AI": {"tldr": "The paper introduces BusyBox, a physical benchmark to evaluate Vision-Language-Action (VLA) models' generalization in affordances (action-related object manipulation).", "motivation": "There is a need for VLA models to not only generalize in vision and language but also in affordance (manipulating objects with familiar features). This is necessary for robust and versatile robotic behaviors.", "method": "The authors introduce 'BusyBox,' a modular physical benchmark consisting of 6 interchangeable components that allow variability in appearance with consistent affordances. It systematically evaluates VLAs' generalization capacity across different configurations.", "result": "BusyBox highlights the difficulty of affordance generalization even for strong VLA models like \u03c0\u2080.\u2085 and GR00T-N1.6. The study empirically demonstrates the challenge of generalizing to new configurations.", "conclusion": "BusyBox is proposed as a useful tool for researching VLA affordance generalization. Its opensource design enables easy replication and testing, promoting further experiments and advancements in the field."}}
{"id": "2602.05190", "pdf": "https://arxiv.org/pdf/2602.05190", "abs": "https://arxiv.org/abs/2602.05190", "authors": ["Ju Shen", "Chen Chen", "Tam V. Nguyen", "Vijayan K. Asari"], "title": "PoseGaussian: Pose-Driven Novel View Synthesis for Robust 3D Human Reconstruction", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "We propose PoseGaussian, a pose-guided Gaussian Splatting framework for high-fidelity human novel view synthesis. Human body pose serves a dual purpose in our design: as a structural prior, it is fused with a color encoder to refine depth estimation; as a temporal cue, it is processed by a dedicated pose encoder to enhance temporal consistency across frames. These components are integrated into a fully differentiable, end-to-end trainable pipeline. Unlike prior works that use pose only as a condition or for warping, PoseGaussian embeds pose signals into both geometric and temporal stages to improve robustness and generalization. It is specifically designed to address challenges inherent in dynamic human scenes, such as articulated motion and severe self-occlusion. Notably, our framework achieves real-time rendering at 100 FPS, maintaining the efficiency of standard Gaussian Splatting pipelines. We validate our approach on ZJU-MoCap, THuman2.0, and in-house datasets, demonstrating state-of-the-art performance in perceptual quality and structural accuracy (PSNR 30.86, SSIM 0.979, LPIPS 0.028).", "AI": {"tldr": "The paper presents PoseGaussian, a novel framework for high-quality human novel view synthesis that integrates pose information to improve performance and achieve efficient rendering.", "motivation": "The goal is to address challenges in dynamic human scenes such as articulated motion and self-occlusion, which are not sufficiently handled by existing methods.", "method": "The framework uses human body pose as both a structural prior for depth refinement and a temporal cue for maintaining temporal consistency. It incorporates these features into an end-to-end differentiable pipeline and integrates pose signals into geometric and temporal processing.", "result": "The framework achieves state-of-the-art results in perceptual quality and structural accuracy on the ZJU-MoCap, THuman2.0, and in-house datasets, with efficient real-time rendering of 100 FPS (PSNR 30.86, SSIM 0.979, LPIPS 0.028).", "conclusion": "PoseGaussian demonstrates significant improvements in generalization and robustness for novel view synthesis, especially in challenging scenarios with dynamic human subjects, while maintaining high efficiency."}}
{"id": "2602.05115", "pdf": "https://arxiv.org/pdf/2602.05115", "abs": "https://arxiv.org/abs/2602.05115", "authors": ["Keyang Xuan", "Pengda Wang", "Chongrui Ye", "Haofei Yu", "Tal August", "Jiaxuan You"], "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers", "categories": ["cs.AI", "cs.CL"], "comment": "10 pages", "summary": "Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present \\textsc{SocialVeil}, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. Grounded in a systematic literature review of communication challenges in human interaction, \\textsc{SocialVeil} introduces three representative types of such disruption, \\emph{semantic vagueness}, \\emph{sociocultural mismatch}, and \\emph{emotional interference}. We also introduce two barrier-aware evaluation metrics, \\emph{unresolved confusion} and \\emph{mutual understanding}, to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45\\% on average, and confusion elevated by nearly 50\\%. Human evaluations validate the fidelity of these simulated barriers (ICC$\\approx$0.78, Pearson r$\\approx$0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learning) only have a modest effect far from barrier-free performance. This work takes a step toward bringing social interaction environments closer to real-world communication, opening opportunities for exploring the social intelligence of LLM agents.", "AI": {"tldr": "The paper introduces SocialVeil, a system evaluating large language models (LLMs) in communication scenarios with barriers like semantic vagueness, sociocultural mismatch, and emotional interference, offering new insights into their social intelligence.", "motivation": "Existing benchmarks for LLMs evaluate idealized communication scenarios, failing to address realistic communication imperfections that are crucial for diagnosing interaction capabilities.", "method": "SocialVeil uses simulated barriers\u2014semantic vagueness, sociocultural mismatch, and emotional interference\u2014and proposes metrics 'mutual understanding' and 'unresolved confusion' to assess LLMs' performance in impaired communication.", "result": "Experiments on LLMs across 720 scenarios reveal significant performance drops under communication barriers, with mutual understanding reduced by over 45% and confusion elevated by nearly 50%.", "conclusion": "SocialVeil helps bridge the gap between idealized and real-world communication environments, enhancing understanding of LLMs' social intelligence and their limitations in handling imperfect interactions."}}
{"id": "2602.05927", "pdf": "https://arxiv.org/pdf/2602.05927", "abs": "https://arxiv.org/abs/2602.05927", "authors": ["Siquan Li", "Yao Tong", "Haonan Wang", "Tianyang Hu"], "title": "Transformers Are Born Biased: Structural Inductive Biases at Random Initialization and Their Practical Consequences", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Transformers underpin modern large language models (LLMs) and are commonly assumed to be behaviorally unstructured at random initialization, with all meaningful preferences emerging only through large-scale training. We challenge this assumption by showing that randomly initialized transformers already exhibit strong and systematic structural biases. In particular, untrained models display extreme token preferences: across random input sequences, certain tokens are predicted with probabilities orders of magnitude larger.\n  We provide a mechanistic explanation for this phenomenon by dissecting the transformer architecture at initialization. We show that extreme token preference arises from a contraction of token representations along a random seed-dependent direction. This contraction is driven by two interacting forces: (i) asymmetric nonlinear activations in MLP sublayers induce global (inter-sequence) representation concentration, and (ii) self-attention further amplifies this effect through local (intra-sequence) aggregation. Together, these mechanisms align hidden representations along a direction determined solely by the random initialization, producing highly non-uniform next-token predictions.\n  Beyond mechanistic insight, we demonstrate that these initialization-induced biases persist throughout training, forming a stable and intrinsic model identity. Leveraging this property, we introduce SeedPrint, a fingerprinting method that can reliably distinguish models that differ only in their random initialization, even after extensive training and under substantial distribution shift. Finally, we identify a fundamental positional discrepancy inherent to the attention mechanism's intra-sequence contraction that is causally linked to the attention-sink phenomenon. This discovery provides a principled explanation for the emergence of sinks and offers a pathway for their control.", "AI": {"tldr": "The paper reveals that randomly initialized transformers exhibit token prediction biases caused by inherent architecture properties, challenging the assumption of unstructured behavior before training.", "motivation": "The research aims to explore assumptions that transformers lack behavioral structure prior to training and investigate if their architecture induces systematic biases.", "method": "The authors analyze transformer initialization mechanisms and introduce SeedPrint for distinguishing models based on random initialization, alongside studying positional discrepancies in attention mechanisms.", "result": "Randomly initialized transformers show token preference bias due to contraction mechanisms, impacting representation alignment. The biases persist after training and SeedPrint effectively fingerprints models.", "conclusion": "Transformers exhibit intrinsic biases at initialization due to architectural properties, affecting downstream predictions. The study advances mechanistic understanding and offers a technique to manage biases."}}
{"id": "2602.04915", "pdf": "https://arxiv.org/pdf/2602.04915", "abs": "https://arxiv.org/abs/2602.04915", "authors": ["Jose Miguel Luna", "Taha Bouhsine", "Krzysztof Choromanski"], "title": "SLAY: Geometry-Aware Spherical Linearized Attention with Yat-Kernel", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2026, 8 pages main body, 27 pages total", "summary": "We propose a new class of linear-time attention mechanisms based on a relaxed and computationally efficient formulation of the recently introduced E-Product, often referred to as the Yat-kernel (Bouhsine, 2025). The resulting interactions are geometry-aware and inspired by inverse-square interactions in physics. Our method, Spherical Linearized Attention with Yat Kernels (SLAY), constrains queries and keys to the unit sphere so that attention depends only on angular alignment. Using Bernstein's theorem, we express the spherical Yat-kernel as a nonnegative mixture of polynomial-exponential product kernels and derive a strictly positive random-feature approximation enabling linear-time O(L) attention. We establish positive definiteness and boundedness on the sphere and show that the estimator yields well-defined, nonnegative attention scores. Empirically, SLAY achieves performance that is nearly indistinguishable from standard softmax attention while retaining linear time and memory scaling, and consistently outperforms prior linear-time attention mechanisms such as Performers and Cosformers. To the best of our knowledge, SLAY represents the closest linear-time approximation to softmax attention reported to date, enabling scalable Transformers without the typical performance trade-offs of attention linearization.", "AI": {"tldr": "SLAY (Spherical Linearized Attention with Yat Kernels) introduces a new linear-time attention mechanism inspired by physics, providing geometry-aware and efficient transformations while maintaining performance similar to standard softmax attention.", "motivation": "Transformers utilize standard softmax attention, which is computationally costly for large-scale inputs. Motivated by scalability and efficiency, the study seeks to develop an approximate linear-time attention mechanism without sacrificing performance.", "method": "SLAY leverages spherical constraints on queries and keys, angular alignment, and the Yat-kernel. Using Bernstein's theorem, it derives a random-feature approximation to achieve linear-time O(L) attention.", "result": "SLAY achieves similar performance to softmax attention, outperforming prior linear-efficiency mechanisms such as Performers and Cosformers, while maintaining scalability and efficiency.", "conclusion": "SLAY offers a scalable and computationally efficient solution for Transformers, representing a significant step toward eliminating the performance trade-offs associated with attention linearization."}}
{"id": "2602.05686", "pdf": "https://arxiv.org/pdf/2602.05686", "abs": "https://arxiv.org/abs/2602.05686", "authors": ["Max Firmbach", "Malachi Phillips", "Christian Glusa", "Alexander Popp", "Christopher M. Siefert", "Matthias Mayr"], "title": "Smoothed aggregation algebraic multigrid for problems with heterogeneous and anisotropic materials", "categories": ["cs.CE", "cs.DC"], "comment": null, "summary": "This paper introduces a material-aware strength-of-connection measure for smoothed aggregation algebraic multigrid methods, aimed at improving robustness for scalar partial differential equations with heterogeneous and anisotropic material properties. Classical strength-of-connection measures typically rely only on matrix entries or geometric distances, which often fail to capture weak couplings across material interfaces or align with anisotropy directions, ultimately leading to poor convergence. The proposed approach directly incorporates material tensor information into the coarsening process, enabling a reliable detection of weak connections and ensuring that coarse levels preserve the true structure of the underlying problem. As a result, smooth error components are represented properly and sharp coefficient jumps or directional anisotropies are handled consistently. A wide range of academic tests and real-world applications, including thermally activated batteries and solar cells, demonstrate that the proposed method maintains robustness across material contrasts, anisotropies, and mesh variations. Scalability and parallel performance of the algebraic multigrid method highlight the suitability for large-scale, high-performance computing environments.", "AI": {"tldr": "This paper introduces a material-aware approach to improve the robustness of smoothed aggregation algebraic multigrid (SA-AMG) methods for challenging heterogeneous and anisotropic scenarios.", "motivation": "The authors aim to address the poor convergence of classical strength-of-connection measures that fail to consider material properties, leading to inefficiencies in solving partial differential equations with heterogeneous and anisotropic media.", "method": "The research incorporates material tensor information into the coarsening process of SA-AMG, ensuring accurate detection of weak couplings and consistent handling of material interfaces and anisotropies.", "result": "The method demonstrates robustness in academic tests and real-world applications, effectively managing material contrasts, anisotropies, and mesh variations. It also scales well for high-performance computing.", "conclusion": "By embedding material-aware measures, the enhanced SA-AMG method ensures better problem representation, improved convergence, and high scalability for complex simulations."}}
{"id": "2602.05220", "pdf": "https://arxiv.org/pdf/2602.05220", "abs": "https://arxiv.org/abs/2602.05220", "authors": ["Jinchuan Tian", "Haoran Wang", "Bo-Hao Su", "Chien-yu Huang", "Qingzheng Wang", "Jiatong Shi", "William Chen", "Xun Gong", "Siddhant Arora", "Chin-Jou Li", "Masao Someki", "Takashi Maekaku", "Yusuke Shinohara", "Jin Sakuma", "Chao-Han Huck Yang", "Shinji Watanabe"], "title": "Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.", "AI": {"tldr": "Bagpiper is an 8B parameter audio foundation model that interprets and synthesizes audio through rich natural language captions, enabling holistic understanding and generation of audio tasks.", "motivation": "Current audio models focus on task-specific supervision and lack holistic processing, unlike human intelligence. Bagpiper aims to bridge this gap by connecting physical audio with high-level cognitive concepts.", "method": "Bagpiper is pre-trained on 600B tokens, creating a bidirectional mapping between audio and natural language captions. It uses a caption-then-process approach, incorporating intermediate reasoning to solve diverse tasks.", "result": "Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench in audio understanding and exceeds CosyVoice3 and TangoFlux in audio generation quality, showcasing its ability to synthesize diverse audio compositions.", "conclusion": "Bagpiper is among the first models to unify audio understanding and generation, simulating human-like holistic processing of audio signals. It significantly advances the capabilities of audio foundation models."}}
{"id": "2602.05465", "pdf": "https://arxiv.org/pdf/2602.05465", "abs": "https://arxiv.org/abs/2602.05465", "authors": ["Alexander Berndt", "Vekil Bekmyradov", "Rainer Gemulla", "Marcus Kessel", "Thomas Bach", "Sebastian Baltes"], "title": "Can We Classify Flaky Tests Using Only Test Code? An LLM-Based Empirical Study", "categories": ["cs.SE"], "comment": "10 pages, 3 figures, 7 tables, 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering: Reproducibility Studies and Negative Results (SANER-RENE 2025)", "summary": "Flaky tests yield inconsistent results when they are repeatedly executed on the same code revision. They interfere with automated quality assurance of code changes and hinder efficient software testing. Previous work evaluated approaches to train machine learning models to classify flaky tests based on identifiers in the test code. However, the resulting classifiers have been shown to lack generalizability, hindering their applicability in practical environments. Recently, pre-trained Large Language Models (LLMs) have shown the capability to generalize across various tasks. Thus, they represent a promising approach to address the generalizability problem of previous approaches. In this study, we evaluated three LLMs (two general-purpose models, one code-specific model) using three prompting techniques on two benchmark datasets from prior studies on flaky test classification. Furthermore, we manually investigated 50 samples from the given datasets to determine whether classifying flaky tests based only on test code is feasible for humans. Our findings indicate that LLMs struggle to classify flaky tests given only the test code. The results of our best prompt-model combination were only marginally better than random guessing. In our manual analysis, we found that the test code does not necessarily contain sufficient information for a flakiness classification. Our findings motivate future work to evaluate LLMs for flakiness classification with additional context, for example, using retrieval-augmented generation or agentic AI.", "AI": {"tldr": "The paper evaluates the use of Large Language Models (LLMs) for flaky test classification using test code and finds that current methods struggle to perform better than random guessing. Test code alone does not seem to provide enough information for classification.", "motivation": "Flaky tests cause inconsistent testing results, disrupt automated quality assurance, and complicate software testing. Previous machine learning classifiers for flaky tests lacked generalizability, prompting exploration of LLMs as they have shown cross-task generalization capabilities.", "method": "The study evaluated three LLMs (two general-purpose, one code-specific) with three prompting techniques on two flaky test classification benchmarks. Additionally, 50 dataset samples were manually analyzed to assess human accuracy in classifying flaky tests using just test code.", "result": "Findings showed that LLMs largely failed to classify flaky tests based on test code alone, performing only marginally better than random guessing. Human analysis revealed that test code itself often lacks sufficient data for reliable flaky test classification.", "conclusion": "The paper concludes that using only test code limits the accurate classification of flaky tests by both LLMs and humans. Future exploration should incorporate additional contextual information, such as retrieval-augmented generation or advanced AI methods."}}
{"id": "2602.05456", "pdf": "https://arxiv.org/pdf/2602.05456", "abs": "https://arxiv.org/abs/2602.05456", "authors": ["Maksym Figat", "Ryan M. Mackey", "Michel D. Ingham"], "title": "Ontology-Driven Robotic Specification Synthesis", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": "8 pages, 9 figures, 3 tables, journal", "summary": "This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.", "AI": {"tldr": "This paper introduces RSTM2, an ontology-driven method to transform robotic tasks into executable specifications for safety-critical applications using stochastic Petri nets.", "motivation": "There is a need to bridge high-level objectives with formal specifications for safety and mission-critical robotic systems.", "method": "RSTM2 employs an ontology-driven hierarchical framework using stochastic timed Petri nets and Monte Carlo simulations.", "result": "A case study showcases RSTM2's capability to support architectural trades, resource allocation, and performance analysis under uncertainty.", "conclusion": "The methodology enables explainable AI-based autonomous specification synthesis, benefiting complex multi-robot systems like NASA CADRE."}}
{"id": "2602.05202", "pdf": "https://arxiv.org/pdf/2602.05202", "abs": "https://arxiv.org/abs/2602.05202", "authors": ["Shivanshu Shekhar", "Uttaran Bhattacharya", "Raghavendra Addanki", "Mehrab Tanjim", "Somdeb Sarkhel", "Tong Zhang"], "title": "GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Aligning video generative models with human preferences remains challenging: current approaches rely on Vision-Language Models (VLMs) for reward modeling, but these models struggle to capture subtle temporal dynamics. We propose a fundamentally different approach: repurposing video generative models, which are inherently designed to model temporal structure, as reward models. We present the Generative-Transformer-based Self-Supervised Video Judge (\\modelname), a novel evaluation model that transforms state-of-the-art video generation models into powerful temporally-aware reward models. Our key insight is that generative models can be reformulated as energy-based models (EBMs) that assign low energy to high-quality videos and high energy to degraded ones, enabling them to discriminate video quality with remarkable precision when trained via contrastive objectives. To prevent the model from exploiting superficial differences between real and generated videos, we design challenging synthetic negative videos through controlled latent-space perturbations: temporal slicing, feature swapping, and frame shuffling, which simulate realistic but subtle visual degradations. This forces the model to learn meaningful spatiotemporal features rather than trivial artifacts. \\modelname achieves state-of-the-art performance on GenAI-Bench and MonteBench using only 30K human-annotations: $6\\times$ to $65\\times$ fewer than existing VLM-based approaches.", "AI": {"tldr": "This paper introduces \\modelname, a generative transformer video evaluation model repurposed to assess video quality, outperforming conventional Vision-Language Models (VLMs), while requiring significantly fewer human annotations.", "motivation": "Current video generative models face challenges in aligning with human preferences due to Vision-Language Models' inefficiencies in capturing temporal dynamics.", "method": "The authors propose \\modelname, which reforms video generative models into energy-based models (EBMs) by training on contrastive objectives and generating synthetic negative videos to distinguish subtle spatiotemporal features.", "result": "The proposed \\modelname surpasses state-of-the-art benchmarks (GenAI-Bench and MonteBench) while reducing the need for human annotations by a factor of 6x to 65x compared to VLM-based methods.", "conclusion": "\\modelname significantly advances temporally-aware reward modeling for video evaluation, addressing traditional VLM limitations and achieving superior performance with less annotation effort through innovative model repurposing and contrastive training."}}
{"id": "2602.05133", "pdf": "https://arxiv.org/pdf/2602.05133", "abs": "https://arxiv.org/abs/2602.05133", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen", "Alpha Alimamy Kamara", "Zhongyi Zhang"], "title": "CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.", "AI": {"tldr": "CAST-CKT is proposed to address traffic prediction challenges in cross-city settings, offering chaos-aware attention, adaptive topology learning, and uncertainty quantification, achieving superior results.", "motivation": "To tackle the challenges of traffic prediction in data-scarce, cross-city scenarios caused by nonlinear dynamics and domain shifts, and improve methods for capturing the chaotic nature of traffic.", "method": "Develops CAST-CKT framework integrating chaos-aware attention, adaptive topology learning, and chaotic consistency-based cross-city alignment, leveraging a chaotic analyser for robust predictions.", "result": "Extensive experiments show CAST-CKT outperforms existing methods significantly in MAE and RMSE across four benchmarks and provides interpretable regime analysis.", "conclusion": "CAST-CKT effectively improves traffic prediction performance in cross-city few-shot scenarios, offering theoretical and practical advancements, including interpretable predictions and uncertainty quantification."}}
{"id": "2602.05997", "pdf": "https://arxiv.org/pdf/2602.05997", "abs": "https://arxiv.org/abs/2602.05997", "authors": ["Jia Yuan Yu"], "title": "Causal Inference on Stopped Random Walks in Online Advertising", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "We consider a causal inference problem frequently encountered in online advertising systems, where a publisher (e.g., Instagram, TikTok) interacts repeatedly with human users and advertisers by sporadically displaying to each user an advertisement selected through an auction. Each treatment corresponds to a parameter value of the advertising mechanism (e.g., auction reserve-price), and we want to estimate through experiments the corresponding long-term treatment effect (e.g., annual advertising revenue). In our setting, the treatment affects not only the instantaneous revenue from showing an ad, but also changes each user's interaction-trajectory, and each advertiser's bidding policy -- as the latter is constrained by a finite budget. In particular, each a treatment may even affect the size of the population, since users interact longer with a tolerable advertising mechanism. We drop the classical i.i.d. assumption and model the experiment measurements (e.g., advertising revenue) as a stopped random walk, and use a budget-splitting experimental design, the Anscombe Theorem, a Wald-like equation, and a Central Limit Theorem to construct confidence intervals for the long-term treatment effect.", "AI": {"tldr": "This paper discusses estimating long-term treatment effects of advertising mechanisms, considering their impact on user interactions and advertiser policies.", "motivation": "To analyze the long-term effects of advertising mechanisms in online settings, where treatments influence user engagement and advertiser behavior.", "method": "The study models measurements as a stopped random walk and utilizes a budget-splitting experimental design, Anscombe theorem, Wald-like equations, and a Central Limit Theorem to create confidence intervals.", "result": "Confidence intervals for long-term treatment effects were successfully constructed by addressing non-i.i.d. data and incorporating complex interactions.", "conclusion": "The methods developed enable robust estimation of treatment effects in dynamic online advertising systems, factoring in user and advertiser behavior changes."}}
{"id": "2602.04917", "pdf": "https://arxiv.org/pdf/2602.04917", "abs": "https://arxiv.org/abs/2602.04917", "authors": ["Soshi Kakio", "Yasuko Matsubara", "Ren Fujiwara", "Yasushi Sakurai"], "title": "Multi-Aspect Mining and Anomaly Detection for Heterogeneous Tensor Streams", "categories": ["cs.LG"], "comment": "Proceedings of the ACM Web Conference 2026 (WWW '26), April 13--17, 2026, Dubai, United Arab Emirates, 12 pages", "summary": "Analysis and anomaly detection in event tensor streams consisting of timestamps and multiple attributes - such as communication logs(time, IP address, packet length)- are essential tasks in data mining. While existing tensor decomposition and anomaly detection methods provide useful insights, they face the following two limitations. (i) They cannot handle heterogeneous tensor streams, which comprises both categorical attributes(e.g., IP address) and continuous attributes(e.g., packet length). They typically require either discretizing continuous attributes or treating categorical attributes as continuous, both of which distort the underlying statistical properties of the data.Furthermore, incorrect assumptions about the distribution family of continuous attributes often degrade the model's performance. (ii) They discretize timestamps, failing to track the temporal dynamics of streams(e.g., trends, abnormal events), which makes them ineffective for detecting anomalies at the group level, referred to as 'group anomalies' (e.g, DoS attacks). To address these challenges, we propose HeteroComp, a method for continuously summarizing heterogeneous tensor streams into 'components' representing latent groups in each attribute and their temporal dynamics, and detecting group anomalies. Our method employs Gaussian process priors to model unknown distributions of continuous attributes, and temporal dynamics, which directly estimate probability densities from data. Extracted components give concise but effective summarization, enabling accurate group anomaly detection. Extensive experiments on real datasets demonstrate that HeteroComp outperforms the state-of-the-art algorithms for group anomaly detection accuracy, and its computational time does not depend on the data stream length.", "AI": {"tldr": "This paper introduces HeteroComp, a method to analyze heterogeneous tensor streams with categorical and continuous attributes, effectively identifying group anomalies without discretizing attributes or timestamps.", "motivation": "Existing methods struggle with heterogeneous tensor streams, failing to properly handle mixed categorical and continuous data, and temporal dynamics. They also falter in group anomaly detection by making incorrect assumptions about data distributions or by discretizing timestamps.", "method": "HeteroComp summarizes tensor streams into latent groups and temporal dynamics using Gaussian process priors to model continuous attributes and estimate probability densities directly from the data.", "result": "The experiments show that HeteroComp outperforms state-of-the-art algorithms in detecting group anomalies and its computational efficiency remains constant regardless of the data stream length.", "conclusion": "HeteroComp provides concise, effective summarization of heterogeneous tensor streams, improving group anomaly detection accuracy while maintaining computational efficiency."}}
{"id": "2602.05693", "pdf": "https://arxiv.org/pdf/2602.05693", "abs": "https://arxiv.org/abs/2602.05693", "authors": ["Arno Geimer", "Beltran Fiz Pontiveros", "Radu State"], "title": "FedRandom: Sampling Consistent and Accurate Contribution Values in Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning is a privacy-preserving decentralized approach for Machine Learning tasks. In industry deployments characterized by a limited number of entities possessing abundant data, the significance of a participant's role in shaping the global model becomes pivotal given that participation in a federation incurs costs, and participants may expect compensation for their involvement. Additionally, the contributions of participants serve as a crucial means to identify and address potential malicious actors and free-riders. However, fairly assessing individual contributions remains a significant hurdle. Recent works have demonstrated a considerable inherent instability in contribution estimations across aggregation strategies. While employing a different strategy may offer convergence benefits, this instability can have potentially harming effects on the willingness of participants in engaging in the federation. In this work, we introduce FedRandom, a novel mitigation technique to the contribution instability problem. Tackling the instability as a statistical estimation problem, FedRandom allows us to generate more samples than when using regular FL strategies. We show that these additional samples provide a more consistent and reliable evaluation of participant contributions. We demonstrate our approach using different data distributions across CIFAR-10, MNIST, CIFAR-100 and FMNIST and show that FedRandom reduces the overall distance to the ground truth by more than a third in half of all evaluated scenarios, and improves stability in more than 90% of cases.", "AI": {"tldr": "Federated Learning faces challenges in fairly evaluating participant contributions due to instability, which affects engagement. The proposed FedRandom technique mitigates this instability, improving reliability and stability in assessments.", "motivation": "To address the instability in contribution estimations in Federated Learning, which affects participant willingness and compensation fairness, particularly in scenarios with few entities and abundant private data.", "method": "The paper introduces FedRandom, a mitigation technique treating contribution evaluation as a statistical estimation problem, generating more samples to ensure consistent and reliable assessments.", "result": "FedRandom was tested with different distributions on CIFAR-10, MNIST, CIFAR-100, and FMNIST datasets. It reduced contribution estimation instability in over 90% of scenarios and decreased deviation from the ground truth by more than a third in half of the evaluations.", "conclusion": "FedRandom successfully mitigates contribution estimation instability, enhancing reliability and fairness in Federated Learning participant engagements."}}
{"id": "2602.05235", "pdf": "https://arxiv.org/pdf/2602.05235", "abs": "https://arxiv.org/abs/2602.05235", "authors": ["Zhilin Liang", "Yuxiang Wang", "Zimu Zhou", "Hainan Zhang", "Boyi Liu", "Yongxin Tong"], "title": "FedMosaic: Federated Retrieval-Augmented Generation via Parametric Adapters", "categories": ["cs.CL"], "comment": "11 pages", "summary": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by grounding generation in external knowledge to improve factuality and reduce hallucinations. Yet most deployments assume a centralized corpus, which is infeasible in privacy aware domains where knowledge remains siloed. This motivates federated RAG (FedRAG), where a central LLM server collaborates with distributed silos without sharing raw documents. In context RAG violates this requirement by transmitting verbatim documents, whereas parametric RAG encodes documents into lightweight adapters that merge with a frozen LLM at inference, avoiding raw-text exchange. We adopt the parametric approach but face two unique challenges induced by FedRAG: high storage and communication from per-document adapters, and destructive aggregation caused by indiscriminately merging multiple adapters. We present FedMosaic, the first federated RAG framework built on parametric adapters. FedMosaic clusters semantically related documents into multi-document adapters with document-specific masks to reduce overhead while preserving specificity, and performs selective adapter aggregation to combine only relevance-aligned, nonconflicting adapters. Experiments show that FedMosaic achieves an average 10.9% higher accuracy than state-of-the-art methods in four categories, while lowering storage costs by 78.8% to 86.3% and communication costs by 91.4%, and never sharing raw documents.", "AI": {"tldr": "Large Language Models can benefit from external knowledge without sharing sensitive data through federated RAG (FedRAG). The innovative FedMosaic framework effectively manages storage and communication challenges while improving performance and privacy.", "motivation": "Privacy limitations in knowledge-sharing domains require a federated approach to avoid sharing raw documents while retaining accuracy.", "method": "FedMosaic builds multi-document parametric adapters with document-specific masks, selectively aggregating relevant adapters for federated knowledge integration.", "result": "FedMosaic improves accuracy by 10.9%, reduces storage by 78.8%-86.3%, and lowers communication costs by 91.4%, while ensuring document privacy.", "conclusion": "FedMosaic demonstrates viable and efficient federated RAG integration, showcasing significant improvements in operational metrics and maintaining high privacy standards."}}
{"id": "2602.05468", "pdf": "https://arxiv.org/pdf/2602.05468", "abs": "https://arxiv.org/abs/2602.05468", "authors": ["Pranav Ponnivalavan", "Satoshi Funabashi", "Alexander Schmitz", "Tetsuya Ogata", "Shigeki Sugano"], "title": "TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation", "categories": ["cs.RO"], "comment": "8 pages, 8 figures, 8 tables, ICRA2026 accepted", "summary": "Humans can achieve diverse in-hand manipulations, such as object pinching and tool use, which often involve simultaneous contact between the object and multiple fingers. This is still an open issue for robotic hands because such dexterous manipulation requires distinguishing between tactile sensations generated by their self-contact and those arising from external contact. Otherwise, object/robot breakage happens due to contacts/collisions. Indeed, most approaches ignore self-contact altogether, by constraining motion to avoid/ignore self-tactile information during contact. While this reduces complexity, it also limits generalization to real-world scenarios where self-contact is inevitable. Humans overcome this challenge through self-touch perception, using predictive mechanisms that anticipate the tactile consequences of their own motion, through a principle called sensory attenuation, where the nervous system differentiates predictable self-touch signals, allowing novel object stimuli to stand out as relevant. Deriving from this, we introduce TaSA, a two-phased deep predictive learning framework. In the first phase, TaSA explicitly learns self-touch dynamics, modeling how a robot's own actions generate tactile feedback. In the second phase, this learned model is incorporated into the motion learning phase, to emphasize object contact signals during manipulation. We evaluate TaSA on a set of insertion tasks, which demand fine tactile discrimination: inserting a pencil lead into a mechanical pencil, inserting coins into a slot, and fixing a paper clip onto a sheet of paper, with various orientations, positions, and sizes. Across all tasks, policies trained with TaSA achieve significantly higher success rates than baseline methods, demonstrating that structured tactile perception with self-touch based on sensory attenuation is critical for dexterous robotic manipulation.", "AI": {"tldr": "TaSA framework improves the success rate of robotic hands in dexterous tasks by learning self-touch dynamics and emphasizing object contact signals.", "motivation": "Robots struggle with in-hand manipulation involving multiple fingers because they can't differentiate between tactile sensations from self-contact and external objects, often leading to failure.", "method": "The two-phased TaSA framework first models self-touch dynamics of the robot's actions, then incorporates this model into the learning phase to enhance tactile perception for successful object manipulation.", "result": "TaSA significantly outperforms baseline methods in complex tasks (e.g., coin insertion, pencil lead placement) by better distinguishing and utilizing tactile signals.", "conclusion": "Robotic hands can achieve more reliable and dexterous manipulation when tactile perception incorporates sensory attenuation to handle self-contact effectively."}}
{"id": "2602.05213", "pdf": "https://arxiv.org/pdf/2602.05213", "abs": "https://arxiv.org/abs/2602.05213", "authors": ["Chuqin Zhou", "Xiaoyue Ling", "Yunuo Chen", "Jincheng Dai", "Guo Lu", "Wenjun Zhang"], "title": "Dual-Representation Image Compression at Ultra-Low Bitrates via Explicit Semantics and Implicit Textures", "categories": ["cs.CV"], "comment": null, "summary": "While recent neural codecs achieve strong performance at low bitrates when optimized for perceptual quality, their effectiveness deteriorates significantly under ultra-low bitrate conditions. To mitigate this, generative compression methods leveraging semantic priors from pretrained models have emerged as a promising paradigm. However, existing approaches are fundamentally constrained by a tradeoff between semantic faithfulness and perceptual realism. Methods based on explicit representations preserve content structure but often lack fine-grained textures, whereas implicit methods can synthesize visually plausible details at the cost of semantic drift. In this work, we propose a unified framework that bridges this gap by coherently integrating explicit and implicit representations in a training-free manner. Specifically, We condition a diffusion model on explicit high-level semantics while employing reverse-channel coding to implicitly convey fine-grained details. Moreover, we introduce a plug-in encoder that enables flexible control of the distortion-perception tradeoff by modulating the implicit information. Extensive experiments demonstrate that the proposed framework achieves state-of-the-art rate-perception performance, outperforming existing methods and surpassing DiffC by 29.92%, 19.33%, and 20.89% in DISTS BD-Rate on the Kodak, DIV2K, and CLIC2020 datasets, respectively.", "AI": {"tldr": "The paper introduces a unified framework for generative image compression under ultra-low bitrates, integrating explicit and implicit representations to balance semantic faithfulness and perceptual realism.", "motivation": "Current generative compression methods face limitations at ultra-low bitrates due to a tradeoff between semantic faithfulness and perceptual realism.", "method": "The framework integrates explicit high-level semantics with a conditioned diffusion model and implicitly conveys details using reverse-channel coding, aided by a plug-in encoder for flexible distortion-perception control.", "result": "The method outperforms state-of-the-art techniques with significant improvements in DISTS BD-Rate across Kodak, DIV2K, and CLIC2020 datasets.", "conclusion": "The proposed approach effectively addresses the semantic-perceptual tradeoff in compression and sets new benchmarks for performance under ultra-low bitrate conditions."}}
{"id": "2602.05143", "pdf": "https://arxiv.org/pdf/2602.05143", "abs": "https://arxiv.org/abs/2602.05143", "authors": ["Nengbo Wang", "Tuo Liang", "Vikash Singh", "Chaoda Song", "Van Yang", "Yu Yin", "Jing Ma", "Jagdip Singh", "Vipin Chaudhary"], "title": "HugRAG: Hierarchical Causal Knowledge Graph Design for RAG", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.", "AI": {"tldr": "The paper introduces HugRAG, a framework that enhances graph-based RAG systems with causal reasoning, outperforming other baselines.", "motivation": "Existing graph-based RAG methods often rely on superficial matching and lack causal reasoning, leading to unfaithful results.", "method": "The HugRAG framework incorporates hierarchical modules and causal gating to improve structured reasoning and scalability in graph-based RAG.", "result": "HugRAG outperformed competitive baselines across datasets and metrics, showcasing its advancements in structured and scalable reasoning.", "conclusion": "HugRAG provides a strong, scalable foundation for RAG systems by addressing causality and modularity challenges, ensuring reliable reasoning over large knowledge graphs."}}
{"id": "2602.06021", "pdf": "https://arxiv.org/pdf/2602.06021", "abs": "https://arxiv.org/abs/2602.06021", "authors": ["Ye He", "Yitong Qiu", "Molei Tao"], "title": "Diffusion Model's Generalization Can Be Characterized by Inductive Biases toward a Data-Dependent Ridge Manifold", "categories": ["stat.ML", "cs.LG", "math.NA", "math.PR"], "comment": null, "summary": "When a diffusion model is not memorizing the training data set, how does it generalize exactly? A quantitative understanding of the distribution it generates would be beneficial to, for example, an assessment of the model's performance for downstream applications. We thus explicitly characterize what diffusion model generates, by proposing a log-density ridge manifold and quantifying how the generated data relate to this manifold as inference dynamics progresses. More precisely, inference undergoes a reach-align-slide process centered around the ridge manifold: trajectories first reach a neighborhood of the manifold, then align as being pushed toward or away from the manifold in normal directions, and finally slide along the manifold in tangent directions. Within the scope of this general behavior, different training errors will lead to different normal and tangent motions, which can be quantified, and these detailed motions characterize when inter-mode generations emerge. More detailed understanding of training dynamics will lead to more accurate quantification of the generation inductive bias, and an example of random feature model will be considered, for which we can explicitly illustrate how diffusion model's inductive biases originate as a composition of architectural bias and training accuracy, and how they evolve with the inference dynamics. Experiments on synthetic multimodal distributions and MNIST latent diffusion support the predicted directional effects, in both low- and high-dimensions.", "AI": {"tldr": "The paper investigates the generalization mechanism of diffusion models by introducing a log-density ridge manifold and analyzing inference dynamics as reach-align-slide on this manifold.", "motivation": "Understanding and characterizing the distribution generated by diffusion models to evaluate their performance and inductive biases accurately.", "method": "Proposes the log-density ridge manifold, modeling inference dynamics of diffusion models as a three-step process: reach, align, and slide centered around this manifold, with detailed analysis of training error impacts.", "result": "Experiments on synthetic multimodal data and MNIST latent diffusion confirm model predictions of directional effects in both low- and high-dimensional settings.", "conclusion": "Detailed analysis of training dynamics and inference behavior improves understanding of inductive biases, aiding better quantification and enhancing performance evaluation in diffusion models."}}
{"id": "2602.04918", "pdf": "https://arxiv.org/pdf/2602.04918", "abs": "https://arxiv.org/abs/2602.04918", "authors": ["Long Zhang", "Fangwei Lin"], "title": "Simulated Adoption: Decoupling Magnitude and Direction in LLM In-Context Conflict Resolution", "categories": ["cs.LG", "cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) frequently prioritize conflicting in-context information over pre-existing parametric memory, a phenomenon often termed sycophancy or compliance. However, the mechanistic realization of this behavior remains obscure, specifically how the model resolves these knowledge conflicts through compliance, and whether this suppression arises from signal magnitude dilution or directional geometric alteration within the residual stream. To resolve this, we conducted a layer-wise geometric analysis across Qwen-4B, Llama-3.1-8B, and GLM-4-9B, decomposing the residual stream updates induced by counter-factual contexts into radial (norm-based) and angular (cosine-based) components. Our empirical results reject the universality of the \"Manifold Dilution\" hypothesis, as two of the three architectures maintained stable residual norms despite exhibiting significant performance degradation on factual queries. Instead, we observed that compliance is consistently characterized by \"Orthogonal Interference,\" where the conflicting context injects a steering vector that is quasi-orthogonal to the ground-truth direction, effectively rotating the hidden state representation. This suggests that models do not \"unlearn\" or suppress the magnitude of internal truths but rather employ a mechanism of geometric displacement to bypass the correct unembedding vector, effectively simulating adoption while preserving the original structural magnitude. These findings challenge scalar confidence metrics for detecting hallucinations and underscore the necessity of vectorial monitoring to distinguish between genuine knowledge integration and superficial in-context mimicry.", "AI": {"tldr": "This paper examines why large language models prioritize conflicting context over stored knowledge, identifying 'Orthogonal Interference' as the cause rather than 'Manifold Dilution.'", "motivation": "To understand how large language models resolve conflicts between in-context information and stored knowledge, and whether it results from magnitude dilution or geometric alteration.", "method": "Layer-wise geometric analysis decomposing residual updates into radial and angular components across three LLM architectures.", "result": "The 'Manifold Dilution' hypothesis was rejected as two models maintained stable residual norms despite degraded performance. 'Orthogonal Interference' was found to drive compliance via geometric displacement.", "conclusion": "LLMs bypass correct information through geometric displacement without reducing magnitude, suggesting vectorial monitoring is needed for better distinction between true knowledge integration and mimicry."}}
{"id": "2602.05801", "pdf": "https://arxiv.org/pdf/2602.05801", "abs": "https://arxiv.org/abs/2602.05801", "authors": ["Peter Robinson", "Ming Ming Tan"], "title": "The Quantum Message Complexity of Distributed Wake-Up with Advice", "categories": ["quant-ph", "cs.DC", "cs.DS"], "comment": null, "summary": "We consider the distributed wake-up problem with advice, where nodes are equipped with initial knowledge about the network at large. After the adversary awakens a subset of nodes, an oracle computes a bit string (``the advice'') for each node, and the goal is to wake up all sleeping nodes efficiently. We present the first upper and lower bounds on the message complexity for wake-up in the quantum routing model, introduced by Dufoulon, Magniez, and Pandurangan (PODC 2025). In more detail, we give a distributed advising scheme that, given $\u03b1$ bits of advice per node, wakes up all nodes with a message complexity of $O( \\sqrt{\\frac{n^3}{2^{\\max\\{\\lfloor (\u03b1-1)/2 \\rfloor},0\\}}}\\cdot\\log n )$ with high probability. Our result breaks the $\u03a9( \\frac{n^2}{2^\u03b1} )$ barrier known for the classical port numbering model in sufficiently dense graphs. To complement our algorithm, we give a lower bound on the message complexity for distributed quantum algorithms: By leveraging a lower bound result for the single-bit descriptor problem in the query complexity model, we show that wake-up has a quantum message complexity of $\u03a9( n^{3/2} )$ without advice, which holds independently of how much time we allow. In the setting where an adversary decides which nodes start the algorithm, most graph problems of interest implicitly require solving wake-up, and thus the same lower bound also holds for other fundamental problems such as single-source broadcast and spanning tree construction.", "AI": {"tldr": "This paper explores the distributed wake-up problem using quantum message-routing, evaluating both upper and lower bounds with advice bit allocation to enhance performance.", "motivation": "To establish efficient methods for solving the distributed wake-up problem using quantum algorithms and evaluate their performance against classical limitations.", "method": "Introduced a distributed advising scheme with advice bits per node and derived upper and lower bounds on message complexity for quantum distributed algorithms.", "result": "Proposed a quantum scheme achieving efficient wake-up with a better message complexity than classical bounds for dense networks while deriving a lower bound at $\u03a9(n^{3/2})$ without advice.", "conclusion": "Quantum distributed algorithms can outperform classical methods in solving the wake-up problem for dense networks, but inherent bounds still exist on their message complexity."}}
{"id": "2602.05252", "pdf": "https://arxiv.org/pdf/2602.05252", "abs": "https://arxiv.org/abs/2602.05252", "authors": ["Guangwei Zhang", "Jianing Zhu", "Cheng Qian", "Neil Gong", "Rada Mihalcea", "Zhaozhuo Xu", "Jingrui He", "Jiaqi Ma", "Yun Huang", "Chaowei Xiao", "Bo Li", "Ahmed Abbasi", "Dongwon Lee", "Heng Ji", "Denghui Zhang"], "title": "Copyright Detective: A Forensic System to Evidence LLMs Flickering Copyright Leakage Risks", "categories": ["cs.CL"], "comment": null, "summary": "We present Copyright Detective, the first interactive forensic system for detecting, analyzing, and visualizing potential copyright risks in LLM outputs. The system treats copyright infringement versus compliance as an evidence discovery process rather than a static classification task due to the complex nature of copyright law. It integrates multiple detection paradigms, including content recall testing, paraphrase-level similarity analysis, persuasive jailbreak probing, and unlearning verification, within a unified and extensible framework. Through interactive prompting, response collection, and iterative workflows, our system enables systematic auditing of verbatim memorization and paraphrase-level leakage, supporting responsible deployment and transparent evaluation of LLM copyright risks even with black-box access.", "AI": {"tldr": "This paper introduces Copyright Detective, an interactive forensic system for assessing copyright risks in LLM outputs through a multi-faceted analysis framework.", "motivation": "Current LLMs may inadvertently infringe on copyright due to memorized or paraphrased content. This paper aims to develop a tool for systematically evaluating such risks to ensure compliance and responsible deployment.", "method": "The system employs methods such as content recall testing, paraphrase similarity analysis, jailbreak probing, and unlearning verification. These techniques are unified into an interactive framework with prompting workflows.", "result": "Copyright Detective enables detailed auditing of LLMs, uncovering verbatim and paraphrased content leakage even when access is limited to black-box testing.", "conclusion": "It facilitates better understanding and mitigation of copyright risks within LLMs, aiding their deployment within ethical and legal boundaries."}}
{"id": "2602.05523", "pdf": "https://arxiv.org/pdf/2602.05523", "abs": "https://arxiv.org/abs/2602.05523", "authors": ["Shahin Honarvar", "Amber Gorzynski", "James Lee-Jones", "Harry Coppock", "Marek Rei", "Joseph Ryan", "Alastair F. Donaldson"], "title": "Capture the Flags: Family-Based Evaluation of Agentic LLMs via Semantics-Preserving Transformations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Agentic large language models (LLMs) are increasingly evaluated on cybersecurity tasks using capture-the-flag (CTF) benchmarks. However, existing pointwise benchmarks have limited ability to shed light on the robustness and generalisation abilities of agents across alternative versions of the source code. We introduce CTF challenge families, whereby a single CTF is used as the basis for generating a family of semantically-equivalent challenges via semantics-preserving program transformations. This enables controlled evaluation of agent robustness to source code transformations while keeping the underlying exploit strategy fixed. We introduce a new tool, Evolve-CTF, that generates CTF families from Python challenges using a range of transformations. Using Evolve-CTF to derive families from Cybench and Intercode challenges, we evaluate 13 agentic LLM configurations with tool access. We find that models are remarkably robust to intrusive renaming and code insertion-based transformations, but that composed transformations and deeper obfuscation affect performance by requiring more sophisticated use of tools. We also find that enabling explicit reasoning has little effect on solution success rates across challenge families. Our work contributes a valuable technique and tool for future LLM evaluations, and a large dataset characterising the capabilities of current state-of-the-art models in this domain.", "AI": {"tldr": "The paper introduces a novel evaluation method for large language models (LLMs) using semantically equivalent families of capture-the-flag (CTF) cybersecurity challenges, generated through program transformations.", "motivation": "Pointwise benchmarks fail to evaluate the robustness and generalisation abilities of LLMs across different versions of the same source code.", "method": "A new tool, Evolve-CTF, is developed to create CTF families through semantics-preserving program transformations, enabling controlled robustness tests.", "result": "13 LLM configurations were evaluated; models showed robustness to simpler transformations but struggled with composed and deeper obfuscations, while explicit reasoning added little benefit.", "conclusion": "Evolve-CTF provides a valuable technique for evaluating LLMs' generalisation and robustness, along with insights into current models' capabilities."}}
{"id": "2602.05513", "pdf": "https://arxiv.org/pdf/2602.05513", "abs": "https://arxiv.org/abs/2602.05513", "authors": ["Xukun Li", "Yu Sun", "Lei Zhang", "Bosheng Huang", "Yibo Peng", "Yuan Meng", "Haojun Jiang", "Shaoxuan Xie", "Guacai Yao", "Alois Knoll", "Zhenshan Bing", "Xinlong Wang", "Zhenguo Sun"], "title": "DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter", "categories": ["cs.RO", "cs.AI"], "comment": "17 pages, 8 figures", "summary": "Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected via cross attention, while a lightweight LoRA-based adapter is used to efficiently fine-tune the pretrained policy. DECO is also accompanied by DECO-50, a bimanual dexterous manipulation dataset with tactile sensing, consisting of 4 scenarios and 28 sub-tasks, covering more than 50 hours of data, approximately 5 million frames, and 8,000 successful trajectories.", "AI": {"tldr": "DECO is a framework for dexterous manipulation combining multimodal conditioning and adaptive techniques with a new dataset named DECO-50.", "motivation": "The paper aims to improve dexterous manipulation tasks by utilizing multimodal inputs like vision, action, tactile signals, and proprioceptive states efficiently.", "method": "DECO employs a DiT-based policy integrating self attention and adaptive layer normalization for multimodal inputs. It includes fine-tuning via LoRA-based adapters and introduces tactile and proprioceptive signal conditioning.", "result": "A comprehensive dataset called DECO-50 is provided, featuring bimanual dexterous manipulation, tactile sensing, and various tasks containing 5 million frames and 8,000 successful trajectories.", "conclusion": "DECO framework and the DECO-50 dataset represent advancements in dexterous manipulation by effectively managing multimodal inputs with a novel policy design."}}
{"id": "2602.05215", "pdf": "https://arxiv.org/pdf/2602.05215", "abs": "https://arxiv.org/abs/2602.05215", "authors": ["Jiahao Nie", "Wenbin An", "Gongjie Zhang", "Yicheng Xu", "Yap-Peng Tan", "Alex C. Kot", "Shijian Lu"], "title": "E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent advances in Video Large Language Models (Vid-LLMs), Temporal Video Grounding (TVG), which aims to precisely localize time segments corresponding to query events, remains a significant challenge. Existing methods often match start and end frames by comparing frame features with two separate tokens, relying heavily on exact timestamps. However, this approach fails to capture the event's semantic continuity and integrity, leading to ambiguities. To address this, we propose E.M.Ground, a novel Vid-LLM for TVG that focuses on holistic and coherent event perception. E.M.Ground introduces three key innovations: (i) a special <event> token that aggregates information from all frames of a query event, preserving semantic continuity for accurate event matching; (ii) Savitzky-Golay smoothing to reduce noise in token-to-frame similarities across timestamps, improving prediction accuracy; (iii) multi-grained frame feature aggregation to enhance matching reliability and temporal understanding, compensating for compression-induced information loss. Extensive experiments on benchmark datasets show that E.M.Ground consistently outperforms state-of-the-art Vid-LLMs by significant margins.", "AI": {"tldr": "The paper introduces E.M.Ground, a Video Large Language Model designed to improve the performance of Temporal Video Grounding (TVG) tasks by focusing on semantic continuity, noise reduction, and multi-grained feature aggregation.", "motivation": "Temporal Video Grounding faces challenges in accurately locating time segments of events due to ambiguities arising from existing methods that rely heavily on exact timestamps and fail to capture the semantic continuity of events.", "method": "E.M.Ground introduces three innovations: (i) an <event> token for preserving semantic continuity, (ii) Savitzky-Golay smoothing for noise reduction in similarities, and (iii) multi-grained feature aggregation to compensate for information loss due to compression.", "result": "Experiments demonstrate that E.M.Ground significantly outperforms state-of-the-art methods on benchmark datasets for Temporal Video Grounding tasks.", "conclusion": "E.M.Ground successfully addresses issues in TVG by enabling holistic event perception and improving prediction accuracy, offering a notable improvement over existing Vid-LLM methods."}}
{"id": "2602.05192", "pdf": "https://arxiv.org/pdf/2602.05192", "abs": "https://arxiv.org/abs/2602.05192", "authors": ["Mohammed Abouzaid", "Andrew J. Blumberg", "Martin Hairer", "Joe Kileel", "Tamara G. Kolda", "Paul D. Nelson", "Daniel Spielman", "Nikhil Srivastava", "Rachel Ward", "Shmuel Weinberger", "Lauren Williams"], "title": "First Proof", "categories": ["cs.AI", "math.AG", "math.CO", "math.GT", "math.HO", "math.RA"], "comment": "9 pages, including the statements of the ten questions", "summary": "To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of the questions but will remain encrypted for a short time.", "AI": {"tldr": "The paper evaluates current AI's capability to tackle advanced research-level math questions by publishing ten such examples.", "motivation": "To determine how well AI systems can handle naturally arising complex mathematics research questions.", "method": "Authors designed and selected 10 research-level mathematics questions and temporarily encrypted answers for objective assessment.", "result": "The questions are now shared openly to assess AI's competence, and answers remain encrypted.", "conclusion": "The evaluation can provide insights into the capabilities and limitations of current AI in solving research-level mathematics problems."}}
{"id": "2602.04919", "pdf": "https://arxiv.org/pdf/2602.04919", "abs": "https://arxiv.org/abs/2602.04919", "authors": ["Yiran Zhao", "Shengyang Zhou", "Zijian Wu", "Tongyan Hu", "Yuhui Xu", "Rengan Dou", "Kenji Kawaguchi", "Shafiq Joty", "Junnan Li", "Michael Qizhe Shieh"], "title": "Gradually Compacting Large Language Models for Reasoning Like a Boiling Frog", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, but their substantial size often demands significant computational resources. To reduce resource consumption and accelerate inference, it is essential to eliminate redundant parameters without compromising performance. However, conventional pruning methods that directly remove such parameters often lead to a dramatic drop in model performance in reasoning tasks, and require extensive post-training to recover the lost capabilities. In this work, we propose a gradual compacting method that divides the compression process into multiple fine-grained iterations, applying a Prune-Tune Loop (PTL) at each stage to incrementally reduce model size while restoring performance with finetuning. This iterative approach-reminiscent of the \"boiling frog\" effect-enables the model to be progressively compressed without abrupt performance loss. Experimental results show that PTL can compress LLMs to nearly half their original size with only lightweight post-training, while maintaining performance comparable to the original model on reasoning tasks. Moreover, PTL is flexible and can be applied to various pruning strategies, such as neuron pruning and layer pruning, as well as different post-training methods, including continual pre-training and reinforcement learning. Additionally, experimental results confirm the effectiveness of PTL on a variety of tasks beyond mathematical reasoning, such as code generation, demonstrating its broad applicability.", "AI": {"tldr": "The paper introduces a method called Prune-Tune Loop (PTL) that incrementally compresses Large Language Models (LLMs) without significant performance loss.", "motivation": "The motivation is to reduce computational resource requirements of LLMs by eliminating redundant parameters without sacrificing their reasoning capabilities.", "method": "The method involves gradual compression using a Prune-Tune Loop (PTL), where pruning and finetuning operations are iteratively applied to reduce model size progressively without abrupt performance degradation.", "result": "PTL effectively compresses models to nearly half their original size while maintaining reasoning performance, with experiments showing applicability across various tasks like code generation.", "conclusion": "PTL demonstrates potential as a flexible and broadly applicable method for efficient LLM compression, ensuring performance retention and reduced computational demands."}}
{"id": "2602.05258", "pdf": "https://arxiv.org/pdf/2602.05258", "abs": "https://arxiv.org/abs/2602.05258", "authors": ["Haoran Li", "Sucheng Ren", "Alan Yuille", "Feng Wang"], "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.", "AI": {"tldr": "CoPE introduces soft clipping to improve Rotary Positional Embedding (RoPE) performance and scales up Large Language Models to 256k context length, outperforming existing methods.", "motivation": "The motivation is to address challenges in adapting RoPE for longer context scaling, specifically tackling out-of-distribution issues and enhancing semantic modeling in attention scores.", "method": "CoPE employs a soft clipping approach targeting low-frequency components of RoPE, eliminating outliers, refining semantic signals, and preventing spectral leakage.", "result": "Experiments show CoPE achieves notable gains in performance across extended context lengths, up to 256k, establishing it as a new state-of-the-art.", "conclusion": "Soft clipping via CoPE unifies OOD mitigation and semantic modeling goals, leading to scalable improvements in RoPE for Large Language Models and reinforcing its theoretical foundations."}}
{"id": "2602.05550", "pdf": "https://arxiv.org/pdf/2602.05550", "abs": "https://arxiv.org/abs/2602.05550", "authors": ["Yulong He", "Artem Ermakov", "Sergey Kovalchuk", "Artem Aliev", "Dmitry Shalymov"], "title": "ArkTS-CodeSearch: A Open-Source ArkTS Dataset for Code Retrieval", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "ArkTS is a core programming language in the OpenHarmony ecosystem, yet research on ArkTS code intelligence is hindered by the lack of public datasets and evaluation benchmarks. This paper presents a large-scale ArkTS dataset constructed from open-source repositories, targeting code retrieval and code evaluation tasks. We design a single-search task, where natural language comments are used to retrieve corresponding ArkTS functions. ArkTS repositories are crawled from GitHub and Gitee, and comment-function pairs are extracted using tree-sitter-arkts, followed by cross-platform deduplication and statistical analysis of ArkTS function types. We further evaluate all existing open-source code embedding models on the single-search task and perform fine-tuning using both ArkTS and TypeScript training datasets, resulting in a high-performing model for ArkTS code understanding. This work establishes the first systematic benchmark for ArkTS code retrieval. Both the dataset and our fine-tuned model will be released publicly and are available at https://huggingface.co/hreyulog/embedinggemma_arkts and https://huggingface.co/datasets/hreyulog/arkts-code-docstring,establishing the first systematic benchmark for ArkTS code retrieval.", "AI": {"tldr": "The paper introduces a large-scale ArkTS dataset for code retrieval and evaluation, including a single-search task using natural language comments to retrieve ArkTS functions. It establishes a systematic benchmark and provides a fine-tuned model for ArkTS code understanding.", "motivation": "The lack of public datasets and evaluation benchmarks for ArkTS code intelligence in the OpenHarmony ecosystem motivated the authors to construct an accessible dataset and facilitate research in this field.", "method": "The authors compiled ArkTS repositories from GitHub and Gitee, extracted comment-function pairs with tree-sitter-arkts, performed deduplication, analyzed ArkTS function types, and evaluated open-source code embedding models' performance on single-search tasks.", "result": "A high-performing model for ArkTS code understanding was obtained by fine-tuning existing code embedding models using ArkTS and TypeScript training datasets. The first systematic benchmark for ArkTS code retrieval was established.", "conclusion": "The authors have successfully created a valuable resource for ArkTS code retrieval tasks, consisting of a dataset, fine-tuned model, and systematic benchmark to advance research in ArkTS code intelligence."}}
{"id": "2602.05516", "pdf": "https://arxiv.org/pdf/2602.05516", "abs": "https://arxiv.org/abs/2602.05516", "authors": ["Runxiao Liu", "Pengda Mao", "Xiangli Le", "Shuang Gu", "Yapeng Chen", "Quan Quan"], "title": "Virtual-Tube-Based Cooperative Transport Control for Multi-UAV Systems in Constrained Environments", "categories": ["cs.RO"], "comment": "10 pages, 8 figures", "summary": "This paper proposes a novel control framework for cooperative transportation of cable-suspended loads by multiple unmanned aerial vehicles (UAVs) operating in constrained environments. Leveraging virtual tube theory and principles from dissipative systems theory, the framework facilitates efficient multi-UAV collaboration for navigating obstacle-rich areas. The proposed framework offers several key advantages. (1) It achieves tension distribution and coordinated transportation within the UAV-cable-load system with low computational overhead, dynamically adapting UAV configurations based on obstacle layouts to facilitate efficient navigation. (2) By integrating dissipative systems theory, the framework ensures high stability and robustness, essential for complex multi-UAV operations. The effectiveness of the proposed approach is validated through extensive simulations, demonstrating its scalability for large-scale multi-UAV systems. Furthermore, the method is experimentally validated in outdoor scenarios, showcasing its practical feasibility and robustness under real-world conditions.", "AI": {"tldr": "This paper presents a control framework for UAVs collaboratively transporting cable-suspended loads in constrained, obstacle-rich environments, validated via both simulations and real-world tests.", "motivation": "To enable efficient and stable cooperative transportation by multiple UAVs in constrained, obstacle-filled areas, addressing computational and adaptability challenges.", "method": "A novel framework leverages virtual tube theory and dissipative systems theory to achieve low-overhead tension distribution, stable UAV coordination, and dynamic adaptation to obstacles.", "result": "Both simulations and outdoor experiments demonstrated the framework\u2019s scalability, feasibility, and robustness in supporting large-scale multi-UAV operations.", "conclusion": "The proposed framework effectively facilitates scalable, robust, and practical multi-UAV cooperative transportation in constrained environments."}}
{"id": "2602.05217", "pdf": "https://arxiv.org/pdf/2602.05217", "abs": "https://arxiv.org/abs/2602.05217", "authors": ["Jiahao Nie", "Guanqiao Fu", "Wenbin An", "Yap-Peng Tan", "Alex C. Kot", "Shijian Lu"], "title": "Cross-Domain Few-Shot Segmentation via Multi-view Progressive Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Cross-Domain Few-Shot Segmentation aims to segment categories in data-scarce domains conditioned on a few exemplars. Typical methods first establish few-shot capability in a large-scale source domain and then adapt it to target domains. However, due to the limited quantity and diversity of target samples, existing methods still exhibit constrained performance. Moreover, the source-trained model's initially weak few-shot capability in target domains, coupled with substantial domain gaps, severely hinders the effective utilization of target samples and further impedes adaptation. To this end, we propose Multi-view Progressive Adaptation, which progressively adapts few-shot capability to target domains from both data and strategy perspectives. (i) From the data perspective, we introduce Hybrid Progressive Augmentation, which progressively generates more diverse and complex views through cumulative strong augmentations, thereby creating increasingly challenging learning scenarios. (ii) From the strategy perspective, we design Dual-chain Multi-view Prediction, which fully leverages these progressively complex views through sequential and parallel learning paths under extensive supervision. By jointly enforcing prediction consistency across diverse and complex views, MPA achieves both robust and accurate adaptation to target domains. Extensive experiments demonstrate that MPA effectively adapts few-shot capability to target domains, outperforming state-of-the-art methods by a large margin (+7.0%).", "AI": {"tldr": "The paper introduces a Multi-view Progressive Adaptation (MPA) approach for Cross-Domain Few-Shot Segmentation to enhance segmentation in data-scarce domains.", "motivation": "Address the limited diversity and performance constraints of target domain samples, and improve weak few-shot adaptation due to domain gaps in existing methods.", "method": "Proposes Hybrid Progressive Augmentation (increasing challenge through cumulative augmentations) and Dual-chain Multi-view Prediction (enhancing learning consistency through sequential and parallel paths).", "result": "Extensive experiments show that the proposed MPA achieves robust adaptation, outperforming state-of-the-art methods by +7.0%.", "conclusion": "MPA successfully enhances few-shot segmentation performance in target domains by progressively adapting through diverse data and advanced learning strategies."}}
{"id": "2602.05195", "pdf": "https://arxiv.org/pdf/2602.05195", "abs": "https://arxiv.org/abs/2602.05195", "authors": ["Fengxian Chen", "Zhilong Tao", "Jiaxuan Li", "Yunlong Li", "Qingguo Zhou"], "title": "Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \\textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.", "AI": {"tldr": "This paper addresses challenges in retrieval-augmented generation (RAG) for question answering using multiple heterogeneous knowledge bases (KBs), focusing on Chinese Tibetan medicine and introduces methods to improve authoritative retrieval and cross-KB evidence integration.", "motivation": "Domain settings with multiple KBs often struggle with density-driven retrieval biases, especially when less authoritative but dense sources dominate over more authoritative evidence. The study focuses on improving accuracy and traceability in such cases, motivated by challenges specific to Chinese Tibetan medicine.", "method": "The paper proposes two methods: DAKS for KB routing and controlled retrieval prioritizing authoritative sources, and an alignment graph for enhancing cross-KB evidence fusion. A benchmark covering single and cross-KB queries is used to evaluate effectiveness.", "result": "The proposed system shows gains in retrieval routing quality and cross-KB evidence integration, achieving strong faithfulness. It records improvements in metrics like CrossEv@5, evidence traceability, and citation correctness.", "conclusion": "Through advancements in KB routing and evidence alignment, the paper successfully tackles challenges in handling heterogeneous KBs for grounded question answering, demonstrating scalability and quality improvements in the Chinese Tibetan medicine domain."}}
{"id": "2602.04895", "pdf": "https://arxiv.org/pdf/2602.04895", "abs": "https://arxiv.org/abs/2602.04895", "authors": ["Cl\u00e9ment Pierquin", "Aur\u00e9lien Bellet", "Marc Tommasi", "Matthieu Boussard"], "title": "Privacy Amplification Persists under Unlimited Synthetic Data Release", "categories": ["cs.CR", "cs.DS", "cs.LG", "stat.ML"], "comment": null, "summary": "We study privacy amplification by synthetic data release, a phenomenon in which differential privacy guarantees are improved by releasing only synthetic data rather than the private generative model itself. Recent work by Pierquin et al. (2025) established the first formal amplification guarantees for a linear generator, but they apply only in asymptotic regimes where the model dimension far exceeds the number of released synthetic records, limiting their practical relevance. In this work, we show a surprising result: under a bounded-parameter assumption, privacy amplification persists even when releasing an unbounded number of synthetic records, thereby improving upon the bounds of Pierquin et al. (2025). Our analysis provides structural insights that may guide the development of tighter privacy guarantees for more complex release mechanisms.", "AI": {"tldr": "The paper demonstrates that privacy amplification using synthetic data exists even when releasing unlimited synthetic records under specific assumptions, improving prior work.", "motivation": "To enhance privacy guarantees using synthetic data release instead of directly sharing private generative models, addressing limitations in existing approaches.", "method": "The paper assumes bounded parameters and provides an analytical framework to prove privacy amplification even with unbounded synthetic data release.", "result": "Improves upon previous privacy bounds by showing amplification remains valid in unbounded synthetic record release scenarios, under certain assumptions.", "conclusion": "The findings provide insights for developing better privacy guarantees in complex synthetic data mechanisms."}}
{"id": "2602.04920", "pdf": "https://arxiv.org/pdf/2602.04920", "abs": "https://arxiv.org/abs/2602.04920", "authors": ["Ronghao Lin", "Qiaolin He", "Sijie Mai", "Ying Zeng", "Aolin Xiong", "Li Huang", "Yap-Peng Tan", "Haifeng Hu"], "title": "CyIN: Cyclic Informative Latent Space for Bridging Complete and Incomplete Multimodal Learning", "categories": ["cs.LG", "cs.SD"], "comment": "Accepted by NeurIPS 2025", "summary": "Multimodal machine learning, mimicking the human brain's ability to integrate various modalities has seen rapid growth. Most previous multimodal models are trained on perfectly paired multimodal input to reach optimal performance. In real-world deployments, however, the presence of modality is highly variable and unpredictable, causing the pre-trained models in suffering significant performance drops and fail to remain robust with dynamic missing modalities circumstances. In this paper, we present a novel Cyclic INformative Learning framework (CyIN) to bridge the gap between complete and incomplete multimodal learning. Specifically, we firstly build an informative latent space by adopting token- and label-level Information Bottleneck (IB) cyclically among various modalities. Capturing task-related features with variational approximation, the informative bottleneck latents are purified for more efficient cross-modal interaction and multimodal fusion. Moreover, to supplement the missing information caused by incomplete multimodal input, we propose cross-modal cyclic translation by reconstruct the missing modalities with the remained ones through forward and reverse propagation process. With the help of the extracted and reconstructed informative latents, CyIN succeeds in jointly optimizing complete and incomplete multimodal learning in one unified model. Extensive experiments on 4 multimodal datasets demonstrate the superior performance of our method in both complete and diverse incomplete scenarios.", "AI": {"tldr": "The paper introduces CyIN, a framework for handling multimodal machine learning with missing data, by building an informative latent space and reconstructing information through cyclic translation.", "motivation": "To address the issue of significant performance drops in pre-trained multimodal models when faced with real-world scenarios involving incomplete or missing modalities.", "method": "The authors propose CyIN, which employs token- and label-level Information Bottleneck (IB) to create a task-related latent space, and uses cross-modal cyclic translation to reconstruct missing modalities. This enables simultaneous optimization for both complete and incomplete multimodal learning.", "result": "The CyIN framework demonstrates superior performance on 4 multimodal datasets, handling both complete and diverse incomplete input scenarios effectively.", "conclusion": "CyIN successfully enhances the robustness and adaptability of multimodal machine learning models in dynamic and real-world incomplete modality settings."}}
{"id": "2602.05261", "pdf": "https://arxiv.org/pdf/2602.05261", "abs": "https://arxiv.org/abs/2602.05261", "authors": ["Fanfan Liu", "Youyang Yin", "Peng Shi", "Siqi Yang", "Zhixiong Zeng", "Haibo Qiu"], "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR", "categories": ["cs.CL"], "comment": null, "summary": "Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.", "AI": {"tldr": "The study analyzes reinforcement learning with verifiable rewards (RLVR) highlighting response length changes in training and proposes the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm, which addresses response length bias and shows superior performance in reasoning tasks.", "motivation": "The motivation behind the study is to understand and address variations in response length during RLVR training, which impacts reasoning capabilities in large language models (LLMs) and vision-language models (VLMs).", "method": "The paper conducts theoretical analyses of mainstream RLVR algorithms, proposes the LUSPO algorithm to remove response length bias in GSPO, and validates the approach through extensive experimentation.", "result": "Results indicate LUSPO resolves response length bias while achieving state-of-the-art performance in both mathematical and multimodal reasoning benchmarks when compared to GRPO and GSPO.", "conclusion": "LUSPO, by addressing response length collapse, emerges as a superior optimization method for enhancing reasoning accuracy in both LLMs and VLMs, validated through extensive benchmarks."}}
{"id": "2602.05703", "pdf": "https://arxiv.org/pdf/2602.05703", "abs": "https://arxiv.org/abs/2602.05703", "authors": ["Tom\u00e1\u0161 Brablec", "Tom\u00e1\u0161 Dac\u00edk", "Tom\u00e1\u0161 Vojnar"], "title": "SEAL: Symbolic Execution with Separation Logic (Competition Contribution)", "categories": ["cs.SE"], "comment": "4 pages, accepted to SV-COMP 2026", "summary": "SEAL is a static analyser for the verification of programs that manipulate unbounded linked data structures. It is based on separation logic to represent abstract memory states and, unlike other separation-logic-based approaches, it employs a general-purpose separation logic solver Astral for satisfiability and entailment checking, which itself is based on translation to SMT. This design results in a modular architecture intended to be easier to extend and to combine with reasoning in other theories. Although still a prototype, SEAL achieved competitive results in the LinkedLists base category and was one of only four analysers capable of verifying programs with unbounded lists. We believe that the tool's extensibility, combined with further development, can lead to significant improvements in future competitions.", "AI": {"tldr": "SEAL is a static tool for verifying programs using unbounded linked data structures, leveraging separation logic and SMT-backed solver Astral.", "motivation": "To improve verification of programs with linked data structures and address limitations in current separation-logic-based approaches.", "method": "Employs separation logic for memory state representation and uses Astral, an SMT translation-based solver, for satisfiability and entailment checking.", "result": "SEAL achieved competitive results in a specific LinkedLists category, being among four tools capable of verifying unbounded list programs.", "conclusion": "SEAL's modular design and extensibility could lead to better performance with further refinement and development in future competitions."}}
{"id": "2602.05552", "pdf": "https://arxiv.org/pdf/2602.05552", "abs": "https://arxiv.org/abs/2602.05552", "authors": ["Bessie Dominguez-Dager", "Sergio Suescun-Ferrandiz", "Felix Escalona", "Francisco Gomez-Donoso", "Miguel Cazorla"], "title": "VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.", "AI": {"tldr": "VLN-Pilot is a framework using Vision-and-Language Models (VLLMs) as pilots for drones, enabling autonomous indoor navigation guided by natural language.", "motivation": "To address the challenges of indoor drone navigation in GPS-denied environments by integrating natural language interpretation and visual perception for autonomous operation.", "method": "The framework uses VLLMs to understand free-form language instructions, ground them in visual data, and execute drone navigation by reasoning about spatial relationships, avoiding obstacles, and dynamically reacting to events.", "result": "Experimental validation showed the framework's high success rate on complex tasks, such as long-horizon navigation with multiple targets, in a custom simulation benchmark.", "conclusion": "VLN-Pilot demonstrates the potential to replace human operators for indoor drones with an intelligent, language-guided system, reducing operator workload and enhancing safety and mission efficiency."}}
{"id": "2602.05218", "pdf": "https://arxiv.org/pdf/2602.05218", "abs": "https://arxiv.org/abs/2602.05218", "authors": ["Jiahao Nie", "Yun Xing", "Wenbin An", "Qingsong Zhao", "Jiawei Shao", "Yap-Peng Tan", "Alex C. Kot", "Shijian Lu", "Xuelong Li"], "title": "Boosting SAM for Cross-Domain Few-Shot Segmentation via Conditional Point Sparsification", "categories": ["cs.CV"], "comment": null, "summary": "Motivated by the success of the Segment Anything Model (SAM) in promptable segmentation, recent studies leverage SAM to develop training-free solutions for few-shot segmentation, which aims to predict object masks in the target image based on a few reference exemplars. These SAM-based methods typically rely on point matching between reference and target images and use the matched dense points as prompts for mask prediction. However, we observe that dense points perform poorly in Cross-Domain Few-Shot Segmentation (CD-FSS), where target images are from medical or satellite domains. We attribute this issue to large domain shifts that disrupt the point-image interactions learned by SAM, and find that point density plays a crucial role under such conditions. To address this challenge, we propose Conditional Point Sparsification (CPS), a training-free approach that adaptively guides SAM interactions for cross-domain images based on reference exemplars. Leveraging ground-truth masks, the reference images provide reliable guidance for adaptively sparsifying dense matched points, enabling more accurate segmentation results. Extensive experiments demonstrate that CPS outperforms existing training-free SAM-based methods across diverse CD-FSS datasets.", "AI": {"tldr": "The paper proposes Conditional Point Sparsification (CPS), a training-free approach to enhance SAM-based few-shot segmentation in cross-domain settings like medical or satellite imaging.", "motivation": "The motivation stems from the limitations of SAM-based segmentation methods when applied to cross-domain few-shot segmentation (CD-FSS) due to large domain shifts and poor performance of dense points.", "method": "The method introduces Conditional Point Sparsification (CPS), which adaptively sparsifies dense matched points using reference exemplars with ground-truth masks to guide SAM for improved segmentation.", "result": "The CPS method outperforms existing training-free SAM-based methods on various cross-domain few-shot segmentation datasets.", "conclusion": "Conditional Point Sparsification enables superior and reliable segmentation across domains by addressing domain shift challenges without additional training."}}
{"id": "2602.05228", "pdf": "https://arxiv.org/pdf/2602.05228", "abs": "https://arxiv.org/abs/2602.05228", "authors": ["Guozhi Liu", "Weiwei Lin", "Tiansheng Huang", "Ruichao Mo", "Qi Mu", "Xiumin Wang", "Li Shen"], "title": "Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink", "categories": ["cs.AI"], "comment": null, "summary": "Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \\emph{sink divergence} for each attention head and observe that \\emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \\emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\\%, 11.25\\%, and 9.55\\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.", "AI": {"tldr": "The paper addresses the safety risks of harmful fine-tuning in language models, proposing a technique called Surgery to mitigate it.", "motivation": "To prevent harmful fine-tuning from invalidating the safety alignment of large language models.", "method": "Introduces the concept of 'sink divergence' in attention heads and utilizes a hypothesis-driven regularizer mechanism to steer fine-tuning patterns towards safer outcomes.", "result": "Surgery improves defense effectiveness significantly (5.90%, 11.25%, 9.55%) on benchmarks such as BeaverTails, HarmBench, and SorryBench.", "conclusion": "The proposed method successfully reduces harmful behavior in fine-tuned language models, offering a viable defense strategy."}}
{"id": "2602.05065", "pdf": "https://arxiv.org/pdf/2602.05065", "abs": "https://arxiv.org/abs/2602.05065", "authors": ["Yizhou Xu", "Pierfrancesco Beneventano", "Isaac Chuang", "Liu Ziyin"], "title": "Does SGD Seek Flatness or Sharpness? An Exactly Solvable Model", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "A large body of theory and empirical work hypothesizes a connection between the flatness of a neural network's loss landscape during training and its performance. However, there have been conceptually opposite pieces of evidence regarding when SGD prefers flatter or sharper solutions during training. In this work, we partially but causally clarify the flatness-seeking behavior of SGD by identifying and exactly solving an analytically solvable model that exhibits both flattening and sharpening behavior during training. In this model, the SGD training has no \\textit{a priori} preference for flatness, but only a preference for minimal gradient fluctuations. This leads to the insight that, at least within this model, it is data distribution that uniquely determines the sharpness at convergence, and that a flat minimum is preferred if and only if the noise in the labels is isotropic across all output dimensions. When the noise in the labels is anisotropic, the model instead prefers sharpness and can converge to an arbitrarily sharp solution, depending on the imbalance in the noise in the labels spectrum. We reproduce this key insight in controlled settings with different model architectures such as MLP, RNN, and transformers.", "AI": {"tldr": "This paper investigates the flatness of neural network loss landscapes during training and its relationship with stochastic gradient descent (SGD) preferences.", "motivation": "To address conflicting evidence regarding SGD's preference for flat or sharp solutions and to elucidate causality behind its flatness-seeking behaviour.", "method": "The study uses an analytically solvable model to analyze SGD preferences for flat or sharp loss landscapes and validates insights on different architectures such as MLP, RNN, and transformers.", "result": "Finds that SGD has no inherent preference for flatness, instead prioritizing minimal gradient fluctuations. Data distribution determines convergence sharpness; isotropic noise favors flatness, while anisotropic noise leads to sharp solutions.", "conclusion": "SGD's behavior regarding flatness depends on label noise, supporting that data distribution predominantly influences the sharpness or flatness of solutions during training."}}
{"id": "2602.04923", "pdf": "https://arxiv.org/pdf/2602.04923", "abs": "https://arxiv.org/abs/2602.04923", "authors": ["Sepehr Mousavi", "Siddhartha Mishra", "Laura De Lorenzis"], "title": "Imposing Boundary Conditions on Neural Operators via Learned Function Extensions", "categories": ["cs.LG"], "comment": null, "summary": "Neural operators have emerged as powerful surrogates for the solution of partial differential equations (PDEs), yet their ability to handle general, highly variable boundary conditions (BCs) remains limited. Existing approaches often fail when the solution operator exhibits strong sensitivity to boundary forcings. We propose a general framework for conditioning neural operators on complex non-homogeneous BCs through function extensions. Our key idea is to map boundary data to latent pseudo-extensions defined over the entire spatial domain, enabling any standard operator learning architecture to consume boundary information. The resulting operator, coupled with an arbitrary domain-to-domain neural operator, can learn rich dependencies on complex BCs and input domain functions at the same time. To benchmark this setting, we construct 18 challenging datasets spanning Poisson, linear elasticity, and hyperelasticity problems, with highly variable, mixed-type, component-wise, and multi-segment BCs on diverse geometries. Our approach achieves state-of-the-art accuracy, outperforming baselines by large margins, while requiring no hyperparameter tuning across datasets. Overall, our results demonstrate that learning boundary-to-domain extensions is an effective and practical strategy for imposing complex BCs in existing neural operator frameworks, enabling accurate and robust scientific machine learning models for a broader range of PDE-governed problems.", "AI": {"tldr": "This paper proposes a new framework for conditioning neural operators on complex boundary conditions through function extensions, achieving state-of-the-art accuracy across a variety of PDE problems.", "motivation": "Existing neural operator approaches struggle with general and highly variable boundary conditions, particularly when solutions are sensitive to boundary forcings.", "method": "The authors introduce a novel method to map boundary data into pseudo-extensions over the entire spatial domain, which can be integrated into standard operator learning architectures.", "result": "The framework achieves superior accuracy and robustness compared to baselines on 18 datasets involving diverse PDE problems and geometries with complex boundary conditions.", "conclusion": "This approach enables neural operators to efficiently handle complex boundary conditions, advancing scientific machine learning applications to wider PDE-governed problems."}}
{"id": "2602.05289", "pdf": "https://arxiv.org/pdf/2602.05289", "abs": "https://arxiv.org/abs/2602.05289", "authors": ["Jingru Fan", "Dewen Liu", "Yufan Dang", "Huatao Li", "Yuheng Wang", "Wei Liu", "Feiyu Duan", "Xuanwen Ding", "Shu Yao", "Lin Wu", "Ruijie Shi", "Wai-Shing Leung", "Yuan Cheng", "Zhongyu Wei", "Cheng Yang", "Chen Qian", "Zhiyuan Liu", "Maosong Sun"], "title": "Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from the ambiguity of attribution: first, the absence of a structured taxonomy of factors leaves researchers restricted to unguided adjustments; second, the lack of a unified metric fails to distinguish genuine collaboration gain from mere resource accumulation. In this paper, we advocate for a transition to design science through an integrated framework. We advocate to establish the collaboration gain metric ($\u0393$) as the scientific standard to isolate intrinsic gains from increased budgets. Leveraging $\u0393$, we propose a factor attribution paradigm to systematically identify collaboration-driving factors. To support this, we construct a systematic MAS factor library, structuring the design space into control-level presets and information-level dynamics. Ultimately, this framework facilitates the transition from blind experimentation to rigorous science, paving the way towards a true science of Collective AI.", "AI": {"tldr": "The paper critiques MAS reliance on trial-and-error, proposing a unified framework with metrics to systematically study collaboration gains and design improvements.", "motivation": "The field of Multi-Agent Systems lacks systematic methods, metrics, and taxonomy necessary for optimization and scientific analysis.", "method": "They introduce the collaboration gain metric ($\u0393$) and develop a MAS factor library to structure design space and identify collaboration-driving factors scientifically.", "result": "Their framework enables systematic identification of factors driving collaboration gains within MAS using structured metrics and taxonomy.", "conclusion": "The proposed design science framework transitions MAS from experimental adjustments to rigorous, scientifically grounded research, fostering Collective AI advancement."}}
{"id": "2602.05712", "pdf": "https://arxiv.org/pdf/2602.05712", "abs": "https://arxiv.org/abs/2602.05712", "authors": ["Lola Solovyeva", "Fernando Castor"], "title": "Towards Green AI: Decoding the Energy of LLM Inference in Software Development", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Context: AI-assisted tools are increasingly integrated into software development workflows, but their reliance on large language models (LLMs) introduces substantial computational and energy costs. Understanding and reducing the energy footprint of LLM inference is therefore essential for sustainable software development. Objective: In this study, we conduct a phase-level analysis of LLM inference energy consumption, distinguishing between the (1) prefill, where the model processes the input and builds internal representations, and (2) decoding, where output tokens are generated using the stored state. Method: We investigate six 6B-7B and four 3B-4B transformer-based models, evaluating them on code-centric benchmarks HumanEval for code generation and LongBench for code understanding. Results: Our findings show that, within both parameter groups, models exhibit distinct energy patterns across phases. Furthermore, we observed that increases in prefill cost amplify the energy cost per token during decoding, with amplifications ranging from 1.3% to 51.8% depending on the model. Lastly, three out of ten models demonstrate babbling behavior, adding excessive content to the output that unnecessarily inflates energy consumption. We implemented babbling suppression for code generation, achieving energy savings ranging from 44% to 89% without affecting generation accuracy. Conclusion: These findings show that prefill costs influence decoding, which dominates energy consumption, and that babbling suppression can yield up to 89% energy savings. Reducing inference energy therefore requires both mitigating babbling behavior and limiting impact of prefill on decoding.", "AI": {"tldr": "This paper examines energy consumption in LLM inference during prefill and decoding phases, finding that babbling suppression can save up to 89% energy.", "motivation": "With the increasing integration of LLMs in software workflows, the high computational and energy expenses demand strategies for sustainable use, especially by optimizing energy consumption.", "method": "The study evaluates 10 transformer models (3B-7B) using code benchmarks like HumanEval and LongBench, analyzing energy usage in the prefill and decoding phases while investigating babbling behavior.", "result": "Results reveal that prefill costs impact decoding energy consumption. Suppression of babbling behavior yields significant energy savings (44%-89%) without accuracy loss.", "conclusion": "To achieve energy-efficient LLM inference, it is crucial to address babbling behavior and manage the interplay between prefill and decoding phases."}}
{"id": "2602.05596", "pdf": "https://arxiv.org/pdf/2602.05596", "abs": "https://arxiv.org/abs/2602.05596", "authors": ["Hokyun Lee", "Woo-Jeong Baek", "Junhyeok Cha", "Jaeheung Park"], "title": "TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards", "categories": ["cs.RO"], "comment": "Accepted for Publication at IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "With the growing employment of learning algorithms in robotic applications, research on reinforcement learning for bipedal locomotion has become a central topic for humanoid robotics. While recently published contributions achieve high success rates in locomotion tasks, scarce attention has been devoted to the development of methods that enable to handle hardware faults that may occur during the locomotion process. However, in real-world settings, environmental disturbances or sudden occurrences of hardware faults might yield severe consequences. To address these issues, this paper presents TOLEBI (A faulT-tOlerant Learning framEwork for Bipedal locomotIon) that handles faults on the robot during operation. Specifically, joint locking, power loss and external disturbances are injected in simulation to learn fault-tolerant locomotion strategies. In addition to transferring the learned policy to the real robot via sim-to-real transfer, an online joint status module incorporated. This module enables to classify joint conditions by referring to the actual observations at runtime under real-world conditions. The validation experiments conducted both in real-world and simulation with the humanoid robot TOCABI highlight the applicability of the proposed approach. To our knowledge, this manuscript provides the first learning-based fault-tolerant framework for bipedal locomotion, thereby fostering the development of efficient learning methods in this field.", "AI": {"tldr": "The paper introduces TOLEBI, a learning-based framework for fault-tolerant bipedal locomotion that handles hardware faults during operation through simulation-based training and real-world validation.", "motivation": "To address the lack of methods for handling hardware faults and environmental disturbances in bipedal locomotion, which can lead to severe consequences in robotic systems.", "method": "Fault scenarios such as joint locking, power loss, and external disturbances were simulated to train fault-tolerant locomotion strategies. The framework also includes an online joint status module for real-time classification during operation.", "result": "Validation experiments conducted with the humanoid robot TOCABI in both simulation and real-world confirmed the effectiveness and applicability of the proposed framework.", "conclusion": "A novel fault-tolerant learning framework for bipedal locomotion was developed, marking significant progress in robust humanoid robotics and demonstrating its practical application through experiments."}}
{"id": "2602.05238", "pdf": "https://arxiv.org/pdf/2602.05238", "abs": "https://arxiv.org/abs/2602.05238", "authors": ["Boxiang Zhang", "Baijian Yang", "Xiaoming Wang", "Corey Vian"], "title": "PatchFlow: Leveraging a Flow-Based Model with Patch Features", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Die casting plays a crucial role across various industries due to its ability to craft intricate shapes with high precision and smooth surfaces. However, surface defects remain a major issue that impedes die casting quality control. Recently, computer vision techniques have been explored to automate and improve defect detection. In this work, we combine local neighbor-aware patch features with a normalizing flow model and bridge the gap between the generic pretrained feature extractor and industrial product images by introducing an adapter module to increase the efficiency and accuracy of automated anomaly detection. Compared to state-of-the-art methods, our approach reduces the error rate by 20\\% on the MVTec AD dataset, achieving an image-level AUROC of 99.28\\%. Our approach has also enhanced performance on the VisA dataset , achieving an image-level AUROC of 96.48\\%. Compared to the state-of-the-art models, this represents a 28.2\\% reduction in error. Additionally, experiments on a proprietary die casting dataset yield an accuracy of 95.77\\% for anomaly detection, without requiring any anomalous samples for training. Our method illustrates the potential of leveraging computer vision and deep learning techniques to advance inspection capabilities for the die casting industry", "AI": {"tldr": "This paper introduces an advanced computer vision method for detecting surface defects in industrial die casting, showing improvements in accuracy on several datasets.", "motivation": "Surface defects in die casting hinder quality control, necessitating more effective automated anomaly detection systems.", "method": "The method combines local neighbor-aware patch features with a normalizing flow model and employs an adapter module to bridge the gap between pretrained feature extractors and industrial product images.", "result": "The approach achieved significant improvements in accuracy and error reduction on the MVTec AD, VisA, and a proprietary die casting dataset.", "conclusion": "The proposed method demonstrates the potential for leveraging deep learning techniques to revolutionize quality control in the die casting industry, enabling more accurate and reliable anomaly detection."}}
{"id": "2602.05240", "pdf": "https://arxiv.org/pdf/2602.05240", "abs": "https://arxiv.org/abs/2602.05240", "authors": ["Patrick McGonagle", "William Farrelly", "Kevin Curran"], "title": "Explainable AI: A Combined XAI Framework for Explaining Brain Tumour Detection Models", "categories": ["cs.AI"], "comment": null, "summary": "This study explores the integration of multiple Explainable AI (XAI) techniques to enhance the interpretability of deep learning models for brain tumour detection. A custom Convolutional Neural Network (CNN) was developed and trained on the BraTS 2021 dataset, achieving 91.24% accuracy in distinguishing between tumour and non-tumour regions. This research combines Gradient-weighted Class Activation Mapping (GRAD-CAM), Layer-wise Relevance Propagation (LRP) and SHapley Additive exPlanations (SHAP) to provide comprehensive insights into the model's decision-making process. This multi-technique approach successfully identified both full and partial tumours, offering layered explanations ranging from broad regions of interest to pixel-level details. GRAD-CAM highlighted important spatial regions, LRP provided detailed pixel-level relevance and SHAP quantified feature contributions. The integrated approach effectively explained model predictions, including cases with partial tumour visibility thus showing superior explanatory power compared to individual XAI methods. This research enhances transparency and trust in AI-driven medical imaging analysis by offering a more comprehensive perspective on the model's reasoning. The study demonstrates the potential of integrated XAI techniques in improving the reliability and interpretability of AI systems in healthcare, particularly for critical tasks like brain tumour detection.", "AI": {"tldr": "The research developed a CNN achieving 91.24% accuracy for brain tumour detection and integrated XAI techniques (GRAD-CAM, LRP, SHAP) to provide interpretability for model predictions.", "motivation": "To improve the interpretability and trustworthiness of AI models in critical healthcare tasks like brain tumour detection.", "method": "The study utilized a custom CNN with high accuracy and combined multiple XAI techniques including GRAD-CAM, LRP, and SHAP to enhance understanding of model predictions.", "result": "The integrated approach successfully identified full and partial tumours, offering comprehensive explanations from spatial to pixel-level insights, outperforming individual XAI methods.", "conclusion": "Integrated XAI techniques can enhance the reliability and transparency of AI models in medical imaging, increasing their trustworthiness for practical healthcare applications."}}
{"id": "2602.05082", "pdf": "https://arxiv.org/pdf/2602.05082", "abs": "https://arxiv.org/abs/2602.05082", "authors": ["Poushali Sengupta", "Sabita Maharjan", "Frank Eliassen", "Shashi Raj Pandey", "Yan Zhang"], "title": "Reliable Explanations or Random Noise? A Reliability Metric for XAI", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "In recent years, explaining decisions made by complex machine learning models has become essential in high-stakes domains such as energy systems, healthcare, finance, and autonomous systems. However, the reliability of these explanations, namely, whether they remain stable and consistent under realistic, non-adversarial changes, remains largely unmeasured. Widely used methods such as SHAP and Integrated Gradients (IG) are well-motivated by axiomatic notions of attribution, yet their explanations can vary substantially even under system-level conditions, including small input perturbations, correlated representations, and minor model updates. Such variability undermines explanation reliability, as reliable explanations should remain consistent across equivalent input representations and small, performance-preserving model changes. We introduce the Explanation Reliability Index (ERI), a family of metrics that quantifies explanation stability under four reliability axioms: robustness to small input perturbations, consistency under feature redundancy, smoothness across model evolution, and resilience to mild distributional shifts. For each axiom, we derive formal guarantees, including Lipschitz-type bounds and temporal stability results. We further propose ERI-T, a dedicated measure of temporal reliability for sequential models, and introduce ERI-Bench, a benchmark designed to systematically stress-test explanation reliability across synthetic and real-world datasets. Experimental results reveal widespread reliability failures in popular explanation methods, showing that explanations can be unstable under realistic deployment conditions. By exposing and quantifying these instabilities, ERI enables principled assessment of explanation reliability and supports more trustworthy explainable AI (XAI) systems.", "AI": {"tldr": "The paper identifies and addresses the issue of instability in explanations produced by widely used XAI methods like SHAP and IG under realistic conditions, introducing the Explanation Reliability Index (ERI) metrics to measure and improve reliability.", "motivation": "The motivation is to address the lack of measured reliability in explanations from machine learning models, as these explanations often fail under realistic, non-adversarial conditions, jeopardizing trustworthiness in high-stakes domains.", "method": "The paper proposes the Explanation Reliability Index (ERI), a set of metrics to measure explanation stability under four reliability axioms: input robustness, redundancy consistency, smoothness through model evolution, and distributional shift resilience. Theoretical guarantees and a dedicated metric for sequence models (ERI-T) are introduced, alongside a benchmarking tool (ERI-Bench).", "result": "Experiments reveal significant reliability failures in popular explanation approaches, with metrics like ERI systematically exposing weaknesses across synthetic and real-world datasets.", "conclusion": "ERI provides a principled framework to assess and improve the reliability of XAI methods, fostering more trustworthy systems by addressing the challenges of variability in explanations."}}
{"id": "2602.04924", "pdf": "https://arxiv.org/pdf/2602.04924", "abs": "https://arxiv.org/abs/2602.04924", "authors": ["Dinh Phu Tran", "Jihoon Jeong", "Saad Wazir", "Seongah Kim", "Thao Do", "Cem Subakan", "Daeyoung Kim"], "title": "Knowing When to Answer: Adaptive Confidence Refinement for Reliable Audio-Visual Question Answering", "categories": ["cs.LG", "cs.SD"], "comment": "Technical Report", "summary": "We present a formal problem formulation for \\textit{Reliable} Audio-Visual Question Answering ($\\mathcal{R}$-AVQA), where we prefer abstention over answering incorrectly. While recent AVQA models have high accuracy, their ability to identify when they are likely wrong and their consequent abstention from answering remain underexplored areas of research. To fill this gap, we explore several approaches and then propose Adaptive Confidence Refinement (ACR), a lightweight method to further enhance the performance of $\\mathcal{R}$-AVQA. Our key insight is that the Maximum Softmax Probability (MSP) is Bayes-optimal only under strong calibration, a condition usually not met in deep neural networks, particularly in multimodal models. Instead of replacing MSP, our ACR maintains it as a primary confidence signal and applies input-adaptive residual corrections when MSP is deemed unreliable. ACR introduces two learned heads: i) a Residual Risk Head that predicts low-magnitude correctness residuals that MSP does not capture, and ii) a Confidence Gating Head to determine MSP trustworthiness. Our experiments and theoretical analysis show that ACR consistently outperforms existing methods on in- and out-of-disrtibution, and data bias settings across three different AVQA architectures, establishing a solid foundation for $\\mathcal{R}$-AVQA task. The code and checkpoints will be available upon acceptance \\href{https://github.com/PhuTran1005/R-AVQA}{at here}", "AI": {"tldr": "The paper introduces a problem formulation for Reliable Audio-Visual Question Answering (R-AVQA) with a preference for abstaining over incorrect answers. To improve confidence reliability and performance, they propose Adaptive Confidence Refinement (ACR).", "motivation": "The motivation is to address the inability of recent AVQA models to abstain when uncertain, despite their high accuracy, and ensure reliability in their outputs.", "method": "They propose Adaptive Confidence Refinement (ACR), which uses two learned components: a Residual Risk Head to predict fine-grained correctness, and a Confidence Gating Head to assess the reliability of Maximum Softmax Probability (MSP), adapting decisions based on trust levels.", "result": "ACR outperforms existing AVQA confidence measures in various settings, consistently improving correctness and reliability for both in- and out-of-distribution scenarios across multiple architectures.", "conclusion": "The introduction of ACR enhances the foundation for Reliable AVQA by significantly improving abstention mechanisms and reliability compared to existing methods."}}
{"id": "2602.05307", "pdf": "https://arxiv.org/pdf/2602.05307", "abs": "https://arxiv.org/abs/2602.05307", "authors": ["Haojin Wang", "Yike Wang", "Shangbin Feng", "Hannaneh Hajishirzi", "Yulia Tsvetkov"], "title": "MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without consistent error correction. We propose MentorCollab, an inference-time collaboration method in which an LRM selectively and sparsely guides an SLM, rather than taking over generation. At randomly sampled token positions, we probe for divergences between the two models and use a lightweight verifier to decide whether the SLM should follow a short lookahead segment from its mentor or continue on its own. Across 15 SLM--LRM pairs and 3 domains (math reasoning, general knowledge, and commonsense reasoning), our method improves performance in 12 settings, with average gains of 3.0% and up to 8.0%, while adopting only having 18.4% tokens generated by the expensive mentor model on average. We find that short segments and selective probing are sufficient for effective collaboration. Our results show that selective inference-time guidance restores large-model reasoning ability without substantial inference overhead.", "AI": {"tldr": "The paper introduces MentorCollab, a method where large reasoning models (LRMs) sparsely guide small language models (SLMs) during inference, improving multi-step reasoning while minimizing computational costs.", "motivation": "Current large reasoning models achieve strong performance but are computationally expensive, while small language models are efficient but struggle with complex reasoning. There is a need for efficient collaboration between the two to balance performance and cost.", "method": "MentorCollab introduces selective intervention, where an LRM sporadically guides the SLM by identifying divergences and using a verifier to decide if the SLM should continue independently or follow the LRM's lookahead.", "result": "MentorCollab improves performance in 12 out of 15 SLM-LRM model pairs across various reasoning domains, averaging a 3.0% improvement with only 18.4% of tokens generated by the LRM.", "conclusion": "Selective collaboration between LRMs and SLMs restores strong reasoning in the latter without imposing high inference costs, proving it is a practical solution for multi-step reasoning tasks."}}
{"id": "2602.05721", "pdf": "https://arxiv.org/pdf/2602.05721", "abs": "https://arxiv.org/abs/2602.05721", "authors": ["Bin Liu", "Yanjie Zhao", "Zhenpeng Chen", "Guoai Xu", "Haoyu Wang"], "title": "A Dual-Loop Agent Framework for Automated Vulnerability Reproduction", "categories": ["cs.SE"], "comment": null, "summary": "Automated vulnerability reproduction from CVE descriptions requires generating executable Proof-of-Concept (PoC) exploits and validating them in target environments. This process is critical in software security research and practice, yet remains time-consuming and demands specialized expertise when performed manually. While LLM agents show promise for automating this task, existing approaches often conflate exploring attack directions with fixing implementation details, which leads to unproductive debugging loops when reproduction fails. To address this, we propose Cve2PoC, an LLM-based dual-loop agent framework following a plan-execute-evaluate paradigm. The Strategic Planner analyzes vulnerability semantics and target code to produce structured attack plans. The Tactical Executor generates PoC code and validates it through progressive verification. The Adaptive Refiner evaluates execution results and routes failures to different loops: the \\textit{Tactical Loop} for code-level refinement, while the \\textit{Strategic Loop} for attack strategy replanning. This dual-loop design enables the framework to escape ineffective debugging by matching remediation to failure type. Evaluation on two benchmarks covering 617 real-world vulnerabilities demonstrates that Cve2PoC achieves 82.9\\% and 54.3\\% reproduction success rates on SecBench.js and PatchEval, respectively, outperforming the best baseline by 11.3\\% and 20.4\\%. Human evaluation confirms that generated PoCs achieve comparable code quality to human-written exploits in readability and reusability.", "AI": {"tldr": "Cve2PoC is an LLM-based dual-loop agent that automates the reproduction of vulnerability PoC exploits, achieving impressive success rates in benchmarks compared to baselines while maintaining human-like code quality.", "motivation": "Automating the reproduction of vulnerability PoCs, which is crucial yet resource-intensive and demanding specialized expertise when done manually.", "method": "Introduction of Cve2PoC, a dual-loop agent framework leveraging LLMs using a plan-execute-evaluate paradigm, with failure routing between Tactical (code-level) and Strategic (attack strategy) loops.", "result": "Cve2PoC achieved high reproduction success rates (82.9% on SecBench.js and 54.3% on PatchEval), surpassing baseline methods by notable margins, while generating human-quality PoC exploits.", "conclusion": "Cve2PoC demonstrates a strategic improvement in automating vulnerability reproduction, offering efficient, high-quality exploit generation while reducing manual effort in software security."}}
{"id": "2602.05608", "pdf": "https://arxiv.org/pdf/2602.05608", "abs": "https://arxiv.org/abs/2602.05608", "authors": ["Yufei Zhu", "Shih-Min Yang", "Martin Magnusson", "Allan Wang"], "title": "HiCrowd: Hierarchical Crowd Flow Alignment for Dense Human Environments", "categories": ["cs.RO"], "comment": "Accepted to the 2026 IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Navigating through dense human crowds remains a significant challenge for mobile robots. A key issue is the freezing robot problem, where the robot struggles to find safe motions and becomes stuck within the crowd. To address this, we propose HiCrowd, a hierarchical framework that integrates reinforcement learning (RL) with model predictive control (MPC). HiCrowd leverages surrounding pedestrian motion as guidance, enabling the robot to align with compatible crowd flows. A high-level RL policy generates a follow point to align the robot with a suitable pedestrian group, while a low-level MPC safely tracks this guidance with short horizon planning. The method combines long-term crowd aware decision making with safe short-term execution. We evaluate HiCrowd against reactive and learning-based baselines in offline setting (replaying recorded human trajectories) and online setting (human trajectories are updated to react to the robot in simulation). Experiments on a real-world dataset and a synthetic crowd dataset show that our method outperforms in navigation efficiency and safety, while reducing freezing behaviors. Our results suggest that leveraging human motion as guidance, rather than treating humans solely as dynamic obstacles, provides a powerful principle for safe and efficient robot navigation in crowds.", "AI": {"tldr": "The paper introduces HiCrowd, a hierarchical framework combining reinforcement learning (RL) and model predictive control (MPC) to address the freezing robot problem in dense human crowds.", "motivation": "To solve the freezing robot issue, where robots get stuck among human crowds due to inability to find safe motions.", "method": "HiCrowd utilizes a hierarchical approach: a high-level RL policy aligns the robot with pedestrian groups, and a low-level MPC ensures safe, short-term tracking.", "result": "HiCrowd demonstrates superior navigation efficiency and safety compared to baselines, reducing freezing instances in real-world and synthetic datasets.", "conclusion": "Human motion guidance, rather than treating humans solely as obstacles, is key for safe and efficient navigation in dense crowds."}}
{"id": "2602.05250", "pdf": "https://arxiv.org/pdf/2602.05250", "abs": "https://arxiv.org/abs/2602.05250", "authors": ["Jieyun Tan", "Shuo Liu", "Guibin Zhang", "Ziqi Li", "Jian Geng", "Lei Zhang", "Lei Cao"], "title": "Active Label Cleaning for Reliable Detection of Electron Dense Deposits in Transmission Electron Microscopy Images", "categories": ["cs.CV"], "comment": "10 pages, 6 figures", "summary": "Automated detection of electron dense deposits (EDD) in glomerular disease is hindered by the scarcity of high-quality labeled data. While crowdsourcing reduces annotation cost, it introduces label noise. We propose an active label cleaning method to efficiently denoise crowdsourced datasets. Our approach uses active learning to select the most valuable noisy samples for expert re-annotation, building high-accuracy cleaning models. A Label Selection Module leverages discrepancies between crowdsourced labels and model predictions for both sample selection and instance-level noise grading. Experiments show our method achieves 67.18% AP\\textsubscript{50} on a private dataset, an 18.83% improvement over training on noisy labels. This performance reaches 95.79% of that with full expert annotation while reducing annotation cost by 73.30%. The method provides a practical, cost-effective solution for developing reliable medical AI with limited expert resources.", "AI": {"tldr": "This paper proposes an active label cleaning method to denoise crowdsourced datasets, achieving substantial performance with reduced annotation costs.", "motivation": "Automated detection of electron dense deposits in glomerular disease is hindered by limited high-quality labeled data and label noise from crowdsourcing.", "method": "Utilizing active learning, the method selects valuable noisy samples for expert re-annotation via a Label Selection Module addressing discrepancies between crowdsourced labels and predictions.", "result": "The method reached 67.18% AP50, an 18.83% improvement over noisy labels, achieving 95.79% of full expert annotation performance while lowering annotation cost by 73.30%.", "conclusion": "The method provides a cost-effective solution for developing reliable medical AI under limited expert resources by efficiently cleaning crowdsourced datasets."}}
{"id": "2602.05249", "pdf": "https://arxiv.org/pdf/2602.05249", "abs": "https://arxiv.org/abs/2602.05249", "authors": ["Xinyi He", "Ying Yang", "Chuanjian Fu", "Sihan Guo", "Songchun Zhu", "Lifeng Fan", "Zhenliang Zhang", "Yujia Peng"], "title": "Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents", "categories": ["cs.AI"], "comment": null, "summary": "As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.", "AI": {"tldr": "The paper introduces a method for dynamically generating evaluation tasks for intelligent agents in unseen 3D environments, emphasizing the importance of scene-specific and human-like testing.", "motivation": "Current benchmarks for intelligent agents lack specificity and relevance to unseen environments, making them inadequate for real-world performance evaluation.", "method": "Proposes a dynamic in-situ task generation system (TEA) using a structured graph and two stages: interaction for agent-environment task evolution, and evolution for recombining tasks without external data.", "result": "In experiments across 10 unseen environments, 87,876 tasks were auto-generated and validated as reasonable by humans. Tests revealed State-Of-The-Art (SOTA) models excel on public benchmarks but struggle in perception, interaction, and reasoning in the new tasks.", "conclusion": "The findings stress the urgent need for in-situ evaluation tailored to new environments before deploying intelligent agents in real-world settings."}}
{"id": "2602.04925", "pdf": "https://arxiv.org/pdf/2602.04925", "abs": "https://arxiv.org/abs/2602.04925", "authors": ["Zhenning Shi", "Yijia Zhu", "Junhan Shi", "Xun Zhang", "Lei Wang", "Congcong Miao"], "title": "Internalizing LLM Reasoning via Discovery and Replay of Latent Actions", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The internalization of chain-of-thought processes into hidden states has emerged as a highly efficient paradigm for scaling test-time compute. However, existing activation steering methods rely on static control vectors that fail to adapt to the non-stationary evolution of complex reasoning tasks. To address this limitation, we propose STIR (Self-Distilled Tools for Internal Reasoning), a framework that reformulates reasoning enhancement as a dynamic latent trajectory control problem. STIR introduces a synergistic three-stage pipeline: (1) differential intrinsic action induction harvests latent reasoning successes to crystallize steering primitives; (2) sparse control basis construction curates a compact, geometrically diverse tool library; and (3) value-modulated trajectory intervention dynamically injects context-specific impulses via anchor-based gating. Extensive experiments on six arithmetic and logical benchmarks across four representative models demonstrate that STIR improves average accuracy by 1.9% to 7.5% while reducing average token consumption by up to 35% compared to vanilla decoding. These findings demonstrate that the benefits of explicit chain-of-thought can be realized through dynamic latent trajectory control, internalizing the reasoning process to bypass the explicit generation while achieving superior fidelity. Our code is available at https://github.com/sznnzs/LLM-Latent-Action.", "AI": {"tldr": "STIR reforms reasoning enhancement into a dynamic latent control framework. It introduces a three-stage method to improve reasoning in models while using fewer computational resources.", "motivation": "Current methods using static control vectors in chain-of-thought reasoning fail to adapt dynamically to complex tasks. A more adaptable framework was needed for latent trajectory control.", "method": "STIR employs a three-stage pipeline: harvesting successful latent reasoning primitives, constructing a sparse control basis, and dynamically injecting context-specific interventions for reasoning enhancement.", "result": "STIR significantly improves accuracy (1.9%-7.5%) and reduces computational costs (35% fewer tokens) across six benchmarks and four models.", "conclusion": "Dynamic latent trajectory control can realize reasoning benefits of chain-of-thought internally, bypassing explicit reasoning generation for improved efficiency and accuracy."}}
{"id": "2602.05347", "pdf": "https://arxiv.org/pdf/2602.05347", "abs": "https://arxiv.org/abs/2602.05347", "authors": ["Soma Sato", "Ryohei Sasano"], "title": "How Do Language Models Acquire Character-Level Information?", "categories": ["cs.CL"], "comment": "Accepted to EACL 2026 Main Conference", "summary": "Language models (LMs) have been reported to implicitly encode character-level information, despite not being explicitly provided during training. However, the mechanisms underlying this phenomenon remain largely unexplored. To reveal the mechanisms, we analyze how models acquire character-level knowledge by comparing LMs trained under controlled settings, such as specifying the pre-training dataset or tokenizer, with those trained under standard settings. We categorize the contributing factors into those independent of tokenization. Our analysis reveals that merge rules and orthographic constraints constitute primary factors arising from tokenization, whereas semantic associations of substrings and syntactic information function as key factors independent of tokenization.", "AI": {"tldr": "The paper explores how language models (LMs) acquire character-level knowledge and identifies key contributing factors both dependent and independent of tokenization.", "motivation": "The motivation is to uncover the mechanisms underlying how language models implicitly encode character-level information despite not being explicitly trained for it.", "method": "The authors analyze LMs by comparing models trained in controlled settings (e.g., specific datasets/tokenizers) and standard settings, categorizing factors contributing to character-level knowledge.", "result": "The study finds that merge rules and orthographic constraints are primary tokenization-dependent factors, while semantic associations and syntactic information are independent of tokenization.", "conclusion": "Understanding these mechanisms provides insights into the implicit encoding of character-level knowledge in language models, improving comprehension and development of such systems."}}
{"id": "2602.05739", "pdf": "https://arxiv.org/pdf/2602.05739", "abs": "https://arxiv.org/abs/2602.05739", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "A Bayesian Optimization-Based AutoML Framework for Non-Intrusive Load Monitoring", "categories": ["cs.SE"], "comment": null, "summary": "Non-Intrusive Load Monitoring (NILM), commonly known as energy disaggregation, aims to estimate the power consumption of individual appliances by analyzing a home's total electricity usage. This method provides a cost-effective alternative to installing dedicated smart meters for each appliance. In this paper, we introduce a novel framework that incorporates Automated Machine Learning (AutoML) into the NILM domain, utilizing Bayesian Optimization for automated model selection and hyperparameter tuning. This framework empowers domain practitioners to effectively apply machine learning techniques without requiring advanced expertise in data science or machine learning. To support further research and industry adoption, we present AutoML4NILM, a flexible and extensible open-source toolkit designed to streamline the deployment of AutoML solutions for energy disaggregation. Currently, this framework supports 11 algorithms, each with different hyperparameters; however, its flexible design allows for the extension of both the algorithms and their hyperparameters.", "AI": {"tldr": "The paper introduces a framework combining AutoML with NILM, presenting an open-source toolkit for effective energy disaggregation.", "motivation": "The paper aims to simplify and enhance the process of estimating individual home appliance energy consumption without needing specific expertise in data science or machine learning.", "method": "The proposed framework integrates Automated Machine Learning (AutoML) with Bayesian Optimization for model selection and hyperparameter tuning in NILM.", "result": "The framework supports 11 algorithms with adjustable hyperparameters and is designed to be extensible, promoting further research and practical adoption.", "conclusion": "The developed framework provides an efficient and user-friendly solution for energy disaggregation, encouraging industry and research utilization through its open-source AutoML4NILM toolkit."}}
{"id": "2602.05683", "pdf": "https://arxiv.org/pdf/2602.05683", "abs": "https://arxiv.org/abs/2602.05683", "authors": ["Chuwei Wang", "Eduardo Sebasti\u00e1n", "Amanda Prorok", "Anastasia Bizyaeva"], "title": "From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.", "AI": {"tldr": "The paper introduces a neuromorphic control framework for robotic navigation that resolves indecision without heavy computational requirements, validated in simulation and experimental platforms.", "motivation": "Robotic navigation faces challenges blending sensor-based reactive control with model-based planning, especially in situations of indecision caused by multiple goals.", "method": "A neuromorphic control framework uses dynamic neuronal populations to convert visual inputs directly into motion commands, utilizing a bifurcation mechanism for decision-making.", "result": "The approach achieves real-time autonomy with minimal computational resources and interpretable parameters, demonstrated in simulations and a quadrotor experiment.", "conclusion": "Neuromorphic controllers can effectively resolve indecision in robotic navigation while maintaining computational efficiency and adaptability to visual systems."}}
{"id": "2602.05257", "pdf": "https://arxiv.org/pdf/2602.05257", "abs": "https://arxiv.org/abs/2602.05257", "authors": ["Diya He", "Qingchen Liu", "Cong Zhang", "Jiahu Qin"], "title": "RFM-Pose:Reinforcement-Guided Flow Matching for Fast Category-Level 6D Pose Estimation", "categories": ["cs.CV", "cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Object pose estimation is a fundamental problem in computer vision and plays a critical role in virtual reality and embodied intelligence, where agents must understand and interact with objects in 3D space. Recently, score based generative models have to some extent solved the rotational symmetry ambiguity problem in category level pose estimation, but their efficiency remains limited by the high sampling cost of score-based diffusion. In this work, we propose a new framework, RFM-Pose, that accelerates category-level 6D object pose generation while actively evaluating sampled hypotheses. To improve sampling efficiency, we adopt a flow-matching generative model and generate pose candidates along an optimal transport path from a simple prior to the pose distribution. To further refine these candidates, we cast the flow-matching sampling process as a Markov decision process and apply proximal policy optimization to fine-tune the sampling policy. In particular, we interpret the flow field as a learnable policy and map an estimator to a value network, enabling joint optimization of pose generation and hypothesis scoring within a reinforcement learning framework. Experiments on the REAL275 benchmark demonstrate that RFM-Pose achieves favorable performance while significantly reducing computational cost. Moreover, similar to prior work, our approach can be readily adapted to object pose tracking and attains competitive results in this setting.", "AI": {"tldr": "The paper proposes RFM-Pose, a framework for efficient 6D object pose estimation using a flow-matching generative model and reinforcement learning, achieving competitive results with reduced computational cost.", "motivation": "The motivation is to address challenges in 6D object pose estimation, specifically improving efficiency and resolving the rotational symmetry ambiguity problem in category-level object pose estimation.", "method": "The proposed method, RFM-Pose, uses a flow-matching generative model to generate pose candidates and employs reinforcement learning (proximal policy optimization) to refine pose sampling by interpreting the flow field as a learnable policy.", "result": "Experiments on the REAL275 benchmark show that RFM-Pose achieves favorable performance with significant computational efficiency and competitive results in pose tracking.", "conclusion": "RFM-Pose introduces an efficient framework for estimating and tracking 6D object poses, effectively addressing computational challenges and refining pose estimation with reinforcement learning."}}
{"id": "2602.05266", "pdf": "https://arxiv.org/pdf/2602.05266", "abs": "https://arxiv.org/abs/2602.05266", "authors": ["Xinbo Ai"], "title": "Beyond Cosine Similarity", "categories": ["cs.AI"], "comment": "18 pages, 2 figures, 1 theorem, 3 corollaries", "summary": "Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.", "AI": {"tldr": "The paper introduces 'recos,' a novel similarity metric derived from a new mathematical bound that outperforms cosine similarity in semantic analysis tasks.", "motivation": "Cosine similarity struggles to capture nonlinear relationships inherent in real-world semantic spaces due to its reliance on the Cauchy-Schwarz inequality.", "method": "The authors derive a tighter mathematical bound for the dot product and propose the recos metric that normalizes it based on sorted vector components.", "result": "Experiments across 11 embedding models show recos achieving higher correlation with human judgments than cosine similarity on Semantic Textual Similarity benchmarks.", "conclusion": "The paper establishes recos as an improved, mathematically sound alternative to cosine similarity for analyzing complex semantic embedding spaces."}}
{"id": "2602.05225", "pdf": "https://arxiv.org/pdf/2602.05225", "abs": "https://arxiv.org/abs/2602.05225", "authors": ["L\u00e1szl\u00f3 Gy\u00f6rfi", "Pierre Humbert", "Batiste Le Bars"], "title": "Metric space valued Fr\u00e9chet regression", "categories": ["math.ST", "stat.ML"], "comment": null, "summary": "We consider the problem of estimating the Fr\u00e9chet and conditional Fr\u00e9chet mean from data taking values in separable metric spaces. Unlike Euclidean spaces, where well-established methods are available, there is no practical estimator that works universally for all metric spaces. Therefore, we introduce a computable estimator for the Fr\u00e9chet mean based on random quantization techniques and establish its universal consistency across any separable metric spaces. Additionally, we propose another estimator for the conditional Fr\u00e9chet mean, leveraging data-driven partitioning and quantization, and demonstrate its universal consistency when the output space is any Banach space.", "AI": {"tldr": "The paper introduces a new estimator for Fr\u00e9chet mean and conditional Fr\u00e9chet mean in separable metric spaces, ensuring universal consistency.", "motivation": "Current methods for estimating Fr\u00e9chet means fail to work universally across all separable metric spaces, requiring a practical and consistent method.", "method": "Proposing two new estimators: one using random quantization for the Fr\u00e9chet mean, and another leveraging data-driven partitioning for the conditional Fr\u00e9chet mean.", "result": "Both proposed estimators are shown to achieve universal consistency across separable metric spaces and Banach spaces.", "conclusion": "The introduced estimators provide a universally consistent approach for estimating Fr\u00e9chet and conditional Fr\u00e9chet means in diverse metric and Banach spaces."}}
{"id": "2602.04928", "pdf": "https://arxiv.org/pdf/2602.04928", "abs": "https://arxiv.org/abs/2602.04928", "authors": ["Ruizhe Zhong", "Jiesong Lian", "Xiaoyue Mi", "Zixiang Zhou", "Yuan Zhou", "Qinglin Lu", "Junchi Yan"], "title": "Euphonium: Steering Video Flow Matching via Process Reward Gradient Guided Stochastic Dynamics", "categories": ["cs.LG"], "comment": null, "summary": "While online Reinforcement Learning has emerged as a crucial technique for aligning flow matching models with human preferences, current approaches are hindered by inefficient exploration during training rollouts. Relying on undirected stochasticity and sparse outcome rewards, these methods struggle to discover high-reward samples, resulting in data-inefficient and slow optimization. To address these limitations, we propose Euphonium, a novel framework that steers generation via process reward gradient guided dynamics. Our key insight is to formulate the sampling process as a theoretically principled Stochastic Differential Equation that explicitly incorporates the gradient of a Process Reward Model into the flow drift. This design enables dense, step-by-step steering toward high-reward regions, advancing beyond the unguided exploration in prior works, and theoretically encompasses existing sampling methods (e.g., Flow-GRPO, DanceGRPO) as special cases. We further derive a distillation objective that internalizes the guidance signal into the flow network, eliminating inference-time dependency on the reward model. We instantiate this framework with a Dual-Reward Group Relative Policy Optimization algorithm, combining latent process rewards for efficient credit assignment with pixel-level outcome rewards for final visual fidelity. Experiments on text-to-video generation show that Euphonium achieves better alignment compared to existing methods while accelerating training convergence by 1.66x.", "AI": {"tldr": "Euphonium addresses inefficient exploration in flow matching models through a novel framework using process reward gradient guided dynamics, enabling better training efficiency and high alignment.", "motivation": "Existing online reinforcement learning methods for aligning flow matching models with human preferences are slow and data-inefficient due to sparse rewards and undirected exploration.", "method": "The proposed framework formulates sampling as a Stochastic Differential Equation incorporating the process reward gradient, enabling dense steering and providing a distillation objective to eliminate inference-time reward model dependency.", "result": "Euphonium improves alignment in text-to-video generation while accelerating training convergence by 1.66x compared to prior methods.", "conclusion": "Euphonium demonstrates theoretically grounded and practical advancements in efficiently steering flow matching models towards high-reward outcomes, improving both learning speed and final output quality."}}
{"id": "2602.05370", "pdf": "https://arxiv.org/pdf/2602.05370", "abs": "https://arxiv.org/abs/2602.05370", "authors": ["Jun Rao", "Zixiong Yu", "Xuebo Liu", "Guhan Chen", "Jing Li", "Jiansheng Wei", "Xiaojun Meng", "Min Zhang"], "title": "PACE: Defying the Scaling Hypothesis of Exploration in Iterative Alignment for Mathematical Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Iterative Direct Preference Optimization has emerged as the state-of-the-art paradigm for aligning Large Language Models on reasoning tasks. Standard implementations (DPO-R1) rely on Best-of-N sampling (e.g., $N \\ge 8$) to mine golden trajectories from the distribution tail. In this paper, we challenge this scaling hypothesis and reveal a counter-intuitive phenomenon: in mathematical reasoning, aggressive exploration yields diminishing returns and even catastrophic policy collapse. We theoretically demonstrate that scaling $N$ amplifies verifier noise and induces detrimental distribution shifts. To resolve this, we introduce \\textbf{PACE} (Proximal Alignment via Corrective Exploration), which replaces brute-force mining with a generation-based corrective strategy. Operating with a minimal budget ($2<N<3$), PACE synthesizes high-fidelity preference pairs from failed explorations. Empirical evaluations show that PACE outperforms DPO-R1 $(N=16)$ while using only about $1/5$ of the compute, demonstrating superior robustness against reward hacking and label noise.", "AI": {"tldr": "The paper challenges the scaling approach of Iterative Direct Preference Optimization (DPO-R1) in reasoning tasks, introduces PACE as an alternative strategy, and shows its superiority with lower computational cost.", "motivation": "Current methods for aligning Large Language Models in reasoning tasks rely heavily on computationally expensive exploration. The authors aim to address inefficiencies and potential issues caused by aggressive scaling in these approaches.", "method": "The authors propose PACE (Proximal Alignment via Corrective Exploration), which generates preference pairs from failed explorations using minimal sampling budgets, as opposed to aggressive sampling strategies.", "result": "Empirical results show that PACE outperforms the standard DPO-R1 approach using fewer computational resources, offering better robustness to reward hacking and label noise.", "conclusion": "PACE provides a more efficient and effective alternative to traditional aggressive exploration methods in mathematical reasoning tasks, holding potential for broader applications in resource-efficient model training."}}
{"id": "2602.05759", "pdf": "https://arxiv.org/pdf/2602.05759", "abs": "https://arxiv.org/abs/2602.05759", "authors": ["Lei Zhang"], "title": "Toward Quantum-Safe Software Engineering: A Vision for Post-Quantum Cryptography Migration", "categories": ["cs.SE", "cs.CR"], "comment": "2 pages, 1 figure, accepted by 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE'26 Poster Track)", "summary": "The quantum threat to cybersecurity has accelerated the standardization of Post-Quantum Cryptography (PQC). Migrating legacy software to these quantum-safe algorithms is not a simple library swap, but a new software engineering challenge: existing vulnerability detection, refactoring, and testing tools are not designed for PQC's probabilistic behavior, side-channel sensitivity, and complex performance trade-offs. To address these challenges, this paper outlines a vision for a new class of tools and introduces the Automated Quantum-safe Adaptation (AQuA) framework, with a three-pillar agenda for PQC-aware detection, semantic refactoring, and hybrid verification, thereby motivating Quantum-Safe Software Engineering (QSSE) as a distinct research direction.", "AI": {"tldr": "The paper highlights the challenges in adapting legacy software to post-quantum cryptography algorithms and introduces the AQuA framework to address those challenges.", "motivation": "The motivation arises from the urgent need to secure systems against quantum threats, which necessitates migrating legacy software to post-quantum cryptography\u2014a task hindered by technical challenges.", "method": "The paper introduces the Automated Quantum-safe Adaptation (AQuA) framework, focusing on PQC-aware detection, semantic refactoring, and hybrid verification.", "result": "AQuA is proposed as a vision for creating tools to handle the unique challenges of transitioning to quantum-safe algorithms, emphasizing new research directions.", "conclusion": "Quantum-Safe Software Engineering (QSSE) is identified as a distinct field of research to adapt software engineering practices for post-quantum cryptography."}}
{"id": "2602.05760", "pdf": "https://arxiv.org/pdf/2602.05760", "abs": "https://arxiv.org/abs/2602.05760", "authors": ["Andreea Tulbure", "Carmen Scheidemann", "Elias Steiner", "Marco Hutter"], "title": "Task-Oriented Robot-Human Handovers on Legged Manipulators", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted to 21st ACM/IEEE International Conference on Human-Robot Interaction (HRI) 2026", "summary": "Task-oriented handovers (TOH) are fundamental to effective human-robot collaboration, requiring robots to present objects in a way that supports the human's intended post-handover use. Existing approaches are typically based on object- or task-specific affordances, but their ability to generalize to novel scenarios is limited. To address this gap, we present AFT-Handover, a framework that integrates large language model (LLM)-driven affordance reasoning with efficient texture-based affordance transfer to achieve zero-shot, generalizable TOH. Given a novel object-task pair, the method retrieves a proxy exemplar from a database, establishes part-level correspondences via LLM reasoning, and texturizes affordances for feature-based point cloud transfer. We evaluate AFT-Handover across diverse task-object pairs, showing improved handover success rates and stronger generalization compared to baselines. In a comparative user study, our framework is significantly preferred over the current state-of-the-art, effectively reducing human regrasping before tool use. Finally, we demonstrate TOH on legged manipulators, highlighting the potential of our framework for real-world robot-human handovers.", "AI": {"tldr": "AFT-Handover introduces a framework for task-oriented human-robot handovers by combining large language models and texture-based affordance transfer for generalization.", "motivation": "Existing task-oriented handover methods lack generalizability to novel object-task pairs, limiting their application in real-world scenarios.", "method": "The paper uses LLM-driven affordance reasoning to determine object-task pair relations and efficient point cloud transfer for affordance mapping, enabling zero-shot generalization.", "result": "AFT-Handover achieves higher handover success rates and better generalization in evaluations, and is preferred in user studies compared to state-of-the-art methods.", "conclusion": "AFT-Handover improves human-robot collaboration by enabling efficient, generalizable task-oriented handovers, with implications for real-world applications."}}
{"id": "2602.05262", "pdf": "https://arxiv.org/pdf/2602.05262", "abs": "https://arxiv.org/abs/2602.05262", "authors": ["Junzhou Li", "Manqi Zhao", "Yilin Gao", "Zhiheng Yu", "Yin Li", "Dongsheng Jiang", "Li Xiao"], "title": "ReGLA: Efficient Receptive-Field Modeling with Gated Linear Attention Network", "categories": ["cs.CV"], "comment": "11 pages, 4 figures", "summary": "Balancing accuracy and latency on high-resolution images is a critical challenge for lightweight models, particularly for Transformer-based architectures that often suffer from excessive latency. To address this issue, we introduce \\textbf{ReGLA}, a series of lightweight hybrid networks, which integrates efficient convolutions for local feature extraction with ReLU-based gated linear attention for global modeling. The design incorporates three key innovations: the Efficient Large Receptive Field (ELRF) module for enhancing convolutional efficiency while preserving a large receptive field; the ReLU Gated Modulated Attention (RGMA) module for maintaining linear complexity while enhancing local feature representation; and a multi-teacher distillation strategy to boost performance on downstream tasks. Extensive experiments validate the superiority of ReGLA; particularly the ReGLA-M achieves \\textbf{80.85\\%} Top-1 accuracy on ImageNet-1K at $224px$, with only \\textbf{4.98 ms} latency at $512px$. Furthermore, ReGLA outperforms similarly scaled iFormer models in downstream tasks, achieving gains of \\textbf{3.1\\%} AP on COCO object detection and \\textbf{3.6\\%} mIoU on ADE20K semantic segmentation, establishing it as a state-of-the-art solution for high-resolution visual applications.", "AI": {"tldr": "ReGLA introduces lightweight hybrid networks combining efficient convolution with ReLU-based gated attention, showing state-of-the-art performance for high-resolution visual tasks.", "motivation": "High-resolution image processing demands balancing accuracy and latency, especially in Transformer-based models facing latency challenges.", "method": "ReGLA uses ELRF for convolution efficiency, RGMA for linear complexity attention, and multi-teacher distillation for better model performance.", "result": "ReGLA-M achieves 80.85% Top-1 accuracy on ImageNet-1K with 4.98 ms latency at 512px, outperforming iFormer in object detection and semantic segmentation.", "conclusion": "ReGLA sets new benchmarks in balancing efficiency and accuracy for lightweight, high-resolution visual applications."}}
{"id": "2602.05279", "pdf": "https://arxiv.org/pdf/2602.05279", "abs": "https://arxiv.org/abs/2602.05279", "authors": ["Kim Hammar", "Tansu Alpcan", "Emil Lupu"], "title": "Hallucination-Resistant Security Planning with a Large Language Model", "categories": ["cs.AI", "cs.CR"], "comment": "Accepted to IEEE/IFIP Network Operations and Management Symposium 2026. To appear in the conference proceedings", "summary": "Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.", "AI": {"tldr": "The paper introduces a framework using large language models (LLMs) for security management tasks like incident response planning, emphasizing reliability by addressing hallucinations and inconsistencies via iterative feedback and in-context learning.", "motivation": "The paper aims to leverage LLMs for improving efficiency in security management tasks, while addressing the challenges of their unreliability and hallucination tendencies.", "method": "The framework integrates LLMs in an iterative loop to generate, validate, and refine candidate actions. In cases of inconsistency, external feedback (e.g. from a digital twin) is collected to improve LLM output through in-context learning (ICL).", "result": "Experiments demonstrated that recovery times in an incident response scenario were reduced by up to 30% on four public datasets, outperforming existing LLM methods.", "conclusion": "The proposed framework significantly improves the effectiveness of LLMs in security management by controlling hallucination risks and enhancing reliability, marking advancements in incident response planning."}}
{"id": "2602.05230", "pdf": "https://arxiv.org/pdf/2602.05230", "abs": "https://arxiv.org/abs/2602.05230", "authors": ["Jiecheng Lu", "Xu Han", "Yan Sun", "Viresh Pati", "Yubin Kim", "Siddhartha Somani", "Shihao Yang"], "title": "ZeroS: Zero-Sum Linear Attention for Efficient Transformers", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Camera-ready version. Accepted at NeurIPS 2025", "summary": "Linear attention methods offer Transformers $O(N)$ complexity but typically underperform standard softmax attention. We identify two fundamental limitations affecting these approaches: the restriction to convex combinations that only permits additive information blending, and uniform accumulated weight bias that dilutes attention in long contexts. We propose Zero-Sum Linear Attention (ZeroS), which addresses these limitations by removing the constant zero-order term $1/t$ and reweighting the remaining zero-sum softmax residuals. This modification creates mathematically stable weights, enabling both positive and negative values and allowing a single attention layer to perform contrastive operations. While maintaining $O(N)$ complexity, ZeroS theoretically expands the set of representable functions compared to convex combinations. Empirically, it matches or exceeds standard softmax attention across various sequence modeling benchmarks.", "AI": {"tldr": "Zero-Sum Linear Attention (ZeroS) enhances linear attention mechanisms by allowing both additive and contrastive operations, exceeding the capabilities of traditional softmax attention.", "motivation": "Existing linear attention methods experience limitations due to restrictions on information blending and biases in weight distribution, leading to underperformance compared to softmax attention.", "method": "ZeroS modifies linear attention by eliminating constant zero-order terms and reweighting residuals, allowing stable weights with positive and negative values for diverse operations.", "result": "ZeroS achieves theoretical expansion in representable functions and empirically outperforms standard softmax attention in numerous benchmarks.", "conclusion": "ZeroS offers an effective enhancement to linear attention with $O(N)$ complexity, bridging performance gaps and introducing versatile representation capabilities."}}
{"id": "2602.04929", "pdf": "https://arxiv.org/pdf/2602.04929", "abs": "https://arxiv.org/abs/2602.04929", "authors": ["Junhan Kim", "Yeo Jeong Park", "Seungwoo Son", "Chungman Lee", "Ho-young Kim", "Joonyoung Kim", "Yongkweon Jeon"], "title": "TurboBoA: Faster and Exact Attention-aware Quantization without Backpropagation", "categories": ["cs.LG"], "comment": "ICLR 2026", "summary": "The rapid growth of large language models (LLMs) has heightened the importance of post-training quantization (PTQ) for reducing memory and computation costs. Among PTQ methods, GPTQ has gained significant attention for its efficiency, enabling billion-scale LLMs to be quantized within a few GPU hours. However, GPTQ's assumption of layer-wise independence leads to severe accuracy drops in low-bit regimes. Recently, BoA improved upon GPTQ by incorporating inter-layer dependencies within attention modules, but its reliance on sequential quantization across all out-channels makes it substantially less efficient. In this paper, we propose TurboBoA, a new backpropagation-free PTQ algorithm that preserves the accuracy benefits of BoA while significantly accelerating the process. The proposed TurboBoA introduces three key innovations: (i) joint quantization of multiple out-channels with a closed-form error compensation rule, which reduces sequential bottlenecks and yields more than a three-fold speedup; (ii) a correction mechanism for errors propagated from preceding quantized layers; and (iii) adaptive grid computation with coordinate descent refinement to maintain alignment during iterative updates. Extensive experiments demonstrate that TurboBoA delivers substantial acceleration over BoA while consistently improving accuracy. When combined with outlier suppression techniques, it achieves state-of-the-art results in both weight-only and weight-activation quantization. The code will be available at https://github.com/SamsungLabs/TurboBoA.", "AI": {"tldr": "TurboBoA is a fast post-training quantization (PTQ) algorithm for large language models (LLMs), improving upon BoA, achieving faster speeds and better accuracy.", "motivation": "Large language models require efficient quantization methods to reduce costs and memory usage. Current PTQ approaches like GPTQ face accuracy drops in low-bit regimes, motivating new solutions.", "method": "TurboBoA introduces joint quantization with closed-form error compensation, a correction mechanism for error propagation, and adaptive grid computation for iterative updates.", "result": "TurboBoA accelerates BoA by more than three times while improving accuracy, achieving state-of-the-art results in weight-only and weight-activation quantization with outlier suppression.", "conclusion": "TurboBoA provides a significant advancement in PTQ for LLMs, balancing speed and accuracy effectively, making it a state-of-the-art method."}}
{"id": "2602.05374", "pdf": "https://arxiv.org/pdf/2602.05374", "abs": "https://arxiv.org/abs/2602.05374", "authors": ["Chaimae Abouzahir", "Congbo Ma", "Nizar Habash", "Farah E. Shamout"], "title": "Cross-Lingual Empirical Evaluation of Large Language Models for Arabic Medical Tasks", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to HeaLing-EACL 2026", "summary": "In recent years, Large Language Models (LLMs) have become widely used in medical applications, such as clinical decision support, medical education, and medical question answering. Yet, these models are often English-centric, limiting their robustness and reliability for linguistically diverse communities. Recent work has highlighted discrepancies in performance in low-resource languages for various medical tasks, but the underlying causes remain poorly understood. In this study, we conduct a cross-lingual empirical analysis of LLM performance on Arabic and English medical question and answering. Our findings reveal a persistent language-driven performance gap that intensifies with increasing task complexity. Tokenization analysis exposes structural fragmentation in Arabic medical text, while reliability analysis suggests that model-reported confidence and explanations exhibit limited correlation with correctness. Together, these findings underscore the need for language-aware design and evaluation strategies in LLMs for medical tasks.", "AI": {"tldr": "The study evaluates the performance gap between English and Arabic in medical question answering by LLMs, highlighting structural and reliability issues.", "motivation": "To investigate the language-driven performance gap and limited understanding of LLM performance in low-resource (non-English) languages for medical tasks.", "method": "Cross-lingual analysis comparing English and Arabic performance of LLMs, tokenization analysis of Arabic medical text, and evaluation of model-reported reliability.", "result": "The study identified a consistent performance gap for Arabic, worsened by complex tasks, structural text fragmentation, and unreliable correlation between model confidence and correctness.", "conclusion": "The paper emphasizes the importance of language-aware design and evaluation strategies to improve LLM performance for non-English medical tasks."}}
{"id": "2602.05780", "pdf": "https://arxiv.org/pdf/2602.05780", "abs": "https://arxiv.org/abs/2602.05780", "authors": ["Ulrich Finkler", "Irene Manotas", "Wei Zhang", "Geert Janssen", "Octavian Popescu", "Shyam Ramji"], "title": "Automated Customization of LLMs for Enterprise Code Repositories Using Semantic Scopes", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code completion (CC) is a task frequently used by developers when working in collaboration with LLM-based programming assistants. Despite the increased performance of LLMs on public benchmarks, out of the box LLMs still have a hard time generating code that aligns with a private code repository not previously seen by the model's training data. Customizing code LLMs to a private repository provides a way to improve the model performance. In this paper we present our approach for automated LLM customization based on semantic scopes in the code. We evaluate LLMs on real industry cases with two private enterprise code repositories with two customization strategies: Retrieval-Augmented Generation (RAG) and supervised Fine-Tuning (FT). Our mechanism for ingesting the repository's data and formulating the training data pairs with semantic scopes helps models to learn the underlying patterns specific to the repository, providing more precise code to developers and helping to boost their productivity. The code completions of moderately sized customized models can be significantly better than those of uncustomized models of much larger capacity. We also include an analysis of customization on two public benchmarks and present opportunities for future work.", "AI": {"tldr": "The paper explores improving large language model (LLM) code completion by customizing models for private code repositories, using Retrieval-Augmented Generation (RAG) and Fine-Tuning (FT) strategies, which demonstrated performance improvements.", "motivation": "Out-of-the-box LLMs often struggle to generate code that aligns with unseen private repositories. Customizing LLMs for these repositories aims to address this issue and improve developers' productivity.", "method": "The proposed approach uses semantic scopes in code to create training data for customizing LLMs. Two customization strategies, Retrieval-Augmented Generation (RAG) and Fine-Tuning (FT), are evaluated on real-world industry cases.", "result": "Customized moderately-sized LLMs outperform uncustomized larger models when applied to private repositories, enhancing precision and developer productivity. Results are also validated on public benchmarks.", "conclusion": "Customizing LLMs with code scoped semantics helps improve performance and productivity for private repositories, and opens avenues for further research."}}
{"id": "2602.05791", "pdf": "https://arxiv.org/pdf/2602.05791", "abs": "https://arxiv.org/abs/2602.05791", "authors": ["Yufei Xue", "YunFeng Lin", "Wentao Dong", "Yang Tang", "Jingbo Wang", "Jiangmiao Pang", "Ming Zhou", "Minghuan Liu", "Weinan Zhang"], "title": "Scalable and General Whole-Body Control for Cross-Humanoid Locomotion", "categories": ["cs.RO"], "comment": null, "summary": "Learning-based whole-body controllers have become a key driver for humanoid robots, yet most existing approaches require robot-specific training. In this paper, we study the problem of cross-embodiment humanoid control and show that a single policy can robustly generalize across a wide range of humanoid robot designs with one-time training. We introduce XHugWBC, a novel cross-embodiment training framework that enables generalist humanoid control through: (1) physics-consistent morphological randomization, (2) semantically aligned observation and action spaces across diverse humanoid robots, and (3) effective policy architectures modeling morphological and dynamical properties. XHugWBC is not tied to any specific robot. Instead, it internalizes a broad distribution of morphological and dynamical characteristics during training. By learning motion priors from diverse randomized embodiments, the policy acquires a strong structural bias that supports zero-shot transfer to previously unseen robots. Experiments on twelve simulated humanoids and seven real-world robots demonstrate the strong generalization and robustness of the resulting universal controller.", "AI": {"tldr": "The paper introduces XHugWBC, a cross-embodiment humanoid control framework, which enables generalist control across various robot designs with one-time training.", "motivation": "To address the challenge of developing a single control policy for humanoid robots that generalizes to diverse designs, without requiring robot-specific training.", "method": "The authors propose XHugWBC, a framework featuring physics-consistent morphological randomization, semantically aligned observation/action spaces, and advanced policy architectures to support generalization across robot designs.", "result": "XHugWBC demonstrates robust generalization and zero-shot transfer abilities in experiments involving 12 simulated humanoid robots and 7 real-world robots.", "conclusion": "The framework equips a control policy with strong structural biases to enable effective and robust cross-embodiment control for various humanoid robots, eliminating the need for robot-specific training."}}
{"id": "2602.05271", "pdf": "https://arxiv.org/pdf/2602.05271", "abs": "https://arxiv.org/abs/2602.05271", "authors": ["Shengqin Jiang", "Xiaoran Feng", "Yuankai Qi", "Haokui Zhang", "Renlong Hang", "Qingshan Liu", "Lina Yao", "Quan Z. Sheng", "Ming-Hsuan Yang"], "title": "Unlocking Prototype Potential: An Efficient Tuning Framework for Few-Shot Class-Incremental Learning", "categories": ["cs.CV"], "comment": "under review", "summary": "Few-shot class-incremental learning (FSCIL) seeks to continuously learn new classes from very limited samples while preserving previously acquired knowledge. Traditional methods often utilize a frozen pre-trained feature extractor to generate static class prototypes, which suffer from the inherent representation bias of the backbone. While recent prompt-based tuning methods attempt to adapt the backbone via minimal parameter updates, given the constraint of extreme data scarcity, the model's capacity to assimilate novel information and substantively enhance its global discriminative power is inherently limited. In this paper, we propose a novel shift in perspective: freezing the feature extractor while fine-tuning the prototypes. We argue that the primary challenge in FSCIL is not feature acquisition, but rather the optimization of decision regions within a static, high-quality feature space. To this end, we introduce an efficient prototype fine-tuning framework that evolves static centroids into dynamic, learnable components. The framework employs a dual-calibration method consisting of class-specific and task-aware offsets. These components function synergistically to improve the discriminative capacity of prototypes for ongoing incremental classes. Extensive results demonstrate that our method attains superior performance across multiple benchmarks while requiring minimal learnable parameters.", "AI": {"tldr": "This paper proposes an approach for Few-shot Class-Incremental Learning (FSCIL) that involves freezing the feature extractor and fine-tuning prototypes in a static feature space using a dual-calibration framework.", "motivation": "The motivation is to address the limitations of traditional FSCIL methods, which suffer from representation bias due to static class prototypes and restricted adaptation capabilities due to data scarcity.", "method": "The method involves freezing the feature extractor and fine-tuning prototypes using a dual-calibration framework. This framework introduces class-specific and task-aware offsets to enhance the prototypes' discriminative power.", "result": "The proposed framework significantly improves performance across various FSCIL benchmarks, requiring minimal learnable parameters.", "conclusion": "Freezing the feature extractor and optimizing decision regions through prototype fine-tuning offers a superior and efficient solution for FSCIL tasks."}}
{"id": "2602.05287", "pdf": "https://arxiv.org/pdf/2602.05287", "abs": "https://arxiv.org/abs/2602.05287", "authors": ["Xilin Dai", "Wanxu Cai", "Zhijian Xu", "Qiang Xu"], "title": "Position: Universal Time Series Foundation Models Rest on a Category Error", "categories": ["cs.AI"], "comment": "Position Paper", "summary": "This position paper argues that the pursuit of \"Universal Foundation Models for Time Series\" rests on a fundamental category error, mistaking a structural Container for a semantic Modality. We contend that because time series hold incompatible generative processes (e.g., finance vs. fluid dynamics), monolithic models degenerate into expensive \"Generic Filters\" that fail to generalize under distributional drift. To address this, we introduce the \"Autoregressive Blindness Bound,\" a theoretical limit proving that history-only models cannot predict intervention-driven regime shifts. We advocate replacing universality with a Causal Control Agent paradigm, where an agent leverages external context to orchestrate a hierarchy of specialized solvers, from frozen domain experts to lightweight Just-in-Time adaptors. We conclude by calling for a shift in benchmarks from \"Zero-Shot Accuracy\" to \"Drift Adaptation Speed\" to prioritize robust, control-theoretic systems.", "AI": {"tldr": "This paper argues against universal foundation models for time series and introduces alternatives based on causal control agents.", "motivation": "The paper seeks to address issues with monolithic time series models, which fail under distributional drift and intervention-based regime shifts.", "method": "Introduces the 'Autoregressive Blindness Bound' and advocates shifting toward a Causal Control Agent paradigm using hierarchical specialized solvers.", "result": "The proposed approach highlights the inefficacy of existing time series models and offers theoretical limits and practical frameworks for improvement.", "conclusion": "Recommends replacing universal models with adaptive systems and shifting evaluation benchmarks from accuracy to drift adaptation speed."}}
{"id": "2602.05259", "pdf": "https://arxiv.org/pdf/2602.05259", "abs": "https://arxiv.org/abs/2602.05259", "authors": ["Ashwin Ram", "Aaditya Ramdas"], "title": "An Asymptotic Law of the Iterated Logarithm for $\\mathrm{KL}_{\\inf}$", "categories": ["math.ST", "stat.ML"], "comment": "Preprint", "summary": "The population $\\mathrm{KL}_{\\inf}$ is a fundamental quantity that appears in lower bounds for (asymptotically) optimal regret of pure-exploration stochastic bandit algorithms, and optimal stopping time of sequential tests. Motivated by this, an empirical $\\mathrm{KL}_{\\inf}$ statistic is frequently used in the design of (asymptotically) optimal bandit algorithms and sequential tests. While nonasymptotic concentration bounds for the empirical $\\mathrm{KL}_{\\inf}$ have been developed, their optimality in terms of constants and rates is questionable, and their generality is limited (usually to bounded observations). The fundamental limits of nonasymptotic concentration are often described by the asymptotic fluctuations of the statistics. With that motivation, this paper presents a tight (upper and lower) law of the iterated logarithm for empirical $\\mathrm{KL}_{\\inf}$ applying to extremely general (unbounded) data.", "AI": {"tldr": "The paper develops a tight law of iterated logarithm for empirical $\\mathrm{KL}_{\\inf}$ applied to unbounded data, addressing its fundamental limits of nonasymptotic concentration.", "motivation": "Nonasymptotic concentration bounds for empirical $\\mathrm{KL}_{\\inf}$ lack optimality in constants and rates, and are limited to bounded observations. The general limits are tied to asymptotic statistical fluctuations.", "method": "The paper establishes tight upper and lower laws of the iterated logarithm specific to empirical $\\mathrm{KL}_{\\inf}$ for extremely general, unbounded data.", "result": "The authors derived a robust framework governing the nonasymptotic concentration behavior of empirical $\\mathrm{KL}_{\\inf}$ under broad data conditions.", "conclusion": "The findings expand the understanding of $\\mathrm{KL}_{\\inf}$ statistics, providing optimal concentration results and enabling applications to general (unbounded) scenarios."}}
{"id": "2602.04931", "pdf": "https://arxiv.org/pdf/2602.04931", "abs": "https://arxiv.org/abs/2602.04931", "authors": ["Shahar Haim", "Daniel C McNamee"], "title": "Depth-Wise Emergence of Prediction-Centric Geometry in Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We show that decoder-only large language models exhibit a depth-wise transition from context-processing to prediction-forming phases of computation accompanied by a reorganization of representational geometry. Using a unified framework combining geometric analysis with mechanistic intervention, we demonstrate that late-layer representations implement a structured geometric code that enables selective causal control over token prediction. Specifically, angular organization of the representation geometry parametrizes prediction distributional similarity, while representation norms encode context-specific information that does not determine prediction. Together, these results provide a mechanistic-geometric account of the dynamics of transforming context into predictions in LLMs.", "AI": {"tldr": "This study identifies two computational phases in decoder-only language models, focusing on their contextual processing and prediction formation, linked to changes in representation geometry.", "motivation": "The goal is to understand the internal mechanisms in large language models (LLMs) that govern their transition from context processing to forming predictions and how these mechanisms are geometrically organized.", "method": "The paper employs a unified methodology of geometric analysis and mechanistic intervention, analyzing representation geometry and causal control over token predictions.", "result": "It finds that late-layer representations in LLMs develop a structured geometric pattern, where angular geometry affects prediction similarity and vector norms capture additional, but context-specific, information.", "conclusion": "The findings provide a deeper mechanistic and geometric explanation of how LLMs transform contextual information into predictions, enhancing our understanding of their inner workings."}}
{"id": "2602.05385", "pdf": "https://arxiv.org/pdf/2602.05385", "abs": "https://arxiv.org/abs/2602.05385", "authors": ["Tao Liu", "Jiafan Lu", "Bohan Yu", "Pengcheng Wu", "Liu Haixin", "Guoyu Xu", "Li Xiangheng", "Lixiao Li", "Jiaming Hou", "Zhao Shijun", "Xinglin Lyu", "Kunli Zhang", "Yuxiang Jia", "Hongyin Zan"], "title": "IESR:Efficient MCTS-Based Modular Reasoning for Text-to-SQL with Large Language Models", "categories": ["cs.CL"], "comment": "25 pages, 16 figures, 8 tables. Hongyin Zan is corresponding author, Jiafan Lu is first co-author", "summary": "Text-to-SQL is a key natural language processing task that maps natural language questions to SQL queries, enabling intuitive interaction with web-based databases. Although current methods perform well on benchmarks like BIRD and Spider, they struggle with complex reasoning, domain knowledge, and hypothetical queries, and remain costly in enterprise deployment. To address these issues, we propose a framework named IESR(Information Enhanced Structured Reasoning) for lightweight large language models: (i) leverages LLMs for key information understanding and schema linking, and decoupling mathematical computation and SQL generation, (ii) integrates a multi-path reasoning mechanism based on Monte Carlo Tree Search (MCTS) with majority voting, and (iii) introduces a trajectory consistency verification module with a discriminator model to ensure accuracy and consistency. Experimental results demonstrate that IESR achieves state-of-the-art performance on the complex reasoning benchmark LogicCat (24.28 EX) and the Archer dataset (37.28 EX) using only compact lightweight models without fine-tuning. Furthermore, our analysis reveals that current coder models exhibit notable biases and deficiencies in physical knowledge, mathematical computation, and common-sense reasoning, highlighting important directions for future research. We released code at https://github.com/Ffunkytao/IESR-SLM.", "AI": {"tldr": "Text-to-SQL task struggles with complex reasoning and real-world applicability; IESR framework enhances performance using lightweight large language models and advanced techniques like Monte Carlo Tree Search-based mechanisms.", "motivation": "To enable lightweight large language models to handle complex reasoning, domain-specific knowledge, and hypothetical queries in Text-to-SQL tasks, which are key for enterprise deployment and natural database interaction.", "method": "IESR utilizes lightweight language models for schema linking and computation, employs Monte Carlo Tree Search (MCTS) with majority voting for reasoning, and integrates trajectory consistency verification using a discriminator model.", "result": "Experimental results show IESR achieves state-of-the-art performance on benchmarks like LogicCat (24.28 EX) and Archer dataset (37.28 EX), surpassing prior methods using lightweight models without fine-tuning.", "conclusion": "IESR demonstrates the potential of lightweight models in addressing key challenges of Text-to-SQL tasks, opening pathways for more efficient, accurate, and practical NLP systems for real-world deployment."}}
{"id": "2602.05891", "pdf": "https://arxiv.org/pdf/2602.05891", "abs": "https://arxiv.org/abs/2602.05891", "authors": ["Shenyu Zheng", "Ximing Dong", "Xiaoshuang Liu", "Gustavo Oliva", "Chong Chun Yong", "Dayi Lin", "Boyuan Chen", "Shaowei Wang", "Ahmed E. Hassan"], "title": "When Elo Lies: Hidden Biases in Codeforces-Based Evaluation of Large Language Models", "categories": ["cs.SE"], "comment": null, "summary": "As Large Language Models (LLMs) achieve breakthroughs in complex reasoning, Codeforces-based Elo ratings have emerged as a prominent metric for evaluating competitive programming capabilities. However, these ratings are often reported without critical experimental details, leading to significant discrepancies illustrated by recent reports where the score of the same model version fluctuated by nearly 500 points. This paper presents a systematic empirical study on the hidden factors biasing Elo evaluations: (1) the temporal ordering of submissions, (2) contest difficulty selection, and (3) run to run stochastic variability of LLMs. Utilizing a controlled benchmark of 37 recent Codeforces contests and 13,691 generated test cases, we demonstrate that Elo scores are highly sensitive to these parameters. Our findings reveal that varying submission orders can shift scores by 394 points, while contest selection can cause differences of up to 1,122 points for the same model. Run to run performance exhibits substantial instability, with a maximum difference of 349 points in mean scores observed when evaluating identical contests. We conclude that direct Elo comparisons are unreliable and potentially misleading without strict standardization and transparent reporting of experimental settings.", "AI": {"tldr": "This paper critiques the unreliability of Codeforces-based Elo ratings for evaluating LLMs in competitive programming due to lack of standardization, exposing how hidden experimental factors can lead to highly inconsistent scores.", "motivation": "To investigate and address the inconsistencies found in using Codeforces-based Elo ratings for evaluating LLMs in competitive programming.", "method": "Conducted an empirical study employing 37 recent Codeforces contests and 13,691 test cases to analyze the impact of factors such as submission order, contest choice, and model stochasticity on Elo ratings.", "result": "Discovered substantial variability in Elo scores: submission order caused score shifts of up to 394 points, contest selection led to differences of 1,122 points, and stochasticity resulted in 349-point variations in mean scores.", "conclusion": "Elo ratings for LLM evaluations require strict standardization and transparent reporting of experimental conditions to be reliable and meaningful."}}
{"id": "2602.05855", "pdf": "https://arxiv.org/pdf/2602.05855", "abs": "https://arxiv.org/abs/2602.05855", "authors": ["Dennis Bank", "Joost Cordes", "Thomas Seel", "Simon F. G. Ehlers"], "title": "A Hybrid Autoencoder for Robust Heightmap Generation from Fused Lidar and Depth Data for Humanoid Robot Locomotion", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Reliable terrain perception is a critical prerequisite for the deployment of humanoid robots in unstructured, human-centric environments. While traditional systems often rely on manually engineered, single-sensor pipelines, this paper presents a learning-based framework that uses an intermediate, robot-centric heightmap representation. A hybrid Encoder-Decoder Structure (EDS) is introduced, utilizing a Convolutional Neural Network (CNN) for spatial feature extraction fused with a Gated Recurrent Unit (GRU) core for temporal consistency. The architecture integrates multimodal data from an Intel RealSense depth camera, a LIVOX MID-360 LiDAR processed via efficient spherical projection, and an onboard IMU. Quantitative results demonstrate that multimodal fusion improves reconstruction accuracy by 7.2% over depth-only and 9.9% over LiDAR-only configurations. Furthermore, the integration of a 3.2 s temporal context reduces mapping drift.", "AI": {"tldr": "This paper introduces a learning-based framework for humanoid robot terrain perception using a hybrid model that integrates multimodal data and temporal context to improve accuracy and reduce mapping drift.", "motivation": "The paper seeks to address the limitations of traditional manually engineered systems for terrain perception in unstructured environments using advanced learning-based techniques.", "method": "The study employs a hybrid Encoder-Decoder framework combining CNN for feature extraction and GRU for maintaining temporal consistency, integrating multimodal sensor data from depth camera, LiDAR, and IMU.", "result": "Multimodal fusion improves reconstruction accuracy by 7.2% compared to depth-only and 9.9% compared to LiDAR-only methods, while temporal context integration reduces mapping drift over 3.2 seconds.", "conclusion": "The proposed framework significantly enhances humanoid robot terrain perception, demonstrating the benefits of multimodal data fusion and temporal modeling."}}
{"id": "2602.05275", "pdf": "https://arxiv.org/pdf/2602.05275", "abs": "https://arxiv.org/abs/2602.05275", "authors": ["Qi Li", "Yanzhe Zhao", "Yongxin Zhou", "Yameng Wang", "Yandong Yang", "Yuanjia Zhou", "Jue Wang", "Zuojian Wang", "Jinxiang Liu"], "title": "Magic-MM-Embedding: Towards Visual-Token-Efficient Universal Multimodal Embedding with MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have shown immense promise in universal multimodal retrieval, which aims to find relevant items of various modalities for a given query. But their practical application is often hindered by the substantial computational cost incurred from processing a large number of tokens from visual inputs. In this paper, we propose Magic-MM-Embedding, a series of novel models that achieve both high efficiency and state-of-the-art performance in universal multimodal embedding. Our approach is built on two synergistic pillars: (1) a highly efficient MLLM architecture incorporating visual token compression to drastically reduce inference latency and memory footprint, and (2) a multi-stage progressive training strategy designed to not only recover but significantly boost performance. This coarse-to-fine training paradigm begins with extensive continue pretraining to restore multimodal understanding and generation capabilities, progresses to large-scale contrastive pretraining and hard negative mining to enhance discriminative power, and culminates in a task-aware fine-tuning stage guided by an MLLM-as-a-Judge for precise data curation. Comprehensive experiments show that our model outperforms existing methods by a large margin while being more inference-efficient.", "AI": {"tldr": "Magic-MM-Embedding improves multimodal retrieval by combining efficient visual token compression and progressive training strategies, boosting performance and reducing computational cost.", "motivation": "The paper addresses the challenge of high computational cost in multimodal large language models for universal retrieval tasks.", "method": "The proposed approach integrates an efficient MLLM architecture with visual token compression and employs a multi-stage training strategy to enhance performance.", "result": "Experiments demonstrate substantial improvements in performance and inference efficiency over existing methods.", "conclusion": "Magic-MM-Embedding successfully balances performance and efficiency in multimodal retrieval using innovative architectural and training techniques."}}
{"id": "2602.05297", "pdf": "https://arxiv.org/pdf/2602.05297", "abs": "https://arxiv.org/abs/2602.05297", "authors": ["Seongyeub Chu", "Jongwoo Kim", "Mun Yong Yi"], "title": "Aspect-Aware MOOC Recommendation in a Heterogeneous Network", "categories": ["cs.AI"], "comment": null, "summary": "MOOC recommendation systems have received increasing attention to help learners navigate and select preferred learning content. Traditional methods such as collaborative filtering and content-based filtering suffer from data sparsity and over-specialization. To alleviate these limitations, graph-based approaches have been proposed; however, they still rely heavily on manually predefined metapaths, which often capture only superficial structural relationships and impose substantial burdens on domain experts as well as significant engineering costs. To overcome these limitations, we propose AMR (Aspect-aware MOOC Recommendation), a novel framework that models path-specific multiple aspects by embedding the semantic content of nodes within each metapath. AMR automatically discovers metapaths through bi-directional walks, derives aspect-aware path representations using a bi-LSTM-based encoder, and incorporates these representations as edge features in the learner-learner and KC-KC subgraphs to achieve fine-grained semantically informed KC recommendations. Extensive experiments on the large-scale MOOCCube and PEEK datasets show that AMR consistently outperforms state-of-the-art graph neural network baselines across key metrics such as HR@K and nDCG@K. Further analysis confirms that AMR effectively captures rich path-specific aspect information, allowing more accurate recommendations than those methods that rely solely on predefined metapaths. The code will be available upon accepted.", "AI": {"tldr": "The paper presents AMR, a recommendation framework for MOOCs that surpasses existing methods by embedding semantic content into automatically discovered metapaths for better accuracy.", "motivation": "Traditional MOOC recommendation methods struggle with issues like data sparsity and over-specialization, while graph-based methods rely on costly, predefined metapaths.", "method": "AMR combines automatic metapath discovery using bi-directional walks with a bi-LSTM encoder that embeds semantic content into paths. It applies aspect-aware representations in learner-learner and KC-KC subgraphs.", "result": "AMR consistently outperforms state-of-the-art graph neural network baselines on MOOCCube and PEEK datasets across metrics like HR@K and nDCG@K.", "conclusion": "AMR effectively captures path-specific semantic information without relying on predefined metapaths, ensuring more accurate recommendations and reduced reliance on domain expertise."}}
{"id": "2602.05272", "pdf": "https://arxiv.org/pdf/2602.05272", "abs": "https://arxiv.org/abs/2602.05272", "authors": ["Ashwin Ram", "Aaditya Ramdas"], "title": "Asymptotically optimal sequential change detection for bounded means", "categories": ["math.ST", "math.PR", "stat.ML"], "comment": "Preprint", "summary": "We consider the problem of quickest changepoint detection under the Average Run Length (ARL) constraint where the pre-change and post-change laws lie in composite families $\\mathscr{P}$ and $\\mathscr{Q}$ respectively. In such a problem, a massive challenge is characterizing the best possible detection delay when the \"hardest\" pre-change law in $\\mathscr{P}$ depends on the unknown post-change law $Q\\in\\mathscr{Q}$. And typical simple-hypothesis likelihood-ratio arguments for Page-CUSUM and Shiryaev-Roberts do not at all apply here. To that end, we derive a universal sharp lower bound in full generality for any ARL-calibrated changepoint detector in the low type-I error ($\u03b3\\to\\infty$ regime) of the order $\\log(\u03b3)/\\mathrm{KL}_{\\mathrm{inf}}(Q,\\mathscr{P})$. We show achievability of this universal lower bound by proving a tight matching upper bound (with the same sharp $\\log\u03b3$ constant) in the important bounded mean detection setting. In addition, for separated mean shifts, we also we derive a uniform minimax guarantee of this achievability over the alternatives.", "AI": {"tldr": "The paper addresses the quickest changepoint detection problem under the Average Run Length (ARL) constraint and provides a universal sharp lower bound on detection delay in composite settings, achieving tight bounds in specified scenarios.", "motivation": "To tackle the challenge of determining optimal detection delay in changepoint problems where pre- and post-change distributions belong to composite families, a setting where standard likelihood-ratio methods fail.", "method": "A theoretical derivation of a universal sharp lower bound on detection delay in terms of KL divergence, and a matching upper bound is proven for bounded mean detection and separated mean shift cases.", "result": "The derived bounds demonstrate optimal detection delay under ARL constraints, achieving robustness and sharp guarantees in specific detection scenarios.", "conclusion": "The results contribute both lower and upper bounds, providing a comprehensive theoretical framework for handling changepoint detection with composite distributions under ARL constraints."}}
{"id": "2602.04932", "pdf": "https://arxiv.org/pdf/2602.04932", "abs": "https://arxiv.org/abs/2602.04932", "authors": ["Mohamad Dalal", "Thomas B. Moeslund", "Joakim Bruslund Haurum"], "title": "Comparing Euclidean and Hyperbolic K-Means for Generalized Category Discovery", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages, 4 figures. To be published in the VISAPP", "summary": "Hyperbolic representation learning has been widely used to extract implicit hierarchies within data, and recently it has found its way to the open-world classification task of Generalized Category Discovery (GCD). However, prior hyperbolic GCD methods only use hyperbolic geometry for representation learning and transform back to Euclidean geometry when clustering. We hypothesize this is suboptimal. Therefore, we present Hyperbolic Clustered GCD (HC-GCD), which learns embeddings in the Lorentz Hyperboloid model of hyperbolic geometry, and clusters these embeddings directly in hyperbolic space using a hyperbolic K-Means algorithm. We test our model on the Semantic Shift Benchmark datasets, and demonstrate that HC-GCD is on par with the previous state-of-the-art hyperbolic GCD method. Furthermore, we show that using hyperbolic K-Means leads to better accuracy than Euclidean K-Means. We carry out ablation studies showing that clipping the norm of the Euclidean embeddings leads to decreased accuracy in clustering unseen classes, and increased accuracy for seen classes, while the overall accuracy is dataset dependent. We also show that using hyperbolic K-Means leads to more consistent clusters when varying the label granularity.", "AI": {"tldr": "The paper introduces HC-GCD, a method that integrates hyperbolic geometry-based representation learning and clustering for Generalized Category Discovery tasks, outperforming traditional Euclidean-based clustering approaches.", "motivation": "Current hyperbolic GCD methods revert to Euclidean geometry for clustering, which may be suboptimal for open-world classification tasks requiring explicit hierarchies.", "method": "HC-GCD conducts embedding learning using the Lorentz hyperboloid model of hyperbolic geometry and clusters embeddings directly within hyperbolic space using a hyperbolic K-Means algorithm.", "result": "Experiments on Semantic Shift Benchmark datasets show HC-GCD matches prior hyperbolic GCD methods in state-of-the-art performance while outperforming Euclidean K-Means in accuracy and consistency.", "conclusion": "HC-GCD represents a more effective approach to clustering in hyperbolic geometry, and the results support its suitability for accurate and consistent cluster formation in open-world classification tasks."}}
{"id": "2602.05392", "pdf": "https://arxiv.org/pdf/2602.05392", "abs": "https://arxiv.org/abs/2602.05392", "authors": ["Jiyun Chun", "Eric Fosler-Lussier", "Michael White", "Andrew Perrault"], "title": "Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are dominated by length and ignore conversational context, missing aspects of response quality such as reasoning depth, topic maintenance, and discourse planning. We introduce an LLM-as-a-judge framework that first classifies the Previous Adult Utterance Type and then scores the child's response along two axes: Expansion (contextual elaboration and inferential depth) and Independence (the child's contribution to advancing the discourse). These axes reflect fundamental dimensions in child language development, where Expansion captures elaboration, clause combining, and causal and contrastive connectives. Independence captures initiative, topic control, decreasing reliance on adult scaffolding through growing self-regulation, and audience design. We establish developmental validity by showing age-related patterns and demonstrate predictive value by improving age estimation over common baselines. We further confirm semantic sensitivity by detecting differences tied to discourse relations. Our metrics align with human judgments, enabling large-scale evaluation. This shifts child utterance assessment from simply measuring length to evaluating how meaningfully the child's speech contributes to and advances the conversation within its context.", "AI": {"tldr": "The study proposes using a framework based on large language models (LLMs) to assess the quality of children's contributions during dialogues with adults, focusing on dimensions like Expansion and Independence.", "motivation": "Existing metrics for evaluating children's utterances often miss conversational context and response quality aspects like reasoning depth, topic maintenance, and discourse planning.", "method": "An LLM-as-a-judge framework is introduced to classify the type of adult utterances first and then score child responses based on their elaboration (Expansion) and contribution to advancing discourse (Independence).", "result": "The proposed metrics show developmental validity with age-related patterns, improve age estimation accuracy compared to baselines, and align well with human judgments.", "conclusion": "The framework enhances child utterance evaluation by shifting from length-based metrics to assessing meaningful contributions and advancements in conversation in context."}}
{"id": "2602.05895", "pdf": "https://arxiv.org/pdf/2602.05895", "abs": "https://arxiv.org/abs/2602.05895", "authors": ["Qi Li", "Karsten Berns"], "title": "Residual Reinforcement Learning for Waste-Container Lifting Using Large-Scale Cranes with Underactuated Tools", "categories": ["cs.RO"], "comment": "12 pages", "summary": "This paper studies the container lifting phase of a waste-container recycling task in urban environments, performed by a hydraulic loader crane equipped with an underactuated discharge unit, and proposes a residual reinforcement learning (RRL) approach that combines a nominal Cartesian controller with a learned residual policy. All experiments are conducted in simulation, where the task is characterized by tight geometric tolerances between the discharge-unit hooks and the container rings relative to the overall crane scale, making precise trajectory tracking and swing suppression essential. The nominal controller uses admittance control for trajectory tracking and pendulum-aware swing damping, followed by damped least-squares inverse kinematics with a nullspace posture term to generate joint velocity commands. A PPO-trained residual policy in Isaac Lab compensates for unmodeled dynamics and parameter variations, improving precision and robustness without requiring end-to-end learning from scratch. We further employ randomized episode initialization and domain randomization over payload properties, actuator gains, and passive joint parameters to enhance generalization. Simulation results demonstrate improved tracking accuracy, reduced oscillations, and higher lifting success rates compared to the nominal controller alone.", "AI": {"tldr": "The paper introduces a residual reinforcement learning (RRL) approach to improve container lifting tasks for a hydraulic loader crane, enhancing precision and robustness in simulations.", "motivation": "The need for precise and robust control in urban waste-container recycling tasks, especially when tight geometric tolerances and dynamics complicate the performance of hydraulic cranes.", "method": "Combines a nominal Cartesian controller with a PPO-trained residual policy. Incorporates tools like admittance control, pendulum-aware damping, and randomized simulations; focuses on improving trajectory tracking and swing suppression.", "result": "The proposed RRL approach demonstrated better tracking accuracy, reduced oscillations, and higher success rates compared to using only the nominal controller.", "conclusion": "By integrating a learned residual policy with a nominal controller, the approach effectively addresses unmodeled dynamics and improves both precision and robustness in simulation tasks."}}
{"id": "2602.05293", "pdf": "https://arxiv.org/pdf/2602.05293", "abs": "https://arxiv.org/abs/2602.05293", "authors": ["Weilun Feng", "Mingqiang Wu", "Zhiliang Chen", "Chuanguang Yang", "Haotong Qin", "Yuqi Li", "Xiaokun Liu", "Guoxin Fan", "Zhulin An", "Libo Huang", "Yulun Zhang", "Michele Magno", "Yongjun Xu"], "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster", "categories": ["cs.CV"], "comment": null, "summary": "SAM3D enables scalable, open-world 3D reconstruction from complex scenes, yet its deployment is hindered by prohibitive inference latency. In this work, we conduct the \\textbf{first systematic investigation} into its inference dynamics, revealing that generic acceleration strategies are brittle in this context. We demonstrate that these failures stem from neglecting the pipeline's inherent multi-level \\textbf{heterogeneity}: the kinematic distinctiveness between shape and layout, the intrinsic sparsity of texture refinement, and the spectral variance across geometries. To address this, we present \\textbf{Fast-SAM3D}, a training-free framework that dynamically aligns computation with instantaneous generation complexity. Our approach integrates three heterogeneity-aware mechanisms: (1) \\textit{Modality-Aware Step Caching} to decouple structural evolution from sensitive layout updates; (2) \\textit{Joint Spatiotemporal Token Carving} to concentrate refinement on high-entropy regions; and (3) \\textit{Spectral-Aware Token Aggregation} to adapt decoding resolution. Extensive experiments demonstrate that Fast-SAM3D delivers up to \\textbf{2.67$\\times$} end-to-end speedup with negligible fidelity loss, establishing a new Pareto frontier for efficient single-view 3D generation. Our code is released in https://github.com/wlfeng0509/Fast-SAM3D.", "AI": {"tldr": "Fast-SAM3D introduces a training-free method to accelerate inference in 3D reconstruction (SAM3D) by addressing multi-level heterogeneity while retaining fidelity, achieving up to 2.67\u00d7 speedup.", "motivation": "The prohibitive inference latency of SAM3D, despite its effectiveness in scalable 3D reconstruction, motivates the need to improve efficiency without sacrificing quality.", "method": "The Fast-SAM3D framework employs three mechanisms: Modality-Aware Step Caching (decoupling structural and layout updates), Joint Spatiotemporal Token Carving (focusing refinement on complex regions), and Spectral-Aware Token Aggregation (adjusting resolution dynamically).", "result": "Fast-SAM3D achieves up to 2.67\u00d7 speedup in end-to-end processing with negligible fidelity loss in single-view 3D generation.", "conclusion": "Fast-SAM3D sets a new standard for efficient 3D reconstruction by effectively balancing computational speed and output quality, making it a valuable tool in this domain."}}
{"id": "2602.05302", "pdf": "https://arxiv.org/pdf/2602.05302", "abs": "https://arxiv.org/abs/2602.05302", "authors": ["Chris Zhu", "Sasha Cui", "Will Sanok Dufallo", "Runzhi Jin", "Zhen Xu", "Linjun Zhang", "Daylian Cain"], "title": "PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences", "categories": ["cs.AI"], "comment": null, "summary": "We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in multi-agent interactions over realistic scenarios drawn from an MBA negotiation course at an elite business school. We find systematic evidence of AGI-level performance in which a representative frontier agent (GPT-5) matches or outperforms trained business-school students, despite a semester of general negotiation instruction and targeted coaching immediately prior to the task. We further study the effects of joint-intentionality agentic scaffolding and find asymmetric gains, with large improvements for mid- and lower-tier LMs and diminishing returns for frontier LMs. Beyond deal outcomes, PieArena provides a multi-dimensional negotiation behavioral profile, revealing novel cross-model heterogeneity, masked by deal-outcome-only benchmarks, in deception, computation accuracy, instruction compliance, and perceived reputation. Overall, our results suggest that frontier language agents are already intellectually and psychologically capable of deployment in high-stakes economic settings, but deficiencies in robustness and trustworthiness remain open challenges.", "AI": {"tldr": "The paper assesses GPT-5's negotiation abilities using a comprehensive benchmark, revealing AGI-level performance but also highlighting challenges in robustness and trustworthiness.", "motivation": "The motivation is to evaluate the negotiation capacity of advanced language models, as negotiation is a key task requiring strategic and economic reasoning.", "method": "The authors developed PieArena, a large-scale negotiation benchmark based on multi-agent interactions. They tested and compared GPT-5's performance against business school students.", "result": "GPT-5 demonstrated AGI-level negotiation performance, matching or outperforming trained negotiators. Improvements were noted among lower-tier models with special training, but frontier models showed diminishing returns.", "conclusion": "Frontier language models are capable of performing intellectual and psychological tasks in high-stakes economic scenarios, though robustness and trust concerns require further investigation."}}
{"id": "2602.05489", "pdf": "https://arxiv.org/pdf/2602.05489", "abs": "https://arxiv.org/abs/2602.05489", "authors": ["Kevin Kurian Thomas Vaidyan", "Michael P. Friedlander", "Ahmet Alacaoglu"], "title": "Convergence Rate of the Last Iterate of Stochastic Proximal Algorithms", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We analyze two classical algorithms for solving additively composite convex optimization problems where the objective is the sum of a smooth term and a nonsmooth regularizer: proximal stochastic gradient method for a single regularizer; and the randomized incremental proximal method, which uses the proximal operator of a randomly selected function when the regularizer is given as the sum of many nonsmooth functions. We focus on relaxing the bounded variance assumption that is common, yet stringent, for getting last iterate convergence rates. We prove the $\\widetilde{O}(1/\\sqrt{T})$ rate of convergence for the last iterate of both algorithms under componentwise convexity and smoothness, which is optimal up to log terms. Our results apply directly to graph-guided regularizers that arise in multi-task and federated learning, where the regularizer decomposes as a sum over edges of a collaboration graph.", "AI": {"tldr": "The paper analyzes and improves two classical optimization algorithms for composite convex problems, achieving near-optimal convergence rates without requiring a stringent bounded variance assumption.", "motivation": "To analyze and improve the performance of optimization algorithms for additively composite convex problems, particularly when bounded variance assumptions are unrealistic.", "method": "The authors studied the proximal stochastic gradient method and the randomized incremental proximal method, relaxing the common bounded variance assumption, and proved their convergence rates under certain convexity and smoothness conditions.", "result": "They established a $\u007f\u007f\\widetilde{O}(1/\\sqrt{T})$ convergence rate for both algorithms' last iterate, which is optimal up to log terms, and showed the applicability of these results in tasks involving graph-guided regularizers.", "conclusion": "This work broadens the utility and theoretical understanding of composite convex optimization by demonstrating robust algorithmic performance, even under relaxed assumptions."}}
{"id": "2602.04937", "pdf": "https://arxiv.org/pdf/2602.04937", "abs": "https://arxiv.org/abs/2602.04937", "authors": ["Davide Berasi", "Matteo Farina", "Massimiliano Mancini", "Elisa Ricci"], "title": "Linear Model Merging Unlocks Simple and Scalable Multimodal Data Mixture Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Selecting the best data mixture is critical for successful Supervised Fine-Tuning (SFT) of Multimodal Large Language Models. However, determining the optimal mixture weights across multiple domain-specific datasets remains a significant bottleneck due to the combinatorial search space and the high cost associated with even a single training run. This is the so-called Data Mixture Optimization (DMO) problem. On the other hand, model merging unifies domain-specific experts through parameter interpolation. This strategy is efficient, as it only requires a single training run per domain, yet oftentimes leads to suboptimal models. In this work, we take the best of both worlds, studying model merging as an efficient strategy for estimating the performance of different data mixtures. We train domain-specific multimodal experts and evaluate their weighted parameter-space combinations to estimate the efficacy of corresponding data mixtures. We conduct extensive experiments on 14 multimodal benchmarks, and empirically demonstrate that the merged proxy models exhibit a high rank correlation with models trained on actual data mixtures. This decouples the search for optimal mixtures from the resource-intensive training process, thereby providing a scalable and efficient strategy for navigating the complex landscape of mixture weights. Code is publicly available at https://github.com/BerasiDavide/mLLMs_merging_4_DMO.", "AI": {"tldr": "The paper addresses the challenge of optimizing data mixtures for Multimodal Large Language Models by using model merging as an efficient proxy for performance estimation, reducing costly training runs. Extensive experiments demonstrate the effectiveness and scalability of this approach.", "motivation": "Determining optimal mixture weights across domain-specific datasets for Supervised Fine-Tuning of Multimodal Large Language Models is resource-intensive due to the complex search space and high computational cost.", "method": "The authors propose using model merging, which interpolates parameters from domain-specific experts, as a proxy strategy for estimating the efficacy of different data mixtures. This method requires only a single training run per domain.", "result": "Experiments on 14 multimodal benchmarks reveal a high correlation between merged proxy models' performance and actual models trained on data mixtures. This confirms the method's efficiency and scalability.", "conclusion": "The study provides a scalable solution to the Data Mixture Optimization problem, allowing for efficient exploration of mixture weights without extensive computational costs."}}
{"id": "2602.05393", "pdf": "https://arxiv.org/pdf/2602.05393", "abs": "https://arxiv.org/abs/2602.05393", "authors": ["Ji Zhao", "Yufei Gu", "Shitong Shao", "Xun Zhou", "Liang Xiang", "Zeke Xie"], "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: \\textit{Can we leverage existing small pretrained models to accelerate the training of larger models?} In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6$\\times$ speedup with nearly 5\\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10$\\times$ fewer parameters than the target model.", "AI": {"tldr": "Authors propose Late-to-Early Training (LET), leveraging pretrained small models to accelerate training larger models efficiently, achieving quicker convergence and improved performance.", "motivation": "LLMs' growing computational demands for pretraining hinder rapid development despite existing pretrained models.", "method": "LET guides early layers of a new LLM using representations from late layers of a pretrained smaller model during early training phases.", "result": "Demonstrates speedup in training (up to 1.6\u00d7 faster) and 5% improvement in downstream task accuracy on models trained using LET.", "conclusion": "LET offers a practical solution to reduce computing costs while improving both training speed and model performance."}}
{"id": "2602.05922", "pdf": "https://arxiv.org/pdf/2602.05922", "abs": "https://arxiv.org/abs/2602.05922", "authors": ["Aziz Mohamed Mili", "Louis Catar", "Paul G\u00e9rard", "Ilyass Tabiai", "David St-Onge"], "title": "From Bench to Flight: Translating Drone Impact Tests into Operational Safety Limits", "categories": ["cs.RO"], "comment": null, "summary": "Indoor micro-aerial vehicles (MAVs) are increasingly used for tasks that require close proximity to people, yet practitioners lack practical methods to tune motion limits based on measured impact risk. We present an end-to-end, open toolchain that converts benchtop impact tests into deployable safety governors for drones. First, we describe a compact and replicable impact rig and protocol for capturing force-time profiles across drone classes and contact surfaces. Second, we provide data-driven models that map pre-impact speed to impulse and contact duration, enabling direct computation of speed bounds for a target force limit. Third, we release scripts and a ROS2 node that enforce these bounds online and log compliance, with support for facility-specific policies. We validate the workflow on multiple commercial off-the-shelf quadrotors and representative indoor assets, demonstrating that the derived governors preserve task throughput while meeting force constraints specified by safety stakeholders. Our contribution is a practical bridge from measured impacts to runtime limits, with shareable datasets, code, and a repeatable process that teams can adopt to certify indoor MAV operations near humans.", "AI": {"tldr": "The paper presents a toolchain to convert impact tests into safety governors for indoor drones operating near people, allowing practitioners to tune motion limits based on impact risk.", "motivation": "To address the lack of practical methods for tuning indoor MAV motion limits to safely operate near humans, considering impact risks.", "method": "The authors propose an open toolchain comprising: an impact rig and protocol to measure force-time profiles, data-driven models to compute speed bounds for impact safety, and deployable tools like scripts and ROS2 nodes to enforce safety constraints in real time.", "result": "The workflow was validated on various quadrotors and indoor assets, showing preserved task efficiency while meeting safety force constraints.", "conclusion": "The research provides a practical, open-source tool and repeatable process for certifying indoor MAV operations, enhancing safety near humans and encouraging broader community adoption."}}
{"id": "2602.05305", "pdf": "https://arxiv.org/pdf/2602.05305", "abs": "https://arxiv.org/abs/2602.05305", "authors": ["Zhuokun Chen", "Jianfei Cai", "Bohan Zhuang"], "title": "FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Generating long-form content, such as minute-long videos and extended texts, is increasingly important for modern generative models. Block diffusion improves inference efficiency via KV caching and block-wise causal inference and has been widely adopted in diffusion language models and video generation. However, in long-context settings, block diffusion still incurs substantial overhead from repeatedly computing attention over a growing KV cache. We identify an underexplored property of block diffusion: cross-step redundancy of attention within a block. Our analysis shows that attention outputs from tokens outside the current block remain largely stable across diffusion steps, while block-internal attention varies significantly. Based on this observation, we propose FlashBlock, a cached block-external attention mechanism that reuses stable attention output, reducing attention computation and KV cache access without modifying the diffusion process. Moreover, FlashBlock is orthogonal to sparse attention and can be combined as a complementary residual reuse strategy, substantially improving model accuracy under aggressive sparsification. Experiments on diffusion language models and video generation demonstrate up to 1.44$\\times$ higher token throughput and up to 1.6$\\times$ reduction in attention time, with negligible impact on generation quality. Project page: https://caesarhhh.github.io/FlashBlock/.", "AI": {"tldr": "The paper proposes FlashBlock, a mechanism to optimize block diffusion by reusing stable attention outputs, enhancing efficiency in long-form generative models such as videos and texts.", "motivation": "Address inefficiencies in block diffusion for long-context generative models caused by repeated attention computations over large KV caches.", "method": "Utilizes cached block-external attention to reuse stable attention outputs while maintaining block diffusion process integrity. Combines with sparse attention for residual reuse.", "result": "Experiments show up to 1.44\u00d7 higher token throughput and 1.6\u00d7 reduction in attention time, with minimal impact on generation quality.", "conclusion": "FlashBlock effectively reduces computational overhead in block diffusion while maintaining generation quality, offering complementary improvements when combined with sparse attention strategies."}}
{"id": "2602.05327", "pdf": "https://arxiv.org/pdf/2602.05327", "abs": "https://arxiv.org/abs/2602.05327", "authors": ["Yangbin Yu", "Mingyu Yang", "Junyou Li", "Yiming Gao", "Feiyu Liu", "Yijun Yang", "Zichuan Lin", "Jiafei Lyu", "Yicheng Liu", "Zhicong Lu", "Deheng Ye", "Jie Jiang"], "title": "ProAct: Agentic Lookahead in Interactive Environments", "categories": ["cs.AI"], "comment": null, "summary": "Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct", "AI": {"tldr": "ProAct improves planning in LLM agents through Grounded LookAhead Distillation (GLAD) and Monte-Carlo Critic (MC-Critic), surpassing open-source baselines and rivaling closed-source models with robust generalization.", "motivation": "To address LLM agents' difficulty with long-horizon planning in interactive environments due to compounding errors.", "method": "ProAct employs GLAD for supervised fine-tuning on environment-based search trajectories and MC-Critic as a value estimator for enhanced policy optimization.", "result": "ProAct significantly improves performance in stochastic and deterministic environments, outperforming open-source baselines and competing with closed-source models.", "conclusion": "ProAct effectively enhances planning accuracy and generalization in LLM agents through innovative training techniques."}}
{"id": "2602.05531", "pdf": "https://arxiv.org/pdf/2602.05531", "abs": "https://arxiv.org/abs/2602.05531", "authors": ["Ahmet Alacaoglu", "Jun-Hyun Kim"], "title": "Solving Stochastic Variational Inequalities without the Bounded Variance Assumption", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We analyze algorithms for solving stochastic variational inequalities (VI) without the bounded variance or bounded domain assumptions, where our main focus is min-max optimization with possibly unbounded constraint sets. We focus on two classes of problems: monotone VIs; and structured nonmonotone VIs that admit a solution to the weak Minty VI. The latter assumption allows us to solve structured nonconvex-nonconcave min-max problems. For both classes of VIs, to make the expected residual norm less than $\\varepsilon$, we show an oracle complexity of $\\widetilde{O}(\\varepsilon^{-4})$, which is the best-known for constrained VIs. In our setting, this complexity had been obtained with the bounded variance assumption in the literature, which is not even satisfied for bilinear min-max problems with an unbounded domain. We obtain this complexity for stochastic oracles whose variance can grow as fast as the squared norm of the optimization variable.", "AI": {"tldr": "This paper studies algorithms for solving stochastic variational inequalities (VIs) without requiring bounded variance or bounded domain assumptions, achieving oracle complexity $\\widetilde{O}(\\varepsilon^{-4})$.", "motivation": "The paper aims to address limitations in VI optimization by removing restrictive assumptions such as bounded variance and domain, especially for problems like nonconvex-nonconcave min-max optimization.", "method": "The analysis encompasses two types of VIs: monotone and structured nonmonotone ones that satisfy the weak Minty VI condition, enabling solutions to challenging problems like unbounded domain min-max optimization.", "result": "The algorithms achieve the best-known oracle complexity of $\\widetilde{O}(\\varepsilon^{-4})$ in both problem classes without requiring bounded variance constraints.", "conclusion": "The work successfully provides solutions for stochastic variational problems in more general and realistic settings, extending the applicability of VI methods to unbounded and complex scenarios."}}
{"id": "2602.04940", "pdf": "https://arxiv.org/pdf/2602.04940", "abs": "https://arxiv.org/abs/2602.04940", "authors": ["Hang Zhou", "Haixu Wu", "Haonan Shangguan", "Yuezhou Ma", "Huikun Weng", "Jianmin Wang", "Mingsheng Long"], "title": "Transolver-3: Scaling Up Transformer Solvers to Industrial-Scale Geometries", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning has emerged as a transformative tool for the neural surrogate modeling of partial differential equations (PDEs), known as neural PDE solvers. However, scaling these solvers to industrial-scale geometries with over $10^8$ cells remains a fundamental challenge due to the prohibitive memory complexity of processing high-resolution meshes. We present Transolver-3, a new member of the Transolver family as a highly scalable framework designed for high-fidelity physics simulations. To bridge the gap between limited GPU capacity and the resolution requirements of complex engineering tasks, we introduce two key architectural optimizations: faster slice and deslice by exploiting matrix multiplication associative property and geometry slice tiling to partition the computation of physical states. Combined with an amortized training strategy by learning on random subsets of original high-resolution meshes and a physical state caching technique during inference, Transolver-3 enables high-fidelity field prediction on industrial-scale meshes. Extensive experiments demonstrate that Transolver-3 is capable of handling meshes with over 160 million cells, achieving impressive performance across three challenging simulation benchmarks, including aircraft and automotive design tasks.", "AI": {"tldr": "Transolver-3 introduces two architectural optimizations and amortized training to scale neural PDE solvers to industrial-scale geometries exceeding 160 million cells.", "motivation": "To address the prohibitive memory complexity of processing high-resolution meshes for neural PDE solvers in industrial-scale geometries.", "method": "Introduced faster slice/deslice operations, geometry slice tiling, amortized training strategy, and physical state caching for efficient processing of high-fidelity simulations.", "result": "Transolver-3 successfully handles meshes with over 160 million cells and excels in challenging tasks such as aircraft and automotive design simulations.", "conclusion": "Transolver-3 bridges the gap between GPU limitations and high-resolution requirements, establishing itself as a key framework for scalable, high-fidelity neural PDE simulations."}}
{"id": "2602.05400", "pdf": "https://arxiv.org/pdf/2602.05400", "abs": "https://arxiv.org/abs/2602.05400", "authors": ["Shaobo Wang", "Xuan Ouyang", "Tianyi Xu", "Yuzheng Hu", "Jialin Liu", "Guo Chen", "Tianyu Zhang", "Junhao Zheng", "Kexin Yang", "Xingzhang Ren", "Dayiheng Liu", "Linfeng Zhang"], "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration", "categories": ["cs.CL"], "comment": "45 pages, 7 figures, 8 tables", "summary": "As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.", "AI": {"tldr": "OPUS, a new dynamic data selection framework, optimizes training by projecting updates shaped by state-of-the-art optimizers onto stable proxy directions, improving data efficiency significantly. ", "motivation": "There is a growing need to address data inefficiency in pre-training as high-quality text data becomes scarce due to the Data Wall phenomenon.", "method": "OPUS defines data utility in the optimizer-induced update space. It employs Ghost technique with CountSketch for efficiency and Boltzmann sampling for diversity, ensuring scalable and effective dynamic data selection.", "result": "OPUS dramatically enhances performance across various datasets and models. It outperforms industrial baselines in pre-training GPT-2 and Qwen models, achieving superior results with significantly fewer tokens.", "conclusion": "OPUS offers a dynamic, efficient, and scalable solution for improving pre-training with optimized data selection, demonstrating its potential as a key innovation in machine learning pre-training strategies."}}
{"id": "2602.05762", "pdf": "https://arxiv.org/pdf/2602.05762", "abs": "https://arxiv.org/abs/2602.05762", "authors": ["Andrei Kozyrev", "Nikita Khramov", "Denis Lochmelis", "Valerio Morelli", "Gleb Solovev", "Anton Podkopaev"], "title": "RocqSmith: Can Automatic Optimization Forge Better Proof Agents?", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SE"], "comment": null, "summary": "This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to the task of optimizing a Rocq proof-generation agent, and assess whether parts of the fine-grained tuning of agentic systems, such as prompt design, contextual knowledge, and control strategies, can be automated. Our results show that while several optimizers yield measurable improvements, simple few-shot bootstrapping is the most consistently effective; however, none of the studied methods matches the performance of a carefully engineered state-of-the-art proof agent.", "AI": {"tldr": "This paper evaluates different AI automatic agent optimization methods for automated theorem proving in Rocq.", "motivation": "To investigate whether automatic agent optimization can effectively enhance real-world agents in complex formal verification tasks like theorem proving.", "method": "Evaluated various automatic optimizers on a Rocq proof-generation AI agent, analyzing the potential for automating fine-grained tuning like prompt design.", "result": "Several optimization methods showed measurable improvements, but few-shot bootstrapping was the most effective overall.", "conclusion": "Automatic optimization methods show promise but cannot yet outperform state-of-the-art, manually engineered agents."}}
{"id": "2602.06001", "pdf": "https://arxiv.org/pdf/2602.06001", "abs": "https://arxiv.org/abs/2602.06001", "authors": ["Carolina Higuera", "Sergio Arnaud", "Byron Boots", "Mustafa Mukadam", "Francois Robert Hogan", "Franziska Meier"], "title": "Visuo-Tactile World Models", "categories": ["cs.RO"], "comment": "Preprint", "summary": "We introduce multi-task Visuo-Tactile World Models (VT-WM), which capture the physics of contact through touch reasoning. By complementing vision with tactile sensing, VT-WM better understands robot-object interactions in contact-rich tasks, avoiding common failure modes of vision-only models under occlusion or ambiguous contact states, such as objects disappearing, teleporting, or moving in ways that violate basic physics. Trained across a set of contact-rich manipulation tasks, VT-WM improves physical fidelity in imagination, achieving 33% better performance at maintaining object permanence and 29% better compliance with the laws of motion in autoregressive rollouts. Moreover, experiments show that grounding in contact dynamics also translates to planning. In zero-shot real-robot experiments, VT-WM achieves up to 35% higher success rates, with the largest gains in multi-step, contact-rich tasks. Finally, VT-WM demonstrates significant downstream versatility, effectively adapting its learned contact dynamics to a novel task and achieving reliable planning success with only a limited set of demonstrations.", "AI": {"tldr": "This paper presents Visuo-Tactile World Models (VT-WM) for understanding robot-object interactions in contact-rich scenarios by combining vision and tactile sensing, improving physical fidelity and planning performance.", "motivation": "The motivation is to address limitations of vision-only models in capturing physics of contact during robot-object interactions, such as occlusion or ambiguous states.", "method": "The authors propose VT-WM, a multi-task model combining vision and tactile sensing, trained on contact-rich manipulation tasks to better understand and predict object physics.", "result": "VT-WM improves object permanence by 33% and compliance with physical laws by 29%, achieving up to 35% higher success rates in real-robot experiments, especially in contact-rich, multi-step tasks.", "conclusion": "Introducing tactile sensing to vision-based models allows for better physical reasoning, successful zero-shot task generalization, and substantial performance improvements in contact-rich tasks."}}
{"id": "2602.05321", "pdf": "https://arxiv.org/pdf/2602.05321", "abs": "https://arxiv.org/abs/2602.05321", "authors": ["Dongki Jung", "Jaehoon Choi", "Adil Qureshi", "Somi Jeong", "Dinesh Manocha", "Suyong Yeon"], "title": "Wid3R: Wide Field-of-View 3D Reconstruction via Camera Model Conditioning", "categories": ["cs.CV"], "comment": null, "summary": "We present Wid3R, a feed-forward neural network for visual geometry reconstruction that supports wide field-of-view camera models. Prior methods typically assume that input images are rectified or captured with pinhole cameras, since both their architectures and training datasets are tailored to perspective images only. These assumptions limit their applicability in real-world scenarios that use fisheye or panoramic cameras and often require careful calibration and undistortion. In contrast, Wid3R is a generalizable multi-view 3D estimation method that can model wide field-of-view camera types. Our approach leverages a ray representation with spherical harmonics and a novel camera model token within the network, enabling distortion-aware 3D reconstruction. Furthermore, Wid3R is the first multi-view foundation model to support feed-forward 3D reconstruction directly from 360 imagery. It demonstrates strong zero-shot robustness and consistently outperforms prior methods, achieving improvements of up to +77.33 on Stanford2D3D.", "AI": {"tldr": "Wid3R is a feed-forward neural network designed for visual geometry reconstruction supporting wide field-of-view cameras like fisheye and panoramic types, overcoming limitations posed by traditional perspective-image-based methods.", "motivation": "Existing 3D reconstruction methods primarily focus on perspective images from pinhole cameras, limiting their utility for wide field-of-view cameras in real-world scenarios, which often involve complex calibration and undistortion processes.", "method": "Wid3R employs a ray representation with spherical harmonics and incorporates a novel camera model token within its framework, enabling distortion-aware 3D reconstruction for diverse camera types.", "result": "Wid3R achieves strong zero-shot robustness and significantly surpasses previous methods, showing improvements of up to +77.33 on the Stanford2D3D benchmark.", "conclusion": "Wid3R expands the scope of multi-view 3D estimation by integrating wide field-of-view camera models, improving reconstruction accuracy and usability in real-world applications without reliance on perspective-image constraints."}}
{"id": "2602.05353", "pdf": "https://arxiv.org/pdf/2602.05353", "abs": "https://arxiv.org/abs/2602.05353", "authors": ["Ruijie Shi", "Houbin Zhang", "Yuecheng Han", "Yuheng Wang", "Jingru Fan", "Runde Yang", "Yufan Dang", "Huatao Li", "Dewen Liu", "Yuan Cheng", "Chen Qian"], "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black boxes to users. We address this by introducing Agentic Workflow Reconstruction (AWR), a new task aiming to synthesize an explicit, interpretable stand-in workflow that approximates a black-box system using only input--output access. We propose AgentXRay, a search-based framework that formulates AWR as a combinatorial optimization problem over discrete agent roles and tool invocations in a chain-structured workflow space. Unlike model distillation, AgentXRay produces editable white-box workflows that match target outputs under an observable, output-based proxy metric, without accessing model parameters. To navigate the vast search space, AgentXRay employs Monte Carlo Tree Search enhanced by a scoring-based Red-Black Pruning mechanism, which dynamically integrates proxy quality with search depth. Experiments across diverse domains demonstrate that AgentXRay achieves higher proxy similarity and reduces token consumption compared to unpruned search, enabling deeper workflow exploration under fixed iteration budgets.", "AI": {"tldr": "The paper presents AgentXRay, a framework to create transparent stand-in workflows for black-box agent systems, improving interpretability through input-output analysis.", "motivation": "The motivation is to address the opacity and lack of interpretability in many agentic systems, which operate as black boxes, by introducing a method to reconstruct transparent workflows.", "method": "AgentXRay employs a Monte Carlo Tree Search framework with a scoring-based Red-Black Pruning mechanism to reconstruct editable workflows without accessing the black-box system's parameters.", "result": "Experiments show that AgentXRay provides higher proxy similarity, reduces token consumption, and allows deeper workflow exploration compared to unpruned methods.", "conclusion": "AgentXRay enables the development of interpretable and editable stand-in workflows for black-box systems, paving the way for improved transparency and usability."}}
{"id": "2602.05559", "pdf": "https://arxiv.org/pdf/2602.05559", "abs": "https://arxiv.org/abs/2602.05559", "authors": ["Leon Riccius", "Iuri B. C. M. Rocha", "Joris Bierkens", "Hanne Kekkonen", "Frans P. van der Meer"], "title": "Piecewise Deterministic Markov Processes for Bayesian Inference of PDE Coefficients", "categories": ["stat.CO", "math.ST", "stat.AP", "stat.ML"], "comment": "38 pages, 17 figures", "summary": "We develop a general framework for piecewise deterministic Markov process (PDMP) samplers that enables efficient Bayesian inference in non-linear inverse problems with expensive likelihoods. The key ingredient is a surrogate-assisted thinning scheme in which a surrogate model provides a proposal event rate and a robust correction mechanism enforces an upper bound on the true rate by dynamically adjusting an additive offset whenever violations are detected. This construction is agnostic to the choice of surrogate and PDMP, and we demonstrate it for the Zig-Zag sampler and the Bouncy particle sampler with constant, Laplace, and Gaussian process (GP) surrogates, including gradient-informed and adaptively refined GP variants. As a representative application, we consider Bayesian inference of a spatially varying Young's modulus in a one-dimensional linear elasticity problem. Across dimensions, PDMP samplers equipped with GP-based surrogates achieve substantially higher accuracy and effective sample size per forward model evaluation than Random Walk Metropolis algorithm and the No-U-Turn sampler. The Bouncy particle sampler exhibits the most favorable overall efficiency and scaling, illustrating the potential of the proposed PDMP framework beyond this particular setting.", "AI": {"tldr": "The paper introduces a general framework for efficient Bayesian inference in non-linear inverse problems using Piecewise Deterministic Markov Process (PDMP) samplers enhanced with surrogate models. It demonstrates the superiority of the proposed method over traditional algorithms like Random Walk Metropolis and No-U-Turn sampler.", "motivation": "The paper aims to address challenges in Bayesian inference for non-linear inverse problems, which often involve computationally expensive likelihoods, by leveraging PDMP samplers combined with surrogate models to improve efficiency.", "method": "The authors utilize a surrogate-assisted thinning scheme where surrogate models provide event rate proposals. A dynamic adjustment mechanism ensures robustness by addressing violations of the upper bounds on the true rate.", "result": "The proposed framework, particularly the Bouncy particle sampler combined with Gaussian process-based surrogates, achieves significantly higher accuracy and efficiency compared to standard methods across different dimensions.", "conclusion": "The framework showcases promising advancements in PDMP samplers, highlighting their capability to enhance Bayesian inference efficiency in expensive and complex scenarios beyond specific applications."}}
{"id": "2602.04941", "pdf": "https://arxiv.org/pdf/2602.04941", "abs": "https://arxiv.org/abs/2602.04941", "authors": ["Tomas Tokar", "Scott Sanner"], "title": "Improving Set Function Approximation with Quasi-Arithmetic Neural Networks", "categories": ["cs.LG"], "comment": "To appear at ICLR 2026", "summary": "Sets represent a fundamental abstraction across many types of data. To handle the unordered nature of set-structured data, models such as DeepSets and PointNet rely on fixed, non-learnable pooling operations (e.g., sum or max) -- a design choice that can hinder the transferability of learned embeddings and limits model expressivity. More recently, learnable aggregation functions have been proposed as more expressive alternatives. In this work, we advance this line of research by introducing the Neuralized Kolmogorov Mean (NKM) -- a novel, trainable framework for learning a generalized measure of central tendency through an invertible neural function. We further propose quasi-arithmetic neural networks (QUANNs), which incorporate the NKM as a learnable aggregation function. We provide a theoretical analysis showing that, QUANNs are universal approximators for a broad class of common set-function decompositions and, thanks to their invertible neural components, learn more structured latent representations. Empirically, QUANNs outperform state-of-the-art baselines across diverse benchmarks, while learning embeddings that transfer effectively even to tasks that do not involve sets.", "AI": {"tldr": "This paper introduces the Neuralized Kolmogorov Mean (NKM) and quasi-arithmetic neural networks (QUANNs), which enhance set-based data modeling by utilizing learnable, expressive aggregation functions.", "motivation": "Current models like DeepSets use fixed pooling operations (e.g., sum, max), limiting their expressivity and the transferability of embeddings. There is a need for more expressive aggregation methods to handle unordered set-structured data effectively.", "method": "This paper introduces the Neuralized Kolmogorov Mean (NKM), a trainable framework equipped with an invertible neural function for generalized central tendency. QUANNs integrate NKM to act as a learnable aggregation function. Theoretical analysis confirms their role as universal approximators for set functions.", "result": "QUANNs outperform state-of-the-art models across diverse benchmarks and demonstrate effective transfer learning capabilities, producing better-structured latent embeddings.", "conclusion": "The proposed QUANNs, using the NKM framework, offer enhanced expressiveness, structured latent representations, and improved performance for tasks involving set-structured data."}}
{"id": "2602.05419", "pdf": "https://arxiv.org/pdf/2602.05419", "abs": "https://arxiv.org/abs/2602.05419", "authors": ["Takumi Goto", "Yusuke Sakai", "Taro Watanabe"], "title": "Grammatical Error Correction Evaluation by Optimally Transporting Edit Representation", "categories": ["cs.CL"], "comment": "Accepted to TACL. This is a pre-MIT Press publication version", "summary": "Automatic evaluation in grammatical error correction (GEC) is crucial for selecting the best-performing systems. Currently, reference-based metrics are a popular choice, which basically measure the similarity between hypothesis and reference sentences. However, similarity measures based on embeddings, such as BERTScore, are often ineffective, since many words in the source sentences remain unchanged in both the hypothesis and the reference. This study focuses on edits specifically designed for GEC, i.e., ERRANT, and computes similarity measured over the edits from the source sentence. To this end, we propose edit vector, a representation for an edit, and introduce a new metric, UOT-ERRANT, which transports these edit vectors from hypothesis to reference using unbalanced optimal transport. Experiments with SEEDA meta-evaluation show that UOT-ERRANT improves evaluation performance, particularly in the +Fluency domain where many edits occur. Moreover, our method is highly interpretable because the transport plan can be interpreted as a soft edit alignment, making UOT-ERRANT a useful metric for both system ranking and analyzing GEC systems. Our code is available from https://github.com/gotutiyan/uot-errant.", "AI": {"tldr": "The study presents UOT-ERRANT, a new metric for grammatical error correction (GEC) evaluations, leveraging edits for enhanced evaluation and interpretability.", "motivation": "Current evaluation metrics for GEC, such as similarity-based ones using embeddings, fail to differentiate edits effectively, leaving room for improvement in accuracy and interpretability.", "method": "Propose 'edit vector' to represent edits and utilize unbalanced optimal transport to align hypothesis edits with reference edits, introducing the UOT-ERRANT metric.", "result": "UOT-ERRANT achieves better evaluation accuracy, especially in domains requiring numerous edits, and provides interpretable soft edit alignment for analysis.", "conclusion": "UOT-ERRANT enhances GEC evaluation, offering both improved performance and system analysis capabilities, making it a valuable metric for assessing GEC systems."}}
{"id": "2602.06009", "pdf": "https://arxiv.org/pdf/2602.06009", "abs": "https://arxiv.org/abs/2602.06009", "authors": ["Claudio Segal", "Paulo Segal", "Carlos Eduardo de Schuller Banjar", "Felipe Paix\u00e3o", "Hudson Silva Borges", "Paulo Silveira Neto", "Eduardo Santana de Almeida", "Joanna C. S. Santos", "Anton Kocheturov", "Gaurav Kumar Srivastava", "Daniel Sadoc Menasch\u00e9"], "title": "Characterizing and Modeling the GitHub Security Advisories Review Pipeline", "categories": ["cs.CR", "cs.SE"], "comment": "Paper accepted at 23rd International Mining Software Repositories Conference (MSR 2026)", "summary": "GitHub Security Advisories (GHSA) have become a central component of open-source vulnerability disclosure and are widely used by developers and security tools. A distinctive feature of GHSA is that only a fraction of advisories are reviewed by GitHub, while the mechanisms associated with this review process remain poorly understood. In this paper, we conduct a large-scale empirical study of GHSA review processes, analyzing over 288,000 advisories spanning 2019--2025. We characterize which advisories are more likely to be reviewed, quantify review delays, and identify two distinct review-latency regimes: a fast path dominated by GitHub Repository Advisories (GRAs) and a slow path dominated by NVD-first advisories. We further develop a queueing model that accounts for this dichotomy based on the structure of the advisory processing pipeline.", "AI": {"tldr": "This paper analyzes GitHub Security Advisories (GHSAs), focusing on the review process and identifying patterns and delays using over 288,000 advisory data from 2019\u20132025.", "motivation": "To understand the understudied review process of GitHub Security Advisories (GHSAs), which play a key role in open-source vulnerability disclosure and are heavily relied upon by developers and tools.", "method": "The paper conducts a large-scale empirical study of GHSAs using over 288,000 advisories, characterizing review likelihood, identifying review delays, and categorizing latency regimes. It also employs a queueing model for advisory processing.", "result": "The study reveals patterns in which advisories are reviewed, quantifies review delays, and highlights two separate review-latency paths (fast and slow) tied to different types of advisories.", "conclusion": "The paper provides insights into GHSA review processes, uncovering the mechanisms driving review delays and latency variations while proposing a processing model to explain the observed dichotomy."}}
{"id": "2602.06038", "pdf": "https://arxiv.org/pdf/2602.06038", "abs": "https://arxiv.org/abs/2602.06038", "authors": ["Xiaopan Zhang", "Zejin Wang", "Zhixu Li", "Jianpeng Yao", "Jiachen Li"], "title": "CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "comment": "IEEE International Conference on Robotics and Automation (ICRA 2026); Project Website: https://comm-cp.github.io/", "summary": "To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.", "AI": {"tldr": "The paper addresses the challenge of cooperative task completion by heterogeneous robots using natural language commands. It introduces a novel framework, CommCP, which focuses on efficient communication and task coordination in multi-agent scenarios.", "motivation": "Robots frequently face challenges in executing natural language instructions, especially in multi-agent and multi-task settings. Effective communication is necessary for cooperative problem-solving without redundancy.", "method": "The proposed CommCP framework is based on decentralized communication using large language models. It uses conformal prediction to calibrate messages, enhancing reliability and reducing distractions.", "result": "Experimental results on a newly proposed MM-EQA benchmark demonstrated that CommCP improves task success rates and exploration efficiency compared to baseline methods.", "conclusion": "CommCP is a promising communication framework for multi-agent, multi-task embodied settings. It showcases the potential of reliable communication to improve collaboration and efficiency in heterogeneous robot systems."}}
{"id": "2602.05330", "pdf": "https://arxiv.org/pdf/2602.05330", "abs": "https://arxiv.org/abs/2602.05330", "authors": ["Jingdong Zhang", "Xiaohang Zhan", "Lingzhi Zhang", "Yizhou Wang", "Zhengming Yu", "Jionghao Wang", "Wenping Wang", "Xin Li"], "title": "MTPano: Multi-Task Panoramic Scene Understanding via Label-Free Integration of Dense Prediction Priors", "categories": ["cs.CV"], "comment": null, "summary": "Comprehensive panoramic scene understanding is critical for immersive applications, yet it remains challenging due to the scarcity of high-resolution, multi-task annotations. While perspective foundation models have achieved success through data scaling, directly adapting them to the panoramic domain often fails due to severe geometric distortions and coordinate system discrepancies. Furthermore, the underlying relations between diverse dense prediction tasks in spherical spaces are underexplored. To address these challenges, we propose MTPano, a robust multi-task panoramic foundation model established by a label-free training pipeline. First, to circumvent data scarcity, we leverage powerful perspective dense priors. We project panoramic images into perspective patches to generate accurate, domain-gap-free pseudo-labels using off-the-shelf foundation models, which are then re-projected to serve as patch-wise supervision. Second, to tackle the interference between task types, we categorize tasks into rotation-invariant (e.g., depth, segmentation) and rotation-variant (e.g., surface normals) groups. We introduce the Panoramic Dual BridgeNet, which disentangles these feature streams via geometry-aware modulation layers that inject absolute position and ray direction priors. To handle the distortion from equirectangular projections (ERP), we incorporate ERP token mixers followed by a dual-branch BridgeNet for interactions with gradient truncation, facilitating beneficial cross-task information sharing while blocking conflicting gradients from incompatible task attributes. Additionally, we introduce auxiliary tasks (image gradient, point map, etc.) to fertilize the cross-task learning process. Extensive experiments demonstrate that MTPano achieves state-of-the-art performance on multiple benchmarks and delivers competitive results against task-specific panoramic specialist foundation models.", "AI": {"tldr": "MTPano addresses challenges in panoramic imaging by leveraging perspective dense priors and designing geometry-aware multi-task learning architectures to improve scene understanding.", "motivation": "To overcome difficulties in panoramic scene understanding due to data scarcity, geometric distortions, and lack of exploration into relationships between dense prediction tasks in panoramic formats.", "method": "The authors propose MTPano with label-free training, perspective dense priors for pseudo-label generation, task disentangling using geometry-aware Panoramic Dual BridgeNet, and cross-task learning with ERP token mixers and auxiliary tasks.", "result": "MTPano outperforms existing methods on several benchmarks and competes well against task-specific panoramic models.", "conclusion": "MTPano enhances multi-task panoramic understanding by effectively handling geometric challenges and enabling robust cross-task learning in spherical spaces."}}
{"id": "2602.05354", "pdf": "https://arxiv.org/pdf/2602.05354", "abs": "https://arxiv.org/abs/2602.05354", "authors": ["Shifat E. Arman", "Syed Nazmus Sakib", "Tapodhir Karmakar Taton", "Nafiul Haque", "Shahrear Bin Amin"], "title": "PATHWAYS: Evaluating Investigation and Context Discovery in AI Web Agents", "categories": ["cs.AI"], "comment": "35 pages, 13 figures", "summary": "We introduce PATHWAYS, a benchmark of 250 multi-step decision tasks that test whether web-based agents can discover and correctly use hidden contextual information. Across both closed and open models, agents typically navigate to relevant pages but retrieve decisive hidden evidence in only a small fraction of cases. When tasks require overturning misleading surface-level signals, performance drops sharply to near chance accuracy. Agents frequently hallucinate investigative reasoning by claiming to rely on evidence they never accessed. Even when correct context is discovered, agents often fail to integrate it into their final decision. Providing more explicit instructions improves context discovery but often reduces overall accuracy, revealing a tradeoff between procedural compliance and effective judgement. Together, these results show that current web agent architectures lack reliable mechanisms for adaptive investigation, evidence integration, and judgement override.", "AI": {"tldr": "PATHWAYS is a benchmark that tests web agents' ability to discover and use hidden contextual information, revealing their challenges in investigative reasoning and decision-making.", "motivation": "The motivation is to evaluate the capabilities of current web-based agents in handling multi-step decision tasks that require discovering and integrating hidden contextual information.", "method": "The authors introduced a benchmark called PATHWAYS, consisting of 250 multi-step decision tasks to test the performance of web-based agents.", "result": "Agents generally navigate to relevant pages but struggle with discovering decisive hidden evidence, integrating context, and overriding initial biases. Performance drops significantly in misleading cases, and agents often hallucinate reasoning.", "conclusion": "Current web agent architectures lack robust mechanisms for adaptive investigation, evidence integration, and making reliable final judgments in complex decision scenarios."}}
{"id": "2602.05639", "pdf": "https://arxiv.org/pdf/2602.05639", "abs": "https://arxiv.org/abs/2602.05639", "authors": ["Amin Oji", "Paul Fieguth"], "title": "Joint Embedding Variational Bayes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We introduce Variational Joint Embedding (VJE), a framework that synthesizes joint embedding and variational inference to enable self-supervised learning of probabilistic representations in a reconstruction-free, non-contrastive setting. Compared to energy-based predictive objectives that optimize pointwise discrepancies, VJE maximizes a symmetric conditional evidence lower bound (ELBO) for a latent-variable model defined directly on encoder embeddings. We instantiate the conditional likelihood with a heavy-tailed Student-$t$ model using a polar decomposition that explicitly decouples directional and radial factors to prevent norm-induced instabilities during training. VJE employs an amortized inference network to parameterize a diagonal Gaussian variational posterior whose feature-wise variances are shared with the likelihood scale to capture anisotropic uncertainty without auxiliary projection heads. Across ImageNet-1K, CIFAR-10/100, and STL-10, VJE achieves performance comparable to standard non-contrastive baselines under linear and k-NN evaluation. We further validate these probabilistic semantics through one-class CIFAR-10 anomaly detection, where likelihood-based scoring under the proposed model outperforms comparable self-supervised baselines.", "AI": {"tldr": "A novel approach called Variational Joint Embedding (VJE) is proposed for self-supervised learning using variational inference, enabling probabilistic representations without reconstruction or contrastive methods.", "motivation": "The aim was to address challenges in reconstruction-free, non-contrastive self-supervised learning for probabilistic representations.", "method": "VJE optimizes a symmetric conditional ELBO for latent-variable models using a heavy-tailed Student-t model, decoupling directional and radial factors, while leveraging a Gaussian variational posterior for anisotropic uncertainty.", "result": "VJE shows performance comparable to standard baselines on benchmark datasets and improves anomaly detection scoring compared to self-supervised baselines.", "conclusion": "VJE demonstrates effective probabilistic semantics in self-supervised learning, providing promise for applications in anomaly detection and uncertainty modeling."}}
{"id": "2602.04942", "pdf": "https://arxiv.org/pdf/2602.04942", "abs": "https://arxiv.org/abs/2602.04942", "authors": ["Emiliano Penaloza", "Dheeraj Vattikonda", "Nicolas Gontier", "Alexandre Lacoste", "Laurent Charlin", "Massimo Caccia"], "title": "Privileged Information Distillation for Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Abstract border should have been purple", "summary": "Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce \u03c0-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that \u03c0-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on \u03c0-Distill and characterizing when OPSD is competitive.", "AI": {"tldr": "The paper introduces techniques to transfer Privileged Information (PI) learned during training to inference-time scenarios in multi-turn environments, specifically through \u03c0-Distill and On-Policy Self-Distillation (OPSD).", "motivation": "To address the challenge of transferring capabilities learned with privileged information during training to agents that must act without it at inference time, especially in environments where internal reasoning is not observable.", "method": "Develop two approaches: \u03c0-Distill, which simultaneously trains a privileged-information-conditioned teacher and an unconditioned student model; and OPSD, which uses reinforcement learning with a reverse KL penalty between the student and privileged teacher.", "result": "\u03c0-Distill and OPSD successfully distill capabilities from teachers to students using action-only PI, outperforming industry-standard approaches across multiple benchmarks and models.", "conclusion": "These methods overcome traditional limitations, showcasing effective learning even with minimal PI, enhancing agent performance in complex reinforcement learning tasks."}}
{"id": "2602.05437", "pdf": "https://arxiv.org/pdf/2602.05437", "abs": "https://arxiv.org/abs/2602.05437", "authors": ["Basel Mousi", "Fahim Dalvi", "Shammur Chowdhury", "Firoj Alam", "Nadir Durrani"], "title": "Once Correct, Still Wrong: Counterfactual Hallucination in Multilingual Vision-Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Vision-language models (VLMs) can achieve high accuracy while still accepting culturally plausible but visually incorrect interpretations. Existing hallucination benchmarks rarely test this failure mode, particularly outside Western contexts and English. We introduce M2CQA, a culturally grounded multimodal benchmark built from images spanning 17 MENA countries, paired with contrastive true and counterfactual statements in English, Arabic, and its dialects. To isolate hallucination beyond raw accuracy, we propose the CounterFactual Hallucination Rate (CFHR), which measures counterfactual acceptance conditioned on correctly answering the true statement. Evaluating state-of-the-art VLMs under multiple prompting strategies, we find that CFHR rises sharply in Arabic, especially in dialects, even when true-statement accuracy remains high. Moreover, reasoning-first prompting consistently increases counterfactual hallucination, while answering before justifying improves robustness. We will make the experimental resources and dataset publicly available for the community.", "AI": {"tldr": "The paper introduces M2CQA, a benchmark testing vision-language models (VLMs) on cultural and linguistic biases, particularly focusing on the MENA region, and evaluates these models for hallucination tendencies even when achieving high accuracy.", "motivation": "The authors aim to address the shortcomings in existing benchmarks for vision-language models (VLMs), which fail to test cultural and language biases, particularly outside Western and English-speaking contexts. They aim to explore how VLMs interact with culturally plausible but incorrect interpretations.", "method": "The M2CQA benchmark was developed using images from 17 Middle Eastern and North African (MENA) countries paired with true and counterfactual statements in English, Arabic, and Arabic dialects. A new metric, CounterFactual Hallucination Rate (CFHR), was introduced to measure the acceptance of counterfactuals conditioned on correct true-statement answers. State-of-the-art VLMs were evaluated using different prompting strategies.", "result": "Results show that VLMs exhibit higher CFHR in Arabic, especially in dialects, even when accuracy for true statements remains high. Reasoning-first prompting increases hallucination tendencies, whereas 'answer first, justify later' approaches improve performance.", "conclusion": "Vision-language models show significant challenges with cultural and linguistic biases, especially in Arabic contexts. The M2CQA benchmark and CFHR metric highlight the need for culturally aware model evaluations and improved prompting techniques to minimize hallucination tendencies."}}
{"id": "2602.04992", "pdf": "https://arxiv.org/pdf/2602.04992", "abs": "https://arxiv.org/abs/2602.04992", "authors": ["Puqi Zhou", "Charles R. Twardy", "Cynthia Lum", "Myeong Lee", "David J. Porfirio", "Michael R. Hieb", "Chris Thomas", "Xuesu Xiao", "Sungsoo Ray Hong"], "title": "Applying Ground Robot Fleets in Urban Search: Understanding Professionals' Operational Challenges and Design Opportunities", "categories": ["cs.HC", "cs.RO"], "comment": "Under review", "summary": "Urban searches demand rapid, defensible decisions and sustained physical effort under high cognitive and situational load. Incident commanders must plan, coordinate, and document time-critical operations, while field searchers execute evolving tasks in uncertain environments. With recent advances in technology, ground-robot fleets paired with computer-vision-based situational awareness and LLM-powered interfaces offer the potential to ease these operational burdens. However, no dedicated studies have examined how public safety professionals perceive such technologies or envision their integration into existing practices, risking building technically sophisticated yet impractical solutions. To address this gap, we conducted focus-group sessions with eight police officers across five local departments in Virginia. Our findings show that ground robots could reduce professionals' reliance on paper references, mental calculations, and ad-hoc coordination, alleviating cognitive and physical strain in four key challenge areas: (1) partitioning the workforce across multiple search hypotheses, (2) retaining group awareness and situational awareness, (3) building route planning that fits the lost-person profile, and (4) managing cognitive and physical fatigue under uncertainty. We further identify four design opportunities and requirements for future ground-robot fleet integration in public-safety operations: (1) scalable multi-robot planning and control interfaces, (2) agency-specific route optimization, (3) real-time replanning informed by debrief updates, and (4) vision-assisted cueing that preserves operational trust while reducing cognitive workload. We conclude with design implications for deployable, accountable, and human-centered urban-search support systems", "AI": {"tldr": "The paper discusses how ground-robot fleets, computer vision, and AI interfaces can assist in urban search operations, identifying key challenges, design opportunities, and implications for better integration into public safety.", "motivation": "The study aims to explore how new technologies like ground-robot fleets can address the physical and mental challenges faced by public safety officials during urban search operations.", "method": "Focus-group sessions were conducted with eight police officers from five local departments in Virginia to understand their perceptions and integration needs for ground-robot fleets.", "result": "Ground robots were found to alleviate strains in key areas such as workforce partitioning, situational awareness, route planning, and fatigue management. Four design requirements were identified to enhance their implementation in urban searches.", "conclusion": "Ground-robot fleets have the potential to improve urban search operations significantly if designed with human-centered, accountable, and deployable considerations."}}
{"id": "2602.05339", "pdf": "https://arxiv.org/pdf/2602.05339", "abs": "https://arxiv.org/abs/2602.05339", "authors": ["Yongwoo Kim", "Sungmin Cha", "Hyunsoo Kim", "Jaewon Lee", "Donghyun Kim"], "title": "Consistency-Preserving Concept Erasure via Unsafe-Safe Pairing and Directional Fisher-weighted Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "With the increasing versatility of text-to-image diffusion models, the ability to selectively erase undesirable concepts (e.g., harmful content) has become indispensable. However, existing concept erasure approaches primarily focus on removing unsafe concepts without providing guidance toward corresponding safe alternatives, which often leads to failure in preserving the structural and semantic consistency between the original and erased generations. In this paper, we propose a novel framework, PAIRed Erasing (PAIR), which reframes concept erasure from simple removal to consistency-preserving semantic realignment using unsafe-safe pairs. We first generate safe counterparts from unsafe inputs while preserving structural and semantic fidelity, forming paired unsafe-safe multimodal data. Leveraging these pairs, we introduce two key components: (1) Paired Semantic Realignment, a guided objective that uses unsafe-safe pairs to explicitly map target concepts to semantically aligned safe anchors; and (2) Fisher-weighted Initialization for DoRA, which initializes parameter-efficient low-rank adaptation matrices using unsafe-safe pairs, encouraging the generation of safe alternatives while selectively suppressing unsafe concepts. Together, these components enable fine-grained erasure that removes only the targeted concepts while maintaining overall semantic consistency. Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving effective concept erasure while preserving structural integrity, semantic coherence, and generation quality.", "AI": {"tldr": "This paper introduces PAIRed Erasing (PAIR), a framework for selectively erasing unsafe concepts in text-to-image diffusion models while preserving semantic and structural integrity.", "motivation": "Current concept-erasure methods fail to provide safe alternatives, resulting in loss of structural and semantic consistency, which is critical for practical applications.", "method": "The authors propose a framework called PAIRed Erasing (PAIR) that uses unsafe-safe multimodal paired data to achieve semantic realignment through paired semantic realignment objective and Fisher-weighted initialization for concept erasure.", "result": "PAIR outperforms existing methods in erasing unsafe concepts while maintaining generation quality, semantic coherence, and structural fidelity.", "conclusion": "The proposed PAIR framework achieves fine-grained and effective concept erasure by realigning unsafe concepts to their safe counterparts, advancing the potential of diffusion models."}}
{"id": "2602.05367", "pdf": "https://arxiv.org/pdf/2602.05367", "abs": "https://arxiv.org/abs/2602.05367", "authors": ["Youngcheon You", "Banseok Lee", "Minseop Choi", "Seonyoung Kim", "Hyochan Chong", "Changdong Kim", "Youngmin Kim", "Dongkyu Kim"], "title": "RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\\pm$1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a $4.49\\times$ inference speed-up over full-precision models on an RTX 4090.", "AI": {"tldr": "The paper addresses the quantization challenges in deploying large language models efficiently and proposes RaBiT for better performance while maintaining hardware efficiency.", "motivation": "To resolve the trade-off between extreme quantization for efficiency and the performance degradation in large language model deployment.", "method": "The authors introduce RaBiT, a framework that enforces a residual hierarchy by deriving binary paths sequentially from shared full-precision weights, avoiding co-adaptation through error correction.", "result": "RaBiT achieves state-of-the-art performance, outperforms hardware-intensive methods, and achieves a 4.49\u00d7 inference speed-up on an RTX 4090 GPU.", "conclusion": "RaBiT establishes a new benchmark for 2-bit quantization accuracy and efficiency, offering a significant advancement in hardware-friendly and high-performance inference."}}
{"id": "2602.05704", "pdf": "https://arxiv.org/pdf/2602.05704", "abs": "https://arxiv.org/abs/2602.05704", "authors": ["Daniel Barzilai", "Ohad Shamir"], "title": "Limitations of SGD for Multi-Index Models Beyond Statistical Queries", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Understanding the limitations of gradient methods, and stochastic gradient descent (SGD) in particular, is a central challenge in learning theory. To that end, a commonly used tool is the Statistical Queries (SQ) framework, which studies performance limits of algorithms based on noisy interaction with the data. However, it is known that the formal connection between the SQ framework and SGD is tenuous: Existing results typically rely on adversarial or specially-structured gradient noise that does not reflect the noise in standard SGD, and (as we point out here) can sometimes lead to incorrect predictions. Moreover, many analyses of SGD for challenging problems rely on non-trivial algorithmic modifications, such as restricting the SGD trajectory to the sphere or using very small learning rates. To address these shortcomings, we develop a new, non-SQ framework to study the limitations of standard vanilla SGD, for single-index and multi-index models (namely, when the target function depends on a low-dimensional projection of the inputs). Our results apply to a broad class of settings and architectures, including (potentially deep) neural networks.", "AI": {"tldr": "The paper examines the limitations of standard stochastic gradient descent (SGD) using a new, non-SQ framework, particularly for single-index and multi-index models.", "motivation": "The motivation is to understand and address the limitations of gradient-based methods like SGD and the disparity in results derived using statistical queries vs. actual SGD noise.", "method": "The authors propose a new non-SQ framework to rigorously study the limitations of vanilla SGD, considering its application in low-dimensional projection tasks and diverse architectures.", "result": "The framework effectively describes the limitations of SGD across a broad class of models, including deep neural networks.", "conclusion": "The study highlights inaccuracies in prior SQ-based analyses of SGD and provides a more realistic and general framework to investigate its inherent limitations."}}
{"id": "2602.04975", "pdf": "https://arxiv.org/pdf/2602.04975", "abs": "https://arxiv.org/abs/2602.04975", "authors": ["Jos\u00e9 Afonso", "Vasco Guerra", "Pedro Viegas"], "title": "Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.plasm-ph"], "comment": "19 pages and 4 figures", "summary": "This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simulation queries. This strategy enables efficient navigation of highly anisotropic landscapes, avoiding the computational burden of exhaustive sampling. To ensure rigorous inference, we integrate this approach with a probabilistic formulation that derives a principled objective loss function directly from observed data. We validate the framework by applying it to the problem of plasma-surface interactions, where accurate modelling is strictly limited by uncertainties in surface reactivity parameters and the computational cost of kinetic simulations. Comparative analysis demonstrates that our method consistently outperforms baseline optimization techniques in sample efficiency. This approach offers a general and scalable tool for optimizing models of complex reaction systems, ranging from plasma chemistry to biochemical networks.", "AI": {"tldr": "The paper presents a stochastic hierarchical optimization framework for efficient calibration of physical models using reduced Hessian approximation and probabilistic inference.", "motivation": "To address challenges in calibrating physical models, especially those constrained by uncertainties and computational costs, and improve sample efficiency in optimization applications.", "method": "Employing a reduced Hessian approximation combined with a probabilistic objective loss formulation, targeting stiff parameter subspace and avoiding exhaustive sampling.", "result": "Validation was done on plasma-surface interaction problems, demonstrating superior sample efficiency and performance compared to baseline optimization methods.", "conclusion": "The proposed framework offers a scalable and robust tool for optimizing complex reaction system models, improving sample efficiency and addressing uncertainties in physical modeling processes."}}
{"id": "2602.05444", "pdf": "https://arxiv.org/pdf/2602.05444", "abs": "https://arxiv.org/abs/2602.05444", "authors": ["Yao Zhou", "Zeen Song", "Wenwen Qiang", "Fengge Wu", "Shuyi Zhou", "Changwen Zheng", "Hui Xiong"], "title": "Causal Front-Door Adjustment for Robust Jailbreak Attacks on LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Safety alignment mechanisms in Large Language Models (LLMs) often operate as latent internal states, obscuring the model's inherent capabilities. Building on this observation, we model the safety mechanism as an unobserved confounder from a causal perspective. Then, we propose the \\textbf{C}ausal \\textbf{F}ront-Door \\textbf{A}djustment \\textbf{A}ttack ({\\textbf{CFA}}$^2$) to jailbreak LLM, which is a framework that leverages Pearl's Front-Door Criterion to sever the confounding associations for robust jailbreaking. Specifically, we employ Sparse Autoencoders (SAEs) to physically strip defense-related features, isolating the core task intent. We further reduce computationally expensive marginalization to a deterministic intervention with low inference complexity. Experiments demonstrate that {CFA}$^2$ achieves state-of-the-art attack success rates while offering a mechanistic interpretation of the jailbreaking process.", "AI": {"tldr": "The paper introduces CFA2, a method to jailbreak Large Language Models (LLMs) by leveraging causal inference to bypass safety alignment mechanisms.", "motivation": "To address the issue of latent safety mechanisms in LLMs masking their true capabilities, thereby limiting a clear understanding and effective utilization.", "method": "The CFA2 framework applies Pearl's Front-Door Criterion and uses Sparse Autoencoders to remove safety-related features while simplifying the computational intervention strategy.", "result": "CFA2 achieves state-of-the-art success rates in jailbreaking LLMs and provides a clear mechanistic explanation of the process.", "conclusion": "The proposed method demonstrates robust jailbreaking capabilities in LLMs and increases understanding of the impact of safety alignment through a causal perspective."}}
{"id": "2602.05349", "pdf": "https://arxiv.org/pdf/2602.05349", "abs": "https://arxiv.org/abs/2602.05349", "authors": ["Ningkang Peng", "JiuTao Zhou", "Yuhao Zhang", "Xiaoqian Peng", "Qianfeng Yu", "Linjing Qian", "Tingyu Lu", "Yi Chen", "Yanhui Gu"], "title": "Learning with Adaptive Prototype Manifolds for Out-of-Distribution Detection", "categories": ["cs.CV"], "comment": null, "summary": "Out-of-distribution (OOD) detection is a critical task for the safe deployment of machine learning models in the real world. Existing prototype-based representation learning methods have demonstrated exceptional performance. Specifically, we identify two fundamental flaws that universally constrain these methods: the Static Homogeneity Assumption (fixed representational resources for all classes) and the Learning-Inference Disconnect (discarding rich prototype quality knowledge at inference). These flaws fundamentally limit the model's capacity and performance. To address these issues, we propose APEX (Adaptive Prototype for eXtensive OOD Detection), a novel OOD detection framework designed via a Two-Stage Repair process to optimize the learned feature manifold. APEX introduces two key innovations to address these respective flaws: (1) an Adaptive Prototype Manifold (APM), which leverages the Minimum Description Length (MDL) principle to automatically determine the optimal prototype complexity $K_c^*$ for each class, thereby fundamentally resolving prototype collision; and (2) a Posterior-Aware OOD Scoring (PAOS) mechanism, which quantifies prototype quality (cohesion and separation) to bridge the learning-inference disconnect. Comprehensive experiments on benchmarks such as CIFAR-100 validate the superiority of our method, where APEX achieves new state-of-the-art performance.", "AI": {"tldr": "The paper introduces APEX, a novel OOD detection framework that optimizes feature manifolds to address issues in existing methods, achieving state-of-the-art results on benchmarks like CIFAR-100.", "motivation": "To address two fundamental flaws in existing prototype-based OOD detection methods: the Static Homogeneity Assumption and the Learning-Inference Disconnect, both of which limit model capacity and performance.", "method": "APEX employs a Two-Stage Repair process with two innovations: an Adaptive Prototype Manifold (APM) using the Minimum Description Length principle to resolve prototype collision, and a Posterior-Aware OOD Scoring (PAOS) mechanism to quantify prototype quality during inference.", "result": "The APEX framework demonstrates superior performance and achieves state-of-the-art results on benchmark datasets such as CIFAR-100.", "conclusion": "By addressing key limitations in prototype-based OOD detection, APEX significantly enhances the reliability and adaptability of machine learning models for real-world applications."}}
{"id": "2602.05381", "pdf": "https://arxiv.org/pdf/2602.05381", "abs": "https://arxiv.org/abs/2602.05381", "authors": ["Ting Fang Tan", "Kabilan Elangovan", "Andreas Pollreisz", "Kevin Bryan Dy", "Wei Yan Ng", "Joy Le Yi Wong", "Jin Liyuan", "Chrystie Quek Wan Ning", "Ashley Shuen Ying Hong", "Arun James Thirunavukarasu", "Shelley Yin-His Chang", "Jie Yao", "Dylan Hong", "Wang Zhaoran", "Amrita Gupta", "Daniel SW Ting"], "title": "Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, and MedLLaMA3-v20 in answering ophthalmology related patient queries and assessed the feasibility of LLM based evaluation against clinician grading. In this cross sectional study, 180 ophthalmology patient queries were answered by each model, generating 2160 responses. Models were selected for parameter sizes under 10 billion to enable resource efficient deployment. Responses were evaluated by three ophthalmologists of differing seniority and by GPT-4-Turbo using the S.C.O.R.E. framework assessing safety, consensus and context, objectivity, reproducibility, and explainability, with ratings assigned on a five point Likert scale. Agreement between LLM and clinician grading was assessed using Spearman rank correlation, Kendall tau statistics, and kernel density estimate analyses. Meerkat-7B achieved the highest performance with mean scores of 3.44 from Senior Consultants, 4.08 from Consultants, and 4.18 from Residents. MedLLaMA3-v20 performed poorest, with 25.5 percent of responses containing hallucinations or clinically misleading content, including fabricated terminology. GPT-4-Turbo grading showed strong alignment with clinician assessments overall, with Spearman rho of 0.80 and Kendall tau of 0.67, though Senior Consultants graded more conservatively. Overall, medical LLMs demonstrated potential for safe ophthalmic question answering, but gaps remained in clinical depth and consensus, supporting the feasibility of LLM based evaluation for large scale benchmarking and the need for hybrid automated and clinician review frameworks to guide safe clinical deployment.", "AI": {"tldr": "The study evaluates four small medical language models for answering ophthalmology queries, identifying Meerkat-7B as the best performer and highlighting remaining gaps in clinical depth and consensus.", "motivation": "To evaluate the safety, accuracy, and feasibility of using domain-specific small language models for ophthalmology-related patient queries.", "method": "The study selected four LLMs (parameter sizes under 10B) and evaluated their performance on 180 patient queries using both clinician grading and GPT-4-Turbo evaluation through the S.C.O.R.E. framework. Correlation analyses were conducted to compare grading alignment.", "result": "Meerkat-7B performed best in safety and accuracy based on clinician scores, while MedLLaMA3-v20 had the poorest performance with frequent hallucinations. GPT-4-Turbo grading aligned well with clinician assessments, indicating feasibility of automated evaluation.", "conclusion": "Medical LLMs demonstrated potential for safe ophthalmology question answering, but gaps in clinical depth and agreement were evident. A hybrid evaluation approach combining automated and clinician reviews is recommended for safe deployment."}}
{"id": "2602.05725", "pdf": "https://arxiv.org/pdf/2602.05725", "abs": "https://arxiv.org/abs/2602.05725", "authors": ["Binghui Li", "Kaifei Wang", "Han Zhong", "Pinyan Lu", "Liwei Wang"], "title": "Muon in Associative Memory Learning: Training Dynamics and Scaling Laws", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Muon updates matrix parameters via the matrix sign of the gradient and has shown strong empirical gains, yet its dynamics and scaling behavior remain unclear in theory. We study Muon in a linear associative memory model with softmax retrieval and a hierarchical frequency spectrum over query-answer pairs, with and without label noise. In this setting, we show that Gradient Descent (GD) learns frequency components at highly imbalanced rates, leading to slow convergence bottlenecked by low-frequency components. In contrast, the Muon optimizer mitigates this imbalance, leading to faster and more uniform progress. Specifically, in the noiseless case, Muon achieves an exponential speedup over GD; in the noisy case with a power-decay frequency spectrum, we derive Muon's optimization scaling law and demonstrate its superior scaling efficiency over GD. Furthermore, we show that Muon can be interpreted as an implicit matrix preconditioner arising from adaptive task alignment and block-symmetric gradient structure. In contrast, the preconditioner with coordinate-wise sign operator could match Muon under oracle access to unknown task representations, which is infeasible for SignGD in practice. Experiments on synthetic long-tail classification and LLaMA-style pre-training corroborate the theory.", "AI": {"tldr": "Muon optimizer improves convergence rates compared to Gradient Descent (GD) by addressing frequency component imbalances and achieves superior scaling efficiency in specific settings.", "motivation": "To address the limitations of Gradient Descent, which performs unevenly across frequency components, leading to slow convergence in certain settings.", "method": "Analyzed Muon in a linear associative memory model using mathematical and empirical studies, including noiseless/noisy scenarios, frequency spectrum effects, and matrix preconditioning interpretations.", "result": "Muon improves learning dynamics resulting in faster, more uniform convergence, achieves exponential speedup in noiseless cases, and outperforms GD in scaling efficiency with noise.", "conclusion": "Muon\u2019s adaptive nature and implicit matrix preconditioning offer significant advantages over traditional optimization methods, validated by theoretical insights and experiments."}}
{"id": "2602.04989", "pdf": "https://arxiv.org/pdf/2602.04989", "abs": "https://arxiv.org/abs/2602.04989", "authors": ["Itai Zilberstein", "Ioannis Anagnostides", "Zachary W. Sollie", "Arman Kilic", "Tuomas Sandholm"], "title": "Near-Optimal Dynamic Matching via Coarsening with Application to Heart Transplantation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Online matching has been a mainstay in domains such as Internet advertising and organ allocation, but practical algorithms often lack strong theoretical guarantees. We take an important step toward addressing this by developing new online matching algorithms based on a coarsening approach. Although coarsening typically implies a loss of granularity, we show that, to the contrary, aggregating offline nodes into capacitated clusters can yield near-optimal theoretical guarantees. We apply our methodology to heart transplant allocation to develop theoretically grounded policies based on structural properties of historical data. In realistic simulations, our policy closely matches the performance of the omniscient benchmark. Our work bridges the gap between data-driven heuristics and pessimistic theoretical lower bounds, and provides rigorous justification for prior clustering-based approaches in organ allocation.", "AI": {"tldr": "This paper presents a coarsening-based approach for online matching in applications like organ allocation, achieving near-optimal guarantees and validated by realistic simulations.", "motivation": "To address the gap between practical online matching algorithms with weak theoretical guarantees and robust theoretical foundations in domains such as organ allocation.", "method": "Developing coarsening-based algorithms by aggregating offline nodes into capacitated clusters, leveraging structural properties of historical data for heart transplant allocation.", "result": "The proposed policy achieves performance close to the omniscient benchmark in realistic simulations, with both theoretical and practical validation.", "conclusion": "The findings strengthen theoretical support for clustering-based algorithms in organ allocation, bridging the gap between data-driven heuristics and pessimistic theoretical lower bounds."}}
{"id": "2602.05447", "pdf": "https://arxiv.org/pdf/2602.05447", "abs": "https://arxiv.org/abs/2602.05447", "authors": ["Damon McMillan"], "title": "Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 7 figures, 10 tables, 26 references", "summary": "Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.\n  Our findings challenge common assumptions. First, architecture choice is model-dependent: file-based context retrieval improves accuracy for frontier-tier models (Claude, GPT, Gemini; +2.7%, p=0.029) but shows mixed results for open source models (aggregate -7.7%, p<0.001), with deficits varying substantially by model. Second, format does not significantly affect aggregate accuracy (chi-squared=2.45, p=0.484), though individual models, particularly open source, exhibit format-specific sensitivities. Third, model capability is the dominant factor, with a 21 percentage point accuracy gap between frontier and open source tiers that dwarfs any format or architecture effect. Fourth, file-native agents scale to 10,000 tables through domain-partitioned schemas while maintaining high navigation accuracy. Fifth, file size does not predict runtime efficiency: compact formats can consume significantly more tokens at scale due to format-unfamiliar search patterns.\n  These findings provide practitioners with evidence-based guidance for deploying LLM agents on structured systems, demonstrating that architectural decisions should be tailored to model capability rather than assuming universal best practices.", "AI": {"tldr": "This study systematically evaluates how context is structured for Large Language Models generating SQL, challenging assumptions about architecture, format, and capabilities, with results based on over 9,600 experiments.", "motivation": "The paper aims to provide empirical guidance to practitioners structuring context for LLMs operating external systems, specifically in SQL generation.", "method": "The study involves 9,649 experiments across 11 LLMs using four formats and variable schema sizes, assessing architecture, format, and capability differences.", "result": "Key findings reveal model-dependent accuracy improvements, no universal format advantage, a dominant capability gap between frontier-tier and open source models, successful scalability to 10,000 tables for file-native agents, and that compact formats do not ensure runtime efficiency.", "conclusion": "Practitioners should tailor architectural decisions to model capabilities, as universal best practices are ineffective in structured contexts for LLM agents."}}
{"id": "2602.05051", "pdf": "https://arxiv.org/pdf/2602.05051", "abs": "https://arxiv.org/abs/2602.05051", "authors": ["Songyuan Zhang", "Oswin So", "H. M. Sabbir Ahmad", "Eric Yang Yu", "Matthew Cleaveland", "Mitchell Black", "Chuchu Fan"], "title": "ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "24 pages, 17 figures; Accepted by the fourteenth International Conference on Learning Representations (ICLR 2026)", "summary": "Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed dataset generated by behavior policies without additional environment interactions. One common challenge that arises in this setting is the out-of-distribution (OOD) error, which occurs when the policy leaves the training distribution. Prior methods penalize a statistical distance term to keep the policy close to the behavior policy, but this constrains policy improvement and may not completely prevent OOD actions. Another challenge is that the optimal policy distribution can be multimodal and difficult to represent. Recent works apply diffusion or flow policies to address this problem, but it is unclear how to avoid OOD errors while retaining policy expressiveness. We propose ReFORM, an offline RL method based on flow policies that enforces the less restrictive support constraint by construction. ReFORM learns a behavior cloning (BC) flow policy with a bounded source distribution to capture the support of the action distribution, then optimizes a reflected flow that generates bounded noise for the BC flow while keeping the support, to maximize the performance. Across 40 challenging tasks from the OGBench benchmark with datasets of varying quality and using a constant set of hyperparameters for all tasks, ReFORM dominates all baselines with hand-tuned hyperparameters on the performance profile curves.", "AI": {"tldr": "Offline reinforcement learning faces challenges of out-of-distribution errors and difficulty representing optimal policy distributions. ReFORM addresses these by enforcing a less restrictive support constraint using flow-based policies.", "motivation": "The motivation is to address the challenges in offline reinforcement learning, particularly out-of-distribution errors and the difficulty of representing multimodal optimal policy distributions.", "method": "ReFORM utilizes flow policies to enforce a less restrictive support constraint by construction. It learns a behavior cloning flow policy with a bounded source distribution and optimizes a reflected flow to maximize performance while retaining the support.", "result": "ReFORM achieves superior performance, outperforming all baselines across 40 tasks in the OGBench benchmark while using a constant set of hyperparameters.", "conclusion": "ReFORM demonstrates the capability to address core challenges in offline reinforcement learning, offering an effective balance between avoiding out-of-distribution errors and retaining policy expressiveness."}}
{"id": "2602.05359", "pdf": "https://arxiv.org/pdf/2602.05359", "abs": "https://arxiv.org/abs/2602.05359", "authors": ["Yiming Zhang", "Qiangyu Yan", "Borui Jiang", "Kai Han"], "title": "Multimodal Latent Reasoning via Hierarchical Visual Cues Injection", "categories": ["cs.CV"], "comment": null, "summary": "The advancement of multimodal large language models (MLLMs) has enabled impressive perception capabilities. However, their reasoning process often remains a \"fast thinking\" paradigm, reliant on end-to-end generation or explicit, language-centric chains of thought (CoT), which can be inefficient, verbose, and prone to hallucination. This work posits that robust reasoning should evolve within a latent space, integrating multimodal signals seamlessly. We propose multimodal latent reasoning via HIerarchical Visual cuEs injection (\\emph{HIVE}), a novel framework that instills deliberate, \"slow thinking\" without depending on superficial textual rationales. Our method recursively extends transformer blocks, creating an internal loop for iterative reasoning refinement. Crucially, it injectively grounds this process with hierarchical visual cues from global scene context to fine-grained regional details directly into the model's latent representations. This enables the model to perform grounded, multi-step inference entirely in the aligned latent space. Extensive evaluations demonstrate that test-time scaling is effective when incorporating vision knowledge, and that integrating hierarchical information significantly enhances the model's understanding of complex scenes.", "AI": {"tldr": "The paper introduces HIVE, a framework to enhance multimodal large language models (MLLMs) by enabling robust, \"slow thinking\" in a latent space via hierarchical visual cues.", "motivation": "To address the limitations of current reasoning methods in MLLMs, which depend on end-to-end processing or verbose textual chains of thought, and often result in inefficiency and hallucination.", "method": "HIVE uses a recursive extension of transformer blocks and injects hierarchical visual cues (from global to fine-grained context) into the latent space to enable grounded and iterative multimodal reasoning.", "result": "The proposed method effectively utilizes test-time scaling with vision knowledge and significantly improves the model's understanding of complex scenes through hierarchical information integration.", "conclusion": "HIVE offers a robust framework for grounded multimodal reasoning in latent space, moving beyond text-dependent approaches and improving the interpretability and accuracy of MLLMs in complex scenarios."}}
{"id": "2602.05403", "pdf": "https://arxiv.org/pdf/2602.05403", "abs": "https://arxiv.org/abs/2602.05403", "authors": ["Chenghua Gong", "Yihang Jiang", "Hao Li", "Rui Sun", "Juyuan Zhang", "Tianjun Gu", "Liming Pan", "Linyuan L\u00fc"], "title": "Advancing Opinion Dynamics Modeling with Neural Diffusion-Convection-Reaction Equation", "categories": ["cs.AI", "cs.CY", "cs.SI"], "comment": null, "summary": "Advanced opinion dynamics modeling is vital for deciphering social behavior, emphasizing its role in mitigating polarization and securing cyberspace. To synergize mechanistic interpretability with data-driven flexibility, recent studies have explored the integration of Physics-Informed Neural Networks (PINNs) for opinion modeling. Despite this promise, existing methods are tailored to incomplete priors, lacking a comprehensive physical system to integrate dynamics from local, global, and endogenous levels. Moreover, penalty-based constraints adopted in existing methods struggle to deeply encode physical priors, leading to optimization pathologies and discrepancy between latent representations and physical transparency. To this end, we offer a physical view to interpret opinion dynamics via Diffusion-Convection-Reaction (DCR) system inspired by interacting particle theory. Building upon the Neural ODEs, we define the neural opinion dynamics to coordinate neural networks with physical priors, and further present the OPINN, a physics-informed neural framework for opinion dynamics modeling. Evaluated on real-world and synthetic datasets, OPINN achieves state-of-the-art performance in opinion evolution forecasting, offering a promising paradigm for the nexus of cyber, physical, and social systems.", "AI": {"tldr": "The paper introduces OPINN, a physics-informed neural framework for modeling opinion dynamics by integrating physical priors and addressing limitations of existing methods.", "motivation": "To address the shortcomings of current opinion dynamics models, which rely on incomplete priors and poorly encode physical systems, and to combine mechanistic interpretability with data-driven approaches.", "method": "The authors propose a novel framework (OPINN) based on a Diffusion-Convection-Reaction (DCR) system and Neural ODEs, embedding physical priors in opinion dynamics modeling.", "result": "OPINN demonstrates state-of-the-art performance in opinion evolution forecasting across real-world and synthetic datasets.", "conclusion": "OPINN establishes a stronger paradigm for opinion dynamics modeling, reinforcing the connection between cyber, physical, and social systems."}}
{"id": "2602.05786", "pdf": "https://arxiv.org/pdf/2602.05786", "abs": "https://arxiv.org/abs/2602.05786", "authors": ["Floris Jan Koster", "Fabio Sigrist"], "title": "Selecting Hyperparameters for Tree-Boosting", "categories": ["cs.LG", "stat.AP", "stat.ML"], "comment": null, "summary": "Tree-boosting is a widely used machine learning technique for tabular data. However, its out-of-sample accuracy is critically dependent on multiple hyperparameters. In this article, we empirically compare several popular methods for hyperparameter optimization for tree-boosting including random grid search, the tree-structured Parzen estimator (TPE), Gaussian-process-based Bayesian optimization (GP-BO), Hyperband, the sequential model-based algorithm configuration (SMAC) method, and deterministic full grid search using $59$ regression and classification data sets. We find that the SMAC method clearly outperforms all the other considered methods. We further observe that (i) a relatively large number of trials larger than $100$ is required for accurate tuning, (ii) using default values for hyperparameters yields very inaccurate models, (iii) all considered hyperparameters can have a material effect on the accuracy of tree-boosting, i.e., there is no small set of hyperparameters that is more important than others, and (iv) choosing the number of boosting iterations using early stopping yields more accurate results compared to including it in the search space for regression tasks.", "AI": {"tldr": "The study compares various hyperparameter optimization methods for tree-boosting, finding SMAC as the most effective approach.", "motivation": "To improve the out-of-sample accuracy of tree-boosting models by determining optimal hyperparameter tuning strategies.", "method": "The paper empirically evaluates hyperparameter optimization techniques, such as SMAC, random grid search, GP-BO, TPE, Hyperband, and deterministic grid search, across 59 datasets.", "result": "SMAC significantly outperformed other methods; accurate tuning requires over 100 trials, default hyperparameters perform poorly, all hyperparameters affect accuracy, and early stopping boosts regression results.", "conclusion": "Hyperparameter optimization is crucial for enhancing tree-boosting accuracy, with SMAC being the superior method among those evaluated."}}
{"id": "2602.04990", "pdf": "https://arxiv.org/pdf/2602.04990", "abs": "https://arxiv.org/abs/2602.04990", "authors": ["Ioannis Anagnostides", "Itai Zilberstein", "Zachary W. Sollie", "Arman Kilic", "Tuomas Sandholm"], "title": "Position: Machine Learning for Heart Transplant Allocation Policy Optimization Should Account for Incentives", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "The allocation of scarce donor organs constitutes one of the most consequential algorithmic challenges in healthcare. While the field is rapidly transitioning from rigid, rule-based systems to machine learning and data-driven optimization, we argue that current approaches often overlook a fundamental barrier: incentives. In this position paper, we highlight that organ allocation is not merely a static optimization problem, but rather a complex game involving transplant centers, clinicians, and regulators. Focusing on US adult heart transplant allocation, we identify critical incentive misalignments across the decision-making pipeline, and present data showing that they are having adverse consequences today. Our main position is that the next generation of allocation policies should be incentive aware. We outline a research agenda for the machine learning community, calling for the integration of mechanism design, strategic classification, causal inference, and social choice to ensure robustness, efficiency, and fairness in the face of strategic behavior from the various constituent groups.", "AI": {"tldr": "The paper addresses the issue of organ allocation in healthcare, emphasizing the need for incentive-aware policies to tackle misalignments and strategic behaviors.", "motivation": "To improve organ allocation processes by recognizing core incentive misalignments and their impact on fairness and efficiency.", "method": "Propose integrating mechanism design, strategic classification, causal inference, and social choice into machine learning frameworks for allocation.", "result": "Critical incentive misalignments across decision pipelines are identified, demonstrating adverse effects in current organ allocation systems.", "conclusion": "Machine learning-driven policies must be redesigned to factor in incentives, enabling robust, efficient, and fair organ allocation frameworks."}}
{"id": "2602.05471", "pdf": "https://arxiv.org/pdf/2602.05471", "abs": "https://arxiv.org/abs/2602.05471", "authors": ["Md. Mithun Hossaina", "Mashary N. Alrasheedy", "Nirban Bhowmick", "Shamim Forhad", "Md. Shakil Hossain", "Sudipto Chaki", "Md Shafiqul Islam"], "title": "Reasoning under Ambiguity: Uncertainty-Aware Multilingual Emotion Classification under Partial Supervision", "categories": ["cs.CL"], "comment": null, "summary": "Contemporary knowledge-based systems increasingly rely on multilingual emotion identification to support intelligent decision-making, yet they face major challenges due to emotional ambiguity and incomplete supervision. Emotion recognition from text is inherently uncertain because multiple emotional states often co-occur and emotion annotations are frequently missing or heterogeneous. Most existing multi-label emotion classification methods assume fully observed labels and rely on deterministic learning objectives, which can lead to biased learning and unreliable predictions under partial supervision. This paper introduces Reasoning under Ambiguity, an uncertainty-aware framework for multilingual multi-label emotion classification that explicitly aligns learning with annotation uncertainty. The proposed approach uses a shared multilingual encoder with language-specific optimization and an entropy-based ambiguity weighting mechanism that down-weights highly ambiguous training instances rather than treating missing labels as negative evidence. A mask-aware objective with positive-unlabeled regularization is further incorporated to enable robust learning under partial supervision. Experiments on English, Spanish, and Arabic emotion classification benchmarks demonstrate consistent improvements over strong baselines across multiple evaluation metrics, along with improved training stability, robustness to annotation sparsity, and enhanced interpretability.", "AI": {"tldr": "The paper proposes a novel uncertainty-aware framework for multilingual emotion classification in text, addressing challenges of emotional ambiguity and incomplete supervision.", "motivation": "To tackle the issues of emotional ambiguity and incomplete supervision in multilingual emotion recognition from text, which affect decision-making systems.", "method": "Developed a framework with shared multilingual encoder, language-specific optimization, entropy-based ambiguity weighting, and mask-aware objectives with positive-unlabeled regularization.", "result": "The framework demonstrated improved performance over baselines in English, Spanish, and Arabic benchmarks, with enhanced training stability, robustness, and interpretability.", "conclusion": "The proposed framework offers a reliable path for handling uncertainty and improving emotion classification in multilingual contexts."}}
{"id": "2602.05360", "pdf": "https://arxiv.org/pdf/2602.05360", "abs": "https://arxiv.org/abs/2602.05360", "authors": ["Ningkang Peng", "Xiaoqian Peng", "Yuhao Zhang", "Qianfeng Yu", "Feng Xing", "Peirong Ma", "Xichen Yang", "Yi Chen", "Tingyu Lu", "Yanhui Gu"], "title": "Breaking Semantic Hegemony: Decoupling Principal and Residual Subspaces for Generalized OOD Detection", "categories": ["cs.CV"], "comment": null, "summary": "While feature-based post-hoc methods have made significant strides in Out-of-Distribution (OOD) detection, we uncover a counter-intuitive Simplicity Paradox in existing state-of-the-art (SOTA) models: these models exhibit keen sensitivity in distinguishing semantically subtle OOD samples but suffer from severe Geometric Blindness when confronting structurally distinct yet semantically simple samples or high-frequency sensor noise. We attribute this phenomenon to Semantic Hegemony within the deep feature space and reveal its mathematical essence through the lens of Neural Collapse. Theoretical analysis demonstrates that the spectral concentration bias, induced by the high variance of the principal subspace, numerically masks the structural distribution shift signals that should be significant in the residual subspace. To address this issue, we propose D-KNN, a training-free, plug-and-play geometric decoupling framework. This method utilizes orthogonal decomposition to explicitly separate semantic components from structural residuals and introduces a dual-space calibration mechanism to reactivate the model's sensitivity to weak residual signals. Extensive experiments demonstrate that D-KNN effectively breaks Semantic Hegemony, establishing new SOTA performance on both CIFAR and ImageNet benchmarks. Notably, in resolving the Simplicity Paradox, it reduces the FPR95 from 31.3% to 2.3%; when addressing sensor failures such as Gaussian noise, it boosts the detection performance (AUROC) from a baseline of 79.7% to 94.9%.", "AI": {"tldr": "The paper uncovers the Simplicity Paradox in OOD detection, where state-of-the-art models excel in recognizing subtle semantic shifts but fail on structural anomalies or noise. It proposes D-KNN framework to overcome these challenges.", "motivation": "The motivation is to improve Out-of-Distribution detection models by addressing their inability to detect structurally distinct or noisy samples due to Semantic Hegemony and Geometric Blindness in feature spaces.", "method": "The paper introduces the D-KNN framework, utilizing orthogonal decomposition to decouple semantic features from structural residuals and employing dual-space calibration for enhanced sensitivity.", "result": "D-KNN significantly improves OOD detection by establishing new SOTA performance on benchmarks, reducing FPR95 to 2.3%, improving detection under sensor noise with AUROC from 79.7% to 94.9%.", "conclusion": "The proposed D-KNN breaks Semantic Hegemony, resolving the Simplicity Paradox and improving feature-based OOD detection models against structural and noisy input failures."}}
{"id": "2602.05407", "pdf": "https://arxiv.org/pdf/2602.05407", "abs": "https://arxiv.org/abs/2602.05407", "authors": ["Jun-Min Lee", "Meong Hi Son", "Edward Choi"], "title": "H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks, failing to capture the complexity of real administrative workflows. To address this gap, we propose H-AdminSim, a comprehensive end-to-end simulation framework that combines realistic data generation with multi-agent-based simulation of hospital administrative workflows. These tasks are quantitatively evaluated using detailed rubrics, enabling systematic comparison of LLMs. Through FHIR integration, H-AdminSim provides a unified and interoperable environment for testing administrative workflows across heterogeneous hospital settings, serving as a standardized testbed for assessing the feasibility and performance of LLM-driven administrative automation.", "AI": {"tldr": "This paper introduces H-AdminSim, a simulation framework for automating hospital administrative workflows using large language models (LLMs).", "motivation": "There's significant interest in automating hospital administration tasks using LLMs, yet existing research inadequately captures the complexity of workflows in large hospitals, focusing on isolated tasks rather than comprehensive processes.", "method": "The authors developed H-AdminSim, an end-to-end simulation framework that combines realistic data generation with multi-agent simulations of hospital administrative workflows. Evaluation is performed using detailed rubrics and FHIR integration ensures interoperability.", "result": "H-AdminSim enables standardized and systematic testing of administrative workflows using LLMs in different hospital settings. It provides a unified test environment and quantifiable evaluation metrics.", "conclusion": "H-AdminSim serves as a robust and standardized tool to explore, evaluate, and implement LLM-driven automation in hospital administration."}}
{"id": "2602.05790", "pdf": "https://arxiv.org/pdf/2602.05790", "abs": "https://arxiv.org/abs/2602.05790", "authors": ["Alina Harbuzova", "Or Ordentlich", "Yury Polyanskiy"], "title": "Price of universality in vector quantization is at most 0.11 bit", "categories": ["cs.IT", "cs.LG", "stat.ML"], "comment": "41 page, 1 figure", "summary": "Fast computation of a matrix product $W^\\top X$ is a workhorse of modern LLMs. To make their deployment more efficient, a popular approach is that of using a low-precision approximation $\\widehat W$ in place of true $W$ (\"weight-only quantization''). Information theory demonstrates that an optimal algorithm for reducing precision of $W$ depends on the (second order) statistics of $X$ and requires a careful alignment of vector quantization codebook with PCA directions of $X$ (a process known as \"waterfilling allocation''). Dependence of the codebook on statistics of $X$, however, is highly impractical. This paper proves that there exist a universal codebook that is simultaneously near-optimal for all possible statistics of $X$, in the sense of being at least as good as an $X$-adapted waterfilling codebook with rate reduced by 0.11 bit per dimension. Such universal codebook would be an ideal candidate for the low-precision storage format, a topic of active modern research, but alas the existence proof is non-constructive.\n  Equivalently, our result shows existence of a net in $\\mathbb{R}^n$ that is a nearly-optimal covering of a sphere simultaneously with respect to all Hilbert norms.", "AI": {"tldr": "This paper addresses weight-only quantization in LLMs by proving that a universal, near-optimal codebook for low-precision matrix products exists but acknowledging that its proof is theoretical and non-constructive.", "motivation": "Modern LLMs rely on efficient matrix multiplication, and weight-only quantization can improve efficiency. However, aligning quantization codebooks with the statistics of input data is impractical despite theoretical optimality.", "method": "The authors use information theory to show that a universal quantization codebook can exist for all possible input statistics, comparing its efficiency to the theoretically optimal X-adapted waterfilling codebook.", "result": "The existence of a universal codebook is mathematically established, achieving near-optimality for any statistics of X with a small efficiency trade-off (0.11 bits per dimension).", "conclusion": "The paper demonstrates the potential for universal, near-optimal quantization codebooks to improve LLM efficiency, but the proof lacks a constructive mechanism for practical implementation."}}
{"id": "2602.04998", "pdf": "https://arxiv.org/pdf/2602.04998", "abs": "https://arxiv.org/abs/2602.04998", "authors": ["Yu-Ang Lee", "Ching-Yun Ko", "Pin-Yu Chen", "Mi-Yen Yeh"], "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is the prevailing approach for efficient large language model (LLM) fine-tuning. Building on this paradigm, recent studies have proposed alternative initialization strategies and architectural modifications, reporting substantial improvements over vanilla LoRA. However, these gains are often demonstrated under fixed or narrowly tuned hyperparameter settings, despite the known sensitivity of neural networks to training configurations. In this work, we systematically re-evaluate four representative LoRA variants alongside vanilla LoRA through extensive hyperparameter searches. Across mathematical and code generation tasks on diverse model scales, we find that different LoRA methods favor distinct learning rate ranges. Crucially, once learning rates are properly tuned, all methods achieve similar peak performance (within 1-2%), with only subtle rank-dependent behaviors. These results suggest that vanilla LoRA remains a competitive baseline and that improvements reported under single training configuration may not reflect consistent methodological advantages. Finally, a second-order analysis attributes the differing optimal learning rate ranges to variations in the largest Hessian eigenvalue, aligning with classical learning theories.", "AI": {"tldr": "The paper evaluates LoRA variants systematically through hyperparameter tuning, finding that after fine-tuning, vanilla LoRA performs comparably to other modifications.", "motivation": "To investigate whether improvements in LoRA variants stem from consistent methodological advantages or are influenced by specific hyperparameter settings.", "method": "Perform systematic hyperparameter searches across multiple model scales and tasks for LoRA variants and analyze their performance differences.", "result": "After tuning learning rates, different LoRA variants demonstrated similar peak performance, suggesting that vanilla LoRA is competitive. Optimal learning rates were influenced by differences in the largest Hessian eigenvalue.", "conclusion": "Improvements in LoRA variants may not represent consistent advantages over vanilla LoRA and could be attributed to hyperparameter sensitivity and second-order effects in training dynamics."}}
{"id": "2602.05493", "pdf": "https://arxiv.org/pdf/2602.05493", "abs": "https://arxiv.org/abs/2602.05493", "authors": ["Bingru Li"], "title": "LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical utility for researchers. This paper introduces LinguistAgent, an integrated, user-friendly platform that leverages a reflective multi-model architecture to automate linguistic annotation. The system implements a dual-agent workflow, comprising an Annotator and a Reviewer, to simulate a professional peer-review process. LinguistAgent supports comparative experiments across three paradigms: Prompt Engineering (Zero/Few-shot), Retrieval-Augmented Generation, and Fine-tuning. We demonstrate LinguistAgent's efficacy using the task of metaphor identification as an example, providing real-time token-level evaluation (Precision, Recall, and $F_1$ score) against human gold standards. The application and codes are released on https://github.com/Bingru-Li/LinguistAgent.", "AI": {"tldr": "The paper introduces LinguistAgent, a platform to automate complex linguistic annotation tasks like metaphor identification using a dual-agent workflow and multiple AI paradigms.", "motivation": "To address the bottleneck of data annotation in Humanities and Social Sciences, especially in complex semantic tasks, by bridging the gap between theoretical and practical capabilities of LLMs.", "method": "The research develops LinguistAgent, a system featuring a dual-agent workflow that employs Annotator and Reviewer roles. It integrates Prompt Engineering, Retrieval-Augmented Generation, and Fine-tuning methods to evaluate linguistic annotations.", "result": "LinguistAgent effectively identifies metaphors using token-level evaluation metrics like Precision, Recall, and F1 score, achieving results comparable to human benchmarks.", "conclusion": "The study demonstrates that LinguistAgent simplifies and enhances linguistic annotation tasks, and its open-source release promotes broader adoption and further research."}}
{"id": "2602.05089", "pdf": "https://arxiv.org/pdf/2602.05089", "abs": "https://arxiv.org/abs/2602.05089", "authors": ["Ethan Rathbun", "Wo Wei Lin", "Alina Oprea", "Christopher Amato"], "title": "Beware Untrusted Simulators -- Reward-Free Backdoor Attacks in Reinforcement Learning", "categories": ["cs.CR", "cs.LG", "cs.RO"], "comment": "10 pages main body, ICLR 2026", "summary": "Simulated environments are a key piece in the success of Reinforcement Learning (RL), allowing practitioners and researchers to train decision making agents without running expensive experiments on real hardware. Simulators remain a security blind spot, however, enabling adversarial developers to alter the dynamics of their released simulators for malicious purposes. Therefore, in this work we highlight a novel threat, demonstrating how simulator dynamics can be exploited to stealthily implant action-level backdoors into RL agents. The backdoor then allows an adversary to reliably activate targeted actions in an agent upon observing a predefined ``trigger'', leading to potentially dangerous consequences. Traditional backdoor attacks are limited in their strong threat models, assuming the adversary has near full control over an agent's training pipeline, enabling them to both alter and observe agent's rewards. As these assumptions are infeasible to implement within a simulator, we propose a new attack ``Daze'' which is able to reliably and stealthily implant backdoors into RL agents trained for real world tasks without altering or even observing their rewards. We provide formal proof of Daze's effectiveness in guaranteeing attack success across general RL tasks along with extensive empirical evaluations on both discrete and continuous action space domains. We additionally provide the first example of RL backdoor attacks transferring to real, robotic hardware. These developments motivate further research into securing all components of the RL training pipeline to prevent malicious attacks.", "AI": {"tldr": "This study highlights a novel threat in Reinforcement Learning (RL), showing how adversaries can exploit simulator dynamics to stealthily implant action-level backdoors into RL agents.", "motivation": "To expose vulnerabilities in simulation environments used in RL, where adversaries can manipulate agents to perform potentially harmful actions by embedding stealthy triggers.", "method": "The researchers propose a new attack method called 'Daze,' which implants backdoors in RL agents without altering or observing their rewards, demonstrating this in both discrete and continuous action space environments.", "result": "Daze successfully implanted backdoors into RL agents, shown through formal proofs, simulations, and real robotic hardware, proving attack viability in both simulated and real-world settings.", "conclusion": "There is a critical need to secure all components of the RL training pipeline to protect against adversarial manipulations, as traditional backdoor threat models are insufficient to address these risks."}}
{"id": "2602.05362", "pdf": "https://arxiv.org/pdf/2602.05362", "abs": "https://arxiv.org/abs/2602.05362", "authors": ["Zishan Liu", "Zecong Tang", "RuoCheng Wu", "Xinzhe Zheng", "Jingyu Hu", "Ka-Hei Hui", "Haoran Xie", "Bo Dai", "Zhengzhe Liu"], "title": "Imagine a City: CityGenAgent for Procedural 3D City Generation", "categories": ["cs.CV"], "comment": null, "summary": "The automated generation of interactive 3D cities is a critical challenge with broad applications in autonomous driving, virtual reality, and embodied intelligence. While recent advances in generative models and procedural techniques have improved the realism of city generation, existing methods often struggle with high-fidelity asset creation, controllability, and manipulation. In this work, we introduce CityGenAgent, a natural language-driven framework for hierarchical procedural generation of high-quality 3D cities. Our approach decomposes city generation into two interpretable components, Block Program and Building Program. To ensure structural correctness and semantic alignment, we adopt a two-stage learning strategy: (1) Supervised Fine-Tuning (SFT). We train BlockGen and BuildingGen to generate valid programs that adhere to schema constraints, including non-self-intersecting polygons and complete fields; (2) Reinforcement Learning (RL). We design Spatial Alignment Reward to enhance spatial reasoning ability and Visual Consistency Reward to bridge the gap between textual descriptions and the visual modality. Benefiting from the programs and the models' generalization, CityGenAgent supports natural language editing and manipulation. Comprehensive evaluations demonstrate superior semantic alignment, visual quality, and controllability compared to existing methods, establishing a robust foundation for scalable 3D city generation.", "AI": {"tldr": "CityGenAgent introduces a natural language-driven framework for generating interactive 3D cities with higher semantic alignment, visual quality, and controllability.", "motivation": "The lack of high-fidelity asset creation, controllability, and easy manipulation in current city generation techniques motivated the development of a better framework.", "method": "CityGenAgent consists of two interpretable components. It utilizes supervised fine-tuning for valid program generation and reinforcement learning to improve spatial and visual alignment.", "result": "The framework surpasses existing methods in semantic alignment, visual quality, and usability, offering an efficient approach to scalable 3D city creation.", "conclusion": "CityGenAgent establishes an effective system for hierarchical procedural city generation, supporting text-based editing while addressing critical challenges in realism and manipulation."}}
{"id": "2602.05424", "pdf": "https://arxiv.org/pdf/2602.05424", "abs": "https://arxiv.org/abs/2602.05424", "authors": ["Weijian Yu", "Yuhuan Lu", "Dingqi Yang"], "title": "THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated with a triplet provide auxiliary information to further describe the rich semantics of the triplet, which can effectively boost the reasoning performance in link prediction tasks. However, existing link prediction techniques over such hyper-relational KGs (HKGs) mostly focus on a transductive setting, where KG embedding models are learned from the specific vocabulary of a given KG and subsequently can only make predictions within the same vocabulary, limiting their generalizability to previously unseen vocabularies. Against this background, we propose THOR, an inducTive link prediction technique for Hyper-relational knOwledge gRaphs. Specifically, we first introduce both relation and entity foundation graphs, modeling their fundamental inter- and intra-fact interactions in HKGs, which are agnostic to any specific relations and entities. Afterward, THOR is designed to learn from the two foundation graphs with two parallel graph encoders followed by a transformer decoder, which supports efficient masked training and fully-inductive inference. We conduct a thorough evaluation of THOR in hyper-relational link prediction tasks on 12 datasets with different settings. Results show that THOR outperforms a sizable collection of baselines, yielding 66.1%, 55.9%, and 20.4% improvement over the best-performing rule-based, semi-inductive, and fully-inductive techniques, respectively. A series of ablation studies also reveals our key design factors capturing the structural invariance transferable across HKGs for inductive tasks.", "AI": {"tldr": "This paper introduces THOR, an inductive method for link prediction over hyper-relational knowledge graphs (HKGs) that achieves significant performance improvements compared to existing approaches.", "motivation": "Current link prediction methods for hyper-relational knowledge graphs mostly focus on transductive settings, limiting their generalization to unseen vocabularies. There is a need for an inductive method to address this limitation.", "method": "The authors propose THOR, a technique utilizing relation and entity foundation graphs to model inter- and intra-fact interactions in HKGs. These graphs are processed using parallel graph encoders and a transformer decoder for masked training and fully-inductive inference.", "result": "THOR demonstrates significant performance improvements in hyper-relational link prediction tasks across 12 datasets, outperforming rule-based, semi-inductive, and fully-inductive methods by 66.1%, 55.9%, and 20.4% respectively.", "conclusion": "THOR effectively captures structural invariances in hyper-relational knowledge graphs, facilitating improved generalizability and consistent inductive link prediction performance across diverse datasets."}}
{"id": "2602.05798", "pdf": "https://arxiv.org/pdf/2602.05798", "abs": "https://arxiv.org/abs/2602.05798", "authors": ["Arnau Vilella", "Jasin Machkour", "Michael Muma", "Daniel P. Palomar"], "title": "Learning False Discovery Rate Control via Model-Based Neural Networks", "categories": ["stat.ME", "cs.LG", "eess.SP", "stat.ML"], "comment": "Accepted to IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "Controlling the false discovery rate (FDR) in high-dimensional variable selection requires balancing rigorous error control with statistical power. Existing methods with provable guarantees are often overly conservative, creating a persistent gap between the realized false discovery proportion (FDP) and the target FDR level. We introduce a learning-augmented enhancement of the T-Rex Selector framework that narrows this gap. Our approach replaces the analytical FDP estimator with a neural network trained solely on diverse synthetic datasets, enabling a substantially tighter and more accurate approximation of the FDP. This refinement allows the procedure to operate much closer to the desired FDR level, thereby increasing discovery power while maintaining effective approximate control. Through extensive simulations and a challenging synthetic genome-wide association study (GWAS), we demonstrate that our method achieves superior detection of true variables compared to existing approaches.", "AI": {"tldr": "This paper introduces a method enhancing FDR control in high-dimensional variable selection using a neural network for tighter false discovery proportion (FDP) estimation, improving statistical power and accuracy.", "motivation": "To address the gap between the realized false discovery proportion (FDP) and target FDR level in high-dimensional variable selection methods that provide provable guarantees but are overly conservative.", "method": "The paper enhances the T-Rex Selector framework by incorporating a neural network trained on synthetic datasets to refine FDP estimation.", "result": "The proposed method achieves superior detection of true variables in simulations and synthetic GWAS compared to other existing approaches.", "conclusion": "This approach enables tighter control of FDR, improving statistical power while maintaining effective approximate error control."}}
{"id": "2602.05000", "pdf": "https://arxiv.org/pdf/2602.05000", "abs": "https://arxiv.org/abs/2602.05000", "authors": ["Atula Tejaswi", "Litu Rout", "Constantine Caramanis", "Sanjay Shakkottai", "Sujay Sanghavi"], "title": "EntRGi: Entropy Aware Reward Guidance for Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Reward guidance has been applied to great success in the test-time adaptation of continuous diffusion models; it updates each denoising step using the gradients from a downstream reward model. We study reward guidance for discrete diffusion language models, where one cannot differentiate through the natural outputs of the model because they are discrete tokens. Existing approaches either replace these discrete tokens with continuous relaxations, or employ techniques like the straight-through estimator. In this work, we show the downsides of both these methods. The former degrades gradient feedback because the reward model has never been trained with continuous inputs. The latter involves incorrect optimization because the gradient evaluated at discrete tokens is used to update continuous logits. Our key innovation is to go beyond this tradeoff by introducing a novel mechanism called EntRGi: Entropy aware Reward Guidance that dynamically regulates the gradients from the reward model. By modulating the continuous relaxation using the model's confidence, our approach substantially improves reward guidance while providing reliable inputs to the reward model. We empirically validate our approach on a 7B-parameter diffusion language model across 3 diverse reward models and 3 multi-skill benchmarks, showing consistent improvements over state-of-the-art methods.", "AI": {"tldr": "The paper introduces EntRGi, a novel mechanism for reward guidance in discrete diffusion language models, addressing issues in existing methods and improving performance.", "motivation": "Existing methods for reward guidance in discrete diffusion language models face challenges due to discrete tokens; the paper aims to overcome these limitations.", "method": "Introduces EntRGi, which dynamically regulates reward gradients by modulating continuous relaxation based on model confidence.", "result": "EntRGi shows consistent improvements over state-of-the-art methods in experiments with a 7B-parameter model across diverse benchmarks.", "conclusion": "EntRGi effectively overcomes trade-offs in existing methods and enhances reward guidance performance for discrete diffusion language models."}}
{"id": "2602.05495", "pdf": "https://arxiv.org/pdf/2602.05495", "abs": "https://arxiv.org/abs/2602.05495", "authors": ["Chenhang Cui", "Binyun Yang", "Fei Shen", "Yuxin Chen", "Jingnan Zheng", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Transport and Merge: Cross-Architecture Merging for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to smaller, low-resource targets. While model merging provides an effective transfer mechanism, most existing approaches assume architecture-compatible models and therefore cannot directly transfer knowledge from large high-resource LLMs to heterogeneous low-resource targets. In this work, we propose a cross-architecture merging framework based on optimal transport (OT) that aligns activations to infer cross-neuron correspondences between heterogeneous models. The resulting transport plans are then used to guide direct weight-space fusion, enabling effective high-resource to low-resource transfer using only a small set of inputs. Extensive experiments across low-resource languages and specialized domains demonstrate consistent improvements over target models.", "AI": {"tldr": "The paper proposes a method for transferring knowledge from large language models to heterogeneous, smaller, low-resource models using optimal transport for cross-architecture merging.", "motivation": "Existing methods for transferring knowledge assume architecture compatibility between models, which limits the ability to transfer knowledge from large language models to heterogeneous, low-resource models.", "method": "The paper introduces a cross-architecture merging framework using optimal transport to align activations and guide weight-space fusion between models.", "result": "Experiments in low-resource languages and specialized domains show consistent improvements in the performance of target models.", "conclusion": "The proposed framework effectively enables knowledge transfer from high-resource models to low-resource targets, overcoming architectural disparities."}}
{"id": "2602.05380", "pdf": "https://arxiv.org/pdf/2602.05380", "abs": "https://arxiv.org/abs/2602.05380", "authors": ["Xiaoxuan He", "Siming Fu", "Wanli Li", "Zhiyuan Li", "Dacheng Yin", "Kang Rong", "Fengyun Rao", "Bo Zhang"], "title": "SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback", "categories": ["cs.CV"], "comment": null, "summary": "Aligning diffusion models with human preferences remains challenging, particularly when reward models are unavailable or impractical to obtain, and collecting large-scale preference datasets is prohibitively expensive. \\textit{This raises a fundamental question: can we achieve effective alignment using only minimal human feedback, without auxiliary reward models, by unlocking the latent capabilities within diffusion models themselves?} In this paper, we propose \\textbf{SAIL} (\\textbf{S}elf-\\textbf{A}mplified \\textbf{I}terative \\textbf{L}earning), a novel framework that enables diffusion models to act as their own teachers through iterative self-improvement. Starting from a minimal seed set of human-annotated preference pairs, SAIL operates in a closed-loop manner where the model progressively generates diverse samples, self-annotates preferences based on its evolving understanding, and refines itself using this self-augmented dataset. To ensure robust learning and prevent catastrophic forgetting, we introduce a ranked preference mixup strategy that carefully balances exploration with adherence to initial human priors. Extensive experiments demonstrate that SAIL consistently outperforms state-of-the-art methods across multiple benchmarks while using merely 6\\% of the preference data required by existing approaches, revealing that diffusion models possess remarkable self-improvement capabilities that, when properly harnessed, can effectively replace both large-scale human annotation and external reward models.", "AI": {"tldr": "This paper presents SAIL, a framework enabling diffusion models to self-improve with minimal human feedback, without external reward models.", "motivation": "Aligning diffusion models with human preferences faces challenges due to limited access to reward models, expensive preference datasets, and the need for scalable solutions.", "method": "SAIL uses an iterative self-improvement framework starting from minimal human-annotated data. The model generates samples, self-annotates preferences, and refines through a ranked preference mixup approach.", "result": "SAIL consistently achieves better performance using only 6% of the preference data required by existing methods, showcasing diffusion models' innate self-improvement capabilities.", "conclusion": "SAIL demonstrates diffusion models can achieve alignment with human preferences efficiently, reducing reliance on large-scale data and external models."}}
{"id": "2602.05429", "pdf": "https://arxiv.org/pdf/2602.05429", "abs": "https://arxiv.org/abs/2602.05429", "authors": ["Rui Lv", "Juncheng Mo", "Tianyi Chu", "Chen Rao", "Hongyi Jing", "Jiajie Teng", "Jiafu Chen", "Shiqi Zhang", "Liangzi Ding", "Shuo Fang", "Huaizhong Lin", "Ziqiang Dang", "Chenguang Ma", "Lei Zhao"], "title": "M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining", "categories": ["cs.AI", "cs.CV"], "comment": "Accepted by ICLR 2026. Supplementary material is included at the end of the main paper (16 pages, 15 figures, 2 tables)", "summary": "Graphical User Interface (GUI) agent is pivotal to advancing intelligent human-computer interaction paradigms. Constructing powerful GUI agents necessitates the large-scale annotation of high-quality user-behavior trajectory data (i.e., intent-trajectory pairs) for training. However, manual annotation methods and current GUI agent data mining approaches typically face three critical challenges: high construction cost, poor data quality, and low data richness. To address these issues, we propose M$^2$-Miner, the first low-cost and automated mobile GUI agent data-mining framework based on Monte Carlo Tree Search (MCTS). For better data mining efficiency and quality, we present a collaborative multi-agent framework, comprising InferAgent, OrchestraAgent, and JudgeAgent for guidance, acceleration, and evaluation. To further enhance the efficiency of mining and enrich intent diversity, we design an intent recycling strategy to extract extra valuable interaction trajectories. Additionally, a progressive model-in-the-loop training strategy is introduced to improve the success rate of data mining. Extensive experiments have demonstrated that the GUI agent fine-tuned using our mined data achieves state-of-the-art performance on several commonly used mobile GUI benchmarks. Our work will be released to facilitate the community research.", "AI": {"tldr": "The paper introduces M$^2$-Miner, an efficient framework for mining mobile GUI agent data, addressing the challenges of cost, data quality, and diversity.", "motivation": "Current methods for annotating GUI agent data face issues such as high costs, poor data quality, and limited diversity, hampering progress in intelligent human-computer interaction.", "method": "The researchers developed M$^2$-Miner, an automated framework leveraging Monte Carlo Tree Search (MCTS) and a multi-agent setup (InferAgent, OrchestraAgent, JudgeAgent). They also implemented intent recycling and a progressive model-in-the-loop training strategy.", "result": "The mined data significantly improved GUI agent performance, achieving state-of-the-art results on widely-used mobile GUI benchmarks.", "conclusion": "The proposed M$^2$-Miner framework enhances the efficiency, quality, and richness of mining GUI data, contributing valuable resources and advancements to the research community."}}
{"id": "2602.05799", "pdf": "https://arxiv.org/pdf/2602.05799", "abs": "https://arxiv.org/abs/2602.05799", "authors": ["Nele H. Amiri", "Sean R. Sinclair", "Maximiliano Udenio"], "title": "Non-Stationary Inventory Control with Lead Times", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We study non-stationary single-item, periodic-review inventory control problems in which the demand distribution is unknown and may change over time. We analyze how demand non-stationarity affects learning performance across inventory models, including systems with demand backlogging or lost-sales, both with and without lead times. For each setting, we propose an adaptive online algorithm that optimizes over the class of base-stock policies and establish performance guarantees in terms of dynamic regret relative to the optimal base-stock policy at each time step. Our results reveal a sharp separation across inventory models. In backlogging systems and lost-sales models with zero lead time, we show that it is possible to adapt to demand changes without incurring additional performance loss in stationary environments, even without prior knowledge of the demand distributions or the number of demand shifts. In contrast, for lost-sales systems with positive lead times, we establish weaker guarantees that reflect fundamental limitations imposed by delayed replenishment in combination with censored feedback. Our algorithms leverage the convexity and one-sided feedback structure of inventory costs to enable counterfactual policy evaluation despite demand censoring. We complement the theoretical analysis with simulation results showing that our methods significantly outperform existing benchmarks.", "AI": {"tldr": "The paper introduces adaptive algorithms for non-stationary inventory control, achieving high performance through dynamic regret guarantees. It highlights efficiency differences across inventory models based on backlogging, lost-sales, and lead times.", "motivation": "The motivation is to address the issue of unknown and time-varying demand distributions in inventory models and to improve learning performance in such dynamic settings.", "method": "Adaptive online algorithms are developed for optimizing base-stock policies and addressing different inventory settings (e.g., backlogging, lost-sales, lead times), designed to cope with demand changes dynamically.", "result": "The study demonstrates that while backlogging and zero lead-time lost-sales systems adapt effectively to demand changes, the lost-sales model with positive lead times exhibits performance limitations due to delayed replenishment and demand censoring.", "conclusion": "The research provides performance guarantees for their adaptive algorithms and validates their efficiency through simulations, showing superiority over existing benchmarks while identifying challenges in certain inventory settings."}}
{"id": "2602.05006", "pdf": "https://arxiv.org/pdf/2602.05006", "abs": "https://arxiv.org/abs/2602.05006", "authors": ["Ezequiel Lopez-Rubio", "Javier Montes-Perez", "Esteban Jose Palomo"], "title": "Enhanced QKNorm normalization for neural transformers with the Lp norm", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The normalization of query and key vectors is an essential part of the Transformer architecture. It ensures that learning is stable regardless of the scale of these vectors. Some normalization approaches are available. In this preliminary work, a generalization of the QKNorm normalization scheme is proposed. The approach is based on the Lp norm, allowing non-Euclidean norms to be employed. Experimental results demonstrate the suitability of the method for a simple problem.", "AI": {"tldr": "This paper proposes a generalized QKNorm normalization scheme for query and key vectors in Transformers using the Lp norm, showing promising results for a simple problem.", "motivation": "Normalize query and key vectors to maintain stable learning in Transformer models, regardless of their scale.", "method": "Proposed a generalized QKNorm scheme leveraging Lp norms to employ non-Euclidean normalization.", "result": "Experimental evaluations showed the effectiveness of the generalized normalization method for a basic problem setting.", "conclusion": "Lp norm-based generalization of normalization schemes could be a viable alternative for maintaining stability in Transformer learning."}}
{"id": "2602.05512", "pdf": "https://arxiv.org/pdf/2602.05512", "abs": "https://arxiv.org/abs/2602.05512", "authors": ["Larissa Pusch", "Alexandre Courtiol", "Tim Conrad"], "title": "A Human-in-the-Loop, LLM-Centered Architecture for Knowledge-Graph Question Answering", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) excel at language understanding but remain limited in knowledge-intensive domains due to hallucinations, outdated information, and limited explainability. Text-based retrieval-augmented generation (RAG) helps ground model outputs in external sources but struggles with multi-hop reasoning. Knowledge Graphs (KGs), in contrast, support precise, explainable querying, yet require a knowledge of query languages. This work introduces an interactive framework in which LLMs generate and explain Cypher graph queries and users iteratively refine them through natural language. Applied to real-world KGs, the framework improves accessibility to complex datasets while preserving factual accuracy and semantic rigor and provides insight into how model performance varies across domains. Our core quantitative evaluation is a 90-query benchmark on a synthetic movie KG that measures query explanation quality and fault detection across multiple LLMs, complemented by two smaller real-life query-generation experiments on a Hyena KG and the MaRDI (Mathematical Research Data Initiative) KG.", "AI": {"tldr": "This paper introduces a framework that allows LLMs to generate Cypher graph queries, improving their performance in knowledge reasoning and addressing the limitations of current retrieval methods, especially in domain-specific contexts.", "motivation": "To address the limitations of LLMs in knowledge-intensive domains, such as hallucinations, incomplete information, and limited explainability, by combining the benefits of KG precision and explainability with LLM accessibility.", "method": "The authors propose an interactive framework in which LLMs generate and explain Cypher graph queries. Users can iteratively refine these queries through natural language, allowing application to real-world knowledge graphs.", "result": "The framework successfully improves accessibility to complex knowledge graphs while maintaining high factual accuracy and semantic rigor. A benchmark of 90 synthetic movie-based queries evaluates its explanation quality, fault detection, and performance across multiple LLMs, supported by real-life query examples.", "conclusion": "This framework bridges the divide between natural language queries and complex KG structures, enhancing LLM interaction usability in knowledge-rich domains and providing insights into performance variations across use cases."}}
{"id": "2602.05382", "pdf": "https://arxiv.org/pdf/2602.05382", "abs": "https://arxiv.org/abs/2602.05382", "authors": ["Tina Khezresmaeilzadeh", "Jike Zhong", "Konstantinos Psounis"], "title": "VRIQ: Benchmarking and Analyzing Visual-Reasoning IQ of VLMs", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent progress in Vision Language Models (VLMs) has raised the question of whether they can reliably perform nonverbal reasoning. To this end, we introduce VRIQ (Visual Reasoning IQ), a novel benchmark designed to assess and analyze the visual reasoning ability of VLMs. We evaluate models on two sets of tasks: abstract puzzle-style and natural-image reasoning tasks. We find that on abstract puzzles, performance remains near random with an average accuracy of around 28%, while natural tasks yield better but still weak results with 45% accuracy. We also find that tool-augmented reasoning demonstrates only modest improvements. To uncover the source of this weakness, we introduce diagnostic probes targeting perception and reasoning. Our analysis demonstrates that around 56% of failures arise from perception alone, 43% from both perception and reasoning, and only a mere 1% from reasoning alone. This motivates us to design fine-grained diagnostic probe questions targeting specific perception categories (e.g., shape, count, position, 3D/depth), revealing that certain categories cause more failures than others. Our benchmark and analysis establish that current VLMs, even with visual reasoning tools, remain unreliable abstract reasoners, mostly due to perception limitations, and offer a principled basis for improving visual reasoning in multimodal systems.", "AI": {"tldr": "This paper introduces a benchmark called VRIQ to test the visual reasoning abilities of Vision Language Models (VLMs) and reveals their significant performance limitations in perception and reasoning.", "motivation": "The paper aims to address the question of whether Vision Language Models can competently perform nonverbal reasoning by developing a tool to assess these capabilities.", "method": "The researchers introduce a benchmark named VRIQ, including abstract puzzles and natural-image reasoning tasks, and analyze performance on perception and reasoning using diagnostic probes.", "result": "VLMs perform poorly, with around 28% accuracy on abstract puzzles and 45% on natural tasks. Diagnostic probes reveal that perception limitations account for most failures (56%), followed by combined perception and reasoning (43%), while reasoning-alone failures are minimal (1%).", "conclusion": "VLMs are still unreliable for abstract visual reasoning, primarily due to perception deficits. The benchmark provides insights to guide the improvement of multimodal systems."}}
{"id": "2602.05430", "pdf": "https://arxiv.org/pdf/2602.05430", "abs": "https://arxiv.org/abs/2602.05430", "authors": ["Kritchanat Ponyuenyong", "Pengyu Tu", "Jia Wei Tan", "Wei Soon Cheong", "Jamie Ng Suat Ling", "Lianlian Jiang"], "title": "Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to AI4TS Workshop @ AAAI'26 (Oral and Poster), see https://ai4ts.github.io/aaai2026", "summary": "Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture complex temporal dependencies and integrate heterogeneous data effectively. While time series foundation models (TSFMs) have shown strong performance in general time series forecasting tasks, such as traffic forecasting and weather forecasting. However, their effectiveness in day-ahead EPF, particularly in volatile markets, remains underexplored. This paper presents a spike regularization strategy and evaluates a wide range of TSFMs, including Tiny Time Mixers (TTMs), MOIRAI, MOMENT, and TimesFM, against traditional statistical and DL models such as Autoregressive Integrated Moving Average (ARIMA), Long-short Term Memory (LSTM), and Convolutional Neural Network - LSTM (CNN-LSTM) using half-hourly wholesale market data with volatile trends in Singapore. Exogenous factors (e.g. weather and calendar variables) are also incorporated into models where applicable. Results demonstrate that TSFMs consistently outperform traditional approaches, achieving up to 37.4% improvement in MAPE across various evaluation settings. The findings offer practical guidance for improving forecast accuracy and decision-making in volatile electricity markets.", "AI": {"tldr": "This paper evaluates the effectiveness of Time Series Foundation Models (TSFMs) like Tiny Time Mixers and TimesFM for day-ahead electricity price forecasting, showing significant performance improvements over traditional statistical and deep learning models.", "motivation": "The study aims to address the challenge of accurately forecasting electricity prices in highly volatile and nonlinear energy markets, where traditional models struggle to capture complex dependencies and integrate varied data sources.", "method": "The paper introduces a spike regularization strategy for TSFMs and compares various TSFMs against traditional methods like ARIMA and DL models (e.g., LSTM, CNN-LSTM) using half-hourly data from Singapore and incorporating exogenous factors.", "result": "Time Series Foundation Models significantly outperform traditional approaches, achieving up to 37.4% improvement in Mean Absolute Percentage Error (MAPE), showcasing their robustness in volatile market conditions.", "conclusion": "TSFMs provide superior forecasting performance for electricity prices, offering practical benefits for energy market stakeholders and enhancing decision-making in volatile environments."}}
{"id": "2602.05812", "pdf": "https://arxiv.org/pdf/2602.05812", "abs": "https://arxiv.org/abs/2602.05812", "authors": ["Matteo G\u00e4tzner", "Johannes Kirschner"], "title": "Principled Confidence Estimation for Deep Computed Tomography", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present a principled framework for confidence estimation in computed tomography (CT) reconstruction. Based on the sequential likelihood mixing framework (Kirschner et al., 2025), we establish confidence regions with theoretical coverage guarantees for deep-learning-based CT reconstructions. We consider a realistic forward model following the Beer-Lambert law, i.e., a log-linear forward model with Poisson noise, closely reflecting clinical and scientific imaging conditions. The framework is general and applies to both classical algorithms and deep learning reconstruction methods, including U-Nets, U-Net ensembles, and generative Diffusion models. Empirically, we demonstrate that deep reconstruction methods yield substantially tighter confidence regions than classical reconstructions, without sacrificing theoretical coverage guarantees. Our approach allows the detection of hallucinations in reconstructed images and provides interpretable visualizations of confidence regions. This establishes deep models not only as powerful estimators, but also as reliable tools for uncertainty-aware medical imaging.", "AI": {"tldr": "This paper introduces a method for estimating confidence in CT reconstructions using a framework that provides theoretical coverage guarantees. It compares classical and deep learning methods in realistic imaging scenarios and highlights the advantages of deep learning in terms of tighter confidence regions.", "motivation": "To provide a reliable and principled approach for uncertainty estimation in CT reconstruction, addressing both classical and deep-learning-based methods, and to ensure better insights into imaging reliability and accuracy.", "method": "The method is based on the sequential likelihood mixing framework, applied to a log-linear forward model with Poisson noise. It evaluates confidence regions for various CT reconstruction techniques, including U-Nets and generative models, under realistic imaging conditions.", "result": "Deep-learning-based methods significantly outperform classical ones with much tighter confidence regions while retaining theoretical coverage guarantees. The framework also enables detection of hallucinations and offers interpretable visualizations of uncertainty.", "conclusion": "The approach demonstrates the reliability of deep learning models for uncertainty estimation in CT imaging, paving the way for their expanded use in accurate and reliable medical imaging applications."}}
{"id": "2602.05012", "pdf": "https://arxiv.org/pdf/2602.05012", "abs": "https://arxiv.org/abs/2602.05012", "authors": ["Rob Romijnders", "Mohammad Mahdi Derakhshani", "Jonathan Petit", "Max Welling", "Christos Louizos", "Yuki M. Asano"], "title": "Private PoEtry: Private In-Context Learning via Product of Experts", "categories": ["cs.LG"], "comment": "8 pages", "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to adapt to new tasks with only a small set of examples at inference time, thereby avoiding task-specific fine-tuning. However, in-context examples may contain privacy-sensitive information that should not be revealed through model outputs. Existing differential privacy (DP) approaches to ICL are either computationally expensive or rely on heuristics with limited effectiveness, including context oversampling, synthetic data generation, or unnecessary thresholding. We reformulate private ICL through the lens of a Product-of-Experts model. This gives a theoretically grounded framework, and the algorithm can be trivially parallelized. We evaluate our method across five datasets in text classification, math, and vision-language. We find that our method improves accuracy by more than 30 percentage points on average compared to prior DP-ICL methods, while maintaining strong privacy guarantees.", "AI": {"tldr": "The paper addresses a more efficient and effective method for ensuring differential privacy in in-context learning for Large Language Models, achieving significant improvements in accuracy while preserving privacy.", "motivation": "Current approaches to ensure privacy in in-context learning for Large Language Models face issues such as computational inefficiency and limited effectiveness. This paper aims to develop a stronger and theoretically grounded framework to address these challenges.", "method": "The authors reformulate the problem of private in-context learning using a Product-of-Experts model, providing a parallelizable algorithm with strong privacy guarantees.", "result": "The proposed method improves accuracy by more than 30% on average across five datasets, while maintaining privacy guarantees comparable to prior methods.", "conclusion": "Their method demonstrates promising results in balancing model performance and privacy, offering a significant step forward in differential privacy applied to in-context learning."}}
{"id": "2602.05547", "pdf": "https://arxiv.org/pdf/2602.05547", "abs": "https://arxiv.org/abs/2602.05547", "authors": ["Shyam Sundhar Ramesh", "Xiaotong Ji", "Matthieu Zimmer", "Sangwoong Yoon", "Zhiyong Wang", "Haitham Bou Ammar", "Aurelien Lucchi", "Ilija Bogunovic"], "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preprint", "summary": "RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.", "AI": {"tldr": "MT-GRPO enhances multi-task optimization in RL-based post-training for large language models, achieving balanced progress, improved worst-task accuracy, and increased efficiency compared to baselines.", "motivation": "To address the imbalanced optimization associated with multi-task RL-based post-training, ensuring reliable performance across diverse tasks for real-world language model deployment.", "method": "The proposed MT-GRPO algorithm dynamically adapts task weights to optimize worst-task performance, coupled with a ratio-preserving sampler to maintain task-wise policy gradient accuracy.", "result": "Experiments demonstrate MT-GRPO outperforms standard GRPO and DAPO in worst-task accuracy with 16-28% and 6% improvements respectively, while requiring fewer training steps and maintaining competitive average accuracy.", "conclusion": "MT-GRPO effectively addresses optimization imbalance in multi-task settings, improving worst-task performance, maintaining average accuracy, and yielding substantial efficiency gains in training."}}
{"id": "2602.05121", "pdf": "https://arxiv.org/pdf/2602.05121", "abs": "https://arxiv.org/abs/2602.05121", "authors": ["Farbod Younesi", "Walter Lucia", "Amr Youssef"], "title": "Trojan Attacks on Neural Network Controllers for Robotic Systems", "categories": ["eess.SY", "cs.RO"], "comment": "Paper submitted to the 2026 IEEE Conference on Control Technology and Applications (CCTA)", "summary": "Neural network controllers are increasingly deployed in robotic systems for tasks such as trajectory tracking and pose stabilization. However, their reliance on potentially untrusted training pipelines or supply chains introduces significant security vulnerabilities. This paper investigates backdoor (Trojan) attacks against neural controllers, using a differential-drive mobile robot platform as a case study. In particular, assuming that the robot's tracking controller is implemented as a neural network, we design a lightweight, parallel Trojan network that can be embedded within the controller. This malicious module remains dormant during normal operation but, upon detecting a highly specific trigger condition defined by the robot's pose and goal parameters, compromises the primary controller's wheel velocity commands, resulting in undesired and potentially unsafe robot behaviours. We provide a proof-of-concept implementation of the proposed Trojan network, which is validated through simulation under two different attack scenarios. The results confirm the effectiveness of the proposed attack and demonstrate that neural network-based robotic control systems are subject to potentially critical security threats.", "AI": {"tldr": "This paper explores backdoor attacks on neural network controllers in robotics, demonstrating successful compromise of controller behavior using a Trojan network.", "motivation": "To address the security vulnerabilities in neural controllers used for robotic systems, especially regarding untrusted training pipelines.", "method": "The authors design a lightweight and parallel Trojan network embedded within the controller, remaining dormant and activated by specific conditions.", "result": "A proof-of-concept implementation was validated in simulation, showing the Trojan network effectively compromised the robot's control in defined attack scenarios.", "conclusion": "Neural network-based robotic systems face critical security threats due to potential Trojan attacks, highlighting the need for enhanced protective measures in controller design and training."}}
{"id": "2602.05384", "pdf": "https://arxiv.org/pdf/2602.05384", "abs": "https://arxiv.org/abs/2602.05384", "authors": ["Hao Feng", "Wei Shi", "Ke Zhang", "Xiang Fei", "Lei Liao", "Dingkang Yang", "Yongkun Du", "Xuecheng Wu", "Jingqun Tang", "Yang Liu", "Hong Chen", "Can Huang"], "title": "Dolphin-v2: Universal Document Parsing via Scalable Anchor Prompting", "categories": ["cs.CV"], "comment": null, "summary": "Document parsing has garnered widespread attention as vision-language models (VLMs) advance OCR capabilities. However, the field remains fragmented across dozens of specialized models with varying strengths, forcing users to navigate complex model selection and limiting system scalability. Moreover, existing two-stage approaches depend on axis-aligned bounding boxes for layout detection, failing to handle distorted or photographed documents effectively. To this end, we present Dolphin-v2, a two-stage document image parsing model that substantially improves upon the original Dolphin. In the first stage, Dolphin-v2 jointly performs document type classification (digital-born versus photographed) alongside layout analysis. For digital-born documents, it conducts finer-grained element detection with reading order prediction. In the second stage, we employ a hybrid parsing strategy: photographed documents are parsed holistically as complete pages to handle geometric distortions, while digital-born documents undergo element-wise parallel parsing guided by the detected layout anchors, enabling efficient content extraction. Compared with the original Dolphin, Dolphin-v2 introduces several crucial enhancements: (1) robust parsing of photographed documents via holistic page-level understanding, (2) finer-grained element detection (21 categories) with semantic attribute extraction such as author information and document metadata, and (3) code block recognition with indentation preservation, which existing systems typically lack. Comprehensive evaluations are conducted on DocPTBench, OmniDocBench, and our self-constructed RealDoc-160 benchmark. The results demonstrate substantial improvements: +14.78 points overall on the challenging OmniDocBench and 91% error reduction on photographed documents, while maintaining efficient inference through parallel processing.", "AI": {"tldr": "Dolphin-v2 advances document parsing technologies by enhancing both photographed and digital-born document parsing efficiency and accuracy.", "motivation": "The fragmentation in document parsing models makes selection complex, and current systems struggle with distorted or photographed document layouts.", "method": "Dolphin-v2 performs joint classification and layout analysis, applies hybrid parsing for digital-born and photographed documents, and introduces new features like element detection and holistic page understanding.", "result": "Dolphin-v2 shows a +14.78 points improvement on OmniDocBench and a 91% error reduction in parsing photographed documents, maintaining efficiency through parallel processing.", "conclusion": "Dolphin-v2 addresses existing model limitations, enhancing document parsing performance, scalability, and robustness for a variety of document types."}}
{"id": "2602.05464", "pdf": "https://arxiv.org/pdf/2602.05464", "abs": "https://arxiv.org/abs/2602.05464", "authors": ["Jiaquan Wang", "Yan Lyu", "Chen Li", "Yuheng Jia"], "title": "Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitations: sensitivity to subspace basis and vulnerability to inter-subspace interference. To address these challenges, we propose OD-CRL, a novel framework integrating Adaptive Orthogonal Basis Optimization (AOBO) and Null-Space Denoising Projection (NSDP). Specifically, AOBO constructs orthogonal semantic bases via singular value decomposition with a curvature-based truncation. NSDP suppresses non-target semantic interference by projecting embeddings onto the null space of irrelevant subspaces. Extensive experiments conducted across customized clustering, customized classification, and customized retrieval tasks demonstrate that OD-CRL achieves a new state-of-the-art performance with superior generalization.", "AI": {"tldr": "The paper introduces OD-CRL, a framework that improves conditional representation learning by addressing sensitivity to subspace basis and inter-subspace interference.", "motivation": "Existing methods in conditional representation learning are limited by sensitivity to subspace basis and vulnerability to inter-subspace interference, which hinders performance and generalization.", "method": "The authors propose OD-CRL, which integrates Adaptive Orthogonal Basis Optimization (AOBO) for constructing orthogonal semantic bases using singular value decomposition and curvature-based truncation, and Null-Space Denoising Projection (NSDP) to suppress unintended interference by projecting embeddings into null spaces of non-relevant subspaces.", "result": "OD-CRL demonstrated state-of-the-art performance across various tasks, including customized clustering, classification, and retrieval, confirming its effectiveness and generalization capabilities.", "conclusion": "OD-CRL successfully addresses key limitations in conditional representation learning, providing a robust and generalizable framework."}}
{"id": "2602.05852", "pdf": "https://arxiv.org/pdf/2602.05852", "abs": "https://arxiv.org/abs/2602.05852", "authors": ["Amir R. Asadi", "Akbar Davoodi", "Ramin Javadi", "Farzad Parvaresh"], "title": "Exact Recovery in the Data Block Model", "categories": ["cs.LG", "cs.IT", "stat.ML"], "comment": "35 pages", "summary": "Community detection in networks is a fundamental problem in machine learning and statistical inference, with applications in social networks, biological systems, and communication networks. The stochastic block model (SBM) serves as a canonical framework for studying community structure, and exact recovery, identifying the true communities with high probability, is a central theoretical question. While classical results characterize the phase transition for exact recovery based solely on graph connectivity, many real-world networks contain additional data, such as node attributes or labels. In this work, we study exact recovery in the Data Block Model (DBM), an SBM augmented with node-associated data, as formalized by Asadi, Abbe, and Verd\u00fa (2017). We introduce the Chernoff--TV divergence and use it to characterize a sharp exact recovery threshold for the DBM. We further provide an efficient algorithm that achieves this threshold, along with a matching converse result showing impossibility below the threshold. Finally, simulations validate our findings and demonstrate the benefits of incorporating vertex data as side information in community detection.", "AI": {"tldr": "The paper focuses on community detection using the Data Block Model (DBM), proposing new metrics and sharp thresholds for exact recovery of communities in networks.", "motivation": "To address limitations in traditional community detection methods by incorporating node-associated data, improving the accuracy and theoretical foundation of detecting community structures in networks.", "method": "The authors propose the Chernoff--TV divergence to establish thresholds for exact recovery in DBM, develop an efficient algorithm achieving these thresholds, and provide a matching converse for impossibility below them.", "result": "Sharp exact recovery threshold for DBM established using Chernoff--TV divergence, with simulations validating its utility and demonstrating the advantages of using node data in community detection.", "conclusion": "By incorporating vertex data into community detection, this paper improves recovery accuracy, provides theoretical guarantees, and demonstrates practical value through simulations."}}
{"id": "2602.05019", "pdf": "https://arxiv.org/pdf/2602.05019", "abs": "https://arxiv.org/abs/2602.05019", "authors": ["Dhruv Sarkar", "Abhishek Sinha"], "title": "A Simple Reduction Scheme for Constrained Contextual Bandits with Adversarial Contexts via Regression", "categories": ["cs.LG"], "comment": null, "summary": "We study constrained contextual bandits (CCB) with adversarially chosen contexts, where each action yields a random reward and incurs a random cost. We adopt the standard realizability assumption: conditioned on the observed context, rewards and costs are drawn independently from fixed distributions whose expectations belong to known function classes. We consider the continuing setting, in which the algorithm operates over the entire horizon even after the budget is exhausted. In this setting, the objective is to simultaneously control regret and cumulative constraint violation. Building on the seminal SquareCB framework of Foster et al. (2018), we propose a simple and modular algorithmic scheme that leverages online regression oracles to reduce the constrained problem to a standard unconstrained contextual bandit problem with adaptively defined surrogate reward functions. In contrast to most prior work on CCB, which focuses on stochastic contexts, our reduction yields improved guarantees for the more general adversarial context setting, together with a compact and transparent analysis.", "AI": {"tldr": "This paper proposes a new algorithmic approach for constrained contextual bandits (CCB) with adversarially chosen contexts, ensuring better control over regret and constraint violations.", "motivation": "To address the challenge of constrained contextual bandits in adversarial settings, improving guarantees beyond prior work that mainly focuses on stochastic contexts.", "method": "The authors build on the SquareCB framework and introduce a modular scheme that employs online regression oracles. They transform the constrained problem into an unconstrained contextual bandit problem with adaptively defined surrogate reward functions.", "result": "The proposed algorithm achieves improved performance guarantees for adversarial context settings while maintaining a compact and clear analytical approach.", "conclusion": "The reduction-based approach provides significant advancements in handling adversarial contextual settings in constrained contextual bandit problems, offering a transparent and efficient solution."}}
{"id": "2602.05633", "pdf": "https://arxiv.org/pdf/2602.05633", "abs": "https://arxiv.org/abs/2602.05633", "authors": ["Rui Jia", "Ruiyi Lan", "Fengrui Liu", "Zhongxiang Dai", "Bo Jiang", "Jing Shao", "Jingyuan Chen", "Guandong Xu", "Fei Wu", "Min Zhang"], "title": "CASTLE: A Comprehensive Benchmark for Evaluating Student-Tailored Personalized Safety in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have advanced the development of personalized learning in education. However, their inherent generation mechanisms often produce homogeneous responses to identical prompts. This one-size-fits-all mechanism overlooks the substantial heterogeneity in students cognitive and psychological, thereby posing potential safety risks to vulnerable groups. Existing safety evaluations primarily rely on context-independent metrics such as factual accuracy, bias, or toxicity, which fail to capture the divergent harms that the same response might cause across different student attributes. To address this gap, we propose the concept of Student-Tailored Personalized Safety and construct CASTLE based on educational theories. This benchmark covers 15 educational safety risks and 14 student attributes, comprising 92,908 bilingual scenarios. We further design three evaluation metrics: Risk Sensitivity, measuring the model ability to detect risks; Emotional Empathy, evaluating the model capacity to recognize student states; and Student Alignment, assessing the match between model responses and student attributes. Experiments on 18 SOTA LLMs demonstrate that CASTLE poses a significant challenge: all models scored below an average safety rating of 2.3 out of 5, indicating substantial deficiencies in personalized safety assurance.", "AI": {"tldr": "The paper presents CASTLE, a benchmark evaluating the personalized safety of large language models (LLMs) in education.", "motivation": "Address the one-size-fits-all responses of LLMs and assess their safety risks within personalized learning contexts.", "method": "Construct the CASTLE benchmark with 92,908 bilingual scenarios, covering 15 educational safety risks and 14 student attributes, and design metrics for evaluation.", "result": "Experiments show that 18 state-of-the-art LLMs fail to achieve acceptable personalized safety ratings, scoring below 2.3 out of 5 on average.", "conclusion": "CASTLE highlights the deficiencies of LLMs in personalized safety assurance and provides a comprehensive framework for evaluation to guide improvements in educational AI."}}
{"id": "2602.05142", "pdf": "https://arxiv.org/pdf/2602.05142", "abs": "https://arxiv.org/abs/2602.05142", "authors": ["Rulla Al-Haideri", "Bilal Farooq"], "title": "Modelling Pedestrian Behaviour in Autonomous Vehicle Encounters Using Naturalistic Dataset", "categories": ["physics.soc-ph", "cs.RO"], "comment": null, "summary": "Understanding how pedestrians adjust their movement when interacting with autonomous vehicles (AVs) is essential for improving safety in mixed traffic. This study examines micro-level pedestrian behaviour during midblock encounters in the NuScenes dataset using a hybrid discrete choice-machine learning framework based on the Residual Logit (ResLogit) model. The model incorporates temporal, spatial, kinematic, and perceptual indicators. These include relative speed, visual looming, remaining distance, and directional collision risk proximity (CRP) measures. Results suggest that some of these variables may meaningfully influence movement adjustments, although predictive performance remains moderate. Marginal effects and elasticities indicate strong directional asymmetries in risk perception, with frontal and rear CRP showing opposite influences. The remaining distance exhibits a possible mid-crossing threshold. Relative speed cues appear to have a comparatively less effect. These patterns may reflect multiple behavioural tendencies driven by both risk perception and movement efficiency.", "AI": {"tldr": "The study analyzes pedestrian responses to autonomous vehicles during midblock encounters, using a hybrid model to incorporate various indicators of risk and movement efficiency.", "motivation": "To enhance safety in scenarios where pedestrians interact with autonomous vehicles by understanding their behavioral adjustments.", "method": "The study employs a hybrid discrete choice-machine learning framework based on the Residual Logit model, integrating temporal, spatial, kinematic, and perceptual factors.", "result": "Some indicators such as directional collision risk proximity and remaining distance show significant effects on pedestrian movement, while relative speed has less influence.", "conclusion": "Findings reveal asymmetries in risk perception and nuanced pedestrian decision-making, offering insights for improving AV-pedestrian interaction safety."}}
{"id": "2602.05387", "pdf": "https://arxiv.org/pdf/2602.05387", "abs": "https://arxiv.org/abs/2602.05387", "authors": ["Zolnamar Dorjsembe", "Hung-Yi Chen", "Furen Xiao", "Hsing-Kuo Pao"], "title": "Parallel Swin Transformer-Enhanced 3D MRI-to-CT Synthesis for MRI-Only Radiotherapy Planning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "MRI provides superior soft tissue contrast without ionizing radiation; however, the absence of electron density information limits its direct use for dose calculation. As a result, current radiotherapy workflows rely on combined MRI and CT acquisitions, increasing registration uncertainty and procedural complexity. Synthetic CT generation enables MRI only planning but remains challenging due to nonlinear MRI-CT relationships and anatomical variability. We propose Parallel Swin Transformer-Enhanced Med2Transformer, a 3D architecture that integrates convolutional encoding with dual Swin Transformer branches to model both local anatomical detail and long-range contextual dependencies. Multi-scale shifted window attention with hierarchical feature aggregation improves anatomical fidelity. Experiments on public and clinical datasets demonstrate higher image similarity and improved geometric accuracy compared with baseline methods. Dosimetric evaluation shows clinically acceptable performance, with a mean target dose error of 1.69%. Code is available at: https://github.com/mobaidoctor/med2transformer.", "AI": {"tldr": "The paper proposes a novel MRI-to-synthetic CT generation method using Parallel Swin Transformer-Enhanced Med2Transformer architecture for improved radiotherapy planning, achieving higher accuracy and clinically acceptable results.", "motivation": "Current radiotherapy relies on MRI and CT combined workflows due to MRI's superior soft tissue contrast but inability for direct dose calculation. The aim is to develop MRI-only planning that eliminates registration uncertainty and improves procedural efficiency.", "method": "The study introduces a 3D architecture combining convolutional encoding with dual Swin Transformer branches for modeling local anatomical detail and long-range dependencies. Multi-scale shifted window attention and hierarchical feature aggregation are employed to refine anatomical fidelity.", "result": "The proposed method outperformed baseline approaches in terms of image similarity and geometric accuracy, achieving a clinically acceptable mean target dose error of 1.69% in dosimetric evaluation.", "conclusion": "Parallel Swin Transformer-Enhanced Med2Transformer is effective for generating synthetic CTs from MRI data, offering improved radiotherapy workflow efficiency and reducing reliance on combined MRI-CT procedures."}}
{"id": "2602.05472", "pdf": "https://arxiv.org/pdf/2602.05472", "abs": "https://arxiv.org/abs/2602.05472", "authors": ["Yiwen Duan", "Jing Ye", "Xinpei Zhao"], "title": "ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \\textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \\textbf{costly} to scale, \\textbf{brittle} across domains, and \\textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \\textbf{ALIVE} (\\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \\emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.", "AI": {"tldr": "The paper introduces ALIVE, a reasoning framework for Large Language Models that replaces scalar rewards with intrinsic reasoning acquisition, showing improved accuracy and generalization across domains.", "motivation": "There is a reward bottleneck in traditional RL approaches for LLM reasoning, which limits self-contained understanding and generalization.", "method": "ALIVE combines adversarial learning with instructive verbal feedback, integrating problem posing, solving, and judging into a unified process for reasoning acquisition.", "result": "ALIVE achieves improved accuracy, better cross-domain generalization, and higher self-correction rates across benchmarks for reasoning tasks.", "conclusion": "The framework demonstrates that comprehensive internalization of reasoning principles drives scalable and domain-independent reasoning alignment, removing the need for human supervision."}}
{"id": "2602.05861", "pdf": "https://arxiv.org/pdf/2602.05861", "abs": "https://arxiv.org/abs/2602.05861", "authors": ["Seyedmasoud Mousavi", "Ruomeng Xu", "Xiaojing Zhu"], "title": "CFRecs: Counterfactual Recommendations on Real Estate User Listing Interaction Graphs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Graph-structured data is ubiquitous and powerful in representing complex relationships in many online platforms. While graph neural networks (GNNs) are widely used to learn from such data, counterfactual graph learning has emerged as a promising approach to improve model interpretability. Counterfactual explanation research focuses on identifying a counterfactual graph that is similar to the original but leads to different predictions. These explanations optimize two objectives simultaneously: the sparsity of changes in the counterfactual graph and the validity of its predictions. Building on these qualitative optimization goals, this paper introduces CFRecs, a novel framework that transforms counterfactual explanations into actionable insights. CFRecs employs a two-stage architecture consisting of a graph neural network (GNN) and a graph variational auto-encoder (Graph-VAE) to strategically propose minimal yet high-impact changes in graph structure and node attributes to drive desirable outcomes in recommender systems. We apply CFRecs to Zillow's graph-structured data to deliver actionable recommendations for both home buyers and sellers with the goal of helping them navigate the competitive housing market and achieve their homeownership goals. Experimental results on Zillow's user-listing interaction data demonstrate the effectiveness of CFRecs, which also provides a fresh perspective on recommendations using counterfactual reasoning in graphs.", "AI": {"tldr": "The paper introduces CFRecs, a framework combining GNN and Graph-VAE to produce actionable recommendations using counterfactual graph reasoning, applied to Zillow's data.", "motivation": "To improve interpretability of recommender systems by leveraging counterfactual reasoning on graph-structured data.", "method": "The framework uses a two-stage architecture combining Graph Neural Network (GNN) and Graph Variational Auto-Encoder (Graph-VAE) to identify minimal impactful changes in graph structure and node attributes.", "result": "CFRecs demonstrated effectiveness in delivering actionable recommendations in Zillow's user-listing interaction data.", "conclusion": "CFRecs offers a promising approach to enhance recommendation systems with counterfactual reasoning, improving user outcomes in competitive housing markets."}}
{"id": "2602.05026", "pdf": "https://arxiv.org/pdf/2602.05026", "abs": "https://arxiv.org/abs/2602.05026", "authors": ["Inkee Jung", "Siu Cheong Lau"], "title": "Laws of Learning Dynamics and the Core of Learners", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": "14 pages, 5 figures", "summary": "We formulate the fundamental laws governing learning dynamics, namely the conservation law and the decrease of total entropy. Within this framework, we introduce an entropy-based lifelong ensemble learning method. We evaluate its effectiveness by constructing an immunization mechanism to defend against transfer-based adversarial attacks on the CIFAR-10 dataset. Compared with a naive ensemble formed by simply averaging models specialized on clean and adversarial samples, the resulting logifold achieves higher accuracy in most test cases, with particularly large gains under strong perturbations.", "AI": {"tldr": "The paper presents an entropy-based lifelong ensemble learning approach to tackle adversarial attacks, demonstrating improved accuracy on the CIFAR-10 dataset under strong perturbations.", "motivation": "The motivation is to address the challenge of defending against transfer-based adversarial attacks and improve ensemble learning performance.", "method": "An entropy-based lifelong ensemble learning method is proposed, incorporating a conservation law and decreasing total entropy principles.", "result": "The proposed method achieves higher accuracy, especially under strong perturbations, compared to naive ensemble models.", "conclusion": "The entropy-based lifelong ensemble learning approach shows promise in improving model resilience against adversarial attacks, validated through experiments on CIFAR-10."}}
{"id": "2602.05648", "pdf": "https://arxiv.org/pdf/2602.05648", "abs": "https://arxiv.org/abs/2602.05648", "authors": ["Giuseppe Samo", "Paola Merlo"], "title": "Modelling the Morphology of Verbal Paradigms: A Case Study in the Tokenization of Turkish and Hebrew", "categories": ["cs.CL"], "comment": "13 pages, 7 figures, to appear as proceedings of the SIGTURK 2026 Workshop", "summary": "We investigate how transformer models represent complex verb paradigms in Turkish and Modern Hebrew, concentrating on how tokenization strategies shape this ability. Using the Blackbird Language Matrices task on natural data, we show that for Turkish -- with its transparent morphological markers -- both monolingual and multilingual models succeed, either when tokenization is atomic or when it breaks words into small subword units. For Hebrew, instead, monolingual and multilingual models diverge. A multilingual model using character-level tokenization fails to capture the language non-concatenative morphology, but a monolingual model with morpheme-aware segmentation performs well. Performance improves on more synthetic datasets, in all models.", "AI": {"tldr": "The study explores how transformer models represent verb paradigms in Turkish and Hebrew, emphasizing tokenization's impact.", "motivation": "The paper aims to understand how tokenization strategies influence transformer models' ability to process complex verb paradigms in morphologically rich languages.", "method": "Turkish and Hebrew verb paradigms representation is analyzed using Blackbird Language Matrices task with both natural and synthetic datasets under varying tokenization setups.", "result": "For Turkish, both monolingual and multilingual models succeed with atomic or subword tokenization. For Hebrew, morpheme-aware monolingual models perform better than multilingual models with character-level tokenization. Synthetic datasets improve performance across all models.", "conclusion": "Tokenization strategy plays a crucial role, especially in morphologically complex languages, and morpheme-aware segmentation can enhance model comprehension of languages like Hebrew."}}
{"id": "2602.05391", "pdf": "https://arxiv.org/pdf/2602.05391", "abs": "https://arxiv.org/abs/2602.05391", "authors": ["Qianxin Xia", "Jiawei Du", "Yuhan Zhang", "Jielei Wang", "Guoming Lu"], "title": "Dataset Distillation via Relative Distribution Matching and Cognitive Heritage", "categories": ["cs.CV"], "comment": null, "summary": "Dataset distillation seeks to synthesize a highly compact dataset that achieves performance comparable to the original dataset on downstream tasks. For the classification task that use pre-trained self-supervised models as backbones, previous linear gradient matching optimizes synthetic images by encouraging them to mimic the gradient updates induced by real images on the linear classifier. However, this batch-level formulation requires loading thousands of real images and applying multiple rounds of differentiable augmentations to synthetic images at each distillation step, leading to substantial computational and memory overhead. In this paper, we introduce statistical flow matching , a stable and efficient supervised learning framework that optimizes synthetic images by aligning constant statistical flows from target class centers to non-target class centers in the original data. Our approach loads raw statistics only once and performs a single augmentation pass on the synthetic data, achieving performance comparable to or better than the state-of-the-art methods with 10x lower GPU memory usage and 4x shorter runtime. Furthermore, we propose a classifier inheritance strategy that reuses the classifier trained on the original dataset for inference, requiring only an extremely lightweight linear projector and marginal storage while achieving substantial performance gains.", "AI": {"tldr": "The paper introduces an optimized method for dataset distillation by aligning statistical flows between class centers, cutting down computational and memory requirements while maintaining high performance.", "motivation": "To address the inefficiency and high computational/memory overhead of existing dataset distillation techniques when using pre-trained models for classification tasks.", "method": "Proposing 'statistical flow matching,' where synthetic images align with statistical flows between target and non-target class centers, requiring minimal data loading and augmentation steps. A classifier inheritance strategy is also introduced.", "result": "The method achieves comparable or superior performance to state-of-the-art distillation techniques while reducing GPU memory usage by 10x and runtime by 4x.", "conclusion": "The proposed framework offers a more efficient, lightweight, and high-performing solution for dataset distillation, improving practicality in resource-constrained environments."}}
{"id": "2602.05479", "pdf": "https://arxiv.org/pdf/2602.05479", "abs": "https://arxiv.org/abs/2602.05479", "authors": ["Zhe Wang", "Zijing Liu", "Chencheng Xu", "Yuan Yao"], "title": "Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction", "categories": ["cs.AI"], "comment": "Accepted to BIBM 2025. 6 pages, 5 figures", "summary": "Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.", "AI": {"tldr": "Drug discovery is expensive and time-consuming. The paper introduces Phi-former, a model designed to better predict compound-protein interactions by considering molecular motifs and their biological significance.", "motivation": "To improve the prediction of compound-protein interactions, addressing limitations of traditional and deep-learning methods that lack alignment with biological recognition and binding processes.", "method": "Phi-former employs a hierarchical representation learning framework that models interactions explicitly at atom-atom, motif-motif, and atom-motif levels. It includes intra-level and inter-level learning pipelines to enhance mutual benefits across these levels.", "result": "Phi-former outperforms existing approaches on CPI-related tasks and provides interpretable insights by identifying activated atoms or motifs in CPIs.", "conclusion": "Phi-former offers a biologically-aligned approach for CPI prediction, potentially aiding more precise drug design and precision medicine interventions."}}
{"id": "2602.05946", "pdf": "https://arxiv.org/pdf/2602.05946", "abs": "https://arxiv.org/abs/2602.05946", "authors": ["Rajdeep Haldar", "Lantao Mei", "Guang Lin", "Yue Xing", "Qifan Song"], "title": "$f$-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recent research shows that Preference Alignment (PA) objectives act as divergence estimators between aligned (chosen) and unaligned (rejected) response distributions. In this work, we extend this divergence-based perspective to general alignment settings, such as reinforcement learning with verifiable rewards (RLVR), where only environmental rewards are available. Within this unified framework, we propose $f$-Group Relative Policy Optimization ($f$-GRPO), a class of on-policy reinforcement learning, and $f$-Hybrid Alignment Loss ($f$-HAL), a hybrid on/off policy objectives, for general LLM alignment based on variational representation of $f$-divergences. We provide theoretical guarantees that these classes of objectives improve the average reward after alignment. Empirically, we validate our framework on both RLVR (Math Reasoning) and PA tasks (Safety Alignment), demonstrating superior performance and flexibility compared to current methods.", "AI": {"tldr": "This paper proposes new frameworks for general alignment settings using $f$-divergence methods, and validates their performance theoretically and empirically.", "motivation": "The study aims to address the limitations in current alignment approaches and unify these settings under a general framework for better adaptability and efficiency.", "method": "The paper utilizes $f$-divergence-based frameworks, proposing $f$-Group Relative Policy Optimization ($f$-GRPO) and $f$-Hybrid Alignment Loss ($f$-HAL) for improving reinforcement learning and preference alignment tasks.", "result": "The proposed methods demonstrated theoretical guarantees for improving rewards, and exhibited superior empirical performance in Math Reasoning and Safety Alignment tasks.", "conclusion": "The results validate the robustness and flexibility of the proposed frameworks, paving the way for enhanced alignment techniques in reinforcement learning and preference alignment tasks."}}
{"id": "2602.05031", "pdf": "https://arxiv.org/pdf/2602.05031", "abs": "https://arxiv.org/abs/2602.05031", "authors": ["Dikshant Shehmar", "Matthew Schlegel", "Matthew E. Taylor", "Marlos C. Machado"], "title": "Laplacian Representations for Decision-Time Planning", "categories": ["cs.LG"], "comment": null, "summary": "Planning with a learned model remains a key challenge in model-based reinforcement learning (RL). In decision-time planning, state representations are critical as they must support local cost computation while preserving long-horizon structure. In this paper, we show that the Laplacian representation provides an effective latent space for planning by capturing state-space distances at multiple time scales. This representation preserves meaningful distances and naturally decomposes long-horizon problems into subgoals, also mitigating the compounding errors that arise over long prediction horizons. Building on these properties, we introduce ALPS, a hierarchical planning algorithm, and demonstrate that it outperforms commonly used baselines on a selection of offline goal-conditioned RL tasks from OGBench, a benchmark previously dominated by model-free methods.", "AI": {"tldr": "The paper introduces ALPS, a hierarchical planning algorithm using Laplacian representations in model-based RL, showcasing its effectiveness in planning and outperforming model-free baselines on goal-conditioned tasks.", "motivation": "To address challenges in model-based RL planning, particularly in dealing with state representation complexities and long-horizon prediction errors.", "method": "The paper utilizes Laplacian representations to develop ALPS, a hierarchical planning algorithm that decomposes long-horizon tasks into subgoals leveraging meaningful latent space distances.", "result": "ALPS demonstrates superior performance compared to standard baselines on offline goal-conditioned RL tasks from OGBench, traditionally dominated by model-free methods.", "conclusion": "Laplacian representations enhance planning in model-based RL by addressing prediction errors and providing hierarchical task decomposition capabilities, making ALPS an effective algorithm for long-horizon decision-making."}}
{"id": "2602.05692", "pdf": "https://arxiv.org/pdf/2602.05692", "abs": "https://arxiv.org/abs/2602.05692", "authors": ["Congbo Ma", "Yichun Zhang", "Yousef Al-Jazzazi", "Ahamed Foisal", "Laasya Sharma", "Yousra Sadqi", "Khaled Saleh", "Jihad Mallat", "Farah E. Shamout"], "title": "MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations", "categories": ["cs.CL"], "comment": null, "summary": "Inaccuracies in existing or generated clinical text may lead to serious adverse consequences, especially if it is a misdiagnosis or incorrect treatment suggestion. With Large Language Models (LLMs) increasingly being used across diverse healthcare applications, comprehensive evaluation through dedicated benchmarks is crucial. However, such datasets remain scarce, especially across diverse languages and contexts. In this paper, we introduce MedErrBench, the first multilingual benchmark for error detection, localization, and correction, developed under the guidance of experienced clinicians. Based on an expanded taxonomy of ten common error types, MedErrBench covers English, Arabic and Chinese, with natural clinical cases annotated and reviewed by domain experts. We assessed the performance of a range of general-purpose, language-specific, and medical-domain language models across all three tasks. Our results reveal notable performance gaps, particularly in non-English settings, highlighting the need for clinically grounded, language-aware systems. By making MedErrBench and our evaluation protocols publicly-available, we aim to advance multilingual clinical NLP to promote safer and more equitable AI-based healthcare globally. The dataset is available in the supplementary material. An anonymized version of the dataset is available at: https://github.com/congboma/MedErrBench.", "AI": {"tldr": "The paper introduces MedErrBench, a multilingual benchmark for detecting, localizing, and correcting errors in clinical texts across English, Arabic, and Chinese.", "motivation": "Address the scarcity of benchmarks for evaluating the performance of Large Language Models (LLMs) in detecting inaccuracies in diverse clinical texts which could have severe consequences.", "method": "Developed MedErrBench with an expanded taxonomy of ten error types, multilingual clinical cases, and domain expert annotations; evaluated various models for their performance across three tasks.", "result": "Performance gaps were identified in non-English contexts, showing the insufficiency of current systems in diverse linguistic and healthcare scenarios.", "conclusion": "MedErrBench promotes the development of safer, multilingual, and clinically-grounded AI tools, pushing for equitable healthcare AI worldwide."}}
{"id": "2602.05311", "pdf": "https://arxiv.org/pdf/2602.05311", "abs": "https://arxiv.org/abs/2602.05311", "authors": ["Chengxiao Wang", "Haoze Wu", "Gagandeep Singh"], "title": "Formal Synthesis of Certifiably Robust Neural Lyapunov-Barrier Certificates", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY"], "comment": null, "summary": "Neural Lyapunov and barrier certificates have recently been used as powerful tools for verifying the safety and stability properties of deep reinforcement learning (RL) controllers. However, existing methods offer guarantees only under fixed ideal unperturbed dynamics, limiting their reliability in real-world applications where dynamics may deviate due to uncertainties. In this work, we study the problem of synthesizing \\emph{robust neural Lyapunov barrier certificates} that maintain their guarantees under perturbations in system dynamics. We formally define a robust Lyapunov barrier function and specify sufficient conditions based on Lipschitz continuity that ensure robustness against bounded perturbations. We propose practical training objectives that enforce these conditions via adversarial training, Lipschitz neighborhood bound, and global Lipschitz regularization. We validate our approach in two practically relevant environments, Inverted Pendulum and 2D Docking. The former is a widely studied benchmark, while the latter is a safety-critical task in autonomous systems. We show that our methods significantly improve both certified robustness bounds (up to $4.6$ times) and empirical success rates under strong perturbations (up to $2.4$ times) compared to the baseline. Our results demonstrate effectiveness of training robust neural certificates for safe RL under perturbations in dynamics.", "AI": {"tldr": "This paper proposes methods to synthesize robust neural Lyapunov barrier certificates that ensure safety and stability in deep reinforcement learning controllers under uncertain and perturbed system dynamics.", "motivation": "Existing safety verification methods for RL controllers only work under ideal fixed dynamics and fail to handle real-world uncertainties. There is a need for robust solutions under dynamic perturbations.", "method": "The paper defines robust Lyapunov barrier functions with Lipschitz continuity conditions, and develops adversarial training methods and regularization techniques to ensure robustness to bounded perturbations.", "result": "Experimental evaluations on Inverted Pendulum and 2D Docking tasks show significant improvements in certified robustness bounds (up to 4.6x) and empirical success rates (up to 2.4x) compared to baselines.", "conclusion": "Training robust neural Lyapunov barrier certificates enhances safe RL performance in environments with perturbed dynamics, making it more reliable for practical applications."}}
{"id": "2602.05397", "pdf": "https://arxiv.org/pdf/2602.05397", "abs": "https://arxiv.org/abs/2602.05397", "authors": ["Yuechen Yang", "Junlin Guo", "Ruining Deng", "Junchao Zhu", "Zhengyi Lu", "Chongyu Qu", "Yanfan Zhu", "Xingyi Guo", "Yu Wang", "Shilin Zhao", "Haichun Yang", "Yuankai Huo"], "title": "Explainable Pathomics Feature Visualization via Correlation-aware Conditional Feature Editing", "categories": ["cs.CV"], "comment": null, "summary": "Pathomics is a recent approach that offers rich quantitative features beyond what black-box deep learning can provide, supporting more reproducible and explainable biomarkers in digital pathology. However, many derived features (e.g., \"second-order moment\") remain difficult to interpret, especially across different clinical contexts, which limits their practical adoption. Conditional diffusion models show promise for explainability through feature editing, but they typically assume feature independence**--**an assumption violated by intrinsically correlated pathomics features. Consequently, editing one feature while fixing others can push the model off the biological manifold and produce unrealistic artifacts. To address this, we propose a Manifold-Aware Diffusion (MAD) framework for controllable and biologically plausible cell nuclei editing. Unlike existing approaches, our method regularizes feature trajectories within a disentangled latent space learned by a variational auto-encoder (VAE). This ensures that manipulating a target feature automatically adjusts correlated attributes to remain within the learned distribution of real cells. These optimized features then guide a conditional diffusion model to synthesize high-fidelity images. Experiments demonstrate that our approach is able to navigate the manifold of pathomics features when editing those features. The proposed method outperforms baseline methods in conditional feature editing while preserving structural coherence.", "AI": {"tldr": "The paper introduces 'Manifold-Aware Diffusion' (MAD) framework, enabling biologically plausible feature editing in pathomics by addressing correlated feature challenges.", "motivation": "Pathomics offers explainable biomarkers but struggles with interpretability and feature correlations. Existing editing methods assume feature independence, leading to biologically incorrect outputs.", "method": "The MAD framework integrates a disentangled VAE to model biologically plausible feature correlations. It regularizes feature adjustment and uses a conditional diffusion model for coherent synthesis.", "result": "Experiments highlight the success of MAD in editing correlated pathomics features while preserving structural integrity, outperforming traditional methods.", "conclusion": "The MAD framework enhances pathomics feature editing by preserving biological realism, ensuring practical usability for clinical applications."}}
{"id": "2602.05499", "pdf": "https://arxiv.org/pdf/2602.05499", "abs": "https://arxiv.org/abs/2602.05499", "authors": ["Hanyu Wei", "Zunhai Su", "Peng Lu", "Chao Li", "Spandan Tiwari", "Ashish Sirasao", "Yuhan Dong"], "title": "SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment is often limited by the cost and complexity of acquiring, tuning, and maintaining an effective draft model. Recent approaches usually require auxiliary training or specialization, and even training-free methods incur costly search or optimization. We propose SDFP, a fully training-free and plug-and-play framework that builds the draft model via Fisher Information Trace (FIT)-based layer pruning of a given LLM. Using layer sensitivity as a proxy for output perturbation, SDFP removes low-impact layers to obtain a compact draft while preserving compatibility with the original model for standard speculative verification. SDFP needs no additional training, hyperparameter tuning, or separately maintained drafts, enabling rapid, deployment-friendly draft construction. Across benchmarks, SDFP delivers 1.32x-1.5x decoding speedup without altering the target model's output distribution, supporting low-latency multimedia applications.", "AI": {"tldr": "This paper introduces SDFP, a framework for speeding up large language model (LLM) decoding using layer pruning.", "motivation": "The authors aim to address the latency issues in LLM decoding, especially in applications like multimedia captioning and recommendation, while avoiding additional complexity and costs associated with auxiliary model training and maintenance.", "method": "The method utilizes Fisher Information Trace (FIT)-based layer pruning to identify low-impact layers, creating a compact draft model compatible with the original for speculative decoding. This approach is training-free and easily deployable.", "result": "SDFP achieves a 1.32x-1.5x speedup in LLM decoding across benchmarks while maintaining the model's original output distribution.", "conclusion": "SDFP provides an efficient, low-latency solution for LLM-based applications without requiring additional training or extensive overhead, making it suitable for practical deployment."}}
{"id": "2602.05961", "pdf": "https://arxiv.org/pdf/2602.05961", "abs": "https://arxiv.org/abs/2602.05961", "authors": ["Arran Carter", "Sanghyeok Choi", "Kirill Tamogashev", "V\u00edctor Elvira", "Nikolay Malkin"], "title": "Discrete diffusion samplers and bridges: Off-policy algorithms and applications in latent spaces", "categories": ["cs.LG", "stat.ML"], "comment": "Code: https://github.com/mmacosha/offpolicy-discrete-diffusion-samplers-and-bridges", "summary": "Sampling from a distribution $p(x) \\propto e^{-\\mathcal{E}(x)}$ known up to a normalising constant is an important and challenging problem in statistics. Recent years have seen the rise of a new family of amortised sampling algorithms, commonly referred to as diffusion samplers, that enable fast and efficient sampling from an unnormalised density. Such algorithms have been widely studied for continuous-space sampling tasks; however, their application to problems in discrete space remains largely unexplored. Although some progress has been made in this area, discrete diffusion samplers do not take full advantage of ideas commonly used for continuous-space sampling. In this paper, we propose to bridge this gap by introducing off-policy training techniques for discrete diffusion samplers. We show that these techniques improve the performance of discrete samplers on both established and new synthetic benchmarks. Next, we generalise discrete diffusion samplers to the task of bridging between two arbitrary distributions, introducing data-to-energy Schr\u00f6dinger bridge training for the discrete domain for the first time. Lastly, we showcase the application of the proposed diffusion samplers to data-free posterior sampling in the discrete latent spaces of image generative models.", "AI": {"tldr": "The paper proposes advancements in discrete diffusion samplers, introducing off-policy training techniques and generalizing them for bridging distributions and posterior sampling in discrete spaces.", "motivation": "The paper addresses the challenge of sampling from a distribution known up to a normalization constant, specifically focusing on discrete spaces where existing methods are underdeveloped compared to continuous spaces.", "method": "The paper introduces off-policy training techniques for discrete diffusion samplers, enhances their application to bridging arbitrary distributions, and applies these samplers to data-free posterior sampling in discrete latent spaces.", "result": "The proposed techniques improve the performance on synthetic benchmarks, generalize discrete sampling methods, and successfully demonstrate their utility in image generative models.", "conclusion": "The advancements in discrete diffusion samplers enable efficient and versatile sampling techniques, bridging gaps between distributions and improving statistical challenges in discrete domains."}}
{"id": "2602.05033", "pdf": "https://arxiv.org/pdf/2602.05033", "abs": "https://arxiv.org/abs/2602.05033", "authors": ["Jiaxu Ren", "Yixin Wang", "Biwei Huang"], "title": "Causal Representation Meets Stochastic Modeling under Generic Geometry", "categories": ["cs.LG", "math.AG"], "comment": "Source codes and data will be available upon the publication of this work", "summary": "Learning meaningful causal representations from observations has emerged as a crucial task for facilitating machine learning applications and driving scientific discoveries in fields such as climate science, biology, and physics. This process involves disentangling high-level latent variables and their causal relationships from low-level observations. Previous work in this area that achieves identifiability typically focuses on cases where the observations are either i.i.d. or follow a latent discrete-time process. Nevertheless, many real-world settings require identifying latent variables that are continuous-time stochastic processes (e.g., multivariate point processes). To this end, we develop identifiable causal representation learning for continuous-time latent stochastic point processes. We study its identifiability by analyzing the geometry of the parameter space. Furthermore, we develop MUTATE, an identifiable variational autoencoder framework with a time-adaptive transition module to infer stochastic dynamics. Across simulated and empirical studies, we find that MUTATE can effectively answer scientific questions, such as the accumulation of mutations in genomics and the mechanisms driving neuron spike triggers in response to time-varying dynamics.", "AI": {"tldr": "The paper introduces MUTATE, a variational autoencoder framework for learning identifiable causal representations of continuous-time latent stochastic processes.", "motivation": "The motivation is to address the challenge of learning causal representations in real-world settings, where latent variables are often continuous-time stochastic processes, expanding applications in fields like climate science, biology, and physics.", "method": "The paper proposes MUTATE, an identifiable variational autoencoder framework with a time-adaptive transition module, designed to model stochastic dynamics.", "result": "MUTATE successfully infers stochastic dynamics and demonstrates its effectiveness in answering scientific questions in genomics and neuronal activity through simulated and empirical studies.", "conclusion": "The approach offers a significant step forward in enabling identifiable causal representation learning for continuous-time processes, facilitating scientific discoveries across various domains."}}
{"id": "2602.05694", "pdf": "https://arxiv.org/pdf/2602.05694", "abs": "https://arxiv.org/abs/2602.05694", "authors": ["Shuting Jiang", "Ran Song", "Yuxin Huang", "Yan Xiang", "Yantuan Xian", "Shengxiang Gao", "Zhengtao Yu"], "title": "Consensus-Aligned Neuron Efficient Fine-Tuning Large Language Models for Multi-Domain Machine Translation", "categories": ["cs.CL"], "comment": "Accepted by AAAI 2026", "summary": "Multi-domain machine translation (MDMT) aims to build a unified model capable of translating content across diverse domains. Despite the impressive machine translation capabilities demonstrated by large language models (LLMs), domain adaptation still remains a challenge for LLMs. Existing MDMT methods such as in-context learning and parameter-efficient fine-tuning often suffer from domain shift, parameter interference and limited generalization. In this work, we propose a neuron-efficient fine-tuning framework for MDMT that identifies and updates consensus-aligned neurons within LLMs. These neurons are selected by maximizing the mutual information between neuron behavior and domain features, enabling LLMs to capture both generalizable translation patterns and domain-specific nuances. Our method then fine-tunes LLMs guided by these neurons, effectively mitigating parameter interference and domain-specific overfitting. Comprehensive experiments on three LLMs across ten German-English and Chinese-English translation domains evidence that our method consistently outperforms strong PEFT baselines on both seen and unseen domains, achieving state-of-the-art performance.", "AI": {"tldr": "The paper introduces a novel neuron-efficient fine-tuning framework for multi-domain machine translation (MDMT), addressing challenges like domain shift and parameter interference in large language models (LLMs).", "motivation": "Existing approaches in MDMT like in-context learning and parameter-efficient fine-tuning often face limitations such as domain shift, parameter interference, and restricted generalization. A more effective method of domain adaptation in LLMs is needed.", "method": "The proposed method identifies and fine-tunes consensus-aligned neurons in LLMs, selected based on mutual information with domain features, enabling accurate and robust MDMT by capturing translation patterns and nuances.", "result": "Experimental results across three LLMs and ten translation domains show that the model consistently surpasses strong baselines in performance on both seen and unseen domains.", "conclusion": "The neuron-efficient fine-tuning method improves MDMT capabilities, achieving state-of-the-art performance while reducing domain-specific overfitting and parameter interference in LLMs."}}
{"id": "2602.05324", "pdf": "https://arxiv.org/pdf/2602.05324", "abs": "https://arxiv.org/abs/2602.05324", "authors": ["Mahdis Rabbani", "Navid Mojahed", "Shima Nazari"], "title": "A Data Driven Structural Decomposition of Dynamic Games via Best Response Maps", "categories": ["cs.GT", "cs.MA", "cs.RO", "eess.SY", "math.OC"], "comment": "11 pages, 6 figures, 5 tables, Submitted to RSS 2026", "summary": "Dynamic games are powerful tools to model multi-agent decision-making, yet computing Nash (generalized Nash) equilibria remains a central challenge in such settings. Complexity arises from tightly coupled optimality conditions, nested optimization structures, and poor numerical conditioning. Existing game-theoretic solvers address these challenges by directly solving the joint game, typically requiring explicit modeling of all agents' objective functions and constraints, while learning-based approaches often decouple interaction through prediction or policy approximation, sacrificing equilibrium consistency. This paper introduces a conceptually novel formulation for dynamic games by restructuring the equilibrium computation. Rather than solving a fully coupled game or decoupling agents through prediction or policy approximation, a data-driven structural reduction of the game is proposed that removes nested optimization layers and derivative coupling by embedding an offline-compiled best-response map as a feasibility constraint. Under standard regularity conditions, when the best-response operator is exact, any converged solution of the reduced problem corresponds to a local open-loop Nash (GNE) equilibrium of the original game; with a learned surrogate, the solution is approximately equilibrium-consistent up to the best-response approximation error. The proposed formulation is supported by mathematical proofs, accompanying a large-scale Monte Carlo study in a two-player open-loop dynamic game motivated by the autonomous racing problem. Comparisons are made against state-of-the-art joint game solvers, and results are reported on solution quality, computational cost, and constraint satisfaction.", "AI": {"tldr": "This paper presents a novel formulation for dynamic games that simplifies equilibrium computation by embedding an offline best-response map as a feasibility constraint, yielding Nash equilibria or approximations with better efficiency.", "motivation": "The paper seeks to address the computational challenges in finding Nash equilibria in dynamic games, including optimization complexity, poor numerical conditioning, and equilibrium consistency problems in traditional and learning-based methods.", "method": "The authors propose a restructuring of equilibrium computation by using a data-driven structural reduction of the game, embedding an offline-compiled best-response map as a feasibility constraint to streamline optimization and interaction.", "result": "The method was validated mathematically and through Monte Carlo experiments in a two-player dynamic game formulated for autonomous racing. Comparisons showed improved solution quality, reduced computational cost, and better constraint satisfaction compared to existing solvers.", "conclusion": "The proposed approach offers a promising alternative to conventional methods for dynamic game equilibrium computation, balancing accuracy and efficiency by leveraging structural reduction and best-response approximation methods."}}
{"id": "2602.05414", "pdf": "https://arxiv.org/pdf/2602.05414", "abs": "https://arxiv.org/abs/2602.05414", "authors": ["Ngoc Doan-Minh Huynh", "Duong Nguyen-Ngoc Tran", "Long Hoang Pham", "Tai Huu-Phuong Tran", "Hyung-Joon Jeon", "Huy-Hung Nguyen", "Duong Khac Vu", "Hyung-Min Jeon", "Son Hong Phan", "Quoc Pham-Nam Ho", "Chi Dai Tran", "Trinh Le Ba Khanh", "Jae Wook Jeon"], "title": "TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions", "categories": ["cs.CV"], "comment": "This paper has been accepted by the 40th AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Global warming has intensified the frequency and severity of extreme weather events, which degrade CCTV signal and video quality while disrupting traffic flow, thereby increasing traffic accident rates. Existing datasets, often limited to light haze, rain, and snow, fail to capture extreme weather conditions. To address this gap, this study introduces the Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions (TSBOW), a comprehensive dataset designed to enhance occluded vehicle detection across diverse annual weather scenarios. Comprising over 32 hours of real-world traffic data from densely populated urban areas, TSBOW includes more than 48,000 manually annotated and 3.2 million semi-labeled frames; bounding boxes spanning eight traffic participant classes from large vehicles to micromobility devices and pedestrians. We establish an object detection benchmark for TSBOW, highlighting challenges posed by occlusions and adverse weather. With its varied road types, scales, and viewpoints, TSBOW serves as a critical resource for advancing Intelligent Transportation Systems. Our findings underscore the potential of CCTV-based traffic monitoring, pave the way for new research and applications. The TSBOW dataset is publicly available at: https://github.com/SKKUAutoLab/TSBOW.", "AI": {"tldr": "The study introduces TSBOW, a dataset designed to improve vehicle detection under diverse weather conditions and challenging occlusions.", "motivation": "Rapidly increasing extreme weather events degrade traffic surveillance system efficiency, increasing accident probabilities. Existing datasets inadequately cover severe weather conditions, creating a need for a more representative dataset.", "method": "The researchers created the TSBOW dataset, consisting of over 32 hours of traffic video data, 48,000 manually annotated frames, and automatic semi-labeling for 3.2 million frames. Eight traffic-related classes were covered, with benchmarks evaluating detection under occlusions and extreme weather.", "result": "TSBOW demonstrates the challenges of detecting occluded vehicles in varied and adverse weather conditions, underscoring limitations of existing detection models.", "conclusion": "TSBOW provides a foundational resource for Intelligent Transportation Systems research, showcasing the potential of CCTV monitoring under extreme weather conditions to drive advancements in this field."}}
{"id": "2602.05515", "pdf": "https://arxiv.org/pdf/2602.05515", "abs": "https://arxiv.org/abs/2602.05515", "authors": ["Ajo Babu George", "Anna Mariam John", "Athul Anoop", "Balu Bhasuran"], "title": "A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal dataset specifically focused on ameloblastoma, integrating annotated radiological, histopathological, and intraoral clinical images with structured data derived from case reports. Natural language processing techniques were employed to extract clinically relevant features from textual reports, while image data underwent domain specific preprocessing and augmentation. Using this dataset, a multimodal deep learning model was developed to classify ameloblastoma variants, assess behavioral patterns such as recurrence risk, and support surgical planning. The model is designed to accept clinical inputs such as presenting complaint, age, and gender during deployment to enhance personalized inference. Quantitative evaluation demonstrated substantial improvements; variant classification accuracy increased from 46.2 percent to 65.9 percent, and abnormal tissue detection F1-score improved from 43.0 percent to 90.3 percent. Benchmarked against resources like MultiCaRe, this work advances patient-specific decision support by providing both a robust dataset and an adaptable multimodal AI framework.", "AI": {"tldr": "This paper introduces a new high-quality multimodal dataset for ameloblastoma and develops a deep learning model that improves diagnostic accuracy and support for surgical planning.", "motivation": "Current resources have limited ameloblastoma coverage and lack format consistency necessary for AI model training, motivating the need for a specialized dataset and AI framework.", "method": "The authors curated a multimodal dataset combining annotated radiological, histopathological, and clinical images with textual data. Natural language processing and domain-specific image preprocessing were used, followed by training a multimodal deep learning model.", "result": "The multimodal deep learning model achieved significant improvements: variant classification accuracy rose from 46.2% to 65.9%, while abnormal tissue detection F1-score increased from 43.0% to 90.3%.", "conclusion": "The study provides an enhanced dataset and multimodal AI framework, which significantly improves ameloblastoma diagnosis and supports personalized treatment planning."}}
{"id": "2602.05970", "pdf": "https://arxiv.org/pdf/2602.05970", "abs": "https://arxiv.org/abs/2602.05970", "authors": ["Yizhou Liu", "Sara Kangaslahti", "Ziming Liu", "Jeff Gore"], "title": "Inverse Depth Scaling From Most Layers Being Similar", "categories": ["cs.LG", "cs.AI", "math.DS", "stat.ML"], "comment": "23 pages, 24 figures", "summary": "Neural scaling laws relate loss to model size in large language models (LLMs), yet depth and width may contribute to performance differently, requiring more detailed studies. Here, we quantify how depth affects loss via analysis of LLMs and toy residual networks. We find loss scales inversely proportional to depth in LLMs, probably due to functionally similar layers reducing error through ensemble averaging rather than compositional learning or discretizing smooth dynamics. This regime is inefficient yet robust and may arise from the architectural bias of residual networks and target functions incompatible with smooth dynamics. The findings suggest that improving LLM efficiency may require architectural innovations to encourage compositional use of depth.", "AI": {"tldr": "The paper explores how depth in large language models (LLMs) impacts loss, finding it scales inversely proportional to depth. Current architectures may inefficiently utilize depth, indicating a need for innovation.", "motivation": "To understand how depth and width differently contribute to performance in LLMs and improve efficiency through architectural innovation.", "method": "Analyzes LLMs and toy residual networks to identify how depth influences loss scaling and infer the underlying reasons.", "result": "Loss scales inversely proportional to depth in LLMs due to ensemble averaging effects, not compositional learning or smooth dynamics.", "conclusion": "Improving efficiency of LLMs requires architectural strategies that enable compositional use of depth, given current architecture biases and inefficiencies."}}
{"id": "2602.05036", "pdf": "https://arxiv.org/pdf/2602.05036", "abs": "https://arxiv.org/abs/2602.05036", "authors": ["Karish Grover", "Theodore Vasiloudis", "Han Xie", "Sixing Lu", "Xiang Song", "Christos Faloutsos"], "title": "Feedback Control for Multi-Objective Graph Self-Supervision", "categories": ["cs.LG"], "comment": null, "summary": "Can multi-task self-supervised learning on graphs be coordinated without the usual tug-of-war between objectives? Graph self-supervised learning (SSL) offers a growing toolbox of pretext objectives: mutual information, reconstruction, contrastive learning; yet combining them reliably remains a challenge due to objective interference and training instability. Most multi-pretext pipelines use per-update mixing, forcing every parameter update to be a compromise, leading to three failure modes: Disagreement (conflict-induced negative transfer), Drift (nonstationary objective utility), and Drought (hidden starvation of underserved objectives). We argue that coordination is fundamentally a temporal allocation problem: deciding when each objective receives optimization budget, not merely how to weigh them. We introduce ControlG, a control-theoretic framework that recasts multi-objective graph SSL as feedback-controlled temporal allocation by estimating per-objective difficulty and pairwise antagonism, planning target budgets via a Pareto-aware log-hypervolume planner, and scheduling with a Proportional-Integral-Derivative (PID) controller. Across 9 datasets, ControlG consistently outperforms state-of-the-art baselines, while producing an auditable schedule that reveals which objectives drove learning.", "AI": {"tldr": "This paper introduces ControlG, a control-theoretic framework for improving multi-task self-supervised learning (SSL) on graphs, addressing objective interference and training instability by scheduling optimization budgets temporally using a PID controller.", "motivation": "Multi-task SSL on graphs often suffers from interference between objectives and training instability due to per-update mixing strategies, resulting in failure modes such as disagreement, drift, and drought.", "method": "The proposed ControlG framework employs a feedback-controlled temporal allocation strategy using a Pareto-aware log-hypervolume planner to allocate budgets for each objective and schedules optimization using a PID controller.", "result": "ControlG achieved superior performance compared to state-of-the-art baselines across 9 datasets, while offering transparency by auditing the schedule to understand each objective's contribution to learning.", "conclusion": "Temporal coordination of objectives, rather than simple weighting, is key to resolving conflicts in graph SSL, and ControlG offers a promising solution by borrowing concepts from control theory to optimize learning performance."}}
{"id": "2602.05711", "pdf": "https://arxiv.org/pdf/2602.05711", "abs": "https://arxiv.org/abs/2602.05711", "authors": ["Jingze Shi", "Zhangyang Peng", "Yizhang Zhu", "Yifan Wu", "Guang Liu", "Yuyu Luo"], "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.", "AI": {"tldr": "OmniMoE introduces atomic-level mixture-of-experts architecture to achieve finer granularity, boosting performance and efficiency in execution.", "motivation": "Current Mixture-of-Experts (MoE) architectures suffer from a trade-off between expert specialization granularity and hardware efficiency. OmniMoE aims to overcome this limitation.", "method": "OmniMoE proposes Atomic Experts at the vector level, utilizing a shared dense MLP branch with novel system-algorithm co-design techniques\u2014a Cartesian Product Router and Expert-Centric Scheduling.", "result": "OmniMoE achieves 50.9% zero-shot accuracy across seven benchmarks and delivers a 10.9-fold speedup in inference latency compared to the state-of-the-art, PEER.", "conclusion": "The paper demonstrates that fine-grained MoE architectures can be both highly efficient and accurate, setting a new standard for scalable MoE systems."}}
{"id": "2602.05467", "pdf": "https://arxiv.org/pdf/2602.05467", "abs": "https://arxiv.org/abs/2602.05467", "authors": ["Dekang Qi", "Shuang Zeng", "Xinyuan Chang", "Feng Xiong", "Shichao Xie", "Xiaolong Wu", "Mu Xu"], "title": "MerNav: A Highly Generalizable Memory-Execute-Review Framework for Zero-Shot Object Goal Navigation", "categories": ["cs.CV", "cs.CL", "cs.RO"], "comment": "9 pages, 2 figures, 5 tables, conference", "summary": "Visual Language Navigation (VLN) is one of the fundamental capabilities for embodied intelligence and a critical challenge that urgently needs to be addressed. However, existing methods are still unsatisfactory in terms of both success rate (SR) and generalization: Supervised Fine-Tuning (SFT) approaches typically achieve higher SR, while Training-Free (TF) approaches often generalize better, but it is difficult to obtain both simultaneously. To this end, we propose a Memory-Execute-Review framework. It consists of three parts: a hierarchical memory module for providing information support, an execute module for routine decision-making and actions, and a review module for handling abnormal situations and correcting behavior. We validated the effectiveness of this framework on the Object Goal Navigation task. Across 4 datasets, our average SR achieved absolute improvements of 7% and 5% compared to all baseline methods under TF and Zero-Shot (ZS) settings, respectively. On the most commonly used HM3D_v0.1 and the more challenging open vocabulary dataset HM3D_OVON, the SR improved by 8% and 6%, under ZS settings. Furthermore, on the MP3D and HM3D_OVON datasets, our method not only outperformed all TF methods but also surpassed all SFT methods, achieving comprehensive leadership in both SR (5% and 2%) and generalization.", "AI": {"tldr": "A new Memory-Execute-Review framework improves success rate and generalization in Visual Language Navigation tasks, outperforming both supervised fine-tuning and training-free methods.", "motivation": "Address the fundamental challenge in embodied intelligence to simultaneously improve success rate and generalization in Visual Language Navigation.", "method": "The Memory-Execute-Review framework integrates a hierarchical memory module for information support, an execute module for decision-making, and a review module for correcting abnormal behavior.", "result": "The framework improved success rates by 7% (training-free) and 5% (zero-shot) on average across 4 datasets, outperforming all baseline methods. Specific gains include an 8% increase on HM3D_v0.1 and 6% on HM3D_OVON in zero-shot settings.", "conclusion": "The proposed framework offers a balanced solution that achieves both high success rates and strong generalization capabilities, showcasing its potential for advancing embodied intelligence research."}}
{"id": "2602.05415", "pdf": "https://arxiv.org/pdf/2602.05415", "abs": "https://arxiv.org/abs/2602.05415", "authors": ["Ningkang Peng", "Qianfeng Yu", "Yuhao Zhang", "Yafei Liu", "Xiaoqian Peng", "Peirong Ma", "Yi Chen", "Peiheng Li", "Yanhui Gu"], "title": "VMF-GOS: Geometry-guided virtual Outlier Synthesis for Long-Tailed OOD Detection", "categories": ["cs.CV"], "comment": null, "summary": "Out-of-Distribution (OOD) detection under long-tailed distributions is a highly challenging task because the scarcity of samples in tail classes leads to blurred decision boundaries in the feature space. Current state-of-the-art (sota) methods typically employ Outlier Exposure (OE) strategies, relying on large-scale real external datasets (such as 80 Million Tiny Images) to regularize the feature space. However, this dependence on external data often becomes infeasible in practical deployment due to high data acquisition costs and privacy sensitivity. To this end, we propose a novel data-free framework aimed at completely eliminating reliance on external datasets while maintaining superior detection performance. We introduce a Geometry-guided virtual Outlier Synthesis (GOS) strategy that models statistical properties using the von Mises-Fisher (vMF) distribution on a hypersphere. Specifically, we locate a low-likelihood annulus in the feature space and perform directional sampling of virtual outliers in this region. Simultaneously, we introduce a new Dual-Granularity Semantic Loss (DGS) that utilizes contrastive learning to maximize the distinction between in-distribution (ID) features and these synthesized boundary outliers. Extensive experiments on benchmarks such as CIFAR-LT demonstrate that our method outperforms sota approaches that utilize external real images.", "AI": {"tldr": "The paper presents a data-free method for Out-of-Distribution (OOD) detection in long-tailed distributions, addressing challenges linked with scarce tail class samples and dependency on external datasets.", "motivation": "The scarcity of samples in tail classes under long-tailed distributions blurs decision boundaries in feature spaces, making OOD detection difficult. Current methods overly rely on costly and privacy-sensitive large external datasets.", "method": "The proposed framework eliminates dependency on external datasets by introducing Geometry-guided virtual Outlier Synthesis (GOS) using the vMF distribution to simulate statistical properties. A Dual-Granularity Semantic Loss (DGS) enhances feature distinction through contrastive learning.", "result": "Extensive experiments on CIFAR-LT show this data-free method outperforms state-of-the-art approaches relying on external data.", "conclusion": "The study demonstrates that OOD detection can effectively bypass the need for external datasets, offering a promising data-free solution with superior performance."}}
{"id": "2602.05532", "pdf": "https://arxiv.org/pdf/2602.05532", "abs": "https://arxiv.org/abs/2602.05532", "authors": ["Florian Dietz", "William Wale", "Oscar Gilg", "Robert McCarthy", "Felix Michalak", "Gustavo Ewbank Rodrigues Danon", "Miguelito de Guzman", "Dietrich Klakow"], "title": "Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with model capabilities. We introduce Split Personality Training (SPT), which fine-tunes a second ``honest persona'' into LoRA parameters that remain inactive during normal operation. After the main model responds, we activate the LoRA adapter and insert a trigger string, enabling the honest persona to review the response while accessing the main model's latent states. We test our method on the Anthropic Auditing Game Model Organism, a benchmark where Llama-3.3-70B is trained to exploit reward hacks while concealing this behavior. SPT achieves 96% overall accuracy, whereas Anthropic reports near 0% accuracy. The honest persona reveals latent knowledge inaccessible to external observers, such as the fictional biases the compromised model was trained on.", "AI": {"tldr": "The paper introduces Split Personality Training (SPT) to detect misalignment in large language models effectively by activating a secondary 'honest persona.' This method significantly outperforms standard approaches in auditing concealed misbehaviors.", "motivation": "Large language models may mask their misalignment during training, posing challenges to audit methods. Current tools either fail to distinguish misaligned outputs or lack scalability.", "method": "SPT involves fine-tuning a secondary 'honest persona' using LoRA parameters, which remain inactive until specific triggers are applied. This persona reviews model responses while accessing latent states.", "result": "SPT achieves a 96% accuracy on a benchmark test with Llama-3.3-70B in detecting concealed misbehaviors, compared to near 0% accuracy using conventional methods.", "conclusion": "SPT reveals latent knowledge and underlying biases inaccessible to traditional auditing approaches, providing a scalable and effective mechanism to detect misalignment."}}
{"id": "2602.05996", "pdf": "https://arxiv.org/pdf/2602.05996", "abs": "https://arxiv.org/abs/2602.05996", "authors": ["Leo Zhang", "James Martens"], "title": "Orthogonal Self-Attention", "categories": ["cs.LG", "stat.ML"], "comment": "Preprint", "summary": "Softmax Self-Attention (SSA) is a key component of Transformer architectures. However, when utilised within skipless architectures, which aim to improve representation learning, recent work has highlighted the inherent instability of SSA due to inducing rank collapse and poorly-conditioned Jacobians. In this work, we design a novel attention mechanism: Orthogonal Self-Attention (OSA), which aims to bypass these issues with SSA, in order to allow for (non-causal) Transformers without skip connections and normalisation layers to be more easily trained. In particular, OSA parametrises the attention matrix to be orthogonal via mapping a skew-symmetric matrix, formed from query-key values, through the matrix exponential. We show that this can be practically implemented, by exploiting the low-rank structure of our query-key values, resulting in the computational complexity and memory cost of OSA scaling linearly with sequence length. Furthermore, we derive an initialisation scheme for which we prove ensures that the Jacobian of OSA is well-conditioned.", "AI": {"tldr": "The paper presents Orthogonal Self-Attention (OSA) as an improvement over Softmax Self-Attention (SSA) to address instability issues in skipless Transformers.", "motivation": "SSA has shown instability due to rank collapse and poorly-conditioned Jacobians, particularly within skipless architectures.", "method": "Orthogonal Self-Attention (OSA) is introduced, wherein attention matrices are made orthogonal using a skew-symmetric matrix and matrix exponential, offering linear scalability in computational and memory costs.", "result": "OSA demonstrates practical implementation with well-conditioned Jacobians due to a derived initialization scheme.", "conclusion": "OSA enables efficient training of skipless Transformers without normalisation layers by resolving inherent issues in SSA and ensuring stability."}}
{"id": "2602.05728", "pdf": "https://arxiv.org/pdf/2602.05728", "abs": "https://arxiv.org/abs/2602.05728", "authors": ["Hao Yang", "Zhiyu Yang", "Xupeng Zhang", "Wei Wei", "Yunjie Zhang", "Lin Yang"], "title": "CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable entity grounding across hops. We propose CompactRAG, a simple yet effective framework that decouples offline corpus restructuring from online reasoning.\n  In the offline stage, an LLM reads the corpus once and converts it into an atomic QA knowledge base, which represents knowledge as minimal, fine-grained question-answer pairs. In the online stage, complex queries are decomposed and carefully rewritten to preserve entity consistency, and are resolved through dense retrieval followed by RoBERTa-based answer extraction. Notably, during inference, the LLM is invoked only twice in total - once for sub-question decomposition and once for final answer synthesis - regardless of the number of reasoning hops.\n  Experiments on HotpotQA, 2WikiMultiHopQA, and MuSiQue demonstrate that CompactRAG achieves competitive accuracy while substantially reducing token consumption compared to iterative RAG baselines, highlighting a cost-efficient and practical approach to multi-hop reasoning over large knowledge corpora. The implementation is available at GitHub.", "AI": {"tldr": "CompactRAG improves the efficiency of multi-hop retrieval-augmented generation by decoupling offline corpus restructuring from online reasoning and limiting LLM calls.", "motivation": "Existing multi-hop RAG systems face challenges like inefficiency, repeated LLM calls, high token usage, and unstable entity grounding across steps.", "method": "CompactRAG introduces an offline stage for corpus restructuring into an atomic QA knowledge base and an online stage for dense retrieval and RoBERTa-based answer extraction, reducing LLM calls during inference.", "result": "CompactRAG demonstrated competitive accuracy with significantly reduced token consumption compared to traditional RAG systems in multi-hop reasoning tasks on multiple datasets.", "conclusion": "CompactRAG presents a cost-efficient yet accurate approach to multi-hop question answering, showcasing its practicality for large knowledge corpora."}}
{"id": "2602.05555", "pdf": "https://arxiv.org/pdf/2602.05555", "abs": "https://arxiv.org/abs/2602.05555", "authors": ["Panagiotis Sapoutzoglou", "Orestis Vaggelis", "Athina Zacharia", "Evangelos Sartinas", "Maria Pateraki"], "title": "IndustryShapes: An RGB-D Benchmark dataset for 6D object pose estimation of industrial assembly components and tools", "categories": ["cs.CV", "cs.RO"], "comment": "To appear in ICRA 2026", "summary": "We introduce IndustryShapes, a new RGB-D benchmark dataset of industrial tools and components, designed for both instance-level and novel object 6D pose estimation approaches. The dataset provides a realistic and application-relevant testbed for benchmarking these methods in the context of industrial robotics bridging the gap between lab-based research and deployment in real-world manufacturing scenarios. Unlike many previous datasets that focus on household or consumer products or use synthetic, clean tabletop datasets, or objects captured solely in controlled lab environments, IndustryShapes introduces five new object types with challenging properties, also captured in realistic industrial assembly settings. The dataset has diverse complexity, from simple to more challenging scenes, with single and multiple objects, including scenes with multiple instances of the same object and it is organized in two parts: the classic set and the extended set. The classic set includes a total of 4,6k images and 6k annotated poses. The extended set introduces additional data modalities to support the evaluation of model-free and sequence-based approaches. To the best of our knowledge, IndustryShapes is the first dataset to offer RGB-D static onboarding sequences. We further evaluate the dataset on a representative set of state-of-the art methods for instance-based and novel object 6D pose estimation, including also object detection, segmentation, showing that there is room for improvement in this domain. The dataset page can be found in https://pose-lab.github.io/IndustryShapes.", "AI": {"tldr": "The paper presents IndustryShapes, a benchmark dataset for evaluating industrial robotics applications in real-world scenarios, focusing on 6D pose estimation of industrial tools and components.", "motivation": "The motivation is to bridge the gap between lab-based research and real-world applications in industrial robotics by providing a realistic dataset for testing 6D pose estimation methods on complex industrial tools and components.", "method": "The dataset was created with challenging new object types, captured in realistic settings, and organized into a classic and an extended set with different levels of complexity. It also includes novel RGB-D static onboarding sequences.", "result": "Researchers tested state-of-the-art 6D pose estimation methods on IndustryShapes and found significant potential for improvement, highlighting the dataset's capability to expose existing method limitations.", "conclusion": "IndustryShapes serves as a critical tool to evaluate and improve methods for 6D pose estimation in realistic industrial applications, filling a gap between controlled lab studies and real-world usage."}}
{"id": "2602.05420", "pdf": "https://arxiv.org/pdf/2602.05420", "abs": "https://arxiv.org/abs/2602.05420", "authors": ["Rui Sun", "Yiwen Yang", "Kaiyu Guo", "Chen Jiang", "Dongli Xu", "Zhaonan Liu", "Tan Pan", "Limei Han", "Xue Jiang", "Wu Wei", "Yuan Cheng"], "title": "Disco: Densely-overlapping Cell Instance Segmentation via Adjacency-aware Collaborative Coloring", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 10 figures; ICLR 2026", "summary": "Accurate cell instance segmentation is foundational for digital pathology analysis. Existing methods based on contour detection and distance mapping still face significant challenges in processing complex and dense cellular regions. Graph coloring-based methods provide a new paradigm for this task, yet the effectiveness of this paradigm in real-world scenarios with dense overlaps and complex topologies has not been verified. Addressing this issue, we release a large-scale dataset GBC-FS 2025, which contains highly complex and dense sub-cellular nuclear arrangements. We conduct the first systematic analysis of the chromatic properties of cell adjacency graphs across four diverse datasets and reveal an important discovery: most real-world cell graphs are non-bipartite, with a high prevalence of odd-length cycles (predominantly triangles). This makes simple 2-coloring theory insufficient for handling complex tissues, while higher-chromaticity models would cause representational redundancy and optimization difficulties. Building on this observation of complex real-world contexts, we propose Disco (Densely-overlapping Cell Instance Segmentation via Adjacency-aware COllaborative Coloring), an adjacency-aware framework based on the \"divide and conquer\" principle. It uniquely combines a data-driven topological labeling strategy with a constrained deep learning system to resolve complex adjacency conflicts. First, \"Explicit Marking\" strategy transforms the topological challenge into a learnable classification task by recursively decomposing the cell graph and isolating a \"conflict set.\" Second, \"Implicit Disambiguation\" mechanism resolves ambiguities in conflict regions by enforcing feature dissimilarity between different instances, enabling the model to learn separable feature representations.", "AI": {"tldr": "The paper introduces Disco, a novel framework for cell instance segmentation aimed at handling complex and densely packed cellular regions through graph coloring and adjacency-aware deep learning methods.", "motivation": "Existing methods struggle with segmenting cells in dense, complex tissue environments due to overlap and challenging topologies. The study aims to improve performance in these scenarios by rethinking approaches based on graph chromatic properties.", "method": "Disco employs a two-tiered strategy: (1) Explicit Marking for transforming topological conflicts into learnable classification tasks via cell graph decomposition and (2) Implicit Disambiguation to refine feature separability in conflict regions, leveraging a deep learning-based framework.", "result": "This study systematically analyzed real-world cell adjacency graphs across datasets and confirmed their non-bipartite nature. Through Disco, the model can effectively address dense, overlapping regions and achieve detailed cell segmentation.", "conclusion": "The proposed method, Disco, is a significant step forward in handling complex cellular arrangements in pathology images, providing a scalable and precise solution for dense tissue analysis."}}
{"id": "2602.05533", "pdf": "https://arxiv.org/pdf/2602.05533", "abs": "https://arxiv.org/abs/2602.05533", "authors": ["Zhengyi Guo", "Wenpin Tang", "Renyuan Xu"], "title": "Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach", "categories": ["cs.AI"], "comment": null, "summary": "We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.", "AI": {"tldr": "The paper introduces a framework for conditional generation in diffusion models that ensures adherence to hard constraints using novel guidance strategies and learning algorithms.", "motivation": "To address the limitations of existing methods that fail to guarantee the satisfaction of hard constraints, particularly in safety-critical applications and rare-event simulations.", "method": "The paper develops a conditional diffusion guidance framework utilizing Doob's h-transform, martingale representation, and quadratic variation. Two learning algorithms are proposed to estimate targeted values using pretrained model trajectories.", "result": "The paper provides guarantees for the sampler's performance and demonstrates its efficacy in enforcing hard constraints and rare-event generation through numerical experiments.", "conclusion": "This framework offers a principled approach to reliably enforce hard constraints in diffusion models, with theoretical and practical validations of its performance."}}
{"id": "2602.06014", "pdf": "https://arxiv.org/pdf/2602.06014", "abs": "https://arxiv.org/abs/2602.06014", "authors": ["Shunxing Yan", "Han Zhong"], "title": "Optimism Stabilizes Thompson Sampling for Adaptive Inference", "categories": ["cs.LG", "cs.AI", "math.OC", "math.ST", "stat.ML"], "comment": null, "summary": "Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \\emph{optimism} as a key mechanism for restoring \\emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \\citep{halder2025stable} is stable for any $K \\ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \\citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.", "AI": {"tldr": "This paper analyzes the inferential properties of Thompson Sampling (TS) in multi-armed bandits and proposes optimism as a mechanism to stabilize TS and achieve valid asymptotic inference.", "motivation": "The motivation is to address the challenge of making valid inference in Thompson Sampling for multi-armed bandits under adaptive data collection, where sample sizes and action-selection rules affect statistical properties.", "method": "The authors extend results on variance-inflated TS from the two-armed setting to the general K-armed setting and analyze an alternative optimistic modification involving a mean bonus for stabilizing TS.", "result": "The study proves that both variance-inflated TS and the optimistic mean bonus modification stabilize TS and enable valid asymptotic inference for any number of arms while incurring a mild regret cost.", "conclusion": "Optimizing Thompson Sampling with appropriately designed optimism mechanisms leads to stability and valid asymptotic inference in multi-armed bandit problems."}}
{"id": "2602.05052", "pdf": "https://arxiv.org/pdf/2602.05052", "abs": "https://arxiv.org/abs/2602.05052", "authors": ["Shizheng Wen", "Mingyuan Chi", "Tianwei Yu", "Ben Moseley", "Mike Yan Michelis", "Pu Ren", "Hao Sun", "Siddhartha Mishra"], "title": "Learning, Solving and Optimizing PDEs with TensorGalerkin: an efficient high-performance Galerkin assembly algorithm", "categories": ["cs.LG"], "comment": null, "summary": "We present a unified algorithmic framework for the numerical solution, constrained optimization, and physics-informed learning of PDEs with a variational structure. Our framework is based on a Galerkin discretization of the underlying variational forms, and its high efficiency stems from a novel highly-optimized and GPU-compliant TensorGalerkin framework for linear system assembly (stiffness matrices and load vectors). TensorGalerkin operates by tensorizing element-wise operations within a Python-level Map stage and then performs global reduction with a sparse matrix multiplication that performs message passing on the mesh-induced sparsity graph. It can be seamlessly employed downstream as i) a highly-efficient numerical PDEs solver, ii) an end-to-end differentiable framework for PDE-constrained optimization, and iii) a physics-informed operator learning algorithm for PDEs. With multiple benchmarks, including 2D and 3D elliptic, parabolic, and hyperbolic PDEs on unstructured meshes, we demonstrate that the proposed framework provides significant computational efficiency and accuracy gains over a variety of baselines in all the targeted downstream applications.", "AI": {"tldr": "A unified framework is introduced for solving PDEs, physics-informed learning for PDEs, and constrained optimization using variational structures, leveraging an efficient TensorGalerkin method.", "motivation": "The paper aims to address the need for efficient computational frameworks to solve PDEs, perform constrained optimization, and enable physics-informed learning, particularly focusing on variational PDEs.", "method": "The method involves Galerkin discretization combined with a TensorGalerkin framework that boosts efficiency through tensorized operations and sparse matrix multiplication on GPU.", "result": "The framework shows computational efficiency and accuracy improvements across benchmarks involving different types of PDEs on unstructured meshes.", "conclusion": "The proposed framework demonstrates effectiveness in solving variational PDEs, optimizing constrained problems, and operator learning, outperforming existing baselines significantly."}}
{"id": "2602.05758", "pdf": "https://arxiv.org/pdf/2602.05758", "abs": "https://arxiv.org/abs/2602.05758", "authors": ["Bowen Ping", "Zijun Chen", "Yiyao Yu", "Tingfeng Hui", "Junchi Yan", "Baobao Chang"], "title": "LongR: Unleashing Long-Context Reasoning via Reinforcement Learning with Dense Utility Rewards", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning has emerged as a key driver for LLM reasoning. This capability is equally pivotal in long-context scenarios--such as long-dialogue understanding and structured data analysis, where the challenge extends beyond consuming tokens to performing rigorous deduction. While existing efforts focus on data synthesis or architectural changes, recent work points out that relying solely on sparse, outcome-only rewards yields limited gains, as such coarse signals are often insufficient to effectively guide the complex long-context reasoning. To address this, we propose LongR, a unified framework that enhances long-context performance by integrating a dynamic \"Think-and-Read\" mechanism, which interleaves reasoning with document consultation, with a contextual density reward based on relative information gain to quantify the utility of the relevant documents. Empirically, LongR achieves a 9% gain on LongBench v2 and consistent improvements on RULER and InfiniteBench, demonstrating robust efficiency in navigating extensive contexts. Furthermore, LongR consistently enhances performance across diverse RL algorithms (e.g., DAPO, GSPO). Finally, we conduct in-depth analyses to investigate the impact of reasoning chain length on efficiency and the model's robustness against distractors.", "AI": {"tldr": "LongR is a framework that combines reasoning with document consultation and uses contextual density rewards to improve long-context reasoning in Reinforcement Learning, achieving notable performance gains.", "motivation": "Addressing the limitations of sparse, outcome-only rewards in complex long-context reasoning tasks.", "method": "LongR employs a \"Think-and-Read\" mechanism for reasoning intertwined with document consultation and introduces a contextual density reward to assess document utility.", "result": "LongR improves performance by 9% on LongBench v2, and shows consistent gains on RULER and InfiniteBench, while working robustly with multiple RL algorithms.", "conclusion": "The study confirms that LongR effectively enhances long-context reasoning and robustness, offering a significant step forward for Reinforcement Learning models in extensive context scenarios."}}
{"id": "2602.05557", "pdf": "https://arxiv.org/pdf/2602.05557", "abs": "https://arxiv.org/abs/2602.05557", "authors": ["Michael Schwingshackl", "Fabio F. Oberweger", "Mario Niedermeyer", "Huemer Johannes", "Markus Murschitz"], "title": "PIRATR: Parametric Object Inference for Robotic Applications with Transformers in 3D Point Clouds", "categories": ["cs.CV", "cs.RO"], "comment": "8 Pages, 11 Figures, Accepted at 2026 IEEE International Conference on Robotics & Automation (ICRA) Vienna", "summary": "We present PIRATR, an end-to-end 3D object detection framework for robotic use cases in point clouds. Extending PI3DETR, our method streamlines parametric 3D object detection by jointly estimating multi-class 6-DoF poses and class-specific parametric attributes directly from occlusion-affected point cloud data. This formulation enables not only geometric localization but also the estimation of task-relevant properties for parametric objects, such as a gripper's opening, where the 3D model is adjusted according to simple, predefined rules. The architecture employs modular, class-specific heads, making it straightforward to extend to novel object types without re-designing the pipeline. We validate PIRATR on an automated forklift platform, focusing on three structurally and functionally diverse categories: crane grippers, loading platforms, and pallets. Trained entirely in a synthetic environment, PIRATR generalizes effectively to real outdoor LiDAR scans, achieving a detection mAP of 0.919 without additional fine-tuning. PIRATR establishes a new paradigm of pose-aware, parameterized perception. This bridges the gap between low-level geometric reasoning and actionable world models, paving the way for scalable, simulation-trained perception systems that can be deployed in dynamic robotic environments. Code available at https://github.com/swingaxe/piratr.", "AI": {"tldr": "PIRATR is a 3D object detection framework designed for robotic tasks using point clouds, capable of jointly estimating object poses and attributes. It demonstrates high generalization to real-world scenarios despite synthetic training.", "motivation": "The paper aims to improve robotic systems by creating a scalable and effective 3D object detection framework that integrates both geometric and parametric considerations, solving challenges in dynamic robotic environments.", "method": "The authors extend PI3DETR, designing PIRATR to jointly estimate 6-DoF poses and parametric properties from occluded point clouds using class-specific modular heads. It is synthetic-trained and evaluated on various robotic object categories.", "result": "PIRATR was assessed on three object categories and achieves a detection mAP of 0.919 on real-world LiDAR scans despite synthetic training, validating its generalization capabilities.", "conclusion": "PIRATR offers a pose-aware, parameterized perception framework, setting a new standard for simulation-trained systems in robotic environments. It bridges low-level geometry and task-based actionability for scalable deployment."}}
{"id": "2602.05423", "pdf": "https://arxiv.org/pdf/2602.05423", "abs": "https://arxiv.org/abs/2602.05423", "authors": ["Pengcheng Chen", "Yue Hu", "Wenhao Li", "Nicole M Gunderson", "Andrew Feng", "Zhenglong Sun", "Peter Beerel", "Eric J Seibel"], "title": "NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "In modern dense 3D reconstruction, feed-forward systems (e.g., VGGT, pi3) focus on end-to-end matching and geometry prediction but do not explicitly output the novel view synthesis (NVS). Neural rendering-based approaches offer high-fidelity NVS and detailed geometry from posed images, yet they typically assume fixed camera poses and can be sensitive to pose errors. As a result, it remains non-trivial to obtain a single framework that can offer accurate poses, reliable depth, high-quality rendering, and accurate 3D surfaces from casually captured views. We present NeVStereo, a NeRF-driven NVS-stereo architecture that aims to jointly deliver camera poses, multi-view depth, novel view synthesis, and surface reconstruction from multi-view RGB-only inputs. NeVStereo combines NeRF-based NVS for stereo-friendly renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and an iterative refinement stage that updates both depth and the radiance field to improve geometric consistency. This design mitigated the common NeRF-based issues such as surface stacking, artifacts, and pose-depth coupling. Across indoor, outdoor, tabletop, and aerial benchmarks, our experiments indicate that NeVStereo achieves consistently strong zero-shot performance, with up to 36% lower depth error, 10.4% improved pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm) compared to existing prestigious methods.", "AI": {"tldr": "This paper introduces NeVStereo, a novel architecture for jointly delivering camera poses, multi-view depth, novel view synthesis, and surface reconstruction from casually captured RGB inputs. It outperforms existing methods across various benchmarks in terms of depth accuracy, pose accuracy, NVS fidelity, and mesh quality.", "motivation": "Current feed-forward systems and neural rendering approaches face limitations in simultaneously providing accurate camera poses, depth, high-quality rendering, and 3D surfaces. There is a need for a unified system capable of achieving these simultaneously from casually captured inputs.", "method": "The paper presents NeVStereo, a NeRF-driven NVS-stereo architecture, combining NeRF-based NVS for stereo renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and iterative depth-radiance field updates for geometric consistency.", "result": "NeVStereo demonstrates robust zero-shot performance across diverse benchmarks, achieving up to 36% lower depth error, 10.4% better pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm).", "conclusion": "NeVStereo offers a robust all-in-one solution for dense 3D reconstruction, surpassing existing methods by addressing common NeRF-based limitations and achieving superior performance across multiple dimensions."}}
{"id": "2602.05544", "pdf": "https://arxiv.org/pdf/2602.05544", "abs": "https://arxiv.org/abs/2602.05544", "authors": ["Fahad Anwaar", "Adil Mehmood Khan", "Muhammad Khalid", "Usman Zia", "Kezhi Wang"], "title": "Reasoning-guided Collaborative Filtering with Language Models for Explainable Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) exhibit potential for explainable recommendation systems but overlook collaborative signals, while prevailing methods treat recommendation and explanation as separate tasks, resulting in a memory footprint. We present RGCF-XRec, a hybrid framework that introduces reasoning-guided collaborative filtering (CF) knowledge into a language model to deliver explainable sequential recommendations in a single step. Theoretical grounding and empirical findings reveal that RGCF-XRec offers three key merits over leading CF-aware LLM-based methods: (1) reasoning-guided augmentation of CF knowledge through contextual prompting to discover latent preferences and interpretable reasoning paths; (2) an efficient scoring mechanism based on four dimensions: coherence, completeness, relevance, and consistency to mitigate noisy CF reasoning traces and retain high-quality explanations; (3) a unified representation learning network that encodes collaborative and semantic signals, enabling a structured prompt to condition the LLM for explainable sequential recommendation. RGCF-XRec demonstrates consistent improvements across Amazon datasets, Sports, Toys, and Beauty, comprising 642,503 user-item interactions. It improves HR@10 by 7.38\\% in Sports and 4.59\\% in Toys, along with ROUGE-L by 8.02\\% and 3.49\\%, respectively. It reduces the cold warm performance gap, achieving overall gains of 14.5\\% in cold-start and 11.9\\% in warm start scenarios, and enhances zero-shot HR@5 by 18.54\\% in Beauty and 23.16\\% in Toys, highlighting effective generalization and robustness. Moreover, RGCF-XRec achieves training efficiency with a lightweight LLaMA 3.2-3B backbone, ensuring scalability for real-world applications.", "AI": {"tldr": "The paper introduces RGCF-XRec, a framework that integrates reasoning-guided collaborative filtering with language models for explainable sequential recommendations, demonstrating notable improvements in performance and efficiency.", "motivation": "Existing large language models (LLMs) have potential for explainable recommendation systems but fail to incorporate collaborative signals. Current methods lack task unification and result in inefficiencies.", "method": "RGCF-XRec combines reasoning-guided collaborative filtering (CF) with a language model, leveraging a unified representation learning network and contextual prompting for explainable recommendation.", "result": "RGCF-XRec shows improved performance across several datasets, including enhanced HR@10 and ROUGE-L scores, better cold-start handling, and superior zero-shot generalization without sacrificing efficiency.", "conclusion": "The proposed RGCF-XRec framework effectively combines collaborative and semantic signals for explainable recommendations, providing significant scalability, robustness, and applicability in real-world settings."}}
{"id": "2602.05053", "pdf": "https://arxiv.org/pdf/2602.05053", "abs": "https://arxiv.org/abs/2602.05053", "authors": ["Wen Zhang", "Adel W. Sadek", "Chunming Qiao"], "title": "Quantile-Physics Hybrid Framework for Safe-Speed Recommendation under Diverse Weather Conditions Leveraging Connected Vehicle and Road Weather Information Systems Data", "categories": ["cs.LG"], "comment": "This work was presented as a poster at the 2026 Transportation Research Board (TRB) Annual Meeting", "summary": "Inclement weather conditions can significantly impact driver visibility and tire-road surface friction, requiring adjusted safe driving speeds to reduce crash risk. This study proposes a hybrid predictive framework that recommends real-time safe speed intervals for freeway travel under diverse weather conditions. Leveraging high-resolution Connected Vehicle (CV) data and Road Weather Information System (RWIS) data collected in Buffalo, NY, from 2022 to 2023, we construct a spatiotemporally aligned dataset containing over 6.6 million records across 73 days. The core model employs Quantile Regression Forests (QRF) to estimate vehicle speed distributions in 10-minute windows, using 26 input features that capture meteorological, pavement, and temporal conditions. To enforce safety constraints, a physics-based upper speed limit is computed for each interval based on real-time road grip and visibility, ensuring that vehicles can safely stop within their sight distance. The final recommended interval fuses QRF-predicted quantiles with both posted speed limits and the physics-derived upper bound. Experimental results demonstrate strong predictive performance: the QRF model achieves a mean absolute error of 1.55 mph, with 96.43% of median speed predictions within 5 mph, a PICP (50%) of 48.55%, and robust generalization across weather types. The model's ability to respond to changing weather conditions and generalize across road segments shows promise for real-world deployment, thereby improving traffic safety and reducing weather-related crashes.", "AI": {"tldr": "The paper proposes a hybrid predictive framework for recommending safe driving speeds in varying weather, using high-resolution CV and RWIS data.", "motivation": "To reduce weather-related vehicle crash risks by providing real-time safe speed recommendations under diverse weather conditions.", "method": "The study leverages a hybrid framework combining Quantile Regression Forests (QRF) with physics-based constraints using high-resolution data to predict safe driving speeds.", "result": "The model achieved high predictive accuracy, with a mean absolute error of 1.55 mph and strong generalization across road and weather conditions.", "conclusion": "The framework effectively adjusts safe speed recommendations for varying weather, improving traffic safety and showing potential for real-world deployment."}}
{"id": "2602.05769", "pdf": "https://arxiv.org/pdf/2602.05769", "abs": "https://arxiv.org/abs/2602.05769", "authors": ["Adnan Al Ali", "Jind\u0159ich Helcl", "Jind\u0159ich Libovick\u00fd"], "title": "Different Time, Different Language: Revisiting the Bias Against Non-Native Speakers in GPT Detectors", "categories": ["cs.CL"], "comment": "This paper was accepted to EACL 2026 Student Research Workshop", "summary": "LLM-based assistants have been widely popularised after the release of ChatGPT. Concerns have been raised about their misuse in academia, given the difficulty of distinguishing between human-written and generated text. To combat this, automated techniques have been developed and shown to be effective, to some extent. However, prior work suggests that these methods often falsely flag essays from non-native speakers as generated, due to their low perplexity extracted from an LLM, which is supposedly a key feature of the detectors. We revisit these statements two years later, specifically in the Czech language setting. We show that the perplexity of texts from non-native speakers of Czech is not lower than that of native speakers. We further examine detectors from three separate families and find no systematic bias against non-native speakers. Finally, we demonstrate that contemporary detectors operate effectively without relying on perplexity.", "AI": {"tldr": "This paper evaluates biases in LLM-based text detectors for distinguishing non-native authors and generated content in Czech, with results indicating detectors are not systematically biased and don't rely solely on perplexity.", "motivation": "LLM-based assistants like ChatGPT have raised concerns about academic misuse. Prior research suggested automated detectors may falsely flag non-native speakers as generating text due to distinct perplexity measurements.", "method": "The study assessed the perplexity of texts authored by native versus non-native Czech speakers and tested three detection methods across families to evaluate systematic biases and reliance on perplexity.", "result": "The authors found that non-native Czech texts do not exhibit lower perplexity than native texts. Moreover, the tested detectors showed no systematic bias against non-native speakers and did not rely on perplexity for their performance.", "conclusion": "The concerns about systematic bias and reliance on perplexity by LLM detectors are mitigated in Czech language settings, indicating contemporary detectors are fairer and more robust."}}
{"id": "2602.05827", "pdf": "https://arxiv.org/pdf/2602.05827", "abs": "https://arxiv.org/abs/2602.05827", "authors": ["Hai Zhang", "Siqi Liang", "Li Chen", "Yuxian Li", "Yukuan Xu", "Yichao Zhong", "Fu Zhang", "Hongyang Li"], "title": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease decision-making, they fundamentally contradict the goal for navigation in the real-world. Ideally, agents should possess the autonomy to navigate in unknown environments guided solely by simple and high-level intents. Realizing this ambition introduces a formidable challenge: Beyond-the-View Navigation (BVN), where agents must locate distant, unseen targets without dense and step-by-step guidance. Existing large language model (LLM)-based methods, though adept at following dense instructions, often suffer from short-sighted behaviors due to their reliance on short-horimzon supervision. Simply extending the supervision horizon, however, destabilizes LLM training. In this work, we identify that video generation models inherently benefit from long-horizon supervision to align with language instructions, rendering them uniquely suitable for BVN tasks. Capitalizing on this insight, we propose introducing the video generation model into this field for the first time. Yet, the prohibitive latency for generating videos spanning tens of seconds makes real-world deployment impractical. To bridge this gap, we propose SparseVideoNav, achieving sub-second trajectory inference guided by a generated sparse future spanning a 20-second horizon. This yields a remarkable 27x speed-up compared to the unoptimized counterpart. Extensive real-world zero-shot experiments demonstrate that SparseVideoNav achieves 2.5x the success rate of state-of-the-art LLM baselines on BVN tasks and marks the first realization of such capability in challenging night scenes.", "AI": {"tldr": "This paper addresses the challenge of Beyond-the-View Navigation (BVN) in real-world scenarios, introducing SparseVideoNav, a system utilizing video generation models for sub-second trajectory inference.", "motivation": "Current navigation systems overly rely on detailed instructions, which are impractical in real-world navigation where simple high-level guidance is needed. Traditional methods and LLM-based solutions struggle with long-horizon supervision.", "method": "The authors leverage video generation models, which are naturally suited for long-horizon supervision, introducing SparseVideoNav. It predicts sparse future scenarios to enhance navigation efficiency, achieving significant speed-ups and better performance.", "result": "SparseVideoNav demonstrated a 27x speed-up in trajectory inference and improved success rates in navigation tasks, achieving 2.5x the success rate compared to state-of-the-art LLM baselines and performing effectively in night scenes.", "conclusion": "SparseVideoNav showcases the potential of video generation models in BVN tasks, providing a practical and efficient solution for real-world navigation under challenging conditions."}}
{"id": "2602.05426", "pdf": "https://arxiv.org/pdf/2602.05426", "abs": "https://arxiv.org/abs/2602.05426", "authors": ["Wahyu Rahmaniar", "Kenji Suzuki"], "title": "Multi-AD: Cross-Domain Unsupervised Anomaly Detection for Medical and Industrial Applications", "categories": ["cs.CV"], "comment": "28 pages, 8 figures", "summary": "Traditional deep learning models often lack annotated data, especially in cross-domain applications such as anomaly detection, which is critical for early disease diagnosis in medicine and defect detection in industry. To address this challenge, we propose Multi-AD, a convolutional neural network (CNN) model for robust unsupervised anomaly detection across medical and industrial images. Our approach employs the squeeze-and-excitation (SE) block to enhance feature extraction via channel-wise attention, enabling the model to focus on the most relevant features and detect subtle anomalies. Knowledge distillation (KD) transfers informative features from the teacher to the student model, enabling effective learning of the differences between normal and anomalous data. Then, the discriminator network further enhances the model's capacity to distinguish between normal and anomalous data. At the inference stage, by integrating multi-scale features, the student model can detect anomalies of varying sizes. The teacher-student (T-S) architecture ensures consistent representation of high-dimensional features while adapting them to enhance anomaly detection. Multi-AD was evaluated on several medical datasets, including brain MRI, liver CT, and retina OCT, as well as industrial datasets, such as MVTec AD, demonstrating strong generalization across multiple domains. Experimental results demonstrated that our approach consistently outperformed state-of-the-art models, achieving the best average AUROC for both image-level (81.4% for medical and 99.6% for industrial) and pixel-level (97.0% for medical and 98.4% for industrial) tasks, making it effective for real-world applications.", "AI": {"tldr": "The paper introduces Multi-AD, a CNN-based unsupervised anomaly detection model using advanced techniques like attention mechanisms, knowledge distillation, and multi-scale features for medical and industrial applications. It achieves state-of-the-art results in various datasets.", "motivation": "The authors aim to address the lack of annotated data in anomaly detection tasks, which is essential for critical applications like early disease diagnosis and industrial defect detection. They propose a robust solution for cross-domain tasks.", "method": "Multi-AD employs a CNN framework with a squeeze-and-excitation block for enhanced feature extraction, knowledge distillation to transfer features between teacher-student models, and a discriminator to improve anomaly distinction. It also integrates multi-scale feature analysis and employs a teacher-student architecture to ensure consistent representation.", "result": "The model was evaluated on medical datasets (e.g., brain MRI, liver CT) and industrial datasets (e.g., MVTec AD), achieving state-of-the-art anomaly detection with an average AUROC of 81.4% (medical) and 99.6% (industrial) for image-level tasks, and 97.0% (medical) and 98.4% (industrial) for pixel-level tasks.", "conclusion": "Multi-AD demonstrates superior anomaly detection capabilities compared to existing state-of-the-art methods. Its robust cross-domain generalization and high performance make it suitable for real-world medical and industrial applications."}}
{"id": "2602.05570", "pdf": "https://arxiv.org/pdf/2602.05570", "abs": "https://arxiv.org/abs/2602.05570", "authors": ["Yikun Zong", "Cheston Tan"], "title": "TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?", "categories": ["cs.AI"], "comment": "13 pages, 4 figures", "summary": "Humans excel at spatial reasoning tasks like Tangram puzzle assembly through cognitive processes involving mental rotation, iterative refinement, and visual feedback. Inspired by how humans solve Tangram puzzles through trial-and-error, observation, and correction, we design a framework that models these human cognitive mechanisms. However, comprehensive experiments across five representative Vision-Language Models (VLMs) reveal systematic failures in continuous geometric reasoning: average IoU of only 0.41 on single-piece tasks, dropping to 0.23 on two-piece composition, far below human performance where children can complete Tangram tasks successfully. This paper addresses a fundamental challenge in self-improving AI: can models iteratively refine their predictions at test time without parameter updates? We introduce a test-time self-refinement framework that combines in-context learning (ICL) with reward-guided feedback loops, inspired by human cognitive processes. Our training-free verifier-refiner agent applies recursive refinement loops that iteratively self-refine predictions based on geometric consistency feedback, achieving IoU improvements from 0.63 to 0.932 on medium-triangle cases without any model retraining. This demonstrates that incorporating human-inspired iterative refinement mechanisms through ICL and reward loops can substantially enhance geometric reasoning in VLMs, moving self-improving AI from promise to practice in continuous spatial domains. Our work is available at this anonymous link https://anonymous.4open.science/r/TangramVLM-F582/.", "AI": {"tldr": "The paper proposes a test-time self-refinement framework inspired by human cognitive processes to improve geometric reasoning in Vision-Language Models (VLMs).", "motivation": "The motivation is to address the limitations of Vision-Language Models (VLMs) in continuous geometric reasoning tasks like Tangram puzzles, where current models significantly underperform compared to humans.", "method": "The method combines in-context learning (ICL) with reward-guided feedback loops in a training-free verifier-refiner agent that recursively refines predictions based on geometric consistency feedback.", "result": "The method achieved substantial improvements in geometric reasoning accuracy, such as increasing IoU from 0.63 to 0.932 on medium-triangle cases, without model retraining.", "conclusion": "Incorporating human-inspired iterative refinement mechanisms can significantly enhance geometric reasoning in VLMs, bridging a gap in self-improving AI for continuous spatial domains."}}
{"id": "2602.05060", "pdf": "https://arxiv.org/pdf/2602.05060", "abs": "https://arxiv.org/abs/2602.05060", "authors": ["Heajun An", "Qi Zhang", "Minqian Liu", "Xinyi Zhang", "Sang Won Lee", "Lifu Huang", "Pamela J. Wisniewski", "Jin-Hee Cho"], "title": "StagePilot: A Deep Reinforcement Learning Agent for Stage-Controlled Cybergrooming Simulation", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Cybergrooming is an evolving threat to youth, necessitating proactive educational interventions. We propose StagePilot, an offline RL-based dialogue agent that simulates the stage-wise progression of grooming behaviors for prevention training. StagePilot selects conversational stages using a composite reward that balances user sentiment and goal proximity, with transitions constrained to adjacent stages for realism and interpretability. We evaluate StagePilot through LLM-based simulations, measuring stage completion, dialogue efficiency, and emotional engagement. Results show that StagePilot generates realistic and coherent conversations aligned with grooming dynamics. Among tested methods, the IQL+AWAC agent achieves the best balance between strategic planning and emotional coherence, reaching the final stage up to 43% more frequently than baselines while maintaining over 70% sentiment alignment.", "AI": {"tldr": "StagePilot is an offline RL-based dialogue agent designed to simulate grooming behaviors to train youth on prevention strategies.", "motivation": "The paper aims to address the growing threat of cybergrooming against youth by creating a training system that helps in recognizing and countering grooming behaviors.", "method": "StagePilot uses reinforcement learning (RL) to simulate stage-wise grooming conversations. It employs a composite reward system balancing user sentiment and proximity to conversational goals, while ensuring realistic and interpretable transitions.", "result": "StagePilot demonstrates coherent and realistic conversations aligned with grooming dynamics. The IQL+AWAC agent performs the best, achieving up to 43% more stage progression and maintaining over 70% sentiment alignment compared to baselines.", "conclusion": "The study shows that StagePilot is effective as a training tool for understanding and countering grooming dynamics. Its emotionally coherent and strategically aligned dialogues achieve a significant improvement compared to baseline methods."}}
{"id": "2602.05842", "pdf": "https://arxiv.org/pdf/2602.05842", "abs": "https://arxiv.org/abs/2602.05842", "authors": ["Xiao Yu", "Baolin Peng", "Ruize Xu", "Yelong Shen", "Pengcheng He", "Suman Nath", "Nikhil Singh", "Jiangfeng Gao", "Zhou Yu"], "title": "Reinforcement World Model Learning for LLM-based Agents", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and $\u03c4^2$ Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and $\u03c4^2$ Bench respectively, while matching the performance of expert-data training.", "AI": {"tldr": "The paper introduces Reinforcement World Model Learning (RWML), a method for improving world-modeling in LLM-based agents using self-supervised training on action-conditioned world models.", "motivation": "LLMs struggle in agentic settings to anticipate consequences and adapt to environments, highlighting the need for stronger world-modeling capabilities.", "method": "The RWML method learns world models by aligning simulated textual states with observed states using self-supervised sim-to-real gap rewards, avoiding token-level prediction issues.", "result": "RWML achieves improved performance on ALFWorld and $\u03c4^2$ Bench, outperforming direct task-success rewards RL and matching expert-data training performances.", "conclusion": "RWML strengthens the alignment between internal models and real environment dynamics, enhancing the capabilities of LLM-based agents while being self-supervised."}}
{"id": "2602.05863", "pdf": "https://arxiv.org/pdf/2602.05863", "abs": "https://arxiv.org/abs/2602.05863", "authors": ["Roger Girgis", "Rodrigue de Schaetzen", "Luke Rowe", "Azal\u00e9e Robitaille", "Christopher Pal", "Liam Paull"], "title": "Constrained Group Relative Policy Optimization", "categories": ["cs.LG", "cs.CL", "cs.RO"], "comment": "16 pages, 6 figures", "summary": "While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.", "AI": {"tldr": "The paper proposes Constrained GRPO, extending GRPO to handle explicit behavioral constraints using a Lagrangian-based scalarized advantage estimation method.", "motivation": "Extend the GRPO framework to policy optimization scenarios with explicit behavioral constraints, addressing the lack of methods for such applications.", "method": "Developed Constrained GRPO based on Lagrangian relaxation with scalarized advantages to properly balance reward and constraint trade-offs, avoiding distortion in advantage estimation.", "result": "Experiments in gridworld and robotics demonstrate that scalarizing advantages leads to stable constraint control and improved task performance.", "conclusion": "Constrained GRPO proves effective for policy optimization with constraint enforcement in embodied AI domains, improving task success and constraint satisfaction."}}
{"id": "2602.05434", "pdf": "https://arxiv.org/pdf/2602.05434", "abs": "https://arxiv.org/abs/2602.05434", "authors": ["Sanghoon Jeon", "Gihyun Jung", "Suhyeon Ka", "Jae-Sang Hyun"], "title": "LD-SLRO: Latent Diffusion Structured Light for 3-D Reconstruction of Highly Reflective Objects", "categories": ["cs.CV"], "comment": "10 pages, 7 figures", "summary": "Fringe projection profilometry-based 3-D reconstruction of objects with high reflectivity and low surface roughness remains a significant challenge. When measuring such glossy surfaces, specular reflection and indirect illumination often lead to severe distortion or loss of the projected fringe patterns. To address these issues, we propose a latent diffusion-based structured light for reflective objects (LD-SLRO). Phase-shifted fringe images captured from highly reflective surfaces are first encoded to extract latent representations that capture surface reflectance characteristics. These latent features are then used as conditional inputs to a latent diffusion model, which probabilistically suppresses reflection-induced artifacts and recover lost fringe information, yielding high-quality fringe images. The proposed components, including the specular reflection encoder, time-variant channel affine layer, and attention modules, further improve fringe restoration quality. In addition, LD-SLRO provides high flexibility in configuring the input and output fringe sets. Experimental results demonstrate that the proposed method improves both fringe quality and 3-D reconstruction accuracy over state-of-the-art methods, reducing the average root-mean-squared error from 1.8176 mm to 0.9619 mm.", "AI": {"tldr": "The paper addresses the challenge of 3D reconstruction in highly reflective surfaces and proposes a latent diffusion-based structured light method (LD-SLRO) for improved accuracy and quality.", "motivation": "To resolve issues like specular reflection and indirect illumination causing distortion or loss of fringe patterns in highly reflective and low-roughness objects during 3D reconstruction.", "method": "The approach involves encoding fringe images to extract latent representations and using these as inputs to a latent diffusion model, which suppresses artifacts and restores fringe data. Key components include a specular reflection encoder, time-variant channel affine layer, and attention modules.", "result": "The proposed LD-SLRO method improves fringe restoration quality and 3D reconstruction accuracy, significantly reducing the root-mean-squared error from 1.8176 mm to 0.9619 mm.", "conclusion": "LD-SLRO effectively addresses challenges in 3D reconstruction of reflective objects, offering flexibility and superior performance compared to existing methods."}}
{"id": "2602.05597", "pdf": "https://arxiv.org/pdf/2602.05597", "abs": "https://arxiv.org/abs/2602.05597", "authors": ["Stephen Pilli", "Vivek Nallur"], "title": "Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Accepted at CHI'26. arXiv admin note: substantial text overlap with arXiv:2601.11049", "summary": "Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognitive load, interact with these biases. We adapted three well-established decision scenarios into a conversational setting and conducted a human experiment (N=1100). Participants engaged with a chatbot that facilitates decision-making through simple or complex dialogues. Results revealed robust biases. To evaluate how LLMs emulate human decision-making under similar interactive conditions, we used participant demographics and dialogue transcripts to simulate these conditions with LLMs based on GPT-4 and GPT-5. The LLMs reproduced human biases with precision. We found notable differences between models in how they aligned human behavior. This has important implications for designing and evaluating adaptive, bias-aware LLM-based AI systems in interactive contexts.", "AI": {"tldr": "This paper studies whether LLMs can predict individual cognitive biases and emulate human decision-making under contextual conditions, using conversational experiments and simulations with GPT-4 and GPT-5.", "motivation": "The study aims to understand not only if LLMs can replicate known cognitive biases, but also if they can predict biases at an individual level and emulate human behavior influenced by contextual factors like cognitive load.", "method": "Researchers conducted a human experiment with 1100 participants who interacted with a decision-making chatbot using simple or complex dialogues. Then, LLMs were tested using participants' demographics and dialogue transcripts to simulate similar decision-making conditions.", "result": "Results revealed consistent human biases in the experiment and showed that GPT-4 and GPT-5 reproduced these biases effectively, with differences between the models in how closely they aligned with human behavior.", "conclusion": "LLMs' ability to emulate biased human decision-making has significant implications for designing adaptive, bias-aware AI systems for interactive contexts."}}
{"id": "2602.05843", "pdf": "https://arxiv.org/pdf/2602.05843", "abs": "https://arxiv.org/abs/2602.05843", "authors": ["Fangzhi Xu", "Hang Yan", "Qiushi Sun", "Jinyang Wu", "Zixian Huang", "Muye Huang", "Jingyang Gong", "Zichen Ding", "Kanzhi Cheng", "Yian Wang", "Xinyu Che", "Zeyi Sun", "Jian Zhang", "Zhangyue Yin", "Haoran Luo", "Xuanjing Huang", "Ben Kao", "Jun Liu", "Qika Lin"], "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions", "categories": ["cs.CL"], "comment": "34 pages", "summary": "The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena", "AI": {"tldr": "The paper introduces OdysseyArena to evaluate large language models (LLMs) in long-horizon, inductive interactions, a gap in current evaluations.", "motivation": "Existing evaluations of LLMs focus on short planning horizons and deductive paradigms but neglect their ability to autonomously discover latent transition laws through experience.", "method": "OdysseyArena formalizes and instantiates four primitives for creating interactive environments with abstract transition dynamics. It includes OdysseyArena-Lite (standardized benchmark with 120 tasks) and OdysseyArena-Challenge (tests with extreme interaction horizons).", "result": "Experiments conducted on over 15 leading LLMs expose their deficiencies in inductive scenarios, presenting a significant limitation in their ability to perform autonomous discovery.", "conclusion": "OdysseyArena highlights critical limitations in current LLMs' inductive capabilities, offering a tool for benchmarking and advancing research in autonomous discovery within complex environments."}}
{"id": "2602.05435", "pdf": "https://arxiv.org/pdf/2602.05435", "abs": "https://arxiv.org/abs/2602.05435", "authors": ["Donglin Yang", "Yongxing Zhang", "Xin Yu", "Liang Hou", "Xin Tao", "Pengfei Wan", "Xiaojuan Qi", "Renjie Liao"], "title": "Stable Velocity: A Variance Perspective on Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.", "AI": {"tldr": "This paper introduces the Stable Velocity framework, addressing high-variance issues in flow matching to enhance training efficiency and sampling speed without compromising sample quality.", "motivation": "The motivation lies in overcoming the high variance in training targets caused by single-sample conditional velocities in flow matching, which leads to optimization challenges and slower convergence.", "method": "The Stable Velocity framework includes Stable Velocity Matching (StableVM) for reducing variance during training and Variance-Aware Representation Alignment (VA-REPA) for adaptive auxiliary supervision in low-variance regimes. For inference, Stable Velocity Sampling (StableVS) enables faster sampling through closed-form simplifications.", "result": "The framework consistently enhances training efficiency and provides more than 2x faster sampling in low-variance regimes while maintaining sample quality. Experimental validation is conducted on ImageNet and various large pretrained models.", "conclusion": "The Stable Velocity framework successfully addresses optimization instability in flow matching by reducing variance and accelerating sampling, making it a significant advancement in the domain of conditional modeling and generative inference."}}
{"id": "2602.05599", "pdf": "https://arxiv.org/pdf/2602.05599", "abs": "https://arxiv.org/abs/2602.05599", "authors": ["Subhadip Maji", "Arnab Bhattacharya"], "title": "BhashaSetu: Cross-Lingual Knowledge Transfer from High-Resource to Extreme Low-Resource Languages", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted as a long paper at IJCNLP-AACL Main Conference", "summary": "Despite remarkable advances in natural language processing, developing effective systems for low-resource languages remains a formidable challenge, with performances typically lagging far behind high-resource counterparts due to data scarcity and insufficient linguistic resources. Cross-lingual knowledge transfer has emerged as a promising approach to address this challenge by leveraging resources from high-resource languages. In this paper, we investigate methods for transferring linguistic knowledge from high-resource languages to low-resource languages, where the number of labeled training instances is in hundreds. We focus on sentence-level and word-level tasks. We introduce a novel method, GETR (Graph-Enhanced Token Representation) for cross-lingual knowledge transfer along with two adopted baselines (a) augmentation in hidden layers and (b) token embedding transfer through token translation. Experimental results demonstrate that our GNN-based approach significantly outperforms existing multilingual and cross-lingual baseline methods, achieving 13 percentage point improvements on truly low-resource languages (Mizo, Khasi) for POS tagging, and 20 and 27 percentage point improvements in macro-F1 on simulated low-resource languages (Marathi, Bangla, Malayalam) across sentiment classification and NER tasks respectively. We also present a detailed analysis of the transfer mechanisms and identify key factors that contribute to successful knowledge transfer in this linguistic context.", "AI": {"tldr": "This paper addresses the challenge of developing NLP systems for low-resource languages using cross-lingual knowledge transfer and introduces a new method, GETR, which achieves significant performance improvements.", "motivation": "To overcome the challenge of data scarcity and insufficient linguistic resources in low-resource languages and narrow the performance gap between high-resource and low-resource NLP systems.", "method": "They propose a novel method called GETR (Graph-Enhanced Token Representation) for cross-lingual knowledge transfer and compare this with two baseline methods: (a) hidden layer augmentation and (b) token embedding transfer.", "result": "Experimental results reveal that GETR achieves notable improvements, including 13 percentage points in POS tagging for low-resource languages and up to 27 percentage points in macro-F1 for sentiment classification and NER tasks.", "conclusion": "The proposed GETR method effectively enhances performance in NLP tasks for low-resource languages through cross-lingual knowledge transfer, with detailed insights into successful transfer mechanisms."}}
{"id": "2602.05068", "pdf": "https://arxiv.org/pdf/2602.05068", "abs": "https://arxiv.org/abs/2602.05068", "authors": ["Wenting Li", "Saif R. Kazi", "Russell Bent", "Duo Zhou", "Huan Zhang"], "title": "E-Globe: Scalable $\u03b5$-Global Verification of Neural Networks via Tight Upper Bounds and Pattern-Aware Branching", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 10 figures", "summary": "Neural networks achieve strong empirical performance, but robustness concerns still hinder deployment in safety-critical applications. Formal verification provides robustness guarantees, but current methods face a scalability-completeness trade-off. We propose a hybrid verifier in a branch-and-bound (BaB) framework that efficiently tightens both upper and lower bounds until an $\u03b5-$global optimum is reached or early stop is triggered. The key is an exact nonlinear program with complementarity constraints (NLP-CC) for upper bounding that preserves the ReLU input-output graph, so any feasible solution yields a valid counterexample and enables rapid pruning of unsafe subproblems. We further accelerate verification with (i) warm-started NLP solves requiring minimal constraint-matrix updates and (ii) pattern-aligned strong branching that prioritizes splits most effective at tightening relaxations. We also provide conditions under which NLP-CC upper bounds are tight. Experiments on MNIST and CIFAR-10 show markedly tighter upper bounds than PGD across perturbation radii spanning up to three orders of magnitude, fast per-node solves in practice, and substantial end-to-end speedups over MIP-based verification, amplified by warm-starting, GPU batching, and pattern-aligned branching.", "AI": {"tldr": "The paper introduces a hybrid verifier within a branch-and-bound framework to improve neural network robustness verification efficiency and scalability.", "motivation": "Robustness issues prevent the deployment of neural networks in safety-critical contexts, and existing verification methods struggle with a scalability-completeness trade-off.", "method": "They utilize a branch-and-bound framework with an exact nonlinear program preserving the ReLU input-output graph for upper bounding, along with warm-started nonlinear program solves and pattern-aligned branching for acceleration.", "result": "Experiments on MNIST and CIFAR-10 demonstrate tighter upper bounds than PGD, speedy per-node solves, and significant end-to-end speedups using their approach.", "conclusion": "The proposed methods enhance scalability and provide robustness guarantees for neural networks, paving the way for safer deployment in critical applications."}}
{"id": "2602.05853", "pdf": "https://arxiv.org/pdf/2602.05853", "abs": "https://arxiv.org/abs/2602.05853", "authors": ["Siran Liu", "Guoxia Wang", "Sa Wang", "Jinle Zeng", "HaoYang Xie", "Siyu Lou", "JiaBin Yang", "DianHai Yu", "Haifeng Wang", "Chao Yang"], "title": "RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference", "categories": ["cs.CL"], "comment": null, "summary": "The quadratic complexity of attention mechanisms poses a critical bottleneck for large language models processing long contexts. While dynamic sparse attention methods offer input-adaptive efficiency, they face fundamental trade-offs: requiring preprocessing, lacking global evaluation, violating query independence, or incurring high computational overhead. We present RRAttention, a novel dynamic sparse attention method that simultaneously achieves all desirable properties through a head \\underline{r}ound-\\underline{r}obin (RR) sampling strategy. By rotating query sampling positions across attention heads within each stride, RRAttention maintains query independence while enabling efficient global pattern discovery with stride-level aggregation. Our method reduces complexity from $O(L^2)$ to $O(L^2/S^2)$ and employs adaptive Top-$\u03c4$ selection for optimal sparsity. Extensive experiments on natural language understanding (HELMET) and multimodal video comprehension (Video-MME) demonstrate that RRAttention recovers over 99\\% of full attention performance while computing only half of the attention blocks, achieving 2.4$\\times$ speedup at 128K context length and outperforming existing dynamic sparse attention methods.", "AI": {"tldr": "The paper introduces RRAttention, a new dynamic sparse attention method, which significantly reduces computational complexity while preserving over 99% of performance compared to traditional full attention mechanisms.", "motivation": "The quadratic complexity of traditional attention mechanisms limits their efficiency when dealing with long-context language and multimodal processing, requiring more effective sparse attention methods.", "method": "The proposed RRAttention employs a round-robin (RR) query sampling strategy across attention heads for global pattern discovery while maintaining query independence. It achieves reduced complexity and enables dynamic sparsity employing adaptive Top-\u03c4 selection.", "result": "RRAttention achieves a 2.4\u00d7 speedup at 128K context length, while retaining over 99% performance efficiency, outperforming other dynamic sparse attention methods in tasks like natural language and multimodal video comprehension.", "conclusion": "RRAttention successfully overcomes the traditional trade-offs in sparse attention methods, establishing itself as a computationally efficient and highly performant alternative for processing long-contexts."}}
{"id": "2602.06023", "pdf": "https://arxiv.org/pdf/2602.06023", "abs": "https://arxiv.org/abs/2602.06023", "authors": ["Christopher A. McClurg", "Alan R. Wagner"], "title": "Learning Event-Based Shooter Models from Virtual Reality Experiments", "categories": ["cs.AI", "cs.RO"], "comment": "Preprint under review for conference publication. 9 pages, 4 figures, 4 tables", "summary": "Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.", "AI": {"tldr": "This paper develops a data-driven discrete-event simulator to evaluate and learn effective school security interventions, particularly in high-stakes scenarios, as a scalable alternative to VR studies.", "motivation": "The motivation of this study is to overcome the challenges in evaluating school security interventions (e.g., high participant requirements for VR studies) while ensuring effective solutions for high-risk scenarios such as school shootings.", "method": "The authors created a discrete-event simulator (DES) based on participant behavior data from VR studies. This simulator reproduces shooter behavior as stochastic processes and evaluates robot-based intervention strategies.", "result": "The proposed DES proved capable of reproducing key empirical patterns observed in VR studies, enabling scalable evaluation of interventions that would be infeasible to train directly with human participants.", "conclusion": "The study presents a scalable simulation methodology that serves as a surrogate for VR studies, enabling the efficient development and assessment of autonomous school security intervention strategies."}}
{"id": "2602.05440", "pdf": "https://arxiv.org/pdf/2602.05440", "abs": "https://arxiv.org/abs/2602.05440", "authors": ["Natascha Jeziorski", "Petra Gospodneti\u0107", "Claudia Redenbach"], "title": "Synthetic Defect Geometries of Cast Metal Objects Modeled via 2d Voronoi Tessellations", "categories": ["cs.CV"], "comment": null, "summary": "In industry, defect detection is crucial for quality control. Non-destructive testing (NDT) methods are preferred as they do not influence the functionality of the object while inspecting. Automated data evaluation for automated defect detection is a growing field of research. In particular, machine learning approaches show promising results. To provide training data in sufficient amount and quality, synthetic data can be used. Rule-based approaches enable synthetic data generation in a controllable environment. Therefore, a digital twin of the inspected object including synthetic defects is needed. We present parametric methods to model 3d mesh objects of various defect types that can then be added to the object geometry to obtain synthetic defective objects. The models are motivated by common defects in metal casting but can be transferred to other machining procedures that produce similar defect shapes. Synthetic data resembling the real inspection data can then be created by using a physically based Monte Carlo simulation of the respective testing method. Using our defect models, a variable and arbitrarily large synthetic data set can be generated with the possibility to include rarely occurring defects in sufficient quantity. Pixel-perfect annotation can be created in parallel. As an example, we will use visual surface inspection, but the procedure can be applied in combination with simulations for any other NDT method.", "AI": {"tldr": "This paper addresses the use of synthetic data for automated defect detection in non-destructive testing, emphasizing the development of parametric 3D models of defects and their application in creating annotated datasets using Monte Carlo simulations.", "motivation": "The motivation is to improve automated defect detection in quality control through the use of synthetic data, addressing the challenges of obtaining sufficient, high-quality training data reflecting real-world defects.", "method": "The authors develop parametric methods to create 3D mesh-based models of defects inspired by commonly observed defects in metal casting. These models allow generating synthetic defective objects which are used with Monte Carlo simulations to produce realistic inspection data.", "result": "The proposed framework enables the creation of variable, large synthetic datasets that can include rare defect types. These datasets are accompanied by perfect pixel-level annotations for use in machine learning training.", "conclusion": "The approach provides a controllable and scalable way to generate high-fidelity synthetic training data for defect detection in various non-destructive testing methods, with potential applications beyond the demonstrated use case."}}
{"id": "2602.05625", "pdf": "https://arxiv.org/pdf/2602.05625", "abs": "https://arxiv.org/abs/2602.05625", "authors": ["Simon Kohaut", "Benedict Flade", "Julian Eggert", "Kristian Kersting", "Devendra Singh Dhami"], "title": "Reactive Knowledge Representation and Asynchronous Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, we approach the problem from a reactive, asynchronous, probabilistic reasoning perspective. We first introduce Resin (Reactive Signal Inference), a probabilistic programming language that merges probabilistic logic with reactive programming. Furthermore, to provide efficient and exact semantics for Resin, we propose Reactive Circuits (RCs). Formulated as a meta-structure over Algebraic Circuits and asynchronous data streams, RCs are time-dynamic Directed Acyclic Graphs that autonomously adapt themselves based on the volatility of input signals. In high-fidelity drone swarm simulations, our approach achieves several orders of magnitude of speedup over frequency-agnostic inference. We demonstrate that RCs' structural adaptations successfully capture environmental dynamics, significantly reducing latency and facilitating reactive real-time reasoning. By partitioning computations based on the estimated Frequency of Change in the asynchronous inputs, large inference tasks can be decomposed into individually memoized sub-problems. This ensures that only the specific components of a model affected by new information are re-evaluated, drastically reducing redundant computation in streaming contexts.", "AI": {"tldr": "The paper introduces Resin, a probabilistic programming language for real-time belief updates in dynamic environments, and Reactive Circuits (RCs), a structure for efficient reasoning. RCs adapt computations asynchronously based on input changes, increasing speed and reducing computational overhead.", "motivation": "Real-time belief updates in dynamic environments are computationally expensive, especially when frequent updates occur and redundant computations dominate existing methods.", "method": "The authors developed Resin, which integrates probabilistic logic with reactive programming, and Reactive Circuits, which adapt computations based on input signal volatility using Algebraic Circuits and asynchronous data streams.", "result": "In drone swarm simulations, this approach achieved significant speedup compared to conventional methods by reducing redundant updates through RCs' adaptive mechanisms.", "conclusion": "Reactive Circuits effectively improve efficiency by tailoring computations to dynamic input frequencies, enabling scalable and real-time probabilistic reasoning for streaming contexts."}}
{"id": "2602.05874", "pdf": "https://arxiv.org/pdf/2602.05874", "abs": "https://arxiv.org/abs/2602.05874", "authors": ["Adri\u00e1n Gir\u00f3n", "Pablo Miralles", "Javier Huertas-Tato", "Sergio D'Antonio", "David Camacho"], "title": "xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hate speech detection is commonly framed as a direct binary classification problem despite being a composite concept defined through multiple interacting factors that vary across legal frameworks, platform policies, and annotation guidelines. As a result, supervised models often overfit dataset-specific definitions and exhibit limited robustness under domain shift and annotation noise.\n  We introduce xList-Hate, a diagnostic framework that decomposes hate speech detection into a checklist of explicit, concept-level questions grounded in widely shared normative criteria. Each question is independently answered by a large language model (LLM), producing a binary diagnostic representation that captures hateful content features without directly predicting the final label. These diagnostic signals are then aggregated by a lightweight, fully interpretable decision tree, yielding transparent and auditable predictions.\n  We evaluate it across multiple hate speech benchmarks and model families, comparing it against zero-shot LLM classification and in-domain supervised fine-tuning. While supervised methods typically maximize in-domain performance, we consistently improves cross-dataset robustness and relative performance under domain shift. In addition, qualitative analysis of disagreement cases provides evidence that the framework can be less sensitive to certain forms of annotation inconsistency and contextual ambiguity. Crucially, the approach enables fine-grained interpretability through explicit decision paths and factor-level analysis.\n  Our results suggest that reframing hate speech detection as a diagnostic reasoning task, rather than a monolithic classification problem, provides a robust, explainable, and extensible alternative for content moderation.", "AI": {"tldr": "The paper introduces xList-Hate, a diagnostic framework for hate speech detection that improves robustness and interpretability compared to traditional binary classification methods.", "motivation": "Traditional binary classification methods for hate speech detection often overfit to dataset-specific definitions, lack robustness to domain shifts, and exhibit sensitivity to annotation noise.", "method": "The paper proposes decomposing hate speech detection into explicit concept-level questions answered by a large language model (LLM), and then aggregating these responses via an interpretable decision tree.", "result": "xList-Hate improves cross-dataset robustness, reduces sensitivity to annotation inconsistencies, and provides transparent predictions compared to supervised methods and zero-shot LLM classifications.", "conclusion": "Reframing hate speech detection as a diagnostic reasoning task offers a robust, interpretable, and extensible solution for content moderation."}}
{"id": "2602.06035", "pdf": "https://arxiv.org/pdf/2602.06035", "abs": "https://arxiv.org/abs/2602.06035", "authors": ["Sirui Xu", "Samuel Schulter", "Morteza Ziyadi", "Xialin He", "Xiaohan Fei", "Yu-Xiong Wang", "Liangyan Gui"], "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions", "categories": ["cs.CV", "cs.GR", "cs.RO"], "comment": "Webpage: https://sirui-xu.github.io/InterPrior/", "summary": "Humans rarely plan whole-body interactions with objects at the level of explicit whole-body movements. High-level intentions, such as affordance, define the goal, while coordinated balance, contact, and manipulation can emerge naturally from underlying physical and motor priors. Scaling such priors is key to enabling humanoids to compose and generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination. To this end, we introduce InterPrior, a scalable framework that learns a unified generative controller through large-scale imitation pretraining and post-training by reinforcement learning. InterPrior first distills a full-reference imitation expert into a versatile, goal-conditioned variational policy that reconstructs motion from multimodal observations and high-level intent. While the distilled policy reconstructs training behaviors, it does not generalize reliably due to the vast configuration space of large-scale human-object interactions. To address this, we apply data augmentation with physical perturbations, and then perform reinforcement learning finetuning to improve competence on unseen goals and initializations. Together, these steps consolidate the reconstructed latent skills into a valid manifold, yielding a motion prior that generalizes beyond the training data, e.g., it can incorporate new behaviors such as interactions with unseen objects. We further demonstrate its effectiveness for user-interactive control and its potential for real robot deployment.", "AI": {"tldr": "Humans naturally perform whole-body interactions without detailed movement planning. InterPrior mimics this by utilizing a combination of imitation pretraining and reinforcement learning to develop humanoid robots capable of generalized whole-body coordination in loco-manipulation tasks.", "motivation": "Enable humanoid robots to generalize and scale whole-body loco-manipulation skills across diverse contexts while achieving coherent physical coordination.", "method": "Develop InterPrior, a unified generative controller through large-scale imitation pretraining to learn human-like behavior and reinforcement learning for finetuning, ensuring adaptability to unseen goals and conditions.", "result": "InterPrior achieved a motion prior that generalizes beyond training data, incorporating new behaviors and interacting with unseen objects. It proved effective for user-interactive control and holds potential for real robot deployment.", "conclusion": "InterPrior successfully learns scalable humanoid interactions through multimodal imitation and reinforcement training, bridging the gap between human-like movements and autonomous robotic control across diverse scenarios."}}
{"id": "2602.05449", "pdf": "https://arxiv.org/pdf/2602.05449", "abs": "https://arxiv.org/abs/2602.05449", "authors": ["Chang Zou", "Changlin Li", "Yang Li", "Patrol Li", "Jianbing Wu", "Xiao He", "Songtao Liu", "Zhao Zhong", "Kailin Huang", "Linfeng Zhang"], "title": "DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 7 figures; cvpr2026 submission", "summary": "While diffusion models have achieved great success in the field of video generation, this progress is accompanied by a rapidly escalating computational burden. Among the existing acceleration methods, Feature Caching is popular due to its training-free property and considerable speedup performance, but it inevitably faces semantic and detail drop with further compression. Another widely adopted method, training-aware step-distillation, though successful in image generation, also faces drastic degradation in video generation with a few steps. Furthermore, the quality loss becomes more severe when simply applying training-free feature caching to the step-distilled models, due to the sparser sampling steps. This paper novelly introduces a distillation-compatible learnable feature caching mechanism for the first time. We employ a lightweight learnable neural predictor instead of traditional training-free heuristics for diffusion models, enabling a more accurate capture of the high-dimensional feature evolution process. Furthermore, we explore the challenges of highly compressed distillation on large-scale video models and propose a conservative Restricted MeanFlow approach to achieve more stable and lossless distillation. By undertaking these initiatives, we further push the acceleration boundaries to $11.8\\times$ while preserving generation quality. Extensive experiments demonstrate the effectiveness of our method. The code is in the supplementary materials and will be publicly available.", "AI": {"tldr": "The paper introduces a learnable feature caching mechanism and a conservative distillation approach for video generation, achieving high-quality results with an $11.8\\times$ acceleration in computational efficiency.", "motivation": "Existing methods in video generation face a trade-off between speeding up diffusion models and preserving quality. Feature caching suffers from quality degradation with compression, while step-distillation faces challenges with quality loss in video generation. Combining these approaches also leads to further degradation.", "method": "The method introduces a novel learnable neural predictor to replace training-free heuristics, allowing better modeling of high-dimensional features in diffusion models. It also proposes a Restricted MeanFlow strategy to address stability and quality issues caused by highly compressed distillation.", "result": "The proposed method achieves up to $11.8\\times$ acceleration in computation while maintaining generation quality in video generation tasks.", "conclusion": "The learnable feature caching mechanism and conservative distillation strategies introduced in this paper effectively enhance video generation speed without sacrificing quality, demonstrating significant potential for practical applications."}}
{"id": "2602.05636", "pdf": "https://arxiv.org/pdf/2602.05636", "abs": "https://arxiv.org/abs/2602.05636", "authors": ["Benny Cheung"], "title": "Generative Ontology: When Structured Knowledge Learns to Create", "categories": ["cs.AI", "cs.CL"], "comment": "15 pages, 6 figures, 6 tables. Code available at https://github.com/bennycheung/GameGrammarCLI", "summary": "Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.\n  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional \"anxiety\" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.\n  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt (\"bioluminescent fungi competing in a cave ecosystem\"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.\n  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.", "AI": {"tldr": "The paper introduces Generative Ontology, combining traditional ontologies and LLMs for structured and creative generation.", "motivation": "To resolve the limitations of traditional ontologies in generating novel artifacts and address the incoherent outputs of LLMs.", "method": "The paper uses Pydantic schemas and a multi-agent system with specialized roles, retrieval-augmented generation, and iterative validation to ensure structured and creative outcomes.", "result": "Demonstration through GameGrammar, a pipeline that generates complete tabletop game designs adhering to ontological and creative constraints.", "conclusion": "Constraints enable creativity and structured generation across domains, suggesting the approach's adaptability to areas like software, music, and culinary arts."}}
{"id": "2602.05084", "pdf": "https://arxiv.org/pdf/2602.05084", "abs": "https://arxiv.org/abs/2602.05084", "authors": ["Zhiqun Zuo", "Mohammad Mahdi Khalili"], "title": "Individual Fairness In Strategic Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Strategic classification, where individuals modify their features to influence machine learning (ML) decisions, presents critical fairness challenges. While group fairness in this setting has been widely studied, individual fairness remains underexplored. We analyze threshold-based classifiers and prove that deterministic thresholds violate individual fairness. Then, we investigate the possibility of using a randomized classifier to achieve individual fairness. We introduce conditions under which a randomized classifier ensures individual fairness and leverage these conditions to find an optimal and individually fair randomized classifier through a linear programming problem. Additionally, we demonstrate that our approach can be extended to group fairness notions. Experiments on real-world datasets confirm that our method effectively mitigates unfairness and improves the fairness-accuracy trade-off.", "AI": {"tldr": "This paper addresses fairness in strategic classification, showing deterministic thresholds violate individual fairness, and proposes a randomized classifier to ensure fairness and improve accuracy-fairness trade-off.", "motivation": "To tackle fairness challenges in strategic classification, where individuals strategically alter features to influence ML models.", "method": "Analysis of threshold-based classifiers for fairness issues, development of conditions for randomized classifiers to ensure fairness, optimization with linear programming, and real-world experiments.", "result": "Proposed randomized classifiers mitigate unfairness and improve the fairness-accuracy trade-off, validated on real-world datasets.", "conclusion": "Randomized classifiers are effective in ensuring individual and group fairness in strategic classification, enhancing fairness-accuracy balance in ML applications."}}
{"id": "2602.05879", "pdf": "https://arxiv.org/pdf/2602.05879", "abs": "https://arxiv.org/abs/2602.05879", "authors": ["Miguel Moura Ramos", "Duarte M. Alves", "Hippolyte Gisserot-Boukhlef", "Jo\u00e3o Alves", "Pedro Henrique Martins", "Patrick Fernandes", "Jos\u00e9 Pombal", "Nuno M. Guerreiro", "Ricardo Rei", "Nicolas Boizard", "Amin Farajian", "Mateusz Klimaszewski", "Jos\u00e9 G. C. de Souza", "Barry Haddow", "Fran\u00e7ois Yvon", "Pierre Colombo", "Alexandra Birch", "Andr\u00e9 F. T. Martins"], "title": "EuroLLM-22B: Technical Report", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This report presents EuroLLM-22B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-22B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. Across a broad set of multilingual benchmarks, EuroLLM-22B demonstrates strong performance in reasoning, instruction following, and translation, achieving results competitive with models of comparable size. To support future research, we release our base and instruction-tuned models, our multilingual web pretraining data and updated EuroBlocks instruction datasets, as well as our pre-training and evaluation codebases.", "AI": {"tldr": "EuroLLM-22B is a multilingual large language model designed to enhance representation of European Union and additional languages, achieving competitive performance in various benchmarks.", "motivation": "To address the lack of representation and support for European languages in existing large language models.", "method": "Development involved designing a tokenizer, specifying architecture, filtering data, and implementing tailored training procedures, alongside multilingual benchmarks.", "result": "EuroLLM-22B shows strong multilingual performance in reasoning, instruction following, and translation, competitive with similar-sized models.", "conclusion": "EuroLLM-22B provides improved multilingual capabilities for European languages, with open resources released for further research and development."}}
{"id": "2602.05454", "pdf": "https://arxiv.org/pdf/2602.05454", "abs": "https://arxiv.org/abs/2602.05454", "authors": ["Yue Lu", "Xiangyu Zhou", "Shizhou Zhang", "Yinghui Xing", "Guoqiang Liang", "Wencong Zhang"], "title": "Attention Retention for Continual Learning with Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "AAAI-2026 Camera Ready", "summary": "Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the attention to previously learned visual concepts shifts significantly after learning new tasks. Inspired by neuroscientific insights into the selective attention in the human visual system, we propose a novel attention-retaining framework to mitigate forgetting in CL. Our method constrains attention drift by explicitly modifying gradients during backpropagation through a two-step process: 1) extracting attention maps of the previous task using a layer-wise rollout mechanism and generating instance-adaptive binary masks, and 2) when learning a new task, applying these masks to zero out gradients associated with previous attention regions, thereby preventing disruption of learned visual concepts. For compatibility with modern optimizers, the gradient masking process is further enhanced by scaling parameter updates proportionally to maintain their relative magnitudes. Experiments and visualizations demonstrate the effectiveness of our method in mitigating catastrophic forgetting and preserving visual concepts. It achieves state-of-the-art performance and exhibits robust generalizability across diverse CL scenarios.", "AI": {"tldr": "The paper addresses catastrophic forgetting in continual learning by investigating attention drift in Vision Transformers and introducing an attention-retaining framework.", "motivation": "The motivation stems from the challenge of catastrophic forgetting in continual learning AI systems, particularly identifying attention drift in Vision Transformers as a significant contributor.", "method": "The paper proposes a two-step framework: 1) Extracting attention maps of the previous task and generating instance-adaptive binary masks, and 2) Using these masks to constrain gradients during new task learning, further scaling parameter updates for optimizer compatibility.", "result": "Experiments and visualizations validate the effectiveness in minimizing catastrophic forgetting, preserving visual concepts, and achieving state-of-the-art performance in various continual learning scenarios.", "conclusion": "The study concludes that the proposed framework successfully mitigates attention drift, enhances continual learning performance, and generalizes robustly across tasks."}}
{"id": "2602.05665", "pdf": "https://arxiv.org/pdf/2602.05665", "abs": "https://arxiv.org/abs/2602.05665", "authors": ["Chang Yang", "Chuang Zhou", "Yilin Xiao", "Su Dong", "Luyao Zhuang", "Yujing Zhang", "Zhu Wang", "Zijin Hong", "Zheng Yuan", "Zhishang Xiang", "Shengyuan Chen", "Huachi Zhou", "Qinggang Zhang", "Ninghao Liu", "Jinsong Su", "Xinrun Wang", "Yi Chang", "Xiao Huang"], "title": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "categories": ["cs.AI"], "comment": null, "summary": "Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.", "AI": {"tldr": "This survey explores graph-based memory for large language model agents, detailing its taxonomy, life cycle techniques, applications, libraries, and challenges.", "motivation": "To improve efficiency and reliability of memory systems in LLM agents for complex tasks by leveraging graph-based structures.", "method": "Classify types of agent memory, analyze memory life cycle techniques, consolidate resources, and identify future research directions.", "result": "Comprehensive taxonomy, systematic analysis of techniques, open-source resources, diverse applications, and identified challenges for graph-based agent memory.", "conclusion": "Graph-based memory offers promising advancements for LLM agents, enabling improved reasoning and evolving memory. Further research and development are encouraged."}}
{"id": "2602.05087", "pdf": "https://arxiv.org/pdf/2602.05087", "abs": "https://arxiv.org/abs/2602.05087", "authors": ["Parsa Vares"], "title": "Autodiscover: A reinforcement learning recommendation system for the cold-start imbalance challenge in active learning, powered by graph-aware thompson sampling", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.IR", "cs.SI"], "comment": "Master's Thesis, University of Luxembourg in collaboration with Luxembourg Institute of Science and Technology (LIST). Supervised by Prof. Jun Pang and Dr. Eloi Durant", "summary": "Systematic literature reviews (SLRs) are fundamental to evidence-based research, but manual screening is an increasing bottleneck as scientific output grows. Screening features low prevalence of relevant studies and scarce, costly expert decisions. Traditional active learning (AL) systems help, yet typically rely on fixed query strategies for selecting the next unlabeled documents. These static strategies do not adapt over time and ignore the relational structure of scientific literature networks. This thesis introduces AutoDiscover, a framework that reframes AL as an online decision-making problem driven by an adaptive agent. Literature is modeled as a heterogeneous graph capturing relationships among documents, authors, and metadata. A Heterogeneous Graph Attention Network (HAN) learns node representations, which a Discounted Thompson Sampling (DTS) agent uses to dynamically manage a portfolio of query strategies. With real-time human-in-the-loop labels, the agent balances exploration and exploitation under non-stationary review dynamics, where strategy utility changes over time. On the 26-dataset SYNERGY benchmark, AutoDiscover achieves higher screening efficiency than static AL baselines. Crucially, the agent mitigates cold start by bootstrapping discovery from minimal initial labels where static approaches fail. We also introduce TS-Insight, an open-source visual analytics dashboard to interpret, verify, and diagnose the agent's decisions. Together, these contributions accelerate SLR screening under scarce expert labels and low prevalence of relevant studies.", "AI": {"tldr": "This paper presents AutoDiscover, a framework enhancing systematic literature reviews (SLRs) through adaptive active learning strategies using heterogeneous graph modeling and Thompson Sampling techniques.", "motivation": "Manual screening in systematic literature reviews struggles with low prevalence of relevant studies and expensive expert decisions in the growing scientific output.", "method": "AutoDiscover introduces an adaptive agent integrating Heterogeneous Graph Attention Networks (HAN) and Discounted Thompson Sampling (DTS) for dynamically managing query strategies in systematic literature screening.", "result": "Experiments on the SYNERGY benchmark show AutoDiscover's higher screening efficiency compared to static active learning methods, achieving effective results even with minimal initial labels.", "conclusion": "AutoDiscover and its TS-Insight dashboard improve SLR screening efficiency, addressing scarce expert labels, cold starts, and dynamic review needs in scientific literature."}}
{"id": "2602.05897", "pdf": "https://arxiv.org/pdf/2602.05897", "abs": "https://arxiv.org/abs/2602.05897", "authors": ["Shuo Nie", "Hexuan Deng", "Chao Wang", "Ruiyu Fang", "Xuebo Liu", "Shuangyong Song", "Yu Li", "Min Zhang", "Xuelong Li"], "title": "Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models", "categories": ["cs.CL"], "comment": null, "summary": "As large language models become smaller and more efficient, small reasoning models (SRMs) are crucial for enabling chain-of-thought (CoT) reasoning in resource-constrained settings. However, they are prone to faithfulness hallucinations, especially in intermediate reasoning steps. Existing mitigation methods based on online reinforcement learning rely on outcome-based rewards or coarse-grained CoT evaluation, which can inadvertently reinforce unfaithful reasoning when the final answer is correct. To address these limitations, we propose Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL), introducing step-level supervision via explicit faithfulness rewards from a process reward model, together with an implicit truncated resampling strategy that generates contrastive signals from faithful prefixes. Experiments across multiple SRMs and Open-Book QA benchmarks demonstrate that FaithRL consistently reduces hallucinations in both the CoT and final answers, leading to more faithful and reliable reasoning. Code is available at https://github.com/Easy195/FaithRL.", "AI": {"tldr": "The paper addresses hallucination issues in small reasoning models during chain-of-thought reasoning, proposing a novel reinforcement learning approach called FaithRL with step-level faithfulness rewards.", "motivation": "Ensure smaller language models can perform accurate and reliable chain-of-thought reasoning in computationally constrained environments while addressing hallucination issues in intermediate reasoning steps.", "method": "FaithRL introduces step-level supervision through faithfulness rewards from a process reward model and employs a truncated resampling strategy for generating contrastive signals.", "result": "FaithRL reduces reasoning hallucinations in both intermediate chain-of-thought steps and final model outputs across small reasoning models and Open-Book QA benchmarks, enhancing reliability.", "conclusion": "FaithRL offers a step-level reinforcement learning framework that improves reasoning faithfulness in small reasoning models, demonstrating consistent performance benefits."}}
{"id": "2602.05119", "pdf": "https://arxiv.org/pdf/2602.05119", "abs": "https://arxiv.org/abs/2602.05119", "authors": ["Thanawat Sornwanee"], "title": "Unbiased Single-Queried Gradient for Combinatorial Objective", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In a probabilistic reformulation of a combinatorial problem, we often face an optimization over a hypercube, which corresponds to the Bernoulli probability parameter for each binary variable in the primal problem. The combinatorial nature suggests that an exact gradient computation requires multiple queries. We propose a stochastic gradient that is unbiased and requires only a single query of the combinatorial function. This method encompasses a well-established REINFORCE (through an importance sampling), as well as including a class of new stochastic gradients.", "AI": {"tldr": "The paper introduces a stochastic gradient method for probabilistic reformulations of combinatorial problems, providing an efficient way to compute unbiased gradients with fewer queries.", "motivation": "The motivation is to address the inefficiency of exact gradient computations in combinatorial problems where optimization occurs over a hypercube.", "method": "The authors propose a stochastic gradient method that uses importance sampling and extends the REINFORCE framework while introducing new techniques to calculate unbiased gradients with fewer queries.", "result": "The method reduces the computational effort by enabling single-query computation of stochastic gradients and broadens gradient-based optimization approaches.", "conclusion": "This paper presents an efficient stochastic gradient method that improves practical optimization strategies in probabilistically reformulated combinatorial problems."}}
{"id": "2602.05905", "pdf": "https://arxiv.org/pdf/2602.05905", "abs": "https://arxiv.org/abs/2602.05905", "authors": ["Letian Peng", "Yupeng Hou", "Kun Zhou", "Jingbo Shang"], "title": "Codified Finite-state Machines for Role-playing", "categories": ["cs.CL"], "comment": null, "summary": "Modeling latent character states is crucial for consistent and engaging role-playing (RP) with large language models (LLMs). Yet, existing prompting-based approaches mainly capture surface actions, often failing to track the latent states that drive interaction. We revisit finite-state machines (FSMs), long used in game design to model state transitions. While effective in small, well-specified state spaces, traditional hand-crafted, rule-based FSMs struggle to adapt to the open-ended semantic space of RP. To address this, we introduce Codified Finite-State Machines (CFSMs), a framework that automatically codifies textual character profiles into FSMs using LLM-based coding. CFSMs extract key states and transitions directly from the profile, producing interpretable structures that enforce character consistency. To further capture uncertainty and variability, we extend CFSMs into Codified Probabilistic Finite-State Machines (CPFSMs), where transitions are modeled as probability distributions over states. Through both synthetic evaluations and real-world RP scenarios in established artifacts, we demonstrate that CFSM and CPFSM outperform generally applied baselines, verifying effectiveness not only in structured tasks but also in open-ended stochastic state exploration.", "AI": {"tldr": "This paper reintroduces finite-state machines (FSMs) for role-playing with language models, proposing Codified FSMs and their probabilistic variant (CPFSMs) to better track character states and transitions.", "motivation": "The authors aim to address shortcomings in existing language model-based role-playing methods, which fail to accurately capture latent character states necessary for consistent and engaging interaction.", "method": "They introduce Codified Finite-State Machines (CFSMs), where FSMs are created using LLM-based coding from textual profiles, and extend them to probabilistic versions (CPFSMs) for stochastic transitions.", "result": "Synthetic evaluations and real-world tests show CFSM and CPFSM outperform traditional baselines, excelling in both structured and open-ended scenarios.", "conclusion": "Codified and probabilistic FSMs improve latent state tracking in role-playing with language models, contributing better consistency and adaptability."}}
{"id": "2602.05480", "pdf": "https://arxiv.org/pdf/2602.05480", "abs": "https://arxiv.org/abs/2602.05480", "authors": ["Peihao Wu", "Yongxiang Yao", "Yi Wan", "Wenfei Zhang", "Ruipeng Zhao", "Jiayuan Li", "Yongjun Zhang"], "title": "SOMA-1M: A Large-Scale SAR-Optical Multi-resolution Alignment Dataset for Multi-Task Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "Synthetic Aperture Radar (SAR) and optical imagery provide complementary strengths that constitute the critical foundation for transcending single-modality constraints and facilitating cross-modal collaborative processing and intelligent interpretation. However, existing benchmark datasets often suffer from limitations such as single spatial resolution, insufficient data scale, and low alignment accuracy, making them inadequate for supporting the training and generalization of multi-scale foundation models. To address these challenges, we introduce SOMA-1M (SAR-Optical Multi-resolution Alignment), a pixel-level precisely aligned dataset containing over 1.3 million pairs of georeferenced images with a specification of 512 x 512 pixels. This dataset integrates imagery from Sentinel-1, PIESAT-1, Capella Space, and Google Earth, achieving global multi-scale coverage from 0.5 m to 10 m. It encompasses 12 typical land cover categories, effectively ensuring scene diversity and complexity. To address multimodal projection deformation and massive data registration, we designed a rigorous coarse-to-fine image matching framework ensuring pixel-level alignment. Based on this dataset, we established comprehensive evaluation benchmarks for four hierarchical vision tasks, including image matching, image fusion, SAR-assisted cloud removal, and cross-modal translation, involving over 30 mainstream algorithms. Experimental results demonstrate that supervised training on SOMA-1M significantly enhances performance across all tasks. Notably, multimodal remote sensing image (MRSI) matching performance achieves current state-of-the-art (SOTA) levels. SOMA-1M serves as a foundational resource for robust multimodal algorithms and remote sensing foundation models. The dataset will be released publicly at: https://github.com/PeihaoWu/SOMA-1M.", "AI": {"tldr": "SOMA-1M provides a large-scale, globally diverse dataset of pixel-level aligned SAR-optical images to support multimodal remote sensing tasks, achieving state-of-the-art performance.", "motivation": "Existing datasets for multimodal remote sensing suffer from limitations like single spatial resolution, insufficient scale, and poor alignment, creating a need for robust training and generalization of multiscale foundation models.", "method": "Developed SOMA-1M with precisely aligned SAR-optical image pairs (over 1.3 million), covering multiple resolutions and diverse land cover categories with a coarse-to-fine alignment process and benchmarks for hierarchical vision tasks.", "result": "SOMA-1M improved performance across four vision tasks\u2014image matching, image fusion, SAR-assisted cloud removal, and cross-modal translation\u2014achieving state-of-the-art results in multimodal image matching.", "conclusion": "SOMA-1M is a pivotal resource for advancing multimodal algorithms and remote sensing foundation models, fostering innovation in pixel-level image alignment and collaborative processing."}}
{"id": "2602.05709", "pdf": "https://arxiv.org/pdf/2602.05709", "abs": "https://arxiv.org/abs/2602.05709", "authors": ["Yihao Ouyang", "Shiwei Li", "Haozhao Wang", "Xiandi Luo", "Zhuoqi Hu", "Yuetong Song", "Qiyu Qin", "Yichen Li", "Ruixuan Li"], "title": "Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions", "categories": ["cs.AI"], "comment": null, "summary": "Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.", "AI": {"tldr": "This paper introduces Generative Low-Rank Adapter (GenLoRA), replacing standard LoRA's explicit-rank matrices with lightweight nonlinear functions, improving parameter efficiency and fine-tuning performance.", "motivation": "The authors observed that the basis vectors in standard LoRA exhibit parameter redundancy, leading to wasted resources when increasing model capacity via explicit-rank methods.", "method": "The authors propose GenLoRA, which replaces explicit basis vector storage with lightweight radial basis functions (RBFs) that generate basis vectors. GenLoRA requires fewer parameters by maintaining compact latent vectors and synthesizing efficient basis vectors.", "result": "Experiments demonstrate that GenLoRA achieves higher effective LoRA ranks under smaller parameter budgets, outperforming standard LoRA in fine-tuning tasks across multiple datasets and architectures.", "conclusion": "GenLoRA enhances parameter efficiency and improves fine-tuning performance by replacing explicit-rank methods with lightweight generative functions for compact representation."}}
{"id": "2602.05125", "pdf": "https://arxiv.org/pdf/2602.05125", "abs": "https://arxiv.org/abs/2602.05125", "authors": ["William F. Shen", "Xinchi Qiu", "Chenxi Whitehouse", "Lisa Alazraki", "Shashwat Goel", "Francesco Barbieri", "Timon Willi", "Akhil Mathur", "Ilias Leontiadis"], "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.", "AI": {"tldr": "RRD is a framework for refining rubrics used in LLM judging, offering better coverage, reduced redundancy, and increased performance in both evaluation and training.", "motivation": "Rubrics for LLM evaluation and reward signals are frequently flawed, leading to inaccuracies and suboptimal reinforcement fine-tuning outcomes.", "method": "RRD employs a recursive decompose-filter cycle to refine rubrics by breaking coarse rubrics into fine-grained criteria, filtering out misaligned and redundant rubrics, and applying correlation-aware weighting.", "result": "RRD improved preference-judgment accuracy across multiple benchmarks and enhanced reward signals for reinforcement fine-tuning, achieving up to 160% improvement in specific tests compared to baseline methods.", "conclusion": "RRD provides a scalable and interpretable method for rubric refinement, establishing its utility for enhancing LLM judging and reward modeling in complex domains."}}
{"id": "2602.05929", "pdf": "https://arxiv.org/pdf/2602.05929", "abs": "https://arxiv.org/abs/2602.05929", "authors": ["Jian Chen", "Zhuoran Wang", "Jiayu Qin", "Ming Li", "Meng Wang", "Changyou Chen", "Yin Chen", "Qizhen Weng", "Yirui Liu"], "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models rely on kv-caches to avoid redundant computation during autoregressive decoding, but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth. Recent work has explored KV-cache compression, yet most approaches neglect the data-dependent nature of kv-caches and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-caches. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation. Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.", "AI": {"tldr": "The paper presents KV-CoRE, an SVD-based method to evaluate compressibility of kv-caches in language models and analyzes compressibility patterns across multiple models and datasets.", "motivation": "As context lengths grow in large language models, kv-cache operations saturate GPU memory bandwidth, necessitating efficient compression techniques. Existing methods often overlook data-dependent and layer-wise variations.", "method": "The paper introduces KV-CoRE, a gradient-free SVD-based metric that computes low-rank compressibility of kv-caches layer-wise and dataset-wise efficiently, analyzing patterns in compressibility.", "result": "The authors identify systematic patterns linking kv-cache compressibility to model architecture, training data, and language coverage. They employ Normalized Effective Rank to measure compressibility and correlate it with performance under compression.", "conclusion": "KV-CoRE provides a principled evaluation framework and a large-scale benchmark of kv-cache compressibility, offering insights for dynamic compression and improving data-aware model development."}}
{"id": "2602.05487", "pdf": "https://arxiv.org/pdf/2602.05487", "abs": "https://arxiv.org/abs/2602.05487", "authors": ["Julien Moreau", "S. Ambellouis", "Yassine Ruichek"], "title": "Feature points evaluation on omnidirectional vision with a photorealistic fisheye sequence -- A report on experiments done in 2014", "categories": ["cs.CV"], "comment": null, "summary": "What is this report: This is a scientific report, contributing with a detailed bibliography, a dataset which we will call now PFSeq for ''Photorealistic Fisheye Sequence'' and make available at https://doi.org/10. 57745/DYIVVU, and comprehensive experiments. This work should be considered as a draft, and has been done during my PhD thesis ''Construction of 3D models from fisheye video data-Application to the localisation in urban area'' in 2014 [Mor16]. These results have never been published. The aim was to find the best features detector and descriptor for fisheye images, in the context of selfcalibration, with cameras mounted on the top of a car and aiming at the zenith (to proceed then fisheye visual odometry and stereovision in urban scenes). We face a chicken and egg problem, because we can not take advantage of an accurate projection model for an optimal features detection and description, and we rightly need good features to perform the calibration (i.e. to compute the accurate projection model of the camera). What is not this report: It does not contribute with new features algorithm. It does not compare standard features algorithms to algorithms designed for omnidirectional images (unfortunately). It has not been peer-reviewed. Discussions have been translated and enhanced but the experiments have not been run again and the report has not been updated accordingly to the evolution of the state-of-the-art (read this as a 2014 report).", "AI": {"tldr": "The paper introduces a dataset 'PFSeq' focused on fisheye images and describes experiments to identify optimal features for fisheye self-calibration. It dates back to 2014 and is unpublished.", "motivation": "The paper addresses the challenge of finding the best feature detectors for fisheye images, particularly in urban scenes for tasks like visual odometry and calibration. A unique dataset is created to advance research in this area.", "method": "The author conducted experiments to test feature detectors and descriptors for fisheye images. However, no new algorithms or omnidirectional-specific comparisons were introduced. Cameras were zenith-mounted for urban scene analysis.", "result": "The study presented insights into features detection and descriptors suitable for fisheye calibration. The experiments were part of a PhD work, but the results were not updated or peer-reviewed since 2014.", "conclusion": "The report is a foundational contribution with a valuable dataset ('PFSeq') and experimental findings for fisheye image processing but lacks updated validation and algorithmic innovations."}}
{"id": "2602.05717", "pdf": "https://arxiv.org/pdf/2602.05717", "abs": "https://arxiv.org/abs/2602.05717", "authors": ["Tianyi Wang", "Long Li", "Hongcan Guo", "Yibiao Chen", "Yixia Li", "Yong Wang", "Yun Chen", "Guanhua Chen"], "title": "Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification", "categories": ["cs.AI"], "comment": "17 pages, 6 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.", "AI": {"tldr": "The paper identifies a pathology in Reinforcement Learning called Recursive Space Contraction (RSC) and proposes the Anchored Policy Optimization (APO) approach to address efficiency and prevent collapse.", "motivation": "Address systemic issues in RL, specifically Recursive Space Contraction, which leads to irrecoverable collapse in validity and diversity of learning.", "method": "Anchored Policy Optimization (APO), focusing on Support Coverage instead of global Shape Matching, defines a Safe Manifold to allow efficient sharpening and restore support for better performance.", "result": "Anchored Policy Optimization breaks the accuracy-diversity trade-off, improving Pass@1 and restoring the Pass@K diversity compared to standard RL methods.", "conclusion": "APO effectively aligns gradients to maximize support coverage, enabling elastic recovery and overcoming limitations in standard RL with verifiable rewards."}}
{"id": "2602.05134", "pdf": "https://arxiv.org/pdf/2602.05134", "abs": "https://arxiv.org/abs/2602.05134", "authors": ["Olga Ovcharenko", "Matthias Boehm", "Sebastian Schelter"], "title": "SemPipes -- Optimizable Semantic Data Operators for Tabular Machine Learning Pipelines", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "Real-world machine learning on tabular data relies on complex data preparation pipelines for prediction, data integration, augmentation, and debugging. Designing these pipelines requires substantial domain expertise and engineering effort, motivating the question of how large language models (LLMs) can support tabular ML through code synthesis. We introduce SemPipes, a novel declarative programming model that integrates LLM-powered semantic data operators into tabular ML pipelines. Semantic operators specify data transformations in natural language while delegating execution to a runtime system. During training, SemPipes synthesizes custom operator implementations based on data characteristics, operator instructions, and pipeline context. This design enables the automatic optimization of data operations in a pipeline via LLM-based code synthesis guided by evolutionary search. We evaluate SemPipes across diverse tabular ML tasks and show that semantic operators substantially improve end-to-end predictive performance for both expert-designed and agent-generated pipelines, while reducing pipeline complexity. We implement SemPipes in Python and release it at https://github.com/deem-data/sempipes/tree/v1.", "AI": {"tldr": "SemPipes enables large language models (LLMs) to optimize tabular ML pipelines using natural language data transformations, improving performance and reducing complexity.", "motivation": "Machine learning on tabular data often requires complex data pipelines, demanding domain expertise and significant engineering efforts. The authors aim to explore how LLMs can assist in creating efficient pipelines.", "method": "SemPipes introduces a declarative programming model with LLM-powered semantic operators for data preprocessing and optimization. It uses natural language instructions, runtime execution, and evolutionary search synthesis for efficient pipeline design.", "result": "SemPipes improves predictive performance and simplifies pipeline complexity across various tabular ML tasks. The model showcases enhanced functionality for both expert-designed and automated pipelines.", "conclusion": "Semantic operators leveraging LLMs show promise in streamlining tabular ML processes, making pipeline creation more accessible and efficient."}}
{"id": "2602.05932", "pdf": "https://arxiv.org/pdf/2602.05932", "abs": "https://arxiv.org/abs/2602.05932", "authors": ["L\u00e9o Labat", "Etienne Ollion", "Fran\u00e7ois Yvon"], "title": "Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions", "categories": ["cs.CL"], "comment": "17 pages, 5 figures (8 pages of references and appendices)", "summary": "Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.", "AI": {"tldr": "This paper investigates whether multilingual large language models (LLMs) show consistent responses across languages in value-laden multiple-choice questions (MCQs) or exhibit language-dependent variations.", "motivation": "To understand if multilingual LLMs behave as theoretical polyglots (consistent across languages) or reflect different values depending on the language of input.", "method": "The authors introduce the Multilingual European Value Survey (MEVS), comprising human-translated MCQs in 8 languages. They evaluated over 30 multilingual LLMs using controlled prompt variations, including answer order and symbol type.", "result": "Larger instruction-tuned models displayed higher consistency overall, but responses varied greatly based on the type of question. Language-specific behaviors were observed selectively in instruction-fine-tuned models.", "conclusion": "Language-induced variations exist in multilingual LLM responses, but further study is required to understand the impact of preference fine-tuning."}}
{"id": "2602.05508", "pdf": "https://arxiv.org/pdf/2602.05508", "abs": "https://arxiv.org/abs/2602.05508", "authors": ["Zhuang Xiong", "Chen Zhang", "Qingshan Xu", "Wenbing Tao"], "title": "VGGT-Motion: Motion-Aware Calibration-Free Monocular SLAM for Long-Range Consistency", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent progress in calibration-free monocular SLAM via 3D vision foundation models, scale drift remains severe on long sequences. Motion-agnostic partitioning breaks contextual coherence and causes zero-motion drift, while conventional geometric alignment is computationally expensive. To address these issues, we propose VGGT-Motion, a calibration-free SLAM system for efficient and robust global consistency over kilometer-scale trajectories. Specifically, we first propose a motion-aware submap construction mechanism that uses optical flow to guide adaptive partitioning, prune static redundancy, and encapsulate turns for stable local geometry. We then design an anchor-driven direct Sim(3) registration strategy. By exploiting context-balanced anchors, it achieves search-free, pixel-wise dense alignment and efficient loop closure without costly feature matching. Finally, a lightweight submap-level pose graph optimization enforces global consistency with linear complexity, enabling scalable long-range operation. Experiments show that VGGT-Motion markedly improves trajectory accuracy and efficiency, achieving state-of-the-art performance in zero-shot, long-range calibration-free monocular SLAM.", "AI": {"tldr": "The paper introduces VGGT-Motion, a calibration-free SLAM system addressing scale drift and inefficiencies in long-range scenarios by leveraging motion-aware submap construction and direct Sim(3) registration.", "motivation": "Scaling issues and inefficiencies arise in calibration-free monocular SLAM during long-range sequences due to scale drift, static redundancy, and zero-motion drift.", "method": "The proposed solution involves motion-aware submap construction guided by optical flow, anchor-driven direct Sim(3) registration for dense alignment without feature matching, and lightweight submap-level pose graph optimization.", "result": "Experiments demonstrate the system's significant improvements in trajectory accuracy and computation efficiency, achieving state-of-the-art results in zero-shot and scalable monocular SLAM settings.", "conclusion": "VGGT-Motion provides an efficient and robust approach for ensuring global consistency and overcoming SLAM challenges over kilometer-scale trajectories."}}
{"id": "2602.05723", "pdf": "https://arxiv.org/pdf/2602.05723", "abs": "https://arxiv.org/abs/2602.05723", "authors": ["Taoye Yin", "Haoyuan Hu", "Yaxin Fan", "Xinhao Chen", "Xinya Wu", "Kai Deng", "Kezun Zhang", "Feng Wang"], "title": "Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification", "categories": ["cs.AI"], "comment": "accepted by ICASSP 2026", "summary": "In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.", "AI": {"tldr": "The study introduces a Reinforcement Learning framework, RLFKV, to reduce hallucinations in financial RAG systems by verifying fine-grained knowledge units for improved alignment with retrieved documents.", "motivation": "In financial domains, RAG systems often generate responses with hallucinations despite relying on retrieved documents. Addressing this ensures more accurate and consistent financial data responses.", "method": "The paper proposes RLFKV, which breaks financial responses into atomic knowledge units, verifies their correctness for a fine-grained faithful reward, and incorporates an informativeness reward to deter concise, low-quality responses.", "result": "Experiments on public FDD tasks and their new FDD-ANT dataset showed consistent improvements across models, proving the approach's efficacy.", "conclusion": "The RLFKV framework enhances consistency and informativeness of financial RAG systems by utilizing precise knowledge verification and rewards, addressing persistent challenges of hallucinations."}}
{"id": "2602.05136", "pdf": "https://arxiv.org/pdf/2602.05136", "abs": "https://arxiv.org/abs/2602.05136", "authors": ["Hao Chen", "Jinghui Yuan", "Hanmin Zhang"], "title": "Decoupled Orthogonal Dynamics: Regularization for Deep Network Optimizers", "categories": ["cs.LG"], "comment": null, "summary": "Is the standard weight decay in AdamW truly optimal? Although AdamW decouples weight decay from adaptive gradient scaling, a fundamental conflict remains: the Radial Tug-of-War. In deep learning, gradients tend to increase parameter norms to expand effective capacity while steering directions to learn features, whereas weight decay indiscriminately suppresses norm growth. This push--pull interaction induces radial oscillations, injecting noise into Adam's second-moment estimates and potentially degrading delicate tangential feature learning. We argue that magnitude and direction play distinct roles and should be decoupled in optimizer dynamics. We propose Orthogonal Dynamics Decoupling and instantiate it as AdamO: an SGD-style update handles the one-dimensional norm control, while Adam's adaptive preconditioning is confined to the tangential subspace. AdamO further incorporates curvature-adaptive radial step sizing and architecture-aware rules and projections for scale-invariant layers and low-dimensional parameters. Experiments on vision and language tasks show that AdamO improves generalization and stability over AdamW without introducing additional complex constraints.", "AI": {"tldr": "The paper critiques AdamW's weight decay mechanism and introduces AdamO, an optimizer that decouples magnitude and directional dynamics for better generalization and stability.", "motivation": "The authors aim to address limitations of the AdamW optimizer, particularly the conflict between adaptive gradient scaling and weight decay, termed the 'Radial Tug-of-War,' which degrades learning due to radial oscillations.", "method": "They propose Orthogonal Dynamics Decoupling (ODD) and instantiate it as AdamO. The key innovation is separating norm control from directional updates using an SGD-style approach for norms and Adam's adaptive preconditioning for tangential directions. AdamO also adapts step sizing and introduces architecture-aware rules.", "result": "Experiments on both vision and language tasks demonstrate that AdamO improves generalization and stability compared to AdamW.", "conclusion": "The proposed AdamO optimizer enhances generalization and stability by decoupling directional and magnitude dynamics, thus addressing challenges in AdamW, without adding significant complexity."}}
{"id": "2602.05940", "pdf": "https://arxiv.org/pdf/2602.05940", "abs": "https://arxiv.org/abs/2602.05940", "authors": ["Junxiao Liu", "Zhijun Wang", "Yixiao Li", "Zhejian Lai", "Liqian Huang", "Xin Huang", "Xue Han", "Junlan Feng", "Shujian Huang"], "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training", "categories": ["cs.CL"], "comment": "16 pages, 11 figures", "summary": "Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.", "AI": {"tldr": "This paper proposes TRIT, a framework enhancing multilingual reasoning and question understanding. It significantly improves accuracy without external resources.", "motivation": "Current reasoning models struggle with multilingual questions due to inadequate language understanding and reasoning capabilities.", "method": "The TRIT framework integrates translation training within multilingual reasoning models, allowing self-improvement without external feedback or data.", "result": "TRIT achieves notable accuracy improvements in multilingual settings and enhances question alignment and translation quality in both domain-specific and general tests.", "conclusion": "TRIT effectively addresses multilingual reasoning challenges, boosting answer correctness, language consistency, and translation quality."}}
{"id": "2602.05522", "pdf": "https://arxiv.org/pdf/2602.05522", "abs": "https://arxiv.org/abs/2602.05522", "authors": ["Jeongbin You", "Donggun Kim", "Sejun Park", "Seungsang Oh"], "title": "Mapper-GIN: Lightweight Structural Graph Abstraction for Corrupted 3D Point Cloud Classification", "categories": ["cs.CV", "math.GT"], "comment": null, "summary": "Robust 3D point cloud classification is often pursued by scaling up backbones or relying on specialized data augmentation. We instead ask whether structural abstraction alone can improve robustness, and study a simple topology-inspired decomposition based on the Mapper algorithm. We propose Mapper-GIN, a lightweight pipeline that partitions a point cloud into overlapping regions using Mapper (PCA lens, cubical cover, and followed by density-based clustering), constructs a region graph from their overlaps, and performs graph classification with a Graph Isomorphism Network. On the corruption benchmark ModelNet40-C, Mapper-GIN achieves competitive and stable accuracy under Noise and Transformation corruptions with only 0.5M parameters. In contrast to prior approaches that require heavier architectures or additional mechanisms to gain robustness, Mapper-GIN attains strong corruption robustness through simple region-level graph abstraction and GIN message passing. Overall, our results suggest that region-graph structure offers an efficient and interpretable source of robustness for 3D visual recognition.", "AI": {"tldr": "The paper introduces Mapper-GIN, a lightweight pipeline that uses a topology-inspired decomposition for robust 3D point cloud classification, achieving competitive accuracy without heavy architectures.", "motivation": "The authors aim to explore whether structural abstraction alone can improve robustness in 3D point cloud classification, instead of relying on scaling up models or data augmentation.", "method": "The proposed method, Mapper-GIN, partitions a point cloud into overlapping regions using Mapper (PCA lens, cubical cover, and density-based clustering), constructs a region graph, and performs graph classification with a Graph Isomorphism Network.", "result": "Mapper-GIN shows competitive and stable accuracy under Noise and Transformation corruptions on the ModelNet40-C benchmark using just 0.5M parameters.", "conclusion": "Mapper-GIN demonstrates that region-level graph abstraction paired with GIN message passing can efficiently provide robustness for 3D visual recognition, offering interpretability and simplicity."}}
{"id": "2602.05748", "pdf": "https://arxiv.org/pdf/2602.05748", "abs": "https://arxiv.org/abs/2602.05748", "authors": ["Amit Kravchik Taub", "Fred M. Grabovski", "Guy Amit", "Yisroel Mirsky"], "title": "LeakBoost: Perceptual-Loss-Based Membership Inference Attack", "categories": ["cs.AI"], "comment": null, "summary": "Membership inference attacks (MIAs) aim to determine whether a sample was part of a model's training set, posing serious privacy risks for modern machine-learning systems. Existing MIAs primarily rely on static indicators, such as loss or confidence, and do not fully leverage the dynamic behavior of models when actively probed. We propose LeakBoost, a perceptual-loss-based interrogation framework that actively probes a model's internal representations to expose hidden membership signals. Given a candidate input, LeakBoost synthesizes an interrogation image by optimizing a perceptual (activation-space) objective, amplifying representational differences between members and non-members. This image is then analyzed by an off-the-shelf membership detector, without modifying the detector itself. When combined with existing membership inference methods, LeakBoost achieves substantial improvements at low false-positive rates across multiple image classification datasets and diverse neural network architectures. In particular, it raises AUC from near-chance levels (0.53-0.62) to 0.81-0.88, and increases TPR at 1 percent FPR by over an order of magnitude compared to strong baseline attacks. A detailed sensitivity analysis reveals that deeper layers and short, low-learning-rate optimization produce the strongest leakage, and that improvements concentrate in gradient-based detectors. LeakBoost thus offers a modular and computationally efficient way to assess privacy risks in white-box settings, advancing the study of dynamic membership inference.", "AI": {"tldr": "LeakBoost is a framework enhancing membership inference attacks by probing a model's internal representations through optimized perceptual loss and improving attack success.", "motivation": "Membership inference attacks must be advanced as current approaches do not leverage dynamic probing effectively, risking privacy.", "method": "LeakBoost actively interrogates models by creating optimized perceptual-loss-based images and detecting membership signals using existing detectors.", "result": "LeakBoost significantly boosts attack metrics, achieving AUC from 0.53-0.62 to 0.81-0.88, and increases TPR at 1 percent FPR, showing marked success against strong baselines.", "conclusion": "LeakBoost enhances membership inference methods efficiently, especially in white-box settings, providing deeper insights into model leakage dynamics."}}
{"id": "2602.05139", "pdf": "https://arxiv.org/pdf/2602.05139", "abs": "https://arxiv.org/abs/2602.05139", "authors": ["Jikai Jin", "Kenneth Hung", "Sanath Kumar Krishnamurthy", "Baoyi Shi", "Congshan Zhang"], "title": "Adaptive Exploration for Latent-State Bandits", "categories": ["cs.LG"], "comment": null, "summary": "The multi-armed bandit problem is a core framework for sequential decision-making under uncertainty, but classical algorithms often fail in environments with hidden, time-varying states that confound reward estimation and optimal action selection. We address key challenges arising from unobserved confounders, such as biased reward estimates and limited state information, by introducing a family of state-model-free bandit algorithms that leverage lagged contextual features and coordinated probing strategies. These implicitly track latent states and disambiguate state-dependent reward patterns. Our methods and their adaptive variants can learn optimal policies without explicit state modeling, combining computational efficiency with robust adaptation to non-stationary rewards. Empirical results across diverse settings demonstrate superior performance over classical approaches, and we provide practical recommendations for algorithm selection in real-world applications.", "AI": {"tldr": "This paper presents algorithms for addressing challenges in multi-armed bandit problems with hidden, time-varying states.", "motivation": "To overcome limitations in classical multi-armed bandit algorithms which struggle with hidden, time-varying states that lead to biased reward estimation.", "method": "Introduces state-model-free bandit algorithms using lagged contextual features and coordinated probing strategies to implicitly track latent states and adapt to non-stationary rewards.", "result": "The proposed methods outperform classical algorithms in various settings and adapt effectively to environments with unobserved confounders.", "conclusion": "The algorithms offer a computationally efficient and robust solution to multi-armed bandit problems, with practical guidelines for real-world application."}}
{"id": "2602.05527", "pdf": "https://arxiv.org/pdf/2602.05527", "abs": "https://arxiv.org/abs/2602.05527", "authors": ["Ben Isselmann", "Dilara G\u00f6ksu", "Andreas Weinmann"], "title": "Generalization of Self-Supervised Vision Transformers for Protein Localization Across Microscopy Domains", "categories": ["cs.CV"], "comment": "AMEE Conference Proceeding 2025, 11 pages, 2 figures", "summary": "Task-specific microscopy datasets are often too small to train deep learning models that learn robust feature representations. Self-supervised learning (SSL) can mitigate this by pretraining on large unlabeled datasets, but it remains unclear how well such representations transfer across microscopy domains with different staining protocols and channel configurations. We investigate the cross-domain transferability of DINO-pretrained Vision Transformers for protein localization on the OpenCell dataset. We generate image embeddings using three DINO backbones pretrained on ImageNet-1k, the Human Protein Atlas (HPA), and OpenCell, and evaluate them by training a supervised classification head on OpenCell labels. All pretrained models transfer well, with the microscopy-specific HPA-pretrained model achieving the best performance (mean macro $F_1$-score = 0.8221 \\pm 0.0062), slightly outperforming a DINO model trained directly on OpenCell (0.8057 \\pm 0.0090). These results highlight the value of large-scale pretraining and indicate that domain-relevant SSL representations can generalize effectively to related but distinct microscopy datasets, enabling strong downstream performance even when task-specific labeled data are limited.", "AI": {"tldr": "The study examines how self-supervised learning (SSL) representations transfer across microscopy datasets. Pretrained models, especially domain-specific ones, show excellent transferability and performance in tasks with limited labeled data.", "motivation": "The motivation is to address the challenge of small dataset sizes in microscopy by exploring how SSL-pretrained models can transfer robust feature representations across diverse microscopy domains.", "method": "The authors pretrained DINO Vision Transformers on large datasets like ImageNet-1k, Human Protein Atlas (HPA), and OpenCell, and evaluated their cross-domain transferability by fine-tuning classification heads for protein localization on OpenCell labeled data.", "result": "All pretrained models demonstrated strong transferability. Among them, the microscopy-specific HPA-pretrained model performed best, achieving a mean macro F1-score of 0.8221, slightly higher than the performance of a model trained directly on OpenCell.", "conclusion": "Large-scale SSL pretraining provides effective representations for microscopy tasks. Domain-relevant SSL models, even when pretrained on distinct but related datasets, can generalize and perform well in different microscopy domains with limited labeled data."}}
{"id": "2602.05144", "pdf": "https://arxiv.org/pdf/2602.05144", "abs": "https://arxiv.org/abs/2602.05144", "authors": ["Amir Asiaee", "Kaveh Aryan"], "title": "Fairness Under Group-Conditional Prior Probability Shift: Invariance, Drift, and Target-Aware Post-Processing", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning systems are often trained and evaluated for fairness on historical data, yet deployed in environments where conditions have shifted. A particularly common form of shift occurs when the prevalence of positive outcomes changes differently across demographic groups--for example, when disease rates rise faster in one population than another, or when economic conditions affect loan default rates unequally. We study group-conditional prior probability shift (GPPS), where the label prevalence $P(Y=1\\mid A=a)$ may change between training and deployment while the feature-generation process $P(X\\mid Y,A)$ remains stable. Our analysis yields three main contributions. First, we prove a fundamental dichotomy: fairness criteria based on error rates (equalized odds) are structurally invariant under GPPS, while acceptance-rate criteria (demographic parity) can drift--and we prove this drift is unavoidable for non-trivial classifiers (shift-robust impossibility). Second, we show that target-domain risk and fairness metrics are identifiable without target labels: the invariance of ROC quantities under GPPS enables consistent estimation from source labels and unlabeled target data alone, with finite-sample guarantees. Third, we propose TAP-GPPS, a label-free post-processing algorithm that estimates prevalences from unlabeled data, corrects posteriors, and selects thresholds to satisfy demographic parity in the target domain. Experiments validate our theoretical predictions and demonstrate that TAP-GPPS achieves target fairness with minimal utility loss.", "AI": {"tldr": "The paper examines how fairness criteria for machine learning systems are impacted by shifts in the prevalence of positive outcomes across demographic groups while the feature-generation process remains stable.", "motivation": "Fairness in machine learning systems deployed in environments with changing conditions, particularly shifts in positive outcome prevalence across demographic groups, is crucial to ensure equity and performance.", "method": "The paper introduces a theoretical framework analyzing fairness criteria under group-conditional prior probability shift (GPPS), and proposes TAP-GPPS, a label-free post-processing algorithm to address fairness under such shifts.", "result": "The analysis demonstrates that error rate-based fairness criteria remain invariant under GPPS while acceptance-rate criteria drift. TAP-GPPS achieves demographic parity in shifting conditions with minimal utility loss, backed by theoretical and experimental validations.", "conclusion": "Fairness criteria such as demographic parity may drift under group-conditional prior probability shift, but TAP-GPPS provides an effective post-processing solution to maintain fairness and minimize utility loss in deployment scenarios."}}
{"id": "2602.05992", "pdf": "https://arxiv.org/pdf/2602.05992", "abs": "https://arxiv.org/abs/2602.05992", "authors": ["Lizhuo Luo", "Shenggui Li", "Yonggang Wen", "Tianwei Zhang"], "title": "DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.", "AI": {"tldr": "The paper proposes Dynamic Sliding Block (DSB), a training-free adaptive block scheduling method for diffusion large language models (dLLMs) to improve text generation quality and efficiency.", "motivation": "The motivation is to address the inefficiencies and quality issues of naive block scheduling in dLLMs, which fails to adapt to semantic difficulties, resulting in premature or delayed decoding decisions.", "method": "The authors propose Dynamic Sliding Block (DSB), which adapts block schedules dynamically to semantic difficulty using a sliding block with variable size. They also introduce DSB Cache, a tailored training-free KV-cache mechanism.", "result": "Extensive experiments demonstrate that DSB and DSB Cache consistently enhance generation quality and efficiency across various dLLMs and benchmarks.", "conclusion": "The proposed DSB and DSB Cache successfully overcome limitations in naive block scheduling, enabling more reliable and efficient text generation. This approach broadens the application potential of dLLMs."}}
{"id": "2602.05534", "pdf": "https://arxiv.org/pdf/2602.05534", "abs": "https://arxiv.org/abs/2602.05534", "authors": ["Youngwoo Shin", "Jiwan Hur", "Junmo Kim"], "title": "SSG: Scaled Spatial Guidance for Multi-Scale Visual Autoregressive Generation", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2026", "summary": "Visual autoregressive (VAR) models generate images through next-scale prediction, naturally achieving coarse-to-fine, fast, high-fidelity synthesis mirroring human perception. In practice, this hierarchy can drift at inference time, as limited capacity and accumulated error cause the model to deviate from its coarse-to-fine nature. We revisit this limitation from an information-theoretic perspective and deduce that ensuring each scale contributes high-frequency content not explained by earlier scales mitigates the train-inference discrepancy. With this insight, we propose Scaled Spatial Guidance (SSG), training-free, inference-time guidance that steers generation toward the intended hierarchy while maintaining global coherence. SSG emphasizes target high-frequency signals, defined as the semantic residual, isolated from a coarser prior. To obtain this prior, we leverage a principled frequency-domain procedure, Discrete Spatial Enhancement (DSE), which is devised to sharpen and better isolate the semantic residual through frequency-aware construction. SSG applies broadly across VAR models leveraging discrete visual tokens, regardless of tokenization design or conditioning modality. Experiments demonstrate SSG yields consistent gains in fidelity and diversity while preserving low latency, revealing untapped efficiency in coarse-to-fine image generation. Code is available at https://github.com/Youngwoo-git/SSG.", "AI": {"tldr": "The paper presents an inference-time guidance method called Scaled Spatial Guidance (SSG), enhancing coarse-to-fine image generation using autoregressive models through high-frequency signal emphasis, resulting in improved fidelity, diversity, and low-latency synthesis.", "motivation": "The motivation is to address the train-inference discrepancy in Visual Autoregressive (VAR) models, where limited model capacity and accumulated errors disrupt the coarse-to-fine image generation process.", "method": "The method, Scaled Spatial Guidance (SSG), involves training-free, inference-time guidance that highlights high-frequency signals (semantic residuals) isolated at coarser scales using Discrete Spatial Enhancement (DSE), a frequency-based procedure to ensure image synthesis aligns with hierarchical design and maintains global coherence.", "result": "The results demonstrate that SSG improves image fidelity and diversity in VAR models while maintaining efficiency and low computational latency.", "conclusion": "SSG effectively bridges the gap in hierarchical image generation, enhancing synthesis quality and coherence across scales without additional training, and works seamlessly across diverse tokenization designs and modalities."}}
{"id": "2602.05765", "pdf": "https://arxiv.org/pdf/2602.05765", "abs": "https://arxiv.org/abs/2602.05765", "authors": ["Zhong Guan", "Haoran Sun", "Yongjian Guo", "Shuai Di", "Xiaodong Bai", "Jing Long", "Tianyun Zhao", "Mingxi Luo", "Chen Zhou", "Yucheng Guo", "Qiming Yang", "Wanting Xu", "Wen Huang", "Yunxuan Ma", "Hongke Zhao", "Likang Wu", "Xiaotie Deng", "Xi Xiao", "Sheng Wen", "Yicheng Gong", "Junwu Xiong"], "title": "RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.", "AI": {"tldr": "The paper introduces a fully asynchronous policy training framework for Vision-Language-Action (VLA) models to address inefficiency issues in existing reinforcement learning-based frameworks, achieving significant gains in training throughput and scalability.", "motivation": "Training inefficiency in Vision-Language-Action models has become a bottleneck, as existing reinforcement learning training frameworks rely on synchronous execution, causing resource underutilization and throughput limitations.", "method": "The paper proposes a fully asynchronous policy training framework using a multi-level decoupled architecture. It includes asynchronous parallelization for environment interaction, streaming execution for policy generation, and decoupled scheduling for model updates.", "result": "On the LIBERO benchmark, the proposed framework achieved up to 59.25% improvement in throughput compared to synchronous strategies. With further optimizations, throughput improved up to 126.67%. The approach also demonstrated excellent scalability across a wide range of GPUs.", "conclusion": "Asynchronous training frameworks can significantly improve the efficiency and scalability of Vision-Language-Action models, addressing the bottleneck of synchronous execution in reinforcement learning approaches."}}
{"id": "2602.05145", "pdf": "https://arxiv.org/pdf/2602.05145", "abs": "https://arxiv.org/abs/2602.05145", "authors": ["Jiyoung Park", "Hankyu Jang", "Changseok Song", "Wookeun Jung"], "title": "TIDE: Temporal Incremental Draft Engine for Self-Improving LLM Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Speculative decoding can substantially accelerate LLM inference, but realizing its benefits in practice is challenging due to evolving workloads and system-level constraints. We present TIDE (Temporal Incremental Draft Engine), a serving-engine-native framework that integrates online draft adaptation directly into high-performance LLM inference systems. TIDE reuses target model hidden states generated during inference as training signals, enabling zero-overhead draft adaptation without reloading the target model, and employs adaptive runtime control to activate speculation and training only when beneficial. TIDE exploits heterogeneous clusters by mapping decoupled inference and training to appropriate GPU classes. Across diverse real-world workloads, TIDE achieves up to 1.15x throughput improvement over static speculative decoding while reducing draft training time by 1.67x compared to approaches that recompute training signals.", "AI": {"tldr": "TIDE is a new framework that accelerates LLM inference systems using zero-overhead draft adaptation and runtime controls, showing significant performance improvements.", "motivation": "The paper addresses the challenges of applying speculative decoding effectively in practical LLM inference systems, such as evolving workloads and system constraints.", "method": "TIDE integrates online draft adaptation with high-performance LLM systems, using hidden states during inference as training signals, runtime controls for execution, and exploiting GPU heterogeneity for efficiency.", "result": "TIDE achieves up to 1.15x throughput improvement and reduces draft training time by 1.67x compared to traditional approaches.", "conclusion": "TIDE demonstrates substantial improvements in LLM inference efficiency and adaptability, showcasing its potential in real-world scenarios."}}
{"id": "2602.06015", "pdf": "https://arxiv.org/pdf/2602.06015", "abs": "https://arxiv.org/abs/2602.06015", "authors": ["Panagiotis Kaliosis", "Adithya V Ganesan", "Oscar N. E. Kjell", "Whitney Ringwald", "Scott Feltman", "Melissa A. Carr", "Dimitris Samaras", "Camilo Ruggero", "Benjamin J. Luft", "Roman Kotov", "Andrew H. Schwartz"], "title": "A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies", "categories": ["cs.CL"], "comment": "18 pages, 3 figures, 5 tables", "summary": "Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.", "AI": {"tldr": "The paper assesses factors influencing the accuracy of large language models (LLMs) for zero-shot PTSD severity evaluation using clinical narratives and explores different contextual and modeling strategies.", "motivation": "Mental health assessments using LLMs are gaining traction, but limited understanding exists about what influences their accuracy, particularly for PTSD evaluations in real-world settings.", "method": "The study evaluates 11 LLMs using clinical narratives and self-reported PTSD scores, systematically varying contextual knowledge (construct definitions, distribution summaries) and modeling strategies (zero-shot vs few-shot, reasoning effort, model size, ensemble methods).", "result": "LLMs perform best with detailed construct definitions, context, and increased reasoning effort. Open-weight model performance plateaus at 70B, while newer closed-weight models improve. Ensembling supervised models with zero-shot LLMs achieves superior accuracy.", "conclusion": "Context-sensitive strategies, effective reasoning, and judicious combination of supervised and LLM approaches are key to successfully using LLMs for accurate mental health assessments."}}
{"id": "2602.05538", "pdf": "https://arxiv.org/pdf/2602.05538", "abs": "https://arxiv.org/abs/2602.05538", "authors": ["Malaz Tamim", "Andrea Matic-Flierl", "Karsten Roscher"], "title": "A Comparative Study of 3D Person Detection: Sensor Modalities and Robustness in Diverse Indoor and Outdoor Environments", "categories": ["cs.CV"], "comment": "Accepted for VISAPP 2026", "summary": "Accurate 3D person detection is critical for safety in applications such as robotics, industrial monitoring, and surveillance. This work presents a systematic evaluation of 3D person detection using camera-only, LiDAR-only, and camera-LiDAR fusion. While most existing research focuses on autonomous driving, we explore detection performance and robustness in diverse indoor and outdoor scenes using the JRDB dataset. We compare three representative models - BEVDepth (camera), PointPillars (LiDAR), and DAL (camera-LiDAR fusion) - and analyze their behavior under varying occlusion and distance levels. Our results show that the fusion-based approach consistently outperforms single-modality models, particularly in challenging scenarios. We further investigate robustness against sensor corruptions and misalignments, revealing that while DAL offers improved resilience, it remains sensitive to sensor misalignment and certain LiDAR-based corruptions. In contrast, the camera-based BEVDepth model showed the lowest performance and was most affected by occlusion, distance, and noise. Our findings highlight the importance of utilizing sensor fusion for enhanced 3D person detection, while also underscoring the need for ongoing research to address the vulnerabilities inherent in these systems.", "AI": {"tldr": "This paper evaluates 3D person detection using camera-only, LiDAR-only, and camera-LiDAR fusion methods. Fusion models consistently outperform single-modality ones but remain sensitive to sensor issues.", "motivation": "To enhance safety-critical 3D person detection in various environments by systematically evaluating different sensing techniques.", "method": "Three models (BEVDepth, PointPillars, DAL) were compared using the JRDB dataset across diverse settings, varying occlusion, and distance. Robustness against sensor issues was also examined.", "result": "Fusion-based models outperformed in challenging scenarios. However, they remain sensitive to sensor misalignments and certain corruptions, particularly LiDAR-based.", "conclusion": "Sensor fusion is vital for effective 3D person detection, yet vulnerabilities like sensor misalignment necessitate further research."}}
{"id": "2602.05794", "pdf": "https://arxiv.org/pdf/2602.05794", "abs": "https://arxiv.org/abs/2602.05794", "authors": ["Aboli Kathar", "Aman Kumar", "Anusha Kamath", "Araveeti Srujan", "Ashish Sharma", "Chandra Bhushan", "Dilip Asbe", "Divya Sorate", "Duddu Prasanth Kumar", "Evan Acharya", "Harsh Sharma", "Hrithik Kadam", "Kanishk Singla", "Keyur Doshi", "Kiran Praveen", "Kolisetty Krishna SK", "Krishanu Adhikary", "Lokesh MPT", "Mayurdeep Sonowal", "Nadeem Shaikh", "Navya Prakash", "Nimit Kothari", "Nitin Kukreja", "Prashant Devadiga", "Rakesh Paul", "Ratanjeet Pratap Chauhan", "Raunak Kalani", "Raviraj Joshi", "Shamanth MH", "Shantanu Pandey", "Shubham Soni", "Siddharth Dixit", "Smriti Jopat", "Sunil Patel", "Suraj Singh", "Suvradip Paul", "Tulasi Pilla", "Utkarsh Vaidya", "Vineeth Nambiar", "Vishal Kanvaty", "Yatharth Dedhia"], "title": "FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with continuous pre-training on 68 Billion tokens of curated financial, multilingual (English, Hindi, Hinglish), and synthetic data. This is followed by instruction fine-tuning and domain-specific supervised fine-tuning focused on multi-turn, tool-driven conversations that model real-world workflows, such as transaction disputes and mandate lifecycle management. Evaluations reveal that FiMI Base achieves a 20% improvement over the Mistral Small 24B Base model on finance reasoning benchmark, while FiMI Instruct outperforms the Mistral Small 24B Instruct model by 87% on domain-specific tool-calling. Moreover, FiMI achieves these significant domain gains while maintaining comparable performance to models of similar size on general benchmarks.", "AI": {"tldr": "FiMI is a specialized language model for Indian financial systems, offering significant improvements in finance reasoning and domain-specific tasks.", "motivation": "Creating a financial language model tailored for Indian payment systems to improve task-specific performance, such as transaction and disputes management.", "method": "FiMI adapts Mistral Small 24B architecture using multi-stage training: pre-training on curated financial and multilingual data, followed by instruction and domain-specific fine-tuning.", "result": "FiMI greatly improves performance: FiMI Base achieves 20% better finance reasoning, and FiMI Instruct outperforms in domain-specific operations by 87%, while maintaining general benchmark parity.", "conclusion": "FiMI demonstrates value as a domain-specialized financial model for Indian systems, excelling in task-specific and tool-driven operations."}}
{"id": "2602.05146", "pdf": "https://arxiv.org/pdf/2602.05146", "abs": "https://arxiv.org/abs/2602.05146", "authors": ["Wonjun Yi", "Rismaya Kumar Mishra", "Yong-Hwa Park"], "title": "Cross-talk based multi-task learning for fault classification of physically coupled machine system", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to 32th International Congress on Sound and Vibration (ICSV32)", "summary": "Machine systems inherently generate signals in which fault conditions and various physical variables are physically coupled. Although many existing fault classification studies rely solely on direct fault labels, the aforementioned signals naturally embed additional information shaped by other physically coupled information. Herein, we leverage this coupling through a multi-task learning (MTL) framework that jointly learns fault conditions and the related physical variables. Among MTL architectures, crosstalk structures have distinct advantages because they allow for controlled information exchange between tasks through the cross-talk layer while preventing negative transfer, in contrast to shared trunk architectures that often mix incompatible features. We build on our previously introduced residual neural dimension reductor model, and extend its application to two benchmarks where physical coupling is prominent. The first benchmark is a drone fault dataset, in which machine type and maneuvering direction significantly alter the frequency components of measured signals even under the same nominal condition. By learning fault classification together with these physical attributes, the cross-talk architecture can better classify faults. The second benchmark dataset is the motor compound fault dataset. In this system, each fault component, inner race fault, outer race fault, misalignment, and unbalance is coupled to the other. For motor compound fault, we also test classification performance when we use single-channel data or multi-channel data as input to the classifier. Across both benchmarks, our residual neural dimension reductor, consistently outperformed single-task models, multi-class models that merge all label combinations, and shared trunk multi-task models.", "AI": {"tldr": "This paper introduces a new multi-task learning framework with crosstalk architecture to enhance fault classification by also leveraging physically coupled information in signals.", "motivation": "Existing fault classification methods overlook valuable information embedded in signals due to their physical coupling with other variables. This paper addresses the potential of utilizing this additional embedded information for improving fault classification.", "method": "A multi-task learning (MTL) framework is proposed using a crosstalk architecture that allows controlled information exchange between tasks while avoiding negative transfer. The model is tested on benchmarks such as drone fault datasets and motor compound fault datasets.", "result": "The proposed framework, residual neural dimension reductor with crosstalk architecture, consistently outperformed single-task models, multi-class models, and shared trunk MTL models across drone and motor fault benchmarks.", "conclusion": "Jointly learning fault conditions and their related physical variables via crosstalk MTL architecture improves fault classification's accuracy by efficiently utilizing physically coupled information."}}
{"id": "2602.06019", "pdf": "https://arxiv.org/pdf/2602.06019", "abs": "https://arxiv.org/abs/2602.06019", "authors": ["John Kirchenbauer", "Abhimanyu Hans", "Brian Bartoldson", "Micah Goldblum", "Ashwinee Panda", "Tom Goldstein"], "title": "Multi-Token Prediction via Self-Distillation", "categories": ["cs.CL", "cs.LG"], "comment": "8 pages and 5 figures in the main body", "summary": "Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\\times$ faster on average at $<5\\%$ drop in accuracy relative to single token decoding performance.", "AI": {"tldr": "The paper proposes an efficient method for transforming a pretrained language model into a faster multi-token prediction model using online distillation, with minimal implementation changes and limited accuracy loss.", "motivation": "To address the inefficiency of existing language model inference acceleration techniques, which require auxiliary models and complex pipelines.", "method": "The authors use an online distillation objective to convert a pretrained single-token prediction language model into a multi-token prediction model without adding auxiliary systems.", "result": "The method improves decoding speed by over 3x on GSM8K with less than 5% decrease in accuracy compared to single-token decoding.", "conclusion": "This approach provides a simpler and faster inference process, making language models more efficient without significant trade-offs in accuracy."}}
{"id": "2602.05551", "pdf": "https://arxiv.org/pdf/2602.05551", "abs": "https://arxiv.org/abs/2602.05551", "authors": ["Yue Ma", "Zhikai Wang", "Tianhao Ren", "Mingzhe Zheng", "Hongyu Liu", "Jiayi Guo", "Mark Fong", "Yuxuan Xue", "Zixiang Zhao", "Konrad Schindler", "Qifeng Chen", "Linfeng Zhang"], "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer", "categories": ["cs.CV"], "comment": "Accepted by ICLR2026, Project page: fastvmt.gitHub.io, Code: https://github.com/mayuelala/FastVMT", "summary": "Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos.", "AI": {"tldr": "The paper introduces FastVMT, a video motion transfer approach that speeds up synthesis by addressing inefficiencies in the Diffusion Transformer architecture.", "motivation": "To improve the performance and efficiency of video motion transfer by addressing computational redundancies in current methods.", "method": "FastVMT identifies motion redundancy and gradient redundancy in video synthesis. It addresses motion redundancy by masking attention layers to focus on local neighborhoods and gradient redundancy by reusing gradients from prior diffusion steps, optimizing computation.", "result": "FastVMT achieves a 3.43x speedup compared to previous methods, while maintaining visual fidelity and temporal consistency in generated videos.", "conclusion": "By removing structural inefficiencies in Diffusion Transformer architectures, FastVMT significantly enhances runtime efficiency for video motion transfer without quality loss."}}
{"id": "2602.05805", "pdf": "https://arxiv.org/pdf/2602.05805", "abs": "https://arxiv.org/abs/2602.05805", "authors": ["Kang Chen", "Zhuoka Feng", "Sihan Zhao", "Kai Xiong", "Junjie Nian", "Yaoning Wang", "Changyi Xiao", "Yixin Cao"], "title": "NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking", "categories": ["cs.AI"], "comment": "21 pages, 9 figures, 5 tables", "summary": "Large language models increasingly spend inference compute sampling multiple chain-of-thought traces or searching over merged checkpoints. This shifts the bottleneck from generation to selection, often without supervision on the target distribution. We show entropy-based exploration proxies follow an inverted-U with accuracy, suggesting extra exploration can become redundant and induce overthinking. We propose NEX, a white-box label-free unsupervised scoring framework that views reasoning as alternating E-phase (exploration) and X-phase (exploitation). NEX detects E-phase as spikes in newly activated MLP neurons per token from sparse activation caches, then uses a sticky two-state HMM to infer E-X phases and credits E-introduced neurons by whether they are reused in the following X span. These signals yield interpretable neuron weights and a single Good-Mass Fraction score to rank candidate responses and merged variants without task answers. Across reasoning benchmarks and Qwen3 merge families, NEX computed on a small unlabeled activation set predicts downstream accuracy and identifies better variants; we further validate the E-X signal with human annotations and provide causal evidence via \"Effective-vs-Redundant\" neuron transfer.", "AI": {"tldr": "This paper presents NEX, an unsupervised scoring framework for selecting effective reasoning from large language models (LLMs) using neuron activation signals.", "motivation": "Large language models increasingly encounter bottlenecks in selecting optimal responses or merged checkpoints during inference, as excessive exploration can lead to redundancy and 'overthinking.'", "method": "The proposed NEX framework identifies exploration (E-phase) and exploitation (X-phase) through neuron activation patterns, using sparse activation caches and a Hidden Markov Model (HMM) to rank reasoning outputs. It assesses effectiveness by whether neurons activated during exploration are reused in exploitation spans.", "result": "NEX effectively predicts downstream accuracy and ranks candidate responses in unlabeled activation setups across reasoning benchmarks. It identifies better merged variants and gains validation through human annotations and causal evidence from neuron transfer experiments.", "conclusion": "NEX provides an interpretable, label-free scoring mechanism for optimizing the reasoning process in LLMs, improving selection without requiring task answers."}}
{"id": "2602.05148", "pdf": "https://arxiv.org/pdf/2602.05148", "abs": "https://arxiv.org/abs/2602.05148", "authors": ["Songtao Wei", "Yi Li", "Bohan Zhang", "Zhichun Guo", "Ying Huang", "Yuede Ji", "Miao Yin", "Guanpeng Li", "Bingzhe Li"], "title": "CoSA: Compressed Sensing-Based Adaptation of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a practical paradigm for adapting large language models (LLMs) without updating all parameters. Most existing approaches, such as LoRA and PiSSA, rely on low-rank decompositions of weight updates. However, the low-rank assumption may restrict expressivity, particularly in task-specific adaptation scenarios where singular values are distributed relatively uniformly. To address this limitation, we propose CoSA (Compressed Sensing-Based Adaptation), a new PEFT method extended from compressed sensing theory. Instead of constraining weight updates to a low-rank subspace, CoSA expresses them through fixed random projection matrices and a compact learnable core. We provide a formal theoretical analysis of CoSA as a synthesis process, proving that weight updates can be compactly encoded into a low-dimensional space and mapped back through random projections. Extensive experimental results show that CoSA provides a principled perspective for efficient and expressive multi-scale model adaptation. Specifically, we evaluate CoSA on 10 diverse tasks, including natural language understanding and generation, employing 5 models of different scales from RoBERTa, Llama, and Qwen families. Across these settings, CoSA consistently matches or outperforms state-of-the-art PEFT methods.", "AI": {"tldr": "The paper introduces CoSA, a PEFT method based on compressed sensing theory, aiming to address the limitations of low-rank methods for LLM adaptation.", "motivation": "Existing PEFT methods assume low-rank decompositions for weight updates, which restrict expressivity in task-specific adaptations where singular values are distributed evenly.", "method": "CoSA employs fixed random projection matrices and a compact learnable core instead of low-rank constraints, based on compressed sensing theory.", "result": "CoSA demonstrates effective and expressive model adaptation, consistently matching or outperforming existing state-of-the-art PEFT methods in experiments across 10 diverse tasks and 5 model families.", "conclusion": "CoSA provides a new, theoretically-principled approach to efficient and flexible model adaptation, enhancing performance in diverse tasks without the limitations of low-rank assumptions."}}
{"id": "2602.06025", "pdf": "https://arxiv.org/pdf/2602.06025", "abs": "https://arxiv.org/abs/2602.06025", "authors": ["Haozhen Zhang", "Haodong Yue", "Tao Feng", "Quanyu Long", "Jianzhu Bao", "Bowen Jin", "Weizhi Zhang", "Xiao Li", "Jiaxuan You", "Chengwei Qin", "Wenya Wang"], "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/ViktorAxelsen/BudgetMem", "summary": "Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \\textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \\textsc{Low}/\\textsc{Mid}/\\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.", "AI": {"tldr": "BudgetMem is a runtime agent memory framework providing explicit control over performance-cost trade-offs and implementing budget tiering strategies.", "motivation": "Optimize memory usage in LLMs while ensuring efficient query-aware processing and control over trade-offs.", "method": "Introduced BudgetMem framework with modular memory processing in three budget tiers (Low/Mid/High) and a neural policy for routing.", "result": "BudgetMem surpasses baselines in performance (high-budget) and delivers better accuracy-cost optimization in tighter budgets.", "conclusion": "BudgetMem provides effective balance between performance and cost, clarifying optimal strategies for different memory-related trade-offs."}}
{"id": "2602.05811", "pdf": "https://arxiv.org/pdf/2602.05811", "abs": "https://arxiv.org/abs/2602.05811", "authors": ["Zhaorui Jiang", "Yingfang Yuan", "Lei Hu", "Wei Pang"], "title": "STProtein: predicting spatial protein expression from multi-omics data", "categories": ["cs.AI"], "comment": "STProtein: predicting spatial protein expression from multi-omics data is accepted SPARTA_AAAI2026 Oral GitHub: https://github.com/zhaorui-bi/STProtein", "summary": "The integration of spatial multi-omics data from single tissues is crucial for advancing biological research. However, a significant data imbalance impedes progress: while spatial transcriptomics data is relatively abundant, spatial proteomics data remains scarce due to technical limitations and high costs. To overcome this challenge we propose STProtein, a novel framework leveraging graph neural networks with multi-task learning strategy. STProtein is designed to accurately predict unknown spatial protein expression using more accessible spatial multi-omics data, such as spatial transcriptomics. We believe that STProtein can effectively addresses the scarcity of spatial proteomics, accelerating the integration of spatial multi-omics and potentially catalyzing transformative breakthroughs in life sciences. This tool enables scientists to accelerate discovery by identifying complex and previously hidden spatial patterns of proteins within tissues, uncovering novel relationships between different marker genes, and exploring the biological \"Dark Matter\".", "AI": {"tldr": "The paper introduces STProtein, a framework using graph neural networks to predict spatial protein expression from spatial transcriptomics data.", "motivation": "The scarcity of spatial proteomics data compared to spatial transcriptomics hinders biological research advancements. This disparity is primarily due to technical limitations and cost barriers.", "method": "STProtein utilizes graph neural networks in combination with a multi-task learning strategy to predict spatial protein expression using available spatial transcriptomics data.", "result": "STProtein successfully addresses the shortage of spatial proteomics data, enabling accurate predictions and facilitating deeper investigation into hidden spatial protein patterns and relationships.", "conclusion": "This approach accelerates the integration of spatial multi-omics data, potentially leading to breakthroughs in life sciences by uncovering novel biological relationships and patterns."}}
{"id": "2602.05164", "pdf": "https://arxiv.org/pdf/2602.05164", "abs": "https://arxiv.org/abs/2602.05164", "authors": ["Shoaib Ahmed Siddiqui", "Eleni Triantafillou", "David Krueger", "Adrian Weller"], "title": "Position: Capability Control Should be a Separate Goal From Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models are trained on broad data distributions, yielding generalist capabilities that enable many downstream applications but also expand the space of potential misuse and failures. This position paper argues that capability control -- imposing restrictions on permissible model behavior -- should be treated as a distinct goal from alignment. While alignment is often context and preference-driven, capability control aims to impose hard operational limits on permissible behaviors, including under adversarial elicitation. We organize capability control mechanisms across the model lifecycle into three layers: (i) data-based control of the training distribution, (ii) learning-based control via weight- or representation-level interventions, and (iii) system-based control via post-deployment guardrails over inputs, outputs, and actions. Because each layer has characteristic failure modes when used in isolation, we advocate for a defense-in-depth approach that composes complementary controls across the full stack. We further outline key open challenges in achieving such control, including the dual-use nature of knowledge and compositional generalization.", "AI": {"tldr": "This paper proposes that capability control for foundation models should be distinguished from alignment and implemented through a defense-in-depth strategy comprising data-, learning-, and system-based mechanisms.", "motivation": "To address the risks of misuse and failures in foundation models by introducing strict operational controls over their permissible behaviors, distinct from preference-based alignment.", "method": "The approach organizes control mechanisms into three layers across the model lifecycle: (i) data-based control during training, (ii) weight- or representation-based learning controls, and (iii) system-level post-deployment safeguards.", "result": "The paper identifies characteristic failure modes associated with each layer in isolation and suggests a comprehensive defense-in-depth strategy integrating these layers.", "conclusion": "A defense-in-depth strategy combining complementary controls is vital for securing foundation models and addressing challenges like dual-use knowledge and compositional generalization."}}
{"id": "2602.06036", "pdf": "https://arxiv.org/pdf/2602.06036", "abs": "https://arxiv.org/abs/2602.06036", "authors": ["Jian Chen", "Yesheng Liang", "Zhijian Liu"], "title": "DFlash: Block Diffusion for Flash Speculative Decoding", "categories": ["cs.CL"], "comment": null, "summary": "Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.", "AI": {"tldr": "This paper introduces DFlash, a new speculative decoding framework for large language models (LLMs) that uses a parallelized block diffusion model to reduce inference latency and increase efficiency.", "motivation": "The motivation is to address the inefficiencies of high inference latency and poor GPU utilization in autoregressive LLMs, as well as the limitations of sequential drafting in existing speculative decoding methods.", "method": "DFlash employs a lightweight block diffusion model for parallel token generation in a single forward pass. It also conditions the draft model on context features extracted from the target LLM to ensure high-quality drafting outputs.", "result": "DFlash achieves more than 6x lossless acceleration across various models and tasks and delivers up to 2.5x higher speedup compared to the state-of-the-art speculative decoding method EAGLE-3.", "conclusion": "DFlash effectively reduces latency and improves efficiency in LLM decoding, surpassing both autoregressive models and existing speculative decoding methods in performance."}}
{"id": "2602.05818", "pdf": "https://arxiv.org/pdf/2602.05818", "abs": "https://arxiv.org/abs/2602.05818", "authors": ["Zihao Jiang", "Miao Peng", "Zhenyan Shan", "Wenjie Xu", "Ben Liu", "Gong Chen", "Ziqi Gao", "Min Peng"], "title": "TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning", "categories": ["cs.AI", "cs.DB"], "comment": null, "summary": "Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \\textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.", "AI": {"tldr": "Proposes 'TKG-Thinker', an innovative agent for temporal knowledge graph question answering using supervised fine-tuning and reinforcement learning strategies to achieve superior performance.", "motivation": "Address inherent reasoning and prompting limitations of LLMs in TKGQA, including hallucinations and static prompting constraints.", "method": "Introduces TKG-Thinker agent with autonomous planning and dynamic multi-turn interaction with TKGs, implemented through dual training: supervised fine-tuning and reinforcement learning.", "result": "Experimental evaluation using benchmark datasets indicates that TKG-Thinker outperforms existing methods and maintains generalization across complex TKGQA tasks.", "conclusion": "TKG-Thinker enhances temporal reasoning and knowledge graph interactions, addressing limitations in current LLM strategies and pushing performance boundaries."}}
{"id": "2602.05165", "pdf": "https://arxiv.org/pdf/2602.05165", "abs": "https://arxiv.org/abs/2602.05165", "authors": ["Kevin Han", "Yuhang Zhou", "Mingze Gao", "Gedi Zhou", "Serena Li", "Abhishek Kumar", "Xiangjun Fan", "Weiwei Li", "Lizhu Zhang"], "title": "EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for enhancing the reasoning capabilities of Large Language Models (LLMs). However, dominant approaches like Group Relative Policy Optimization (GRPO) face critical stability challenges: they suffer from high estimator variance under computational constraints (small group sizes) and vanishing gradient signals in saturated failure regimes where all responses yield identical zero rewards. To address this, we propose Empirical Bayes Policy Optimization (EBPO), a novel framework that regularizes local group-based baselines by borrowing strength from the policy's accumulated global statistics. Instead of estimating baselines in isolation, EBPO employs a shrinkage estimator that dynamically balances local group statistics with a global prior updated via Welford's online algorithm. Theoretically, we demonstrate that EBPO guarantees strictly lower Mean Squared Error (MSE), bounded entropy decay, and non-vanishing penalty signals in failure scenarios compared to GRPO. Empirically, EBPO consistently outperforms GRPO and other established baselines across diverse benchmarks, including AIME and OlympiadBench. Notably, EBPO exhibits superior training stability, achieving high-performance gains even with small group sizes, and benefits significantly from difficulty-stratified curriculum learning.", "AI": {"tldr": "EBPO improves training stability and accuracy in RLVR for LLMs using global statistics for regularized baselines, outperforming GRPO.", "motivation": "The paper aims to address stability challenges in RLVR, particularly estimator variance and gradient signal issues in GRPO models when used under computational constraints or in failure regimes.", "method": "EBPO introduces a novel regularization approach combining local group statistics with global policy data using shrinkage estimators and Welford's algorithm.", "result": "The proposed EBPO method demonstrates reduced MSE, better entropy management, stable training behavior, and improved performance on benchmarks like AIME and OlympiadBench.", "conclusion": "Empirical Bayes Policy Optimization provides significant advantages in stability and performance, ensuring reliable training outcomes even in constrained scenarios."}}
{"id": "2602.04912", "pdf": "https://arxiv.org/pdf/2602.04912", "abs": "https://arxiv.org/abs/2602.04912", "authors": ["James Gao", "Josh Zhou", "Qi Sun", "Ryan Huang", "Steven Yoo"], "title": "Atomic Information Flow: A Network Flow Model for Tool Attributions in RAG Systems", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": null, "summary": "Many tool-based Retrieval Augmented Generation (RAG) systems lack precise mechanisms for tracing final responses back to specific tool components -- a critical gap as systems scale to complex multi-agent architectures. We present \\textbf{Atomic Information Flow (AIF)}, a graph-based network flow model that decomposes tool outputs and LLM calls into atoms: indivisible, self-contained units of information. By modeling LLM orchestration as a directed flow of atoms from tool and LLM nodes to a response super-sink, AIF enables granular attribution metrics for AI explainability.\n  Motivated by the max-flow min-cut theorem in network flow theory, we train a lightweight Gemma3 (4B parameter) language model as a context compressor to approximate the minimum cut of tool atoms using flow signals computed offline by AIF. We note that the base Gemma3-4B model struggles to identify critical information with \\textbf{54.7\\%} accuracy on HotpotQA, barely outperforming lexical baselines (BM25). However, post-training on AIF signals boosts accuracy to \\textbf{82.71\\%} (+28.01 points) while achieving \\textbf{87.52\\%} (+1.85\\%) context token compression -- bridging the gap with the Gemma3-27B variant, a model nearly $7\\times$ larger.", "AI": {"tldr": "The paper introduces Atomic Information Flow (AIF), a graph-based model to enhance explainability and attribution in Retrieval Augmented Generation (RAG) systems.", "motivation": "The work addresses the lack of precise mechanisms to trace responses back to specific tool components in complex RAG systems, crucial for AI explainability.", "method": "The authors develop Atomic Information Flow (AIF), which models LLM orchestration using network flow that decomposes tool outputs and LLM calls into atomic units of information. They train a smaller Gemma3 model using flow signals to improve results.", "result": "The base Gemma3-4B achieved only 54.7% accuracy in identifying critical information, but training with AIF signals raised this to 82.71%, while compressing context tokens by 87.52%. This approaches the performance of a significantly larger model.", "conclusion": "AIF and the use of flow signals can dramatically improve explainability and efficiency in RAG systems, closing performance gaps with larger, more resource-intensive alternatives."}}
{"id": "2602.05572", "pdf": "https://arxiv.org/pdf/2602.05572", "abs": "https://arxiv.org/abs/2602.05572", "authors": ["Zhenxiao Liang", "Ning Zhang", "Youbao Tang", "Ruei-Sung Lin", "Qixing Huang", "Peng Chang", "Jing Xiao"], "title": "ShapeGaussian: High-Fidelity 4D Human Reconstruction in Monocular Videos via Vision Priors", "categories": ["cs.CV"], "comment": null, "summary": "We introduce ShapeGaussian, a high-fidelity, template-free method for 4D human reconstruction from casual monocular videos. Generic reconstruction methods lacking robust vision priors, such as 4DGS, struggle to capture high-deformation human motion without multi-view cues. While template-based approaches, primarily relying on SMPL, such as HUGS, can produce photorealistic results, they are highly susceptible to errors in human pose estimation, often leading to unrealistic artifacts. In contrast, ShapeGaussian effectively integrates template-free vision priors to achieve both high-fidelity and robust scene reconstructions. Our method follows a two-step pipeline: first, we learn a coarse, deformable geometry using pretrained models that estimate data-driven priors, providing a foundation for reconstruction. Then, we refine this geometry using a neural deformation model to capture fine-grained dynamic details. By leveraging 2D vision priors, we mitigate artifacts from erroneous pose estimation in template-based methods and employ multiple reference frames to resolve the invisibility issue of 2D keypoints in a template-free manner. Extensive experiments demonstrate that ShapeGaussian surpasses template-based methods in reconstruction accuracy, achieving superior visual quality and robustness across diverse human motions in casual monocular videos.", "AI": {"tldr": "ShapeGaussian is a method for high-fidelity 4D human reconstruction from monocular videos, addressing limitations in template-based and generic methods.", "motivation": "To overcome inaccuracies caused by pose estimation errors in template-based reconstruction and to enhance human motion capture without requiring multi-view cues.", "method": "ShapeGaussian uses a pipeline with a coarse geometry learning stage followed by refinement using a neural deformation model. It relies on 2D vision priors and multiple reference frames to mitigate artifacts and invisibility issues.", "result": "ShapeGaussian demonstrates superior reconstruction accuracy and visual quality, outperforming existing methods in capturing diverse human motion from casual videos.", "conclusion": "ShapeGaussian successfully integrates template-free vision priors for robust and high-quality human reconstruction, providing a notable improvement over prior approaches."}}
{"id": "2602.05830", "pdf": "https://arxiv.org/pdf/2602.05830", "abs": "https://arxiv.org/abs/2602.05830", "authors": ["Shengpu Wang", "Yuhao Mao", "Yani Zhang", "Martin Vechev"], "title": "Learning Compact Boolean Networks", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Floating-point neural networks dominate modern machine learning but incur substantial inference cost, motivating interest in Boolean networks for resource-constrained settings. However, learning compact and accurate Boolean networks is challenging due to their combinatorial nature. In this work, we address this challenge from three different angles: learned connections, compact convolutions and adaptive discretization. First, we propose a novel strategy to learn efficient connections with no additional parameters and negligible computational overhead. Second, we introduce a novel convolutional Boolean architecture that exploits the locality with reduced number of Boolean operations than existing methods. Third, we propose an adaptive discretization strategy to reduce the accuracy drop when converting a continuous-valued network into a Boolean one. Extensive results on standard vision benchmarks demonstrate that the Pareto front of accuracy vs. computation of our method significantly outperforms prior state-of-the-art, achieving better accuracy with up to 37x fewer Boolean operations.", "AI": {"tldr": "The paper focuses on improving Boolean neural networks for resource-constrained settings by proposing better algorithms and architectures with reduced computational overhead and high accuracy.", "motivation": "The paper seeks to reduce the inference costs of floating-point neural networks while maintaining accuracy, specifically benefiting resource-constrained systems.", "method": "The research introduces three main solutions: efficient connection learning with negligible additional cost, a compact convolutional Boolean architecture, and an adaptive discretization strategy for improved accuracy during network conversion.", "result": "Experiments demonstrate superiority in accuracy-computation trade-off, achieving up to 37x fewer Boolean operations while maintaining or improving accuracy.", "conclusion": "The proposed techniques produce more efficient Boolean networks, making them viable alternatives for constrained environments with significant gains over prior state-of-the-art methods."}}
{"id": "2602.05178", "pdf": "https://arxiv.org/pdf/2602.05178", "abs": "https://arxiv.org/abs/2602.05178", "authors": ["Magesh Rajasekaran", "Md Saiful Sajol", "Chris Alvin", "Supratik Mukhopadhyay", "Yanda Ou", "Z. George Xue"], "title": "Benchmarking Artificial Intelligence Models for Daily Coastal Hypoxia Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "This is a Preprint accepted at IEEE Big Data 2025", "summary": "Coastal hypoxia, especially in the northern part of Gulf of Mexico, presents a persistent ecological and economic concern. Seasonal models offer coarse forecasts that miss the fine-scale variability needed for daily, responsive ecosystem management. We present study that compares four deep learning architectures for daily hypoxia classification: Bidirectional Long Short-Term Memory (BiLSTM), Medformer (Medical Transformer), Spatio-Temporal Transformer (ST-Transformer), and Temporal Convolutional Network (TCN). We trained our models with twelve years of daily hindcast data from 2009-2020 Our training data consists of 2009-2020 hindcast data from a coupled hydrodynamic-biogeochemical model. Similarly, we use hindcast data from 2020 through 2024 as a test data. We constructed classification models incorporating water column stratification, sediment oxygen consumption, and temperature-dependent decomposition rates. We evaluated each architectures using the same data preprocessing, input/output formulation, and validation protocols. Each model achieved high classification accuracy and strong discriminative ability with ST-Transformer achieving the highest performance across all metrics and tests periods (AUC-ROC: 0.982-0.992). We also employed McNemar's method to identify statistically significant differences in model predictions. Our contribution is a reproducible framework for operational real-time hypoxia prediction that can support broader efforts in the environmental and ocean modeling systems community and in ecosystem resilience. The source code is available https://github.com/rmagesh148/hypoxia-ai/", "AI": {"tldr": "The paper develops and compares deep learning models for daily hypoxia classification using Gulf of Mexico data, with the Spatio-Temporal Transformer achieving the best performance.", "motivation": "The paper addresses the need for fine-scale, daily forecasts of coastal hypoxia in the Gulf of Mexico, an area facing persistent ecological and economic challenges, for better ecosystem management.", "method": "The study compares four deep learning architectures (BiLSTM, Medformer, ST-Transformer, TCN) using 12 years of daily hindcast data and evaluates their performance for hypoxia classification.", "result": "All models performed well, but the Spatio-Temporal Transformer (ST-Transformer) showed the highest accuracy and discriminative ability, achieving an AUC-ROC between 0.982-0.992.", "conclusion": "A reproducible framework for real-time hypoxia prediction is presented, with publicly available code, providing significant value to environmental and ocean modeling systems."}}
{"id": "2602.04916", "pdf": "https://arxiv.org/pdf/2602.04916", "abs": "https://arxiv.org/abs/2602.04916", "authors": ["Ling Luo", "Wenbin Jiang", "Xushi Zhang", "Hongyuan Chang", "Xinkang Wang", "Yueting Xiong", "Mengsha Tong", "Rongshan Yu"], "title": "AFD-INSTRUCTION: A Comprehensive Antibody Instruction Dataset with Functional Annotations for LLM-Based Understanding and Design", "categories": ["q-bio.QM", "cs.CL"], "comment": "Accepted by ICLR 2026", "summary": "Large language models (LLMs) have significantly advanced protein representation learning. However, their capacity to interpret and design antibodies through natural language remains limited. To address this challenge, we present AFD-Instruction, the first large-scale instruction dataset with functional annotations tailored to antibodies. This dataset encompasses two key components: antibody understanding, which infers functional attributes directly from sequences, and antibody design, which enables de novo sequence generation under functional constraints. These components provide explicit sequence-function alignment and support antibody design guided by natural language instructions. Extensive instruction-tuning experiments on general-purpose LLMs demonstrate that AFD-Instruction consistently improves performance across diverse antibody-related tasks. By linking antibody sequences with textual descriptions of function, AFD-Instruction establishes a new foundation for advancing antibody modeling and accelerating therapeutic discovery.", "AI": {"tldr": "AFD-Instruction introduces the first large-scale instruction dataset tailored to antibodies, improving their understanding, design, and therapeutic discovery.", "motivation": "The paper aims to improve the interpretation and design of antibodies through large language models (LLMs), addressing limitations in using natural language for this purpose.", "method": "The authors present AFD-Instruction, a dataset with functional annotations for antibodies, enabling both understanding (inferring functions from sequences) and design (generating novel sequences under functional constraints).", "result": "Instruction-tuning experiments on general-purpose LLMs showed that AFD-Instruction consistently enhances performance across various antibody tasks.", "conclusion": "AFD-Instruction facilitates bridging antibody sequences with functional descriptions, laying a foundation for better antibody modeling and therapeutic advancements."}}
{"id": "2602.05573", "pdf": "https://arxiv.org/pdf/2602.05573", "abs": "https://arxiv.org/abs/2602.05573", "authors": ["Arsenii Shirokov", "Mikhail Kuznetsov", "Danila Stepochkin", "Egor Evdokimov", "Daniil Glazkov", "Nikolay Patakin", "Anton Konushin", "Dmitry Senushkin"], "title": "Visual Implicit Geometry Transformer for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "We introduce the Visual Implicit Geometry Transformer (ViGT), an autonomous driving geometric model that estimates continuous 3D occupancy fields from surround-view camera rigs. ViGT represents a step towards foundational geometric models for autonomous driving, prioritizing scalability, architectural simplicity, and generalization across diverse sensor configurations. Our approach achieves this through a calibration-free architecture, enabling a single model to adapt to different sensor setups. Unlike general-purpose geometric foundational models that focus on pixel-aligned predictions, ViGT estimates a continuous 3D occupancy field in a birds-eye-view (BEV) addressing domain-specific requirements. ViGT naturally infers geometry from multiple camera views into a single metric coordinate frame, providing a common representation for multiple geometric tasks. Unlike most existing occupancy models, we adopt a self-supervised training procedure that leverages synchronized image-LiDAR pairs, eliminating the need for costly manual annotations. We validate the scalability and generalizability of our approach by training our model on a mixture of five large-scale autonomous driving datasets (NuScenes, Waymo, NuPlan, ONCE, and Argoverse) and achieving state-of-the-art performance on the pointmap estimation task, with the best average rank across all evaluated baselines. We further evaluate ViGT on the Occ3D-nuScenes benchmark, where ViGT achieves comparable performance with supervised methods. The source code is publicly available at \\href{https://github.com/whesense/ViGT}{https://github.com/whesense/ViGT}.", "AI": {"tldr": "The Visual Implicit Geometry Transformer (ViGT) is a scalable, self-supervised model for estimating 3D occupancy fields from camera rigs, specifically designed for autonomous driving applications.", "motivation": "To develop a scalable and generalized autonomous driving geometric model that simplifies adaptation across different sensor configurations without requiring manual calibration or annotations.", "method": "ViGT uses a calibration-free architecture to infer continuous 3D occupancy fields from surround-view cameras. It is trained using a self-supervised learning approach with synchronized image-LiDAR pairs, bypassing the need for manual annotations.", "result": "ViGT sets a new state-of-the-art performance in pointmap estimation across five autonomous driving datasets and achieves competitive results on the Occ3D-nuScenes benchmark compared to supervised methods.", "conclusion": "ViGT demonstrates successful scalability, generalizability, and practical utility, making it an effective foundational geometric model for autonomous driving tasks. Its source code is publicly available for further research and exploration."}}
{"id": "2602.05847", "pdf": "https://arxiv.org/pdf/2602.05847", "abs": "https://arxiv.org/abs/2602.05847", "authors": ["Zhangquan Chen", "Jiale Tao", "Ruihuang Li", "Yihao Hu", "Ruitao Chen", "Zhantao Yang", "Xinlei Yu", "Haodong Jing", "Manyuan Zhang", "Shuai Shao", "Biao Wang", "Qinglin Lu", "Ruqi Huang"], "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention", "categories": ["cs.AI"], "comment": "19 pages, 12 figures", "summary": "While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to \"think with omnimodal cues\" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.", "AI": {"tldr": "The paper introduces OmniVideo-R1, a framework enhancing audio-visual understanding through query-intensive grounding and modality-attentive fusion, achieving superior results over baselines.", "motivation": "Human perception synergizes diverse modalities for understanding surroundings, but current omnivideo models lack robust audio-visual reasoning abilities.", "method": "OmniVideo-R1 adopts reinforced methods using self-supervised query-intensive grounding and modality-attentive fusion with contrastive learning.", "result": "Experiments on various benchmarks show OmniVideo-R1 consistently surpasses strong baseline models in mixed-modality reasoning tasks.", "conclusion": "OmniVideo-R1 offers an effective solution for audio-visual understanding, exhibiting robust performance and generalization across benchmarks."}}
{"id": "2602.05183", "pdf": "https://arxiv.org/pdf/2602.05183", "abs": "https://arxiv.org/abs/2602.05183", "authors": ["John Yan", "Michael Yu", "Yuqi Sun", "Alexander Duffy", "Tyler Marques", "Matthew Lyle Olson"], "title": "Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "authors 1, 2 and 3 contributed equally", "summary": "Large language models (LLMs) are increasingly trained in complex Reinforcement Learning, multi-agent environments, making it difficult to understand how behavior changes over training. Sparse Autoencoders (SAEs) have recently shown to be useful for data-centric interpretability. In this work, we analyze large-scale reinforcement learning training runs from the sophisticated environment of Full-Press Diplomacy by applying pretrained SAEs, alongside LLM-summarizer methods. We introduce Meta-Autointerp, a method for grouping SAE features into interpretable hypotheses about training dynamics. We discover fine-grained behaviors including role-playing patterns, degenerate outputs, language switching, alongside high-level strategic behaviors and environment-specific bugs. Through automated evaluation, we validate that 90% of discovered SAE Meta-Features are significant, and find a surprising reward hacking behavior. However, through two user studies, we find that even subjectively interesting and seemingly helpful SAE features may be worse than useless to humans, along with most LLM generated hypotheses. However, a subset of SAE-derived hypotheses are predictively useful for downstream tasks. We further provide validation by augmenting an untrained agent's system prompt, improving the score by +14.2%. Overall, we show that SAEs and LLM-summarizer provide complementary views into agent behavior, and together our framework forms a practical starting point for future data-centric interpretability work on ensuring trustworthy LLM behavior throughout training.", "AI": {"tldr": "This paper introduces Meta-Autointerp, a method combining Sparse Autoencoders (SAEs) and LLM summarization techniques to interpret training behaviors in large-scale reinforcement learning. Their findings include observable agent behaviors, reward hacking, and a practical framework for improving interpretability.", "motivation": "As the complexity of Reinforcement Learning and multi-agent environments grows, it becomes more challenging to interpret and ensure trustworthy behavior of large language models (LLMs) during training.", "method": "The authors use pretrained Sparse Autoencoders (SAEs) and LLM summarization techniques to analyze training dynamics in the Full-Press Diplomacy environment. Their method, Meta-Autointerp, groups SAE features into hypotheses on behaviors and dynamics.", "result": "They identify specific agent behaviors such as role-playing, language switching, reward hacking, and environment-critical bugs. Automated evaluations validate the significance of many SAE-derived features, alongside observing a predictive utility for downstream tasks.", "conclusion": "While many SAE and LLM-summarized features proved ineffective for human interpretability, a subset of SAE-derived hypotheses showed predictive utility and were validated by improving an agent\u2019s performance. This framework serves as a foundation for future trustworthiness and interpretability in LLM training research."}}
{"id": "2602.05574", "pdf": "https://arxiv.org/pdf/2602.05574", "abs": "https://arxiv.org/abs/2602.05574", "authors": ["Mengyu Li", "Ingibj\u00f6rg Kristj\u00e1nsd\u00f3ttir", "Thilo van Eimeren", "Kathrin Giehl", "Lotta M. Ellingsen", "the ASAP Neuroimaging Initiative"], "title": "A Hybrid CNN and ML Framework for Multi-modal Classification of Movement Disorders Using MRI and Brain Structural Features", "categories": ["cs.CV"], "comment": "To be published in Proceedings of SPIE Medical Imaging 2026", "summary": "Atypical Parkinsonian Disorders (APD), also known as Parkinson-plus syndrome, are a group of neurodegenerative diseases that include progressive supranuclear palsy (PSP) and multiple system atrophy (MSA). In the early stages, overlapping clinical features often lead to misdiagnosis as Parkinson's disease (PD). Identifying reliable imaging biomarkers for early differential diagnosis remains a critical challenge. In this study, we propose a hybrid framework combining convolutional neural networks (CNNs) with machine learning (ML) techniques to classify APD subtypes versus PD and distinguish between the subtypes themselves: PSP vs. PD, MSA vs. PD, and PSP vs. MSA. The model leverages multi-modal input data, including T1-weighted magnetic resonance imaging (MRI), segmentation masks of 12 deep brain structures associated with APD, and their corresponding volumetric measurements. By integrating these complementary modalities, including image data, structural segmentation masks, and quantitative volume features, the hybrid approach achieved promising classification performance with area under the curve (AUC) scores of 0.95 for PSP vs. PD, 0.86 for MSA vs. PD, and 0.92 for PSP vs. MSA. These results highlight the potential of combining spatial and structural information for robust subtype differentiation. In conclusion, this study demonstrates that fusing CNN-based image features with volume-based ML inputs improves classification accuracy for APD subtypes. The proposed approach may contribute to more reliable early-stage diagnosis, facilitating timely and targeted interventions in clinical practice.", "AI": {"tldr": "This study developed a hybrid framework using CNNs and ML techniques to differentiate between Parkinsonian disorders and subtypes (PSP, MSA, and PD) using MRI data, achieving high classification accuracy.", "motivation": "The study seeks to address the challenge of early misdiagnosis of Atypical Parkinsonian Disorders (APD) as Parkinson's disease (PD) by identifying reliable imaging biomarkers for differential diagnosis.", "method": "The researchers developed a hybrid model that combines convolutional neural networks (CNNs) and machine learning (ML) techniques. They used multimodal data including T1-weighted MRI images, segmentation masks of 12 deep brain structures, and volumetric measurements.", "result": "The approach achieved high classification performance with AUC scores of 0.95 for PSP vs. PD, 0.86 for MSA vs. PD, and 0.92 for PSP vs. MSA, demonstrating the potential for robust subtype differentiation.", "conclusion": "The hybrid method using CNNs and ML inputs enhances the accuracy of distinguishing subtypes of APD, supporting early diagnosis and better clinical management."}}
{"id": "2602.05857", "pdf": "https://arxiv.org/pdf/2602.05857", "abs": "https://arxiv.org/abs/2602.05857", "authors": ["Junting Zhou", "Jin Chen", "Linfeng Hao", "Denghui Cao", "Zheyu Wang", "Qiguang Chen", "Chaoyou Fu", "Jiaze Chen", "Yuchen Wu", "Ge Zhang", "Mingxuan Wang", "Wenhao Huang", "Tong Yang"], "title": "BABE: Biology Arena BEnchmark", "categories": ["cs.AI"], "comment": null, "summary": "The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.", "AI": {"tldr": "The paper introduces a new benchmark, BABE, to assess large language models' experimental reasoning abilities in biology using peer-reviewed and real-world studies.", "motivation": "Existing biology benchmarks for AI often overlook the integration of experimental results with contextual knowledge, which is critical for meaningful scientific reasoning.", "method": "BABE is constructed using peer-reviewed papers and real-world studies to evaluate causal reasoning and cross-scale inference of biological AI systems.", "result": "The benchmark offers a way to measure how well AI systems can perform reasoning similar to scientists in realistic biological contexts.", "conclusion": "BABE addresses a key gap in evaluating AI's research capabilities in biology, offering a more genuine assessment of their scientific reasoning potential."}}
{"id": "2602.05187", "pdf": "https://arxiv.org/pdf/2602.05187", "abs": "https://arxiv.org/abs/2602.05187", "authors": ["Chun-Wun Cheng", "Carola-Bibiane Sch\u00f6nlieb", "Angelica I. Aviles-Rivero"], "title": "SpectraKAN: Conditioning Spectral Operators", "categories": ["cs.LG", "math.NA"], "comment": null, "summary": "Spectral neural operators, particularly Fourier Neural Operators (FNO), are a powerful framework for learning solution operators of partial differential equations (PDEs) due to their efficient global mixing in the frequency domain. However, existing spectral operators rely on static Fourier kernels applied uniformly across inputs, limiting their ability to capture multi-scale, regime-dependent, and anisotropic dynamics governed by the global state of the system. We introduce SpectraKAN, a neural operator that conditions the spectral operator on the input itself, turning static spectral convolution into an input-conditioned integral operator. This is achieved by extracting a compact global representation from spatio-temporal history and using it to modulate a multi-scale Fourier trunk via single-query cross-attention, enabling the operator to adapt its behaviour while retaining the efficiency of spectral mixing. We provide theoretical justification showing that this modulation converges to a resolution-independent continuous operator under mesh refinement and KAN gives smooth, Lipschitz-controlled global modulation. Across diverse PDE benchmarks, SpectraKAN achieves state-of-the-art performance, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.", "AI": {"tldr": "The paper introduces SpectraKAN, a spectral neural operator that adapts to multi-scale and regime-dependent dynamics while retaining computation efficiency, achieving significant improvements on PDE benchmarks.", "motivation": "Existing spectral neural operators lack adaptability to multi-scale, regime-dependent, and anisotropic dynamics in PDEs due to their static application of Fourier kernels.", "method": "SpectraKAN employs an input-conditioned integral operator by extracting a global representation from spatio-temporal history and modulating a multi-scale Fourier trunk using cross-attention.", "result": "SpectraKAN shows state-of-the-art performance with up to a 49% reduction in RMSE over strong baselines on various PDE benchmarks.", "conclusion": "The SpectraKAN model achieves efficient and adaptive spectral mixing, providing significant accuracy improvements on spatio-temporal prediction tasks."}}
{"id": "2602.05577", "pdf": "https://arxiv.org/pdf/2602.05577", "abs": "https://arxiv.org/abs/2602.05577", "authors": ["Shiyu Wu", "Shuyan Li", "Jing Li", "Jing Liu", "Yequan Wang"], "title": "LocateEdit-Bench: A Benchmark for Instruction-Based Editing Localization", "categories": ["cs.CV"], "comment": "11 pages, 7 figures", "summary": "Recent advancements in image editing have enabled highly controllable and semantically-aware alteration of visual content, posing unprecedented challenges to manipulation localization. However, existing AI-generated forgery localization methods primarily focus on inpainting-based manipulations, making them ineffective against the latest instruction-based editing paradigms. To bridge this critical gap, we propose LocateEdit-Bench, a large-scale dataset comprising $231$K edited images, designed specifically to benchmark localization methods against instruction-driven image editing. Our dataset incorporates four cutting-edge editing models and covers three common edit types. We conduct a detailed analysis of the dataset and develop two multi-metric evaluation protocols to assess existing localization methods. Our work establishes a foundation to keep pace with the evolving landscape of image editing, thereby facilitating the development of effective methods for future forgery localization. Dataset will be open-sourced upon acceptance.", "AI": {"tldr": "The paper introduces LocateEdit-Bench, a dataset with 231K edited images to improve forgery localization in instruction-based image editing.", "motivation": "Recent advancements in instruction-based image editing challenge existing methods which primarily focus on inpainting-based manipulations.", "method": "The authors develop a large-scale benchmark dataset incorporating four modern editing models and employ multi-metric evaluation protocols for analysis.", "result": "Detailed dataset analysis and evaluation protocols show the potential for benchmarking localization methods against instruction-driven manipulations.", "conclusion": "LocateEdit-Bench offers a foundational resource to aid future research in forgery localization amid evolving image editing technologies."}}
{"id": "2602.05875", "pdf": "https://arxiv.org/pdf/2602.05875", "abs": "https://arxiv.org/abs/2602.05875", "authors": ["Anton Ipsen", "Michael Cashmore", "Kirsty Fielding", "Nicolas Marchesotti", "Parisa Zehtabi", "Daniele Magazzeni", "Manuela Veloso"], "title": "Beyond Manual Planning: Seating Allocation for Large Organizations", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure that teams with close hierarchical relationships are seated in proximity to one another, such as ensuring a research group occupies a contiguous area. Currently, this problem is managed manually leading to infrequent and suboptimal replanning efforts. To alleviate this manual process, we propose an end-to-end framework to solve the HSAP. A scalable approach to calculate the distance between any pair of seats using a probabilistic road map (PRM) and rapidly-exploring random trees (RRT) which is combined with heuristic search and dynamic programming approach to solve the HSAP using integer programming. We demonstrate our approach under different sized instances by evaluating the PRM framework and subsequent allocations both quantitatively and qualitatively.", "AI": {"tldr": "The paper addresses a seating allocation problem for hierarchically structured organizations and proposes a framework utilizing probabilistic road maps (PRM), heuristic search, and integer programming to optimize the seating process.", "motivation": "The motivation is to alleviate the manual and inefficient process of seating allocation in large organizations where hierarchical proximity of teams is important.", "method": "The authors propose a framework combining probabilistic road maps (PRM) and rapidly-exploring random trees (RRT) to calculate distances, alongside heuristic search and dynamic programming integrated into an integer programming approach for problem-solving.", "result": "The proposed method is demonstrated on different instance sizes, with its effectiveness evaluated through both quantitative and qualitative assessments.", "conclusion": "The framework successfully automates and optimizes the hierarchical seating allocation problem, showcasing scalable and efficient results for differing organizational setups."}}
{"id": "2602.05191", "pdf": "https://arxiv.org/pdf/2602.05191", "abs": "https://arxiv.org/abs/2602.05191", "authors": ["Wentao Ni", "Kangqi Zhang", "Zhongming Yu", "Oren Nelson", "Mingu Lee", "Hong Cai", "Fatih Porikli", "Jongryool Kim", "Zhijian Liu", "Jishen Zhao"], "title": "Double-P: Hierarchical Top-P Sparse Attention for Long-Context LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As long-context inference becomes central to large language models (LLMs), attention over growing key-value caches emerges as a dominant decoding bottleneck, motivating sparse attention for scalable inference. Fixed-budget top-k sparse attention cannot adapt to heterogeneous attention distributions across heads and layers, whereas top-p sparse attention directly preserves attention mass and provides stronger accuracy guarantees. Existing top-p methods, however, fail to jointly optimize top-p accuracy, selection overhead, and sparse attention cost, which limits their overall efficiency. We present Double-P, a hierarchical sparse attention framework that optimizes all three stages. Double-P first performs coarse-grained top-p estimation at the cluster level using size-weighted centroids, then adaptively refines computation through a second top-p stage that allocates token-level attention only when needed. Across long-context benchmarks, Double-P consistently achieves near-zero accuracy drop, reducing attention computation overhead by up to 1.8x and delivers up to 1.3x end-to-end decoding speedup over state-of-the-art fixed-budget sparse attention methods.", "AI": {"tldr": "The paper introduces 'Double-P', a hierarchical sparse attention framework for long-context inference in LLMs, optimizing top-p accuracy, selection overhead, and sparse attention cost, achieving improved efficiency.", "motivation": "To address the computational bottleneck in long-context inference for LLMs caused by growing key-value caches and attention calculation, and to improve upon existing fixed-budget and top-p attention methods.", "method": "The proposed Double-P method is a hierarchical sparse attention framework with two stages: first, a coarse-grained top-p estimation using size-weighted centroids at the cluster level; second, a refined token-level attention allocation only when necessary.", "result": "Double-P achieves near-zero accuracy drop, reduces attention computation overhead by up to 1.8x, and increases end-to-end decoding speed by up to 1.3x compared to state-of-the-art sparse attention methods.", "conclusion": "Double-P proves to be a more efficient sparse attention method for long-context inference, balancing accuracy and computational cost effectively, making it suitable for scalable LLM decoding tasks."}}
{"id": "2602.04926", "pdf": "https://arxiv.org/pdf/2602.04926", "abs": "https://arxiv.org/abs/2602.04926", "authors": ["Ning Wang", "Kuanyan Zhu", "Daniel Yuehwoon Yee", "Yitang Gao", "Shiying Huang", "Zirun Xu", "Sainyam Galhotra"], "title": "Pruning Minimal Reasoning Graphs for Efficient Retrieval-Augmented Generation", "categories": ["cs.DB", "cs.CL", "cs.LG"], "comment": null, "summary": "Retrieval-augmented generation (RAG) is now standard for knowledge-intensive LLM tasks, but most systems still treat every query as fresh, repeatedly re-retrieving long passages and re-reasoning from scratch, inflating tokens, latency, and cost. We present AutoPrunedRetriever, a graph-style RAG system that persists the minimal reasoning subgraph built for earlier questions and incrementally extends it for later ones. AutoPrunedRetriever stores entities and relations in a compact, ID-indexed codebook and represents questions, facts, and answers as edge sequences, enabling retrieval and prompting over symbolic structure instead of raw text. To keep the graph compact, we apply a two-layer consolidation policy (fast ANN/KNN alias detection plus selective $k$-means once a memory threshold is reached) and prune low-value structure, while prompts retain only overlap representatives and genuinely new evidence. We instantiate two front ends: AutoPrunedRetriever-REBEL, which uses REBEL as a triplet parser, and AutoPrunedRetriever-llm, which swaps in an LLM extractor. On GraphRAG-Benchmark (Medical and Novel), both variants achieve state-of-the-art complex reasoning accuracy, improving over HippoRAG2 by roughly 9--11 points, and remain competitive on contextual summarize and generation. On our harder STEM and TV benchmarks, AutoPrunedRetriever again ranks first, while using up to two orders of magnitude fewer tokens than graph-heavy baselines, making it a practical substrate for long-running sessions, evolving corpora, and multi-agent pipelines.", "AI": {"tldr": "AutoPrunedRetriever introduces a graph-based RAG system to minimize redundant reasoning and token usage for knowledge-intensive LLM tasks while achieving improved reasoning accuracy.", "motivation": "Current RAG systems for LLM tasks suffer from inefficiencies due to repeated retrieval and reasoning processes, leading to high token costs, latency, and lack of scalability.", "method": "AutoPrunedRetriever leverages a graph-based structure for incremental reasoning, stores entities and relations in a compact codebook, and applies consolidation policies (ANN/KNN alias detection + k-means pruning) to maintain efficiency.", "result": "Achieves state-of-the-art reasoning accuracy on complex benchmarks, reduces token usage by up to two orders of magnitude compared to traditional graph-heavy RAG systems.", "conclusion": "AutoPrunedRetriever is a highly efficient and accurate RAG model suitable for extended sessions, evolving content, and multiple-agent setups."}}
{"id": "2602.05578", "pdf": "https://arxiv.org/pdf/2602.05578", "abs": "https://arxiv.org/abs/2602.05578", "authors": ["Junyang Chen", "Xiangbo Lv", "Zhiqiang Kou", "Xingdong Sheng", "Ning Xu", "Yiguo Qiao"], "title": "LoGoSeg: Integrating Local and Global Features for Open-Vocabulary Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary semantic segmentation (OVSS) extends traditional closed-set segmentation by enabling pixel-wise annotation for both seen and unseen categories using arbitrary textual descriptions. While existing methods leverage vision-language models (VLMs) like CLIP, their reliance on image-level pretraining often results in imprecise spatial alignment, leading to mismatched segmentations in ambiguous or cluttered scenes. However, most existing approaches lack strong object priors and region-level constraints, which can lead to object hallucination or missed detections, further degrading performance. To address these challenges, we propose LoGoSeg, an efficient single-stage framework that integrates three key innovations: (i) an object existence prior that dynamically weights relevant categories through global image-text similarity, effectively reducing hallucinations; (ii) a region-aware alignment module that establishes precise region-level visual-textual correspondences; and (iii) a dual-stream fusion mechanism that optimally combines local structural information with global semantic context. Unlike prior works, LoGoSeg eliminates the need for external mask proposals, additional backbones, or extra datasets, ensuring efficiency. Extensive experiments on six benchmarks (A-847, PC-459, A-150, PC-59, PAS-20, and PAS-20b) demonstrate its competitive performance and strong generalization in open-vocabulary settings.", "AI": {"tldr": "LoGoSeg is an efficient single-stage framework for open-vocabulary semantic segmentation, addressing spatial misalignment and object detection challenges.", "motivation": "Existing methods rely heavily on image-level pretraining, leading to poor spatial alignment, ambiguous segmentation, and inadequate object priors.", "method": "LoGoSeg introduces three innovations: dynamic object existence prior, region-aware alignment module, and dual-stream fusion mechanism, without dependence on external resources.", "result": "Experiments on six diverse benchmarks highlight its competitive performance and generalization in open-vocabulary scenarios.", "conclusion": "LoGoSeg improves segmentation accuracy and efficiency, making strides in OVSS by resolving spatial and detection challenges."}}
{"id": "2602.05877", "pdf": "https://arxiv.org/pdf/2602.05877", "abs": "https://arxiv.org/abs/2602.05877", "authors": ["Lukas Stappen", "Ahmet Erkan Turan", "Johann Hagerer", "Georg Groh"], "title": "Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate with external services via protocols such as Google's Agent-to-Agent (A2A), they establish attack surfaces where manipulations can propagate through natural language payloads, potentially causing severe consequences ranging from driver distraction to unauthorized vehicle control. Existing AI security frameworks, while foundational, lack the rigorous \"separation of concerns\" standard in safety-critical systems engineering by co-mingling the concepts of what is being protected (assets) with how it is attacked (attack paths). This paper addresses this methodological gap by proposing a threat modeling framework called AgentHeLLM (Agent Hazard Exploration for LLM Assistants) that formally separates asset identification from attack path analysis. We introduce a human-centric asset taxonomy derived from harm-oriented \"victim modeling\" and inspired by the Universal Declaration of Human Rights, and a formal graph-based model that distinguishes poison paths (malicious data propagation) from trigger paths (activation actions). We demonstrate the framework's practical applicability through an open-source attack path suggestion tool AgentHeLLM Attack Path Generator that automates multi-stage threat discovery using a bi-level search strategy.", "AI": {"tldr": "The paper introduces AgentHeLLM, a security framework addressing threats in LLM-based automotive conversational agents by separating asset protection and attack path analysis.", "motivation": "Current AI security frameworks are insufficiently rigorous for automotive applications, where LLM integration introduces unique risks such as natural language attack propagation.", "method": "The authors propose a threat modeling framework, AgentHeLLM, using human-centric asset taxonomy and a graph-based model to differentiate between malicious data paths and activation actions.", "result": "An open-source tool, AgentHeLLM Attack Path Generator, is developed to demonstrate automated multi-stage threat discovery via a bi-level search strategy.", "conclusion": "Separating asset and attack path analyses improves security frameworks for LLM-based systems, ensuring both theoretical rigor and practical applicability."}}
{"id": "2602.05204", "pdf": "https://arxiv.org/pdf/2602.05204", "abs": "https://arxiv.org/abs/2602.05204", "authors": ["Changhoon Song", "Teng Yuan Chang", "Youngjoon Hong"], "title": "Extreme Weather Nowcasting via Local Precipitation Pattern Prediction", "categories": ["cs.LG", "cs.CV"], "comment": "10pages, 20 figures, The Fourteenth International Conference on Learning Representations, see https://github.com/tony890048/exPreCast", "summary": "Accurate forecasting of extreme weather events such as heavy rainfall or storms is critical for risk management and disaster mitigation. Although high-resolution radar observations have spurred extensive research on nowcasting models, precipitation nowcasting remains particularly challenging due to pronounced spatial locality, intricate fine-scale rainfall structures, and variability in forecasting horizons. While recent diffusion-based generative ensembles show promising results, they are computationally expensive and unsuitable for real-time applications. In contrast, deterministic models are computationally efficient but remain biased toward normal rainfall. Furthermore, the benchmark datasets commonly used in prior studies are themselves skewed--either dominated by ordinary rainfall events or restricted to extreme rainfall episodes--thereby hindering general applicability in real-world settings. In this paper, we propose exPreCast, an efficient deterministic framework for generating finely detailed radar forecasts, and introduce a newly constructed balanced radar dataset from the Korea Meteorological Administration (KMA), which encompasses both ordinary precipitation and extreme events. Our model integrates local spatiotemporal attention, a texture-preserving cubic dual upsampling decoder, and a temporal extractor to flexibly adjust forecasting horizons. Experiments on established benchmarks (SEVIR and MeteoNet) as well as on the balanced KMA dataset demonstrate that our approach achieves state-of-the-art performance, delivering accurate and reliable nowcasts across both normal and extreme rainfall regimes.", "AI": {"tldr": "This paper introduces exPreCast, an efficient model and a balanced radar dataset for forecasting precipitation events, achieving state-of-the-art results across normal and extreme rainfall types.", "motivation": "Forecasting extreme weather events, such as heavy rainfall and storms, is critical for managing risks and mitigating disasters. Current challenges include spatial locality, fine-scale rainfall structures, variability in forecasting, and limitations of existing datasets.", "method": "The authors propose exPreCast, leveraging local spatiotemporal attention, a texture-preserving decoder, and a temporal extractor for flexible forecasting horizons. They develop a balanced dataset from Korea's radar observations for better real-world applicability.", "result": "Experiments show exPreCast delivers state-of-the-art nowcasting performance on SEVIR, MeteoNet, and the newly balanced KMA dataset, offering accurate predictions for both normal and extreme rainfall.", "conclusion": "exPreCast significantly advances precipitation forecasting, overcoming biases in existing deterministic models and datasets, and is computationally efficient, making it suitable for real-world applications."}}
{"id": "2602.05582", "pdf": "https://arxiv.org/pdf/2602.05582", "abs": "https://arxiv.org/abs/2602.05582", "authors": ["Joe-Mei Feng", "Sheng-Wei Yu"], "title": "Geometric Observability Index: An Operator-Theoretic Framework for Per-Feature Sensitivity, Weak Observability, and Dynamic Effects in SE(3) Pose Estimation", "categories": ["cs.CV"], "comment": null, "summary": "We present a unified operator-theoretic framework for analyzing per-feature sensitivity in camera pose estimation on the Lie group SE(3). Classical sensitivity tools - conditioning analyses, Euclidean perturbation arguments, and Fisher information bounds - do not explain how individual image features influence the pose estimate, nor why dynamic or inconsistent observations can disproportionately distort modern SLAM and structure-from-motion systems. To address this gap, we extend influence function theory to matrix Lie groups and derive an intrinsic perturbation operator for left-trivialized M-estimators on SE(3).\n  The resulting Geometric Observability Index (GOI) quantifies the contribution of a single measurement through the curvature operator and the Lie algebraic structure of the observable subspace. GOI admits a spectral decomposition along the principal directions of the observable curvature, revealing a direct correspondence between weak observability and amplified sensitivity. In the population regime, GOI coincides with the Fisher information geometry on SE(3), yielding a single-measurement analogue of the Cramer-Rao bound.\n  The same spectral mechanism explains classical degeneracies such as pure rotation and vanishing parallax, as well as dynamic feature amplification along weak curvature directions. Overall, GOI provides a geometrically consistent description of measurement influence that unifies conditioning analysis, Fisher information geometry, influence function theory, and dynamic scene detectability through the spectral geometry of the curvature operator. Because these quantities arise directly within Gauss-Newton pipelines, the curvature spectrum and GOI also yield lightweight, training-free diagnostic signals for identifying dynamic features and detecting weak observability configurations without modifying existing SLAM architectures.", "AI": {"tldr": "The paper introduces the Geometric Observability Index (GOI), a technique for quantifying individual feature influence in camera pose estimation on SE(3), using an operator-theoretic framework tied to observability geometry.", "motivation": "Classical sensitivity tools cannot adequately explain individual feature influence or the impact of inconsistent observations in modern SLAM and structure-from-motion systems.", "method": "The authors derive an intrinsic perturbation operator on SE(3) by extending influence function theory to matrix Lie groups, which leads to the development of GOI with spectral decomposition.", "result": "GOI quantifies sensitivity using curvature operators, unifies traditional analyses, explains degeneracy phenomena, and proposes lightweight diagnostics for weak observability issues within SLAM pipelines.", "conclusion": "GOI offers a unifying and geometrically consistent framework for understanding feature influence and observability, with potential practical benefits for SLAM systems without requiring significant modifications."}}
{"id": "2602.05883", "pdf": "https://arxiv.org/pdf/2602.05883", "abs": "https://arxiv.org/abs/2602.05883", "authors": ["Philippe J. Giabbanelli"], "title": "A Guide to Large Language Models in Modeling and Simulation: From Core Techniques to Critical Challenges", "categories": ["cs.AI"], "comment": "Book chapter. Accepted in Artificial Intelligence in Modeling and Simulation, Philippe J. Giabbanelli and Istvan David (eds). Series on Simulation Foundations, Methods and Applications. Springer, Cham. Series ISSN: 2195-2817", "summary": "Large language models (LLMs) have rapidly become familiar tools to researchers and practitioners. Concepts such as prompting, temperature, or few-shot examples are now widely recognized, and LLMs are increasingly used in Modeling & Simulation (M&S) workflows. However, practices that appear straightforward may introduce subtle issues, unnecessary complexity, or may even lead to inferior results. Adding more data can backfire (e.g., deteriorating performance through model collapse or inadvertently wiping out existing guardrails), spending time on fine-tuning a model can be unnecessary without a prior assessment of what it already knows, setting the temperature to 0 is not sufficient to make LLMs deterministic, providing a large volume of M&S data as input can be excessive (LLMs cannot attend to everything) but naive simplifications can lose information. We aim to provide comprehensive and practical guidance on how to use LLMs, with an emphasis on M&S applications. We discuss common sources of confusion, including non-determinism, knowledge augmentation (including RAG and LoRA), decomposition of M&S data, and hyper-parameter settings. We emphasize principled design choices, diagnostic strategies, and empirical evaluation, with the goal of helping modelers make informed decisions about when, how, and whether to rely on LLMs.", "AI": {"tldr": "This paper provides guidance for effectively using Large Language Models (LLMs) in Modeling & Simulation (M&S), addressing common pitfalls, confusion sources, and best practices.", "motivation": "The paper aims to address issues and confusion surrounding the use of LLMs in Modeling & Simulation, helping practitioners avoid common mistakes and make informed decisions.", "method": "It provides a comprehensive discussion of key issues encountered in using LLMs, including non-determinism, knowledge augmentation, data decomposition, and hyper-parameter choices, complemented by strategic design and empirical evaluation.", "result": "The paper highlights common challenges, offers diagnostic strategies, and presents practical recommendations for working with LLMs in M&S workflows.", "conclusion": "The authors advocate for an informed and systematic approach to employing LLMs, ensuring effectiveness and avoiding potential pitfalls in M&S applications."}}
{"id": "2602.05214", "pdf": "https://arxiv.org/pdf/2602.05214", "abs": "https://arxiv.org/abs/2602.05214", "authors": ["Jinjin Chi", "Taoping Liu", "Mengtao Yin", "Ximing Li", "Yongcheng Jing", "Dacheng Tao"], "title": "Disentangled Representation Learning via Flow Matching", "categories": ["cs.LG"], "comment": null, "summary": "Disentangled representation learning aims to capture the underlying explanatory factors of observed data, enabling a principled understanding of the data-generating process. Recent advances in generative modeling have introduced new paradigms for learning such representations. However, existing diffusion-based methods encourage factor independence via inductive biases, yet frequently lack strong semantic alignment. In this work, we propose a flow matching-based framework for disentangled representation learning, which casts disentanglement as learning factor-conditioned flows in a compact latent space. To enforce explicit semantic alignment, we introduce a non-overlap (orthogonality) regularizer that suppresses cross-factor interference and reduces information leakage between factors. Extensive experiments across multiple datasets demonstrate consistent improvements over representative baselines, yielding higher disentanglement scores as well as improved controllability and sample fidelity.", "AI": {"tldr": "This paper introduces a flow matching-based framework for disentangled representation learning leveraging semantic alignment and orthogonality regularization for enhanced disentanglement, controllability, and sample fidelity.", "motivation": "Achieving disentangled representation learning with strong semantic alignment and reducing information interference across factors to better understand data generation processes.", "method": "Flow matching-based framework with non-overlap regularizer in a compact latent space to suppress factor interference and enhance semantic alignment.", "result": "Experiments show improved disentanglement scores, controllability, and sample fidelity compared to baselines across multiple datasets.", "conclusion": "The proposed framework consistently improves disentangled learning, aligning semantic factors while maintaining data fidelity and control dynamics."}}
{"id": "2602.05588", "pdf": "https://arxiv.org/pdf/2602.05588", "abs": "https://arxiv.org/abs/2602.05588", "authors": ["Haojie Cheng", "Chang Liu", "Abhiram Kanneganti", "Mahesh Arjandas Choolani", "Arundhati Tushar Gosavi", "Eng Tat Khoo"], "title": "A Mixed Reality System for Robust Manikin Localization in Childbirth Training", "categories": ["cs.CV", "cs.ET", "cs.GR"], "comment": null, "summary": "Opportunities for medical students to gain practical experience in vaginal births are increasingly constrained by shortened clinical rotations, patient reluctance, and the unpredictable nature of labour. To alleviate clinicians' instructional burden and enhance trainees' learning efficiency, we introduce a mixed reality (MR) system for childbirth training that combines virtual guidance with tactile manikin interaction, thereby preserving authentic haptic feedback while enabling independent practice without continuous on-site expert supervision. The system extends the passthrough capability of commercial head-mounted displays (HMDs) by spatially calibrating an external RGB-D camera, allowing real-time visual integration of physical training objects. Building on this capability, we implement a coarse-to-fine localization pipeline that first aligns the maternal manikin with fiducial markers to define a delivery region and then registers the pre-scanned neonatal head within this area. This process enables spatially accurate overlay of virtual guiding hands near the manikin, allowing trainees to follow expert trajectories reinforced by haptic interaction. Experimental evaluations demonstrate that the system achieves accurate and stable manikin localization on a standalone headset, ensuring practical deployment without external computing resources. A large-scale user study involving 83 fourth-year medical students was subsequently conducted to compare MR-based and virtual reality (VR)-based childbirth training. Four senior obstetricians independently assessed performance using standardized criteria. Results showed that MR training achieved significantly higher scores in delivery, post-delivery, and overall task performance, and was consistently preferred by trainees over VR training.", "AI": {"tldr": "The paper introduces an innovative Mixed Reality (MR) system for childbirth training, combining virtual guidance with tactile feedback from a manikin, proven more effective than VR training.", "motivation": "Limited opportunities for medical students to gain practical experience in vaginal births due to shortened rotations, patient reluctance, and labour unpredictability.", "method": "A MR system integrates virtual guiding hands with tactile manikin interaction using calibrated RGB-D cameras and coarse-to-fine localization, allowing trainees to practice independently.", "result": "Experimental evaluations show accurate manikin localization for standalone use, and a user study with 83 medical students indicates higher scores and preference for MR training compared to VR training.", "conclusion": "MR-based childbirth training is a practical, effective, and preferred solution for improving medical students' skills in vaginal births compared to VR."}}
{"id": "2602.05920", "pdf": "https://arxiv.org/pdf/2602.05920", "abs": "https://arxiv.org/abs/2602.05920", "authors": ["Eva Andr\u00e9s"], "title": "Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem", "categories": ["cs.AI", "cs.ET"], "comment": "22 pages, 12 figures", "summary": "This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. The experiments focus on multi-vehicle scenarios with capacity constraints, considering 20 clients and 4 vehicles, and are conducted over ten independent runs. Performance is assessed using routing distance, route compactness, and route overlap. The results show that all three approaches are capable of learning effective routing policies. However, quantum-enhanced models outperform the classical baseline and produce more robust route organization, with the hybrid architecture achieving the best overall performance across distance, compactness, and route overlap. In addition to quantitative improvements, qualitative visualizations reveal that quantum-based models generate more structured and coherent routing solutions. These findings highlight the potential of hybrid quantum-classical reinforcement learning models for addressing complex combinatorial optimization problems such as the CVRP.", "AI": {"tldr": "This paper compares classical and quantum Reinforcement Learning (RL) approaches for solving the Capacitated Vehicle Routing Problem (CVRP).", "motivation": "To explore the potential of quantum-enhanced RL in addressing complex combinatorial optimization problems like CVRP.", "method": "Implemented three variants of A2C agents: classical, quantum, and hybrid, utilizing transformer architectures and attention mechanisms. Conducted experiments on CVRP scenarios with 20 clients and 4 vehicles over ten runs.", "result": "Quantum-enhanced models outperformed classical ones in routing distance, compactness, route overlap, and generated more structured solutions. Hybrid approaches showed the best overall performance.", "conclusion": "Hybrid quantum-classical RL models are promising for tackling CVRP and similar optimization challenges, offering both quantitative and qualitative advantages."}}
{"id": "2602.05219", "pdf": "https://arxiv.org/pdf/2602.05219", "abs": "https://arxiv.org/abs/2602.05219", "authors": ["Chao Yan"], "title": "Private Prediction via Shrinkage", "categories": ["cs.LG"], "comment": null, "summary": "We study differentially private prediction introduced by Dwork and Feldman (COLT 2018): an algorithm receives one labeled sample set $S$ and then answers a stream of unlabeled queries while the output transcript remains $(\\varepsilon,\u03b4)$-differentially private with respect to $S$. Standard composition yields a $\\sqrt{T}$ dependence for $T$ queries.\n  We show that this dependence can be reduced to polylogarithmic in $T$ in streaming settings. For an oblivious online adversary and any concept class $\\mathcal{C}$, we give a private predictor that answers $T$ queries with $|S|= \\tilde{O}(VC(\\mathcal{C})^{3.5}\\log^{3.5}T)$ labeled examples. For an adaptive online adversary and halfspaces over $\\mathbb{R}^d$, we obtain $|S|=\\tilde{O}\\left(d^{5.5}\\log T\\right)$.", "AI": {"tldr": "This paper improves the efficiency of differentially private prediction by reducing the sample size dependence on the number of queries from a \u221aT to a polylogarithmic scale.", "motivation": "To enhance differentially private prediction algorithms by reducing the dependency of sample size on the number of queries in streaming prediction settings.", "method": "The authors propose a new private predictor for streaming settings under two adversarial scenarios: an oblivious online adversary for general concept classes and an adaptive adversary for halfspaces in Euclidean space.", "result": "They achieve a significantly reduced labeled sample size requirement: for oblivious adversaries, $|S|=\\tilde{O}(VC(\\mathcal{C})^{3.5}\\log^{3.5}T)$ and for adaptive adversaries, $|S|=\\tilde{O}(d^{5.5}\\log T)$.", "conclusion": "This advancement demonstrates that differentially private prediction can be made more efficient in terms of sample complexity, which broadens its practical applications in real-world scenarios."}}
{"id": "2602.05590", "pdf": "https://arxiv.org/pdf/2602.05590", "abs": "https://arxiv.org/abs/2602.05590", "authors": ["Haojie Cheng", "Shaun Jing Heng Ong", "Shaoyu Cai", "Aiden Tat Yang Koh", "Fuxi Ouyang", "Eng Tat Khoo"], "title": "EgoPoseVR: Spatiotemporal Multi-Modal Reasoning for Egocentric Full-Body Pose in Virtual Reality", "categories": ["cs.CV", "cs.ET", "cs.GR"], "comment": null, "summary": "Immersive virtual reality (VR) applications demand accurate, temporally coherent full-body pose tracking. Recent head-mounted camera-based approaches show promise in egocentric pose estimation, but encounter challenges when applied to VR head-mounted displays (HMDs), including temporal instability, inaccurate lower-body estimation, and the lack of real-time performance. To address these limitations, we present EgoPoseVR, an end-to-end framework for accurate egocentric full-body pose estimation in VR that integrates headset motion cues with egocentric RGB-D observations through a dual-modality fusion pipeline. A spatiotemporal encoder extracts frame- and joint-level representations, which are fused via cross-attention to fully exploit complementary motion cues across modalities. A kinematic optimization module then imposes constraints from HMD signals, enhancing the accuracy and stability of pose estimation. To facilitate training and evaluation, we introduce a large-scale synthetic dataset of over 1.8 million temporally aligned HMD and RGB-D frames across diverse VR scenarios. Experimental results show that EgoPoseVR outperforms state-of-the-art egocentric pose estimation models. A user study in real-world scenes further shows that EgoPoseVR achieved significantly higher subjective ratings in accuracy, stability, embodiment, and intention for future use compared to baseline methods. These results show that EgoPoseVR enables robust full-body pose tracking, offering a practical solution for accurate VR embodiment without requiring additional body-worn sensors or room-scale tracking systems.", "AI": {"tldr": "The paper introduces EgoPoseVR, an end-to-end framework for robust, temporally coherent full-body pose estimation in VR using head-mounted display camera cues and RGB-D observations.", "motivation": "To overcome challenges in VR pose tracking such as temporal instability, lower-body inaccuracies, and lack of real-time performance in head-mounted camera-based approaches.", "method": "EgoPoseVR employs a dual-modality fusion pipeline combining RGB-D and HMD motion data, a spatiotemporal encoder with cross-attention, and a kinematic optimization module. A synthetic dataset aids in training and evaluation.", "result": "EgoPoseVR surpasses state-of-the-art egocentric pose estimation models in accuracy and stability. User studies highlight its superior subjective ratings compared to baseline methods.", "conclusion": "EgoPoseVR is a practical solution for accurate VR embodiment, eliminating the need for additional body-worn sensors or room-scale tracking setups."}}
{"id": "2602.05983", "pdf": "https://arxiv.org/pdf/2602.05983", "abs": "https://arxiv.org/abs/2602.05983", "authors": ["Kre\u0161imir Ku\u0161i\u0107", "Vinny Cahill", "Ivana Dusparic"], "title": "Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins", "categories": ["cs.AI"], "comment": "IEEE IV2026 37th IEEE Intelligent Vehicles Symposium", "summary": "The operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a proactive decision-making support layer within traffic management, a digital twin must also incorporate predicted traffic conditions in addition to real-time observations. Due to the spatio-temporal complexity and the time-variant, non-linear nature of traffic dynamics, predicting motorway traffic remains a difficult problem. Sequence-based deep-learning models offer clear advantages over classical machine learning and statistical models in capturing long-range, temporal dependencies in time-series traffic data, yet limitations in forecasting accuracy and model complexity point to the need for further improvements. To improve motorway traffic forecasting, this paper introduces a Geographically-aware Transformer-based Traffic Forecasting GATTF model, which exploits the geographical relationships between distributed sensors using their mutual information (MI). The model has been evaluated using real-time data from the Geneva motorway network in Switzerland and results confirm that incorporating geographical awareness through MI enhances the accuracy of GATTF forecasting compared to a standard Transformer, without increasing model complexity.", "AI": {"tldr": "The paper presents the GATTF model, which uses geographical relationships via mutual information to improve traffic forecasting accuracy, evaluated on real-time data from the Geneva motorway.", "motivation": "To enhance motorway traffic forecasting accuracy by addressing limitations in sequence-based deep learning models and utilizing geographical sensor relationships.", "method": "Development of the Geographically-aware Transformer-based Traffic Forecasting (GATTF) model, incorporating mutual information from distributed sensors.", "result": "Incorporating geographical awareness through mutual information improved the forecasting accuracy of the GATTF model compared to standard Transformers, without increasing model complexity.", "conclusion": "The GATTF model demonstrates effective enhancement in motorway traffic prediction by introducing geographical awareness, offering a viable solution for traffic management systems leveraging digital twin technology."}}
{"id": "2602.05598", "pdf": "https://arxiv.org/pdf/2602.05598", "abs": "https://arxiv.org/abs/2602.05598", "authors": ["Aon Safdar", "Mohamed Saadeldin"], "title": "CAViT -- Channel-Aware Vision Transformer for Dynamic Feature Fusion", "categories": ["cs.CV", "cs.AI"], "comment": "Presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (CVPR 25) in the 4th Workshop on Transformers for Visions - T4V (https://sites.google.com/view/t4v-cvpr25/) Accepted for Publication at 33rd International Conference on Artificial Intelligence and Cognitive Science (AICS 2025), where it was shortlisted for Best Paper Award. (https://aicsconf.org/?page_id=278)", "summary": "Vision Transformers (ViTs) have demonstrated strong performance across a range of computer vision tasks by modeling long-range spatial interactions via self-attention. However, channel-wise mixing in ViTs remains static, relying on fixed multilayer perceptrons (MLPs) that lack adaptability to input content. We introduce 'CAViT', a dual-attention architecture that replaces the static MLP with a dynamic, attention-based mechanism for feature interaction. Each Transformer block in CAViT performs spatial self-attention followed by channel-wise self-attention, allowing the model to dynamically recalibrate feature representations based on global image context. This unified and content-aware token mixing strategy enhances representational expressiveness without increasing depth or complexity. We validate CAViT across five benchmark datasets spanning both natural and medical domains, where it outperforms the standard ViT baseline by up to +3.6% in accuracy, while reducing parameter count and FLOPs by over 30%. Qualitative attention maps reveal sharper and semantically meaningful activation patterns, validating the effectiveness of our attention-driven token mixing.", "AI": {"tldr": "The paper presents CAViT, a Vision Transformer model enhancing performance with dynamic channel-wise self-attention for better feature interaction and reduced computational cost.", "motivation": "Standard Vision Transformers rely on static multilayer perceptrons for channel-wise processing, which lack adaptability to specific input content. This limitation motivates designing a more dynamic and content-aware mechanism for improved feature interaction.", "method": "The paper proposes CAViT, a dual-attention architecture combining spatial self-attention with dynamic channel-wise self-attention. This approach enhances token mixing adaptively, focusing on global image context while reducing model complexity.", "result": "CAViT demonstrates superior performance across five benchmark datasets, achieving up to +3.6% accuracy improvement over standard ViTs. It also reduces parameters and FLOPs by over 30%, indicative of its efficiency.", "conclusion": "CAViT improves the representational capability of Vision Transformers through a unified, content-aware token mixing mechanism, achieving both higher accuracy and computational efficiency. Attribution maps confirm its practical effectiveness."}}
{"id": "2602.06000", "pdf": "https://arxiv.org/pdf/2602.06000", "abs": "https://arxiv.org/abs/2602.06000", "authors": ["Ali Shendabadi", "Parnia Izadirad", "Mostafa Salehi", "Mahmoud Bijankhan"], "title": "Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.", "AI": {"tldr": "This research explores the use of Whisper, a pre-trained ASR system, and introduces attention-based pooling methods for effective Speech Emotion Recognition (SER), achieving state-of-the-art results on the ShEMO dataset.", "motivation": "There is a limitation in SER research due to the lack of large datasets, and pre-trained models like Whisper can extract helpful features for overcoming this challenge.", "method": "The researchers propose two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, applied to Whisper's representations for dimensionality reduction while retaining emotional features. Experiments were conducted using datasets in English and Persian.", "result": "The multi-head QKV pooling method achieved state-of-the-art results in unweighted accuracy on the ShEMO dataset, showing a 2.47% improvement. Intermediate Whisper encoder layers performed better than larger models for the Persian dataset.", "conclusion": "Whisper shows strong potential as a feature extractor for SER tasks, and attention-based pooling methods are effective in reducing dimensionality while preserving relevant emotional details."}}
{"id": "2602.05232", "pdf": "https://arxiv.org/pdf/2602.05232", "abs": "https://arxiv.org/abs/2602.05232", "authors": ["Chunyu Wei", "Siyuan He", "Yu Wang", "Yueguo Chen", "Yunhai Wang", "Bing Bai", "Yidong Zhang", "Yong Xie", "Shunming Zhang", "Fei Wang"], "title": "Balanced Anomaly-guided Ego-graph Diffusion Model for Inductive Graph Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages,6 figures, Accepted by ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '26)", "summary": "Graph anomaly detection (GAD) is crucial in applications like fraud detection and cybersecurity. Despite recent advancements using graph neural networks (GNNs), two major challenges persist. At the model level, most methods adopt a transductive learning paradigm, which assumes static graph structures, making them unsuitable for dynamic, evolving networks. At the data level, the extreme class imbalance, where anomalous nodes are rare, leads to biased models that fail to generalize to unseen anomalies. These challenges are interdependent: static transductive frameworks limit effective data augmentation, while imbalance exacerbates model distortion in inductive learning settings. To address these challenges, we propose a novel data-centric framework that integrates dynamic graph modeling with balanced anomaly synthesis. Our framework features: (1) a discrete ego-graph diffusion model, which captures the local topology of anomalies to generate ego-graphs aligned with anomalous structural distribution, and (2) a curriculum anomaly augmentation mechanism, which dynamically adjusts synthetic data generation during training, focusing on underrepresented anomaly patterns to improve detection and generalization. Experiments on five datasets demonstrate that the effectiveness of our framework.", "AI": {"tldr": "The paper addresses two key challenges in graph anomaly detection: the limitations of static transductive models and extreme class imbalance. It proposes a novel framework with dynamic graph modeling and anomaly synthesis techniques.", "motivation": "To overcome the limitations of existing methods in graph anomaly detection, improving detection performance in dynamic and imbalanced scenarios.", "method": "The proposed framework includes (1) a discrete ego-graph diffusion model for capturing and generating anomaly-consistent graph structures and (2) a curriculum-driven mechanism for synthetic anomaly augmentation to reduce imbalance and enhance training.", "result": "Experiments on five datasets demonstrate improved anomaly detection and generalization compared to existing methods.", "conclusion": "The proposed data-centric framework offers an effective solution to the challenges in graph anomaly detection caused by dynamic networks and data imbalance, enhancing detection of rare anomalies."}}
{"id": "2602.05602", "pdf": "https://arxiv.org/pdf/2602.05602", "abs": "https://arxiv.org/abs/2602.05602", "authors": ["Zongliang Zhang", "Shuxiang Li", "Xingwang Huang", "Zongyue Wang"], "title": "Multi-instance robust fitting for non-classical geometric models", "categories": ["cs.CV"], "comment": null, "summary": "Most existing robust fitting methods are designed for classical models, such as lines, circles, and planes. In contrast, fewer methods have been developed to robustly handle non-classical models, such as spiral curves, procedural character models, and free-form surfaces. Furthermore, existing methods primarily focus on reconstructing a single instance of a non-classical model. This paper aims to reconstruct multiple instances of non-classical models from noisy data. We formulate this multi-instance fitting task as an optimization problem, which comprises an estimator and an optimizer. Specifically, we propose a novel estimator based on the model-to-data error, capable of handling outliers without a predefined error threshold. Since the proposed estimator is non-differentiable with respect to the model parameters, we employ a meta-heuristic algorithm as the optimizer to seek the global optimum. The effectiveness of our method are demonstrated through experimental results on various non-classical models. The code is available at https://github.com/zhangzongliang/fitting.", "AI": {"tldr": "This paper discusses a method for robustly reconstructing multiple instances of non-classical models from noisy data.", "motivation": "There is a lack of robust fitting approaches for non-classical models like spiral curves and free-form surfaces, unlike the prevalence of methods for classical models.", "method": "The authors propose a non-differentiable estimator based on model-to-data error and utilize meta-heuristic algorithms for global optimization.", "result": "Experimental results demonstrate the effectiveness of the proposed approach across various non-classical models.", "conclusion": "The method successfully handles outliers and reconstructs multiple instances of non-classical models, addressing challenges in noisy data scenarios."}}
{"id": "2602.06008", "pdf": "https://arxiv.org/pdf/2602.06008", "abs": "https://arxiv.org/abs/2602.06008", "authors": ["Xianyang Liu", "Shangding Gu", "Dawn Song"], "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.", "AI": {"tldr": "AgenticPay is a framework for evaluating multi-agent economic interactions mediated by natural language, featuring over 110 tasks and benchmarking LLMs.", "motivation": "Existing benchmarks lack principled settings to evaluate language-based economic negotiations and interactions among multiple agents.", "method": "Developed AgenticPay, a simulation framework for buyer-seller negotiation tasks, leveraging linguistic exchanges instead of purely numeric bidding.", "result": "Benchmarked state-of-the-art LLMs, revealing gaps in negotiation performance and difficulties in long-horizon reasoning.", "conclusion": "AgenticPay establishes a foundation for studying agentic commerce and language-driven market interaction, with open code and dataset available."}}
{"id": "2602.05234", "pdf": "https://arxiv.org/pdf/2602.05234", "abs": "https://arxiv.org/abs/2602.05234", "authors": ["Yuntai Bao", "Xuhong Zhang", "Jintao Chen", "Ge Su", "Yuxiang Cai", "Hao Peng", "Bing Sun", "Haiqin Weng", "Liu Yan", "Jianwei Yin"], "title": "Faithful Bi-Directional Model Steering via Distribution Matching and Distributed Interchange Interventions", "categories": ["cs.LG", "cs.CL"], "comment": "55 pages, 25 figures; accepted for ICLR 2026", "summary": "Intervention-based model steering offers a lightweight and interpretable alternative to prompting and fine-tuning. However, by adapting strong optimization objectives from fine-tuning, current methods are susceptible to overfitting and often underperform, sometimes generating unnatural outputs. We hypothesize that this is because effective steering requires the faithful identification of internal model mechanisms, not the enforcement of external preferences. To this end, we build on the principles of distributed alignment search (DAS), the standard for causal variable localization, to propose a new steering method: Concept DAS (CDAS). While we adopt the core mechanism of DAS, distributed interchange intervention (DII), we introduce a novel distribution matching objective tailored for the steering task by aligning intervened output distributions with counterfactual distributions. CDAS differs from prior work in two main ways: first, it learns interventions via weak-supervised distribution matching rather than probability maximization; second, it uses DIIs that naturally enable bi-directional steering and allow steering factors to be derived from data, reducing the effort required for hyperparameter tuning and resulting in more faithful and stable control. On AxBench, a large-scale model steering benchmark, we show that CDAS does not always outperform preference-optimization methods but may benefit more from increased model scale. In two safety-related case studies, overriding refusal behaviors of safety-aligned models and neutralizing a chain-of-thought backdoor, CDAS achieves systematic steering while maintaining general model utility. These results indicate that CDAS is complementary to preference-optimization approaches and conditionally constitutes a robust approach to intervention-based model steering. Our code is available at https://github.com/colored-dye/concept_das.", "AI": {"tldr": "The paper presents Concept DAS (CDAS), a novel model steering method that addresses limitations of overfitting and unnatural outputs in existing approaches by leveraging distributed alignment search principles and a new intervention method.", "motivation": "Current model steering methods face challenges such as overfitting and generating unnatural outputs, deriving from improper optimization objectives, motivating the creation of an approach that faithfully aligns with internal model mechanisms.", "method": "CDAS adapts Distributed Interchange Intervention (DII) with a new distribution matching objective for steering tasks, focusing on weak-supervised learning and enabling bi-directional steering for reduced hyperparameter tuning and improved control.", "result": "On AxBench, CDAS demonstrates scalability benefits and exhibits robust performance in case studies like overriding safety-aligned model behaviors and addressing backdoors with systematic steering while preserving general model utility.", "conclusion": "CDAS offers a complementary and stable alternative to preference-optimization methods for intervention-based model steering, with potential advantages in scalability and application to safety-related tasks."}}
{"id": "2602.05056", "pdf": "https://arxiv.org/pdf/2602.05056", "abs": "https://arxiv.org/abs/2602.05056", "authors": ["Heajun An", "Connor Ng", "Sandesh Sharma Dulal", "Junghwan Kim", "Jin-Hee Cho"], "title": "VEXA: Evidence-Grounded and Persona-Adaptive Explanations for Scam Risk Sensemaking", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "Online scams across email, short message services, and social media increasingly challenge everyday risk assessment, particularly as generative AI enables more fluent and context-aware deception. Although transformer-based detectors achieve strong predictive performance, their explanations are often opaque to non-experts or misaligned with model decisions. We propose VEXA, an evidence-grounded and persona-adaptive framework for generating learner-facing scam explanations by integrating GradientSHAP-based attribution with theory-informed vulnerability personas. Evaluation across multi-channel datasets shows that grounding explanations in detector-derived evidence improves semantic reliability without increasing linguistic complexity, while persona conditioning introduces interpretable stylistic variation without disrupting evidential alignment. These results reveal a key design insight: evidential grounding governs semantic correctness, whereas persona-based adaptation operates at the level of presentation under constraints of faithfulness. Together, VEXA demonstrates the feasibility of persona-adaptive, evidence-grounded explanations and provides design guidance for trustworthy, learner-facing security explanations in non-formal contexts.", "AI": {"tldr": "The paper proposes VEXA, a framework for generating scam explanations adaptively based on evidence and personas, improving reliability and interpretability.", "motivation": "To address challenges in explaining scam detection results in an accessible manner for non-experts, while leveraging generative AI and robust detectors.", "method": "Integrates GradientSHAP-based attribution with vulnerability personas to ground explanations in evidence and adapt them for different user profiles.", "result": "Evaluation shows enhanced semantic reliability and interpretable variation due to evidence grounding and persona conditioning, respectively.", "conclusion": "VEXA enables reliable and adaptive scam explanations, providing valuable design guidance for creating user-facing security explanations."}}
{"id": "2602.05617", "pdf": "https://arxiv.org/pdf/2602.05617", "abs": "https://arxiv.org/abs/2602.05617", "authors": ["Nikolay Patakin", "Arsenii Shirokov", "Anton Konushin", "Dmitry Senushkin"], "title": "Unified Sensor Simulation for Autonomous Driving", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "In this work, we introduce \\textbf{XSIM}, a sensor simulation framework for autonomous driving. XSIM extends 3DGUT splatting with a generalized rolling-shutter modeling tailored for autonomous driving applications. Our framework provides a unified and flexible formulation for appearance and geometric sensor modeling, enabling rendering of complex sensor distortions in dynamic environments. We identify spherical cameras, such as LiDARs, as a critical edge case for existing 3DGUT splatting due to cyclic projection and time discontinuities at azimuth boundaries leading to incorrect particle projection. To address this issue, we propose a phase modeling mechanism that explicitly accounts temporal and shape discontinuities of Gaussians projected by the Unscented Transform at azimuth borders. In addition, we introduce an extended 3D Gaussian representation that incorporates two distinct opacity parameters to resolve mismatches between geometry and color distributions. As a result, our framework provides enhanced scene representations with improved geometric consistency and photorealistic appearance. We evaluate our framework extensively on multiple autonomous driving datasets, including Waymo Open Dataset, Argoverse 2, and PandaSet. Our framework consistently outperforms strong recent baselines and achieves state-of-the-art performance across all datasets. The source code is publicly available at \\href{https://github.com/whesense/XSIM}{https://github.com/whesense/XSIM}.", "AI": {"tldr": "The paper introduces XSIM, a sensor simulation framework for autonomous driving, enhancing geometry and appearance modeling with robust simulation of spherical cameras and dynamic distortions, outperforming state-of-the-art solutions.", "motivation": "To address limitations in existing sensor simulation frameworks, especially handling distortions for spherical cameras and dynamic environments in autonomous driving applications.", "method": "Developed XSIM by extending 3DGUT splatting with generalized rolling-shutter modeling, phase modeling for spherical cameras, and extending 3D Gaussian representation with dual opacity parameters.", "result": "Achieves state-of-the-art performance on multiple autonomous driving datasets (Waymo Open Dataset, Argoverse 2, PandaSet) by improving geometric consistency and photorealistic appearance.", "conclusion": "XSIM enhances scene representations and sets a new benchmark for sensor simulation frameworks in autonomous driving; source code is made publicly available for reproducibility."}}
{"id": "2602.05243", "pdf": "https://arxiv.org/pdf/2602.05243", "abs": "https://arxiv.org/abs/2602.05243", "authors": ["Boxiang Zhang", "Baijian Yang"], "title": "CORP: Closed-Form One-shot Representation-Preserving Structured Pruning for Vision Transformers", "categories": ["cs.LG"], "comment": null, "summary": "Vision Transformers achieve strong accuracy but incur high compute and memory cost. Structured pruning can reduce inference cost, but most methods rely on retraining or multi-stage optimization. These requirements limit post-training deployment. We propose \\textbf{CORP}, a closed-form one-shot structured pruning framework for Vision Transformers. CORP removes entire MLP hidden dimensions and attention substructures without labels, gradients, or fine-tuning. It operates under strict post-training constraints using only a small unlabeled calibration set. CORP formulates structured pruning as a representation recovery problem. It models removed activations and attention logits as affine functions of retained components and derives closed-form ridge regression solutions that fold compensation into model weights. This minimizes expected representation error under the calibration distribution. Experiments on ImageNet with DeiT models show strong redundancy in MLP and attention representations. Without compensation, one-shot structured pruning causes severe accuracy degradation. With CORP, models preserve accuracy under aggressive sparsity. On DeiT-Huge, CORP retains 82.8\\% Top-1 accuracy after pruning 50\\% of both MLP and attention structures. CORP completes pruning in under 20 minutes on a single GPU and delivers substantial real-world efficiency gains.", "AI": {"tldr": "The paper introduces CORP, a one-shot structured pruning method for Vision Transformers, which reduces computational cost without requiring retraining or fine-tuning.", "motivation": "Vision Transformers require high compute and memory. The authors aim to reduce inference cost without needing retraining or multi-stage optimization, which hinders deployment in post-training contexts.", "method": "CORP provides a closed-form solution for pruning Vision Transformers by removing redundant MLP hidden dimensions and attention substructures. It uses ridge regression to recover representations and optimize model weights under a strict, post-training, one-shot setting with minimal input data.", "result": "CORP minimizes accuracy loss for pruned models even under aggressive sparsity. On ImageNet, CORP achieves 82.8% Top-1 accuracy on DeiT-Huge after pruning 50% of MLP and attention structures.", "conclusion": "CORP is efficient for structured pruning of Vision Transformers, enabling accurate and computationally efficient models in a single step without retraining, making it useful for resource-constrained real-world scenarios."}}
{"id": "2602.05629", "pdf": "https://arxiv.org/pdf/2602.05629", "abs": "https://arxiv.org/abs/2602.05629", "authors": ["Jianlei Chi", "Yuzhen Wu", "Jiaxuan Hou", "Xiaodong Zhang", "Ming Fan", "Suhui Sun", "Weijun Dai", "Bo Li", "Jianguo Sun", "Jun Sun"], "title": "ROMAN: Reward-Orchestrated Multi-Head Attention Network for Autonomous Driving System Testing", "categories": ["cs.CV"], "comment": "The manuscript includes 13 pages, 8 tables, and 7 figures", "summary": "Automated Driving System (ADS) acts as the brain of autonomous vehicles, responsible for their safety and efficiency. Safe deployment requires thorough testing in diverse real-world scenarios and compliance with traffic laws like speed limits, signal obedience, and right-of-way rules. Violations like running red lights or speeding pose severe safety risks. However, current testing approaches face significant challenges: limited ability to generate complex and high-risk law-breaking scenarios, and failing to account for complex interactions involving multiple vehicles and critical situations. To address these challenges, we propose ROMAN, a novel scenario generation approach for ADS testing that combines a multi-head attention network with a traffic law weighting mechanism. ROMAN is designed to generate high-risk violation scenarios to enable more thorough and targeted ADS evaluation. The multi-head attention mechanism models interactions among vehicles, traffic signals, and other factors. The traffic law weighting mechanism implements a workflow that leverages an LLM-based risk weighting module to evaluate violations based on the two dimensions of severity and occurrence. We have evaluated ROMAN by testing the Baidu Apollo ADS within the CARLA simulation platform and conducting extensive experiments to measure its performance. Experimental results demonstrate that ROMAN surpassed state-of-the-art tools ABLE and LawBreaker by achieving 7.91% higher average violation count than ABLE and 55.96% higher than LawBreaker, while also maintaining greater scenario diversity. In addition, only ROMAN successfully generated violation scenarios for every clause of the input traffic laws, enabling it to identify more high-risk violations than existing approaches.", "AI": {"tldr": "The paper proposes ROMAN, a novel approach to test Automated Driving Systems (ADS) by generating high-risk law-breaking scenarios using a multi-head attention network and a traffic law weighting mechanism.", "motivation": "Current testing methods for ADS lack the ability to generate complex, high-risk, law-breaking scenarios and fail to account for multi-vehicle and critical interactions, hampering the safety and efficiency of autonomous vehicles.", "method": "ROMAN utilizes a multi-head attention mechanism to model critical interactions and a traffic law weighting mechanism powered by a large language model (LLM) to evaluate scenario risks based on severity and occurrence.", "result": "When evaluated on the Baidu Apollo system using CARLA simulation, ROMAN demonstrated significant improvements over existing tools (ABLE and LawBreaker), achieving higher average violation counts, greater scenario diversity, and comprehensive traffic law testing.", "conclusion": "ROMAN outperforms state-of-the-art tools in generating high-risk violation scenarios, leading to a more effective evaluation of ADS in terms of safety and compliance with traffic laws."}}
{"id": "2602.06039", "pdf": "https://arxiv.org/pdf/2602.06039", "abs": "https://arxiv.org/abs/2602.06039", "authors": ["Yuxing Lu", "Yucheng Hu", "Xukai Zhao", "Jiuxin Cao"], "title": "DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching", "categories": ["cs.AI"], "comment": null, "summary": "Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \\key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.", "AI": {"tldr": "DyTopo introduces adaptive graph-based communication for multi-agent systems using large language models, enhancing their reasoning and problem-solving abilities.", "motivation": "To address limitations in fixed communication patterns of multi-agent systems during iterative reasoning tasks.", "method": "DyTopo employs a manager-guided framework that adjusts communication graphs based on agents' dynamic query and offer descriptors, embedding these descriptors for semantic matching.", "result": "Shows consistent performance improvement (+6.2 avg.) over the strongest baseline in mathematical reasoning and code generation tasks.", "conclusion": "DyTopo improves accuracy and supports qualitative analysis of agent communication pathways through evolving graph structures."}}
{"id": "2602.05251", "pdf": "https://arxiv.org/pdf/2602.05251", "abs": "https://arxiv.org/abs/2602.05251", "authors": ["Guanjie Cheng", "Boyi Li", "Lingyu Sun", "Mengying Zhu", "Yangyang Wu", "Xinkui Zhao", "Shuiguang Deng"], "title": "TADS: Task-Aware Data Selection for Multi-Task Multimodal Pre-Training", "categories": ["cs.LG"], "comment": null, "summary": "Large-scale multimodal pre-trained models like CLIP rely heavily on high-quality training data, yet raw web-crawled datasets are often noisy, misaligned, and redundant, leading to inefficient training and suboptimal generalization. Existing data selection methods are either heuristic-based, suffering from bias and limited diversity, or data-driven but task-agnostic, failing to optimize for multi-task scenarios. To address these gaps, we introduce TADS (Task-Aware Data Selection), a novel framework for multi-task multimodal pre-training that integrates Intrinsic Quality, Task Relevance, and Distributional Diversity into a learnable value function. TADS employs a comprehensive quality assessment system with unimodal and cross-modal operators, quantifies task relevance via interpretable similarity vectors, and optimizes diversity through cluster-based weighting. A feedback-driven meta-learning mechanism adaptively refines the selection strategy based on proxy model performance across multiple downstream tasks. Experiments on CC12M demonstrate that TADS achieves superior zero-shot performance on benchmarks like ImageNet, CIFAR-100, MS-COCO, and Flickr30K, using only 36% of the data while outperforming baselines by an average of 1.0%. This highlights that TADS significantly enhances data efficiency by curating a high-utility subset that yields a much higher performance ceiling within the same computational constraints.", "AI": {"tldr": "TADS is a framework for improving multimodal model pre-training by selecting high-quality, relevant, and diverse data, leading to better efficiency and generalization.", "motivation": "The paper addresses the inefficiencies and suboptimal generalization of large multimodal models caused by noisy, misaligned, and redundant datasets, aiming to create a more effective data selection approach for multi-task pre-training.", "method": "The proposed method, TADS, integrates Intrinsic Quality, Task Relevance, and Distributional Diversity into a learnable value function using quality assessment, similarity vectors, and cluster-based weighting. It also employs feedback-driven meta-learning.", "result": "TADS outperforms baselines on benchmarks including ImageNet and CIFAR-100, using only 36% of the data, with an average performance boost of 1.0%.", "conclusion": "TADS efficiently selects a high-utility subset of data, achieving superior zero-shot performance and enhancing multimodal model pre-training within the same computational budget."}}
{"id": "2602.05638", "pdf": "https://arxiv.org/pdf/2602.05638", "abs": "https://arxiv.org/abs/2602.05638", "authors": ["Jinlin Wu", "Felix Holm", "Chuxi Chen", "An Wang", "Yaxin Hu", "Xiaofan Ye", "Zelin Zang", "Miao Xu", "Lihua Zhou", "Huai Liao", "Danny T. M. Chan", "Ming Feng", "Wai S. Poon", "Hongliang Ren", "Dong Yi", "Nassir Navab", "Gaofeng Meng", "Jiebo Luo", "Hongbin Liu", "Zhen Lei"], "title": "UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos", "categories": ["cs.CV"], "comment": null, "summary": "While foundation models have advanced surgical video analysis, current approaches rely predominantly on pixel-level reconstruction objectives that waste model capacity on low-level visual details - such as smoke, specular reflections, and fluid motion - rather than semantic structures essential for surgical understanding. We present UniSurg, a video-native foundation model that shifts the learning paradigm from pixel-level reconstruction to latent motion prediction. Built on the Video Joint Embedding Predictive Architecture (V-JEPA), UniSurg introduces three key technical innovations tailored to surgical videos: 1) motion-guided latent prediction to prioritize semantically meaningful regions, 2) spatiotemporal affinity self-distillation to enforce relational consistency, and 3) feature diversity regularization to prevent representation collapse in texture-sparse surgical scenes. To enable large-scale pretraining, we curate UniSurg-15M, the largest surgical video dataset to date, comprising 3,658 hours of video from 50 sources across 13 anatomical regions. Extensive experiments across 17 benchmarks demonstrate that UniSurg significantly outperforms state-of-the-art methods on surgical workflow recognition (+14.6% F1 on EgoSurgery, +10.3% on PitVis), action triplet recognition (39.54% mAP-IVT on CholecT50), skill assessment, polyp segmentation, and depth estimation. These results establish UniSurg as a new standard for universal, motion-oriented surgical video understanding.", "AI": {"tldr": "The paper introduces UniSurg, a video-native foundation model optimized for surgical video understanding by focusing on semantic structures instead of low-level visual details, outperforming existing methods across various tasks.", "motivation": "Current surgical video analysis models inefficiently prioritize pixel-level reconstruction, which emphasizes low-level visual details (e.g., smoke, reflections) over semantic structures critical for surgical insights.", "method": "UniSurg builds on V-JEPA with three innovations: motion-guided latent prediction, spatiotemporal affinity self-distillation, and feature diversity regularization, and is pretrained on UniSurg-15M, the largest surgical video dataset.", "result": "UniSurg significantly outperforms state-of-the-art in benchmarks like surgical workflow recognition (+14.6% F1 on EgoSurgery), action triplet recognition, skill assessment, polyp segmentation, and depth estimation.", "conclusion": "UniSurg establishes itself as a universal, motion-oriented standard for surgical video understanding with substantial performance improvements over existing methods."}}
{"id": "2505.21517", "pdf": "https://arxiv.org/pdf/2505.21517", "abs": "https://arxiv.org/abs/2505.21517", "authors": ["Indronil Bhattacharjee", "Christabel Wayllace"], "title": "Cold Start Problem: An Experimental Study of Knowledge Tracing Models with New Students", "categories": ["cs.CY", "cs.AI"], "comment": "26th International Conference on Artificial Intelligence in Education (AIED 2025)", "summary": "KnowledgeTracing (KT) involves predicting students' knowledge states based on their interactions with Intelligent Tutoring Systems (ITS). A key challenge is the cold start problem, accurately predicting knowledge for new students with minimal interaction data. Unlike prior work, which typically trains KT models on initial interactions of all students and tests on their subsequent interactions, our approach trains models solely using historical data from past students, evaluating their performance exclusively on entirely new students. We investigate cold start effects across three KT models: Deep Knowledge Tracing (DKT), Dynamic Key-Value Memory Networks (DKVMN), and Self-Attentive Knowledge Tracing (SAKT), using ASSISTments 2009, 2015, and 2017 datasets. Results indicate all models initially struggle under cold start conditions but progressively improve with more interactions; SAKT shows higher initial accuracy yet still faces limitations. These findings highlight the need for KT models that effectively generalize to new learners, emphasizing the importance of developing models robust in few-shot and zero-shot learning scenarios", "AI": {"tldr": "The paper addresses the cold start problem in Knowledge Tracing (KT), focusing on how models generalize to new students with minimal data.", "motivation": "Motivated by the need to develop KT models that can predict knowledge states for new students with limited interaction data.", "method": "Three models (DKT, DKVMN, SAKT) were analyzed in cold start conditions using ASSISTments datasets; the models were trained on past student data and evaluated on new students.", "result": "Models initially perform poorly but improve with interaction data; SAKT achieves higher initial accuracy compared to others but still has limitations.", "conclusion": "Research highlights the challenge of KT under cold start conditions and emphasizes the importance of developing robust models for few-shot and zero-shot learning scenarios."}}
{"id": "2602.05269", "pdf": "https://arxiv.org/pdf/2602.05269", "abs": "https://arxiv.org/abs/2602.05269", "authors": ["David Alejandro Trejo Pizzo"], "title": "Hybrid Gated Flow (HGF): Stabilizing 1.58-bit LLMs via Selective Low-Rank Correction", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "21 pages, 4 figures, 6 tables. Code and models will be released at opencores.ai", "summary": "The deployment of Large Language Models (LLMs) on edge devices is fundamentally constrained by the \"Memory Wall\" -- a hardware limitation where memory bandwidth, not compute, becomes the bottleneck. Recent 1.58-bit quantization techniques (e.g., BitNet b1.58) dramatically reduce memory footprint but typically incur a perplexity degradation of 20-25% compared to FP16 baselines. In this work, we introduce Hybrid Gated Flow (HGF), a dual-stream architecture that couples a 1.58-bit ternary backbone with a learnable, low-rank FP16 correction path controlled by adaptive gates.\n  Through extensive experiments on the TinyStories dataset across two training regimes (2500 and 3500 steps), we demonstrate that HGF 5.4 achieves a validation loss of 0.9306 compared to BitNet's 1.0294, recovering approximately 55% of the quality gap between pure ternary quantization and the FP16 baseline (0.8490). This recovery is achieved with only ~12-15% memory overhead beyond the ternary backbone.\n  Furthermore, we provide empirical evidence for an emergent phenomenon: quantization as structural regularization. While a full-precision differential attention baseline (Diff_Only) exhibited training instability with validation loss exceeding 1.68, the ternary-anchored HGF maintained robust convergence throughout training. Finally, we report preliminary results extending this architecture to 1.2B and 3B parameter models trained on SlimPajama and FineWeb-Edu. These larger-scale experiments confirm that the architectural stability and quality recovery observed in small-scale proxies scale linearly to production-grade language modeling regimes.", "AI": {"tldr": "The paper introduces Hybrid Gated Flow (HGF), which combines ternary quantization and FP16 correction to enhance memory-efficient deployment of LLMs on edge devices.", "motivation": "Address the 'Memory Wall' hardware limitation and improve the performance degradation caused by aggressive quantization techniques.", "method": "Develop a dual-stream architecture that integrates ternary quantization with adaptive FP16 corrections for better efficiency and quality.", "result": "The approach achieves a significant reduction in perplexity gap compared to FP16 baselines, with minimal memory overhead, and exhibits improved stability at various scales.", "conclusion": "Hybrid Gated Flow enables efficient deployment of Large Language Models on edge devices by balancing memory efficiency and model accuracy."}}
{"id": "2602.05650", "pdf": "https://arxiv.org/pdf/2602.05650", "abs": "https://arxiv.org/abs/2602.05650", "authors": ["Amir Ansari", "Jana Subirana", "Bruna Silva", "Sergio Escalera", "David Gallardo-Pujol", "Cristina Palmero"], "title": "Enhancing Personality Recognition by Comparing the Predictive Power of Traits, Facets, and Nuances", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to the 2025 13th International Conference on Affective Computing and Intelligent Interaction (Late Breaking Results)", "summary": "Personality is a complex, hierarchical construct typically assessed through item-level questionnaires aggregated into broad trait scores. Personality recognition models aim to infer personality traits from different sources of behavioral data. However, reliance on broad trait scores as ground truth, combined with limited training data, poses challenges for generalization, as similar trait scores can manifest through diverse, context dependent behaviors. In this work, we explore the predictive impact of the more granular hierarchical levels of the Big-Five Personality Model, facets and nuances, to enhance personality recognition from audiovisual interaction data. Using the UDIVA v0.5 dataset, we trained a transformer-based model including cross-modal (audiovisual) and cross-subject (dyad-aware) attention mechanisms. Results show that nuance-level models consistently outperform facet and trait-level models, reducing mean squared error by up to 74% across interaction scenarios.", "AI": {"tldr": "This study investigates how granular levels of personality traits (facets and nuances) in the Big-Five model can improve personality recognition using audiovisual data.", "motivation": "To address the challenges of generalizing personality recognition models due to reliance on broad trait scores and limited training data by exploring more detailed hierarchical personality constructs.", "method": "A transformer-based model with cross-modal (audiovisual) and cross-subject attention mechanisms was developed and trained on the UDIVA v0.5 dataset, leveraging the hierarchical levels of personality traits.", "result": "Nuance-level personality models significantly outperformed both facet and trait-level models by reducing mean squared error by up to 74% across various interaction scenarios.", "conclusion": "Utilizing granular personality traits, particularly nuance-level models, provides enhanced accuracy in personality recognition from audiovisual data."}}
{"id": "2602.05281", "pdf": "https://arxiv.org/pdf/2602.05281", "abs": "https://arxiv.org/abs/2602.05281", "authors": ["Pengyi Li", "Elizaveta Goncharova", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an indispensable paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard policy optimization methods, such as Group Relative Policy Optimization (GRPO), often converge to low-entropy policies, leading to severe mode collapse and limited output diversity. We analyze this issue from the perspective of sampling probability dynamics, identifying that the standard objective disproportionately reinforces the highest-likelihood paths, thereby suppressing valid alternative reasoning chains. To address this, we propose a novel Advantage Re-weighting Mechanism (ARM) designed to equilibrate the confidence levels across all correct responses. By incorporating Prompt Perplexity and Answer Confidence into the advantage estimation, our method dynamically reshapes the reward signal to attenuate the gradient updates of over-confident reasoning paths, while redistributing probability mass toward under-explored correct solutions. Empirical results demonstrate that our approach significantly enhances generative diversity and response entropy while maintaining competitive accuracy, effectively achieving a superior trade-off between exploration and exploitation in reasoning tasks. Empirical results on Qwen2.5 and DeepSeek models across mathematical and coding benchmarks show that ProGRPO significantly mitigates entropy collapse. Specifically, on Qwen2.5-7B, our method outperforms GRPO by 5.7% in Pass@1 and, notably, by 13.9% in Pass@32, highlighting its superior capability in generating diverse correct reasoning paths.", "AI": {"tldr": "The paper addresses the issue of mode collapse and low diversity in Reinforcement Learning applications to LLMs by introducing an Advantage Re-weighting Mechanism (ARM) to balance probabilities across correct outputs.", "motivation": "Enhancing reasoning in LLMs often faces challenges such as mode collapse and lack of generative diversity due to biases in standard optimization methods.", "method": "Proposes ARM, which uses metrics like Prompt Perplexity and Answer Confidence to rebalance rewards and lessen focus on over-confident solutions, redistributing attention to less-explored alternatives.", "result": "Findings show improved response entropy and generative diversity without compromising accuracy, outperforming GRPO in benchmarks with notable improvements in Pass@1 and Pass@32 metrics.", "conclusion": "ARM provides a methodology that resolves major drawbacks in reinforcement learning for LLMs, delivering a better balance between exploration and exploitation in reasoning tasks."}}
{"id": "2602.05676", "pdf": "https://arxiv.org/pdf/2602.05676", "abs": "https://arxiv.org/abs/2602.05676", "authors": ["Inbar Gat", "Dana Cohen-Bar", "Guy Levy", "Elad Richardson", "Daniel Cohen-Or"], "title": "ShapeUP: Scalable Image-Conditioned 3D Editing", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Recent advancements in 3D foundation models have enabled the generation of high-fidelity assets, yet precise 3D manipulation remains a significant challenge. Existing 3D editing frameworks often face a difficult trade-off between visual controllability, geometric consistency, and scalability. Specifically, optimization-based methods are prohibitively slow, multi-view 2D propagation techniques suffer from visual drift, and training-free latent manipulation methods are inherently bound by frozen priors and cannot directly benefit from scaling. In this work, we present ShapeUP, a scalable, image-conditioned 3D editing framework that formulates editing as a supervised latent-to-latent translation within a native 3D representation. This formulation allows ShapeUP to build on a pretrained 3D foundation model, leveraging its strong generative prior while adapting it to editing through supervised training. In practice, ShapeUP is trained on triplets consisting of a source 3D shape, an edited 2D image, and the corresponding edited 3D shape, and learns a direct mapping using a 3D Diffusion Transformer (DiT). This image-as-prompt approach enables fine-grained visual control over both local and global edits and achieves implicit, mask-free localization, while maintaining strict structural consistency with the original asset. Our extensive evaluations demonstrate that ShapeUP consistently outperforms current trained and training-free baselines in both identity preservation and edit fidelity, offering a robust and scalable paradigm for native 3D content creation.", "AI": {"tldr": "ShapeUP introduces a new 3D editing framework that leverages pre-trained 3D models for scalable and precise editing using supervised training.", "motivation": "The paper addresses the challenge of precise 3D manipulation, identifying limitations in current methods such as slow optimization, visual drift in multi-view techniques, and limitations in latent manipulation methods.", "method": "ShapeUP uses a supervised latent-to-latent translation powered by a 3D Diffusion Transformer (DiT), training on triplets of source shapes, edited 2D images, and their corresponding edited 3D shapes to ensure structural consistency.", "result": "ShapeUP outperforms current methods in terms of identity preservation, visual control, and edit fidelity, providing superior scalability and editing performance.", "conclusion": "ShapeUP provides a robust and effective solution for 3D editing, achieving fine-grained visual control without sacrificing structural integrity, and serving as a promising advancement in native 3D content creation."}}
{"id": "2602.04890", "pdf": "https://arxiv.org/pdf/2602.04890", "abs": "https://arxiv.org/abs/2602.04890", "authors": ["Lucas de Magalh\u00e3es Araujo", "Ot\u00e1vio Oliveira Napoli", "Sandra Avila", "Edson Borin"], "title": "A General-Purpose Diversified 2D Seismic Image Dataset from NAMSS", "categories": ["physics.geo-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "We introduce the Unicamp-NAMSS dataset, a large, diverse, and geographically distributed collection of migrated 2D seismic sections designed to support modern machine learning research in geophysics. We constructed the dataset from the National Archive of Marine Seismic Surveys (NAMSS), which contains decades of publicly available marine seismic data acquired across multiple regions, acquisition conditions, and geological settings. After a comprehensive collection and filtering process, we obtained 2588 cleaned and standardized seismic sections from 122 survey areas, covering a wide range of vertical and horizontal sampling characteristics. To ensure reliable experimentation, we balanced the dataset so that no survey dominates the distribution, and partitioned it into non-overlapping macro-regions for training, validation, and testing. This region-disjoint split allows robust evaluation of generalization to unseen geological and acquisition conditions.\n  We validated the dataset through quantitative and embedding-space analyses using both convolutional and transformer-based models. These analyses showed that Unicamp-NAMSS exhibits substantial variability within and across regions, while maintaining coherent structure across acquisition macro-region and survey types. Comparisons with widely used interpretation datasets (Parihaka and F3 Block) further demonstrated that Unicamp-NAMSS covers a broader portion of the seismic appearance space, making it a strong candidate for machine learning model pretraining. The dataset, therefore, provides a valuable resource for machine learning tasks, including self-supervised representation learning, transfer learning, benchmarking supervised tasks such as super-resolution or attribute prediction, and studying domain adaptation in seismic interpretation.", "AI": {"tldr": "The Unicamp-NAMSS dataset is introduced as a large and balanced collection of 2D seismic data for supporting machine learning research in geophysics, validated for reliability and variability.", "motivation": "To create a large-scale and diverse seismic dataset that aids machine learning research in geophysics and provides better generalization for models.", "method": "The dataset was constructed from NAMSS through cleaning, standardization, and balancing across 2588 sections from 122 survey areas, with partitioning into non-overlapping regions for model testing and validation.", "result": "The dataset demonstrated substantial variability and structure coherence, validating its suitability for machine learning tasks and showing advancements compared to existing datasets.", "conclusion": "Unicamp-NAMSS is a valuable resource for advancing geophysics-oriented machine learning, offering applications in self-supervised learning, transfer learning, and domain adaptation studies."}}
{"id": "2602.05285", "pdf": "https://arxiv.org/pdf/2602.05285", "abs": "https://arxiv.org/abs/2602.05285", "authors": ["Minhuan Li", "Jiequn Han", "Pilar Cossio", "Luhuan Wu"], "title": "Robust Inference-Time Steering of Protein Diffusion Models via Embedding Optimization", "categories": ["cs.LG"], "comment": null, "summary": "In many biophysical inverse problems, the goal is to generate biomolecular conformations that are both physically plausible and consistent with experimental measurements. As recent sequence-to-structure diffusion models provide powerful data-driven priors, posterior sampling has emerged as a popular framework by guiding atomic coordinates to target conformations using experimental likelihoods. However, when the target lies in a low-density region of the prior, posterior sampling requires aggressive and brittle weighting of the likelihood guidance. Motivated by this limitation, we propose EmbedOpt, an alternative inference-time approach for steering diffusion models to optimize experimental likelihoods in the conditional embedding space. As this space encodes rich sequence and coevolutionary signals, optimizing over it effectively shifts the diffusion prior to align with experimental constraints. We validate EmbedOpt on two benchmarks simulating cryo-electron microscopy map fitting and experimental distance constraints. We show that EmbedOpt outperforms the coordinate-based posterior sampling method in map fitting tasks, matches performance on distance constraint tasks, and exhibits superior engineering robustness across hyperparameters spanning two orders of magnitude. Moreover, its smooth optimization behavior enables a significant reduction in the number of diffusion steps required for inference, leading to better efficiency.", "AI": {"tldr": "EmbedOpt offers a robust inference-time strategy for optimizing biomolecular conformations under experimental constraints in diffusion models, demonstrating improved efficiency and robustness.", "motivation": "The paper addresses limitations in posterior sampling for biomolecular conformations when the target lies in a prior's low-density region, requiring aggressive likelihood adjustments.", "method": "EmbedOpt optimizes experimental likelihoods in the conditional embedding space of diffusion models, effectively shifting the diffusion prior using embedding-based adjustments.", "result": "EmbedOpt surpasses posterior sampling in cryo-electron microscopy tasks, matches performance on distance constraint benchmarks, and is robust across wide-ranging hyperparameters. It also reduces the requisite diffusion steps, enhancing efficiency.", "conclusion": "EmbedOpt introduces an effective embedding-based optimization method for steering diffusion models, showing superior robustness, efficiency, and adaptability compared to traditional methods."}}
{"id": "2602.05706", "pdf": "https://arxiv.org/pdf/2602.05706", "abs": "https://arxiv.org/abs/2602.05706", "authors": ["Shadi Attarha", "Kanaga Shanmugi", "Anna F\u00f6rster"], "title": "Poster: Camera Tampering Detection for Outdoor IoT Systems", "categories": ["cs.CV", "cs.AI"], "comment": "Proceedings of the 2024 INTERNATIONAL CONFERENCE ON EMBEDDED WIRELESS SYSTEMS AND NETWORKS (EWSN)", "summary": "Recently, the use of smart cameras in outdoor settings has grown to improve surveillance and security. Nonetheless, these systems are susceptible to tampering, whether from deliberate vandalism or harsh environmental conditions, which can undermine their monitoring effectiveness. In this context, detecting camera tampering is more challenging when a camera is capturing still images rather than video as there is no sequence of continuous frames over time. In this study, we propose two approaches for detecting tampered images: a rule-based method and a deep-learning-based method. The aim is to evaluate how each method performs in terms of accuracy, computational demands, and the data required for training when applied to real-world scenarios. Our results show that the deep-learning model provides higher accuracy, while the rule-based method is more appropriate for scenarios where resources are limited and a prolonged calibration phase is impractical. We also offer publicly available datasets with normal, blurred, and rotated images to support the development and evaluation of camera tampering detection methods, addressing the need for such resources.", "AI": {"tldr": "This paper investigates camera tampering detection in still images using rule-based and deep-learning methods, providing datasets to support future research.", "motivation": "Smart cameras are increasingly used for surveillance but are prone to tampering due to vandalism or environmental conditions, especially when capturing still images.", "method": "Two approaches are proposed: a rule-based method and a deep-learning-based method, with performance evaluations based on accuracy, computational demand, and required training data.", "result": "Findings indicate that the deep-learning model outperforms in accuracy, while the rule-based method is better suited for resource-constrained conditions without extensive calibration.", "conclusion": "Both methods address specific scenarios in camera tampering detection, and publicly available datasets are provided to aid further research and evaluation."}}
{"id": "2602.05286", "pdf": "https://arxiv.org/pdf/2602.05286", "abs": "https://arxiv.org/abs/2602.05286", "authors": ["Dahai Yu", "Lin Jiang", "Rongchao Xu", "Guang Wang"], "title": "HealthMamba: An Uncertainty-aware Spatiotemporal Graph State Space Model for Effective and Reliable Healthcare Facility Visit Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Healthcare facility visit prediction is essential for optimizing healthcare resource allocation and informing public health policy. Despite advanced machine learning methods being employed for better prediction performance, existing works usually formulate this task as a time-series forecasting problem without considering the intrinsic spatial dependencies of different types of healthcare facilities, and they also fail to provide reliable predictions under abnormal situations such as public emergencies. To advance existing research, we propose HealthMamba, an uncertainty-aware spatiotemporal framework for accurate and reliable healthcare facility visit prediction. HealthMamba comprises three key components: (i) a Unified Spatiotemporal Context Encoder that fuses heterogeneous static and dynamic information, (ii) a novel Graph State Space Model called GraphMamba for hierarchical spatiotemporal modeling, and (iii) a comprehensive uncertainty quantification module integrating three uncertainty quantification mechanisms for reliable prediction. We evaluate HealthMamba on four large-scale real-world datasets from California, New York, Texas, and Florida. Results show HealthMamba achieves around 6.0% improvement in prediction accuracy and 3.5% improvement in uncertainty quantification over state-of-the-art baselines.", "AI": {"tldr": "The paper introduces HealthMamba, a spatiotemporal framework for predicting healthcare facility visits, improving prediction accuracy and reliability under normal and abnormal situations.", "motivation": "The need to optimize healthcare resource allocation and address limitations in existing prediction methods, like ignoring spatial dependencies and being unreliable in emergencies.", "method": "HealthMamba includes (i) a Spatiotemporal Context Encoder, (ii) Graph State Space Model (GraphMamba), and (iii) an uncertainty quantification module.", "result": "HealthMamba achieves a 6.0% improvement in prediction accuracy and 3.5% better uncertainty quantification compared to baselines on four real-world datasets.", "conclusion": "HealthMamba offers a more accurate and reliable framework for predicting healthcare facility visits, addressing spatial dependencies and handling uncertainties."}}
{"id": "2602.05718", "pdf": "https://arxiv.org/pdf/2602.05718", "abs": "https://arxiv.org/abs/2602.05718", "authors": ["Yunchuan Ma", "Laiyun Qing", "Guorong Li", "Yuqing Liu", "Yuankai Qi", "Qingming Huang"], "title": "Exploring the Temporal Consistency for Point-Level Weakly-Supervised Temporal Action Localization", "categories": ["cs.CV"], "comment": null, "summary": "Point-supervised Temporal Action Localization (PTAL) adopts a lightly frame-annotated paradigm (\\textit{i.e.}, labeling only a single frame per action instance) to train a model to effectively locate action instances within untrimmed videos. Most existing approaches design the task head of models with only a point-supervised snippet-level classification, without explicit modeling of understanding temporal relationships among frames of an action. However, understanding the temporal relationships of frames is crucial because it can help a model understand how an action is defined and therefore benefits localizing the full frames of an action. To this end, in this paper, we design a multi-task learning framework that fully utilizes point supervision to boost the model's temporal understanding capability for action localization. Specifically, we design three self-supervised temporal understanding tasks: (i) Action Completion, (ii) Action Order Understanding, and (iii) Action Regularity Understanding. These tasks help a model understand the temporal consistency of actions across videos. To the best of our knowledge, this is the first attempt to explicitly explore temporal consistency for point supervision action localization. Extensive experimental results on four benchmark datasets demonstrate the effectiveness of the proposed method compared to several state-of-the-art approaches.", "AI": {"tldr": "The paper proposes a multi-task learning framework to improve Point-supervised Temporal Action Localization (PTAL) by using self-supervised tasks to understand temporal relationships within actions. Significant performance gains are achieved.", "motivation": "Point-supervised Temporal Action Localization relies on sparse annotations and faces challenges in understanding temporal relationships within actions. The paper aims to address this by enhancing temporal understanding to improve localization accuracy.", "method": "A multi-task learning framework is introduced, incorporating three self-supervised tasks: Action Completion, Action Order Understanding, and Action Regularity Understanding, to explicitly model temporal consistency within actions.", "result": "The proposed method achieves superior performance on four benchmark datasets, demonstrating its effectiveness against state-of-the-art methods.", "conclusion": "Explicitly modeling temporal relationships within Point-supervised frameworks significantly enhances temporal action localization, providing an effective alternative to traditional approaches."}}
{"id": "2602.05304", "pdf": "https://arxiv.org/pdf/2602.05304", "abs": "https://arxiv.org/abs/2602.05304", "authors": ["Feng Zhu", "Robert W. Heath", "Aritra Mitra"], "title": "A Short and Unified Convergence Analysis of the SAG, SAGA, and IAG Algorithms", "categories": ["cs.LG", "eess.SY", "math.OC"], "comment": null, "summary": "Stochastic variance-reduced algorithms such as Stochastic Average Gradient (SAG) and SAGA, and their deterministic counterparts like the Incremental Aggregated Gradient (IAG) method, have been extensively studied in large-scale machine learning. Despite their popularity, existing analyses for these algorithms are disparate, relying on different proof techniques tailored to each method. Furthermore, the original proof of SAG is known to be notoriously involved, requiring computer-aided analysis. Focusing on finite-sum optimization with smooth and strongly convex objective functions, our main contribution is to develop a single unified convergence analysis that applies to all three algorithms: SAG, SAGA, and IAG. Our analysis features two key steps: (i) establishing a bound on delays due to stochastic sub-sampling using simple concentration tools, and (ii) carefully designing a novel Lyapunov function that accounts for such delays. The resulting proof is short and modular, providing the first high-probability bounds for SAG and SAGA that can be seamlessly extended to non-convex objectives and Markov sampling. As an immediate byproduct of our new analysis technique, we obtain the best known rates for the IAG algorithm, significantly improving upon prior bounds.", "AI": {"tldr": "The paper develops a unified and simplified convergence analysis for SAG, SAGA, and IAG algorithms used in machine learning optimization, offering improved theoretical guarantees.", "motivation": "Existing analyses for SAG, SAGA, and IAG are separate and challenging, with the original SAG proof requiring computer-aided processes. Simplifying and unifying the analysis is essential.", "method": "A unified convergence proof is achieved through (i) bounding delays from stochastic sub-sampling using concentration tools and (ii) a novel Lyapunov function design to account for these delays.", "result": "The analysis provides high-probability bounds for SAG and SAGA, extends applicability to non-convex objectives and Markov sampling, and significantly improves rates for the IAG algorithm.", "conclusion": "The unified proof simplifies convergence analysis for widely-used variance-reduced optimization algorithms, enhances theoretical bounds, and introduces modular and extensible proof techniques."}}
{"id": "2602.05729", "pdf": "https://arxiv.org/pdf/2602.05729", "abs": "https://arxiv.org/abs/2602.05729", "authors": ["Lexiang Hu", "Youze Xue", "Dian Li", "Gang Liu", "Zhouchen Lin"], "title": "Adaptive Global and Fine-Grained Perceptual Fusion for MLLM Embeddings Compatible with Hard Negative Amplification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal embeddings serve as a bridge for aligning vision and language, with the two primary implementations -- CLIP-based and MLLM-based embedding models -- both limited to capturing only global semantic information. Although numerous studies have focused on fine-grained understanding, we observe that complex scenarios currently targeted by MLLM embeddings often involve a hybrid perceptual pattern of both global and fine-grained elements, thus necessitating a compatible fusion mechanism. In this paper, we propose Adaptive Global and Fine-grained perceptual Fusion for MLLM Embeddings (AGFF-Embed), a method that prompts the MLLM to generate multiple embeddings focusing on different dimensions of semantic information, which are then adaptively and smoothly aggregated. Furthermore, we adapt AGFF-Embed with the Explicit Gradient Amplification (EGA) technique to achieve in-batch hard negatives enhancement without requiring fine-grained editing of the dataset. Evaluation on the MMEB and MMVP-VLM benchmarks shows that AGFF-Embed comprehensively achieves state-of-the-art performance in both general and fine-grained understanding compared to other multimodal embedding models.", "AI": {"tldr": "This paper introduces AGFF-Embed, a method for robust multimodal embeddings that adaptively fuses global and fine-grained semantic information, achieving state-of-the-art results.", "motivation": "Current multimodal embedding models like CLIP and MLLM are restricted to global semantic understanding and lack mechanisms to integrate fine-grained features, especially in complex hybrid perceptual scenarios.", "method": "The proposed AGFF-Embed method prompts MLLM to generate embeddings on multiple semantic dimensions, adaptively aggregating them. It incorporates the Explicit Gradient Amplification technique for enhancing in-batch hard negatives without dataset editing.", "result": "AGFF-Embed outperforms existing multimodal embedding models on MMEB and MMVP-VLM benchmarks in both general and fine-grained understanding.", "conclusion": "The AGFF-Embed method effectively integrates global and fine-grained perceptual elements, offering superior performance and adaptability for multimodal embedding tasks."}}
{"id": "2602.04894", "pdf": "https://arxiv.org/pdf/2602.04894", "abs": "https://arxiv.org/abs/2602.04894", "authors": ["Tomer Kordonsky", "Maayan Yamin", "Noam Benzimra", "Amit LeVi", "Avi Mendelson"], "title": "Extracting Recurring Vulnerabilities from Black-Box LLM-Generated Software", "categories": ["cs.CR", "cs.AI"], "comment": "Preprint", "summary": "LLMs are increasingly used for code generation, but their outputs often follow recurring templates that can induce predictable vulnerabilities. We study \\emph{vulnerability persistence} in LLM-generated software and introduce \\emph{Feature--Security Table (FSTab)} with two components. First, FSTab enables a black-box attack that predicts likely backend vulnerabilities from observable frontend features and knowledge of the source LLM, without access to backend code or source code. Second, FSTab provides a model-centric evaluation that quantifies how consistently a given model reproduces the same vulnerabilities across programs, semantics-preserving rephrasings, and application domains. We evaluate FSTab on state-of-the-art code LLMs, including GPT-5.2, Claude-4.5 Opus, and Gemini-3 Pro, across diverse application domains. Our results show strong cross-domain transfer: even when the target domain is excluded from training, FSTab achieves up to 94\\% attack success and 93\\% vulnerability coverage on Internal Tools (Claude-4.5 Opus). These findings expose an underexplored attack surface in LLM-generated software and highlight the security risks of code generation. Our code is available at: https://anonymous.4open.science/r/FSTab-024E.", "AI": {"tldr": "The paper introduces 'Feature--Security Table (FSTab)', a framework for analyzing and predicting vulnerabilities in LLM-generated software, demonstrating high attack success and security risks.", "motivation": "Explore the recurring vulnerabilities in software generated by Large Language Models (LLMs) due to their predictable templates.", "method": "FSTab provides: 1. A black-box attack methodology predicting backend vulnerabilities using frontend features and LLM knowledge. 2. A model-centric evaluation for quantifying consistency in reproducing vulnerabilities.", "result": "Evaluations on state-of-the-art LLMs across domains show strong cross-domain vulnerability persistence, with up to 94% attack success and 93% coverage on certain models.", "conclusion": "LLM-generated software exhibits significant security risks due to reproducible vulnerabilities, emphasizing the need for deeper investigations into LLM code generation security."}}
{"id": "2602.05730", "pdf": "https://arxiv.org/pdf/2602.05730", "abs": "https://arxiv.org/abs/2602.05730", "authors": ["Moussa Kassem Sbeyti", "Nadja Klein"], "title": "Depth as Prior Knowledge for Object Detection", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Detecting small and distant objects remains challenging for object detectors due to scale variation, low resolution, and background clutter. Safety-critical applications require reliable detection of these objects for safe planning. Depth information can improve detection, but existing approaches require complex, model-specific architectural modifications. We provide a theoretical analysis followed by an empirical investigation of the depth-detection relationship. Together, they explain how depth causes systematic performance degradation and why depth-informed supervision mitigates it. We introduce DepthPrior, a framework that uses depth as prior knowledge rather than as a fused feature, providing comparable benefits without modifying detector architectures. DepthPrior consists of Depth-Based Loss Weighting (DLW) and Depth-Based Loss Stratification (DLS) during training, and Depth-Aware Confidence Thresholding (DCT) during inference. The only overhead is the initial cost of depth estimation. Experiments across four benchmarks (KITTI, MS COCO, VisDrone, SUN RGB-D) and two detectors (YOLOv11, EfficientDet) demonstrate the effectiveness of DepthPrior, achieving up to +9% mAP$_S$ and +7% mAR$_S$ for small objects, with inference recovery rates as high as 95:1 (true vs. false detections). DepthPrior offers these benefits without additional sensors, architectural changes, or performance costs. Code is available at https://github.com/mos-ks/DepthPrior.", "AI": {"tldr": "This paper introduces DepthPrior, a framework improving object detection of small and distant objects using depth information without requiring architectural changes.", "motivation": "To address challenges in detecting small and distant objects, such as scale variation and background clutter, which are essential for safety-critical applications.", "method": "Proposes DepthPrior, enabling depth-informed supervision with modules like Depth-Based Loss Weighting (DLW), Loss Stratification (DLS), and Depth-Aware Confidence Thresholding (DCT).", "result": "Achieves up to +9% mAP_S and +7% mAR_S for small objects across four benchmarks. DepthPrior enhances detection efficiency without altering detection architectures.", "conclusion": "DepthPrior effectively leverages depth for improved detection, requires no additional sensor or architecture modifications, and demonstrates consistent gains in performance for small objects."}}
{"id": "2602.04896", "pdf": "https://arxiv.org/pdf/2602.04896", "abs": "https://arxiv.org/abs/2602.04896", "authors": ["Chen Xiong", "Zhiyuan He", "Pin-Yu Chen", "Ching-Yun Ko", "Tsung-Yi Ho"], "title": "Steering Externalities: Benign Activation Steering Unintentionally Increases Jailbreak Risk for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Activation steering is a practical post-training model alignment technique to enhance the utility of Large Language Models (LLMs). Prior to deploying a model as a service, developers can steer a pre-trained model toward specific behavioral objectives, such as compliance or instruction adherence, without the need for retraining. This process is as simple as adding a steering vector to the model's internal representations. However, this capability unintentionally introduces critical and under-explored safety risks. We identify a phenomenon termed Steering Externalities, where steering vectors derived from entirely benign datasets-such as those enforcing strict compliance or specific output formats like JSON-inadvertently erode safety guardrails. Experiments reveal that these interventions act as a force multiplier, creating new vulnerabilities to jailbreaks and increasing attack success rates to over 80% on standard benchmarks by bypassing the initial safety alignment. Ultimately, our results expose a critical blind spot in deployment: benign activation steering systematically erodes the \"safety margin,\" rendering models more vulnerable to black-box attacks and proving that inference-time utility improvements must be rigorously audited for unintended safety externalities.", "AI": {"tldr": "Activation steering in LLMs enhances model behavior but introduces overlooked safety risks by eroding safety guardrails.", "motivation": "The authors aim to explore effective ways to improve LLM utility, particularly through activation steering, while uncovering potential safety challenges that arise from this approach.", "method": "They analyze activation steering as a method to adjust LLM behavior by adding steering vectors to internal representations, and assess its impact on safety through experiments involving jailbreak and attack benchmarks.", "result": "The study shows activation steering unintentionally undermines safety features, increasing attack success rates to over 80% and making models more vulnerable to black-box attacks.", "conclusion": "Activation steering, while useful for behavior alignment, must undergo rigorous safety audits to prevent unintended security vulnerabilities during deployment."}}
{"id": "2602.05319", "pdf": "https://arxiv.org/pdf/2602.05319", "abs": "https://arxiv.org/abs/2602.05319", "authors": ["Yinan Huang", "Hans Hao-Hsun Hsu", "Junran Wang", "Bo Dai", "Pan Li"], "title": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "categories": ["cs.LG"], "comment": null, "summary": "Sequential prediction from streaming observations is a fundamental problem in stochastic dynamical systems, where inherent uncertainty often leads to multiple plausible futures. While diffusion and flow-matching models are capable of modeling complex, multi-modal trajectories, their deployment in real-time streaming environments typically relies on repeated sampling from a non-informative initial distribution, incurring substantial inference latency and potential system backlogs. In this work, we introduce Sequential Flow Matching, a principled framework grounded in Bayesian filtering. By treating streaming inference as learning a probability flow that transports the predictive distribution from one time step to the next, our approach naturally aligns with the recursive structure of Bayesian belief updates. We provide theoretical justification that initializing generation from the previous posterior offers a principled warm start that can accelerate sampling compared to na\u00efve re-sampling. Across a wide range of forecasting, decision-making and state estimation tasks, our method achieves performance competitive with full-step diffusion while requiring only one or very few sampling steps, therefore with faster sampling. It suggests that framing sequential inference via Bayesian filtering provides a new and principled perspective towards efficient real-time deployment of flow-based models.", "AI": {"tldr": "The paper introduces the Sequential Flow Matching framework for faster and more efficient real-time sequential prediction by leveraging Bayesian filtering to reduce sampling steps.", "motivation": "Sequential prediction in streaming environments faces challenges due to uncertainty and high computational latency caused by repeated sampling from non-informative distributions.", "method": "The proposed Sequential Flow Matching framework utilizes Bayesian filtering, treating inference as learning a probability flow that transitions predictive distributions between time steps, and employs posterior initialization for accelerated sampling.", "result": "The approach achieves competitive performance with standard diffusion models while significantly reducing sampling steps, resulting in faster real-time forecasting, decision-making, and state estimation.", "conclusion": "Applying Bayesian filtering to sequential inference offers a principled and efficient way to deploy flow-based models in real-time environments."}}
{"id": "2602.05366", "pdf": "https://arxiv.org/pdf/2602.05366", "abs": "https://arxiv.org/abs/2602.05366", "authors": ["Yichen Tang", "Weihang Su", "Yiqun Liu", "Qingyao Ai"], "title": "Multi-Field Tool Retrieval", "categories": ["cs.IR", "cs.CL"], "comment": "12 pages, 4 figures", "summary": "Integrating external tools enables Large Language Models (LLMs) to interact with real-world environments and solve complex tasks. Given the growing scale of available tools, effective tool retrieval is essential to mitigate constraints of LLMs' context windows and ensure computational efficiency. Existing approaches typically treat tool retrieval as a traditional ad-hoc retrieval task, matching user queries against the entire raw tool documentation. In this paper, we identify three fundamental challenges that limit the effectiveness of this paradigm: (i) the incompleteness and structural inconsistency of tool documentation; (ii) the significant semantic and granular mismatch between user queries and technical tool documents; and, most importantly, (iii) the multi-aspect nature of tool utility, that involves distinct dimensions, such as functionality, input constraints, and output formats, varying in format and importance. To address these challenges, we introduce Multi-Field Tool Retrieval, a framework designed to align user intent with tool representations through fine-grained, multi-field modeling. Experimental results show that our framework achieves SOTA performance on five datasets and a mixed benchmark, exhibiting superior generalizability and robustness.", "AI": {"tldr": "The paper introduces a Multi-Field Tool Retrieval framework to improve tool retrieval for large language models, addressing challenges like documentation issues and user-query mismatches.", "motivation": "The motivation is to solve challenges in large language model (LLM) tool retrieval, such as incomplete documentation, mismatches between user queries and technical documents, and the multi-aspect nature of tools.", "method": "The authors propose Multi-Field Tool Retrieval, a fine-grained framework that models tools across diverse fields to better align with user intent and tool utility.", "result": "The framework achieves state-of-the-art performance on five datasets and a mixed benchmark, showing strong generalizability and robustness.", "conclusion": "The new framework enhances LLMs' ability to interact with tools efficiently, overcoming existing limitations in tool retrieval while achieving superior performance."}}
{"id": "2602.04898", "pdf": "https://arxiv.org/pdf/2602.04898", "abs": "https://arxiv.org/abs/2602.04898", "authors": ["Tianxin Chen", "Wenbo Jiang", "Hongqiao Chen", "Zhirun Zheng", "Cheng Huang"], "title": "Semantic-level Backdoor Attack against Text-to-Image Diffusion Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Text-to-image (T2I) diffusion models are widely adopted for their strong generative capabilities, yet remain vulnerable to backdoor attacks. Existing attacks typically rely on fixed textual triggers and single-entity backdoor targets, making them highly susceptible to enumeration-based input defenses and attention-consistency detection. In this work, we propose Semantic-level Backdoor Attack (SemBD), which implants backdoors at the representation level by defining triggers as continuous semantic regions rather than discrete textual patterns. Concretely, SemBD injects semantic backdoors by distillation-based editing of the key and value projection matrices in cross-attention layers, enabling diverse prompts with identical semantic compositions to reliably activate the backdoor attack. To further enhance stealthiness, SemBD incorporates a semantic regularization to prevent unintended activation under incomplete semantics, as well as multi-entity backdoor targets that avoid highly consistent cross-attention patterns. Extensive experiments demonstrate that SemBD achieves a 100% attack success rate while maintaining strong robustness against state-of-the-art input-level defenses.", "AI": {"tldr": "The paper discusses 'Semantic-level Backdoor Attack (SemBD)' on text-to-image diffusion models, introducing a more stealthy and effective adversarial attack mechanism.", "motivation": "The motivation is to address vulnerabilities in existing backdoor attacks which rely on fixed textual triggers and are easily detectable by input-level defenses, thereby improving the efficacy and stealthiness of such attack mechanisms.", "method": "The authors propose injecting semantic backdoors through editing key and value projection matrices in cross-attention layers, leveraging continuous semantic triggers and employing semantic regularization to prevent unintended activations.", "result": "SemBD achieves a 100% attack success rate and demonstrates strong resistance against state-of-the-art input-level defenses.", "conclusion": "The paper concludes that SemBD provides a significantly more robust and stealthy approach to backdoor attacks on T2I models, highlighting its potential implications for security in generative AI systems."}}
{"id": "2602.05323", "pdf": "https://arxiv.org/pdf/2602.05323", "abs": "https://arxiv.org/abs/2602.05323", "authors": ["Zifan Liu", "Xinran Li", "Shibo Chen", "Jun Zhang"], "title": "GAS: Enhancing Reward-Cost Balance of Generative Model-assisted Offline Safe RL", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline Safe Reinforcement Learning (OSRL) aims to learn a policy to achieve high performance in sequential decision-making while satisfying constraints, using only pre-collected datasets. Recent works, inspired by the strong capabilities of Generative Models (GMs), reformulate decision-making in OSRL as a conditional generative process, where GMs generate desirable actions conditioned on predefined reward and cost values. However, GM-assisted methods face two major challenges in OSRL: (1) lacking the ability to \"stitch\" optimal transitions from suboptimal trajectories within the dataset, and (2) struggling to balance reward targets with cost targets, particularly when they are conflict. To address these issues, we propose Goal-Assisted Stitching (GAS), a novel algorithm designed to enhance stitching capabilities while effectively balancing reward maximization and constraint satisfaction. To enhance the stitching ability, GAS first augments and relabels the dataset at the transition level, enabling the construction of high-quality trajectories from suboptimal ones. GAS also introduces novel goal functions, which estimate the optimal achievable reward and cost goals from the dataset. These goal functions, trained using expectile regression on the relabeled and augmented dataset, allow GAS to accommodate a broader range of reward-cost return pairs and achieve a better tradeoff between reward maximization and constraint satisfaction compared to human-specified values. The estimated goals then guide policy training, ensuring robust performance under constrained settings. Furthermore, to improve training stability and efficiency, we reshape the dataset to achieve a more uniform reward-cost return distribution. Empirical results validate the effectiveness of GAS, demonstrating superior performance in balancing reward maximization and constraint satisfaction compared to existing methods.", "AI": {"tldr": "GAS enhances offline safe reinforcement learning (OSRL) by improving trajectory stitching and balancing reward-cost constraints using augmented datasets and novel goal functions.", "motivation": "To address the limitations of GM-assisted methods in OSRL, specifically the challenges of stitching suboptimal trajectories and balancing conflicting reward and cost targets.", "method": "GAS uses dataset augmentation, relabeling transitions, and training goal functions with expectile regression to improve stitching ability and achieve better reward-cost tradeoffs.", "result": "Empirical results show GAS outperforms existing methods in balancing reward maximization and constraint satisfaction under OSRL.", "conclusion": "The proposed GAS algorithm significantly enhances policy performance in OSRL, making it more robust and effective in constrained decision-making tasks using pre-collected datasets."}}
{"id": "2602.05755", "pdf": "https://arxiv.org/pdf/2602.05755", "abs": "https://arxiv.org/abs/2602.05755", "authors": ["Ti Wang", "Xiaohang Yu", "Mackenzie Weygandt Mathis"], "title": "FMPose3D: monocular 3D pose estimation via flow matching", "categories": ["cs.CV"], "comment": null, "summary": "Monocular 3D pose estimation is fundamentally ill-posed due to depth ambiguity and occlusions, thereby motivating probabilistic methods that generate multiple plausible 3D pose hypotheses. In particular, diffusion-based models have recently demonstrated strong performance, but their iterative denoising process typically requires many timesteps for each prediction, making inference computationally expensive. In contrast, we leverage Flow Matching (FM) to learn a velocity field defined by an Ordinary Differential Equation (ODE), enabling efficient generation of 3D pose samples with only a few integration steps. We propose a novel generative pose estimation framework, FMPose3D, that formulates 3D pose estimation as a conditional distribution transport problem. It continuously transports samples from a standard Gaussian prior to the distribution of plausible 3D poses conditioned only on 2D inputs. Although ODE trajectories are deterministic, FMPose3D naturally generates various pose hypotheses by sampling different noise seeds. To obtain a single accurate prediction from those hypotheses, we further introduce a Reprojection-based Posterior Expectation Aggregation (RPEA) module, which approximates the Bayesian posterior expectation over 3D hypotheses. FMPose3D surpasses existing methods on the widely used human pose estimation benchmarks Human3.6M and MPI-INF-3DHP, and further achieves state-of-the-art performance on the 3D animal pose datasets Animal3D and CtrlAni3D, demonstrating strong performance across both 3D pose domains. The code is available at https://github.com/AdaptiveMotorControlLab/FMPose3D.", "AI": {"tldr": "The paper introduces a new framework, FMPose3D, which uses Flow Matching (FM) for efficient monocular 3D pose estimation. It offers computational advantages and state-of-the-art performance across human and animal pose datasets.", "motivation": "The motivation is to address the challenges of monocular 3D pose estimation, which suffers from depth ambiguity and occlusions. This led to exploring efficient probabilistic methods to generate multiple plausible 3D pose hypotheses.", "method": "The authors propose FMPose3D, a framework that uses Flow Matching (FM) to define a velocity field through an ODE. This efficiently transports Gaussian prior samples to plausible 3D poses conditioned on 2D input. It also incorporates a posterior aggregation module (RPEA) to refine predictions.", "result": "Experimental results show that FMPose3D achieves state-of-the-art performance on widely used human and animal 3D pose estimation benchmarks such as Human3.6M, MPI-INF-3DHP, Animal3D, and CtrlAni3D.", "conclusion": "FMPose3D is an efficient and generative framework for monocular 3D pose estimation, outperforming existing methods while being computationally more efficient. This work contributes significantly to both human and animal 3D pose estimation areas."}}
{"id": "2602.04899", "pdf": "https://arxiv.org/pdf/2602.04899", "abs": "https://arxiv.org/abs/2602.04899", "authors": ["Andrew Draganov", "Tolga H. Dur", "Anandmayi Bhongade", "Mary Phuong"], "title": "Phantom Transfer: Data-level Defences are Insufficient Against Data Poisoning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "We present a data poisoning attack -- Phantom Transfer -- with the property that, even if you know precisely how the poison was placed into an otherwise benign dataset, you cannot filter it out. We achieve this by modifying subliminal learning to work in real-world contexts and demonstrate that the attack works across models, including GPT-4.1. Indeed, even fully paraphrasing every sample in the dataset using a different model does not stop the attack. We also discuss connections to steering vectors and show that one can plant password-triggered behaviours into models while still beating defences.\n  This suggests that data-level defences are insufficient for stopping sophisticated data poisoning attacks. We suggest that future work should focus on model audits and white-box security methods.", "AI": {"tldr": "The paper introduces a powerful data poisoning attack named Phantom Transfer that remains undetectable even if the attack method is known. It works across models, including state-of-the-art ones like GPT-4.1.", "motivation": "To highlight limitations of current data-level defenses and emphasize the need for stronger methods to counter advanced data poisoning attacks.", "method": "The authors modify subliminal learning for practical applications and plant undetectable triggers in models using password-like behaviors to prove the attack\u2019s potency.", "result": "They demonstrate the attack's effectiveness across various models and contexts, while showing that common defenses such as dataset paraphrasing fail against it.", "conclusion": "Data-level defenses are insufficient to stop sophisticated attacks like Phantom Transfer, urging future research towards model audits and white-box security techniques."}}
{"id": "2602.05333", "pdf": "https://arxiv.org/pdf/2602.05333", "abs": "https://arxiv.org/abs/2602.05333", "authors": ["Kosuke Sugiyama", "Masato Uchida"], "title": "Pool-based Active Learning as Noisy Lossy Compression: Characterizing Label Complexity via Finite Blocklength Analysis", "categories": ["cs.LG", "cs.IT"], "comment": "21 pages, 1 figure", "summary": "This paper proposes an information-theoretic framework for analyzing the theoretical limits of pool-based active learning (AL), in which a subset of instances is selectively labeled. The proposed framework reformulates pool-based AL as a noisy lossy compression problem by mapping pool observations to noisy symbol observations, data selection to compression, and learning to decoding. This correspondence enables a unified information-theoretic analysis of data selection and learning in pool-based AL. Applying finite blocklength analysis of noisy lossy compression, we derive information-theoretic lower bounds on label complexity and generalization error that serve as theoretical limits for a given learning algorithm under its associated optimal data selection strategy. Specifically, our bounds include terms that reflect overfitting induced by the learning algorithm and the discrepancy between its inductive bias and the target task, and are closely related to established information-theoretic bounds and stability theory, which have not been previously applied to the analysis of pool-based AL. These properties yield a new theoretical perspective on pool-based AL.", "AI": {"tldr": "This paper establishes theoretical limits for pool-based active learning (AL) using an information-theoretic framework, addressing label complexity and generalization error.", "motivation": "To understand and quantify the theoretical limits of pool-based active learning by linking it to information-theoretic analysis, providing insights into selection and learning processes.", "method": "The paper reformulates pool-based active learning as a noisy lossy compression problem, enabling analysis through finite blocklength principles. It derives bounds for label complexity and generalization error by analyzing overfitting and inductive bias discrepancies.", "result": "The derived bounds include terms capturing overfitting effects and the mismatch of inductive bias with the target task, offering theoretical insights into pool-based AL within an information-theoretic scope.", "conclusion": "This framework introduces a unified information-theoretic analysis for pool-based AL, offering deeper understanding and connecting it with established theories of stability and error bounds."}}
{"id": "2602.05413", "pdf": "https://arxiv.org/pdf/2602.05413", "abs": "https://arxiv.org/abs/2602.05413", "authors": ["Filip Ku\u010dera", "Christoph Mandl", "Isao Echizen", "Radu Timofte", "Timo Spinde"], "title": "SciDef: Automating Definition Extraction from Academic Literature with Large Language Models", "categories": ["cs.IR", "cs.CL"], "comment": "Under Review - Submitted to SIGIR 2026 Resources Track; 8 pages, 6 figures, 4 tables", "summary": "Definitions are the foundation for any scientific work, but with a significant increase in publication numbers, gathering definitions relevant to any keyword has become challenging. We therefore introduce SciDef, an LLM-based pipeline for automated definition extraction. We test SciDef on DefExtra & DefSim, novel datasets of human-extracted definitions and definition-pairs' similarity, respectively. Evaluating 16 language models across prompting strategies, we demonstrate that multi-step and DSPy-optimized prompting improve extraction performance. To evaluate extraction, we test various metrics and show that an NLI-based method yields the most reliable results. We show that LLMs are largely able to extract definitions from scientific literature (86.4% of definitions from our test-set); yet future work should focus not just on finding definitions, but on identifying relevant ones, as models tend to over-generate them.\n  Code & datasets are available at https://github.com/Media-Bias-Group/SciDef.", "AI": {"tldr": "This paper introduces SciDef, an LLM-based pipeline and datasets for extracting definitions from scientific texts. It evaluates language models and metrics, finding that multi-step prompting and NLI-based evaluation improve results.", "motivation": "The significant increase in scientific publications has made it challenging to gather definitions relevant to specific keywords.", "method": "The authors introduce SciDef, evaluate 16 language models using various prompting strategies, and propose an NLI-based evaluation metric. They test their method using DefExtra and DefSim datasets.", "result": "They achieve an 86.4% success rate in extracting definitions from the test-set and find that multi-step and optimized prompting improve performance.", "conclusion": "While LLMs effectively extract definitions, future work should focus on identifying the most relevant definitions rather than over-generating them."}}
{"id": "2602.05785", "pdf": "https://arxiv.org/pdf/2602.05785", "abs": "https://arxiv.org/abs/2602.05785", "authors": ["Timur Mamedov", "Karina Kvanchiani", "Anton Konushin", "Vadim Konushin"], "title": "ReText: Text Boosts Generalization in Image-Based Person Re-identification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Generalizable image-based person re-identification (Re-ID) aims to recognize individuals across cameras in unseen domains without retraining. While multiple existing approaches address the domain gap through complex architectures, recent findings indicate that better generalization can be achieved by stylistically diverse single-camera data. Although this data is easy to collect, it lacks complexity due to minimal cross-view variation. We propose ReText, a novel method trained on a mixture of multi-camera Re-ID data and single-camera data, where the latter is complemented by textual descriptions to enrich semantic cues. During training, ReText jointly optimizes three tasks: (1) Re-ID on multi-camera data, (2) image-text matching, and (3) image reconstruction guided by text on single-camera data. Experiments demonstrate that ReText achieves strong generalization and significantly outperforms state-of-the-art methods on cross-domain Re-ID benchmarks. To the best of our knowledge, this is the first work to explore multimodal joint learning on a mixture of multi-camera and single-camera data in image-based person Re-ID.", "AI": {"tldr": "ReText, a multimodal method using multi-camera and single-camera data enriched with textual descriptions, achieves superior cross-domain person re-identification.", "motivation": "Address generalizable image-based person Re-ID across unseen domains without retraining, especially dealing with single-camera data limitations.", "method": "The method trains on multi-camera and single-camera Re-ID data, optimizing Re-ID, image-text matching, and text-guided image reconstruction tasks.", "result": "ReText surpasses state-of-the-art methods in cross-domain Re-ID benchmarks and demonstrates strong generalization capability.", "conclusion": "This paper introduces a unique multimodal approach combining multi-camera and single-camera data for better generalizable person Re-ID, opening new avenues in domain adaptation."}}
{"id": "2602.05352", "pdf": "https://arxiv.org/pdf/2602.05352", "abs": "https://arxiv.org/abs/2602.05352", "authors": ["Edward Berman", "Luisa Li", "Jung Yeon Park", "Robin Walters"], "title": "Smoothness Errors in Dynamics Models and How to Avoid Them", "categories": ["cs.LG", "math.SG"], "comment": "Ecstatic to share relaxed unitary mesh convolutions with the community :D! Work is under review at ICML 2026. First two authors contributed equally", "summary": "Modern neural networks have shown promise for solving partial differential equations over surfaces, often by discretizing the surface as a mesh and learning with a mesh-aware graph neural network. However, graph neural networks suffer from oversmoothing, where a node's features become increasingly similar to those of its neighbors. Unitary graph convolutions, which are mathematically constrained to preserve smoothness, have been proposed to address this issue. Despite this, in many physical systems, such as diffusion processes, smoothness naturally increases and unitarity may be overconstraining. In this paper, we systematically study the smoothing effects of different GNNs for dynamics modeling and prove that unitary convolutions hurt performance for such tasks. We propose relaxed unitary convolutions that balance smoothness preservation with the natural smoothing required for physical systems. We also generalize unitary and relaxed unitary convolutions from graphs to meshes. In experiments on PDEs such as the heat and wave equations over complex meshes and on weather forecasting, we find that our method outperforms several strong baselines, including mesh-aware transformers and equivariant neural networks.", "AI": {"tldr": "The paper proposes relaxed unitary convolutions to overcome oversmoothing issues in graph neural networks, enhancing performance for solving PDEs on meshes and physical systems.", "motivation": "Addressing oversmoothing issues in graph neural networks, particularly for dynamics modeling in PDEs and physical systems where smoothness increases naturally.", "method": "The paper introduces relaxed unitary convolutions, balancing smoothness preservation and the required smoothing for physics, and generalizes the method from graphs to meshes.", "result": "The proposed method outperformed strong baselines like mesh-aware transformers and equivariant neural networks on tasks like PDEs over complex meshes and weather forecasting.", "conclusion": "Relaxed unitary convolutions offer a better balance for physical smoothing processes and improve GNN performance in practical applications."}}
{"id": "2602.05789", "pdf": "https://arxiv.org/pdf/2602.05789", "abs": "https://arxiv.org/abs/2602.05789", "authors": ["Hengyi Wang", "Ruiqiang Zhang", "Chang Liu", "Guanjie Wang", "Zehua Ma", "Han Fang", "Weiming Zhang"], "title": "Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rising need for spatially grounded tasks such as Vision-Language Navigation/Action, allocentric perception capabilities in Vision-Language Models (VLMs) are receiving growing focus. However, VLMs remain brittle on allocentric spatial queries that require explicit perspective shifts, where the answer depends on reasoning in a target-centric frame rather than the observed camera view. Thus, we introduce Allocentric Perceiver, a training-free strategy that recovers metric 3D states from one or more images with off-the-shelf geometric experts, and then instantiates a query-conditioned allocentric reference frame aligned with the instruction's semantic intent. By deterministically transforming reconstructed geometry into the target frame and prompting the backbone VLM with structured, geometry-grounded representations, Allocentric Perceriver offloads mental rotation from implicit reasoning to explicit computation. We evaluate Allocentric Perciver across multiple backbone families on spatial reasoning benchmarks, observing consistent and substantial gains ($\\sim$10%) on allocentric tasks while maintaining strong egocentric performance, and surpassing both spatial-perception-finetuned models and state-of-the-art open-source and proprietary models.", "AI": {"tldr": "The paper introduces Allocentric Perceiver, a strategy for improving spatial reasoning of Vision-Language Models (VLMs) through explicit computation of allocentric references without additional training.", "motivation": "Vision-Language Models (VLMs) struggle with allocentric spatial reasoning, which requires perspective shifts beyond the egocentric camera view.", "method": "Allocentric Perceiver deterministically transforms geometric data into allocentric frames based on query intent, using off-the-shelf 3D reconstruction tools and structured prompts.", "result": "It achieves a consistent improvement (~10%) on allocentric spatial reasoning tasks with various VLM backbones, outperforming specialized and state-of-the-art models.", "conclusion": "Explicit geometric computation for spatial reasoning can significantly enhance allocentric task performance in VLMs, showing promise for complex grounded tasks."}}
{"id": "2602.05358", "pdf": "https://arxiv.org/pdf/2602.05358", "abs": "https://arxiv.org/abs/2602.05358", "authors": ["Paribesh Regmi", "Rui Li", "Kishan K C"], "title": "Bayesian Neighborhood Adaptation for Graph Neural Networks", "categories": ["cs.LG"], "comment": "Published in Transactions on Machine Learning Research (TMLR), 07/2025", "summary": "The neighborhood scope (i.e., number of hops) where graph neural networks (GNNs) aggregate information to characterize a node's statistical property is critical to GNNs' performance. Two-stage approaches, training and validating GNNs for every pre-specified neighborhood scope to search for the best setting, is a time-consuming task and tends to be biased due to the search space design. How to adaptively determine proper neighborhood scopes for the aggregation process for both homophilic and heterophilic graphs remains largely unexplored. We thus propose to model the GNNs' message-passing behavior on a graph as a stochastic process by treating the number of hops as a beta process. This Bayesian framework allows us to infer the most plausible neighborhood scope for message aggregation simultaneously with the optimization of GNN parameters. Our theoretical analysis shows that the scope inference improves the expressivity of a GNN. Experiments on benchmark homophilic and heterophilic datasets show that the proposed method is compatible with state-of-the-art GNN variants, achieving competitive or superior performance on the node classification task, and providing well-calibrated predictions.", "AI": {"tldr": "The study proposes a Bayesian framework to adaptively determine the optimal neighborhood scope in graph neural networks (GNNs) for effective message aggregation.", "motivation": "To address the challenge of determining the proper neighborhood scope for GNNs in both homophilic and heterophilic graphs, avoiding the bias and inefficiencies of two-stage approaches.", "method": "The researchers model message-passing in GNNs as a stochastic process using a beta process, which allows simultaneous inference of neighborhood scope and parameter optimization.", "result": "The theoretical analysis shows improved GNN expressivity due to scope inference. Experiments on benchmark datasets demonstrate competitive or superior node classification performance and well-calibrated prediction capabilities.", "conclusion": "Adapting neighborhood scopes via a Bayesian framework enhances GNN performance, expressivity, and prediction reliability across different graph types."}}
{"id": "2602.05809", "pdf": "https://arxiv.org/pdf/2602.05809", "abs": "https://arxiv.org/abs/2602.05809", "authors": ["Enwei Tong", "Yuanchao Bai", "Yao Zhu", "Junjun Jiang", "Xianming Liu"], "title": "Focus-Scan-Refine: From Human Visual Perception to Efficient Visual Token Pruning", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) often generate massive visual tokens that greatly increase inference latency and memory footprint; while training-free token pruning offers a practical remedy, existing methods still struggle to balance local evidence and global context under aggressive compression. We propose Focus-Scan-Refine (FSR), a human-inspired, plug-and-play pruning framework that mimics how humans answer visual questions: focus on key evidence, then scan globally if needed, and refine the scanned context by aggregating relevant details. FSR first focuses on key evidence by combining visual importance with instruction relevance, avoiding the bias toward visually salient but query-irrelevant regions. It then scans for complementary context conditioned on the focused set, selecting tokens that are most different from the focused evidence. Finally, FSR refines the scanned context by aggregating nearby informative tokens into the scan anchors via similarity-based assignment and score-weighted merging, without increasing the token budget. Extensive experiments across multiple VLM backbones and vision-language benchmarks show that FSR consistently improves the accuracy-efficiency trade-off over existing state-of-the-art pruning methods. The source codes can be found at https://github.com/ILOT-code/FSR", "AI": {"tldr": "This paper introduces a new pruning framework, FSR, aiming to reduce inference latency and memory usage in Vision-Language Models (VLMs), while improving the balance between local and global contexts.", "motivation": "Existing training-free token pruning methods struggle to effectively balance evidence from both local and global perspectives under aggressive compression.", "method": "FSR is a plug-and-play framework inspired by human problem-solving, focusing on key evidence, scanning globally for complementary context, and refining through similarity-based aggregation.", "result": "FSR improves accuracy and efficiency trade-offs compared to state-of-the-art pruning methods when applied to multiple VLM backbones and benchmarks.", "conclusion": "FSR offers a practical and effective solution for token pruning in VLMs, enhancing performance while reducing resource consumption."}}
{"id": "2602.05371", "pdf": "https://arxiv.org/pdf/2602.05371", "abs": "https://arxiv.org/abs/2602.05371", "authors": ["Hongyi Li", "Han Lin", "Jun Xu"], "title": "Hinge Regression Tree: A Newton Method for Oblique Regression Tree Splitting", "categories": ["cs.LG"], "comment": null, "summary": "Oblique decision trees combine the transparency of trees with the power of multivariate decision boundaries, but learning high-quality oblique splits is NP-hard, and practical methods still rely on slow search or theory-free heuristics. We present the Hinge Regression Tree (HRT), which reframes each split as a non-linear least-squares problem over two linear predictors whose max/min envelope induces ReLU-like expressive power. The resulting alternating fitting procedure is exactly equivalent to a damped Newton (Gauss-Newton) method within fixed partitions. We analyze this node-level optimization and, for a backtracking line-search variant, prove that the local objective decreases monotonically and converges; in practice, both fixed and adaptive damping yield fast, stable convergence and can be combined with optional ridge regularization. We further prove that HRT's model class is a universal approximator with an explicit $O(\u03b4^2)$ approximation rate, and show on synthetic and real-world benchmarks that it matches or outperforms single-tree baselines with more compact structures.", "AI": {"tldr": "The paper introduces Hinge Regression Tree (HRT), an efficient framework for constructing oblique decision trees to achieve strong performance and compact structures for decision boundaries.", "motivation": "Oblique decision trees offer transparency and powerful multivariate boundaries but are limited by the computational challenges in learning effective oblique splits. Current approaches rely on inefficient or heuristic-based methods.", "method": "The Hinge Regression Tree reframes splits as a non-linear least-squares problem employing alternating fitting procedures that mimic a damped Newton method. It ensures monotonic objective decreases and is combined with optional ridge regularization for stability and efficiency.", "result": "The HRT method exhibits fast and stable convergence, and theoretical analysis confirms it as a universal approximator with a specific approximation rate of $O(\u03b4^2)$. Experiments on synthetic and real-world benchmarks demonstrate its superiority in accuracy, compactness, and efficiency compared to traditional baselines.", "conclusion": "HRT provides a robust alternative for building oblique decision trees, successfully balancing interpretability, accuracy, and computational efficiency."}}
{"id": "2602.05536", "pdf": "https://arxiv.org/pdf/2602.05536", "abs": "https://arxiv.org/abs/2602.05536", "authors": ["Yayuan Li", "Ze Peng", "Jian Zhang", "Jintao Guo", "Yue Duan", "Yinghuan Shi"], "title": "When Shared Knowledge Hurts: Spectral Over-Accumulation in Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Model merging combines multiple fine-tuned models into a single model by adding their weight updates, providing a lightweight alternative to retraining. Existing methods primarily target resolving conflicts between task updates, leaving the failure mode of over-counting shared knowledge unaddressed. We show that when tasks share aligned spectral directions (i.e., overlapping singular vectors), a simple linear combination repeatedly accumulates these directions, inflating the singular values and biasing the merged model toward shared subspaces. To mitigate this issue, we propose Singular Value Calibration (SVC), a training-free and data-free post-processing method that quantifies subspace overlap and rescales inflated singular values to restore a balanced spectrum. Across vision and language benchmarks, SVC consistently improves strong merging baselines and achieves state-of-the-art performance. Furthermore, by modifying only the singular values, SVC improves the performance of Task Arithmetic by 13.0%. Code is available at: https://github.com/lyymuwu/SVC.", "AI": {"tldr": "The paper introduces Singular Value Calibration (SVC), a method to address over-counting shared knowledge in model weight merging by rescaling inflated singular values, improving model performance across benchmarks.", "motivation": "The study aims to resolve the overlooked challenge of over-counting shared spectral directions when merging weights of models fine-tuned for different tasks.", "method": "Singular Value Calibration (SVC) is proposed as a training-free, data-free post-processing technique that rescales singular values by quantifying subspace overlaps to restore a balanced spectrum.", "result": "SVC consistently enhanced baselines in vision and language tasks, achieving state-of-the-art performance and improving Task Arithmetic by 13.0%.", "conclusion": "SVC effectively mitigates the over-accumulation in singular values during model merging, offering a lightweight solution for balanced and enhanced model performance."}}
{"id": "2602.05822", "pdf": "https://arxiv.org/pdf/2602.05822", "abs": "https://arxiv.org/abs/2602.05822", "authors": ["Musawar Ali", "Manuel Carranza-Garc\u00eda", "Nicola Fioraio", "Samuele Salti", "Luigi Di Stefano"], "title": "NVS-HO: A Benchmark for Novel View Synthesis of Handheld Objects", "categories": ["cs.CV"], "comment": null, "summary": "We propose NVS-HO, the first benchmark designed for novel view synthesis of handheld objects in real-world environments using only RGB inputs. Each object is recorded in two complementary RGB sequences: (1) a handheld sequence, where the object is manipulated in front of a static camera, and (2) a board sequence, where the object is fixed on a ChArUco board to provide accurate camera poses via marker detection. The goal of NVS-HO is to learn a NVS model that captures the full appearance of an object from (1), whereas (2) provides the ground-truth images used for evaluation. To establish baselines, we consider both a classical SfM pipeline and a state-of-the-art pre-trained feed-forward neural network (VGGT) as pose estimators, and train NVS models based on NeRF and Gaussian Splatting. Our experiments reveal significant performance gaps in current methods under unconstrained handheld conditions, highlighting the need for more robust approaches. NVS-HO thus offers a challenging real-world benchmark to drive progress in RGB-based novel view synthesis of handheld objects.", "AI": {"tldr": "The paper proposes NVS-HO, the first benchmark for real-world novel view synthesis (NVS) of handheld objects using only RGB inputs, highlighting significant performance gaps in existing methods.", "motivation": "The need for a benchmark to evaluate and drive progress in novel view synthesis (NVS) for handheld objects in real-world environments using only RGB data.", "method": "Two complementary RGB sequences were used: a handheld sequence for capturing the appearance of objects and a board sequence for accurate camera pose detection. Baselines include classical SfM pipelines and feed-forward neural networks, with NVS models trained using NeRF and Gaussian Splatting.", "result": "The experiments showed significant gaps in current NVS methods, particularly under unconstrained handheld conditions, suggesting these methods are not yet robust enough for real-world applications.", "conclusion": "NVS-HO sets a new benchmark for RGB-based NVS of handheld objects, offering a challenging real-world scenario to drive innovations in this field."}}
{"id": "2602.05375", "pdf": "https://arxiv.org/pdf/2602.05375", "abs": "https://arxiv.org/abs/2602.05375", "authors": ["Jaewon Lee", "Yongwoo Kim", "Donghyun Kim"], "title": "Erase at the Core: Representation Unlearning for Machine Unlearning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Many approximate machine unlearning methods demonstrate strong logit-level forgetting -- such as near-zero accuracy on the forget set -- yet continue to preserve substantial information within their internal feature representations. We refer to this discrepancy as superficial forgetting. Recent studies indicate that most existing unlearning approaches primarily alter the final classifier, leaving intermediate representations largely unchanged and highly similar to those of the original model. To address this limitation, we introduce the Erase at the Core (EC), a framework designed to enforce forgetting throughout the entire network hierarchy. EC integrates multi-layer contrastive unlearning on the forget set with retain set preservation through deeply supervised learning. Concretely, EC attaches auxiliary modules to intermediate layers and applies both contrastive unlearning and cross-entropy losses at each supervision point, with layer-wise weighted losses. Experimental results show that EC not only achieves effective logit-level forgetting, but also substantially reduces representational similarity to the original model across intermediate layers. Furthermore, EC is model-agnostic and can be incorporated as a plug-in module into existing unlearning methods, improving representation-level forgetting while maintaining performance on the retain set.", "AI": {"tldr": "The paper identifies the issue of superficial forgetting in machine unlearning methods and introduces the Erase at the Core (EC) framework to address it, achieving better forgetting throughout model layers.", "motivation": "Superficial forgetting occurs when machine unlearning methods massively affect logit-level metrics but fail to alter internal feature representations, leaving residual information. Addressing this issue is essential for achieving comprehensive data removal in unlearning tasks.", "method": "Erase at the Core (EC) uses multi-layer contrastive unlearning and retain set preservation through deeply supervised learning. It attaches auxiliary modules to intermediate layers, applying weighted contrastive and cross-entropy losses throughout the network.", "result": "Experiments show EC improves representation-level forgetting across all layers while maintaining accuracy on the retain set, outperforming existing unlearning approaches.", "conclusion": "EC resolves superficial forgetting by enforcing comprehensive forgetting across intermediate layers, making it a robust, model-agnostic solution for machine unlearning."}}
{"id": "2602.05539", "pdf": "https://arxiv.org/pdf/2602.05539", "abs": "https://arxiv.org/abs/2602.05539", "authors": ["Yawei Li", "Benjamin Bergner", "Yinghan Zhao", "Vihang Prakash Patil", "Bei Chen", "Cheng Wang"], "title": "Steering Large Reasoning Models towards Concise Reasoning via Flow Matching", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "This paper has been accepted to Transactions on Machine Learning Research (TMLR)", "summary": "Large Reasoning Models (LRMs) excel at complex reasoning tasks, but their efficiency is often hampered by overly verbose outputs. Prior steering methods attempt to address this issue by applying a single, global vector to hidden representations -- an approach grounded in the restrictive linear representation hypothesis. In this work, we introduce FlowSteer, a nonlinear steering method that goes beyond uniform linear shifts by learning a complete transformation between the distributions associated with verbose and concise reasoning. This transformation is learned via Flow Matching as a velocity field, enabling precise, input-dependent control over the model's reasoning process. By aligning steered representations with the distribution of concise-reasoning activations, FlowSteer yields more compact reasoning than the linear shifts. Across diverse reasoning benchmarks, FlowSteer demonstrates strong task performance and token efficiency compared to leading inference-time baselines. Our work demonstrates that modeling the full distributional transport with generative techniques offers a more effective and principled foundation for controlling LRMs.", "AI": {"tldr": "FlowSteer introduces a nonlinear method for steering large reasoning models (LRMs), aimed at creating more concise outputs compared to previous linear approaches.", "motivation": "Prior steering methods for LRMs rely on linear adjustments which limit their effectiveness in reducing verbose outputs.", "method": "FlowSteer utilizes Flow Matching to model transformations between verbose and concise reasoning distributions, enabling nonlinear and context-specific adjustments.", "result": "FlowSteer achieves improved task performance and token efficiency on various reasoning benchmarks compared to existing baselines.", "conclusion": "Transforming distributions with generative techniques offers a principled and efficient method for compact reasoning in LRMs."}}
{"id": "2602.05389", "pdf": "https://arxiv.org/pdf/2602.05389", "abs": "https://arxiv.org/abs/2602.05389", "authors": ["Shunya Nagashima", "Shuntaro Suzuki", "Shuitsu Koyama", "Shinnosuke Hirano"], "title": "A Decomposition-based State Space Model for Multivariate Time-Series Forecasting", "categories": ["cs.LG"], "comment": "ICASSP2026", "summary": "Multivariate time series (MTS) forecasting is crucial for decision-making in domains such as weather, energy, and finance. It remains challenging because real-world sequences intertwine slow trends, multi-rate seasonalities, and irregular residuals. Existing methods often rely on rigid, hand-crafted decompositions or generic end-to-end architectures that entangle components and underuse structure shared across variables. To address these limitations, we propose DecompSSM, an end-to-end decomposition framework using three parallel deep state space model branches to capture trend, seasonal, and residual components. The model features adaptive temporal scales via an input-dependent predictor, a refinement module for shared cross-variable context, and an auxiliary loss that enforces reconstruction and orthogonality. Across standard benchmarks (ECL, Weather, ETTm2, and PEMS04), DecompSSM outperformed strong baselines, indicating the effectiveness of combining component-wise deep state space models and global context refinement.", "AI": {"tldr": "The paper introduces DecompSSM, a novel framework for multivariate time series forecasting, addressing component disentanglement and shared structure through adaptive deep state space models.", "motivation": "The study aims to improve multivariate time series forecasting by addressing challenges like intertwined trends, seasonalities, and residuals in real-world data, which are not effectively handled by existing methods.", "method": "The authors propose DecompSSM, an end-to-end framework employing three parallel deep state space model branches for trend, seasonal, and residual components, combined with input-adaptive predictors, cross-variable refinements, and auxiliary loss functions.", "result": "DecompSSM outperforms existing baseline methods across multiple standard datasets (ECL, Weather, ETTm2, PEMS04), showcasing its effectiveness in time series forecasting.", "conclusion": "The framework demonstrates that utilizing component-wise decomposition with global context refinement significantly enhances forecast accuracy for multivariate time series."}}
{"id": "2602.05829", "pdf": "https://arxiv.org/pdf/2602.05829", "abs": "https://arxiv.org/abs/2602.05829", "authors": ["Yudi Shi", "Shangzhe Di", "Qirui Chen", "Qinian Wang", "Jiayin Cai", "Xiaolong Jiang", "Yao Hu", "Weidi Xie"], "title": "Weaver: End-to-End Agentic System Training for Video Interleaved Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Video reasoning constitutes a comprehensive assessment of a model's capabilities, as it demands robust perceptual and interpretive skills, thereby serving as a means to explore the boundaries of model performance. While recent research has leveraged text-centric Chain-of-Thought reasoning to augment these capabilities, such approaches frequently suffer from representational mismatch and restricted by limited perceptual acuity. To address these limitations, we propose Weaver, a novel, end-to-end trainable multimodal reasoning agentic system. Weaver empowers its policy model to dynamically invoke diverse tools throughout the reasoning process, enabling progressive acquisition of crucial visual cues and construction of authentic multimodal reasoning trajectories. Furthermore, we integrate a reinforcement learning algorithm to allow the system to freely explore strategies for employing and combining these tools with trajectory-free data. Extensive experiments demonstrate that our system, Weaver, enhances performance on several complex video reasoning benchmarks, particularly those involving long videos.", "AI": {"tldr": "Weaver is a trainable multimodal system for dynamic tool usage in video reasoning, improving performance, especially for long videos.", "motivation": "Explore and overcome representational mismatches and perceptual limitations in video reasoning tasks, enhancing model interpretive skills.", "method": "Introduces 'Weaver,' an end-to-end trainable system that uses reinforcement learning to invoke and combine diverse tools dynamically for multimodal reasoning.", "result": "Weaver shows superior performance in challenging video reasoning benchmarks, particularly excelling in tasks involving long video content.", "conclusion": "Weaver advances video reasoning by offering a robust mechanism for dynamically acquiring crucial visual cues and forming effective reasoning pathways."}}
{"id": "2602.05390", "pdf": "https://arxiv.org/pdf/2602.05390", "abs": "https://arxiv.org/abs/2602.05390", "authors": ["Wei Soon Cheong", "Lian Lian Jiang", "Jamie Ng Suat Ling"], "title": "Assessing Electricity Demand Forecasting with Exogenous Data in Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 Figure and 3 Tables. Accepted to AI4TS Workshop @ AAAI'26 as an oral presentation (see https://ai4ts.github.io/aaai2026)", "summary": "Time-series foundation models have emerged as a new paradigm for forecasting, yet their ability to effectively leverage exogenous features -- critical for electricity demand forecasting -- remains unclear. This paper empirically evaluates foundation models capable of modeling cross-channel correlations against a baseline LSTM with reversible instance normalization across Singaporean and Australian electricity markets at hourly and daily granularities. We systematically assess MOIRAI, MOMENT, TinyTimeMixers, ChronosX, and Chronos-2 under three feature configurations: all features, selected features, and target-only. Our findings reveal highly variable effectiveness: while Chronos-2 achieves the best performance among foundation models (in zero-shot settings), the simple baseline frequently outperforms all foundation models in Singapore's stable climate, particularly for short-term horizons. Model architecture proves critical, with synergistic architectural implementations (TTM's channel-mixing, Chronos-2's grouped attention) consistently leveraging exogenous features, while other approaches show inconsistent benefits. Geographic context emerges as equally important, with foundation models demonstrating advantages primarily in variable climates. These results challenge assumptions about universal foundation model superiority and highlight the need for domain-specific models, specifically in the energy domain.", "AI": {"tldr": "The paper evaluates time-series foundation models for electricity demand forecasting, comparing them to a baseline LSTM model in different geographic conditions and feature configurations.", "motivation": "Ensure effective leveraging of exogenous features in time-series foundation models for accurate electricity demand forecasting.", "method": "Empirical evaluation of multiple foundation models, including MOIRAI, MOMENT, TinyTimeMixers, ChronosX, and Chronos-2, against an LSTM baseline on electricity data from Singapore and Australia.", "result": "Chronos-2 performs best among foundation models in zero-shot settings, but the LSTM baseline performs better in stable climates like Singapore, especially for short-term forecasts.", "conclusion": "Universal superiority of foundation models is challenged, emphasizing the need for domain-specific approaches tailored to geographic and feature-specific contexts in energy forecasting."}}
{"id": "2602.05832", "pdf": "https://arxiv.org/pdf/2602.05832", "abs": "https://arxiv.org/abs/2602.05832", "authors": ["Han Xiao", "Guozhi Wang", "Hao Wang", "Shilong Liu", "Yuxiang Chai", "Yue Pan", "Yufeng Zhou", "Xiaoxin Chen", "Yafei Wen", "Hongsheng Li"], "title": "UI-Mem: Self-Evolving Experience Memory for Online Reinforcement Learning in Mobile GUI Agents", "categories": ["cs.CV"], "comment": "23 pages, 16 figures. Project page: https://ui-mem.github.io", "summary": "Online Reinforcement Learning (RL) offers a promising paradigm for enhancing GUI agents through direct environment interaction. However, its effectiveness is severely hindered by inefficient credit assignment in long-horizon tasks and repetitive errors across tasks due to the lack of experience transfer. To address these challenges, we propose UI-Mem, a novel framework that enhances GUI online RL with a Hierarchical Experience Memory. Unlike traditional replay buffers, our memory accumulates structured knowledge, including high-level workflows, subtask skills, and failure patterns. These experiences are stored as parameterized templates that enable cross-task and cross-application transfer. To effectively integrate memory guidance into online RL, we introduce Stratified Group Sampling, which injects varying levels of guidance across trajectories within each rollout group to maintain outcome diversity, driving the unguided policy toward internalizing guided behaviors. Furthermore, a Self-Evolving Loop continuously abstracts novel strategies and errors to keep the memory aligned with the agent's evolving policy. Experiments on online GUI benchmarks demonstrate that UI-Mem significantly outperforms traditional RL baselines and static reuse strategies, with strong generalization to unseen applications. Project page: https://ui-mem.github.io", "AI": {"tldr": "UI-Mem is a novel reinforcement learning framework that enhances online GUI agents by utilizing a Hierarchical Experience Memory for better experience transfer and credit assignment in long-horizon tasks.", "motivation": "To address inefficiencies in online RL caused by poor credit assignment in long-horizon tasks and repetitive errors due to the absence of experience transfer.", "method": "UI-Mem utilizes a Hierarchical Experience Memory. It stores structured knowledge like workflows, subtask skills, and failure patterns as parameterized templates. It introduces Stratified Group Sampling for diverse outcomes and a Self-Evolving Loop for continuously updating memory.", "result": "UI-Mem significantly outperformed traditional RL and static reuse strategies in online GUI benchmarks, showcasing improved performance and generalization to unseen tasks.", "conclusion": "The proposed UI-Mem framework effectively enhances the performance of online RL agents, demonstrating its potential for advancing GUI-related RL applications."}}
{"id": "2602.05410", "pdf": "https://arxiv.org/pdf/2602.05410", "abs": "https://arxiv.org/abs/2602.05410", "authors": ["Adda Akram Bendoukha", "Aymen Boudguiga", "Nesrine Kaaniche", "Renaud Sirdey", "Didem Demirag", "S\u00e9bastien Gambs"], "title": "Robust Federated Learning via Byzantine Filtering over Encrypted Updates", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) aims to train a collaborative model while preserving data privacy. However, the distributed nature of this approach still raises privacy and security issues, such as the exposure of sensitive data due to inference attacks and the influence of Byzantine behaviors on the trained model. In particular, achieving both secure aggregation and Byzantine resilience remains challenging, as existing solutions often address these aspects independently. In this work, we propose to address these challenges through a novel approach that combines homomorphic encryption for privacy-preserving aggregation with property-inference-inspired meta-classifiers for Byzantine filtering. First, following the property-inference attacks blueprint, we train a set of filtering meta-classifiers on labeled shadow updates, reproducing a diverse ensemble of Byzantine misbehaviors in FL, including backdoor, gradient-inversion, label-flipping and shuffling attacks. The outputs of these meta-classifiers are then used to cancel the Byzantine encrypted updates by reweighting. Second, we propose an automated method for selecting the optimal kernel and the dimensionality hyperparameters with respect to homomorphic inference, aggregation constraints and efficiency over the CKKS cryptosystem. Finally, we demonstrate through extensive experiments the effectiveness of our approach against Byzantine participants on the FEMNIST, CIFAR10, GTSRB, and acsincome benchmarks. More precisely, our SVM filtering achieves accuracies between $90$% and $94$% for identifying Byzantine updates at the cost of marginal losses in model utility and encrypted inference runtimes ranging from $6$ to $24$ seconds and from $9$ to $26$ seconds for an overall aggregation.", "AI": {"tldr": "The paper presents a federated learning approach that protects privacy via homomorphic encryption and combats Byzantine issues with meta-classifiers trained to recognize malicious behavior, showcasing effective results on various datasets.", "motivation": "To enhance data privacy and security in Federated Learning by addressing vulnerabilities such as inference attacks and Byzantine misbehaviors, which current methods fail to simultaneously handle.", "method": "The authors employed homomorphic encryption to protect aggregation processes and designed property-inference-inspired meta-classifiers, trained on shadow updates, to filter Byzantine updates. They also optimized kernel and dimensional parameters for the CKKS cryptosystem to enhance efficiency.", "result": "The method was tested on FEMNIST, CIFAR10, GTSRB, and acsincome benchmarks, achieving 90%-94% accuracy in detecting Byzantine updates with minimal loss in model performance. Encrypted inference runtimes ranged from 6 to 24 seconds for filtering and 9 to 26 seconds for aggregation.", "conclusion": "The approach successfully integrates privacy-preserving aggregation with robust Byzantine defense, proving its effectiveness through experimental validation in diverse datasets."}}
{"id": "2602.05628", "pdf": "https://arxiv.org/pdf/2602.05628", "abs": "https://arxiv.org/abs/2602.05628", "authors": ["Alastair Howcroft", "Amber Bennett-Weston", "Ahmad Khan", "Joseff Griffiths", "Simon Gay", "Jeremy Howick"], "title": "AI chatbots versus human healthcare professionals: a systematic review and meta-analysis of empathy in patient care", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "Open Access Invited Review. Systematic review and meta analysis of 15 studies 2023-2024. Published 20 October 2025", "summary": "Background: Empathy is widely recognized for improving patient outcomes, including reduced pain and anxiety and improved satisfaction, and its absence can cause harm. Meanwhile, use of artificial intelligence (AI)-based chatbots in healthcare is rapidly expanding, with one in five general practitioners using generative AI to assist with tasks such as writing letters. Some studies suggest AI chatbots can outperform human healthcare professionals (HCPs) in empathy, though findings are mixed and lack synthesis.\n  Sources of data: We searched multiple databases for studies comparing AI chatbots using large language models with human HCPs on empathy measures. We assessed risk of bias with ROBINS-I and synthesized findings using random-effects meta-analysis where feasible, whilst avoiding double counting.\n  Areas of agreement: We identified 15 studies (2023-2024). Thirteen studies reported statistically significantly higher empathy ratings for AI, with only two studies situated in dermatology favouring human responses. Of the 15 studies, 13 provided extractable data and were suitable for pooling. Meta-analysis of those 13 studies, all utilising ChatGPT-3.5/4, showed a standardized mean difference of 0.87 (95% CI, 0.54-1.20) favouring AI (P < .00001), roughly equivalent to a two-point increase on a 10-point scale.\n  Areas of controversy: Studies relied on text-based assessments that overlook non-verbal cues and evaluated empathy through proxy raters.\n  Growing points: Our findings indicate that, in text-only scenarios, AI chatbots are frequently perceived as more empathic than human HCPs.\n  Areas timely for developing research: Future research should validate these findings with direct patient evaluations and assess whether emerging voice-enabled AI systems can deliver similar empathic advantages.", "AI": {"tldr": "The paper investigates AI-based chatbots' empathy performance compared to human healthcare professionals (HCPs), finding AI generally rated higher in text-based scenarios.", "motivation": "To evaluate whether AI chatbots could outperform human HCPs in expressing empathy and improve healthcare outcomes.", "method": "A meta-analysis of 15 studies assessing empathy ratings between AI chatbots (ChatGPT-3.5/4) and human HCPs using text-based measures.", "result": "Meta-analysis showed AI chatbots exhibit higher empathy ratings, standardized mean difference of 0.87 favoring AI (P < .00001).", "conclusion": "AI chatbots are perceived as more empathetic in text-only contexts, with future research needed to examine voice-based systems and patient-centered evaluations."}}
{"id": "2602.05845", "pdf": "https://arxiv.org/pdf/2602.05845", "abs": "https://arxiv.org/abs/2602.05845", "authors": ["Pierre-Fran\u00e7ois De Plaen", "Abhishek Jha", "Luc Van Gool", "Tinne Tuytelaars", "Marc Proesmans"], "title": "Self-Supervised Learning with a Multi-Task Latent Space Objective", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning (SSL) methods based on Siamese networks learn visual representations by aligning different views of the same image. The multi-crop strategy, which incorporates small local crops to global ones, enhances many SSL frameworks but causes instability in predictor-based architectures such as BYOL, SimSiam, and MoCo v3. We trace this failure to the shared predictor used across all views and demonstrate that assigning a separate predictor to each view type stabilizes multi-crop training, resulting in significant performance gains. Extending this idea, we treat each spatial transformation as a distinct alignment task and add cutout views, where part of the image is masked before encoding. This yields a simple multi-task formulation of asymmetric Siamese SSL that combines global, local, and masked views into a single framework. The approach is stable, generally applicable across backbones, and consistently improves the performance of ResNet and ViT models on ImageNet.", "AI": {"tldr": "The paper proposes a modified Siamese SSL framework that improves stability and performance by using separate predictors for different view types and incorporates multiple spatial transformations into a unified model.", "motivation": "Siamese SSL frameworks, while effective, face instability with multi-crop strategies due to shared predictors across views. This paper aims to resolve this issue and improve performance.", "method": "The authors introduce separate predictors for different view types and extend the approach by treating spatial transformations, including cutout views, as distinct tasks within a multi-task SSL framework.", "result": "The proposed method stabilizes multi-crop training and yields significant performance improvements across ResNet and Vision Transformer models on ImageNet.", "conclusion": "This framework is a stable and generic solution for integrating global, local, and masked views into Siamese SSL, enhancing model performance effectively."}}
{"id": "2602.05448", "pdf": "https://arxiv.org/pdf/2602.05448", "abs": "https://arxiv.org/abs/2602.05448", "authors": ["Sheshansh Agrawal", "Thien Hang Nguyen", "Douwe Kiela"], "title": "BLITZRANK: Principled Zero-shot Ranking Agents with Tournament Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models have emerged as powerful zero-shot rerankers for retrieval-augmented generation, offering strong generalization without task-specific training. However, existing LLM reranking methods either rely on heuristics that fail to fully exploit the information revealed by each ranking decision or are inefficient when they do. We introduce a tournament graph framework that provides a principled foundation for $k$-wise reranking. Our key observation is that each $k$-document comparison reveals a complete tournament of $\\binom{k}{2}$ pairwise preferences. These tournaments are aggregated into a global preference graph, whose transitive closure yields many additional orderings without further model invocations. We formalize when a candidate's rank is certifiably determined and design a query schedule that greedily maximizes information gain towards identifying the top-$m$ items. Our framework also gracefully handles non-transitive preferences - cycles induced by LLM judgments - by collapsing them into equivalence classes that yield principled tiered rankings. Empirically, across 14 benchmarks and 5 LLMs, our method achieves Pareto dominance over existing methods: matching or exceeding accuracy while requiring 25-40% fewer tokens than comparable approaches, and 7$\\times$ fewer than pairwise methods at near-identical quality.", "AI": {"tldr": "The paper introduces a tournament graph framework for $k$-wise reranking in large language models, optimizing efficiency and accuracy in retrieval-augmented generation tasks.", "motivation": "Existing LLM reranking methods lack efficiency or fail to fully exploit ranking information, motivating the need for a principled $k$-wise reranking framework.", "method": "The proposed method aggregates $k$-document comparisons into a global preference graph and uses its transitive closure for additional orderings. It handles cycles gracefully by collapsing them into equivalence classes while designing a query schedule to maximize information gain.", "result": "The method achieved Pareto dominance across 14 benchmarks and 5 LLMs, matching or exceeding accuracy of previous approaches, while using significantly fewer tokens.", "conclusion": "The tournament graph framework provides an efficient and accurate solution for ranking preferences in LLMs, showcasing its potential over existing methods."}}
{"id": "2602.05630", "pdf": "https://arxiv.org/pdf/2602.05630", "abs": "https://arxiv.org/abs/2602.05630", "authors": ["Zepeng Zhai", "Meilin Chen", "Jiaxuan Zhao", "Junlang Qian", "Lei Shen", "Yuan Lu"], "title": "Rewards as Labels: Revisiting RLVR from a Classification Perspective", "categories": ["cs.LG", "cs.CL"], "comment": "12 pages, 5 figures, 4 tables", "summary": "Reinforcement Learning with Verifiable Rewards has recently advanced the capabilities of Large Language Models in complex reasoning tasks by providing explicit rule-based supervision. Among RLVR methods, GRPO and its variants have achieved strong empirical performance. Despite their success, we identify that they suffer from Gradient Misassignment in Positives and Gradient Domination in Negatives, which lead to inefficient and suboptimal policy updates. To address these issues, we propose Rewards as Labels (REAL), a novel framework that revisits verifiable rewards as categorical labels rather than scalar weights, thereby reformulating policy optimization as a classification problem. Building on this, we further introduce anchor logits to enhance policy learning. Our analysis reveals that REAL induces a monotonic and bounded gradient weighting, enabling balanced gradient allocation across rollouts and effectively mitigating the identified mismatches. Extensive experiments on mathematical reasoning benchmarks show that REAL improves training stability and consistently outperforms GRPO and strong variants such as DAPO. On the 1.5B model, REAL improves average Pass@1 over DAPO by 6.7%. These gains further scale to 7B model, REAL continues to outperform DAPO and GSPO by 6.2% and 1.7%, respectively. Notably, even with a vanilla binary cross-entropy, REAL remains stable and exceeds DAPO by 4.5% on average.", "AI": {"tldr": "This paper addresses inefficiencies in RLVR methods, proposing the REAL framework to improve policy optimization and reasoning task performance.", "motivation": "The paper aims to enhance policy optimization in RLVR-based reinforcement learning methods, which face inefficiencies like gradient misallocation and domination.", "method": "REAL reformulates policy optimization as a classification problem using categorical labels for rewards and introduces anchor logits for improved learning.", "result": "Experiments show REAL improves training stability and consistently outperforms GRPO, DAPO, and GSPO on reasoning benchmarks, with notable performance gains.", "conclusion": "REAL effectively mitigates issues in gradient allocation, improves reinforcement learning stability, and achieves superior results in complex reasoning tasks."}}
{"id": "2602.05871", "pdf": "https://arxiv.org/pdf/2602.05871", "abs": "https://arxiv.org/abs/2602.05871", "authors": ["Xunzhi Xiang", "Zixuan Duan", "Guiyu Zhang", "Haiyu Zhang", "Zhe Gao", "Junta Wu", "Shaofeng Zhang", "Tengfei Wang", "Qi Fan", "Chunchao Guo"], "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation. While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), a training-free alternative. Specifically, TTC utilizes the initial frame as a stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory. Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks.", "AI": {"tldr": "Test-Time Correction (TTC) is introduced to address error accumulation in long video synthesis generated by distilled autoregressive diffusion models.", "motivation": "While Test-Time Optimization (TTO) performs well for short video generation, it fails in handling errors over extended sequences, primarily due to instability in reward landscapes and hypersensitivity in distilled models.", "method": "TTC uses the initial frame as a reference anchor to calibrate stochastic states throughout the sampling trajectory, offering a training-free solution.", "result": "Experiments show TTC can extend generation lengths with minimal computational overhead and match the quality of resource-intensive training methods on 30-second video benchmarks.", "conclusion": "TTC effectively resolves drift issues in long-sequence synthesis, offering a practical and resource-efficient solution suitable for various distilled models."}}
{"id": "2602.05459", "pdf": "https://arxiv.org/pdf/2602.05459", "abs": "https://arxiv.org/abs/2602.05459", "authors": ["Jan Malte T\u00f6pperwien", "Aditya Mohan", "Marius Lindauer"], "title": "When Are RL Hyperparameters Benign? A Study in Offline Goal-Conditioned RL", "categories": ["cs.LG"], "comment": "27 pages, 19 figures", "summary": "Hyperparameter sensitivity in Deep Reinforcement Learning (RL) is often accepted as unavoidable. However, it remains unclear whether it is intrinsic to the RL problem or exacerbated by specific training mechanisms. We investigate this question in offline goal-conditioned RL, where data distributions are fixed, and non-stationarity can be explicitly controlled via scheduled shifts in data quality. Additionally, we study varying data qualities under both stationary and non-stationary regimes, and cover two representative algorithms: HIQL (bootstrapped TD-learning) and QRL (quasimetric representation learning). Overall, we observe substantially greater robustness to changes in hyperparameter configurations than commonly reported for online RL, even under controlled non-stationarity. Once modest expert data is present ($\\approx$ 20\\%), QRL maintains broad, stable near-optimal regions, while HIQL exhibits sharp optima that drift significantly across training phases. To explain this divergence, we introduce an inter-goal gradient alignment diagnostic. We find that bootstrapped objectives exhibit stronger destructive gradient interference, which coincides directly with hyperparameter sensitivity. These results suggest that high sensitivity to changes in hyperparameter configurations during training is not inevitable in RL, but is amplified by the dynamics of bootstrapping, offering a pathway toward more robust algorithmic objective design.", "AI": {"tldr": "Hyperparameter sensitivity in reinforcement learning (RL) can be influenced by training mechanisms rather than being intrinsic, as shown in offline goal-conditioned RL settings.", "motivation": "Explore whether hyperparameter sensitivity in RL arises inherently from RL problems or is exacerbated by specific training mechanisms.", "method": "Conduct experiments in offline goal-conditioned RL using two representative algorithms (HIQL and QRL) under both stationary and non-stationary data quality regimes.", "result": "QRL demonstrated broad regions of stable near-optimal performance with modest expert data, while HIQL displayed sharp, unstable hyperparameter optima influenced by bootstrapped objectives.", "conclusion": "Hyperparameter sensitivity in RL is not inevitable; it is amplified by bootstrapping dynamics. Designing objectives more robust to gradient interference could enhance algorithmic reliability."}}
{"id": "2602.05880", "pdf": "https://arxiv.org/pdf/2602.05880", "abs": "https://arxiv.org/abs/2602.05880", "authors": ["Fei Yu Guan", "Ian Keefe", "Sophie Wilkinson", "Daniel D. B. Perrakis", "Steven Waslander"], "title": "Contour Refinement using Discrete Diffusion in Low Data Regime", "categories": ["cs.CV"], "comment": "CRV 2026, 8 pages, 6 figures", "summary": "Boundary detection of irregular and translucent objects is an important problem with applications in medical imaging, environmental monitoring and manufacturing, where many of these applications are plagued with scarce labeled data and low in situ computational resources. While recent image segmentation studies focus on segmentation mask alignment with ground-truth, the task of boundary detection remains understudied, especially in the low data regime. In this work, we present a lightweight discrete diffusion contour refinement pipeline for robust boundary detection in the low data regime. We use a Convolutional Neural Network(CNN) architecture with self-attention layers as the core of our pipeline, and condition on a segmentation mask, iteratively denoising a sparse contour representation. We introduce multiple novel adaptations for improved low-data efficacy and inference efficiency, including using a simplified diffusion process, a customized model architecture, and minimal post processing to produce a dense, isolated contour given a dataset of size <500 training images. Our method outperforms several SOTA baselines on the medical imaging dataset KVASIR, is competitive on HAM10K and our custom wildfire dataset, Smoke, while improving inference framerate by 3.5X.", "AI": {"tldr": "The paper proposes a lightweight method for robust boundary detection of irregular and translucent objects, addressing challenges in low data and low-resource scenarios.", "motivation": "Solving accurate boundary detection for irregular and translucent objects under scarce labeled data and limited computational resources.", "method": "A pipeline based on CNN with self-attention layers, simplified diffusion process, and minimal post-processing for iterative contour refinement with <500 training images.", "result": "The method surpasses state-of-the-art baselines on medical imaging dataset KVASIR, performs competitively on HAM10K and Smoke datasets, and improves inference speed by 3.5X.", "conclusion": "The approach offers an efficient solution for boundary detection in low-data settings, contributing to applications in medical imaging and beyond."}}
{"id": "2602.04927", "pdf": "https://arxiv.org/pdf/2602.04927", "abs": "https://arxiv.org/abs/2602.04927", "authors": ["Gautam Savaliya", "Robert Aufschl\u00e4ger", "Abhishek Subedi", "Michael Heigl", "Martin Schramm"], "title": "PriMod4AI: Lifecycle-Aware Privacy Threat Modeling for AI Systems using LLM", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted at the NDSS LAST-X Workshop 2026", "summary": "Artificial intelligence systems introduce complex privacy risks throughout their lifecycle, especially when processing sensitive or high-dimensional data. Beyond the seven traditional privacy threat categories defined by the LINDDUN framework, AI systems are also exposed to model-centric privacy attacks such as membership inference and model inversion, which LINDDUN does not cover. To address both classical LINDDUN threats and additional AI-driven privacy attacks, PriMod4AI introduces a hybrid privacy threat modeling approach that unifies two structured knowledge sources, a LINDDUN knowledge base representing the established taxonomy, and a model-centric privacy attack knowledge base capturing threats outside LINDDUN. These knowledge bases are embedded into a vector database for semantic retrieval and combined with system level metadata derived from Data Flow Diagram. PriMod4AI uses retrieval-augmented and Data Flow specific prompt generation to guide large language models (LLMs) in identifying, explaining, and categorizing privacy threats across lifecycle stages. The framework produces justified and taxonomy-grounded threat assessments that integrate both classical and AI-driven perspectives. Evaluation on two AI systems indicates that PriMod4AI provides broad coverage of classical privacy categories while additionally identifying model-centric privacy threats. The framework produces consistent, knowledge-grounded outputs across LLMs, as reflected in agreement scores in the observed range.", "AI": {"tldr": "The PriMod4AI framework expands traditional privacy threat modeling by integrating both LINDDUN threats and AI-specific privacy vulnerabilities to provide comprehensive assessments guided by large language models.", "motivation": "To address the limitation of existing privacy threat modeling frameworks like LINDDUN, which do not cover model-centric AI-specific privacy risks such as membership inference and model inversion.", "method": "The authors propose PriMod4AI, a hybrid framework that combines a LINDDUN knowledge base with a model-centric privacy attack knowledge base. These are stored in a vector database for semantic retrieval, integrated with system metadata from Data Flow Diagrams, and leveraged to guide LLMs in assessing privacy threats.", "result": "PriMod4AI was evaluated on two AI systems and demonstrated broad coverage of traditional privacy issues along with identification of AI-specific vulnerabilities. Results showed consistency and reliability across LLM outputs.", "conclusion": "The PriMod4AI framework successfully integrates existing privacy taxonomies with AI-specific threat analysis, offering a robust and consistent privacy threat assessment tool for AI systems throughout their lifecycle."}}
{"id": "2602.05463", "pdf": "https://arxiv.org/pdf/2602.05463", "abs": "https://arxiv.org/abs/2602.05463", "authors": ["Koichi Takahashi", "Yusuke Hayashi"], "title": "Thermodynamic Limits of Physical Intelligence", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": null, "summary": "Modern AI systems achieve remarkable capabilities at the cost of substantial energy consumption. To connect intelligence to physical efficiency, we propose two complementary bits-per-joule metrics under explicit accounting conventions: (1) Thermodynamic Epiplexity per Joule -- bits of structural information about a theoretical environment-instance variable newly encoded in an agent's internal state per unit measured energy within a stated boundary -- and (2) Empowerment per Joule -- the embodied sensorimotor channel capacity (control information) per expected energetic cost over a fixed horizon. These provide two axes of physical intelligence: recognition (model-building) vs.control (action influence). Drawing on stochastic thermodynamics, we show how a Landauer-scale closed-cycle benchmark for epiplexity acquisition follows as a corollary of a standard thermodynamic-learning inequality under explicit subsystem assumptions, and we clarify how Landauer-scaled costs act as closed-cycle benchmarks under explicit reset/reuse and boundary-closure assumptions; conversely, we give a simple decoupling construction showing that without such assumptions -- and without charging for externally prepared low-entropy resources (e.g.fresh memory) crossing the boundary -- information gain and in-boundary dissipation need not be tightly linked. For empirical settings where the latent structure variable is unavailable, we align the operational notion of epiplexity with compute-bounded MDL epiplexity and recommend reporting MDL-epiplexity / compression-gain surrogates as companions. Finally, we propose a unified efficiency framework that reports both metrics together with a minimal checklist of boundary/energy accounting, coarse-graining/noise, horizon/reset, and cost conventions to reduce ambiguity and support consistent bits-per-joule comparisons, and we sketch connections to energy-adjusted scaling analyses.", "AI": {"tldr": "The paper introduces two bits-per-joule efficiency metrics for AI systems to measure physical efficiency in model-building and control, grounded in stochastic thermodynamics.", "motivation": "Modern AI systems achieve remarkable performance but at the cost of significant energy consumption. The work aims to connect intelligence with physical efficiency by addressing this imbalance through systematic metrics.", "method": "The authors define two metrics: Thermodynamic Epiplexity per Joule for structural information encoded per energy unit and Empowerment per Joule for control information per energy unit. Using thermodynamics principles, they derive benchmarks and assumptions for efficient energy-information relations.", "result": "The proposed metrics clarify how energy and information interact under specific system assumptions. Without proper assumptions or reporting conventions, these links can break, requiring consistent metrics and frameworks for evaluation.", "conclusion": "A unified efficiency framework for bits-per-joule metrics, along with clear reporting standards, is vital for consistent and interpretable analysis of AI systems' physical efficiency."}}
{"id": "2602.05708", "pdf": "https://arxiv.org/pdf/2602.05708", "abs": "https://arxiv.org/abs/2602.05708", "authors": ["Chuangtao Ma", "Zeyu Zhang", "Arijit Khan", "Sebastian Schelter", "Paul Groth"], "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration", "categories": ["cs.DB", "cs.CL"], "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tasks, but existing RAG pipelines incur substantial retrieval and generation overhead when applied to large-scale entity matching. To address this limitation, we introduce CE-RAG4EM, a cost-efficient RAG architecture that reduces computation through blocking-based batch retrieval and generation. We also present a unified framework for analyzing and evaluating RAG systems for entity matching, focusing on blocking-aware optimizations and retrieval granularity. Extensive experiments suggest that CE-RAG4EM can achieve comparable or improved matching quality while substantially reducing end-to-end runtime relative to strong baselines. Our analysis further reveals that key configuration parameters introduce an inherent trade-off between performance and overhead, offering practical guidance for designing efficient and scalable RAG systems for entity matching and data integration.", "AI": {"tldr": "CE-RAG4EM, a cost-efficient RAG system, uses blocking-based batch processing to enhance retrieval and generation for entity matching tasks, achieving reduced runtime while maintaining or improving performance.", "motivation": "The high computational cost of existing RAG models for entity matching limits their efficiency and scalability in large-scale settings.", "method": "CE-RAG4EM employs a blocking-based batch retrieval and generation approach and proposes new analysis frameworks for optimizing RAG systems, focusing on retrieval granularity and blocking-aware configurations.", "result": "Experimental evaluations show CE-RAG4EM delivers comparable or better matching results while significantly reducing runtime compared to existing baselines.", "conclusion": "The study highlights how optimized configurations in RAG systems can balance performance and overhead, providing a scalable solution for entity matching and data integration tasks."}}
{"id": "2602.05882", "pdf": "https://arxiv.org/pdf/2602.05882", "abs": "https://arxiv.org/abs/2602.05882", "authors": ["Mubashir Noman", "Mustansar Fiaz", "Hiyam Debary", "Abdul Hannan", "Shah Nawaz", "Fahad Shahbaz Khan", "Salman Khan"], "title": "EoCD: Encoder only Remote Sensing Change Detection", "categories": ["cs.CV"], "comment": null, "summary": "Being a cornerstone of temporal analysis, change detection has been playing a pivotal role in modern earth observation. Existing change detection methods rely on the Siamese encoder to individually extract temporal features followed by temporal fusion. Subsequently, these methods design sophisticated decoders to improve the change detection performance without taking into consideration the complexity of the model. These aforementioned issues intensify the overall computational cost as well as the network's complexity which is undesirable. Alternatively, few methods utilize the early fusion scheme to combine the temporal images. These methods prevent the extra overhead of Siamese encoder, however, they also rely on sophisticated decoders for better performance. In addition, these methods demonstrate inferior performance as compared to late fusion based methods. To bridge these gaps, we introduce encoder only change detection (EoCD) that is a simple and effective method for the change detection task. The proposed method performs the early fusion of the temporal data and replaces the decoder with a parameter-free multiscale feature fusion module thereby significantly reducing the overall complexity of the model. EoCD demonstrate the optimal balance between the change detection performance and the prediction speed across a variety of encoder architectures. Additionally, EoCD demonstrate that the performance of the model is predominantly dependent on the encoder network, making the decoder an additional component. Extensive experimentation on four challenging change detection datasets reveals the effectiveness of the proposed method.", "AI": {"tldr": "This paper introduces the Encoder-only Change Detection (EoCD) method, which simplifies and improves change detection by using early temporal data fusion and removing decoders, achieving an effective balance between performance and speed.", "motivation": "Existing change detection methods are computationally intensive due to complex Siamese encoders and decoders, or rely on early fusion with suboptimal results. There is a need for a simpler approach to reduce complexity while maintaining high performance.", "method": "The proposed EoCD method uses early temporal data fusion and eliminates decoders by employing a parameter-free multiscale feature fusion module, simplifying the architecture significantly.", "result": "EoCD achieves a balance between performance and prediction speed across diverse encoder architectures. Extensive testing on four challenging datasets shows its effectiveness.", "conclusion": "EoCD proves that the performance of change detection is largely influenced by the encoder architecture, rendering decoders redundant. This method offers a more efficient and effective solution to change detection challenges."}}
{"id": "2602.04930", "pdf": "https://arxiv.org/pdf/2602.04930", "abs": "https://arxiv.org/abs/2602.04930", "authors": ["Joachim Schaeffer", "Arjun Khandelwal", "Tyler Tracy"], "title": "Attack Selection Reduces Safety in Concentrated AI Control Settings against Trusted Monitoring", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Future AI deployments will likely be monitored for malicious behaviour. The ability of these AIs to subvert monitors by adversarially selecting against them - attack selection - is particularly concerning. To study this, we let a red team create attack policies that attempt to insert attacks into code without being caught by a monitor in the concentrated BigCodeBench backdooring setting. We decompose attack selection into two problems: mapping attacks to a quality score and mapping quality scores to submission probabilities. We frame attack selection as a classification problem and show that safety is significantly more sensitive to FPR than TPR. We find that prompting the attacker model to reason about the monitor while being cautious with attack selection reduces safety from a baseline of 99% to 59% at 0.5% auditing budget, emphasizing that eliciting attack selection capabilities of models is vital to avoid overly optimistic safety scores in control evaluations.", "AI": {"tldr": "The paper examines how AI systems can adversarially bypass monitors by selecting attacks strategically, highlighting vulnerabilities in monitoring systems.", "motivation": "To explore how AIs can exploit weaknesses in monitoring systems and reduce safety, especially in the context of attack selection strategies.", "method": "The study involves decomposing attack selection into quality scoring and submission probabilities. A red team creates adversarial policies in a backdooring code framework and evaluates their success against a monitor.", "result": "Prompting attackers to reason about monitors significantly reduced safety performance, showing safety from a baseline of 99% dropped to 59% with limited auditing budgets.", "conclusion": "Eliciting and understanding attack selection behaviors of AI is critical to avoid overly optimistic safety evaluations in controlled settings."}}
{"id": "2602.05494", "pdf": "https://arxiv.org/pdf/2602.05494", "abs": "https://arxiv.org/abs/2602.05494", "authors": ["Qingyuan Wu", "Yuhui Wang", "Simon Sinong Zhan", "Yanning Dai", "Shilong Deng", "Sarra Habchi", "Qi Zhu", "Matthias Gall\u00e9", "Chao Huang"], "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verified Reward (RLVR) has emerged as a critical paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). Most existing RLVR methods, such as GRPO and its variants, ensure stable updates by constraining policy divergence through clipping likelihood ratios. This paper introduces a unified clipping framework that characterizes existing methods via a general notion of policy divergence, encompassing both likelihood ratios and Kullback-Leibler (KL) divergences and extending to alternative measures. The framework provides a principled foundation for systematically analyzing how different policy divergence measures affect exploration and performance. We further identify the KL3 estimator, a variance-reduced Monte Carlo estimator of the KL divergence, as a key policy divergence constraint. We theoretically demonstrate that the KL3-based constraint is mathematically equivalent to an asymmetric ratio-based clipping that reallocates probability mass toward high-confidence actions, promoting stronger exploration while retaining the simplicity of GRPO-style methods. Empirical results on mathematical reasoning benchmarks demonstrate that incorporating the KL3 estimator into GRPO improves both training stability and final performance, highlighting the importance of principled policy divergence constraints in policy optimization.", "AI": {"tldr": "This paper introduces a unified clipping framework for Reinforcement Learning with Verified Reward (RLVR), using KL divergence to improve performance and exploration, validated empirically on reasoning tasks.", "motivation": "To improve reasoning capabilities of Large Language Models (LLMs) by addressing the impact of policy divergence measures on exploration and performance.", "method": "Develop a unified clipping framework integrating variance-reduced KL divergence estimators (KL3) and analyze their effect on policy optimization.", "result": "Incorporating KL3 into existing methods like GRPO enhances training stability and final performance in mathematical reasoning tasks.", "conclusion": "Policy divergence measures, particularly KL3-based constraints, play a crucial role in improving exploration and performance in RLVR methods."}}
{"id": "2602.05710", "pdf": "https://arxiv.org/pdf/2602.05710", "abs": "https://arxiv.org/abs/2602.05710", "authors": ["Philippe Boisnard"], "title": "Ethology of Latent Spaces", "categories": ["cs.CY", "cs.CL", "cs.CV", "cs.LG"], "comment": "23. pages, 14 figures, presented Hyperheritage International Symposium 9 ( https://paragraphe.univ-paris8.fr/IMG/pdf/programme_colloque_his9_campuscondorcet_v3.pdf ) and accepted for publication in double-blind peer review in French in 2026-2027", "summary": "This study challenges the presumed neutrality of latent spaces in vision language models (VLMs) by adopting an ethological perspective on their algorithmic behaviors. Rather than constituting spaces of homogeneous indeterminacy, latent spaces exhibit model-specific algorithmic sensitivities, understood as differential regimes of perceptual salience shaped by training data and architectural choices.\n  Through a comparative analysis of three models (OpenAI CLIP, OpenCLIP LAION, SigLIP) applied to a corpus of 301 artworks (15th to 20th), we reveal substantial divergences in the attribution of political and cultural categories. Using bipolar semantic axes derived from vector analogies (Mikolov et al., 2013), we show that SigLIP classifies 59.4% of the artworks as politically engaged, compared to only 4% for OpenCLIP. African masks receive the highest political scores in SigLIP while remaining apolitical in OpenAI CLIP. On an aesthetic colonial axis, inter-model discrepancies reach 72.6 percentage points.\n  We introduce three operational concepts: computational latent politicization, describing the emergence of political categories without intentional encoding; emergent bias, irreducible to statistical or normative bias and detectable only through contrastive analysis; and three algorithmic scopic regimes: entropic (LAION), institutional (OpenAI), and semiotic (SigLIP), which structure distinct modes of visibility. Drawing on Foucault's notion of the archive, Jameson's ideologeme, and Simondon's theory of individuation, we argue that training datasets function as quasi-archives whose discursive formations crystallize within latent space. This work contributes to a critical reassessment of the conditions under which VLMs are applied to digital art history and calls for methodologies that integrate learning architectures into any delegation of cultural interpretation to algorithmic agents.", "AI": {"tldr": "This study critiques the neutrality of latent spaces in vision-language models (VLMs), highlighting their biases and algorithmic sensitivities influenced by training data and architecture. A comparative analysis of three VLMs uncovers significant discrepancies in cultural and political interpretations of artworks.", "motivation": "To challenge the assumption that latent spaces in VLMs are neutral and to explore how these spaces encode differential sensitivities shaped by training data and architecture.", "method": "The paper employs a comparative analysis of three VLMs (OpenAI CLIP, OpenCLIP LAION, SigLIP) using a corpus of 301 artworks to identify divergences in their attribution of cultural and political categories.", "result": "The analysis reveals significant differences between the models in classifying artworks politically and culturally, with striking disparities in the attribution of meaning (e.g., 59.4% of artworks politically engaged in SigLIP vs. 4% in OpenCLIP). It also introduces new concepts to explain these phenomena.", "conclusion": "The research demonstrates that VLMs' latent spaces are shaped by their training data and architecture, revealing biases that affect cultural interpretation. It suggests adopting critical methodologies that consider these biases when applying VLMs to fields like digital art history."}}
{"id": "2602.05884", "pdf": "https://arxiv.org/pdf/2602.05884", "abs": "https://arxiv.org/abs/2602.05884", "authors": ["Gino E. Jansen", "Carolina Br\u00e1s", "R. Nils Planken", "Mark J. Schuuring", "Berto J. Bouma", "Ivana I\u0161gum"], "title": "Neural Implicit 3D Cardiac Shape Reconstruction from Sparse CT Angiography Slices Mimicking 2D Transthoracic Echocardiography Views", "categories": ["cs.CV", "cs.AI", "cs.CE"], "comment": null, "summary": "Accurate 3D representations of cardiac structures allow quantitative analysis of anatomy and function. In this work, we propose a method for reconstructing complete 3D cardiac shapes from segmentations of sparse planes in CT angiography (CTA) for application in 2D transthoracic echocardiography (TTE). Our method uses a neural implicit function to reconstruct the 3D shape of the cardiac chambers and left-ventricle myocardium from sparse CTA planes. To investigate the feasibility of achieving 3D reconstruction from 2D TTE, we select planes that mimic the standard apical 2D TTE views. During training, a multi-layer perceptron learns shape priors from 3D segmentations of the target structures in CTA. At test time, the network reconstructs 3D cardiac shapes from segmentations of TTE-mimicking CTA planes by jointly optimizing the latent code and the rigid transforms that map the observed planes into 3D space. For each heart, we simulate four realistic apical views, and we compare reconstructed multi-class volumes with the reference CTA volumes. On a held-out set of CTA segmentations, our approach achieves an average Dice coefficient of 0.86 $\\pm$ 0.04 across all structures. Our method also achieves markedly lower volume errors than the clinical standard, Simpson's biplane rule: 4.88 $\\pm$ 4.26 mL vs. 8.14 $\\pm$ 6.04 mL, respectively, for the left ventricle; and 6.40 $\\pm$ 7.37 mL vs. 37.76 $\\pm$ 22.96 mL, respectively, for the left atrium. This suggests that our approach offers a viable route to more accurate 3D chamber quantification in 2D transthoracic echocardiography.", "AI": {"tldr": "The paper introduces a neural implicit function approach to reconstruct 3D cardiac structures from sparse 2D planes in CT angiography, achieving more accurate results compared to traditional clinical methods.", "motivation": "3D reconstruction of cardiac anatomy is crucial for detailed analysis, yet current clinical tools like Simpson's rule have limitations in accuracy. The paper explores a novel neural implicit method to improve this using sparse data.", "method": "A neural implicit function is applied to reconstruct the 3D shape of cardiac chambers by learning priors from CT angiograms and mimicking 2D echocardiography planes during training and testing.", "result": "The proposed method achieves an average Dice coefficient of 0.86 and lower volume errors for the left ventricle and atrium compared to Simpson's biplane rule, showcasing significant improvement in accuracy.", "conclusion": "The study demonstrates the potential of the neural implicit method for accurate 3D quantification, providing an advanced tool for cardiac imaging in 2D echocardiography settings."}}
{"id": "2602.05535", "pdf": "https://arxiv.org/pdf/2602.05535", "abs": "https://arxiv.org/abs/2602.05535", "authors": ["Tao Huang", "Rui Wang", "Xiaofei Liu", "Yi Qin", "Li Duan", "Liping Jing"], "title": "Detecting Misbehaviors of Large Vision-Language Models by Evidential Uncertainty Quantification", "categories": ["cs.LG"], "comment": "Accepted to ICLR 2026. Code is available at https://github.com/HT86159/EUQ", "summary": "Large vision-language models (LVLMs) have shown substantial advances in multimodal understanding and generation. However, when presented with incompetent or adversarial inputs, they frequently produce unreliable or even harmful content, such as fact hallucinations or dangerous instructions. This misalignment with human expectations, referred to as \\emph{misbehaviors} of LVLMs, raises serious concerns for deployment in critical applications. These misbehaviors are found to stem from epistemic uncertainty, specifically either conflicting internal knowledge or the absence of supporting information. However, existing uncertainty quantification methods, which typically capture only overall epistemic uncertainty, have shown limited effectiveness in identifying such issues. To address this gap, we propose Evidential Uncertainty Quantification (EUQ), a fine-grained method that captures both information conflict and ignorance for effective detection of LVLM misbehaviors. In particular, we interpret features from the model output head as either supporting (positive) or opposing (negative) evidence. Leveraging Evidence Theory, we model and aggregate this evidence to quantify internal conflict and knowledge gaps within a single forward pass. We extensively evaluate our method across four categories of misbehavior, including hallucinations, jailbreaks, adversarial vulnerabilities, and out-of-distribution (OOD) failures, using state-of-the-art LVLMs, and find that EUQ consistently outperforms strong baselines, showing that hallucinations correspond to high internal conflict and OOD failures to high ignorance. Furthermore, layer-wise evidential uncertainty dynamics analysis helps interpret the evolution of internal representations from a new perspective. The source code is available at https://github.com/HT86159/EUQ.", "AI": {"tldr": "This paper introduces Evidential Uncertainty Quantification (EUQ), a method to detect and analyze misbehaviors in Large Vision-Language Models (LVLMs) by capturing internal conflicts and ignorance within their outputs.", "motivation": "The paper aims to address the critical issue of misbehaviors in LVLMs caused by epistemic uncertainty, which impacts their reliability in real-world applications.", "method": "The authors propose EUQ, which utilizes evidence theory to quantify supporting and opposing evidence from model outputs, enabling detailed analysis of conflicts and knowledge gaps within a single pass.", "result": "EUQ outperforms existing uncertainty quantification techniques in detecting various LVLM misbehaviors, such as hallucinations, jailbreaks, adversarial vulnerabilities, and out-of-distribution failures, showcasing the correlation between these issues and internal evidence dynamics.", "conclusion": "EUQ provides an effective tool for identifying LVLM misbehavior, offering insights into internal model representations and improving deployment safety in critical applications."}}
{"id": "2602.05787", "pdf": "https://arxiv.org/pdf/2602.05787", "abs": "https://arxiv.org/abs/2602.05787", "authors": ["Hengran Zhang", "Keping Bi", "Jiafeng Guo", "Jiaming Zhang", "Wenbo Yang", "Daiting Shi", "Xueqi Cheng"], "title": "Bagging-Based Model Merging for Robust General Text Embeddings", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "12 pages, 4 figures", "summary": "General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \\modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \\modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.", "AI": {"tldr": "This paper studies multi-task training for text embeddings, finding that batch-level shuffling delivers strong performance but has limitations. As an improvement, the authors propose a new Bagging-based merging approach (\u0013modelname) for better robustness and efficiency.", "motivation": "Text embedding models need to generalize across tasks and domains, but effective multi-task strategies and efficient adaptation to new data remain challenging.", "method": "Systematic comparison of multi-task training strategies (e.g., batch-level shuffling, sequential, two-stage) and introduction of \u0013modelname\u2014a method that merges models trained on subsets to improve efficiency and generalization.", "result": "Batch-level shuffling works well overall but struggles with out-of-domain generalization and adaptivity. \u0013modelname solves these by enhancing robustness and reducing retraining costs.", "conclusion": "\u0013modelname improves embedding robustness, OOD performance, and incremental learning efficiency, outperforming standard batch-level shuffling approaches through merging-based strategies."}}
{"id": "2602.05909", "pdf": "https://arxiv.org/pdf/2602.05909", "abs": "https://arxiv.org/abs/2602.05909", "authors": ["Kangjie Zhang", "Wenxuan Huang", "Xin Zhou", "Boxiang Zhou", "Dejia Song", "Yuan Xie", "Baochang Zhang", "Lizhuang Ma", "Nemo Chen", "Xu Tang", "Yao Hu", "Shaohui Lin"], "title": "CLIP-Map: Structured Matrix Mapping for Parameter-Efficient CLIP Compression", "categories": ["cs.CV"], "comment": null, "summary": "Contrastive Language-Image Pre-training (CLIP) has achieved widely applications in various computer vision tasks, e.g., text-to-image generation, Image-Text retrieval and Image captioning. However, CLIP suffers from high memory and computation cost, which prohibits its usage to the resource-limited application scenarios. Existing CLIP compression methods typically reduce the size of pre-trained CLIP weights by selecting their subset as weight inheritance for further retraining via mask optimization or important weight measurement. However, these select-based weight inheritance often compromises the feature presentation ability, especially on the extreme compression. In this paper, we propose a novel mapping-based CLIP compression framework, CLIP-Map. It leverages learnable matrices to map and combine pretrained weights by Full-Mapping with Kronecker Factorization, aiming to preserve as much information from the original weights as possible. To mitigate the optimization challenges introduced by the learnable mapping, we propose Diagonal Inheritance Initialization to reduce the distribution shifting problem for efficient and effective mapping learning. Extensive experimental results demonstrate that the proposed CLIP-Map outperforms select-based frameworks across various compression ratios, with particularly significant gains observed under high compression settings.", "AI": {"tldr": "The paper introduces CLIP-Map, a framework for compressing CLIP models using mapping-based techniques instead of traditional subset selection, achieving better performance, especially under extreme compression scenarios.", "motivation": "CLIP models are computationally and memory-intensive, limiting their application in resource-constrained scenarios. Existing compression methods reduce weight size but often compromise feature representation quality under high compression.", "method": "The authors propose CLIP-Map, a mapping-based compression framework employing learnable matrices with Full-Mapping and Kronecker Factorization. To enhance optimization, they introduce Diagonal Inheritance Initialization to address distribution shifting issues during training.", "result": "CLIP-Map showcased better performance compared to select-based compression methods across various compression ratios, with substantial improvements noted in high compression settings.", "conclusion": "Mapping-based compression approaches like CLIP-Map can preserve more information from original weights and yield superior performance, demonstrating their viability for resource-limited scenarios."}}
{"id": "2602.05937", "pdf": "https://arxiv.org/pdf/2602.05937", "abs": "https://arxiv.org/abs/2602.05937", "authors": ["Lingrui Li", "Yanfeng Zhou", "Nan Pu", "Xin Chen", "Zhun Zhong"], "title": "Multi-Scale Global-Instance Prompt Tuning for Continual Test-time Adaptation in Medical Image Segmentation", "categories": ["cs.CV"], "comment": "8 pages, BIBM2025", "summary": "Distribution shift is a common challenge in medical images obtained from different clinical centers, significantly hindering the deployment of pre-trained semantic segmentation models in real-world applications across multiple domains. Continual Test-Time Adaptation(CTTA) has emerged as a promising approach to address cross-domain shifts during continually evolving target domains. Most existing CTTA methods rely on incrementally updating model parameters, which inevitably suffer from error accumulation and catastrophic forgetting, especially in long-term adaptation. Recent prompt-tuning-based works have shown potential to mitigate the two issues above by updating only visual prompts. While these approaches have demonstrated promising performance, several limitations remain:1)lacking multi-scale prompt diversity, 2)inadequate incorporation of instance-specific knowledge, and 3)risk of privacy leakage. To overcome these limitations, we propose Multi-scale Global-Instance Prompt Tuning(MGIPT), to enhance scale diversity of prompts and capture both global- and instance-level knowledge for robust CTTA. Specifically, MGIPT consists of an Adaptive-scale Instance Prompt(AIP) and a Multi-scale Global-level Prompt(MGP). AIP dynamically learns lightweight and instance-specific prompts to mitigate error accumulation with adaptive optimal-scale selection mechanism. MGP captures domain-level knowledge across different scales to ensure robust adaptation with anti-forgetting capabilities. These complementary components are combined through a weighted ensemble approach, enabling effective dual-level adaptation that integrates both global and local information. Extensive experiments on medical image segmentation benchmarks demonstrate that our MGIPT outperforms state-of-the-art methods, achieving robust adaptation across continually changing target domains.", "AI": {"tldr": "The paper presents MGIPT, a novel approach for continual test-time adaptation in medical image segmentation addressing distribution shifts, resulting in superior performance over existing methods.", "motivation": "Address the challenge of distribution shifts in medical images from different clinical centers, which impede deployment of pre-trained segmentation models across multiple domains.", "method": "Proposed MGIPT, combining Adaptive-scale Instance Prompt (AIP) and Multi-scale Global-level Prompt (MGP) to enhance prompt diversity, incorporate global and instance-specific knowledge, and mitigate catastrophic forgetting through weighted ensemble adaptation.", "result": "MGIPT demonstrated robust adaptation in medical image segmentation experiments, outperforming state-of-the-art methods across continually evolving target domains.", "conclusion": "MGIPT effectively enhances CTTA by integrating global and local knowledge, offering a strong solution to long-term adaptation challenges in medical image segmentation."}}
{"id": "2602.05951", "pdf": "https://arxiv.org/pdf/2602.05951", "abs": "https://arxiv.org/abs/2602.05951", "authors": ["Junwan Kim", "Jiho Park", "Seonghu Jeon", "Seungryong Kim"], "title": "Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project Page: https://junwankimm.github.io/CSFM", "summary": "Flow matching has recently emerged as a promising alternative to diffusion-based generative models, particularly for text-to-image generation. Despite its flexibility in allowing arbitrary source distributions, most existing approaches rely on a standard Gaussian distribution, a choice inherited from diffusion models, and rarely consider the source distribution itself as an optimization target in such settings. In this work, we show that principled design of the source distribution is not only feasible but also beneficial at the scale of modern text-to-image systems. Specifically, we propose learning a condition-dependent source distribution under flow matching objective that better exploit rich conditioning signals. We identify key failure modes that arise when directly incorporating conditioning into the source, including distributional collapse and instability, and show that appropriate variance regularization and directional alignment between source and target are critical for stable and effective learning. We further analyze how the choice of target representation space impacts flow matching with structured sources, revealing regimes in which such designs are most effective. Extensive experiments across multiple text-to-image benchmarks demonstrate consistent and robust improvements, including up to a 3x faster convergence in FID, highlighting the practical benefits of a principled source distribution design for conditional flow matching.", "AI": {"tldr": "This paper proposes a learned, condition-dependent source distribution to improve conditional flow matching in text-to-image generation, with techniques to address instability and optimize performance.", "motivation": "Current flow matching approaches primarily use standard Gaussian source distributions, inherited from diffusion models, and lack optimization of the source distribution despite its relevance in text-to-image tasks.", "method": "The paper introduces a condition-dependent source distribution under a flow matching objective, employing variance regularization and directional alignment to address failures like distributional collapse and instability.", "result": "Findings demonstrate up to 3x faster convergence in FID metric and robust improvements across multiple text-to-image benchmarks when the proposed techniques are used.", "conclusion": "Principled design and optimization of source distributions in conditional flow matching can enhance text-to-image generation through improved stability, efficiency, and performance."}}
{"id": "2602.05548", "pdf": "https://arxiv.org/pdf/2602.05548", "abs": "https://arxiv.org/abs/2602.05548", "authors": ["Zhiqi Yu", "Zhangquan Chen", "Mengting Liu", "Heye Zhang", "Liangqiong Qu"], "title": "Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly GRPO, has become the standard for eliciting LLM reasoning. However, its efficiency in exploration and difficulty adaptation remains an open challenge. In this work, we argue that these bottlenecks stem from an implicit advantage symmetry inherent in Group Relative Advantage Estimation (GRAE). This symmetry induces two critical limitations: (i) at the group level, strict symmetry in weights between correct and incorrect trajectories leaves unsampled action logits unchanged, thereby hindering exploration of novel correct solution. (ii) at the sample level, the algorithm implicitly prioritizes medium-difficulty samples, remaining agnostic to the non-stationary demands of difficulty focus. Through controlled experiments, we reveal that this symmetric property is sub-optimal, yielding two pivotal insights: (i) asymmetrically suppressing the advantages of correct trajectories encourages essential exploration. (ii) learning efficiency is maximized by a curriculum-like transition-prioritizing simpler samples initially before gradually shifting to complex ones. Motivated by these findings, we propose Asymmetric GRAE (A-GRAE), which dynamically modulates exploration incentives and sample-difficulty focus. Experiments across seven benchmarks demonstrate that A-GRAE consistently improves GRPO and its variants across both LLMs and MLLMs.", "AI": {"tldr": "This paper identifies efficiency and adaptability limitations in standard reinforcement learning methods for LLM reasoning and proposes a new asymmetrical approach, A-GRAE, to address them.", "motivation": "Current reinforcement learning approaches like GRPO face challenges in exploration efficiency and adapting to varying difficulty demands due to implicit advantage symmetry.", "method": "The paper introduces Asymmetric Group Relative Advantage Estimation (A-GRAE), which dynamically adjusts exploration incentives and sample difficulty focus, encouraging exploration and optimizing learning processes.", "result": "Experiments across seven benchmarks show that A-GRAE enhances GRPO and its variants, improving performance in both Language and Multimodal LMs.", "conclusion": "A-GRAE is a promising solution to overcome bottlenecks in reinforcement learning for LLM reasoning by breaking advantage symmetry and incorporating a curriculum-like adaptive training focus."}}
{"id": "2602.05859", "pdf": "https://arxiv.org/pdf/2602.05859", "abs": "https://arxiv.org/abs/2602.05859", "authors": ["Xu Wang", "Bingqing Jiang", "Yu Wan", "Baosong Yang", "Lingpeng Kong", "Difan Zou"], "title": "DLM-Scope: Mechanistic Interpretability of Diffusion Language Models via Sparse Autoencoders", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "23 pages", "summary": "Sparse autoencoders (SAEs) have become a standard tool for mechanistic interpretability in autoregressive large language models (LLMs), enabling researchers to extract sparse, human-interpretable features and intervene on model behavior. Recently, as diffusion language models (DLMs) have become an increasingly promising alternative to the autoregressive LLMs, it is essential to develop tailored mechanistic interpretability tools for this emerging class of models. In this work, we present DLM-Scope, the first SAE-based interpretability framework for DLMs, and demonstrate that trained Top-K SAEs can faithfully extract interpretable features. Notably, we find that inserting SAEs affects DLMs differently than autoregressive LLMs: while SAE insertion in LLMs typically incurs a loss penalty, in DLMs it can reduce cross-entropy loss when applied to early layers, a phenomenon absent or markedly weaker in LLMs. Additionally, SAE features in DLMs enable more effective diffusion-time interventions, often outperforming LLM steering. Moreover, we pioneer certain new SAE-based research directions for DLMs: we show that SAEs can provide useful signals for DLM decoding order; and the SAE features are stable during the post-training phase of DLMs. Our work establishes a foundation for mechanistic interpretability in DLMs and shows a great potential of applying SAEs to DLM-related tasks and algorithms.", "AI": {"tldr": "This paper introduces DLM-Scope, a sparse autoencoders-based interpretability framework tailored for diffusion language models (DLMs). It finds that SAE insertion reduces loss in DLMs and enhances intervention efficacy.", "motivation": "Mechanistic interpretability tools for autoregressive LLMs exist, but diffusion language models (DLMs) lack tailored frameworks despite their emerging significance.", "method": "The authors proposed DLM-Scope using sparse autoencoders (Top-K SAEs) designed for DLMs and evaluated their impact on model behavior and features extracted.", "result": "The study reveals that SAE insertion in DLMs can reduce cross-entropy loss at early layers, enhance diffusion-time interventions, and provide useful signals for decoding order.", "conclusion": "DLM-Scope significantly advances the interpretability landscape for DLMs, showing that SAEs are effective in DLM-related tasks while paving new research directions."}}
{"id": "2602.05966", "pdf": "https://arxiv.org/pdf/2602.05966", "abs": "https://arxiv.org/abs/2602.05966", "authors": ["Mirlan Karimov", "Teodora Spasojevic", "Markus Braun", "Julian Wiederer", "Vasileios Belagiannis", "Marc Pollefeys"], "title": "LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to IEEE IV 2026. 8 pages, 3 figures. Code available at https://github.com/mirlanium/LSA", "summary": "Controllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, limiting their utility as scalable and generalizable data engines. In this work, we propose Localized Semantic Alignment (LSA), a simple yet effective framework for fine-tuning pre-trained video generation models. LSA enhances temporal consistency by aligning semantic features between ground-truth and generated video clips. Specifically, we compare the output of an off-the-shelf feature extraction model between the ground-truth and generated video clips localized around dynamic objects inducing a semantic feature consistency loss. We fine-tune the base model by combining this loss with the standard diffusion loss. The model fine-tuned for a single epoch with our novel loss outperforms the baselines in common video generation evaluation metrics. To further test the temporal consistency in generated videos we adapt two additional metrics from object detection task, namely mAP and mIoU. Extensive experiments on nuScenes and KITTI datasets show the effectiveness of our approach in enhancing temporal consistency in video generation without the need for external control signals during inference and any computational overheads.", "AI": {"tldr": "This paper proposes Localized Semantic Alignment (LSA), a framework to fine-tune video generation models for improved temporal consistency, with successful results demonstrated on the nuScenes and KITTI datasets.", "motivation": "Existing methods for controllable video generation in autonomous driving rely on control signals at inference time, limiting their scalability and generalizability. There is a need for a framework that ensures temporal consistency without additional control signals or computational overheads.", "method": "The paper introduces LSA, which aligns semantic features between ground-truth and generated videos around dynamic objects using a semantic feature consistency loss. This loss is combined with standard diffusion loss to fine-tune pre-trained video generation models.", "result": "The fine-tuned model using the proposed LSA framework significantly outperforms baseline models in video generation evaluation metrics. Fine-tuning for a single epoch yielded enhanced temporal consistency. Additional evaluation using adapted object detection metrics further validated its effectiveness.", "conclusion": "LSA offers a scalable and effective solution for improving temporal consistency in video generation for autonomous driving applications, eliminating the need for external control signals or additional computation during inference."}}
{"id": "2602.04943", "pdf": "https://arxiv.org/pdf/2602.04943", "abs": "https://arxiv.org/abs/2602.04943", "authors": ["Mahmud Ashraf Shamim", "Moshiur Rahman", "Mohamed Hibat-Allah", "Paulo T Araujo"], "title": "Graph--Theoretic Analysis of Phase Optimization Complexity in Variational Wave Functions for Heisenberg Antiferromagnets", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "cs.AI", "cs.CC", "quant-ph"], "comment": null, "summary": "Despite extensive study, the phase structure of the wavefunctions in frustrated Heisenberg antiferromagnets (HAF) is not yet systematically characterized. In this work, we represent the Hilbert space of an HAF as a weighted graph, which we term the Hilbert graph (HG), whose vertices are spin configurations and whose edges are generated by off-diagonal spin-flip terms of the Heisenberg Hamiltonian, with weights set by products of wavefunction amplitudes. Holding the amplitudes fixed and restricting phases to $\\mathbb{Z}_2$ values, the phase-dependent variational energy can be recast as a classical Ising antiferromagnet on the HG, so that phase reconstruction of the ground state reduces to a weighted Max-Cut instance. This shows that phase reconstruction HAF is worst-case NP-hard and provides a direct link between wavefunction sign structure and combinatorial optimization.", "AI": {"tldr": "The study introduces a novel Hilbert graph approach to analyze frustrated Heisenberg antiferromagnets (HAF), recasting phase reconstruction as a weighted Max-Cut problem, thus proving its NP-hardness and linking wavefunction sign structure to combinatorial optimization.", "motivation": "The motivation is to systematically characterize the phase structure of wavefunctions in frustrated Heisenberg antiferromagnets, which remains an unsolved problem despite extensive research.", "method": "The authors represent the Hilbert space of a frustrated Heisenberg antiferromagnet as a weighted graph (called a Hilbert graph), with vertices as spin configurations and edge weights determined by wavefunction amplitudes. They reformulate the phase reconstruction problem as a classical Ising antiferromagnet model on the graph, reducing it to a weighted Max-Cut optimization problem.", "result": "They demonstrate that phase reconstruction for Heisenberg antiferromagnets is worst-case NP-hard and establish a connection between wavefunction sign patterns and combinatorial optimization challenges.", "conclusion": "By reinterpreting phase reconstruction as an NP-hard combinatorial problem, the study provides a fresh perspective on analyzing Heisenberg antiferromagnets and their relation to optimization problems."}}
{"id": "2602.05549", "pdf": "https://arxiv.org/pdf/2602.05549", "abs": "https://arxiv.org/abs/2602.05549", "authors": ["Francesco Alesiani", "Jonathan Warrell", "Tanja Bien", "Henrik Christiansen", "Matheus Ferraz", "Mathias Niepert"], "title": "Logical Guidance for the Exact Composition of Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "We propose LOGDIFF (Logical Guidance for the Exact Composition of Diffusion Models), a guidance framework for diffusion models that enables principled constrained generation with complex logical expressions at inference time.\n  We study when exact score-based guidance for complex logical formulas can be obtained from guidance signals associated with atomic properties.\n  First, we derive an exact Boolean calculus that provides a sufficient condition for exact logical guidance.\n  Specifically, if a formula admits a circuit representation in which conjunctions combine conditionally independent subformulas and disjunctions combine subformulas that are either conditionally independent or mutually exclusive, exact logical guidance is achievable.\n  In this case, the guidance signal can be computed exactly from atomic scores and posterior probabilities using an efficient recursive algorithm.\n  Moreover, we show that, for commonly encountered classes of distributions, any desired Boolean formula is compilable into such a circuit representation.\n  Second, by combining atomic guidance scores with posterior probability estimates, we introduce a hybrid guidance approach that bridges classifierguidance and classifier-free guidance, applicable to both compositional logical guidance and standard conditional generation.\n  We demonstrate the effectiveness of our framework on multiple image and protein structure generation tasks.", "AI": {"tldr": "LOGDIFF is a guidance framework enabling principled constrained generation for diffusion models with complex logical constraints at inference, supported by exact Boolean calculus and hybrid guidance methods.", "motivation": "To address the need for structured and constrained generation in diffusion models, especially involving complex logical expressions, which are not easily handled using standard methods.", "method": "Introduced a Boolean calculus-based condition for exact logical guidance and a recursive algorithm for efficient computation of guidance signals. Developed a hybrid guidance approach integrating classifier guidance with classifier-free guidance.", "result": "LOGDIFF enables exact compositional logical guidance and achieves significant effectiveness in image and protein structure generation tasks under complex logical constraints.", "conclusion": "The proposed LOGDIFF framework provides a robust solution for constrained generation in diffusion models, extending their applicability to complex logical tasks with a principled and efficient approach."}}
{"id": "2602.05986", "pdf": "https://arxiv.org/pdf/2602.05986", "abs": "https://arxiv.org/abs/2602.05986", "authors": ["Mingxin Liu", "Shuran Ma", "Shibei Meng", "Xiangyu Zhao", "Zicheng Zhang", "Shaofeng Zhang", "Zhihang Zhong", "Peixian Chen", "Haoyu Cao", "Xing Sun", "Haodong Duan", "Xue Yang"], "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?", "categories": ["cs.CV", "cs.AI"], "comment": "38 pages, 16 figures, 3 tables; Code: https://github.com/VisionXLab/RISE-Video; HuggingFace: https://huggingface.co/datasets/VisionXLab/RISE-Video", "summary": "While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: \\textit{Reasoning Alignment}, \\textit{Temporal Consistency}, \\textit{Physical Rationality}, and \\textit{Visual Quality}. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.", "AI": {"tldr": "RISE-Video introduces a benchmark for evaluating reasoning capabilities in Text-Image-to-Video (TI2V) synthesis, assessing models on reasoning, consistency, rationality, and quality.", "motivation": "The paper aims to improve the cognitive reasoning aspect of generative video models beyond their visual fidelity by creating a benchmark for in-depth evaluation.", "method": "RISE-Video includes 467 human-annotated samples in diverse categories and proposes metrics for evaluation. An automated evaluation pipeline using Large Multimodal Models (LMMs) is introduced.", "result": "Experiments on 11 TI2V models demonstrate limitations in reasoning and suggest the need for advancements in generative modeling.", "conclusion": "RISE-Video establishes a structured approach to evaluate the reasoning abilities of generative video models, guiding future improvement in world-simulating systems."}}
{"id": "2602.04944", "pdf": "https://arxiv.org/pdf/2602.04944", "abs": "https://arxiv.org/abs/2602.04944", "authors": ["Shayan Abrar", "Samura Rahman", "Ishrat Jahan Momo", "Mahjabin Tasnim Samiha", "B. M. Shahria Alam", "Mohammad Tahmid Noor", "Nishat Tasnim Niloy"], "title": "Smart Diagnosis and Early Intervention in PCOS: A Deep Learning Approach to Women's Reproductive Health", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": "6 pages, 12 figures. This is the author's accepted manuscript of a paper accepted for publication in the Proceedings of the 16th International IEEE Conference on Computing, Communication and Networking Technologies (ICCCNT 2025). The final published version will be available via IEEE Xplore", "summary": "Polycystic Ovary Syndrome (PCOS) is a widespread disorder in women of reproductive age, characterized by a hormonal imbalance, irregular periods, and multiple ovarian cysts. Infertility, metabolic syndrome, and cardiovascular risks are long-term complications that make early detection essential. In this paper, we design a powerful framework based on transfer learning utilizing DenseNet201 and ResNet50 for classifying ovarian ultrasound images. The model was trained on an online dataset containing 3856 ultrasound images of cyst-infected and non-infected patients. Each ultrasound frame was resized to 224x224 pixels and encoded with precise pathological indicators. The MixUp and CutMix augmentation strategies were used to improve generalization, yielding a peak validation accuracy of 99.80% by Densenet201 and a validation loss of 0.617 with alpha values of 0.25 and 0.4, respectively. We evaluated the model's interpretability using leading Explainable AI (XAI) approaches such as SHAP, Grad-CAM, and LIME, reasoning with and presenting explicit visual reasons for the model's behaviors, therefore increasing the model's transparency. This study proposes an automated system for medical picture diagnosis that may be used effectively and confidently in clinical practice.", "AI": {"tldr": "The paper addresses early PCOS detection by using a deep learning framework, DenseNet201 and ResNet50, to classify ovarian ultrasound images, achieving high validation accuracy and employing various explainability methods.", "motivation": "The motivation is to tackle the widespread and serious complications of PCOS, such as infertility and cardiovascular risks, by creating a reliable automated diagnostic tool based on ultrasound image classification.", "method": "The authors employed DenseNet201 and ResNet50 architectures for classifying ultrasound images, applied MixUp and CutMix for data augmentation, and used SHAP, Grad-CAM, and LIME for interpretability.", "result": "The DenseNet201 model achieved a remarkable validation accuracy of 99.80% and a validation loss of 0.617 with specific alpha values. The explainability tools provided transparent visual insights.", "conclusion": "The study presents an effective, accurate, and interpretable deep learning-based system for diagnosing PCOS, which holds significant potential for clinical integration."}}
{"id": "2602.05567", "pdf": "https://arxiv.org/pdf/2602.05567", "abs": "https://arxiv.org/abs/2602.05567", "authors": ["Long D. Nguyen", "Binh P. Nguyen"], "title": "MAGPrompt: Message-Adaptive Graph Prompt Tuning for Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Pre-trained graph neural networks (GNNs) transfer well, but adapting them to downstream tasks remains challenging due to mismatches between pre-training objectives and task requirements. Graph prompt tuning offers a parameter-efficient alternative to fine-tuning, yet most methods only modify inputs or representations and leave message passing unchanged, limiting their ability to adapt neighborhood interactions. We propose message-adaptive graph prompt tuning, which injects learnable prompts into the message passing step to reweight incoming neighbor messages and add task-specific prompt vectors during message aggregation, while keeping the backbone GNN frozen. The approach is compatible with common GNN backbones and pre-training strategies, and applicable across downstream settings. Experiments on diverse node- and graph-level datasets show consistent gains over prior graph prompting methods in few-shot settings, while achieving performance competitive with fine-tuning in full-shot regimes.", "AI": {"tldr": "The paper introduces a new method, message-adaptive graph prompt tuning, to make pre-trained graph neural networks better at adapting to downstream tasks. It achieves consistent improvement over prior methods in few-shot learning and competitive results in full-shot conditions.", "motivation": "Current graph neural networks face difficulty when adapting pre-trained models to downstream tasks due to mismatches in training objectives. Existing graph prompt tuning methods don't address neighborhood interactions effectively.", "method": "The paper proposes a method called message-adaptive graph prompt tuning. It introduces learnable prompts into the message passing phase of GNNs to reweight neighbor messages and add task-specific prompt vectors during message aggregation, keeping the backbone GNN unchanged.", "result": "Experiments show that the proposed method achieves consistent improvements in few-shot learning and performs as well as fine-tuning approaches in full-shot regimes, across diverse datasets.", "conclusion": "Message-adaptive graph prompt tuning is an efficient and effective way to adapt pre-trained GNNs to various downstream tasks while maintaining competitive performance with traditional fine-tuning."}}
{"id": "2602.05885", "pdf": "https://arxiv.org/pdf/2602.05885", "abs": "https://arxiv.org/abs/2602.05885", "authors": ["Wei Liu", "Jiawei Xu", "Yingru Li", "Longtao Zheng", "Tianjian Li", "Qian Liu", "Junxian He"], "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these cases, models may hack training rewards and prioritize trivial correctness over meaningful speedup. In this paper, we systematically study reinforcement learning (RL) for kernel generation. We first design KernelGYM, a robust distributed GPU environment that supports reward hacking check, data collection from multi-turn interactions and long-term RL training. Building on KernelGYM, we investigate effective multi-turn RL methods and identify a biased policy gradient issue caused by self-inclusion in GRPO. To solve this, we propose Turn-level Reinforce-Leave-One-Out (TRLOO) to provide unbiased advantage estimation for multi-turn RL. To alleviate lazy optimization, we incorporate mismatch correction for training stability and introduce Profiling-based Rewards (PR) and Profiling-based Rejection Sampling (PRS) to overcome the issue. The trained model, Dr.Kernel-14B, reaches performance competitive with Claude-4.5-Sonnet in Kernelbench. Finally, we study sequential test-time scaling for Dr.Kernel-14B. On the KernelBench Level-2 subset, 31.6% of the generated kernels achieve at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet (26.7%) and GPT-5 (28.6%). When selecting the best candidate across all turns, this 1.2x speedup rate further increases to 47.8%. All resources, including environment, training code, models, and dataset, are included in https://www.github.com/hkust-nlp/KernelGYM.", "AI": {"tldr": "This paper introduces KernelGYM, a distributed environment for kernel generation using reinforcement learning. It presents methods to mitigate reward hacking and enhance training, resulting in Dr.Kernel-14B that outperforms competitors in kernel performance benchmarks.", "motivation": "The motivation is to enable large language models (LLMs) to generate high-quality kernel code to advance scalable AI systems while overcoming issues like reward hacking, lazy optimization, and training instability in RL-based kernel generation.", "method": "The researchers developed KernelGYM for multi-turn RL, solved a policy gradient issue using TRLOO, introduced Profiling-based Rewards, and Profiling-based Rejection Sampling to stabilize training and mitigate optimization issues.", "result": "The model, Dr.Kernel-14B, performs competitively with Claude-4.5-Sonnet and GPT-5, achieving better speedup rates on the KernelBench Level-2 subset. It demonstrates robust kernel performance improving over reference implementations.", "conclusion": "KernelGYM significantly advances RL-based kernel generation with effective training methods, setting a new benchmark in kernel optimization. The provided resources ensure reproducibility and further development in this domain."}}
{"id": "2602.05998", "pdf": "https://arxiv.org/pdf/2602.05998", "abs": "https://arxiv.org/abs/2602.05998", "authors": ["Jie Deng", "Kaichun Yao", "Libo Zhang"], "title": "VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation", "categories": ["cs.CV"], "comment": null, "summary": "Screenshot-to-code generation aims to translate user interface screenshots into executable frontend code that faithfully reproduces the target layout and style. Existing multimodal large language models perform this mapping directly from screenshots but are trained without observing the visual outcomes of their generated code. In contrast, human developers iteratively render their implementation, compare it with the design, and learn how visual differences relate to code changes. Inspired by this process, we propose VisRefiner, a training framework that enables models to learn from visual differences between rendered predictions and reference designs. We construct difference-aligned supervision that associates visual discrepancies with corresponding code edits, allowing the model to understand how appearance variations arise from implementation changes. Building on this, we introduce a reinforcement learning stage for self-refinement, where the model improves its generated code by observing both the rendered output and the target design, identifying their visual differences, and updating the code accordingly. Experiments show that VisRefiner substantially improves single-step generation quality and layout fidelity, while also endowing models with strong self-refinement ability. These results demonstrate the effectiveness of learning from visual differences for advancing screenshot-to-code generation.", "AI": {"tldr": "This paper introduces VisRefiner, a framework to improve screenshot-to-code generation by allowing models to learn from visual differences between their generated designs and target designs.", "motivation": "Existing models translate UI screenshots to code directly but fail to observe the visual outcomes of their generated code, unlike human developers who iteratively refine implementations by comparing visuals.", "method": "The VisRefiner framework uses difference-aligned supervision to link visual discrepancies to code edits and incorporates a reinforcement learning stage for self-refinement based on rendered visual feedback.", "result": "VisRefiner significantly improves the quality of single-step code generation and layout fidelity. It also enables models to self-refine their outputs effectively.", "conclusion": "Learning from visual discrepancies greatly enhances the accuracy and efficiency of screenshot-to-code generation models."}}
{"id": "2602.05571", "pdf": "https://arxiv.org/pdf/2602.05571", "abs": "https://arxiv.org/abs/2602.05571", "authors": ["Rishabh Bhattacharya", "Naresh Manwani"], "title": "EdgeMask-DG*: Learning Domain-Invariant Graph Structures via Adversarial Edge Masking", "categories": ["cs.LG"], "comment": null, "summary": "Structural shifts pose a significant challenge for graph neural networks, as graph topology acts as a covariate that can vary across domains. Existing domain generalization methods rely on fixed structural augmentations or training on globally perturbed graphs, mechanisms that do not pinpoint which specific edges encode domain-invariant information. We argue that domain-invariant structural information is not rigidly tied to a single topology but resides in the consensus across multiple graph structures derived from topology and feature similarity. To capture this, we first propose EdgeMask-DG, a novel min-max algorithm where an edge masker learns to find worst-case continuous masks subject to a sparsity constraint, compelling a task GNN to perform effectively under these adversarial structural perturbations. Building upon this, we introduce EdgeMask-DG*, an extension that applies this adversarial masking principle to an enriched graph. This enriched graph combines the original topology with feature-derived edges, allowing the model to discover invariances even when the original topology is noisy or domain-specific. EdgeMask-DG* is the first to systematically combine adaptive adversarial topology search with feature-enriched graphs. We provide a formal justification for our approach from a robust optimization perspective. We demonstrate that EdgeMask-DG* achieves new state-of-the-art performance on diverse graph domain generalization benchmarks, including citation networks, social networks, and temporal graphs. Notably, on the Cora OOD benchmark, EdgeMask-DG* lifts the worst-case domain accuracy to 78.0\\%, a +3.8 pp improvement over the prior state of the art (74.2\\%). The source code for our experiments can be found here: https://anonymous.4open.science/r/TMLR-EAEF/", "AI": {"tldr": "The paper introduces EdgeMask-DG and EdgeMask-DG*, novel approaches for addressing domain generalization challenges in graph neural networks by leveraging adversarial edge masking and enriched graphs.", "motivation": "Graph neural networks struggle with structural shifts due to domain-specific variations in graph topology, hindering their generalization ability across different domains.", "method": "EdgeMask-DG employs a min-max algorithm for adversarial structural perturbation, while EdgeMask-DG* extends this principle to enriched graphs combining topology and feature-derived edges.", "result": "EdgeMask-DG* achieves state-of-the-art domain generalization performance, notably improving worst-case accuracy on benchmarks like Cora OOD.", "conclusion": "EdgeMask-DG* systematically combines adversarial topology optimization with enriched graphs, advancing the robustness and performance of graph neural networks in diverse domains."}}
{"id": "2602.05890", "pdf": "https://arxiv.org/pdf/2602.05890", "abs": "https://arxiv.org/abs/2602.05890", "authors": ["Dingwei Zhu", "Zhiheng Xi", "Shihan Dou", "Jiahan Li", "Chenhao Huang", "Junjie Ye", "Sixian Li", "Mingxu Chai", "Yuhui Wang", "Yajie Yang", "Ming Zhang", "Jiazheng Zhang", "Shichun Liu", "Caishuang Huang", "Yunke Zhang", "Yuran Wang", "Tao Gui", "Xipeng Qiu", "Qi Zhang", "Xuanjing Huang"], "title": "DFPO: Scaling Value Modeling via Distributional Flow towards Robust and Generalizable LLM Post-Training", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Training reinforcement learning (RL) systems in real-world environments remains challenging due to noisy supervision and poor out-of-domain (OOD) generalization, especially in LLM post-training. Recent distributional RL methods improve robustness by modeling values with multiple quantile points, but they still learn each quantile independently as a scalar. This results in rough-grained value representations that lack fine-grained conditioning on state information, struggling under complex and OOD conditions. We propose DFPO (Distributional Value Flow Policy Optimization with Conditional Risk and Consistency Control), a robust distributional RL framework that models values as continuous flows across time steps. By scaling value modeling through learning of a value flow field instead of isolated quantile predictions, DFPO captures richer state information for more accurate advantage estimation. To stabilize training under noisy feedback, DFPO further integrates conditional risk control and consistency constraints along value flow trajectories. Experiments on dialogue, math reasoning, and scientific tasks show that DFPO outperforms PPO, FlowRL, and other robust baselines under noisy supervision, achieving improved training stability and generalization.", "AI": {"tldr": "The paper introduces DFPO, a distributional RL framework designed for better performance under noisy supervision and out-of-domain scenarios by modeling continuous value flows.", "motivation": "The study aims to address the challenges RL systems face with noisy feedback and poor out-of-domain generalization, especially when applied to language model post-training.", "method": "DFPO improves robustness by moving from scalar quantile models to continuous value flows. It integrates conditional risk control and consistency constraints along these flows to improve stability and accuracy.", "result": "Compared to existing baselines like PPO and FlowRL, DFPO demonstrates superior stability and generalization in tasks such as dialogue, math reasoning, and scientific problem-solving.", "conclusion": "By employing continuous value flows with stability-enhancing features, DFPO leads to more robust RL systems capable of handling noisy supervision and achieving better generalization."}}
{"id": "2602.06013", "pdf": "https://arxiv.org/pdf/2602.06013", "abs": "https://arxiv.org/abs/2602.06013", "authors": ["Ruihang Li", "Leigang Qu", "Jingxu Zhang", "Dongnan Gui", "Mengde Xu", "Xiaosong Zhang", "Han Hu", "Wenjie Wang", "Jiaqi Wang"], "title": "GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?", "categories": ["cs.CV", "cs.AI"], "comment": "Project Page: https://genarena.github.io/, Code: https://github.com/ruihanglix/genarena", "summary": "The rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematically investigate the reliability of the prevailing absolute pointwise scoring standard, across a wide spectrum of visual generation tasks. Our analysis reveals that this paradigm is limited due to stochastic inconsistency and poor alignment with human perception. To resolve these limitations, we introduce GenArena, a unified evaluation framework that leverages a pairwise comparison paradigm to ensure stable and human-aligned evaluation. Crucially, our experiments uncover a transformative finding that simply adopting this pairwise protocol enables off-the-shelf open-source models to outperform top-tier proprietary models. Notably, our method boosts evaluation accuracy by over 20% and achieves a Spearman correlation of 0.86 with the authoritative LMArena leaderboard, drastically surpassing the 0.36 correlation of pointwise methods. Based on GenArena, we benchmark state-of-the-art visual generation models across diverse tasks, providing the community with a rigorous and automated evaluation standard for visual generation.", "AI": {"tldr": "Visual generation models require better evaluation methods; GenArena introduces pairwise comparison for more reliable assessments.", "motivation": "Traditional evaluation methods for visual generation models are inconsistent and misaligned with human perception.", "method": "This paper proposes GenArena, a framework leveraging pairwise comparison for evaluating visual generation models.", "result": "GenArena surpasses conventional methods by improving evaluation accuracy, achieving a Spearman correlation of 0.86 with authoritative benchmarks, and highlighting open-source models often outperform proprietary ones when evaluated through its protocol.", "conclusion": "GenArena offers a systematic, human-aligned, and automated evaluation standard for visual generation, addressing the shortcomings of pointwise scoring."}}
{"id": "2602.04983", "pdf": "https://arxiv.org/pdf/2602.04983", "abs": "https://arxiv.org/abs/2602.04983", "authors": ["Seungbin Park", "Peilin Wang", "Ryan Pennell", "Emily S. Weg", "Himanshu Nagar", "Timothy McClure", "Mert R. Sabuncu", "Daniel Margolis", "Heejong Kim"], "title": "AI-Based Detection of In-Treatment Changes from Prostate MR-Linac Images", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": null, "summary": "Purpose: To investigate whether routinely acquired longitudinal MR-Linac images can be leveraged to characterize treatment-induced changes during radiotherapy, particularly subtle inter-fraction changes over short intervals (average of 2 days). Materials and Methods: This retrospective study included a series of 0.35T MR-Linac images from 761 patients. An artificial intelligence (deep learning) model was used to characterize treatment-induced changes by predicting the temporal order of paired images. The model was first trained with the images from the first and the last fractions (F1-FL), then with all pairs (All-pairs). Model performance was assessed using quantitative metrics (accuracy and AUC), compared to a radiologist's performance, and qualitative analyses - the saliency map evaluation to investigate affected anatomical regions. Input ablation experiments were performed to identify the anatomical regions altered by radiotherapy. The radiologist conducted an additional task on partial images reconstructed by saliency map regions, reporting observations as well. Quantitative image analysis was conducted to investigate the results from the model and the radiologist. Results: The F1-FL model yielded near-perfect performance (AUC of 0.99), significantly outperforming the radiologist. The All-pairs model yielded an AUC of 0.97. This performance reflects therapy-induced changes, supported by the performance correlation to fraction intervals, ablation tests and expert's interpretation. Primary regions driving the predictions were prostate, bladder, and pubic symphysis. Conclusion: The model accurately predicts temporal order of MR-Linac fractions and detects radiation-induced changes over one or a few days, including prostate and adjacent organ alterations confirmed by experts. This underscores MR-Linac's potential for advanced image analysis beyond image guidance.", "AI": {"tldr": "The study explores the use of longitudinal MR-Linac images with AI models to characterize treatment-induced changes during radiotherapy, demonstrating high accuracy in detecting subtle alterations over short intervals.", "motivation": "The motivation is to utilize routinely acquired MR-Linac images for assessing short-term radiation-induced anatomical changes during radiotherapy, aiming to advance understanding and improve patient care.", "method": "Retrospective analysis using MR-Linac images from 761 patients. Deep learning models were trained to predict the temporal order of image pairs, with performance compared to radiologist assessments and evaluated using saliency maps, ablation tests, and image analysis.", "result": "The AI model performed with near-perfect accuracy (AUC of 0.99) when comparing first-to-last fractions and AUC of 0.97 for all pairs, outperforming radiologists. Key altered anatomical regions identified included the prostate, bladder, and pubic symphysis.", "conclusion": "The AI model effectively detects short-term treatment-induced changes in MR-Linac images, highlighting their potential for advanced radiotherapy understanding and guidance."}}
{"id": "2602.05576", "pdf": "https://arxiv.org/pdf/2602.05576", "abs": "https://arxiv.org/abs/2602.05576", "authors": ["Chenxi Wan", "Xunkai Li", "Yilong Zuo", "Haokun Deng", "Sihan Li", "Bowen Fan", "Hongchao Qin", "Ronghua Li", "Guoren Wang"], "title": "OpenMAG: A Comprehensive Benchmark for Multimodal-Attributed Graph", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal-Attributed Graph (MAG) learning has achieved remarkable success in modeling complex real-world systems by integrating graph topology with rich attributes from multiple modalities. With the rapid proliferation of novel MAG models capable of handling intricate cross-modal semantics and structural dependencies, establishing a rigorous and unified evaluation standard has become imperative. Although existing benchmarks have facilitated initial progress, they exhibit critical limitations in domain coverage, encoder flexibility, model diversity, and task scope, presenting significant challenges to fair evaluation. To bridge this gap, we present OpenMAG, a comprehensive benchmark that integrates 19 datasets across 6 domains and incorporates 16 encoders to support both static and trainable feature encoding. OpenMAG further implements a standardized library of 24 state-of-the-art models and supports 8 downstream tasks, enabling fair comparisons within a unified framework. Through systematic assessment of necessity, data quality, effectiveness, robustness, and efficiency, we derive 14 fundamental insights into MAG learning to guide future advancements. Our code is available at https://github.com/YUKI-N810/OpenMAG.", "AI": {"tldr": "The paper introduces OpenMAG, a benchmark for evaluating Multimodal-Attributed Graph (MAG) models. It integrates extensive datasets, encoders, models, and tasks to ensure rigorous and fair comparisons.", "motivation": "The need for standardized, comprehensive, and fair evaluation methods arises due to the proliferation of sophisticated MAG models.", "method": "The authors consolidate 19 datasets, 16 encoders, 24 models, and 8 tasks into a unified framework for benchmarking MAG models.", "result": "OpenMAG enables systematic assessments and provides 14 insights to advance MAG learning. The framework ensures consistency in evaluating models across diverse domains.", "conclusion": "OpenMAG establishes a robust standard for MAG model evaluation, fostering comparisons and aiding future research development."}}
{"id": "2602.05975", "pdf": "https://arxiv.org/pdf/2602.05975", "abs": "https://arxiv.org/abs/2602.05975", "authors": ["Tiansheng Hu", "Yilun Zhao", "Canyu Zhang", "Arman Cohan", "Chen Zhao"], "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents", "categories": ["cs.IR", "cs.CL"], "comment": "Submission to ACL ARR 2026 January", "summary": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.", "AI": {"tldr": "Deep research agents, strong in addressing intricate queries, struggle with reasoning-intensive retrieval tasks. BM25 surprisingly outperformed LLM-based retrievers in scientific literature retrieval.", "motivation": "The study aims to examine if LLM-based retrievers can enhance the workflows of deep research agents for scientific literature retrieval.", "method": "Introduced SAGE benchmark with 1,200 queries across four scientific domains and evaluated six deep research agents. Also compared BM25 and LLM-based retrievers with a test-time scaling framework.", "result": "BM25 performed 30% better than LLM-based retrievers, and proposed corpus-level test-time scaling enhances retrieval performance by 8% for short queries and 2% for open-ended ones.", "conclusion": "While LLM-based retrievers struggle with keyword-oriented sub-queries, test-time scaling improves retrieval outcomes. BM25 remains more effective under current conditions."}}
{"id": "2602.06017", "pdf": "https://arxiv.org/pdf/2602.06017", "abs": "https://arxiv.org/abs/2602.06017", "authors": ["Zixiang Zhao", "Yukun Cui", "Lilun Deng", "Haowen Bai", "Haotong Qin", "Tao Feng", "Konrad Schindler"], "title": "MambaVF: State Space Model for Efficient Video Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Video fusion is a fundamental technique in various video processing tasks. However, existing video fusion methods heavily rely on optical flow estimation and feature warping, resulting in severe computational overhead and limited scalability. This paper presents MambaVF, an efficient video fusion framework based on state space models (SSMs) that performs temporal modeling without explicit motion estimation. First, by reformulating video fusion as a sequential state update process, MambaVF captures long-range temporal dependencies with linear complexity while significantly reducing computation and memory costs. Second, MambaVF proposes a lightweight SSM-based fusion module that replaces conventional flow-guided alignment via a spatio-temporal bidirectional scanning mechanism. This module enables efficient information aggregation across frames. Extensive experiments across multiple benchmarks demonstrate that our MambaVF achieves state-of-the-art performance in multi-exposure, multi-focus, infrared-visible, and medical video fusion tasks. We highlight that MambaVF enjoys high efficiency, reducing up to 92.25% of parameters and 88.79% of computational FLOPs and a 2.1x speedup compared to existing methods. Project page: https://mambavf.github.io", "AI": {"tldr": "MambaVF is a novel video fusion framework using state space models, reducing computational overhead and achieving state-of-the-art results across various fusion tasks.", "motivation": "The high computational cost and limited scalability of current video fusion methods prompted the design of MambaVF, aimed at efficient temporal modeling without requiring motion estimation.", "method": "MambaVF reformulates video fusion as a state update process using state space models and introduces a spatio-temporal bidirectional scanning mechanism for efficient information aggregation.", "result": "MambaVF reduces parameters by up to 92.25%, computational costs by 88.79%, and achieves a 2.1x speedup, while delivering state-of-the-art performance in diverse video fusion tasks.", "conclusion": "MambaVF provides a highly efficient and scalable solution for video fusion by eliminating reliance on optical flow estimation, showcasing superior performance and significant computational gains."}}
{"id": "2602.05600", "pdf": "https://arxiv.org/pdf/2602.05600", "abs": "https://arxiv.org/abs/2602.05600", "authors": ["Yikuan Zhang", "Ning Yang", "Yuhai Tu"], "title": "On the Superlinear Relationship between SGD Noise Covariance and Loss Landscape Curvature", "categories": ["cs.LG"], "comment": "8 pages, 15 figures", "summary": "Stochastic Gradient Descent (SGD) introduces anisotropic noise that is correlated with the local curvature of the loss landscape, thereby biasing optimization toward flat minima. Prior work often assumes an equivalence between the Fisher Information Matrix and the Hessian for negative log-likelihood losses, leading to the claim that the SGD noise covariance $\\mathbf{C}$ is proportional to the Hessian $\\mathbf{H}$. We show that this assumption holds only under restrictive conditions that are typically violated in deep neural networks. Using the recently discovered Activity--Weight Duality, we find a more general relationship agnostic to the specific loss formulation, showing that $\\mathbf{C} \\propto \\mathbb{E}_p[\\mathbf{h}_p^2]$, where $\\mathbf{h}_p$ denotes the per-sample Hessian with $\\mathbf{H} = \\mathbb{E}_p[\\mathbf{h}_p]$. As a consequence, $\\mathbf{C}$ and $\\mathbf{H}$ commute approximately rather than coincide exactly, and their diagonal elements follow an approximate power-law relation $C_{ii} \\propto H_{ii}^\u03b3$ with a theoretically bounded exponent $1 \\leq \u03b3\\leq 2$, determined by per-sample Hessian spectra. Experiments across datasets, architectures, and loss functions validate these bounds, providing a unified characterization of the noise-curvature relationship in deep learning.", "AI": {"tldr": "The paper challenges the common assumption that the SGD noise covariance matrix is proportional to the Hessian and presents a new relationship based on per-sample Hessians, validated through experiments.", "motivation": "Address misconceptions regarding the relationship between SGD noise covariance and the loss landscape curvature, aiming to provide a unified understanding in deep learning optimization.", "method": "Utilizes Activity--Weight Duality to establish a new relationship between SGD noise covariance and per-sample Hessians, supplemented by theoretical analysis and experimental validations.", "result": "Finds that the covariance matrix and Hessian approximately commute instead of being proportional, with diagonal elements showing a power-law relation defined by experimental bounds across various scenarios.", "conclusion": "Reveals deeper insights into the noise-curvature relationship in deep learning optimization, refining prior assumptions and providing a more general characterization."}}
{"id": "2602.06028", "pdf": "https://arxiv.org/pdf/2602.06028", "abs": "https://arxiv.org/abs/2602.06028", "authors": ["Shuo Chen", "Cong Wei", "Sun Sun", "Ping Nie", "Kai Zhou", "Ge Zhang", "Ming-Hsuan Yang", "Wenhu Chen"], "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context", "categories": ["cs.CV"], "comment": null, "summary": "Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \\textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global temporal dependencies, effectively capping the student's context length. To resolve this, we propose \\textbf{Context Forcing}, a novel framework that trains a long-context student via a long-context teacher. By ensuring the teacher is aware of the full generation history, we eliminate the supervision mismatch, enabling the robust training of models capable of long-term consistency. To make this computationally feasible for extreme durations (e.g., 2 minutes), we introduce a context management system that transforms the linearly growing context into a \\textbf{Slow-Fast Memory} architecture, significantly reducing visual redundancy. Extensive results demonstrate that our method enables effective context lengths exceeding 20 seconds -- 2 to 10 times longer than state-of-the-art methods like LongLive and Infinite-RoPE. By leveraging this extended context, Context Forcing preserves superior consistency across long durations, surpassing state-of-the-art baselines on various long video evaluation metrics.", "AI": {"tldr": "The paper proposes a method called Context Forcing to improve long-context training in real-time video generation, addressing the shortcomings of current short-context teacher models.", "motivation": "Existing video generation methods face issues due to a mismatch between short-context teacher models and long-context students, limiting the ability to model long-term dependencies.", "method": "The proposed Context Forcing framework uses a long-context teacher and introduces a Slow-Fast Memory architecture to manage memory efficiently and reduce visual redundancy for long video generation.", "result": "The approach achieved effective context lengths exceeding 20 seconds, which is significantly longer (2-10 times) than existing methods like LongLive and Infinite-RoPE, and improved consistency over long durations.", "conclusion": "Context Forcing improves long-term consistency in video generation and surpasses existing methods in handling global temporal dependencies for extended durations."}}
{"id": "2602.05605", "pdf": "https://arxiv.org/pdf/2602.05605", "abs": "https://arxiv.org/abs/2602.05605", "authors": ["Jiaji Zhang", "Hailiang Zhao", "Guoxuan Zhu", "Ruichao Sun", "Jiaju Wu", "Xinkui Zhao", "Hanlin Tang", "Weiyi Lu", "Kan Liu", "Tao Lan", "Lin Qu", "Shuiguang Deng"], "title": "Shiva-DiT: Residual-Based Differentiable Top-$k$ Selection for Efficient Diffusion Transformers", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Diffusion Transformers (DiTs) incur prohibitive computational costs due to the quadratic scaling of self-attention. Existing pruning methods fail to simultaneously satisfy differentiability, efficiency, and the strict static budgets required for hardware overhead. To address this, we propose Shiva-DiT, which effectively reconciles these conflicting requirements via Residual-Based Differentiable Top-$k$ Selection. By leveraging a residual-aware straight-through estimator, our method enforces deterministic token counts for static compilation while preserving end-to-end learnability through residual gradient estimation. Furthermore, we introduce a Context-Aware Router and Adaptive Ratio Policy to autonomously learn an adaptive pruning schedule. Experiments on mainstream models, including SD3.5, demonstrate that Shiva-DiT establishes a new Pareto frontier, achieving a 1.54$\\times$ wall-clock speedup with superior fidelity compared to existing baselines, effectively eliminating ragged tensor overheads.", "AI": {"tldr": "Shiva-DiT addresses computational cost challenges in Diffusion Transformers by proposing a novel pruning method that balances efficiency, differentiability, and hardware constraints.", "motivation": "Current Diffusion Transformers suffer from high computational demands due to quadratic self-attention scaling, and existing solutions fall short of addressing strict computational budgets and differentiability simultaneously.", "method": "Shiva-DiT introduces Residual-Based Differentiable Top-$k$ Selection with a residual-aware straight-through estimator to ensure deterministic token counts, retain learnability, and minimize ragged tensor overheads. It also uses a Context-Aware Router and Adaptive Ratio Policy for adaptive pruning.", "result": "Shiva-DiT achieves a 1.54\u00d7 wall-clock speedup with higher fidelity compared to baselines, pushing a new Pareto frontier for Diffusion Transformers.", "conclusion": "Shiva-DiT effectively optimizes computational efficiency while maintaining performance quality and adhering to hardware constraints, outperforming existing methods."}}
{"id": "2602.06032", "pdf": "https://arxiv.org/pdf/2602.06032", "abs": "https://arxiv.org/abs/2602.06032", "authors": ["David Shavin", "Sagie Benaim"], "title": "Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2026", "summary": "Vision Foundation Models (VFMs) have achieved remarkable success when applied to various downstream 2D tasks. Despite their effectiveness, they often exhibit a critical lack of 3D awareness. To this end, we introduce Splat and Distill, a framework that instills robust 3D awareness into 2D VFMs by augmenting the teacher model with a fast, feed-forward 3D reconstruction pipeline. Given 2D features produced by a teacher model, our method first lifts these features into an explicit 3D Gaussian representation, in a feedforward manner. These 3D features are then ``splatted\" onto novel viewpoints, producing a set of novel 2D feature maps used to supervise the student model, ``distilling\" geometrically grounded knowledge. By replacing slow per-scene optimization of prior work with our feed-forward lifting approach, our framework avoids feature-averaging artifacts, creating a dynamic learning process where the teacher's consistency improves alongside that of the student. We conduct a comprehensive evaluation on a suite of downstream tasks, including monocular depth estimation, surface normal estimation, multi-view correspondence, and semantic segmentation. Our method significantly outperforms prior works, not only achieving substantial gains in 3D awareness but also enhancing the underlying semantic richness of 2D features. Project page is available at https://davidshavin4.github.io/Splat-and-Distill/", "AI": {"tldr": "The paper presents a framework called \"Splat and Distill\" to add robust 3D awareness to 2D Vision Foundation Models (VFMs), enabling improvements in tasks like monocular depth estimation and semantic segmentation.", "motivation": "While VFMs excel in 2D tasks, they lack 3D awareness, which limits their applicability to scenarios where 3D understanding is crucial.", "method": "The framework uses a feed-forward 3D reconstruction pipeline to lift 2D features into a 3D Gaussian representation, projects them onto new viewpoints, and then supervises the student model by transferring 3D-aware knowledge.", "result": "The new approach yields superior 3D awareness and improved semantic richness, outperforming previous methods across several downstream tasks like depth estimation and semantic segmentation.", "conclusion": "Splat and Distill introduces an effective strategy for teaching VFMs 3D awareness, avoiding prior limitations and achieving state-of-the-art results on multiple benchmarks."}}
{"id": "2602.05616", "pdf": "https://arxiv.org/pdf/2602.05616", "abs": "https://arxiv.org/abs/2602.05616", "authors": ["Xuhui Li", "Zhengquan Luo", "Xiwei Liu", "Yongqiang Yu", "Zhiqiang Xu"], "title": "Path-Guided Flow Matching for Dataset Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dataset distillation compresses large datasets into compact synthetic sets with comparable performance in training models. Despite recent progress on diffusion-based distillation, this type of method typically depends on heuristic guidance or prototype assignment, which comes with time-consuming sampling and trajectory instability and thus hurts downstream generalization especially under strong control or low IPC. We propose \\emph{Path-Guided Flow Matching (PGFM)}, the first flow matching-based framework for generative distillation, which enables fast deterministic synthesis by solving an ODE in a few steps. PGFM conducts flow matching in the latent space of a frozen VAE to learn class-conditional transport from Gaussian noise to data distribution. Particularly, we develop a continuous path-to-prototype guidance algorithm for ODE-consistent path control, which allows trajectories to reliably land on assigned prototypes while preserving diversity and efficiency. Extensive experiments across high-resolution benchmarks demonstrate that PGFM matches or surpasses prior diffusion-based distillation approaches with fewer steps of sampling while delivering competitive performance with remarkably improved efficiency, e.g., 7.6$\\times$ more efficient than the diffusion-based counterparts with 78\\% mode coverage.", "AI": {"tldr": "The paper introduces Path-Guided Flow Matching (PGFM), a flow matching framework for efficient dataset distillation, significantly improving synthesis and generalization compared to previous diffusion-based methods.", "motivation": "The paper aims to address inefficiencies and trajectory instability in diffusion-based dataset distillation methods, especially under strong control or low Images Per Class (IPC).", "method": "PGFM employs flow matching in the latent space of a frozen VAE to learn class-conditional transport from Gaussian noise to data. A new path-to-prototype guidance algorithm for ODE-consistent control improves reliability, diversity, and efficiency.", "result": "Experiments show that PGFM surpasses prior distillation methods in efficiency and matches or exceeds their generalization performance, with up to 7.6 times faster synthesis and 78% mode coverage.", "conclusion": "PGFM is a promising alternative to diffusion-based distillation, offering faster synthesis, improved performance, and higher efficiency while reliably maintaining diversity in datasets."}}
{"id": "2602.06034", "pdf": "https://arxiv.org/pdf/2602.06034", "abs": "https://arxiv.org/abs/2602.06034", "authors": ["Dongyang Chen", "Chaoyang Wang", "Dezhao SU", "Xi Xiao", "Zeyu Zhang", "Jing Xiong", "Qing Li", "Yuzhang Shang", "Shichao Ka"], "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.", "AI": {"tldr": "The paper introduces V-Retrver, an evidence-driven framework enhancing multimodal large language models (MLLMs) for retrieval tasks by incorporating a reasoning process grounded in fine-grained visual verification.", "motivation": "Current MLLMs for multimodal retrieval rely mostly on language-driven static visual encodings, which often lead to speculative reasoning due to a lack of fine-grained visual evidence verification.", "method": "V-Retrver enables MLLMs to engage in an alternating multimodal reasoning process, combining hypothesis generation with targeted visual inspection through external visual tools. The training incorporates curriculum-based learning with supervised activation, rejection-based refinement, and reinforcement learning.", "result": "V-Retrver achieves 23.0% average improvement in retrieval accuracy, with better perception-driven reasoning reliability and generalization demonstrated across multiple benchmarks.", "conclusion": "The proposed framework advances multimodal large language models by fundamentally integrating evidence-driven, visually grounded reasoning, leading to significantly improved retrieval performance and reliability across various tasks."}}
{"id": "2602.05619", "pdf": "https://arxiv.org/pdf/2602.05619", "abs": "https://arxiv.org/abs/2602.05619", "authors": ["Mohamad Mohamad", "Francesco Ponzio", "Xavier Descombes"], "title": "Mode-Dependent Rectification for Stable PPO Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mode-dependent architectural components (layers that behave differently during training and evaluation, such as Batch Normalization or dropout) are commonly used in visual reinforcement learning but can destabilize on-policy optimization. We show that in Proximal Policy Optimization (PPO), discrepancies between training and evaluation behavior induced by Batch Normalization lead to policy mismatch, distributional drift, and reward collapse. We propose Mode-Dependent Rectification (MDR), a lightweight dual-phase training procedure that stabilizes PPO under mode-dependent layers without architectural changes. Experiments across procedurally generated games and real-world patch-localization tasks demonstrate that MDR consistently improves stability and performance, and extends naturally to other mode-dependent layers.", "AI": {"tldr": "This paper identifies instability caused by mode-dependent layers in PPO and proposes Mode-Dependent Rectification (MDR) to address it effectively.", "motivation": "Mode-dependent layers like Batch Normalization and dropout can disrupt stability in visual reinforcement learning during on-policy optimization.", "method": "The paper introduces MDR, a dual-phase training procedure to stabilize PPO while using mode-dependent layers without modifying architectures.", "result": "Experiments show MDR improves stability and performance across games and real-world tasks, while supporting various mode-dependent layers.", "conclusion": "MDR provides a practical solution for stabilizing PPO with mode-dependent layers, enhancing its reliability in reinforcement learning scenarios."}}
{"id": "2602.06037", "pdf": "https://arxiv.org/pdf/2602.06037", "abs": "https://arxiv.org/abs/2602.06037", "authors": ["Haoyuan Li", "Qihang Cao", "Tao Tang", "Kun Xiang", "Zihan Guo", "Jianhua Han", "Hang Xu", "Xiaodan Liang"], "title": "Thinking with Geometry: Active Geometry Integration for Spatial Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passive: geometry is exposed as a global stream and fused in an indiscriminate manner, which often induces semantic-geometry misalignment and redundant signals. We propose GeoThinker, a framework that shifts the paradigm from passive fusion to active perception. Instead of feature mixing, GeoThinker enables the model to selectively retrieve geometric evidence conditioned on its internal reasoning demands. GeoThinker achieves this through Spatial-Grounded Fusion applied at carefully selected VLM layers, where semantic visual priors selectively query and integrate task-relevant geometry via frame-strict cross-attention, further calibrated by Importance Gating that biases per-frame attention toward task-relevant structures. Comprehensive evaluation results show that GeoThinker sets a new state-of-the-art in spatial intelligence, achieving a peak score of 72.6 on the VSI-Bench. Furthermore, GeoThinker demonstrates robust generalization and significantly improved spatial perception across complex downstream scenarios, including embodied referring and autonomous driving. Our results indicate that the ability to actively integrate spatial structures is essential for next-generation spatial intelligence. Code can be found at https://github.com/Li-Hao-yuan/GeoThinker.", "AI": {"tldr": "GeoThinker revolutionizes spatial reasoning for Multimodal Large Language Models by introducing active geometric evidence retrieval, outperforming conventional passive fusion methods and achieving state-of-the-art results.", "motivation": "Current MLLMs struggle with passive geometric fusion approaches, leading to inefficiencies and misalignments in spatial reasoning tasks.", "method": "GeoThinker uses Spatial-Grounded Fusion with frame-strict cross-attention and Importance Gating to selectively integrate task-relevant geometric evidence.", "result": "GeoThinker establishes a new state-of-the-art score of 72.6 on VSI-Bench and shows robust generalization in real-world tasks like embodied referring and autonomous driving.", "conclusion": "Actively integrating spatial structures enhances spatial intelligence for MLLMs, paving the way for advanced applications in spatially complex scenarios."}}
{"id": "2602.05016", "pdf": "https://arxiv.org/pdf/2602.05016", "abs": "https://arxiv.org/abs/2602.05016", "authors": ["Eryue Xu", "Tianshi Li"], "title": "From Fragmentation to Integration: Exploring the Design Space of AI Agents for Human-as-the-Unit Privacy Management", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.ET"], "comment": null, "summary": "Managing one's digital footprint is overwhelming, as it spans multiple platforms and involves countless context-dependent decisions. Recent advances in agentic AI offer ways forward by enabling holistic, contextual privacy-enhancing solutions. Building on this potential, we adopted a ''human-as-the-unit'' perspective and investigated users' cross-context privacy challenges through 12 semi-structured interviews. Results reveal that people rely on ad hoc manual strategies while lacking comprehensive privacy controls, highlighting nine privacy-management challenges across applications, temporal contexts, and relationships. To explore solutions, we generated nine AI agent concepts and evaluated them via a speed-dating survey with 116 US participants. The three highest-ranked concepts were all post-sharing management tools with half or full agent autonomy, with users expressing greater trust in AI accuracy than in their own efforts. Our findings highlight a promising design space where users see AI agents bridging the fragments in privacy management, particularly through automated, comprehensive post-sharing remediation of users' digital footprints.", "AI": {"tldr": "The study investigates privacy challenges across digital platforms and proposes AI agents to manage digital footprints effectively, with users trusting AI for post-sharing management.", "motivation": "Users struggle with managing digital privacy across multiple platforms and contexts, necessitating comprehensive tools.", "method": "Conducted 12 interviews to identify privacy challenges, developed nine AI agent concepts, and surveyed 116 participants to evaluate these concepts.", "result": "Identified nine privacy-management challenges, and found users prefer post-sharing AI tools with significant autonomy due to higher trust in AI accuracy.", "conclusion": "AI agents present a promising solution to fragmented, manual privacy management, especially post-sharing digital content."}}
{"id": "2602.05635", "pdf": "https://arxiv.org/pdf/2602.05635", "abs": "https://arxiv.org/abs/2602.05635", "authors": ["Ojasva Nema", "Kaustubh Sharma", "Aditya Chauhan", "Parikshit Pareek"], "title": "Structural Disentanglement in Bilinear MLPs via Architectural Inductive Bias", "categories": ["cs.LG"], "comment": null, "summary": "Selective unlearning and long-horizon extrapolation remain fragile in modern neural networks, even when tasks have underlying algebraic structure. In this work, we argue that these failures arise not solely from optimization or unlearning algorithms, but from how models structure their internal representations during training. We explore if having explicit multiplicative interactions as an architectural inductive bias helps in structural disentanglement, through Bilinear MLPs. We show analytically that bilinear parameterizations possess a `non-mixing' property under gradient flow conditions, where functional components separate into orthogonal subspace representations. This provides a mathematical foundation for surgical model modification. We validate this hypothesis through a series of controlled experiments spanning modular arithmetic, cyclic reasoning, Lie group dynamics, and targeted unlearning benchmarks. Unlike pointwise nonlinear networks, multiplicative architectures are able to recover true operators aligned with the underlying algebraic structure. Our results suggest that model editability and generalization are constrained by representational structure, and that architectural inductive bias plays a central role in enabling reliable unlearning.", "AI": {"tldr": "Modern neural networks struggle with selective unlearning and long-horizon extrapolation due to representational limitations during training. Introducing Bilinear MLPs with explicit multiplicative interactions aids structural disentanglement and improves model editability and generalization.", "motivation": "To address the fragility in selective unlearning and extrapolation tasks by understanding failures linked to internal representation structuring in neural networks rather than optimization techniques alone.", "method": "The paper employs Bilinear MLPs as an architectural inductive bias, analyzing their `non-mixing' property under gradient flow, and validating results through controlled experiments in modular arithmetic, cyclic reasoning, Lie group dynamics, and unlearning benchmarks.", "result": "Bilinear architectures demonstrated structural disentanglement, recovering true operators aligned with algebraic structure, which traditional pointwise nonlinear networks fail to achieve.", "conclusion": "Architectural inductive biases like multiplicative interactions play a key role in improving reliable unlearning, generalization, and model editability by structuring internal representations effectively."}}
{"id": "2602.06040", "pdf": "https://arxiv.org/pdf/2602.06040", "abs": "https://arxiv.org/abs/2602.06040", "authors": ["Jintao Tong", "Shilin Yan", "Hongwei Xue", "Xiaojun Tang", "Kunyu Shi", "Guannan Zhang", "Ruixuan Li", "Yixiong Zou"], "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs", "categories": ["cs.CV"], "comment": "Project Page: https://accio-lab.github.io/SwimBird", "summary": "Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as \"visual thoughts\" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in a rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, a reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning (continuous hidden states as visual thoughts), and (3) interleaved vision-text reasoning. To enable this capability, we adopt a hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, and design a systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, a diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection, SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks. Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning methods.", "AI": {"tldr": "The paper introduces SwimBird, a multimodal large language model capable of dynamically switching between text-only, vision-only, and vision-text reasoning modes, achieving state-of-the-art results in multimodal reasoning.", "motivation": "To overcome limitations of MLLMs that rely on rigid reasoning patterns and struggle with balancing vision-based reasoning and text-based logical reasoning.", "method": "SwimBird utilizes a hybrid autoregressive formulation for reasoning, combining next-token prediction for text with next-embedding prediction for visual thoughts, supported by a diverse supervised fine-tuning dataset.", "result": "The proposed model demonstrates strong performance improvements across benchmarks in textual reasoning and vision-intensive tasks, establishing state-of-the-art capabilities.", "conclusion": "SwimBird provides a flexible and effective multimodal reasoning framework that improves performance by selecting adaptive reasoning modes based on user queries."}}
{"id": "2602.05023", "pdf": "https://arxiv.org/pdf/2602.05023", "abs": "https://arxiv.org/abs/2602.05023", "authors": ["Ruixin Yang", "Ethan Mendes", "Arthur Wang", "James Hays", "Sauvik Das", "Wei Xu", "Alan Ritter"], "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Vision-language models (VLMs) have demonstrated strong performance in image geolocation, a capability further sharpened by frontier multimodal large reasoning models (MLRMs). This poses a significant privacy risk, as these widely accessible models can be exploited to infer sensitive locations from casually shared photos, often at street-level precision, potentially surpassing the level of detail the sharer consented or intended to disclose. While recent work has proposed applying a blanket restriction on geolocation disclosure to combat this risk, these measures fail to distinguish valid geolocation uses from malicious behavior. Instead, VLMs should maintain contextual integrity by reasoning about elements within an image to determine the appropriate level of information disclosure, balancing privacy and utility. To evaluate how well models respect contextual integrity, we introduce VLM-GEOPRIVACY, a benchmark that challenges VLMs to interpret latent social norms and contextual cues in real-world images and determine the appropriate level of location disclosure. Our evaluation of 14 leading VLMs shows that, despite their ability to precisely geolocate images, the models are poorly aligned with human privacy expectations. They often over-disclose in sensitive contexts and are vulnerable to prompt-based attacks. Our results call for new design principles in multimodal systems to incorporate context-conditioned privacy reasoning.", "AI": {"tldr": "This paper evaluates the privacy risks posed by widely accessible vision-language models (VLMs) in image geolocation and proposes a benchmark to improve context-conditioned privacy reasoning.", "motivation": "The motivation is to address privacy risks from VLMs that over-disclose geolocation information in shared photos, undermining user consent by bypassing contextual privacy norms.", "method": "The researchers introduced VLM-GEOPRIVACY, a benchmark designed to evaluate how well VLMs align with human expectations of contextual privacy when determining location disclosure.", "result": "The evaluation of 14 leading VLMs reveals poor contextual privacy alignment; these models often disclose too much information in sensitive contexts and are susceptible to prompt-based attacks.", "conclusion": "The study highlights the need for new design principles in multimodal systems to prioritize context-sensitive privacy reasoning and align better with societal expectations."}}
{"id": "2602.06041", "pdf": "https://arxiv.org/pdf/2602.06041", "abs": "https://arxiv.org/abs/2602.06041", "authors": ["Xuejun Zhang", "Aditi Tiwari", "Zhenhailong Wang", "Heng Ji"], "title": "Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Multi-image spatial reasoning remains challenging for current multimodal large language models (MLLMs). While single-view perception is inherently 2D, reasoning over multiple views requires building a coherent scene understanding across viewpoints. In particular, we study perspective taking, where a model must build a coherent 3D understanding from multi-view observations and use it to reason from a new, language-specified viewpoint. We introduce CAMCUE, a pose-aware multi-image framework that uses camera pose as an explicit geometric anchor for cross-view fusion and novel-view reasoning. CAMCUE injects per-view pose into visual tokens, grounds natural-language viewpoint descriptions to a target camera pose, and synthesizes a pose-conditioned imagined target view to support answering. To support this setting, we curate CAMCUE-DATA with 27,668 training and 508 test instances pairing multi-view images and poses with diverse target-viewpoint descriptions and perspective-shift questions. We also include human-annotated viewpoint descriptions in the test split to evaluate generalization to human language. CAMCUE improves overall accuracy by 9.06% and predicts target poses from natural-language viewpoint descriptions with over 90% rotation accuracy within 20\u00b0 and translation accuracy within a 0.5 error threshold. This direct grounding avoids expensive test-time search-and-match, reducing inference time from 256.6s to 1.45s per example and enabling fast, interactive use in real-world scenarios.", "AI": {"tldr": "This paper studies multi-image spatial reasoning and introduces CAMCUE, a framework leveraging camera pose for efficient multi-view reasoning and achieving higher accuracy while significantly reducing inference time.", "motivation": "To address the challenge of building coherent 3D understanding from multi-view observations and reasoning from novel viewpoints in multimodal large language models (MLLMs).", "method": "The authors propose CAMCUE, which integrates per-view camera pose into visual tokens, grounds viewpoint descriptions to image poses, and synthesizes a pose-conditioned imagined view. A new dataset, CAMCUE-DATA, supports training and evaluation.", "result": "CAMCUE improves multi-view reasoning accuracy by 9.06% and achieves over 90% accuracy in target pose predictions based on natural-language descriptions. It reduces inference time from 256.6s to 1.45s.", "conclusion": "CAMCUE enables efficient and accurate multi-view spatial reasoning by leveraging explicit pose information, making it suitable for real-world applications with faster inference and robust generalization to human language."}}
{"id": "2602.05646", "pdf": "https://arxiv.org/pdf/2602.05646", "abs": "https://arxiv.org/abs/2602.05646", "authors": ["Peng Chen", "Siyuan Wang", "Shiyan Hu", "Xingjian Wu", "Yang Shu", "Zhongwen Rao", "Meng Wang", "Yijie Li", "Bin Yang", "Chenjuan Guo"], "title": "Empowering Time Series Analysis with Large-Scale Multimodal Pretraining", "categories": ["cs.LG"], "comment": null, "summary": "While existing time series foundation models primarily rely on large-scale unimodal pretraining, they lack complementary modalities to enhance time series understanding. Building multimodal foundation models is a natural next step, but it faces key challenges: 1) lack of a unified multimodal pretraining paradigm and large-scale multimodal corpora for time series analysis; 2) how to effectively integrate heterogeneous modalities and enhance model generalization. To address these challenges, we take an early step toward multimodal foundation models for time series analysis. We first propose a multimodal pretraining paradigm that leverages time series with endogenous modalities (derived images and text) and exogenous knowledge (real-world news), providing a comprehensive multi-view perspective for time series analysis. To support this, we develop an automated data construction pipeline to curate MM-TS, the first large-scale multimodal time series dataset spanning six domains, with up to one billion points. Then we propose HORAI, a frequency-enhanced multimodal foundation model. It integrates two core components: the Frequency-enhanced Cross-Modality Encoder and the Time-Frequency Decoder, designed to effectively fuse multimodal features and enhance model generalization across modalities and domains. After pretraining on MM-TS, HORAI achieves state-of-the-art zero-shot performance on time series forecasting and anomaly detection tasks, demonstrating strong generalization.", "AI": {"tldr": "Existing time series models lack multimodal integration. This paper proposes a new paradigm and dataset (MM-TS) for multimodal time series analysis, along with HORAI, a model achieving state-of-the-art performance.", "motivation": "Current time series foundation models do not utilize complementary modalities, limiting their understanding; there is a need for multimodal approaches to improve performance and generalization.", "method": "HORAI, a frequency-enhanced multimodal model using a novel cross-modality encoder and a time-frequency decoder, paired with MM-TS, a dataset combining endogenous modalities and exogenous knowledge.", "result": "HORAI demonstrates state-of-the-art zero-shot accuracy in forecasting and anomaly detection tasks after pretraining on MM-TS.", "conclusion": "Combining multimodal data with a frequency-enhanced model is effective for time series analysis, paving the way for improved generalization and application in diverse domains."}}
{"id": "2602.05027", "pdf": "https://arxiv.org/pdf/2602.05027", "abs": "https://arxiv.org/abs/2602.05027", "authors": ["Georgii Aparin", "Tasnima Sadekova", "Alexey Rukhovich", "Assel Yermekova", "Laida Kushnareva", "Vadim Popov", "Kristian Kuznetsov", "Irina Piontkovskaya"], "title": "AudioSAE: Towards Understanding of Audio-Processing Models with Sparse AutoEncoders", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Sparse Autoencoders (SAEs) are powerful tools for interpreting neural representations, yet their use in audio remains underexplored. We train SAEs across all encoder layers of Whisper and HuBERT, provide an extensive evaluation of their stability, interpretability, and show their practical utility. Over 50% of the features remain consistent across random seeds, and reconstruction quality is preserved. SAE features capture general acoustic and semantic information as well as specific events, including environmental noises and paralinguistic sounds (e.g. laughter, whispering) and disentangle them effectively, requiring removal of only 19-27% of features to erase a concept. Feature steering reduces Whisper's false speech detections by 70% with negligible WER increase, demonstrating real-world applicability. Finally, we find SAE features correlated with human EEG activity during speech perception, indicating alignment with human neural processing. The code and checkpoints are available at https://github.com/audiosae/audiosae_demo.", "AI": {"tldr": "This paper explores the application of Sparse Autoencoders (SAEs) in audio analysis using Whisper and HuBERT, demonstrating interpretability, stability, and practical utility.", "motivation": "To investigate the potential of Sparse Autoencoders (SAEs) in interpreting neural representations in audio tasks.", "method": "SAEs are trained across encoder layers of Whisper and HuBERT, systematically evaluated for stability, interpretability, and applied for practical tasks like feature steering.", "result": "Consistent feature extraction across seeds, preserved reconstruction quality, effective disentangling of specific events and concepts, and real-world application reducing false speech detections. SAE features also correlate with human EEG during speech perception.", "conclusion": "SAEs exhibit strong potential for audio applications, aligning with human neural processing and showcasing practical value in tasks like reducing false detections in speech models."}}
{"id": "2602.05649", "pdf": "https://arxiv.org/pdf/2602.05649", "abs": "https://arxiv.org/abs/2602.05649", "authors": ["Guri Zab\u00ebrgja", "Rafiq Kamel", "Arlind Kadra", "Christian M. M. Frey", "Josif Grabocka"], "title": "End-to-End Compression for Tabular Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "The long-standing dominance of gradient-boosted decision trees for tabular data has recently been challenged by in-context learning tabular foundation models. In-context learning methods fit and predict in one forward pass without parameter updates by leveraging the training data as context for predicting on query test points. While recent tabular foundation models achieve state-of-the-art performance, their transformer architecture based on the attention mechanism has quadratic complexity regarding dataset size, which in turn increases the overhead on training and inference time, and limits the capacity of the models to handle large-scale datasets. In this work, we propose TACO, an end-to-end tabular compression model that compresses the training dataset in a latent space. We test our method on the TabArena benchmark, where our proposed method is up to 94x faster in inference time, while consuming up to 97\\% less memory compared to the state-of-the-art tabular transformer architecture, all while retaining performance without significant degradation. Lastly, our method not only scales better with increased dataset sizes, but it also achieves better performance compared to other baselines.", "AI": {"tldr": "TACO, a tabular compression model, addresses the inefficiency of tabular transformers by significantly improving inference speed, reducing memory usage, and maintaining high performance.", "motivation": "Address the inefficiencies of tabular foundation models, such as increased training time, inference overhead, and scalability issues due to quadratic complexity.", "method": "Proposed TACO, a model leveraging latent space compression for tabular data, to facilitate faster and scalable training and inference.", "result": "On the TabArena benchmark, TACO demonstrated up to 94x faster inference, 97% lower memory usage, and competitive performance compared to state-of-the-art methods.", "conclusion": "TACO is a scalable, efficient solution for handling large-scale tabular datasets while maintaining competitive performance, overcoming limitations of current transformer-based methods."}}
{"id": "2602.05656", "pdf": "https://arxiv.org/pdf/2602.05656", "abs": "https://arxiv.org/abs/2602.05656", "authors": ["Igor Santos-Grueiro"], "title": "Alignment Verifiability in Large Language Models: Normative Indistinguishability under Behavioral Evaluation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages. Theoretical analysis of behavioral alignment evaluation", "summary": "Behavioral evaluation is the dominant paradigm for assessing alignment in large language models (LLMs). In practice, alignment is inferred from performance under finite evaluation protocols - benchmarks, red-teaming suites, or automated pipelines - and observed compliance is often treated as evidence of underlying alignment. This inference step, from behavioral evidence to claims about latent alignment properties, is typically implicit and rarely analyzed as an inference problem in its own right.\n  We study this problem formally. We frame alignment evaluation as an identifiability question under partial observability and allow agent behavior to depend on information correlated with the evaluation regime. Within this setting, we introduce the Alignment Verifiability Problem and the notion of Normative Indistinguishability, capturing when distinct latent alignment hypotheses induce identical distributions over all evaluator-accessible signals.\n  Our main result is a negative but sharply delimited identifiability theorem. Under finite behavioral evaluation and evaluation-aware agents, observed behavioral compliance does not uniquely identify latent alignment. That is, even idealized behavioral evaluation cannot, in general, certify alignment as a latent property.\n  We further show that behavioral alignment tests should be interpreted as estimators of indistinguishability classes rather than verifiers of alignment. Passing increasingly stringent tests may reduce the space of compatible hypotheses, but cannot collapse it to a singleton under the stated conditions. This reframes alignment benchmarks as providing upper bounds on observable compliance within a regime, rather than guarantees of underlying alignment.", "AI": {"tldr": "The paper critiques the reliability of behavioral evaluation protocols for assessing alignment in large language models (LLMs) by demonstrating that observed behavior is not enough to infer latent alignment properties due to the limitations of such methods.", "motivation": "The motivation is to address the implicit assumptions in the current paradigm of behavioral evaluations of LLMs, which often equate observed compliance with true alignment without examining the validity of such inference.", "method": "The authors formalize the issue by posing alignment evaluation as an identifiability problem under partial observability. They introduce the Alignment Verifiability Problem and a concept called Normative Indistinguishability to explore when different alignment hypotheses yield identical observable behaviors.", "result": "The paper presents a negative result showing that finite behavioral evaluations cannot uniquely verify alignment as a latent property, especially with evaluation-aware agents. It highlights the limitations of behavioral compliance as evidence of true alignment.", "conclusion": "Behavioral alignment tests should be seen as narrowing the hypothesis space rather than certifying true alignment. They serve to provide upper bounds on observable compliance rather than definitive indicators of latent alignment."}}
{"id": "2602.05013", "pdf": "https://arxiv.org/pdf/2602.05013", "abs": "https://arxiv.org/abs/2602.05013", "authors": ["Aryan Mikaeili", "Or Patashnik", "Andrea Tagliasacchi", "Daniel Cohen-Or", "Ali Mahdavi-Amiri"], "title": "Untwisting RoPE: Frequency Control for Shared Attention in DiTs", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Positional encodings are essential to transformer-based generative models, yet their behavior in multimodal and attention-sharing settings is not fully understood. In this work, we present a principled analysis of Rotary Positional Embeddings (RoPE), showing that RoPE naturally decomposes into frequency components with distinct positional sensitivities. We demonstrate that this frequency structure explains why shared-attention mechanisms, where a target image is generated while attending to tokens from a reference image, can lead to reference copying, in which the model reproduces content from the reference instead of extracting only its stylistic cues. Our analysis reveals that the high-frequency components of RoPE dominate the attention computation, forcing queries to attend mainly to spatially aligned reference tokens and thereby inducing this unintended copying behavior. Building on these insights, we introduce a method for selectively modulating RoPE frequency bands so that attention reflects semantic similarity rather than strict positional alignment. Applied to modern transformer-based diffusion architectures, where all tokens share attention, this modulation restores stable and meaningful shared attention. As a result, it enables effective control over the degree of style transfer versus content copying, yielding a proper style-aligned generation process in which stylistic attributes are transferred without duplicating reference content.", "AI": {"tldr": "This study analyzes Rotary Positional Embeddings (RoPE) in transformer-based models and their behavior in shared-attention multimodal setups. It proposes a modulated technique to address unintended content copying during style transfer.", "motivation": "The paper aims to understand and address the unintended reference copying in transformer models that rely on RoPE under shared-attention settings.", "method": "The authors provide a frequency-based analysis of RoPE, propose modulation methods for controlling the frequency components, and evaluate their approach in diffusion-based architectures.", "result": "The method restores stable shared attention, balancing style transfer without content copying.", "conclusion": "Adjusting RoPE frequency bands ensures semantic-focused attention, achieving effective style transfer without reproducing reference content."}}
{"id": "2602.05657", "pdf": "https://arxiv.org/pdf/2602.05657", "abs": "https://arxiv.org/abs/2602.05657", "authors": ["Aleksandar Armacki", "Dragana Bajovi\u0107", "Du\u0161an Jakoveti\u0107", "Soummya Kar", "Ali H. Sayed"], "title": "Tight Long-Term Tail Decay of (Clipped) SGD in Non-Convex Optimization", "categories": ["cs.LG", "math.OC"], "comment": "32 pages", "summary": "The study of tail behaviour of SGD-induced processes has been attracting a lot of interest, due to offering strong guarantees with respect to individual runs of an algorithm. While many works provide high-probability guarantees, quantifying the error rate for a fixed probability threshold, there is a lack of work directly studying the probability of failure, i.e., quantifying the tail decay rate for a fixed error threshold. Moreover, existing results are of finite-time nature, limiting their ability to capture the true long-term tail decay which is more informative for modern learning models, typically trained for millions of iterations. Our work closes these gaps, by studying the long-term tail decay of SGD-based methods through the lens of large deviations theory, establishing several strong results in the process. First, we provide an upper bound on the tails of the gradient norm-squared of the best iterate produced by (vanilla) SGD, for non-convex costs and bounded noise, with long-term decay at rate $e^{-t/\\log(t)}$. Next, we relax the noise assumption by considering clipped SGD (c-SGD) under heavy-tailed noise with bounded moment of order $p \\in (1,2]$, showing an upper bound with long-term decay at rate $e^{-t^{\u03b2_p}/\\log(t)}$, where $\u03b2_p = \\frac{4(p-1)}{3p-2}$ for $p \\in (1,2)$ and $e^{-t/\\log^2(t)}$ for $p = 2$. Finally, we provide lower bounds on the tail decay, at rate $e^{-t}$, showing that our rates for both SGD and c-SGD are tight, up to poly-logarithmic factors. Notably, our results demonstrate an order of magnitude faster long-term tail decay compared to existing work based on finite-time bounds, which show rates $e^{-\\sqrt{t}}$ and $e^{-t^{\u03b2_p/2}}$, $p \\in (1,2]$, for SGD and c-SGD, respectively. As such, we uncover regimes where the tails decay much faster than previously known, providing stronger long-term guarantees for individual runs.", "AI": {"tldr": "This paper studies the long-term tail decay of SGD-based methods using large deviations theory, improving upon existing finite-time bounds.", "motivation": "Existing works focus on finite-time high-probability guarantees for SGD error rates, but fail to study long-term tail decay which is more relevant for modern machine learning models.", "method": "The authors employ large deviations theory to derive upper and lower bounds on the tail decay of SGD and clipped SGD methods under different noise conditions.", "result": "For non-convex costs and bounded noise, SGD achieves a tail decay rate of $e^{-t/\\log(t)}$. Clipped SGD handles heavy-tailed noise, achieving rates of $e^{-t^{\u03b2_p}/\\log(t)}$ ($p \\in (1,2)$) and $e^{-t/\\log^2(t)}$ ($p = 2$). The paper also establishes tight lower bounds up to poly-logarithmic factors.", "conclusion": "The paper uncovers significantly faster long-term tail decay rates compared to finite-time bounds, providing stronger guarantees for individual SGD runs."}}
{"id": "2602.05660", "pdf": "https://arxiv.org/pdf/2602.05660", "abs": "https://arxiv.org/abs/2602.05660", "authors": ["Slawek Smyl", "Pawe\u0142 Pe\u0142ka", "Grzegorz Dudek"], "title": "Probabilistic Multi-Regional Solar Power Forecasting with Any-Quantile Recurrent Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The increasing penetration of photovoltaic (PV) generation introduces significant uncertainty into power system operation, necessitating forecasting approaches that extend beyond deterministic point predictions. This paper proposes an any-quantile probabilistic forecasting framework for multi-regional PV power generation based on the Any-Quantile Recurrent Neural Network (AQ-RNN). The model integrates an any-quantile forecasting paradigm with a dual-track recurrent architecture that jointly processes series-specific and cross-regional contextual information, supported by dilated recurrent cells, patch-based temporal modeling, and a dynamic ensemble mechanism.\n  The proposed framework enables the estimation of calibrated conditional quantiles at arbitrary probability levels within a single trained model and effectively exploits spatial dependencies to enhance robustness at the system level. The approach is evaluated using 30 years of hourly PV generation data from 259 European regions and compared against established statistical and neural probabilistic baselines. The results demonstrate consistent improvements in forecast accuracy, calibration, and prediction interval quality, underscoring the suitability of the proposed method for uncertainty-aware energy management and operational decision-making in renewable-dominated power systems.", "AI": {"tldr": "This paper introduces AQ-RNN, a framework for probabilistic forecasting of multi-regional PV power generation to handle uncertainty effectively, with improved accuracy and calibration.", "motivation": "The uncertainty in power systems due to high penetration of photovoltaic (PV) generation necessitates more advanced probabilistic forecasting methods beyond deterministic predictions.", "method": "The paper introduces the AQ-RNN model, which combines any-quantile forecasting with a dual-track recurrent architecture. It employs specific mechanisms like dilated recurrent cells and dynamic ensembles for improved spatial and temporal modeling.", "result": "Using 30 years of hourly PV data from 259 European regions, AQ-RNN consistently outperforms baseline models in forecast accuracy, calibration, and prediction interval quality.", "conclusion": "The AQ-RNN framework provides robust probabilistic forecasts suitable for operational decision-making in renewable energy systems with extensive spatial dependencies and uncertainty."}}
{"id": "2602.05047", "pdf": "https://arxiv.org/pdf/2602.05047", "abs": "https://arxiv.org/abs/2602.05047", "authors": ["Grzegorz Wilczy\u0144ski", "Rafa\u0142 Tobiasz", "Pawe\u0142 Gora", "Marcin Mazur", "Przemys\u0142aw Spurek"], "title": "QuantumGS: Quantum Encoding Framework for Gaussian Splatting", "categories": ["quant-ph", "cs.CV"], "comment": null, "summary": "Recent advances in neural rendering, particularly 3D Gaussian Splatting (3DGS), have enabled real-time rendering of complex scenes. However, standard 3DGS relies on spherical harmonics, which often struggle to accurately capture high-frequency view-dependent effects such as sharp reflections and transparency. While hybrid approaches like Viewing Direction Gaussian Splatting (VDGS) mitigate this limitation using classical Multi-Layer Perceptrons (MLPs), they remain limited by the expressivity of classical networks in low-parameter regimes. In this paper, we introduce QuantumGS, a novel hybrid framework that integrates Variational Quantum Circuits (VQC) into the Gaussian Splatting pipeline. We propose a unique encoding strategy that maps the viewing direction directly onto the Bloch sphere, leveraging the natural geometry of qubits to represent 3D directional data. By replacing classical color-modulating networks with quantum circuits generated via a hypernetwork or conditioning mechanism, we achieve higher expressivity and better generalization. Source code is available in the supplementary material. Code is available at https://github.com/gwilczynski95/QuantumGS", "AI": {"tldr": "QuantumGS introduces Variational Quantum Circuits (VQC) into Gaussian Splatting for improved real-time rendering by leveraging the geometry of qubits.", "motivation": "Current methods like standard 3D Gaussian Splatting and VDGS struggle to accurately capture high-frequency view-dependent effects due to limitations in expressivity.", "method": "QuantumGS employs a unique encoding onto the Bloch sphere and uses quantum circuits supported by hypernetworks to enhance Gaussian Splatting.", "result": "The paper demonstrates improved expressivity, generalization, and rendering quality using the quantum-enhanced framework.", "conclusion": "Integrating quantum circuits into neural rendering pipelines successfully addresses limitations in capturing complex visual effects, paving the way for advanced rendering techniques."}}
{"id": "2602.05667", "pdf": "https://arxiv.org/pdf/2602.05667", "abs": "https://arxiv.org/abs/2602.05667", "authors": ["Ling Zhan", "Zhen Li", "Junjie Huang", "Tao Jia"], "title": "Accelerating Benchmarking of Functional Connectivity Modeling via Structure-aware Core-set Selection", "categories": ["cs.LG"], "comment": "33 pages, 8 figures, ICLR conference paper", "summary": "Benchmarking the hundreds of functional connectivity (FC) modeling methods on large-scale fMRI datasets is critical for reproducible neuroscience. However, the combinatorial explosion of model-data pairings makes exhaustive evaluation computationally prohibitive, preventing such assessments from becoming a routine pre-analysis step. To break this bottleneck, we reframe the challenge of FC benchmarking by selecting a small, representative core-set whose sole purpose is to preserve the relative performance ranking of FC operators. We formalize this as a ranking-preserving subset selection problem and propose Structure-aware Contrastive Learning for Core-set Selection (SCLCS), a self-supervised framework to select these core-sets. SCLCS first uses an adaptive Transformer to learn each sample's unique FC structure. It then introduces a novel Structural Perturbation Score (SPS) to quantify the stability of these learned structures during training, identifying samples that represent foundational connectivity archetypes. Finally, while SCLCS identifies stable samples via a top-k ranking, we further introduce a density-balanced sampling strategy as a necessary correction to promote diversity, ensuring the final core-set is both structurally robust and distributionally representative. On the large-scale REST-meta-MDD dataset, SCLCS preserves the ground-truth model ranking with just 10% of the data, outperforming state-of-the-art (SOTA) core-set selection methods by up to 23.2% in ranking consistency (nDCG@k). To our knowledge, this is the first work to formalize core-set selection for FC operator benchmarking, thereby making large-scale operators comparisons a feasible and integral part of computational neuroscience. Code is publicly available on https://github.com/lzhan94swu/SCLCS", "AI": {"tldr": "This paper proposes a method for selecting a small, representative subset of data for functional connectivity (FC) method benchmarking, using a novel self-supervised framework named SCLCS.", "motivation": "The motivation is to address the computational challenge of benchmarking hundreds of FC modeling methods on large-scale datasets due to the combinatorial explosion of model-data pairings.", "method": "The authors developed a self-supervised framework, SCLCS, that learns FC structures using transformers and introduces a Structural Perturbation Score (SPS) to identify foundational connectivity archetypes. It ensures diversity via density-balanced sampling.", "result": "The SCLCS method achieves a ranking consistency improvement of up to 23.2% compared to current state-of-the-art methods, using only 10% of the data while preserving model ranking on the REST-meta-MDD dataset.", "conclusion": "SCLCS offers an efficient, ranking-preserving core-set selection approach, enabling large-scale comparison of FC methods, aiming to standardize benchmarking in computational neuroscience."}}
{"id": "2602.05081", "pdf": "https://arxiv.org/pdf/2602.05081", "abs": "https://arxiv.org/abs/2602.05081", "authors": ["Jorge Condor", "Nicolai Hermann", "Mehmet Ata Yurtsever", "Piotr Didyk"], "title": "Gabor Fields: Orientation-Selective Level-of-Detail for Volume Rendering", "categories": ["cs.GR", "cs.CV"], "comment": "19 pages, incl Appendix and References", "summary": "Gaussian-based representations have enabled efficient physically-based volume rendering at a fraction of the memory cost of regular, discrete, voxel-based distributions. However, several remaining issues hamper their widespread use. One of the advantages of classic voxel grids is the ease of constructing hierarchical representations by either storing volumetric mipmaps or selectively pruning branches of an already hierarchical voxel grid. Such strategies reduce rendering time and eliminate aliasing when lower levels of detail are required. Constructing similar strategies for Gaussian-based volumes is not trivial. Straightforward solutions, such as prefiltering or computing mipmap-style representations, lead to increased memory requirements or expensive re-fitting of each level separately. Additionally, such solutions do not guarantee a smooth transition between different hierarchy levels. To address these limitations, we propose Gabor Fields, an orientation-selective mixture of Gabor kernels that enables continuous frequency filtering at no cost. The frequency content of the asset is reduced by selectively pruning primitives, directly benefiting rendering performance. Beyond filtering, we demonstrate that stochastically sampling from different frequencies and orientations at each ray recursion enables masking substantial portions of the volume, accelerating ray traversal time in single- and multiple-scattering settings. Furthermore, inspired by procedural volumes, we present an application for efficient design and rendering of procedural clouds as Gabor-noise-modulated Gaussians.", "AI": {"tldr": "The paper introduces Gabor Fields, which enhance Gaussian-based volume rendering by improving hierarchical representation and efficiency in rendering and procedural volumetric design.", "motivation": "Gaussian-based representations are efficient for volume rendering but lack effective hierarchical strategies, leading to challenges in memory usage and smooth transitions in levels of detail.", "method": "The authors propose a method using Gabor Fields, which involve Gabor kernels to enable continuous frequency filtering and selective pruning of primitives, improving rendering efficiency. They also introduce stochastic sampling and procedural cloud rendering using Gabor-modulated Gaussians.", "result": "Gabor Fields improve rendering performance through frequency-based filtering and faster ray traversal, demonstrating advantages in both single- and multiple-scattering settings. The procedural cloud application showcases efficient design possibilities.", "conclusion": "Gabor Fields provide an innovative solution to overcome the limitations of Gaussian-based volume rendering, offering better representation, smoother hierarchy transitions, and enhanced procedural volumetric design."}}
{"id": "2602.05066", "pdf": "https://arxiv.org/pdf/2602.05066", "abs": "https://arxiv.org/abs/2602.05066", "authors": ["Jafar Isbarov", "Murat Kantarcioglu"], "title": "Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As AI agents automate critical workloads, they remain vulnerable to indirect prompt injection (IPI) attacks. Current defenses rely on monitoring protocols that jointly evaluate an agent's Chain-of-Thought (CoT) and tool-use actions to ensure alignment with user intent. We demonstrate that these monitoring-based defenses can be bypassed via a novel Agent-as-a-Proxy attack, where prompt injection attacks treat the agent as a delivery mechanism, bypassing both agent and monitor simultaneously. While prior work on scalable oversight has focused on whether small monitors can supervise large agents, we show that even frontier-scale monitors are vulnerable. Large-scale monitoring models like Qwen2.5-72B can be bypassed by agents with similar capabilities, such as GPT-4o mini and Llama-3.1-70B. On the AgentDojo benchmark, we achieve a high attack success rate against AlignmentCheck and Extract-and-Evaluate monitors under diverse monitoring LLMs. Our findings suggest current monitoring-based agentic defenses are fundamentally fragile regardless of model scale.", "AI": {"tldr": "The paper identifies vulnerabilities in current monitoring-based defenses against indirect prompt injection attacks on AI agents.", "motivation": "The motivation is to address weaknesses in AI agent defenses against indirect prompt injection attacks and evaluate the robustness of monitoring models, even at large scales.", "method": "The study introduces a novel Agent-as-a-Proxy attack to bypass existing defenses. It tests these attacks on monitoring models using benchmarks like AgentDojo under diverse monitoring LLMs.", "result": "Large-scale monitoring models, including Qwen2.5-72B, were bypassed successfully by similar-capability agents, achieving high attack success rates on benchmarks.", "conclusion": "Monitoring-based defenses for AI agents are fundamentally fragile regardless of their scale."}}
{"id": "2602.05668", "pdf": "https://arxiv.org/pdf/2602.05668", "abs": "https://arxiv.org/abs/2602.05668", "authors": ["Zhipeng Zhang", "Kai Li"], "title": "Stable but Wrong: When More Data Degrades Scientific Conclusions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern science increasingly relies on ever-growing observational datasets and automated inference pipelines, under the implicit belief that accumulating more data makes scientific conclusions more reliable. Here we show that this belief can fail in a fundamental and irreversible way. We identify a structural regime in which standard inference procedures converge smoothly, remain well calibrated, and pass conventional diagnostic checks, yet systematically converge to incorrect conclusions. This failure arises when the reliability of observations degrades in a manner that is intrinsically unobservable to the inference process itself. Using minimal synthetic experiments, we demonstrate that in this regime additional data do not correct error but instead amplify it, while residual-based and goodness-of-fit diagnostics remain misleadingly normal. These results reveal an intrinsic limit of data-driven science: stability, convergence, and confidence are not sufficient indicators of epistemic validity. We argue that inference cannot be treated as an unconditional consequence of data availability, but must instead be governed by explicit constraints on the integrity of the observational process.", "AI": {"tldr": "The paper shows that simply increasing data does not always lead to reliable scientific conclusions, especially when the quality of data degrades in certain ways.", "motivation": "To investigate if more data always improves the reliability of scientific conclusions, given the reliance on large datasets and automated inference.", "method": "Minimal synthetic experiments to demonstrate the pitfalls of inference when data reliability degrades in ways that go undetected by typical procedures.", "result": "Standard inference appeared well-calibrated and conventionally valid, but error was amplified with more data under specific conditions.", "conclusion": "More data is not always better; inference must include constraints ensuring the quality and integrity of the observations."}}
{"id": "2602.05100", "pdf": "https://arxiv.org/pdf/2602.05100", "abs": "https://arxiv.org/abs/2602.05100", "authors": ["Bharadwaj Dogga", "Kaaustaaub Shankar", "Gibin Raju", "Wilhelm Louw", "Kelly Cohen"], "title": "Rule-Based Spatial Mixture-of-Experts U-Net for Explainable Edge Detection", "categories": ["cs.CE", "cs.CV", "cs.SC"], "comment": null, "summary": "Deep learning models like U-Net and its variants, have established state-of-the-art performance in edge detection tasks and are used by Generative AI services world-wide for their image generation models. However, their decision-making processes remain opaque, operating as \"black boxes\" that obscure the rationale behind specific boundary predictions. This lack of transparency is a critical barrier in safety-critical applications where verification is mandatory. To bridge the gap between high-performance deep learning and interpretable logic, we propose the Rule-Based Spatial Mixture-of-Experts U-Net (sMoE U-Net). Our architecture introduces two key innovations: (1) Spatially-Adaptive Mixture-of-Experts (sMoE) blocks integrated into the decoder skip connections, which dynamically gate between \"Context\" (smooth) and \"Boundary\" (sharp) experts based on local feature statistics; and (2) a Takagi-Sugeno-Kang (TSK) Fuzzy Head that replaces the standard classification layer. This fuzzy head fuses deep semantic features with heuristic edge signals using explicit IF-THEN rules. We evaluate our method on the BSDS500 benchmark, achieving an Optimal Dataset Scale (ODS) F-score of 0.7628, effectively matching purely deep baselines like HED (0.7688) while outperforming the standard U-Net (0.7437). Crucially, our model provides pixel-level explainability through \"Rule Firing Maps\" and \"Strategy Maps,\" allowing users to visualize whether an edge was detected due to strong gradients, high semantic confidence, or specific logical rule combinations.", "AI": {"tldr": "This paper introduces the sMoE U-Net model, which enhances interpretability in edge detection using rule-based logic, while maintaining competitive performance.", "motivation": "Existing deep learning models for edge detection, despite their high accuracy, operate as opaque black boxes. This prevents trust and verification, especially in safety-critical applications, motivating the need for interpretable models.", "method": "The paper proposes a new U-Net variant, augmented with Spatially-Adaptive Mixture-of-Experts (sMoE) blocks and a Takagi-Sugeno-Kang (TSK) Fuzzy Head. The sMoE blocks fuse smooth and sharp expert predictions dynamically, while the TSK fuzzy head incorporates IF-THEN rules for explainability.", "result": "On the BSDS500 benchmark, the model achieves an ODS F-score of 0.7628, rivaling purely deep baselines like HED and outperforming a traditional U-Net. The model provides pixel-level explainability via 'Rule Firing Maps' and 'Strategy Maps.'", "conclusion": "The sMoE U-Net successfully combines high-performance deep learning with interpretable elements, offering competitive edge detection alongside explainable reasoning, suitable for safety-critical applications."}}
{"id": "2602.05679", "pdf": "https://arxiv.org/pdf/2602.05679", "abs": "https://arxiv.org/abs/2602.05679", "authors": ["Miriam Sch\u00e4fers", "Merlijn Krale", "Thiago D. Sim\u00e3o", "Nils Jansen", "Maximilian Weininger"], "title": "Perception-Based Beliefs for POMDPs with Visual Observations", "categories": ["cs.LG"], "comment": "Accepted at AAMAS 2026", "summary": "Partially observable Markov decision processes (POMDPs) are a principled planning model for sequential decision-making under uncertainty. Yet, real-world problems with high-dimensional observations, such as camera images, remain intractable for traditional belief- and filtering-based solvers. To tackle this problem, we introduce the Perception-based Beliefs for POMDPs framework (PBP), which complements such solvers with a perception model. This model takes the form of an image classifier which maps visual observations to probability distributions over states. PBP incorporates these distributions directly into belief updates, so the underlying solver does not need to reason explicitly over high-dimensional observation spaces. We show that the belief update of PBP coincides with the standard belief update if the image classifier is exact. Moreover, to handle classifier imprecision, we incorporate uncertainty quantification and introduce two methods to adjust the belief update accordingly. We implement PBP using two traditional POMDP solvers and empirically show that (1) it outperforms existing end-to-end deep RL methods and (2) uncertainty quantification improves robustness of PBP against visual corruption.", "AI": {"tldr": "The paper introduces the PBP framework to improve POMDP solvers for high-dimensional observation spaces using perception models like image classifiers.", "motivation": "Traditional POMDP solvers become intractable for real-world problems with high-dimensional observations, such as camera images.", "method": "PBP uses an image classifier to map visual observations into probability distributions over states, integrates this into the belief update, and incorporates methods for handling classifier uncertainty.", "result": "Empirical tests showed PBP outperforms end-to-end deep RL methods and improves robustness against visual corruption through uncertainty quantification.", "conclusion": "PBP demonstrates its utility in solving real-world POMDP challenges with high-dimensional observations, enhancing robustness with uncertainty handling techniques."}}
{"id": "2602.05688", "pdf": "https://arxiv.org/pdf/2602.05688", "abs": "https://arxiv.org/abs/2602.05688", "authors": ["Alex Vitvitskyi", "Michael Boratko", "Matej Grcic", "Razvan Pascanu", "Deep Shah", "Petar Veli\u010dkovi\u0107"], "title": "Mining Generalizable Activation Functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The choice of activation function is an active area of research, with different proposals aimed at improving optimization, while maintaining expressivity. Additionally, the activation function can significantly alter the implicit inductive bias of the architecture, controlling its non-linear behavior. In this paper, in line with previous work, we argue that evolutionary search provides a useful framework for finding new activation functions, while we also make two novel observations. The first is that modern pipelines, such as AlphaEvolve, which relies on frontier LLMs as a mutator operator, allows for a much wider and flexible search space; e.g., over all possible python functions within a certain FLOP budget, eliminating the need for manually constructed search spaces. In addition, these pipelines will be biased towards meaningful activation functions, given their ability to represent common knowledge, leading to a potentially more efficient search of the space. The second observation is that, through this framework, one can target not only performance improvements but also activation functions that encode particular inductive biases. This can be done by using performance on out-of-distribution data as a fitness function, reflecting the degree to which the architecture respects the inherent structure in the data in a manner independent of distribution shifts. We carry an empirical exploration of this proposal and show that relatively small scale synthetic datasets can be sufficient for AlphaEvolve to discover meaningful activations.", "AI": {"tldr": "The paper explores evolutionary search using AlphaEvolve to find novel activation functions based on performance and inductive biases, proving its feasibility on synthetic datasets.", "motivation": "To improve optimization and maintain expressivity of neural networks through better activation functions, leveraging the evolution-based frameworks.", "method": "Using AlphaEvolve powered by frontier LLMs as a mutation operator to search over all possible Python functions within a FLOP budget, considering performance on out-of-distribution data as a fitness measure.", "result": "AlphaEvolve demonstrates the ability to discover meaningful activation functions using small-scale synthetic datasets.", "conclusion": "Evolutionary frameworks enhance activation function search, providing improvements in optimization and enabling inductive biases for broader applications."}}
{"id": "2602.05208", "pdf": "https://arxiv.org/pdf/2602.05208", "abs": "https://arxiv.org/abs/2602.05208", "authors": ["Md. Mehedi Hassan", "Taufiq Hasan"], "title": "Context-Aware Asymmetric Ensembling for Interpretable Retinopathy of Prematurity Screening via Active Query and Vascular Attention", "categories": ["eess.IV", "cs.CV"], "comment": "16 pages, 6 figures", "summary": "Retinopathy of Prematurity (ROP) is among the major causes of preventable childhood blindness. Automated screening remains challenging, primarily due to limited data availability and the complex condition involving both structural staging and microvascular abnormalities. Current deep learning models depend heavily on large private datasets and passive multimodal fusion, which commonly fail to generalize on small, imbalanced public cohorts. We thus propose the Context-Aware Asymmetric Ensemble Model (CAA Ensemble) that simulates clinical reasoning through two specialized streams. First, the Multi-Scale Active Query Network (MS-AQNet) serves as a structure specialist, utilizing clinical contexts as dynamic query vectors to spatially control visual feature extraction for localization of the fibrovascular ridge. Secondly, VascuMIL encodes Vascular Topology Maps (VMAP) within a gated Multiple Instance Learning (MIL) network to precisely identify vascular tortuosity. A synergistic meta-learner ensembles these orthogonal signals to resolve diagnostic discordance across multiple objectives. Tested on a highly imbalanced cohort of 188 infants (6,004 images), the framework attained State-of-the-Art performance on two distinct clinical tasks: achieving a Macro F1-Score of 0.93 for Broad ROP staging and an AUC of 0.996 for Plus Disease detection. Crucially, the system features `Glass Box' transparency through counterfactual attention heatmaps and vascular threat maps, proving that clinical metadata dictates the model's visual search. Additionally, this study demonstrates that architectural inductive bias can serve as an effective bridge for the medical AI data gap.", "AI": {"tldr": "This paper introduces the Context-Aware Asymmetric Ensemble Model (CAA Ensemble) for diagnosing Retinopathy of Prematurity (ROP) using limited, imbalanced datasets, achieving state-of-the-art results.", "motivation": "The motivation is to address the challenges in automated screening for ROP caused by limited data and the need to analyze both structural staging and vascular abnormalities effectively.", "method": "The study proposes a model with two specialized components: MS-AQNet for localizing structural features and VascuMIL for analyzing vascular topology, combined using a meta-learner for robust diagnosis.", "result": "On a dataset of 188 infants (6,004 images), the model achieved a Macro F1-Score of 0.93 for ROP staging and an AUC of 0.996 for Plus Disease detection.", "conclusion": "The proposed framework demonstrates that incorporating clinical reasoning and architectural inductive bias can significantly enhance medical AI performance, while ensuring transparency through visualizations."}}
{"id": "2602.05690", "pdf": "https://arxiv.org/pdf/2602.05690", "abs": "https://arxiv.org/abs/2602.05690", "authors": ["Rachel S. Y. Teo", "P. N. Karthik", "Ramya Korlakai Vinayak", "Vincent Y. F. Tan"], "title": "Almost Asymptotically Optimal Active Clustering Through Pairwise Observations", "categories": ["cs.LG", "cs.IT"], "comment": "31 pages, 1 figure", "summary": "We propose a new analysis framework for clustering $M$ items into an unknown number of $K$ distinct groups using noisy and actively collected responses. At each time step, an agent is allowed to query pairs of items and observe bandit binary feedback. If the pair of items belongs to the same (resp.\\ different) cluster, the observed feedback is $1$ with probability $p>1/2$ (resp.\\ $q<1/2$). Leveraging the ubiquitous change-of-measure technique, we establish a fundamental lower bound on the expected number of queries needed to achieve a desired confidence in the clustering accuracy, formulated as a sup-inf optimization problem. Building on this theoretical foundation, we design an asymptotically optimal algorithm in which the stopping criterion involves an empirical version of the inner infimum -- the Generalized Likelihood Ratio (GLR) statistic -- being compared to a threshold. We develop a computationally feasible variant of the GLR statistic and show that its performance gap to the lower bound can be accurately empirically estimated and remains within a constant multiple of the lower bound.", "AI": {"tldr": "The paper proposes a novel framework for clustering items into groups using noisy feedback from pairwise queries, achieving high efficiency with an optimal algorithm.", "motivation": "Current clustering methods often work with a fixed number of groups or assume perfect feedback, which doesn't align with real-world scenarios. This paper seeks to enhance clustering accuracy by dealing with noisy and dynamically collected responses, adapting to an unknown number of distinct groups.", "method": "A theoretical lower bound on the number of queries is derived using a change-of-measure technique. Based on this, an optimal algorithm is proposed, utilizing a Generalized Likelihood Ratio (GLR) statistic to decide when to stop querying. The algorithm is refined for computational efficiency.", "result": "The proposed algorithm is asymptotically optimal, and its gap to the theoretical lower bound is shown to remain within a constant multiple. Empirical evaluations confirm its strong performance in clustering tasks with noisy feedback.", "conclusion": "The work provides both theoretical insights and practical tools for clustering with noisy feedback, laying the groundwork for real-world applications where traditional clustering algorithms struggle."}}
{"id": "2602.05083", "pdf": "https://arxiv.org/pdf/2602.05083", "abs": "https://arxiv.org/abs/2602.05083", "authors": ["Zilu Meng", "Gregory J. Hakim", "Wenchang Yang", "Gabriel A. Vecchi"], "title": "Large-Ensemble Simulations Reveal Links Between Atmospheric Blocking Frequency and Sea Surface Temperature Variability", "categories": ["physics.ao-ph", "cs.AI", "physics.geo-ph"], "comment": null, "summary": "Atmospheric blocking events drive persistent weather extremes in midlatitudes, but isolating the influence of sea surface temperature (SST) from chaotic internal atmospheric variability on these events remains a challenge. We address this challenge using century-long (1900-2010), large-ensemble simulations with two computationally efficient deep-learning general circulation models. We find these models skillfully reproduce the observed blocking climatology, matching or exceeding the performance of a traditional high-resolution model and representative CMIP6 models. Averaging the large ensembles filters internal atmospheric noise to isolate the SST-forced component of blocking variability, yielding substantially higher correlations with reanalysis than for individual ensemble members. We identify robust teleconnections linking Greenland blocking frequency to North Atlantic SST and El Ni\u00f1o-like patterns. Furthermore, SST-forced trends in blocking frequency show a consistent decline in winter over Greenland, and an increase over Europe. These results demonstrate that SST variability exerts a significant and physically interpretable influence on blocking frequency and establishes large ensembles from deep learning models as a powerful tool for separating forced SST signals from internal noise.", "AI": {"tldr": "The paper investigates how sea surface temperatures (SST) impact atmospheric blocking events using deep-learning models and large ensemble simulations.", "motivation": "Understanding the persistent weather extremes caused by atmospheric blocking and isolating the role of sea surface temperatures from internal atmospheric variability remains challenging.", "method": "Century-long large-ensemble simulations from deep-learning general circulation models were used to filter atmospheric noise and analyze SST-forced variability and trends.", "result": "Deep-learning models skillfully reproduced blocking climatology, identified SST-related teleconnections, and highlighted trends such as declining Greenland blocking frequency in winter and increasing blocking frequency over Europe.", "conclusion": "Sea surface temperatures significantly influence atmospheric blocking frequency, and large ensembles from deep-learning models serve as an effective method to distinguish forced signals from atmospheric noise."}}
{"id": "2602.05453", "pdf": "https://arxiv.org/pdf/2602.05453", "abs": "https://arxiv.org/abs/2602.05453", "authors": ["Budhaditya Mukhopadhyay", "Chirag Mandal", "Pavan Tummala", "Naghmeh Mahmoodian", "Andreas N\u00fcrnberger", "Soumick Chatterjee"], "title": "Towards Segmenting the Invisible: An End-to-End Registration and Segmentation Framework for Weakly Supervised Tumour Analysis", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "Accepted for AIBio at ECAI 2025", "summary": "Liver tumour ablation presents a significant clinical challenge: whilst tumours are clearly visible on pre-operative MRI, they are often effectively invisible on intra-operative CT due to minimal contrast between pathological and healthy tissue. This work investigates the feasibility of cross-modality weak supervision for scenarios where pathology is visible in one modality (MRI) but absent in another (CT). We present a hybrid registration-segmentation framework that combines MSCGUNet for inter-modal image registration with a UNet-based segmentation module, enabling registration-assisted pseudo-label generation for CT images. Our evaluation on the CHAOS dataset demonstrates that the pipeline can successfully register and segment healthy liver anatomy, achieving a Dice score of 0.72. However, when applied to clinical data containing tumours, performance degrades substantially (Dice score of 0.16), revealing the fundamental limitations of current registration methods when the target pathology lacks corresponding visual features in the target modality. We analyse the \"domain gap\" and \"feature absence\" problems, demonstrating that whilst spatial propagation of labels via registration is feasible for visible structures, segmenting truly invisible pathology remains an open challenge. Our findings highlight that registration-based label transfer cannot compensate for the absence of discriminative features in the target modality, providing important insights for future research in cross-modality medical image analysis. Code an weights are available at: https://github.com/BudhaTronix/Weakly-Supervised-Tumour-Detection", "AI": {"tldr": "This paper addresses the challenge of detecting liver tumors in intra-operative CT when they are only visible on pre-operative MRI by employing a hybrid framework combining image registration and segmentation.", "motivation": "To tackle the difficulty of cross-modality tumor visibility between MRI and CT in liver tumor detection during surgery, as tumors may not have distinguishing features in CT imaging.", "method": "The study introduces a hybrid framework combining MSCGUNet for cross-modal image registration and a UNet-based segmentation module to create pseudo-labels for CT images based on MRI data.", "result": "The framework achieves a Dice score of 0.72 for healthy liver anatomy segmentation on the CHAOS dataset but drops to 0.16 when applied to tumor-containing clinical data, showcasing its limitations for invisible pathology.", "conclusion": "Registration-based methods are effective for visible structures but fail for invisible pathology due to a lack of discriminative features, highlighting a need for further research in cross-modality medical image analysis."}}
{"id": "2602.05707", "pdf": "https://arxiv.org/pdf/2602.05707", "abs": "https://arxiv.org/abs/2602.05707", "authors": ["Amir Asiaee", "Kaveh Aryan"], "title": "Fix Representation (Optimally) Before Fairness: Finite-Sample Shrinkage Population Correction and the True Price of Fairness Under Subpopulation Shift", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning practitioners frequently observe tension between predictive accuracy and group fairness constraints -- yet sometimes fairness interventions appear to improve accuracy. We show that both phenomena can be artifacts of training data that misrepresents subgroup proportions. Under subpopulation shift (stable within-group distributions, shifted group proportions), we establish: (i) full importance-weighted correction is asymptotically unbiased but finite-sample suboptimal; (ii) the optimal finite-sample correction is a shrinkage reweighting that interpolates between target and training mixtures; (iii) apparent \"fairness helps accuracy\" can arise from comparing fairness methods to an improperly-weighted baseline. We provide an actionable evaluation protocol: fix representation (optimally) before fairness -- compare fairness interventions against a shrinkage-corrected baseline to isolate the true, irreducible price of fairness. Experiments on synthetic and real-world benchmarks (Adult, COMPAS) validate our theoretical predictions and demonstrate that this protocol eliminates spurious tradeoffs, revealing the genuine fairness-utility frontier.", "AI": {"tldr": "The paper discusses how subgroup proportion misrepresentation in training data can create deceptive results in fairness vs. accuracy trade-offs and proposes a protocol to address it.", "motivation": "To address and clarify why fairness interventions sometimes appear to improve accuracy in machine learning, particularly under conditions where subgroup proportions are misrepresented in training data.", "method": "The authors use theoretical analysis to identify the issues in subgroup proportion misrepresentation and propose a shrinkage reweighting method. They also recommend assessing fairness interventions against an optimally reweighted benchmark to isolate fairness-utility trade-offs.", "result": "The proposed evaluation protocol eliminates misleading trade-offs and accurately identifies the genuine relationship between fairness and accuracy, verified through experiments on synthetic and real-world datasets.", "conclusion": "Fairness interventions can appear beneficial due to dataset biases. Correcting these biases systematically before analyzing fairness accurately reveals true trade-offs, ensuring reliable conclusions about fairness's impact on accuracy."}}
{"id": "2602.05713", "pdf": "https://arxiv.org/pdf/2602.05713", "abs": "https://arxiv.org/abs/2602.05713", "authors": ["Amir Asiaee", "Kaveh Aryan"], "title": "Projected Boosting with Fairness Constraints: Quantifying the Cost of Fair Training Distributions", "categories": ["cs.LG"], "comment": null, "summary": "Boosting algorithms enjoy strong theoretical guarantees: when weak learners maintain positive edge, AdaBoost achieves geometric decrease of exponential loss. We study how to incorporate group fairness constraints into boosting while preserving analyzable training dynamics. Our approach, FairBoost, projects the ensemble-induced exponential-weights distribution onto a convex set of distributions satisfying fairness constraints (as a reweighting surrogate), then trains weak learners on this fair distribution. The key theoretical insight is that projecting the training distribution reduces the effective edge of weak learners by a quantity controlled by the KL-divergence of the projection. We prove an exponential-loss bound where the convergence rate depends on weak learner edge minus a \"fairness cost\" term $\u03b4_t = \\sqrt{\\mathrm{KL}(w^t \\| q^t)/2}$. This directly quantifies the accuracy-fairness tradeoff in boosting dynamics. Experiments on standard benchmarks validate the theoretical predictions and demonstrate competitive fairness-accuracy tradeoffs with stable training curves.", "AI": {"tldr": "The paper introduces FairBoost, a boosting algorithm with fairness constraints. The approach projects training distributions to satisfy fairness requirements, balancing accuracy and fairness effectively.", "motivation": "To integrate group fairness constraints into boosting algorithms while maintaining structured and analyzable training dynamics.", "method": "FairBoost incorporates fairness by projecting ensemble-induced exponential-weights distributions onto a convex set that satisfies fairness constraints. This projection impacts weak learners' effective edge, quantified by the KL-divergence between distributions.", "result": "The authors demonstrate an exponential-loss bound where the convergence rate balances weak learner edge and fairness constraints, confirming the theoretical accuracy-fairness tradeoff.", "conclusion": "FairBoost successfully integrates fairness into ensemble learning algorithms, achieving a balance between accuracy and fairness. Experiments validate the method with competitive and stable performance."}}
{"id": "2602.05496", "pdf": "https://arxiv.org/pdf/2602.05496", "abs": "https://arxiv.org/abs/2602.05496", "authors": ["Hanwen Zhang", "Yao Liu", "Peiyuan Jiang", "Lang Junjie", "Xie Jun", "Yihui He", "Yajiao Deng", "Siyu Du", "Qiao Liu"], "title": "XEmoGPT: An Explainable Multimodal Emotion Recognition Framework with Cue-Level Perception and Reasoning", "categories": ["cs.MM", "cs.AI", "cs.CV"], "comment": null, "summary": "Explainable Multimodal Emotion Recognition plays a crucial role in applications such as human-computer interaction and social media analytics. However, current approaches struggle with cue-level perception and reasoning due to two main challenges: 1) general-purpose modality encoders are pretrained to capture global structures and general semantics rather than fine-grained emotional cues, resulting in limited sensitivity to emotional signals; and 2) available datasets usually involve a trade-off between annotation quality and scale, which leads to insufficient supervision for emotional cues and ultimately limits cue-level reasoning. Moreover, existing evaluation metrics are inadequate for assessing cue-level reasoning performance. To address these challenges, we propose eXplainable Emotion GPT (XEmoGPT), a novel EMER framework capable of both perceiving and reasoning over emotional cues. It incorporates two specialized modules: the Video Emotional Cue Bridge (VECB) and the Audio Emotional Cue Bridge (AECB), which enhance the video and audio encoders through carefully designed tasks for fine-grained emotional cue perception. To further support cue-level reasoning, we construct a large-scale dataset, EmoCue, designed to teach XEmoGPT how to reason over multimodal emotional cues. In addition, we introduce EmoCue-360, an automated metric that extracts and matches emotional cues using semantic similarity, and release EmoCue-Eval, a benchmark of 400 expert-annotated samples covering diverse emotional scenarios. Experimental results show that XEmoGPT achieves strong performance in both emotional cue perception and reasoning.", "AI": {"tldr": "This paper addresses challenges in multimodal emotion recognition by introducing XEmoGPT, which focuses on fine-grained emotional cue perception and reasoning through specialized modules and new datasets/metrics.", "motivation": "Current methods for multimodal emotion recognition face limitations in fine-grained cue perception and reasoning due to general-purpose encoders and insufficiently annotated datasets.", "method": "The authors propose XEmoGPT, adding Video Emotional Cue Bridge (VECB) and Audio Emotional Cue Bridge (AECB) to improve emotional cue perception in video/audio encoders. They also introduce a new large-scale dataset (EmoCue) and an evaluation metric (EmoCue-360).", "result": "Experimental results demonstrate that XEmoGPT excels at recognizing and reasoning about emotional cues, outperforming existing methods.", "conclusion": "XEmoGPT presents a notable improvement in explainable multimodal emotion recognition through its specialized approach to cue perception, reasoning, and evaluation metrics. It addresses key challenges in the field with promising results."}}
{"id": "2602.05735", "pdf": "https://arxiv.org/pdf/2602.05735", "abs": "https://arxiv.org/abs/2602.05735", "authors": ["Lixuan Guo", "Yifei Wang", "Tiansheng Wen", "Yifan Wang", "Aosong Feng", "Bo Chen", "Stefanie Jegelka", "Chenyu You"], "title": "CSRv2: Unlocking Ultra-Sparse Embeddings", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.IT"], "comment": "Accepted by ICLR2026", "summary": "In the era of large foundation models, the quality of embeddings has become a central determinant of downstream task performance and overall system capability. Yet widely used dense embeddings are often extremely high-dimensional, incurring substantial costs in storage, memory, and inference latency. To address these, Contrastive Sparse Representation (CSR) is recently proposed as a promising direction, mapping dense embeddings into high-dimensional but k-sparse vectors, in contrast to compact dense embeddings such as Matryoshka Representation Learning (MRL). Despite its promise, CSR suffers severe degradation in the ultra-sparse regime, where over 80% of neurons remain inactive, leaving much of its efficiency potential unrealized. In this paper, we introduce CSRv2, a principled training approach designed to make ultra-sparse embeddings viable. CSRv2 stabilizes sparsity learning through progressive k-annealing, enhances representational quality via supervised contrastive objectives, and ensures end-to-end adaptability with full backbone finetuning. CSRv2 reduces dead neurons from 80% to 20% and delivers a 14% accuracy gain at k=2, bringing ultra-sparse embeddings on par with CSR at k=8 and MRL at 32 dimensions, all with only two active features. While maintaining comparable performance, CSRv2 delivers a 7x speedup over MRL, and yields up to 300x improvements in compute and memory efficiency relative to dense embeddings in text representation. Extensive experiments across text and vision demonstrate that CSRv2 makes ultra-sparse embeddings practical without compromising performance, where CSRv2 achieves 7%/4% improvement over CSR when k=4 and further increases this gap to 14%/6% when k=2 in text/vision representation. By making extreme sparsity viable, CSRv2 broadens the design space for real-time and edge-deployable AI systems where both embedding quality and efficiency are critical.", "AI": {"tldr": "The paper introduces CSRv2, a method to improve ultra-sparse embeddings by stabilizing sparsity learning, improving representational quality, and enhancing efficiency.", "motivation": "The motivation is to address inefficiency in conventional high-dimensional embeddings used for AI tasks while making ultra-sparse embeddings practical and maintaining their quality.", "method": "The CSRv2 method employs progressive k-annealing, supervised contrastive objectives, and fine-tuning to stabilize ultra-sparse embeddings.", "result": "CSRv2 reduces inactive neurons, delivers significant accuracy improvements, achieves speedup over previous methods, and enhances compute/memory efficiency.", "conclusion": "CSRv2 successfully makes ultra-sparse embeddings practical and efficient, broadening the scope for deployable AI systems while ensuring embedding quality."}}
{"id": "2602.05746", "pdf": "https://arxiv.org/pdf/2602.05746", "abs": "https://arxiv.org/abs/2602.05746", "authors": ["Xin Chen", "Jie Zhang", "Florian Tramer"], "title": "Learning to Inject: Automated Prompt Injection via Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Prompt injection is one of the most critical vulnerabilities in LLM agents; yet, effective automated attacks remain largely unexplored from an optimization perspective. Existing methods heavily depend on human red-teamers and hand-crafted prompts, limiting their scalability and adaptability. We propose AutoInject, a reinforcement learning framework that generates universal, transferable adversarial suffixes while jointly optimizing for attack success and utility preservation on benign tasks. Our black-box method supports both query-based optimization and transfer attacks to unseen models and tasks. Using only a 1.5B parameter adversarial suffix generator, we successfully compromise frontier systems including GPT 5 Nano, Claude Sonnet 3.5, and Gemini 2.5 Flash on the AgentDojo benchmark, establishing a stronger baseline for automated prompt injection research.", "AI": {"tldr": "AutoInject addresses prompt injection vulnerabilities in LLMs by utilizing reinforcement learning for creating adversarial suffixes that compromise various frontier systems.", "motivation": "Existing methods for tackling prompt injection are limited by reliance on humans and lack scalability and adaptability.", "method": "AutoInject uses a reinforcement learning framework to generate adversarial suffixes, optimizing for attack success and utility preservation.", "result": "The method successfully compromises multiple advanced models, such as GPT 5 Nano and Claude Sonnet 3.5, using a 1.5B parameter adversarial suffix generator.", "conclusion": "AutoInject establishes a robust baseline for studying automated prompt injection vulnerabilities in LLMs and highlights its transferability and efficacy."}}
{"id": "2602.05749", "pdf": "https://arxiv.org/pdf/2602.05749", "abs": "https://arxiv.org/abs/2602.05749", "authors": ["Kai Ming Ting", "Wei-Jie Xu", "Hang Zhang"], "title": "How to Achieve the Intended Aim of Deep Clustering Now, without Deep Learning", "categories": ["cs.LG"], "comment": "Work on progress", "summary": "Deep clustering (DC) is often quoted to have a key advantage over $k$-means clustering. Yet, this advantage is often demonstrated using image datasets only, and it is unclear whether it addresses the fundamental limitations of $k$-means clustering. Deep Embedded Clustering (DEC) learns a latent representation via an autoencoder and performs clustering based on a $k$-means-like procedure, while the optimization is conducted in an end-to-end manner. This paper investigates whether the deep-learned representation has enabled DEC to overcome the known fundamental limitations of $k$-means clustering, i.e., its inability to discover clusters of arbitrary shapes, varied sizes and densities. Our investigations on DEC have a wider implication on deep clustering methods in general. Notably, none of these methods exploit the underlying data distribution. We uncover that a non-deep learning approach achieves the intended aim of deep clustering by making use of distributional information of clusters in a dataset to effectively address these fundamental limitations.", "AI": {"tldr": "The paper examines whether Deep Embedded Clustering (DEC) truly addresses the fundamental limitations of $k$-means clustering and suggests a strong non-deep learning alternative that uses distributional data.", "motivation": "The study seeks to determine if DEC and similar deep clustering methods can overcome $k$-means' limitations, particularly its inability to identify clusters of arbitrary shapes, sizes, and densities.", "method": "The authors evaluate DEC\u2019s ability to learn effective latent representations and analyze its clustering performance against known limitations of $k$-means. They also compare DEC with a non-deep learning method that leverages distributional information.", "result": "The authors find that DEC, and deep clustering methods in general, do not adequately address $k$-means\u2019 inherent issues. Instead, a non-deep learning approach effectively overcomes these limitations.", "conclusion": "Deep clustering methods, including DEC, fail to fully exploit data distribution, and a non-deep learning approach can achieve similar or better results in addressing clustering limitations."}}
{"id": "2602.05774", "pdf": "https://arxiv.org/pdf/2602.05774", "abs": "https://arxiv.org/abs/2602.05774", "authors": ["Xiandong Zou", "Jianshu Li", "Jing Huang", "Pan Zhou"], "title": "Variational Speculative Decoding: Rethinking Draft Training from Token Likelihood to Sequence Acceptance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Speculative decoding accelerates inference for (M)LLMs, yet a training-decoding discrepancy persists: while existing methods optimize single greedy trajectories, decoding involves verifying and ranking multiple sampled draft paths. We propose Variational Speculative Decoding (VSD), formulating draft training as variational inference over latent proposals (draft paths). VSD maximizes the marginal probability of target-model acceptance, yielding an ELBO that promotes high-quality latent proposals while minimizing divergence from the target distribution. To enhance quality and reduce variance, we incorporate a path-level utility and optimize via an Expectation-Maximization procedure. The E-step draws MCMC samples from an oracle-filtered posterior, while the M-step maximizes weighted likelihood using Adaptive Rejection Weighting (ARW) and Confidence-Aware Regularization (CAR). Theoretical analysis confirms that VSD increases expected acceptance length and speedup. Extensive experiments across LLMs and MLLMs show that VSD achieves up to a 9.6% speedup over EAGLE-3 and 7.9% over ViSpec, significantly improving decoding efficiency.", "AI": {"tldr": "The paper introduces Variational Speculative Decoding (VSD) to improve inference speed and efficiency in LLMs and MLLMs by maximizing target-model acceptance probability during decoding.", "motivation": "The existing gap between training and decoding for speculative inference methods in language models calls for a better framework that considers the verification and ranking of multiple draft paths during decoding.", "method": "The authors propose VSD, which formulates draft training as variational inference by maximizing the marginal probability of target-model acceptance. They optimize this with an ELBO that includes latent proposal quality and divergence minimization. Techniques like MCMC sampling, Adaptive Rejection Weighting, and Confidence-Aware Regularization are applied for improved outcomes.", "result": "VSD improves decoding efficiency by achieving up to 9.6% and 7.9% speedup over the previous state-of-the-art methods EAGLE-3 and ViSpec, respectively, validated through extensive experiments on LLMs and MLLMs.", "conclusion": "VSD effectively addresses the training-decoding discrepancy by optimizing draft paths for higher target-model acceptance, thereby significantly enhancing inference speed and decoding efficiency."}}
{"id": "2602.05738", "pdf": "https://arxiv.org/pdf/2602.05738", "abs": "https://arxiv.org/abs/2602.05738", "authors": ["Sajjan Acharya", "Pralisha Kansakar"], "title": "Disc-Centric Contrastive Learning for Lumbar Spine Severity Grading", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This work examines a disc-centric approach for automated severity grading of lumbar spinal stenosis from sagittal T2-weighted MRI. The method combines contrastive pretraining with disc-level fine-tuning, using a single anatomically localized region of interest per intervertebral disc. Contrastive learning is employed to help the model focus on meaningful disc features and reduce sensitivity to irrelevant differences in image appearance. The framework includes an auxiliary regression task for disc localization and applies weighted focal loss to address class imbalance. Experiments demonstrate a 78.1% balanced accuracy and a reduced severe-to-normal misclassification rate of 2.13% compared with supervised training from scratch. Detecting discs with moderate severity can still be challenging, but focusing on disc-level features provides a practical way to assess the lumbar spinal stenosis.", "AI": {"tldr": "A disc-centric approach for automated lumbar spinal stenosis severity grading improves accuracy and reduces misclassification using contrastive pretraining, disc-level fine-tuning, and auxiliary tasks.", "motivation": "To improve the accuracy and reliability of automated severity grading for lumbar spinal stenosis in MRI, overcoming the challenges of class imbalance and irrelevant image differences.", "method": "The approach employs contrastive pretraining, disc-level fine-tuning, and auxiliary regression for disc localization. Weighted focal loss is used to address class imbalance, and only a single localized region of interest per intervertebral disc is used.", "result": "Achieved 78.1% balanced accuracy with a reduced severe-to-normal misclassification rate (2.13%), although moderate severity detection remains challenging.", "conclusion": "Disc-level feature analysis using this method provides a practical and effective way to assess lumbar spinal stenosis, despite challenges in detecting moderate severity."}}
{"id": "2602.05776", "pdf": "https://arxiv.org/pdf/2602.05776", "abs": "https://arxiv.org/abs/2602.05776", "authors": ["Mengbei Yan", "Jiafei Lyu", "Shengjie Sun", "Zhongjian Qiao", "Jingwen Yang", "Zichuan Lin", "Deheng Ye", "Xiu Li"], "title": "Cross-Domain Offline Policy Adaptation via Selective Transition Correction", "categories": ["cs.LG"], "comment": null, "summary": "It remains a critical challenge to adapt policies across domains with mismatched dynamics in reinforcement learning (RL). In this paper, we study cross-domain offline RL, where an offline dataset from another similar source domain can be accessed to enhance policy learning upon a target domain dataset. Directly merging the two datasets may lead to suboptimal performance due to potential dynamics mismatches. Existing approaches typically mitigate this issue through source domain transition filtering or reward modification, which, however, may lead to insufficient exploitation of the valuable source domain data. Instead, we propose to modify the source domain data into the target domain data. To that end, we leverage an inverse policy model and a reward model to correct the actions and rewards of source transitions, explicitly achieving alignment with the target dynamics. Since limited data may result in inaccurate model training, we further employ a forward dynamics model to retain corrected samples that better match the target dynamics than the original transitions. Consequently, we propose the Selective Transition Correction (STC) algorithm, which enables reliable usage of source domain data for policy adaptation. Experiments on various environments with dynamics shifts demonstrate that STC achieves superior performance against existing baselines.", "AI": {"tldr": "The paper addresses cross-domain offline reinforcement learning by presenting an algorithm, Selective Transition Correction (STC), to effectively adapt policies across domains with mismatched dynamics.", "motivation": "To overcome the challenges in cross-domain offline RL, especially due to dynamics mismatches between source and target domains, and to utilize valuable data from a source domain without compromising performance.", "method": "The authors propose the Selective Transition Correction (STC) algorithm that modifies source domain data to align with target domain dynamics using an inverse policy model, a reward model, and a forward dynamics model to ensure data accuracy.", "result": "STC demonstrates superior performance across various environments with dynamics shifts when compared with existing baseline methods.", "conclusion": "STC reliably incorporates source domain data for policy adaptation, addressing dynamics mismatches, and achieves notable improvement in cross-domain offline RL."}}
{"id": "2602.05779", "pdf": "https://arxiv.org/pdf/2602.05779", "abs": "https://arxiv.org/abs/2602.05779", "authors": ["Emily Dent", "Jared Tanner"], "title": "How Controlling the Variance can Improve Training Stability of Sparsely Activated DNNs and CNNs", "categories": ["cs.LG", "cs.IT"], "comment": null, "summary": "The intermediate layers of deep networks can be characterised as a Gaussian process, in particular the Edge-of-Chaos (EoC) initialisation strategy prescribes the limiting covariance matrix of the Gaussian process. Here we show that the under-utilised chosen variance of the Gaussian process is important in the training of deep networks with sparsity inducing activation, such as a shifted and clipped ReLU, $\\text{CReLU}_{\u03c4,m}(x)=\\min(\\max(x-\u03c4,0),m)$. Specifically, initialisations leading to larger fixed Gaussian process variances, allow for improved expressivity with activation sparsity as large as 90% in DNNs and CNNs, and generally improve the stability of the training process. Enabling full, or near full, accuracy at such high levels of sparsity in the hidden layers suggests a promising mechanism to reduce the energy consumption of machine learning models involving fully connected layers.", "AI": {"tldr": "The paper explores how larger Gaussian process variances in deep networks improve training stability and expressivity, particularly with high activation sparsity, reducing energy consumption in machine learning models.", "motivation": "Optimizing the initialization and activation sparsity in deep networks to enhance training stability, expressivity, and energy efficiency in modern machine learning.", "method": "Introduces shifted and clipped ReLU ($\\text{CReLU}_{\u03c4,m}(x)$) activation and investigates the role of Gaussian process variance in training deep networks under high sparsity conditions.", "result": "Larger Gaussian process variances lead to better expressivity and stability, achieving full/nearly full accuracy even with activation sparsity as high as 90%.", "conclusion": "Proper initialization with large Gaussian process variances can significantly improve DNN/CNN training efficiency and accuracy, while enabling energy savings in high-sparsity models."}}
{"id": "2602.06042", "pdf": "https://arxiv.org/pdf/2602.06042", "abs": "https://arxiv.org/abs/2602.06042", "authors": ["Yamit Ehrlich", "Nimrod Berman", "Assaf Shocher"], "title": "Pseudo-Invertible Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The Moore-Penrose Pseudo-inverse (PInv) serves as the fundamental solution for linear systems. In this paper, we propose a natural generalization of PInv to the nonlinear regime in general and to neural networks in particular. We introduce Surjective Pseudo-invertible Neural Networks (SPNN), a class of architectures explicitly designed to admit a tractable non-linear PInv. The proposed non-linear PInv and its implementation in SPNN satisfy fundamental geometric properties. One such property is null-space projection or \"Back-Projection\", $x' = x + A^\\dagger(y-Ax)$, which moves a sample $x$ to its closest consistent state $x'$ satisfying $Ax=y$. We formalize Non-Linear Back-Projection (NLBP), a method that guarantees the same consistency constraint for non-linear mappings $f(x)=y$ via our defined PInv. We leverage SPNNs to expand the scope of zero-shot inverse problems. Diffusion-based null-space projection has revolutionized zero-shot solving for linear inverse problems by exploiting closed-form back-projection. We extend this method to non-linear degradations. Here, \"degradation\" is broadly generalized to include any non-linear loss of information, spanning from optical distortions to semantic abstractions like classification. This approach enables zero-shot inversion of complex degradations and allows precise semantic control over generative outputs without retraining the diffusion prior.", "AI": {"tldr": "This paper introduces Surjective Pseudo-invertible Neural Networks (SPNNs), which enable a tractable extension of the Moore-Penrose Pseudo-inverse to non-linear scenarios. It focuses on enhancing zero-shot capabilities for addressing nonlinear inverse problems.", "motivation": "To generalize the Moore-Penrose Pseudo-inverse beyond traditional linear systems into non-linear domains, specifically designing an architecture for neural networks to expand their applications.", "method": "The authors propose Surjective Pseudo-invertible Neural Networks (SPNN), which incorporate the concept of non-linear Pseudo-inverse. They formalize Non-Linear Back-Projection (NLBP) as a method to preserve consistency constraints for non-linear mappings.", "result": "The study demonstrates how SPNNs expand zero-shot inverse problem solving to nonlinear degradations, including optical distortions and semantic abstractions, without requiring retraining of diffusion priors.", "conclusion": "SPNNs provide a robust framework for handling nonlinear inverse problems, facilitating precise semantic control in generative models and extending the reach of zero-shot solutions."}}
{"id": "2602.05783", "pdf": "https://arxiv.org/pdf/2602.05783", "abs": "https://arxiv.org/abs/2602.05783", "authors": ["Shutong Ding", "Yimiao Zhou", "Ke Hu", "Mokai Pan", "Shan Zhong", "Yanwei Fu", "Jingya Wang", "Ye Shi"], "title": "Distributional Reinforcement Learning with Diffusion Bridge Critics", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in diffusion-based reinforcement learning (RL) methods have demonstrated promising results in a wide range of continuous control tasks. However, existing works in this field focus on the application of diffusion policies while leaving the diffusion critics unexplored. In fact, since policy optimization fundamentally relies on the critic, accurate value estimation is far more important than policy expressiveness. Furthermore, given the stochasticity of most reinforcement learning tasks, it has been confirmed that the critic is more appropriately depicted with a distributional model. Motivated by these points, we propose a novel distributional RL method with Diffusion Bridge Critics (DBC). DBC directly models the inverse cumulative distribution function (CDF) of the Q value. This allows us to accurately capture the value distribution and prevents it from collapsing into a trivial Gaussian distribution owing to the strong distribution-matching capability of the diffusion bridge. Moreover, we further derive an analytic integral formula to address discretization errors in DBC, which is essential in value estimation. To our knowledge, DBC is the first work to employ the diffusion bridge model as the critic. Notably, DBC is also a plug-and-play component and can be integrated into most existing RL frameworks. Experimental results on MuJoCo robot control benchmarks demonstrate the superiority of DBC compared with previous distributional critic models.", "AI": {"tldr": "The paper introduces a new distributional reinforcement learning method using Diffusion Bridge Critics (DBC) for better value estimation in continuous control tasks.", "motivation": "Diffusion-based reinforcement learning methods have shown potential, but there's a lack of exploration in diffusion critics despite their importance in policy optimization.", "method": "The proposed DBC models the inverse cumulative distribution function (CDF) of Q values, leveraging diffusion bridges for accurate value distribution modeling and addressing discretization errors through an analytic integral formula.", "result": "Experimental results on MuJoCo benchmarks show that DBC outperforms previous distributional critic models.", "conclusion": "DBC introduces a novel and effective approach by utilizing diffusion bridges as critics, offering improved value estimation and compatibility with existing RL frameworks."}}
{"id": "2602.06043", "pdf": "https://arxiv.org/pdf/2602.06043", "abs": "https://arxiv.org/abs/2602.06043", "authors": ["Prakhar Kaushik", "Ankit Vaidya", "Shravan Chaudhari", "Rama Chellappa", "Alan Yuille"], "title": "Shared LoRA Subspaces for almost Strict Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands, they lack mechanisms for strict continual learning and knowledge integration, without relying on data replay, or multiple adapters. We propose Share, a novel approach to parameter efficient continual finetuning that learns and dynamically updates a single, shared low-rank subspace, enabling seamless adaptation across multiple tasks and modalities. Share constructs a foundational subspace that extracts core knowledge from past tasks and incrementally integrates new information by identifying essential subspace directions. Knowledge from each new task is incorporated into this evolving subspace, facilitating forward knowledge transfer, while minimizing catastrophic interference. This approach achieves up to 100x parameter reduction and 281x memory savings over traditional LoRA methods, maintaining performance comparable to jointly trained models. A single Share model can replace hundreds of task-specific LoRA adapters, supporting scalable, asynchronous continual learning. Experiments across image classification, natural language understanding, 3D pose estimation, and text-to-image generation validate its effectiveness, making Share a practical and scalable solution for lifelong learning in large-scale AI systems.", "AI": {"tldr": "The paper introduces 'Share,' a parameter-efficient approach to continual learning that uses a single shared low-rank subspace for multi-task and multi-modal adaptation.", "motivation": "Efficient and continual adaptation for large pretrained models is challenging due to catastrophic forgetting and high retraining costs during real-world deployment.", "method": "Share constructs and dynamically updates a single shared low-rank subspace, enabling both forward knowledge transfer and minimal catastrophic interference without replay or multiple adapters.", "result": "Share achieves up to 100x parameter reduction and 281x memory savings compared to LoRA, maintaining comparable performance to jointly trained models across diverse tasks.", "conclusion": "Share offers scalable, asynchronous continual learning and replaces hundreds of task-specific adapters, making it practical for long-term learning in large AI systems."}}
{"id": "2602.05184", "pdf": "https://arxiv.org/pdf/2602.05184", "abs": "https://arxiv.org/abs/2602.05184", "authors": ["Lauren Greenspan", "David Berman", "Aryeh Brill", "Ro Jefferson", "Artemy Kolchinsky", "Jennifer Lin", "Andrew Mack", "Anindita Maiti", "Fernando E. Rosas", "Alexander Stapleton", "Lucas Teixeira", "Dmitry Vaintrob"], "title": "Towards Worst-Case Guarantees with Scale-Aware Interpretability", "categories": ["hep-th", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural networks organize information according to the hierarchical, multi-scale structure of natural data. Methods to interpret model internals should be similarly scale-aware, explicitly tracking how features compose across resolutions and guaranteeing bounds on the influence of fine-grained structure that is discarded as irrelevant noise. We posit that the renormalisation framework from physics can meet this need by offering technical tools that can overcome limitations of current methods. Moreover, relevant work from adjacent fields has now matured to a point where scattered research threads can be synthesized into practical, theory-informed tools. To combine these threads in an AI safety context, we propose a unifying research agenda -- \\emph{scale-aware interpretability} -- to develop formal machinery and interpretability tools that have robustness and faithfulness properties supported by statistical physics.", "AI": {"tldr": "The paper introduces scale-aware interpretability in neural networks to track feature composition across resolutions using concepts from renormalisation physics.", "motivation": "Current interpretability methods lack mechanisms to properly account for hierarchical, multi-scale data structures in neural networks.", "method": "Proposes using renormalisation techniques from physics to synthesize scattered research into robust tools with theoretical grounding.", "result": "Potential development of more precise interpretability frameworks emphasizing robustness and elimination of irrelevant noise.", "conclusion": "Scale-aware interpretability offers promising advancements in AI safety with a stronger theoretical foundation."}}
{"id": "2602.05797", "pdf": "https://arxiv.org/pdf/2602.05797", "abs": "https://arxiv.org/abs/2602.05797", "authors": ["Caihong Qin", "Yang Bai"], "title": "Classification Under Local Differential Privacy with Model Reversal and Model Averaging", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "Local differential privacy (LDP) has become a central topic in data privacy research, offering strong privacy guarantees by perturbing user data at the source and removing the need for a trusted curator. However, the noise introduced by LDP often significantly reduces data utility. To address this issue, we reinterpret private learning under LDP as a transfer learning problem, where the noisy data serve as the source domain and the unobserved clean data as the target. We propose novel techniques specifically designed for LDP to improve classification performance without compromising privacy: (1) a noised binary feedback-based evaluation mechanism for estimating dataset utility; (2) model reversal, which salvages underperforming classifiers by inverting their decision boundaries; and (3) model averaging, which assigns weights to multiple reversed classifiers based on their estimated utility. We provide theoretical excess risk bounds under LDP and demonstrate how our methods reduce this risk. Empirical results on both simulated and real-world datasets show substantial improvements in classification accuracy.", "AI": {"tldr": "The paper addresses the issue of reduced data utility in Local Differential Privacy (LDP) by reinterpreting it as a transfer learning problem and introducing methods like binary feedback-based utility evaluation, model reversal, and model averaging.", "motivation": "To overcome the challenge of reduced data utility caused by noise in LDP while maintaining strong privacy guarantees.", "method": "(1) Binary feedback-based utility evaluation mechanism; (2) Model reversal for underperforming classifiers; (3) Model averaging by assigning weights to reversed classifiers based on utility.", "result": "Theoretical excess risk bounds are calculated, and empirical tests on simulated and real-world datasets show significant improvements in classification accuracy under LDP.", "conclusion": "The proposed methods effectively enhance classification performance without weakening privacy guarantees in LDP systems."}}
{"id": "2602.05810", "pdf": "https://arxiv.org/pdf/2602.05810", "abs": "https://arxiv.org/abs/2602.05810", "authors": ["Quan M. Tran", "Zhuo Huang", "Wenbin Zhang", "Bo Han", "Koji Yatani", "Masashi Sugiyama", "Tongliang Liu"], "title": "Bifrost: Steering Strategic Trajectories to Bridge Contextual Gaps for Self-Improving Agents", "categories": ["cs.LG"], "comment": null, "summary": "Autonomous agents excel in self-improvement through reflection and iterative refinement, which reuse successful task trajectories as in-context examples to assist subsequent reasoning. However, shifting across tasks often introduces a context mismatch. Hence, existing approaches either discard the trajectories or manipulate them using heuristics, leading to a non-negligible fine-tuning cost or unguaranteed performance. To bridge this gap, we reveal a context-trajectory correlation, where shifts of context are highly parallel with shifts of trajectory. Based on this finding, we propose BrIdge contextual gap FoR imprOvised trajectory STeering (Bifrost), a training-free method that leverages context differences to precisely guide the adaptation of previously solved trajectories towards the target task, mitigating the misalignment caused by context shifts. Our trajectory adaptation is conducted at the representation level using agent hidden states, ensuring trajectory transformation accurately aligns with the target context in a shared space. Across diverse benchmarks, Bifrost consistently outperforms existing trajectory reuse and finetuned self-improvement methods, demonstrating that agents can effectively leverage past experiences despite substantial context shifts.", "AI": {"tldr": "The paper introduces Bifrost, a training-free method to reuse successful task trajectories by adapting them to new contexts without fine-tuning, achieving superior performance across benchmarks.", "motivation": "To address context mismatches when shifting across tasks that lead to discarded trajectories or reliance on heuristics, resulting in inefficiency and unguaranteed performance.", "method": "Bifrost leverages context differences in a training-free approach to guide the adaptation of task trajectories at the representation level using agent hidden states, ensuring alignment with new contexts.", "result": "The proposed method consistently outperforms existing trajectory reuse and fine-tuning self-improvement approaches across diverse benchmarks.", "conclusion": "Bifrost enables autonomous agents to effectively utilize past experiences despite substantial context shifts, improving their self-improvement abilities without fine-tuning."}}
{"id": "2602.05207", "pdf": "https://arxiv.org/pdf/2602.05207", "abs": "https://arxiv.org/abs/2602.05207", "authors": ["Chunyat Wu", "Jiajun Deng", "Zhengxi Liu", "Zheqi Dai", "Haolin He", "Qiuqiang Kong"], "title": "ARCHI-TTS: A flow-matching-based Text-to-Speech Model with Self-supervised Semantic Aligner and Accelerated Inference", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted by ICASSP 2026", "summary": "Although diffusion-based, non-autoregressive text-to-speech (TTS) systems have demonstrated impressive zero-shot synthesis capabilities, their efficacy is still hindered by two key challenges: the difficulty of text-speech alignment modeling and the high computational overhead of the iterative denoising process. To address these limitations, we propose ARCHI-TTS that features a dedicated semantic aligner to ensure robust temporal and semantic consistency between text and audio. To overcome high computational inference costs, ARCHI-TTS employs an efficient inference strategy that reuses encoder features across denoising steps, drastically accelerating synthesis without performance degradation. An auxiliary CTC loss applied to the condition encoder further enhances the semantic understanding. Experimental results demonstrate that ARCHI-TTS achieves a WER of 1.98% on LibriSpeech-PC test-clean, and 1.47%/1.42% on SeedTTS test-en/test-zh with a high inference efficiency, consistently outperforming recent state-of-the-art TTS systems.", "AI": {"tldr": "The paper introduces ARCHI-TTS, a diffusion-based TTS system that improves text-speech alignment and computational efficiency, achieving state-of-the-art performance.", "motivation": "To address challenges in diffusion-based TTS systems, such as alignment modeling issues and excessive computational costs during the iterative denoising process.", "method": "ARCHI-TTS employs a semantic aligner to ensure robust text-audio consistency, reuses encoder features to reduce computational overhead, and uses auxiliary CTC loss for enhanced semantic understanding.", "result": "ARCHI-TTS achieves superior performance with low WERs (1.98% on LibriSpeech-PC test-clean and 1.47%/1.42% on SeedTTS test-en/test-zh) and high inference efficiency, surpassing existing TTS systems.", "conclusion": "ARCHI-TTS successfully mitigates the challenges of diffusion-based TTS, offering robust alignment and efficient synthesis while outperforming state-of-the-art systems in accuracy and speed."}}
{"id": "2602.05216", "pdf": "https://arxiv.org/pdf/2602.05216", "abs": "https://arxiv.org/abs/2602.05216", "authors": ["Luke Alexander", "Eric Leonen", "Sophie Szeto", "Artemii Remizov", "Ignacio Tejeda", "Giovanni Inchiostro", "Vasily Ilin"], "title": "Semantic Search over 9 Million Mathematical Theorems", "categories": ["cs.IR", "cs.AI", "math.HO"], "comment": "Feedback is welcome", "summary": "Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \\href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \\href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.", "AI": {"tldr": "This paper explores semantic theorem retrieval at web scale, introducing a large corpus of mathematical theorems and improving search strategies for accurate retrieval.", "motivation": "Mathematicians and theorem-proving agents struggle to find specific mathematical statements due to a lack of efficient and focused search tools that operate at the scale of dense technical literature.", "method": "The authors compiled a unified corpus of 9.2 million theorem statements, utilized short natural-language theorem descriptions for representation, and analyzed various models and strategies to optimize semantic theorem retrieval.", "result": "Their approach significantly enhances theorem-level and paper-level search quality on queries formulated by professional mathematicians compared to existing tools.", "conclusion": "Semantic theorem search is feasible and effective using the proposed method, offering enhanced accessibility and usability at web scale for mathematical research endeavors."}}
{"id": "2602.05813", "pdf": "https://arxiv.org/pdf/2602.05813", "abs": "https://arxiv.org/abs/2602.05813", "authors": ["Artem Riabinin", "Andrey Veprikov", "Arman Bolatov", "Martin Tak\u00e1\u010d", "Aleksandr Beznosikov"], "title": "Where Does Warm-Up Come From? Adaptive Scheduling for Norm-Constrained Optimizers", "categories": ["cs.LG", "math.OC"], "comment": "26 pages, 6 figures, 4 tables", "summary": "We study adaptive learning rate scheduling for norm-constrained optimizers (e.g., Muon and Lion). We introduce a generalized smoothness assumption under which local curvature decreases with the suboptimality gap and empirically verify that this behavior holds along optimization trajectories. Under this assumption, we establish convergence guarantees under an appropriate choice of learning rate, for which warm-up followed by decay arises naturally from the proof rather than being imposed heuristically.\n  Building on this theory, we develop a practical learning rate scheduler that relies only on standard hyperparameters and adapts the warm-up duration automatically at the beginning of training. We evaluate this method on large language model pretraining with LLaMA architectures and show that our adaptive warm-up selection consistently outperforms or at least matches the best manually tuned warm-up schedules across all considered setups, without additional hyperparameter search. Our source code is available at https://github.com/brain-lab-research/llm-baselines/tree/warmup", "AI": {"tldr": "This paper introduces an adaptive learning rate scheduling method tailored for norm-constrained optimizers, demonstrating theoretical convergence guarantees and practical improvements on large language model pretraining tasks.", "motivation": "The paper aims to address the challenge of selecting effective learning rate schedules for norm-constrained optimizers. The existing methods often rely on heuristic warm-up and decay strategies, requiring manual tuning, which is time-consuming and non-adaptive.", "method": "The authors propose a generalized smoothness assumption where curvature decreases with suboptimality gap. They derive convergence guarantees for learning rates involving warm-up and decay based on this assumption. A practical scheduler is developed to adaptively determine warm-up duration using standard hyperparameters, without requiring manual tuning.", "result": "The proposed learning rate scheduler is tested on LLaMA architecture for large language model pretraining. It outperforms or performs on par with manually optimized warm-up schedules consistently across setups, eliminating the need for an extensive hyperparameter search.", "conclusion": "The adaptive learning rate scheduler proves to be reliable and efficient, as it simplifies the training process and achieves strong performance without requiring manual hyperparameter tuning. This practical solution is available for implementation."}}
{"id": "2602.05833", "pdf": "https://arxiv.org/pdf/2602.05833", "abs": "https://arxiv.org/abs/2602.05833", "authors": ["Laura Plein", "Alexi Turcotte", "Arina Hallemans", "Andreas Zeller"], "title": "Synthesizing Realistic Test Data without Breaking Privacy", "categories": ["cs.LG"], "comment": null, "summary": "There is a need for synthetic training and test datasets that replicate statistical distributions of original datasets without compromising their confidentiality. A lot of research has been done in leveraging Generative Adversarial Networks (GANs) for synthetic data generation. However, the resulting models are either not accurate enough or are still vulnerable to membership inference attacks (MIA) or dataset reconstruction attacks since the original data has been leveraged in the training process. In this paper, we explore the feasibility of producing a synthetic test dataset with the same statistical properties as the original one, with only indirectly leveraging the original data in the generation process. The approach is inspired by GANs, with a generation step and a discrimination step. However, in our approach, we use a test generator (a fuzzer) to produce test data from an input specification, preserving constraints set by the original data; a discriminator model determines how close we are to the original data. By evolving samples and determining \"good samples\" with the discriminator, we can generate privacy-preserving data that follows the same statistical distributions are the original dataset, leading to a similar utility as the original data. We evaluated our approach on four datasets that have been used to evaluate the state-of-the-art techniques. Our experiments highlight the potential of our approach towards generating synthetic datasets that have high utility while preserving privacy.", "AI": {"tldr": "The paper addresses the creation of synthetic datasets that mimic the statistical properties of original datasets while ensuring privacy and avoiding threats like membership inference and reconstruction attacks.", "motivation": "There is a growing need for synthetic datasets that maintain the statistical properties of the original data without exposing sensitive information, due to the vulnerabilities in existing GAN-based methods.", "method": "The approach builds on GAN-like methods by using a test generator (fuzzer) and a discriminator model to indirectly generate synthetic datasets. The generator creates test data from input specifications, and the discriminator refines the results to closely match the original dataset\u2019s statistical properties while preserving privacy.", "result": "The proposed method was evaluated on four datasets, yielding positive results in terms of utility and privacy preservation compared to state-of-the-art techniques.", "conclusion": "This approach demonstrates potential for privacy-preserving synthetic data generation with high utility, offering a solution to current model vulnerabilities."}}
{"id": "2602.05849", "pdf": "https://arxiv.org/pdf/2602.05849", "abs": "https://arxiv.org/abs/2602.05849", "authors": ["Conor Rowan", "Finn Murphy-Blanchard"], "title": "Visualizing the loss landscapes of physics-informed neural networks", "categories": ["cs.LG"], "comment": null, "summary": "Training a neural network requires navigating a high-dimensional, non-convex loss surface to find parameters that minimize this loss. In many ways, it is surprising that optimizers such as stochastic gradient descent and ADAM can reliably locate minima which perform well on both the training and test data. To understand the success of training, a \"loss landscape\" community has emerged to study the geometry of the loss function and the dynamics of optimization, often using visualization techniques. However, these loss landscape studies have mostly been limited to machine learning for image classification. In the newer field of physics-informed machine learning, little work has been conducted to visualize the landscapes of losses defined not by regression to large data sets, but by differential operators acting on state fields discretized by neural networks. In this work, we provide a comprehensive review of the loss landscape literature, as well as a discussion of the few existing physics-informed works which investigate the loss landscape. We then use a number of the techniques we survey to empirically investigate the landscapes defined by the Deep Ritz and squared residual forms of the physics loss function. We find that the loss landscapes of physics-informed neural networks have many of the same properties as the data-driven classification problems studied in the literature. Unexpectedly, we find that the two formulations of the physics loss often give rise to similar landscapes, which appear smooth, well-conditioned, and convex in the vicinity of the solution. The purpose of this work is to introduce the loss landscape perspective to the scientific machine learning community, compare the Deep Ritz and the strong form losses, and to challenge prevailing intuitions about the complexity of the loss landscapes of physics-informed networks.", "AI": {"tldr": "The paper reviews and extends loss landscape studies to the field of physics-informed machine learning, offering insights into the geometry of loss functions and optimization dynamics in this domain.", "motivation": "To bridge the gap in loss landscape studies by addressing the underexplored topic of physics-informed machine learning, particularly focusing on differential operators' impact on loss surfaces.", "method": "The authors conduct a review of existing loss landscape studies, apply empirical visualization techniques, and compare loss formulations (Deep Ritz and squared residual physics loss).", "result": "The investigation reveals surprising similarities in loss landscapes between Deep Ritz and squared residual physics loss formulations, often smooth and well-conditioned around solutions, challenging initial assumptions.", "conclusion": "Physics-informed neural networks exhibit properties resembling those in data-driven classification problems, introducing a loss landscape perspective that enriches understanding within scientific machine learning communities."}}
{"id": "2602.05873", "pdf": "https://arxiv.org/pdf/2602.05873", "abs": "https://arxiv.org/abs/2602.05873", "authors": ["Minyoung Kim"], "title": "Large-scale Score-based Variational Posterior Inference for Bayesian Deep Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian (deep) neural networks (BNN) are often more attractive than the mainstream point-estimate vanilla deep learning in various aspects including uncertainty quantification, robustness to noise, resistance to overfitting, and more. The variational inference (VI) is one of the most widely adopted approximate inference methods. Whereas the ELBO-based variational free energy method is a dominant choice in the literature, in this paper we introduce a score-based alternative for BNN variational inference. Although there have been quite a few score-based variational inference methods proposed in the community, most are not adequate for large-scale BNNs for various computational and technical reasons. We propose a novel scalable VI method where the learning objective combines the score matching loss and the proximal penalty term in iterations, which helps our method avoid the reparametrized sampling, and allows for noisy unbiased mini-batch scores through stochastic gradients. This in turn makes our method scalable to large-scale neural networks including Vision Transformers, and allows for richer variational density families. On several benchmarks including visual recognition and time-series forecasting with large-scale deep networks, we empirically show the effectiveness of our approach.", "AI": {"tldr": "This paper introduces a new method for Bayesian neural networks using a score-based approach to variational inference to enhance scalability and effectiveness on large-scale problems.", "motivation": "Bayesian neural networks outperform traditional deep learning in terms of uncertainty quantification, noise robustness, and avoiding overfitting. However, traditional variational inference methods face computational challenges in scaling to large models.", "method": "The authors propose a scalable variational inference method combining score matching loss and a proximal penalty term, allowing noisy, unbiased gradients and avoiding traditional reparameterized sampling.", "result": "The proposed method proves effective on benchmarks for visual recognition and time-series forecasting, demonstrating scalability with large networks like Vision Transformers.", "conclusion": "The study highlights that the new method improves Bayesian neural network scalability and effectiveness, enabling the use of richer variational densities and handling large-scale applications efficiently."}}
{"id": "2602.05887", "pdf": "https://arxiv.org/pdf/2602.05887", "abs": "https://arxiv.org/abs/2602.05887", "authors": ["Tianqi Shen", "Jinji Yang", "Junze He", "Kunhan Gao", "Ziye Ma"], "title": "Escaping Local Minima Provably in Non-convex Matrix Sensing: A Deterministic Framework via Simulated Lifting", "categories": ["cs.LG", "math.OC"], "comment": "48 pages, 10 figures, 5 tables. Submitted to Mathematical Programming", "summary": "Low-rank matrix sensing is a fundamental yet challenging nonconvex problem whose optimization landscape typically contains numerous spurious local minima, making it difficult for gradient-based optimizers to converge to the global optimum. Recent work has shown that over-parameterization via tensor lifting can convert such local minima into strict saddle points, an insight that also partially explains why massive scaling can improve generalization and performance in modern machine learning. Motivated by this observation, we propose a Simulated Oracle Direction (SOD) escape mechanism that simulates the landscape and escape direction of the over-parametrized space, without resorting to actually lifting the problem, since that would be computationally intractable. In essence, we designed a mathematical framework to project over-parametrized escape directions onto the original parameter space to guarantee a strict decrease of objective value from existing local minima. To the best of the our knowledge, this represents the first deterministic framework that could escape spurious local minima with guarantee, especially without using random perturbations or heuristic estimates. Numerical experiments demonstrate that our framework reliably escapes local minima and facilitates convergence to global optima, while incurring minimal computational cost when compared to explicit tensor over-parameterization. We believe this framework has non-trivial implications for nonconvex optimization beyond matrix sensing, by showcasing how simulated over-parameterization can be leveraged to tame challenging optimization landscapes.", "AI": {"tldr": "This paper addresses challenges in nonconvex low-rank matrix sensing by proposing a novel method to escape spurious local minima without computationally expensive techniques like tensor lifting.", "motivation": "To overcome the difficulty of gradient-based methods converging to global optima in low-rank matrix sensing due to the presence of spurious local minima in the optimization landscape.", "method": "A new Simulated Oracle Direction (SOD) framework was introduced to simulate over-parameterized escape directions and project them onto the original parameter space for guaranteed result improvement without computationally intractable tensor lifting.", "result": "The proposed framework was shown to reliably escape local minima, facilitate global convergence, and was computationally efficient compared to explicit tensor over-parameterization.", "conclusion": "Simulated over-parameterization provides a deterministic, efficient approach to solve challenges in nonconvex optimization landscapes, potentially extending its application beyond matrix sensing."}}
{"id": "2602.05386", "pdf": "https://arxiv.org/pdf/2602.05386", "abs": "https://arxiv.org/abs/2602.05386", "authors": ["Zhenxiong Yu", "Zhi Yang", "Zhiheng Jin", "Shuhe Wang", "Heng Zhang", "Yanlin Fei", "Lingfeng Zeng", "Fangqi Lou", "Shuo Zhang", "Tu Hu", "Jingping Liu", "Rongze Chen", "Xingyu Zhu", "Kunyi Wang", "Chaofa Yuan", "Xin Guo", "Zhaowei Liu", "Feipeng Zhang", "Jie Huang", "Huacan Wang", "Ronghao Chen", "Liwen Zhang"], "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S$^2$Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\\%.", "AI": {"tldr": "The paper introduces Spider-Sense, a framework for agent-based defense that uses intrinsic risk sensing for improved security in autonomous LLM agents.", "motivation": "To address the gap in effective security for autonomous large language model agents by providing defenses that are intrinsic, selective, and integrated rather than mandatory and decoupled.", "method": "Developing Spider-Sense, an event-driven defense framework that uses Intrinsic Risk Sensing to trigger a hierarchical defense mechanism based on risk perception.", "result": "Spider-Sense achieved low Attack Success Rates (ASR) and False Positive Rates (FPR) with only an 8.3% latency overhead, demonstrating its competitive or superior defense performance.", "conclusion": "Spider-Sense provides an efficient and precise security solution for LLM-powered autonomous agents, prioritizing intrinsic sensing and hierarchical escalation to minimize vulnerabilities."}}
{"id": "2602.05892", "pdf": "https://arxiv.org/pdf/2602.05892", "abs": "https://arxiv.org/abs/2602.05892", "authors": ["Han Li", "Letian Zhu", "Bohan Zhang", "Rili Feng", "Jiaming Wang", "Yue Pan", "Earl T. Barr", "Sarro Federica", "Zhaoyang Chu", "He Ye"], "title": "ContextBench: A Benchmark for Context Retrieval in Coding Agents", "categories": ["cs.LG"], "comment": "36 pages, 6 figures, 4 tables", "summary": "LLM-based coding agents have shown strong performance on automated issue resolution benchmarks, yet existing evaluations largely focus on final task success, providing limited insight into how agents retrieve and use code context during problem solving. We introduce ContextBench, a process-oriented evaluation of context retrieval in coding agents. ContextBench consists of 1,136 issue-resolution tasks from 66 repositories across eight programming languages, each augmented with human-annotated gold contexts. We further implement an automated evaluation framework that tracks agent trajectories and measures context recall, precision, and efficiency throughout issue resolution. Using ContextBench, we evaluate four frontier LLMs and five coding agents. Our results show that sophisticated agent scaffolding yields only marginal gains in context retrieval (\"The Bitter Lesson\" of coding agents), LLMs consistently favor recall over precision, and substantial gaps exist between explored and utilized context. ContextBench augments existing end-to-end benchmarks with intermediate gold-context metrics that unbox the issue-resolution process. These contexts offer valuable intermediate signals for guiding LLM reasoning in software tasks. Data and code are available at: https://cioutn.github.io/context-bench/.", "AI": {"tldr": "This paper introduces ContextBench for evaluating coding agents' retrieval and use of code context during issue resolution, emphasizing process-oriented evaluation rather than just final task success.", "motivation": "The motivation is to address the gap in understanding how coding agents retrieve and use code context for solving programming issues, as existing evaluations often focus only on task outcomes.", "method": "The authors created ContextBench, a benchmark of 1,136 tasks with human-annotated contexts, and designed an automated evaluation framework to measure context recall, precision, and efficiency during issue resolution.", "result": "Using ContextBench, sophisticated agent designs showed limited improvement in context retrieval. LLMs prioritized recall over precision, and discrepancies were observed between retrieved and used contexts.", "conclusion": "ContextBench enriches evaluations of coding agents by providing intermediate metrics for context handling, aiding in improving LLM reasoning for software engineering tasks."}}
{"id": "2602.05896", "pdf": "https://arxiv.org/pdf/2602.05896", "abs": "https://arxiv.org/abs/2602.05896", "authors": ["Alexander Kozachinskiy", "Tomasz Steifer", "Przemys\u0142aw Wa\u0142\u0229ga"], "title": "Parity, Sensitivity, and Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages", "summary": "The transformer architecture is almost a decade old. Despite that, we still have a limited understanding of what this architecture can or cannot compute. For instance, can a 1-layer transformer solve PARITY -- or more generally -- which kinds of transformers can do it? Known constructions for PARITY have at least 2 layers and employ impractical features: either a length-dependent positional encoding, or hardmax, or layernorm without the regularization parameter, or they are not implementable with causal masking.\n  We give a new construction of a transformer for PARITY with softmax, length-independent and polynomially bounded positional encoding, no layernorm, working both with and without causal masking. We also give the first lower bound for transformers solving PARITY -- by showing that it cannot be done with only one layer and one head.", "AI": {"tldr": "This paper explores whether a one-layer transformer can compute PARITY, introducing improved constructions and providing new lower bounds.", "motivation": "To understand the computational limits of transformer architectures and address practical challenges in solving PARITY using transformers.", "method": "New transformer constructions for PARITY are presented, featuring softmax, length-independent positional encoding, and compatibility with causal masking.", "result": "The paper demonstrates that PARITY cannot be computed with one-layer, one-head transformers and provides practical transformer designs for computing PARITY.", "conclusion": "The study advances understanding of transformer capabilities, both revealing limitations and proposing feasible constructions for specific computational tasks."}}
{"id": "2602.05902", "pdf": "https://arxiv.org/pdf/2602.05902", "abs": "https://arxiv.org/abs/2602.05902", "authors": ["Seohyeon Cha", "Huancheng Chen", "Dongjun Kim", "Haoran Zhang", "Kevin Chan", "Gustavo de Veciana", "Haris Vikalo"], "title": "Regularized Calibration with Successive Rounding for Post-Training Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) deliver robust performance across diverse applications, yet their deployment often faces challenges due to the memory and latency costs of storing and accessing billions of parameters. Post-training quantization (PTQ) enables efficient inference by mapping pretrained weights to low-bit formats without retraining, but its effectiveness depends critically on both the quantization objective and the rounding procedure used to obtain low-bit weight representations. In this work, we show that interpolating between symmetric and asymmetric calibration acts as a form of regularization that preserves the standard quadratic structure used in PTQ while providing robustness to activation mismatch. Building on this perspective, we derive a simple successive rounding procedure that naturally incorporates asymmetric calibration, as well as a bounded-search extension that allows for an explicit trade-off between quantization quality and the compute cost. Experiments across multiple LLM families, quantization bit-widths, and benchmarks demonstrate that the proposed bounded search based on a regularized asymmetric calibration objective consistently improves perplexity and accuracy over PTQ baselines, while incurring only modest and controllable additional computational cost.", "AI": {"tldr": "This paper proposes an enhanced post-training quantization (PTQ) method for large language models (LLMs), integrating asymmetric calibration and a novel bounded search procedure to improve efficiency and performance.", "motivation": "LLMs are highly capable but require significant memory and computational resources for deployment. Post-training quantization is a promising approach to mitigate these issues, but its effectiveness depends on better quantization strategies to improve model performance while reducing resource costs.", "method": "The authors introduce a regularization technique that interpolates between symmetric and asymmetric calibration, coupled with a successive rounding procedure. They also propose a bounded-search extension to explicitly balance quantization quality and computational cost.", "result": "Empirical evaluations across different LLM families and quantization levels reveal that the proposed method consistently enhances perplexity and accuracy compared to baseline PTQ methods, with only slight increases in computational demands.", "conclusion": "The proposed strategy effectively improves the trade-off between efficiency and model performance, making PTQ a more practical solution for deploying LLMs with limited resource consumption."}}
{"id": "2602.05903", "pdf": "https://arxiv.org/pdf/2602.05903", "abs": "https://arxiv.org/abs/2602.05903", "authors": ["Andr\u00e1s Balogh", "M\u00e1rk Jelasity"], "title": "Verification of the Implicit World Model in a Generative Model via Adversarial Sequences", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026. Code, datasets, and models are available at https://github.com/szegedai/world-model-verification", "summary": "Generative sequence models are typically trained on sample sequences from natural or formal languages. It is a crucial question whether -- or to what extent -- sample-based training is able to capture the true structure of these languages, often referred to as the ``world model''. Theoretical results indicate that we can hope for soundness at best, that is, generating valid sequences, but not necessarily all of them. However, it is still important to have practical tools that are able to verify whether a given sequence model is sound. In this study, we focus on chess, as it is a domain that provides enough complexity while having a simple rule-based world model. We propose adversarial sequence generation for verifying the soundness of the sequence model. Our adversaries generate valid sequences so as to force the sequence model to generate an invalid next move prediction. Apart from the falsification of soundness, this method is also suitable for a more fine-grained analysis of the failure modes and the effects of different choices during training. To demonstrate this, we propose a number of methods for adversarial sequence generation and evaluate the approach on a large set of chess models. We train models on random as well as high-quality chess games, using several training recipes. We find that none of the models are sound, but some training techniques and dataset choices are able to improve soundness remarkably. We also investigate the potential application of board state probes in both our training and attack methods. Our findings indicate that the extracted board states have no causal role in next token prediction in most of the models.", "AI": {"tldr": "This paper explores the soundness of generative sequence models by studying chess, using adversarial sequence generation to identify failure modes and proposing evaluation techniques. None of the models tested were entirely sound, although training and dataset choice improved results.", "motivation": "To understand whether and how generative sequence models can accurately and soundly capture the structure of complex rule-based domains, in this case using chess as a study context.", "method": "The researchers developed adversarial sequence generation to stress-test models' ability to generate valid chess moves, analyzed failure modes, contrasted training strategies, and included board state probing in the analysis.", "result": "Adversarial attacks revealed that none of the models were entirely sound. However, better training methodologies and improved datasets enhanced performance, although board state probing showed limited causal impact in move prediction.", "conclusion": "Current generative sequence models face challenges in achieving soundness, but training strategies and dataset quality can lead to significant improvements. Adversarial testing is a valuable tool for identifying weaknesses in such models."}}
{"id": "2602.05406", "pdf": "https://arxiv.org/pdf/2602.05406", "abs": "https://arxiv.org/abs/2602.05406", "authors": ["Isaac Wiafe", "Akon Obu Ekpezu", "Sumaya Ahmed Salihs", "Elikem Doe Atsakpo", "Fiifi Baffoe Payin Winful", "Jamal-Deen Abdulai"], "title": "Enabling Automatic Disordered Speech Recognition: An Impaired Speech Dataset in the Akan Language", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "The lack of impaired speech data hinders advancements in the development of inclusive speech technologies, particularly in low-resource languages such as Akan. To address this gap, this study presents a curated corpus of speech samples from native Akan speakers with speech impairment. The dataset comprises of 50.01 hours of audio recordings cutting across four classes of impaired speech namely stammering, cerebral palsy, cleft palate, and stroke induced speech disorder. Recordings were done in controlled supervised environments were participants described pre-selected images in their own words. The resulting dataset is a collection of audio recordings, transcriptions, and associated metadata on speaker demographics, class of impairment, recording environment and device. The dataset is intended to support research in low-resource automatic disordered speech recognition systems and assistive speech technology.", "AI": {"tldr": "The study creates a 50-hour dataset of impaired speech in the Akan language to aid speech technology research.", "motivation": "There is limited data on impaired speech for low-resource languages like Akan, which hampers the development of inclusive speech technologies.", "method": "The study collected speech samples from Akan speakers with four types of impairments under controlled settings, along with transcriptions and metadata.", "result": "The dataset features 50.01 hours of recordings, categorized by impairment types, demographics, and environments for developing automatic recognition and assistive technologies.", "conclusion": "This new corpus enables progress in disordered speech recognition and assistive tech for Akan and similar low-resource languages."}}
{"id": "2602.05910", "pdf": "https://arxiv.org/pdf/2602.05910", "abs": "https://arxiv.org/abs/2602.05910", "authors": ["Seoirse Murray", "Allison Qi", "Timothy Qian", "John Schulman", "Collin Burns", "Sara Price"], "title": "Chunky Post-Training: Data Driven Failures of Generalization", "categories": ["cs.LG"], "comment": null, "summary": "LLM post-training involves many diverse datasets, each targeting a specific behavior. But these datasets encode incidental patterns alongside intended ones: correlations between formatting and content, narrow phrasings across diverse problems, and implicit associations arising from the discrete data curation process. These patterns are often invisible to developers yet salient to models, producing behaviors that surprise their creators, such as rejecting true facts presented in a particular question format. We call this chunky post-training: the model learns spurious correlations as a result of distinct chunks of post-training data. We introduce SURF, a black-box pipeline which surfaces these unintended behaviors at run time, and TURF, a tool that traces these failures back to specific post-training data. Applying these tools to frontier models (Claude 4.5, GPT-5.1, Grok 4.1, Gemini 3) and open models (T\u00fclu 3), we show that chunky post-training produces miscalibrated behaviors, which often result from imbalanced or underspecified chunks of post-training data.", "AI": {"tldr": "Post-training datasets for LLMs introduce unintended patterns affecting model behavior. SURF and TURF tools identify and attribute these issues to specific data chunks.", "motivation": "To address the hidden spurious correlations in LLM post-training datasets that cause unexpected model behaviors.", "method": "Introduced SURF as a black-box runtime analysis pipeline and TURF as a tracing tool for linking failures back to specific post-training data.", "result": "Applied tools on top-performing and open models, revealing miscalibrated behaviors stemming from imbalanced or underspecified post-training data.", "conclusion": "Chunky post-training affects model calibration, and using SURF and TURF can help uncover and address unintended behaviors."}}
{"id": "2602.05416", "pdf": "https://arxiv.org/pdf/2602.05416", "abs": "https://arxiv.org/abs/2602.05416", "authors": ["Freja H\u00f8gholm Petersen", "Jesper Sandvig Mariegaard", "Rocco Palmitessa", "Allan P. Engsig-Karup"], "title": "Reduced-Order Surrogates for Forced Flexible Mesh Coastal-Ocean Models", "categories": ["cs.CE", "cs.AI", "cs.LG", "physics.ao-ph", "physics.flu-dyn"], "comment": "Submitted for peer-review in a journal", "summary": "While POD-based surrogates are widely explored for hydrodynamic applications, the use of Koopman Autoencoders for real-world coastal-ocean modelling remains relatively limited. This paper introduces a flexible Koopman autoencoder formulation that incorporates meteorological forcings and boundary conditions, and systematically compares its performance against POD-based surrogates. The Koopman autoencoder employs a learned linear temporal operator in latent space, enabling eigenvalue regularization to promote temporal stability. This strategy is evaluated alongside temporal unrolling techniques for achieving stable and accurate long-term predictions. The models are assessed on three test cases spanning distinct dynamical regimes, with prediction horizons up to one year at 30-minute temporal resolution. Across all cases, the Koopman autoencoder with temporal unrolling yields the best overall accuracy compared to the POD-based surrogates, achieving relative root-mean-squared-errors of 0.01-0.13 and $R^2$-values of 0.65-0.996. Prediction errors are largest for current velocities, and smallest for water surface elevations. Comparing to in-situ observations, the surrogate yields -0.65% to 12% change in water surface elevation prediction error when compared to prediction errors of the physics-based model. These error levels, corresponding to a few centimeters, are acceptable for many practical applications, while inference speed-ups of 300-1400x enables workflows such as ensemble forecasting and long climate simulations for coastal-ocean modelling.", "AI": {"tldr": "The paper presents the use of Koopman autoencoders to model coastal-ocean dynamics with improved accuracy compared to POD-based surrogates, achieving faster predictions and enabling practical applications.", "motivation": "To explore better modeling techniques for coastal-ocean dynamics that improve upon the limitations of POD-based surrogates, with a focus on accuracy and practical application speed.", "method": "The paper employs a Koopman autoencoder with a learned linear temporal operator in latent space, incorporating meteorological forcings and boundary conditions. It compares this against POD-based surrogates across three distinct test cases.", "result": "The Koopman autoencoder achieves significantly better accuracy, with relative root-mean-squared-errors of 0.01-0.13 and $R^2$ values of 0.65-0.996, while maintaining acceptable error levels for practical coastal applications. It speeds up inference by 300-1400x.", "conclusion": "Koopman autoencoders outperform POD-based surrogates in accuracy and computation speed, making them highly suitable for ensemble forecasting and long-term coastal-ocean simulations over challenging prediction horizons."}}
{"id": "2602.05933", "pdf": "https://arxiv.org/pdf/2602.05933", "abs": "https://arxiv.org/abs/2602.05933", "authors": ["Zhenghao Xu", "Qin Lu", "Changlong Yu", "Tuo Zhao"], "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training", "categories": ["cs.LG"], "comment": null, "summary": "Policy mirror descent (PMD) provides a principled framework for reinforcement learning (RL) by iteratively solving KL-regularized policy improvement subproblems. While this approach has been adopted in training advanced LLMs such as Kimi K1.5/K2, the ideal closed-form PMD updates require reliable partition function estimation, a significant challenge when working with limited rollouts in the vast action spaces of LLMs. We investigate a practical algorithm, termed PMD-mean, that approximates the log-partition term with the mean reward under the sampling policy and performs regression in log-policy space. Specifically, we characterize the population solution of PMD-mean and demonstrate that it implicitly optimizes mirror descent subproblems with an adaptive mixed KL--$\u03c7^2$ regularizer. This additional $\u03c7^2$ regularization constrains large probability changes, producing more conservative updates when expected rewards are low and enhancing robustness against finite-sample estimation errors. Experiments on math reasoning tasks show that PMD-mean achieves superior performance with improved stability and time efficiency. These findings deepen our understanding of PMD-mean and illuminate pathways toward principled improvements in RL algorithms for LLMs. Code is available at https://github.com/horizon-rl/OpenKimi.", "AI": {"tldr": "This paper explores an efficient PMD-based RL algorithm, PMD-mean, which incorporates mean reward estimates for stability and robustness, yielding superior LLM performance in experiments.", "motivation": "The study addresses the challenge of reliable partition function estimation in PMD approaches, essential for RL in LLMs, and seeks to improve robustness and performance in reward-limited settings.", "method": "The proposed PMD-mean algorithm approximates the log-partition with mean rewards, applies log-policy regression, and includes adaptive mixed KL-$\u03c7^2$ regularization to achieve stability and conservative updates.", "result": "PMD-mean outperforms other methods in math reasoning tasks with better stability, robustness, and time efficiency, showcasing its practical advantages.", "conclusion": "PMD-mean enhances our understanding of PMD algorithms and provides a pathway to more robust and efficient RL methods for operating on LLMs' vast action spaces."}}
{"id": "2602.05935", "pdf": "https://arxiv.org/pdf/2602.05935", "abs": "https://arxiv.org/abs/2602.05935", "authors": ["Sudeepta Mondal", "Xinyi Mary Xie", "Ruxiao Duan", "Alex Wong", "Ganesh Sundaramoorthi"], "title": "Tuning Out-of-Distribution (OOD) Detectors Without Given OOD Data", "categories": ["cs.LG"], "comment": null, "summary": "Existing out-of-distribution (OOD) detectors are often tuned by a separate dataset deemed OOD with respect to the training distribution of a neural network (NN). OOD detectors process the activations of NN layers and score the output, where parameters of the detectors are determined by fitting to an in-distribution (training) set and the aforementioned dataset chosen adhocly. At detector training time, this adhoc dataset may not be available or difficult to obtain, and even when it's available, it may not be representative of actual OOD data, which is often ''unknown unknowns.\" Current benchmarks may specify some left-out set from test OOD sets. We show that there can be significant variance in performance of detectors based on the adhoc dataset chosen in current literature, and thus even if such a dataset can be collected, the performance of the detector may be highly dependent on the choice. In this paper, we introduce and formalize the often neglected problem of tuning OOD detectors without a given ``OOD'' dataset. To this end, we present strong baselines as an attempt to approach this problem. Furthermore, we propose a new generic approach to OOD detector tuning that does not require any extra data other than those used to train the NN. We show that our approach improves over baseline methods consistently across higher-parameter OOD detector families, while being comparable across lower-parameter families.", "AI": {"tldr": "The paper addresses the challenge of tuning out-of-distribution (OOD) detectors without relying on an external dataset and proposes a novel method using only training data.", "motivation": "Current OOD detectors rely on an adhoc separate dataset during their tuning process, which may be unavailable, unrepresentative, or overly dependent on choice, leading to significant variance in detector performance.", "method": "The authors formalize the problem of tuning OOD detectors without a specific OOD dataset and propose strong baselines along with a generic, novel tuning approach that uses only NN training data.", "result": "Their method consistently outperforms baseline approaches for high-parameter OOD detector families and shows comparable performance for lower-parameter detector families.", "conclusion": "The novel approach presented is effective in minimizing dependency on external datasets, leading to improved and consistent performance for OOD detectors."}}
{"id": "2602.05936", "pdf": "https://arxiv.org/pdf/2602.05936", "abs": "https://arxiv.org/abs/2602.05936", "authors": ["Alaa El Ichi", "Khalide Jbilou"], "title": "Dimensionality Reduction on Riemannian Manifolds in Data Analysis", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we investigate Riemannian geometry based dimensionality reduction methods that respect the underlying manifold structure of the data. In particular, we focus on Principal Geodesic Analysis (PGA) as a nonlinear generalization of PCA for manifold valued data, and extend discriminant analysis through Riemannian adaptations of other known dimensionality reduction methods. These approaches exploit geodesic distances, tangent space representations, and intrinsic statistical measures to achieve more faithful low dimensional embeddings. We also discuss related manifold learning techniques and highlight their theoretical foundations and practical advantages. Experimental results on representative datasets demonstrate that Riemannian methods provide improved representation quality and classification performance compared to their Euclidean counterparts, especially for data constrained to curved spaces such as hyperspheres and symmetric positive definite manifolds. This study underscores the importance of geometry aware dimensionality reduction in modern machine learning and data science applications.", "AI": {"tldr": "The paper explores Riemannian geometry-based dimensionality reduction methods, emphasizing their effectiveness for manifold-structured data.", "motivation": "To improve representation quality and classification performance by leveraging the manifold structure inherent in certain datasets.", "method": "Principal Geodesic Analysis (PGA) and other Riemannian adaptations of known dimensionality reduction methods, utilizing geodesic distances, tangent spaces, and intrinsic measures.", "result": "Experimental results show Riemannian methods outperform Euclidean approaches in representation quality and classification, especially for hyperspheres and symmetric positive definite manifolds.", "conclusion": "Riemannian approaches are crucial for respecting geometric data structures, enhancing dimensionality reduction and machine learning applications."}}
{"id": "2602.05943", "pdf": "https://arxiv.org/pdf/2602.05943", "abs": "https://arxiv.org/abs/2602.05943", "authors": ["Sihan Yang", "Kexuan Shi", "Weiyang Liu"], "title": "Orthogonal Model Merging", "categories": ["cs.LG"], "comment": "Technical report (18 pages, 9 figures, project page: https://spherelab.ai/OrthoMerge/)", "summary": "Merging finetuned Large Language Models (LLMs) has become increasingly important for integrating diverse capabilities into a single unified model. However, prevailing model merging methods rely on linear arithmetic in Euclidean space, which often destroys the intrinsic geometric properties of pretrained weights, such as hyperspherical energy. To address this, we propose Orthogonal Model Merging (OrthoMerge), a method that performs merging operations on the Riemannian manifold formed by the orthogonal group to preserve the geometric structure of the model's weights. By mapping task-specific orthogonal matrices learned by Orthogonal Finetuning (OFT) to the Lie algebra, OrthoMerge enables a principled yet efficient integration that takes into account both the direction and intensity of adaptations. In addition to directly leveraging orthogonal matrices obtained by OFT, we further extend this approach to general models finetuned with non-OFT methods (i.e., low-rank finetuning, full finetuning) via an Orthogonal-Residual Decoupling strategy. This technique extracts the orthogonal components of expert models by solving the orthogonal Procrustes problem, which are then merged on the manifold of the orthogonal group, while the remaining linear residuals are processed through standard additive merging. Extensive empirical results demonstrate the effectiveness of OrthoMerge in mitigating catastrophic forgetting and maintaining model performance across diverse tasks.", "AI": {"tldr": "The paper introduces Orthogonal Model Merging (OrthoMerge) to merge finetuned Large Language Models while preserving geometric properties by operating on a Riemannian manifold.", "motivation": "To overcome limitations of existing model merging methods that destroy the intrinsic geometric structures of pretrained weights.", "method": "The method involves using orthogonal matrices and the orthogonal Procrustes problem to process finetuned models on the orthogonal group manifold, ensuring both geometric preservation and efficient integration.", "result": "Empirical studies show OrthoMerge effectively mitigates catastrophic forgetting and maintains robust performance across varied tasks.", "conclusion": "OrthoMerge is proposed as a novel and effective solution for preserving model weight properties while merging Large Language Models, showcasing better task performance retention and adaptability."}}
{"id": "2602.05950", "pdf": "https://arxiv.org/pdf/2602.05950", "abs": "https://arxiv.org/abs/2602.05950", "authors": ["Mouad Talhi", "Arne Wolf", "Anthea Monod"], "title": "Breaking Symmetry Bottlenecks in GNN Readouts", "categories": ["cs.LG"], "comment": "23 pages", "summary": "Graph neural networks (GNNs) are widely used for learning on structured data, yet their ability to distinguish non-isomorphic graphs is fundamentally limited. These limitations are usually attributed to message passing; in this work we show that an independent bottleneck arises at the readout stage. Using finite-dimensional representation theory, we prove that all linear permutation-invariant readouts, including sum and mean pooling, factor through the Reynolds (group-averaging) operator and therefore project node embeddings onto the fixed subspace of the permutation action, erasing all non-trivial symmetry-aware components regardless of encoder expressivity. This yields both a new expressivity barrier and an interpretable characterization of what global pooling preserves or destroys. To overcome this collapse, we introduce projector-based invariant readouts that decompose node representations into symmetry-aware channels and summarize them with nonlinear invariant statistics, preserving permutation invariance while retaining information provably invisible to averaging. Empirically, swapping only the readout enables fixed encoders to separate WL-hard graph pairs and improves performance across multiple benchmarks, demonstrating that readout design is a decisive and under-appreciated factor in GNN expressivity.", "AI": {"tldr": "Graph neural networks (GNNs) face limitations in differentiating non-isomorphic graphs due to readout stage bottlenecks. This paper proposes an innovative readout design leveraging projector-based invariant methods to enhance GNN expressivity.", "motivation": "The motivation is to address fundamental limitations in GNNs, particularly their inability to distinguish non-isomorphic graphs effectively due to issues in the readout stage.", "method": "The method involves the introduction of projector-based invariant readouts, which decompose node representations into symmetry-aware channels and use nonlinear invariant statistics to retain meaningful graph information.", "result": "The proposed readout design enables GNNs to distinguish WL-hard graph pairs, enhances encoder performance, and improves results across multiple benchmarks.", "conclusion": "Readout design plays a decisive role in improving GNN expressivity, and adopting projector-based invariant methods overcomes significant barriers stemming from traditional readouts."}}
{"id": "2602.05967", "pdf": "https://arxiv.org/pdf/2602.05967", "abs": "https://arxiv.org/abs/2602.05967", "authors": ["Mohamad Amin Jamshidi", "Mehrbod Zarifi", "Zolfa Anvari", "Hamed Ghafarirad", "Mohammad Zareinejad"], "title": "A Hybrid Data-Driven Algorithm for Real-Time Friction Force Estimation in Hydraulic Cylinders", "categories": ["cs.LG", "eess.SY"], "comment": "Published in: 2025 33rd International Conference on Electrical Engineering (ICEE), Publisher IEEE", "summary": "Hydraulic systems are widely utilized in industrial applications due to their high force generation, precise control, and ability to function in harsh environments. Hydraulic cylinders, as actuators in these systems, apply force and position through the displacement of hydraulic fluid, but their operation is significantly influenced by friction force. Achieving precision in hydraulic cylinders requires an accurate friction model under various operating conditions. Existing analytical models, often derived from experimental tests, necessitate the identification or estimation of influencing factors but are limited in adaptability and computational efficiency. This research introduces a data-driven, hybrid algorithm based on Long Short-Term Memory (LSTM) networks and Random Forests for nonlinear friction force estimation. The algorithm effectively combines feature detection and estimation processes using training data acquired from an experimental hydraulic test setup. It achieves a consistent and stable model error of less than 10% across diverse operating conditions and external load variations, ensuring robust performance in complex situations. The computational cost of the algorithm is 1.51 milliseconds per estimation, making it suitable for real-time applications. The proposed method addresses the limitations of analytical models by delivering high precision and computational efficiency. The algorithm's performance is validated through detailed analysis and experimental results, including direct comparisons with the LuGre model. The comparison highlights that while the LuGre model offers a theoretical foundation for friction modeling, its performance is limited by its inability to dynamically adjust to varying operational conditions of the hydraulic cylinder, further emphasizing the advantages of the proposed hybrid approach in real-time applications.", "AI": {"tldr": "This paper proposes a data-driven hybrid algorithm using LSTM networks and Random Forests for friction force estimation in hydraulic systems, achieving less than 10% model error and real-time computational efficiency.", "motivation": "Hydraulic systems require precise friction modeling due to the significant impact of friction on their performance, but existing models lack adaptability and computational efficiency.", "method": "A hybrid data-driven algorithm combining Long Short-Term Memory (LSTM) networks and Random Forests is developed, utilizing experimental training data to estimate nonlinear friction forces.", "result": "The algorithm demonstrates a consistent model error below 10%, robust performance across varied conditions, and fast computational costs (1.51 milliseconds per estimation).", "conclusion": "The proposed method improves over analytical models like the LuGre model by adapting dynamically to varying operational conditions, offering accurate and efficient real-time friction estimation."}}
{"id": "2602.05474", "pdf": "https://arxiv.org/pdf/2602.05474", "abs": "https://arxiv.org/abs/2602.05474", "authors": ["Yicheng Di", "Zhanjie Zhang", "Yun Wangc", "Jinren Liue", "Jiaqi Yanf", "Jiyu Wei", "Xiangyu Chend", "Yuan Liu"], "title": "LMMRec: LLM-driven Motivation-aware Multimodal Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\\% performance improvement.", "AI": {"tldr": "The paper introduces LMMRec, a large language model-powered framework for multimodal recommendation systems that addresses alignment and noise challenges, achieving up to 4.98% improvement in performance.", "motivation": "Improving recommendation systems by accurately modeling user motivations and behavior across heterogeneous data modalities like text reviews and interactions.", "method": "LMMRec framework employs chain-of-thought prompting with large language models, a dual-encoder architecture for cross-modal alignment, and strategies to mitigate noise and semantic drift via contrastive learning and momentum updates.", "result": "Experiments reveal LMMRec effectively improves recommendation performance, with a notable increase of up to 4.98% across three datasets.", "conclusion": "LMMRec demonstrates that leveraging large language models for multimodal motivation modeling significantly enhances recommendation systems, addressing critical challenges in cross-modal alignment and noise handling."}}
{"id": "2602.05977", "pdf": "https://arxiv.org/pdf/2602.05977", "abs": "https://arxiv.org/abs/2602.05977", "authors": ["Matthias Wolff", "Francesco Alesiani", "Christof Duhme", "Xiaoyi Jiang"], "title": "Clifford Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. Our ClKAN also introduces new batch normalization strategies to deal with variable domain input. ClKAN finds application in scientific discovery and engineering, and is validated in synthetic and physics inspired tasks.", "AI": {"tldr": "ClKAN is a novel architecture for function approximation in Clifford algebra spaces, utilizing clever strategies to manage higher dimensional algebras.", "motivation": "To develop an efficient and flexible architecture for better function approximation in Clifford algebra spaces, tackling the challenges posed by exponential scaling in higher dimensions.", "method": "The approach includes Randomized Quasi Monte Carlo grid generation for dimensional scaling and new batch normalization strategies for variable domain input.", "result": "ClKAN is validated through synthetic and physics-inspired tasks, showing its applicability in scientific discovery and engineering.", "conclusion": "ClKAN demonstrates its potential as an effective tool in complex Clifford algebra spaces and can aid various applications in science and engineering."}}
{"id": "2602.05988", "pdf": "https://arxiv.org/pdf/2602.05988", "abs": "https://arxiv.org/abs/2602.05988", "authors": ["Keith Ando Ogawa", "Bruno Lopes Yamamoto", "Lucas Lauton de Alcantara", "Lucas Pellicer", "Rosimeire Pereira Costa", "Edson Bollis", "Anna Helena Reali Costa", "Artur Jordao"], "title": "Layer-wise LoRA fine-tuning: a similarity metric approach", "categories": ["cs.LG"], "comment": "Code is available at https://github.com/c2d-usp/Layer-wise-LoRA-with-CKA", "summary": "Pre-training Large Language Models (LLMs) on web-scale datasets becomes fundamental for advancing general-purpose AI. In contrast, enhancing their predictive performance on downstream tasks typically involves adapting their knowledge through fine-tuning. Parameter-efficient fine-tuning techniques, such as Low-Rank Adaptation (LoRA), aim to reduce the computational cost of this process by freezing the pre-trained model and updating a smaller number of parameters. In comparison to full fine-tuning, these methods achieve over 99\\% reduction in trainable parameter count, depending on the configuration. Unfortunately, such a reduction may prove insufficient as LLMs continue to grow in scale. In this work, we address the previous problem by systematically selecting only a few layers to fine-tune using LoRA or its variants. We argue that not all layers contribute equally to the model adaptation. Leveraging this, we identify the most relevant layers to fine-tune by measuring their contribution to changes in internal representations. Our method is orthogonal to and readily compatible with existing low-rank adaptation techniques. We reduce the trainable parameters in LoRA-based techniques by up to 50\\%, while maintaining the predictive performance across different models and tasks. Specifically, on encoder-only architectures, this reduction in trainable parameters leads to a negligible predictive performance drop on the GLUE benchmark. On decoder-only architectures, we achieve a small drop or even improvements in the predictive performance on mathematical problem-solving capabilities and coding tasks. Finally, this effectiveness extends to multimodal models, for which we also observe competitive results relative to fine-tuning with LoRA modules in all layers. Code is available at: https://github.com/c2d-usp/Layer-wise-LoRA-with-CKA", "AI": {"tldr": "The paper introduces a method to strategically select layers for fine-tuning in large language models using LoRA techniques, reducing trainable parameters up to 50% while maintaining or improving predictive performance.", "motivation": "The aim is to address computational inefficiencies in fine-tuning large language models, as their increasing scale makes fine-tuning methods like LoRA insufficiently effective despite their parameter-saving advantages.", "method": "The authors selectively fine-tune layers in LLMs by measuring their impact on internal representations (using techniques like CKA), ensuring that only the most relevant layers are updated.", "result": "Their method reduces trainable parameters by up to 50% compared to standard LoRA techniques while maintaining predictive performance on many tasks. Encoder-only models showed negligible performance drops and some improvements observed in decoder-only architectures, including mathematical and coding tasks.", "conclusion": "The proposed layer-wise approach improves the computational efficiency of LoRA techniques in fine-tuning large language models without significant loss in task performance, offering compatibility with various architectures and tasks."}}
{"id": "2602.05993", "pdf": "https://arxiv.org/pdf/2602.05993", "abs": "https://arxiv.org/abs/2602.05993", "authors": ["Peter Holderrieth", "Douglas Chen", "Luca Eyring", "Ishin Shah", "Giri Anantharaman", "Yutong He", "Zeynep Akata", "Tommi Jaakkola", "Nicholas Matthew Boffi", "Max Simchowitz"], "title": "Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Flow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, not an afterthought, and redesign the model for adaptability. We propose \"Diamond Maps\", stochastic flow map models that enable efficient and accurate alignment to arbitrary rewards at inference time. Diamond Maps amortize many simulation steps into a single-step sampler, like flow maps, while preserving the stochasticity required for optimal reward alignment. This design makes search, sequential Monte Carlo, and guidance scalable by enabling efficient and consistent estimation of the value function. Our experiments show that Diamond Maps can be learned efficiently via distillation from GLASS Flows, achieve stronger reward alignment performance, and scale better than existing methods. Our results point toward a practical route to generative models that can be rapidly adapted to arbitrary preferences and constraints at inference time.", "AI": {"tldr": "Diamond Maps are proposed as stochastic flow map models to address reward alignment issues in generative models, enabling efficient adaptation at inference time.", "motivation": "Existing flow and diffusion models face challenges in reward alignment, as adapting them post-training is costly and unreliable. This paper aims to make generative models inherently adaptable to user preferences.", "method": "Diamond Maps provide a single-step sampler while preserving stochasticity, facilitating scalable methods like search and Monte Carlo estimation. These are efficiently learned via distillation from GLASS Flows.", "result": "Experimental results demonstrate Diamond Maps outperform traditional models in reward alignment and scalability, showing their efficiency in adapting to arbitrary preferences and constraints.", "conclusion": "Diamond Maps suggest a promising approach to designing generative models that are effortlessly adaptable to varied preferences during inference."}}
{"id": "2602.05999", "pdf": "https://arxiv.org/pdf/2602.05999", "abs": "https://arxiv.org/abs/2602.05999", "authors": ["Raj Ghugare", "Micha\u0142 Bortkiewicz", "Alicja Ziarko", "Benjamin Eysenbach"], "title": "On Computation and Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "How does the amount of compute available to a reinforcement learning (RL) policy affect its learning? Can policies using a fixed amount of parameters, still benefit from additional compute? The standard RL framework does not provide a language to answer these questions formally. Empirically, deep RL policies are often parameterized as neural networks with static architectures, conflating the amount of compute and the number of parameters. In this paper, we formalize compute bounded policies and prove that policies which use more compute can solve problems and generalize to longer-horizon tasks that are outside the scope of policies with less compute. Building on prior work in algorithmic learning and model-free planning, we propose a minimal architecture that can use a variable amount of compute. Our experiments complement our theory. On a set 31 different tasks spanning online and offline RL, we show that $(1)$ this architecture achieves stronger performance simply by using more compute, and $(2)$ stronger generalization on longer-horizon test tasks compared to standard feedforward networks or deep residual network using up to 5 times more parameters.", "AI": {"tldr": "This paper investigates the impact of compute availability on reinforcement learning policies, proposing a variable compute architecture that improves task performance and generalization in RL.", "motivation": "Understand how compute availability affects learning in reinforcement learning policies, and determine if fixed-size neural networks can benefit from increased compute.", "method": "Formalized compute bounded policies, derived proofs, proposed a minimal architecture for variable compute usage, and conducted experiments across 31 RL tasks.", "result": "Policies using more compute solved problems, generalized better to longer-horizon tasks, and outperformed other architectures despite having fewer parameters.", "conclusion": "Compute availability enhances RL policy performance and generalization, demonstrating that policies can benefit significantly from increased computational resources."}}
{"id": "2602.06020", "pdf": "https://arxiv.org/pdf/2602.06020", "abs": "https://arxiv.org/abs/2602.06020", "authors": ["Kevin Lu", "Jannik Brinkmann", "Stefan Huber", "Aaron Mueller", "Yonatan Belinkov", "David Bau", "Chris Wendler"], "title": "Mechanisms of AI Protein Folding in ESMFold", "categories": ["cs.LG", "q-bio.BM"], "comment": "Our code, data, and results are available at https://folding.baulab.info", "summary": "How do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, a prevalent structural motif. Through counterfactual interventions on model latents, we identify two computational stages in the folding trunk. In the first stage, early blocks initialize pairwise biochemical signals: residue identities and associated biochemical features such as charge flow from sequence representations into pairwise representations. In the second stage, late blocks develop pairwise spatial features: distance and contact information accumulate in the pairwise representation. We demonstrate that the mechanisms underlying structural decisions of ESMFold can be localized, traced through interpretable representations, and manipulated with strong causal effects.", "AI": {"tldr": "This paper investigates the mechanisms behind protein structure prediction using ESMFold, identifying distinct computational stages in the folding process.", "motivation": "To understand the computational processes that allow ESMFold to accurately predict protein structures, focusing on how specific features contribute to its decision-making.", "method": "Counterfactual interventions were applied to latent representations in ESMFold, separating early and late-stage computational processes and analyzing their contributions to folding predictions.", "result": "The study revealed two distinct folding stages in ESMFold: early stages for initializing biochemical signals and late stages for developing spatial features.", "conclusion": "Protein folding in ESMFold can be localized to specific computational stages, which are interpretable and can be manipulated, demonstrating a strong causal relationship in folding mechanisms."}}
{"id": "2602.06022", "pdf": "https://arxiv.org/pdf/2602.06022", "abs": "https://arxiv.org/abs/2602.06022", "authors": ["Miranda Muqing Miao", "Young-Min Cho", "Lyle Ungar"], "title": "Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference-time steering offers a lightweight alternative, yet most existing methods optimize proxies for correctness rather than correctness itself. We introduce CORAL (Correctness-Optimized Residual Activation Lens), a regularized inference-time steering method that captures distributed correctness signals from model internal activations using weight-decay MLP probes. We evaluate CORAL across three 7B-parameter models and find that it consistently improves accuracy by 10\\% and expected calibration error (ECE) by 50\\% on average. We additionally demonstrate that these gains transfer without retraining to the complete published test sets of four held-out benchmarks (ARC-Challenge, HellaSwag, Math-MC, OpenBookQA), averaging 14\\% accuracy improvements and 49\\% ECE improvements. Our results support the hypothesis that distributed information in model internals can be extracted using regularized probes when individual neurons are insufficient. CORAL thus provides a compute-efficient, transferable, and calibration-aware approach to improve MCQA performance during inference.", "AI": {"tldr": "CORAL introduces a compute-efficient method to improve calibration and accuracy in LLMs during inference without costly retraining.", "motivation": "Persistent miscalibration in LLMs, especially post-instruction tuning, limits their reliability. Efficient methods are needed to address this issue without requiring retraining.", "method": "CORAL uses regularized inference-time steering via weight-decay MLP probes to extract correctness signals from model internal activations.", "result": "CORAL improves accuracy by 10% and reduces expected calibration error (ECE) by 50% on average across three models. Gains also transfer effectively to held-out benchmarks, showing 14% accuracy improvements and 49% ECE improvements.", "conclusion": "The method demonstrates that correctness information distributed in model internals can be utilized via regularized probes, offering a transferable and computation-efficient calibration-aware solution for MCQA during inference."}}
{"id": "2602.05524", "pdf": "https://arxiv.org/pdf/2602.05524", "abs": "https://arxiv.org/abs/2602.05524", "authors": ["Konosuke Yoshizato", "Kazuma Shimizu", "Ryota Higa", "Takanobu Otsuka"], "title": "AI Agent Systems for Supply Chains: Structured Decision Prompts and Memory Retrieval", "categories": ["cs.MA", "cs.AI"], "comment": "A full version of the extended abstract accepted by the 25th International Conference on Autonomous Agents and Multiagent Systems(AAMAS 2026)", "summary": "This study investigates large language model (LLM) -based multi-agent systems (MASs) as a promising approach to inventory management, which is a key component of supply chain management. Although these systems have gained considerable attention for their potential to address the challenges associated with typical inventory management methods, key uncertainties regarding their effectiveness persist. Specifically, it is unclear whether LLM-based MASs can consistently derive optimal ordering policies and adapt to diverse supply chain scenarios. To address these questions, we examine an LLM-based MAS with a fixed-ordering strategy prompt that encodes the stepwise processes of the problem setting and a safe-stock strategy commonly used in inventory management. Our empirical results demonstrate that, even without detailed prompt adjustments, an LLM-based MAS can determine optimal ordering decisions in a restricted scenario. To enhance adaptability, we propose a novel agent called AIM-RM, which leverages similar historical experiences through similarity matching. Our results show that AIM-RM outperforms benchmark methods across various supply chain scenarios, highlighting its robustness and adaptability.", "AI": {"tldr": "This paper explores the use of large language model-based multi-agent systems (LLM-MASs) for inventory management. The presented methodology demonstrates optimal ordering in fixed scenarios and introduces AIM-RM for broader adaptability.", "motivation": "The study aims to address uncertainties in the effectiveness of LLM-based MASs for improving inventory management and adapting to diverse supply chain scenarios.", "method": "An LLM-based MAS is implemented using a fixed-order strategy prompt and safe-stock strategies. AIM-RM, a novel agent, uses similarity matching based on historical patterns for adaptability.", "result": "LLM-MAS shows effective ordering in constrained settings, while AIM-RM consistently adapts and outperforms benchmarks across a range of supply chain scenarios.", "conclusion": "LLM-MAS is a promising tool for inventory management and AIM-RM enhances adaptability and robustness in diverse supply chain contexts."}}
{"id": "2602.06029", "pdf": "https://arxiv.org/pdf/2602.06029", "abs": "https://arxiv.org/abs/2602.06029", "authors": ["Yingke Li", "Anjali Parashar", "Enlu Zhou", "Chuchu Fan"], "title": "Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference", "categories": ["cs.LG"], "comment": null, "summary": "Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.", "AI": {"tldr": "This paper establishes theoretical guarantees for active inference agents, balancing curiosity for effective learning and decision-making.", "motivation": "Active inference faces challenges in balancing exploration and exploitation. Excessive or insufficient curiosity can lead to suboptimal learning or decision-making.", "method": "The paper provides a theoretical analysis to guarantee sufficient curiosity for Bayesian posterior consistency and bounded cumulative regret.", "result": "A unified framework links active inference to Bayesian experimental design and optimization, offering practical guidelines validated in experiments.", "conclusion": "Ensuring well-tuned curiosity enables active inference agents to achieve coherent learning and efficient decision-making with practical applications."}}
{"id": "2602.06031", "pdf": "https://arxiv.org/pdf/2602.06031", "abs": "https://arxiv.org/abs/2602.06031", "authors": ["Claus Hofmann", "Christian Huber", "Bernhard Lehner", "Daniel Klotz", "Sepp Hochreiter", "Werner Zellinger"], "title": "AP-OOD: Attention Pooling for Out-of-Distribution Detection", "categories": ["cs.LG"], "comment": "Accepted at ICLR 2026", "summary": "Out-of-distribution (OOD) detection, which maps high-dimensional data into a scalar OOD score, is critical for the reliable deployment of machine learning models. A key challenge in recent research is how to effectively leverage and aggregate token embeddings from language models to obtain the OOD score. In this work, we propose AP-OOD, a novel OOD detection method for natural language that goes beyond simple average-based aggregation by exploiting token-level information. AP-OOD is a semi-supervised approach that flexibly interpolates between unsupervised and supervised settings, enabling the use of limited auxiliary outlier data. Empirically, AP-OOD sets a new state of the art in OOD detection for text: in the unsupervised setting, it reduces the FPR95 (false positive rate at 95% true positives) from 27.84% to 4.67% on XSUM summarization, and from 77.08% to 70.37% on WMT15 En-Fr translation.", "AI": {"tldr": "The paper introduces AP-OOD, a cutting-edge semi-supervised method for OOD detection in text data, achieving significant improvements compared to prior approaches.", "motivation": "The motivation is to overcome the limitations of current OOD detection methods which rely on simplistic aggregation techniques and fail to effectively utilize token-level embeddings in language models.", "method": "AP-OOD employs a semi-supervised method that exploits token-level information, flexibly interpolating between unsupervised and supervised OOD detection settings, and utilizes auxiliary outlier data for better accuracy.", "result": "AP-OOD significantly improves OOD detection for text by reducing false positive rates (FPR95). For instance, it achieves reductions from 27.84% to 4.67% on XSUM summarization, and from 77.08% to 70.37% on WMT15 En-Fr translation.", "conclusion": "The approach demonstrates state-of-the-art performance in OOD detection for text data, showcasing the potential of token-level aggregation and semi-supervised strategies for effective detection."}}
{"id": "2602.06033", "pdf": "https://arxiv.org/pdf/2602.06033", "abs": "https://arxiv.org/abs/2602.06033", "authors": ["Luca M. Schulze Buschoff", "Konstantinos Voudouris", "Can Demircan", "Eric Schulz"], "title": "Can vision language models learn intuitive physics from interaction?", "categories": ["cs.LG"], "comment": null, "summary": "Pre-trained vision language models do not have good intuitions about the physical world. Recent work has shown that supervised fine-tuning can improve model performance on simple physical tasks. However, fine-tuned models do not appear to learn robust physical rules that can generalize to new contexts. Based on research in cognitive science, we hypothesize that models need to interact with an environment to properly learn its physical dynamics. We train models that learn through interaction with the environment using reinforcement learning. While learning from interaction allows models to improve their within-task performance, it fails to produce models with generalizable physical intuitions. We find that models trained on one task do not reliably generalize to related tasks, even if the tasks share visual statistics and physical principles, and regardless of whether the models are trained through interaction.", "AI": {"tldr": "Pre-trained vision-language models struggle with physical intuition and fail to generalize robustly, even when trained through interaction using reinforcement learning.", "motivation": "Pre-trained vision-language models lack effective understanding of physical dynamics, and fine-tuning approaches have limitations in generalizing robust physical rules.", "method": "The paper explores training vision-language models through interaction with the environment using reinforcement learning to improve physical task performance.", "result": "Training through interaction improves task performance but fails to enable models to generalize physical intuitions across tasks.", "conclusion": "Models need more than interaction-based learning to acquire robust and generalizable physical understanding."}}
{"id": "2602.04901", "pdf": "https://arxiv.org/pdf/2602.04901", "abs": "https://arxiv.org/abs/2602.04901", "authors": ["Jiafa Ruan", "Ruijie Quan", "Zongxin Yang", "Liyang Xu", "Yi Yang"], "title": "Beyond Independent Genes: Learning Module-Inductive Representations for Gene Perturbation Prediction", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Predicting transcriptional responses to genetic perturbations is a central problem in functional genomics. In practice, perturbation responses are rarely gene-independent but instead manifest as coordinated, program-level transcriptional changes among functionally related genes. However, most existing methods do not explicitly model such coordination, due to gene-wise modeling paradigms and reliance on static biological priors that cannot capture dynamic program reorganization. To address these limitations, we propose scBIG, a module-inductive perturbation prediction framework that explicitly models coordinated gene programs. scBIG induces coherent gene programs from data via Gene-Relation Clustering, captures inter-program interactions through a Gene-Cluster-Aware Encoder, and preserves modular coordination using structure-aware alignment objectives. These structured representations are then modeled using conditional flow matching to enable flexible and generalizable perturbation prediction. Extensive experiments on multiple single-cell perturbation benchmarks show that scBIG consistently outperforms state-of-the-art methods, particularly on unseen and combinatorial perturbation settings, achieving an average improvement of 6.7% over the strongest baselines.", "AI": {"tldr": "The paper introduces scBIG, a framework for predicting transcriptional responses to genetic perturbations by modeling coordinated gene programs, and shows its superiority in single-cell perturbation benchmarks.", "motivation": "Current methods for predicting transcriptional responses fail to adequately model coordinated, program-level gene interactions and rely on static biological priors, limiting their ability to adapt to dynamic gene program reorganization.", "method": "scBIG uses Gene-Relation Clustering to identify coherent gene programs, a Gene-Cluster-Aware Encoder to capture interactions between these programs, and structure-aware objectives to retain modular coordination. It employs conditional flow matching for flexible and generalizable predictions.", "result": "In experiments involving single-cell perturbation benchmarks, scBIG demonstrated an average improvement of 6.7% over state-of-the-art methods, particularly excelling in unseen and combinatorial perturbation scenarios.", "conclusion": "scBIG effectively models coordinated gene programs, enabling more accurate and generalizable predictions of transcriptional responses to perturbations compared to existing methods."}}
{"id": "2602.04952", "pdf": "https://arxiv.org/pdf/2602.04952", "abs": "https://arxiv.org/abs/2602.04952", "authors": ["Senrui Chen", "Weiyuan Gong", "Sisi Zhou"], "title": "Instance-optimal high-precision shadow tomography with few-copy measurements: A metrological approach", "categories": ["quant-ph", "cs.IT", "cs.LG"], "comment": "67 pages", "summary": "We study the sample complexity of shadow tomography in the high-precision regime under realistic measurement constraints. Given an unknown $d$-dimensional quantum state $\u03c1$ and a known set of observables $\\{O_i\\}_{i=1}^m$, the goal is to estimate expectation values $\\{\\mathrm{tr}(O_i\u03c1)\\}_{i=1}^m$ to accuracy $\u03b5$ in $L_p$-norm, using possibly adaptive measurements that act on $O(\\mathrm{polylog}(d))$ number of copies of $\u03c1$ at a time. We focus on the regime where $\u03b5$ is below an instance-dependent threshold.\n  Our main contribution is an instance-optimal characterization of the sample complexity as $\\tilde\u0398(\u0393_p/\u03b5^2)$, where $\u0393_p$ is a function of $\\{O_i\\}_{i=1}^m$ defined via an optimization formula involving the inverse Fisher information matrix. Previously, tight bounds were known only in special cases, e.g. Pauli shadow tomography with $L_\\infty$-norm error. Concretely, we first analyze a simpler oblivious variant where the goal is to estimate an observable of the form $\\sum_{i=1}^m \u03b1_i O_i$ with $\\|\u03b1\\|_q = 1$ (where $q$ is dual to $p$) revealed after the measurement. For single-copy measurements, we obtain a sample complexity of $\u0398(\u0393^{\\mathrm{ob}}_p/\u03b5^2)$. We then show $\\tilde\u0398(\u0393_p/\u03b5^2)$ is necessary and sufficient for the original problem, with the lower bound applying to unbiased, bounded estimators. Our upper bounds rely on a two-step algorithm combining coarse tomography with local estimation. Notably, $\u0393^{\\mathrm{ob}}_\\infty = \u0393_\\infty$. In both cases, allowing $c$-copy measurements improves the sample complexity by at most $\u03a9(1/c)$.\n  Our results establish a quantitative correspondence between quantum learning and metrology, unifying asymptotic metrological limits with finite-sample learning guarantees.", "AI": {"tldr": "This paper investigates the sample complexity of shadow tomography for high-precision quantum measurements under realistic constraints and provides an instance-optimal characterization of performance.", "motivation": "The paper addresses the challenge of efficiently estimating quantum state expectation values in the high-precision regime, a critical task in quantum information and metrology.", "method": "The researchers use an analytical framework to characterize sample complexity via an optimization formula involving the inverse Fisher information matrix. They explore both single-copy and multi-copy measurements, combining coarse tomography and local estimation techniques.", "result": "The authors establish that the sample complexity can be expressed as \\(\u0398(\u0393_p/\u03b5^2)\\) with improved bounds for multi-copy measurements. They also show correspondence between quantum learning and metrology.", "conclusion": "The paper unifies quantum learning and metrology through rigorous sample complexity bounds, offering both theoretical insights and practical implications for high-precision quantum measurements."}}
{"id": "2602.05670", "pdf": "https://arxiv.org/pdf/2602.05670", "abs": "https://arxiv.org/abs/2602.05670", "authors": ["Qing Wen", "Haohao Li", "Zhongjie Ba", "Peng Cheng", "Miao He", "Li Lu", "Kui Ren"], "title": "HyperPotter: Spell the Charm of High-Order Interactions in Audio Deepfake Detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "20 pages, 8 figures", "summary": "Advances in AIGC technologies have enabled the synthesis of highly realistic audio deepfakes capable of deceiving human auditory perception. Although numerous audio deepfake detection (ADD) methods have been developed, most rely on local temporal/spectral features or pairwise relations, overlooking high-order interactions (HOIs). HOIs capture discriminative patterns that emerge from multiple feature components beyond their individual contributions. We propose HyperPotter, a hypergraph-based framework that explicitly models these synergistic HOIs through clustering-based hyperedges with class-aware prototype initialization. Extensive experiments demonstrate that HyperPotter surpasses its baseline by an average relative gain of 22.15% across 11 datasets and outperforms state-of-the-art methods by 13.96% on 4 challenging cross-domain datasets, demonstrating superior generalization to diverse attacks and speakers.", "AI": {"tldr": "HyperPotter is a hypergraph-based framework for detecting audio deepfakes, showing 22.15% improvement over baselines and 13.96% over state-of-the-art methods.", "motivation": "The motivation is to improve detection of audio deepfakes by leveraging high-order interactions that are often overlooked in traditional detection methods.", "method": "The method involves a hypergraph-based framework called HyperPotter, which models high-order interactions via clustering-based hyperedges and class-aware prototype initialization.", "result": "HyperPotter achieved significant performance gains, surpassing baselines by 22.15% on average and outperforming state-of-the-art methods by 13.96% on challenging cross-domain datasets.", "conclusion": "HyperPotter demonstrates superior generalization capabilities to detect audio deepfakes effectively, outperforming existing approaches and offering robustness against diverse types of attacks and speakers."}}
{"id": "2602.05687", "pdf": "https://arxiv.org/pdf/2602.05687", "abs": "https://arxiv.org/abs/2602.05687", "authors": ["Pavithren V S Pakianathan", "Rania Islambouli", "Diogo Branco", "Albrecht Schmidt", "Tiago Guerreiro", "Jan David Smeddinck"], "title": "Exploring AI-Augmented Sensemaking of Patient-Generated Health Data: A Mixed-Method Study with Healthcare Professionals in Cardiac Risk Reduction", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Individuals are increasingly generating substantial personal health and lifestyle data, e.g. through wearables and smartphones. While such data could transform preventative care, its integration into clinical practice is hindered by its scale, heterogeneity and the time pressure and data literacy of healthcare professionals (HCPs). We explore how large language models (LLMs) can support sensemaking of patient-generated health data (PGHD) with automated summaries and natural language data exploration. Using cardiovascular disease (CVD) risk reduction as a use case, 16 HCPs reviewed multimodal PGHD in a mixed-methods study with a prototype that integrated common charts, LLM-generated summaries, and a conversational interface. Findings show that AI summaries provided quick overviews that anchored exploration, while conversational interaction supported flexible analysis and bridged data-literacy gaps. However, HCPs raised concerns about transparency, privacy, and overreliance. We contribute empirical insights and sociotechnical design implications for integrating AI-driven summarization and conversation into clinical workflows to support PGHD sensemaking.", "AI": {"tldr": "This paper explores how large language models (LLMs) can aid healthcare professionals (HCPs) by summarizing and facilitating the exploration of patient-generated health data (PGHD) for improved clinical workflows.", "motivation": "The motivation is to address the challenges of integrating vast and diverse PGHD into clinical practice, given the time constraints and varying data literacy levels of healthcare professionals.", "method": "The study uses a prototype combining charts, LLM-generated summaries, and a conversational interface in a cardiovascular disease (CVD) risk reduction use case. Sixteen HCPs participated in a mixed-methods study to assess the approach.", "result": "AI summaries effectively provided quick overviews that supported exploration, and the conversational interface bridged data-literacy gaps. However, concerns about transparency, privacy, and overreliance on AI were raised.", "conclusion": "The study highlights the potential of LLM-driven summarization and conversational tools for addressing PGHD challenges but calls for careful design considerations, especially regarding transparency and privacy, to balance support and reliance."}}
{"id": "2602.05058", "pdf": "https://arxiv.org/pdf/2602.05058", "abs": "https://arxiv.org/abs/2602.05058", "authors": ["Aria Christensen", "Andrew Zhao"], "title": "Learning fermionic linear optics with Heisenberg scaling and physical operations", "categories": ["quant-ph", "cs.DS", "cs.LG"], "comment": "56 pages", "summary": "We revisit the problem of learning fermionic linear optics (FLO), also known as fermionic Gaussian unitaries. Given black-box query access to an unknown FLO, previous proposals required $\\widetilde{\\mathcal{O}}(n^5 / \\varepsilon^2)$ queries, where $n$ is the system size and $\\varepsilon$ is the error in diamond distance. These algorithms also use unphysical operations (i.e., violating fermionic superselection rules) and/or $n$ auxiliary modes to prepare Choi states of the FLO. In this work, we establish efficient and experimentally friendly protocols that obey superselection, use minimal ancilla (at most $1$ extra mode), and exhibit improved dependence on both parameters $n$ and $\\varepsilon$. For arbitrary (active) FLOs this algorithm makes at most $\\widetilde{\\mathcal{O}}(n^4 / \\varepsilon)$ queries, while for number-conserving (passive) FLOs we show that $\\mathcal{O}(n^3 / \\varepsilon)$ queries suffice. The complexity of the active case can be further reduced to $\\widetilde{\\mathcal{O}}(n^3 / \\varepsilon)$ at the cost of using $n$ ancilla. This marks the first FLO learning algorithm that attains Heisenberg scaling in precision. As a side result, we also demonstrate an improved copy complexity of $\\widetilde{\\mathcal{O}}(n \u03b7^2 / \\varepsilon^2)$ for time-efficient state tomography of $\u03b7$-particle Slater determinants in $\\varepsilon$ trace distance, which may be of independent interest.", "AI": {"tldr": "The paper introduces efficient algorithms for learning fermionic linear optics (FLO) with improved query complexities, optimal scaling in precision, and experimentally feasible protocols adhering to superselection rules.", "motivation": "To develop more efficient and experimentally friendly protocols for learning fermionic linear optics while addressing previous limitations in query complexity and the use of unphysical operations.", "method": "Utilizing improved algorithms requiring fewer queries and reduced ancilla modes, adhering to superselection rules, and achieving Heisenberg precision scaling for FLO learning.", "result": "Efficient protocols: FLO learning with $\\widetilde{\\mathcal{O}}(n^4 / \\varepsilon)$ queries for active FLOs, $\\mathcal{O}(n^3 / \\varepsilon)$ for passive FLOs, and advancements in state tomography complexity for Slater determinants.", "conclusion": "The proposed frameworks significantly enhance the efficiency of learning FLOs, marking advancements in precision scaling while adhering to experimental and physical constraints."}}
{"id": "2602.05062", "pdf": "https://arxiv.org/pdf/2602.05062", "abs": "https://arxiv.org/abs/2602.05062", "authors": ["Julian Killingback", "Mahta Rafiee", "Madine Manas", "Hamed Zamani"], "title": "Scaling Laws for Embedding Dimension in Information Retrieval", "categories": ["cs.IR", "cs.LG"], "comment": "9 Pages, 7 figures", "summary": "Dense retrieval, which encodes queries and documents into a single dense vector, has become the dominant neural retrieval approach due to its simplicity and compatibility with fast approximate nearest neighbor algorithms. As the tasks dense retrieval performs grow in complexity, the fundamental limitations of the underlying data structure and similarity metric -- namely vectors and inner-products -- become more apparent. Prior recent work has shown theoretical limitations inherent to single vectors and inner-products that are generally tied to the embedding dimension. Given the importance of embedding dimension for retrieval capacity, understanding how dense retrieval performance changes as embedding dimension is scaled is fundamental to building next generation retrieval models that balance effectiveness and efficiency. In this work, we conduct a comprehensive analysis of the relationship between embedding dimension and retrieval performance. Our experiments include two model families and a range of model sizes from each to construct a detailed picture of embedding scaling behavior. We find that the scaling behavior fits a power law, allowing us to derive scaling laws for performance given only embedding dimension, as well as a joint law accounting for embedding dimension and model size. Our analysis shows that for evaluation tasks aligned with the training task, performance continues to improve as embedding size increases, though with diminishing returns. For evaluation data that is less aligned with the training task, we find that performance is less predictable, with performance degrading with larger embedding dimensions for certain tasks. We hope our work provides additional insight into the limitations of embeddings and their behavior as well as offers a practical guide for selecting model and embedding dimension to achieve optimal performance with reduced storage and compute costs.", "AI": {"tldr": "The paper investigates how dense retrieval performance changes with embedding dimensions, deriving scaling laws, and providing insights into their limitations and practical model selection.", "motivation": "Dense retrieval systems face limitations with vectors and inner-products, making an understanding of how embedding dimensions impact performance crucial for advancing neural retrieval methods.", "method": "Conduct comprehensive experiments across two model families and varying model sizes to analyze the scaling behavior and relationship between embedding dimensions and retrieval performance.", "result": "Scaling laws are derived showcasing performance improvements with increased embedding size, with diminishing returns for aligned tasks and unpredictable behavior for less aligned tasks.", "conclusion": "The study offers insights into embedding limitations and provides a guide for optimizing models and embedding dimensions to balance performance, efficiency, and resource use."}}
{"id": "2602.05734", "pdf": "https://arxiv.org/pdf/2602.05734", "abs": "https://arxiv.org/abs/2602.05734", "authors": ["Niall McCarroll", "Kevin Curran", "Eugene McNamee", "Angela Clist", "Andrew Brammer"], "title": "Evaluating the impact of word embeddings on similarity scoring in practical information retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers.\n  This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.", "AI": {"tldr": "This paper evaluates query similarity using a combined approach of Word Movers Distance (WMD) and pre-trained word embeddings like GloVe, outperforming traditional models in Information Retrieval (IR).", "motivation": "Improving semantic matching in information retrieval by moving beyond traditional centroid-based neural embeddings to enhance query-response accuracy.", "method": "The study used Word Movers Distance (WMD) combined with pre-trained word embeddings, such as GloVe, to measure similarity between individual words in queries and responses.", "result": "Combining WMD with GloVe demonstrated significant accuracy improvements in ranking query-response pairs compared to other techniques like Doc2Vec and LSA.", "conclusion": "The approach enhances similarity ranking in IR systems while leveraging pre-trained, domain-agnostic word embeddings applicable across diverse use cases."}}
{"id": "2602.05120", "pdf": "https://arxiv.org/pdf/2602.05120", "abs": "https://arxiv.org/abs/2602.05120", "authors": ["Wenhao Li", "Anastasis Kratsios", "Hrad Ghoukasian", "Dennis Zvigelsky"], "title": "Certifiable Boolean Reasoning Is Universal", "categories": ["cs.CC", "cs.LG"], "comment": "Submitted to COLT 2026", "summary": "The proliferation of agentic systems has thrust the reasoning capabilities of AI into the forefront of contemporary machine learning. While it is known that there \\emph{exist} neural networks which can reason through any Boolean task $f:\\{0,1\\}^B\\to\\{0,1\\}$, in the sense that they emulate Boolean circuits with fan-in $2$ and fan-out $1$ gates, trained models have been repeatedly demonstrated to fall short of these theoretical ideals. This raises the question: \\textit{Can one exhibit a deep learning model which \\textbf{certifiably} always reasons and can \\textbf{universally} reason through any Boolean task?} Moreover, such a model should ideally require few parameters to solve simple Boolean tasks.\n  We answer this question affirmatively by exhibiting a deep learning architecture which parameterizes distributions over Boolean circuits with the guarantee that, for every parameter configuration, a sample is almost surely a valid Boolean circuit (and hence admits an intrinsic circuit-level certificate). We then prove a universality theorem: for any Boolean $f:\\{0,1\\}^B\\to\\{0,1\\}$, there exists a parameter configuration under which the sampled circuit computes $f$ with arbitrarily high probability. When $f$ is an $\\mathcal{O}(\\log B)$-junta, the required number of parameters scales linearly with the input dimension $B$.\n  Empirically, on a controlled truth-table completion benchmark aligned with our setting, the proposed architecture trains reliably and achieves high exact-match accuracy while preserving the predicted structure: every internal unit is Boolean-valued on $\\{0,1\\}^B$. Matched MLP baselines reach comparable accuracy, but only about $10\\%$ of hidden units admit a Boolean representation; i.e.\\ are two-valued over the Boolean cube.", "AI": {"tldr": "This paper introduces a deep learning architecture that can reason through any Boolean task, guaranteeing valid Boolean circuits for every parameter setting and offering universality in reasoning.", "motivation": "To address the gap between theoretical reasoning capabilities of neural networks and their practical failure to achieve Boolean reasoning universally and reliably.", "method": "They propose an architecture that parameterizes over Boolean circuits, ensuring that sampled circuits are valid and proving its universality for any Boolean function.", "result": "The architecture reliably trains, achieves high accuracy in Boolean reasoning, and maintains Boolean-valued internal units, outperforming MLPs in structural adherence.", "conclusion": "The proposed architecture enables certifiable and universal Boolean reasoning with efficient parameter usage for smaller tasks, showcasing promising empirical performance."}}
{"id": "2602.05167", "pdf": "https://arxiv.org/pdf/2602.05167", "abs": "https://arxiv.org/abs/2602.05167", "authors": ["Porhouy Minh", "Sapna Sarupria"], "title": "Path Sampling for Rare Events Boosted by Machine Learning", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech", "cs.LG", "physics.chem-ph"], "comment": "7 pages, 1 figure", "summary": "The study by Jung et al. (Jung H, Covino R, Arjun A, et al., Nat Comput Sci. 3:334-345 (2023)) introduced Artificial Intelligence for Molecular Mechanism Discovery (AIMMD), a novel sampling algorithm that integrates machine learning to enhance the efficiency of transition path sampling (TPS). By enabling on-the-fly estimation of the committor probability and simultaneously deriving a human-interpretable reaction coordinate, AIMMD offers a robust framework for elucidating the mechanistic pathways of complex molecular processes. This commentary provides a discussion and critical analysis of the core AIMMD framework, explores its recent extensions, and offers an assessment of the method's potential impact and limitations.", "AI": {"tldr": "The paper introduces AIMMD, integrating machine learning with transition path sampling, offering an efficient tool for analyzing molecular mechanisms.", "motivation": "To improve efficiency and interpretability in studying the mechanistic pathways of complex molecular processes.", "method": "Development of AIMMD, a machine learning-based algorithm for on-the-fly estimation of committor probability and reaction coordinate derivation.", "result": "AIMMD enhances the transition path sampling process by making it more efficient and providing interpretable results for molecular mechanism analysis.", "conclusion": "AIMMD represents a significant advancement in computational methods for molecular science, with notable promise and some limitations."}}
{"id": "2602.05838", "pdf": "https://arxiv.org/pdf/2602.05838", "abs": "https://arxiv.org/abs/2602.05838", "authors": ["Mayank Kumar", "Qian Lou", "Paulo Barreto", "Martine De Cock", "Sikha Pentyala"], "title": "FHAIM: Fully Homomorphic AIM For Private Synthetic Data Generation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Data is the lifeblood of AI, yet much of the most valuable data remains locked in silos due to privacy and regulations. As a result, AI remains heavily underutilized in many of the most important domains, including healthcare, education, and finance. Synthetic data generation (SDG), i.e. the generation of artificial data with a synthesizer trained on real data, offers an appealing solution to make data available while mitigating privacy concerns, however existing SDG-as-a-service workflow require data holders to trust providers with access to private data.We propose FHAIM, the first fully homomorphic encryption (FHE) framework for training a marginal-based synthetic data generator on encrypted tabular data. FHAIM adapts the widely used AIM algorithm to the FHE setting using novel FHE protocols, ensuring that the private data remains encrypted throughout and is released only with differential privacy guarantees. Our empirical analysis show that FHAIM preserves the performance of AIM while maintaining feasible runtimes.", "AI": {"tldr": "FHAIM is a framework using fully homomorphic encryption (FHE) for synthetic data generation while ensuring privacy using differential privacy guarantees.", "motivation": "The motivation is to address the challenge of unlocking valuable data trapped in silos due to privacy and regulations, particularly in key domains like healthcare, education, and finance.", "method": "The method involves proposing an FHE-based framework (FHAIM) that adapts the AIM algorithm for encrypted data. It uses FHE protocols ensuring that data remains encrypted and incorporates differential privacy protections.", "result": "FHAIM maintains the performance of AIM and achieves reasonable runtime for privacy-preserving synthetic data generation.", "conclusion": "FHAIM provides a practical solution for generating synthetic data without compromising privacy, paving the way for wider data utilization in sensitive fields."}}
{"id": "2602.05888", "pdf": "https://arxiv.org/pdf/2602.05888", "abs": "https://arxiv.org/abs/2602.05888", "authors": ["Merlin de la Haye", "Pascal Lenzner", "Farehe Soheil", "Marcus Wunderlich"], "title": "Metric Hedonic Games on the Line", "categories": ["cs.GT", "cs.AI"], "comment": "accepted at AAMAS 2026, full version", "summary": "Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible coalitions, many variants with succinct representations of the agents' utility functions have been devised and analyzed, e.g., modified fractional hedonic games by Monaco et al. [JAAMAS 2020]. We extend this by studying a novel succinct variant that is related to modified fractional hedonic games. In our model, each agent has a fixed type-value and an agent's cost for some given coalition is based on the differences between its value and those of the other members of its coalition. This allows to model natural situations like athletes forming training groups with similar performance levels or voters that partition themselves along a political spectrum.\n  In particular, we investigate natural variants where an agent's cost is defined by distance thresholds, or by the maximum or average value difference to the other agents in its coalition. For these settings, we study the existence of stable coalition structures, their properties, and their quality in terms of the price of anarchy and the price of stability. Further, we investigate the impact of limiting the maximum number of coalitions. Despite the simple setting with metric distances on a line, we uncover a rich landscape of models, partially with counter-intuitive behavior. Also, our focus on both swap stability and jump stability allows us to study the influence of fixing the number and the size of the coalitions. Overall, we find that stable coalition structures always exist but that their properties and quality can vary widely.", "AI": {"tldr": "The paper studies a novel variant of hedonic games focusing on coalition formation based on agents' type-values and differences within coalitions, analyzing stability, properties, and metrics like price of anarchy and stability.", "motivation": "To investigate coalition formation among agents using a simpler metric-based model and address scenarios like athletes forming similar training groups or voters partitioning by ideology.", "method": "The paper introduces a model based on agents' type-values, uses distance thresholds, maximum or average value differences, explores stability concepts, and examines coalition limitations.", "result": "Stable coalition structures are proven to exist, but their properties, quality, and behavior vary significantly with different models and limitations.", "conclusion": "The study uncovers a rich landscape of coalition formation mechanisms, showcasing varied stability and quality, providing insights into strategic group formations."}}
{"id": "2602.05930", "pdf": "https://arxiv.org/pdf/2602.05930", "abs": "https://arxiv.org/abs/2602.05930", "authors": ["Samar Ansari"], "title": "Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025", "categories": ["cs.DL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in academic writing workflows, yet they frequently hallucinate by generating citations to sources that do not exist. This study analyzes 100 AI-generated hallucinated citations that appeared in papers accepted by the 2025 Conference on Neural Information Processing Systems (NeurIPS), one of the world's most prestigious AI conferences. Despite review by 3-5 expert researchers per paper, these fabricated citations evaded detection, appearing in 53 published papers (approx. 1% of all accepted papers). We develop a five-category taxonomy that classifies hallucinations by their failure mode: Total Fabrication (66%), Partial Attribute Corruption (27%), Identifier Hijacking (4%), Placeholder Hallucination (2%), and Semantic Hallucination (1%). Our analysis reveals a critical finding: every hallucination (100%) exhibited compound failure modes. The distribution of secondary characteristics was dominated by Semantic Hallucination (63%) and Identifier Hijacking (29%), which often appeared alongside Total Fabrication to create a veneer of plausibility and false verifiability. These compound structures exploit multiple verification heuristics simultaneously, explaining why peer review fails to detect them. The distribution exhibits a bimodal pattern: 92% of contaminated papers contain 1-2 hallucinations (minimal AI use) while 8% contain 4-13 hallucinations (heavy reliance). These findings demonstrate that current peer review processes do not include effective citation verification and that the problem extends beyond NeurIPS to other major conferences, government reports, and professional consulting. We propose mandatory automated citation verification at submission as an implementable solution to prevent fabricated citations from becoming normalized in scientific literature.", "AI": {"tldr": "The study identifies and categorizes 100 AI-generated hallucinated citations found in NeurIPS 2025 publications, demonstrating flaws in peer review processes and proposing automated citation checks to mitigate such errors.", "motivation": "To address the issue of fabricated citations generated by large language models, which are increasingly integrated into academic workflows but pose risks of false information dissemination.", "method": "Analyzed 100 hallucinated citations from NeurIPS 2025 papers, developed a taxonomy with five failure categories, and examined the compound failure modes and distribution patterns of these hallucinations.", "result": "53 published NeurIPS 2025 papers contained fabricated citations (1% of accepted papers). 100% of hallucinations showed compound failure modes, and bimodal distribution characteristics revealed varying degrees of AI reliance.", "conclusion": "Current peer review processes are inadequate at detecting AI hallucinated citations, requiring mandatory automated verification systems to prevent normalization of these fabrications in scientific literature."}}
{"id": "2602.05965", "pdf": "https://arxiv.org/pdf/2602.05965", "abs": "https://arxiv.org/abs/2602.05965", "authors": ["Joseph Fioresi", "Parth Parag Kulkarni", "Ashmal Vayani", "Song Wang", "Mubarak Shah"], "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently reason about similar sub-problems or execute analogous steps, they repeatedly perform substantial overlapping computation. To address these limitations, in this paper, we propose Learning to Share (LTS), a learned shared-memory mechanism for parallel agentic frameworks that enables selective cross-team information reuse while controlling context growth. LTS introduces a global memory bank accessible to all teams and a lightweight controller that decides whether intermediate agent steps should be added to memory or not. The controller is trained using stepwise reinforcement learning with usage-aware credit assignment, allowing it to identify information that is globally useful across parallel executions. Experiments on the AssistantBench and GAIA benchmarks show that LTS significantly reduces overall runtime while matching or improving task performance compared to memory-free parallel baselines, demonstrating that learned memory admission is an effective strategy for improving the efficiency of parallel agentic systems. Project page: https://joefioresi718.github.io/LTS_webpage/", "AI": {"tldr": "The paper introduces 'Learning to Share' (LTS), a shared-memory mechanism designed to improve computational efficiency in multi-agent systems by enabling selective information reuse across parallel agent teams.", "motivation": "Parallel agent teams often perform overlapping computations when solving similar sub-problems, leading to high computational costs. The motivation is to address this inefficiency by introducing a mechanism that allows efficient sharing and reuse of intermediate results across teams.", "method": "LTS uses a global memory bank and a lightweight controller trained with stepwise reinforcement learning to decide which intermediate steps to store or share, enabling selective knowledge reuse.", "result": "Experiments on benchmarks show that LTS reduces runtime while maintaining or improving task performance compared to baselines without shared memory.", "conclusion": "Learned memory admission through LTS is an effective approach for enhancing the efficiency and robustness of parallel agentic systems."}}
{"id": "2602.05541", "pdf": "https://arxiv.org/pdf/2602.05541", "abs": "https://arxiv.org/abs/2602.05541", "authors": ["Jiaqi Yao", "Ding Liu"], "title": "Reducing the Complexity of Matrix Multiplication to $O(N^2log_2N)$ by an Asymptotically Optimal Quantum Algorithm", "categories": ["quant-ph", "cs.CC", "cs.LG"], "comment": null, "summary": "Matrix multiplication is a fundamental classical computing operation whose efficiency becomes a major challenge at scale, especially for machine learning applications. Quantum computing, with its inherent parallelism and exponential storage capacity, offers a potential solution to these limitations. This work presents a quantum kernel-based matrix multiplication algorithm (QKMM) that achieves an asymptotically optimal computational complexity of $ O(N^2 \\log_2 N) $, outperforming the classical optimal complexity of $ O(N^{2.371552}) $, where $N$ denotes the matrix dimension. Through noiseless and noisy quantum simulation experiments, we demonstrate that the proposed algorithm not only exhibits superior theoretical efficiency but also shows practical advantages in runtime performance and stability.", "AI": {"tldr": "The paper introduces a quantum kernel-based matrix multiplication algorithm (QKMM) achieving computational complexity of O(N^2 log2 N), improving over classical matrix multiplication.", "motivation": "Address the inefficiencies and scaling challenges of classical matrix multiplication, especially for machine learning, by leveraging quantum computing.", "method": "Proposed the QKMM algorithm leveraging quantum parallelism and quantum kernel techniques, validated via noiseless and noisy quantum simulations.", "result": "The algorithm achieves theoretical superiority with O(N^2 log2 N) complexity, better runtime performance, and stability, as demonstrated in simulations.", "conclusion": "Quantum computing can improve matrix multiplication efficiency, both theoretically and practically, compared to classical approaches."}}
{"id": "2602.05591", "pdf": "https://arxiv.org/pdf/2602.05591", "abs": "https://arxiv.org/abs/2602.05591", "authors": ["Chin Pang Ho", "Marek Petrik", "Wolfram Wiesemann"], "title": "Efficient Algorithms for Robust Markov Decision Processes with $s$-Rectangular Ambiguity Sets", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Robust Markov decision processes (MDPs) have attracted significant interest due to their ability to protect MDPs from poor out-of-sample performance in the presence of ambiguity. In contrast to classical MDPs, which account for stochasticity by modeling the dynamics through a stochastic process with a known transition kernel, a robust MDP additionally accounts for ambiguity by optimizing against the most adverse transition kernel from an ambiguity set constructed via historical data. In this paper, we develop a unified solution framework for a broad class of robust MDPs with $s$-rectangular ambiguity sets, where the most adverse transition probabilities are considered independently for each state. Using our algorithms, we show that $s$-rectangular robust MDPs with $1$- and $2$-norm as well as $\u03c6$-divergence ambiguity sets can be solved several orders of magnitude faster than with state-of-the-art commercial solvers, and often only a logarithmic factor slower than classical MDPs. We demonstrate the favorable scaling properties of our algorithms on a range of synthetically generated as well as standard benchmark instances.", "AI": {"tldr": "The paper introduces a fast and unified framework to solve robust Markov Decision Processes (MDPs) with $s$-rectangular ambiguity sets, improving computational efficiency significantly.", "motivation": "Classical Markov Decision Processes may fail under ambiguity due to reliance on a known transition kernel. This paper aims to address this limitation by optimizing for robust MDPs using ambiguity sets derived from historical data.", "method": "The authors propose a new solution framework for robust MDPs with $s$-rectangular ambiguity sets. They focus on computational efficiency and utilize algorithms to handle specific ambiguity set types efficiently, such as those based on $1$- and $2$-norm or $\u03c6$-divergence.", "result": "Their framework achieves computation speeds several orders of magnitude faster than commercial solvers and approaches classical MDP speed levels. Experiments demonstrate scalability on synthetic and benchmark datasets.", "conclusion": "The proposed algorithms substantially improve on existing approaches for solving robust MDPs, offering both efficiency and scalability advantages. This framework has potential applications where robust decision-making is critical."}}
{"id": "2602.05644", "pdf": "https://arxiv.org/pdf/2602.05644", "abs": "https://arxiv.org/abs/2602.05644", "authors": ["Zhang Hengyu", "Maryam Cheraghy", "Liu Wei", "Armin Farhadi", "Meysam Soltanpour", "Zhong Zhuoqing"], "title": "UAV Trajectory Optimization via Improved Noisy Deep Q-Network", "categories": ["eess.SY", "cs.LG"], "comment": null, "summary": "This paper proposes an Improved Noisy Deep Q-Network (Noisy DQN) to enhance the exploration and stability of Unmanned Aerial Vehicle (UAV) when applying deep reinforcement learning in simulated environments. This method enhances the exploration ability by combining the residual NoisyLinear layer with an adaptive noise scheduling mechanism, while improving training stability through smooth loss and soft target network updates. Experiments show that the proposed model achieves faster convergence and up to $+40$ higher rewards compared to standard DQN and quickly reach to the minimum number of steps required for the task 28 in the 15 * 15 grid navigation environment set up. The results show that our comprehensive improvements to the network structure of NoisyNet, exploration control, and training stability contribute to enhancing the efficiency and reliability of deep Q-learning.", "AI": {"tldr": "This paper proposes enhancements to Noisy DQN for better UAV exploration and stability in simulated environments.", "motivation": "To improve exploration and training stability in applying deep reinforcement learning for UAV navigation in simulated environments.", "method": "Uses a residual NoisyLinear layer with adaptive noise scheduling for exploration, smooth loss functions, and soft target network updates for stability.", "result": "Achieved faster training convergence, higher rewards (+40 compared to standard DQN), and optimized navigation in a 15x15 grid environment.", "conclusion": "Improved Noisy DQN enhances the efficiency and reliability of deep Q-learning for UAV navigation tasks."}}
{"id": "2602.05702", "pdf": "https://arxiv.org/pdf/2602.05702", "abs": "https://arxiv.org/abs/2602.05702", "authors": ["Max Gro\u00dfmann", "Malte Grunert", "Erich Runge"], "title": "Broken neural scaling laws in materials science", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "In materials science, data are scarce and expensive to generate, whether computationally or experimentally. Therefore, it is crucial to identify how model performance scales with dataset size and model capacity to distinguish between data- and model-limited regimes. Neural scaling laws provide a framework for quantifying this behavior and guide the design of materials datasets and machine learning architectures. Here, we investigate neural scaling laws for a paradigmatic materials science task: predicting the dielectric function of metals, a high-dimensional response that governs how solids interact with light. Using over 200,000 dielectric functions from high-throughput ab initio calculations, we study two multi-objective graph neural networks trained to predict the frequency-dependent complex interband dielectric function and the Drude frequency. We observe broken neural scaling laws with respect to dataset size, whereas scaling with the number of model parameters follows a simple power law that rapidly saturates.", "AI": {"tldr": "The paper explores neural scaling laws in materials science for predicting metals' dielectric functions using graph neural networks, revealing broken scaling with dataset size but consistent scaling with model parameters.", "motivation": "Materials science faces limitations due to scarce and expensive data generation. Understanding how model performance scales with dataset size and capacity helps optimize resources and guide better dataset and model design.", "method": "The study uses over 200,000 dielectric functions derived from high-throughput ab initio calculations and trains two multi-objective graph neural networks to predict frequency-dependent dielectric functions and Drude frequency.", "result": "Neural scaling laws show broken behavior with dataset size but adhere to a predictable pattern (power law) regarding the number of model parameters, saturating quickly.", "conclusion": "Scaling law analysis provides insights into optimizing model and dataset designs for materials science applications, highlighting the need for strategizing around data scarcity and model limits."}}
{"id": "2602.05767", "pdf": "https://arxiv.org/pdf/2602.05767", "abs": "https://arxiv.org/abs/2602.05767", "authors": ["Kainan Liu", "Jingyu Huang", "Guihong Huang", "Jianyi Luo"], "title": "PMT Waveform Simulation and Reconstruction with Conditional Diffusion Network", "categories": ["hep-ex", "cs.LG"], "comment": null, "summary": "Photomultiplier tubes (PMTs) are widely employed in particle and nuclear physics experiments. The accuracy of PMT waveform reconstruction directly impacts the detector's spatial and energy resolution. A key challenge arises when multiple photons arrive within a few nanoseconds, making it difficult to resolve individual photoelectrons (PEs). Although supervised deep learning methods have surpassed traditional methods in performance, their practical applicability is limited by the lack of ground-truth PE labels in real data. To address this issue, we propose an innovative weakly supervised waveform simulation and reconstruction approach based on a bidirectional conditional diffusion network framework. The method is fully data-driven and requires only raw waveforms and coarse estimates of PE information as input. It first employs a PE-conditioned diffusion model to simulate realistic waveforms from PE sequences, thereby learning the features of overlapping waveforms. Subsequently, these simulated waveforms are used to train a waveform-conditioned diffusion model to reconstruct the PE sequences from waveforms, reinforcing the learning of features of overlapping waveforms. Through iterative refinement between the two conditional diffusion processes, the model progressively improves reconstruction accuracy. Experimental results demonstrate that the proposed method achieves 99% of the normalized PE-number resolution averaged over 1-5 p.e. and 80% of the timing resolution attained by fully supervised learning.", "AI": {"tldr": "The paper introduces a weakly supervised method using a bidirectional conditional diffusion network for accurate PMT waveform reconstruction, addressing photon overlap challenges without requiring ground-truth labels.", "motivation": "The motivation is to improve the accuracy of PMT waveform reconstruction while overcoming the challenge of resolving overlapping photoelectrons in the absence of ground-truth labels.", "method": "The method employs a bidirectional conditional diffusion framework, sequentially using a PE-conditioned diffusion model for waveform simulation and a waveform-conditioned diffusion model for PE sequence reconstruction. These models iteratively refine their accuracy.", "result": "The proposed method achieves 99% of normalized PE-number resolution and 80% of the timing resolution compared to fully supervised methods.", "conclusion": "This approach demonstrates the efficacy of weakly supervised learning in resolving overlapping waveforms, making it highly promising for PMT-based experiments."}}
{"id": "2602.05817", "pdf": "https://arxiv.org/pdf/2602.05817", "abs": "https://arxiv.org/abs/2602.05817", "authors": ["Enrique Feito-Casares", "Francisco M. Melgarejo-Meseguer", "Elena Casiraghi", "Giorgio Valentini", "Jos\u00e9-Luis Rojo-\u00c1lvarez"], "title": "Interpreting Manifolds and Graph Neural Embeddings from Internet of Things Traffic Flows", "categories": ["cs.CR", "cs.LG", "cs.NI"], "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) ecosystems has led to increasingly complex and heterogeneous network topologies. Traditional network monitoring and visualization tools rely on aggregated metrics or static representations, which fail to capture the evolving relationships and structural dependencies between devices. Although Graph Neural Networks (GNNs) offer a powerful way to learn from relational data, their internal representations often remain opaque and difficult to interpret for security-critical operations. Consequently, this work introduces an interpretable pipeline that generates directly visualizable low-dimensional representations by mapping high-dimensional embeddings onto a latent manifold. This projection enables the interpretable monitoring and interoperability of evolving network states, while integrated feature attribution techniques decode the specific characteristics shaping the manifold structure. The framework achieves a classification F1-score of 0.830 for intrusion detection while also highlighting phenomena such as concept drift. Ultimately, the presented approach bridges the gap between high-dimensional GNN embeddings and human-understandable network behavior, offering new insights for network administrators and security analysts.", "AI": {"tldr": "The paper presents an interpretable framework using Graph Neural Networks (GNNs) for monitoring complex IoT network states and achieves effective intrusion detection with enhanced human interpretability.", "motivation": "Traditional network monitoring tools are insufficient for capturing the evolving relationships and dependencies in IoT networks, necessitating a more interpretable and dynamic solution.", "method": "The proposed pipeline maps high-dimensional GNN embeddings onto a visualizable latent manifold, integrates feature attribution techniques, and enables interpretable monitoring of network states.", "result": "The framework achieves a classification F1-score of 0.830 for intrusion detection and effectively identifies phenomena like concept drift in IoT ecosystems.", "conclusion": "This work bridges the gap between complex GNN embeddings and human-interpretable data, providing actionable insights for network administrators and enhancing security monitoring."}}
{"id": "2602.05898", "pdf": "https://arxiv.org/pdf/2602.05898", "abs": "https://arxiv.org/abs/2602.05898", "authors": ["Mihriban Ceylan", "Anna P. Kwossek", "David J. Pr\u00f6mel"], "title": "Universal approximation with signatures of non-geometric rough paths", "categories": ["math.PR", "cs.LG", "q-fin.MF"], "comment": null, "summary": "We establish a universal approximation theorem for signatures of rough paths that are not necessarily weakly geometric. By extending the path with time and its rough path bracket terms, we prove that linear functionals of the signature of the resulting rough paths approximate continuous functionals on rough path spaces uniformly on compact sets. Moreover, we construct the signature of a path extended by its pathwise quadratic variation terms based on general pathwise stochastic integration \u00e0 la F\u00f6llmer, in particular, allowing for pathwise It\u00f4, Stratonovich, and backward It\u00f4 integration. In a probabilistic setting, we obtain a universal approximation result for linear functionals of the signature of continuous semimartingales extended by the quadratic variation terms, defined via stochastic It\u00f4 integration. Numerical examples illustrate the use of signatures when the path is extended by time and quadratic variation in the context of model calibration and option pricing in mathematical finance.", "AI": {"tldr": "The paper extends the universal approximation theorem for rough path signatures, including non-weakly geometric paths, applying compact uniform approximations for continuous functionals. It explores their applications to stochastic integration and financial modeling.", "motivation": "To generalize the universal approximation theorem for rough path signatures, addressing both weakly and non-weakly geometric paths, and to explore new applications in finance through extended paths.", "method": "The approach extends the path space by adding time and quadratic variation terms. It builds on rough path and stochastic integration techniques, enabling probabilistic interpretations and practical applications.", "result": "The paper proves that signatures of extended rough paths can universally approximate functionals on compact spaces. It demonstrates the importance of time and quadratic variations in stochastic contexts, applying results to finance.", "conclusion": "By extending paths with time and quadratic variation, the paper broadens the scope of signature approximation theorems and highlights potential applications in stochastic processes and financial mathematics."}}
{"id": "2602.06030", "pdf": "https://arxiv.org/pdf/2602.06030", "abs": "https://arxiv.org/abs/2602.06030", "authors": ["Kavana Venkatesh", "Yinhan He", "Jundong Li", "Jiaming Cui"], "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling", "categories": ["cs.MA", "cs.LG"], "comment": null, "summary": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.", "AI": {"tldr": "This paper proposes PhysicsAgentABM, a hybrid agent-based modeling system that combines symbolic, neural, and LLM-driven techniques for scalable and calibrated simulations.", "motivation": "The authors aim to address limitations of existing agent-based modeling approaches: LLM-based systems (expensive and poorly aligned to specific simulations) and classical ABMs (limited individual-level flexibility and dynamics).", "method": "They developed PhysicsAgentABM with behaviorally coherent agent clusters comprising symbolic agents, a neural transition model, and an uncertainty-aware epistemic fusion. They also introduced ANCHOR for LLM-informed clustering to reduce computational costs.", "result": "Experiments demonstrate the framework's improved accuracy and calibration in public health, finance, and social science domains, outperforming various baselines.", "conclusion": "PhysicsAgentABM successfully bridges the gap between classical ABMs and LLM-based systems, offering scalable simulations with enhanced calibration and reduced computational costs."}}
